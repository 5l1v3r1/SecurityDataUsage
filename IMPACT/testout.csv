reason,type,keyWord,,
To evaluate network anomaly detection system,evaluation, evaluat,,
The data will be used to evaluate a SDN-based scanning detection framework for research purpose,evaluation, evaluat,,
"Hi, We are designing an anomaly detection system (on the victim side) for NIST. We are evaluating and analyzing the behavior of various attacks (DDoS, worms, etc.) for our research. This dataset will be used to capture the behavior of malicious traffic that are identified by firewalls and applications.Thanks!Best,Kang-Hao Peng",evaluation, evaluat,,
"Hi, We are designing an anomaly detection system for NIST. We need this dataset to evaluate and analyze the behavior of interior attacks for our research.Thanks!Kang-Hao Peng",evaluation, evaluat,,
"Hi, We are designing an anomaly detection system (on the victim side) for NIST. We need this dataset to evaluate and analyze the behavior of DDoS attacks for our research. Thanks!Kang-Hao Peng",evaluation, evaluat,,
"Hi, We are designing an anomaly detection system (on the victim side) for NIST. We need this dataset to evaluate and analyze the behavior of various attacks (DDoS, worms, etc.) for our research. Thanks!Kang-Hao Peng",evaluation, evaluat,,
We are evaluating a Bayesean network approach to detecting and characterizing DDoS attacks as part of a DHS-funded project.  This will be one of several data sets used in the evaluation.,evaluation, evaluat,,
"Need to evaluate new approaches for DoS resilient clouds, mainly focusing on TCP SYN floods. For that, first I need to understand how SYN flood attacks take place and progress over time. I will use the data set to identify characteristics that are specific to SYN floods, as well as evaluate any approach that I come up with. ",evaluation, evaluat,,
Need to create a realistic topology for evaluation of wide area network protocols for CPS,evaluation, evaluat,,
Need to evaluate the effectiveness of a DoS defense system against the DNS attack ,evaluation, evaluat,,
"We want to evaluate if SDN technologies can leverage many malicious scanning activities to help mitigate DoS and other attacks over a whole network rather than any single host, thanks!",evaluation, evaluat,,
We would like to use this dataset to evaluate our blacklisting approach ,evaluation, evaluat,,
To evaluate a botnet behavior model for research purposes,evaluation, evaluat,,
To evaluate our proposed botnet behavior model for research purposes,evaluation, evaluat,,
"The goal of our research is to develop screening and anomaly detection methods for private data.  Employing methods such as group testing, active learning, and sequential hypothesis testing, our objective is to be able to detect anomalous points in data sets while protecting privacy of non-anomalous individuals.  We will explore the performance of different methods of anomalous point detection in the context of both finding anomalies and protecting privacy with the goal of evaluating how well the techniques perform and what contexts differential private algorithms can be used.The requested data set will provide real data for performing anomalous point detection.  Using it, we will be able to perform tests for Denial of Service attacks while attempting to protect privacy by limiting examinations of legitimate packets.  This data set will provide a benchmark for testing our various detection methods.",evaluation, evaluat,,
"In this project, we propose to integrate monitor capabilities into the software switches (OpenvSwitch) that support OpenFlow protocol. The proposed framework should be able to provide flexible and scalable monitoring functions for security applications running on the SDN control platform. As a result, to evaluate the performance and accuracy of our proposed architecture, we need traffic traces with verified attacks, which are provided by Skaion Dataset.",evaluation, evaluat,,
"This data will potentially be used as part of a research project to discover correlations between malicious activities and real-world events. The goal for this project is to discover trends in the volume of traffic that correlate to physical events taking place around the world. One of the primary objectives is to first find a suitable dataset to conduct analysis on. As such, the first step will be to evaluate the suitability of the GT Malware data to see if the data can be included in the study. If the data is found to be suitable, further analysis will be performed as part of this research project. The project is being undertaken as part of a Syracuse University program of instruction (IST 687: Data Science).",evaluation, evaluat,,
"I would like to use this data for two projects. First, to research techniques to replay traffic inside of simulated environments such as mininet. The goal in this research is to derive behavioral parameters that host agents in mininet can use to generate traffic without having to replay exact traces.Second, as a test workload for our switch-level OpenFlow security platform. In this project, we will replay the data through our testbed network to evaluate the performance of our system. ",evaluation, evaluat,,
"Component One: Data collection and preparation We will utilize the data repository provided by the PREDICT (Protected Repository for the Defense of Infrastructure Against Cyber Threats) [PREDICT14]. Students will acquire access to the Synthetically Generated Data which are generated in a synthetic environment, where benign user activity and malicious attacks are emulated by computer programs. This data includes full network packets, firewall logs, application logs, and malicious attacks. The students will use two subcategories of datasets: (1) Synthetic Cyber Exercise Data which represents traffic from a cyber-defense competition based on a typical small company network configuration of 50+ users, 7-10 servers, and common Internet services such as web server, mail server, and e-commerce site. Traffic generators continuously feed simulated user traffic into the network as users handle business requests and detect and respond to threats.(2) Synthetic Mixed Traffic from Scalable Network Monitoring Program, which include synthetic HTTP, SMTP, and DNS background data. The attacks are large scale network attacks including DNS worms, http worms, and DDoS attacks. The worms and DDoS attacks have been parameterized to exhibit various propagation characteristics. The students will understand the data format, structure, and domain knowledge. They will pre-process the collected data to make them available for further analysis, for example, turning strings of text into information that can be indexed, stored, managed and searched automatically. Component Two: Real-time security assessment Students will process and analyze the collected security data from PREDICT, such as network packets, firewall logs, application logs, etc. for security assessment intelligence processing for the network. The students will combine network traffic and logs from multiple sources and correlate events together to create real-time alerts of abnormal traffic such as distributed denial of service attack, port scans, or worm outbreaks. Catching a hacker and being able to stop them while the attack is taking place is more useful than being able to use forensics to piece together an attack that already took place. The students will apply statistical methods and data mining techniques to analyze the datasets. The real-time evaluation requires fast data retrieval, fast storage, fast processing, and fast reporting. The students will investigate the possibility of improving process speed for big data processing and analysis through optimization, parallel computing, as well as utilizing tools such as Hadoop and MapReuce for BDA, etc. Component Three: Managing and reporting results The students will develop a software system ÃƒÂ¢Ã‚â‚¬Ã‚Å“Real-time Security Assessment DashboardÃƒÂ¢Ã‚â‚¬Ã‚Âù for system administrators or security analysts to monitor the real-time security assessment results and alerts using a component-based development method. This component provides a graphic user interface for the user to see interactive reports and visualizations of security assessment results. The students will investigate how to best communicate the data analysis results to the user to support intelligent decision making to protect the security of the network. Description: Students will utilize the data repository provided by the PREDICT This course will scrutinize, evaluate and utilize data repository provided by PREDICT (Protected Repository of the Defense of Infrastructure against Cyber threats). From the website: www.predict.org. Also PREDICT provides qualified evaluators and developers with continually updated network operation data that they are able to utilize in their cyber security research. This course will enable students to understand the data format, structure, and domain knowledge.",evaluation, evaluat,,
"Determining connectivity of large cloud service providers, such as Amazon AWS, via traceroutes to hitlist IPs. The history will be used to evaluate traceroute effectiveness.",evaluation, evaluat,,
"We want to write an article according to ""http://www.ucs.louisiana.edu/~met4671/publications/ifip2012-tozal.pdf"" In this paper, Dr. Tozal have proposed a framework for sampling subnets in the Internet with using some statistical properties of subnets with 6 different ISP. We want to increase this job entire internet. First we will match IP to AS and take random %10 IP addresses from each AS. With using exploreNET tool, we will find subnet of each IP addresses. After we will make apply same statistical approaches and evaluate data. According to our evaluation, we want to show that our sampling approach is also work well at entire internet.I want this dataset because of IP to AS matching and after that take sample and use estimator. I need data for evaluation part of this work.",evaluation, evaluat,,
"We plan to develop visualization tools to analyze network security data including IDS, firewall, netflow, etc. The data requested may be useful when we evaluate the effectiveness of developed visualization too.",evaluation, evaluat,,
"Component One: Data collection and preparationWe will utilize the data repository provided by the PREDICT (Protected Repository for the Defense of Infrastructure Against Cyber Threats) [PREDICT14]. Students will acquire access to the Synthetically Generated Data which are generated in a synthetic environment, where benign user activity and malicious attacks are emulated by computer programs. This data includes full network packets, firewall logs, application logs, and malicious attacks. The students will use two subcategories of datasets: (1) Synthetic Cyber Exercise Data which represents traffic from a cyber-defense competition based on a typical small company network configuration of 50+ users, 7-10 servers, and common Internet services such as web server, mail server, and e-commerce site. Traffic generators continuously feed simulated user traffic into the network as users handle business requests and detect and respond to threats.(2) Synthetic Mixed Traffic from Scalable Network Monitoring Program, which include synthetic HTTP, SMTP, and DNS background data. The attacks are large scale network attacks including DNS worms, http worms, and DDoS attacks. The worms and DDoS attacks have been parameterized to exhibit various propagation characteristics. The students will understand the data format, structure, and domain knowledge. They will pre-process the collected data to make them available for further analysis, for example, turning strings of text into information that can be indexed, stored, managed and searched automatically. Component Two: Real-time security assessmentStudents will process and analyze the collected security data from PREDICT, such as network packets, firewall logs, application logs, etc. for security assessment intelligence processing for the network. The students will combine network traffic and logs from multiple sources and correlate events together to create real-time alerts of abnormal traffic such as distributed denial of service attack, port scans, or worm outbreaks. Catching a hacker and being able to stop them while the attack is taking place is more useful than being able to use forensics to piece together an attack that already took place. The students will apply statistical methods and data mining techniques to analyze the datasets. The real-time evaluation requires fast data retrieval, fast storage, fast processing, and fast reporting. The students will investigate the possibility of improving process speed for big data processing and analysis through optimization, parallel computing, as well as utilizing tools such as Hadoop and MapReuce for BDA, etc. Component Three: Managing and reporting resultsThe students will develop a software system ÃƒÂ¢Ã‚â‚¬Ã‚Å“Real-time Security Assessment DashboardÃƒÂ¢Ã‚â‚¬Ã‚Âù for system administrators or security analysts to monitor the real-time security assessment results and alerts using a component-based development method. This component provides a graphic user interface for the user to see interactive reports and visualizations of security assessment results. The students will investigate how to best communicate the data analysis results to the user to support intelligent decision making to protect the security of the network. Description: Students will utilize the data repository provided by the PREDICT This course will scrutinize, evaluate and utilize data repository provided by PREDICT (Protected Repository of the Defense of Infrastructure against Cyber threats). From the website: www.predict.org. Also PREDICT provides qualified evaluators and developers with continually updated network operation data that they are able to utilize in their cyber security research. This course will enable students to understand the data format, structure, and domain knowledge. Students will acquire access to the Synthetically Generated Data which are generated in a synthetic environment, where benign user activity and malicious attacks are emulated by computer programs. Data mi",evaluation, evaluat,,
The purpose of this data set in our research is to stress test our detection algorithm. This will help us evaluate the performance of our proposed algorithm. ,evaluation, evaluat,,
"Research project: Cross-domain collaborative intrusion detection. Proposed use: Evaluating techniques to improve IDS accuracy via automated data sharing.",evaluation, evaluat,,
"I have developed a new data-mining based intrusion detection system to trigger alarms when the detected networking behavior deviates significantly from an expected normal model built for data. The new system is capable of not only distinguishing between normal and anomalous network traffic but also identifying different types of anomalous network traffic.I plan to use this dataset to evaluate the performance of the system.",evaluation, evaluat,,
"We are investigating algorithms on detecting early signs of cyber security through behavior modeling.We will use the Skaion data set to develop and evaluate the algorithm.The data will not be disclosed in any means.",evaluation, evaluat,,
Our current research is focusing on the development of adaptive neural-based models that will be capable of identifying new forms of attacks based on previously observed attack sequences. The requested dataset would be used to train and evaluate our existing models and guide the development of more effective models.,evaluation, evaluat,,
Our current research is focusing on the development of adaptive neural-based models that will be capable of identifying new forms of attacks based on previously observed attack sequences.  The requested dataset would be used to train and evaluate our existing models and guide the development of more effective models.,evaluation, evaluat,,
"We have been conducting intrusion analysis research based on a research prototype tool called SnIPS developed at Kansas State University. We need data with mixed attack and benign traffic with documented ground truth to evaluate our methodologies. So far the only publicly available dataset of this nature is LL DARPA IDS evaluation dataset. The conclusions one can draw from evaluating on a single dataset is limited and we need to run our tool on other datasets to understand the effectiveness and generality of the methods. Relevant publications of the research can be found at:http://people.cis.ksu.edu/~xou/publications.htmlPublications #3,#5,#9 describe this research.Prioritizing intrusion analysis using dempster-shafer theory. Loai Zomlot, Sathya Chandran Sundaramurthy, Kui Luo, Xinming Ou, and S. Raj Rajagopalan. To appear in 4TH ACM Workshop on Artificial Intelligence and Security (AISec), Chicago, USA, Oct. 2011.Practical IDS alert correlation in the face of dynamic threats. Sathya Chandran Sundaramurthy, Loai Zomlot, and Xinming Ou. In The 2011 International Conference on Security and Management (SAM'11), Las Vegas, USA, July 2011. An empirical approach to modeling uncertainty in intrusion analysis. Xinming Ou, S. Raj Rajagopalan, and Sakthiyuvaraja Sakthivelmurugan. Annual Computer Security Applications Conference (ACSAC), Honolulu, Hawaii, USA, Dec 2009.If additional information is needed, please do not hesitate to contact me.Thanks,-Simon",evaluation, evaluat,,
"Network traffic modeling and anonymization research. Seeking packet data from diverse sources. Per Email 3-24/2011: The Columbia University Intrusion Detection Systems Lab is engaging in research in network data anonymization. We aim to develop machine learning algorithms which match hosts to groups of other hosts based on statistical profiles for their ""behavior."" By intermixing traffic from groups of similarly-behaving hosts, and assigning group identities, we aim to develop novel anonymization methodologies that provide anonymity to individual hosts within groups. Towards this end we are collecting packet-capture and netflow datasets from a variety of sources. We are looking for datasets that contain network traffic for a large amount of hosts, with long durations. We aim to extract behavior profiles from these hosts and evaluate our algorithms by splitting the dataset into train/test subsets, aiming to match the testing sub-flows with the training flows. We are not targeting USC data specifically, however, the description of the LANDERS dataset seem to match our desired properties in the data.Network traffic modeling and anonymization research. Seeking packet data from diverse sources. ",evaluation, evaluat,still evaluate,
Need to compare the results of network events identified by our passive measurement technique with the active probing outages for my PhD thesis research. My research focus is on using passive measurements to identify threats and events in the Internet.,thesis, thesis,,
"I am requesting this information to compare current locations of fiber optic cables with historical locations of Crude Oil Pipelines in Pennsylvania. This is related to my current PhD work at UCSC. My PhD program (Film and Digital Media) is a praxis based program; my work amounts to theoretical and critical analysis, as well as practice based visual work. Thank you.",thesis, phd,,
We aim to design protocols for encrypted and distributed computation of aggregate network statistics. Network security such as anomaly detection can be benefited if several data owners can aggregate their private data to jointly perform a computation. Our goal is to exploit secure multi-party computation (MPC) techniques to enable encrypted and distributed computation of aggregate network information. This project forms an important part of my PhD-thesis research and getting access to real-world datasets will significantly benefit my research.,thesis, phd,,
"hiI'm a Ph.D. candidate at Rensselaer polytechnic institute and my research is in anomaly detection to identify cyber threats in large networks. This work can greatly benefit from this dataset, and I appreciate you making it available to the research community. Thanks.",thesis, ph.d,,
Trying to develop a distributed collaborative method for detecting the DDoS attacks. Will analyze the features from the trace file to see whether a set of features can be extracted. PhD-thesis research  ,thesis, phd,,
To evaluate approaches to path prediction for my phd-thesis research,thesis, phd,evaluation, evaluat
Need sample dataset to compare with my user modelling framework for my master thesis.,thesis, thesis,,
Need to learn and perform graph based data analysis in cyber security domain for my Master's thesis. ,thesis, thesis,,
Evaluate new approaches using tensor decomposition for attributing cyberthreats to virtual actors for Astrolavos Lab's Ph.D. students,thesis, ph.d,,
Need to learn and perform graph based data analysis in cyber security domain for my Master's thesis.,thesis, thesis,,
I need this dataset to infer what is the relevant information to answering queries in cyber situation assessment for my PhD-thesis research,thesis, phd,,
Need to evaluate if a new warm spread model can approximate the worm spread for my PhD-thesis.    ,thesis, phd,evaluation, evaluat
Learn about the communication behavior of malware to create a graph-based model for APT detection for my PhD research,thesis, phd,,
"This is for my PhD Project. I am measuring network analysts performance shutting down attacks through the use of Splunk Enterprise. I am looking for a DDoS attack and a APT attack. This will serve as the DDoS. I also requested the Syn-ack request, but I want this one instead.",thesis, phd,,
This data is going to be used for evaluating the practicality of machine learning algorithms in detecting network level events. This is for my Ph.D research that investigates the use of machine learning to improve network management.,thesis, ph.d,evaluation, evaluat
I am working on my phd research based on anomaly detection and checking this data for experiments will be hopefully very useful.,thesis, phd,,
Studying anomaly detection for my phd research. I've used part of the data while UCSD was still maintaining it. This transfer to IMPACT has seriously affected the timeline of my research deliverable. I request access to this dataset. Will appreciate if it be done sooner rather than later.,thesis, phd,,
"My thesis topic is intrusion/attack detection using Machine learning and for this purpose I need these data sets",thesis, thesis,,
I am working on my Masters of Science in Computer Science-Cybersecurity. So i am researching major attacks used against computer systems and possible countermeasures. The use of data will allow me to do beginner statistical analysis for my project. ,thesis, master,,
"The dataset will possibly be used in a PhD dissertation study of intrusion detection systems looking into the effects of intrusion detection system latency in relation to cyber attacks.  The data will be statistically studied using a quantitative methodology and findings will be reported anonymously.It the dataset does not contain what information is needed, it will not be used.",thesis, phd,,
"This data will be utilized to drive:(i) the cyber situation assessment research being conducted by a PhD student under my supervision. The research will be used to carry out data fusion of multiple data sets to create cyber situation awareness.  (ii) Visualize the progression of DoS attacks ",thesis, phd,,
"I am doing Master's thesis in networking and wanted to work on network traffic related data sets.Our main aim is to design a traffic analysis toolbox using Matlab, which would help a novice in performing all statistical operations pertaining to network traffic data. I am collecting data from different universities/sources, in order to validate my codes in MATLAB.I require the network traffic datasets, in order to carry out the visualization and perform statistical analysis on data.This would help us understand various factors which helps in either increase/decrease in network related performance such as end to end latency, traffic flow analysis, thresholding( critical alarms), link utilization and short/long term traffic.Which would further help in may be utilizing the resources to an optimum/acceptable level, so that one could decide where the entire bandwidth is been used/how effectively one could use it, depending upon the results obtained. ",thesis, thesis,,
For cyber security club exercises. We want to look at what the red team does to better train our team and also learn how to analyze traffic,,,,
"The motivation of the project is to develop a comprehensive system that will capture the Internet topology at fine granularity and periodicallyprovide snapshots of the Internet backbone. The mapping system will then be utilized to investigate topological characteristics of the Internet andprovide an underlay for applications to optimize their communications. Compared to the existing Internet topology measurement platforms, thesystem will (i) build Internet topology graphs with higher accuracy as the system integrates several mechanisms to efficiently handle large-scalemeasurement data; (ii) work at higher level of granularity by providing backbone topology maps at link layer; (iii) periodically release annotatednetwork topologies in addition to the raw measurement data so that the community can utilize them in their experiments and optimize networkcommunications; (iv) help in understanding Internet topology dynamics and providing network enhancements; and (v) provide a graph indexing toolto process and analyze large-scale networks. In particular, we will be using the IP addresses discovered(actively responding to the ICMP calls) in thisdataset as feed to our probing system to further expand our target range in our measurement campaign. Web Page of our project can be found inthis link: im.cse.unr.edu",,,,
Attempting to leverage modern classification techniques to attempt to predict DoS attacks.,,,,
Large-scale ELK analysis of network security traffic.  Identification of behavioral trends that can be used to enhance defenses.,,,,
Internal ICMP_ECHO_REPLY comparison with GT-based IPv4-wide ping sweep.,,,,
Requesting an update on the previous data obtained to better understand regional physical infrastructure of the Internet,,,,
"Hi, I'm working on big data visualization and pattern recognition, from a cybersecurity perspective. Your dataset would help me research proper patterns to help identify threats.",,,,
I'm working on a big data visualization tool and this dataset would help my work in identifying data visual patterns. Thank you!,,,,
Need to do a cross domain privacy sharing predictive analysis based on different times.,,,,
Need to do a cross domain privacy sharing predictive analysis.,,,,
To test a DDoS detection technique.,,,,
"The motivation of the project is to develop a comprehensive system that will capture the Internet topology at fine granularity and periodically provide snapshots of the Internet backbone. The mapping system will then be utilized to investigate topological characteristics of the Internet and provide an underlay for applications to optimize their communications. Compared to the existing Internet topology measurement platforms, the system will (i) build Internet topology graphs with higher accuracy as the system integrates several mechanisms to efficiently handle large-scale measurement data; (ii) work at higher level of granularity by providing backbone topology maps at link layer; (iii) periodically release annotated network topologies in addition to the raw measurement data so that the community can utilize them in their experiments and optimize network communications; (iv) help in understanding Internet topology dynamics and providing network enhancements; and (v) provide a graph indexing tool to process and analyze large-scale networks.In particular, we will be using the IP addresses discovered(actively responding to the ICMP calls) in this dataset as feed to our probing system to further expand our target range in our  measurement campaign.Web Page of our project can be found in this link: im.cse.unr.edu",,,,
"Our dependence of the internet has grown much faster than our understandingof its underlying structure, global dynamics, operational threats, and overallhealth. Large-scale internet service disruptions due to malware and/orpolitically motivated activities occur with some regularity.We have developed a methodology that uses dark space data from the UCSDNetwork Telescope, that identifies networks affected by an outage, anddetermines what techniques are used to cause deliberate disruption.We obtain metrics to quantitatively gauge the geographic and topologicalextent of the impact of geophysical disasters on internet infrastructure,and techniques to investigate the chronological dynamics of the outageand restoration.The USC Lander datasets provide reference information on normally reachablehosts/networks for the study and targeted analysis of these large-scaleinternet outages",,,,
"Our dependence of the internet has grown much faster than our understandingof its underlying structure, global dynamics, operational threats, and overallhealth. Large-scale internet service disruptions due to malware and/orpolitically motivated activities occur with some regularity.We have developed a methodology that uses dark space data from the UCSDNetwork Telescope, that identifies networks affected by an outage, anddetermines what techniques are used to cause deliberate disruption.We obtain metrics to quantitatively gauge the geographic and topologicalextent of the impact of geophysical disasters on internet infrastructure,and techniques to investigate the chronological dynamics of the outageand restoration.The USC Lander datasets provide reference information on normally reachablehosts/networks for the study and targeted analysis of these large-scaleinternet outages",,,,
Examining how certificates for the same site differ depending on where the client is located,,,,
"Hi, We are designing an anomaly detection system (on the victim side) for NIST. This dataset will be analyzed to capture the behavior of DoS attack for our research.Thank you!Best,Kang-Hao PengThanks!Kang-Hao Peng",,,,
We are designing an anomaly detection system (on the victim side) for NIST. This dataset will be analyzed to capture the uniform attack behavior for our research. ,,,,
"This data will be used to test new visualization tool for big data that I am currently researching at CMU, using a modified directed forced graph, whose (ultimate) purpose is using visual pattern recognition in aiding in cybersecurity threat detection and pattern recognition. The point behind it is to visualize the data in a way that conveys more information than what a text based medium could. I need this particular data to test specific cases and see how can the visualization be improved.",,,,
"This data will be used to test new visualization tool for big data that I am currently researching at CMU, using a modified directed forced graph, whose (ultimate) purpose is using visual pattern recognition in aiding in cybersecurity threat detection and pattern recognition. The point behind it is to visualize the data in a way that conveys more information than what a text based medium could. I need this particular data to test specific cases and see how can the visualization be improved.",,,,
"Conducting undergraduate research regarding IoT botnet behavior. Attempts to use a series of tools and methods, (such as multiresolution analysis), in order to determine the extent to which Mirai botnet behavior is detectable. Also interested in extending this behavior to similar IoT botnets, that are derivations of Mirai (possibly with extended capabilities). ",,,,
Will use the dataset to study the pattern of the flow in attack and then compare it with the pattern seen for normal datasets.,,,,
"Government funded research to benefit humanitarian aid and disaster relief community. Looking to see if we can correlate changes in network host reponsiveness with power outages/loss of communications infrastructure.",,,,
"Government funded research to benefit humanitarian aid and disaster relief community. Looking to see if we can correlate changes in BGP data with power outages/loss of communications infrastructure.",,,,
Government funded research to benefit humanitarian aid and disaster relief community. Looking to see if we can correlate changes in BGP routing data with loss of power/communications infrastructure.,,,,
need to analyse the dataset to obtain a pattern in attack flow to conduct the experiment and write a paper.,,,,
"Hello,I am a research assistant of Professor Richard La in University of Maryland - College Park. We are interested in the anomaly detection of network traffic. We need the CAIDA dataset to correctly model the DDoS behavior in our aggregate traffic thus improve our system's performance. Thank you.Sincerely,Kang-Hao Peng",,,,
"As a presenter at the Florida Academy of Sciences (FAS) conference 2017 to be held in March, I am conducting experiments in netflow classification. My research is intended to provide benchmarks for researchers in the cybersecurity community regarding the use of three data mining algorithms. Specifically, the title of my presentation is ""A Comparison of Performances of ID3, Random Forest, and One-R in the classification of Netflow data"" For information on FAS, please visit http://www.floridaacademyofsciences.org/.",,,,
Government funded research to benefit the humanitarian aid and disaster relief community. Looking to see if we can correlate reduction in/absence of this kind of network traffic with power outages/loss of communications infrastructure after a disaster.,,,,
Government funded research to benefit humanitarian aid and disaster relief community. Looking to see if we can correlate reduction in this type of network traffic with power outages/loss of communications infrastructure.,,,,
I will study the relationship between access to the Internet and proximity to Internet infrastructure using an instrumental variables procedure for my academic research.,,,,
Seeking to study new relationships between proximity to fiber line cables and access to Internet services using instrumental variable regression techniques for my academic research.,,,,
"I have several aspirational uses for this data:(1) Graph analytics (degree distribution, clustering coefficient, degree centrality, PageRank, etc.) on DoS log data. (2) Use the graphs and analyses from (1)  -- in the form of matrices -- to train a neural network (a common feed-forward NN at first, then perhaps a convolutional NN) to recognize DoS attacks.(3) Compare the ""ML on graphs"" approach from (2) to the more traditional ML on raw log data approaches.(4) Compare the NN approaches of (2) and (3) with other ML techniques: SVM, decision trees, regressions, etc.(5) Static Data Quality measures on this data. (DQ is a vague field, but I'm going to try to make it more precise for real-world use cases.)(6) Dynamic Data Quality measures of this data, as it is a time-series. (DDQ is brand new!)",,,,
Doctorate Research GWU security event identification within companies. ,,,,
Use for doctorate research GWU in regards to security event identification.  ,,,,
"DSHIELD and GT Malware will be used to build and test a Security Analytics project, ",,,,
"DSHIELD and GT Malware will be used to build and test a Security Analytics project,",,,,
To train classifiers for attack detection ,,,,
We will perform time series analyses with this malware data. ,,,,
Will correlate events in cyber security data with known events of interest in service of research on non-traditional indirect indicators and warning,,,,
Develop predictive models of cyber attacks for the IARPA CAUSE program,,,,
Need to recreate results from the SIGCOMM paper that uses this data ,,,,
I am measuring analyst performance shutting down a DOS attack and a APT attack through the Splunk Enterprise. This serves as my DOS attack unless you suggest a better one. Next I will request the APT attack.,,,,
Evaluate new statistical approach for modeling conficker worm in my research,,,,
"I am doing a project on DDoS detection for my Network Forensics class at John Jay College.  At the moment I'm comparing the 2007 DDoS dataset from CAIDA with their 2016 network trace, using a variety of analysis tools.  The purpose of the project is to hypothesize criteria for finding (or finding suggestions of) DDoS traffic or botnet recruitment.  So far I'm primarily using self-written Python scripts to process .pcaps, and SiLK for flow data.  ",,,,
"We are studying query volume and replica selection anomalies associated with the d-root name server and would like to integrate broader statistics to determine whether events observed in samples of d-root also appear more broadly, or conversely, whether events occur but are missed by our approach or data.  We expect that routing information may explain replica selection anomalies and traffic volume shifts.",,,,
This data will be used for academic research on statistical inference for cyber attacking patterns over time and over IP addresses. ,,,,
"I am trying to build a simulation model for cyber-attacks, primarily network based attacks. I am going to use the dataset to verify the simulation results.",,,,
I plan to use the data to create simulation model to test different types of cyber-attacks.,,,,
"We want to study the dataset and build a Machine Learning based model to detect malicious traffic. How we can avoid the false alarm conditions and a really really fast model. In real time, we have to take decision promptly. After receiving the dataset we can analyze and construct features from it.",,,,
Import in the Splunk lookup for ip tagging purposes. Thank you. Splunk queries limited to the team of 4.,,,,
To investigate spam campaigns from malware,,,,
"Re: DSR-158We plan on building on the work in ÃƒÂ¢Ã‚â‚¬Ã‚Å“Day After Patch Tuesday Effects Observable in IP Darkspace TrafficÃƒÂ¢Ã‚â‚¬Ã‚Âù (Tanja Zseby, Alistair King, Nevil Brownlee, and K. C. Claffy, 2013) by expanding the focus to a comparative analysis of other network facing software, as well as moving towards a different statistical approach (Net increase in traffic, rather than increased unique source IPs).We plan on analyzing the difference from the mean traffic on that day of week for the affected protocol. Ãƒâ€_Ã‚Â We will use the ÃƒÂ¢Ã‚â‚¬Ã‚Å“Patch Tuesday DatasetÃƒÂ¢Ã‚â‚¬Ã‚Âù, normalized based on standard traffic for that weekday and other factors, such as simultaneous patching, to endeavor to sort which service patches lead to the largest increase in traffic.",,,,
"We are studying RR support on the internet.  We begin by sending an RR ping to a hitlist destination for each BGP prefix.  For prefixes whose hitlist IP does not respond, we need other historically active IPs to ping.  For larger aggregates (e.g. /16) we can choose other hitlist destinations, however for /24 networks, we need other candidates.",,,,
for investigating internet-wide scanners.,,,,
I will use this data set as a base for my project for  the course(Quantitative Methods and Experimental Design in CS ) . I will apply quantitative analysis methods on this set and build statistical profile for anomaly and normal traffic,,,,
This dataset would be used as a basis for generating an extensive inter-AS connectivity map (with a city granularity) for the US. This dataset is needed since it outlines the fiber infrastructure of the US and could facilitate in creating this map.,,,,
I will use this data set as a base for my project in the course(Quantitative Methods and Experimental Design in CS ) . I will apply quantitative analysis methods on this set.,,,,
Discover previously-unknown amplification vulnerable UDP protocols,,,,
"Two fold:1) To develop a course for graduate students on the use of big data and machine learning techniques to identify performance and network anomalies.2) To develop machine learning techniques to identify performance and network anomalies and to categorize them.",,,,
The data will be used in an ongoing study on the current state of IPv4 Record Route support on the internet.  Selected addresses will be pinged with RR packets to asses the responsiveness and reachability from our vantage points.,,,,
The data-set will be used in an empirical study to improve classification performance of different algorithms by alleviating data quality challenges (e.g. Class imbalance),,,,
"Only internally as test data for the algorithms we developed. We have some recent results hopefully can be used to identify suspicious sequences of events, which we would like to have some realistic data to test on, in order to verify the ideas. ",,,,
Research improves cyber-security.,,,,
We are interested in enriching our monitoring infrastructure with DNS data from malware datasets. These network IOCs can be tagged in our sensors for followup.,,,,
We will use it to validate our findings about biases of passive observation,,,,
Research project for DDoS Detection,,,,
Graph mining research,,,,
Data will be used in our IDS model.,,,,
It will be used as a test data set for testing our IDS model,,,,
for the education of the faculty member,,,,
We're researching alternate paths/locations for our disaster recovery/business continuity program.,,,,
Investigating Internet-wide Scanners,,,,
Conduct network research and data analysis to identify new methods for communicating in an emerging technical environment. Develop and test algorithms that may be applied to additional data sets.,,,,
DDoS detection/mitigation algorithm research.,,,,
DDoS detection/mitigation algorithm research,,,,
"I am part of a project group that is exploring the potential of an adaptive, distributed DDoS detection system.  To test our system, I plan to make use of the tools available for replaying attack traffic within DeterLab (http://deter-project.org/about_deterlab).  For this reason, I am seeking access to publicly available DDoS datasets, and particularly those that involve packet data.",,,,
Evaluate the performance of a SDN architecture for research purposes,,,,
Project looking at the effects of cable connection on political outcomes in West Africa.,,,,
We will use this dataset to test our attack detection tool,,,,
We will test our attack detection tool on this dataset,,,,
We will test our attack detection tool with this dataset,,,,
learning/testing of IDS system,,,,
Project looking at the effects of the Internet on political participation,,,,
Project looking at the effects of the Internet on political participation in the US,,,,
Working on a research paper which is an extension of other papers my team has worked on with this particular data set.,,,,
The data will be used for research purposes. The research aims to find a way to detect and mitigate attacks with a network based attack vector in a cloud environment,,,,
Training/Testing for DDoS detection algorithm,,,,
The data will be used to study malware activities targeting various locations over the world. ,,,,
The data will be used to create a more realistic attack source topology for a DDoS defense simulation study. Only the source IP or source prefix will be used.,,,,
The data will be used for purely research purposes. Our Research aims to detect attacks which have a network based vector and develop methods to mitigate the damage.,,,,
I am working with Michael Kallitsis on a data mining competition for U-M graduates.  The data are to be used in that effort.,,,,
We would like to use the DNS dataset for malware research.,,,,
"The purpose of this data is to act as a source of synthetic data to demonstrate an anomaly detector and data visualization capability in a research conference (CNW 2016) held at MIT Lincoln Laboratory. We intend to (a) run the pcaps in this data set through an IDS system to generate IDS alerts, and (b) process the pcaps to generate netflow records as well as DNS records. These output data will be used as input to a publicly releasable demonstration  of our anomaly detection and data visualization tool. The data sets we normally use, being real as opposed to synthetic, are not releasable. Note that the underlying pcaps which make up the data set will not be disclosed, only IDS alerts, netflows, and DNS records.",,,,
"We have a project that aims to estimate network distance between arbitrary Internet endpoints. For this purpose, we utilize Content Distribution Networks and ENDS0 client-subnet extension (ECS). Our measurement system requires no additional infrastructure to be deployed. The measured endpoints do not need to participate by sending or responding to probes. Our systemfurther generates no load on endpoints. It only queries DNS, whose infrastructure is designed for large loads. In order to validate our system's effectiveness, i.e., its ability to estimate network distance, we would significantly benefit from the requested data set. In particular, we have experienced anomalous behavior that we believe could be resolved by using the requested data set.",,,,
To validate certain statistical anomaly detection methods,,,,
"Our dependence of the internet has grown much faster than our understanding of its underlying strucure, global dynamics, operational threats, and overall health. Large-scale internet service disruptions due to malware and/or politically motivated activities occur with some regularity. We have developed a methodology that uses dark space data from the UCSD Network Telescope, that identifies networks affected by an outage, and determines what techniques are used to cause deliberate disruption. We obtain metrics to quantitatively gauge the geographic and topological extent of the impact of geophysical disasters on internet infrastructure, and techniques to investigate the chronological dynamics of the outage and restoration. The USC Lander datasets provide reference information on normally reachable hosts/networks for the study and targeted analysis of these large-scale internet outages. We have recently developed methodologies based on passive traffic analysis that allow additional insight into whether a given IP network prefix is actively used. We will combine our results with the USC Lander datasets to generate derived datasets that we plan to share through PREDICT. Researchers will be able to use these data sets for similar purposes as the existing USC Lander data sets, e.g., inference of address space utilization. This request is a follow-up to similar requests over the last years. We are only requesting the datasets not covered by these earlier requests.",,,,
"The purpose of the project is to correlate different logs from an enterprise network with the IDS alerts to improve the current state-of-the-art intrusion detection mechanism. But we have not found such logs from an enterprise network that are publicly available. So, the initial idea is to collect the existing datasets which meets a subset of our requirements and check whether those data can be correlated with some other datasets (i.e. botnets, malware DNS requests).",,,,
To validate certain statistical anomaly detection methods.,,,,
To validate certain statistical anomaly detection methods,,,,
To validate certain statistical anomaly detection methods.,,,,
To validate certain statistical anomaly detection methods,,,,
I want to use the data to help verify a new tool that attempts to identify inter-AS link interfaces.,,,,
The dataset is needed to validate certain anomaly detection methods.,,,,
A study of internet infrastructure for an urban focused architectural studio at Yale University.,,,,
"Conducting targeted traceroutes from cloud service providers. The connectivity of large cloud service providers, such as Amazon AWS, will be inferred from traceroutes to the hitlist IPs.",,,,
"Project Proposal: The mission of the UTSA Cyber Security Association is to provide training and professional events for students of the university who are interested in cyber security.In keeping with that mission, we will use the data from the NCCD Competitions to create training for our members on the identification of network attacks on large enterprise networks.The nature of the some of the questions we hope to answer are as follows:How do you select and isolate a signal/flow from the noise of routine network traffic, without direct visualization of the network traffic through Wireshark?How do you determine if a signal/flow is malicious without direct visualization of the network traffic through Wireshark? Does your cybersecurity solution/tool scale across massive amounts of data? ( greater than 1TB).Dataset Choice (Why this data set?):The best penetration testers/researchers in industry, and the best security minded college students are competing against each other.  This presents a rare opportunity to analyze ÃƒÂ¢Ã‚â‚¬Ã‚Å“security principles in practice.ÃƒÂ¢Ã‚â‚¬Ã‚ÂùSince there are multiple teams, each team presents discrete sets of data for analysis of security principles.  Thus we potentially get multiple data points.Since the data is captured from a cyber competition there is a guarantee of ""malicious"" traffic, and this guarantee presents with a data set against which our goals, questions, tools, and potential solutions can be tested.The data set has clear start and finish times, and is relatively short in duration (two days), but is saturated with different types of ""malicious traffic.""The data set is as close to a standard model as a researcher may find ""in the wild.""  That is, the strict rules governing red/blue team actions, and the same equipment/scenarios across multiple teams creates a fairly standardized model from which to conduct research.Final Goal:Create training slides (based on the above statements) for our student members.Thank you,Jose David Mireles",,,,
Review of prior year's competition,,,,
"We are developing a new method of increasing the efficiency of intrusion detection systems.  The request file should be a useful test set.",,,,
I am studying the robustness of the financial network system under a DHS S&T grant.  This research is looking for vulnerabilities in the nature of equity market trading.,,,,
"We are looking for data for our data analytics and visualization project especially targeted towards networks infrastructures and / or cybersecurity. The PCH and US Long-haul topology dataset particularly fits our infrastructure data needs while the GT Malware data can help us proceed with our cybersecurity research project. The project will utilize several graph theory techniques, scientific data analytics approaches and also include an interactive visualization web app development as part of the exploratory data analysis (EDA) process. It'll be a great help if we receive approval for the dataset. We shall also responsibly manage and restrict access in accordance to the usage policies in the terms of use.",,,,
Our research is to compare relationships between different cyber threat intelligence sources. Specifically we want to compare the content of this web site with what is available on HAILATAXII.,,,,
PhD Research,,,,
Graduate project research,,,,
To improve network visualization. ,,,,
Exploring the dataset to see if the information that was collected can be used as the input to some of the systems that we developed.,,,,
"We want to look into the dataset and see if the type of data and the information that were collected can be applied to the systems that our lab has developed. Hence we want to use this dataset as a mean to test our systems and produce interesting results out of them.We are currently exploring various dataset to see which one is more applicable to our needs.",,,,
"We are currently working on a research project at CCAA center and we would like to investigate these datasets in order to see whether we can use them. CCAA has been established under the National Science Foundation (NSF) Industry/University Cooperative Research Program (I/UCRC) in September 2013. The center is a public, private, and academic consortium established and led by the University of North Carolina at Charlotte in partnership with George Mason University and a broad membership of industry and government organizations.",,,,
"Hi. I would like to use the long haul fiber lines that you show on your map. I do not need any data or information about the lines, I just want to show where they are in the US like you do in your original map. I am planning on incorporating these lines into a map I am making, and the long haul fiber lines will just be background information. These lines are going into a map about railways in the U.S. If you would like to see the map I would add it too, let me know and I can send it your way. ",,,,
"Our dependence of the internet has grown much faster than our understanding of its underlying strucure, global dynamics, operational threats, and overall health. Large-scale internet service disruptions due to malware and/or politically motivated activities occur with some regularity.We have developed a methodology that uses dark space data from the UCSD Network Telescope, that identifies networks affected by an outage, and determines what techniques are used to cause deliberate disruption. We obtain metrics to quantitatively gauge the geographic and topological extent of the impact of geophysical disasters on internet infrastructure, and techniques to investigate the chronological dynamics of the outage and restoration.The USC Lander datasets provide reference information on normally reachable hosts/networks for the study and targeted analysis of these large-scale internet outages.We have recently developed methodologies based on passive traffic analysis that allow additional insight into whether a given IP network prefix is actively used.  We will combine our results  with the USC Lander datasets to generate derived datasets that  we plan to share through PREDICT.  Researchers will be able to use these data sets for similar purposes as the existing USC Lander data sets, e.g., inference of address space utilization.This request is a follow-up to similar requests over the last years. We are only requesting the datasets not covered by these earlier requests.",,,,
"We want to examine how different kinds of data like vulnerability scan data, firewall logs, operating system logs, web server logs etc. can be utilized to correlate IDS alerts to real attacks in a risk-aware way. As a result we need real world data that can meet at least some of our requirements.  ",,,,
The data will be used for a revision of the Reverse Traceroute system. It will be used to test support for the types of probes that are used as well as to improve the measurement techniques utilized by the system.,,,,
Malware distribution research,,,,
Analysis of long-haul backbone in Northwest Florida: Understanding fiber-optics infrastructure for economic opportunity,,,,
"In order to protect the members of our university, we want to look at the relationship between risky behavior in the phyiscal world and vulnerability to phishing attack. In other words, we want to see if things like smoking, excessive drinking, or promiscuity can predict when someone is more likely to trust a ""phishy""-looking email. We can't say for certain what we will do with the data in the logs until we see the fields available, but we are planning on looking at general demographics first.",,,,
Researching various long-haul communications links involving MIT facilities.,,,,
research of fiber routing paths for CT research network diversity,,,,
The data will be used to develop and test anomaly detection algorithms as part of a Capstone project for the MSPA graduation program at Northwestern University.,,,,
Research in attacker modeling,,,,
We are going to use this dataset for our NSF funded project. The aim of our project is to minimize the redundant probing on internet measurement techniques.,,,,
"As a participant in the Computational Cybersecurity in Compromised Environments (C3E) workshop, I plan to use this dataset to research solutions to the C3E challenge problem",,,,
We are going to use this data to perform our experiments on our NSF funded Internet Measurement project. We aim to create a new way of probing system that reduces the probing overhead.,,,,
"The motivation of our project is to develop a comprehensive system that will capture the Internet topology at fine granularity and periodically provide snapshots of the Internet backbone. The mapping system will then be utilized to investigate topological characteristics of the Internet and provide an underlay for applications to optimize their communications.This data sets will be merged with the others we are collecting from CAIDA,ROUTEVIEWS and CIDR in order to have the current collection of datasets together that we can run our tests on them. ",,,,
I am researching on novel ways to analyze a large quantity of system generated logs and messages to extract relevant security information and categorize security events. The data will be used to measure the performance of the feature extraction and event classification algorithms that I am developing. ,,,,
"Apply big data Techniques to Malware analysisClassify viruses using Dynamic behavior data and static features",,,,
Conducting network research and data analysis to identify new methods for communicating in an emerging technical environment. Developing and testing algorithms which may be applied to additional data sets.,,,,
We would like to investigate the possibility of using this dataset in one of our projects at Center for Configuration Analytics and Automation (CCAA). CCAA is a multi-university and multi-industry consortium established and led by the University of North Carolina at Charlotte in partnership with George Mason University and a broad membership of industry and government organizations,,,,
Use for malware analysis research project in Georgia Tech.,,,,
"The intended purpose for this request is to incorporate the DNS data feed into a Security Onion deployment. The Security Onion machine includes NSM tools, such as Bro IDS, which will allow for alerting and reporting of suspicious, or anomalous activity. The goal is to gauge the effectives of incorporating an external entities DNS feed (Georgia Tech).",,,,
The Astrolavos lab aims to provide generalizable solutions to security problems with high operational impact. We need malware related datasets to form ground truth of many projects.,,,,
Threat intelligence platform development,,,,
Just some comparison with other feed data.,,,,
"I work in the information security operations center, and would like the data for IOCs that will help find malicious traffic.",,,,
Member of SIGCOMM program committee and would like to review electronic component of published paper,,,,
The data will be used for a revision of the Reverse Traceroute system. It will be used to test support for the types of probes that are used as well as to improve the measurement techniques utilized by the system. ,,,,
For participation in the 2015 C3E challenge.  http://cps-vo.org/group/c3e/ccp,,,,
For the 2015 C3E challenge.  http://cps-vo.org/group/c3e/ccp,,,,
We intend to use this dataset as part of our ongoing border blocking project. Our goal for the use of the data would be to further reduce malicious incoming traffic destined for Duke.,,,,
"Correlate passive DNS pcap information with domains used by malicious or suspect executables.Correlate passive DNS data with other threat intel collected at GWU.Our goals are to improve detection and classification of existing data seen on our SIEM.We also just want to take a look at the data feed and its format to determine how it may best server the network security team at GWU.",,,,
"Operational security at Emory University, such alerting on activity for included hosts, or blocking requests to included hosts",,,,
to determine the effectiveness of algorithms on infiltration and ex-filtration of an attack on a system. ,,,,
This data will be used for research on network intrustion detection,,,,
The research this data is used for Network Intrusion Detection.,,,,
Conducting targeted traceroutes from cloud service providers,,,,
"This project focuses on NetFlow data. We attempt to transform theincoming stream of low-level data to a high-level understanding of thenetworkÃƒÂ¢Ã‚â‚¬Ã‚â„¢s operational status and reach actionable recommendations. EachNetFlow record includes some basic information about the sampled flow,including its source and destination address, duration, size, etc. Anindividual NetFlow record cannot give us much information about whathappens in the network. Therefore, instead of trying to understand whathappens at the level of individual flows, we focus our analysis on thelevel of aggregated flows. Aggregation will not be ÃƒÂ¢Ã‚â‚¬Ã‚Å“hardwiredÃƒÂ¢Ã‚â‚¬Ã‚Âù, e.g.,based on fixed prefix resolution. Instead, we will propose a clusteringalgorithm for flow aggregation that selects automatically the set offeatures that produce the most homogeneous clusters of NetFlow records.We will utilize spatio-temporal information of the NetFlow dataset torefine clusters to a meaningful homogeneous level. For example, a goodcluster of NetFlow records may end up being all NetFlix traffic thatoriginates from a certain Limelight caching site in Atlanta to allComcast customers in Macon GA during a 6-hour time period.After the clustering step is performed, the next task will be toidentify significant correlations between clusters.Temporal correlationsof these clusters are leveraged to form a graphical model between them.The graphical model with nodes being clusters of flows and edges beingtemporal correlations between them offers parsimonious model of networkdynamics. We will use this model to monitor the network for behavioralshifts and anomalies, which can be proxies for security attacks, networkproblems, structural changes or real changes in the behavior of thenetwork subscribers.",,,,
determine the effectiveness of determine infiltration and ex-filtration of malicious attitudes. ,,,,
"Our project involves studying various characteristics of real Internet traffic.  Our study (which has been approved by IRB,  CWRU IRB Protocol Number:  IRB-2012-171)   involves operating a traffic monitor on the border between our own campus and the Internet and analyzing collected traffic at this vantage point.  Our goal is to study TCP algorithm details,  including questions such as ACKs that cover multiple segments, and  frequency of TCP timestamp use.   We would like to augment our analysis with another vantage point.   Specifically, we are requesting 1 day of data containing just IP and TCP headers (including TCP options).   ",,,,
The motivation of the project is to develop a comprehensive system that will capture the Internet topology at fine granularity and periodically provide snapshots of the Internet backbone. The mapping system will then be utilized to investigate topological characteristics of the Internet and provide an underlay for applications to optimize their communications.,,,,
View and analyze traffic to work test effectiveness of snort rules,,,,
Data analysis for IDS/IPS tuning exercise,,,,
I am a graduate student at Texas A&M University researching deterrence in cybersecurity policy.  I am trying to conduct quantitative analysis on unclassified cyber data to see if major cyber events have caused a change in activity.  I will be using the data to conduct statistical analysis and then possibly be used in a research paper.  I do not intend to publish this paper or otherwise disclose it beyond the professor of the course.,,,,
"Continued work to identify and confirm high latency hosts, investigate subnet structure, develop failure detection methods based on observations of real ping responses.",,,,
The motivation of the project is to develop a comprehensive system that will capture the Internet topology at fine granularity and periodically provide snapshots of the Internet backbone. ,,,,
"Goals:1. Find top hacking methodology2. Find tools used3. Find ports usedObjective: Research past event data to prep team for national competition. This will not necessarily be used right now for publication but will be used to enhance classroom experience as well as prep experience for the CCDC groups.",,,,
Research attack vectors and successful exploitation attempts in order to build stronger defenses.,,,,
Conduct analysis of traffic used in a national cyber defense competition to use as a basis for other cyber defense competitions.,,,,
"Our dependence on the Internet has grown much faster than our understanding of its underlying structure, global dynamics, operational threats, and overall health. We have developed metrics to quantitatively gauge the geographic and topological extent of the impact of geophysical disasters on internet infrastructure, and techniques as they manifest themselves on the UCSD Network Telescope. This dataset will provide required reference information on known Internet outages.",,,,
"We intend to analyze the polygonal foot print of address blocksover the world in order to get a clear picture of IP block levelvisualization. We also intend to show how much of a given IP block is actually in use, in a visual manner.",,,,
Data sets support the analysis of paths (by organization) from major content providers to end-user networks.,,,,
"We intend to analyze the polygonal foot print of address blocks over the world in order to get a clear picture of IP block level visualization. We also intend to show how much of a given IP block is actually in use, in a visual manner.",,,,
I intend to use this information as research to help provide further understanding as to what sort of scale attacks take place on the Internet.,,,,
"I am currently advising Yitian Tang, an undergraduate student at the  University of Illinois at Urbana Champaign, in the context of an undergraduate research program, on Quickest Change Detection (QCD) methods, which is one of my research areas. One of the main goals of our project is to illustrate the usefulness of these techniques to the area of  cybersecurity.  Various QCD techniques have been proposed in the literature in order to design anomaly-based intrusion detection schemes.  We aim to explore the performance of novel techniques from quickest detection to this area and compare them with existing methods.  ",,,,
"Our dependence on the Internet has grown much faster than our understanding of its underlying structure, global dynamics, operational threats, and overall health. Large-scale internet service disruptions due to malware and/or politically-motiviated activities occur with some regularity. We have developed a methodology, using dark space data from the UCSD Network Telescope, that can identify the networks that are affected by an outage, and can determine what techniques are used to cause a deliberate disruption. We have developed metrics to quantitatively gauge the geographic and topological extent of the impact of geophysical disasters on internet infrastructure, and techniques to investigate the chronological dynamics of the outage and restoration. The USC Lander datasets will provide required reference information on normally reachable hosts/networks for the study and targeted analysis of these large-scale Internet outages.",,,,
"This project is intended to understand responsiveness properties of arbitrary internet hosts and subnetting characteristics.  The survey data is particularly useful given its repeated probing of wide aspects of the internet.  We now hope to look at longitudinal properties given older and newer data from what we have previously studied, and to confirm that conclusions observed in previously requested data held in 2014.NOTE: this is a partial renewal of survey_reprobing data previously requested including datasets 20111102-20131017, which need not be made available for download.",,,,
"Trace the source IP obfuscated due to network address translations (NAT).However, the data would be useful only if some of the devices are performing NAT and are operating at the Internet Level.",,,,
"Project: Perform IP trace using Syslog data to detect IP address obfuscation due to Network Address Translation (NAT)However, I would like some of the devices to have some NAT and have these devices operate at the Internet level.",,,,
"We are currently using the BGP data available from Route Views and RIPE to perform analysis on Internet topology and routing events, particularly as it relates to nation-states and organizations of interest. We would like to acquire additional data about Internet topology to perform additional analysis, and determine whether the CAIDA topology data provides additional insight missing from the data sources we're already using.",,,,
"Determining connectivity of large cloud service providers, such as Amazon AWS, via traceroutes to hitlist IPs.",,,,
Analysis of DoS attack traffic data in order to develop attack detection and mitigation mechanisms. Existing attack data will be used to extract features in order to select parameters required for training of a learning system which should detect generic DoS attack.,,,,
"Our dependence on the Internet has grown much faster than our understanding of its underlying structure, global dynamics, operational threats, and overall health. Large-scale internet service disruptions due to malware and/or politically-motiviated activities occur with some regularity. We have developed a methodology, using dark space data from the UCSD Network Telescope, that can identify the networks that are affected by an outage, and can determine what techniques are used to cause a deliberate disruption. We have developed metrics to quantitatively gauge the geographic and topological extent of the impact of geophysical disasters on internet infrastructure, and techniques to investigate the chronological dynamics of the outage and restoration. The USC Lander datasets will provide required reference information on normally reachable hosts/networks for the study and targeted analysis of these large-scale Internet outages.Note that this request is for the same datasets requested in earlier requests (id 8061 and 6800).",,,,
"These census, history and hitlist datasets provide reference information about reachable hosts and network, useful in several CAIDA studies, such as the analysis of network outages.",,,,
"The USC Lander datasets provide reference information on normally reachable hosts and networks, useful in various CAIDA studies such as network outages and network congestion.",,,,
"The project is to detecting cyber attack using artificial intelligence, such as clustering, KVM and SVM. The dataset will be used to clustering and training vector machine meanwhile testing training result. ",,,,
"Sorry to submit two separate request. As a new user, I apologize for the trouble. The same as my first request, basic purpose of the project is to look into clustering application in DDoS amplification. I'm mainly focusing on DNS amplification, but according to several papers similar amplification strategy can be used in NTP, SMTP and P2P. The dataset will be used to find special feature of attack traffic and cluster them with those features. It may help us to detect an attack from legal traffic. This request is for another two protocols I mentioned: NTP and SMTP",,,,
"Basic purpose of the project is to look into clustering application in DDoS amplification. I'm mainly focusing on DNS amplification, but according to several papers similar amplification strategy can be used in NTP, SMTP and P2P. The dataset will be used to find special feature of attack traffic and cluster them with those features. It may help us to detect an attack from legal traffic. ",,,,
We are working on Data Analytics Cyber Security project. The main goal of this project is to analyze the data to prevent cyber security threats. We use this data to analyze the various scenarios possible with this threats.,,,,
"The research project is about using multilevel memristors for hashing. This is a purely academic research project, and the data will be used to simulate hashing in an internet router.",,,,
Abstract: Large scale attack traffic present challenges identifying and classifying attack behaviors. Offline host and flow clustering attempt to group similar behaviors in order to expedite analysis. The goal of this research is to move such clustering online and generate attack models. The NCCDC logs will be mined for observables in order to cluster and produce the models.,,,,
To improve the visualization and processing of CAIDA's ITDK.,,,,
"This data set request revolves around the detection of anomalies in NTP traffic using advanced ideas in unsupervised machine learning.   In particular, we propose to use algorithms such as robust principal component analysis and manifold learning to assess the normal background state of a computer network and thereby detect sparse, anomalous departures from that ambient background.  The requested data will form a foundation for the development and validation of our algorithmic approaches.",,,,
"The goal of my research is to use ideas such as Robust Principal Component Analysis and Manifold learning for the detection of anomalies in network traffic.  This data will allow the testing of these ideas on synthetically generated data.Key objectives include the detection of anomalies that are indicative of network attacks.",,,,
"Study the economic impacts of protests. In order to do this we need high frequency data on economic activity and we believe internet traffic is a good proxy for this. The idea is to assess what are the economic consequences of protest and how people adapt to it.  For example, do people compensate for days lost (because of protests) overworking days before or after? How do governments (or other parties) react to protest depending on the extent of the protest and its impact on economic activity. ",,,,
The goal of the task is to extract features and develop a machine learning method that will be able to categorize passive DNA data into benign and malicious.  ,,,,
I would like to use this dataset to help me in executing network intrusion detection system that has the capabilities of dealing with imbalanced data between the normal and abnormal behaviour and the dealing with dynamic profiles to each the future traffic using the on-line statistics methods. ,,,,
"I am working on an Internet Oracle that will predict paths based on observed traceroutes. To do this, I need to collect a data set that targets a moderate number of destination hosts from a set of traceroute vantage points. I would like to issue a traceroute to each BGP atom. The hitlist will be used to choose likely responsive host within each BGP atom. ",,,,
I would like to use this dataset to analyze the raw data for a Statistics class.  I hope to find some trends and correlations that I can use as the foundation for my dissertation in Cyber-Security.  Eventually I would like to show that a security analyst can use passed malware trends to predict future malware attacks.,,,,
"DDoS classification for our CS194-16 Data Science course.  We would like to be able to successfully classify different types of DDoS attacks given characteristics of packet traces within a given time period, which can help in mitigating such attacks.",,,,
"I am currently working on developing a  framework that enables American Indian Tribes to easily collect and analyze data regarding broadband coverage on reservations that could be used as part of the application for FCC grant funding for broadband and telecom build-out.  I would like to use this data to establish finer-grained patterns in diurnal Internet usage in Tribal areas in the United States. This would be used as motivation for research into Tribal broadband development, as it is expected to show daily usage patterns similar to those observed in developing and low-GDP areas. ",,,,
The data will potentially be used for a research funded by the Distributed Analytics and Security Institute at Mississippi State University. The purpose of the research is to develop innovative methods and tools to better understand and defend against phishing attacks.  ,,,,
"We are a group of undergraduates at UPenn who are doing research into data visualization, especially with regards to anomaly detection. We have a full research proposal if requested.",,,,
"We are interested in information visualization, particularly with respect to anomalies in large data sets. We plan to use open source software to do the analysis and front-end, and just need sample data to get started with our tests. We have a full research proposal available if desired.",,,,
"Study the economic impacts of protests. In order to do this we need high frequency data on economic activity and we believe internet traffic is a good proxy for this. The idea is to assess what are the economic consequences of protest and how people adapt to it.For example, do people compensate for days lost (because of protests) overworking days before or after? How do governments (or other parties) react to protest depending on the extent of the protest and its impact on economic activity.We intend to combine the internet address survey reporbing data with maxmind geolite database(http://dev.maxmind.com/geoip/geoip2/geolite2/) to get the number of active IP addresses in a region.",,,,
"Project abstract:The rise of Cloud computing is being driven by the need to access content and services on any device. With the migration of access networks to all-IP and the growing trend of SDN-enabled networks, a shift in network architecture has begun that allows opportunity for a unified security architecture. This project proposes the design and creation of this architecture, comprised by a set of virtualized integrated network edge functions, that can provide early attack mitigation and protection against coordinated attacks originating across a diverse set of networks. Our approach simplifies and improves overall security for both Cloud and access networks. The dataset will be used to test our detection algorithms.",,,,
"My research project is about using situation awareness in cyber security domain. The goal of this project is to identify the relevant information that are sufficient to describe the attack. So I need some data, which includes both normal network packages and attacks. ",,,,
This request for the IP histlist data is for the use of this data in the iPlane project (http://iplane.cs.washington.edu). The IPs in this hitlist will be used as the targets for iPlane's probes.,,,,
This data will be used to develop a research paper on cyber security that will be submitted to the Journal of Information Systems.,,,,
To analyze cybersecurity for a potential publication in the Journal of Information Systems ,,,,
"I'm working on the study of pattern detection of different types of traffic. The goal is to identify and model specific behavior patterns for different users (or activities) in the system. I'd like to compare the models collected from users on each year of the competition and see how/if they evolve. ",,,,
"C3E challenge problem - Malware discovery",,,,
"Taking into account and managing risk perception is a major aspect of successful risk management. After all, many safety interventions ÃƒÂ¢Ã‚â‚¬Ã‚â€œ like cancer screenings or keeping computer software up-to-date ÃƒÂ¢Ã‚â‚¬Ã‚â€œ depend on the participation of the public for success.      There have been numerous studies on the relationship between actuarial risk and risk perception. It is well documented that risk perception and actuarial risk are not often aligned. For example, people perceive risks they dread or take involuntarily as more severe than others, so that skiing or plastic surgery are experienced as much less risky than they actually are.      For cyber security, the relationship between risk perception and actuarial risk is much less well studied. Most studies investigate how risk perception impacts behavior, e.g., to bank and shop online.     This study would shed light on the origins of risk perceptions rather than its consequences by combining data on actuarial risk with data from risk perception surveys in several countries. The PREDICT database would provide data on the actuarial risk, i.e., the frequency of various types of cyber-attacks. A simple regression analysis would reveal, whether people in countries suffering more attacks or in countries from which more attacks originate are more concerned about cybersecurity.     If there is a large gap between actuarial risk and risk perception ÃƒÂ¢Ã‚â‚¬Ã‚â€ù i.e., if people feel safe when they should not-, policy to manage cyber risk perception and to boost participation by the public in keeping computer systems safe is urgently needed. If there is no such gap, policymakers should try to benefit from the publicÃƒÂ¢Ã‚â‚¬Ã‚â„¢s awareness in order to develop cost-efficient cyber risk management efforts.  ",,,,
C3E challenge problem,,,,
Abstract: Large scale attack traffic present challenges identifying and classifying attack behaviors. Offline host and flow clustering attempt to group similar behaviors in order to expedite analysis. The goal of this research is to move such clustering online and generate attack models. The Skaion sensor alerts will be mined for observables in order to cluster and produce the models.,,,,
Abstract: Large scale attack traffic present challenges identifying and classifying attack behaviors. Offline host and flow clustering attempt to group similar behaviors in order to expedite analysis. The goal of this research is to move such clustering online and generate attack models. The DShield sensor alerts will be mined for observables in order to cluster and produce the models.,,,,
The motivation of the project is to develop a comprehensive system that will capture the Internet topology at fine granularity and periodically provide snapshots of the Internet backbone. The mapping system will then be utilized to investigate topological characteristics of the Internet and provide an underlay for applications to optimize their communications. Compared to the existing Internet topology measurement platforms.,,,,
need the dataset to test a new algorithm for attack detection,,,,
This work is in connection with the challenge problem for the C3E workshop - sponsored by SCORE. We will investigate recognizable patterns in DNS records for malware detection. ,,,,
Evaluation of large scale anomalies using information distance metrics.,,,,
"This research project focuses on using a cutting-edge graph database, STINGER (stingergraph.com), and proprietary analysis algorithms to find anomalous or interesting patterns of network access. We plan to use Netflow data to build a graph of connection activity which will store the protocol, port, length of connection, amount of bytes transferred, and any other relevant attributes for each connection. We will then use graph analytics to detect anomalous behavior, centers of gravity, and common network paths. We also want to determine how the network flows differ depending on protocol. In addition to static analysis of the complete graph, we plan to playback the Netflow data to build the graph in ""real time"" and perform streaming analysis. Overall, we wish to perform these analyses in anticipation of detecting interesting, anomalous, or malicious behavior on a high-throughput network in real time.",,,,
Our goal is to detect DDoS attacks using clustering techniques and principal  component analysis. We need multiple timeseries in order to achieve this. Our initial analysis involves post forensic analysis of the data sets. We would also like to explore real time detection using the findings of this analysis.,,,,
Network and Information Processing,,,,
I would like to get the data in order to research malware detection techniques for the 2014 C3E workshop.  This database was identified as useful for the challenge problem.  The results of my team's analysis of the data will be presented at the workshop this October (2014).,,,,
"We are now research into high performance traffic classification using feature decomposition and utilize parallel computing. Also we want to detect abnormal behavior of traffic flow. Please provides us this valuable dataset. Thank you! ",,,,
We are now research into high performance traffic classification using feature decomposition and utilize parallel computing. Also we want to detect abnormal behavior of traffic flow. Please provides us this valuable dataset. Thank you! ,,,,
We are researching into a highly performance traffic classification algorithm that can also detect abnormal condition of the traffic flow using features decomposition to boost performance. Please provide us DoS data set to train our algorithm. Thank you!,,,,
Conducting traceroutes to inspect the average number of AS hops from a cloud service provider to other Internet prefixes. Using the hitlist to determine the best IPs to direct the traceroutes towards.,,,,
 the purpose of requesting this dataset is to use it in a research project about flow-based intrusion detection. The purpose of this research project is to utilize semantics and context in intrusion detection,,,,
This data will be used by Georgia Tech CyberSecurity operations as a feed into various operational tools to help better protect the Georgia Tech users and data.,,,,
"We consider the problem of large scale multiple testing for data that have spatially clustered signals. With this structure, we apply techniques from change-point inference and propose a boundary detection algorithm so that the spatial clustering information can be utilized. We show that by exploiting the spatial structure, the precision of a multiple testing procedure can be improved substantially",,,,
"We are working under an NSF grant to produce a map of the Internet backbone. We will use this data in developing our own database, along with data on A.S. relationships. Thanks for your help!",,,,
"I will be directing my focus to this resource of data for a independent study in the Computer Science of my university. I must understand data format, structure, and domain knowledge.",,,,
"Our dependence of the internet has grown much faster than our understanding of its underlying strucure, global dynamics, operational threats, and overall health. Large-scale internet service disruptions due to malware and/or politically motivated activities occur with some regularity.We have developed a methodology that uses dark space data from the UCSD Network Telescope, that identifies networks affected by an outage, and determines what techniques are used to cause deliberate disruption. We obtain metrics to quantitatively gauge the geographic and topological extent of the impact of geophysical disasters on internet infrastructure, and techniques to investigate the chronological dynamics of the outage and restoration.The USC Lander datasets provide reference information on normally reachable hosts/networks for the study and targeted analysis of these large-scale internet outages.This request is a follow-up to requests submitted in April and November 2013. If possible, we request that standing access is granted to future census hitlist, history and census datasets for the USC Lander West monitor (i.e. the it##w sequence of datasets).",,,,
Look to mine spam for malicious URLs and other indicators to more proactive identify malicious infrastructure for remediation.,,,,
Using the data to analyze for patterns to more proactively identify use of DNS in malware.,,,,
The goal of this project is to determine which domains/networks have previously been involved with hosting malware activity with the overall intent that this will be anther input source into our project that is trying to determine the overall reputation of various networks on the Internet.  The information will be aggregated up from individual IP addresses to higher level aggregations such as prefixes/ASes or even organizations.,,,,
"Helping federal civilian government organizations fuse and prioritize indicator sets as well as create improved situational awareness of intruder  activity, and enrich publications to advance the state of practice in Internet security analysis.",,,,
"The goal of this research is to determine a better estimate of the number of active hosts in a given prefix.  Our current approach to network reputation simply looks at the entire size of the prefix which gives us a lower-bound on the intensity of malicious activity (most mild estimate).For example we might detect x fraction of a prefix to be malicious but in reality it might be worse as the entire prefix might not actually be used.",,,,
Our research project studies network outages using a different set of methods.  Our goal in using this data is to compare and validate.,,,,
We plan to use Internet census data to study measurement dataset biases.,,,,
Our project studies network reliability semicolon we intend to use this data to compare and validate our separate measurement technique.,,,,
We perform anomaly detection on big communication data.,,,,
Working on Internet Measurement Project (NSF funded) for Dr.Mehmet Gunes at University of Nevada - Reno. I am a student. I am woking on software to parse and sort measurement data for our project.,,,,
"This data is part of the NCCDC competition. This data contains custom malware used by the red team as well as numerous uses of metasploit and potentially data relevant to mapping out red team pivoting between compromised machines. This project aims to understand the red team.The goal of this project is to extract custom malware, fingerprint it, and the traffic it creates.",,,,
"The research is related to network topology modeling and mapping, and its purpose is ""achieving a Subnet level map"" and ""studying characteristics of Subnets"" by using most recent dataset of subnets.In Detail, after sampling subnets in target domains, we will estimate their global characteristics and derive proper estimators for various subnet characteristics.",,,,
Model behavior profile for anomaly detection,,,,
"Our dependence on the Internet has grown much faster than our understanding of its underlying structure, global dynamics, operational threats, and overall health. Large-scale internet service disruptions due to malware and/or politically-motiviated activities occur with some regularity.We have developed a methodology, using dark space data from the UCSD Network Telescope, that can identify the networks that are affected by an outage, and can determine what techniques are used to cause a deliberate disruption. We have developed metrics to quantitatively gauge the geographic and topological extent of the impact of geophysical disasters on internet infrastructure, and techniques to investigate the chronological dynamics of the outage and restoration.The USC Lander datasets will provide required reference information on normally reachable hosts/networks for the study and targeted analysis of these large-scale Internet outages. This request is a follow-on to a request submitted in April 2013 (title: Strategies for combining heterogeneous datasets for the characterization of network outage events).",,,,
Apply the use of entropy for paramter selection for intrusion detection. Entropy is calculated for the different parameters presented and algorithms applied to select the most relevemt parameters to detect different classes of attacks.,,,,
"Analyzing the statistical characteristics of cyber threats as exhibited by Georgia Tech's sinkhole data. This datasets are complementary to the other datasets that my research team has been analyzing.",,,,
"We are performing a longitudinal study of malware population across the Internet, trying to understand what are the most/least infected regions and investigating trends over time. We will compare/integrate data from different sources and aggregate data at AS level or at country/city level through IP geolocation.",,,,
"We consider the problem of efficient online anomaly detection in computer network traffic. The problem is approached statically, as that of sequential change-point detection. A multi-cycle setting of quickest change detection is a natural fit for this problem. We propose a novel score-based multi-cyclic detection algorithm.As a case study, we are going to verify our algorithm using network traffic with maliciousness embedded. ",,,,
"Characterize scanners of IPv4 address spacebased on what shows up in darknet address space.We plan to compare what we see in a large (/8) darknet in this data with our own small internal darknets.",,,,
"Firewalls are the primary security devices in cyber defense. Yet, the security of firewalls depends on the quality of protection obtained by the firewall policy hardening.The lack of metrics and attack incident data make measuring the security of firewall policies a challenging task. This requires defining a set of objective metrics to measure and to compare quality of protection of firewall policies objectively.This research project intends to propose a new set of quantitative metrics that can be used to measure and to compare the security level of firewall policies in an enterprise network. The presented metrics should be proven to be (1) valid as compared with the ground truth, and (2) practically useful as each one implies actionable security hardening. ÃƒÂ¢Ã‚â‚¬Ã‚Å“DShield dataset ÃƒÂ¢Ã‚â‚¬Ã‚Å“ will be used to show that the implementation and usability of these metrics are attainable and affordable.",,,,
"I am doing research on different types of attacks, and I would like to find a way to develop cyber resilience framework, including prevention, sustainment, and recovery.",,,,
"Our dependence on the Internet has rapidly grown much stronger than ourcomprehension of its underlying structure, global dynamics, operationalthreats, and overall network health. Wide-scale Internet service disruptionsand even politically motivated interference with Internet access in orderto hinder anti-government organization are not new.We have developed a methodology, using dark space data from the UCSD NetworkTelescope, that can identify which networks are affected by an outage, andwhich techniques are used to effect a deliberate disruption. We have alsodeveloped metrics to quantitatively gauge the geographic and topologicalextent of the impact of geophysical disasters on Internet infrastructure, andtechniques to investigate the chronological dynamics of the outage andrestoration.The USC Lander address history and hitlist datasets will provide referenceinformation on normally reachable hosts/networks for the study and targetedanalysis of these large-scale Internet outages.",,,,
This research is concerned with the design and analysis of statistical methodology for rapid intrusion detection in cybersecurity. Real data are needed to validate the proposed algorithms.,,,,
"The basis of the research is to study the feature of various network flows and use the parametric estimation method and fitting test to find the difference between the flows in their distribution and parameters. But what we have got now is not sufficient for the statistical research. More dataset , especially the DoS/DDoS attack ones, are need to go on. We would apply for three datasets: Dos 80-20110715, UniformnAttack Traces Generated20070821-20041202 and UniformAttack traces-20070115.DoS 80-20110715 is used to study DoS attack with background traffic. UniformnAttack Traces Generated20070821-20041202 and UniformAttack traces-20070115 are used to study the same uniform attack with different background traffic. We will use statistical software such as Matlab to get the statistical characteristics and then more researches will be done. We will be appreciated if our request are approved.",,,,
"This dataset will be used to test anomaly detectors of observed DNS activity, particularly fluxing. ",,,,
"We want to develop module for DDoS attack detection. In particular, we want to test existing DDoS detection tool such as Snort on this dataset.",,,,
The research is focused on private sector funding for information security.  Are businesses allocated sufficient resources to information security to combat the growing number of cyber attacks?  The requested data will be used to create trends in the quantity of attacks over time.,,,,
"In this project, we aim to study internet traffic  and detect what indicators could help in identifying security incidents. We are interested in using this dataset to craft a profile of baseline traffic in absence of incidents.",,,,
"This work is part of CAIDA's SaTC project (""Detection and analysis of large-scale Internet infrastructure outages"") funded by NSF.  All work will be conducted at CAIDA, UC San Diego.          http://www.caida.org/funding/satc/This project will result in an experimental operational deployment to validate and extend an empirically-grounded methodology for detection and analysis of large-scale Internet outages. In addition to improving our understanding of how measurements yield insights into network behavior, and strengthening our ability to model large scale complex networks, use of such a system will also illuminate infrastructure vulnerabilities that derive from architectural, topological, or economic constraints, suggesting how to mitigate or eliminate these weaknesses in future Internet architecture and measurement research. A deployed platform will be able to detect and monitor connectivity disruption and censorship events on a planetary scale thus enabling situational awareness of the nature and causes of network outages to national decision-makers who must determine the type and extent of proper response.We need a set of known responding destinations so that we can regularly probe them to determine outages caused by Hurricane Sandy and other causes.",,,,
"For purposes of our research, we propose to use this data to study abnormalities in network activity. An abnormality in network activity/traffic flow is determined by an unusual shift or increase from the base probability between two givennodes. The objective of this study is to understand and define the normal occurrence of activity on a network using ascanning approach, in order to be able to detect any anomalies or groups of anomalies (an anomalous window) in thetraffic flow and how it related to particular topology of nodes in the network. The contributions of this study are directed towards providing new insights on the issue of cyber security, particularly from a data mining perspective.",,,,
"For purposes of our research, we propose to use this data to study abnormalities in network activity.  An abnormality in network activity/traffic flow is determined by an unusual shift or increase from the base probability between two given nodes. The objective of this study is to understand and define the normal occurrence of activity on a network using a scanning approach, in order to be able to detect any anomalies or groups of anomalies (an anomalous window) in the traffic flow and how it related to particular topology of nodes in the network. The contributions of this study are directed towards providing new insights on the issue of cyber security, particularly from a data mining perspective.",,,,
"In response to a recent ""request for proposals"" from the Institute for Homeland Security Solutions, I am interested in data to examine internet use over both space and time, specifically with the intent to understand how internet use has grown across countries and over time, and how the number of security threats (internet attacks or disruptions of various forms) have grown, too. With this data, I intend to use Econometric techniques to explain two features of internet use (the field of Econometrics is a specialty in Economics, where the econometrician applies advanced statistics to economic problems).  One, I can describe and explain the time series properties of internet use and disruptions to that use.  Understanding the time series properties of the data is fundamental to understanding how the phenomenon evolves and further understanding what might affect or disrupt internet traffic.  An analogy from economics in general would be Gross Domestic Product in the United States.  Econometricians take great pains to explain the time series properties of gross domestic product in order to understand how the long run trend changes over time and how the economy fluctuates around that trend.  My project is based on the premise that understanding how internet use evolves over time is important to explaining how policy makers may or may not be able to predict when a disruption will occur, just as economists attempt to predict when a recession might occur in the economy at large. The second feature of internet use that PREDICT data may allow me to explore is the cross-country characteristics of internet use (note, data collected both over space and time is known as ÃƒÂ¢Ã‚â‚¬Ã‚Å“panel dataÃƒÂ¢Ã‚â‚¬Ã‚Âù to econometricians, or ÃƒÂ¢Ã‚â‚¬Ã‚Å“longitudinal dataÃƒÂ¢Ã‚â‚¬Ã‚Âù in the social sciences more broadly).  Understanding how internet use has spread across countries over time may also be important for understanding the policy implications of internet attacks or disruptions.  The policy implications may include not just diplomatic conflict, but also measuring the cost of the disruptions emanating from one country on another countyÃƒÂ¢Ã‚â‚¬Ã‚â„¢s economy, or the cost of guarding against future attacks or disruptions.  For the cyber world, an analogy from the real world is economists are interested in understanding how goods and services flow between countries, and then understanding the policy implications of the disruptions to that flow, such as arising from trade embargo or even from piracy. I am interested in the PREDICT data sets to see if they can be used in such a study as I have described.  Thus far, little has been said about the time series and longitudinal properties of internet traffic, no doubt due to the lack of data on the subject.  However, with the PREDICT data, I may be able to begin to piece together a panel data set in order to address the issues alluded to above.  I am interested in this data as an econometrician, but also, my employer, the US Naval Academy, has just begun an initiative to study Cyber Defense (and Warfare).  My current research project is motivated in part by that larger agenda.I am interested in this data as an econometrician, but also, my employer, the US Naval Academy, has just begun an initiative to study Cyber Defense (and Warfare).My current research project is motivated in part by that larger agenda.",,,,