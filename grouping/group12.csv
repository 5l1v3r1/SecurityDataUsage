 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| CCS’16, October 24-28, 2016, Vienna, Austria © 2016 ACM ISBN 978-1-4503-4139-4/16/10  |,Non-data,32
 $1500 DOI: http://dxdoiorg/10,Non-data,32
1145/29767492978322 libraries A previous study shows that 85% of the apps in the Google Play store contain at least one embedded browser (ie,Non-data,32
|, WebView on Android) [1] Other than the natural use case of just displaying web content, there are some interesting ways to use these web containers in apps: advertisement libraries use embedded browsers to display ad content within apps, app developers can rely on embedded browsers to tightly couple web sites with similar functionality to the app in order to reuse web site’s UI code and to provide fast and convenient updates Additionally, hybrid frameworks (eg|,Non-data,32
|, PhoneGap) rely on embedded browsers to enable app developers to write their apps purely with web languages (eg, JavaScript and HTML) with the premise of ease of programming and portability to other mobile operating systems Even though they are extremely useful, these embedded browsers come with their own security problems|,Non-data,32
| They are inherently given the ability to execute web code (ie, JavaScript) Additionally, through the use of JavaScript bridges, they can allow web code to interact directly with app components (i|,Non-data,32
|e, internal Java code) Indeed, these bridges are what hybrid apps rely on to allow access to system re- sources such as contact list, camera, Bluetooth, SMS etc Obviously, the misuse of this functionality by malicious web domains can be detrimental to the user and to the app since an attacker, whose web domain (hence malicious code) was loaded into a WebView can exploit the existing bridges to collect information about the user and even change the app’s behavior|,Non-data,32
| The main problem here is that there is no means of performing access control on the untrusted code running within a WebView, any origin loaded into the WebView is free to use all the available JavaScript bridges With the introduction of API level 17, Android made an attempt to mitigate the negative consequences of this problem (ie, accessing Android runtime via Java reflection) by introducing mechanisms to allow the developer to specify which methods will be exposed to JavaScript|,Non-data,32
| However, this does not eliminate the problem as the untrusted code loaded into a WebView still inherits the same permissions as the host app and can exploit just the exposed parts of the bridge to perform its malicious activities Since the origin (as in same origin policy) infor- mation is not propagated through the bridge, the app developer has no control over this access attempt and cannot perform any access control based on the origin Prior research studies on security issues in WebViews and Java- Script bridges fall short in at least four significant ways First, they have limited scope, since they mainly target hybrid apps and create solutions that work only for the hybrid frameworks [2]|,Non-data,32
| Second, they are incomplete, since they focus only on protecting permission- protected resources (such as the camera and microphone) [2, 3], and disregard other cases where a foreign domain is inadvertently allowed to access sensitive information (such as a user’s social secu- rity number) Third, they rely on whitelisting policies that always 104block unknown domains and therefore deprive developers of the flexibility to make decisions based on user input Fourth, they are ad hoc since they focus only on a subset of resource access channels and do not provide a uniform solution that works across all channels The current disorganized and complex nature of interactions be- tween web origins and applications creates confusion for developers|,Non-data,32
| From our inspection of the apps in the Google Play store, we ob- served that the danger of loading untrusted web origins and exposing resources to them is not very well understood by app developers Developers mistakenly assume that targeting API versions that ad- dress some of the issues with embedded browsers (eg, using API level 17 or higher on Android) will protect their apps from these vulnerabilities|,Non-data,32
| When they seem to be aware of the danger, assuring protection seems to be burdensome, and they tend to make mistakes while trying to evade the problem by implementing navigation con- trol logic or multiple WebViews with different levels of exposure However, even taking the correct programmatic precautions does not completely eradicate the problem since there is no guarantee that a trusted web domain will consist only of trusted components Indeed, it is quite common for web pages to use an iframe in order to display ad content, and once loaded, there is no means for a developer to protect the resources that were exposed to web content from these potentially malicious components All of this creates the necessity for an access control mechanism targeting web code where devel- opers are given the ability to specify desired access characteristics of web origins in terms of app and device resources|,Non-data,32
| Developers should be allowed to specify what capabilities should be given to web origins with a fine granularity, and if they need user input to make decisions This brings forth the need for a policy language, which developers can use to describe the expected behavior and use of resources by web origins, without having to rely on any complex programmatic structures, and the need for a mechanism that will take into consideration the developer policies to make access control decisions In this work, we systematically study the vulnerabilities that are caused by loading untrusted web domains in WebViews on Android We show cases where top-selling Android apps suffer from these vulnerabilities|,Non-data,32
| Based on the threats we identified, we designed an easy to use, declarative policy language called Draconian Policy Language (DPL) for developers to specify access control policies on resources exposed to web origins DPL allows declaration of policies with different levels of trust (ie, fully-trusted, semi-trusted, untrusted) for different origins|,Non-data,32
| We implement a system called Draco for fine-grained access control of web code: Draco enables app devel- opers and device manufacturers (OEMs) to insert explicit Draconian policies into their apps, and dynamically enforces these policy rules at runtime in an efficient manner Our contributions can be summa- rized as follows: 1 We model web origin access and design a new policy language for app developers and device manufacturers to dictate how web origins should access resources 2|,Non-data,32
 We provide a fine-grained access control runtime system for web containers to make access control decisions based on ori- gins and their expected behavior without requiring OS modi- fications 3 We provide a real world implementation that works on An- droid devices and evaluate the overhead of our approach The rest of the paper is organized as follows,Non-data,32
| In section 2, we give background information on how the Android embedded web browser works In section 3, we describe the problems caused by the lack of a uniform access control mechanism in WebView in more detail, show our analysis on the use of WebView APIs by the top free apps on Google Play Store, and present case studies of top-selling Android apps that suffer from this problem In section 4, we present the Draco framework, which consists of a declarative policy language for controlling web code execution and a runtime system that enforces the policies in Chromium’s Android WebView implementation In section 5, we evaluate our implementation|,Non-data,32
| In section 6, we present related work on privilege separation and WebView vulnerabilities Finally in section 7, we conclude with a discussion of our future work 2 BACKGROUND We refer to the applications that utilize WebViews as mobile web apps [1]|,Non-data,32
| In order to understand the vulnerabilities caused by embedded browsers in mobile web apps, we need to have an understanding of the functionalities provided by these browsers For the rest of the paper, we will focus on Android WebView, which is the widely-used open source embedded browser that forms the basic building block for modern web browser applications on the Android platform This web container allows app developers to display web content fetched from the local storage or from the web Developers use WebViews to seamlessly integrate web content into their apps, without having to rely on a full-featured, heavy-weight web browser to render web content|,Non-data,32
 21 WebView Implementation WebView was first introduced in the API level 1 of the Android platform It inherits from Android View and has additional render- ing capabilities for displaying web pages In Android 4,Non-data,32
|3 (Jelly- Bean) and earlier, WebView implementation is based on Apple’s WebKit browser engine [4], which powers several web browsers such as Safari, Google Chrome and Opera Starting from Android 44 (KitKat), the WebView implementation is instead based on Chromium [5], which is Google’s widely-used, open-source browser project Chromium uses Google’s fork of WebKit, called Blink, as a rendering engine, and Google’s high-performance V8 JavaScript engine|,Non-data,32
| Up until Android 44 (inclusive), the WebView implementation resided in the Android Open Source Project (AOSP) [6]; hence, any update to the WebView requires modifications to the operating system and can be pushed to users only with an OS update With the introduction of Android 5 (Lollipop), WebView became a system app (called Android System WebView), presumably to ship updates quickly to the WebView code through Google Play Apps that use WebViews load WebView code as a library into the app’s process from the System WebView app|,Non-data,32
| 22 WebView API The WebView API allows app developers to load web content by calling the methods loadURL(), loadData(), loadDataWithBaseURL() and postURL() with a string argument that is the URL of the desired web content JavaScript can be enabled on a WebView by calling setJavaScriptEnabled() on a WebSettings instance of a WebView The source of JavaScript can be a file on the local storage or a remote domain|,Non-data,32
| Additionally, the app can directly execute JavaScript by calling loadURL() with a string that starts with “javascript:” and is followed by the JavaScript code Navigation Android developers have the option of controlling nav- igation within WebViews Whenever the user clicks on a link in a page on a WebView, the developer can intercept this to make a decision on how this page should be loaded, or if it should be loaded at all|,Non-data,32
| Developers have the option of allowing page loading 105from only certain domains, and open pages from untrusted domains in the web browser This can be implemented by overriding the shouldOverrideUrlLoading() callback method and checking the do- main of the page before it is loaded  JavaScript interfaces The WebView API allows inserting Java ob- jects into WebViews using the addJavaScriptInterface() method|,Non-data,32
| JavaScript loaded in the WebView can have access to application’s in- ternal Java code, giving web code the ability to interact more tightly with an app, and in some cases get access to system resources (eg, hybrid frameworks) Mobile web apps commonly utilize JavaScript interfaces to meld web content with application code and provide users with a richer user experience compared to pure web apps|,Non-data,32
| Listing 1 shows how JavaScript interfaces can be used in appli- cations First, the app needs to register a Java object with a spe- cific WebView instance and give this object a name As shown in the example, this can be done by addJavaScriptInterface(new MyJSInterface(),"InjectedObject") After this, JavaScript code running in the WebView can execute the methods of this object by using the name of the object and the name of the method, as in InjectedObject|,Non-data,32
|myExposedMethod() Android API 17 introduced the use of @JavaScript annotation tag to export only the desired Java methods of a Java class to JavaScript, primarily to prevent reflection-based attacks, where an adversary can use Java reflection to get access to the Android runtime and then ex- ecute arbitrary commands via calling InjectedObjectgetClass() forName("java|,Non-data,32
|langRuntime")getMethod("getRuntime",null) invoke(null,null)|,Non-data,32
|exec(cmd) The use of the annotations is illus- trated in Listing 1, where only the annotated method is made acces- sible to JavaScript Even though API level 17 addresses a critical problem, it does not completely eradicate all the issues with Web- Views WebView still provides no access control on the JavaScript interfaces; any domain whose content was loaded into a WebView is free to use all the exported parts of the exposed Java object|,Non-data,32
| Listing 1: JavaScript Interfaces in Android WebView mWebViewaddJavaScriptInterface(new MyJSInterface(), "InjectedObject"); //|,Non-data,32
| public class MyJSInterface { @JavaScriptInterface public void myExposedMethod() { // do some sensitive activity } public void myHiddenMethod() { // JavaScript cannot access me, do some other activity } } JavaScript event handlers The WebView API allows develop- ers to handle the alert, prompt and confirm JavaScript events, by registering the onJsAlert(), onJsPrompt() and onJsConfirm() Java callback methods, respectively Whenever the JavaScript side calls any of these event methods, their respective handler will be called, if it is overridden The developer is free to implement any logic in these event handlers|,Non-data,32
| In fact, these event handlers are used in some hybrid frameworks to connect the web side to the local side Handling HTML5 API requests The rise of HTML5 has brought in a set of APIs that can give web applications the ability to access de- vice hardware via JavaScript Some examples to these HTML5 APIs are Geolocation and getUserMedia, which enable access to GPS and to media devices such as camera and microphone, respectively|,Non-data,32
| When a web domain requests access to one of these devices, the user should be prompted to grant access to this request Starting from API level 21, Android WebView provides support for these HTML5 APIs and introduces mechanisms to grant or deny requests for accessing device hardware In order to handle requests from web origins, the developer needs to make use of onGeolocationShowPrompt (for ge- olocation), and onPermissionRequest (for media devices) to grant or deny permission to the requests In Listing 2, we show an example of how HTML5 geolocation permission can be handled on Android|,Non-data,32
| Listing 3 shows how granting permissions for HTML5 request will be combined with Android 60’s run time permissions Evidently, handling HTML5 requests can get cumbersome when combined with Android 60’s run time permissions|,Non-data,32
| Listing 2: Granting access to HTML5 geolocation requests @Override public void onGeolocationPermissionsShowPrompt(String origin, GeolocationPermissionsCallback callback) { myCallback = callback; //myCallback is global //If the permission is not yet granted, ask for it if (ContextCompatcheckSelfPermission(getApplicationContext(), Manifest|,Non-data,32
|permissionACCESS_FINE_LOCATION) != PackageManagerPERMISSION_GRANTED) { ActivityCompatrequestPermissions(thisActivity, new String[]{Manifest|,Non-data,32
|permissionACCESS_FINE_LOCATION}, MY_PERMISSIONS_REQUEST_ACCESS_FINE_LOCATION); } else { // Permission is already granted callbackinvoke(origin, true, false); } } Listing 3: Run time permissions on Android @Override public void onRequestPermissionsResult(int requestCode, String permissions[], int[] grantResults) { switch (requestCode) { case MY_PERMISSIONS_REQUEST_ACCESS_FINE_LOCATION: { if (grantResultslength > 0 && grantResults[0] == PackageManager|,Non-data,32
|PERMISSION_GRANTED) { // permission was granted, do your location task myCallbackinvoke(myOrigin, true, false); } else { // permission denied // disable functionality depenging on this permission } //Handle other permissions|,Non-data,32
| 3 UNDERSTANDING THE PROBLEM In this section, we will discuss the lack of access control in Java- script bridges in WebView We will argue that even though the Android APIs for handling HTML5 requests provide the means to perform limited origin-based access control (i|,Non-data,32
|e, only for a subset of the device resources), developers simply avoid leveraging that due to the cumbersome and complex nature of the permission han- dling APIs Finally, we will present our case studies on two mature and popular free Android apps that suffer from the nonexistence of access control in WebViews 3|,Non-data,32
|1 Lack of Access Control in WebView The vulnerabilities in WebViews have been investigated by previ- ous work [1, 7, 8, 9, 10] A recurrent and fundamental problem is that there is no way of performing access control on the foreign code executed within a WebView; any origin loaded into the WebView is free to use the exposed JavaScript bridges In particular, since the origin information is not propagated to the app through the bridges, the app developer has no control over the behavior of foreign code and cannot make access decisions based on the real origin of the 106invocation With the introduction of API level 17, Android addressed some critical problems of WebViews such as reflection-based attacks by introducing Java annotations into the WebView API to limit the extent of exposure|,Non-data,32
| However, this does not completely solve the problem as the foreign code loaded into the WebView still has the same permissions as the host app, and it can exploit the exposed parts of the JavaScript bridges to perform malicious activities such as accessing system resources, getting the user’s private information, and executing code that was meant for use only by the web domain of the developer In order for a JavaScript bridge to be exploitable, the app must load untrusted content into the associated WebView An obvious way is by allowing the WebView to navigate to untrusted websites or to sites with untrusted content (eg|,Non-data,32
|, iframe) Previous work shows that navigation to untrusted sites is common among applications: 34% of the apps that use WebViews do allow the user to navigate to third-party websites [1], and 425% of the apps that register a JS interface allow the user to navigate to third-party websites or to web- sites with untrusted content [8] In order to verify these results, we picked three top-selling Android apps that demonstrate the common vulnerabilities identified by previous work: USPS, CVS Caremark, and JobSearch by Indeed|,Non-data,32
| Through manually analyzing their code, we observed that developers do try to take precautions against the attacks on JS bridges by loading pages from untrusted domains in either the browser instead of the WebView (eg, USPS app), or in separate WebViews with limited functionality which they create for this purpose (eg|,Non-data,32
|, JobSearch app by Indeed) However, developers can make mistakes while implementing the navigation control logic For example, in the USPS app, the developer checks if the loaded URL contains “uspscom” rather than checking if the host’s domain name matches “usps|,Non-data,32
|com”, mistakenly allowing any non-USPS web- site that partially matches “uspscom” (eg, musps|,Non-data,32
|com, uuspscom) Additionally, developers might make wrong assumptions about the navigation behavior of the WebView We have identified that the app developer might assume that the content provided to the Web- View intrinsically does not allow navigation (i|,Non-data,32
|e, it does not contain hyperlinks) and provide the user with functionalities that can break this assumption (eg, allowing users to input hyperlinks) as in Job- Search app by Indeed, or they simply do not foresee that a specific WebView can be used by the user to navigate out of the trust-zone of the app by just following the links on the web pages as in the CVS Caremark app|,Non-data,32
| We will examine the CVS Caremark and JobSearch apps in more detail later in this section Although it may look like correct implementation of navigation control would solve the JavaScript bridge exploitation issues (and fix the USPS app), we argue that it is simply an insufficient measure to protect JavaScript bridges Even if developers implement all navigation behavior correctly and do not allow the user to navigate to untrusted web origins within the context of their apps, the pages from trusted domains might include untrusted components such as iframes, which also inherit the same permissions as the app and have access to all the exposed bridges Thus, the system does not provide the necessary means for developers to completely protect their apps against attacks on the JavaScript bridges|,Non-data,32
| 32 Prevalence While the current design of JavaScript bridges by default grants access to a domain for all the exposed resources, for HTML5 APIs the access model is exactly the opposite; the default behavior is to deny all the requests by a domain for a permission unless the onPermissionRequestResult and onPermissionsRequest or onGeolocationPermissionPrompt methods are overridden by the app developer In order to better understand how this difference between the JavaScript bridges and the HTML5 APIs affects the develop- ers, we statically analyzed the top 1337 free Android applications from 21 Google Play categories selected at our discretion Table 1 depicts the prevalence of WebViews and how often WebView APIs are used in these apps|,Non-data,32
| Here, we distinguish ad and core WebViews (WebView in the core of the app) based on our comprehensive list of package names for ad libraries, and also give the cumulative result including both uses of WebView In line with the previous work [1, 8], we have observed that WebView is a commonly-used component as around 92% of the applications in our dataset make use of it in their core application code (ie, not used by advertisement libraries)|,Non-data,32
| Among the applications that include at least one WebView in their core code, 77% of them use JavaScript interfaces, and 70% use event handlers However, it can be observed that there is a sudden drop in the numbers when it comes to the use of HTML5 APIs This might be happening for two reasons On the one hand, developers generally do not wish to grant access to permission-protected re- sources to external domains, and apps can operate without having to rely on external web origins|,Non-data,32
| On the other hand, even though more than 85% of the apps in our dataset target API 21 or higher and are able to handle HTML5 API requests, they simply decide not to do so, possibly due to the complex request handling logic of the HTML5 APIs Since the majority of the apps require API 21 or higher, they need to comply with the run time permissions introduced by Android 60 This means that each time they wish to grant access to a web domain, they also need to check if the app was granted the permission of interest by the user and, if not, they must prompt the user to grant it|,Non-data,32
|ABSTRACT We describe a lightweight protocol for oblivious evaluation of a pseudorandom function (OPRF) in the presence of semi- honest adversaries In an OPRF protocol a receiver has an input r; the sender gets output s and the receiver gets output F (s, r), where F is a pseudorandom function and s is a random seed Our protocol uses a novel adaptation of 1- out-of-2 OT-extension protocols, and is particularly efficient when used to generate a large batch of OPRF instances The cost to realize m OPRF instances is roughly the cost to realize 3|,Non-data,34
|5m instances of standard 1-out-of-2 OTs (using state-of-the-art OT extension) We explore in detail our protocol’s application to semi- honest secure private set intersection (PSI) The fastest state- of-the-art PSI protocol (Pinkas et al, Usenix 2015) is based on efficient OT extension|,Non-data,34
 We observe that our OPRF can be used to remove their PSI protocol’s dependence on the bit-length of the parties’ items We implemented both PSI protocol variants and found ours to be 31–36× faster than Pinkas et al,Non-data,34
| for PSI of 128-bit strings and sufficiently large sets Concretely, ours requires only 38 seconds to securely compute the intersection of 220-size sets, regardless of the bit length of the items For very large sets, our protocol is only 4|,Non-data,34
|3× slower than the insecure na ̈ıve hashing approach for PSI 1 INTRODUCTION This work involves OT, OPRF and PSI constructions We start by reviewing the three primitives|,Non-data,34
 Oblivious Transfer Oblivious Transfer (OT) has been a central primitive in Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita- tion on the first page Copyrights for components of this work owned by others than ACM must be honored Abstracting with credit is permitted,Non-data,34
| To copy otherwise, or re- publish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acmorg CCS’16, October 24-28, 2016, Vienna, Austria c(cid:13) 2016 ACM|,Non-data,34
 ISBN 978-1-4503-4139-4/16/10   $15,Non-data,34
00 DOI: http://dxdoiorg/101145/2976749,Non-data,34
|2978381 the area of secure computation Indeed, the original proto- cols of Yao [30] and GMW [7, 8] both use OT in a critical manner In fact, OT is both necessary and sufficient for se- cure computation [15] Until early 2000’s, the area of generic secure computation was often seen mainly as a feasibility exercise, and improving OT performance was not a priority research direction|,Non-data,34
 This changed when Yao’s Garbled Cir- cuit (GC) was first implemented [20] and a surprisingly fast OT protocol (which we will call IKNP) was devised by Ishai et al [12] The IKNP OT extension protocol [12] is truly a gem; it allows 1-out-of-2 OT execution at the cost of computing and sending only a few hash values (but a security parameter of public key primitives evaluations were needed to bootstrap the system) IKNP was immediately noticed and since then universally used in implementations of the Yao and GMW protocols,Non-data,34
| It took a few years to realize that OT extension’s use goes far beyond these fundamental applications Many aspects of secure computation were strengthened and sped up by using OT extension For example, Nielsen et al [24] propose an approach to malicious two-party secure compu- tation, which relates outputs and inputs of OTs in a larger construction|,Non-data,34
| They critically rely on the low cost of batched OTs Another example is the application of information- theoretic Gate Evaluation Secret Sharing (GESS) [16] to the computational setting [17] The idea of [17] is to stem the high cost in secret sizes of the GESS scheme by evaluating the circuit by shallow slices, and using OT extension to ef- ficiently “glue” them together Particularly relevant for our work, efficient OTs were recognized by Pinkas et al|,Non-data,34
| [28] as an effective building block for private set intersection, which we discuss in more detail later The IKNP OT extension, despite its wide and heavy use, received very few updates In the semi-honest model it is still state-of-the-art Robustness was added by Nielsen [23], and in the malicious setting it was improved only very re- cently [2, 14]|,Non-data,34
| Improvement for short secret sizes, motivated by the GMW use case, was proposed by Kolesnikov and Ku- maresan [18] We use ideas from their protocol, and refer to it as the KK protocol Under the hood, KK [18] noticed that one core aspect of IKNP data representation can be ab- stractly seen as a repetition error-correcting code, and their improvement stems from using a better code As a result, 818instead of 1-out of-2 OT, a 1-out of-n OT became possible at nearly the same cost, for n up to approximately 256|,Non-data,34
| Oblivious PRFs An oblivious pseudorandom function (OPRF) [6] is a pro- tocol in which a sender learns (or chooses) a random PRF seed s while the receiver learns F (s, r), the result of the PRF on a single input r chosen by the receiver While the gen- eral definition of an OPRF allows the receiver to evaluate the PRF on several inputs, in this paper we consider only the case where the receiver can evaluate the PRF on a single input The central primitive of this work, an efficient OPRF pro- tocol, can be viewed as a variant of Oblivious Transfer (OT) of random values|,Non-data,34
| We build it by modifying the core of OT extension protocols [12, 18], and its internals are much closer to OT than to prior works on OPRF Therefore, our presentation is OT-centric, with the results stated in OPRF terminology OT of random messages shares many properties with OPRF In OT of random messages, the sender learns random m0, m1 while the receiver learns mr for a choice bit r ∈ {0, 1}|,Non-data,34
| One can think of the function F ((m0, m1), r) = mr as a pseudorandom function with input domain {0, 1} Similarly, one can interpret 1-out-of-n OT of random messages as an OPRF with input domain {1,   |,Non-data,34
| , n} In this work, we propose a novel extension to the IKNP and KK protocols At almost the same cost as 1-out-of-2 IKNP and KK OTs, we are able to achieve an 1-out-of-n OT of random messages for arbitrarily large n This can be viewed as an OPRF with unbounded input domain {0, 1}∗|,Non-data,34
| That is, the receiver has an input r ∈ {0, 1}∗ and learns the value R(r), while the sender obtains the ability to evaluate R(r(cid:48)) for any string r(cid:48), where R is a pseudorandom function We call our main protocol batched, related-key OPRF (BaRK-OPRF) since it achieves a large number of OPRF instances, with keys that are related (in a way we describe later) This is a new primitive, which nevertheless suffices for the application to private set intersection that we con- sider Application to Private Set Intersection (PSI)|,Non-data,34
| Private set intersection (PSI) refers to the setting where two parties each hold sets of items and wish to learn noth- ing more than the intersection of these sets Today, PSI is a truly practical primitive, with extremely fast cryptograph- ically secure implementations [27] Incredibly, these imple- mentations are only a relatively small factor slower than than the na ̈ıve and insecure method of exchanging hashed values Among the problems of secure computation, PSI is probably the one most strongly motivated by practice|,Non-data,34
| In- deed, already today companies such as Facebook routinely share and mine shared information [25, 31] In 2012, (at least some of) this sharing was performed with insecure naive hashing Today, companies are able and willing to tolerate a reasonable performance penalty, with the goal of achiev- ing stronger security [31] We believe that the ubiquity and the scale of private data sharing, and PSI in particular, will continue to grow as big data becomes bigger and privacy becomes a more recognized issue|,Non-data,34
| We refer reader to [27, 28] for additional discussion and motivation of PSI In our work, we significantly improve state-of-the-art PSI protocol of [27] by replacing one of its components with BaRK-OPRF This change results in a factor 23–3|,Non-data,34
|6× perfor- mance improvement for PSI of moderate-length strings (64 or 128 bits) and reasonably large sets We substantiate our algorithmic results with implementation and detailed evalu- ation Our largest improvement is for the case of larger sets (224 items each) of long strings (128 bits), which requires only one minute in our protocol but 214 seconds using [27] 1|,Non-data,34
|1 Related work Oblivious transfer Our BaRK-OPRF protocol can be seen as an OPRF proto- col as well as a variant of oblivious transfer in the paradigm of IKNP [12] As mentioned in Section 1, given its critical importance in secure computation, the IKNP OT extension has a surprisingly short list of follow up improvements, ex- tensions and generalizations Most relevant prior work for us is the KK protocol [18], which views the IKNP OT from a new angle and presents a framework generalizing IKNP|,Non-data,34
| More specifically, under the hood, players in the IKNP protocol encode Receiver’s se- lection bit b as a repetition string of k copies of b KK generalized this and allowed the use of an error-correcting code (ECC) with large distance as the selection bit encod- ing For a code consisting of n codewords, this allowed to do 1-out of-n OT with consuming a single row of the OT ex- tension matrix In this work, we take the coding-theoretic perspective to the extreme|,Non-data,34
| We observe that we never need to decode codewords, and by using (pseudo-)random codes we are able to achieve what amounts to a 1-out-of-poly OT by consuming a single row of the OT matrix, which for the same security guarantee is only about 35× longer than in the original IKNP protocol Our work is strictly in the semi-honest security model Other work on OT extension extends the IKNP protocol to the malicious model [2, 14] and the PVC (publicly verifiable covert) model [19]|,Non-data,34
| Oblivious PRF Oblivious pseudorandom functions were introduced by In general, the Freedman, Ishai, Pinkas, & Reingold [6] most efficient prior protocols for OPRF require expensive public-key operations because they are based on algebraic PRFs For example, an OPRF of [6] is based on the Naor- Reingold PRF [22] and therefore requires exponentiations|,Non-data,34
| Furthermore, it requires a number of OTs proportional to the bit-length of the PRF input The protocol of [3] con- structs an OPRF from unique blind signature schemes The protocol of [13] obliviously evaluates a variant of the Dodis- Yampolskiy PRF [4] and hence requires exponentiations (as well as other algebraic encryption components to facilitate the OPRF protocol) Private set intersection|,Non-data,34
| Oblivious PRFs have many applications, but in this paper we explore in depth the application to private set intersec- tion (PSI) We consider only the semi-honest security model Our PSI protocol is most closely related to that of Pinkas et al [27], which is itself an optimized variant of a previous protocol of [28]|,Non-data,34
| We describe this protocol in great detail in Section 5 We refer the reader to [28] for an overview of the many different protocol paradigms for PSI As we have mentioned, 819the OT-based protocols have proven to be the fastest in prac- tice We do, however, point out that the OT-based proto- cols do not have the lowest communication cost|,Non-data,34
| In settings where computation is not a factor, but communication is at a premium, the best protocols are those in the Diffie-Hellman paradigm introduced in [11] In the semi-honest version of these protocols, each party sends only 2n group elements, where n is the number of items in each set However, these protocols require a number of exponentiations proportional to the number of items, making their performance slow in practice Concretely, [27] found Diffie-Hellman-based proto- cols to be over 200× slower than the OT-based ones|,Non-data,34
| While we closely follow the paradigm of [28], we abstract parts of their protocol in the language of oblivious PRFs (OPRF) The connection between OPRF and PSI was al- ready pointed out in [6] However, the most straightforward way of using OPRF to achieve PSI requires an OPRF pro- tocol in which the receiver can evaluate the PRF on many inputs, whereas our OPRF allows only a single evaluation point for the receiver OPRFs have been used for PSI else- where, generally in the malicious adversarial model [13, 10, 9]|,Non-data,34
| Other applications of OPRF Just like a standard OPRF, our BaRK-OPRF variant im- mediately and efficiently implies the keyword search func- tionality of [6] (also called “string-select OT (SOT)” in [17]) Keyword search allows the receiver R to select the received In SOT the sender S has a mapping secret via a string of keywords to secret values|,Non-data,34
| R receives the secret corre- sponding to the keyword string it selected In [17], SOT for k-bit selection strings is built by executing k 1-out of-2 OTs, and this technique is also essentially what is used in the PSI protocol of [28] Using BaRK-OPRF, we can achieve keyword search by consuming only a single row of the OT extension matrix Oblivious PRFs can be used for secure pattern match- ing [10, 5], where one party holds a long text T and the other party holds a short pattern string p|,Non-data,34
| The parties learn the location of all occurrences of p within T  2 TECHNICAL OVERVIEW OF OUR RE- SULTS We start with the OT-extension paradigm of Ishai, Kilian, Nissim & Petrank (IKNP) [12] The goal of OT extension is to use a small number k of “base-OTs,” plus only symmetric- key operations, to achieve m (cid:29) k “effective OTs|,Non-data,34
|” Here, k is chosen depending on the computational security parameter κ; in the following we show to what value k should be set Below we describe an OT extension that achieves m 1-out- of-2 OTs of random strings, in the presence of semi-honest adversaries We follow the notation of [18] as it explicates the coding- theoretic framework for OT extension Suppose the receiver has choice bits r ∈ {0, 1}m|,Non-data,34
| He chooses two m × k matrices (m rows, k columns), T and U  Let tj, uj ∈ {0, 1}k denote the j-th row of T and U , respectively The matrices are chosen at random, so that: (cid:40) tj ⊕ uj = rj · 1k def= 1k 0k if rj = 1 if rj = 0 The sender chooses a random string s ∈ {0, 1}k The parties engage in k instances of 1-out-of-2 string-OT, with their roles reversed, to transfer to sender S the columns of either T or U , depending on the sender’s bit si in the string s it chose|,Non-data,34
| In the i-th OT, the receiver gives inputs ti and ui, where these refer to the i-th column of T and U , respectively The sender uses si as its choice bit and receives output qi ∈ {ti, ui} Note that these are OTs of strings of length m (cid:29) k — the length of OT messages is easily extended This can be done, e|,Non-data,34
|g, by encrypting and sending the two m-bit long strings, and using OT on short strings to send the right decryption key Now let Q denote the matrix obtained by the sender, whose columns are qi Let qj denote the jth row|,Non-data,34
| The key observation is that (cid:40) qj = tj ⊕ [rj · s] = tj tj ⊕ s if rj = 0 if rj = 1 (1) Let H be a random oracle (RO) We have that the sender can compute two random strings H(qj) and H(qj ⊕ s), of which the receiver can compute only one, via H(tj) Note that tj equals either qj or qj ⊕ s, depending on the receiver’s choice bit rj Note that the receiver has no information about s, so intuitively he can learn only one of the two random strings H(qj), H(qj ⊕ s)|,Non-data,34
| Hence, each of the m rows of the matrix can be used to produce a single 1-out-of-2 OT As pointed out by [12], it is sufficient to assume that H is a correlation-robust hash function, a weaker assumption than RO A special assumption is required because the same s is used for every resulting OT instance See Section 3 for definition of correlation-robustness|,Non-data,34
| Coding interpretation In IKNP, the receiver prepares secret shares of T and U such that each row of T ⊕ U is either all zeros or all ones Kolesnikov & Kumaresan [18] interpret this aspect of IKNP as a repetition code and suggest to use other codes instead Consider how we might use the IKNP OT extension pro- tocol to realize 1-out-of-2(cid:96) OT|,Non-data,34
| Well, instead of a choice bit ri for the receiver, ri will now be an (cid:96)-bit string Let C be a linear error correcting code of dimension (cid:96) and codeword length k The receiver will prepare matrices T and U so that tj ⊕ uj = C(rj) Now, generalizing Equation 1 the sender receives qj = tj ⊕ [C(rj) · s] (2) where “·” now denotes bitwise-AND of two strings of length k|,Non-data,34
| (Note that when C is a repetition code, this is exactly Equation 1) For each value r(cid:48) ∈ {0, 1}(cid:96), the sender associates the secret value H(qj ⊕ [C(r(cid:48)) · s]), which it can compute for all r(cid:48) ∈ {0, 1}(cid:96) At the same time, the receiver can compute one of these values, namely, H(tj) Rearranging Equation 2, we have: H(tj) = H(qj ⊕ [C(rj) · s]) Hence, the value that the receiver can learn is the secret value that the sender associates with the receiver’s choice string r(cid:48) = rj|,Non-data,34
| At this point, OT of random strings is completed For OT of chosen strings, the sender will use each H(qi ⊕ [C(r) · s]) as a key to encrypt the r’th OT message The receiver will be able to decrypt only one of these encryptions, namely one corresponding to its choice string rj 820To argue that the receiver learns only one string, suppose the receiver has choice bits rj but tries to learn also the secret H(qj ⊕ [C( ̃r) · s]) corresponding to a different choice ̃r|,Non-data,34
| We observe: (3) qj ⊕ [C( ̃r) · s] = tj ⊕ [C(rj) · s] ⊕ [C( ̃r) · s] = tj ⊕ [(C(rj) ⊕ C( ̃r)) · s] Importantly, everything in this expression is known to the receiver except for s Now suppose the minimum distance of C is κ (the security parameter) Then C(rj) ⊕ C( ̃r) has Hamming weight at least κ Intuitively, the adversary would have to guess at least κ bits of the secret s in order to violate security|,Non-data,34
| The protocol is secure in the RO model, and can also be proven under the weaker assumption of correlation robustness, following [12, 18] Finally, we remark that the width k of the OT extension matrix is equal to the length of codewords in C The param- eter k determines the number of base OTs and the overall cost of the protocol Pseudorandom codes|,Non-data,34
| The main technical observation we make in this work is pointing out that the code C need not have many of the properties of error-correcting codes In particular, • We make no use of decoding, thus our code does not need to be efficiently decodable • We require only that for all possibilities r, r(cid:48), the value C(r) ⊕ C(r(cid:48)) has Hamming weight at least equal to the computational security parameter κ In fact, it is sufficient even if the Hamming distance guarantee is only probabilistic — i|,Non-data,34
|e, it holds with overwhelm- ing probability over choice of C (we discuss subtleties below) For ease of exposition, imagine letting C be a random ora- cle with suitably long output (Later we will show that C can be instantiated from a pseudorandom function in a straight- forward way|,Non-data,34
|) Intuitively, when C is sufficiently long, it should be hard to find a “near-collision” That is, it should be hard to find values r and r(cid:48) such that C(r) ⊕ C(r(cid:48)) has low (less than a computational security parameter κ) Ham- ming weight Later in Table 2 we compute the parameters more precisely, but for now we simply point out that a ran- dom function with output length k = 4κ suffices to make near-collisions negligible in our applications We refer to such a function C (or family of functions, in our standard-model instantiation) as a pseudoran- dom code (PRC), since its coding-theoretic properties — namely, minimum distance — hold in a cryptographic sense|,Non-data,34
| By relaxing the requirement on C from an error-correcting code to a pseudorandom code, we remove the a-priori bound on the size of the receiver’s choice string! In essence, the receiver can use any string as its choice string; the sender can associate a secret value H(qj ⊕ [C(r(cid:48))· s]) for any string r(cid:48) As discussed above, the receiver is only able to compute H(tj) = H(qj ⊕ [C(r) · s]) — the secret corresponding to its choice string r The property of the PRC is that, with overwhelming probability, all other values of qj ⊕ [C( ̃r) · s] (that a polytime player may ever ask) differ from tj in a way that would require the receiver to guess at least κ bits of s Interpretation as an oblivious PRF variant|,Non-data,34
| As discussed in Section 1, we can view the functionality achieved by this protocol as a kind of oblivious PRF Intu- itively, r (cid:55)→ H(q ⊕ [C(r) · s]) is a function that the sender can evaluate on any input, whose outputs are pseudoran- dom, and which the receiver can evaluate only on its chosen input r In Section 3 we give a formal definition of the functionality that we achieve The main subtleties of the definition are: 1|,Non-data,34
| the fact that the receiver learns slightly more than the output of this “PRF” — in particular, the receiver learns t = q ⊕ [C(r) · s] rather than H(t); 2 the fact that the protocol realizes many instances of this “PRF” but with related keys — s and C are shared among all instances We prove our construction secure assuming C is a pseudo- random code and that H satisfies a natural generalization of the “correlation robust” assumption from [12] Summary & cost|,Non-data,34
| With our new variant of the IKNP protocol, we can obtain m OPRF instances efficiently, using only k base OTs plus symmetric-key operations Compared to IKNP-paradigm OT extension for 1-out-of-2 OTs, the main differences in cost are: • Cost associated with the increased width of the OT extension matrices In our case, the matrix has width k rather than κ — concretely 3κ < k < 4κ in our applications Note that the parameter k controls the number of base OTs required|,Non-data,34
|1 • Computational costs associated with the pseudoran- dom code C While in IKNP C is a repetition code, and in [18] C is a short Walsh-Hadamard code, in our protocol C is cryptographic However, we are able to instantiate C using a PRF In practice, we use AES as the PRF, and the associated hardware acceleration for AES in modern processors makes the cost of comput- ing C minimal|,Non-data,34
| Application to private set intersection Private set intersection (PSI) refers to a computation in which Alice has a set A of items, Bob has a set B of items, and the two learn only A ∩ B and nothing more We show how BaRK-OPRF can be used to significantly re- duce the cost of semi-honest-secure PSI The current fastest protocol for the task is that of Pinkas et al|,Non-data,34
| [27] The pro- tocol relies heavily on efficient OT extension (for standard 1-out-of-2 OTs) Looking closely at the PSI protocol of [27], we see that they use a number of OTs that is proportional to N (cid:96), where N is the number of items in the parties’ sets and (cid:96) is the length (in bits) of those items We can replace their use of 1-out-of-2 OTs with a suitable use of BaRK-OPRF and 1In our instantiation, we actually use IKNP to extend κ base OTs to k OTs, and then use those k OTs as base OTs for BaRK-OPRF instances|,Non-data,34
| Hence, the number of public-key OT operations is unchanged Still, the total communication cost remains proportional to km in our protocol rather than κm 821remove the dependence on (cid:96) Our protocol uses a number of BaRK-OPRF instances that is proportional only to N |,Non-data,34
| We implemented our BaRK-OPRF-based PSI protocol and compared its performance to that of [27] For PSI on strings of length (cid:96) ∈ {64, 128} and sufficiently large sets, our proto- col is 23–36 times faster|,Non-data,34
 This is a significant achievement in the already very polished PSI state of the art! 3 TECHNICAL PRELIMINARIES We write (cid:107)x(cid:107)H to denote the hamming weight of a binary string x Our computational security parameter is κ and statistical security parameter is σ 3,Non-data,34
|1 Correlation Robustness The OT extension protocol of IKNP [12] is proven secure under a so-called correlation robustness assumption on the underlying hash function Our protocol makes use of the following generalization of this notion: Definition 1 Let H be a hash function with input length n Then H is d-Hamming correlation robust if, for any strings z1, |,Non-data,34
|   , zm ∈ {0, 1}∗, a1,  |,Non-data,34
|  , am, b1,   |,Non-data,34
| , bm ∈ {0, 1}n with (cid:107)bi(cid:107)H ≥ d, the following distribution, induced by ran- dom sampling of s ← {0, 1}n, is pseudorandom: H(z1(cid:107)a1 ⊕ [b1 · s]),    , H(zm(cid:107)am ⊕ [bm · s]) As in the overview, “·” denotes bitwise-AND|,Non-data,34
| The definition generalizes previous ones in the following way: • If d = n, then the only legal choice of bi is 1n, and H(zi(cid:107)ai ⊕ [bi · s]) simplifies to H(zi(cid:107)ai ⊕ s) Restrict- ing the definition in this way, and taking zi = i corre- sponds to the IKNP notion of correlation robustness • If the bi values are required to be elements of a linear error correcting code C, then the resulting definition is one under which the construction of [18] is secure (for simplicity they prove security in the random oracle model) 3|,Non-data,34
|2 Pseudorandom Codes We now formalize the notion of a pseudorandom code, motivated in Section 2 Definition 2 Let C be a family of functions We say that C is a (d, ) pseudorandom code (PRC) if for all strings x (cid:54)= x(cid:48), (cid:104)(cid:107)C(x) ⊕ C(x Pr C←C (cid:105) ≤ 2 − (cid:48) )(cid:107)H < d That is, a (d, )-PRC guarantees that the hamming dis- tance of two codewords is less or equal to d with probability at most 2−|,Non-data,34
| The reader may find it convenient to think of C as a ran- dom oracle However, it suffices for C to be a pseudorandom function instantiated with random seed: Lemma 1 Suppose F : {0, 1}κ × {0, 1}∗ → {0, 1}n is a pseudorandom function Define C = {F (s,·) || s ∈ {0, 1}κ}|,Non-data,34
| Then C is a (d, )-pseudorandom-code where: probability 2−n(cid:80)d−1 Proof Consider the following game An adversary has It queries its oracle O on x strings x and x(cid:48) hard-coded and x(cid:48) and outputs 1 if O(x) and O(x(cid:48)) are within Hamming distance d|,Non-data,34
| When O is instantiated as a random function, a simple counting argument shows that the adversary outputs 1 with When O is instantiated as a PRF F with random seed, the probability must be within ν(κ) of the above probability, where ν is negligible The adversary’s output probability in this instantiation is exactly the probability specified in the PRC security definition, so the lemma follows (cid:0)n (cid:1) i=0 i Note that in our typical usage of PRCs, the choice of C (in this case, the seed to the PRF) is a public value|,Non-data,34
| But in both the security definition for PRC and in this analysis, the values x and x(cid:48) are fixed before the PRF key is chosen Whether or not F (s, x) and F (s, x(cid:48)) are within Hamming distance d is not affected by making the PRF seed pub- lic 33 Our Oblivious PRF Variant As outlined in Section 2, our main construction is a variant of OT-extension which associates a pseudorandom output R(x) for every possible input r ∈ {0, 1}∗|,Non-data,34
| The sender can compute R(r) for any r, while the receiver learns R(x) for only a single value r This functionality is reminiscent of an oblivious PRF (OPRF) [6] In this section we describe how our construction can be interpreted as a variant OPRF functionality In an OPRF functionality for a PRF F , the receiver pro- vides an input2 r; the functionality chooses a random seed s, gives s to the sender and F (s, r) to the receiver|,Non-data,34
| In our protocol, the sender knows qj and s We can con- sider these values as keys to a PRF: F ((qj, s), r) = H(j(cid:107)qj ⊕ [C(r) · s]) Intuitively, the sender can evaluate this PRF at any point, while the receiver can evaluate it on only one However, we point out some subtleties: • In our protocol, the receiver learns tj = qj ⊕ [C(r∗)· s] for his chosen input r∗, which is more information than the “PRF output” H(j(cid:107)tj) However, even knowing tj, the other outputs of the “PRF” still look random|,Non-data,34
| This common feature of an OPRF protocol leaking slightly more than the PRF output is called relaxed OPRF in [6] • In our protocol, we realize many “OPRF” instances with related keys In particular, all instances have the same component s (and C) We encapsulate these properties in the following defini- tions|,Non-data,34
| 331 Our PRF variant We refer to F as a relaxed PRF if there is another func- tion (cid:101)F , such that F (k, r) can be efficiently computed given just (cid:101)F (k, r) We then define the relevant notion of secu- function (cid:101)F rather than just F |,Non-data,34
 rity with respect to an adversary who can query the relaxed d−1(cid:88) (cid:32) (cid:33) n i − = 2 2 −n and ν is a negligible function i=0 + ν(κ) 2More general OPRF variants allow the receiver to learn the PRF output on many inputs — here it suffices to limit the receiver to one input 822Definition 3,Non-data,34
| Let F be a relaxed PRF with output length v, for which we can write the seed as a pair (k∗, k) Then F has m-related-key-PRF (m-RK-PRF) security if the advantage of any PPT adversary in the following game is negligible: 1 The adversary chooses strings x1,  |,Non-data,34
|  , xn and m pairs (j1, y1),   |,Non-data,34
| , (jm, ym), where yi (cid:54)= xji  2 Challenger chooses random values appropriate for PRF seeds k∗, k1,  |,Non-data,34
|  , kn and tosses a coin b ← {0, 1} (a) If b = 0, the challenger outputs {(cid:101)F ((k∗, kj), xj)}j and {F ((k∗, kji ), yi)}i {0, 1}v and outputs {(cid:101)F ((k∗, kj), xj)}j and {zi}i, (b) If b = 1 the challenger chooses z1, |,Non-data,34
|   , zm ← 3 The adversary outputs a bit b(cid:48)|,Non-data,34
| The advantage of the ♦ adversary is Pr[b = b(cid:48)] − 1/2 Intuitively, the PRF is instantiated with n related keys (sharing the same k∗ value) The adversary learns the re- laxed output of the PRF on one chosen input for each key Then any m additional PRF outputs (corresponding to any seed) are indistinguishable from random by the adversary|,Non-data,34
| Lemma 2 Let C be a (d, +log2 m)-PRC, where 1/2 is a negligible function, Let H be a d-Hamming correlation robust hash function Define the following relaxed PRF, for C ∈ C: (cid:16) (cid:16) F (cid:101)F ((C, s), (q, j)), r ((C, s), (q, j)), r (cid:17) (cid:17) = H(j(cid:107)q ⊕ [C(r) · s]) = (j, C, q ⊕ [C(r) · s]) Then F has m-RK-PRF security Proof|,Non-data,34
| In the m-RK-PRF game with this PRF, we can rewrite the adversary’s view as in Section 2 as: (C,{tj}j,{H(ji(cid:107)tji ⊕ [(C(xji ) ⊕ C(yi)) · s])}i) There are m terms of the form C(xji ) ⊕ C(yi) for xji (cid:54)= yi Each of these terms has Hamming weight at least d with probability at least 1 − 2−−log2 m over the choice of C By a union bound, all m terms have Hamming weight at least d with probability 1 − 2− Conditioning on this (overwhelmingly likely) event, we can apply the d-Hamming correlation robust property of H to see that the H-outputs are indistinguishable from random|,Non-data,34
| 332 Our BaRK-OPRF functionality In Figure 1 we formally describe the variant OPRF func- tionality we achieve It generates m instances of the PRF with related keys, and allows the receiver to learn the (re- laxed) output on one input per key|,Non-data,34
| 4 MAIN CONSTRUCTION We present our main construction, which is a semi-honest secure protocol for the functionality in Figure 1, instantiated with the relaxed PRF defined in Lemma 2 The functionality is parameterized by a relaxed PRF F , a number m of instances, and two parties: a sender and receiver On input (r1, |,Non-data,34
|   , rm) from the receiver, • Choose random components for seeds to the PRF: k∗, k1,  |,Non-data,34
|  , km and give these to the sender • Give (cid:101)F ((k∗, k1), r1),  |,Non-data,34
|  ,(cid:101)F ((k∗, km), rm) to the re- ceiver Figure 1: Batched, related-key OPRF (BaRK-OPRF) ideal functionality We use the notation OTk 4|,Non-data,34
|1 Notation m to denote k instances of 1-out- of-2 string-OT where the strings are m bits long Let S de- note the sender, and let R denote the receiver In OTk m, the sender’s input is {(xj,0, xj,1)}j∈[k], ie|,Non-data,34
|, m pairs of strings, each of length m, and the receiver holds input {rj}j∈[k], where each rj is a choice bit Note that if S provides input m, and if R provides input {rj}j∈[k] {(xj,0, xj,1)}j∈[k] to OTk m, then R receives back {xj,rj}j∈[k], while S receives to OTk nothing Following the convention in IKNP, we denote vectors in bold, and matrices in capitals For a matrix A, we let aj denote the j-th row of A, and ai denote the i-th column of A|,Non-data,34
| If a = a1(cid:107)···(cid:107)ap and b = b1(cid:107)···(cid:107)bp are two vectors, then we define ⊕ and · operations as follows We use the notation a⊕ b to denote the vector (a1⊕ b1)(cid:107)···(cid:107)(ap⊕ bp) Similarly, the notation a · b denotes the vector (a1 · b1)(cid:107)···(cid:107)(ap · bp) Finally, suppose c ∈ {0, 1}, then c · a denotes the vector (c · a1)(cid:107)···(cid:107)(c · ap)|,Non-data,34
| We note that to simplify notation via indexing, in the following we will refer to the OT matrices as T0 and T1, rather than as T and U , as we did when presenting high- level overview of our work 42 The BaRK-OPRF construction Our BaRK-OPRF protocol is presented in Figure 2 It closely follows the high-level overview|,Non-data,34
| Recall that we are considering a PRF whose seed is of the form ((C, s), (j, qj)) and whose relaxed output is of the form t0,j = qj⊕(C(rj)·s) Theorem 3 The BaRK-OPRF protocol in Figure 2 se- curely realizes the functionality of Figure 1, instantiated with the relaxed PRF defined in Lemma 2, in the presence of semi-honest adversaries, where κ is the computational secu- rity parameter Proof|,Non-data,34
| When using the abstraction of our OPRF func- tionality, the proof is elementary Simulating S The simulator receives output from the OPRF ideal functionality consisting of related PRF seeds: a common (C, s) and a qj for each j ∈ [m] Let Q be a matrix whose rows are the qj|,Non-data,34
| Let qi denote the ith column of Q The simulator simulates an execution of the protocol in which S chooses C in step 0, chooses s in step 1, and receives output {qi}i∈[k] as OT output in step 3 Simulating R The simulator has input (r1, |,Non-data,34
|   , rm) and receives output from the OPRF ideal functionality consist- ing of a relaxed PRF output (j, C, tj) for each j ∈ [m] 823Input of R: m selection strings r = (r1, |,Non-data,34
|   , rm), ri ∈ {0, 1}∗ Parameters: • A (κ, )-PRC family C with output length k = k(κ)|,Non-data,34
| • A κ-Hamming correlation-robust H : [m] × • An ideal OTk {0, 1}k → {0, 1}v m primitive Protocol: 0 S chooses a random C ← C and sends it to R|,Non-data,34
| 1 S chooses s ← {0, 1}k at random Let si denote the i-th bit of s 2|,Non-data,34
| R forms m× k matrices T0, T1 in the following way: • For j ∈ [m], choose t0,j ← {0, 1}k and set t1,j = C(rj) ⊕ t0,j 0, ti Let ti respectively 1 denote the i-th column of matrices T0, T1 3 S and R interact with OTk m in the following way: • S acts as receiver with input {si}i∈[k]|,Non-data,34
| • R acts as sender with input {ti • S receives output {qi}i∈[k] 0, ti 1}i∈[k] S forms m × k matrix Q such that the i-th column of Q is the vector qi (Note qi = ti si |,Non-data,34
|) Let qj denote the j-th row of Q Note, qj = ((t0,j ⊕t1,j)·s)⊕t0,j Simplifying, qj = t0,j ⊕ (C(rj) · s) 4|,Non-data,34
| For j ∈ [m], S outputs the PRF seed ((C, s), (j, qj)) 5 For j ∈ [m], R outputs relaxed PRF output (C, j, t0,j) Figure 2: The BaRK-OPRF protocol The simulator simulates an execution of the protocol in which R receives C in step 0 and samples t0,j = tj in step 2|,Non-data,34
 In both cases it is straightforward to check that the sim- ulation is perfect 5 IMPROVING PRIVATE SET INTERSEC- TION The main application of BaRK-OPRF is to improve the performance of semi-honest-secure private set intersec- tion (PSI) Pinkas et al,Non-data,34
| [28] give a thorough summary of many different paradigms for PSI in this model For our purposes, we summarize only the most efficient PSI protocol, which is the OT-based paradigm of [28] in- cluding the optimizations suggested in follow up work [27] Hereafter we refer to their protocol as the “PSSZ” protocol 5|,Non-data,34
|1 The OPRF Implicit in PSSZ The main building block of PSSZ, private equality test, can be viewed as a relaxed OPRF based on random OTs (ie, oblivious transfers of random messages), which can be obtained efficiently from OT extension The protocol is as follows, where Bob has input r, with (cid:96) = ||r|||,Non-data,34
| • The parties perform (cid:96) 1-out-of-2 OTs of random mes- sages, with Alice as receiver Bob acts as receiver and uses the bits of r as his choice bits In the ith OT, Alice learns random strings mi,0 and mi,1, while Bob learns mi,r[i] • Define the mapping F (x) = H(cid:0)(cid:76) (cid:1), where H is i mi,x[i] a random oracle|,Non-data,34
| One can then view F as a PRF whose keys are the mi,b values (known to Alice) Bob learns the output of F on r only More precisely, he learns relaxed output {mi,r[i]}i, for which all other outputs of F are pseudorandom In this description, we have treated r as a string of bits, and therefore use 1-out-of-2 (random) OTs|,Non-data,34
| However, when using the OT extension protocol of [18], the cost of a 1-out- of-2 random OT is essentially the same as a 1-out-of-256 random OT Hence, PSSZ interpret r as strings of characters over {0, 1}8 The protocol uses one instance of 1-out-of-256 ROT for each byte (not bit) of r Regardless of whether one uses 1-out-of-2 or 1-out-of-256 OT, this OPRF protocol has cost that scales with length of the input r, whereas ours has cost independent of the input length|,Non-data,34
 Our main improvement to PSSZ consists of replacing their OPRF with ours The rest of the protocol is largely unchanged 52 PSI from OPRF We now describe how the PSSZ paradigm achieves PSI us- ing an OPRF,Non-data,34
| This part of the overall PSI protocol is nearly identical between our implementation and that of [27] (we include an additional small optimization) For concreteness, we describe the parameters used in PSSZ when the parties have roughly the same number n of items The protocol relies on Cuckoo hashing [26] with 3 hash functions, which we briefly review now To assign n items into b bins using Cuckoo hashing, first choose random func- tions h1, h2, h3 : {0, 1}∗ → [b] and initialize empty bins B[1, |,Non-data,34
|   , b] To hash an item x, first check to see whether any of the bins B[h1(x)], B[h2(x)], B[h3(x)] are empty|,Non-data,34
| If so, then place x in one of the empty bins and terminate Other- wise, choose a random i ∈ {1, 2, 3}, evict the item currently in B[hi(x)], replacing it with x, and then recursively try to insert the evicted item If this process does not terminate after a certain number of iterations, then the final evicted element is placed in a special bin called the stash PSSZ use Cuckoo hashing for PSI in the following way|,Non-data,34
| First, the parties choose 3 random hash functions h1, h2, h3 suitable for 3-way Cuckoo hashing Suppose Alice has a set X of inputs and Bob has a set Y , where ||X|| = ||Y || = n Bob maps his items into 12n bins using Cuckoo hashing and a stash of size s|,Non-data,34
| At this point Bob has at most one item per bin and at most s items in his stash — he pads his input with dummy items so that each bin contains exactly 1 item and the stash contains exactly s items The parties then run 12n+s instances of an OPRF, where Bob plays the role of receiver and uses each of his 12n + s items as OPRF input|,Non-data,34
| Let F (ki,·) denote the PRF evaluated in the ith OPRF instance If Bob has mapped item y to bin i via cuckoo hashing, then Bob learns F (ki, y); if Bob 824has mapped y to position j in the stash, then Bob learns F (k12n+j, y) On the other hand, Alice can compute F (ki,·) for any i|,Non-data,34
| So she computes sets of candidate PRF outputs: H = {F (khi(x), x) || x ∈ X and i ∈ {1, 2, 3}} S = {F (k12n+j, x) || x ∈ X and j ∈ {1,   |,Non-data,34
| , s}} She randomly permutes elements of H and elements of S and sends them to Bob Bob can identify the intersection of X and Y as follows If Bob has an item y mapped to the stash, he checks whether the associated OPRF output is present in S If Bob has an item y not mapped to the stash, he checks whether its associated OPRF output is in H|,Non-data,34
| Intuitively, the protocol is secure against a semi-honest Bob by the PRF property For an item x ∈ X \ Y , the corresponding PRF outputs F (ki, y) are pseudorandom It is easy to see that security holds even if Bob learns relaxed PRF outputs and the PRF achieves RK-PRF security, Def- inition 3 (ie|,Non-data,34
|, Alice’s PRF outputs are pseudorandom to an adversary who learns relaxed PRF outputs) Similarly, if the PRF outputs are pseudorandom even under related keys, then it is safe for the OPRF protocol to instantiate the PRF instances with related keys The protocol is correct as long as the PRF does not in- troduce any further collisions (ie|,Non-data,34
|, F (ki, x) = F (ki(cid:48) , x(cid:48)) for x (cid:54)= x(cid:48)) Below we discuss the parameters required to pre- vent such collisions An Optimization In the protocol summary above, Bob must search for each of his OPRF outputs, either in the set H or the set S|,Non-data,34
| Fur- thermore, ||H|| = 3n and ||S|| = sn Even when using a reasonable data structure for these comparisons, they have a non-trivial effect on the protocol’s running time We now describe an optimization that reduces this cost (by approx- imately 10% in our implementation) The full protocol is described in Figure 3|,Non-data,34
| Our modification works as follows First, Bob keeps track of a hash index z ∈ {1, 2, 3} for each item y ∈ Y that is not mapped to the stash For example, if Bob’s Cuckoo hashing maps y to bin #h2(y), then Bob associates z = 2 with y If for example y is mapped to bin by two hash functions #h1(y) = #h2(y) then Bob may choose either z = 1 or z = 2 arbitrarily|,Non-data,34
| Then in the first 12n OPRF instances, Bob uses input y(cid:107)z For the OPRF instances associated with the stash, he does not need to append the index z Summarizing, if Bob has mapped item to position j in the stash, then Bob learns F (k1|,Non-data,34
|2n+j, y) If he has not mapped y to the stash, then he learns F (khz (x), y(cid:107)z) for exactly one z Then Alice computes the following sets: Hi = {F (khi(x), x(cid:107)i) || x ∈ X}, for i ∈ {1, 2, 3} Sj = {F (k12n+j, x) || x ∈ X}, for j ∈ {1, |,Non-data,34
|   , s} She randomly permutes the contents of each Hi and each Sj and sends them to Bob For each item y of Bob, if y is not mapped to the stash then Bob can whether F (khz (y), y(cid:107)z) ∈ Hz, for the associated hash-index z|,Non-data,34
| If his Cuckoo hashing maps item y to position j in the stash, he can check whether F (k12n+j, y) ∈ Sj The reason for appending the hash-index z to the PRF in- put is as follows Suppose h1(x) = h2(x) = i, which is indeed can happen with noticeable probability, since the output range of h1, h2 is small ([1|,Non-data,34
|2n]) Without appending z, both H1 and H2 would contain the identical value F (ki, x) This would leak the fact that a collision h1(x) = h2(x) occurred Such an event is input-dependent so cannot be simulated|,Non-data,34
|3 With our optimization: (1) All of the calls to the PRF made by Alice (to compute the Hi’s and Sj’s) invoke the PRF on distinct key-input pairs This ensures that the con- tents of these sets can be easily simulated; (2) Bob searches for each of his PRF outputs within only one set (either an Hi or an Sj) of n items Contrast this with the approach described previously, where Bob must find each OPRF out- put in either a set of size 3n or sn (depending on whether the item is in the stash or not) Recall that the protocol is correct as long as there are no spurious collisions among PRF outputs|,Non-data,34
| Since there are at most n2 opportunities for a spurious collision (Bob searches each time for a PRF output in a set of n items), we can limit the overall probability of a spurious collision to 2−σ by using PRF outputs of length σ + log2(n2) Parameters: Alice has input X; Bob has input Y , with ||X|| = ||Y || = n s is an upper bound on the stash size for Cuckoo hashing 1|,Non-data,34
| Bob specifies random hash functions h1, h2, h3 : {0, 1}∗ → [12n] and tells them to Alice 2 Bob assigns his items Y into 1|,Non-data,34
2n bins using Cuckoo hashing Let Bob keep track of z(y) for each y so that: if z(y) = ⊥ then y is in the stash; otherwise y is in bin hz(y)(y) Arrange the items in the stash in an arbitrary order Bob selects OPRF inputs as follows: for i ∈ [1,Non-data,34
|2n], if bin #i is empty, then set ri to a dummy value; otherwise if y is in bin #i then set ri = y(cid:107)z(y) For i ∈ [s], if position i in the stash is y, then set ri = y; otherwise set ri to a dummy value 3 The parties invoke 1|,Non-data,34
|2n + s OPRF instances, with Bob the receiver with inputs (r1,    , r1|,Non-data,34
|2n+s) Alice receives (k1,   |,Non-data,34
| , k12n+s) and Bob receives F (ki, ri) for all i 4 Alice computes: Hi = {F (khi(x), x(cid:107)i) || x ∈ X}, for i ∈ {1, 2, 3} Sj = {F (k1|,Non-data,34
|2n+j, x) || x ∈ X}, for j ∈ {1,    , s} and sends a permutation of each set to Bob|,Non-data,34
| 5 Bob initializes an empty set O and does the follow- ing for y ∈ Y : If z(y) = ⊥ and y is at position j in the stash and F (k12n+j, y) ∈ Sj, then Bob adds y to O If z(y) (cid:54)= ⊥ and F (khz(y)(y), y(cid:107)z(y)) ∈ Hz(y) then Bob adds y to O|,Non-data,34
| 6 Bob sends O to Alice and both parties output O Figure 3: Our optimization to the PSSZ PSI proto- col, written in terms of an OPRF functionality 3The protocol and implementation of PSSZ do not account for such collisions among the Cuckoo hash functions|,Non-data,34
| Dupli- cate values will appear in H in such an event 82553 Comparing OPRF Subprotocols When comparing our protocol to that of PSSZ, the ma- jor difference is the choice of OPRF subprotocols Later in Section 6 we give an empirical comparison of the protocols|,Non-data,34
| For now, we derive an analytical comparison of the costs of the two OPRF subprotocols, to give a better sense of our improvement We focus on the communication cost associated with the OT primitives Communication cost is an objective metric, and it often reflects the bottleneck in practice (especially in these protocols where essentially all of the cryptographic computations are precomputed) Although the computation costs of our protocols are different (e|,Non-data,34
|g, ours requires com- puting the pseudorandom code, which is a cryptographic operation), communication cost is nonetheless a good proxy for computation costs in OT extension protocols The data that is communicated in these protocols is a large matrix that must be transposed, and this transposition is the pri- mary contributor to the computational cost The main benefit of our protocol is that its cost does not scale with the size of the items being compared|,Non-data,34
 Each in- stance of OPRF consumes just one row of the OT extension matrix The width of this OT extension matrix is exactly the length of the pseudorandom code (PRC) In Section 61 we describe how to compute an appropriate length of PRC,Non-data,34
| For the range of parameters we consider, this parameter is 424–448 bits Hence the OT-cost of one instance of our OPRF protocol is 424–448 bits The specific numbers are in Table 1 The PSSZ OPRF protocol uses several instances of 1-out- of-256 ROT|,Non-data,34
| With security parameter 128, the cost of such a random OT is 256 bits using the OT extension of [18] The main optimization of [27] allows for the OPRF sub- protocols to be performed on items of length (cid:96)∗ = (cid:96) − log n (n is the number of items in the overall PSI protocol) rather than length (cid:96) Let (cid:96)∗ denote this effective item length Then (cid:96)∗/8 instances of 1-out-of-256 ROT are needed for one OPRF instance|,Non-data,34
| The total OT-cost of their OPRF protocol is therefore 256(cid:96)∗/8 = 32(cid:96)∗ bits Hence, we see that our protocol has lower communication cost whenever (cid:96)∗ > 448/32 = 14 Among the different pa- rameter settings reported in [27], the only configuration with (cid:96)∗ < 14 is for PSI of n ≥ 220 items of length 32 bits For all other configurations, our PSI protocol has lower communi- cation cost, with the savings increasing as the items become longer|,Non-data,34
| See Table 1 Remark on pre-hashing long PSI inputs Our improvements to PSI are most significant for PSI of long items Yet, if the parties have items which are very long strings (say, thousands of bits), they can agree on a random hash function, hash their items locally, and perform PSI on the shorter hashes instead|,Non-data,34
| The reader may rightfully wonder whether this idea make our improvements irrelevant! For this approach (hash-then-PSI) to work, we must en- sure that the hashing introduces no collisions among the parties’ items If the parties have n items each, and we wish to limit the probability of a collision to 2−σ, then we must choose a hash function whose length is σ + 2 log n When using the optimizations of [27], the effective item length can be reduced from σ + 2 log n to σ + log n bits We see that pre-hashing the items cannot reduce their effective length below σ bits, where σ is a statistical security n 28 28 28 212 212 212 216 216 216 220 220 220 224 224 224 (cid:96) 32 64 128 32 64 128 32 64 128 32 64 128 32 64 128 (cid:96)∗ 24 56 120 20 52 116 16 48 112 12 44 108 8 40 104 OT cost PSSZ our BaRK-OPRF 768 1792 3840 640 1664 3712 576 1536 3584 384 1408 3456 256 1280 3328 424 424 424 432 432 432 440 440 440 448 448 448 448 448 448 ratio 0|,Non-data,34
54 024 011 068 0,Non-data,34
26 012 076 029 0,Non-data,34
12 117 032 013 1,Non-data,34
|75 035 013 Table 1: Comparing the OT-cost of PSSZ-paradigm OPRF subprotocol and ours, for various parameters The entries in the table refer to the contribution (in bits) to the size of the OT-extension matrices|,Non-data,34
| (cid:96) is the item length (in bits), n is the total number of items in the parties’ sets, and (cid:96)∗ is the effective item length when using the optimizations of [27] parameter Standard practice suggests σ ≥ 40, and yet our protocol outperforms [27] whenever the effective item length is at least 14 bits Hence hash-then-PSI does not allow one to bypass our improvement to [27]|,Non-data,34
| On a similar note, in our experimental results we report performance of the protocols only for PSI inputs up to 128 bits long For statistical security parameter σ = 40, as long as the parties have at most 234 (17 billion) items, they can use hash-then-PSI with a 128-bit hash 6 IMPLEMENTATION & PERFORMANCE We implemented our PSI protocol and report on its per- formance in comparison with the state-of-the-art PSI pro- tocol of [27]|,Non-data,34
| Our complete implementation is available on GitHub: https://githubcom/osu-crypto/BaRK-OPRF In our implementation we used parameter settings consis- tent with PSSZ or stricter, and ran their and our code on our system so as to obtain meaningful comparisons As do PSSZ, we use matrix transposition code from [1] and several other optimizations|,Non-data,34
| 61 Choosing Suitable Parameters In this section we discuss concrete parameters used in our implementation We use a computational security parame- ter of κ = 128 and a statistical security parameter of σ = 40 The other parameters are: s: the maximum size of the stash for Cuckoo hashing, when hashing n items into 1|,Non-data,34
2n using 3 hash functions k: length of the pseudorandom code (and hence the width of the OT extension matrix) in the BaRK-OPRF pro- tocol v: output length of the PRF realized by the BaRK-OPRF protocol 826n 28 212 216 220 224 s 12 6 4 3 2 k 424 432 440 448 448 v 56 64 72 80 88 Table 2: Parameters used in our implementation,Non-data,34
 n is the size of the parties’ input sets; s is the maxi- mum stash size for Cuckoo hashing; k is the width of the pseudorandom code (in bits); v is the length of OPRF output (in bits) A summary of our concrete parameter choices is given in Table 2 Below we describe how these parameters were de- rived Hashing parameters,Non-data,34
| Bob uses Cuckoo hashing with 3 hash functions to assign his n items into 12n bins (and a stash) For the appropriate choice of the stash size s, we use the numbers given in [27], which limit the probability of hashing failure to 2−40 Size of pseudorandom code|,Non-data,34
| Our BaRK-OPRF protocol requires a pseudorandom code achieving minimum distance κ = 128 In our protocol, Alice evaluates the PRF on (3 + s)n values In order to argue that these values can be collectively pseudorandom, so we require the underlying PRF to have m-RK-PRF security (Definition 3) for m = (3 + s)n From Lemma 2, this means we must choose a pseudoran- dom code with parameters (d = κ,  = σ + log m)|,Non-data,34
| Using Lemma 1, we calculate the minimum length of such a pseu- dorandom code; the results are column k in Table 2 We round up to the nearest multiple of 8 so that protocol mes- sages will always be whole bytes Length of OPRF outputs The length of OPRF output controls the probability of a spurious collision in the PSI protocol|,Non-data,34
| In Section 52 we argued that output length of σ + log2(n2) is sufficient to bound the probability of any spurious collision to 2−σ Using σ = 40, we compute the appropriate length in col- umn v of Table 2 We round up to the nearest multiple of 8 so that protocol messages will always be whole bytes|,Non-data,34
| 62 Environment settings All of our experiments were implemented on a server with Intel(R) Xeon(R) CPU E5-2699 v3 230GHz CPU and 256 GB RAM We run both clients on the same machine, but simulate a LAN and WAN connection using the Linux tc command|,Non-data,34
| In the WAN setting, the average network band- width and the average (round-trip) latency are set to be 50 MB/s and 96 ms, respectively In the LAN setting, the net- work has 02ms latency All of our experiments use a single thread for each party|,Non-data,34
| 63 Implementation Details In our BaRK-OPRF protocol, the offline phase is con- ducted to obtain an OT extension matrix of size (12n+s)×k by using the IKNP OT extension Specifically, first we use the Naor-Pinkas construction [21] to get 128 base-OTs, which are then extended to a k × 128 matrix by utilizing the pseudorandom generator|,Non-data,34
 The transpose of this matrix yields the k base OTs for the BaRK-OPRF extension proto- col We extend to 12n + s OPRF instances We hash all inputs of both client and server at the begin- ning of the online phase,Non-data,34
| Following Lemma 1, we use a PRF with suitably long output as our pseudorandom code More concretely, the parties agree on an AES-128 key sk, which is independent of their inputs, and then extend the output of AES via: C(x) = AESsk(1(cid:107)x)(cid:107)AESsk(2(cid:107)x)(cid:107)AESsk(3(cid:107)x)(cid:107)AESsk(4(cid:107)x) to obtain the desired k random output bits Furthermore, to reduce the waiting time at the server side, the client will constantly send a new packet encompassing multiple code words to the server Based on trail-and-error approach, the packet size of 212 × k bits is selected to minimize the waiting time|,Non-data,34
| In Table 4, we report the running time of our proto- col for both offline and online phases in different settings For instance, in LAN environment, the online phase of our BaRK-OPRF protocol takes about 32s for n = 220 To illustrate the efficacy of the BaRK-OPRF-PSI approach, we compared it with a na ̈ıve hashing protocol and the PSSZ protocol|,Non-data,34
| The na ̈ıve hashing protocol is a widely- used insecure protocol [27] where both parties use the same cryptographic hash function to hash their elements, then one of the parties permutes their hash value and sends the result to the other party, who will compute the intersection by computing the match of the hash values In the following, we conducted several performance tests with the input sets of equal size n and for inputs of length 32, 64, and 128 bits Note that the running time of our PSI protocol does not depend on the bit length of the input It can be explained as follows|,Non-data,34
| First, the upper bound of the length of the input is 128 bits Second, the hash function will call a block of 128 bits to encrypt the input data, thus our protocol has the same computation cost for all bit length of the input In addition, the communication cost of our BaRK-OPRF pro- tocol depends only on the length of the pseudorandom code k and the length v of the OPRF outputs, which are inde- pendent of the bit length (cid:96) Similarly, the na ̈ıve hashing protocol does not depend on (cid:96)|,Non-data,34
| This was confirmed by our simulation results for different bit lengths (eg 32 bits, 64 bits, and 128 bits) Table 3 presents the running time of the na ̈ıve hashing protocol, PSSZ, and our PSI protocol in both LAN and WAN environment|,Non-data,34
| As we can see in the tables, our protocol outperforms PSSZ in almost all the case studies, especially for the long bit length of input (cid:96) and large values of the input size n For example, we consider the results in the LAN setting For the input size of 220, our approach can improve 28 times and 3|,Non-data,34
|6 times the performance of PSSZ for the bit lengths of 64 bits and 128 bits, respectively For the input size of 224, the corresponding improvements are 23 times and 36 times|,Non-data,34
| It is worth mentioning that it takes about 1 minute to compute the intersection for the sets of size n = 224 Similar obser- vations can be inferred from Table 3 for the WAN setting At the same time, for smaller bit lengths, the PSSZ pro- tocol can be faster than our PSI protocol This is the case, for example, when the bit length is 32 bits and n = 224 in LAN setting|,Non-data,34
| Since the two protocols are very similar, differing only in the choice of OPRF subprotocol, it would 827Setting Protocol (insecure) na ̈ıve hashing LAN PSSZ BaRK-OPRF-PSI (insecure) na ̈ıve hashing WAN PSSZ BaRK-OPRF-PSI Bit length (cid:96) {32, 64, 128} 32 64 128 {32, 64, 128} {32, 64, 128} 32 64 128 {32, 64, 128} 28 1 306 306 307 192 97 609 624 624 556 212 6 380 442 443 211 101 701 742 746 585 75 770 1,236 1,352 387 180 1,425 2,142 2,198 1,259 set size n 216 220 759 4,438 10,501 13,814 3,780 1,422 8,222 18,398 23,546 7,455 224 13,529 42,221 137,383 213,597 58,567 22,990 81,234 248,919 381,913 106,828 Table 3: Running time in ms for PSI protocols with n elements per party LAN Setting Phase Offline Online Offline Online WAN 28 171 21 291 265 212 171 40 313 272 set size n 216 216 171 316 943 220 601 3,179 758 6,697 224 7,615 50,952 7,482 99,346 Table 4: Running time of our BaRK-OPRF protocol in ms in offline and online phases Protocol na ̈ıve hashing Bit length (cid:96) {32, 64, 128} PSSZ BaRK-OPRF-PSI 32 64 128 {32, 64, 128} 28 001 006 009 0|,Non-data,34
10 004 212 003 077 1,Non-data,34
37 152 053 set size n 216 056 9,Non-data,34
18 1878 2358 806 220 10,Non-data,34
00 14280 29640 41160 127,Non-data,34
|20 224 17600 1,57440 4,03200 6,489|,Non-data,34
|60 1,95520 Asymptotic [bit] nv 2κ(12n + s)(cid:100) min(v(cid:48),(cid:96))−log(n) 8 (cid:101) + (3 + s)nv(cid:48) k(12n + s) + (3 + s)nv Table 5: Communication in MB for PSI protocols with n elements per party|,Non-data,34
| Parameters k, s, and v refer to those in Table 2 / Section 61 PSSZ requires slightly long OPRF outputs: v(cid:48) = σ + log(3n2) Communication costs for PSSZ and for our protocol ignore the fixed cost of base OTs for OT extension|,Non-data,34
| be relatively straightforward to implement a hybrid that al- ways chooses the best OPRF subprotocol based on n and (cid:96) according to Table 1 However, in order to clarify the strengths/weaknesses of the two protocols, we report the performance for our approach even when it is worse Similar to the running time result, our communication cost is 29–3|,Non-data,34
|3× faster than Pinkas et al for PSI of 128- bit strings and sufficiently large sets Concretely, for the input size of 220, our protocol can improve 32 times the performance of PSSZ for the bit lengths 128 bits|,Non-data,34
| Table 5 presents the communication (in MB) of the na ̈ıve hashing protocol, PSSZ, and our BaRK-OPRF-PSI protocol Acknowledgments We thank Peter Rindal for contributing libraries and helpful suggestions to our protocol implementation We also thank Michael Zohner for answering our many questions about the implementation of [27] Finally, we thank the anonymous CCS reviewers for their helpful feedback|,Non-data,34
| The first author is supported by the Office of Naval Re- search (ONR) contract number N00014-14-C-0113 The sec- ond author is supported by NSF Grants CNS-1350619 and CNS-1414119, in part by the Defense Advanced Research Projects Agency (DARPA) and the US Army Research Of- fice under contracts W911NF-15-C-0226, and an MIT Trans- lational Fellowship|,Non-data,34
| The third and fourth authors are sup- ported by NSF award 1149647 and a Google research award This work was initiated while the first three authors were visiting the Simons Institute for the Theory of Comput- ing, supported by the Simons Foundation and by the DI- MACS/Simons Collaboration in Cryptography through NSF grant #CNS-1523467 7 |,Non-data,34
|Abstract Failing to properly isolate components in the same address space has resulted in a substantial amount of vulnerabilities Enforcing the least privilege principle for memory accesses can selectively isolate software components to restrict at- tack surface and prevent unintended cross-component mem- ory corruption However, the boundaries and interactions between software components are hard to reason about and existing approaches have failed to stop attackers from ex- ploiting vulnerabilities caused by poor isolation We present the secure memory views (SMV) model: a practical and efficient model for secure and selective mem- ory isolation in monolithic multithreaded applications|,Non-data,35
