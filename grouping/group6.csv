 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| Logarithmic numbers are represented with squares, golden section with diamonds, floating-point numbers with circles and fixed-point numbers with triangles The accuracy of operations increases with shade, so that white shapes denote least precision and best performance We have measured addition, multiplication, reciprocal and square root For floating-point and logarithmic numbers we also benchmarked exponentiation and natural logarihm|,Non-data,9
| In most cases, maximum relative error was measured, but for fixed-point numbers and some golden number protocols this is not reasonable In these cases maximum absolute error was measured, and this is denoted by adding label “A” to the mark Some operations, such as fixed-point addition, achieve perfect accuracy within their number representation These cases are marked with a “(cid:63)”|,Non-data,9
| Instead of maximum error, we plot the value of half of the step between two consecutive numbers in this representation In Figure 1 we can see that golden section numbers com- pare relatively well with fixed-point numbers They achieve somewhat worse performance in our aggregated benchmarks, but the true picture is actually more detailed What is not reflected on the graph is the fact that golden section multiplication requires significantly fewer communi- cation rounds than fixed-point multiplication For instance, fix32 multiplication requires 16 communication rounds, but comparable G64 multiplication requires only 11|,Non-data,9
| This makes golden section numbers more suitable for high latency and high throughput situations, and also better for applications that perform many consecutive operations on small inputs The worse performance of golden section numbers after the saturation point can be wholly attributed to increased communication cost Namely, every multiplication of G64 numbers requires 6852 bits of network communication, but a single fix32 multiplication requires only 2970 We can also see that compared to floating-point numbers, logarithmic numbers perform significantly better in case of multiplication (Figure 1b), reciprocal (Figure 1d) and square root (Figure 1c), while offering similar accuracy|,Non-data,9
| Unfor- tunately, logarithmic numbers do not compare favourably to floating-point numbers with both lower performance and worse accuracy of addition (Figure 1a) In case of natu- ral logarithm and exponentiation, logarithmic numbers are close to floating-point numbers in both performance and ac- curacy This means that logarithmic numbers are a poor choice for applications that are very addition heavy but an excellent choice for applications that require many multi- plicative operations 7|,Non-data,9
| CONCLUSIONS AND FURTHER WORK Technically, protected computation domains are very dif- ferent from the classical open ones Many low-level bit ma- nipulation techniques are too cumbersome to implement and hence standard numeric algorithms do not work very well This holds true even for basic arithmetic operations A full IEEE 754 floating-point number specification is too complex to be efficient in an oblivious setting|,Non-data,9
| Even a reimplementa- tion of the signif icand· 2exponent representation is too slow, even in case of simple addition, since oblivious radix point alignment is very inefficient Hence, alternatives need to be studied This paper proposed two new candidate representations for oblivious real numbers – golden and logarithmic repre- sentations The corresponding algorithms were implemented on the Sharemind SMC engine and benchmarked for vari- ous precision levels and input sizes|,Non-data,9
| The results show that we still do not have a clear winner Since logarithmic representation is multiplicative, adding two logarithmic numbers is slow However, significant per- formance improvements can be achieved for several elemen- tary functions like multiplication, inverse, and square root 562Golden number representation allows for very fast (actu- ally, local) addition, and its multiplication speed is compara- ble with that of fixed-point numbers|,Non-data,9
| However, this format only allows for relatively slow elementary function compu- tations Thus the choice of real number representation depends on application domain and computations to be performed Another aspect to consider is precision Our analysis shows that logarithmic representation achieves the best rela- tive error for most of the operations (except addition)|,Non-data,9
| How- ever, precision achieved by our other implementations seems more than sufficient for practical statistical applications In this paper we have developed only the most basic math- ematical tools In order to be applied to actual data analysis tasks (eg|,Non-data,9
| statistical tests, finding correlation coefficients, variances, etc), higher-level operations need to be imple- mented It is an interesting open question which real num- ber representations perform optimally for various operations and input sizes This study will be a subject for our future research|,Non-data,9
 8 ACKNOWLEDGEMENTS This research has been supported by Estonian Research Council under the grant no IUT27-1 9,Non-data,9
|ABSTRACT Motivated by the impossibility of achieving fairness in secure com- putation [Cleve, STOC 1986], recent works study a model of fair- ness in which an adversarial party that aborts on receiving output is forced to pay a mutually predefined monetary penalty to every other party that did not receive the output These works show how to de- sign protocols for secure computation with penalties that guaran- tees that either fairness is guaranteed or that each honest party ob- tains a monetary penalty from the adversary Protocols for this task are typically designed in an hybrid model where parties have access to a “claim-or-refund” transaction functionality denote F∗ In this work, we obtain improvements on the efficiency of these constructions by amortizing the cost over multiple executions of secure computation with penalties More precisely, for computa- tional security parameter λ, we design a protocol that implements (cid:96) = poly(λ) instances of secure computation with penalties where the total number of calls to F∗ Keywords: Secure computation, fairness, Bitcoin, amortization|,Non-data,10
| CR is independent of (cid:96) CR 1 INTRODUCTION Protocols for secure multiparty computation [23, 10] allow a set of mutually distrusting parties to carry out a distributed computa- tion without compromising on privacy of inputs or correctness of the end result|,Non-data,10
| Despite being a powerful tool, it is known that secure computation protocols do not provide fairness or guaranteed output delivery when a majority of the parties are dishonest [7] Address- ing this deficiency is critical if secure computation is to be widely adopted in practice, especially given the current interest in practi- cal secure computation Several workarounds have been proposed in the literature to counter adversaries that may decide to abort, pos- sibly depending on the outcome of the protocol In this work, we are interested in the workaround proposed in [18, 17] where an ad- versarial party that aborts on receiving output is forced to pay a mu- tually predefined monetary penalty to every other part that did not receive the output|,Non-data,10
| In practice, such mechanisms would be effective if the compensation amount is rightly defined While the original works [18, 17] depended on e-cash systems, recent works [4, 2, 6, 14, 1, 15, 12] have shown how to use a decentralized digital cur- Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page Copyrights for components of this work owned by others than the author(s) must be honored Abstracting with credit is permitted|,Non-data,10
| To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acmorg CCS’16, October 24 - 28, 2016, Vienna, Austria c(cid:13) 2016 Copyright held by the owner/author(s)|,Non-data,10
 Publication rights licensed to ACM ISBN 978-1-4503-4139-4/16/10  ,Non-data,10
 $1500 DOI: http://dxdoiorg/10,Non-data,10
|1145/29767492978424 Iddo Bentov Cornell University Ithaca, New York iddobentov@cornelledu rency (like Bitcoin) to design protocols for secure computation in the penalty model In this work, we propose major improvements to the efficiency of protocols for secure computation with penalties by amortizing the cost over multiple executions (effectively making the amortized “on-chain” cost zero)|,Non-data,10
| To better explain our contributions, we first discuss the model, efficiency metrics, settings, and the efficiency of state-of-the-art protocols Claim-or-refund transaction functionality In [6, 15], protocols for secure computation with penalties are designed in a hybrid model where parties have access to an ideal transaction functionality called the claim-or-refund transaction functionality [6, 5, 19] This func- tionality, denoted as F∗ CR, takes care of handling “money/coins” and allows protocols to be designed independently of the Bitcoin CR implements the following func- ecosystem|,Non-data,10
| tionality: (1) it accepts a deposit of coins(q), a Boolean circuit φ and a time-limit τ from a designated sender S; and (2) waits until time τ to get a witness w from a designated receiver R such that φ(w) = 1; and (3) if such a witness was received within time τ transfers coins(q) to R; (4) else returns coins(q) back to S CR explain its importance: (1) F∗ Three features of F∗ In a nutshell, F∗ CR-hybrid model work as long as F∗ CR can be very efficiently implemented in Bitcoin (see Appendix A), and (2) F∗ CR provides an abstraction which makes protocols designed in the F∗ CR-hybrid model robust to changes in the Bitcoin architec- ture, and (3) F∗ CR is “complete” for secure computation with penal- ties Protocols for secure computation with penalties designed in the F∗ CR is implemented Such an implementation need not be tied to Bitcoin, i|,Non-data,10
|e, banks and other financial institutions could, in principle, support F∗ CR transactions Capturing the cost of secure computation with penalties A pro- tocol for secure computation with penalties typically involves an sequence of F∗ CR deposits|,Non-data,10
| Thus the costs of such protocols can be captured in a variety of ways such as (1) the total number of calls to F∗ CR in the sequence of deposits, and the complexity of the parameters, specif- ically (3) the maximum/total size of Boolean circuits φ employed in the sequence and (4) the maximum value of time-limit τ used in the sequence To realize F∗ CR in Bitcoin, we need at least one Bit- coin transaction to be broadcasted by the sender (cf Appendix A) Thus, the number of calls to F∗ CR captures the number of Bitcoin transactions that need to be broadcasted to and supported by the Bitcoin network|,Non-data,10
| The deposits made to F∗ CR capture the amount of funds that need to be locked up in Bitcoin transactions during the course of the protocol The size of the Boolean circuit φ used in an F∗ CR transaction captures the amount of time miners need to spend to validate that F∗ CR transaction, consequently captures the load on the network for verifying transactions Additionally, Bitcoin trans- actions currently offer limited support for Bitcoin “scripts” (essen- CR, (2) the maximum/total deposits made to F∗ 418tially the circuit φ) While this is expected to improve in the future (and other alt-coins like Ethereum are already offer generous sup- port for scripts), the size of the Boolean circuit does a good job in capturing the complexity of the scripts that Bitcoin needs to sup- port secure computation with penalties|,Non-data,10
| We denote the total size of the Boolean scripts (ie, Bitcoin scripts) used in our protocols as the “script complexity” of the protocol Finally, the maximum value of the time-limit used in the sequence of F∗ CR deposits cap- tures the “round complexity” of the protocol|,Non-data,10
| Sometimes we make a distinction between “on-chain round complexity” and “off-chain round complexity” This distinction is expected to yield a tighter grip on the efficiency of the protocol The “on-chain round com- plexity” refers to the number of sequential transactions that need to be made on the blockchain Since the time taken to confirm a transaction on the blockchain today is about 1 hour, an “on-chain round complexity” of s implies that the protocol will take at least s hours to complete|,Non-data,10
| The “off-chain round complexity” refers to the standard metric of round complexity used in traditional MPC pro- tocols Note that an off-chain round typically takes less than a few seconds to complete Thus, we believe that for a fair comparison this distinction needs to be made Our contributions|,Non-data,10
 We show how to amortize the cost of secure computation with penalties Let λ be a computational security pa- rameter Then for (cid:96) = poly(λ) we show how (cid:96) sequential in- stances of an n-party non-reactive (resp reactive) secure compu- tation penalties can be realized with the same “on-chain” cost of a single execution in [6] (resp,Non-data,10
| [15]) Since the on-chain latency is typically very high and the on-chain costs capture the load on the Bitcoin network, we believe that our results deliver major im- provements to the efficiency of secure computation with penalties and make it more easy to envision practical implementations on the Bitcoin network (or other networks) Finally, in our protocols neither the parameter (cid:96) nor the sequence of possibly different func- tions that need to be evaluated need to be known in advance (For the reactive case, an upper bound on the transcript and rounds need to be known in advance|,Non-data,10
|) Technical overview and differences from prior work The main difference from prior work is that we reuse a single initial set of F∗ CR deposits for multiple instances of secure computation with penalties That is, parties make an initial set of F∗ CR deposits first, then locally execute secure computation protocols, and whenever there is an abort in the local execution, they have recourse to the F∗ CR deposits in order to get penalties That is, in an optimistic setting where all parties follow the protocol, the initial set of F∗ CR deposits remain untouched throughout the (cid:96) local executions|,Non-data,10
| In the general case, the initial set of F∗ CR deposits will be claimed when an abort occurs in one of the local executions To make things simple, we divide the implementation of (cid:96) in- stances into three stages: (1) the master setup and deposit phase, (21) a local setup phase for each execution, (22) a local exchange phase for each execution, and (3) the master claim phase|,Non-data,10
| In the master setup and deposit phase, parties run an unfair standard se- cure computation protocol that helps specify the Boolean circuits required for the initial F∗ CR deposits, following which parties make these F∗ CR deposits, referred to as the “master deposits” Note that parties do not yet know the inputs of any of the instances of secure computation with penalties and thus all they supply to the mas- ter setup phase is simply randomness Consequently, the Boolean circuits in the F∗ CR deposits will also be independent of the in- puts/outputs of the (cid:96) executions This is one of the fundamental differences between the previous protocols [6, 15, 16] and ours|,Non-data,10
| For example in the non-reactive protocols of [6, 16], the Boolean circuits in the F∗ CR deposits are commitments on the secret shares of the final output That is, the function evaluation occurs first even before the F∗ CR deposits are made On the other hand, in our case, there are multiple function evaluations and the master deposits are made before any of the function evaluations begin Further, the master deposits will need to allow honest parties to obtain penal- ties in case any of the function evaluation instances are aborted by the adversary|,Non-data,10
| Our approach can be applied to the setting of [6, 15, 16] by setting (cid:96) = 1 By performing the master deposits be- fore the function evaluation, our approach surprisingly makes the security analysis easier In particular, we no longer need to worry about aborts that happen during the deposit phase Even better, all the master deposits can be made simultaneously, i|,Non-data,10
|e, in O(1) on-chain rounds, unlike prior protocols where the deposit phase re- quired O(n) on-chain rounds Also, in an optimistic setting where all parties behave honestly, the master claim phase (described later) can also be made simultaneously, ie|,Non-data,10
|, in O(1) on-chain rounds Once all the master deposits have been made, parties sequen- tially perform the local executions At the beginning of each local execution, parties run a secure computation protocol specified in the local setup phase The objective of this phase is to set things up in a way such that penalties can be obtained from the parties in case of aborts|,Non-data,10
| Following this, parties enter the local exchange phase for that execution, where they exchange messages that reveal the output of that execution Note that these phases do not involve F∗ CR It is only when there is an abort in any of these phases, do parties enter the master claim phase where they try to claim these deposits We describe the three phases in more detail|,Non-data,10
| Master setup and deposit phase In this phase, parties run a se- cure computation protocol that implements the following function- ality: (1) run the key generation algorithm of a signature scheme to generate (mvk, msk), (2) secret share msk among all parties, and output mvk to all parties We refer to (mvk, msk) as the master keys Note that msk is unknown to the adversary|,Non-data,10
| Fol- lowing the secure computation protocol, parties make a series of F∗ CR deposits These are the master deposits The Boolean cir- cuits used in these deposits perform two checks: first, they check for one or more messages each of which contain a signature that verifies against the master verification key mvk, and second, they check that the messages obeys a certain structural relation between them The structural relation is necessary to ensure that the honest parties obtain penalties if a local execution was aborted|,Non-data,10
| More on this later Curiously, the sequence of F∗ CR deposits in the master deposit phase is identical to the “see-saw” deposits of [15] in both the non-reactive and reactive cases Of course, we will be using different (more complicated) scripts in each F∗ Local execution phase In this overview, we will focus only on handling the non-reactive case|,Non-data,10
| In the k-th local setup phase (for k ∈ [(cid:96)]), parties run a secure computation protocol that evaluates the function fk on inputs provided by the parties, and then secret shares the output among the parties The secret shares of the out- puts are authenticated twice: once under the msk and once under a local signing key that is generated inside this MPC Note that to authenticate the output secret shares under msk, the parties will need to provide the secret shares of msk to the MPC Neither the msk nor the local signing key will be revealed to the parties|,Non-data,10
| Also, the messages that are signed aren’t simply output secret shares but will include the execution number k and the identity of the party That is, if si is the i-th output secret share, then signatures under msk and the local signing key will be computed on the message (i, k, si) Furthermore, the setup phase will also produce signatures under msk on messages of the form (j, i, k) where j, i ∈ [n]1 1To avoid clutter in our presentation, we assume that the messages CR deposit|,Non-data,10
| 419These are referred to as the “lock witnesses” Another caveat is that we require that the MPC of the local setup phase to deliver outputs in a particular order This specific ordering, the use of lock witnesses, and the structure of the messages containing the secret shares all will be important ideas that will ensure that the honest parties get compensated in the event of aborts Following the k-th local setup phase, parties enter the k-th local exchange phase in which parties broadcast the output shares along with the authentication under the local signing key to all parties|,Non-data,10
| Again, we will require a specific ordering in which the parties per- form broadcasts If all parties behave honestly, then parties will obtain the output of the k-th local execution, and will proceed to the next execution, and so on If there was an abort in either the lo- cal setup phase or the local exchange phase, parties enter the master claim phase and do not engage in any further local executions Note that signatures under msk are never revealed during the local exe- cutions; they will be revealed only during the claim of the master deposits in the master claim phase|,Non-data,10
| Master claim phase In this phase, parties take turns to claim mas- ter deposits The objective of this phase is to ensure that if a local execution was aborted mid-way, then either this local execution is continued to its completion in this phase, or else guarantee that the honest parties obtain penalties An important attack to defend against is one where the adversary replays messages from an older execution|,Non-data,10
| Such an attack would end up allowing the adversary to claim all the master deposits it is required to claim thereby the ad- versary does not pay penalties to honest parties Furthermore, it en- sures that the most recent local execution remains aborted and only the adversary learns the output of that execution Such attacks are taken care of (1) by the use of signatures under the master signing keys that will be revealed only in the master claim phase, and (2) by imposing certain conditions on the structural relations between the messages used in the claim of a master deposit Claiming a master deposit involves revealing a partial transcript containing, say the first j output secret share messages that are of the form (i, k,∗) for all i ∈ [j] and for some specific value k ∈ [(cid:96)]|,Non-data,10
|2 The messages of this form alone are not sufficient to claim the deposit; one has to produce the corresponding signatures under msk as well By imposing such conditions, namely that j signatures on messages (1, k,∗),   |,Non-data,10
| , (j, k,∗) are required to claim a deposit, we can en- sure that the current local execution is continued Signatures under msk on messages of the form (i,∗,∗) will be revealed by honest Pi for a unique value k (typically the most recent local execution) This in turn will ensure that the k-th local execution is continued in the master claim phase Of course, if the adversary were to abort in the master claim phase as well, we will show that this would result in all honest parties obtaining the necessary penalty|,Non-data,10
 Important caveats Note that the penalties can be obtained only at the end of the master claim phase The time-limits on the master deposits will typically be high in order to let all the (cid:96) executions fin- ish Suppose the very first execution was aborted by the adversary,Non-data,10
| Then the funds of the honest parties will remain locked up until the time-limit on the master deposit expires We note that for the single instance case, ie, (cid:96) = 1, more efficient protocols are pre- sented in [16]|,Non-data,10
| Unfortunately, we were not able to take advantage of the techniques in their work Finally, our protocols can also im- prove the efficiency of protocols for secure cash distribution with penalties considered in [2, 15] While our protocols may be used of the form (i, k, si) and (j, i, k) are padded appropriately so that signatures on messages of one form cannot be trivially used to forge signatures on messages of the other form 2We often use ‘*’ as the wildcard character|,Non-data,10
| to implement the protocol part of the construction in [15], the cash distribution part will require fresh deposits per execution Still, we believe that the best venues for our results will be in applications such as poker where repeated executions among the same set of parties are likely Related work The works of [4, 5] construct 2-party lottery proto- cols using Bitcoin scripts which essentially implement F∗ CR|,Non-data,10
| Other notable works which are not in the F∗ CR model include the works of [2, 1, 13, 12, 14] The works of [13, 12] use a more power- ful transaction functionality which implements a blockchain to im- plement “smart contracts” and fair secure computation (under the penalties notion) We wish to emphasize that protocols constructed in the F∗ CR-hybrid model can be easily cast into protocols in any of the above models Also, we make an explicit distinction be- tween the off-chain costs and the on-chain costs which is not al- ways captured in other works|,Non-data,10
| For instance, in Ethereum, the entire smart contract (or the function) is put on the blockchain, and in a naïve construction, every miner is involved in the computation of the function as well as the state changes associated with executing the contract These are exactly the type of burdens on the miners that we are trying to relieve via use of (possibly expensive) off- chain mechanisms (eg, secure computation)|,Non-data,10
| The works of [21, 8] are concerned with the establishment of a “payment channel” to allows parties to do an unbounded number of money transfers without burdening the blockchain 2 PRELIMINARIES A function μ(·) is negligible in λ if for every positive polynomial p(·) and all sufficiently large λ’s it holds that μ(λ) < 1/p(λ) A probability ensemble X = {X(a, λ)}a∈{0,1}∗,n∈N is an infinite sequence of random variables indexed by a and λ ∈ N|,Non-data,10
| Two dis- tribution ensembles X = {X(a, λ)}λ∈N and Y = {Y (a, λ)}λ∈N c≡ Y are said to be computationally indistinguishable, denoted X if for every non-uniform polynomial-time algorithm D there exists a negligible function μ(·) such that for every a ∈ {0, 1}∗, ||Pr[D(X(a, λ)) = 1] − Pr[D(Y (a, λ)) = 1]|| ≤ μ(λ) All parties are assumed to run in time polynomial in the security parameter λ We prove security in the “secure computation with coins” (SCC) model proposed in [6] Note that the main difference from standard definitions of secure computation [9] is that now the view of Z contains the distribution of coins|,Non-data,10
| Let IDEALf,S,Z (λ, z) denote the output of environment Z initialized with input z after interacting in the ideal process with ideal process adversary S and (standard or special) ideal functionality Gf on security parameter λ Recall that our protocols will be run in a hybrid model where parties will have access to a (standard or special) ideal functionality Gg We denote the output of Z after interacting in an execution of π in such a model with A by HYBRIDg π,A,Z (λ, z), where z denotes Z’s input We are now ready to define what it means for a protocol to SCC realize a functionality|,Non-data,10
| DEFINITION 1 Let n ∈ N Let π be a probabilistic polynomial- time n-party protocol and let Gf be a probabilistic polynomial-time n-party (standard or special) ideal functionality We say that π SCC realizes Gf with abort in the Gg-hybrid model (where Gg is a standard or a special ideal functionality) if for every non-uniform probabilistic polynomial-time adversary A attacking π there exists a non-uniform probabilistic polynomial-time adversary S for the ideal model such that for every non-uniform probabilistic polynomial- time adversary Z, {IDEALf,S,Z (λ, z)}λ∈N,z∈{0,1}∗ c≡ {HYBRIDg π,A,Z (λ, z)}λ∈N,z∈{0,1}∗ |,Non-data,10
| 420session identifier sid, an n-input, n(cid:48)-output function Notation: f, a hard-coded ordering of outputs χ = (χ1,    , χn(cid:48) ), parties P1, |,Non-data,10
|   , Pn, adversary S that corrupts parties {Ps}s∈C, set H = [n] \ C INPUT PHASE: • Wait to receive a message (input, sid, ssid, r, yr) from Pr for all • Wait to receive a message (input, sid, ssid, s, {ys}s∈C ) from S|,Non-data,10
| OUTPUT DELIVERY: • Compute ((χ1, z1),    , (χn(cid:48) , zn(cid:48) )) ← f (y1, |,Non-data,10
|   , yn) • For j ∈ [n(cid:48)], sequentially do: send (output, sid, ssid, zj ) to r ∈ H|,Non-data,10
| Pχj  If χj ∈ C, then: – If S sends (abort, sid, ssid), send (output, sid, ssid, ⊥) to Pr for r ∈ H Figure 1: The ideal functionality F ord ery of output f enforcing ordered deliv- DEFINITION 2|,Non-data,10
| Let π be a protocol and f be a multiparty func- tionality We say that π securely computes f with penalties if π SCC-realizes the functionality F (cid:63) f according to Definition 1 Throughout this paper, we deal only with static adversaries and impose no restrictions on the number of parties that can be cor- rupted Our schemes also make use of a digital signature scheme which we denote as (SigKeyGen, SigSign, SigVerify)|,Non-data,10
| 21 Ideal Functionalities Secure function evaluation with ordered output delivery In our protocols, we ask parties to run secure computation protocols that deliver output in a certain order (Note that standard secure compu- tation protocols do not guarantee fairness in the presence of a dis- honest majority|,Non-data,10
|) Such protocols can be obtained easily by tweak- ing existing MPC protocols in the following way First, the func- tion is evaluated on the inputs to produce, say n outputs z1,   |,Non-data,10
| , zn Each zi is then secret shared among the parties Once the outputs are delivered to the parties, they then proceed to reconstruct the ac- tual outputs in order That is, in the first reconstruction phase, all parties broadcast their shares of z1|,Non-data,10
| At the end of this phase, P1 ob- tains z1 Then parties broadcast their shares of z2 in the next phase and so on Our protocols typically involve sending the outputs in reverse order The actual order is slightly more complicated, but the idea above can be trivially generalized to accommodate our needs|,Non-data,10
| For clarity, we present the generalized definition of the functional- ity in Figure 1 The values χj specify the index of the party that is supposed to receive the output in the j-th phase That is, in phase j, party Pχj receives the output zj Note that n(cid:48) > n is possi- ble|,Non-data,10
| In our protocols we will need n(cid:48) = O(n2) but simple round reduction techniques can be applied to implement the desired func- tionality in O(n) rounds Note that the protocol realizing F ord f does not guarantee fairness Also note that F ord can be realized in the FOT-hybrid model Claim-or-refund transaction functionality F∗ CR [6, 5, 19]|,Non-data,10
| At a high level, F (cid:63) CR allows a sender Ps to conditionally send coins(x) to a receiver Pr The condition is formalized as the revelation of a satisfying assignment (ie, witness) for a sender-specified circuit φs,r( · ; z) (i|,Non-data,10
|e, relation) that may depend on some public input z Further, there is a “time” bound, formalized as a round num- ber τ, within which Pr has to act in order to claim the coins An f F (cid:63) CR with session identifier sid, running with parties P1, |,Non-data,10
|   , Pn, a parameter 1λ, and an ideal adversary S proceeds as follows: • Deposit the from Ps, tuple record (deposit, sid, ssid, s, r, φs,r, τ, coins(x)) the message (deposit, sid, ssid, s, r, φs,r, τ, x) and send it to all parties Ignore any future deposit messages with the same ssid from Ps to Pr|,Non-data,10
| receiving phase Upon • Claim phase τ: time upon Until receiving (1) (claim, sid, ssid, s, r, φs,r, τ, x, w) from Pr, check if recorded, a tuple send and (2) send (claim, sid, ssid, s, r, φs,r, τ, x, w) (claim, sid, ssid, s, r, φs,r, τ, coins(x)) to Pr, and delete the record (deposit, sid, ssid, s, r, φs,r, τ, x) (deposit, sid, ssid, s, r, φs,r, τ, x) was if φs,r(w) = 1|,Non-data,10
| If both checks pass, parties, all to • Refund After phase: record (deposit, sid, ssid, s, r, φs,r, τ, x) was not deleted, then send (refund, sid, ssid, s, r, φs,r, τ, coins(x)) to Ps, delete record (deposit, sid, ssid, s, r, φs,r, τ, x) time the τ: if Figure 2: The special ideal functionality F (cid:63) CR important property that we wish to stress is that the satisfying wit- ness is made public by F (cid:63) CR Any cryptocurrency that supports time-dependent scripts can be used to realize F∗ CR|,Non-data,10
| Earlier Bitcoin implementations of F∗ CR were given in [6, 5, 19], and we provide a more secure implementation in Appendix A In a Bitcoin real- ization of F∗ CR, sending a message with coins(x) corresponds to broadcasting a transaction to the Bitcoin network, and waiting ac- cording to some time parameter until there is enough confidence that the transaction will not be reversed We denote an F (cid:63) CR trans- action where sender Ps asks receiver Pr for a witness for a predi- cate φ in exchange for coins(q) with deadline τ by: Ps −−−−−−−−−−−−−→ φ q,τ Pr Next, we define an important metric of protocols that involve a se- quence of F∗ CR deposits called the “script complexity” This metric captures the load on the Bitcoin network for verifying the F∗ CR transactions|,Non-data,10
| DEFINITION 3 (SCRIPT COMPLEXITY [14]) Let Π be a protocol among P1,   |,Non-data,10
| , Pn in the F∗ CR-hybrid model For circuit φ, let ||φ|| denote its circuit complexity For a given execution of Π starting from a particular initialization Ω of parties’ inputs and random tapes and distribution of coins, let VΠ,Ω denote the sum of all ||φ|| such that some honest party claimed an F∗ CR transaction by producing a witness for φ during an execution of Π Then the script ♦ complexity of Π, denoted VΠ, equals maxΩ (VΠ,Ω)|,Non-data,10
 Secure computation with penalties—multiple executions We now present the functionality F∗ MSFE which we wish to realize Recall that secure computation with penalties guarantees the fol- lowing An honest party never has to pay any penalty,Non-data,10
| If a party aborts after learning the output and does not deliver output to honest parties, then every honest party is compen- sated See Figure 3 for a formal description The main difference between the prior definitions in [6, 15] is that F∗ MSFE directly realizes multi- ple invocations of secure computation with penalties For simplic- itly F∗ In the first phase referred to as the deposit phase, the functional- ity F∗ MSFE accepts safety deposits coins(d) from each honest party MSFE deals only with the non-reactive case|,Non-data,10
| 421Notation: session identifier sid, parties P1,    , Pn, adversary S that corrupts {Ps}s∈C, safety deposit d, penalty amount q, a time-limit τ, set H = [n] \ C|,Non-data,10
| DEPOSIT PHASE: Initialize flg = ⊥ • Wait to get message (setup, sid, ssid, i, coins(d)) from Pi for all i ∈ H Then wait to get message (setup, sid, ssid, coins(hq)) from S where h = ||H|| EXECUTION PHASE: Set flg = 0|,Non-data,10
| For k = 1,   , sequentially do: • Wait to receive a message (input, sid, ssid(cid:107)k, i, x(k) • Wait until , fk) from Pi for all i ∈ H|,Non-data,10
| Send (function, sid, ssid(cid:107)k, fk) to all parties time τ to receive a message (input, sid, ssid(cid:107)k, s }s∈C , fk) from S If no such message was received within {x(k) time τ, then go to the claim phase i 1 , |,Non-data,10
|   , z(k) • Compute (z(k) • Send message (output, sid, ssid(cid:107)k, {z(k) • If S returns (continue, sid, ssid), n ) ← fk(x(k) 1 ,  |,Non-data,10
|  , x(k) n ) s }s∈C ) to S then send (output, sid, ssid(cid:107)k, z(k) i ) to each Pi|,Non-data,10
| • Else if S returns (abort, sid, ssid), update flg = 1, and go to the claim phase CLAIM PHASE: At time τ, do: • If flg = 0 or ⊥, send (return, sid, ssid, coins(d)) to all Pr for r ∈ H If flg = 0, send (return, sid, ssid, coins(hq)) to S • Else if flg = 1, send (penalty, sid, ssid, coins(d + q + qi)) to Pi for all i ∈ H where qi = 0 unless S sent a message (extra, sid, ssid, {qi}i∈H ,(cid:80) i∈H coins(qi))|,Non-data,10
| Figure 3: Special ideal functionality F∗ quential SFE with penalties MSFE for multiple se- and penalty deposit coins(hq) from the adversary Note that the penalty deposit suffices to compensate each honest party in the event of an abort Once the deposits are made, parties enter the next phase referred to as the execution phase where parties can en- gage in unbounded number of secure function evaluations|,Non-data,10
| In each execution, parties submit inputs and wait to receive outputs As usual, the ideal adversary S gets to learn the output first and then decide whether to deliver the output to all parties If S decides to abort, then no further executions are carried out, parties enter the claim phase, and honest parties get coins(d + q), ie|,Non-data,10
|, their safety deposit plus the penalty amount Note that penalties are distributed only at time τ Now if S never aborts during a local execution, then the safety deposits are returned back to the honest parties, and S gets back its penalty deposit at time τ Note that we require S to deposit coins(hq) up front|,Non-data,10
| This is different from the definition of secure computation with penalties in [6], where S may not submit coins(hq) and yet the computation might proceed We believe that our definition is more natural We are able to support this definition because in our protocol (unlike the case in [6]), the computation happens only after all the deposits are made Next, we discuss the reactive case|,Non-data,10
| Reactive case The definition for the secure computation with penalties in the reactive setting F∗ MSFE ex- cept that the function fk is composed of sub-functions for the dif- ferent stages, ie, fk = (fk,1, |,Non-data,10
|   , fk,ρ), where ρ denotes the num- ber of stages Now, S can abort between different stages of fk or within a single stage, say fk,ρ(cid:48)|,Non-data,10
| In either case, the honest parties will be compensated via the penalty deposit coins(hq) submitted by S in the deposit phase For lack of space, the formal definition is presented in the full version MMPC is identical to F∗ 3 TWO PARTY NON-REACTIVE CASE j j We describe the protocol for the 2-party non-reactive case in Fig- ure 4|,Non-data,10
| For clarity, we annotate each of the steps in (1) the master deposits as Txj, (2) the k-th local setup phase as sp(k) , (3) the k- th local exchange phase as ex(k) , (4) the master claims as clmj Sometimes we treat these annotations as Boolean variables which are set to 1 if the corresponding event occurred or else they are set to 0 As an example, we say “sp(k) delivered output to P1 We now explain the design of the protocol and describe each of the phases in more detail|,Non-data,10
| In the presentation here we ignore some details on the time-limits 1 = 1” iff F ord(cid:98)fk In the master setup phase, parties interact with an unfair ideal functionality that runs the key generation algorithm for a digital signature scheme, and outputs the master verification key mvk to both parties, and secret shares the master signing key msk In ad- dition, the master function will authenticate the shares of the mas- ter signing key Looking ahead we will need this authentication because each subsequent local execution will need to produce sig- natures verifiable by the master verification key|,Non-data,10
| To do so, these subsequent local executions will reconstruct the master signing key from the authenticated secret shares held by both parties Follow- ing this, parties enter the master deposit phase where they make F∗ CR deposits as follows In the following, τ2 > τ1 P1 P2 φ2 −−−−−−−−−−−−−→ −−−−−−−−−−−−−→ q,τ2 φ1 q,τ1 P2 P1 (Tx2) (Tx1) Here, the predicates φ1, φ2 have the master verification key mvk hardcoded in them|,Non-data,10
| The predicates essentially check if their input is a valid signature against the master verification key mvk The mes- sages that are signed under msk will be secret shares of the output of a function evaluation (more on this in the next paragraph), and we will append the player index and an execution number denoted id, and then sign the message consisting of player id, nonce, and secret share under the master signing key msk As we will see be- low, the predicate φ1 takes as input one message and a correspond- ing signature, while the predicate φ2 takes as input two messages and corresponding signatures In addition to checking the validity of the signatures, the predicates also verify an additional condition on the nonces contained in the underlying signed messages|,Non-data,10
| Below, we explicitly specify the predicates φ1 and φ2: φ1(id1, t1, σ1; mvk) = SigVerify(mvk, (1, id1, t1), σ1) φ2(id1, t1, σ1, id2, t2, σ2; mvk) =  (id1 = id2) (cid:86) SigVerify(mvk, (1, id1, t1), σ1) (cid:86) SigVerify(mvk, (2, id2, t2), σ2)  functionality F ord(cid:98)fk Next, we describe the local setup phase In the k-th local setup phase, the parties submit their authenticated shares of the master signing key, and further also submit the inputs to an unfair ideal computing the function fk that is to be com- puted in this phase As described before, the k-th setup phase first reconstructs the master signing key from the authenticated shares submitted by the parties Then it computes the function fk on the inputs submitted by the parties to obtain the output z(k)|,Non-data,10
| (For sim- plicity, we assume that all parties obtain the same output) Fol- lowing this, the output z(k) is secret shared using an additive secret sharing scheme to produce shares s(k) 2  Each of these shares is then authenticated twice: once using the reconstructed master sign- 1 , s(k) 422MASTER SETUP PHASE: P1 and P2 interact with an ideal func- tionality F(cid:98)f that computes (mvk, msk) ← SigKeyGen(1λ) and computes secret shares msk1, msk2 of msk and delivers msk1, mvk, MAC(msk2) to P1 and msk2, mvk, MAC(msk1) to P2 where MAC is (an information-theoretic) message authentication code MASTER DEPOSIT PHASE: Parties make the following F∗ CR deposits: P1 P2 −−−−−−−−−−−−−−−→ φ2 q,τ2 −−−−−−−−−−−−−−−→ φ1 q,τ1 P2 P1 (Tx2) (Tx1) where: φ1(id1, t1, σ1; mvk) = SigVerify(mvk, (1, id1, t1), σ1) φ2(id1, t1, σ1, id2, t2, σ2; mvk) =  (id1 = id2) (cid:86) SigVerify(mvk, (1, id1, t1), σ1) (cid:86) SigVerify(mvk, (2, id2, t2), σ2)  interact with an ideal functionality F ord(cid:98)fk and the corresponding MACs|,Non-data,10
| F ord(cid:98)fk EXECUTION PHASE: In the k-th local setup phase: Parties agree on the function to be executed fk via broadcast If there is disagree- ment, then parties enter the master claim phase Else, P1 and P2 to which they input: (1) the function fk and inputs to fk, and (2) mvk, secret shares of msk, computes the output z(k) ob- tained by evaluating fk on the inputs provided by the parties, then it loc ) ← secret shares z(k) = s(k) SigKeyGen(1λ) and computes σ(k) i = SigSign(msk, (i, k, s(k) and ψ(k) )) F ord(cid:98)fk the following order (i|,Non-data,10
|e, χ = (2, 1) for F ord(cid:98)fk )) sends the outputs in 2  It then computes (vk(k) i = SigSign(sk(k) loc , (i, k, s(k) 1 ⊕s(k) loc , sk(k) ): i i (sp(k) 2 ) (sp(k) 1 ) loc ) to P2, loc ) to P1 2|,Non-data,10
| (s(k) 1 (s(k) 2 , σ(k) 1 , σ(k) 2 , ψ(k) 1 , ψ(k) 2 ; vk(k) 1 ; vk(k) In the k-th local exchange phase: 1 P1 sends (s1, ψ1) = (s(k) 2 If SigVerify(vk(k) 2 ) to P1|,Non-data,10
| 2 , ψ(k) 1 , ψ(k) 1 ) to P2 loc , (1, k, s1), ψ1) = 1: (ex(k) 1 ) P2 sends (ex(k) 2 ) CLAIM PHASE: Parties enter this phase when either all local execu- tions are completed or in the event of aborts after/during the master deposit phase (s(k) 2 At 1|,Non-data,10
| At time τ1: 1 1 If sp(k+1) = 1, , σ(k+1) 1 , σ(k) time τ2, 1 1 ) if k > 0 tion ness (k + 1, s(k+1) (k, s(k) let k denote the last completed local execu- then P1 claims Tx1 using wit- ), else claim Tx1 using witness (clm1) if party P1 claimed Tx1 using witness (id1, t1, σ1), then party P2 claims Tx2 at time τ2 using wit- ness (id1, t1, σ1, id2 = id1, t2 = s(id1) , σ2 = σ(id1) ) If there exists k such that sp(k) 2 = 0, then both parties output t1⊕t2 as the output of the k-th execution|,Non-data,10
| (clm2) 2 = 1 but ex(k) 2 2 Figure 4: 2-party realization of F∗ MSFE ing key msk, and once using a local signing key sk(k) loc generated inside the unfair ideal functionality We stress that the local sign- ing key sk(k) loc is never revealed to any party; recall that the global signing key msk is never revealed to any party either Finally, the local outputs of the unfair ideal functionality in the k-th local setup phase are distributed in the following order to the two parties: 1 Party P2 obtains its secret share of the output s(k) 2 on T (k) a signature σ(k) and a signature ψ(k) corresponding local verification key vk(k) loc |,Non-data,10
| 2 = (2, k, s(k) on T (k) 2 2 2 along with 2 ) signed under msk loc and the (sp(k) 2 ) signed under sk(k) 1 1 1 1 on T (k) signed under sk(k) 1 = (1, k, s(k) on T (k) 2 Party P1 obtains its secret share of the output s(k) a signature σ(k) and a signature ψ(k) corresponding local verification key vk(k) loc  along with 1 ) signed under msk loc , and the (sp(k) 1 ) We will shortly discuss why the order of outputs as above is needed (ie|,Non-data,10
|, why P1 obtains the output of the local setup phase after P2) Observe that to obtain the output of the local phase, par- ties simply have to exchange the shares s(k) 2 , and the out- put of the local phase equals s(k) 2  The local exchange phase happens in the following order: 1 ⊕s(k) and s(k) 1 1 Party P1 first sends T (k) 1 and ψ(k) 1 to P2|,Non-data,10
| (ex(k) 1 ) 2 to P1 2 If a valid message was received, then P2 sends T (k) and ψ(k) 2 (ex(k) 2 ) After this, the local phase completes, and the parties have obtained the outputs Note that since signatures under sk(k) loc are unforgeable except with negligible probability (because each party only has an additive share of sk(k) loc ), it follows except with negligible proba- bility that a valid (T (k) ) pair sent by party Pi has to be the one generated by the local setup phase, and hence results in parties generating the correct output|,Non-data,10
| Following this, the parties can then proceed to the next local phase and so on Suppose (cid:96) denote the total number of successfully completed local executions Once all the (cid:96) local executions are completed, the parties proceed to master claim phase where the following happens in order: , ψ(k) i i 1 , σ(k) time τ2, 1 At time τ1: If sp(k+1) tion|,Non-data,10
| ness (k + 1, s(k+1) (k, s(k) let k denote the last completed local execu- then P1 claims Tx1 using wit- ), else claim Tx1 using witness (clm1) = 1, , σ(k+1) 1 ) if k > 0 1 1 1 2 At if party P1 claimed Tx1 using witness (id1, t1, σ1), then party P2 claims Tx2 at time τ2 using wit- ness (id1, t1, σ1, id2 = id1, t2 = s(id1) If there exists k such that sp(k) 2 = 0, then both parties output t1⊕t2 as the output of the k-th execution (clm2) 2 = 1 but ex(k) , σ2 = σ(id1) )|,Non-data,10
| 2 2 The master claim phase is designed in a way that allows the hon- est party to force the completion of the most recent local execu- tion that is incomplete For instance, P1 can force the comple- tion of the (k + 1)-th execution by claiming Tx1 using witness , σ(k+1) (k + 1, s(k+1) ) This then forces P2 to reveal the secret share s(k+1) without which it cannot claim Tx2 This is because the only signature under msk on messages of the form (2, k + 1,∗) that P2 possesses is T (k+1) )|,Non-data,10
| Thus, we have that either P2 claims Tx2 or pays a penalty coins(q) to honest P1 = (2, k + 1, s(k+1) 1 2 1 2 2 423On the other hand, if P1 was dishonest or if all local executions were completed, then parties effectively replay some old execution That is, P1 will claim Tx1 using witnesses obtained from the k-th local execution for which ex(k) 2 = 1 Following this P2 can claim Tx2 using witness revealed by P1 and witness obtained from the k-th local setup phase|,Non-data,10
| We prove: THEOREM 1 Assume one-way functions exist There exists a 2-party protocol that SCC-realizes F∗ CR)- hybrid model such that the number of calls to F∗ CR, its script com- plexity, and deposit amounts are independent of the number of exe- cutions MSFE in the (FOT,F∗ Proof sketch|,Non-data,10
| Let Pj denote the party corrupted by the adversary A We describe the simulator S for the protocol of Figure 4 S begins by acting as the unfair ideal functionality in the master setup phase, and runs the key generation algorithm of a digital signature scheme to produce (mvk, msk) It then chooses a random mskj to give to A|,Non-data,10
| If A aborts the master setup phase, then S outputs whatever A outputs and terminates the simulation Else, in the master de- posit phase, S acts as F∗ CR If j = 2, it waits to receive a deposit from A If the deposit was not received or the deposit is not of the specified format, then S aborts outputting whatever A outputs|,Non-data,10
| Else, S obtains coins(q) from A which it forwards to F∗ MSFE as the penalty deposit On the other hand, if j = 1, then S acting as F∗ informs A that (honest) P2 made the deposit as instructed Then CR it waits for A to make the deposit Again if the deposit is not of the correct form or was not made, then S terminates the simulation outputting whatever A outputs|,Non-data,10
| In this case, the simulation is in- distinguishable from the real execution since honest P2 would have got coins(q) refunded from Tx2 with all but negligible probability (except in the case A manages to forge signatures under msk) Else, it obtains coins(q) from A which it forwards to F∗ MSFE as the penalty deposit This concludes the simulation of the master setup and deposit phases In the k-th local setup phase, S learns of the function to be evalu- MSFE and acts as the unfair ideal functionality F ord(cid:98)fk ated fk from F∗ , and obtains the input for this execution from A|,Non-data,10
| Note that if A sends incorrect shares of msk, then S terminates the simulation, and the simulation will be indistinguishable from the real execution since the MAC checks won’t pass in the real execution except with negligible probability Then S runs the key generation algorithm of a digital signature scheme to generate (vk(k) loc ), and com- putes the signature ψ(k) j = (j, k, s) If A for random value s aborts in this step, then S rejects any further local executions and goes directly to the simulation of the master claim phase (described below) This still results in a valid simulation since A should not be able to forge a signature under sk(k) loc due to the unforgeability property of the digital signature scheme|,Non-data,10
| Otherwise, S begins the simulation of the local exchange phase If j = 1, then it waits to receive (T, ψ) from A ), S termi- nates the simulation (since this is a forgery that should happen only with negligible probability) Otherwise, S contacts F∗ with the extracted input (obtained while acting as F ord(cid:98)fk MSFE ) to obtain the output of the local execution z(k)|,Non-data,10
| S acting as P2 sends the 2 = (2, k, z(k)⊕s) and the signature ψ(k) value T (k) to A The case when j = 2 is also handled similarly S first sub- mits the extracted input to F∗ MSFE to get the output of the k-th local execution z(k) Then S acting as honest P1 sends the value 1 = (1, k, s⊕z(k)) along with a signature ψ(k) to A|,Non-data,10
| It T (k) loc , sk(k) loc on message T (k) , vk(k) loc If (T, ψ) (cid:54)= (T (k) It then sends T (k) under sk(k) on T (k) to A on T (k) , ψ(k) , ψ(k) 2 j j j j j 2 1 1 1  Now, S acting as F∗ is easy to see that the simulation is indistinguishable from the real execution Finally, we describe the simulation of the master claim phase|,Non-data,10
| S enters this phase either because there were: (1) aborts in the local setup phase, (2) aborts in the local exchange phase, or (3) all ex- ecutions were successfully completed We analyze separately the case when P1 is corrupt and the case when P2 is corrupt Suppose j = 1 S waits until time τ1 to see if P1 claims Tx1|,Non-data,10
| Suppose P1 does not claim Tx1, then S waits to get its penalty deposit back from F∗ MSFE and sends it to P1 as refund obtained from Tx2 The simulation is indistinguishable from the real execution because P2 always obtains the output first in the local execution; thus if P1 had received the output of a local execution phase, then so did P2 Therefore, S will be able to get its penalty deposit coins(q) back from F∗ MSFE Now on the other hand, suppose P1 did claim Tx1 using some witness (id1, t1, σ1), then S checks if σ(id1) 1 = σ1 (i|,Non-data,10
|e, if σ1 was handed to A during the simulation) The check will pass with all but negligible probability since this corresponds to A forg- ing a signature under msk In the rest of the analysis we will as- sume that σ1 = σ(id1) CR will need to produce coins(q) to A as the claim reward for claiming Tx1|,Non-data,10
| To do so, S will need to obtain its penalty amount from F∗ MSFE As before, this step is possible since P1 cannot learn the output of a local execution before the honest party (recall P2 always obtains outputs first in the local exchange phase), and thus S will be able to get its penalty deposit back from F∗ MSFE which it can send to P1 as the money obtained by claiming Tx1 Now all that S needs to do is to produce witnesses for claiming Tx2 in order to justify that coins(q) from Tx2 are not going to be refunded back to P1 This is easy since the witness (id1, t1, σ1, id2 = id1, t2 = z(id1)⊕t1, σ2 = σ(id2) ) satisfies φ2|,Non-data,10
| In other words, the secret shares and corresponding signatures from the id1-th execution will allow honest P2 to claim Tx2 This concludes the simulation in the case when P1 is corrupt It is easy to see that the simulation is indistinguishable from the real execution Next, we consider the case when j = 2|,Non-data,10
| Now S will need to act first (as honest P1) in the master claim phase Let k de- note the number of completed local executions, ie, ex(k) 2 = 1|,Non-data,10
| If k = 0, then S does not have to act in the master claim phase It will simply get back its penalty deposit from F∗ MSFE and return it to P2 as refund of Tx1 The simulation is indistinguishable from real since except with negligible probability P2 will not be able to produce signatures under msk to claim Tx2 In the rest of the simulation, we assume k > 0|,Non-data,10
| At time τ1, S will have to claim Tx1 To do so, S first checks if there was an incomplete local execution, ie, if sp(k+1) = 1|,Non-data,10
| If there was, this means that the output of the (k + 1)-th execution was not obtained by both par- ties (in fact, it is possible that only P2 obtained the output and not P1) S will claim Tx1 using the witness (k + 1, s⊕z(k+1), σ(k+1) ) where s was the secret share given to P2 as part of the output of the (k + 1)-th local setup phase Now, S waits to see if P2 claims Tx2 Suppose P2 does not claim Tx2, then this means that in the real execution honest P1 would not obtain the output, but only the penalty|,Non-data,10
| Thus, to make the simulation indistinguishable from real, S will send an abort message to F∗ MSFE, and termi- nate the simulation (in particular, it will not get its penalty deposit back from F∗ MSFE) On the other hand, if P2 did claim Tx2, then except with negligible probability it has to do using the witness (k + 1, s⊕z(k+1), σ(k+1) ) This is because the only signature under msk on messages of the form (k + 1,∗,∗) that A possesses is on the message (k + 1, s, σ(k+1) ) obtained dur- ing the interaction with S Thus, in this case, S asks F∗ MSFE to , k + 1, s, σ(k+1) 2 1 1 2 2 1 424n,i < τi = τ unlock i+1,i = Note on time-limits: τ1 < τ2 < ··· < τn|,Non-data,10
| For each i ∈ [n − 1]: τ lock i+1,i = ··· τ lock ··· τ unlock ROOF DEPOSITS For each j ∈ [n − 1]: n,i  φn Pj −−−−−−−−−−−−−−−−→ Pn LADDER DEPOSITS For i = n − 1 down to 1: • Rung unlock: For j = n down to i + 1: q,τn tially check if their input is a valid signature against the master verification key mvk|,Non-data,10
| The messages that are signed under msk will be secret shares of the output of a function evaluation (more on this in the next paragraph), and we will append the player in- dex and a nonce denoted id which essentially denotes an execution number, and then sign the message consisting of player id, nonce, and secret share under the master signing key msk In addition to checking the validity of the signatures, the predicates also verify an additional structural relation on the nonces contained in the under- lying signed messages Below, we explicitly specify the predicates {φlock j,i },{φi},{φunlock }: j,i −−−−−−−−−−−−−−−−→ φunlock j,i q,τ unlock j,i Pi j,i (TT, id, σ; mvk) = tv(id) φlock i−1(TT) SigVerify(mvk, (j, i, id), σ) (Txn,j) (Txunlock j,i ) (Txi) (Txlock j,i ) Pj • Rung climb: −−−−−−−−−−−−−−−−→ Pi • Rung lock: For each j = n down to i + 1: φi i·q,τi Pi+1 Pi −−−−−−−−−−−−−−−→ φlock j,i q,τ lock j,i Pj Figure 5: Locked ladder mechanism from [15] 1 deliver the output to P1 for execution k + 1, and obtains back the penalty deposit from F∗ MSFE which it forwards to P2 as the reward obtained for claiming Tx2|,Non-data,10
| Finally, we consider the case when sp(k+1) = 0, ie, the (k + 1)-th execution did not deliver outputs In this case, S gets its penalty deposit coins(q) to either party MSFE|,Non-data,10
| Then S claims Tx1 using witnesses from the back from F∗ k-th execution, ie, (k, s⊕z(k), σ(k) 1 ) where s was the random se- cret share sent to P2 Now if P2 claims Tx2, except with negligible probability it has to do using witness (k, s⊕z(k), σ(k) 1 , k, s, σ(k) 2 )|,Non-data,10
| Suppose P2 claimed Tx2, then S produces the necessary coins(q) from the returned penalty deposit On the other hand, if P2 did not claim Tx2, then S sends the returned coins(q) back to F∗ MSFE to be delivered to the honest party as extra reward It is easy to see that the simulation is indistinguishable from real both in the stan- dard sense as well as with respect to the distribution of coins This concludes the proof of the theorem|,Non-data,10
| 4 MULTIPARTY CASE We describe the protocol for the multiparty non-reactive case MASTER SETUP PHASE AND MASTER DEPOSIT PHASE In the master setup phase, parties interact with an unfair ideal functional- ity that realizes the master setup function which runs the key gen- eration algorithm for a digital signature scheme, and outputs the master verification key mvk to all n parties, and secret shares the master signing key msk|,Non-data,10
| In addition, the master function will au- thenticate the shares of the master signing key That is, in spirit, the master setup phase is identical to the one in the 2-party case, except now it caters to n parties Next, parties enter the master deposit phase where they make F∗ CR deposits as in Figure 5 (ie|,Non-data,10
|, identical to the locked ladder mechanism in [15]) Note that rela- tion between time-limits is specified in Figure 5 j,i } all have the master verification key mvk hardcoded in them The predicates essen- Here, the predicates {φi}, {φunlock }, {φlock j,i (cid:94) (cid:94) φi(TT, id; mvk) = tv(id) (TT) i φunlock j,i (TT, id, σ; mvk) = tv(id) i (TT) SigVerify(mvk, (j, i, id), σ) In the above, we refer to the witness σ as the “lock witness|,Non-data,10
|” The description of the predicates use the transcript validator tv which we define below: Let TT = (T (id1) tv(id) 1 (TT) = 1 iff i , σ(id1) 1 )(cid:107)···(cid:107)(T (idi) i , σ(idi) i ) Then – id1 = ··· = idi ≥ id – for all j ≤ i: T (idj ) j is a message of the form (j, idj,∗) and σ(idj ) j is a valid signature on T (idj ) j under msk i That is, tv(id) puts to an unfair ideal functionality F ord(cid:98)fk ensures that the witnesses reveal the partial tran- script containing the first i message-signature pairs, i|,Non-data,10
|e, (T, σ) pairs Furthermore the relation between the transcript witness and the lock witness is that the id’s contained in them are such that id1 = ··· = idi ≥ id LOCAL SETUP PHASE|,Non-data,10
| Next, we describe the local setup phase In the k-th local setup phase, the parties submit their authenticated shares of the master signing key, and further also submit the in- computing the function fk The k-th local setup phase first reconstructs the master signing key from the authenticated shares submitted by the parties Then it computes the function fk on the inputs submitted by the parties to obtain the output z(k)|,Non-data,10
| Following this, the output z(k) is secret shared using an additive secret sharing scheme to produce shares s(k) 1 ,    , s(k) n |,Non-data,10
| Each of these shares is then authenticated twice: once using the reconstructed master signing key msk, and once using a fresh local signing key sk(k)  In ad- dition signatures under msk are generated on messages (j, i, k) for all i, j ∈ [n] × [n] such that j ≥ i We stress that the local sign- ing key sk(k) loc is never revealed to any party; recall that the global signing key msk is never revealed to any party either Finally, the local outputs of the unfair ideal functionality in the k-th local setup phase are distributed in the following order to the parties: loc generated inside F(cid:98)fk For i = n down to 1: (a) [Main witness signed under both local and global keys] along with a ) signed under loc and the (sp(k) ) Party Pi obtains its secret share of the output s(k) signature σ(k) i = (i, k, s(k) msk and a signature ψ(k) corresponding local verification key vk(k) loc |,Non-data,10
| on the message T (k) on T (k) signed under sk(k) i i i i i i 425Pj obtains a signature σ(k) Observe that the witnesses delivered by F ord(cid:98)fk (b) [Lock witness signed under global key] For j = n to i + 1: j,i on “(j, i, k)” under msk (sp(k) j,i ) are in the reverse order of the witnesses that are required to claim the master de- posits Later in the local exchange phase, these witnesses will be exchanged among the parties in the reverse order in which they were distributed in the setup phase LOCAL EXCHANGE PHASE|,Non-data,10
| To obtain the output of the local phase, parties simply have to exchange the shares {s(k) i }, and the output of i = z(k) The local exchange phase the local phase equals(cid:76) is(k) happens in the following order: For i = 1 to n: (a) Party Pi broadcasts T (k) (b) [Abort] Let μ(k) i i i = (T (k) and ψ(k) , ψ(k) (ex(k) to all parties ) ) denote the message sent is not of the form (i, k,∗) or if by Pi ) (cid:54)= 1, then all parties terminate SigVerify(vk(k) the k-th local phase, do not participate in any further local ex- ecutions, and enter the master claim phase|,Non-data,10
| If either T (k) loc , T (k) i , ψ(k) i i i i i i i , ψ(k) After this, the local phase completes, and the parties have obtained the outputs Note that since signatures under sk(k) loc are unforgeable except with negligible probability (because each party only has an additive share of sk(k) loc ), it follows except with negligible proba- bility that a valid (T (k) ) pair sent by party Pi has to be the one generated by the local setup phase, and hence results in parties generating the correct output Following this, the parties can then proceed to the next local phase and so on Alternatively, if some party did not send a valid message, then the honest parties would simply terminate the local executions and enter the master claim phase|,Non-data,10
| An important note is that it may be the case that at this point the adversary already knows the output, therefore in these cases, we have to ensure that the honest party is compensated This will be handled in the master claim phase MASTER CLAIM PHASE From the discussion above, it is clear that parties may enter the master claim phase if there was an abort that happened during one of the earlier phases|,Non-data,10
| We will handle all these cases in our description of the master claim phase Let k denote the most recent completed execution, ie, ex(k) n = 1|,Non-data,10
| It is possible that the (k +1)-th execution was never started (either there was an abort or the parties unanimously agreed to terminate all local executions), or there was an abort in the middle which means sp(k+1) = 1 or even ex(k+1) = 0 must hold (otherwise (k + 1)-th execution was also completed) We describe the master claim phase for each Pi 1 For j = 1 to i − 1: At time τ lock = 1 for some i|,Non-data,10
| Note however that ex(k+1) n i i i,j if j = 1 or clmj−1 = 1 or (clmlock i,j ) clmunlock i(cid:48),j−1 = 1 for some i(cid:48): 1 i,1 (a) If j = 1 and i (cid:54)= 1, then claim Txlock i,1 using witness (TT0 = = ) if sp(k+1) NULL, k(cid:48), σ(cid:48)), where (k(cid:48), σ(cid:48)) = (k + 1, σ(k+1) 1, else (k(cid:48), σ(cid:48)) = (k, σ(k) i,1 ) (b) Else, let TT be the set of transcripts that were revealed dur- ing the claim of Txj−1,{Txunlock i(cid:48),j−1} Let ID denote the set of id’s that the transcripts in TT are consistent with, ie|,Non-data,10
|, for TT ∈ TT, there is an id ∈ ID, such that tv(id) j−1(TT) = 1 Let id(cid:48) denote the maximum value in ID and let TT(cid:48) de- note the corresponding transcript Claim Txlock i,j using witness TT(cid:48), id(cid:48), σ(id(cid:48)) i,j  2|,Non-data,10
| At time τi if (1) i = 1 or (2) clmi−1 = 1 or (3) clmunlock j,i−1 = 1 (clmi) where k(cid:48) is the 1 1 , σ(k(cid:48)) for some j or (4) clmlock j,i = 1 for some j: (a) If i = 1, then claim Tx1 using T (k(cid:48)) 1 = 1 j,i−1},{Txlock maximum value such that sp(k(cid:48)) (b) Else, let TT be the set of transcripts that were revealed during the claim of Txi−1,{Txunlock j,i } (Note that all these transcripts contain the first i − 1 secret shares) Let ID denote the set of id’s that the transcripts in TT are consistent with, i|,Non-data,10
|e, for TT ∈ TT, there is an id ∈ ID, such that tv(id) i−1(TT) = 1 Let id(cid:48) denote the maximum value in ID and let TT(cid:48) denote the corresponding transcript Claim Txi using witness TTi = (TT(cid:48)(cid:107)(T (id(cid:48)) ), id(cid:48))|,Non-data,10
| Save the value TTi to use in the next step (cid:107)σ(id(cid:48)) i i (a) Claim Txunlock j,i 3 For j = i + 1 to n: At time τ unlock (clmunlock ) using TTi (from the previous step), k(cid:48), σj,i j,i = 1: if clmlock j,i j,i where (∗, k(cid:48), σj,i) was the witness used to claim Txlock j,i  This concludes the description of the master claim phase|,Non-data,10
| We present a series of propositions which will be useful to prove that our protocol realizes F∗ MSFE Detailed proofs of the propositions are available in the full version In the following, we assume that k denotes the most recent completed execution, ie|,Non-data,10
|, ex(k) n = 1 PROPOSITION 2 Honest parties never lose money during the claim phase That is, for every honest Pi: 1|,Non-data,10
| If Txi−1 was claimed, then Pi will be able to claim Txi 2 If Txlock j,i was claimed by Pj for j > i, then Pi will be able to claim Txunlock  j,i 3|,Non-data,10
| If Txunlock i,j was claimed by Pj for j > i,then it must hold that Txlock i,j was claimed by Pi Proof sketch The main argument is that the local setup phase re- leases witnesses in a way such that if Txi−1 can be claimed then so can Txi This is because Step sp(k) i−1 occurs after Step sp(k) |,Non-data,10
| j,i will require witnesses for claiming Next, note that a claim of Txlock Txi−1 and the lock witness σj,i Now to claim Txunlock , Pi needs witnesses for claiming Txi and the lock witness σj,i Therefore, if Txlock using witnesses for j,i claiming Txi (this follows from the argument for the previous case) j,i  This and the lock witness σj,i revealed during the claim of Txlock completes the proof|,Non-data,10
| is claimed then Pi can claim Txunlock j,i j,i i PROPOSITION 3 There exists a unique k(cid:48) ≤ k + 1 such that for each i ∈ H (ie, Pi is honest), the only signatures under msk on messages of the form (i, k(cid:48)(cid:48),∗) that are revealed to adversary are for k(cid:48) = k(cid:48)(cid:48)|,Non-data,10
| Proof sketch The main argument is that the lexicographically first honest party, say Pi will reveal only one signature under msk on messages of the form (i,∗,∗) That is there will be a unique k(cid:48) for which Pi will release only one signature under msk on a mes- sage of the form (i, k(cid:48),∗) Denote this message-signature pair as (Ti, σi)|,Non-data,10
| Actually, (Ti, σi) = (T (k) ) where the latter is re- ceived in Step sp(k)  Clearly, (Ti, σi) is released when Pi claims Txi Let TTi be the witness used to claim Txi The master claim is designed in a way such that TTi along with a lock witness is used to claim Txunlock (see Steps (2b) and (3a))|,Non-data,10
| Now given that , σ(k) i i i j,i 426honest Pi releases signatures under msk only on Ti, it follows that any valid partial transcript TTi(cid:48) released by honest party Pi(cid:48) to claim Txi(cid:48) or Txunlock i(cid:48),j for j > i will necessarily have (Ti, σi) ∈ TTi(cid:48) Thus, for TTi(cid:48) to be a valid partial transcript, it must hold that (Ti(cid:48) , σi(cid:48) ) ∈ TTi(cid:48) must be such that Ti(cid:48) = (i(cid:48), k(cid:48),∗) This completes the proof or Txlock j,i(cid:48) PROPOSITION 4|,Non-data,10
| Suppose the local setup phase of the (k + 1)- th execution is successfully completed Then, either the (k + 1)-th execution was completed in the master claim phase, or all honest parties obtained a penalty More precisely, for every j ∈ [n], the following holds right after the j-th unlock phase: either TTj con- taining the transcript of the most recent execution up to the j-th se- cret share was revealed by Pj, or all honest parties have obtained a penalty already i,1 i,1 i,1 using the lock witness σ(k+1) Proof sketch|,Non-data,10
| Suppose the (k + 1)-th local setup phase was com- pleted This means that all honest parties obtained the local wit- nesses for the (k + 1)-th execution Thus, each honest party Pi will begin claiming Txlock on mes- , party P1 must produce TT1 sage (i, 1, k + 1) To claim Txunlock which contains main witness (1, k +1,∗), i|,Non-data,10
|e, corresponding to the (k + 1)-th execution It no such main witness is released, then it follows that honest parties claim penalty coins(q) from P1 (In this case, by Proposition 2 we have that honest parties don’t lose money elsewhere, so they end up with penalty coins(q)|,Non-data,10
|) The remainder of the proof follows by an induction argument on each Pj (with the base proved above for j = 1) for the statement exactly as in the proposition We note that for the general case, honest parties whose index is less than j would have claimed penalty coins(q) from the coins((j − 1)q) deposited in Txj−1, and the honest parties whose index is above j would have claimed penalty coins(q) from the lock deposits Txlock i,j  Note that the proposition implies that if the adver- sary gets the output of the (k + 1)-th execution, then either honest parties also obtain the output or they obtain a penalty PROPOSITION 5|,Non-data,10
| Suppose there was an abort in the (k + 1)-th local setup phase Then, the adversary obtains the output of the (k + 1)-th execution only if (1) the honest parties also obtained the output of (k + 1)-th execution, or (2) all honest parties obtained a penalty 1 1 Proof sketch Suppose sp(k+1) = 0|,Non-data,10
| Then we argue that no party gets the output of the (k +1)-th execution This is because no party obtains the first secret share of the output Then by Proposition 2 we have that honest parties don’t lose money, and this suffices for security On the other hand if sp(k+1) = 1, then it is possible that the adversary obtains the output of the (k + 1)-th execution|,Non-data,10
| Note that since an abort happened in the (k + 1)-th local setup phase, it follows that the honest parties would not have broadcasted any messages in the (k + 1)-th local exchange phase Thus, for the adversary to get output, it needs honest parties to reveal the main witnesses corresponding to the (k + 1)-th execution during the master claim phase By Proposition 3, it follows that the adver- sary must ensure that the first honest party, say Pi reveals the main witness corresponding to the (k + 1)-th execution (even though the adversary might have obtained this witness from the (k + 1)-th lo- cal exchange phase) Then, by an argument similar to the proof of Proposition 4 and starting the base case of the induction from in- dex i + 1 we have that either the (k + 1)-th local execution was completed or all honest parties obtained a penalty|,Non-data,10
| On the other hand, if the first honest party does not produce a main witness cor- responding to the (k + 1)-th execution, then the adversary will not obtain the output of the (k + 1)-th execution In this case, invoking Proposition 2 is sufficient to ensure security We defer the proof of the following theorem to the full version THEOREM 6|,Non-data,10
| Assume one-way functions exist There exists CR)-hybrid CRand its script complexity are MSFE in the (FOT,F∗ a protocol that SCC-realizes F∗ model st the number of calls to F∗ independent of the number of executions|,Non-data,10
| 41 The Reactive Case j, tv(cid:48) j−1(TT(cid:48) j}j∈[n] Here tv(cid:48) Due to space limitations, we only provide a short sketch of our protocol More details are avaiable in the full version|,Non-data,10
| We will follow the idea used in [15] to realize secure computation of re- active functionalities with penalties At a high level, the idea is to let the parties run an MPC protocol π(cid:48) for the underlying reac- tive functionality, and have the predicates in the F∗ CR transactions check the validity of the partial protocol transcript That is, let an n-party m-message protocol π(cid:48) be defined by pairs of algorithms {nmf(cid:48) j is the transcript validator function that takes a transcript of the protocol up to the j-th message, and out- puts 1 iff it is a valid transcript of π(cid:48) The algorithm nmf(cid:48) j is the next message function that takes a valid partial transcript TT(cid:48) j−1 (i|,Non-data,10
|e, tv(cid:48) j−1) = 1), party Pj mod n’s input xj mod n and its private randomness, say ωj mod n, and produces the j-th message μ(cid:48) j of the protocol signed under Pj mod n’s public key We define j−1(cid:107)μ(cid:48) the j-th partial transcript TT(cid:48) j Protocol transformation|,Non-data,10
| As in [15], we will transform a n-party j}j∈[m] into an equivalent n- m-message protocol π(cid:48) = {nmf(cid:48) message m-message protocol (cid:101)π = {(cid:103)nmf j,(cid:101)tvj}j∈[m] where the j = TT(cid:48) j, tv(cid:48) protocol messages contain layers of signatures That is, each party signs each message it sends, so messages contain layers of sig- natures Also, parties do not accept messages which do not have correct signatures Our construction|,Non-data,10
| Surprisingly, our construction for the reactive case is very similar to the protocol for the non-reactive case In fact, the master setup phase and the master deposit phase is identical That is, the sequence of deposits is the same as the locked ladder mechanism presented in Figure 5 As it turns out, the predicate descriptions are also identical as in the non-reactive case, of course with the important difference that now tv will also need to include the transcript validator of the MPC protocol realizing the reactive functionality|,Non-data,10
| Thus, our predicates are: j,i (TT, id, σ; mvk) = tv(id) φlock i−1(TT) SigVerify(mvk, (j, i, id), σ) φi(TT, id; mvk) = tv(id) (TT) i (cid:94) (cid:94) j,i φunlock (TT, id, σ; mvk) = tv(id) The transcript validator tv defined below, now depends on (cid:101)π = {(cid:103)nmf j,(cid:101)tvj}j∈[m]: SigVerify(mvk, (j, i, id), σ) (TT) i 1, id1, ψ1, T1, σ1)(cid:107)···(cid:107)(μ(cid:48) i, idi, ψi, Ti, σi) Let TT = (μ(cid:48) Then tv(id) i (TT) = 1 iff – (cid:101)tv(id) i – id1 = ··· = idi ≥ id – for all j ≤ i: Tj is a message of the form (j, idj,∗) and σj is a valid signature on Tj under msk (μ(cid:48) 1, id1, ψ1)(cid:107)···(cid:107)(μ(cid:48) to denote i, idi, ψi) = 1 of We use (μj, idj, ψj, Tj, σj) and (cid:102)TT to denote concatenation of three- tuples (μj, idj, ψj)|,Non-data,10
| tv,(cid:101)tv are the respective transcript validators concatenation five-tuples TT 427Specifically, of TT,(cid:102)TT We give details on the rest of the protocol At a the main new argument high level, all of the phases are very similar to the non-reactive case except for the use of additional witnesses (μ(cid:48) i, id, ψi) which essentially correspond to the actual MPC execution of the reactive functionality to prove security will be the unforgeability of the signature ψi for honest Pi on the message (μ(cid:48) i, id) and that in a witness TTj used by corrupt Pj, the id’s in TTj must be consistent with T (id) for honest Pi (the unique id under which honest parties release signatures under msk) which in turn forces μ(cid:48) i, id, ψi used as part of TTj to be exactly as the ones released by Pi|,Non-data,10
| As in the non-reactive case, we will be able to prove that the id corresponds to an incomplete local execution if there is one LOCAL SETUP PHASE In the k-th local setup phase parties submit the authenticated secret shares of the master signing key as input that delivers outputs in the fol- to an unfair ideal functionality F ord(cid:98)fk i lowing order: For i = n down to 1: (a) [Main witness signed under global keys] Party Pi obtains a on the message (sp(k) ) (b) [Lock witness signed under global key] For j = n down to along with a signature σ(k) ) signed under msk random value s(k) i = (i, k, s(k) T (k) i i i i i + 1: Pj obtains a signature σ(k) j,i on message (j, i, k) under msk|,Non-data,10
| (sp(k) j,i ) Observe that this phase is identical to the non-reactive case ex- i (k) j ,(cid:101)tv(k) are completely random cept now the values s(k) LOCAL EXCHANGE PHASE Parties start exchanging messages cor- responding to the local reactive MPC evaluating reactive function fk We denote this reactive MPC protocol as(cid:101)π(k) defined by a pair of algorithms {(cid:103)nmf above|,Non-data,10
 Party P1 starts by running (cid:103)nmf j }j∈[m] Note that we will be using the protocol obtained as a result of transformation procedure described to generate the first mes- sage μ(k) of the protocol π(k) realizing the reactive function fk Then party P2 upon receiving μ(k) to generate μ(k) and broadcasts this to all parties The protocol pro- ceeds like this till the very end when Pn sends the message μ(k) n ,Non-data,10
| More precisely, let μ(k) 0 = NULL, and let protocol(cid:101)π(k) from P1, invokes (cid:103)nmf (k) 1 (k) 2 1 1 2 be defined as {(cid:103)nmf 0 = (cid:102)TT(k) ,(cid:101)tv(k) (k) j j }j∈[n] For j ∈ [n]: j mod n and randomness ω(k) Upon receiving μ(k) with input x(k) (cid:101)tv(k) j−1) = 1 and if so, sets (cid:102)TT(k) j = (cid:103)nmf parties, and sets(cid:102)TT(k) j−1; (x(k) j−1(cid:107)μ(k) j−1 from party Pj−1 mod n, party Pj mod n j mod n checks if j−2(cid:107)μ(k) j−1, j mod n)) to all (ex(k) ) ((cid:102)TT(k) j =(cid:102)TT(k) j−1 = (cid:102)TT(k) j−1(μ(k) sends μ(k) j mod n, ω(k) (k) j  j j MASTER CLAIM PHASE Denote by k the most recent completed execution, i|,Non-data,10
|e, ex(k) n = 1 It is possible that the (k + 1)-th execu- tion was never started (either there was an abort or the parties unan- imously agreed to terminate all local executions), or there was an abort in the middle which means sp(k+1) = 1 for some i Note that party Pi needs to act only at time instances {τ lock }j>i We describe the master claim phase for Pi: i,j }i>j, τi,{τ unlock = 1 or even ex(k+1) j,i i i 1|,Non-data,10
| For j = 1 to i − 1: At time τ lock i,j clmunlock i(cid:48),j−1 = 1 for some i(cid:48): if j = 1 or clmj−1 = 1 or (clmlock i,j ) 1 i,1 (a) If j = 1 and i (cid:54)= 1, then claim Txlock i,1 using witness (TT0 = = ) if sp(k+1) NULL, k(cid:48), σ(cid:48)), where (k(cid:48), σ(cid:48)) = (k + 1, σ(k+1) 1, else (k(cid:48), σ(cid:48)) = (k, σ(k) i,1 ) (b) Else, let TT be the set of transcripts that were revealed dur- ing the claim of Txj−1,{Txunlock i(cid:48),j−1} Let ID denote the set of id’s that the transcripts in TT are consistent with, ie|,Non-data,10
|, for TT ∈ TT, there is an id ∈ ID, such that tv(id) j−1(TT) = 1 Let id(cid:48) denote the maximum value in ID and let TT(cid:48) de- note the corresponding transcript Claim Txlock i,j using witness TT(cid:48), id(cid:48), σ(id(cid:48)) i,j  1 1 1 1 1 1 1 1 |,Non-data,10
| (k(cid:48)) 1 , T (k(cid:48)) j,i−1},{Txlock on inputs x(k(cid:48)) for some j or (4) clmlock 2 At time τi if (1) i = 1 or (2) clmi−1 = 1 or (3) clmunlock j,i−1 = 1 (clmi) , σ(k(cid:48)) ) 1 = 1, and μ(k(cid:48)) , and ran- j,i = 1 for some j: (a) If i = 1, then claim Tx1 using (μ(k(cid:48)) is obtained by applying (cid:103)nmf , k(cid:48), ψ(k(cid:48)) where k(cid:48) is the maximum value such that sp(k(cid:48)) ψ(k(cid:48)) domness ω(k(cid:48)) (b) Else, let TT be the set of transcripts that were revealed during j,i } (Note that all these the claim of Txi−1,{Txunlock transcripts contain the first i − 1 secret shares) Let ID denote the set of id’s that the transcripts in TT are consistent with, i|,Non-data,10
|e, for TT ∈ TT, there is an id ∈ ID, such that tv(id) i−1(TT(cid:48)) = 1 Let id(cid:48) denote the maximum value in ID and let TT(cid:48) denote the corresponding transcript i|,Non-data,10
| If ex(id(cid:48)) then set TTi−1 = (μ1, id(cid:48), ψ1, T1, σ1)(cid:107) ···(cid:107)(μi−1, id(cid:48), ψi−1, Ti−1, σi−1) where the messages μ1,    , μi−1 and the corresponding signatures ψ1, |,Non-data,10
|   , ψi−1 are obtained from the id(cid:48)-th local exchange phase (ie|,Non-data,10
|, from a transcript before) and the values T1,    , Ti−1 and the corresponding signatures σ1, |,Non-data,10
|   , σi−1 are ob- tained from TT(cid:48) Let (μ(id(cid:48)) ) be the message that Pi sent during the id(cid:48)-th local exchange phase|,Non-data,10
| Set , id(cid:48), ψ(id(cid:48)) TTi = TTi−1(cid:107)(μ(id(cid:48)) plying (cid:103)nmf i ii Else: let (μ(id(cid:48)) ) be the message obtained by ap- i (id(cid:48)) that is implicit in TT(cid:48), us- i ing input x(id(cid:48)) (ie, exactly the in- puts/random tape it would have used in the id(cid:48)-th local execu- , T (id(cid:48)) tion)|,Non-data,10
| Set TTi = TT(cid:48)(cid:107)(μ(id(cid:48)) Claim Txi using witness TTi and save the value TTi to use in the next step and randomness ω(id(cid:48)) , id(cid:48), ψ(id(cid:48)) on transcript (cid:102)TT , id(cid:48), ψ(id(cid:48)) , T (id(cid:48)) , id(cid:48), ψ(id(cid:48)) , σ(id(cid:48)) , σ(id(cid:48)) = 1, ) ) (cid:48) i i i i i i i i i i i i i 3|,Non-data,10
| For j = i + 1 to n: At time τ unlock j,i if clmlock (clmunlock ) using TTi (from the previous step), k(cid:48), σj,i j,i = 1: j,i (a) Claim Txunlock j,i where (∗, k(cid:48), σj,i) was the witness used to claim Txlock j,i  This concludes the description of the master claim phase and of the protocol Please see the full version for the formal description and the security proof 5|,Non-data,10
| CONCLUSIONS We made a distinction between “on-chain” complexity (verifi- cation complexity imposed on miners) and “off-chain” complex- ity (that is borne by the protocol participants) In this paper we showed how to amortize the “on-chain”cost of secure computation 428with penalties Several important questions remain Could we re- duce the “on-chain” complexity of a single execution? Alterna- tively, can we derive the amortization result for the reactive case using only O(nr) initial deposits? Also, can we improve the prac- ticality of our schemes by possibly removing the need to do the signature generation/verification part inside the MPC? Acknowledgements Research of the first author is supported in part by NSF Grants CNS-1350619 and CNS-1414119, in part by the Defense Advanced Research Projects Agency (DARPA) and the U|,Non-data,10
|S Army Research Office under contracts W911NF-15-C-0226, and an MIT Transla- tional Fellowship Research of the second author is supported by funding from the European Community’s Seventh Framework Pro- gramme (FP7/2007-2013) under grant agreement number 240258 and NSF grant 1561209 6|,Non-data,10
|ABSTRACT Authenticated encryption (AE) schemes are symmetric-key encryption schemes ensuring strong notions of confiden- tiality and integrity Although various AE schemes are known, there remains significant interest in developing schemes that are more efficient, meet even stronger secu- rity notions (eg, misuse-resistance), or satisfy certain non- cryptographic properties (e|,Non-data,13
|g, being patent-free) We present an automated approach for analyzing and syn- thesizing blockcipher-based AE schemes, significantly ex- tending prior work by Malozemoff et al (CSF 2014) who syn- thesize encryption schemes satisfying confidentiality only|,Non-data,13
| Our main insight is to restrict attention to a certain class of schemes that is expressive enough to capture several known constructions yet also admits automated reasoning about security We use our approach to generate thousands of AE schemes with provable security guarantees, both known (eg, variants of OCB and CCM) and new|,Non-data,13
| Implementing two of these new schemes, we find their performance com- petitive with state-of-the-art AE schemes 1 INTRODUCTION Historically, symmetric-key encryption schemes were de- signed only to ensure confidentiality With the realization that practitioners were often (implicitly) assuming that such schemes also provided some form of integrity, however, re- searchers began explicit consideration and analysis of en- cryption schemes additionally satisfying that property [16, 7]|,Non-data,13
| Since then, a tremendous amount of research has focused on the design of authenticated encryption (AE) schemes en- suring both confidentiality and integrity While a generic construction of an AE scheme based on any CPA-secure encryption scheme and message authenti- cation code is possible [7], more efficient AE schemes can be devised One example is OCB [25, 23, 17], which is on- line (ie|,Non-data,13
|, requires only a single pass over the data), prov- ably secure, and very fast Unfortunately, due to patent restrictions, the scheme never gained widespread use Other Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page Copyrights for components of this work owned by others than the author(s) must be honored|,Non-data,13
| Abstracting with credit is permitted To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from Permissions@acmorg|,Non-data,13
| CCS’15, October 12–16, 2015, Denver, CO, USA Copyright is held by the owner/author(s) Publication rights licensed to ACM ACM 978-1-4503-3832-5/15/10 |,Non-data,13
$1500,Non-data,13
 DOI: http://dxdoiorg/101145/2810103,Non-data,13
|2813636 well-known AE schemes include CCM [10] and GCM [20]; however, these schemes are slower than OCB [17] and have other disadvantages as well1 Overall, the problem of de- signing AE schemes is still of interest, as evidenced by the ongoing CAESAR competition [9] In designing efficient AE schemes, one might fail to realize opportunities to improve efficiency|,Non-data,13
| For example, OCB was first introduced in 2001 [25] and its authors have been active in maintaining and optimizing the scheme, releasing OCB2 in 2004 [23] and OCB3 in 2011 [17] However, recently, Mine- matsu [21] showed that a simple change to OCB’s design al- lows one to use only the forward direction of the underlying blockcipher, saving chip area in hardware realizations In this work, we propose an automated approach for an- alyzing and synthesizing AE schemes Our approach builds on and extends the work of Malozemoff et al|,Non-data,13
| [19], who explored a similar goal but limited to encryption schemes achieving confidentiality only At a high level, as in their work, we view an encryption scheme as being defined by a directed acyclic graph in which each node corresponds to an instruction (eg, XORing two values) and is associated with an intermediate n-bit value|,Non-data,13
| The graph defines how individual message blocks are processed; messages of arbi- trary length are encrypted by iterating the computation de- fined by this graph over all the blocks of the message (We actually consider processing two message blocks at a time, as this allows us to capture more AE schemes within our framework) We develop a type system for the nodes of such graphs, and define constraints on how nodes can be typed based on their parents’ types We then show that any “well-typed” graph defines a secure AE scheme|,Non-data,13
| This allows us to automatically analyze a given scheme by check- ing whether the graph defining the scheme can be properly typed Building on this, we can synthesize schemes by enu- merating over valid graphs and analyzing each one to see if it is secure Through a generic transformation, our work can handle messages of arbitrary length, whereas the prior work of Malozemoff et al is limited to messages whose length is a multiple of the block length|,Non-data,13
| Although the high-level structure of our approach is sim- ilar to that of Malozemoff et al, the technical details differ greatly due to the added challenge of handling integrity (In- deed, this was left as an explicit open question in their work) We were unable to directly extend their work to deal with integrity; instead, we modify their approach and consider 1For example, GCM is fairly complex and has a problematic security proof [14], whereas CCM is not online and cannot pre-process associated data|,Non-data,13
| 84a restricted class of encryption schemes for which an auto- mated analysis of integrity is tractable Specifically, we focus on schemes constructed using tweakable blockciphers [18] in a particular way2 Several existing AE schemes satisfy our requirements, indicating that our framework is not overly restrictive The abstraction from using a tweakable blockci- pher also significantly reduces the size of the graphs that we have to enumerate, making the synthesis feasible|,Non-data,13
| Despite this simplification, our graphs are a lot more complex than those that Malozemoff et al consider For example, in the prior work, it is relatively easy to tell if a scheme is decrypt- able, as there is only one path from a node representing a plaintext block to a node representing a ciphertext block In our case, this no longer holds—the graphs of schemes like OTR [21] have multiple paths between such pairs of nodes, and we have to find a nontrivial algorithm to explicitly con- struct a graph of the encryption scheme, given a graph of the decryption scheme|,Non-data,13
| Using our approach, we are able to synthesize thousands of secure AE schemes, hundreds of which are “optimal” in the sense that they use only one tweakable blockcipher call per block, on par with OCB These schemes are provably secure, as verified by our analysis tool, with concrete se- curity bounds In contrast, the prior work of Malozemoff et al [19] only gives asymptotic analyses|,Non-data,13
| We also employ a simple algorithm to find fully parallelizable constructions among the “optimal” schemes, and discover seventeen such schemes, five of which use the same number of instructions as OCB We implement two of these schemes and find that the running times are comparable to those of OCB Thus, these schemes may be of interest to practitioners looking for efficient, simple, and patent-free AE schemes Finally, in the full version [13] of this work, we devise a method for automatically finding attacks on schemes that our approach cannot claim secure, and we find that most of those schemes indeed are susceptible to concrete attacks|,Non-data,13
| Related work Recently there has been a growing interest in applying automated techniques to the analysis and de- sign of cryptographic primitives In the public-key setting, Barthe et al [4] introduced an approach applicable to RSA- based encryption schemes|,Non-data,13
| More recently, Tiwari et al [26] developed a unified technique for synthesizing both RSA- based encryption schemes and modes of operation, among other cryptographic primitives Other work has looked at automated analysis of assumptions in generic groups [5] with applications to automated synthesis of signature schemes having certain properties [5, 6] Finally, Akinyele et al|,Non-data,13
| [1, 2] developed tools for analyzing signature and encryption schemes to determine when (and how) known secure trans- formations can be applied 2 PRELIMINARIES Notation Let Z denote the set of all integers, and let N denote the set of positive integers|,Non-data,13
| Let {0, 1}∗ denote the set of all binary strings, including the empty string For a string M , let ||M|| denote the length of M  For M ∈ {0, 1}∗ and 1 ≤ i ≤ j ≤ ||M||, let M [i] denote the i-th bit of M , and M [i, j] the substring of M from the ith to the jth bit, 2Roughly, a tweakable blockcipher accepts a “tweak” in ad- dition to a key and a regular input; for a fixed key, different tweaks should produce “independent-looking” permutations See the following section for a formal definition|,Non-data,13
| inclusive For two strings X and Y , we write XY or X (cid:107) Y to denote the concatenation of X and Y  We write x ←$ S to denote uniform sampling of x from finite set S For finite sets S1, S2, and random variables X, Y ∈ S1, Z ∈ S2, define (cid:107)X − Y || Z(cid:107), the statistical distance between X and Y given Z, as Pr[Z = z]·(cid:12)(cid:12)(cid:12) Pr[X = v || Z = z]−Pr[Y = v || Z = z] (cid:88) (cid:12)(cid:12)(cid:12)|,Non-data,13
| 1 2 v∈S1,z∈S2 Games We use the code-based, game-playing framework of Bellare and Rogaway [8] Due to lack of space, we assume the reader is familiar with this framework Tweakable blockciphers [18]|,Non-data,13
| Let n ∈ N A tweak- able blockcipher on n-bit strings with tweak space T and key space K is a map E : K × T × {0, 1}n → {0, 1}n such that EK (T,·) is a permutation on {0, 1}n for any K ∈ K and T ∈ T  Let E−1 denote the inverse of E, meaning K (T, EK (T, x)) = x for K ∈ K, T ∈ T , and x ∈ {0, 1}n −1 E For brevity we sometimes write ET K (x) for EK (T, x)|,Non-data,13
| De- fine the strong tweakable-PRP advantage of an adversary A against E as (cid:12)(cid:12)(cid:12) Pr[K ←$ K : AEK (·,·),E −1 K (·,·) ⇒ 1] ±(cid:103)prp E Adv (A) = (cid:12)(cid:12)(cid:12), − Pr[π ←$ Perm(T , n) : Aπ(·,·),π−1(·,·) ⇒ 1] where Perm(T , n) is the set of all T -indexed families of per- mutations on {0, 1}n (Ie, Perm(T , n) is the set of all functions π : T × {0, 1}n → {0, 1}n with the property that for each T ∈ T , the reduced function π(T,·) is a permuta- tion on {0, 1}n|,Non-data,13
|) If the adversary is prohibited from making write Adv(cid:103)prp queries to the second oracle, we drop the word “strong” and E (A) instead Authenticated encryption Rather than view encryp- tion schemes as being randomized or stateful, we follow Ro- gaway [24] in viewing them as deterministic transformations that take as input a message along with some associated data (which need not be kept secret) as well as a user-supplied nonce Security is then required to hold as long as the same nonce is never used twice|,Non-data,13
| Formally, an authenticated encryption (AE) scheme [7, 16, 22, 24] is a tuple Π = (K,E,D) with key space K, nonce space N , associated data space A, message space M, and tag length τ ∈ N Both algorithms E and D are deter- ministic The encryption algorithm E maps an input tuple (K, N, A, M ) ∈ K×N ×A×M to a ciphertext C ∈ {0, 1}∗ Decryption D reverses encryption, mapping an input tuple (K, N, A, C) ∈ K × N × A × {0, 1}∗ to either a message M ∈ M or a distinguished error symbol ⊥|,Non-data,13
| The correctness requirement demands that DN,A K (M )) = M for every (K, N, A, M ) ∈ K × N × A × M We define the privacy advantage of an adversary A against Π (A) = (cid:12)(cid:12)(cid:12)Pr[K ←$ K : AEK (·,·,·) ⇒ 1] − Pr[A$(·,·,·) ⇒ 1] an AE scheme Π as Advpriv K (E N,A (cid:12)(cid:12)(cid:12) , where $(·,·,·) is an oracle that, on any input (N, A, M ), outputs a fresh, uniform (||M|| + τ )-bit answer We require here that the adversary never uses the same nonce twice as input to its oracle Informally, a scheme satisfies privacy if the privacy advantage of any efficient adversary is small|,Non-data,13
| 85Nonces used by the honest party during encryption need only be unique3, not uniform For authenticity, the adversary is again given access to an encryption oracle EK (·,·,·), and as before must not use the same nonce twice We say that A outputs a forgery if it outputs (N, A, C) such that DK (N, A, C) (cid:54)= ⊥ and C was not the result of a prior oracle query EK (N, A, M ) for some message M  We define the authenticity advantage of A Π (A) = Pr[K ←$ K : AEK (·,·,·) outputs a forgery]|,Non-data,13
| as Advauth Informally, a scheme satisfies authenticity if the authenticity advantage of any efficient adversary is small 3 AUTOMATED SECURITY ANALYSIS We now describe our approach to the automated analy- sis of AE schemes constructed from tweakable blockciphers following a particular template (cf Section 3|,Non-data,13
|1) Although this template does not capture all known AE schemes, it is expressive enough to include simplified variants of, eg, OCB [23], XCBC [12], COPA [3], OTR [21], and CCM [10]|,Non-data,13
|4 As discussed in the Introduction, we view an encryption scheme as being defined by a directed acyclic graph in which each node is associated with an instruction and carries an n-bit intermediate value In Section 32 we describe a type system for the nodes of such graphs, and show how to use these types for reasoning about properties of the intermedi- ate values that those nodes carry Then, in Section 3|,Non-data,13
|3, we show how this reasoning enables us to automatically verify whether an AE scheme, given by its graph representation, satisfies privacy and authenticity 31 A Template for AE Schemes Fix associated data space A, and let N = {0, 1}n Let T = N × A × Z and let E : K × T × {0, 1}n → {0, 1}n be a tweakable blockcipher|,Non-data,13
|We consider AE schemes Π[E] = (K,E,D) that use E as an oracle The schemes we consider have message space5 M = ({0, 1}2n)∗ and are built from algorithms (Enc, Dec, Tag) having the following form: • EncEK takes as input tweak T = (N, A, v) ∈ T , an ini- tial state X ∈ {0, 1}2n, and a (double-length) mes- sage block M ∈ {0, 1}2n It outputs a (double-length) ciphertext block C ∈ {0, 1}2n and final state Y ∈ {0, 1}2n This algorithm makes a fixed number of queries to EK , denoted by Cost(Π), and we require that the tweak in the ith such query is (N, A, v +i−1)|,Non-data,13
| 3The requirement that nonces be unique is necessary, since repeating (N, A, M ) will repeat the corresponding cipher- text For real schemes such as OCB, reusing a nonce is dev- astating, damaging the privacy and authenticity of not just past queries, but also future ones It is the responsibility of the implementation to ensure that nonces are unique 4For efficiency, the real-world variants are often built di- rectly from a blockcipher instead of a tweakable one, and em- ploy a scheme-specific way to handle fragmentary data|,Non-data,13
| The real-world CCM is not online due to its treatment of frag- mentary data, whereas our variant is online OCB is built from a tweakable blockcipher, but the tweaks are (N, i) in- stead of (N, A, i) To handle associated data, OCB employs an XOR-universal hash (based on a tweakable blockcipher), and XORs the hash image to the tag 5Messages of arbitrary length can be handled by naive padding in the usual way|,Non-data,13
| In the full version [13] we de- scribe a more efficient approach for handling messages of arbitrary length EK (N, A, M ) X := 02n; v := 1; M1 · · · M2m := M // ||Mi|| = n for i = 1 to m do // ||Cj|| = n T := (N, A, v) (Y, C2i−1C2i) := EncEK (T, X, M2i−1M2i) v := v + Cost(Π); X := Y T := (N, A, 1 − v); V := TagEK (T, X) return C1 · · · C2m (cid:107) V [1, τ ] DK (N, A, C) if ||C|| (cid:54)≡ τ (mod 2n) then return ⊥ C1 · · · C2m (cid:107) tag := C // ||Ci|| = n and ||tag|| = τ X := 02n; v := 1 for i = 1 to m do T := (N, A, v) (Y, M2i−1M2i) := DecEK ,E v := v + Cost(Π); X := Y T := (N, A, 1 − v); V := TagEK (T, X) if tag (cid:54)= V [1, τ ] then return ⊥ else return M1 · · · M2m −1 K (T, X, C2i−1C2i) Figure 31: Code of an AE scheme Π = (K,E,D) following our template The scheme is based on a tweakable blockcipher E and a triple of deterministic algorithms (Enc, Dec, Tag)|,Non-data,13
| • DecEK ,E −1 K “inverts” algorithm Enc in the following sense: if EncEK (T, X, M ) = (Y, C) then it holds that DecEK ,E X ∈ {0, 1}2n, and produces a tag V ∈ {0, 1}n makes a single query to EK using tweak T  • TagEK takes as input tweak T ∈ T and initial state It −1 K (T, X, C) = (Y, M ) The encryption/decryption algorithms (E,D) of Π are then defined as in Figure 3|,Non-data,13
|1, where we require τ ≤ n Roughly, to encrypt a message M = M1M2 ··· M2m using nonce N and associated data A, set the initial state X = 02n and set T = (N, A, 1) Then, iteratively process two message blocks at a time using Enc, each time updating the initial state and outputting the next two ciphertext blocks After processing the entire message, Tag is used to compute a tag based on the final state output by Enc and a designated tweak that depends on the message length; the (truncated) tag is appended to the ciphertext|,Non-data,13
| Graph representation As in the work of Malozemoff et al [19], we represent algorithms Enc, Dec, and Tag as directed acyclic graphs, where each node is associated with an instruction and carries an n-bit value The n-bit value on each node is determined by applying the instruction at that node to the values at the parent nodes|,Non-data,13
