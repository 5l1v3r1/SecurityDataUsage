 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| Instead, we compute each element Ai,j, Bi,j, Ci,j as a chameleon hash value of its children, ie, the element Ai,j is computed as Ai,j ← Ch(Ai+1,s, Bi+1,s, Ci+1,s; ri,j) for some integer s So far, we have described an n-ary Merkle tree whose nodes are computed via a chameleon hash function|,Non-data,56
| Now we explain how to handle an exponential number of nodes without computing all of them The basic idea is to exploit the collision property of the chameleon hash Instead of computing the node Ai,j as Ai,j ← function Ch(Ai+1,s, Bi+1,s, Ci+1,s; ri,j), we replace all elements with ie|,Non-data,56
|, Ai,j ← Ch(xi,j; ri,j) These ele- dummy elements, ments are derived via a pseudo-random function F, ie, xi,j ← F(i, j), and can be computed on the fly|,Non-data,56
| That is, to compute Ai,j, no other tree nodes are necessary Since all elements are computed deterministically, it means that this modification results in an exponential number of nodes without any connection to each other We re-establish this connection using the trapdoor of the chameleon hash function whenever we assert a new element We illustrate the assertion operation with Fig|,Non-data,56
| 1 Assume that we would like to assert a statement in the context (as- sociated with) C3,6 To do so, we need to compute the the elements A3,6, B3,6, A2,2, B2,2, A1,1, C1,1 and the correspond- ing randomness for each node This information will suffice for the verifier to reconstruct the assertion path from C3,6 to the root as in an ordinary Merkle tree|,Non-data,56
| To compute the aforementioned elements, we compute all dummy elements xA3,6, xB2,2, xC1,1 and we also derive the randomness for each node via F Now, to assert the statement st in the context C3,6, we compute the first collision in C3,6 ← Ch(xC3,6; rC3,6) We use the trapdoor of the chameleon hash to find a matching randomness r0 such that Ch(xC3,6; rC3,6) = C3,6 = Ch(S(st); r0), where S computes a digest of the statement st Now, to assert (A3,6, B3,6, C3,6) with respect to the parent C2,2, we need to find a second collision in C2,2, which is computed as C2,2 ← Ch(xC2,2; rC2,2)|,Non-data,56
| Again, we use the trapdoor to compute some randomness r00 such that Ch(xC2,2; rC2,2) = C2,2 = Ch(h; r00) where h = (A3,6, B3,6, C3,6) We repeat this procedure up to the root Observe that independent of the statements asserted in the contexts A3,6, B3,6, and C3,6, the value h will always be the same because the first collision is always computed in the leaf This concludes the description of the underlying asserted data structure|,Non-data,56
| Now, we will explain how to extract the secret key in the case that the sender asserts two different statements in the same context Let us assume that the sender asserted two statements st0, st1 in the context associated with C3,6 In the simplest case, there exist two pairs (st0, r0), (st1, r1) such that Ch(S(st0); r0) = C3,6 = Ch(S(st1); r1) (This is like in the “first approach”|,Non-data,56
|) In a more complicated case, we could have Ch(S(st0); r0) = C3,6 6= C0 3,6 = Ch(S(st1); r1), because the attacker could have used a collision in C2,2 to associate its rightmost child 3,6 6= C3,6 But then, this collision can be with a value C0 used to extract the trapdoor Generally speaking, we will find a collision somewhere on the path from the leaf to the root Observe that this always terminates for valid assertions because a digest of the root itself is fixed in the public key|,Non-data,56
| 52 Construction We present the full description of our scheme Let ‘ and n be arbitrary positive integers defining the height of a tree and its branching factor Let Fk be a pseudorandom func- tion, and H be a collision-resistant hash function|,Non-data,56
| Further- more, let S and L be two hash functions modeled as random oracles L maps arbitrary bitstrings to {1,   |,Non-data,56
| , n‘}3 Let CH = (GenCh, Ch, Col, ExtractCsk) be a uniform, collision- resistant, and extractable chameleon hash function The accountable assertion scheme is defined as follows: Key Generation: The key generation algorithm chooses a key for the pseudo-random function k ← {0, 1}λ, and a key pair (cpk, csk) ← GenCh(1λ) for the chameleon hash function, Let p be an unique identifier for the position of the root node The algorithm computes the root node as i ← Fk(p, i, 0), r1 i ) for x1 3Since L is only required for a low failure probability of the assertion algorithm but not for security, the size of the output space of L may or may not depend on the security parameter|,Non-data,56
| i ← Fk(p, i, 1), and y1 i = Ch(x1 i ; r1 224i ∈ {1,    , n} and sets z = H(y1 n)|,Non-data,56
| Finally, it sets 1,    , y1 apk := (cpk, z), ask := csk, and auxsk := k|,Non-data,56
| Assertion: The stateful assertion algorithm maintains an initially empty set L of used leaf positions To assert a statement st in a context ct, the algorithm verifies that L(ct) /∈ L and fails otherwise4 Then, it adds L(ct) to L and computes the assertion path (Y‘, a‘, Y‘−1, a‘−1,  |,Non-data,56
|  , Y1, a1) from a leaf Y‘ to the root Y1 Each node Yj = (yj n) 1,  |,Non-data,56
|  , yj stores n entries and the position aj ∈ {1,   |,Non-data,56
| , n} defines the position in the node Y‘ is the leaf that stores the entry with the number L(ct), counted across all leaves from left to right, and a‘ is the position of this entry within Y‘ In the := Fk(pj, i, 1), where following, let xj pj is a unique identifier of the position of the node Yj Compute Y‘: Assert the statement st with respect to Y‘ by computing r0‘ a‘ , S(st))|,Non-data,56
| Observe that Ch(x‘ ) = y‘ i; r‘ i) for i ∈ {1,    , n} \ {a‘}|,Non-data,56
| The leaf Y‘ stores the entries n) and let further f‘ = (y‘1,    , y‘ (y‘1, |,Non-data,56
|   , y‘ n) Let z‘ ← H(y‘1, |,Non-data,56
|   , y‘ a‘−1, y‘ Compute the remaining entries in node Y‘ as y‘ a‘ ← Col(csk, x‘ = Ch(S(st); r0‘ := Fk(pj, i, 0) and rj Compute the nodes up to the root for h = ‘ − 1,  |,Non-data,56
|  , 1: • Assert zh+1 with respect to Yh by computing r0h ; rh a‘ , zh+1) Observe that Ch(xh i = Ch(x‘ a‘+1,  |,Non-data,56
|  , y‘ a‘ ← ) = a‘ , r‘ ) a‘ a‘ , rh n) ; r‘ a‘ a‘ a‘ a‘ a‘ i i Col(csk, xh yh a‘ = Ch(zh+1; r0h a‘ )|,Non-data,56
| • Compute the remaining entries in this node Yh as yh i = ) for i ∈ {1,    , n}\{a‘}|,Non-data,56
| The node Yh stores n) and i i ; rp Ch(xp the elements (yh1 ,    , yh fh = (yh1 , |,Non-data,56
|   , yh a‘−1, yh The assertion is τ := (r0‘ n) Let zh ← H(yh1 , |,Non-data,56
|   , yh n) a‘+1, |,Non-data,56
|   , yh a‘ , f‘, a‘,  |,Non-data,56
|  , r01 1, f1, a1) n) = z 1, |,Non-data,56
|   , y1 a‘ , f‘, a‘,  |,Non-data,56
|  , r01 Verification: The verification algorithm verifies that cpk is a valid chameleon hash public key and outputs 0 otherwise It parses τ as (r0‘ 1, f1, a1), and checks the validity of a statement st in a context ct by reconstructing the nodes (Y‘, Y‘−1,  |,Non-data,56
|  , Y1) in a bottom-up order, from the leaf Y‘ to the root Y1 The verification algorithm outputs 1 if and only if H(y1 Extraction: The extraction algorithm takes as input (apk, ct, st0, st1, τ0, τ1) It computes like the verification algorithm the assertion paths for both st0 and st1 from the bottom up to the root until a position in the tree is found where the two assertion paths form a collision in the chameleon hash function, i|,Non-data,56
|e, a position in the tree where values x0, r0 are used in the assertion path of st0 and values x1, r1 are used in the assertion path of st1 such that Ch(x0; r0) = Ch(x1; r1) Then the extraction algorithm outputs the secret key ask = csk ← ExtractCsk(x0, r0, x1, r1) computed via the extraction algorithm of the chameleon hash function If no such position is found, the extraction algorithm fails|,Non-data,56
 53 Analysis We establish the security of the construction Theorem 1 The construction is extractable,Non-data,56
| Proof Assume for contradiction that there is a ppt attacker A that breaks extractability That is, with non- negligible probability, A outputs a public key apk and two as- 4The set L can be implemented efficiently by a Bloom filter [9, 46], at the cost of a slightly increased failure rate A Bloom filter is a space-efficient probabilistic data structure|,Non-data,56
| It may indicate x ∈ L wrongly with small probability but it never indicates x /∈ L wrongly sertions τ0, τ1 that are valid for different statements st0 6= st1 in the same context ct, but the extraction algorithm fails to extract the secret key ask given these values By construction of the verification algorithm, the assertion paths of τ0 and τ1 belong to two Merkle trees T0 and T1 such that i) the roots of T0 and T1 are identical, and ii) the two leaves of T0 and T1 that belong to the context ct have different inputs st0 6= st1 for the chameleon hash function; note that these leaves are at the same position in T0 and T1 Thus there is a node position on the assertion paths output by A such that the nodes of T0 and T1 at this position form a collision in either the chameleon hash function or the collision-resistant hash function H|,Non-data,56
| By construction of the extraction algorithm, it would not fail to output ask if this collision was a collision in the chameleon hash function Consequently, it is a collision in the hash function H, and the existence of A contradicts the collision-resistance of H Theorem 2 The construction is secret in the random oracle model|,Non-data,56
| Proof sketch The proof proceeds in two steps First, we prove a non-adaptive (or selective) secrecy notion where the attacker outputs all queries to the assertion oracle in the beginning Only afterwards, the attacker obtains the public key and the responses from the oracle, and the attacker’s goal is to output the secret key|,Non-data,56
| In this non-adaptive case, the reduction can answer all assertion queries without knowing the trapdoor by computing the tree from the bottom up Whenever the attacker wins, the reduction can easily break the collision-resistance of the chameleon hash function In the second step, we reduce adaptive security to non- adaptive security The reduction first outputs randomly chosen statements in randomly chosen contexts as its non- adaptive queries, and obtains a public key and the resulting assertions|,Non-data,56
| Whenever the attacker queries the assertion oracle, the reduction programs the random oracles such that one of the non-adaptively obtained assertions is a valid response of the assertion oracle A complete proof appears in the full version [34] Failure Probability of the Assertion Algorithm The construction allows a context space of {0, 1}∗|,Non-data,56
| The probabil- ity that the assertion algorithm fails when given q queries is the probability that there are two contexts ct0 6= ct1 in the queries with L(ct0) = L(ct1) Under the assumption that L : {0, 1}∗ → {1,   |,Non-data,56
| , n‘} has uniform outputs, its (birthday) collision probability is below (q + 1)2/(2 · (n‘ + 1 − q)) [37] Complete Accountable Assertions A variant of the construction yields a complete accountable assertion scheme Suppose n‘ is large enough (with respect to the security pa- rameter λ) to ensure that L is collision-resistant, e|,Non-data,56
|g, ‘ = 2λ Then, we can drop the check for L(ct) /∈ L, which fails now only with negligible probability This eliminates the state from the authentication algorithm and makes the scheme complete, i|,Non-data,56
|e, the assertion algorithm always succeeds 54 Instantiation and Implementation We have implemented the construction given in the pre- vious section|,Non-data,56
| In this section, we describe the details of the implementation, and we evaluate the practicality of the construction, as it will dominate the computation as well as communication costs of non-equivocation contracts Our 225implementation is available online [28] It makes use of the libsecp256k1 library [49], which has evolved from the standard Bitcoin client Chameleon Hash Function|,Non-data,56
| We use a chameleon hash function proposed by Krawczyk and Rabin [30], which is secure if the discrete logarithms assumption holds in the un- derlying group In the elliptic curve setting, the chameleon hash function CH = (GenCh, Ch, Col) with extraction algo- rithm ExtractCsk is defined as follows GenCh(1λ): The key generation algorithm chooses a secure elliptic curve and a base point g of prime order q where q is at least 2λ bits long It chooses a random integer α ∈ Z∗ q and returns (csk, cpk) = (α, X) with X = gα|,Non-data,56
| Ch(x; r): The input of the hash algorithm is a public key cpk = X and a message x ∈ Z∗ q It picks a random value r ∈ Z∗ q and outputs gxX r Col(csk, x0, r0, x1): The collision finding algorithm returns r1 = α−1(x0 − x1) + r0 (mod q) ExtractCsk(cpk, x0, r0, x1, x1): If the inputs are a collision, we have gx0+αr0 = gx1+αr1|,Non-data,56
| The extraction algorithm returns α = (x0 − x1)/(r1 − r0) (mod q) This chameleon hash function has unique keys A public key can be validated by verifying that it is an elliptic curve point in the correct-prime order group To be compatible with Bitcoin keys, we work on the prime-order elliptic curve secp256k1 [15] at a security level of 128 bits|,Non-data,56
| Cryptographic Algorithms We use HMAC-SHA256 to in- stantiate the pseudorandom function F, SHA256 to instantiate the collision-resistant hash function H, and HMAC-SHA256 with fixed keys to instantiate the random oracles L and S Other Parameters We have chosen ‘ = 64 as the height and n = 2 as the branching factor of the tree, implying that the failure probability of the assertion algorithm is below 2−37 for q = 10000 queries|,Non-data,56
| Computation Cost On a 210GHz (Intel Core i7-4600U) machine with DDR3-1600 RAM, a chameleon hash evaluation takes 66 μs with a secret key, and the computation time increases to 85 μs if only a public key is available Let ‘ denote the height of the authentication tree|,Non-data,56
| The assertion algorithm of our accountable assertion scheme in Section 52 requires n‘ chameleon hash function evaluations using secret keys, while the verification algorithm of our accountable assertion scheme scheme requires ‘ chameleon hash function evaluations using public keys In our test environment, the assertion algorithm takes around 9 ms, while the verification algorithm takes approxi- mately 4 ms to complete Storage Costs|,Non-data,56
| A chameleon hash value is a point on the elliptic curve secp256k1 and thus requires 257 bits < 33 bytes in compressed form A randomness input of the chameleon hash function is an integer in the underlying field of the curve, and requires 32 bytes An assertion is a sequence of ‘ = 64 chameleon hash values and chameleon hash randomness inputs, and thus requires 64 · (33 bytes + 32 bytes) = 4160 bytes To store q = 10000 assertions, we need about 42 MB|,Non-data,56
| 6 NON-EQUIVOCATION CONTRACTS Putting everything together, we explain how to realize non- equivocation contracts by combining accountable assertions and deposits Non-equivocation contracts make it possible to penalize paltering in distributed protocols monetarily Setup|,Non-data,56
| Let A be a party to be penalized by the loss of B p if it equivocates before time T and let d be a parameter that depends on p (we will discuss the choice of d in Section 61) 1 Party A creates a Bitcoin key pair (pk, sk)|,Non-data,56
| Also, A sets up the accountable assertion scheme given in Section 52 with the Bitcoin key pair (pk, sk) That is, A predefines the secret key ask := sk of the accountable assertion scheme and creates the corresponding public key apk and the auxiliary secret information auxsk as specified in the key generation algorithm Note that apk = (pk, z) for some root hash z|,Non-data,56
| 2 A creates a deposit of B d with expiry time T (see Section 31) using pk The deposit may or may not specify an explicit beneficiary P , who will receive the funds in case of equivocation|,Non-data,56
 3 Every party B expecting to receive asserted statements from A waits until the transaction that creates the deposit has been confirmed by the Bitcoin network Usage The distributed protocol is augmented as follows: 1,Non-data,56
| Whenever A is supposed to send a statement st to differ- ent protocol parties in a context ct, party A additionally sends an assertion τ ← Assert(ask, auxsk, ct, st) 2 Each recipient B verifies that Verify(apk, ct, st, τ) = 1 and that T ≤ t for the current time t Party B ignores the message if any of the checks fail|,Non-data,56
| Otherwise, B sends the record (apk, ct, st, τ) to the beneficiary P , who will store it (If there is no explicit beneficiary, B publishes the record to the miners, who have an incentive to store it) 3 If P (or the miners) detect an equivocation in two records (apk, ct, st0, τ0) and (apk, ct, st1, τ1), they use the corresponding assertions to extract A’s secret key sk ← Extract(apk, ct, st0, st1, τ0, τ1)|,Non-data,56
| Using sk, party P transfers the funds in the deposit to an address fully under his control (If there is no explicit beneficiary, the miners wait until the expiry time of the deposit is reached Then each miner will try to create a block that includes a transaction transferring the deposit to an address under his control) If A does not equivocate, A will re-obtain full control over the deposit after its expiry|,Non-data,56
| Observe that an honest non-rational miner may not want to profit from a leaked secret key because the leakage could be the result of a security breach or carelessness However, since the assertions constitute cryptographic proof of A’s misbehavior, the miner can be assured that he acts honestly when claiming the deposit 61 Analysis We analyze the consequences of an equivocation by A|,Non-data,56
| With Explicit Beneficiary If an explicit beneficiary P is specified in the deposit, then the properties of the deposit ensure that only P can spend the deposit in case of an equivocation In particular, the safety margins as discussed in Section 31 ensure that the transaction created by P will have been confirmed already and thus the deposit will have been withdrawn already when its expiry will be reached|,Non-data,56
| The size B d of the deposit should be equal to the penalty B p Without Explicit Beneficiary If no explicit beneficiary is given, the analysis is more complicated, because a malicious sender A can participate in the mining process The goal of A is to establish the validity of a transaction tx that withdraws the funds in the deposit to an address 226impl conf is too small (say T controlled by A, even though her secret key has been pub- lished|,Non-data,56
| Recall that such a transaction cannot be included in a block before the expiry of the deposit (Section 31) First, we explain how to choose the safety margin T conf to prevent impl A from pre-mining the transaction tx First observe that, if T conf = 0 for simplicity), A can impl pursue the following strategy: Before the expiry time T , she tries to mine a block B that includes tx and builds upon the most current block Bcur|,Non-data,56
| If A manages to find such a block B, she will keep her block B secret at first If additionally no other miner finds another block B0 building upon Bcur, the malicious sender A will equivocate just before T  Then, by publishing B after time T , A will have a very high chance not to lose her deposit because the transaction tx in B will most likely prevail However, if A does not manage to find a block B, she will refrain from the equivocation attack|,Non-data,56
| This strategy is successful because the malicious sender avoids the risk of losing the deposit by performing the equiv- ocation only if success is almost guaranteed This is a variant of the so-called Finney attack [25] impl conf is larger, eg|,Non-data,56
|, T However, assume that T While a safety margin T conf = 60 min impl Then 60 min before the expiry time of the deposit, A will need to have secretly pre-mined several sequential blocks (one of them containing tx) on top of the current block Bcur to perform the equivocation Precisely, she will need to have pre-mined more blocks than she expects to be found by honest miners within the next 60 min This is considered infeasible if A controls only the minority of the computation power in the network, which is the one of the underlying assumptions for security of the Bitcoin network|,Non-data,56
| conf excludes pre-mining attacks, impl A can try to mine the first block B after time T  Even if other miners find a contradicting block B0 (and maybe more sequential blocks), A can try to catch up with the blockchain, which may be worthwhile in the case of a large deposit We counter such attacks by a careful selection of the deposit size B d Assume that the mining power of the whole network and the A’s fraction f of it stay constant|,Non-data,56
| If f < 05, the probability that her block B prevails is f /(1 − f) [41] Thus the expected penalty E for A is E = d−d·f /(1−f) At minimum, we require E ≥ p, which yields d ≥ p(f − 1)/(2f − 1)|,Non-data,56
| For example, a deposit of d ≥ 3p/2 is required for a malicious fraction of f = 025 62 Application Examples Many systems require users to trust in a service provider for data integrity|,Non-data,56
| However, the service provider may choose to equivocate and show different users different states of the system For instance, this has indeed been reported in the case of online social networks A user of the Chinese microblogging service Sina Weibo claims that Sina Weibo censored his posts by not showing them to other users [44] However, the server showed the posts to the user himself to avoid complaints from him|,Non-data,56
| To detect misbehavior of the service provider, a variety of systems have been proposed for different scenarios, eg, SUNDR [35] for cloud storage, SPORC [24] for group collab- oration, Application Transparency [22] for software distribu- tion, and Frientegrity [23] for social networks They basically ensure the following property: If the server violates the linearity of the system by showing contradicting states to different users, it cannot merge these states again without being detected|,Non-data,56
| Furthermore, if users that have received contradicting states exchange messages out of band, they can detect and prove the wrongdoing of the server (The basic property is called fork consistency [12, 35]) Observe that a violation of linearity is a case of equivo- cation Although clients can cryptographically verify the append-only property, i|,Non-data,56
|e, that a new system state is a proper extension of an old known system state, a malicious server can still provide different extensions to different clients Non-equivocation contracts are applicable in these set- tings The context is a revision number of the state, and the statement is a digest of the state itself at this revision number|,Non-data,56
| Depending on the system, the context may be more complex than an increasing counter Frientegrity [23], for instance, does not maintain a total order on all operations in the system, but rather a total order per object This is to avoid sacrificing performance So the context in which a state is asserted is not just an increasing counter but rather the pair of (objectID, perObjectRevisionNumber)|,Non-data,56
| As a concrete application, imagine a non-equivocation con- tract between a cloud storage provider and a client company, which is willing to pay a slightly higher usage fee as an insur- ance against accidental or malicious equivocation The client company is specified as the beneficiary of the deposit Then, the resulting contract serves as cryptographically-enforced insurance If the service provider equivocates to individual employees of the company, the company receives the deposit|,Non-data,56
| In another example scenario, consider a market with two main providers of app stores Both providers put down a global deposit without explicit beneficiary If one of the providers becomes malicious and sends different binaries of the same app (and version) to different users, then it will lose its deposit Thus, after the expiry of the deposit, the malicious provider will have to put down a new second de- posit to remain in business and competitive with the honest provider, even if the loss of reputation was small|,Non-data,56
| In com- parison, the honest service provider can re-use the funds to put down a second deposit after the first deposit has expired Alternatively, the malicious provider could choose not to put down a second deposit but then the honest provider can do the same while getting the funds back 7 ASYNCHRONOUS PAYMENTS As explained in Section 3|,Non-data,56
|2, payment channels [45, 48] allow a user A to perform many transactions to a predefined recipient B up to a predefined cumulative amount B d Once the channel is established, it is possible for A to send funds to B even when both parties are offline However, if the recipient B is a distributed system, ie|,Non-data,56
|, B actually consists of many unsynchronized entities B1,    , Bn, then offline transactions are not secure|,Non-data,56
| The problem is that A can double-spend the same funds to Bi and Bj, who cannot talk to each other because they are offline and thus not synchronized When B wants to close its channel and clear the payment in the Bitcoin network, it can clear these funds only once We can secure offline transaction through payment chan- nels in cases where a reasonable finite penalty for double- spending can be found Example: Public Transport|,Non-data,56
| For an illustrative example, assume B is a company offering public transport on buses A would like to use B’s services as a passenger Thus, A establishes a payment channel to B by sending a transaction 227to the Bitcoin network Once the transaction is confirmed, the payment channel is open and A can use it to pay for several single rides when she enters one of B’s buses Bi up to the limit B d of the channel|,Non-data,56
| It is reasonable to assume that A and B have at most sporadic Internet connectivity in this mobile setting, so the payment should be performed offline Still, B’s buses are synchronized every night This system is flawed: A can double-spend to B’s buses Say the current state in the channel is b = 3|,Non-data,56
| Then A can ride two (or more) buses Bi and Bj on the same day, by presenting them proof of updating the channel to b = 4 The bus company will only notice at night during the synchronization that it has been defrauded by A Using accountable assertions, we can secure this protocol Then B can penalize the double-spending user A when closing the channel|,Non-data,56
| Here, a reasonable penalty is at least the fare for a day ticket (valid for several rides on the same day) Basic Idea The idea of the modified protocol is as follows: Since the points of sale Bi are offline and not synchronized, we let A keep the state of the payment channel The state consists essentially of just the current value of the channel, and a revision number of the state|,Non-data,56
| To ensure that the user cannot modify the state, it is signed by the individual points of sale Bi However, the user can still show an old signed state and re-use it This is exactly where we can use accountable assertions: whenever the user A would like to perform a payment through the channel and claims that the latest state has revision number k, we require her to assert the statement “I buy a ticket with serial number r” in context ct = k, where r is a fresh nonce created by Bi Thus, if A reuses an old signed state, her key will be extractable|,Non-data,56
| 71 Full Protocol • VrfySig(spk Bj , state∗, σ∗) = 1 (valid state) • Verify(apk, k∗, r, τ∗) = 1 (valid assertion) • tx∗ is a valid transaction that updates the state • b∗ + x ≤ d∗ (unexhausted channel) of the channel to b∗ + x ), respectively Our full protocol for asynchronous payment channels con- sists of three phases It uses an unforgeable signature scheme with algorithms Sign and VrfySig, and assumes that B and its points of sale Bi have corresponding key pairs (spk B, ssk B) and (ssk Bi , spk Bi Setup|,Non-data,56
| To create an asynchronous payment channel from A to B with amount B d, penalty B p, and expiry time T , the parties execute the following steps: 1 A sets up a Bitcoin key pair (pk, sk) and account- able assertions keys (apk, ask = sk, auxsk) as for non- equivocation contracts (Section 6) 2 A creates a payment channel with B with amount B (d + p) and expiry time T (Section 3|,Non-data,56
|2) 3 After the channel is confirmed by the Bitcoin net- work, B provides A with a signed statement σ = Sign(ssk B, state), where state = (T, d, k = 0, b = 0, B) Payment|,Non-data,56
| Whenever A would like to pay B x offline at some point of sale Bi, the parties execute the following protocol: 1 Bi creates a fresh nonce r and sends it to A 2 A sets b := b + x and τ ← Assert(ask, auxsk, k, r)|,Non-data,56
| A creates a transaction tx updating the channel to state b, and sends (tx, τ, state, σ) to Bi 3 Bi receives (tx∗, τ∗, state∗, σ∗), parses state∗ as (T ∗, d∗, k∗, b∗, Bj), and verifies all the following conditions: • A /∈ X (A is not blacklisted) • t < T ∗ for the current time t (unexpired deposit) If any of the checks fail, Bi aborts the payment Oth- erwise, Bi computes a new state state0 = (T ∗, d∗, k∗ + 1, b∗ + x, Bi), signs it via σ0 ← Sign(ssk Bi , state0), and sends (state0, σ0) to A|,Non-data,56
 Bi records tx and τ and provides service to A 4 A updates the variables state and σ with the values received from Bi which can delete the transactions afterwards,Non-data,56
| Synchronization At the end of each time period, B syn- chronizes with each point of sale Bi: 1 B collects all transactions recorded by point of sale Bi, 2 B verifies that there are no double-spends among all transactions collected so far|,Non-data,56
| If B detects that A has double-spent, B extracts A’s secret key sk and uses it to sign a transaction that spends the whole payment channel worth B (d + p) to an address under the control of B B adds A to the blacklist X, and sends updates of the blacklist X to each point of sale Bi 3 Before time T , B closes the channel (Section 3|,Non-data,56
|2) B adds A to the blacklist X, and sends updates of the blacklist X to each point of sale Bi 72 Analysis because she will be blacklisted afterwards|,Non-data,56
| Observe that A can double-spend on at most one day Assume A has successfully double-spent Since all states are different, and the state contains the value b of the payment channel, she must have shown the same signed state with some revision number k twice successfully But then, A has sent two assertions τ0 and τ1 that are valid in the same context ct = k Since the corresponding statements st0 and st1 are fresh nonces, they differ with overwhelming probability|,Non-data,56
| Thus B can extract A’s secret key successfully, and close the payment channel at the maximum value B (d + p) Since the points of sale Bi accept payments only up to B b, the penalty for A in case of double-spending is at least B p 8 RELATED WORK Trusted Hardware for Non-equivocation|,Non-data,56
| One way to prevent equivocation is to relay on trusted hardware assumptions [4, 19, 20, 33] In particular, the resilience of tasks such as reliable broadcast, Byzantine agreement, and multiparty computation have been improved using a non-equivocation functionality based on a trusted hardware module, such as a trusted, increment-only local counter and a signature oracle, at each party Unlike our approach, which disincentives parties from equivocation, these systems fully prevent it, but at the same time they rely on a much stronger hardware assumption Smart Contracts|,Non-data,56
| Crypto-currencies with more expres- sive, eg, Turing-complete, script languages [11, 29] offer a simpler way to achieve non-equivocation contracts In such systems, it is possible to create a deposit that can be opened when presented with cryptographic evidence of equivocation|,Non-data,56
| As digital signatures suffice to provide such evidence and extractability is not required, they can be used instead of accountable assertions The monetary penalty is enforced by the consensus rules of the currency While crypto-currencies with Turing-complete languages are a very promising direc- 228tion, they have not yet withstood the test of time, and their powerful languages might lead to unforeseen security issues Traditional E-cash|,Non-data,56
| Similar to accountable assertions, Chaumian e-cash systems and one-show anonymous creden- tial systems [5, 13, 14, 16] allow a secret to be revealed in case of double-spending In these settings, the revealed secret is not used as a key but as the identity of the double-spender, ie, her anonymity is revoked upon double-spending|,Non-data,56
| However, these protocols are not applicable to our scenario, because they work in a fundamentally different setting: They rely on the property that a central authority (a bank) issues coins by generating cryptographic tokens In the decentral- ized Bitcoin setting, no central bank exists and cryptographic secrets are generated by the users 9 CONCLUSION In this paper, we introduced non-equivocation contracts in Bitcoin to penalize paltering in distributed systems|,Non-data,56
| In the process of designing these contracts, we presented a novel cryptographic primitive called accountable assertions, which reveals a predefined secret key in case of equivoca- tion We analyzed the security as well as the performance of our accountable assertions construction and found it to be practical for real-life use To prevent double-spending at unsynchronized points of sale, we further applied non-equivocation contracts to the Bitcoin network itself Acknowledgments We thank Dario Fiore for insightful discussions on chameleon hash functions and the anonymous reviewers for their helpful suggestions and comments|,Non-data,56
|ABSTRACT We consider the task of secure multi-party computation of arithmetic circuits over a finite field Unlike Boolean cir- cuits, arithmetic circuits allow natural computations on in- tegers to be expressed easily and efficiently In the strongest setting of malicious security with a dishonest majority — where any number of parties may deviate arbitrarily from the protocol — most existing protocols require expensive public-key cryptography for each multiplication in the pre- processing stage of the protocol, which leads to a high total cost We present a new protocol that overcomes this limita- tion by using oblivious transfer to perform secure multipli- cations in general finite fields with reduced communication and computation|,Non-data,60
| Our protocol is based on an arithmetic view of oblivious transfer, with careful consistency checks and other techniques to obtain malicious security at a cost of less than 6 times that of semi-honest security We describe a highly optimized implementation together with experimen- tal results for up to five parties By making extensive use of parallelism and SSE instructions, we improve upon previous runtimes for MPC over arithmetic circuits by more than 200 times Keywords Multi-party computation; oblivious transfer 1|,Non-data,60
| INTRODUCTION Secure multi-party computation (MPC) allows a set of parties to jointly compute a function on their private inputs, ∗ † Supported by EPSRC via grant EP/M016803 Supported by ERC Advanced Grant ERC-2010-AdG- 267188-CRIPTO ‡ Supported by the Defense Advanced Research Projects Agency (DARPA) and Space and Naval Warfare Systems Center, Pacific (SSC Pacific) under contract No N66001- 15-C-4070|,Non-data,60
| Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page Copyrights for components of this work owned by others than the author(s) must be honored Abstracting with credit is permitted To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee|,Non-data,60
| Request permissions from permissions@acmorg CCS’16, October 24 - 28, 2016, Vienna, Austria c(cid:2) 2016 Copyright held by the owner/author(s) Publication rights licensed to ACM|,Non-data,60
 ISBN 978-1-4503-4139-4/16/10   $15,Non-data,60
00 DOI: http://dxdoiorg/101145/2976749,Non-data,60
|2978357 learning only the output of the function In the last decade, MPC has rapidly moved from purely theoretical study to an object of practical interest, with a growing interest in prac- tical applications, and many implementations now capable of handling complex computations [28, 29] Most MPC protocols either perform secure computation of Boolean circuits, or arithmetic circuits over a finite ring or field such as Fp, for some prime p Historically, the Boolean circuit approach has led to fast protocols that mostly need only symmetric cryptography, such as two-party protocols based on Yao’s garbled circuits [41], or protocols based on fast oblivious transfer techniques [30, 34]|,Non-data,60
| In contrast, pro- tocols for arithmetic circuits are typically based on more expensive, public-key technology (except for special cases when a majority of the parties are honest) Despite the need for expensive techniques, secret-sharing- based MPC protocols for arithmetic circuits have the key advantage that secure addition requires no communication and essentially come ‘for free’, whereas with current Boolean circuit-based 2-PC, the only ‘free’ operation is XOR The following motivating examples further highlight the practical applicability of integer-based secure computation, compared with Boolean circuits: - Bogdanov et al [8, 9] describe using MPC to perform secure statistical analysis of income tax records for the Estonian government|,Non-data,60
| The latter work analyzed a large database with over 600000 students and 10 mil- lion tax records The kinds of computations involved were very simple statistics, but made heavy use of the fact that secure additions are non-interactive - In [13], an application of MPC to confidential bench- marking was presented, allowing banks to jointly eval- uate customers’ risks whilst retaining privacy for the customers’ data They used secure linear program- ming, which is a highly complex task in MPC, requir- ing either secure floating point arithmetic or very large integer arithmetic (to emulate real numbers without overflow), both of which would be impractical using Boolean circuits|,Non-data,60
| - MPC has been suggested as a tool for helping pre- vent collisions between satellites, by securely perform- ing collision detection using sensitive location and tra- jectory data Kamm et al [25] showed how to imple- ment the relevant conjunction analysis algorithms in MPC with a protocol based on secret-sharing This also requires secure floating point operations|,Non-data,60
| 830Unfortunately, all of the above case studies are somewhat limited, in either the security properties obtained, or the ef- ficiency The first and third examples above used the Share- mind system [1], which is restricted to semi-honest security with three parties, where at most one is corrupt The second example used the SPDZ MPC protocol [17], which has se- curity against any number of maliciously corrupted parties, but is much slower They report a fairly quick evaluation time of around 20–30 s with a prototype implementation, but this does not include the costly ‘preprocessing’ stage required in SPDZ, which would likely take several hours|,Non-data,60
| We conclude that although these applications are practi- cal, the MPC protocols used still fall short: in many real- world applications, semi-honest adversaries and an honest majority are not realistic assumptions, and MPC may not be cost-effective if it requires several hours of heavy compu- tation Furthermore, it is the case that all known practical proto- cols for MPC with integer operations either require an hon- est majority, or expensive public-key techniques for every multiplication in the circuit For example, the SPDZ proto- col [15, 17] mentioned above uses a somewhat homomorphic encryption scheme to perform secure multiplications, whilst the BDOZ protocol [6] uses additively homomorphic encryp- tion, and both of these require expensive zero-knowledge proofs or cut-and-choose techniques to achieve security against malicious adversaries These protocols mitigate this cost to an extent by restrict- ing the expensive computation to a preprocessing phase, which is independent of the inputs and can be done in advance|,Non-data,60
| Al- though this is highly effective for reducing the latency of the secure computation — as the online phase is indeed very ef- ficient — the total cost of these protocols can still be thou- sands of times greater than the online phase, which may render them ineffective for many applications Frederiksen et al [19] recently showed how to efficiently use oblivious transfer to generate multiplication triples — the main task of the SPDZ preprocessing — in binary fields, and estimated much improved performance, compared with previous methods However, this does not give the benefits of general arithmetic circuits that allow integer operations|,Non-data,60
| 11 Our contributions In this paper, we present MASCOT: a new MPC proto- col designed to overcome the above limitations of the pre- processing phase, allowing for efficient, secure computation of general arithmetic circuits using almost exclusively fast, symmetric cryptography Protocol Field SPDZ (active) SPDZ (covert, pr 1/10) Ours (active) Fp, 128-bit F240 Fp, 128-bit F240 Fp, 128-bit F2128 Comms|,Non-data,60
| (kbit) 215n(n − 1) 2272n(n−1) 66n(n − 1) 844n(n − 1) 180n(n − 1) 180n(n − 1) Throughput, n = 2 (/s) 235 368 204 319 4842 4827 Table 1: Comparing the cost of n-party secure mul- tiplication in our OT-based protocol with previous implementations of SPDZ [14, 15]|,Non-data,60
| Arithmetic-circuit MPC from OT We present a practical protocol for secure multi-party computation of arithmetic circuits based on oblivious trans- fer (OT), for the first time with malicious security in the dishonest majority setting We achieve this by taking an “arithmetic” view of OT (as was done by Gilboa for two- party RSA key generation [20] and Demmler et al [18] for two-party computation in the semi-honest model), which al- lows us to generalize the preprocessing protocol by Frederik- sen et al|,Non-data,60
| [19] to create multiplication triples in any (suffi- ciently large) finite field, instead of just binary fields We achieve security against malicious adversaries using simple consistency checking and privacy amplification techniques, with the result that our maliciously secure protocol is only 6 times less efficient than a semi-honest version of the protocol Moreover, our protocol can be based entirely on symmetric primitives, after a one-time setup phase, by using efficient OT extensions [23, 26] Implementation|,Non-data,60
| A key advantage of our approach to triple generation is that we obtain a streamlined protocol, which is highly amenable to a parallelized and pipelined implementation that inter- leaves computation and communication Table 1 highlights this: the time for a single secure multiplication in a prime field is 200 times faster than the previous best actively se- cure implementation based on somewhat homomorphic en- cryption [15], in spite of a fairly small improvement in com- munication cost Compared with a covertly secure imple- mentation1 using SHE [15], our actively secure protocol re- quires slightly more communication, but still runs over 20 times faster In binary fields, where SHE is much less suited, the improvement is over 1000 times, compared to previous figures [14]|,Non-data,60
| Note that the online phase of our protocol is identical to that of SPDZ, which has been previously re- ported to achieve very practical performance for a range of applications [28] Our optimized implementation utilizes over 80% of the network’s capacity, whereas the previous schemes based on SHE are so computation-intensive that the network cannot come close to capacity We also describe new techniques for reducing the cost of OT extension using consumer hard- ware instructions, namely efficient matrix transposition us- ing SSE instead of Eklundh’s algorithm, and hashing using the Matyas–Meyer–Oseas construction from any block ci- pher, which allows hashing 128-bit messages with AES-NI whilst avoiding a re-key for every hash More general assumptions|,Non-data,60
| We also improve upon the previous most practical pro- tocol by allowing a much wider variety of cryptographic assumptions, since we only require a secure OT protocol, which can be built from DDH, quadratic residuosity or lat- tices [36] In contrast, security of the SHE scheme used in SPDZ is based on the ring learning with errors assumption, which is still relatively poorly understood — it is possible that new attacks could surface that render the protocol to- tally impractical for secure parameters So as well as in- creasing efficiency, we obtain much greater confidence in the 1For F240 in SPDZ with covert security, we could not find precise figures so the throughput in Table 1 is estimated based on other results 831security of our protocol, and it seems more likely to with- stand the test of time|,Non-data,60
| 12 Technical overview The main goal of our MPC protocol is to create multipli- cation triples, which are essentially additive secret sharings of tuples (a, b, a· b, a· Δ, b· Δ, a· b· Δ) where a, b are random values and Δ is a secret-shared global random MAC key Shares of a, b and Δ can be generated by every party choos- ing a random share It remains to generate secret sharings of the products|,Non-data,60
| Our starting point is the passively secure two-party product- sharing protocol of Gilboa [20], which uses k oblivious trans- fers to multiply two k-bit field elements By running OT instances between every pair of parties, the multiplication triples can be created However, corrupted parties can deviate by providing in- consistent inputs to the different OT instances2 These de- viations will not only lead to potentially incorrect results when the triples are used in SPDZ but also to selective fail- ures, that is, the checks used in SPDZ might fail (or not) depending on secret information|,Non-data,60
| To obtain an actively secure protocol, we use two different strategies: one to ensure correctness of the products in the MAC generation, and one to ensure correctness and privacy of the multiplication triples themselves For the MAC generation, it turns out the passively secure protocol is almost enough; we just need to check random linear combinations of the MACs immediately after creation, and also when later opening values Proving the security of this, however, is not straightforward and requires a careful, technical analysis of the possible deviations To simplify this as much as possible, we model the MAC generation and opening requirements in a separate functionality, F(cid:2)·(cid:3), which can be seen as a generalization of verifiable secret- sharing to the case of full-threshold corruption|,Non-data,60
| This greatly reduces the work in proving higher-level protocols secure, as these can then be made independent of the MAC scheme and underlying MAC keys For triple generation, we need to ensure correctness and privacy of the triples Correctness is easily verified with a standard sacrifice technique [16, 17], which checks a pair of triples such that one can then be used securely To guaran- tee privacy we use a simple variant of privacy amplification, where first several leaky triples are produced, from which a single, random triple is extracted by taking random combi- nations|,Non-data,60
| In more detail, the protocol starts by generating shares of a correlated vector triple (a, b, c), where b ∈ F and a, c ∈ Fτ for some constant τ , using Gilboa’s multiplication protocol If at this point the triple is checked with a sacrifice, b is guaranteed to be uniformly random, but the fact that the sacrifice passes may leak a few bits of a, if a corrupt party used inconsistent inputs to some of the OTs To counteract this, the parties sample a public random vector r ∈ Fτ and obtain the triple (a, b, c) by defining a = (cid:3)a, r(cid:4), c = (cid:3)c, r(cid:4) In the security proof, the simulator can precisely define any leakage and bound the min-entropy of a by analysing the 2We assume that the OT instances themselves are secure against malicious parties adversary’s inputs to the OTs|,Non-data,60
| We then use the leftover hash lemma to show that a is uniformly random when τ is large enough At this point, we could repeat the process to obtain an- other triple, then authenticate both triples and check cor- rectness with a sacrifice However, we observe that this stage can be optimized by using the original vector triple (a, b, c) to obtain a second, correlated triple, with the same b value, at a lower cost To do this, we simply sample another ran- dom vector ˆr and compute ˆa, ˆc accordingly|,Non-data,60
| Again, we can show (for suitable τ ) that ˆa is uniformly random and inde- pendent of a We can then use (ˆa, b, ˆc) to check correctness of (a, b, c), as follows After adding MACs to both triples, the parties sample a random value s ∈ F and open ρ = s · a − ˆa Now, we have: s · c − ˆc − b · ρ = s · (c − a · b) + (ˆa · b − ˆc) Since the left-hand side is linear in the shared values, the parties can compute this and check that it opens to zero|,Non-data,60
| If one or both triples are incorrect then this is non-zero with probability at most 1/||F||, since s is uniformly random and unknown at the time of authentication It turns out that for this optimized method, using τ = 4 suffices to give a correct triple and ensure a distinguishing advantage in O(1/||F||) then we can have τ = 3 Concretely, this means that we can use τ = 3 for ≥ 128-bit fields with 64-bit statistical security|,Non-data,60
| If we allow this to be O(1/ p||F||) Comparison with Previous Techniques Previous works have used similar privacy amplification techniques for MPC In [16], privacy amplification was done on a large batch of triples using packed Shamir secret-sharing, which leads to high computation costs In contrast, our pro- tocol only requires removing leakage on one of the three triple values, which we do very efficiently by combining a constant-sized vector of correlated triples|,Non-data,60
| In situations where leakage is possible on more than one triple component, our techniqe would have to be repeated and [16] may be more efficient, at least in terms of communication Other works use more complex ‘bucketing’ techniques [35] to remove leak- age in F2, but when working in large finite fields this is not needed We also note that our authentication method is similar to that of the triple generation protocol for binary fields in [19], except there, MACs are only checked after opening values, whereas we also check MACs at time of creation That work did not describe the online phase of the resulting MPC protocol, and it turns out that for creating inputs in the online phase, this is not enough, and our additional check is crucial for security of the whole protocol|,Non-data,60
| Roadmap We model oblivious transfer and random oblivious trans- fer with FOT and FROT, respectively The multiplication with fixed element provided by OT extension with FCOPEe described in Section 3 This functionality is then used to implement F(cid:2)·(cid:3) in Section 4, which guarantees the correct- ness of linear operations|,Non-data,60
| Both FROT and F(cid:2)·(cid:3) are required to implement the triple generation functionality FTriple in Sec- tion 5, which is used for the online protocol described in the full version [27] In Section 6, we evaluate the complexity 832and the implementation of our protocol Fig 1 illustrates the relationship between our functionalities|,Non-data,60
| FOT FCOPE F(cid:2)·(cid:3) FROT FTriple Figure 1: Dependency among functionalities 13 Related work Aside from the works already mentioned, many other se- cure computation protocols use oblivious transfer Proto- cols based on GMW [2, 21] and TinyOT [10, 30, 34] use OT extensions for efficient MPC on binary circuits, and fast gar- bled circuit protocols use OT extensions in the input stage of the protocol [31] Pinkas et al|,Non-data,60
| [37, 38] used OT exten- sions to achieve a very efficient and scalable protocol for the dedicated application of private set intersection Ishai et al [24] present another protocol achieving mali- cious security based on OT However, they only give asymp- totic complexity measures|,Non-data,60
| Furthermore, the building blocks of their protocol such as codes and fast fourier transforms suggest more expensive computation than our protocol, where the computation mainly consists of a few field operations Baum et al [3] described improvements to the ‘sacrifice’ step and the zero-knowledge proofs used with somewhat ho- momorphic encryption in SPDZ Their sacrifice technique requires generating triples that form codewords, which does not seem straightforward with our protocol|,Non-data,60
| Their zero- knowledge proofs improve upon the method by Damg ̊ard et al [15] by roughly a factor of two, but our protocol still performs much faster 2 PRELIMINARIES In this section, we describe the security model, introduce some important notation, define the oblivious transfer prim- itive, and give a basic overview of the SPDZ protocol|,Non-data,60
| Security model We prove our security statements in the universal com- position (UC) framework of Canetti [11], and assume famil- iarity with this Our protocols work with n parties from the set P = {P1,  |,Non-data,60
|  , Pn}, and we consider security against malicious, static adversaries, ie corruption may only take place before the protocols start, corrupting up to n − 1 par- ties|,Non-data,60
| When we say that a protocol Π securely implements a functionality F with statistical (resp computational) se- curity parameter κ (resp λ), our theorems guarantee that the advantage of any environment in distinguishing the real −λ)) Here, and ideal executions is in O(2 κ and λ denote the statistical and computational security parameters, respectively|,Non-data,60
| −κ) (resp O(2 Notation 2k , and write F statistical security parameter κ, and μ ∈ poly(k) then with overwhelming probability a random element of Fp can be represented with k bits in {0, 1}, and likewise for any ele- ∼ 2k  Let F denote the finite field, which will be either ment of F Fp or F = F2[X]/f (X) for some monic, ir- reducible polynomial f (X) of degree k|,Non-data,60
| We use lower case letters to denote finite field elements and bold lower case let- ters for vectors in F, for any finite field F If x, y are vectors over F, then x ∗ y denotes the component-wise products of the vectors We denote by a $← A the uniform sampling of a from a set A, and by [d] the set of integers {1,  |,Non-data,60
|  , d} 2k Following notation often used in lattice-based cryptogra- phy, define the ‘gadget’ vector g consisting of the powers of two (in Fp) or powers of X (in F 2k ), so that g = (1, g, g2,  |,Non-data,60
|  , gk−1) ∈ F k, −1 : F → {0, 1}k 2k  Let g where g = 2 in Fp and g = X in F be the ‘bit decomposition’ function that maps x ∈ F to a −1(x) ∈ {0, 1}k, such that xB can be bit vector xB = g −1(x)(cid:4) = mapped back to F by taking the inner product (cid:3)g, g x These basic tools allow us to easily switch between field elements and vectors of bits whilst remaining independent of the underlying finite field|,Non-data,60
| Oblivious Transfer Oblivious transfer (OT) is a protocol between a sender and a receiver, where the sender transmits one of several mes- sages to the receiver, whilst remaining oblivious to which message was sent All known constructions of OT require public-key cryptography, but in 1996, Beaver [5] introduced the concept of OT extensions, where cheap, symmetric prim- itives (often available in consumer hardware) are used to produce many OTs from only a few Ishai et al|,Non-data,60
| [23] later optimized this concept to the form that we will use in this paper Recently, Keller et al [26] presented a simple consistency check that allows maliciously secure OT extension at essen- tially no extra cost: the cost for a single OT on random strings is almost that of computing two hash function eval- uations and sending one string The ideal functionality for a single 1-out-of-2 oblivious transfer on k-bit strings is specified as follows, along with the random OT variant, where the sender’s messages are sampled at random: (cid:10)→ (⊥, sb) (cid:10)→ ((r0, r1), rb), F 1,k OT : ((s0, s1), b) ROT : (⊥, b) F 1,k $← {0, 1}k, and b ∈ {0, 1} is the receiver’s input|,Non-data,60
| ROT to denote l sets of oblivious where r0, r1 We use the notation F l,k transfers on k-bit strings 21 The SPDZ Protocol OT ,F l,k The online phase of SPDZ [15, 17] uses additive secret sharing over a finite field, combined with information-theoretic MACs to ensure active security A secret value x ∈ F is rep- resented by The protocols we present in this paper work in both Fp, for prime p = 2k + μ, and F 2k ; we introduce some notation to unify the two finite fields|,Non-data,60
| First note that if k ≥ κ, for (cid:2)x(cid:3) = (x(1),    , x(n), m(1), |,Non-data,60
|   , m(n), Δ(1),  |,Non-data,60
|  , Δ(n)), where each party Pi holds the random share x(i), the random 833which is illustrated for Fp in Fig 2, and also used in our triple generation protocol later The two parties run k sets of OTs on k-bit strings, where in each OT the sender, PS, $← F and the correlated value ti +a, inputs a random value ti where a ∈ F is the sender’s input|,Non-data,60
| The receiver inputs the bit decomposition of their input, (b1,    , bk) ∈ {0, 1}k, and receives back either ti or ti + a, depending on the bit bi|,Non-data,60
| Since the sender’s correlation is computed over F, we have the relation qi = ti + bi · a, where qi is the receiver’s output in the i-th OT Now both parties simply compute the inner product of their values (qi)i, (−ti)i with the gadget vector g to obtain values q and t which form an additive sharing of the product of the inputs, so that q + t = a · b ∈ F Correlated OPE To obtain COPE, where one party’s input is fixed for many protocol runs, we only need to perform the k OTs once, where the receiver, PB, inputs their bits of Δ ∈ F and the sender, PA, inputs k pairs of random λ-bit seeds (recall that λ is the computational security parameter and k = (cid:12)log ||F||(cid:13))|,Non-data,60
| This is the Initialize phase of ΠCOPEe (Pro- tocol 1) After initialization, on each Extend call the parties ex- pand the original seeds using a PRF to create k bits of fresh random OTs, with the same receiver’s choice bits ΔB Party PA now creates a correlation between the two sets of PRF outputs using their input, x (step (b)) The masked correla- tion is sent to PB, who uses this to adjust the PRF output accordingly; now both parties have k correlated OTs on field elements|,Non-data,60
| These are then mapped into a single field element by taking the inner product of their outputs with the gadget vector g to obtain an additive sharing of x · Δ in steps 4–5 Malicious behavior Now consider what happens in ΠCOPEe if the parties do not follow the protocol Party PB fixes their input Δ at the start of the protocol, and sends no more messages thereafter, so cannot possibly cheat|,Non-data,60
| On the other hand, PA may use different values of x in each ui that is sent in step 2 of Extend Suppose a corrupt PA uses xi to compute ui, for i ∈ [k], then in step 4 we will instead have q = t + x ∗ ΔB, where x = (x1,   |,Non-data,60
| , xk), which then results in t + q = (cid:3)g ∗ x, ΔB(cid:4) We do not prevent this in our protocol, but instead model this behavior in the functionality FCOPEe (given in the full version [27]) The proof of the following theorem, showing that our pro- tocol securely implements FCOPEe in the FOT-hybrid model if F is a PRF, is given in the full version Theorem 1 The protocol ΠCOPEe securely implements FCOPEe in the FOT-hybrid model with computational security param- eter λ, ifF is a PRF|,Non-data,60
| Figure 2: Two-party secret-shared multiplication in Fp using 1-out-of-2 OT MAC share m(i) and the fixed MAC key share Δ(i), such that the MAC relation m = x · Δ holds, for X X X x(i), m = m(i), Δ = Δ(i) x = i i i over F When opening a shared value (cid:2)x(cid:3), parties first broadcast their shares x(i) and compute x To ensure that x is correct, they then check the MAC by committing to and opening m(i) − x · Δ(i), and checking these shares sum up to zero To increase efficiency when opening many values, a random linear combination of the MACs can be checked instead|,Non-data,60
| The main task of the SPDZ preprocessing phase is to pro- duce the following types of random, authenticated shared values: Input Pi: ((cid:2)r(cid:3), i) a random, shared value r, such that only party Pi knows the value r Triple: ((cid:2)a(cid:3), (cid:2)b(cid:3), (cid:2)c(cid:3)) for uniformly random a, b, with c = a · b In the online phase, parties interact and use the Input val- ues to create shared representations of their private inputs, and the Triple values to perform multiplications on secret- shared values Note that since the (cid:2)·(cid:3) representation is lin- ear, additions and linear functions can be computed locally|,Non-data,60
| 3 CORRELATED OBLIVIOUS PRODUCT EVALUATION In this section we describe an arithmetic generalization of the passively secure OT extension of Ishai et al [23], which we call correlated oblivious product evaluation (COPE) This allows two parties to obtain an additive sharing of the prod- uct x · Δ, where one party holds x ∈ F and the other party holds Δ ∈ F|,Non-data,60
| The correlation, Δ, is fixed at the start of the protocol, and then future iterations create sharings for different values of x Oblivious product evaluation The key mechanism behind COPE is a general method for (possibly non-correlated) oblivious product evaluation, 834Protocol 1 The protocol ΠCOPEe: Oblivious correlated prod- uct evaluation with errors over the finite field F The protocol uses a PRF F : {0, 1}λ × {0, 1}λ → F and maintains a counter j := 0|,Non-data,60
| After initialization, Extend may be called multiple times Initialize: On input Δ ∈ F from PB: 1: PA samples k pairs of seeds, {(ki 2: Both parties call F k,λ {0, 1}λ PA and ΔB = (Δ0,  |,Non-data,60
|  , Δk−1) ∈ {0, 1}k from PB 0, ki OT with inputs {ki i=1, each in 1}i∈[k] from 1)}k 0, ki 3: PB receives ki Extend: On input x ∈ F from PA: Δi for i ∈ [k] 1: For each i = 1, |,Non-data,60
|   , k: (a) Define 0 = F (ki ti so PA knows (ti (b) PA sends ui = ti (c) PB computes 0, j) ∈ F and ti 1 = F (ki 0, ti 1) and PB knows ti 0 − ti 1 + x to PB 1, j) ∈ F Δi |,Non-data,60
| qi = Δi · ui + ti 0 + Δi · x = ti Δi 2: Store j := j + 1 3: Let q = (q1,    , qk) and t = (t1 0, |,Non-data,60
|   , tk 0 ) Note that q = t + x · ΔB ∈ F k|,Non-data,60
| 4: PB outputs q = (cid:3)g, q(cid:4) 5: PA outputs t = −(cid:3)g, t(cid:4) 6: Now it holds that t + q = x · Δ ∈ F Complexity|,Non-data,60
| The communication complexity of a single iteration of our COPE protocol, after the k base OTs in initialization, is k field elements, for a total of k2 bits The computation cost is 3k PRF evaluations and 8k finite field operations between the two parties 4 AUTHENTICATING AND OPENING AD- DITIVE SHARES In this section we show how to create authenticated SPDZ shares using COPE and securely open linear combinations of these shares with a MAC checking procedure|,Non-data,60
| The main challenge is to ensure that an adversary who inputs errors in our COPE protocol cannot later open an authenticated share to the incorrect value We model these requirements in a single functionality, F(cid:2)·(cid:3) (Fig 3), which is independent of the details of the MAC scheme used and the underlying MAC keys One can see this functionality as a generaliza- tion of verifiable secret sharing with the main difference that it allows full-threshold corruption|,Non-data,60
| We first explain the me- chanics of the functionality, and then describe the protocols for implementing it Inputs are provided to the functionality with the Input command, which takes as input a list of values x1,   |,Non-data,60
| , xl from one party and stores these along with the identifiers Protocol 2 MAC checking subprotocol On input an opened value y, a MAC share m(i) and a MAC key share Δ(i) from party Pi, eachP i does the following: 1: Compute σ(i) ← m(i)−y·Δ(i) and call FComm to commit 2: Call FComm with (Open, τi) to open the commitments 3: If σ(1) + ··· + σ(n) (cid:14)= 0, output ⊥ and abort, otherwise to this and receive the handle τi continue id1, |,Non-data,60
|   , idl Linear functions can then be computed on values that have been input using the LinComb command|,Non-data,60
| The Open command lets the adversary output inconsistent or incorrect values However, if this happened to honest parties, the Check command will reveal this 41 Authentication using COPE We first consider a natural approach for one party to cre- ate an authenticated sharing of their private inputs using the correlated oblivious product evaluation protocol, and describe why this is not sufficient for active security on its own|,Non-data,60
| We then show that an actively secure protocol can be obtained by authenticating one extra random value and checking a random linear combination of all MACs during the input phase For ease of exposition, we restrict ourselves to the two-party setting, and briefly explain at the end how Π(cid:2)·(cid:3) (Protocol 3) extends this to n parties Suppose party P1 is honest and wishes to authenticate an input x ∈ F P1 runs an instance of FCOPEe with P2 and inputs x into the Extend command, whilst P2 inputs a MAC key share Δ(2)|,Non-data,60
| P1 then receives t and Pj receives q such that q + t = x · Δ(2) P1 then defines the MAC share m(1) = x· Δ(1) + t, and P2 defines the MAC share m(2) = q Clearly, we have m(1) + m(2) = x · Δ, as required To convert x into shares, P1 simply generates random ad- ditive shares x(1), x(2) and sends x(2) to P2|,Non-data,60
| Note that since the shares and MACs are linear, computing linear combi- nations on authenticated values is straightforward Parties can also add a constant by adjusting their MAC shares ac- cordingly, and choosing one party (say, P1) to adjust their share FCOPEe If P this is 1 in the first k/2 positions and 0 elsewhere, then the relation between the MAC shares becomes: ∗ 1 , who can input a vector x into 1 chooses x = (1, |,Non-data,60
|   , 1, 0,  |,Non-data,60
|  , 0) ∈ Fk, where ∗ Now consider a corrupt P m(1) + m(2) = (cid:3)g ∗ (1,   |,Non-data,60
| , 1, 0,    , 0), ΔB(cid:4) where we have defined m(1) = t + (cid:3)g ∗ x, Δ(1)(cid:4) for conve- nience|,Non-data,60
| ∗ 1 ’s input is later opened, then to pass the MAC check, If P ∗ 1 essentially needs to come up with a value x and a valid + m(2) = x· Δ One possibility , and compute P MAC share m is to guess the first k/2 bits of Δ, denoted Δ such that m ∗ ∗ (cid:4) ∗ = m(1) − (cid:3)g, Δ m B(cid:4) (cid:4) ∗ which gives a valid MAC relation for x = 0 However, P 1 could similarly try to guess the latter k/2 bits of Δ, which corresponds to opening to x = 1 Note that each of these −k/2, but for effi- openings only succeeds with probability 2 835Functionality F(cid:2)·(cid:3) The functionality maintains a dictionary, Val, to keep track of the authenticated values|,Non-data,60
| Entries of Val lie in the (fixed) finite field F and cannot be changed, for simplicity set Val[idi] ← xi for i = 1,   |,Non-data,60
| , l Input: On receiving (Input, id1,   |,Non-data,60
| ,id l, x1,    , xl, Pj ) from party Pj and (Input, id1, |,Non-data,60
|   ,id l, Pj ) from all other parties, where xi ∈ F, Linear comb: On receiving (LinComb, id, id1, |,Non-data,60
|   ,id t, c1,  |,Non-data,60
|  , ct, c) from all parties, where (id1,   |,Non-data,60
| , idt) ⊆ Valkeys() and the com- Open: On receiving (Open, id) from all parties, where id ∈ Valkeys(), send Val[id], wait for x from the adversary, and output x to bination coefficients c1,  |,Non-data,60
|  , ct, c ∈ F, set Val[id] ← P Val[idi] · ci + c t i=1 all parties and Val[idj ] = xj for all j, return OK to all parties, otherwise return ⊥ and terminate|,Non-data,60
| Check: On receiving (Check, id1,    , idt, x1, |,Non-data,60
|   , xt) from every party Pi, wait for an input from the adversary If it inputs OK, Abort: On receiving Abort from the adversary, send ⊥ to all parties and terminate|,Non-data,60
| Figure 3: Functionality for authenticating, computing linear combinations of, and opening additively shared values −k The main problem here is that P ciency we would like to achieve a failure probability much closer to 2 ∗ 1 can choose, at the time of opening, what to open to, and is not committed to one particular value This means the simulator cannot compute a valid input during the Input stage, and we cannot securely realize the functionality To get around this problem, we require two changes to the Input stage|,Non-data,60
| Firstly, P1 samples a random dummy input $← F, and authenticates this as well as the m actual in- x0 puts Secondly, after computing the MACs using FCOPEe, P1 opens a random linear combination of the inputs x0,   |,Non-data,60
| , xl, and the MAC on this is checked by all parties This ensures that P1 is committed to their inputs during the input stage and cannot later open to a different value, whilst x0 masks the actual inputs in this opening We now examine in more detail why this suffices Suppose ∗ 1 is meant to input m values to be shared, in a corrupt P the actual protocol Π(cid:2)·(cid:3)|,Non-data,60
| A dummy value x0 ∈ F is sampled, and P ∗ 1 , P2 can obtain MAC shares such that: 1 ’s inputs to FCOPEe In the MAC check of ∗ where xh are P the Input stage, the parties sample a random r ∈ Fl+1, and ∗ ∗ 1 can force to be any 1 then opens the value y, which P P value Next, P2 computes during steps 8–9 the values: lX rh · m(2) m(2) = σ(2) = m(2) − y · Δ h=0 h ⇔ σ(1) − X h h = y · Δ − lX rh · m(1) h=0 rh · (cid:3)g ∗ xh, ΔB(cid:4)|,Non-data,60
| (1) Since rh, m(1) h are known to P Clearly, one way of achieving this is letting xh = (xh,    , xh) ∗ 1 , this is equivalent to guess- ing the right-hand side of (1), after choosing xh (indepen- dently of rh) and y|,Non-data,60
| P for some xh ∈ F, which implies that (cid:3)g ∗ xh, ΔB(cid:4) = xh · Δ, h=0 rh · xh This corresponds to the hon- and letting y = est behavior Otherwise, we prove in the full version that ∗ 1 , passing the check implies being able to compute a for P correct MAC share for xh Once a correct MAC share for a specific value is known, passing a later MAC check for another value implies knowledge of the MAC key|,Non-data,60
| for some xh (cid:14)= 0, h ∈ [l] This implies that As an example, consider the case of xh = (0, xh,   |,Non-data,60
| , xh) l lX i=0 rh · (cid:3)g ∗ xh, ΔB(cid:4) = lX lX h=0 rh · (xh · Δ − xh · Δ1) rh · xh · (Δ − Δ1), where Δ1 denotes the first bit of ΔB Define Δ Then, (1) can be written as σ(1) − lX P h=0 h = (y − lX h=0 rh · m(1) h=0 rh · xh, P l (cid:4) = Δ − Δ1 rh · xh · Δ1 (cid:4) − lX h=0 rh · xh) · Δ If y (cid:14)= the check|,Non-data,60
| Otherwise, P by “guessing” Δ1 If successful, P Δ1, which is a correct MAC share for xh because ∗ 1 has only negligible chance of passing ∗ 1 can succeed with probability 1/2 h + xh · ∗ 1 can compute m(1) h = (cid:3)g ∗ xh, ΔB(cid:4) + xh · Δ1 h + xh · Δ1 + m(2) m(1) m(1) h + m(2) h = (cid:3)g ∗ xh, ΔB(cid:4), for h = 0,   |,Non-data,60
| , l = h=0 ∗ 1 must then come up with a value σ(1) such that σ(1) + P σ(2) = 0, which implies: σ(1) = −σ(2) = y · Δ − lX rh · ((cid:3)g ∗ xh, ΔB(cid:4) − m(1) h ) 0 = h=0 h=0 ∗ 1 is effectively committed to xh Finally, This means that P the simulation involves solving D g · y − g ∗ lX E rh · xh, ̃ΔB = (cid:3)g · xh, ΔB(cid:4) = xh · Δ 836Protocol 3 Π(cid:2)·(cid:3), creating (cid:2)·(cid:3) elements This protocol additively shares and authenticates inputs in F, and allows linear operations and openings to be carried out on these shares Note that the Initialize procedure only needs to be called once, to set up the MAC key|,Non-data,60
| Initialize: Each party Pi samples a MAC key share Δ(i) ∈ F Each pair of parties (Pi, Pj) (for i (cid:14)= j) calls FCOPEeInitialize(F) where Pj inputs Δ(j) Input: On input (Input, id1, |,Non-data,60
|   , idl, x1,  |,Non-data,60
|  , xl, Pj) from Pj and (Input, id1,   |,Non-data,60
| , idl, Pj) from all other parties: $← F P 1: Pj samples x0 2: For h = 0,   |,Non-data,60
| , l, Pj generates a random additive 3: For every i (cid:14)= j, Pi and Pj call FCOPEeExtend, where sharing Pj inputs (x0,   |,Non-data,60
| , xl) ∈ Fl+1 h = xh and sends x(i) h to Pi i x(i) 4: Pi receives q(i,j) and Pj receives t(j,i) such that h h q(i,j) h + t(j,i) h = xh · Δ(i), for h = 0,  |,Non-data,60
|  , l 5: Each Pi, i (cid:14)= j, defines the MAC shares m(i) h = q(i,j) h , and Pj computes the MAC shares h = xh · Δ(j) + m(j) t(j,i) h X j(cid:5)=i to obtain (cid:2)xh(cid:3), for h = 0,  |,Non-data,60
|  , l P 6: The parties sample r ← FRand(Fl+1) P h=0 rh · xh|,Non-data,60
| 7: Pj computes and broadcasts y = h=0 rh · m(i) 8: Each party Pi computes m(i) = h  9: The parties execute ΠMACCheck with y and {m(i)}i∈[n] l l 10: All parties store their shares and MAC shares under the handles id1,  |,Non-data,60
|  , idl Linear comb: input (LinComb, id, id1, |,Non-data,60
|   , idt, c1,  |,Non-data,60
|  , ct, c), On the parties retrieve their shares and MAC shares j , m(xj)(i)}j∈[t],i∈[n] corresponding to id1,   |,Non-data,60
| , idt, {x(i) and each Pi computes: ( y(i) = m(y)(i) = j + cj · x(i) c i = 1 0 i (cid:14)= 1 cj · m(xj)(i) + c · Δ(i), tX tX j=1 j=1 P They then store the new share and MAC of (cid:2)y(cid:3) under the handle id Open: On input (Open, id): 1: Each Pi retrieves and broadcasts their share x(i) i=1 x(i) and output it 2: Parties reconstruct x = n Check: On input (Check, id1, |,Non-data,60
|   , idt, x1,  |,Non-data,60
|  , xt), the par- 2: Compute y ←P ties do the following: 1: Sample a public, random vector r ← FRand(Ft) j=1 rj · xj and m(y)(i) ←P j=1 rj · idj denotes Pi’s MAC share stored un- m(i) idj , where m(i) der idj for all i ∈ [n] and j ∈ [t] t t 3: Execute ΠMACCheck with y and m(y)(i)|,Non-data,60
| lX = h=0 rh · xh · ̃Δ1 for ̃Δ Clearly, the first bit of any solution ̃Δ must be zero It is easy to see that −1 · (cid:3)g ∗ xh, ̃Δ(cid:4) = xh ̃Δ We need that, once P for any such ̃Δ This is how the simulator in our proof ∗ 1 is committed to after passing the computes the value P check|,Non-data,60
| ∗ 1 has passed the check in the input phase, they are committed to a particular value However, the adversary has an edge because only a random combina- tion of inputs can be checked (otherwise all the inputs would be revealed) This can be seen as follows: Denote by xh,g the g-th entry of the vector xh input when authenticating the h-th value, and denote by {rh}h∈[l] the random coefficients P (cid:4) ∈ [k], if xh,g (cid:14)= xh,g(cid:2) , there generated using FRand For g (cid:14)= g is a 1/||F|| chance that rhxh,g(cid:2) |,Non-data,60
| Because the check only relates to the randomly weighted sum, the adver- sary could therefore act as if xh,g = xh,g(cid:2) and decide later between {xh,g}h∈[l] and {xh,g(cid:2)}h∈[l] The fact that there are explains the 2 log log ||F|| log ||F||(log ||F||−1)/2 such pairs g (cid:14)= g subtrahend in the theorem below It is easy to see that a repeated check would suffice for security parameter log ||F|| rhxh,g = P (cid:4) Extension to more than two parties|,Non-data,60
| P Extending the authentication protocol to n parties is rela- tively straightforward When party Pj is inputing a value x, Pj runs FCOPEe (on input x) with every other party Pi (cid:14)= Pj, who each inputs the MAC key share Δ(i) Summing up these outputs allows Pj to obtain an authenticated share i Δ(i) Note that this under the global MAC key, Δ = introduces further potential avenues for cheating, as Pj may provide inconsistent x’s to FCOPEe with different parties, and the other parties may not use the correct Δ(i)|,Non-data,60
| However, it is easy to see that except with probability 1/||F||, these devi- ations will cause the MAC check to fail in the Input stage, so are not a problem The security of our authentication and MAC checking pro- tocols is given formally in the following theorem, which we prove in the full version [27] Theorem 2 The protocol Π(cid:2)·(cid:3) securely implements F(cid:2)·(cid:3) in the (FCOPEe,FComm,FRand)-hybrid model, with statistical security parameter log ||F|| − 2 log log||F|||,Non-data,60
| 5 MULTIPLICATION TRIPLES USING OBLIVIOUS TRANSFER In the previous section we showed how parties can com- pute linear functions on their private inputs using the au- thentication and MAC checking protocols We now extend this to arbitrary functions, by showing how to create multi- plication triples using F(cid:2)·(cid:3) and OT Recall that a multiplication triple is a tuple of shared val- ues ((cid:2)a(cid:3), (cid:2)b(cid:3), (cid:2)c(cid:3)) where a, b $← F and c = a·b|,Non-data,60
| Given F(cid:2)·(cid:3) and a protocol for preprocessing triples, the online phase of the resulting MPC protocol is straightforward, using Beaver’s method for multiplying two secret-shared values [4] For completeness, this is detailed in the full version [27] Throughout this section, we write (cid:2)x(cid:3) to mean that each party holds a random, additive share of x, and the value of x is stored in the ideal functionality F(cid:2)·(cid:3) The protocol ΠTriple (Protocol 4) begins with the Multi- ply step, which uses FOT to compute a secret sharing of the 837Protocol 4 Triple generation protocol, ΠTriple The integer parameter τ ≥ 3 specifies the number of triples to be generated per output triple|,Non-data,60
| Multiply: 1: Each party samples a(i) $← Fτ , b(i) $← F 2: Every ordered pair of parties (Pi, Pj) does the follow- ROT where Pi inputs ing: (a) Both parties 1 ,   |,Non-data,60
| , a(i) (a(i) τ k) = g call F τ k,k −1(a(i)) ∈ Fτ k 2  (b) Pj receives q(j,i) 0,h , q(j,i) 1,h ∈ F and Pi receives s(i,j) h = q(j) (i) a h ,h , for h = 1,   |,Non-data,60
| , τ k (c) Pj sends d(j,i) (d) Pi sets t(i,j) h = s(i,j) h = q(j,i) 0,h − q(j,i) h +a(i)·d(j,i) 1,h + b(j), h ∈ [τ k] h = q(j,i) 0,h +a(i) h ·b(j), for h = 1,  |,Non-data,60
|  , τ k Set q(j,i) h = q(j,i) 0,h  , |,Non-data,60
|   , q(j,i) (e) Split (t(i,j) ,  |,Non-data,60
|  , t(i,j) τ k ) intoτ vectors of k components each, (t1,   |,Non-data,60
| , tτ ) and (q1,    , qτ )|,Non-data,60
| τ k ) and (q(j,i) 1 1 (f) Pi sets c(i) (g) Pj sets c(j) (h) Now we have i,j = ((cid:3)g, t1(cid:4),    , (cid:3)g, tτ(cid:4)) ∈ Fτ |,Non-data,60
| i,j = −((cid:3)g, q1(cid:4),    , (cid:3)g, qτ(cid:4)) ∈ Fτ |,Non-data,60
| c(i) i,j + c(j) 3: Each party Pi computes: i,j = a(i) · b(j) ∈ F τ c(i) = a(i) · b(i) + (c(i) i,j + c(i) j,i ) X j(cid:5)=i Combine: 1: Sample r, ˆr ← FRand(Fτ ) 2: Each party Pi sets a(i) = (cid:3)a(i), r(cid:4), ˆa(i) = (cid:3)a(i), ˆr(cid:4), c(i) = (cid:3)c(i), r(cid:4) ˆc(i) = (cid:3)c(i), ˆr(cid:4) and Authenticate: Each party Pi runs F(cid:2)·(cid:3)Input on their shares to obtain authenticated shares (cid:2)a(cid:3), (cid:2)b(cid:3), (cid:2)c(cid:3), (cid:2)ˆa(cid:3), (cid:2)ˆc(cid:3) Sacrifice: Check correctness of the triple ((cid:2)a(cid:3), (cid:2)b(cid:3), (cid:2)c(cid:3)) by sacrificing (cid:2)ˆa(cid:3), (cid:2)ˆc(cid:3)|,Non-data,60
 1: Sample s ← FRand(F) 2: Call F(cid:2)·(cid:3)LinComb to store s · (cid:2)a(cid:3) − (cid:2)ˆa(cid:3) under (cid:2)ρ(cid:3) 3: Call F(cid:2)·(cid:3),Non-data,60
|Open on input (cid:2)ρ(cid:3) to obtain ρ 4: Call F(cid:2)·(cid:3)LinComb to store s · (cid:2)c(cid:3) − (cid:2)ˆc(cid:3) − (cid:2)b(cid:3) · ρ under 5: Run F(cid:2)·(cid:3)Check((cid:2)ρ(cid:3), (cid:2)σ(cid:3), ρ, 0) and abort if F(cid:2)·(cid:3) aborts|,Non-data,60
| (cid:2)σ(cid:3) Output: ((cid:2)a(cid:3), (cid:2)b(cid:3), (cid:2)c(cid:3)) as a valid triple product of b ∈ F and a ∈ Fτ , where τ ≥ 3 is a parame- ter affecting security This is done by running τ copies of the basic two-party product sharing protocol between every pair of parties (steps (a)–(g)), followed by each party locally summing up their shares|,Non-data,60
| During this stage, a corrupt Pj may attempt to guess some bits of a by using values other than b(j) in step (c) This is why we start with τ components for a instead of just one, ensuring that a still has sufficient randomness to produce a triple Note that there is no need for privacy amplification on b, which is already protected by the protocol because the − q(j,i) shares b(j) are only used to compute d(j,i) = q(j,i) 1,h + 0,h b(j), which is uniformly random because Pj learns only one of q(j,i) 0,h and q(j,i) 1,h  After the Multiply step, the parties have an additively shared triple (a, b, c), which may be incorrect if someone was dishonest|,Non-data,60
| In the Combine step, they take random linear combinations of the τ components of (a, b, c) using random r and ˆr in Fτ obtained from FRand By using two sets of random coefficients, this produces two triples with the same b component; later, one of these will be ‘sacrificed’ to check correctness of the other Using random combinations ensures that even if a few bits of the vector a are leaked to the adversary, the values a, ˆa are still statistically close to uniform The parties then use F(cid:2)·(cid:3) to Authenticate their shares of a, ˆa, b, c and ˆc|,Non-data,60
| Finally, correctness of the triple (cid:2)a(cid:3), (cid:2)b(cid:3), (cid:2)c(cid:3) is checked in a Sacrifice phase, using (cid:2)ˆa(cid:3) and (cid:2)ˆc(cid:3) The idea of this step is similar to the corresponding step in previous works [15, 17], with the key difference that in our case both triples have the same b value We observe that this still suffices to check correctness of the triples, and means we only need to authenticate 5 values instead of 6 5|,Non-data,60
|1 Security analysis Then, for each i (cid:14)∈ A, let δ(j,i) We now give some more intuition behind the security of the protocol Let us first examine the possible adversarial deviations in the Multiply step Suppose Pj is corrupt Let a(j,i) ∈ Fτ and b(j,i) ∈ Fτ k be the actual values used by Pj in the two executions of steps 1 and 3 with an honest Pi, instead of a(j) and b(j)|,Non-data,60
| Define the values a(j) and b(j) to be those values used in the instance with an arbitrary (eg lowest index) honest party Pi0  a = a(j,i) − a(j) ∈ Fτ and = b(j,i) − (b(j), |,Non-data,60
