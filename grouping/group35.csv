 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
446 343003 340682 389194 10,Non-data,83
630 SanDisk16G 119962 122583 122550 125,Non-data,83
309 1383 40246 97724 22,Non-data,83
286 839120 850743 851300 851,Non-data,83
766 2670 Original ProvUSB 65382 50857 Med Table 2: USB enumeration time (ms) averaged across 20 plugging operations for different devices,Non-data,83
| MB flash memory and a USB OTG port, running Yocto 16 with Linux kernel version 357|,Non-data,83
| The device uses an 8 GB class 10 microSDHC flash memory card; the USB storage partition is 1 GB in size, formatted as a FAT16 filesystem with the logical block size of 512 bytes We compare the ProvUSB storage with two commercial USB storage devices: a Kingston DataTraveler 2 GB USB thumb drive, and a San- Disk Cruzer Fit 16 GB USB stick All devices were plugged into the same USB 20 port throughout the evaluation|,Non-data,83
| 61 TPM Operations One source of overhead imposed by our system is the intro- duction of a TPM-based attestation procedure during device enumeration We determined the cost of host attestation by measuring the completion time of each TPM operation used by ProvUSB Averaged across 1000 iterations, we found that reading the system measurement from PCRs takes 12|,Non-data,83
|19 ms, while retrieving the AIK public key takes 5724 ms The cost of attestation is dominated by the quote operation, which re- quired 34403 ms to complete on average, with a standard deviation of 6|,Non-data,83
|10 ms, as shown in Table 1 Fortunately, this overhead is a one-time effort during USB enumeration, and does not affect the runtime performance of the device The speed of TPM operations is constrained by the performance of the TPM hardware Though TPM are usually low-speed chips, the enumeration overhead could be brought to mini- mum through the help of high-end TPM chips that uses the 400 KHz I2C bus [28]|,Non-data,83
| 62 USB Enumeration To show the overhead of USB enumeration using ProvUSB compared to other commercial devices, we measured the complete procedure from the host side, starting from the beginning of the device probing, to the TPM attestation protocol (for ProvUSB), and including the SCSI scanning for the USB storage, by manually plugging each storage de- vice into the host machine 20 times As shown in Table 2, Kingston 2G takes 34300 ms on average while SanDisk 16G needs 122|,Non-data,83
|58 ms Compared to these products, the Gum- stix board we use for ProvUSB is much faster, spending only 6538 ms to finish the enumeration This is due to the host kernel quickly recognizing the device as a USB storage gad- get and loading the corresponding driver immediately|,Non-data,83
| The time required by ProvUSB is 85074 ms on average This is high compared to commercial products, but this is a one- time effort per session or plugging Less than one second is required to mount a partition|,Non-data,83
 248Figure 7: ProvUSB throughput (M B/s) using fileserver workload with differ- ent file sizes 8: Figure fileserver throughput (M B/s) comparison of different devices with different mean file sizes Provenance Figure 9: storage us- ing fileserver workload with different mean file sizes Figure 10: Block control storage us- ing fileserver workload with different mean file sizes,Non-data,83
| Figure 11: Provenance overhead with ProvUSB optimization using Direct I/O with different read-write ratios Figure 12: Performance comparison of different USB devices using real-world workloads 63 I/O Operations To measure the runtime performance of ProvUSB, we used filebench [62] to benchmark throughput and latency, then compared the results to the Kingston and SanDisk devices|,Non-data,83
| We chose the fileserver workload model within filebench as the testing base, because it covers all file related opera- tions, including read, write, create, open, close, delete, and stat However, as fileserver was designed to benchmark file servers, to reflect a plausible usage pattern for a USB storage device, we changed the default configuration as fol- lows: The mean file size in operation ranged from 1 KB to 10 MB; the number of files in total was fixed at 20; the num- ber of operation threads was set to 1; the I/O size was fixed to 1024 bytes, and the run time was fixed to 60 seconds We selected this configuration to represent a single user making rapid edits to a set of documents, which is a more realistic usage pattern for a USB device The throughput of ProvUSB under different configura- tions is shown in Figure 7|,Non-data,83
 Original signifies the origi- nal Gumstix device without ProvUSB functionality enabled ProvFlush refers to the ProvUSB device synchronously flush- ing provenance once created ProvSave is the ProvUSB device using the optimized provenance logging method de- scribed in Section 35,Non-data,83
| When the file size is small (1 KB and 10 KB), ProvUSB achieves roughly half of the throughput of the original device Intuitively, the cost of creating a new provenance record remains the same regardless of the size of the file being accessed As such, ProvUSB still needs to examine a large number of blocks when files are distributed sparsely in the filesystem, since each file holds the whole block (cluster) even if it is small As the mean file size grows (from 100 KB to 10 MB), both ProvFlush and ProvSave demonstrate throughput similar to the original device|,Non-data,83
| For example, when the file size is 10 MB, the throughput of Orig- inal is 60 MB/s, while that of both ProvFlush and ProvSave are 54 MB/s (10% overhead) Comparing ProvUSB to the unmodified Gumstix Overo COM may not be representative of overhead imposed on commercial USB storage devices|,Non-data,83
| To address this, we then compared ProvUSB’s original device performance on the same benchmark against commercial storage devices from Kingston and SanDisk The results are shown in Figure 8 Kingston 2G demonstrates a high throughput jump when the mean file size is bigger than 1 MB, but the lowest throughput when the mean file size is small SanDisk 16G shows better throughput compared to Kingston 2G when the mean file size is small, and maintains the throughput at around 7 MB/s when the mean file size is greater than 1 MB|,Non-data,83
| The original ProvUSB device has the best through- put when the mean file size is small, and a comparable throughput with SanDisk 16G when the mean file size is 10 MB In general, as the mean file size increases, the utiliza- tion of each block gets better, as well as the utilization of transmission bandwidth of storage devices The corresponding latencies for the tests from Figures 7 and 8 are shown in Table 3 Both ProvFlush and ProvSave perform comparably to the original device when the mean 249Device/Configuration 1K 10K 100K 1M 10M 11|,Non-data,83
9 1055 7686 123 104,Non-data,83
8 8976 135 1113 856,Non-data,83
5 934 3866 701 722,Non-data,83
4 10 31 29 48,Non-data,83
5 423 623 35 10,Non-data,83
3 Kingston2G SanDisk16G ProvFlush ProvSave 21 36 35 Original 4,Non-data,83
|3 Table 3: Latency (ms) of ProvUSB under different config- urations, Kingston 2G, and SanDisk 16G devices using the fileserver workload with different file sizes file size is smaller than 10 KB due to the sparse block allo- cation for small files With a 10 MB file size, ProvFlush im- poses 168% overhead while ProvSave introduces 11|,Non-data,83
|4% over- head compared to the unmodified device Kingston 2G’s la- tency is largest when the mean file size is smaller than 1 MB, but smallest when the mean file size is 10 MB, which also explains its throughput behavior We suspect that its USB microcontroller is optimized for large bulk data transfer, and the result is reflective of realistic workloads on this device Aligned with its throughput model, SanDisk 16G shows sim- ilar latencies with ProvFlush and ProvSave’s when the mean file size is small, and latencies comparable to the unmodi- fied device as the mean file size increases|,Non-data,83
| ProvUSB devices thus perform comparably to commercial devices, providing a realistic assessment of overheads we introduce if our mech- anisms are deployed on production devices 64 Provenance Collection To evaluate the provenance storage costs introduced by ProvUSB, we measured the provenance log size during the filebench testing As shown in Figure 9, both ProvFlush and ProvSave generate around 800 KB of provenance, when the mean file size is 1 KB|,Non-data,83
| Besides the total number of files (20) in operation, the main reason for this relatively large amount of provenance is the large number of I/Os (read and write) performed by filebench given the running time, as a result of the small file size In this case, ProvFlush and ProvSave have 305 and 329 I/Os respectively This also ex- plains why the throughput and latency of ProvUSB are not optimal when the mean file size is small (< 10 KB) As the mean file size increases, the overhead of provenance logging decreases, since each I/O takes more time, and filebench does not repeat the same I/O multiple times|,Non-data,83
| For exam- ple, when the mean file size is 100 KB, ProvFlush has 80 I/Os, whereas ProvSave has 73 I/Os in total If we assume the total amount of data is 200 MB (10M B × 20, based on the fileserver workload configuration) when the mean file size is 10 MB, the provenance storage takes around 120 KB, introducing only 006% storage overhead In addition to provenance logging, ProvUSB also tracks the integrity level of each block|,Non-data,83
| This block control infor- mation is loaded automatically every time the ProvUSB de- vice powered on, helping enforce persistent block-level pol- icy control As shown in Figure 10, regardless of the dif- ferent scale of the provenance storage overhead, the block control storage pattern looks almost the same as the prove- nance storage, demonstrating that write operations are dom- inant in the filebench benchmark In our testing, we find that the number of write I/Os usually doubles the num- ber of read ones, which is the behavior of filebench using the fileserver workload To mitigate the impact of re- peated I/Os during the workload, we compute the average Provenance per I/O 1K 10K 100K 1M 10M 2|,Non-data,83
76 278 314 1191 148,Non-data,83
80 275 278 317 11,Non-data,83
32 14820 ProvFlush ProvSave Table 4: Provenance overhead (KB) of ProvUSB per I/O using the fileserver workload with different file sizes KVM Storage Size ClamAV Workload Files 581 MB 152 MB 581 MB 186 KB 81 KB 471 KB 003% 0,Non-data,83
|05% 007% Provenance Overhead Tor Table 5: Provenance storage overhead using ProvUSB (ProvFlush) is less than 01% for different workloads provenance overhead (provenance + block control storage) per I/O, as shown in Table 4|,Non-data,83
| Even when file size is small (< 10KB), both ProvFlush and ProvSave show a decrease in overhead due to reduced interaction with the filesystem, such as searching the allocation table and updating file meta- data As the file size increases, the overhead of provenance is amortized accordingly For instance, when the file size is 10 MB, the provenance overhead is no more than 15% of the original storage|,Non-data,83
| The difference between ProvFlush and ProvSave is ob- scured in filebench, as shown in Figure 9 and Table 4, due to the effect of the system cache (page cache) in the Linux kernel, which may buffer a significant portion of the USB storage partition in memory To verify the advantage of ProvSave, we used direct I/O (bypassing the system cache) to read or write the Linux kernel 44 zipped source file (83 MB) 100 times for 6 runs, each of which randomly gener- ated the read-write ratio based on a uniform distribution from 0 to 1 We then measured the provenance log size for ProvFlush and ProvSave with the proportion of writes rang- ing from 0% to 50%|,Non-data,83
| The results are shown in Figure 11 As the proportion of writes increases, the provenance stor- age overhead increases almost linearly in ProvSave, from 0 KB to 2 MB, whereas the storage overhead in ProvFlush stays almost constantly at 26 MB, since ProvFlush does not distinguish read operations from write ones to filter loggings When the probability of write operations is less than 40%, ProvSave reduces provenance storage cost by over 50%|,Non-data,83
| While system cache is desirable, large volume USB storage (eg, large external hard drives) would benefit from ProvSave since only a small portion of the storage can be cached Applications bypassing the system cache (e|,Non-data,83
|g, databases) would also benefit from ProvSave The size of the block integrity storage stays the same (5696 bytes) during the testing regardless of the number of write operations 6|,Non-data,83
|5 Real-world Workloads To arrive at a more accurate estimate of ProvUSB’s per- formance in practice, we chose three real-world workloads using USB storage devices, then compared the performance of ProvUSB (ProvFlush) against the Kingston and SanDisk devices In the KVM workload, an Ubuntu 1404 image was loaded from the storage device to create and install a KVM virtual machine automatically on the host machine The Tor workload benchmarked the portable Tor browser in storage devices by accessing the browser performance benchmarking web site [4]|,Non-data,83
| The final workload unzipped the Ubuntu 1404 image file in device storage and then ran ClamAV [39] to 250scan the whole image directory for virus All measurements are in seconds, as shown in Figure 12, except the Tor mea- surement, which are scores given by the benchmarking web site, and are divided by 10 to fit into the figure Compared to commercial USB devices, ProvUSB takes less time to finish the new virtual machine creation and in- stallation|,Non-data,83
| In the Tor browser benchmarking, all the three devices share similar scores Within the ClamAV virus scan- ning benchmark, ProvUSB doubles scanning time compared to the other two devices This is not surprising consider- ing that unlike with the KVM and Tor workloads, where not all the files within the storage are needed to finish the task, a normal virus scanning has to touch every file in the storage to fulfill the job To confirm the effect of system caching on system performance, we relaunched ClamAV im- mediately after completion of the first test|,Non-data,83
| As expected, scanning completes much faster in the second iteration (ap- prox 20 seconds) regardless of which storage device is used The corresponding provenance logging by ProvUSB was also collected for all workloads, shown in Table 5 Compared to workload file size, the overhead of provenance storage is consistently less than 0|,Non-data,83
|1% The ClamAV workload gener- ates the most provenance, providing more insight as to why ProvUSB imposes higher performance overhead during virus scanning In the majority of cases, enabling provenance col- lection mechanisms has little effect on real-world workloads 6|,Non-data,83
6 Case Study We now present a scenario in which ProvUSB can help to track (and possibly prevent) the spread of malware The Stuxnet virus leveraged multiple USB-based attack vectors in an attempt to spread to its intended targets One of these methods of propagation was to embed a malicious payload in an autoruninf file on the storage device [18],Non-data,83
| Until recently, this file denoted a special system script that was automatically executed by Windows operating systems upon connecting a device to the host In this scenario, we have an administrator Alice (Host A) and a normal user Bob (Host B), and Bob’s host has been infected with Stuxnet Alice has used Host A to configure and distribute ProvUSB devices throughout the organiza- tion, including installing a policy that marks Host A as high integrity (H) and Host B as low integrity (L) In an at- tempt to deliver a critical system patch, Alice now plugs her ProvUSB device into the infected Host B|,Non-data,83
| Case 1: Detect Malware Propagation Once the storage is plugged into Host B, Stuxnet writes a malicious au- toruninf to the device, yielding the provenance record <201509161750,B,w,2505,1282560,512>, consisting of a timestamp, host machine identifier, operation, block num- ber, file offset, and amount Let us assume that block 2505 is the only block needed to save the file|,Non-data,83
| While the storage partition of the device has been infected, ProvUSB is able to collect provenance as normal Eventually, Alice may dis- cover the infection on one of the hosts in her network She can then use the f2b tool to identify the blocks associated with autoruninf, query the provenance to reconstruct the chain of infections, and prepare a recovery plan|,Non-data,83
| Case 2: Integrity Assurance Using Host A, Alice has configured her ProvUSB device to automatically run diag- nostic utilities on the host via an autoruninf script As a result, prior to the attack ProvUSB will possess a block con- trol record <2505,H> marking block 2505 as high integrity|,Non-data,83
| When Alice plugs her device into Host B, Stuxnet will again attempt to infect the device ProvUSB will compare the access request <w,2505,integrity(B)> against the integrity label <2505,H>, and transition the block’s integrity label to <2505,L> When Alice plugs the device back into Host A, block 2505 will not be permitted to flow to the high integrity host This example demonstrates that integrity protection can be enabled on any critical system blocks on a ProvUSB device, preventing low integrity objects from flowing to high integrity hosts, thereby quarantining sensitive machines in the network from USB-borne malware|,Non-data,83
| 7 DISCUSSION Smart Storage Devices: While low cost USB thumb drives cannot run their own operating systems, a variety of enterprise devices contain CPUs or cryptographic coproces- sors, including products from IronKey [32] and Kingston [38] We believe these devices already contain the necessary hardware to support adapted versions of ProvUSB There are many embedded devices in the market that support full operating systems|,Non-data,83
| Gumstix Thumbo [26] runs an ARM processor and embedded Linux Intel Edison [29] and Google Project Vault [24] provide OS distributions in an SD-card form factor USB Armory [30] embeds an ARM processor and Linux in the USB stick Given this trend of increasingly sophisticated storage devices, we are confident that device provenance is achievable for USB storage|,Non-data,83
| Provenance Relay: With ProvUSB, provenance logging requires less than 01% storage overhead compared to the workload file size of a given benchmarking run Never- theless, the device would run out of space given enough time, depending on the storage size and the frequency of workloads Ideally, provenance should be relayed to a trusted server using a secure channel directly by the device itself|,Non-data,83
| Enterprise versions of some secure USB devices (eg, IronKey) are already capable of communicating with such a server [31] When networking is not viable, we rely on the owner or sysadmin of the device with root permission to export the provenance manually, making sure enough space is left for normal functionality|,Non-data,83
| Unlike provenance logging, block integrity information is always kept within the device to consistently enforce policy control within the device This space could be reserved based on the storage size, For example, a 16 GB storage with 33,554,432 blocks (assuming 512 bytes per block) needs 268 MB in total, since we require 8 bytes per block to store integrity metadata System Caching: As a side effect of caching in the host operating system, the timestamps for some ProvUSB prove- nance records do not accurately reflect the actual access time Modern operating systems apply multi-layer caches to improve the performance of USB storage|,Non-data,83
| For instance, when mounting a smaller storage partition (1 GB), we observed that the Linux kernel reads most storage into the page cache to speed up future operations Once data is in the page cache, I/O operations for the USB storage partition occur in memory, outside of the view of the USB storage driver When write operations occur, a dedicated kernel thread periodically flushes data to the block device (write-back) A by-product of this behavior is a reduction in benefit of ProvUSB’s provenance storage optimization, shown in Figure 9, though the optimization is still useful for large storage and certain applications|,Non-data,83
| Fortunately, host caching does not impact the forensic validity of block 251provenance collected by ProvUSB Provenance is eventually generated for all writes to USB storage, and for the first read to a given block after enumeration Although repeated reads to the same block may be masked by host-level caching, it is known that the host accessed the block Filesystem Integrity: In order for ProvUSB devices to be mounted by high-integrity hosts, blocks containing the filesystem’s metadata need to be made world read-writable|,Non-data,83
| This leaves a small window of opportunity for malware propagation If attackers discover an exploitable bug in the host’s filesystem subsystem, this may allow them to infect the host and the device Otherwise, this offers limited ad- vantage to attackers, as writing data to the filesystem blocks would merely result in corrupting the storage partition We are not aware of any malware that propagates through the filesystem metadata of a USB storage device|,Non-data,83
|2 8 RELATED WORK need for smart USB storage devices armed with advanced features has been well noted both by industry and in the literature By running the Knoppix OS on a USB storage device, C ́aceres et al take snapshots of a running operating system that can later be resumed in another virtual ma- chine [14]|,Non-data,83
| Surie et al use a smart USB device to measure the software stack of host machines, but not a hardware- based root of trust, and are therefore vulnerable to software attacks targeting the BIOS, bootloader or kernel [63] Mc- Cune theorizes that host system state can be attested via USB, but does not design or implement a system [44] Bates et al|,Non-data,83
| measure timing characteristics during USB enumer- ation to infer characteristics of the host machine, but are unable to reliably identify specific instances of similar ma- chines [6, 42] By leveraging the TPM in the host machine, Butler et al design and implement Kells [12], exposing the private partition of USB storage based on the measurement of host machines Tian et al|,Non-data,83
| propose GoodUSB [67] and USBFILTER [68] to defend against malicious USB firmware in the devices for host machines, while Cinch [3] leverages virtualization to achieve the same goal For traditional storage systems, Gibson et al’s NASD adds secure capabilities to SCSI disks [23] Strunk et al|,Non-data,83
’s self-securing storage (S4) mitigates attempts to tamper with data by internally auditing all requests from the OS [61] Both NASD and S4 operate at the high-level ob- jects rather than the low-level blocks directly Pennington et al present a storage-based intrusion detection system [53],Non-data,83
| Unlike ProvUSB which is designed to be filesystem agnostic, Sivathanu et al’s semantically-smart disks (SDS) leverage filesystem information to improve performance of the standard SCSI interface [60] and database management systems [59] Butler at al design rootkit-resistant storage by labeling certain blocks as immutable to prevent the corruption of the operating system [13], but do not record data provenance or ensure integrity of other data blocks|,Non-data,83
| Data provenance provides a means for defending against security threats Provenance has been employed to detect compromised nodes in data centers [5, 21, 65, 74], detect data exfiltration [35, 41], enrich access controls [7, 50], and 2However, some filesystems, eg, NTFS, allow storing small files into metadata|,Non-data,83
| In this case, the provenance of ProvUSB devices still works, though the block-level policy control may not be easily extended to cover metadata enforce regulatory compliance [7, 8] Mechanisms that fa- cilitate the capture of provenance have been proposed for a variety of system layers including filesystems [46, 47], oper- ating systems [8, 22], system libraries [27], workflow engines [2, 15], and network middle boxes [5, 74], among others Whereas past approaches such as PASS focused on a par- ticular filesystem type (EXT2 [47]), ProvUSB is compatible with any SCSI storage devices regardless of filesystems|,Non-data,83
| 9 CONCLUSION Modern USB storage devices do not support provenance, which means that there is no way to answer questions such as when and where a piece of malware infected and impacted the system In this paper, we presented ProvUSB, which adds provenance for each I/O operation at the block level and enforces a provenance-based integrity policy for each block ProvUSB introduces a small overhead (< 1s) during device enumeration, reaches 90% throughput as mean file size increases, and imposes only a small provenance storage overhead (< 0|,Non-data,83
|1%) in real-world workloads To our knowl- edge, ProvUSB is the first provenance-aware USB storage solution that enforces data integrity within storage, work- ing at the ubiquitous, non-circumventable block layer Acknowledgements This work is supported in part by the US National Sci- ence Foundation under grant numbers CNS-1563883, CNS- 1540217, and CNS-1540218, and by the Florida Center for Cybersecurity (F C 2) seed grant program 10|,Non-data,83
|ABSTRACT Cache side-channel attacks have been extensively studied on x86 architectures, but much less so on ARM processors The technical challenges to conduct side-channel attacks on ARM, presumably, stem from the poorly documented ARM cache implementations, such as cache coherence protocols and cache flush operations, and also the lack of understand- ing of how different cache implementations will affect side- channel attacks This paper presents a systematic explo- ration of vectors for Flush-Reload attacks on ARM pro- cessors Flush-Reload attacks are among the most well- known cache side-channel attacks on x86|,Non-data,85
| It has been shown in previous work that they are capable of exfiltrating sensi- tive information with high fidelity We demonstrate in this work a novel construction of flush-reload side channels on last-level caches of ARM processors, which, particularly, ex- ploits return-oriented programming techniques to reload in- structions We also demonstrate several attacks on Android OS (eg|,Non-data,85
|, detecting hardware events and tracing software ex- ecution paths) to highlight the implications of such attacks for Android devices Keywords Cache side channels; flush-reload 1 INTRODUCTION Cache side-channel attacks have been gaining attraction in recent years, in part due to their noteworthy security impli- cations in computing environment where processor caches are shared among mutually distrustful software programs, eg|,Non-data,85
|, public multi-tenant clouds Due to the popularity of x86 processors in cloud data centers, most prior studies on cache side-channel attacks focus on x86 architectures In contrast, much less research has been done on side-channel attacks on ARM architectures Although it is tempting to presume similar attacks can be easily migrated from x86 to ARM processors, in fact due to significant differences in the cache design and implementation, conclusions drawn Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page|,Non-data,85
| Copyrights for components of this work owned by others than the author(s) must be honored Abstracting with credit is permitted To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acm|,Non-data,85
|org CCS’16, October 24 - 28, 2016, Vienna, Austria © 2016 Copyright held by the owner/author(s) Publication rights licensed to ACM ISBN 978-1-4503-4139-4/16/10|,Non-data,85
   $1500 DOI: http://dx,Non-data,85
doiorg/101145/29767492978360 on Intel processors about these hardware-dependent security threats cannot be directly applied to ARM,Non-data,85
| To date, we have not seen much work on the exploitability of ARM caches in side-channel attacks Such studies, however, are of growing significance due to the increasing popularity of ARM pro- cessors in mobile devices and even cloud servers [20] In this paper, we present a systematic exploration of Flush- Reload side-channel attacks on ARM caches Flush-Reload attacks have been extensively studied on x86 platforms and are well known for their high accuracy and efficiency|,Non-data,85
| The adversary who has control of an application running on a shared computer system can exploit the unprivileged clflush instruction on x86 to Flush cache lines out of the entire cache hierarchy, and then measure the time to Reload it back The key to the attack is that such flush operations, though taking virtual addresses as input, work on physical addresses of a cache line, so that cache lines shared with a victim application will also be evicted in the procedure Therefore, the time to Reload the cache line back reveals whether this line has been recently (after Flush and before Reload) accessed, and thus loaded into the shared cache, by the victim application (ie|,Non-data,85
|, fast Reload) or not (ie, slow Reload) However, replicating the Flush-Reload attacks on ARM is not as straightforward as one might imagine|,Non-data,85
| The fol- lowing research questions are yet to be explored: First, what is ARM’s alternative for x86’s unprivileged clflush instruction? Second, without a user-space accessible high- precision clock, eg, x86’s rdtsc, how does the adversary measure time with high fidelity on ARM (to perform this timing attack)? Third, how does ARM’s cache coherence (eg|,Non-data,85
|, point of coherency/unification [10], inclusiveness of last-level caches) affect Flush-Reload attacks? Unfortu- nately, none of these questions has been answered in prior research Many of these questions (eg, the first one) are even considered the fundamental obstacles for conducting such attacks on ARM1 [50]|,Non-data,85
| Our exploration of these questions is driven by Android operating systems (OS) that run on ARM processors An- droid is arguably the most popular operating system in mo- bile devices We aim, in exploring these research questions, to demonstrate practical cache side-channel attacks on com- modity Android-based smartphones from zero-permission An- droid apps However, we stress the results might be ex- 1 It was asserted that “ARM architecture does not allow user pro- cess to selectively evict memory lines and the Flush-Reload is not applicable in this architecture” [50]|,Non-data,85
| 858tended to iOS and other computing environments should they be powered by ARM processors More specially, in this paper, we show a cross-core Flush- Reload side-channel attack on ARM that operates in ways that are similar to return-oriented programming (ROP) at- tacks The first notable novelty in this attack is the use of a cache-flush interface that is available on ARM-based operating systems This interface is designed to support self-modifying code (e|,Non-data,85
|g, Just-in-Time compilation) due to ARM’s lack of coherence between data caches and instruc- tion caches—instruction caches must be flushed explicitly to reflect changes made in data caches The exact implemen- tation of this interface, however, is processor-specific (see Sec 3|,Non-data,85
|2) Particularly, on our testbed, a Samsung Galaxy S6 smartphone, we are constrained to conduct Flush-Reload attacks using instruction Flushes and Reloads, which in contrast to previously shown Flush-Reload attacks on data caches, is a brand new attempt However, efficient exploita- tion of instruction Reloads is non-trivial We show by clev- erly leveraging gadgets in shared libraries, an adversary may redirect the control flow of cache Reloads to instructions in the libraries and return back from the gadgets immedi- ately after loading the cache lines into the shared last-level cache (LLC)|,Non-data,85
| This type of instruction-based Reloads ef- fectively and efficiently replace the conventional data-based Reloads We call our new construction of Flush-Reload attacks on ARM the return-oriented Flush-Reload attacks We further demonstrate two categories of attacks on An- droid enabled by our presented Flush-Reload side chan- nels: detecting hardware events and tracing software exe- cution paths We particularly show our attacks can detect the occurrence of touchscreen interrupts with high fidelity, therefore enabling the unlock pattern inference attack shown in [21] even without procfs; detect the use of hardware com- ponents, e|,Non-data,85
|g, scanning credit cards using the camera from an Uber app, thus facilitating other attack goals (such as those in [19, 31]); detect updates in the frame buffer of the smart- phone display, hence monitoring the user’s private actions on the device We argue the applicability of the attacks is beyond these examples, and we leave a thorough exploration of attack spaces as future work Contributions|,Non-data,85
| To summarize, we make the following con- tributions in this paper • A systematic exploration of vectors for Flush-Reload side-channel attacks on ARM in two aspects: cache flush operations and last-level cache inclusiveness Particu- larly, we study the effects of the clearcache system call on the caches of five different ARM processors We also design novel approaches to programmatically determine the inclusiveness of ARM’s last-level caches|,Non-data,85
| • A novel construction of return-oriented Flush-Reload cache side-channel attacks on ARM processors that work on last-level caches To our knowledge, our paper presents the first attempt to implement Flush-Reload side chan- nels on ARM Conducting these attacks in return-oriented manners by exploiting gadgets in shared libraries is also innovative • A demonstration of the presented Flush-Reload at- tacks in Android|,Non-data,85
| We show these cache-based side chan- nels have similar power as many procfs-based side chan- nels, and therefore opening new, and hard to mitigate, attack vectors once procfs side channels are eliminated We also show novel UI tracing attacks to illustrate the new capabilities of our Flush-Reload attacks compared to existing side-channel attacks in Android Roadmap In the rest of the paper, we first provide the background knowledge of ARM processors and cache side- channel attacks in Sec|,Non-data,85
 2 A systematic exploration of ARM’s cache flush operations and cache coherence implementation is presented in Sec 3 We then elaborate our construction of the return-oriented Flush-Reload side channels on ARM processors in Sec,Non-data,85
| 4 Next, we demonstrate two categories of security attacks on Android that are enabled by our side channels in Sec 5 Countermeasures to our attacks are dis- cussed in Sec|,Non-data,85
| 6 and related work in Sec 7 Finally, we con- clude the paper in Sec 8|,Non-data,85
| 2 BACKGROUND 21 ARM Cache-Memory Hierarchy Similar to x86 processors, ARM processors also adopt a modified Harvard architecture, in which the upper-level caches (eg|,Non-data,85
|, L1) are split into instruction caches and data caches so that the processors can access the data bus and instruction bus simultaneously, while the lower-level caches (eg, L2) and the main memory are unified so instructions can be manipulated as data Supporting self-modifying code|,Non-data,85
| One difference be- tween ARM and x86 processors is that ARM does not main- tain coherence between the main memory and instruction caches [10] As such, memory writes to the code sections will not be automatically reflected in the instruction cache, causing the processors to execute staled code This de- sign feature affects the processors’ capability to execute self- modifying code, which is common in Just-in-Time compi- lation Accordingly, operating systems, e|,Non-data,85
|g, Android OS, provide a system call (ie, clearcache) to flush a range of virtual addresses out of the caches|,Non-data,85
| This system call in im- plemented in the kernel by instructing the cp15 coprocessor Inclusive vs exclusive LLCs An inclusive LLC, in the case of most ARM processors—the L2 cache, guarantees that every cache line in the L1 cache also has a copy in the L2 cache|,Non-data,85
| In contrast, if the L2 cache is exclusive to L1, only one copy of the same memory block is stored in ei- ther the L1 cache or the L2 cache A third option is usually called non-inclusive cache [29], which behaves in between of the other two—a cache line evicted out of the L2 cache is not also evicted from the L1 cache Processors may implement different LLC inclusiveness For example, older Intel proces- sors (e|,Non-data,85
|g, Core 2 processors) have non-inclusive L2 caches; recent Intel processors all come with inclusive L3 caches; in contrast, AMD processors usually have exclusive LLCs [27] ARM’s L2 caches can be configured to be inclusive, exclusive or non-inclusive to L1 instruction or data caches 2|,Non-data,85
|2 Cache Side-Channel Attacks Sensitive information of a software program can be leaked through CPU caches Because the cache data cannot be read by the adversary directly, such leakage is usually indi- rect, through “side” information Therefore, this type of at- tacks is called cache side-channel attacks Prior studies have explored three types of cache side channels: time-driven, access-driven and trace-driven|,Non-data,85
| They differ in their threat models Time-driven attacks assume only the overall execu- tion time of certain operation is observable by the adversary; 859trace-driven attacks assume the adversary is able to observe the power consumption traces of the execution; and access- driven attacks assume the adversary has logical access to a cache shared with the victim and infers the victim program’s execution through its own use of the shared cache In this paper, we study access-driven cache side-channel attacks on ARM The other two types are less practical in either their threat models (e|,Non-data,85
|g, knowledge of power con- sumption in trace-driven attacks) or their unrealistic as- sumptions (eg, assumptions of noise-free network commu- nication in time-driven attacks)|,Non-data,85
| Access-driven attacks can be performed in several ways Here, we highlight two ap- proaches that are widely studied in recent years: Prime- Probe [37] and Flush-Reload [23] We omit variations of these attacks, such as Flush-Flush and Evict-Reload Prime-Probe attacks work on cache sets|,Non-data,85
| By pre-loading every cache line in the target cache set with his own memory blocks, the adversary makes sure his future memory accesses (to these blocks) will be served by the cache, unless some of the cache lines are evicted by the victim program during its execution Therefore, his own cache misses will reveal the victim’s cache usage in the target cache set In Flush- Reload attacks, the adversary shares some physical mem- ory pages (eg|,Non-data,85
|, through dynamic shared libraries) with the victim By issuing cache flush instructions (eg, clflush on x86) on certain virtual address range (mapped to the shared pages), the adversary can flush the (physical) cache lines that correspond to this address range out of the entire cache hierarchy|,Non-data,85
| Therefore future reading (ie, Reload) of the cache lines will be slower because they are loaded from the memory, unless they have been accessed by the victim (and thus have been fetched into the shared cache) 2|,Non-data,85
|3 Threat Model We assume the adversary is a regular Android app with no additional permission than the default settings Moreover, we do not assume the device itself is rooted to facilitate the attack (eg, through kernel extensions)|,Non-data,85
| To differentiate our attacks from prior work on procfs-based side channels (see Sec 7), we do not require this third-party app to have access to procfs As such, our attack will work even when these side channels are eliminated The only assumption we need to make is that the malicious app is packaged together with a native component that is compiled with Android NDK|,Non-data,85
| This configuration is very common on Android app markets According to a recent study published in 2016, at least 37% Android apps execute native code [14] 3 DISSECTING ARM CACHES Unlike their counterparts in x86 processors, caches in ARM processors are much less understood in the context of side- channel attacks|,Non-data,85
| In order to exploit ARM caches for Flush- Reload side-channel attacks, we need to understand how ARM caches operate in both Flush and Reload operations More particularly, we aim to explore the follow aspects: • Cache flush interfaces The cache flush interfaces on x86 is well documented: the entire cache hierarchy can be invalidated together using the privileged WBINVD in- struction, and individual cache lines can be flushed us- ing the unprivileged clflush instruction In contrast, no userspace-accessible cache flush instruction is available on ARM|,Non-data,85
| We will study a less-known attack vector— clearcache system call—on Android OS, and determine its impact on all levels of caches • Cache inclusiveness The cache coherence design, partic- ularly inclusiveness of the last-level cache to upper-level caches, is crucial to cross-core Flush-Reload attacks: Whether the victim’s memory access on a different CPU core will affect the adversary’s Reloads However, such information is seldom mentioned in ARM specification or manufacturers’ documentation2|,Non-data,85
| We aim to design novel methods to empirically determine cache inclusive- ness from Android apps In this section, we empirically evaluate these cache proper- ties on three most popular Android smartphones, ie, Sam- sung Galaxy S5 and S6 and Google Nexus 6, and the five processors they are equipped with|,Non-data,85
 The Samsung Galaxy S5 implements an octa-core architecture—one quad-core 19 GHz Cortex-A15 CPU and one quad-core 13 GHz Cortex- A7 CPU—on the Exynos 5422 system-on-chip (SoC) The Samsung Galaxy S6 is equipped with one quad-core 1,Non-data,85
|5 GHz Cortex-A53 CPU and one quad-core 21 GHz Cortex-A57 CPU, on the Exynos Octa 7420 SoC Google Nexus 6 comes with single quad-core Krait 450 processors on the Snap- dragon 805 SoC Cortex-A53 and Cortex-A57 are based on 64-bit ARMv8, while other CPUs are 32-bit ARMv7-based|,Non-data,85
| Roadmap of the section In Sec 31, we study the la- tency of several available clocks on Android to perform our timing channel attacks|,Non-data,85
| In Sec 32, we explore the effects of clearcache system call and in Sec 3|,Non-data,85
|3, we empirically de- termine the LLC (ie, L2) inclusiveness to both L1 caches on these processors We discuss our findings in Sec|,Non-data,85
 34 31 Time Measurement Facilities Android apps do not enjoy the unprivileged rdtsc instruc- tion available to their x86 counterparts,Non-data,85
| However, accurate and low-latency time measurement is critical to cache tim- ing attacks on ARM In this section, we examine the latency of the POSIX clock_gettime system call, which is a fine- grained time measurement facility that is accessible in all Android versions We considered using clock_gettime() with three clocks: CLOCK REALTIME, CLOCK MONOTONIC, and the per-thread clock CLOCK THREAD CPUTIME ID To se- lect one clock with minimum latency, we conducted the fol- lowing experiments: In an Android app compiled with NDK on Samsung Galaxy S6, we used one of the three clocks to measure the execution time of a loop that is expected to consume (roughly) constant time|,Non-data,85
| We show in Fig 1 the measurements of running 1, 2,··· , 10 of such loops using the three clocks, respectively The results shown are mean val- ues and one standard deviation of 20 runs The latency of each clock can be roughly estimated by the time measure- ments of executing i loops subtracting the estimated exe- cution time of i loops|,Non-data,85
| From the figure, we can see that CLOCK REALTIME and CLOCK MONOTONIC per- forms much better in terms of measurement latency (ie, roughly 130 ns) than CLOCK THREAD CPUTIME ID (ie|,Non-data,85
|, about 780 ns) In our paper, the monotonic clock was chosen because the other may be unexpectedly adjusted by Network Time Protocol (NTP) daemon 2 Prior knowledge on cache inclusiveness of a particular processor im- plementation is only available through anecdotes [42] 8603|,Non-data,85
|2 Cache Flushes We empirically study how the clearcache sys- tem call can be used in Flush-Reload at- tacks We focused, however, only on its effects on instruction caches, because the ker- nel source code that implements the clearcache system call only cleaned the data caches but in- validated the instruc- tion caches3 Cache cleaning means writing dirty cache lines out to the next level of cache/memory hierarchy and then clear the dirty bits; cache invalidation means clearing the valid bits of the cache lines [2] Therefore, it is only necessary to conduct exper- iments to understand the behavior of clearcache on the instruction cache—will the L1 instruction cache and the L2 cache both be flushed? Figure 1: Time measurement using three different clocks (evaluated on A53 running at highest frequency)|,Non-data,85
| We developed an Android app with Android NDK and a native shared library that exports a dummy library func- tion (consisting of “mov x0, x0” in the 64-bit version, and “mov r0,r0” in the 32-bit version), which, after compilation, occupies exactly 1KB of memory space To eliminate unex- pected side-effects, we intentionally aligned the offset of the beginning of the function to be a multiple of 4KB within the shared library Because of the coarse-grained address space layout randomization (ASLR) in Linux, when the library is loaded at runtime, the function will still be page-aligned The Android app dynamically linked this self-developed li- brary into their address space using dlopen at runtime|,Non-data,85
| Then it split into two threads, which used sched_setaffinity system call to pin themselves on two different cores sharing the same L2 cache In the following tests, all experiments were repeated 1000 times (run at the maximum CPU fre- quency) to measure the mean and standard deviation In the first experiment, thread A repeatedly executed the function code while thread B stayed idle The average time to execute the entire function in this way was measured as T1|,Non-data,85
| Essentially, T1 measures the time to execute the function from the L1 instruction cache (ie, all L1 cache hits) In the second experiment, while keeping thread B idle, thread A called the clearcache system call before starting to execute the function|,Non-data,85
| The time of the function execution itself was measured as T2 Hence T2 represents the effects of the clearcache system call on the local instruction cache and the unified L2 cache In the third experiment, while thread A executed the func- tion in the same way as the first experiment, thread B re- peatedly called the clearcache system call without any in- terval to flush the entire function The execution time of the function by thread A is denoted as T3|,Non-data,85
| Therefore, T3 reflects the effects of cross-core instruction cache flushing In the last experiment, we still kept thread B idle Thread A measured the time taken (T4) to execute the function 3 clearcache is implemented in the __flush_cache_user_range function in mm/cacheS of the Android’s kernel source code (v3|,Non-data,85
|109 on Galaxy S5 and Nexus 6, v31061 on Galaxy S6) Figure 2: Effects of clearcache on instruction caches|,Non-data,85
| code with L2 cache misses In order to achieve this effect, thread A cleansed the entire L1 instruction cache and uni- fied L2 cache in between of two function executions The method to do so with guarantees to cleanse the entire L1 and L2 caches, however, is not straightforward We developed our own method as described in Appendix B|,Non-data,85
 The results for running the experiments on all three smartphones (five CPUs) are shown in Fig 2 We will discuss these results shortly in Sec 3,Non-data,85
|4 33 Cache Inclusiveness We design a method using only cache timing to determine whether the L2 cache is inclusive, exclusive or non-inclusive to L1 data cache and L1 instruction cache, respectively To do so, we first developed a shared native library which ex- ports a dummy function (e|,Non-data,85
|g, 1KB) in exactly the same way as in Sec 32|,Non-data,85
| Then in the native component of an Android app, the following test was conducted: Detecting inclusive L2 caches In the first experiment, the function was loaded into the L1 data cache by reading each cache line The average time needed to load the entire function once is denoted T1 Then in the second experiment, the Android app completely cleansed the L2 cache without polluting the L1 data cache—by executing instructions as described in Appendix B—in between of two function code readings|,Non-data,85
| The time to read the function was measured as If T1 (cid:28) T2, T2 reflects L1 data (and also L2) cache T2 misses Therefore cleansing L2 cache from instruction cache also cleanses the L1 data cache, and therefore the L2 cache is inclusive to the L1 data cache Otherwise it is either exclusive or non-inclusive to the L1 data cache|,Non-data,85
| Because the same L2 cache may have different inclusive- ness to the L1 data cache and the instruction cache, we have to conducted a similar test for L1 instruction cache Spe- cially, the dummy function was executed and the time to complete one execution was measured as T1 Then in the second experiment, the L2 cache was cleansed completely from the data-cache side so that the instruction cache was not polluted (again, using method described in Appendix B) in between of two function execution The execution time was measured as T2|,Non-data,85
| If T1 (cid:28) T2, T2 represents L1 instruction (and L2) cache misses Hence, cleansing L2 cache from the data cache also cleanses the L1 instruction cache, and there- fore the L2 cache is inclusive to the L1 instruction cache Otherwise it is either exclusive or non-inclusive to the L1 instruction cache 12345loops0200400600800100012001400Time (ns)CLOCK_REALTIMECLOCK_MONOTONICCLOCK_THREAD_CPUTIME_IDKrait 450A15A7A57A53020004000600080001600020000T1T2T3T4861Smartphone Krait 450 (dcache) Krait 450 (icache) Cortex-A15 (dcache) Cortex-A15 (icache) Cortex-A7 (dcache) Cortex-A7 (icache) Cortex-A57 (dcache) Cortex-A57 (icache) Cortex-A53 (dcache) Cortex-A53 (icache) T1 1169 1020 2600 2484 3378 3551 223 150 325 275 T2 3700 4350 6469 5474 15460 15822 907 794 1633 1287 inclusiveness inclusive inclusive inclusive inclusive inclusive inclusive inclusive inclusive inclusive inclusive Table 1: L2 cache inclusiveness tests|,Non-data,85
| From Table 1 we can clearly see that on all the tested processors the L2 caches are inclusive to both data caches and instruction caches Therefore, there is no need to con- duct further experiments to distinguish exclusive and non- inclusive L2 caches However, we describe an algorithm in Appendix C with which these two types of cache implemen- tations can be programmatically differentiated We hope it can be helpful to other research on similar topics|,Non-data,85
| 34 Discussion Cache flushes In order to perform Flush-Reload side- channel attacks on the L2 cache, the flush operations must evict the targeted memory block out of (1) the local L1 caches, (2) the shared L2 cache, (3) and the L1 caches of If condition 1 is not met, Reload will only other cores if condition 2 is not met, Reload will observe L1 hits; only observe L2 hits; if condition 3 is not met, the victim can continue using its local copy, so its operation will not make any changes to the shared L2 cache|,Non-data,85
| We already know data caches cannot be used Flush-Reload attacks because clearcache only cleans but not flushes the L1 data cache— condition 1 not met Moreover, as is seen from Fig 2, not all instruction caches on these ARM processors satisfy these requirements, either: T2 (local clearcache) and T3 (cross- core clearcache) of Krait 450, Cortex A15 and Cortex A7 are merely larger than T1 (L1 hits) and are much smaller than T4 (L2 misses) Therefore, clearcache does not flush the L2 caches on these processors (condition 2 not satis- fied)|,Non-data,85
| Cache flush operations on the instruction cache of Cortex A53 and A57 meet all three requirements: T2 and T3, though slightly less than T4, are significantly greater than T1—both the local L1 instruction cache and the L1 in- struction cache on other cores, and the shared L2 cache are flushed by the cache invalidation operation The difference of cache flush implementation can be ex- plained by the different implementation of point of coherency (PoC) and point of unification (PoU) on ARM [10] PoC specifies the point at which all CPU cores are guaranteed to observe the same copy of a memory block; PoU specifies the point at which the data cache and the instruction cache on the same core are guaranteed to see the same copy of a memory block However, ARM does not explicitly specify the choice of PoU and PoC, leaving them highly implemen- tation dependent|,Non-data,85
| Our conjecture, therefore, is that on A53 and A57 the PoU is implemented to be the memory, while on other processors the PoU is specified as the L2 cache sion property with L1 data caches [5, 6], but in all other cases, these properties are not specified and therefore are implementation dependent Conclusion Because the clearcache system call on Cor- tex A57 and A53 processors will flush instructions to the main memory, and at the same time the L2 caches on these processors are inclusive to the instruction cache, these two ARMv8 processors satisfy all requirements for conducting Flush-Reload attacks on shared instruction pages|,Non-data,85
| As they represent the latest processor generations on the mar- ket, we anticipate future processors may have similar fea- In this paper, we demonstrate Flush-Reload at- tures tacks on the instruction side of Samsung Galaxy S6 4 RETURN-ORIENTED FLUSH-RELOAD ATTACKS ON ARM In Sec|,Non-data,85
| 3, we have shown that on ARM Cortex A57 and A53 processors we are constrained to use only instruction caches in Flush and Reload operations Hence in this section, we first outline a basic construction of a Flush- Reload side channel on these processors by Flushing and Reloading instructions (Sec 41)|,Non-data,85
 Then we detail our novel design of return-oriented Flush-Reload side-channel at- tacks (Sec 42) We next empirically characterize the pre- sented return-oriented side channels (Sec,Non-data,85
 43) and discuss practical considerations of exploiting such side channels on Android (Sec 44),Non-data,85
 41 Basic Flush-Reload Side-Channel Attacks We first describe a basic construction of a Flush-Reload side-channel attack using the clearcache system call on An- droid The side channel works on shared LLCs (ie,Non-data,85
|, L2 caches) Therefore it can be exploited by an Android app to attack another running on a different CPU core The attacker Android app from which side-channel attacks are conducted is a zero-permission Android app packaged together with a native library The Java component of the app interacts with the native C code through standard Java Native Interface (JNI)|,Non-data,85
| To enable physical memory sharing between the attacker and victim apps, the native code uses the dlopen system call to dynamically link a certain shared library (ie, so file) used by the victim app into the attacker app’s own address space When the attack starts, the service component inside the attacker app creates a new thread, which calls into its native component to conduct Flush- Reload operations in the background: • Flush: The attacker app calls clearcache to flush a • Flush-Reload interval: The attacker app waits for a fixed time period (may be zero), during which the victim app may execute the function|,Non-data,85
 • Reload: The attacker app executes the function and measures the time of execution Shorter execution time indicates the function has been executed (thus fetched into the L2 cache) by some other apps (possibly the vic- tim app) during the Flush-Reload interval function in the code section of this shared library Inclusiveness,Non-data,85
| Table 1 suggests all the L2 caches we eval- uated are inclusive to both L1 data and instruction caches This is in line with the limited information available from ARM official documentations: According to ARM specifica- tions, Cortex-A57 and Cortex-A15 implement strict inclu- The primary difference between our work and previous study [16, 49, 50, 53] is that we exploit the instruction cache, while prior studies use the data cache Nevertheless, the seemingly minor distinction imposes considerable technical challenges to our attack First, to call library functions, the 862attacker app needs to re-construct the program semantics (e|,Non-data,85
|g, preparing parameters, global variables, etc) before calling, which is very tedious and does not work for some functions Second, the execution time of a function may vary from one run to another, which makes differentiating cache misses and cache hits very challenging in the Reload phase|,Non-data,85
| This is typically true if the function call also involves system calls Third, Flush and Reload take too much time; many fast victim operations will be missed by such slow Flush-Reload attacks To address these challenges, we next design a return-oriented Flush-Reload attack 4|,Non-data,85
|2 Return-Oriented Reloads Instead of calling the entire function in the Reload phase, we touch upon selected memory blocks of the function code in a return-oriented manner Particularly, much similar to control-flow hijacking attacks using return-oriented pro- gramming [18, 41], a number of small gadgets are collected from the target function, and then in our attacker app, an auxiliary function will be constructed to jump to these gad- gets (and then jump back) one after another The overall execution time of these gadgets will be measured as the out- come of the Reload phase It is important to avoid having more than one gadgets in the same 64-byte cache line, be- cause only the execution of the first gadget will fetch the memory block into the cache, and subsequent gadgets in the same cache line merely introduce noise|,Non-data,85
| The set of ARM instructions that can lead to indirect control flow transfers are listed in Table 2 On 32-bit ARM v7 architectures, bx Rm sets the current PC value to be the value of the register Rm (ie, indirect jump); blx Rm also sets the value of LR (i|,Non-data,85
|e, R14) to be the address of the next instruction before jumping to the address specified by Rm (ie, indirect call)|,Non-data,85
| Direct manipulation of PC is also allowed by using mov or pop or ldm instructions4 On 64-bit ARM v8 architectures, in addition to the difference in the size of the registers (64 bits), ret instructions are also available: ret instruction changes the PC value to the value of LR; ret Xm sets PC to the value stored in Xm rather than LR However, the PC register can no longer be manipulated directly on ARM v8 architectures Architecture ARM v7 (32 bit) ARM v8 (64 bit) Instructions bx LR bx Rm blx Rm mov PC LR pop {pc} ldm {pc} br Xm blr Xm ret Xm ret Effects PC := LR PC := Rm LR(R14) := next instr|,Non-data,85
| PC := Rm PC := LR PC := top of stack load multiple regs PC := Xm LR(X30) := next instr PC := Xm PC := Xm PC := LR(X30) Table 2: Indirect control-flow transfer instructions on ARM The gadgets used in our attack will be easier to construct compared to those in ROP attacks—our gadgets do not need to complete any meaningful operations We only need to jump to one of these indirect control transfer instructions 4 There are four variations of ldm: ldmia, ldmib, ldmda, ldmdb|,Non-data,85
 Their usage can be found in [3] (listed in Table 2) so that the memory block that holds the instruction is loaded into the cache The control flow will be immediately transferred back to the auxiliary function after the instruction is fetched and executed We illustrate the use of the 64-bit ret and blr Xm in- structions to construct gadgets in Fig,Non-data,85
| 3 In particular, in this example, the adversary hopes to Flush-Reload a func- tion, clock_gettime, in libcso To exploit the blr X4 in- struction as a gadget, the attacker app calculates the virtual address of the instruction at runtime (i|,Non-data,85
|e, the base address of the library’s code section plus the offset of the instruction within the library) Here, let’s assume the virtual address is 0x246a0 This address is first loaded into register X19, so that the control flow will be transferred to the gadget later by br X19|,Non-data,85
| The adversary then makes a copy of X30 to an- other register, say X20, because it will be modified by the gadget instruction blr X4 Then the adversary prepares the value of X4, the target address of blr X4, so that the control flow will be redirected back to the auxiliary function once the gadget is executed It is important to maintain the cor- rectness of the subsequent execution by restoring the value of X30 from register X20 Exploiting ret is much easier|,Non-data,85
| The adversary first stores the address of the gadget in a register, say X19 Then the control flow is transferred by blr X19, which sets the value of X30 to be the address of the next instruction and then changes the PC value to the address stored in X19 The control flow will be transferred back to the address stored in X30 by the ret instruction Figure 3: Examples of gadgets|,Non-data,85
| Availability of the reload gadgets To investigate the availability of the reload gadgets in Android shared libraries, we used objdump to disassemble five widely-used shared li- braries used on a 64-bit Android OS (Samsung Galaxy S6, Android version 511)|,Non-data,85
 We then wrote a Python script to count the number of indirect control transfer instructions and the number of useful gadgets (those in separate cache lines) in these libraries The results are listed in Table 3 Libraries libcso libc++,Non-data,85
so libinputso libcryptoso libandroidso code size 912 KB 1050 KB 186 KB 2065 KB 92 KB branch instr,Non-data,85
| 2755 3714 585 6897 430 gadgets 1547 2174 283 4246 180 Table 3: Availability of the reload gadgets 863attacks can be performed To empirically determine this property, we executed the same receiver app developed in the paragraph above It Flush-Reloads on k gadgets (k ranges from 1 to 10) without Flush-Reload intervals|,Non-data,85
| The mean execution time of one Flush-Reload cycle and one standard deviation are reported in Fig 4b We can see that Flush-Reload cycles for one gadget on A53 is around 500ns, and that for more gadgets increases (roughly) lin- early 4|,Non-data,85
|4 Practical Considerations To make these attacks practical on Android, however, we consider several factors that may constrain the attacks CPU frequency Mobile devices dynamically scale up and down the operation frequency of each CPU core indepen- dently to reduce power consumption The timing channel, when executed on CPUs with varying frequency, may lead to unstable results|,Non-data,85
| In the practical attacks that we will demonstrate in Sec 5, fixing CPU frequency from the ker- nel is not an option Therefore, we evaluated to what extent will the frequency vary during our Flush-Reload attacks To do so, we conducted an experiment in which we measured the frequency of the CPU core on which the Flush-Reload attack runs|,Non-data,85
| This can be done by reading sysfs6 within the attacker app itself, because no additional permission is re- quired We found in all cases after starting running our Flush-Reload attacks from an otherwise idle CPU core, the operation frequency would reach the maximum and stay unchanged until the attacks finished Therefore, CPU fre- quency scaling will not impact our attack once the malicious app warms up the CPU Thread scheduling and cgroups|,Non-data,85
| To limit the resource consumption of background threads, Android employs two control groups (cgroups) The background apps and threads are assigned to the background cgroups where up to 5% CPU resources can be used when contending with other apps However, we found in our experiments that the attacks are not affected by such mechanisms as long as the device is not running computation-intensive apps that occupy all CPU resources, in which case the CPU caches will be highly pol- luted and cache attacks will hardly work anyway Dual CPU architectures|,Non-data,85
| More recent smartphones (eg, Samsung Galaxy S5 and S6) come with octa-core processors— two processor packages with four cores each For exam- ple, recent Samsung Exynos processors usually have two asymmetric processors, one with higher operation frequency to support CPU-intensive applications and one with lower frequency to save power when the demand is low|,Non-data,85
| How- ever, in our experiments, although the malicious app and the victim app run on different CPUs, the return-oriented Flush-Reload attacks can still successfully differentiate whether the victim touched the shared library functions or not (though the differences are slightly smaller) We pre- sume this is because of the ARM Cache Coherent Inter- connect [4] Similar cross-core Flush-Reload side chan- nels have been observed by Irazoqui et al on AMD proces- sors [27]|,Non-data,85
| Therefore, we only run the malicious app on a core of Cortex-A53 processor (using sched_setaffinity system call that requires no additional permission) and the victim app running on either of the CPUs can be targeted (a) Minimum gadgets (b) Min Flush-Reload cycles|,Non-data,85
| Figure 4: Characteristics of Flush-Reload side channels 43 Characterizing ARM Flush-Reload Attacks In this section, we evaluate two important characteris- tics of the return-oriented Flush-Reload side-channel at- tacks described above: (1) the minimum number of gadgets needed to Flush-Reload at the same time in order to reli- ably differentiate cache hits from cache misses, and (2) the shortest Flush-Reload cycles (ie|,Non-data,85
|, time to finish one round of Flush and Reload with zero Flush-Reload interval) for one gadget The experiments were run on A53 with CPU frequency set as 15GHz Minimum gadgets for successful attacks|,Non-data,85
| In a success- ful Flush-Reload side-channel attack, the adversary exfil- trates one bit information pertaining to a target system-level event—happen or not happen—during a certain time period Such information is learned by determining if Reloads lead to cache hits or cache misses To reliably detect the oc- currence of the events, the adversary might need to Flush- Reload more than one gadgets from the same function (eg|,Non-data,85
|, Fig 3), or from different functions that will be called sequen- tially during the same event We evaluate the minimum number of gadgets that the adversary needs in Flush-Reload attacks by testing the strength of the signal of a Flush-Reload covert channel Specially, we chose 10 functions from the libc|,Non-data,85
|so5, and con- structed one gadget from each function, by using the last ret instruction Then two Android apps were developed: The receiver repeatedly Flushed k gadgets one after another (k ranges from 1 to 8), then after zero Flush-Reload inter- val he Reloaded the gadgets in the same order; the sender sent ‘0’ by running in an empty loop, and sent ‘1’ by calling the corresponding functions repeatedly We want to find out the minimum number of gadgets that allows the adversary to differentiate the signal ‘0’ from ‘1’ The results for run- ning the experiment 100 times (with mean and one standard deviation) are shown in Fig|,Non-data,85
| 4a The white bars show the Reload time when the sender sent ‘0’ and the solid bars show the Reload time when the sender sent ‘1’ We can see the signal is clear even when only one gadget is used, and becomes more reliable when more gadgets are used Shortest Flush-Reload cycles|,Non-data,85
| The granularity of the side channel is characterized by the shortest Flush-Reload cycles—the time to finish one round of Flush and Reload with zero Flush-Reload interval The shortest cycle indi- cates the highest frequency with which the Flush-Reload 5 The 10 functions are: atoi, fflush, free, getgid, getuid, isdigit, isspace, malloc, strnlen, strtof 6 /sys/devices/system/cpu/cpu<n>/cpufreq/scaling_cur_freq 12345678Gadget Number050010001500Time (ns)signal 0signal 112345678Gadget Number010002000300040005000Time (ns)86464-bit vs|,Non-data,85
| 32-bit devices and libraries Our return- oriented Flush-Reload attacks work differently on 64-bit apps and 32-bit apps On the 64-bit Samsung Galaxy S6, both 64-bit and 32-bit apps can be executed However, if the attacker app is compiled as a 64-bit app, it cannot conduct a return-oriented attacks on a shared 32-bit library|,Non-data,85
| Similarly, a 32-bit attacker app cannot exploit a shared 64-bit library, either Therefore, two versions of the malicious app were developed to attack both types Background noise Similar to prior work on cache side- channel attacks, our return-oriented Flush-Reload side- channel attacks are also subject to background noise|,Non-data,85
| The most notable noise comes from a third app that shares the same library and calls the functions that are being Reloaded by the attacker app To address the problem, we Flush- Reload multiple gadgets from different rarely-used func- tions at the same time, so that the likelihood of these func- tions being called together by another app is very low Hence, most background noise of this kind can be eliminated Power consumption|,Non-data,85
| When the attacker app runs in the background, one entire CPU core (ie, 12% of all CPU re- sources) is taken, and 15% battery was consumed every 20 minutes|,Non-data,85
| The power consumption is probably on par with (or slightly lower than) that reported in Diao et al [21] Be- cause Flush-Reload attacks do not need to evict an entire cache set (as is the case in Prime-Probe or Evict-Reload attacks), we suspect our techniques may consume less power than ARMageddon [32] Vulnerability analysis|,Non-data,85
| The following steps can be taken to analyze the vulnerabilities of an app in an offline proce- dure: First, all libraries linked in an app can be learned from /proc/<pid>/maps at runtime We could extract the sym- bols for all exported functions of the library of interest using objdump Then, using a Python script, we can generate a gdb initialization file, which contains breakpoint information of all (or a subset) of the functions in the objdump result Next, by employing gdb debugger on Android [8], we attach to the victim app remotely and insert all the breakpoints by loading the initialization file|,Non-data,85
| After that, we manually act on the app and see if any breakpoint is triggered This will provide a coarse-grained call graphs for identifying the most critical execution path of the program Of course, this approach is manual-intensive and error-prone We leave a fully automated analysis for future work|,Non-data,85
| 5 CASE STUDIES ON ANDROID In this section, we demonstrate a few real-world examples to illustrate how the return-oriented Flush-Reload side- channel attacks can be applied in practice Specially, we show two categories of attacks: detecting hardware events and tracing software execution paths The attacks were all demonstrated on Samsung Galaxy S6 (SM-G920F), with Android version 5|,Non-data,85
11 and Linux kernel version 310 5,Non-data,85
|1 Detecting Hardware Events Our return-oriented Flush-Reload attacks can be ex- ploited to detect hardware events, such as occurrences of hardware interrupts and software’s interactions with hard- ware devices (eg, GPS, microphones, cameras, etc)|,Non-data,85
| To demonstrate such capabilities in concrete contexts, we con- duct two case studies: In the first case study, we exploit the established side channel to accurately detect hardware inter- rupts due to touchscreen events; in the second case study, we show how an attacker can learn from the side channel when the camera is used by the Uber app7 to scan credit cards (using cardio libraries) 51|,Non-data,85
|1 Touchscreen Interrupts The Flush-Reload side channel does not detect inter- rupt directly; it only detects these events by monitoring system libraries that are triggered to dispatch these events to user-space applications Specially, in Linux’s multi-touch protocol, the user’s interaction with the touchscreen gener- ates a sequence of multi-touch transfers—each transfer may include multiple event packets if the user has multiple con- current contacts with the device By the end of each multi- touch transfer, a SYN_REPORT event is delivered to userspace software [40] In fact, each of these multi-touch transfer cor- relates with one touch event [7]|,Non-data,85
| It has been shown in a recent study by Diao et al [21] that side channels can be es- tablished through procfs (ie, /proc/interrupts) to infer unlock pattern|,Non-data,85
| Here in our paper, we show that our return- oriented Flush-Reload side-channel attacks can be used to replace this procfs side channel—should future Android OS restricts unauthorized usage of procfs, the security threats still exist The attack To detect these SYN_REPORT events, the ma- licious app Flush-Reloads three gadgets in three different functions (ie|,Non-data,85
|, TouchInputMapper::sync, CursorMotionAc- cumulator::clearRelativeAxes, and MultiTouchMotionAc- cumulator::finishSync in libinputflingerso) that will be called together when the driver calls the input_sync() function to deliver SYN_REPORT events We assign a fast Reload a value ‘1’; a slow one a value ‘0’ To reduce noise in measurements, we group every 20 consecutive data points: If there are more than 10 ‘1’s within these 20 points, we consider it the beginning of a SYN_REPORT event|,Non-data,85
| Sim- ilarly, within 20 consecutive data points, if all values are ‘0’s, we consider the event has finished In practice, these functions may sometimes take longer to finish so that two consecutive SYN_REPORT events cannot be separated To ad- dress this problem, we first estimated the average interval between every two consecutive SYN_REPORT events between a pair of BTN_TOUCH_DOWN and BTN_TOUCH_UP events An aver- age value of 11|,Non-data,85
|659ms was calculated from 500 pairs of con- secutive SYN_REPORT events Therefore we used such a value as the threshold in our detection: If the same SYN_REPORT event does not finish after 11659ms, we artificially add an- other event at this point Results|,Non-data,85
| We first show that our Flush-Reload-based event detection can be correlated with both SYN_REPORT events and counter increments in /proc/interrupts To do so, we collected three sequences of events simultaneously while touching the touchscreen: SYN_REPORT events (through the getevent command in Android Debug Bridge), counter in- crements of /proc/interrupts (on Samsung Galaxy S6, the fts touch device), and our aggregated return-oriented Flush- Reload detection (described in the above paragraph) These values are synchronized using timestamps, and reported in Fig 5|,Non-data,85
 It is clear the three events can be correlated with one another (with occasional mismatches) Therefore the Flush-Reload side channel can replace the procfs side channels 7 https://wwwuber,Non-data,85
|com/ 865report Figure 5: Correlations be- tween events, from top to bot- tom: SYN_REPORT events, Flush- Reload, /proc/interrupts Unlike procfs side channels, however, cache side channels are sub- ject to noise and may have both false pos- itives and false neg- atives We manu- ally generated 10294 SYN_REPORT events and here our de- tection accuracy in Table 4 Each column represents the maximal allowed la- tency: only detection within the allowed la- tency (detection should happen after the SYN_REPORT event) is counted as accurate detection|,Non-data,85
| As such, a false positive (FP) is defined as an event detection reported without an corresponding SYN_REPORT event proceeding it; and a false negative (FN) is counted as one SYN_REPORT event that is not detected within the allowed latency We see from the table when the allowed latency is small (eg, 400μs), the accuracy is low|,Non-data,85
| This is because the interrupt dispatcher functions are called by the driver later than the actual events But if the allowed latency is larger (eg, 1 or 2ms), the FP and FN rates are much lower|,Non-data,85
| For attacks in [21], latency of 1 or 2ms can be tolerated because the maximum frequency of touchscreen IRQs is only 135Hz, which means touch events will be dispatched every 7ms at most; the level of inaccu- racy (less than 10%) should still permit the unlock pattern inference attack in [21] Latency (ms) FP(%) FN(%) 04 06 0|,Non-data,85
8 10 12 14 1,Non-data,85
6 18 20 528 25,Non-data,85
6 33 592 320 16,Non-data,85
0 110 97 96 4,Non-data,85
5 30 94 27 9,Non-data,85
1 25 89 25 8,Non-data,85
|9 Table 4: Detection accuracy 512 Credit Card Scanning Some Android apps, such as Uber and PayPal, use card|,Non-data,85
|io libraries developed by PayPal8 to scan credit card informa- tion from their apps Although cardio is a 32-bit third-party library, we can still perform Flush-Reload side-channel at- tacks on gadgets collected from it We demonstrate that a malicious app can accurately detect when the user scans her credit card from the Uber app using Flush-Reload chan- nels|,Non-data,85
| Such capabilities, though not dangerous by itself, may take the places of various procfs side channels [19, 31] and facilitate other security attacks, such as taking pictures from the background [19] at the right moment and taking screen- shots when sensitive information is displayed [31] Gad- gets were collected from setScanCardNumberResult, setDe- tectedCardImage, and scanner_add_frame_with_expiry in libcardioRecognizerso By Flush-Reload these three gadgets together, we could reliably detect when the user scans her credit card using the app|,Non-data,85
| 52 Tracing Software Execution Paths It has been shown x86 Flush-Reload attacks can be used to trace software execution paths [53] in clouds, here we 8 https://wwwcardio demonstrate our return-oriented Flush-Reload side chan- nels have similar power in mobile devices|,Non-data,85
| Specially, we illus- trate an interesting attack against SurfaceFlinger, dubbed the UI tracing attacks SurfaceFlinger is an important An- droid component that accepts graphic buffers from multiple sources, composes the buffers together to resolve inconsis- tency, and then, upon receiving a vsync signal, sends the composed graphic buffer to the display (by calling Surface- Flinger::postFramebuffer()) if there is an update in the buffer We show by conducting a Flush-Reload attack on this function, the malicious app can (1) detect when a no- tification appears and disappears in the status bar, and (2) infer the number of characters that the user has typed in a password field Detecting push notifications|,Non-data,85
| An Android push notifi- cation will be shown on the status bar temporarily once it is received Detecting the occurrence of push notifications may reveal the user’s private action on the smartphone By Flush-Reloading the postFramebuffer function, one can accurately pinpoint the time period that the notification is listed on the status bar This capability is shown in Fig|,Non-data,85
| 6a In this figure, and also the other two figures in Fig 6, the X- axis shows real-time Flush-Reload events (roughly 250K points per second), and the Y-axis shows the raw values of Reloads: values higher than 240ns are considered 240ns All data points are connected with lines|,Non-data,85
| Therefore a verti- cal “bar” is actually several data points connected with lines From the figure, we can see that the notification showed up at around 1s, and disappeared at 4s, which is consistent with the ground truth Detecting display updates Updates to the display can be reflected by Flush-Reloading the postFramebuffer func- tion|,Non-data,85
| For instance, On a Discover banking app we down- loaded from the Google Play Store, a password field in the user login activity, when focused, will show a blinking cursor at the frequency of 500ms [1] As seen in Fig 6b, The blink- ing cursor can be detected with a sequence of fast Reloads (ie|,Non-data,85
|, about 170ns) of the postFramebuffer gadget every 500ms Moreover, whenever the user types a password, the display needs to be updated accordingly Fig 6c shows five abnormal display update activities, corresponding to the five characters typed in the password field|,Non-data,85
| This capability can leak inter-keystroke information that may lead to password cracking 6 COUNTERMEASURES Disallow user-space cache flushes By disabling the system interfaces to flush the instruction caches, the Flush- Reload side channels can be removed entirely from ARM- based devices|,Non-data,85
| However, because ARM does not maintain cache coherence between data caches and instruction caches, disallowing user-space cache flushes entirely also disables self-modifying code That means features like just-in-time compilation (eg, heavily used in Dalvik VM) will not work on Android|,Non-data,85
| An alternative solution is to only disable ex- plicit cache flush system calls, eg, clearcache, but allow implicit cache flushes after mprotect The feasibility and security of such a design requires further investigation|,Non-data,85
 Restrict fine-grained time measurements Removing clock_gettime system call and other fine-grained timers from Android will mitigate all timing side channels How- 050100Time [ms]SYN_REPORTFlush-ReloadInterrupt600650700866(a) Notification detection (b) Cursor blinking,Non-data,85
| Figure 6: UI tracing attacks (c) Five characters entered ever, doing so will make many apps that rely on accurate time measurement unusable Moveover, we also note re- moving these fine-grained timers alone does not guaran- tee elimination of timing channels|,Non-data,85
| It has been argued by Wray [48] that reference clocks can be established using other approaches, such as I/O or memory subsystems Prevent physical memory sharing The return-oriented Flush-Reload attack on ARM will be completely elimi- nated if no memory sharing is allowed between apps How- ever, the expansion of the memory footprint because of this method will stress the availability of the physical memory|,Non-data,85
 The copy-on-access mechanism proposed by Zhou et al [55] appears to be the only effective and efficient countermeasure against Flush-Reload attacks The method keeps a state machine to track the sharing of each physical page between security domains (eg,Non-data,85
|, containers) Accessing shared page by any security domain will trigger a page copy thus pre- venting Flush-Reload based attacks entirely Given the low performance overhead of the method, it is probable for future Android OS or even mainstream Linux kernels to im- plement such defense methods 7|,Non-data,85
| RELATED WORK Cache side-channel attacks Most prior studies on cache side-channel attacks focused on caches in x86 architectures, including data caches (and also per-core L2 unified caches) [23, 24, 35, 37, 38, 46], instruction caches [12, 13, 52], and inclusive LLCs [16, 22, 25, 26, 28, 33, 36, 49, 50, 53] ARM-based cache side-channel attacks have also been studied, but most of them were in the context of time-driven attacks [43, 45, 47] (see Sec 2)|,Non-data,85
| Access-driven cache side-channel attacks on ARM have only been explored by two recent studies [32,44] Particularly, the attacks presented by Spreitzer et al [44] required root privilege and kernel modules to facilitate the attacks, which have been considered impractical Most rel- evant to our work is due to Lipp et al|,Non-data,85
| [32], who explored Evict-Reload and Prime-Probe attacks on ARM The major advantage of the Flush-Reload attacks presented in our paper is that we do not require knowledge of virtual- to-physical address translation, which is a necessity in [32] On Android, such knowledge can only be learned by reading /proc/<pid>/pagemaps, which is considered a vulnerability and has already been restricted from mainstream Linux ker- nels [9] and Android OS [11]9 Side channels on Android|,Non-data,85
| Other types of side channels have also been studied previously These research are gener- ally divided into two categories: procfs-based side chan- nels [19, 21, 30, 31, 39, 51, 54] and sensor-based side chan- nels [15,17,34] Our Flush-Reload attacks, as a third type, can enhance, or be enhanced by, these side-channel attacks For instance, Chen et al|,Non-data,85
| [19] studied the use of procfs to de- tect Android activity transition, which can facilitate our UI tracing attacks (Sec 52) Moreover, our attack can replace many procfs-based side channels, if access to this pseudo file system is restricted, and even achieve finer-grained ob- servation than existing techniques, for instance, via tracing software execution paths|,Non-data,85
| 8 CONCLUSION In this paper, we successfully demonstrated the feasibility of conducting Flush-Reload side-channel attacks on ARM last-level caches Our contributions are at least three-fold: First, we showed that Flush can be implemented on ARM by leveraging the clearcache system call that are avail- able on all ARM-based operating systems (eg|,Non-data,85
|, Android) for maintaining coherence between the data and instruction caches Second, we designed a novel return-oriented Reload mechanism so that code segments in shared libraries can be loaded into the instruction caches in units of gadgets, rather than functions Third, we studied how these side channels can be exploited on Android-based mobile devices We took into consideration practical issues such as CPU frequency scaling, thread scheduling, multi-CPU architecture, power consumption, etc|,Non-data,85
|, and demonstrated two categories of at- tacks on Android: detecting hardware events and tracing software execution paths Acknowledgements We would like to thank the National Science Foundation for supporting our research through grant 1566444 9 |,Non-data,85
|ABSTRACT Modern applications often operate on data in multiple administra- tive domains In this federated setting, participants may not fully trust each other These distributed applications use transactions as a core mechanism for ensuring reliability and consistency with per- sistent data However, the coordination mechanisms needed for transactions can both leak confidential information and allow unau- thorized influence|,Non-data,86
| By implementing a simple attack, we show these side channels can be exploited However, our focus is on preventing such attacks We explore secure scheduling of atomic, serializable transactions in a federated setting While we prove that no protocol can guaran- tee security and liveness in all settings, we establish conditions for sets of transactions that can safely complete under secure schedul- ing|,Non-data,86
