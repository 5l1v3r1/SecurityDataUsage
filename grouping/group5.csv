 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| 2 MOTIVATING EXAMPLE Before diving into the technical details we’ll first present our motivating example, which involves accuracy-dependent privacy, advanced composition, and interactive privacy We first review the definition of differential privacy, a relational property about proba- bilistic programs proposed by Dwork, McSherry, Nissim and Smith Definition 1|,Non-data,8
| Let the adjacency relation be Φ ⊆ A × A, and , δ > 0 A program M : A → Distr(B) satisfies (, δ)-differential privacy with respect to Φ if for every pair of inputs a, a(cid:48) ∈ A such that Φ(a, a(cid:48)) and every subset of outputs S ⊆ B, we have y←M a(cid:48)[y ∈ S] + δ When δ = 0, we say that M is -differentially private [y ∈ S] ≤ exp() Pr y←M a Pr Intuitively, Φ relates inputs that differ in a single individual’s data|,Non-data,8
| Then, differential privacy requires that the two resulting distributions on outputs should be close ASVbt(a, b, M, N, d) := i ← 0; l ← []; u $← L/2(0); A ← a − u; B ← b + u; while i < N ∧ ||l|| < M do q ← A(l); S $← L(cid:48)/3(evalQ(q, d)); if (A ≤ S ≤ B) then l ← i :: l; i ← i + 1; return l Figure 1: Sparse Vector for Between Thresholds Our motivating example is Adaptive Sparse Vector for Between Thresholds (ASVbt), a variant of the Sparse Vector algorithm Our algorithm takes a stream of numeric queries as input, and answers only the queries that take a value within some range The main benefit of Sparse Vector is that queries that take a value outside the range do not increase the privacy cost, even though testing whether whether the query is (approximately) in the range involves private data|,Non-data,8
| Sparse Vector is an appealing example, because of its popularity and its difficulty In particular, the privacy proof of Above Threshold is non-compositional and notoriously tricky, and several variants1 of the algorithm were supposedly proved to be private but were later shown to be non-private (Lyu et al [34] provide a comprehensive survey) The code of ASVbt is shown in Fig|,Non-data,8
| 1 At a high level, the algo- rithm accepts a stream of adversarially chosen queries and produces a list of queries whose answer lies (approximately) between two threshold parameters a and b The algorithm computes noisy ver- sions A and B of a and b using the Laplace mechanism L, which we review in the next section, and then performs an interactive loop for a fixed number (N) of iterations Each step, a stateful adver- sary A receives the current list l of queries whose answer on input database d lies between [A, B] and selects a new query q|,Non-data,8
| If its noisy answer S lies in [A, B] and there have been fewer than M queries between threshold, the algorithm adds q to the list l Our algorithm differs from standard presentations of Adaptive Sparse Vector [17] in two significant respects: • we use BetweenThresholds rather than AboveThreshold for deciding whether to add a query to the list; • we do not rerandomize the noise on the thresholds each time a query is added to l; therefore, our algorithm adds less noise ASVbt satisfies the following privacy guarantee Theorem 2|,Non-data,8
| Let  and δ both be in (0, 1) Set 4(cid:112)2M ln(2/δ)  , (cid:48) (cid:44)  and suppose a and b are such that b − a ≥ 6 (cid:48) ln(4/ (cid:48) ) + 4  ln(2/δ) 1There exist multiple versions of Sparse Vector The earliest ref- erence seems to be Dwork et al|,Non-data,8
| [20]; several refinements were proposed by Hardt and Rothblum [30], Roth and Roughgarden [44] Applications often use their own variants, eg Shokri and Shmatikov [46]|,Non-data,8
| The most canonical version of the algorithm is the version by Dwork and Roth [17] 56The level of privacy depends on the sensitivity of the query, which measures how far the function may differ on two related inputs Roughly, adding the same level of Laplace noise to a higher sensi- tivity query will be less private Definition 4 (Sensitivity)|,Non-data,8
| A function F : A → Z is k-sensitive with respect to Φ ⊆ A × A if ||F (a1) − F (a2)|| ≤ k for every a1, a2 ∈ A such that Φ(a1, a2) The Laplace mechanism satisfies an accuracy specification Proposition 5 (Laplace accuracy) Let , β > 0, and suppose x is the result from running L(t)|,Non-data,8
| Then ||x−t|| ≤ 1 β with probability at least 1 − β  ln 1 Besides private primitives, the other main tools for construct- ing private programs are the composition theorems These results describe the privacy level for a combination of private programs— say, calls to the Laplace mechanism We will use a bit of nota- tion for compositions|,Non-data,8
| Let {fi} be a set of n functions of type A → D → Distr(A) Denote the n-fold composition f n : A → D → Distr(A) by f k(a, d) = unit a bind f k−1(a, d) fk(−, d) : k = 0 : k ≥ 1 Here, unit : A → Distr(A) and bind : Distr(A) → (A → Distr(B)) → Distr(B) are the monadic operations for distribu- tions They satisfy the following equalities: (cid:40) (cid:26) 1 if a = b (cid:88) 0 otherwise b unit(a)(b) = and for f : A → Distr(B) and F : A → B → Distr(C) , (bind f F )(a)(c) = f (a)(b) F (a)(b)(c)|,Non-data,8
| We will also use this composition notation when the functions {fi} have type A → Distr(A), simply dropping the parameter d above when defining f n : A → Distr(A) Then, the most basic composition theorem in differential privacy is sequential composition : A → D → Theorem 6 (Sequential composition) Let fi Distr(A) be a sequence of n functions, such that for every fixed a ∈ A, the functions fi(a) : D → Distr(A) are (i, δi)- differentially private for some adjacency relation on D|,Non-data,8
| Then for every initial value a ∈ A, the composition f n(a) : D → Distr(A) is (∗, δ∗)-differentially private for n(cid:88) n(cid:88) ∗  = i and ∗ δ = δi If all adversarial queries q are 1-sensitive (ie ||evalQ(q, d) − evalQ(q, d(cid:48))|| ≤ 1 for every adjacent databases d and d(cid:48)), then ASVbt is (, δ)-differentially private|,Non-data,8
| The formal proof of this theorem, which we have verified in an implementation of our logic within the EasyCrypt system, involves several features: • reasoning principles for mixing accuracy and privacy guar- antees, using a combination of relational logics [6, 10] and non-relational logics [11]; • a generalization of the advanced composition theorem for handling the body of the loop; • an adversary rule for handling interactive inputs in the loop; and • a new reasoning principle, called optimal subset coupling, for handling the Laplace mechanism in the loop We stress that the use of pointwise equality, which is required for proving privacy of between thresholds, makes the proof significantly more challenging than other examples involving solely adaptive adversaries, advanced composition, and accuracy-dependent privacy We remark that Bun et al [13] proposed Between Threshold and proved its privacy|,Non-data,8
| Their proof does not use advanced composition, and follows from a somewhat complicated calculations about the probabilities of certain events Our proof demonstrates the power of approximate liftings: somewhat surprisingly, we arrive at an elegant privacy proof without probabilistic reasoning 3 BACKGROUND is a distribution over B if(cid:80) Before presenting our new extensions, we first review some pre- liminaries about differential privacy, the connection to approximate liftings, the program logic apRHL [6] and its extension apRHL+ [10], and the union bound logic aHL [11]|,Non-data,8
| 31 Mathematical preliminaries To avoid measure-theoretic issues, we base our technical develop- ment on distributions over discrete sets B A function μ : B → R≥0 b∈supp(μ) μ(b) = 1 As usual, the sup- port supp(μ) is the subset of B with non-zero weight under μ|,Non-data,8
| We write Distr(B) for the set of discrete distributions over B Equality of distributions is defined as pointwise equality of functions We will also use marginal distributions Formally, the first and second marginals of a distribution μ ∈ Distr(B1 × B2) are simply the projections: the distributions π1(μ) ∈ Distr(B1) and π2(μ) ∈ Distr(B2) given by (cid:88) (cid:88) b2∈B2 π1(μ)(b1) = μ(b1, b2) π2(μ)(b2) = μ(b1, b2)|,Non-data,8
| i=1 i=1 That is, the epsilons and deltas sum up through composition b1∈B1 32 Differential privacy We will need several tools from differential privacy; readers should consult the textbook by Dwork and Roth [17] for a more comprehensive introduction Most differentially private algorithms are constructed from private primitive operations|,Non-data,8
| The most famous primitive is the Laplace mechanism Definition 3 (Laplace mechanism [19]) Let  > 0 The (discrete) Laplace mechanism L : Z → Distr(Z) is defined by L(t) = t + ν, where ν ∈ Z with probability proportional to Pr[ν] ∝ exp (− · ||ν||)|,Non-data,8
| The sequential composition theorem is quite useful, and is the main principle supporting modular verification of differential pri- vacy However, there is another composition theorem, known as advanced composition [22] Instead of summing up the privacy costs, this theorem gives slower growth of  in exchange for in- creasing the δ parameter Advanced composition is an extremely common tool for analyzing differentially private algorithms, but it is not supported by most formal verification systems today|,Non-data,8
| : A → D → Theorem 7 (Advanced composition) Let fi Distr(A) be a sequence of n functions, such that for every fixed a ∈ A, the functions fi(a) : D → Distr(A) are (, δ)-differentially 57private for some adjacency relation on D Then, for every a ∈ A and ω ∈ (0, 1), the composed function f n(a) : D → Distr(A) is (∗, δ∗)-differentially private for  + n(e − 1) and ∗ δ = nδ + ω (cid:16)(cid:112)2n ln(1/ω) (cid:17) ∗  = In particular, if we have (cid:48) ∈ (0, 1), ω ∈ (0, 1/2), and 2(cid:112)2n ln(1/ω) (cid:48) ,  = a short calculation shows that differentially private|,Non-data,8
| the function f n is ((cid:48), δ∗)- Kairouz et al [32] propose sharper versions of this composition theorem, including a provably optimal version and a version for the heterogeneous case when the privacy level (i, δi) may depend on i We will use Theorem 7 for simplicity, but our techniques enable other composition theorems to be easily plugged in 3|,Non-data,8
|3 Approximate liftings While the definition of differential privacy seems to be a straight- forward property about probabilities in two distributions, a recent line of work initiated by Barthe et al [6] and subsequently devel- oped [2, 10] shows that differential privacy is a consequence of an approximate version of probabilistic coupling, called approximate liftings Couplings are a long-standing tool in probability theory for analyzing pairs of distributions, but the relation between differential privacy and approximate couplings is still being explored Unlike couplings, where there is a single accepted definition, several incomparable notions of approximate liftings have been proposed|,Non-data,8
| The first definition is by Barthe et al [6] but has some technical shortcomings; we will use a more recent definition by Barthe and Olmedo [2] We begin by defining a distance on distribu- tions, closely related to (, δ)-differential privacy Definition 8 (Barthe and Olmedo [2])|,Non-data,8
| Let  ≥ 0 The -DP diver- gence ∆(μ1, μ2) between two distributions μ1 ∈ Distr(A) and μ2 ∈ Distr(A) is defined as (cid:19) (cid:18) sup S⊆A Pr x←μ1 [x ∈ S] − exp() Pr x←μ2 [x ∈ S]  For the connection to differential privacy, it is not hard to see that if M : D → Distr(A), then M is (, δ)-differentially inputs d, d(cid:48), we have private iff for every pair of adjacent ∆(M (d), M (d(cid:48))) ≤ δ This distance is also central to the defi- nition of approximate liftings|,Non-data,8
| Definition 9 (Barthe and Olmedo [2]) Two distributions μ1 ∈ Distr(A1) and μ2 ∈ Distr(A2) are related by the (, δ)-lifting of Ψ ⊆ A1 × A2, written μ1 Ψ(cid:93)(,δ) μ2, if there exist two witness distributions μL ∈ Distr(A1 × A2) and μR ∈ Distr(A1 × A2) such that 1 π1(μL) = μ1 and π2(μR) = μ2; 2 supp(μL) ⊆ Ψ and supp(μR) ⊆ Ψ; and 3|,Non-data,8
| ∆(μL, μR) ≤ δ Approximate liftings generalize several concepts for relating dis- tributions When μL = μR, we have a (0, 0)-lifting, sometimes called an exact probabilistic lifting Such a lifting, with any Ψ, implies a probabilistic coupling between (μ1, μ2)|,Non-data,8
| Approximate liftings satisfy the following property, also known as the fundamental lemma of approximate liftings Lemma 10 (Barthe and Olmedo [2]) Let E1 ⊆ B1, E2 ⊆ B2, μ1 ∈ Distr(B1) and μ2 ∈ Distr(B2) Let Ψ = {(x1, x2) ∈ B1 × B2 || x1 ∈ E1 ⇒ x2 ∈ E2}|,Non-data,8
| If μ1 Ψ(cid:93)(,δ) μ2, then Pr x1←μ1 [x1 ∈ E1] ≤ exp() Pr x2←μ2 [x2 ∈ E2] + δ Using this lemma, one can prove that differential privacy is equiv- alent to a particular form of approximate lifting Proposition 11 (Barthe and Olmedo [2]) A probabilistic compu- tation M : D → Distr(A) is (, δ)-differentially private for adja- cency relation Φ iff M (a) =(cid:93)(,δ) M (a (cid:48) ) for every two adjacent inputs a and a(cid:48)|,Non-data,8
| Approximate liftings form the basis of the program logic apRHL, to which we turn next 34 The relational program logic The logic apRHL, originally proposed by Barthe et al [6], is a relational program logic for verifying differential privacy|,Non-data,8
| We take this logic as our point of departure; we briefly recall the main points here We consider a simple imperative language with random sampling, oracle calls and adversary calls; the latter two are new to the present work The set of commands is defined inductively: C ::= skip || C; C || X ← E || X $← L(E) || if E then C else C || while E do C || (X ,  |,Non-data,8
|  ,X ) ← A(E,   |,Non-data,8
| ,E) || (X ,    ,X ) ← O(E, |,Non-data,8
|   ,E) noop sequencing deterministic assignment Laplace mechanism conditional while loop adversary call procedure call where X is a set of variables and E is a set of expressions Vari- ables and expressions are typed, and range over standard types like booleans, integers, databases, queries, lists, etc|,Non-data,8
| We omit the seman- tics of expressions, which is standard Commands are interpreted as maps State → Distr(State); this is also a standard choice (eg, see Barthe et al|,Non-data,8
| [6])2 We will write [[c]]m to mean the output distribution of command c, executed on input memory m An apRHL judgment has the form (cid:96) c ∼(cid:104),δ(cid:105) c (cid:48) : Φ =⇒ Ψ Reminiscent of Hoare logic, Φ represents the pre-condition while Ψ represents the post-condition|,Non-data,8
| Both Φ and Ψ are first order formulas over the program variables For expressing relational properties, program variables are tagged with either (cid:104)1(cid:105) or (cid:104)2(cid:105) to indicate whether they belong to c or c(cid:48) respectively For instance, we can assert that the variable x differs by at most 1 in the two runs with the assertion ||x(cid:104)1(cid:105) − x(cid:104)2(cid:105)|| ≤ 1 Crucially, the post-condition Ψ is interpreted as an approximate lifting over the output distributions|,Non-data,8
| More formally, the judgment is valid iff for every two memories m1 and m2 such that m1 Φ m2, we have ([[c1]]m1 ) Ψ(cid:93)(,δ) ([[c2]]m2 ) 2We will assume that commands are terminating on all executions The logic apRHL can also reason about possibly non-terminating programs by working with sub-distributions instead of distributions 58We present selected rules, taken from prior presentations of apRHL [6, 10] in Fig|,Non-data,8
| 2; F V (Φ) denotes the set of program variables in the assertion Φ, and M V (c) denotes the set of program variables that are modified (ie, written) by program c Many of the rules bear a resemblance to the standard Hoare logic rules|,Non-data,8
| The rules [ASSN] and [COND] are relational versions of the assignment and conditional rules; note that [COND] assumes that the two guards are equal in the pre-condition The rule [SEQ] reflects the composition principle of approximate liftings, where the indices  and δ add; this rule generalizes the standard composition theorem of differential privacy The rule [WHILE] extends this reasoning to loops with a bound number of iterations, again assuming that the guards are equal in both programs The next two rules, [LAPNULL] and [LAPGEN], are for relating two sampling instructions from the Laplace distribution|,Non-data,8
| Intuitively [LAPNULL] models adding identical noise on both sides, so that the distance between the samples (y1(cid:104)1(cid:105), y2(cid:104)2(cid:105)) is equal to the distance between the means (e1(cid:104)1(cid:105), e2(cid:104)2(cid:105)) [LAPGEN] is a general rule for assuming that the two samples are shifted and related by y1(cid:104)1(cid:105) + k = y2(cid:104)2(cid:105); the privacy cost depends on how far the means (e1(cid:104)1(cid:105) + k, e2(cid:104)2(cid:105)) are The final group of rules are the structural rules Besides the usual rules for consequence and framing ([CONSEQ] and [FRAME]), the most interesting rule is the pointwise equality rule [PW-EQ]|,Non-data,8
| This rule proves differential privacy by showing a pointwise judgment for each possible output value i, and is the key tool for supporting privacy proofs beyond the standard composition theorems 35 The union bound logic When reasoning about privacy, we will sometimes need to prove probabilistic bounds on accuracy Since accuracy properties are not relational, we cannot verify them in apRHL|,Non-data,8
| There is a long history of research for formally verifying probabilistic properties, and we are free to choose any of these techniques to interface with our logic In our favor, we are interested in simple accuracy properties of the form Pr[Ψ] < β, where Ψ is an assertion on the program memory We call such assertions bad event assertions, since they state that the probability of some event Ψ—the “bad event”—is at most β We will prove accuracy assertions in the Hoare logic aHL [11], which is specialized to prove bad event assertions|,Non-data,8
| We will highlight just the features of aHL needed for our purposes; readers should consult Barthe et al [11] for a complete presentation Concretely, aHL judgments have the following form: (cid:96)β c : Φ =⇒ Ψ, where Φ and Ψ are (non-probabilistic) assertions over program memories, and β ∈ [0, 1] is a real-valued index Assertions in aHL are non-relational, and mention program variables from a single memory instead of program variables tagged with (cid:104)1(cid:105) or (cid:104)2(cid:105)|,Non-data,8
| To mediate between the non-relational assertions of aHL and the rela- tional assertions of apRHL, from a non-relational assertion Φ we can define relational assertions Φ(cid:104)1(cid:105) and Φ(cid:104)2(cid:105) by interpreting Φ where all program variables are tagged with (cid:104)1(cid:105) or (cid:104)2(cid:105) respectively The semantics of commands is unchanged from apRHL; we interpret commands as maps State → Distr(State) The above judgement means: for any initial memory satisfying Φ, the prob- ability that ¬Ψ holds in the resulting distribution on memories is at most β For instance, the accuracy specification of the Laplace mechanism (Proposition 5) is given by the following aHL judgment: (cid:96)β y $← L(e) : (cid:62) =⇒ ||y − e|| ≤ 1  log 1 β for every β ∈ (0, 1)|,Non-data,8
| 4 ACCURACY-DEPENDENT PRIVACY Let us begin with our first class of private algorithms, where privacy follows from an accuracy property For our purposes, these accuracy properties are non-relational probabilistic properties that hold on a single execution of a single program For instance, the assertion Pr[x > 0] < 0|,Non-data,8
|2, stating that the probability x is positive is at most 02, is an accuracy property Accuracy properties appear in privacy proofs in a variety of ways For instance, they may imply that the privacy cost  is smaller than expected|,Non-data,8
| Or, privacy may be conditional: if the accuracy property holds then we have differential privacy, otherwise the algorithm fails and there is no guarantee Programs in the latter case satisfy (, δ)-differential privacy, where the probability of failure is included in δ 41 Up-to-bad reasoning To integrate accuracy assertions into apRHL, we will use a technique from cryptographic verification: up-to-bad reasoning|,Non-data,8
| Roughly speaking, rather than directly proving the equality lifting corresponding to differential privacy: μ1 (=)(cid:93)(,δ) μ2, we will prove a conditional, up-to-bad lifting: μ1 {(x1, x2) || (¬Φ(x1, x2) → x1 = x2)}(cid:93)(,δ) μ2 Here, Φ is an assertion involving just variables from one side Roughly speaking, the lifting shows that if the bad event Φ does not hold, then we have differential privacy Then, we conclude the proof with a structural rule that combines the bad event assertion—proved externally in aHL—with the up-to-bad lifting, removing the bad event while adjusting the privacy parameters (, δ)|,Non-data,8
| To support this reasoning in our program logic, we propose the two rules in Fig 3 The rules, [UTB-L] and [UTB-R], internalize an approximate version of up-to-bad reasoning If the assertion Θ holds, then we have the (, δ)-lifting of equality|,Non-data,8
| So, if we know the probability of ¬Θ is at most δ(cid:48), then we can show the (, δ + δ(cid:48))-differential privacy when Θ is a property of the first run, and (, δ + eδ(cid:48))-differential privacy when Θ is a property of the second run The asymmetry in the left and right versions of the rule reflects the asymmetric definition of approximate lifting, which is in turn inspired by the asymmetric definition of differential privacy In order to include these rules, we show that they are valid To prove the equality lifting for privacy, we would like to use the equiv- alence in Proposition 11|,Non-data,8
| However, there is a catch: we only know that the distributions over e are differentially private—the distri- butions over the whole memory may not be differentially private Therefore, we will use a new property of approximate liftings: they are well-behaved when mapping the underlying distribution Proposition 12 For a function f : A → B, let f (cid:93): Distr(A) → Distr(B) denote function lifted to a map on distributions|,Non-data,8
| If f is surjective, and R is a relation on B, then μ1 {(x1, x2) || f (x1) R f (x2)}(cid:93)(,δ) μ2 if and only if f (cid:93) (μ1) {(y1, y2) || y1 R y2}(cid:93)(,δ)f (cid:93) (μ2) In particular, if we have a set E of equivalence classes of A and the distribution μ/E : Distr(E) represents the probability of being in each equivalence class, taking f : A → E mapping an element to its equivalence class and R to be the equivalence relation gives a result by Barthe and Olmedo [2, Proposition 8]: μ1 (=E)(cid:93)(,δ) μ2 ⇐⇒ μ1/E (=)(cid:93)(,δ) μ2/E 59ASSN (cid:96) x1 ← e1 ∼(cid:104)0,0(cid:105) x2 ← e2 : Ψ{e1(cid:104)1(cid:105), e2(cid:104)2(cid:105)/x1(cid:104)1(cid:105), x2(cid:104)2(cid:105)} =⇒ Ψ COND (cid:96) c1 ∼(cid:104),δ(cid:105) c2 : Φ ∧ b1(cid:104)1(cid:105) =⇒ Ψ (cid:96) if b1 then c1 else c 1 ∼(cid:104),δ(cid:105) if b2 then c2 else c (cid:48) (cid:96) c 1 ∼(cid:104),δ(cid:105) c (cid:48) 2 : Φ ∧ ¬b1(cid:104)1(cid:105) =⇒ Ψ (cid:48) 2 : Φ ∧ b1(cid:104)1(cid:105) = b2(cid:104)2(cid:105) =⇒ Ψ (cid:48) SEQ (cid:96) c1 ∼(cid:104),δ(cid:105) c2 : Φ =⇒ Ψ (cid:48) 1 ∼(cid:104)(cid:48),δ(cid:48)(cid:105) c (cid:96) c (cid:48) (cid:48) (cid:48) 2 : Ψ 1 ∼(cid:104)+(cid:48),δ+δ(cid:48)(cid:105) c2; c 2 : Φ =⇒ Ψ (cid:48) (cid:48) (cid:96) c1; c =⇒ Ψ WHILE (cid:96) c1 ∼(cid:104)k,δk(cid:105) c2 : Θ ∧ b1(cid:104)1(cid:105) ∧ b2(cid:104)2(cid:105) ∧ e(cid:104)1(cid:105) = k =⇒ Θ ∧ b1(cid:104)1(cid:105) = b2(cid:104)2(cid:105) ∧ e(cid:104)1(cid:105) < k (cid:96) while b1 do c1 ∼(cid:104)(cid:80)n ||= Θ ∧ e(cid:104)1(cid:105) ≤ 0 → ¬b1(cid:104)1(cid:105) k=1 δk(cid:105) while b2 do c2 : Θ ∧ b1(cid:104)1(cid:105) = b2(cid:104)2(cid:105) ∧ e(cid:104)1(cid:105) ≤ n =⇒ Θ ∧ ¬b1(cid:104)1(cid:105) ∧ ¬b2(cid:104)2(cid:105) k=1 k,(cid:80)n LAPNULL (cid:96) y1 $← L(e1) ∼(cid:104)0,0(cid:105) y2 $← L(e2) : (cid:62) =⇒ y1(cid:104)1(cid:105) − y2(cid:104)2(cid:105) = e1(cid:104)1(cid:105) − e2(cid:104)2(cid:105) y1 /∈ F V (e1) y2 /∈ F V (e2) LAPGEN (cid:96) y1 $← L(e1) ∼(cid:104)k(cid:48)·,0(cid:105) y2 $← L(e2) : ||k + e1(cid:104)1(cid:105) − e2(cid:104)2(cid:105)|| ≤ k (cid:48) → Ψ (cid:48) ∼(cid:104)(cid:48),δ(cid:48)(cid:105) c1 : c2 =⇒ Ψ (cid:48) (cid:96) Φ (cid:48) (cid:48) =⇒ y1(cid:104)1(cid:105) + k = y2(cid:104)2(cid:105) (cid:48) ≤   (cid:48) ≤ δ δ CONSEQ ||= Φ → Φ ||= Ψ (cid:96) c1 ∼(cid:104),δ(cid:105) c2 : Φ =⇒ Ψ FRAME (cid:96) c1 ∼(cid:104),δ(cid:105) c2 : Φ =⇒ Ψ F V (Θ) ∩ M V (c1, c2) = ∅ (cid:96) c1 ∼(cid:104),δ(cid:105) c2 : Φ ∧ Θ =⇒ Ψ ∧ Θ PW-EQ ∀i (cid:96) c1 ∼(cid:104),δi(cid:105) c2 : Φ =⇒ x(cid:104)1(cid:105) = i → x(cid:104)2(cid:105) = i (cid:96) c1 ∼(cid:104),(cid:80) i∈I δi(cid:105) c2 : Φ =⇒ x(cid:104)1(cid:105) = x(cid:104)2(cid:105) Figure 2: Selected proof rules of apRHL [6, 10] ||= Φ → Φ0(cid:104)1(cid:105) ||= Φ → Φ0(cid:104)2(cid:105) UTB-L UTB-R (cid:96) c ∼(cid:104),δ(cid:105) c (cid:48) (cid:96) c ∼(cid:104),δ+δ(cid:48)(cid:105) c (cid:96) c ∼(cid:104),δ(cid:105) c (cid:48) (cid:96) c ∼(cid:104),δ+eδ(cid:48)(cid:105) c (cid:48) : Φ =⇒ Θ(cid:104)1(cid:105) → e(cid:104)1(cid:105) = e(cid:104)2(cid:105) : Φ =⇒ e(cid:104)1(cid:105) = e(cid:104)2(cid:105) : Φ =⇒ Θ(cid:104)2(cid:105) → e(cid:104)1(cid:105) = e(cid:104)2(cid:105) : Φ =⇒ e(cid:104)1(cid:105) = e(cid:104)2(cid:105) (cid:48) (cid:96)δ(cid:48) c : Φ0 =⇒ Θ (cid:96)δ(cid:48) c (cid:48) : Φ0 =⇒ Θ Figure 3: Up-to-bad rules This result allows us to prove an approximate lifting for a distri- bution over memories by proving an approximting lifting for the distribution over a single variable or expression|,Non-data,8
| We defer the details of the proof to the full version Now, we are ready to show soundness of the up-to-bad rules Theorem 13 The rules [UTB-L] and [UTB-R] are sound|,Non-data,8
| Proof We will start with [UTB-L] Take any two memories (m1, m2) such that (m1, m2) ||= Φ, and let μ1, μ2 be [[c]]m1 and [[c(cid:48)]]m2 respectively Note that m1 ||= Φ0|,Non-data,8
| By validity of the premise, we know [¬Θ] ≤ δ (cid:48) Pr m∼μ1 and we have a pair of witnesses μL, μR for the relation R (cid:44) Θ(cid:104)1(cid:105) → e(cid:104)1(cid:105) = e(cid:104)2(cid:105), such that ∆(μL, μR) ≤ δ Our goal is to show that the marginal distributions of [[e]] in μ1, μ2 satisfy (, δ + δ(cid:48))-differential privacy, ie for any set S, Pr m∼μ1 [[[e]]m ∈ S] ≤ e Pr m(cid:48)∼μ2 [[[e]]m(cid:48) ∈ S] + δ + δ (cid:48) |,Non-data,8
| To begin, we know that Pr m∼μ1 [[[e]]m ∈ S] = Pr m∼μ1 [[[e]]m ∈ S ∧ m ||= Θ] [[[e]]m ∈ S ∧ m ||= ¬Θ] [[[e]]m ∈ S ∧ m ||= Θ] + δ (cid:48) + Pr m∼μ1 ≤ Pr m∼μ1 since the probability of ¬Θ in μ1 is at most δ(cid:48) Now, we can con- clude with the coupling: [[[e]]m ∈ S ∧ m ||= Θ] + δ (cid:48) [[[e]]m ∈ S ∧ m ||= Θ] + δ (cid:48) [[[e]]m ∈ S ∧ m ||= Θ] + δ + δ (cid:48) Pr m∼μ1 = ≤ e ≤ e Pr (m,m(cid:48))∼μL Pr (m,m(cid:48))∼μR Pr m ∈ S] + δ + δ (cid:48) [[[e]] (m,m(cid:48))∼μR m ∈ S] + δ + δ (cid:48) [[[e]] , (cid:48) (cid:48) = e Pr m(cid:48)∼μ2 where the first inequality uses ∆(μL, μR) ≤ δ, while the second inequality uses (m, m(cid:48)) ∈ supp(μR) So, the distributions of [[e]] satisfy differential privacy By Proposition 11 and Proposition 12 60with equivalence classes defined by the value of [[e]], we can con- clude soundness of [UTB-L]|,Non-data,8
| We can show soundness of [UTB-R] in a similar way Let μ1, μ2 be as above We can use the coupling as follows: Pr m∼μ1 = ≤ e = e + e ≤ e [[[e]]m ∈ S] Pr (m,m(cid:48))∼μL Pr (m,m(cid:48))∼μR [[[e]]m ∈ S] Pr (m,m(cid:48))∼μR Pr (m,m(cid:48))∼μR Pr (m,m(cid:48))∼μR [[[e]]m ∈ S] + δ [[[e]]m ∈ S ∧ m [[[e]]m ∈ S ∧ m m ∈ S] + e (cid:48) [[[e]] [[[e]]m(cid:48) ∈ S] + e Pr m(cid:48)∼μ2 [[[e]]m(cid:48) ∈ S] + δ + eδ (cid:48) = e Pr m(cid:48)∼μ2 ≤ e Pr m(cid:48)∼μ2 (cid:48) ||= Θ] (cid:48) ||= ¬Θ] + δ (cid:48) ||= ¬Θ] + δ (m,m(cid:48))∼μR [m Pr (cid:48) ||= ¬Θ] + δ [m The first inequality uses the bound on the distance between the wit- nesses: ∆(μL, μR) ≤ δ The second inequality uses the support of μR|,Non-data,8
| The final inequality uses the fact that Prm(cid:48)∼μ2 [m(cid:48) ||= ¬Θ] ≤ δ(cid:48) Since the distributions of [[e]] in μ1, μ2 satisfy (, δ + eδ(cid:48))- differential privacy, we can again use Proposition 11 and Proposi- tion 12 to show [UTB-R] is sound 42 Propose-Test-Release To give a small example of up-to-bad reasoning, we can prove privacy for the Propose-Test-Release (PTR) framework [16, 48], a classic example of privacy depending on an accuracy guarantee|,Non-data,8
| The goal is to release the answer to a function f Rather than adding noise directly to the answer (which may be non-numeric), PTR estimates the distance to instability of the database d with respect to f, denoted DistToInst f (d) This quantity measures the distance from d to the closest database d(cid:48) such that f (d) (cid:54)= f (d(cid:48)), where adjacent databases are at distance 1 We will use the following two properties of DistToInst: DistToInst f (d) > 1 → ∀d Adj(d, d (cid:48) (cid:48) ) → ||DistToInst f (d) − DistToInst f (d (cid:48) ) → f (d) = f (d (cid:48) )|| ≤ 1 (cid:48) |,Non-data,8
| (Adj(d, d )) Since the distance itself is private information, PTR first adds noise to the distance, calling the noisy result dist If it is large enough, then PTR returns the value of f with no noise Otherwise, PTR returns a default value ⊥ In code: dist $← L(DistToInst f (d)); if dist > ln(1/δ)/ + 1 then r ← f (d); r ← ⊥; else return r The key to the privacy of PTR is that if the noise when estimating dist is not too large, then there are two cases|,Non-data,8
| If dist is large, then there is no privacy cost for releasing the value of q when dist is large Otherwise, we return a default value ⊥ revealing nothing In either case, we just have privacy cost  from computing the noisy distance If the noise when estimating dist is too large (happening with probability at most δ), we may violate privacy|,Non-data,8
| So, we get an (, δ)-private algorithm Theorem 14 PTR is (, δ)-differentially private for , δ > 0 Proof sketch|,Non-data,8
| To prove differential privacy, we will use the rule [UTB-L] We can take the event Θ to hold exactly when the noise is not too large: Θ (cid:44) ||dist − DistToInst f (d)|| < ln(1/δ)/ Then, we couple the noise to be the same, so that we take the same branch in both runs Then, under assumption Θ, we know that if we estimate that the distance to instability is large and we take the first branch, then in fact f (d(cid:104)1(cid:105)) = f (d(cid:104)2(cid:105)) as desired|,Non-data,8
| Finally, using a tail bound for the Laplace distribution in aHL gives (cid:96)δ c : Φ(cid:104)1(cid:105) =⇒ Θ, and rule [UTB-L] gives (, δ)-differential privacy 5 ADVANCED COMPOSITION Advanced composition is a key tool for giving a more precise privacy analysis of a composition of private programs In this section, we extend apRHL with a new loop rule that supports advanced composition for arbitrary invariants and we show how the rule can be applied for proving privacy of a non-interactive variant of ASVbt|,Non-data,8
| Before presenting our solution, we stress that there are some tech- nical challenges in extending apRHL with advanced composition On the one hand, apRHL derives its expressiveness from its ability to reason about arbitrary approximate liftings, and not simply about approximate liftings for the equality relation; as a consequence, an advanced composition rule for apRHL should support approxi- mate liftings in order to be useful (in fact, an advanced composition rule for just approximate liftings of equality would be too weak for verifying our running example) On the other hand, the proof of advanced composition is substantially more technical than the proof for the sequential composition theorem, using sophisticated results from fields such as martingale theory and hypothesis test- ing We overcome these obstacles by showing approximate liftings from a version of differential privacy; as we saw before, differ- ential privacy is also a consequence of an approximate lifting of equality|,Non-data,8
| The key observation is that the two witnesses μL and μR used in the definition of an approximate lifting define a mecha- nism μ : B → Distr(A1 × A2) such that μ(true) = μL and μ(false) = μR where ∆(μL, μR) ≤ δ iff μ is (, δ)-differentially private Next, we show how to take advantage of this observation Since the (, δ) parameters from approximate lifting are defined by the -distance ∆(μ1, μ2) between the two witnesses, we will first show an advanced composition theorem for -distance Proposition 15 (Advanced composition for -distance)|,Non-data,8
| Let fi, gi : A → Distr(A) such that ∆(fi(a), gi(a)) ≤ δ for every a ∈ A For any ω > 0, let: ∗ (cid:44)(cid:16)(cid:112)2n ln(1/ω) (cid:17)   + n(e − 1) and ∗ (cid:44) nδ + ω δ Then for every n ∈ N and a ∈ A, ∆∗ (f n(a), gn(a)) ≤ δ∗ : A → B → Distr(A) be such that for every Proof|,Non-data,8
| Let hi a ∈ A, hi(a, true) = fi(a) and hi(a, false) = gi(a) Then ∆(fi(a), gi(a)) ≤ δ iff hi(a) : B → Distr(A) is (, δ)- differentially private for every a ∈ A By directly applying the advanced composition theorem of differ- ential privacy (Theorem 7), the function hn(a) : B → Distr(A) is (∗, δ∗)-differentially private for each a ∈ A So for every b, b(cid:48) ∈ B and a ∈ A, ∆∗ (hn(a, b), hn(a, b(cid:48))) ≤ δ∗|,Non-data,8
| Now for every a ∈ A, hn(a, true) = f n(a) and hn(a, false) = gn(a) Therefore, ∆∗ (f n(a), gn(a)) ≤ δ∗ 61Now that we have an advanced composition for -distance, it is a simple matter to extend our result to approximate liftings Note here that we apply advanced composition not to the distributions on A—which are related by an approximate lifting, but perhaps not related by differential privacy—but rather to the two witnesses of the lifting, distributions on pairs in A × A|,Non-data,8
| Proposition 16 (Advanced composition for lifting) Let fi, f(cid:48) : A → Distr(A) and Φ ⊆ A × A such that for every a, a(cid:48) ∈ A, (a, a(cid:48)) ||= Φ implies i fi(a) Φ(cid:93)(,δ) f (cid:48) (cid:48) i (a ) Let n ∈ N and let ((cid:48), δ(cid:48)) be as in Theorem 7 For any ω > 0, let (cid:48) (cid:44) nδ + ω|,Non-data,8
| (cid:48) (cid:44)(cid:16)(cid:112)2n ln(1/ω) (cid:17)  + n(e − 1) and δ  Then for every a, a(cid:48) ∈ A such that (a, a(cid:48)) ||= Φ, we have f n(a) Φ(cid:93)((cid:48),δ(cid:48)) f (cid:48)n(a (cid:48) ) Proof We can map any pair (a, a(cid:48)) ∈ Φ to the left and right witnesses of the approximate lifting That is, there exists hl i, hr i : (A × A) → Distr(A × A) such that for every (a, a(cid:48)) ||= Φ: • π1(hl • supp(hl • ∆(hl i(a, a(cid:48))) = fi(a) and π2(hr i(a, a(cid:48))) ⊆ Φ and supp(hr i(a, a(cid:48)), hr i (a, a(cid:48))) ≤ δ i (a(cid:48)) i (a, a(cid:48))) = f(cid:48) i (a, a(cid:48))) ⊆ Φ i(a, a(cid:48)) = Without loss of generality, we can assume that hl i (a, a(cid:48)) = 0 if (a, a(cid:48)) ||= ¬Φ|,Non-data,8
| By Proposition 15, we also hr i (a, a(cid:48))) ≤ δ(cid:48) for every i ∈ N and have ∆(cid:48) (hl (a, a(cid:48)) ||= Φ By induction on i, for every (a, a(cid:48)) ||= Φ we have supp((hl)n(a, a(cid:48))) ⊆ Φ and supp((hr)n(a, a(cid:48))) ⊆ Φ, π1((hl)n(a, a(cid:48))) = f n(a) and π2((hr)n(a, a(cid:48))) = f(cid:48)n i(a, a(cid:48)), hr i (a(cid:48)) We remark that our connection between the witnesses of liftings and differential privacy allows us to directly import other composi- tion theorems of differential privacy and their proofs without change For instance, Kairouz et al|,Non-data,8
| [32] consider two variants of advanced composition: an optimal variant that provably gives the best bound on  and δ, and a heterogeneous variant that allows  and δ be dif- ferent for the different mechanisms In unpublished work, Rogers et al [43] consider a version of the advanced composition theorem where the privacy level i and δi for the i-th mechanism may be chosen adaptively, ie|,Non-data,8
|, depending on the results from the first i − 1 mechanisms These composition theorems are quite tricky to prove, involving sophisticated tools from martingale theory and hypothesis testing We expect that we can internalize all of these composition theorems—and directly generalize to liftings—with minimal effort Based on the previous result, we introduce a new rule [AC- WHILE] that formalizes advanced composition for loops|,Non-data,8
| The sound- ness for the new rule, which is given in Fig 4 follows immediately from the results of the previous section Theorem 17 The rule [AC-WHILE] is sound|,Non-data,8
| 6 INTERACTIVE PRIVACY So far, we have seen how to incorporate composition theorems and accuracy proofs into our logic Now, we consider the last piece needed to verify ASVbt: proving privacy for interactive algorithms To date, privacy has only been formally verified for algorithms where the entire input is available in a single piece; such algorithms are called offline algorithms|,Non-data,8
| In contrast, interactive or online algorithms accept input piece by piece, in a finite stream of input, and must produce an intermediate outputs as inputs arrive The differential literature proposes several interactive algorithms; examples include private counters [14, 21], the Sparse Vector mech- anism, and other algorithms using these mechanisms [30] The main difficulty in verifying privacy is to model adaptivity: later inputs can depend on earlier outputs Indeed, differential privacy behaves well under adaptivity, a highly useful property enabling applications to adaptive data analysis and statistics [23]|,Non-data,8
| We can view adaptive inputs as controlled by an adversary, who receives earlier outputs and selects the next input We draw on tech- niques for formally verifying cryptographic proofs, which often also involve an adversary who is trying to break the protocol We take inspiration from the treatment of adversaries in the logic pRHL, an exact version of apRHL that has been used for verifying cryp- tographic proofs [4] Specifically, we extend apRHL with a rule [ADV] for the adversary|,Non-data,8
| The rule, displayed in Figure 5, general- izes the adversary rule from pRHL; let Φ an assertion that does not contain any adversary variable, and assume that the adversary A has access to oracles O1,    , On and that each oracle guarantees equality of outputs and an invariant Φ, provided it is called on equal inputs that satisfy Φ|,Non-data,8
| Then, A guarantees equality of outputs and an invariant Φ, provided it is called on equal inputs that satisfy Φ Moreover, the privacy cost of calling the adversary A is equal to k=1 qkδk(cid:105) where (cid:104)i, δi(cid:105) is the cost of calling once the oracle Oi, and qi is the maximal number of adversarial queries for oracle Oi One can prove the soundness of the adversary rule by induction on the code of the adversary Proposition 18|,Non-data,8
| The rule [ADV] is sound (cid:104)(cid:80)n k=1 qkk,(cid:80)n Note that the proof of sparse vector only makes a restricted use of the [ADV] rule: as A does not have access to any oracle, the pRHL rule suffices for the proof However, the following, oracle based, presentation of sparse vector uses the full power of the [ADV] rule: l ← []; u $← L/2(0); A ← a − u; B ← b + u; x ← AO(); return l where O is an oracle that takes a query and checks whether it is between thresholds and updates a public list l, and A is allowed to query O up to N times In addition, we note that our new rule can also be useful for cryptographic proofs which involve reasoning about statistical distance|,Non-data,8
| 7 OPTIMAL SUBSET COUPLING The privacy proof of ASVbt relies on a new interval coupling rule [LAPINT] for Laplace sampling, Fig 6 This rule allows us to relate a larger interval with a smaller interval nested inside|,Non-data,8
| That is, we can assume that the sample y1(cid:104)1(cid:105) lies in [p, q] if and only if the sample y2(cid:104)2(cid:105) lies in [r, s] contained in [p, q] The privacy cost depends on two things: the difference in sizes of the two intervals (q − p) − (s − r), and the size of the inner interval s − r Roughly, a larger inner interval and smaller outer interval yield a smaller privacy cost To show that this rule is sound, we will first prove a general construction for liftings of the form μ (y1 ∈ P ↔ y2 ∈ Q)(cid:93)(,0) μ for Q ⊆ P |,Non-data,8
| We call such such liftings subset couplings, since they relate a set of outputs to a subset of outputs Our construction applies 62||= Θ ∧ e(cid:104)1(cid:105) ≤ 0 → ¬b1(cid:104)1(cid:105)  + n(e − 1) ∗ (cid:44) nδ + ω δ ω > 0 AC-WHILE (cid:96) c1 ∼(cid:104),δ(cid:105) c2 : Θ ∧ b1(cid:104)1(cid:105) ∧ b2(cid:104)2(cid:105) ∧ e(cid:104)1(cid:105) = k =⇒ Θ ∧ b1(cid:104)1(cid:105) = b2(cid:104)2(cid:105) ∧ e(cid:104)1(cid:105) < k (cid:96) while b1 do c1 ∼(cid:104)∗,δ∗(cid:105) while b2 do c2 : Θ ∧ b1(cid:104)1(cid:105) = b2(cid:104)2(cid:105) ∧ e(cid:104)1(cid:105) ≤ n =⇒ Θ ∧ ¬b1(cid:104)1(cid:105) ∧ ¬b2(cid:104)2(cid:105) ∗ (cid:44)(cid:16)(cid:112)2n ln(1/ω) (cid:17)  Figure 4: Advanced composition rule ADV (cid:96) (cid:126)x ← A((cid:126)e) ∼(cid:104)(cid:80)n k=1 qkk,(cid:80)n ∀i, (cid:126)y, (cid:126)z (cid:96) (cid:126)y ← Oi((cid:126)z) ∼(cid:104)i,δi(cid:105) (cid:126)y ← Oi((cid:126)z) : (cid:126)z(cid:104)1(cid:105) = (cid:126)z(cid:104)2(cid:105) ∧ Φ =⇒ (cid:126)y(cid:104)1(cid:105) = (cid:126)y(cid:104)2(cid:105) ∧ Φ k=1 qkδk(cid:105) (cid:126)x ← A((cid:126)e) : (cid:126)e(cid:104)1(cid:105) = (cid:126)e(cid:104)2(cid:105) ∧ xA(cid:104)1(cid:105) = xA(cid:104)2(cid:105) ∧ Φ =⇒ (cid:126)x(cid:104)1(cid:105) = (cid:126)x(cid:104)2(cid:105) ∧ xA(cid:104)1(cid:105) = xA(cid:104)2(cid:105) ∧ Φ where q1,  |,Non-data,8
|  , qn are the maximal number of queries that A can make to oracles O1,   |,Non-data,8
| ,On and xA is the state of the adversary Figure 5: Adversary rule to all discrete distributions, and is optimal in a precise sense: among all liftings of the relation, our construction gives the smallest (ie, the most precise) |,Non-data,8
| proving a property of the discrete Laplace distribution Formally, let L(v) for v ∈ Z have distribution over Z with probability propor- tional to Theorem 19 (Optimal subset coupling) Let μ be a distribution over S, and consider two proper subsets P, Q of S such that Q ⊆ P  Then μ(P ) ≤ αμ(Q) if and only if the following lifting holds: μ R(cid:93)(ln α,0) μ where the relation R is defined by the following clause: (y1, y2) ∈ R (cid:44) y1 ∈ P ↔ y2 ∈ Q Pr[r] ∝ exp(−||r − v||)|,Non-data,8
| We write L to mean L(0) We will use the following property, a discrete version of Bun et al [13, Claim 513]|,Non-data,8
| Lemma 20 Let r be a draw from L, and take a, a(cid:48), b, b(cid:48) ∈ Z such that a < b and [a, b] ⊆ [a(cid:48), b(cid:48)] Then, Pr[r ∈ [a (cid:48) (cid:48) ]] ≤ α Pr[r ∈ [a, b]] , b Proof The reverse direction follows from the fundamental lemma of approximate liftings [2]|,Non-data,8
| For the forward implication, we con- struct two witnesses Note that the theorem is trivial if μ(P \Q) = 0 since we can just take the identity coupling, so we will assume oth- erwise Define the following witnesses: μ(x)μ(y) μ(Q) 0 μ(x)  μ(y) 0 μ(y) λ · μ(y) (1−λ)μ(x)μ(y) μ(P\Q) μL(x, y) = μR(x, y) = if x /∈ P \ Q ∧ x = y if x ∈ P \ Q ∧ y ∈ Q otherwise if x = y ∧ y /∈ P if x = y ∧ y ∈ Q if x ∈ P \ Q ∧ y ∈ Q if x = x0 ∈ S \ P ∧ y ∈ P \ Q otherwise|,Non-data,8
| Here, x0 is an arbitrary element of S \ P  We set λ = μ(Q)/μ(P ) Note that λ satisfies: λ = (1 − λ) μ(Q) μ(P \ Q)  For the witnesses, it is not hard to see that the marginal conditions are satisfied, and that x R y for all pairs (x, y) in the supports of μL and μR|,Non-data,8
| Furthermore, for all x ∈ P and y ∈ Q, we have μL(x, y) = (1/λ) · μR(x, y) by our choice of λ By the condition on marginals and the support, we have a (ln(1/λ), 0)-lifting This immediately implies the (ln α, 0)-lifting for any α ≥ 1/λ = μ(P )/μ(Q) This result is very much in the spirit of the optimal or maximal coupling for exact probabilistic couplings (see, e|,Non-data,8
|g, [49]) By com- puting the total variation distance between two distributions, the maximal coupling construction shows how to create a coupling that exactly realizes the total variation distance Similarly, by the optimal subset coupling, we can construct a subset coupling and calculate the distance  in the lifting by simply with α = exp(η) 1 − exp(−(b − a + 2)/2) , η = (b (cid:48) − a (cid:48) ) − (b − a)|,Non-data,8
| The proof follows by a small calculation; we defer the details to the full version With this property, we can now prove soundness of our subset rule for sampling from the Laplace distribution Theorem 21 The rule [LAPINT] is sound|,Non-data,8
| Proof Suppose that [[e(cid:104)1(cid:105)]] = v1, [[e(cid:104)2(cid:105)]] = v2, and ||v1 − v2|| = ∆ ≤ k Let the noises be w1 = x(cid:104)1(cid:105) − v1, w2 = x(cid:104)2(cid:105) = v2; note that both samples are distributed as L(0) Note that x(cid:104)1(cid:105) ∈ [a(cid:48), b(cid:48)] exactly when w1 ∈ [a(cid:48) − v1, b(cid:48) − v1], and similarly for x2 and w2|,Non-data,8
| By Proposition 12, to show a lifting on memories, it suffices to find a lifting on the distribution over the sampled variable y, taking f to be the function that maps a memory m to the value m(y) So, it suffices to show L(0) {w1 ∈ I1 ↔ w2 ∈ I2}(cid:93)((cid:48),0) L(0) where I1 (cid:44) [a(cid:48) − v1, b(cid:48) − v1] and I2 (cid:44) [a − v2, b − v2] Since a(cid:104)1(cid:105) + k ≤ a(cid:104)2(cid:105) and b(cid:104)1(cid:105) ≤ b(cid:104)2(cid:105) − k, we know I2 ⊆ I1 Then, we can directly apply Lemma 20 on these two intervals with η = ||I1|| − ||I2|| = (b(cid:48) − a(cid:48)) − (b − a), and we are done|,Non-data,8
 8 PROVING PRIVACY FOR ASVbt We verify differential privacy for the full version of ASVbt with an adaptive adversary that chooses its queries interactively We recall the theorem Theorem 22,Non-data,8
| Let  and δ both be in (0, 1) Set 4(cid:112)2M ln(2/δ)   (cid:48) (cid:44)  63(cid:18) (cid:48) (cid:44) ln  LAPINT (cid:19) exp(η) 1 − exp(−σ/2) Φ (cid:44) ||e(cid:104)1(cid:105) − e(cid:104)2(cid:105)|| ≤ k ∧ (p + k ≤ r < s ≤ q − k) ∧ (q − p) − (s − r) ≤ η ∧ 0 < σ ≤ (s − r) + 2 (cid:96) y1 $← L(e) ∼(cid:104)(cid:48),0(cid:105) y2 $← L(e) : Φ =⇒ y1(cid:104)1(cid:105) ∈ [p, q] ↔ y2(cid:104)2(cid:105) ∈ [r, s] Figure 6: Interval coupling for Laplace If all adversarial queries q are 1-sensitive (ie|,Non-data,8
| ||evalQ(q, d) − evalQ(q, d(cid:48))|| ≤ 1 for every adjacent databases d and d(cid:48)), then ASVbt is (, δ)-differentially private Formally, (cid:96) ASVbt ∼(cid:104),δ(cid:105) ASVbt : Φ =⇒ r(cid:104)1(cid:105) = r(cid:104)2(cid:105) where Φ is defined as ={a,b,N,qs} ∧Adj(d(cid:104)1(cid:105), d(cid:104)2(cid:105)) ∧ b(cid:104)1(cid:105) − a(cid:104)1(cid:105) ≥ γ for γ (cid:44) 6 (cid:48) ln(4/ (cid:48) ) + 4  ln(2/δ) Proof sketch Now, we put everything together to prove ASVbt is (, δ)-private algorithm|,Non-data,8
| We present just the key points of the proof here; the full proof is formalized in the EasyCrypt system We first transform the algorithm to an equivalent algorithm:3 ASVbt(a, b, M, N, d) := i ← 0; l ← []; u $← L/2(0); A ← a − u; B ← b + u; while i < N ∧ ||l|| < M do i(cid:48) ← i; hd ← −1; while i(cid:48) < N do if (hd = −1) q ← A(l); S $← L(cid:48)/3(evalQ(q, d)); if (A ≤ S ≤ B) then hd ← i; i ← i + 1; i(cid:48) ← i(cid:48) + 1; if (hd (cid:54)= −1) then l ← hd :: l; return l The main change is that the loop iterations in Fig 1 are grouped into blocks of queries, each handled by an inner loop Each outer iteration now corresponds to finding a single query between the thresholds|,Non-data,8
| The inner iterations loop through the queries until there is a between threshold query To allow the inner loop to be analyzed in a synchronized fashion, the inner loop always continues up to iteration N, doing nothing for all iterations beyond the first between threshold query This transformation allows us to use both advanced composition and pointwise equality At a high level, we follow four steps|,Non-data,8
| First, we set up the threshold noise, so that the noisy interval [A, B] is smaller in the first run than in the second run; this costs a bit of privacy Then, we handle the loop working inside to out: we apply the adversary rule, the subset coupling, and pointwise equality to the inner loop to show privacy for each block of queries that stops as soon as we see a between threshold query, assuming that the noisy intervals [A, B] are sufficiently large Next, we apply advanced composition to bound the privacy cost of the outer loop, 3We have formally verified equivalence of this program with the program in Fig 1 by using a recently-proposed asynchronous loop rule [3]|,Non-data,8
| still assuming [A, B] is sufficiently large Finally, we use up-to-bad reasoning to remove this assumption, increasing δ slightly for the final (, δ)-privacy bound We now detail each step To reduce notation, we will suppress the adjacency predicate Adj(d(cid:104)1(cid:105), d(cid:104)2(cid:105)) which is preserved throughout the computation and the proof|,Non-data,8
| Threshold coupling Let ct be the initialization command, in- cluding all commands before the loop First, we can prove: (cid:96) ct ∼(cid:104)  2 ,0(cid:105) ct : Φ =⇒ Φ (cid:48) where Φ(cid:48) (cid:44) A(cid:104)1(cid:105) + 1 = A(cid:104)2(cid:105) ∧ B(cid:104)1(cid:105) = B(cid:104)2(cid:105) + 1, by applying the rule [LAPGEN] to ensure u(cid:104)1(cid:105) = u(cid:104)2(cid:105) + 1 as a post-condition This step costs (/2, 0) privacy|,Non-data,8
| The inner loop For the inner loop, we will assume the threshold condition Φ(cid:48) and l(cid:104)1(cid:105) = l(cid:104)2(cid:105) initially; both conditions are preserved by the inner loop We will also assume that the noisy interval [A, B] is sufficiently large:4 Ψ (cid:44) B − A ≥ 6 (cid:48) ln(4/ (cid:48) ) Let ci be the inner loop|,Non-data,8
| We will first prove the pointwise judgment: (cid:96)ci ∼(cid:104)(cid:48),0(cid:105) ci : (cid:48) ∧ Ψ(cid:104)1(cid:105) ∧ l(cid:104)1(cid:105) = l(cid:104)2(cid:105) =⇒ (hd(cid:104)1(cid:105) = v) → (hd(cid:104)2(cid:105) = v) Φ (1) for each index v We focus on the case where 0 ≤ v ≤ N, as other cases are easy First, we apply the [WHILE] rule, with i = 0 except for i = v, where we set v =  2  Whenever we call the adversary for the next query, we know that l(cid:104)1(cid:105) = l(cid:104)2(cid:105), so we may apply adversary rule with cost (0, 0) to ensure that q(cid:104)1(cid:105) = q(cid:104)2(cid:105) throughout|,Non-data,8
| Then, the proof for the rest of the loop body goes as follows: • For the iterations i < v and i > v, we use the rule [LAP- NULL] to couple the noisy query answers S(cid:104)1(cid:105), S(cid:104)2(cid:105) This has no privacy cost and preserves the invariant • For the iteration i = v, suppose that S(cid:104)1(cid:105) ∈ [A(cid:104)1(cid:105), B(cid:104)1(cid:105)] (otherwise we are done) We can apply a coupling for the Laplace distribution, [LAPINT], to ensure that S(cid:104)2(cid:105) ∈ [A(cid:104)2(cid:105), B(cid:104)2(cid:105)] as well|,Non-data,8
| Under Ψ(cid:104)1(cid:105) and the coupling on the noisy thresholds Φ(cid:48), the inner interval [A(cid:104)2(cid:105), B(cid:104)2(cid:105)] has size at least (6/(cid:48)) ln(4/(cid:48)) − 2 Taking (p, q, r, s) = (A(cid:104)1(cid:105), B(cid:104)1(cid:105), A(cid:104)2(cid:105), B(cid:104)2(cid:105)), η = 2, σ = (6/(cid:48)) ln(4/(cid:48)), and k = 1, a calculation shows that [LAPINT] gives a ((cid:48), 0)- lifting so the critical iteration has privacy cost (cid:48) This establishes Eq (1)|,Non-data,8
| By the pointwise equality rule [PW-EQ], we have: (cid:96) ci ∼(cid:104)(cid:48),0(cid:105) ci : Φ (cid:48) ∧ Ψ(cid:104)1(cid:105) ∧ l(cid:104)1(cid:105) = l(cid:104)2(cid:105) =⇒ hd(cid:104)1(cid:105) = hd(cid:104)2(cid:105) 4While Ψ does not have tagged variables, we will later interpret A and B as coming from the first run 64By [FRAME] and some manipulations, we can assume that l(cid:104)1(cid:105) = l(cid:104)2(cid:105) at the end of each iteration of the outer loop The outer loop For the outer loop, we apply advanced compo- sition|,Non-data,8
| Letting co be the outer loop, our choice of (cid:48) and corresponds to the setting in Theorem 7, so we have the following judgment by [AC-WHILE]: (cid:96) co ∼(cid:104)/2,0(cid:105) co : l(cid:104)1(cid:105) = l(cid:104)2(cid:105) ∧ Φ (cid:48) ∧ Ψ(cid:104)1(cid:105) =⇒ l(cid:104)1(cid:105) = l(cid:104)2(cid:105) Since co does not modify the thresholds and preserves Ψ(cid:104)1(cid:105), [FRAME] and some manipulations allows us to move this asser- tion into the post-condition: (cid:96) co ∼(cid:104)/2,0(cid:105) co : l(cid:104)1(cid:105) = l(cid:104)2(cid:105) ∧ Φ =⇒ Ψ(cid:104)1(cid:105) → l(cid:104)1(cid:105) = l(cid:104)2(cid:105) (cid:48) Applying up-to-bad reasoning Finally, we can apply [SEQ] with our judgement for the initialization ci and the outer loop co, giving: (cid:96) ASVbt ∼(cid:104)/2,0(cid:105) ASVbt : Φ0 =⇒ Ψ(cid:104)1(cid:105) → l(cid:104)1(cid:105) = l(cid:104)2(cid:105) for Φ0 (cid:44) ={a,b,N,qs} ∧ Adj(d(cid:104)1(cid:105), d(cid:104)2(cid:105)) ∧ b(cid:104)1(cid:105) − a(cid:104)1(cid:105) ≥ γ|,Non-data,8
| To conclude the proof, all that remains is to remove the assertion Ψ(cid:104)1(cid:105) We will bound the probability that Ψ(cid:104)1(cid:105) does not hold The accuracy rule for the Laplace mechanism gives (cid:96)δ u $← L/2(0) : b − a ≥ γ =⇒ ||u|| ≤ 2  log(1/δ), from which we can conclude (cid:96)δ ASVbt : b − a ≥ γ =⇒ Ψ Finally, applying [UTB-L] yields the desired judgment: (cid:96) ASVbt ∼(cid:104)/2,δ(cid:105) ASVbt : Φ0 =⇒ l(cid:104)1(cid:105) = l(cid:104)2(cid:105) 9|,Non-data,8
| RELATED WORKS Differential privacy [19] has been an area of intensive research in the last decade We refer readers interested in a more compre- hensive treatment of the algorithmic aspects of differential privacy to the excellent monograph by Dwork and Roth [17] Several tools have been developed to support the development of differentially private data analysis PINQ [36] internalizes the use of standard composition in the form of a privacy budget management platform, Airavat [45] uses differential privacy combined with the map-reduce approach, GUPT [40] implements the general idea of sample and aggregate [41]|,Non-data,8
| Other tools implement algorithms targeting specific applications like: location data [35], genomic data [27, 47], mobility data [37], and browser error reports [26] Several tools have been proposed for providing formal verifica- tion of the differential privacy guarantee, using a wide variety of verification approaches: dynamic checking [24, 36], relational pro- gram logic [2, 6] and relational refinement type systems [9], linear (dependent) type systems [29, 42], product programs [7], meth- ods based on computing bisimulations families for probabilistic automata [50, 51], and methods based on counting variants of satis- fiability modulo theories [28] None of these techniques can handle advanced composition, interactive online algorithms and privacy depending on accuracy Barthe et al|,Non-data,8
| [5] present a system for rea- soning about computational differential privacy [39] a relaxation of differential privacy where the adversary are computationally-bound Coupling is an established tool in probability theory, but it seems less familiar to computer science It was only quite recently that couplings have been used in cryptography; according to Hoang and Rogaway [31], who use couplings to reason about generalized Feis- tel networks, Mironov [38] first used this technique in his analysis of RC4 There are seemingly few applications of coupling in formal verification, despite considerable research on probabilistic bisimu- lation (first introduced by Larsen and Skou [33]) and probabilistic relational program logics (first introduced by Barthe et al|,Non-data,8
 [4]) The connection between liftings and couplings was recently noted by Barthe et al [8] and explored for differential privacy by Barthe et al [10],Non-data,8
| The latter uses a coupling argument to prove differen- tially private the sparse vector algorithm that we also consider in this work The additional challenges that we face are: first, the inte- gration of advanced composition, providing a much better privacy bound; second, the proof that sparse vector is differentially private also in the interactive model, which requires additionally to have a logic that permits to reason about the adversary Moreover, Barthe et al [10] do not provide methods to prove privacy using accuracy|,Non-data,8
| In promising recent work, Zhang and Kifer [52] design a system to automatically verify differentially privacy for examples where the privacy proof uses tools beyond the standard composition the- orem, including the Sparse Vector technique Their proof strategy is morally similar to couplings, but their work uses a combination of product programs and lightweight refinement types backed by novel type-inference techniques, rather than a relational program logic like we consider Their system can also optimize the privacy cost, something that we do not consider While their work is highly automated, their system is limited to pure, (, 0) differential privacy, so it cannot verify the algorithms we consider, where privacy fol- lows from accuracy or the advanced composition theorem|,Non-data,8
| Their techniques also seem limited to couplings from bijections; in partic- ular, it is not clear how to prove privacy for examples that use more advanced couplings like the optimal subset coupling 10 CONCLUDING REMARKS We have presented an extension of the logic apRHL [6] that can express three classes of privacy proofs beyond current state-of- the-art techniques for privacy verification: privacy depending on accuracy, privacy from advanced composition, and privacy for inter- active algorithm We have formalized a generalization of the adap- tive Sparse Vector algorithm, known as Between Thresholds [13]|,Non-data,8
| This and other possible generalizations of sparse vector could bring interesting results in domains like geo-indistinguishability [1] For the future, it would be interesting to explore generalizations of differential privacy like the recent notion of concentrated dif- ferential privacy [12, 18] This generalization features a simple composition principle that internalizes the advanced composition principle of standard differential privacy However, it is currently unclear whether the definition of concentrated differential privacy, which involves Rényi divergences, can be modeled using apRHL|,Non-data,8
| Additionally, there is still room for improving the expressivity of apRHL for differential privacy One interesting example combin- ing accuracy and privacy is the large margin mechanism [15] The privacy proof for this algorithm requires careful reasoning about the size of the support when applying pointwise equality, and so- phisticated facts about the accuracy Sparse Vector This example seems beyond the reach of our techniques, but we believe it could be handled by generalizing the existing rules|,Non-data,8
| Finally, it would be interesting to explore a tighter integration of accuracy and privacy proofs We currently use two systems, aHL and apRHL, to verify privacy This can lead to awkward proofs since the two logics can only interact in specific places in the proof (ie|,Non-data,8
|ABSTRACT This paper extends the choice available for secure real num- ber implementations with two new contributions We will consider the numbers represented in form a − φb where φ is the golden ratio, and in form (−1)s · 2e where e is a fixed-point number We develop basic arithmetic operations together with some frequently used elementary functions All the operations are implemented and benchmarked on Sharemind secure multi-party computation framework|,Non-data,9
| It turns out that the new proposals provide viable alternatives to standard floating- and fixed-point implementations from the performance/error viewpoint in various settings How- ever, the optimal choice still depends on the exact require- ments of the numerical algorithm to be implemented Keywords Secure fixed- and floating-point arithmetic, privacy-preserving data analysis, secure computations 1 INTRODUCTION It is estimated that currently human knowledge doubles approximately every year [21]|,Non-data,9
| It means that data analysis facilities should keep up with this pace However, it is not conceivable that all the organisations depending on big data analysis would upgrade their server farms every year Consequently, the only way to manage this growth is to rely on computation as a service, and this is the core reason behind the success of cloud computing business idea On the other hand, outsourcing computations has other restrictions with data privacy being on top of the list|,Non-data,9
| Privacy- preserving data analysis is the holy grail of cloud computing, but unfortunately it is easier said than done There are several paradigms proposed enabling to offload some of the computations to another party in a way that some privacy guarantees could be given Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita- tion on the first page Copyrights for components of this work owned by others than ACM must be honored|,Non-data,9
| Abstracting with credit is permitted To copy otherwise, or re- publish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acmorg|,Non-data,9
| CCS ’16, October 24–28, 2016, Vienna, Austria c(cid:13) 2016 ACM ISBN 978-1-4503-4139-4/16/10 |,Non-data,9
  $1500 DOI: http://dxdoi,Non-data,9
|org/101145/29767492978348 Historically, the first framework was the garbled circuits (GC) approach originally proposed by Yao in 1982 [3,18,23] At its core, GC provides secure function evaluation capa- bility for two mutually distrusting parties, one acting as a garbler and another as evaluator|,Non-data,9
| Soon, secure multi-party computation protocols were de- veloped in a series of seminal papers [4, 9, 12] These pro- tocols can be implemented on top of several basic technolo- gies, with secret sharing being one of the most often used ones [5, 22] The most recent breakthrough in secure computation out- sourcing was achieved by Gentry who proposed the first so- lution to achieve fully homomorphic encryption in 2009 [11] All of these approaches have their strengths and weak- nesses, but their common characteristic is that they intro- duce a remarkable performance penalty to achieve privacy- preserving features|,Non-data,9
| Archer et al have compared the main secure computation implementations of AES-128 block cipher [2] and conclude that the fastest alternative is secure multi-party computing based on linear secret sharing However, an efficient secure computation framework is only the first step, providing basic elementary operations like bit manipulation or integer addition and multiplication Statistical data analysis methods require higher level proto- cols like division and roots|,Non-data,9
| To implement those, data types richer than bits and (modular) integers are required This paper presents a contribution on secure data types, more precisely, secure real number implementations The paper is organised as follows First, we will review the state of the art in secure real number implementations in Section 2 and list the required preliminaries in Section 3|,Non-data,9
| Then, Sections 4 and 5 describe two new proposed approaches based on golden section and logarithmic representations Performance benchmarks and error analysis are presented in Section 6 and some conclusions are drawn in Section 7 2 STATE OF THE ART The first attempt to extend modular integer domains pro- vided by basic secure computation frameworks was made by Catrina et al|,Non-data,9
| They implemented fixed-point arithmetic and applied it to linear programming [6–8] In 2011, Franz and Katzenbeisser [10] proposed a solu- tion to implementation of floating-point arithmetic for se- cure signal processing Their approach relies on two-party 553computations working over garbled circuits, and they have not provided any actual implementation or benchmarking results In 2013, Aliasgari et al|,Non-data,9
| designed and evaluated floating- point computation techniques and protocols for square root, logarithm and exponentiation in a standard linear secret sharing framework [1] This approach was extended in 2015 by Kamm and Wil- lemson who implemented and optimised a number of nu- meric primitives, building a complete solution for privacy- preserving satellite collision analysis [13] In order to provide further improvements, Krips and Wil- lemson [15, 16], and Kerik et al [14] have proposed and im- plemented several tricks that increase the efficiency of spe- cific elementary functions used under various restrictions|,Non-data,9
| The standardised IEEE 754 format is not well suited for secure computations on oblivious values For example, it has an exceptional not-a-number value and it assumes explicit bit access that is inefficient to implement on top of modular integer arithmetic Thus, all of the aforementioned imple- mentations use a custom format, ignoring some of the details of IEEE 754 standard The first full standard-compliant im- plementation was achieved by Pullonen and Siim who used a hybrid of garbled circuits and secret sharing [20]|,Non-data,9
| However, the overhead required to support the whole standard is too high for larger data volumes 3 PRELIMINARIES Our protocols will make use of both public and private (protected) values To express that x is private, we will de- note it by(cid:74)x(cid:75)|,Non-data,9
| Concrete instantiation of the value protection mechanism may vary between implementations In princi- ple, any secure computation framework (say, garbled cir- cuits, fully homomorphic encryption or secret-sharing based multi-party computation) may be used However, we will make some assumptions about the un- derlying framework We will assume that the framework provides access to modular integer arithmetic|,Non-data,9
| In addition to integers, we use several kinds of fixed-point numbers Two’s complement and biased fixed-point numbers will be represented and hence also notated as integers Fixed-point numbers that use a sign bit instead of two’s complement or biased representation will be denoted as tuples (s, a) A tuple (s, a) that is a signed fixed-point number with radix- point m signifies the value (−1)s · a · 2−m|,Non-data,9
| We will also assume access to the following operations • Addition of two private values(cid:74)x(cid:75) and(cid:74)y(cid:75) denoted as (cid:74)x(cid:75) +(cid:74)y(cid:75) If the underlying protection framework is linear, this is equal to(cid:74)x + y(cid:75) • Multiplication of a private value(cid:74)x(cid:75) by a public scalar c denoted as c·(cid:74)x(cid:75)|,Non-data,9
| If the underlying protection frame- work is linear, this is equal to(cid:74)c · x(cid:75) • Multiplication of two private values (cid:74)x(cid:75) and (cid:74)y(cid:75) de- noted as(cid:74)x(cid:75) ·(cid:74)y(cid:75) If the underlying framework is not fully homomorphic, evaluating this primitive generally requires communication between the computing par- ties • Standard comparison operators >, ≥, etc|,Non-data,9
| The inputs of these operators will be protected integer values and outputs will be protected bits containing the values of the corresponding predicate evaluations if the bit b = 1 then • Standard Boolean operations (conjunction, disjunction, xor) on one-bit protected values with the output being a protected bit again type consisting of several integer values Note that while usually x and y are integers, they might also refer to more complicated types that consist of several integer values|,Non-data,9
| • ObliviousChoice((cid:74)b(cid:75),(cid:74)x(cid:75),(cid:74)y(cid:75)): this function outputs (cid:74)x(cid:75), otherwise it outputs (cid:74)y(cid:75) • Swap((cid:74)c(cid:75),(cid:74)x(cid:75),(cid:74)y(cid:75)) outputting ((cid:74)x(cid:75),(cid:74)y(cid:75)) if c = 0 and ((cid:74)y(cid:75),(cid:74)x(cid:75)) if c = 1 Here also x and y can refer to a • ConjBit({(cid:74)xi(cid:75)}n i=0,(cid:74)y(cid:75)) takes an array of bits x and a • PublicBitShiftRightProtocol((cid:74)x(cid:75), k) This function Takes a protected value(cid:74)x(cid:75) and a public integer k, and outputs(cid:74)x (cid:29) k(cid:75) where x (cid:29) k is equal to x shifted right • BitExtract((cid:74)x(cid:75)) takes a protected value(cid:74)x(cid:75) and out- by k bits|,Non-data,9
| x (cid:29) k is also equal to x/2k rounded down, so sometimes in the protocol we will use syntactic sugar like x/2k to denote x (cid:29) k single bit y and finds the conjunction of every bit of x with y puts a vector of protected bits corresponding to the bit representation of x Note that when we use linear integer protection mechanism (like secret sharing) this operation is rather expensive|,Non-data,9
| • MSNZB({(cid:74)bi(cid:75)}n−1 i=0 ) (Most Significant Non-Zero Bit) takes a vector of protected bits and outputs a similar vec- tor, where only the highest 1-bit (ie the 1-bit with the largest index value) has remained and all the other bits are set to 0 If all the input bits are 0, they will also remain so in the output|,Non-data,9
| j=0}k {{pi,j}l • Vectorised fixed-point polynomial evaluation protocol cPoly but more efficient than evaluating each polyno- mial independently Therefore, both the range and the domain are [0, 1) Implementation details can be found in [14] a public polynomial p = {pi}l sider that the inputs are fixed-point numbers and that • Polynomial evaluation protocol cPoly(p,(cid:74)x(cid:75)) evaluates i=0 on (cid:74)x(cid:75)|,Non-data,9
| We con- both(cid:74)x(cid:75) and the output have 0 bits before radix point cPolyArr(p,(cid:74)x(cid:75)) takes an array of polynomials p = i=0 and an argument(cid:74)x(cid:75) and evaluates all the polynomials on (cid:74)x(cid:75) This protocol is similar to • Pick({(cid:74)xi(cid:75)}l i=0,(cid:74)n(cid:75)) takes a shared array {(cid:74)xi(cid:75)}l a shared index(cid:74)n(cid:75) and returns(cid:74)xn(cid:75) • Truncate((cid:74)x(cid:75), n) takes an integer(cid:74)x(cid:75) and casts it down that the length of (cid:74)x(cid:75) is no less than n bits|,Non-data,9
| • ConvertUp((cid:74)x(cid:75), k, l) takes in a shared k-bit two’s com- plement integer (cid:74)x(cid:75) and returns a shared l-bit two’s to n bits by discarding the highest bits We presume If the underlying protection framework is linear then trun- cating a shared integer is achieved by truncating all the shares complement integer that has the same value We pre- sume that k < l|,Non-data,9
| i=0 and 554• FixSubtract(((cid:74)s0(cid:75),(cid:74)a0(cid:75)), ((cid:74)s1(cid:75),(cid:74)a1(cid:75))) takes two signed fixed-point numbers ((cid:74)s0(cid:75),(cid:74)a0(cid:75)) and ((cid:74)s1(cid:75),(cid:74)a1(cid:75)) and returns their difference as a signed fixed-point number For benchmarking, we will implement our algorithms on Sharemind1 multi-party computation engine that relies on linear secret sharing and provides all the primitive opera- tions listed above It was recently shown by Pettai and Laud that, when properly composed, Sharemind protocols provide privacy against active adversaries [19] They also produced a soft- ware toolkit allowing for the respective analysis to run on the Sharemind protocols implemented in the domain spe- cific language developed by Randmets and Laud [17]|,Non-data,9
| All the protocols described in this paper have been formally verified using this toolkit 4 GOLDEN SECTION NUMBERS We shall now describe a real number type that can depict signed real numbers, has free addition, and is reasonably efficient for other operations We use a tuple of secret signed two’s complement integers ((cid:74)a(cid:75),(cid:74)b(cid:75)) to denote the positive real number a− φb|,Non-data,9
| We call these numbers golden section numbers or golden numbers We may refer to these numbers as either a− φb or (a, b) For a given real number x, we denote its (approximate) golden representation as gx For a golden section number a − φb, we refer to a as its integer representand and to b as its φ- representand|,Non-data,9
| Note that we will be using a and b throughout this section to refer to the integer representand and the φ- representand of the number being considered, respectively We will now see how addition and multiplication work on golden section numbers Addition is quite straightforward: a − φb + c − φd = (a + c) − φ(b + d) For multiplication, we note that φ2 = φ + 1 and thus obtain (a − φb) · (c − φd) = (ac + bd) − φ(bc + ad − bd) |,Non-data,9
| Golden numbers are not monotone with respect to repre- sentands Hence, finding a good approximation for a given number is a non-trivial problem on its own (1) Definition 1 Given a real number x, we say that the tu- ple of integers (a, b) is a (k, ε)-approximation of x if ||a|| ,||b|| ≤ 2k and ||a − φb − x||≤ ε|,Non-data,9
| If k is implied by the context or not important in the context, we shall refer to (a, b) as just an ε-representation of x If ε is implied or not important, we shall refer to (a, b) as a (k,·)-representation of x If neither are important (or are implied) we refer to (a, b) as just as a representation of x It is preferable to use such a (k, ε)-approximation of a number where both k and ε are relatively small|,Non-data,9
| While it is clear that a small ε implies a small error and is thus better, the reason why a small k is good is a bit more difficult Namely, we observe that when we multiply two golden sec- tion numbers x and y with (k,·)-approximation, then their product has a (2k + 1,·)-approximation We will later see how we can replace a golden section number x with a (k, )- representation of it We shall assume throughout the section that the error ε is quite a small number, several orders of magnitude smaller 1https://sharemind|,Non-data,9
|cyberee/ than 1 Thus, when we discuss how either the number or the representands need to be bounded by some quite large numbers, we shall ignore ε in those analyses as rounding down used in finding those large numbers will cover any overflow ε might cause Golden numbers are also relatively dense in real numbers|,Non-data,9
| Lemma 1 For a real number x which satisfies ||x|| < φs+1, and a positive integer k, there exists a (φs+1 + φk+1, φ−k)- approximation of x no i so that ai = 1 and ai+1 = 1 would both hold Proof|,Non-data,9
| We note that we can write every positive real number as a (possibly infinite) sum of powers of φ We can i=−∞ aiφi where ai ∈ {0, 1} and where there is write x =(cid:80)s We also note that given such a requirement,(cid:80)s(cid:48) Thus, if we choose to represent x as x = (cid:80)s (cid:80)s i=s(cid:48) aiφi||≤ φs(cid:48) The following three facts about Fibonacci numbers Fk φs(cid:48)+1 holds for any s(cid:48) the error we make is no greater than φs(cid:48) (k ∈ Z) are common knowledge and are easily proven: i=−∞ aiφi < i=s(cid:48) aiφi, ||x − , that is,  • φk = Fkφ + Fk−1 for every k, • Fk ≈ φk for every positive k, and • (cid:80)k s(cid:88) i =s(cid:48) aiφi = s(cid:88) s(cid:48)(cid:88) i=0 i=0 Fk = Fk+1 − 1 for every positive k|,Non-data,9
| From these facts it follows that ai(Fiφ + Fi−1) ≤ s(cid:88) ||Fi||φ + ||Fi−1||= i=s(cid:48) ||Fi||φ + ||Fi−1||+ i=s(cid:48) ||Fi||φ + ||Fi−1||= s(cid:88) i=1 (Fs(cid:48)+1 − 1)φ + (Fs(cid:48) ) + (Fs+1 − 2)φ + Fs − 1 = (Fs(cid:48)+1 + Fs+1 − 3)φ + Fs + Fs(cid:48) − 1 We see that taking k = −s(cid:48) gives us the result However, there is a problem with this number system Namely, we may use large integers to depict small real num- bers|,Non-data,9
| This, however, means that when multiplying several small real numbers, the representands may grow exponen- tially and may overflow very fast We would like to keep the absolute value of the representands to be smaller than some reasonable constant The solution for this comes from the fact that there may be several different (k, ε)-approximations of a number Thus we want a method for replacing a (k1, ε1)-approximation with a (k2, ε2)-approximation where ε2 may be slightly greater than ε1, but where k2 < k1|,Non-data,9
| We shall use a method that we shall call normalization, which is, in essence, subtracting a suitable representation of 0 from the golden section number Definition 2 We say that a golden section number is (cid:96)-normalized if the absolute value of its integer representand is not greater than (cid:96) Note that this definition depends only on the integer rep- resentand and not the φ-representand of a golden number, and that a too large φ-representand could also cause similar overflow problems as a too large integer representand does|,Non-data,9
| 555However, we shall see that if the absolute value of integer representand is smaller than (cid:96) then, provided that we put an extra constraint on the size of the numbers that we can represent, the absolute value of the φ-representand shall also be smaller than (cid:96) More precisely, we shall require that ||a − φb||≤ (cid:96)(φ − 1) Lemma 2 Let a golden section number a−φb satisfy also ||a − φb||≤ (cid:96)(φ − 1) and be (cid:96)-normalized|,Non-data,9
| Then ||b||≤ (cid:96) Proof Using the reverse triangle inequality, we obtain ||||a|| − ||bφ|||| ≤ ||a − bφ|| ≤ (cid:96)(φ − 1) From this we obtain ||bφ||− (cid:96)(φ− 1) ≤ ||a|| ≤ ||bφ|| + (cid:96)(φ− 1)|,Non-data,9
| Consider the first half — ||bφ||−(cid:96)(φ−1) ≤ ||a||, from which we obtain ||bφ||−(cid:96)φ+(cid:96) ≤ (cid:96), ie ||bφ|| ≤ (cid:96)φ This is equivalent to ||b|| ≤ (cid:96)|,Non-data,9
| We thus will assume from this point on that if we are talking about a golden section number, then ||a− φb||≤ (cid:96)(φ− 1) We want to settle for a general value for (cid:96) that we will use across the article The main idea for choosing (cid:96) shall be the idea that if we multiply together two (cid:96)-normalized numbers, no overflow should happen We shall generally take (cid:96) = , where n refers (cid:22)(cid:113) (cid:23) 2n−1−1 2 to the bit length of a and b|,Non-data,9
| (cid:22)(cid:113) (cid:23) Lemma 3 If two golden section numbers a−φb and c−φd -normalized, then both the integer represen- 2n−1−1 are 2 tand and the φ-representand of their product are smaller than 2n−1 Proof Let us denote a − φb · c − φd with x − φy, i|,Non-data,9
|e x = ac + bd and y = ad + bc − bd We give the proof for x ≥ 0 as the proof for x < 0 is analogous We assume that ||a|| ,||b|| ,||c|| ,||d|| ≤ (cid:96)|,Non-data,9
| Thus x = ac + bd ≤ 2(cid:96)2 < 2n−1 We assume that the absolute value of the product x − φy is no greater than (cid:96)(φ − 1) In a similar way as we did in the proof of Lemma 2, we obtain that ||yφ||−(cid:96)(φ − 1) ≤ x Thus ||yφ||≤ 2(cid:96)2 + (cid:96)(φ − 1) which gives us ||y||< 2(cid:96)2 < 2n−1|,Non-data,9
| From now on, we shall speak of normalized numbers which shall mean -normalized numbers Likewise, (cid:96) (cid:22)(cid:113) (cid:22)(cid:113) (cid:23) (cid:23) 2n−1−1 2 2n−1−1 2  shall refer to 41 Normalization In the previous subsection we described a problem where representands grow exponentially on multiplication and threaten to overflow really fast|,Non-data,9
| Thus, we want to significantly reduce the absolute values of the representands of the number while keeping its value relatively the same There are various possibilities for this, but due to the na- ture of the task, they are equivalent to deducing suitable ̄ε-representations of zero from the number Namely, sup- pose that we normalized a − φb and ended up with a(cid:48) − φb(cid:48) Let the error made in this process be no greater than ̄ε, ||a − φb − (a(cid:48) − φb(cid:48))|| ≤ ̄ε|,Non-data,9
| This means that ||(a − a(cid:48)) − ie φ(b−b(cid:48))||≤ ̄ε, ie|,Non-data,9
| ||(a − a(cid:48)) − φ(b − b(cid:48))|| is an ̄ε-representation of 0 The smaller the ̄ε, the smaller the error arising from the normalization process and thus it is desirable to obtain ̄ε-representations of 0 where ̄ε is very small The process should also be not very resource-consuming We first note that, thanks to Lemma 2, it suffices to nor- malize only the integer representand of the number|,Non-data,9
| If the normalization error is small, then the result will still be an ε-representation of a golden number, and thus the absolute value of the φ-representand of the result will also be smaller than (cid:96) Note also that in order to normalize an integer represen- tand down to 2k, we need either the n − k most signifi- cant bits to be zero (if this repesentand is positive) or the n − k most significant bits to be one (if it is negative) in the end-result (In principle, k can be chosen freely, but we 2 − 1) We note that using the proto- col BitExtract((cid:74)·(cid:75)), we can have access to the individual bits generally take k = n −an−12n−1 +(cid:80)n−2 If the bit representation of a is a0a1 |,Non-data,9
   an−1 then a = i=0 ai2i (recall we are using two’s comple- ment representation) In the positive case we could make the i-th bit of a zero by deducting 2i from a,Non-data,9
| We will later confirm that in the negative case in a similar fashion we could make the ith bit zero by adding 2i to a In the end we would use an−1 to obliviously choose between the negative and positive cases of a φ (cid:105) (cid:105) (cid:104) 2i (cid:104) 2i Thus we shall describe a method where for every bit ai ), i|,Non-data,9
|e  We would perform the BitExtract((cid:74)a(cid:75)) protocol of a we have a representation of 0 that is (2i, 2i − φ and then use the higher bits of a to perform oblivious choice about whether to deduce or add (2i, ) from a or not In i=k ai2i = the positive case we would end up with a −(cid:80)n−2 (cid:80)k−1 i=0 ai2i ≤ 2k − 1 and in the negative case with n−1(cid:88) n−2(cid:88) n−2(cid:88) (1 − ai)2i = −2n−1 + (1 − ai)2i (1 − ai)2i n−2(cid:88) n−2(cid:88) n−2(cid:88) ai2i + ai2i + 2i + a + i =k i=k i=k i=0 i=0 φ (cid:105) (cid:104) 2i φ (ai − 1)2i + (1 − ai)2i i=0 = −1 + = −1 − n−2(cid:88) n−2(cid:88) k−1(cid:88) k−1(cid:88) = −1 + ≥ −1 + i=0 i=0 i=k (ai − 1)2i −2i = −2k|,Non-data,9
| i=0 (cid:105) (cid:104) 2i We would then perform oblivious choice between them using an−1 We would end up with a number where the absolute value of a is no greater than 2k which is small enough for a suitable k φ (cid:105) (cid:104) k However, this approach has a problem – namely, (2i, φ ]||||k ∈ Z} is quite uniformly distributed in [0, φ ) tends to be a very poor representation of 0 The set {||k − φ[ k 2 ) and thus for most integers k, (k − φ ) is a poor representation of 0 as the error is too large|,Non-data,9
| Thus we want to modify our algorithm somewhat — we want to find numbers xi that are close to 2i but where ||xi − φ ||2i − xi|| to be small, since if ||2i − xi|| is too large, then the number that we obtain after the normalization process is still not normalized (cid:105)|| is very small On the other hand, we also wish (cid:104) xi φ φ 556We shall now describe the algorithm for normalization We use a number of pairs of public constants (xi, yi) such that xi − φyi ≈ 0 and that xi is close to 2i|,Non-data,9
| After describing the algorithm we shall see what properties they must satisfy The protocol is formalized in Algorithm 1 We are given a golden section number(cid:74)a(cid:75)− φ(cid:74)b(cid:75) We per- form bit decomposition on(cid:74)a(cid:75) and obtain its bits(cid:74)a0(cid:75), |,Non-data,9
|   , (cid:74)an−1(cid:75) Out of these, we are interested in bits with large indices as the less significant bits will not be important in normalizing|,Non-data,9
| Let us consider the positive and negative cases separately for easier reading In the algorithm, we will com- pute both of them and then use an−1 to obliviously choose between them First let us consider the case where a is pos- itive If ai = 1 and n − 1 > i ≥ k, we will deduce xi from a and yi from b|,Non-data,9
| This is done by multiplying xi with(cid:74)ai(cid:75) and deducing(cid:74)xiai(cid:75) from(cid:74)a(cid:75), and likewise, multiplying yi with (cid:74)ai(cid:75) and deducing(cid:74)yiai(cid:75) from(cid:74)b(cid:75) Note that these protocols are local and thus practically free Likewise, in the negative case, if ai = 0 and n− 1 > i ≥ k, we will add xi to a and yi to b following inequalities: (cid:88) (2i − xi) ≤ k−1(cid:88) i:2i<xi k≤i≤n−2 i=0 ≤ 2k − 1 + n−2(cid:88) (cid:88) i=k ai2i + ai(2i − xi) (cid:88) (xi − 2i) ≥ −1 + k−1(cid:88) i:2i<xi k≤i≤n−2 i=0 ≥ −2k + i(cid:48):2i(cid:48) >xi k≤i≤n−2 (2i(cid:48) − xi(cid:48) ) , n−2(cid:88) (ai − 1)2i + (1− ai)(xi − 2i) (cid:88) i=k (xi − 2i) |,Non-data,9
| in order to achieve that a −(cid:80)n−2 (cid:80)n−2 i=k aixi or a + Thus, i=k (1 − ai)xi belongs the interval (−(cid:96), (cid:96)), it suffices for i:2i>xi k≤i≤n−2 both cases that (2i − xi) −(cid:96) ≤ (cid:88) (cid:88) i:2i<xi k≤i≤n−2 i(cid:48):2i(cid:48) >xi k≤i≤n−2 2k + (2i(cid:48) − xi(cid:48) ) ≤ (cid:96)  Thus we arrive to the following definition Definition 3 A (k, (cid:96), ε, n)-normalization set is a set of integers {xk, |,Non-data,9
|   , xn−1, yk,  |,Non-data,9
|  , yn−1} with the following prop- erties: 1 (cid:80)n−2 2 (cid:80) 3|,Non-data,9
| 2k +(cid:80) i:2i<xi k≤i≤n−2 i=k ||xi − φ · yi||≤ ε (2i − xi) ≥ −(cid:96) (2i(cid:48) − xi(cid:48) ) ≤ (cid:96) i(cid:48):2i(cid:48) >xi k≤i≤n−2 There is some freedom in choosing k, with lower values giving us more freedom in choosing the normalization set, but reducing the number of values that a normalized number can have 42 Finding Normalization Sets The key part of finding normalization sets is finding in- teger pairs (xi, yi) where on the one hand xi is very close yi to φ and on the other hand xi must be very close to 2i In essence, we have to find suitable constants xi, since yi is defined by xi as [ xi φ ]|,Non-data,9
| Note that this can be considered a minimization problem – we have to guarantee that proper- ties 2 and 3 in Definition 3 hold, but how loosely or strictly they hold is not really important for us i=k ||xi − φ· yi|| as much as possible in order to minimize the error caused by the normalization protocol Thus we can see finding the normalization set as an optimisation problem to minimize On the other hand, we do want to minimize(cid:80)n−1 (cid:80)n−1 i=k ||xi − φ · [ xi For easier notation, let us define err(x) := x − φ[ x φ ] φ ]|| with the constraints 2|,Non-data,9
| and 3 in Defini- tion 3 holding Result: Given a golden section number and a normalization set, returns the number normalized according to the set and i=k i=k,{yi}n Algorithm 1: GoldenNorm Data: (cid:74)a(cid:75),(cid:74)b(cid:75),{xi}n i=0 ← BitExtract((cid:74)a(cid:75)); 1 {(cid:74)ai(cid:75)}n−1 i=k ← {(cid:74)ai(cid:75)}n−2 2 {(cid:74)zi(cid:75)}n−2 i=k · {xi}n−2 i=k ← {(cid:74)ai(cid:75)}n−2 3 {(cid:74)wi(cid:75)}n−2 i=k ; i=k · {yi}n−2 i(cid:75)}n−2 i=k ← {(cid:74)1 − ai)(cid:75)}n−2 4 {(cid:74)z(cid:48) i=k ; i(cid:75)}n−2 5 {(cid:74)w(cid:48) i=k ← {(cid:74)(1 − ai)(cid:75)}n−2 (cid:74)a(cid:48)(cid:75) ←(cid:74)a(cid:75) −(cid:74)zi(cid:75); (cid:74)b(cid:48)(cid:75) ←(cid:74)b(cid:75) −(cid:74)wi(cid:75); (cid:74)a(cid:48)(cid:48)(cid:75) ←(cid:74)a(cid:75) +(cid:74)z(cid:48) i(cid:75); i(cid:75); (cid:74)b(cid:48)(cid:48)(cid:75) ←(cid:74)b(cid:75) +(cid:74)w(cid:48) 6 for i ← k to n − 2 do 8 7 9 i=k · {xi}n−2 i=k ; i=k · {yi}n−2 i=k ; 10 11 end 12 (cid:74)a(cid:75) ← ObliviousChoice((cid:74)an−1(cid:75),(cid:74)a(cid:48)(cid:75),(cid:74)a(cid:48)(cid:48)(cid:75)); 13 (cid:74)b(cid:75) ← ObliviousChoice((cid:74)an−1(cid:75),(cid:74)b(cid:48)(cid:75),(cid:74)b(cid:48)(cid:48)(cid:75)); 14 return(cid:74)a(cid:75),(cid:74)b(cid:75) Now we shall see what properties the pairs (xi, yi) must satisfy so that the final result would have an absolute value no greater than (cid:96) and that its difference from the original golden number would be no greater than |,Non-data,9
| We want the end result, which is a −(cid:80)n−2 positive case and a +(cid:80)n−2 i=k aixi in the i=k (1 − ai)xi in the negative case, to be in the interval (−(cid:96), (cid:96)) We note that in the positive k−1(cid:88) case the following equality holds n−2(cid:88) a − n−2(cid:88) ai(2i − xi) ai2i + aixi = i=k i=0 i=k Likewise, in the negative case this holds|,Non-data,9
| k−1(cid:88) n−2(cid:88) n−2(cid:88) a + (1− ai)xi = −1 + (ai − 1)2i + (ai − 1)(2i − xi) i=k i=0 i=k In attempting to estimate these quantities with inequal- ities, it is important whether 2i is smaller or greater than xi Thus, by distinguishing these cases, we arrive at the 557We searched for these coefficients using the facts that err(Fk) tend to be small and that when when x and x(cid:48) are such that if err(x) and err(x(cid:48)) are small, then also err(x+x(cid:48)) is small, more precisely, ||err(x + x(cid:48))|| ≤ ||err(x)|| + ||err(x(cid:48))|| Thus, we would take a small interval around a power of 2 and find all elements zi for which err(zi) was suitably small|,Non-data,9
| Then, in a larger interval, the only possible candidates w for a minimal ||err(w)|| had to have the format zi + j · Fk Thus we needed to check these elements to find a minimal one If necessary, this process could be iterated 4|,Non-data,9
|3 Protocols for golden section numbers We shall now present a few protocols on golden numbers We have already described addition, multiplication and nor- malization protocols and thus we will not discuss them any further here We will denote with GoldenMult((cid:74)x(cid:75),(cid:74)y(cid:75)) golden number multiplication as described in equation (1) Generally we as- sume that all functions get normalized inputs, unless speci- fied otherwise|,Non-data,9
| We will thus not normalize the inputs before performing multiplication, but will normalize the product In some cases, such as when it is the final result that will be declassified, the product can be left unnormalized refer to computing the product(cid:81)k−1 We will also use the function GoldenProd(x0,  |,Non-data,9
|  , xk−1) to i=0 xi using GoldenMult Computing the product of k−1 golden numbers takes l·log k rounds where l is the number of rounds required for a single multiplication 4|,Non-data,9
|31 Multiplication by φ We will describe now a protocol for multiplying an inte- ger by the golden ratio This protocol, presented in Algo- rithm 2, will be useful for performing golden-to-fix conver- sion described in Section 43|,Non-data,9
|2 i=0 Algorithm 2: MultWithPhi Data: (cid:74)x(cid:75), n, m, (m > n),{pi}∞ Result: (cid:74)xφ(cid:75) 1 {(cid:74)xi(cid:75)}n−1 i=0 ← BitExtract((cid:74)x(cid:75)); 2 (cid:74)s0(cid:75) ←(cid:80)m i=0 pi · ((cid:80) j=0(cid:74)xj(cid:75) · 2m+j−i); i=m+1 pi · ((cid:80) 3 (cid:74)s1(cid:75) ←(cid:80)m+n j=i−m(cid:74)xj(cid:75) · 2m+j−i); 4 (cid:74)s(cid:75) ←(cid:74)s0(cid:75) +(cid:74)s1(cid:75); i=0 ← BitExtract((cid:74)−x(cid:75)); i(cid:75)}n−1 5 {(cid:74)x(cid:48) 0(cid:75) ←(cid:80)m i=0 pi · ((cid:80) j=0(cid:74)x(cid:48) j(cid:75) · 2m+j−i); 6 (cid:74)s(cid:48) 1(cid:75) ←(cid:80)m+n i=m+1 pi · ((cid:80) j(cid:75) · 2m+j−i); 7 (cid:74)s(cid:48) j=i−m(cid:74)x(cid:48) 0(cid:75) +(cid:74)s(cid:48) 8 (cid:74)s(cid:48)(cid:75) ←(cid:74)s(cid:48) 1(cid:75); 9 (cid:74)r(cid:75) ← ObliviousChoice((cid:74)xn−1(cid:75),(cid:74)s(cid:48)(cid:75),(cid:74)s(cid:75)); 10 return ((cid:74)xn−1(cid:75),(cid:74)r(cid:75)) The protocol takes in a secret signed integer (cid:74)x(cid:75) and re- turns a signed fixed-point number that represents(cid:74)xφ(cid:75) This choice|,Non-data,9
| We start with a secret integer (cid:74)x(cid:75) We also have put(cid:74)x(cid:75) We then compute(cid:80)m i=0 We extract the bits(cid:74)xi(cid:75) from the in- j=0(cid:74)xj(cid:75) · 2m+j−i) + (cid:80)m+n i=m+1 pi·((cid:80) j=i−m(cid:74)xj(cid:75)·2m+j−i) that represents xφ if x is protocol needs one bit-extraction protocol and one oblivious the bits of φ, {pi}∞ positive|,Non-data,9
| We then do the same for −x and obliviously choose between the two cases based on the last bit of x The last bit of x is also the sign of the resulting fixed-point number, as multiplication with φ does not change the sign i=0 pi · ((cid:80) 43|,Non-data,9
|2 Conversion to a fixed-point number Algorithm 3 presents the protocol for converting a golden section number to a fixed-point number Result: A fixed-point number that represents the same 2 // we will also obtain an−1 as a side product value as the golden number input Algorithm 3: GoldToFix Data: (cid:74)a(cid:75) − φ(cid:74)b(cid:75), n, m, (n > m) 1 (cid:74)bigA(cid:75) ← ConvertUp((cid:74)a(cid:75), n, n + m); 3 (cid:74)f ixA(cid:75) ← ((cid:74)an−1(cid:75),(cid:74)bigA(cid:75) · 2m); 4 (cid:74)f ixB(cid:75) ← MultWithPhi((cid:74)b(cid:75), n, m); 5 (cid:74)f ix(cid:75) ← FixSubtract((cid:74)f ixA(cid:75),(cid:74)f ixB(cid:75)); 6 return(cid:74)f ix(cid:75) from the ConvertUp function While conversion functions are important on their own, here we will also use them as subprotocols in more compli- cated algorithms|,Non-data,9
| Since we have access to MultWithPhi function, convert- ing a golden number to a fixed-point number is trivial We need to convert both the integer representand and the φ- representand to a respective fixed-point number and deduce the second from the first 43|,Non-data,9
|3 Return a constant based on power of two We will see that in both the inverse protocol and the square root protocol, we get a secret golden number (cid:74)gx(cid:75) return a golden number(cid:74)gzi(cid:75) and, based on the interval [2i, 2i+1) its absolute value is in, The protocol for performing this operation is presented in Algorithm 4 Result: Will return the sign of the input and (xj, yj) if gx ∈ [2j, 2j+1) Algorithm 4: TwoPowerConst Data: (cid:74)gx(cid:75),{gzi} = {(xi, yi)}, n, m < n 1 (cid:74)sign(cid:75),(cid:74)f(cid:75) ← GoldToFix((cid:74)gx(cid:75)); 2 {(cid:74)bi(cid:75)}n+m−1 i=0 ← MSNZB((cid:74)f(cid:75)); 3 ((cid:74)s(cid:75),(cid:74)t(cid:75)) ←(cid:80)n−1 4 return(cid:74)sign(cid:75), ((cid:74)s(cid:75),(cid:74)t(cid:75)) i=−m((cid:74)bi(cid:75) · xi,(cid:74)bi(cid:75) · yi); The computation is performed the following way|,Non-data,9
 We con- vert the input to a fixed-point number We then perform MSNZB on the integer representative of the fixed-point num- ber and compute the scalar product with the set of public coefficients {gzi} Note that finding the scalar product is a local operation Inverse 4,Non-data,9
|34 We shall now describe the protocol for computing the in- verse of a secret golden number (cid:74)gx(cid:75) A protocol for com- puting the inverse of numbers in [05, 1] is presented in Al- gorithm 5|,Non-data,9
| It uses the approximation 1 + 1) that works well in the neighbourhood of 1 (being equivalent to the respective Taylor series) x =(cid:81)((1 − x)2i The protocol for computing the inverse of a golden number is presented in Algorithm 6 We use Algorithm 5 as a subprotocol Given gx as an input, we need to find gx(cid:48) and gy so that x(cid:48) ∈ [0|,Non-data,9
|5, 1] and 5584 5 end Algorithm 5: HalfToOneInv 3 for i ← 0 to k − 1 do Data: (cid:74)gx(cid:75)(x ∈ [05, 1]), n, m, (n > m), k Result: (cid:74)g 1 x(cid:75) 1 (cid:74)gy(cid:75) ← 1 −(cid:74)gx(cid:75); 2 (cid:74)gy0(cid:75) ←(cid:74)gy(cid:75); (cid:74)gyi+1(cid:75) ← GoldenMult((cid:74)gyi(cid:75),(cid:74)gyi(cid:75)); 6 (cid:74)gz(cid:75) ← GoldenProd((cid:74)gy0(cid:75) + 1,(cid:74)gy1(cid:75) + 1,   |,Non-data,9
| ,(cid:74)gyk(cid:75) + 1); 7 return(cid:74)gz(cid:75) Data: (cid:74)gx(cid:75), n, m, (n > m),{(xi, yi)} x(cid:75) Result: (cid:74)g 1 1 ((cid:74)sign(cid:75),(cid:74)gy(cid:75)) ← TwoPowerConst((cid:74)gx(cid:75),{gzi}); 2 (cid:74)gx(cid:48)(cid:75) ← GoldenMult((cid:74)gx(cid:75),(cid:74)gy(cid:75)); 3 (cid:74)gz(cid:75) ← HalfToOneInv((cid:74)gx(cid:48)(cid:75)); 4 (cid:74)gw(cid:75) ← GoldenMult((cid:74)gy(cid:75),(cid:74)gz(cid:75)); 5 (cid:74)gu(cid:75) ← ObliviousChoice((cid:74)sign(cid:75),−(cid:74)gw(cid:75),(cid:74)gw(cid:75)); 6 return(cid:74)gu(cid:75) Algorithm 6: GoldInv x · 1 x(cid:48) = 1 that x · y = x(cid:48) We can then use the HalfToOneInv function to compute 1 y which we shall then multiply with y to obtain 1 x  y is an approximation of a suitable power of 2 Here the gzi are approximations of different powers of 2 – when x ∈ [2j, 2j+1), then TwoPowerConst should return ap- proximately 2−j−1|,Non-data,9
| We compute y using the function TwoPowerConst((cid:74)gx(cid:75),{gzi}) We compute(cid:74)gx(cid:48)(cid:75) by multiplying(cid:74)gx(cid:75) and(cid:74)gy(cid:75) We then use the HalfToOneInv protocol on(cid:74)gx(cid:48)(cid:75), obtaining(cid:74)g 1 x(cid:48)(cid:75) To Finally, since our current result is approximately(cid:74)g(cid:12)(cid:12) 1 (cid:12)(cid:12)(cid:75), get this back to the correct range, we multiply it by(cid:74)gy(cid:75)|,Non-data,9
 we have to make an oblivious choice between the result and its additive inverse so that it would have the correct sign 435 Square Root Protocol Algorithm 7 presents the protocol for finding the square x(cid:48) root of a golden section number,Non-data,9
| 3 4 Algorithm 7: GoldSqrt 2 for i ← 0 to k − 1 do Data: (cid:74)gx(cid:75), m, n, (n > m), k,{gwi} x(cid:75) Result: (cid:74)g√ 1 (cid:74)gy0(cid:75) ← TwoPowerConst((cid:74)gx(cid:75),{gwi}); (cid:74)gz0(cid:75) ← GoldenMult((cid:74)gyi(cid:75),(cid:74)gx(cid:75)); (cid:74)gz1(cid:75) ← GoldenMult((cid:74)gyi(cid:75),(cid:74)gz0(cid:75)); (cid:74)gz1(cid:75) ← 3 −(cid:74)gz1(cid:75); (cid:74)gz2(cid:75) ← GoldenMult((cid:74)gyi(cid:75),g 05); (cid:74)gyi+1(cid:75) ← GoldenMult((cid:74)gz1(cid:75),(cid:74)gz2(cid:75)); 9 (cid:74)gw(cid:75) ← GoldenMult((cid:74)gx(cid:75),(cid:74)gyk(cid:75)); 10 return(cid:74)gw(cid:75) 7 8 end 6 5 The protocol is following We first compute the inverse square root of the input x and then multiply it with x There x where the formula for exists an iterative algorithm for the nth approximation is yn+1 = 0|,Non-data,9
|5yn(3−xy2 n) The reason why we use inverse square root to compute square root is 1√ that general iterative methods for square root need division, which is too costly in out setting To obtain the starting approximations, we shall use the 2 – if x ∈ function TwoPowerConst where the constants are 2 [2j, 2j+1), the function will return 2 j 2  i 5|,Non-data,9
| LOGARITHMIC NUMBERS In this section we will present logarithmic numbers We will explain the format, and then describe algorithms for computing the inverse, product, square root, logarithm, ex- ponential function and sum 51 Logarithmic number format We represent a logarithmic number x as a triple (zx, sx, ex)|,Non-data,9
 Zero-bit zx is 0 if x is zero and 1 if x is non-zero Sign bit sx is 0 if x is positive and 1 if x is negative Exponent ex is an (m + n)-bit integer which represents a fixed-point number with m bits before and n bits after the radix point The exponent is biased and so can be both positive and negative,Non-data,9
| The value of the number is computed as follows: (z, s, e) → z · (−1)s · 2(e−Bias)/2n , where Bias is 2m+n−2 − 1 The larger m, the larger the range of numbers we can rep- resent The larger n, the more precision we have While the length of the exponent is m + n bits, only the lowest m + n − 1 bits are used|,Non-data,9
| The highest bit is always zero to achieve faster comparisons between exponents 52 Inverse Algorithm 8 presents the protocol for finding the inverse of a logarithmic number Algorithm 8: LogNumInv Data: (cid:74)x(cid:75) = ((cid:74)zx(cid:75),(cid:74)sx(cid:75),(cid:74)ex(cid:75)) Result: (cid:74)1/x(cid:75) 1 return ((cid:74)1(cid:75),(cid:74)sx(cid:75), 2 ·(cid:74)Bias(cid:75) −(cid:74)ex(cid:75)) Inverse is computed by leaving the sign unchanged and negating the exponent, based on the formula ((−1)sx·2ex )−1 = (−1)sx · 2−ex |,Non-data,9
| We assume that the input is not zero The zero-bit of the result is set to 1 to indicate that the result is non-zero We also have to account for the bias when com- puting the exponent When changing the sign of a biased integer, we have to not only change the sign but also add the double of the bias|,Non-data,9
| 53 Multiplication Algorithm 9 presents the protocol for multiplying loga- rithmic numbers Algorithm 9: LogNumMult Data: (cid:74)x(cid:75) = ((cid:74)zx(cid:75),(cid:74)sx(cid:75),(cid:74)ex(cid:75)),(cid:74)y(cid:75) = ((cid:74)zy(cid:75),(cid:74)sy(cid:75),(cid:74)ey(cid:75)) Result: (cid:74)x · y(cid:75) 1 (cid:74)e(cid:75) ←(cid:74)ex(cid:75) +(cid:74)ey(cid:75); 2 (cid:74)z(cid:75) ←(cid:74)zx(cid:75) ∧(cid:74)zy(cid:75) ∧ ((cid:74)e(cid:75) ≥(cid:74)Bias(cid:75)); 3 return ((cid:74)z(cid:75),(cid:74)sx(cid:75) ⊕(cid:74)sy(cid:75),(cid:74)e(cid:75) −(cid:74)Bias(cid:75)) Multiplication of logarithmic numbers is based on the for- mula 2ex 2ey = 2ex+ey  Because our exponents are biased, we have to subtract the bias when adding them|,Non-data,9
| To get the sign of the result, we compute the XOR of the signs of 559the operands The zero-bit of the end result is computed as follows: the result is non-zero iff both operands are non- zero and their product does not underflow Therefore, any underflows are rounded down to zero 5|,Non-data,9
|4 Square root Algorithm 10 presents the protocol for finding the square root of a logarithmic number Algorithm 10: LogNumSqrt Data: (cid:74)x(cid:75) = ((cid:74)zx(cid:75),(cid:74)sx(cid:75),(cid:74)ex(cid:75)) x(cid:75) Result: (cid:74)√ 1 return ((cid:74)zx(cid:75),(cid:74)0(cid:75), ((cid:74)ex(cid:75) +(cid:74)Bias(cid:75))/2) √ We assume that the input is non-negative If the input is zero we return zero, and if the input is non-zero then we 2ex = 2ex/2 When divide the exponent by two because dividing a biased integer by two we have to double the bias before division in order to get the end result with the correct bias|,Non-data,9
| 55 Logarithm Algorithm 11 presents the protocol for finding the binary logarithm of a logarithmic number i=0 Algorithm 11: LogNumLg Data: m, n,(cid:74)x(cid:75) = ((cid:74)zx(cid:75),(cid:74)sx(cid:75),(cid:74)ex(cid:75)), p = {pi}l Result: (cid:74)lg x(cid:75) 1 (cid:74)s(cid:75) ←(cid:74)ex(cid:75) <(cid:74)Bias(cid:75); 2 (cid:74)e(cid:48)(cid:75) ←(cid:74)ex(cid:75) −(cid:74)Bias(cid:75); 3 (cid:74)e(cid:48)(cid:48)(cid:75) ←(cid:74)Bias(cid:75) −(cid:74)ex(cid:75); 4 (cid:74)e(cid:75) ← ObliviousChoice((cid:74)s(cid:75),(cid:74)e(cid:48)(cid:48)(cid:75),(cid:74)e(cid:48)(cid:75)); i=0 ← MSNZB(BitExtract((cid:74)e(cid:75))); 5 {(cid:74)ji(cid:75)}m+n−3 6 (cid:74)v(cid:75) ←(cid:74)e(cid:75) −(cid:80)m+n−3 (cid:74)ji(cid:75) · 2i; 7 (cid:74)w(cid:75) ←(cid:80)m+n−3 ((cid:74)ji(cid:75) · 2m+n−i) ·(cid:74)v(cid:75); 8 (cid:74)z(cid:75) ←(cid:74)ex(cid:75) (cid:54)=(cid:74)Bias(cid:75); 9 (cid:74)t(cid:75) ← cPoly(p,(cid:74)w(cid:75))/2m−1; 10 (cid:74)u(cid:75) ← 2n+1 ·(cid:80)m+n−3 ((cid:74)ji(cid:75) · (n + 1 − i)); 11 return ((cid:74)z(cid:75),(cid:74)s(cid:75),(cid:74)t(cid:75) −(cid:74)u(cid:75) +(cid:74)Bias(cid:75)) i=0 i=0 i=0 To compute the binary logarithm of a logarithmic num- ber, we assume that the input is positive We note that if 2ey = lg 2ex then ey = lg ex|,Non-data,9
| Therefore, the exponent of the output is the binary logarithm of the exponent of the input, which means that the problem is reduced to comput- ing the binary logarithm of a fixed-point number However, logarithmic numbers with negative and zero exponents (log- arithmic numbers that lie in (0, 1]) need special handling, be- cause we do not want to deal with computing the logarithms of negative numbers If the exponent of the input is negative, we find the result using the formula lg 2−ex = −2lg ex  Thus, to compute the binary logarithm of a logarithmic number we compute the logarithm of the absolute value of the exponent, and set the sign bit of the end result to 0 if the exponent is positive, and 1 if the exponent is negative|,Non-data,9
| If the expo- nent is equal to 0 then we set the zero-bit of the result to 0, otherwise we set it to 1 We compute the binary logarithm of a fixed-point number with the help of a polynomial p that approximates f(cid:48)(x) = log4 (x + 1) + 1/2 in [0, 1) (obtained using Chebychev inter- polation) Our polynomial evaluation protocol only allows inputs and outputs in range [0, 1), therefore, instead of ap- proximating f (x) = lg x directly, we first shift the number to the left so that we shift out all leading zeroes and the most significant non-zero bit (via BitExtract and MSNZB protocols and multiplications) Then we consider the resulting num- ber as a fixed-point number with 0 bits before radix point and approximate the function f(cid:48)(x) = log4 (x + 1)+1/2, the values of which are in [0|,Non-data,9
|5, 1) In order to derive the loga- rithm of the original number from this intermediate result, we divide it by 2m−1 and subtract a constant which depends on the most significant non-zero bit of the original number In order to compute natural logarithm via binary log- arithm, we multiply the result by ln 2, because loga x = loga 2 · lg x 5|,Non-data,9
|6 Exponent Algorithm 12 presents the protocol for finding the base 2 exponent of a logarithmic number i=0 Algorithm 12: LogNumExp Data: m, n,(cid:74)x(cid:75) = ((cid:74)zx(cid:75),(cid:74)sx(cid:75),(cid:74)ex(cid:75)), p = {pi}l Result: (cid:74)2x(cid:75) 1 (cid:74)g(cid:75) ← Truncate((cid:74)ex(cid:75), n); 2 (cid:74)w(cid:75) ←(cid:74)2m−2 + m − 3(cid:75) −(cid:74)ex(cid:75)/2n; 3 (cid:74)y(cid:75) ← cPoly(p, 2m−2 ·(cid:74)g(cid:75)); 4 (cid:74)t(cid:75) ← Pick({(cid:74)y(cid:75)/2i}m+n−3 ,(cid:74)w(cid:75)); 5 (cid:74)z(cid:75) ←(cid:74)zx(cid:75) ∨ ((cid:74)ex(cid:75) <(cid:74)2n · (m − 2) + Bias(cid:75)); 6 (cid:74)u(cid:75) ←(cid:74)zx(cid:75) · ObliviousChoice((cid:74)sx(cid:75),−(cid:74)t(cid:75),(cid:74)t(cid:75)) +(cid:74)Bias(cid:75); 7 return ((cid:74)z(cid:75),(cid:74)0(cid:75),(cid:74)u(cid:75)) i=0 To compute the base 2 exponential function on logarith- mic numbers, we note that if 2ey = 22ex then ey = 2ex  Therefore, the exponent of the output is 2 to the power of the exponent of the input, and the problem is reduced to computing base 2 exponential function on fixed-point num- bers To find the base 2 exponent of a fixed-point number, we use the formula 2ex = 2(cid:98)ex(cid:99)+1·2{ex}−1|,Non-data,9
| Separating the input into whole and fractional part allows us to approximate the function f (x) = 2x−1 on the fractional part, with inputs in range [0, 1) and outputs in range [05, 1), which is suitable for our interpolation protocol In the algorithm, approximation polynomial for f (x) = 2x−1 is denoted as p After exponentiating the fractional part, we shift the re- sult right by a number of bits which depends on the whole part|,Non-data,9
| This is done by computing all public shifts and obliv- iously picking the right one (line 4) Note that in order to achieve good precision when approxi- mating 2{ex}−1, we do not just truncate the exponent to get the fractional part We truncate and then perform a left shift so that polynomial evaluation protocol has more bits of precision to work with Therefore, after polynomial eval- uation we do not have to perform a left shift, which shifts in zeroes from the right and therefore means lost precision, but a right shift, which shifts out bits to the right and therefore means ridding ourselves of excess precision achieved with polynomial approximation|,Non-data,9
| lg e, because ax = 2lg a·x In order to compute exp x, we multiply the argument by 56057 Addition Algorithm 13 presents the protocol for finding the sum of logarithmic numbers i=0 )) {di}m+n−3 i=0 Algorithm 13: LogNumAdd , d = , c = 2n(2m + lg (1 − 2−2−n Data: (cid:74)x(cid:75) = ((cid:74)zx(cid:75),(cid:74)sx(cid:75),(cid:74)ex(cid:75)),(cid:74)y(cid:75) = ((cid:74)zy(cid:75),(cid:74)sy(cid:75),(cid:74)ey(cid:75)), a = {ai}m+n−3 Result: (cid:74)x + y(cid:75) 1 (cid:74)l(cid:75) ←(cid:74)zx(cid:75) ∨(cid:74)zy(cid:75) ∧ ((cid:74)ex(cid:75) <(cid:74)ey(cid:75)); 2 ((cid:74)x(cid:75),(cid:74)y(cid:75)) ← Swap((cid:74)l(cid:75),(cid:74)x(cid:75),(cid:74)y(cid:75)); 3 (cid:74)e(cid:75) ←(cid:74)ex(cid:75) −(cid:74)ey(cid:75); 4 {(cid:74)bi(cid:75)}m+n−1 i=0 ← BitExtract(e); 5 (cid:74)t(cid:75) ←(cid:74)sx(cid:75) ⊕(cid:74)sy(cid:75); 6 {(cid:74)pi(cid:75)}m+n−2 i=0 ← MSNZB({(cid:74)bi(cid:75)}m+n−2 i=0 ← ConjBit({(cid:74)pi(cid:75)}m+n−2 7 {(cid:74)ri(cid:75)}m+n−2 ,(cid:74)t(cid:75)); i=0 ← {(cid:74)ri(cid:75)}m+n−2 8 {(cid:74)qi(cid:75)}m+n−2 ⊕ {(cid:74)pi(cid:75)}m+n−2 9 (cid:74)k(cid:75) ←(cid:80)m+n−2 ((cid:74)pi(cid:75) · 2m+n−1−i · ((cid:74)e(cid:75) −(cid:74)2i(cid:75))); i=0 ← cPolyArr(a,(cid:74)k(cid:75)); 10 {(cid:74)vi(cid:75)}m+n−3 i=0 ← cPolyArr(d,(cid:74)k(cid:75)); 11 {(cid:74)wi(cid:75)}m+n−3 a(cid:75) ← ((cid:87)m+n−2 (cid:74)bi(cid:75) ⊕(cid:74)q0(cid:75)) · 2n; 12 (cid:74)g(cid:48) 13 (cid:74)ga(cid:75) ←(cid:80)m+n−3 ((cid:74)qi+1(cid:75) ·(cid:74)vi(cid:75)); 14 (cid:74)g(cid:48) d(cid:75) ←(cid:74)r0(cid:75) · c; 15 (cid:74)gd(cid:75) ←(cid:80)m+n−3 ((cid:74)ri+1(cid:75) ·(cid:74)wi(cid:75)); 16 (cid:74)u(cid:75) ←(cid:74)zy(cid:75) · ((cid:74)g(cid:48) a(cid:75) +(cid:74)ga(cid:75) +(cid:74)g(cid:48) 17 (cid:74)z(cid:75) ←(cid:74)zx(cid:75) ⊕(cid:74)zx(cid:75) ∧(cid:74)zy(cid:75) ∧(cid:74)t(cid:75) ∧ ((cid:74)ex(cid:75) < −(cid:74)u(cid:75)); 18 return ((cid:74)z(cid:75),(cid:74)sx(cid:75),(cid:74)ex(cid:75) +(cid:74)u(cid:75)) d(cid:75) +(cid:74)gd(cid:75)); i=0 ; i=0 ); i=0 i=0 i=0 i=0 i=0 i=1 First, we sort the operands by their absolute value|,Non-data,9
| If the absolute value of x is smaller than the absolute value of y then we swap them (lines 1 and 2) Now we know that ||x|| ≥ ||y|| In order to reduce addition to a single- operand function, we factorise 2ex ±2ey as 2ex (1±2ey−ex ) = 2ex+lg (1±2ey−ex ) Knowing that the first operand is larger is beneficial for two reasons: it gives us the sign of the end result (which is equal to the sign of the larger operand), and it ensures that lg (1 − 2ey−ex ) is a real-valued function|,Non-data,9
| Now that the operands are sorted, we approximate two different functions, one for addition and one for subtraction To compute lg (1 ± 2ey−ex ) we find the difference of the exponents (line 3) and denote it with e We also find all its bits (line 4) We denote with t (line 5) a bit which is 0 if we perform addition and 1 if we subtract|,Non-data,9
| Both fa(x) = lg (1 + 2x) and fd(x) = lg (1 − 2x) are func- tions for which interpolating with a single polynomial though Chebyshev nodes yields poor precision, especially for the val- ues of the argument near zero Therefore, our approach for approximating these functions is to find the most significant non-zero bit of the argument (line 6) and shift the argu- ment to the left so that we shift out all leading zeroes and the most significant non-zero bit (line 9) On the resulting number we compute a separate polynomial for each function and each possible position of the most significant non-zero bit (lines 10 and 11) (In the algorithm, we denote the array of polynomials for addition as a and the array of polynomials for subtraction as d|,Non-data,9
|) There are also two special cases which are not covered by the polynomials: if the argument is zero, and if the most significant non-zero bit of the argument is in the lowest pos- sible position If the argument is zero then it means that x and y have an equal absolute value, in which case for addition we return as the value of fa(x) = lg (1 + 2x) a constant representing 1 (line 12), and for subtraction we re- turn 0 as the final result If the most significant non-zero bit of the argument is in the lowest possible position then for addition we return as the value of fa(x) = lg (1 + 2x) a constant representing 1, and for subtraction we return as the value of fd(x) = lg (1 − 2x) a constant c representing 2m + lg (1 − 2−2−n ) (line 14) In lines 13 and 15 we pick the right interpolation result de- pending on the most significant nonzero bit of the argument|,Non-data,9
| From this collection of constants and polynomial approxima- tion results, we pick the correct one based on whether we are performing addition or subtraction, and depending on the most significant non-zero bit of (cid:74)ex(cid:75) −(cid:74)ey(cid:75) In line 16 we pick the value u which is added to the exponent of the larger logarithmic number to achieve the final result Note that if the smaller operand is zero then u is also set to zero In case of subtraction, we check for underflow, and if the result of subtraction is smaller than is possible to accurately represent with a non-zero number we round the result down to zero (line 17)|,Non-data,9
| The approach to addition presented in Algorithm 13 re- sults in precision which is reasonable but still far from ideal One way to perform precise logarithmic addition is based on formula x + y = x· lg (2 · 2y/x) where we find the sum of two numbers with the help of division, exponentiation, multipli- cation, and logarithm In order to achieve good precision with this method, the operands have to be cast up before computing the sum As this method involves a composition of exponentiation and logarithm, both performed on num- bers twice the size of the original inputs, it is extremely inefficient, but it allows for near-ideal precision|,Non-data,9
| 6 ANALYSIS OF ERROR AND PERFOR- MANCE In this section, we compare golden and logarithmic num- bers against existing implementations of floating-point and fixed-point representations Comparisons are made in both performance and accuracy for different operations and bit- widths We look at addition, multiplication, reciprocal and square root|,Non-data,9
| For floating-point and logarithmic numbers, we additionally measure the performance and accuracy of exponentiation and natural logarithm We have implemented logarithmic and golden section num- bers on the Sharemind SMC platform We chose Share- mind because of its maturity, tooling, and availability of fixed-point and floating-point numbers As existing num- ber systems were already implemented using Sharemind’s domain-specific language [17], we decided to also use it for golden section and logarithmic representations|,Non-data,9
| The proto- col language provides us with directly comparable perfor- mance and allows to avoid many complexities that a direct C++ implementation would have To provide a clear overview of accuracy and speed trade- offs, we measured the performance of each number system on multiple bit-widths Generally, higher bit-widths offer us better accuracy for the cost of performance We implemented three different versions of logarithmic numbers: Lh, Ls and Ld (with h, s and d standing for half, single and double precision)|,Non-data,9
| For Lh, we chose m = 6 and 561n = 16 (Section 51) so that it offers at least as much range and precision as IEEE 754 half-precision floating-point num- bers and also aligns to a byte boundary (2 + 6 + 16 = 24 bits or 3 bytes) For Ls, we chose m = 9 and n = 29 for a size of 40 bits and accuracy comparable to single-precision floating- point numbers For Ld, we chose m = 12 and n = 58 for a size of 72 bits and accuracy comparable to double-precision floating-point numbers|,Non-data,9
| We also implemented tree versions of golden numbers (Sec- tion 4): G32, G64 and G128 where for Gn we store two n-bit components to provide comparable accuracy to n-bit fixed- point numbers with radix point at (cid:98)n/2(cid:99) We compare our results against existing secure real num- ber implementations that Sharemind already provides Two floating-point number representations are used: floats, pro- viding comparable accuracy to single-precision floating-point numbers, and floatd, providing comparable accuracy to double- precision floating-point numbers See [13–15] for implemen- tation details|,Non-data,9
| Logarithmic numbers compare well with floating- point numbers as both are designed to provide good relative errors Additionally, Sharemind provides 32-bit and 64-bit fixed-point numbers with radix point in the middle (denoted with fix32 and fix64 respectively) Golden numbers compare well with fixed-point numbers as both are designed to pro- vide good absolute errors Accuracy was measured experimentally, by identifying the range of inputs in which the largest errors should be found, and then uniformly sampling this range to find maximum error|,Non-data,9
| Performance measurements were made on a cluster of three computers connected with 10Gbps Ethernet Each cluster node was equipped with 128GB DDR4 memory and two 8- core Intel Xeon (E5-2640 v3) processors, and was running Debian 82 Jessie with memory overcommit and swap dis- abled We measured each operation on various input sizes, exe- cuting the operation in parallel on the inputs|,Non-data,9
| Each mea- surement was repeated a minimum of ten times and the mean of the measurements was recorded Measurements were performed in randomized order Note that due to the networked nature of the protocols, parallel execution im- proves performance drastically up to the so called saturation point We recorded maximum achieved operations per second that states how many parallel operations can be evaluated on given input size per second|,Non-data,9
| For example, if we can per- form a single parallel operation on 100-element vectors per second this gives us 100 operations per second Our performance and accuracy measurements are displayed in Figure 1 For every variant of every real number rep- resentation, we plot its maximum achieved performance in operations per second (OP/s) on the y-axis and its error on the x-axis Note that performance increases on the y-axis and accuracy improves on the x-axis|,Non-data,9
