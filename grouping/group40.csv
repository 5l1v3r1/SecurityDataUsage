 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| Intel’s Software Guard Extensions (SGX) [8, 21, 28, 30] is a set of new instructions that confer hardware protec- tions on user-level code SGX enables process execution in a protected address space known as an enclave The enclave protects the confidentiality and integrity of the process from certain forms of hardware attack and other software on the same host, including the operating system An enclave process cannot make system calls, but can read and write memory outside the enclave region|,Non-data,101
| Thus isolated execution in SGX may be viewed in terms of an ideal model in which a process is guaranteed to execute correctly and with perfect confidentiality, but relies on a (potentially mali- cious) operating system for network and file-system access1 SGX allows a remote system to verify the software in an enclave and communicate securely with it When an enclave is created, the CPU produces a hash of its initial state known as a measurement The software in the enclave may, at a later time, request a report which includes a measurement and supplementary data provided by the process, such as a public key|,Non-data,101
| The report is digitally signed using a hardware- protected key to produce a proof that the measured software is running in an SGX-protected enclave This proof, known as a quote, can be verified by a remote system, while the process-provided public key can be used by the remote sys- tem to establish a secure channel with the enclave or verify signed data it emits We use the generic term attestation to refer to a quote, and denote it by att We assume that a trustworthy measurement of the code for the enclave com- ponent of TC is available to any client that wishes to verify 1This model is a simplification: SGX is known to expose some internal enclave state to the OS [18]|,Non-data,101
| Our basic security model for TC assumes ideal isolated execution, but again, TC can also be distributed across multiple SGX instances as a hedge against compromise an attestation SGX signs quotes using a group signature scheme called EPID [12] This choice of primitive is signifi- cant in our design of Town Crier, as EPID is a proprietary signature scheme not supported natively in Ethereum|,Non-data,101
| SGX additionally provides a trusted time source via the function sgx_get_trusted_time On invoking this function, an en- clave obtains a measure of time relative to a reference point indexed by a nonce A reference point remains stable, but SGX does not provide a source of absolute or wall-clock time, another limitation we must work around in TC TLS / HTTPS|,Non-data,101
| We assume basic familiarity by readers with TLS and HTTPS (HTTP over TLS) As we explain later, TC exploits an important feature of HTTPS, namely that it can be partitioned into interoperable layers: an HTTP layer interacting with web servers, a TLS layer handling handshakes and secure communication, and a TCP layer providing reliable data stream Smart contracts While TC can in principle support any smart-contract system, we focus in this paper on its use in Ethereum, whose model we now explain|,Non-data,101
| For further details, see [14, 37] A smart contract in Ethereum is represented as what is called a contract account, endowed with code, a currency balance, and persistent memory in the form of a key/value store A contract accepts messages as inputs to any of a number of designated functions These entry points, de- termined by the contract creator, represent the API of the contract|,Non-data,101
| Once created, a contract executes autonomously; it persists indefinitely with even its creator unable to mod- ify its code2 Contract code executes in response to receipt of a message from another contract or a transaction from a non-contract (externally owned ) account, informally what we call a wallet Thus, contract execution is always initi- ated by a transaction Informally, a contract only executes when “poked,” and poking progresses through a sequence of entry points until no further message passing occurs (or a shortfall in gas occurs, as explained below)|,Non-data,101
| The “poking” model aside, as a simple abstraction, a smart contract may be viewed as an autonomous agent on the blockchain Ethereum has its own associated cryptocurrency called Ether (At the time of writing, 1 Ether has a market value of just under $15 US|,Non-data,101
| [1]) To prevent DoS attacks, pre- vent inadvertent infinite looping within contracts, and gen- erally control network resource expenditure, Ethereum al- lows Ether-based purchase of a resource called gas to power contracts Every operation, including sending data, exe- cuting computation, and storing data, has a fixed gas cost Transactions include a parameter (GASLIMIT) specifying a bound on the amount of gas expended by the computations they initiate|,Non-data,101
| When a function calls another function, it may optionally specify a lower GASLIMIT for the child call which expends gas from the same pool as the parent Should a function fail to complete due to a gas shortfall, it is aborted and any state changes induced by the partial computation are rolled back to their pre-call state; previous computations on the call path, though, are retained and gas is still spent Along with a GASLIMIT, a transaction specifies a GASPRICE, the maximum amount in Ether that the transaction is will- ing to pay per unit of gas The transaction thus succeeds only if the initiating account has a balance of GASLIMIT × 2There is one exception: a special opcode suicide wipes code from a contract account|,Non-data,101
| 272GASPRICE Ether and GASPRICE is high enough to be accepted by the system (miner) As we discuss in Section 51, the management of gas is critical to the availability of TC (and other Ethereum-based services) in the face of malicious users Finally, we note that transactions in Ethereum are digi- tally signed for a wallet using ECDSA on the curve Secp256k1 and the hash function SHA3-256|,Non-data,101
| 3 ARCHITECTURE AND SECURITY MODEL Town Crier includes three main components: The TC Contract (CTC ), the Enclave (whose code is denoted by progencl), and the Relay (R) The Enclave and Relay re- side on the TC server, while the TC Contract resides on the blockchain We refer to a smart contract making use of the Town Crier service as a requester or relying contract, which we denote CU , and its (off-chain) owner as a client or user|,Non-data,101
| A data source, or source for short, is an online server (running HTTPS) that provides data which TC draws on to compose datagrams An architectural schematic of TC showing its interaction with external entities is given in Figure 1 Blockchain TC Server Data Source TC Contract CTC RelayR HTTPS lots-o- datacom User Contract CU Enclave (progencl) Figure 1: Basic Town Crier architecture|,Non-data,101
 Trusted components are depicted in green The TC Contract CTC  The TC Contract is a smart contract that acts as the blockchain front end for TC It is designed to present a simple API to a relying contract CU for its requests to TC,Non-data,101
| CTC accepts datagram requests from CU and returns corresponding datagrams from TC Addi- tionally, CTC manages TC’s monetary resources The Enclave We refer to an instance of the TC code running in an SGX enclave simply as the Enclave and de- note the code itself by progencl|,Non-data,101
| In TC, the Enclave ingests and fulfills datagram requests from the blockchain To ob- tain the data for inclusion in datagrams, it queries external data sources, specifically HTTPS-enabled internet services It returns a datagram to a requesting contract CU as a dig- itally signed blockchain message Under our basic security model for SGX, network functions aside, the Enclave runs in complete isolation from an adversarial OS as well as other process on the host|,Non-data,101
| The Relay R As an SGX enclave process, the Enclave lacks direct network access Thus the Relay handles bidirec- tional network traffic on behalf of the Enclave Specifically, the Relay provides network connectivity from the Enclave to three different types of entities: 1|,Non-data,101
| The Blockchain (the Ethereum system): The Relay scrapes the blockchain in order to monitor the state of CTC  In this way, it performs implicit message passing from CTC to the Enclave, as neither component itself has network connectivity Additionally, the Relay places messages emitted from the Enclave (datagrams) on the blockchain 2|,Non-data,101
| Clients: The Relay runs a web server to handle off-chain service requests from clients—specifically requests for En- clave attestations As we soon explain, an attestation provides a unique public key for the Enclave instance to the client and proves that the Enclave is executing cor- rect code in an SGX enclave and that its clock is correct in terms of absolute (wall-clock) time A client that suc- cessfully verifies an attestation can then safely create a relying contract CU that uses the TC 3|,Non-data,101
| Data sources: The Relay relays traffic between data sources (HTTPS-enabled websites) and the Enclave The Relay is an ordinary user-space application It does not benefit from integrity protection by SGX and thus, un- like the Enclave, can be subverted by an adversarial OS on the TC server to cause delays or failures A key design aim of TC, however, is that Relay should be unable to cause incor- rect datagrams to be produced or users to lose fees paid to TC for datagrams (although they may lose gas used to fuel their requests)|,Non-data,101
| As we will show, in general the Relay can only mount denial-of-service attacks against TC Security model Here we give a brief overview of our secu- rity model for TC, providing more details in later sections We assume the following: • The TC Contract|,Non-data,101
 CTC is globally visible on the blockchain and its source code is published for clients Thus we as- sume that CTC behaves honestly • Data sources We assume that clients trust the data sources from which they obtain TC datagrams,Non-data,101
| We also assume that these sources are stable, ie, yield consistent data- grams, during a requester’s specified time interval T  (Re- quests are generally time-invariant, e|,Non-data,101
|g, for a stock price at a particular time) • Enclave security We make three assumptions: (1) The Enclave behaves honestly, i|,Non-data,101
|e, progencl, whose source code is published for clients, correctly executes the protocol; (2) For an Enclave-generated keypair (skTC , pkTC ), the private key skTC is known only to the Enclave; and (3) The Enclave has an accurate (internal) real-time clock We explain below how we use SGX to achieve these prop- erties • Blockchain communication|,Non-data,101
| Transaction and message sources are authenticable, ie, a transaction m sent from wallet WX (or message m from contract CX ) is identified by the receiving account as originating from X Transactions and messages are integrity protected (as they are digitally signed by the sender), but not confidential|,Non-data,101
| • Network communication The Relay (and other untrusted components of the TC server) can tamper with or delay communications to and from the Enclave (As we explain in our SGX security model, the Relay cannot otherwise observe or alter the Enclave’s behavior) Thus the Relay is subsumed by an adversary that controls the network|,Non-data,101
| 4 TC PROTOCOL OVERVIEW We now outline the protocol of TC at a high level The basic structure is conceptually simple: a user contract CU 273requests a datagram from the TC Contract CTC , CTC for- wards the request to the Enclave and then returns the re- sponse to CU  There are many details, however, relating to message contents and protection and the need to connect the off-chain parts of TC with the blockchain|,Non-data,101
| First we give a brief overview of the protocol structure Then we enumerate the data flows in TC Finally, we present the framework for modeling SGX as ideal functionalities in- spired by the universal-composability (UC) framework 4|,Non-data,101
|1 Datagram Lifecycle The lifecycle of a datagram may be briefly summarized in m2 = (id, params) m3 = (id, params, data) TC Server Enclave (progencl) (obtains data from data source) Blockchain TC Contract CTC m1 = (params, callback) m4 = (data) User Contract CU on the blockchain the following steps: • Initiate request CU sends a datagram request to CTC • Monitor and relay The Relay monitors CTC and relays any incoming datagram request with parameters params to the Enclave|,Non-data,101
| • Securely fetch feed To process the request specified in params, the Enclave contacts a data source via HTTPS and obtains the requested datagram It forwards the data- gram via the Relay to CTC  • Return datagram|,Non-data,101
| CTC returns the datagram to CU  We now make this data flow more precise 42 Data Flows A datagram request by CU takes the form of a message m1 = (params, callback) to CTC on the blockchain|,Non-data,101
| params specifies the requested datagram, eg, params := (url, spec, T ), where url is the target data source, spec specifies content of a the datagram to be retrieved (eg|,Non-data,101
|, a stock ticker at a particular time), and T specifies the delivery time for the datagram (initiated by scraping of the data source) The parameter callback in m1 indicates the entry point to which the datagram is to be returned While callback need not be in CU , we assume it is for simplicity CTC generates a fresh unique id and forwards m2 = (id, params) to the Enclave|,Non-data,101
| In response it receives m3 = (id, params, data) from the TC service, where data is the datagram (eg, the desired stock ticker price) CTC checks the consistency of params on the request and response and, if they match, for- wards data to the callback entry point in message m4|,Non-data,101
| For simplicity here, we assume that CU makes a one-time datagram request Thus it can trivially match m4 with m1 Our full protocol contains an optimization by which CTC re- turns id to CU after m1 as a consistent, trustworthy identifier for all data flows This enables straightforward handling of multiple datagram requests from the same instance of CU |,Non-data,101
| Fig 2 shows the data flows involved in processing a data- gram request For simplicity, the figure omits the Relay, which is only responsible for data passing Digital signatures are needed to authenticate messages, such as m3, entering the blockchain from an external source|,Non-data,101
| We let (skTC , pkTC ) denote the private / public keypair as- sociated with the Enclave for such message authentication For simplicity, Fig 2 assumes that the Enclave can send signed messages directly to CTC  We explain later how TC uses a layer of indirection to sends m3 as a transaction via an Ethereum wallet WTC |,Non-data,101
| Figure 2: Data flows in datagram processing 43 Use of SGX Let progencl represent the code for Enclave, which we pre- sume is trusted by all system participants Our protocols in TC rely on the ability of SGX to attest to execution of an instance of progencl|,Non-data,101
| To achieve this goal, we first present a model that abstracts away the details of SGX, helping to simplify our protocol presentation and security proofs We also explain how we use the clock in SGX Our discussion draws on formalism for SGX from Shi et al [34]|,Non-data,101
| Formal model and notation We adopt a formal abstrac- tion of Intel SGX proposed by Shi et al [34] Following the UC and GUC paradigms [15–17], Shi et al|,Non-data,101
| propose to ab- stract away the details of SGX implementation, and instead view SGX as a third party trusted for both confidentiality and integrity Specifically, we use a global UC functionality Fsgx(Σsgx)[progencl,R] to denote (an instance of) an SGX functionality parameterized by a (group) signature scheme Σsgx Here progencl denotes the SGX enclave program and R the physical SGX host (which we assume for simplicity is the same as that of the TC Relay) As described in Fig|,Non-data,101
| 3, upon initialization, Fsgx runs outp := progenclInitialize() and attests to the code of progencl as well as outp Upon a resume call with (id, params), Fsgx runs and outputs the re- sult of progenclResume(id, params)|,Non-data,101
| Further formalism for Fsgx is given in the appendix of the online version [39] Fsgx[progencl,R]: abstraction for SGX Hardcoded: sksgx Assume: progencl has entry points Initialize and Resume Initialize: On receive (init) from R: Let outp := progenclInitalize() // models EPID signature σatt := Σsgx|,Non-data,101
|Sign(sksgx, (progencl, outp)) Output (outp, σatt) Resume: On receive (resume, id, params) from R: Let outp := progenclResume(id, params) Output outp Figure 3: Formal abstraction for SGX execution capturing a subset of SGX features sufficient for im- plementation of TC 274SGX Clock As noted above, the trusted clock for SGX provides only relative time with respect to a reference point|,Non-data,101
| To work around this, the Enclave is initialized with the current wall-clock time provided by a trusted source (eg, the Relay under a trust-on-first-use model) In the current implementation of TC, clients may, in real time, request and verify a fresh timestamp—signed by the Enclave under pkTC —via a web interface in the Relay|,Non-data,101
| Thus, a client can determine the absolute clock time of the Enclave to within the round-trip time of its attestation request plus the at- testation verification time—hundreds of milliseconds in a wide-area network This high degree of accuracy is poten- tially useful for some applications but only loose accuracy is required for most Ethereum targets a block interval of 12s and the clock serves in TC primarily to: (1) Schedule connections to data sources and (2) To check TLS certifi- cates for expiration when establishing HTTPS connections For simplicity, we assume in our protocol specifications that the Enclave clock provides accurate wall-clock time in the canonical format of seconds since the Unix epoch January 1, 1970 00:00 UTC|,Non-data,101
| Note that the trusted clock for SGX, backed by Intel Manageability Engine [22], is resilient to power outages and reboots [31] We let clock() denote measurement of the SGX clock from within the enclave, expressed as the current absolute (wall- clock) time 5 TWO KEY SECURITY PROPERTIES Before presenting the TC protocol details, we discuss two key security properties informing its design: gas sustainabil- ity and TCB minimization in TC’s hybridized TCB model|,Non-data,101
| While we introduce them in this work, as we shall explain, they are of broad and general applicability 51 Gas Sustainability As explained above, Ethereum’s fee model requires that gas costs be paid by the user who initiates a transaction, in- cluding all costs resulting from dependent calls This means that a service that initiates calls to Ethereum contracts must spend money to execute those calls|,Non-data,101
| Without careful design, such services run the risk of malicious users (or protocol bugs) draining financial resources by triggering blockchain calls for which the service’s fees will not be reimbursed This could cause financial depletion and result in an application- layer denial-of-service attack It is thus critical for the avail- ability of Ethereum-based services that they always be re- imbursed for blockchain computation they initiate To ensure that a service is not vulnerable to such attacks, we define gas sustainability, a new condition necessary for the liveness of blockchain contract-based services|,Non-data,101
 Gas sus- tainability is a basic requirement for any self-perpetuating Ethereum service It can also generalize beyond Ethereum; any decentralized blockchain-based smart contract system must require fees of some kind to reimburse miners for per- forming and verifying computation Let bal(W) denote the balance of an Ethereum wallet W Definition 1 (K-Gas Sustainability),Non-data,101
| A service with wallet W and blockchain functions f1,    , fn is K-gas sustainable If bal(W) ≥ K prior to execution if the following holds|,Non-data,101
| of any fi and the service behaves honestly, then after each execution of an fi initiated by W, bal(W) ≥ K Recall that a call made in Ethereum with insufficient gas will abort, but spend all provided gas While Ethereum trivially guarantees 0-gas sustainability, if a transaction is submitted by a wallet with insufficient funds, the wallet’s balance will drop to 0 Therefore, to be K-gas sustainable for K > 0, each blockchain call made by the service must re- imburse gas expenditures|,Non-data,101
| Moreover, the service must have sufficient gas for each call or such reimbursement will be reverted with the rest of the transaction The need for gas sustainability (with K > 0, as required by TC) informs our protocol design in Section 6 We prove that TC achieves this property in Section 7 5|,Non-data,101
|2 Hybrid TCB Minimization TOff: abstraction for off-chain TCB Initialize(void): (pk, sk) := ΣKeyGen(1λ) Output pk Resume(req): Assert OAuth(req) resp := f (req) σ := ΣSign(sk, (req, resp)) Output ((req, resp), σ) TOn: abstraction for on-chain TCB Request(req): Send (req) to TOff Deliver(req, resp, σ): ΣVerify((req, resp), σ) // can now use resp as trusted Figure 4: Systems like TC have a hybrid TCB|,Non-data,101
 Au- thentication between two components can greatly increase TCB complexity of implemented naively We propose techniques to eliminate the most ex- pensive operations (highlighted in red) In a system involving a smart contract interacting with an off-chain trusted computing environment (eg,Non-data,101
| SGX), the TCB is a hybrid of two components with distinct prop- erties Computation in the smart contract is slow, costly, and completely transparent, meaning it cannot rely on se- crets An SGX enclave is computationally powerful and exe- cutes privately, but all external interaction—notably includ- ing communication with the contract—must go through an untrusted intermediary While this hybrid TCB is powerful and useful well beyond TC, it presents a challenge: estab- lishing secure communication between the components while minimizing the code in the TCB|,Non-data,101
| We define abstractions for both TCB components in Fig 4 To distinguish these abstractions from formal ideal function- alities, we use T (for trusted component), rather than F We model the authentication of on-chain messages by an oracle OAuth, which returns true if an input is a valid blockchain transaction|,Non-data,101
| Since Ethereum blocks are self-authenticated using Merkle trees [14, 37], in principle we can realize OAuth by including an Ethereum client in the TCB Doing so dras- tically increases the code footprint, however, as the core Ethereum implementation is about 50k lines of C++ Simi- larly, a smart contract could authenticate messages from an SGX by checking attestations, but implementing this veri- 275fication in a smart contract would be error-prone and com- putationally (and thus financially) expensive Instead we propose two general techniques to avoid these calls and thereby minimize code size in the TCB|,Non-data,101
| The first applies to any hybrid system where one TCB component is a blockchain contract The second applies to any hybrid system where the TCB components communicate only to make and respond to requests Binding TOff to WTC  Due to the speed and cost of compu- tation in the on-chain TCB, we wish to avoid implementing signature verification (e|,Non-data,101
|g Intel’s EPID) There does exist a precompiled Ethereum contract to verify ECDSA signa- tures [37], but the operation requires a high gas cost In- stead, we describe here how to bind the identity of TOff to an Ethereum wallet, which allows TOn to simply check the mes- sage sender, which is already verified as part of Ethereum’s transaction protocol|,Non-data,101
| The key observation is that information can only be in- serted into the Ethereum blockchain as a transaction from a wallet Thus, the only way the Relay can relay messages from TOff to TOn is through a wallet WTC  Since Ethereum itself already verifies signatures on transactions (ie|,Non-data,101
|, users interact with Ethereum through an authenticated channel), we can piggyback verification of TOff signatures on top of the existing transaction signature verification mechanism Sim- ply put, the TOff creates WTC with a fresh public key pkOff whose secret is known only to TOff To make this idea work fully, the public key pkOff must be hardcoded into TOn A client creating or relying on a contract that uses TOn is responsible for ensuring that this hardcoded pkOff has an appropriate SGX attestation before interacting with TOn|,Non-data,101
| Letting Verify denote a verification algorithm for EPID signatures, Fig 5 gives the protocol for a client to check that TOn is backed by a valid TOff in- stance (We omit the modeling here of IAS online revocation checks) In summary, by assuming that relying clients have verified an attestation of TOff, we can assume that datagrams sent from WTC are trusted to originate from TOff|,Non-data,101
| This eliminates the need to do costly EPID signature verification in TOn Additionally, SGX can seal pkOff in non-volatile storage while protecting integrity and confidentiality [8,21], allowing us to maintain the same binding through server restarts User: offline verification of SGX attestation Inputs: pksgx, pkOff, TOff, σatt Verify: Assert TOff is the expected enclave code Assert ΣsgxVerify(pksgx, σatt, (TOff, pkOff)) Assert TOn is correct and parametrized with pkOff // now okay to rely on TOn Figure 5: A client checks an SGX attestation of the enclave’s code TOff and public key pkOff|,Non-data,101
| The client also checks that pkOff is hardcoded into blockchain contract TOn before using TOn Eliminating OAuth To eliminate the need to call OAuth from TOff, we leverage the fact that all messages from TOff to TOn are responses to existing requests Instead of veri- fying request parameters in TOff, we can verify in TOn that TOff responded to the correct request|,Non-data,101
| For each request, TOn stores the parameters of that request In each response, TOff includes the parameters it used to fulfill the request TOn can then check that the parameters in a response match the stored parameters and, if not, and simply reject Storing parameters and checking equality are simple operations, so this vastly simpler than calling OAuth inside TOff|,Non-data,101
| This approach may appear to open new attacks (eg, the Relay can send bogus requests to which the TOff respond) As we prove in Section 7, however, all such attacks reduce to DoS attacks from the network or the Relay—attacks to which hybrid TCB systems are inherently susceptible and which we do not aim to protect against in TC|,Non-data,101
| 6 TOWN CRIER PROTOCOL We now present some preliminaries followed by the TC protocol For simplicity, we assume a single instance of progencl, although our architecture could scale up to mul- tiple enclaves and even multiple hosts To ensure gas sustainability, we require that requesters make gas payments up front as Ether|,Non-data,101
| CTC then reimburses the gas costs of TC By having a trusted component perform the reimbursement, we are also able to guarantee that a malicious TC cannot steal an honest user’s money without delivering valid data Notation We use msg|,Non-data,101
|mi to label messages corresponding to those in Fig 2 For payment, let $g denote gas and $f to denote non-gas currency In both cases $ is a type an- notation and the letter denotes the numerical amount|,Non-data,101
| For simplicity, we assume that gas and currency adopt the same units (allowing us to avoid explicit conversions) We use the following identifiers to denote currency and gas amounts $f $greq $gdvr $gcncl $gclbk Currency a requester deposits to refund Town Crier’s gas expenditure to deliver a datagram GASLIMIT when invoking Request, Deliver, or Cancel, respectively GASLIMIT for callback while executing Deliver, set to the max value that can be reimbursed $Gmin Gas required for Deliver excluding callback $Gmax Maximum gas TC can provide to invoke Deliver $Gcncl Gas needed to invoke Cancel $G∅ Gas needed for Deliver on a canceled request $Gmin, $Gmax, $Gcncl, and $G∅ are system constants, $f is chosen by the requester (and may be malicious if the re- quester is dishonest), and $gdvr is chosen by the TC Enclave when calling Deliver Though $greq and $gcncl are set by the requester, a user-initiated transaction will abort if they are too small, so we need not worry about the values|,Non-data,101
| Initialization TC deposits at least $Gmax into the WTC  The TC Contract CTC  The TC Contract accepts a data- gram request with fee $f from CU , assigns it a unique id, and records it|,Non-data,101
| The Town Crier Relay R monitors requests and forwards them to the Enclave As we discussed in Sec- tion 52, upon receipt of a response from WTC , CTC verifies that params(cid:48) = params to ensure validity If the request is valid, CTC forwards the resulting datagram data by calling the callback specified in the initial request|,Non-data,101
| To ensure that all gas spent can be reimbursed, CTC sets $gclbk := $f − $Gmin 276for this sub-call CTC is specified fully in Fig 6 Here, Call denotes a call to a contact entry point|,Non-data,101
| Town Crier blockchain contract CTC with fees Initialize: Counter := 0 Program for Town Crier Relay R Initialize: Send init to Fsgx[progencl,R] On recv (pkTC , σatt) from Fsgx[progencl,R]: Publish (pkTC , σatt) Request: On recv (params, callback, $f, $greq) from some Handle(id, params): , T ) Parse params as ( , Wait until clock() ≥ Tmin Send (resume, id, params) to Fsgx[progencl,R] On recv ((id, params, data, $gdvr), σ) from Fsgx[progencl,R]: AuthSend (id, params, data, $gdvr) to CTC as WTC // msgm3 Main: Loop Forever: Wait for CTC to records request (id, params, Fork a process of Handle(id, params) , , ): End Figure 7: The Town Crier Relay R Then progencl fetches the requested datagram and returns it to R along with params, id, and a GASLIMIT $gdvr := $Gmax, all digitally signed with skTC |,Non-data,101
| Fig 8 shows the protocol for progencl Program for Town Crier Enclave (progencl) Initialize (void) // Subroutine call from Fsgx, which attests to // progencl and pkTC  See Figure 3|,Non-data,101
| (pkTC , skTC ) := ΣKeyGen(1λ) Output pkTC Resume (id, params) Parse params as (url, spec, T ): Assert clock() ≥ Tmin Contact url via HTTPS, obtaining cert Verify cert is valid for time clock() Obtain webpage w from url Assert clock() ≤ Tmax Parse w to extract data with specification spec $gdvr := $Gmax σ := Σ|,Non-data,101
|Sign(skTC , (id, params, data, $gdvr)) Output ((id, params, data, $gdvr), σ) CU : Assert $Gmin ≤ $f ≤ $Gmax id := Counter; Counter := Counter + 1 Store (id, params, callback, $f,CU ) // $f held by contract // msgm1 Deliver: On recv (id, params, data, $gdvr) from WTC : (1) If isCanceled[id] and not isDelivered[id] (2) Set isDelivered[id] Send $G∅ to WTC Return Retrieve stored (id, params(cid:48), callback, $f, ) Assert params = params(cid:48) and $f ≤ $gdvr // abort if not found and isDelivered[id] not set (3) Send $f to WTC Set isDelievered[id] Set $gclbk := $f − $Gmin (4) Call callback(data) with gas $gclbk // msgm4 Cancel: On recv (id, $gcncl) from CU : , $f,C(cid:48) U ) U and $f ≥ $G∅ and isDelivered[id] not set and isCanceled[id] not set Retrieve stored (id, Assert CU = C(cid:48) // abort if not found , Set isCanceled[id] (5) Send ($f − $G∅) to CU // hold $G∅ Figure 6: TC contract CTC reflecting fees The last argument of each function is the GASLIMIT provided|,Non-data,101
| The Relay R As noted in Section 3, R bridges the gap between the Enclave and the blockchain in three ways 1 It scrapes the blockchain and monitors CTC for new re- quests (id, params)|,Non-data,101
| 2 It boots the Enclave with progenclInitialize() and calls progenclResume(id, params) on incoming requests|,Non-data,101
 3 It forwards datagrams from the Enclave to the blockchain Recall that it forwards already-signed transacations to the blockchain as WTC  The program for R is shown in Fig,Non-data,101
 7 The function AuthSend inserts a transaction to blockchain (“as WTC ” means the transaction is already signed with skTC ) An honest Relay will invoke progenclResume ex- actly once with the parameters of each valid request and never otherwise,Non-data,101
| The Enclave progencl When initialized through Initial- ize(), progencl ingests the current wall-clock time; by storing this time and setting a clock reference point, it calibrates its absolute clock It generates an ECDSA keypair (pkTC , skTC ) (parameterized as in Ethereum), where pkTC is bound to the progencl instance through insertion into attestations Upon a call to Resume(id, params), progencl contacts the data source specified by params via HTTPS and checks that the corresponding certificate cert is valid|,Non-data,101
 (We discuss cer- tificate checking in the appendix of the online version [39]) Figure 8: The Town Crier Enclave progencl The Requester Contract CU  An honest requester first follows the protocol in Fig,Non-data,101
| 5 to verify the SGX attestation Then she prepares params and callback, sets $greq to the cost of Request with params, sets $f to $Gmin plus the cost of ex- ecuting callback, and invokes Request(params, callback, $f) with GASLIMIT $greq If callback is not executed, she can invoke Cancel(id) with GASLIMIT $Gcncl to receive a partial refund An honest re- quester will invoke Cancel at most once for each of her requests and never for any other user’s request|,Non-data,101
| 61 Private and Custom Datagrams In addition to ordinary datagrams, TC supports private datagrams, which are requests where params includes ci- 277Wallets User WU Contracts User Contract CU Request ($greq, $f) Deliver $gclbk WTC $gdvr $f TC Contract CTC $f Figure 9: Money Flow for a Delivered Request Red arrows denote flow of money and brown arrows de- note gas limits The thickness of lines indicate the quantity of resources|,Non-data,101
| The $gclbk arrow is thin be- cause $gclbk is limited to $f − $Gmin phertexts under pkTC  Private datagrams can thus enable confidentiality-preserving applications despite the public read- ability of the blockchain Custom datagrams, also supported by TC, allow a contract to specify a particular web-scraping target, potentially involving multiple interactions, and thus greatly expand the range of possible relying contracts for TC|,Non-data,101
| We do not treat them in our security proofs, but give examples of both datagram types in Section 81 62 Enhanced Robustness via Replication Our basic security model for TC assumes the ideal isola- tion model for SGX described above as well as client trust in data sources|,Non-data,101
| Given various concerns about SGX secu- rity [18,38] and the possible fallibility of data sources, we ex- amine two important ways TC can support hedging To pro- tect against the compromise of a single SGX instance, con- tracts may request datagrams from multiple SGX instances and implement majority voting among the responses This hedge requires increased gas expenditure for additional re- quests and storage of returned data Similarly, TC can hedge against the compromise of a data source by scraping mul- tiple sources for the same data and selecting the majority response|,Non-data,101
 We demonstrate both of these mechanisms in our example financial derivative application in Section 82 (A potential optimization is mentioned in Section 10) 6,Non-data,101
|3 Implementation Details We implemented a full version of the TC protocol in a complete, end-to-end system using Intel SGX and Ethereum We defer discussion of implementation details and other practical considerations to the appendix of the online ver- sion [39] 7 SECURITY ANALYSIS Proofs of theorems in this section appear in the appendix of the online version [39]|,Non-data,101
| Authenticity Intuitively, authenticity means that an ad- versary (including a corrupt user, Relay, or collusion thereof) cannot convince CTC to accept a datagram that differs from the expected content obtained by crawling the specified url at the specified time In our formal definition, we assume that the user and CTC behave honestly Recall that the user must verify upfront the attestation σatt that vouches for the enclave’s public key pkTC|,Non-data,101
| Definition 2 (Authenticity of Data Feed) We say that the TC protocol satisfies Authenticity of Data Feed if, for any polynomial-time adversary A that can interact arbitrar- ily with Fsgx, A cannot cause an honest verifier to accept (pkTC, σatt, params := (url, pkurl, T ), data, σ) where data is not the contents of url with the public key pkurl at time T (progenclResume(id, params) in our model) More for- mally, for any probabilistic polynomial-time adversary A,  (pkTC, σatt, id, params, data, σ) ← AFsgx (1λ) : (cid:0)Σsgx|,Non-data,101
|Verify(pksgx, σatt, (progencl, pkTC)) = 1(cid:1)∧ (ΣVerify(pkTC, id, params, data) = 1)∧ data (cid:54)= progenclResume(id, params)  Pr ≤ negl(λ), for security parameter λ Theorem 1 (Authenticity)|,Non-data,101
| Assume that Σsgx and Σ are secure signature schemes Then, the TC protocol achieves authenticity of data feed under Definition 23 Fee Safety Our protocol in Section 6 ensures that an hon- est Town Crier will not run out of money and that an honest requester will not pay excessive fees|,Non-data,101
| Theorem 2 (Gas Sustainability) Town Crier is $Gmax-gas sustainable An honest user should only have to pay for computation that is executed honestly on her behalf If a valid datagram is delivered, this is a constant value plus the cost of executing callback|,Non-data,101
| Otherwise the requester should be able to recover the cost of executing Deliver For Theorem 2 to hold, CTC must retain a small fee on cancellation, but we allow the user to recover all but this small constant amount We now formalize this intuition Theorem 3 (Fair Expenditure for Honest Requester)|,Non-data,101
| For any params and callback, let $Greq and $F be the honestly- chosen values of $greq and $f, respectively, when submitting the request (params, callback, $f, $greq) For any such request submitted by an honest user, one of the following holds: • callback is invoked with a valid datagram matching the request parameters params, and the requester spends at most $Greq + $Gcncl + $F; • The requester spends at most $Greq + $Gcncl + $G∅ Other security concerns In Section 6|,Non-data,101
|2, we addressed concerns about attacks outside the SGX isolation model em- braced in the basic TC protocol A threat we do not address in TC is the risk of traffic analysis by a network adversary or compromised Relay against confidential applications (eg, with private datagrams), although we briefly discuss the is- sue in Section 8|,Non-data,101
|1 We also note that while TC assumes the correctness of data sources, if a scraping failure occurs, TC delivers an empty datagram, enabling relying contracts to fail gracefully 3Recall that we model SGX’s group signature as a regular signature scheme under a manufacturer public key pksgx us- ing the model in [34] 2788|,Non-data,101
 EXPERIMENTS We implemented three showcase applications which we plan to launch together with TC We provide a brief descrip- tion of our applications followed by cost and performance measurements We refer the reader to the appendix of the online version [39] for more details on the applications and code samples 8,Non-data,101
|1 Requesting Contracts Financial Derivative (CashSettledPut) Financial deriva- tives are among the most commonly cited smart contract applications, and exemplify the need for a data feed on financial instruments We implemented an example con- tract CashSettledPut for a cash-settled put option This is an agreement for one party to buy an asset from the other at an agreed upon price on or before a particular date|,Non-data,101
| It is “cash-settled” in that the sale is implicit, ie, no asset changes hands, only cash reflecting the asset’s value Flight Insurance (FlightIns)|,Non-data,101
| Flight insurance indemnifies a purchaser should her flight be delayed or canceled We have implemented a simple flight insurance contract called FlightIns Our implementation showcases TC’s private-datagram feature to address an obvious concern: customers may not wish to reveal their travel plans publicly on the blockchain Roughly speaking, a customer submits to CTC a request EncpkTC (req) encrypted under Town Crier enclave’s public key pkTC |,Non-data,101
| The enclave decrypts req and checks that it is well-formed (eg, submitted sufficiently long before the flight time) The enclave will then fetch the flight informa- tion from a target website at a specified later time, and send to CTC a datagram indicating whether the flight is delayed or canceled|,Non-data,101
| Finally, to avoid leaking information through timing (eg, when the flight information website is accessed or datagram sent), random delays are introduced Steam Marketplace (SteamTrade)|,Non-data,101
| Authenticated data feeds and smart contracts can enable fair exchange of dig- ital goods between Internet users who do not have pre- established trust We have developed an example applica- tion supporting fair trade of virtual items for Steam [4], an online gaming platform that supports thousands of games and maintains its own marketplace, where users can trade, buy, and sell games and other virtual items We imple- mented a contract for the sale of games and items for Ether that showcases TC’s support for custom datagrams through the use of Steam’s access-controlled API In our implemen- tation, the seller sends EncpkTC (account credentials, req) to CTC , such that the Enclave can log in as the seller and deter- mine from the web-page whether the virtual item has been shipped|,Non-data,101
| 82 Measurements We evaluated the performance of TC on a Dell Inspiron 13-7359 laptop with an Intel i7-6500U CPU and 800GB memory, one of the few SGX-enabled systems commercially available at the time of writing We show that on this single host—not even a server, but a consumer device—our imple- mentation of TC can easily process transactions at the peak global rate of Bitcoin, currently the most heavily loaded de- centralized blockchain|,Non-data,101
 We report mean run times (with the standard deviation in parenthesis) over 100 trials TCB Size The trusted computing base (TCB) of Town Crier includes the Enclave and TC Contract The Enclave consists of approximately 46,Non-data,101
|4k lines of C/C++ code, the vast majority of which (427k lines) is the modified mbedTLS library [9] The source code of mbedTLS has been widely deployed and tested, while the remainder of the Enclave codebase is small enough to admit formal verification The TC Contract is also compact; it consists of approximately 120 lines of Solidity code|,Non-data,101
| Enclave Response Time We measured the enclave re- sponse time for handling a TC request, defined as the inter- val between (1) the Relay sending a request to the enclave and (2) the Relay receiving a response from the enclave Table 1 summarizes the total enclave response time as well as its breakdown over 500 runs For the three applications we implemented, the enclave response time ranges from 180 ms to 599 ms|,Non-data,101
| The response time is clearly dominated by the web scraper time, ie, the time it takes to fetch the re- quested information from a website Among the three appli- cations evaluated, SteamTrade has the longest web scraper time, as it interacts with the target website over multiple roundtrips to fetch the desired datagram|,Non-data,101
| Transaction Throughput We performed a sequence of Linear Scaling SteamTrade FlightIns CashSettledPut 60 40 20 ) c e s / x t ( t u p h g u o r h T 0 0 5 10 15 20 Number of enclaves on a single machine Figure 10: Throughput on a single SGX machine The x-axis is the number of concurrent enclaves and the y-axis is the number of tx/sec Dashed lines in- dicate the ideal scaling for each application, and er- ror bars, the standard deviation|,Non-data,101
 We ran 20 rounds of experiments (each round processing 1000 trans- actions in parallel) experiments measuring the transaction throughput while scal- ing up the number of concurrently running enclaves on our single SGX-enabled host from 1 to 20 20 TC enclaves is the maximum possible given the enclave memory constraints on the specific machine model we used Fig,Non-data,101
| 10 shows that, for the three applications evaluated, a single SGX machine can handle 15 to 65 tx/sec Several significant data points show how effectively TC can serve the needs of today’s blockchains for authenticated data: Ethereum currently handles under 1 tx/sec on av- erage Bitcoin today handles slightly more than 3 tx/sec, 279CashSettledPut mean % mean % FlightIns tmax tmax 312 258 26|,Non-data,101
6 084 tmin 025 135 187 0,Non-data,101
24 σt 031 18 152 008 0,Non-data,101
6 872 112 02 0,Non-data,101
24 954 40 008 2,Non-data,101
94 600 253 067 tmin 017 418 18,Non-data,101
9 020 σt 032 31 14 0,Non-data,101
08 SteamTrade tmax 325 765 248 065 tmin 0,Non-data,101
36 489 188 024 σt 035 52 1,Non-data,101
28 009 020 962 3,Non-data,101
4 007 mean % 117 576 203 0,Non-data,101
39 599 Ctx switch Web scraper Sign Serialization Total 100 157 202 0,Non-data,101
|40 180 123 482 205 038 505 100 284 158 18 100 623 439 31 100 787 510 52 Table 1: Enclave response time t, with profiling breakdown|,Non-data,101
| All times are in milliseconds We executed 500 experimental runs, and report the statistics including the average (mean), proportion (%), maximum (tmax), minimum (tmin), and standard deviation (σt) Note that Total is the end-to-end response time as defined in Enclave Response Time Times may not sum to this total due to minor unprofiled overhead|,Non-data,101
| and its maximum throughput (with full block utilization) is roughly 7 tx/sec We know of no measurement study of the throughput bound of the Ethereum peer-to-peer network Recent work [19] indicates that Bitcoin cannot scale beyond 26 tx/sec without a protocol redesign Thus, with few hosts TC can easily meet the data feed demands of even future decentralized blockchains|,Non-data,101
| Gas Costs Currently 1 gas costs 5 × 10−8 Ether, so at the exchange rate of $15 per Ether, $1 buys 13 million gas Here we provide costs for our implementation components|,Non-data,101
| The callback-independent portion of Deliver costs about 35,000 gas (26¢), so this is the value of $Gmin We set $Gmax = 3,100,000 gas ($233), as this is approximately Ethereum’s maximum GASLIMIT|,Non-data,101
| The cost for executing Re- quest is approximately 120,000 gas (9¢) of fixed cost, plus 2500 gas (019¢) for every 32 bytes of request parameters The cost to execute Cancel is 62500 gas (47¢) including the gas cost $Gcncl and the refund $G∅ paid to TC should Deliver be called after Cancel|,Non-data,101
| The total callback-independent cost of acquiring a data- gram from TC (ie, the cost of the datagram, not the appli- cation) ranges from 119¢ (CashSettledPut) to 12|,Non-data,101
|9¢ (Steam- Trade)4 The variation results from differing parameter lengths Component-Compromise Resilience For the CashSet- tledPut application, we implemented and evaluated two modes of majority voting (as in Section 6|,Non-data,101
|2): • 2-out-of-3 majority voting within the enclave, providing robustness against data-source compromise In our exper- iments the enclave performed simple sequential scraping of current stock prices from three different data sources: Bloomberg, Google Finance and Yahoo Finance The en- clave response time is roughly 1743 (109) ms in this case (cf|,Non-data,101
| 1058 (88), 423 (34) and 262 (12) ms for each respec- tive data source) There is no change in gas cost, as voting is done inside the SGX enclave In the future, we will in- vestigate parallelization of SGX’s thread mechanism, with careful consideration of the security implications • 2-out-of-3 majority voting within the requester contract, which provides robustness against SGX compromise|,Non-data,101
| We ran three instances of SGX enclaves, all scraping the same data source In this scenario the gas cost would increase by a factor of 3 plus an additional 585¢ So CashSettledPut would cost 35|,Non-data,101
6¢ for Deliver without Cancel The extra 585¢ is the cost to store votes until a winner is known Offline Measurements,Non-data,101
 Recall that an enclave requires 4This cost is for 1 item Each additional item costs 019¢ a one-time setup operation that involves attestation gener- ation,Non-data,101
 Setting up the TC Enclave takes 495 (72) ms and attestation generation takes 619 (10,Non-data,101
|7) ms, including 765 (097) ms for the report, and 549 (10|,Non-data,101
|3) ms for the quote Recall also that since clock() yields only relative time in SGX, TC’s absolute clock is calibrated through an exter- nally furnished wall-clock timestamp A user can verify the correctness of the Enclave absolute clock by requesting a digitally signed timestamp This procedure is, of course, accurate only to within its end-to-end latency|,Non-data,101
 Our experi- ments show that the time between Relay transmission of a clock calibration request to the enclave and receipt of a re- sponse is 114 (19) ms of which 105 (1,Non-data,101
|9) ms is to sign the timestamp To this must be added the wide-area network roundtrip latency, rarely more than a few hundred millisec- onds 9 RELATED WORK Virtual Notary [6, 26] is an early online data attestation service that verifies and digitally signs any of a range of user-requested “factoids” (web page contents, stock prices, etc|,Non-data,101
) potentially suitable for smart contracts It predates and does not at present interface with Ethereum Several data feeds are deployed today for smart contract systems such as Ethereum Examples include PriceFeed [3] and Oraclize,Non-data,101
|it [7] The latter achieves distributed trust by using a second service called TLSnotary [5], which digitally signs TLS session data As a result, unlike TC which can flexibly tailor datagrams, Oraclizeit must serve data ver- batim from a web session or API call; verbose sources thus mean superfluous data and inflated gas costs|,Non-data,101
| Additionally, these services ultimately rely on the reputations of their (small) providers to ensure data authenticity and cannot support private or custom datagrams Alternative systems such as SchellingCoin [13] and Augur [2] rely on prediction markets to decentralize trust, creating a heavy reliance on human input and severely constraining their scope and data types Despite an active developer community, research results on smart contracts are limited Work includes off-chain con- tract execution for confidentiality [27], and, more tangen- tially, exploration of e|,Non-data,101
|g, randomness sources in [11] The only research involving data feeds to date explores criminal applications [25] SGX is similarly in its infancy|,Non-data,101
| While a Windows SDK [23] and programming manual [21] have just been released, a number of pre-release papers have already explored SGX, eg, [8, 28, 30, 32, 38] Researchers have demonstrated ap- 280plications including enclave execution of legacy (non-SGX) code [10] and use of SGX in a distributed setting for map- reduce computations [32]|,Non-data,101
| Several works have exposed short- comings of the security model for SGX [18,33,34], including side-channel attacks against enclave state 10 FUTURE WORK We plan to develop TC after its initial deployment to in- corporate a number of additional features We discuss a few of those features here|,Non-data,101
| Freeloading Protection There are concerns in the Ethereum community about “parasite contracts” that forward or re- sell datagrams from fee-based data feeds [36] As a coun- termeasure, we plan to deploy the following mechanism in TC inspired by designated verifier proofs [24] The set of n users U = {U1, |,Non-data,101
|   , Un} of a requesting contract generate an (n, n)-secret-shared key pair (skU , pkU ) They submit their n individual shares to the TC Enclave (e|,Non-data,101
|g, as ciphertexts under pkTC sent to CTC ) TC now can sign datagrams using skU  Each user Ui can be sure individually that a datagram produced by TC is valid, since she did not collude in its creation|,Non-data,101
| Poten- tial parasitic users, however, cannot determine whether the datagram was produced by CTC or by U, and thus whether or not it is valid Such a source-equivocal datagram renders parasite contracts less trustworthy and thus less attractive Revocation Support There are two forms of revocation relevant to TC|,Non-data,101
| First, the certificates of data sources may be revoked Since TC already uses HTTPS, it could easily use the Online Certificate Status Protocol (OCSP) to check TLS certificates Second, an SGX host could become com- promised, prompting revocation of its EPID signatures by Intel The Intel Attestation Service (IAS) will reportedly disseminate such revocations|,Non-data,101
| Conveniently, clients already use the IAS when checking the attestation σatt, so revoca- tion checking will require no modification to TC Hedging Against SGX Compromise We discussed in Section 62 how TC can support majority voting across SGX hosts and data sources|,Non-data,101
| Design enhancements to TC could reduce associated latency and gas costs For SGX voting, we plan to investigate a scheme in which SGX-enabled TC hosts agree on a datagram value X via Byzantine consensus The hosts may then use a threshold digital signature scheme to sign the datagram response from WTC , and each partici- pating host can monitor the blockchain to ensure delivery Updating TC’s Code|,Non-data,101
| As with any software, we may discover flaws in TC or wish to add new functionality after initial deployment With TC as described above, however, updating progencl would cause the Enclave to lose access to skTC and thus be unable to respond to requests in CTC  The TC operators could set up a new contract C(cid:48) TC referencing new keys, but this would be expensive and burdensome for TC’s operators and users While arbitrary code changes would be insecure, we could create a template for user con- tracts that includes a means to approve upgrades|,Non-data,101
| We plan to investigate this and other mechanisms Generalized Custom Datagrams and Within-Enclave Smart-Contract Execution In our SteamTrade example contract we demonstrated a custom datagram that scrapes a user’s online account using her credentials A more generic approach would allow users to supply their own general- purpose code to TC and data-source-enriched emulation of private contracts as in Hawk [27], but with considerably less computational overhead|,Non-data,101
| Placing such large requests on the blockchain would be prohibitively expensive, but code could easily be loaded into the TC enclave off-chain Of course, deploying arbitrary user code raises many security and confidentiality concerns which TC would need to ad- dress TC offers a basic framework, however, within which to provide confidential, integrity-protected smart-contract code execution off-chain with trustworthy integration into on-chain smart-contract code 11|,Non-data,101
| CONCLUSION We have introduced Town Crier (TC), an authenticated data feed for smart contracts specifically designed to support Ethereum Use of Intel’s new SGX trusted hardware allows TC to serve datagrams with a high degree of trustworthiness We defined gas sustainability, a critical availability property of Ethereum services, and provided techniques for shrinking the size of a hybrid TCB spanning the blockchain and an SGX We proved in a formal model that TC serves only data from authentic sources, and showed that TC is gas sustain- able and minimizes cost to honest users should the code be- have maliciously|,Non-data,101
| In experiments involving end-to-end use of the system with the Ethereum blockchain, we demonstrated TC’s practicality, cost effectiveness, and flexibility for three example applications We believe that TC offers a power- ful, practical means to address the lack of trustworthy data feeds hampering Ethereum evolution today and that it will support a rich range of applications Pending deployment of the Intel Attestation Service (IAS), we will make a version of TC freely available as a public service Acknowledgements This work is funded in part by NSF grants CNS-1314857, CNS-1330599, CNS-1453634, CNS-1518765, CNS-1514261, a Packard Fellowship, a Sloan Fellowship, Google Faculty Research Awards, and a VMWare Research Award|,Non-data,101
|ABSTRACT We put forth a new cryptographic primitive called a Traitor Deterring Scheme (TDS) A TDS is a multi-recipient public- key encryption scheme where an authority issues decryption keys to a set of users The distinguishing feature of a TDS is that secret-keys are issued only after the users provide some private information as a form of collateral The traitor de- terring property ensures that if a malicious coalition of users (aka “traitors”) produces an unauthorized (aka “pirate”) de- cryption device, any recipient of the device will be able to re- cover at least one of the traitors’ collaterals with only black- box access to the device|,Non-data,102
| On the other hand, honest users’ collaterals are guaranteed to remain hidden In this fashion a TDS deincentivizes malicious behavior among users We model, construct and analyze TDS’s based on various cryptographic assumptions and we show how bitcoin can be used as collateral for real world deployment of TDS’s for the distribution of digital content Along the way, we present cryptographic building blocks that may be of independent interest, namely fuzzy lockers, and comparison predicate en- cryption schemes for exponentially large domains|,Non-data,102
| We also compare TDS with previous primitives specifically traitor tracing schemes (TTS) introduced by Chor et al [9] and digital signets for self enforcement introduced by Dwork et al [12] A TDS constitutes a strict strengthening of a TTS and, when modeled in what we call the “known ciphertext model”, it is a reformulation of digital signets in the public- key, black-box secure setting|,Non-data,102
| In digital signets the adver- sary attempts to transmit a pirate copy at a favorable “space rate”, ie, without having to send the whole plaintext (and without revealing the traitor collaterals) It is an open ques- tion from [12] to construct o(1) space rate schemes under a falsifiable assumption|,Non-data,102
 With our TDS constructions we re- solve this open question showing feasibility for space rates O(log λ/λ) and infeasibility for space rates Ω(log2 λ/λ) Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita- tion on the first page Copyrights for components of this work owned by others than ACM must be honored Abstracting with credit is permitted,Non-data,102
| To copy otherwise, or re- publish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from Permissions@acmorg CCS’15, October 12–16, 2015, Denver, Colorado, USA|,Non-data,102
 c(cid:13) 2015 ACM ISBN 978-1-4503-3832-5/15/10 ,Non-data,102
$1500 DOI: http://dxdoi,Non-data,102
org/101145/28101032813698 Categories and Subject Descriptors K,Non-data,102
|6 [Management of Computing and Information Sys- tems]: Security and Protection; E3 [Data Encryption]: Public key Cryptosystems Keywords Digital Rights Management; Public-key Cryptography; Self- enforcement; Key Management; Bitcoin 1 INTRODUCTION A traitor tracing scheme (TTS) is a multi-user encryp- tion scheme that when some users (aka traitors) collude to produce an unauthorized decryption device (aka a pirate de- cryption box), it is possible to recover at least one of their identities TTS’s de-incentivize piracy, in the sense that colluders may be identified by the authority once an unau- thorized device is detected|,Non-data,102
| Since it was introduced in [9], there have been numerous works, improving different aspects of efficiency and security considerations, cf [2–5, 8, 22, 23] However, in a TTS, recovering the identity of a traitor can only happen when the authority becomes aware of the unau- thorized decryption device This means that if the traitors operate stealthily (e|,Non-data,102
|g, distribute a pirate device in some closed network) there is nothing the authority can do to de- ter them, and thus in this setting the tracing mechanism becomes ineffective Furthermore, the penalty that the au- thority may inflict to the traitors can only be applied “after- the-fact”, ie|,Non-data,102
|, only after the unauthorized decoder has been recovered and analyzed by the authority To address the challenges above, we strengthen the notion of TTS and put forth a new primitive we call a traitor de- terring scheme (TDS): a multi-recipient encryption scheme where each recipient (henceforth also called a user) has some secret information that is provided as a collateral and hid- den in a public directory If the user is honest and keeps her key to herself, her secret information remains hidden On the other hand, if some users collude to produce an unau- thorized decryption device, any recipient of the device will be able to recover one of the colluders’ collateral secret in- formation|,Non-data,102
| One particularly suitable user-specific information that can be used as collateral within a TDS is a bitcoin address secret key When registering for service, the subscriber puts as collateral a small bitcoin amount into a fresh address and the secret-key of the bitcoin address is embedded as col- lateral In case the bitcoin address is used as input to a transaction, the public nature of the bitcoin ledger enables 231the service provider to detect it and take appropriate action (See section 6 for details) Compared to TTS’s, the main difficulty of constructing a TDS is that one needs to enable a public recovering proce- dure which returns the user’s secret information that is an element of an exponentially sized domain — in other words linear number of bits in the security parameter λ need to be extracted from the pirate box|,Non-data,102
| Contrary to that, in a TTS, the authority only needs to recover the identity of a traitor, which is an element of merely a polynomially sized domain — in other words just logarithmic number of bits in the se- curity parameter λ need to be extracted from the pirate box As in TTS, the recovering procedure should work given only black-box access to the pirate decryption box which may be only partially working Furthermore, it should operate without utilizing any private-key information, as in a TTS with public traceability [8] A TDS (or a TTS) can also be considered in a stronger ad- versarial model that we call “the known ciphertext model”|,Non-data,102
| In this model the adversary aims at communicating a pirated copy consisting of a sequence of plaintexts that corresponds to a given set of (polynomially many) ciphertexts (eg, the contents in a CD or a public database); without loss of gen- erality we can assume the pirate copy is in the form of a pirate box that acts only on the known sequence of cipher- texts The adversary aims at producing a pirate box of smaller size than the sequence of plaintexts; we capture this in the model by requiring the “space rate” of the attacker to be o(1)|,Non-data,102
| This problem was first considered by Dwork, Lotspiech and Naor [12] Constructing a TDS or a TTS in the known ciphertext model under a falsifiable assumption has been an open question since then Our contributions We formalize TDS’s and we give two different construction methods that we instantiate in various ways; further, we formalize the known-ciphertext model in the spirit of [12] and we provide both feasibility and infea- sibility results for TDS in this model|,Non-data,102
| Finally we elaborate on how to use bitcoin as collateral in conjunction to a TDS In more detail: 1 We put forth the formal model for TDS’s Such schemes enable the embedding of hidden user-specific informa- tion in a public parameter, and have three security properties: (i) security of plaintexts which is formal- ized in a standard fashion as in public-key encryption; (ii) privacy of user information that is hidden in the public parameters|,Non-data,102
| This property should be upheld even if all other users conspire against a user as long as the secret key of the user is not compromised; fi- nally, (iii) traitor deterring suggests that there is a re- coverability algorithm that given black-box access to some working implementation of a decryption device, it is capable of recovering the private information of at least one traitor, using only public information 2 We give two construction methods for TDS’s The first one is based on fingerprinting codes [9, 20] and a new primitive we call a fuzzy locker|,Non-data,102
| In a fuzzy locker, the message is encrypted using a random code- word Ci; the decryption operation returns the message given any C∗ that would result in the i-th user be- ing accused in the underlying fingerprinting code In the TDS construction, the recovering procedure will first retrieve a pirate codeword C∗ from the decryp- tion device; the traceability of the fingerprinting code will guarantee that one of the collusion’s codewords will be accused, thus the corresponding traitor secret will be unlocked We then give a concrete construction of a fuzzy locker for CFN codes [9] using the idea of fuzzy extractors [11] paired with efficient list decoding for Reed-Solomon codes [17,30] Our second construc- tion method for TDS’s generalizes the constructions of [4, 5] that are based on comparison predicate en- cryption (CPE)|,Non-data,102
| Contrary to these works however, we require that the user identity space is exponentially large, so that a randomly chosen user identity can be used as a secret key to hide the user secret information directly To recover the hidden information given a pi- rate decryption decoder we utilize a binary search type of recovering mechanism to navigate through the expo- nentially sized domain and discover one of the traitor identities Given this identity we proceed to unlock the user hidden data A CPE scheme can be obtained via functional encryption (FE) using indistinguisha- bility Obfuscation (iO) [13]|,Non-data,102
| In order to obtain a con- struction based on standard assumptions we resort to bounded collusion FE [14, 15] We provide a more ef- ficient construction for this primitive via a combinato- rial argument and we then use it to instantiate a CPE with exponential size domain Our TDS constructions are summarized in Fig 1|,Non-data,102
| 3 We revisit the problem of digital signets [12] and we formulate the “known ciphertext model” for TDS where the adversary knows the target set of (polynomially many) ciphertexts before implementing the pirate box In an attack in this model, the adversary tries to achieve a favorable “space rate”, ie|,Non-data,102
|, produce a decryption box that has size smaller than the total plaintext mate- rial that is encoded in the known ciphertexts without leaking any of the traitors’ collaterals Constructing a TDS in the known ciphertext model is equivalent to the problem of constructing digital-signets with self- enforcement as defined in [12] which is open under fal- sifiable assumptions; the construction of [12] assumes an incompressible function of a specific type (this is an unfalsifiable assumption) and the recovering strat- egy has full access to the key It works for any space rate o(1) With our TDS constructions we resolve the open question showing feasibility under falsifiable as- sumptions for space rates O(log λ/λ) while we show infeasibility for space rates Ω(log2 λ/λ) in the black- box recoverability setting|,Non-data,102
| In our results, we exploit bounds on the false positive rate of the membership testing problem to show how our TDS schemes can be used while our negative result applies Bloom filters [1] to provide an efficient attacker strategy 4 We describe how one can use bitcoin as a collateral in a TDS Recall that collaterals are arbitrary strings hence a service provider (SP) can embed as collat- eral the secret-key of a fresh bitcoin address credited by the user|,Non-data,102
| As part of the user agreement, the ac- count should remain frozen (ie, any outgoing trans- action from this account can be noticed by the service provider from the public ledger and the subscription will be cancelled) As long as the user respects the service agreement the collateral remains safe and the user may reclaim it when the service contract termi- nates|,Non-data,102
| 232Assumption Ciphertext size Upper bound on t Recoverability Construction I Construction I Construction II Construction II PKE PKE LWE iO O(t2 log2(n/)) O(log(n/)/λ) O(t4λ) O(t3+epoly(λ)) O(1) n n n Black-box Black-box Black-box Black-box Figure 1: Comparison of our TDS’s; t is the collusion size, n is total number of users, e = 1/poly(λ),  is the error term in the fingerprinting code which is negl(λ) and λ is the security parameter PKE denotes public-key encryption, LWE denotes the learning with errors problem, and iO denotes indistinguishability obfuscation Related primitives As discussed above, a TTS aims at providing “a posteriori” deterrence of malicious users while TDS provides, in addition, a proactive way of deterrence|,Non-data,102
| Furthermore, traitor tracing is possible only when the au- thority gains access to the pirate box, while in a TDS, the mere act of sharing a decryption key (or any, even partially working, implementation of a decryption algorithm contain- ing such key) will lead to the leakage of one of the traitors’ secrets We show that a traitor deterring scheme implies a publicly traceable traitor tracing scheme [8] (cf Section 2) Another closely related notion to a TDS is digital signets for self-enforcement [12]|,Non-data,102
| In this multi-user encryption sys- tem, the adversary that controls a set of traitor user keys and wants to retransmit a certain plaintext that was trans- mitted, will either send a message as long as the plaintext itself, or will have to leak some of the traitors’ private data The formalization of the problem in [12] assumes that re- coverability of the collateral information requires direct ac- cess to the traitor keys (also called white-box access) In our terminology, they provide a symmetric-key TDS that is only secure in the non-black-box sense The construc- tion provided by [12] relies on the unfalsifiable assumption that f (x) = gx (cid:96) is incompressible (incompress- ible means given x, f , no adversary can come up with an intermediate value y, such that: (1)|,Non-data,102
| ||y||/||f (x)|| = o(1); (2) one can recover f (x); (3) x remains hidden) 2|||| |,Non-data,102
|  ||||gx 1||||gx Kiayias and Tang studied the problem of leakage deter- ring (LD) public key cryptography [21] If a key owner leaks any partially working decryption box, a piece of secret infor- mation that is embedded in her public key will be revealed to the recipient|,Non-data,102
 Our notion of TDS is a generalization of LD from the single user setting to the multi-user setting We note that because of collusion attacks in the multi-user setting the techniques for recoverability from [21] are not directly applicable for building a TDS (even a scheme with ciphertext size linear in the number of users is not obvious) 2 DEFINITIONS AND SECURITY MODELS We provide the formal definition and security model of TDS’s and demonstrate their relationship to TTS’s,Non-data,102
| Syntax of traitor deterring schemes Informally, a traitor de- terring scheme is a multi-user encryption scheme with a de- terring mechanism such that if some of the receivers collude to leak an implementation of a (potentially only partially working) decryption device, any recipient of the device will be able to recover one of the colluding user’s secret informa- tion which is hidden in the public parameter of the system Formally we have the following: • Setup(1λ, s1,  |,Non-data,102
|  , sn): This algorithm is composed of two parts: KeyGen, which, on input the security pa- rameter it outputs an encryption key pk, and a set of decryption keys sk1,   |,Non-data,102
| , skn; and ParGen that on in- put pk, sk1,    , skn and the users’ secrets s1, |,Non-data,102
|   , sn ∈ {0, 1}λ it outputs public parameter para • Enc(pk, m): on input para, pk and a message m, it outputs a ciphertext c|,Non-data,102
| • Dec(ski, c): on input para, pk, one of the secret keys ski and a ciphertext c, it outputs a plaintext m • RecB,D(pk, para): on input para, pk with has oracle access to a device B and a distribution D it outputs a string in {0, 1}λ or ⊥ The correctness of the scheme is standard and entails that Enc(pk,·) can be inverted by Dec(ski,·) for any i = 1,  |,Non-data,102
|  , n The intended functionality of the algorithm Rec is that if B is created by a collusion of receivers with se- cret keys ski1 ,  |,Non-data,102
|  , skit and operates correctly for ciphertexts whose corresponding plaintext follows a distribution D, the algorithm outputs at least one of the strings si1 ,   |,Non-data,102
| , sit  We clarify the conditions under which this is supposed to hap- pen (as well as the other necessary security properties) in the next paragraph Security model There are three security requirements for a traitor deterring scheme, security of plaintexts, privacy of user’s secrets, and traitor deterring|,Non-data,102
| IND-CPA security Regarding security of plaintexts we consider a security property of IND-CPA defined in a stan- dard fashion: the challenger C runs setup to obtain s1,   |,Non-data,102
| , sn and provides the adversary A with para, pk In response, A provides two plaintexts m0, m1 to C Subsequently C com- putes ψ = Enc(pk, mb) for a random b ∈ {0, 1} and provides ψ to A A returns a bit b(cid:48) and C terminates with 1 if b = b(cid:48) and 0 otherwise|,Non-data,102
 The probability that C returns 1 means that A is successful and we denote it by SuccindcpaA (1λ) For (1λ)] ≤ 1/2 + security to hold it must be that Pr[SuccindcpaA negl(λ) The notion of security can be extended in a straight- forward manner to IND-CCA2 Privacy,Non-data,102
| Regarding the privacy of user secret information it should be the case that each si value remains hidden within the public parameter even all other users are corrupted For- mally, consider the following game: • The challenger C first simulates the KeyGen part of the Setup algorithm and returns pk to the adversary • The adversary A sends an index i as well as private information {sj}j(cid:54)=i and the pair si,0, si,1 to C • The challenger C randomly flips a bit b, and simulates the ParGen part of Setup on input pk, sk1, |,Non-data,102
|   , skn, s1,  |,Non-data,102
|  , si−1, si,b, si+1,   |,Non-data,102
| , sn C sends to A the values para, sk1,   |,Non-data,102
|, ski−1, ski+1,    , skn|,Non-data,102
 • A returns a single bit b(cid:48) and C returns 1 if b = b(cid:48) 233The event that C returns 1 means A is successful and we denote it by SuccprivA (1λ) For privacy of secret information to hold it must be that Pr[SuccprivA (1λ)] ≤ 1/2 + negl(λ) for any PPT adversary A Note that letting the challenger send the public key first makes the definition stronger,Non-data,102
| It is also possible to define weaker variants of the above definition, eg, where A is restricted to a number t of secret-keys or the pk is returned together with the secret keys Traitor-Deterring|,Non-data,102
| Finally we define the traitor deter- ring property In order to specify the definition we need first to define the notion of δ-correctness with respect to a public-key pk and a plaintext distribution D A device B is δ−correct with respect to D and pk if it satisfies that Pr[B(Enc(pk, m)) = m : m ← D] ≥ δ With the public parameter, and a non-trivial pirate decryption box B which is created by the collusion of all users, the recovering algo- rithm should determine of the colluder’s secret information si|,Non-data,102
| Formally, consider the following game: • The challenger C simulates the Setup algorithm and the adversary A receives pk A then provides a vector of secret information s1,   |,Non-data,102
| , sn as well as an arbitrary subset T ⊆ {1,    , n} to the challenger C and A re- ceives the secret keys of all users in T , {ski || i ∈ T} as well as the public parameter para|,Non-data,102
| • A outputs an implementation B and a distribution D • C returns 1 iff RecB,D(pk, para) (cid:54)∈ {si || i ∈ T} We define by SuccdeterA (1λ) the event that C returns 1 We say a scheme achieves fully collusion resilient, black-box traitor deterring w|,Non-data,102
rt a class of distributions D (that may depend on δ) if for any PPT adversary A it holds that Pr[B is δ-correct wr,Non-data,102
t D∧D ∈ D∧SuccdeterA (1λ)] = negl(λ) In the above experiment we assume that Rec has reset- table black-box access to B Weaker variants of the above formulation may be relevant in some settings and can be “t- collusion resilient” (as opposed to fully-collusion resilient) or they may extend Rec’s access to B (e,Non-data,102
|g, in a non-black-box setting Rec may have access to the traitor keys) Definition 21 (cid:104)Setup, Enc, Dec, Rec(cid:105) is a (fully-collusion resistant, black-box) traitor deterring scheme if it satisfies, (i) correctness, (ii) IND-CPA security, (iii) privacy and (iv) fully-collision resistant, black-box traitor deterring|,Non-data,102
| TDS and TTS We conclude the section by a brief argu- ment that a traitor deterring scheme is a strict generalization of a traitor tracing scheme (in fact of a TTS with “public- traceability” [8]) Given a TDS: (cid:104)Setup, Enc, Dec, Rec(cid:105), the reduction is easy with the following simple observation First we set si = i for all i = 1, |,Non-data,102
|   , n It follows that the Setup algorithm requires no other input other than the se- curity parameter λ|,Non-data,102
| Observe now that the Rec algorithm will output one of the indices of the colluding users who jointly produce the decryption box B with only access to pk, hence it is a TTS with public-traceability 3 TRAITOR DETERRING FROM FINGER- PRINTING CODES In this section, we will present our first technique of con- structing a TDS from fingerprinting codes We first formal- ize a new encryption scheme we call fuzzy locker (w|,Non-data,102
|rt a fingerprinting scheme), from which together with a public key encryption, we will construct a TDS We then give a concrete construction of fuzzy locker for CFN codes [9] First, let us recall the definition of fingerprinting codes [20]|,Non-data,102
| A q-ary fingerprinting code is a pair of algorithms (Gen, Accuse) Gen is a probabilistic algorithm with input a security/error parameter  and two numbers n, t denoting the number of users and the maximum collusion size respec- tively, and t ∈ [n] = {1,   |,Non-data,102
| , n} It outputs n q-ary strings C = {C1,   |,Non-data,102
| , Cn} (called codewords), where Ci = ci 1    ci for i ∈ [n], j ∈ [(cid:96)], ci j ∈ Q–the alphabet set with size q and (cid:96) a tracing key tk|,Non-data,102
| Accuse is a deterministic algorithm with input a “pirate” codeword C∗, and a user codeword Ci and the tracing key tk; it outputs a bit in {0, 1} Suppose adversary A corrupts up to t users (whose indices form a set Ucor ⊂ [n]), and outputs a pirate codeword C∗ = (cid:96)  We define the accused user set as Uacc = {i ∈ 1  |,Non-data,102
|  c∗ c∗ [n] : Accuse(tk, C∗, Ci) = 1] A fingerprinting code is called t−collusion resistant (fully collusion resistant if t = n) if it satisfies: (i) traceability, if the strategy of producing C∗ satisfies the “marking assumption”, (for each i ∈ [n], c∗ i = i for some j ∈ Ucor), then one of the colluders must be cj accused, ie|,Non-data,102
|, Pr[Uacc ∩Ucor = ∅] ≤ ; and (ii) soundness, the probability that an innocent user is accused is bounded by , ie, Pr[([n] − Ucor) ∩ Uacc (cid:54)= ∅] ≤  3|,Non-data,102
|1 TDS from fuzzy lockers Fingerprinting codes are combinatorial designs that en- able testing whether a codeword is used in generating a pi- rate codeword They were demonstrated to be very useful in building TTS in a line of previous works, eg|,Non-data,102
|, [3, 9, 22] The basic idea is that each user will be assigned an “identity” which is represented by a codeword, and the secret keys for the user will be selected from a group of keys according to his codeword The encryption algorithm will cover all the user keys The tracing algorithm will first recover a “pirate codeword” by feeding the pirate decryption device with mal- formed (but seemingly valid in the view of A) ciphertexts, and then it will run the tracing algorithm of the fingerprint- ing code to identify at least one of the colluding users who participated in producing the pirate codeword|,Non-data,102
| The main challenge of upgrading the above paradigm to a TDS is the way of embedding and recovering of the secret information of the users To address this, we formalize a new primitive we call fuzzy locker wrt|,Non-data,102
| a (publicly traceable) fingerprinting code In a fuzzy locker, a message is encrypted using a random codeword Ci The message can be decrypted (“unlocked”) only if one provides a pirate codeword C∗ such that Ci will be accused by the accusation algorithm, other- wise, the message will remain IND-CPA secure Given such a primitive, one can construct a TDS as follows: the em- bedding of the user private information can be simply done via encryption using the user’s codeword (which is normally randomly selected according to the Gen algorithm)|,Non-data,102
| The pri- vacy requirement can be easily achieved via the security of the fuzzy locker The recover algorithm will first retrieve a “pirate codeword” from the pirate box and then it will try decrypting all locked data using this pirate codeword The traitor deterring property can be guaranteed by the traitor tracing property of the fingerprinting code, since at least one of the codewords used in producing the pirate codeword will be accused and thus the private user data can be retrieved We first give the formal definition and security model of 234a fuzzy locker|,Non-data,102
 Wlog,Non-data,102
|, we can think of the Gen algorithm of the fingerprinting code C to operate in two phases, first, using n, t and the security parameter produces a secret state st and then uses a CSample subroutine that produces the codewords one-by-one while updating the state st Definition 31 A fuzzy locker w|,Non-data,102
|rt a (publicly traceable) fingerprinting code C consists of the following two algorithms: • FLEnc(Ci, m): Given a codeword Ci ← CSample and a message m, the encryption algorithm outputs a ciphertext c|,Non-data,102
| • FLDec(C∗, c): Given a ciphertext c and a string C∗, the algorithm outputs a message m or ⊥ Correctness: If CAccuse(tk, Ci, C∗) = 1: Pr[FL|,Non-data,102
|Dec(C ∗ , c) = m] ≥ 1 − negl(λ) Security of a fuzzy locker We define t-resilient security (fully resilient if t = n) of a fuzzy locker scheme in the sense of IND-CPA security, by considering the following game be- tween a challenger C and an adversary A: • The challenger produces st using Gen on input , t, n and sends C1,  |,Non-data,102
|  , Ct ← CSample(st) to A • A selects two messages m0, m1 and sends them to C|,Non-data,102
| • The challenger randomly samples a codeword C0 ← CSample(st), randomly flips a coin b, and sends c = FLEnc(C0, mb) to the adversary A • A outputs her guess b(cid:48)|,Non-data,102
