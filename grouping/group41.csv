 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| A fuzzy locker is t-resilient IND-CPA secure if: || ≤ negl(λ) FL = || Pr[b A Adv (cid:48) = b] − 1 2 Construction-I of TDS Given a fuzzy locker and a public key encryption (PKE) with the algorithms (KeyGen, Enc, Dec), we can construct a TDS as follows: • Setup(1λ, s1,  |,Non-data,102
|  , sn, t): The algorithm first runs the (q-ary) codeword generation algorithm CGen which in- puts the security parameter, and t, n, it returns {Ci}i∈[n], tk, where Ci = ci KeyGen of the PKE and returns q(cid:96) key pairs: (cid:96) The algorithm then runs the 1, |,Non-data,102
|   , ci (pk1,1, sk1,1),  |,Non-data,102
|  , (pk1,(cid:96), sk1,(cid:96)); (pk2,1, sk2,1),   |,Non-data,102
| , (pk2,(cid:96), sk2,(cid:96));    (pkq,1, skq,1), |,Non-data,102
|   , (pkq,(cid:96), skq,(cid:96)) Finally, the Setup algorithm takes users’ secrets s1,  |,Non-data,102
|  , sn, tk, C1,   |,Non-data,102
| , Cn and all those key pairs as inputs, and it outputs system parameter para, an encryption key pk, and a set of decryption keys sk1,    , skn|,Non-data,102
| Specif- ically, pk contains all the public keys above; ski = } for i ∈ [n]; and para contains tk {sk1,ci and (cid:104)ω1,    , ωn(cid:105), where ωi = FL|,Non-data,102
|Enc(Ci, si) ,   |,Non-data,102
| , sk(cid:96),ci 1 (cid:96) putes m(cid:96) = m−(cid:80)(cid:96)−1 • Enc(pk, m): This algorithm is given pk and a message m It first randomly samples m1,   |,Non-data,102
| , m(cid:96)−1, then com- i=1 mi and cti,j = Enc(pki,j, mj) for i ∈ [q], j ∈ [(cid:96)]; it outputs the ciphertext ct = {cti,j} • Dec(ski, ct): This algorithm takes inputs para, pk, a secret key ski and a ciphertext ct It parses the secret key and the ciphertext, and computes mj = Dec(skj,ci i=1 mi The algorithm outputs m|,Non-data,102
| and further m =(cid:80)(cid:96) j , cti,j) • RecB,D(pk, para): This algorithm inputs para, pk and has oracle access to a device B and a distribution D It first runs the following procedure for each index k ∈ [(cid:96)] to extract a pirate codeword from B: and computes mk = m −(cid:80) 1 It initializes the pointer value i0 = 1 2|,Non-data,102
| It samples m ← D, samples messages {mi}i(cid:54)=k 3 It feeds ciphertext {cti,j} to B where ci,j = Enc(pki,j, mj) i(cid:54)=k mi if j (cid:54)= k or i > i0; and ci,k = Enc(pki,k, ri) for i ≤ i0 where ri is a random message denoted by n0|,Non-data,102
|), or it returns ri0 +(cid:80) 4 If in N runs (a value that will be determined in the analysis), the number of times n1 that B re- turns m correctly is sufficiently smaller than that in the (i0 − 1)−th experiment (the difference is j(cid:54)=k mj the algorithm returns c∗ k = i0; otherwise, it stores n1, sets i0 = i0 + 1, and repeats from step 2 The pirate codeword retrieved is C∗ The algorithm parses para to identify the data (cid:104)ω1, |,Non-data,102
|   , ωn(cid:105) It then runs the decryption algorithm of the fuzzy locker on all of them, i|,Non-data,102
|e, for i ∈ [n], it runs FLDec(C∗, ωi) = s∗ i  The algorithm stops if ∃s∗ i (cid:54)= ⊥ and it returns s∗ i  Security analysis|,Non-data,102
| Due to lack of space, we present here only a brief sketch about the security properties, and refer to the full version for the detailed proofs Regarding IND-CPA security, it follows in a straightfor- ward manner from the security of the underlying PKE scheme Regarding privacy of the honest user secrets, follows easily from the security of the fuzzy locker Regarding the black-box traitor deterring property, note that the Rec algorithm proceeds in two steps, it first recov- ers a pirate codeword C∗ from the box B|,Non-data,102
| If there exists a colluder codeword Ci, st, Accuse(tk, C∗, Ci) = 1, then in the second step, according to the correctness of the fuzzy locker, the decryption of FLDec(C∗, ωi) will return si|,Non-data,102
| The security of the fingerprinting code guarantees that if any pi- rate codeword is produced following the “marking assump- tion”, it can be used to accuse at least one of the colluders The IND-CPA security of the underlying PKE scheme es- sentially enforces the “marking assumption” To see this, suppose the collusion user secret keys are {ski} for i ∈ Ucor, for each index j, the alphabet c∗ for the pirate codeword for k (cid:54)∈ Ucor with probabil- at index i can not be any ck ity significantly larger than the guessing probability δ − α i Otherwise, these keys may be used to decrypt a ciphertext encrypted under a public key pkk,i|,Non-data,102
| i The choice of N, n0 can be easily determined as follows There must exist an index i0 such that the probability of returning a correct plaintext (denoted by p1) is at least [δ − (δ − α)]/q = α/q smaller than that for i0 − 1 (denoted by p2) From the Chernoff bound Pr[X < (1− ω)μ] ≤ e−ω2μ/2, let us use X 1 i = 1 denote the event that decryption query for i0 − 1 is answered correctly while X 2 i = 0 denote that for i0 is not answered correctly Also we use Xi = 1 denote the above joint event, i|,Non-data,102
|e, Pr[Xi = 1] = Pr[X 1 i = 0] = p1(1−p2) ≥ p1−p2 ≥ α/q When we set N = q α log2 λ, n0 = α 2q N , where λ is the security parameter, the gap will almost always appear and thus a pirate codeword will be identified i = 1 ∧ X 2 Theorem 3|,Non-data,102
|2 Given a public key encryption scheme, and a fully secure fuzzy locker (for a q-ary fingerprinting code), there exists a TDS satisfying: fully collusion resilient, black- 235box traitor deterring property wrt to any message distribu- tion D that has min-entropy H∞(D) ≥ − log(δ − α), where δ is the correctness required by the adversarial device, α is a non-negligible amount that is significantly smaller than δ, and the parameters are set to be N = q 32 A Fuzzy locker for CFN codes|,Non-data,102
| α log2 λ, n0 = α 2q N  1,   |,Non-data,102
| , cj We now propose a construction for a fuzzy locker wrt CFN codes [9]|,Non-data,102
|Consider the CFN fingerprinting scheme where the collusion size is set to be t; in order generate a codeword (cid:96) ← for a user j, the authority randomly samples cj [q](cid:96) The tracing algorithm accuses the user whose codeword has the largest number of locations that share the same sym- bol with the pirate codeword Observe that this accusation procedure is identical to finding the “closest” among all user codewords to the pirate codeword To put it in another way, the user codewords are random strings, but the trac- ing property of the CFN code guarantees that under the “marking assumption”, any pirate codeword produced by a collusion of no more that t random codewords will have a small L1-distance to one of the colluder codewords|,Non-data,102
|1 To facilitate the construction of the fuzzy locker we employ a fuzzy extractor [11] which enables one to retrieve the same random string from two different but correlated strings that have high entropy (cf the fuzzy vault scheme [18]) In more detail, most of the fuzzy extractors follow a correct- then-extract strategy When the two strings are close enough, an error correcting code (ECC) can be used to eliminate their discrepancies and then a randomness extractor [7] is applied to extract a uniform output (which will later be used as a key) from the high entropy codeword (which will be the source from the point of view of the extractor)|,Non-data,102
| However for the fuzzy locker for CFN codes, the portion of disagreement (errors) between the codeword used for encryption and the pirate codeword extracted for decryption is quite large and beyond the decoding capability of a unique decoding ECC We thus give up perfect correctness for the fuzzy locker, and turn to the use of list decoding [17, 30] In a list decodable code, the error correction returns multiple candidates, but it can decode efficiently a number of errors up to portion almost 1 (as opposed to unique decoding) One last thing we need to be careful is that the rate of the ECC should be selected in a way that the entropy loss will not prohibit randomness extraction|,Non-data,102
| Combining the above tools, we will use the uniform string extracted from the fuzzy extractor as a secret key to en- crypt the user secret data We further will assume the valid messages are easily identifiable, and that decryption using a wrong key will almost never yield a valid message These two assumptions are easy to achieve by including in the plaintext a message authentication code or a signature on the message, for details about this technique, we refer to [11, 24] Fuzzy locker for CFN codes|,Non-data,102
|: We present below the fuzzy locker for CFN codes; the choices of the parameters will be specified later Given a randomness extractor Ext and a secure symmetric key encryption (SEEnc, SEDec): • FL|,Non-data,102
|Enc(C, m): The algorithm inputs C = c1    c(cid:96) U←− F (cid:96) q , and message m|,Non-data,102
| It first samples a random ((cid:96), κ)q Reed-Solomon code X = x1,    , x(cid:96) which can correct 1Actually, from the analysis of CFN one infers that if the pirate codeword and user codeword agree on more than (cid:96)/t symbols, the user can be accused|,Non-data,102
| up to (cid:96) − (cid:96)/t errors, and computes Y = (cid:104)y1,    , y(cid:96)(cid:105), where yi = ci + xi mod q; It then selects a random bitstring s and computes k = Ext(s, C), 2 and c = SE|,Non-data,102
|Enc(k, m) The algorithm outputs ct = (Y, s, c) 1,  |,Non-data,102
|  , X(cid:48) (cid:96) and ciphertext ct, it first computes C(cid:48) = c(cid:48) i = yi − c∗ • FLDec(C∗, ct): On input a pirate codeword C∗ = c∗ 1  |,Non-data,102
  c(cid:48) 1   ,Non-data,102
| c∗ where c(cid:48) i mod q, and it runs the list de- coding algorithm on C(cid:48) to get a list of RS codewords {X(cid:48) L} It then computes a list of possible user codewords {C1,   |,Non-data,102
| , CL} where Ci = Yi − X(cid:48) i, where “-” stands for component-wise modular subtraction The algorithm tries the following procedure for ev- it computes ri = Ext(s, Ci) and ery user codeword: If there exists an m (cid:54)= ⊥, the mi = SEDec(ri, c) algorithm outputs m, otherwise, it outputs ⊥|,Non-data,102
 (cid:96) Security analysis Regarding correctness First we re- call the basic idea of the CFN code It randomly samples C ← F (cid:96) q ,Non-data,102
 Suppose t users (wlog,Non-data,102
|, we assume they have codewords C1,    , Ct) collude to produce a pirate codeword C∗|,Non-data,102
| Due to the marking assumption, each symbol c∗ i equals to one of the corresponding symbols in C1,    , Ct|,Non-data,102
| It follows easily that there exists a Ci, such that C∗ and Ci agree on at least (cid:96)/t locations We now check the decryption algorithm on cti = FLEnc(Ci, mi) C(cid:48) = Y − C∗ = X + (C − C∗) (cid:96)} agree with x1, |,Non-data,102
|   , x(cid:96) on at least (cid:96)/t mod q, thus {c(cid:48) 1,  |,Non-data,102
|  , c(cid:48) locations For a Reed-Solomon code RS: Σκ → Σ(cid:96), it can (cid:96)κ errors If we have (cid:96)/t ≥ √ decode at most (cid:96) − √ (cid:96)κ, then RS would return a list of possible candidates which contains the actual X|,Non-data,102
| Then Y − X would yield the user codeword Ci; correctness then follows easily Regarding security: for any honest user whose codeword C that is uniformly selected, we can think it is selected after the pirate code C∗ is produced Following the probabilistic  /3, and q ≥ 4t, it holds analysis from [9], if (cid:96) ≥ 4t log n that Pr[C∗, C agree on (cid:96)/t locations] ≤  It follows that the decoding algorithm will not return any user codeword|,Non-data,102
| A bit more formally, we can think of the ciphertext (Y, s, c) as being generated following the KEM/DEM [10] framework, where Y, s encrypt the session key k which is used to encrypt the data in c Conditioned on Y, s, the min-entropy of C can be calculated as (cid:96) log q− ((cid:96)− κ) log ||Σ|| as s is independent of C, Y is of length (cid:96), and the original random codeword has entropy κ log ||Σ|| Now if we have (cid:96) log q − ((cid:96) − κ) log ||Σ|| ≥ Θ(λ), the strong extractor can output a sufficiently long uniform key k, thus Y, s form a secure KEM Now the IND- CPA security of the message follows from the security of the symmetric key encryption|,Non-data,102
| Due to lack of space, we defer the detailed proof in the full version Setting up the parameters There are multiple con- straints about selecting the parameters for the first con- struction of TDS from the CFN code More specifically, for parameters (cid:96), κ, n, t, , λ being the dimension and de- gree of the RS code, the number of users, the bound of colluders, the error term in the fingerprinting code and the security parameter respectively, they have to satisfy: (1)|,Non-data,102
| (cid:96) ≥ max(κt2, 4t log n  ); (2) (cid:96) log q − ((cid:96) − k) log (cid:96) ≥ Θ(λ)  , we can choose (cid:96) = q = 4t log n, and κ = Θ(λ) The resulting traitor deterring scheme will When κt2 ≤ 4t log n 2we assume here extractors can be applied to large alphabet, if not, we can simply use the bit string representing C to be the input to the extractor|,Non-data,102
| 236have ciphertext size O(t2 log2 n the collusion size is t = O(log n  ), and the upper bound of  /λ); When κt2 ≥ 4t log n  , we can choose (cid:96) = q = λt2, and κ = Θ(λ) The resulting traitor deterring scheme will have ciphertext size O(λt4) for any collusion size t To summarize, if we select the parameters in a way that all the conditions above are satisfied, then the correctness and security of the fuzzy locker for CFN code follows Then from the general construction, we can conclude that: Corollary 3|,Non-data,102
|3 Given PKE, there exists a TDS satisfying: fully-collusion resilient, black-box traitor deterring wrt to any message distribution D that has min-entropy H∞(D) ≥ − log(δ − α), where δ is the correctness probability required by the adversarial device and α is a non-negligible amount significantly smaller than δ|,Non-data,102
| And it is with ciphertext size O(log n  /λ 4 CONSTRUCTION FROM COMPARISON  /λ; and O(t4λ), if t ≥ 4 log n  /λ) when t ≤ 4 log n PREDICATE ENCRYPTION In this section, we will present our second technique of constructing TDS’s based on comparison predicate encryp- tion (CPE) with an exponentially large attribute space We first give the general construction of TDS, then instantiate the CPE from (optimized) bounded collusion functional en- cryption|,Non-data,102
| The resulting TDS exhibits better efficiency than our CFN construction for larger traitor collusions 41 TDS from CPE In a CPE, decryption succeeds only when v ≤ x, where x, v are the attributes for the the ciphertext and the secret key respectively|,Non-data,102
| Moreover, besides standard security, it also requires an attribute hiding property that no adversary A can distinguish c0, c1 which have attributes x0, x1 (assuming x0 < x1) respectively, as long as A does not have a secret key skv such that x0 ≤ v < x1 (even if A has secret key skv that can decrypt both c0, c1) (This corresponds to the fully attribute hiding of predicate encryption [19]) It was shown in [4,5] that a weaker version of CPE (called private linear broadcast encryption in [4], which has only a polynomially large identity space) implies a TTS In the con- struction, each user is assigned an integer index as identity, and the encryption scheme has the property that Enc(pk, i, m) is indistinguishable from Enc(pk, i + 1, m) provided A does not hold ski|,Non-data,102
| Thus the tracer can do a linear scan in the iden- tity space and feed ciphertexts generated using attributes from 0 to n + 1 for each test If he notices a gap between the responses for some i, and i + 1, then the user i will be ac- cused The gap is guaranteed to exist as all users can decrypt Enc(pk, n + 1, m) and no user can decrypt Enc(pk, 0, m) To construct a TDS, we observe that if the indices are cho- sen randomly from an exponentially large space, they could be used as secret keys to hide the user private information|,Non-data,102
| Unfortunately, it is not clear how to generalize [4, 5] to an exponentially large identity space We tackle this problem by constructing CPE’s for an exponential large attribute space from functional encryption; furthermore, we apply a binary search type of tracing In particular, in each step of search (feeding a sequence of tracing ciphertexts using a corresponding pivot identity), the recovering algorithm only consider two states for the pirate box It is functioning, if the decryption probability is close to the claimed correctness of the pirate box; or not functioning, otherwise|,Non-data,102
| Then Rec decides to move to a smaller pivot or a larger oneGiven a CPE (CPESetup,CPEKeyGen,CPE|,Non-data,102
|Enc,CPEDec) and an authenticated encryption (AEEnc, AEDec), our second con- struction of TDS (construction-II) is as follows: • Setup(λ, n, s1, |,Non-data,102
|   , sn): It first runs the CPESetup al- gorithm to output a master key pair (mpk, msk), then it randomly selects n bitstrings id1, |,Non-data,102
|   , idn with length (cid:96), (that is as an integer, each idi ∈ [2(cid:96) − 1]), and runs the CPEKeyGen algorithm to generate secret keys for the users|,Non-data,102
| For user i it assigns the identity idi and then generates the secret key ski =CPEKeyGen(msk, idi) It embeds the secret information of the user si as the ciphertext ωi = AEEnc(idi, si)|,Non-data,102
| The setup algorithm outputs public key mpk, secret keys sk1,    , skn, and the public parameter para, where para = (cid:104)ω1, |,Non-data,102
|   , ωn(cid:105) It runs CPE|,Non-data,102
|Enc(mpk, 2(cid:96), m) and re- • Enc(mpk, m): turns the corresponding output c as ciphertext • Dec(ski, c): This algorithm runs CPEDec with input ski and ciphertext c and returns m or ⊥ • RecB,D(mpk, para): The algorithm maintains a counter j with initial value (cid:96)− 1 and repeats the following pro- cedure until j = 0: It first samples a sequence of mes- sages m1, |,Non-data,102
|   , mN from D; then it generates the query ciphertexts c1,  |,Non-data,102
|  , cq, where ci =CPEEnc(mpk, p, mi) for the position p = 2j and records how many correct answers does the box B produce; If the number of cor- rect decryptions is more than n0, the algorithm will set the pivot for the next test position to be p := p− 2j−1, otherwise p := p + 2j−1; The algorithm then decreases the counter j := j − 1 and repeats the procedure The values for the parameters N, n0 will be determined in the analysis|,Non-data,102
| Suppose the above algorithm stops at po- sition p The Rec algorithm then runs AEDec(p, ωi) on all ωi and returns the first non-⊥ value si Remark: We may implement the authenticated encryption as SE|,Non-data,102
|Enc(k, s||||σ) where σ = Sig(s), where Sig is a signature scheme and the verification key is included in para where SEEnc is any secure symmetric key encryption scheme Analysis Correctness and privacy follow straightforwardly, so we focus on the intuition of the black-box traitor-deterring property|,Non-data,102
| Let us first present the following observations (1) If all the colluder identities are smaller than the index p used in the tracing ciphertext, the box will decrypt correctly with probability close to δ This holds because of the the attribute hiding property that CPE|,Non-data,102
|Enc(mpk, p, m) is indistinguish- able from the regular ciphertext CPEEnc(mpk, 2(cid:96), m) From this it can be deduced that failing to decrypt with proba- bility close to δ suggests that at least one colluder identity is larger than p, thus the algorithm will not err by moving to a larger pivot (2)|,Non-data,102
| Similarly, if all colluder identities are larger than the pivot index p used in the tracing ciphertext, the box will work with just negligible probability because of the payload hiding property It follows that decrypting with a probability close to δ (non-negligible) implies at least one colluder identities is smaller than the attribute in the tracing ciphertext, and hence the tracing algorithm will not err by moving to a smaller position attribute (see lemmas in the appendix) The above observations imply that every move is towards a subspace containing some pirate identities|,Non-data,102
| To be a bit more formal, consider a complete binary tree which represents the whole identity space We can think of 237the path walked by the Rec algorithm as moving along such tree It starts from the root (represented by index 2(cid:96)−1) and moves to the root of a complete subtree in each step We will show via strong induction that in each move, the subtree will contain at least one colluding identity|,Non-data,102
| Theorem 41 Construction-II satisfies fully collusion re- silient, black-box traitor deterring property wrt|,Non-data,102
| to any message distribution D with min-entropy H∞(D) ≥ − log(δ− α) for some non-negligible α, st, δ ≥ 15α where δ is the correctness probability provided by the adversarial device, and the parameters N = α−2log2 λ, n0 = (δ − α 2 )N |,Non-data,102
| Proof Correctness follows directly from the correctness of the underlying CPE scheme Privacy is also straightfor- ward, as the user identity is uniformly sampled, the IND- CPA security of the underlying encryption scheme guaran- tees no information about the plaintext is leaked Regarding the traitor-deterring property: Suppose a pi- rate box B is created using secret keys of the users id1, |,Non-data,102
|   , idt, and it is with δ−correctness wr|,Non-data,102
|t a message distribution D, st, H∞(D) ≥ − log δ0, where δ0 = δ − α, for some α We first present three lemmas that follow easily from the pay- load hiding and attribute hiding properties of CPE|,Non-data,102
| Lemma 42 If the underlying CFE is payload hiding, and the tracing ciphertext C is created using a pivot p and mes- sage m randomly sampled from D, and idi > p for all i = 1,   |,Non-data,102
| , t, then: || Pr[B(C) = m] − δ0|| = negl(λ) Lemma 43 If the underlying CFE is attribute hiding, and two tracing ciphertexts C1, C2 are created using message m, and pivots p1, p2 respectively, and for all i = 1,  |,Non-data,102
|  , t, idi (cid:54)∈ [p1, p2), then: || Pr[B(C1) = m]− Pr[B(C2) = m]|| = negl(λ) Lemma 44 If the underlying CFE is attribute hiding, the tracing ciphertext C is created using a message m randomly sampled from D and a pivot p, and idi ≤ p for i = 1, |,Non-data,102
|   , t, then || Pr[B(C) = m] − δ|| = negl(λ) when X = (cid:80) Xi, {Xi} are independent random variables We then estimate the parameters n0, N for determining whether B works|,Non-data,102
| Following the Chernoff bounds, Pr[X < (1 − ω)μ] ≤ e−ω2μ/2, and Pr[X > (1 + ω)μ] ≤ e−ω2μ/3, over {0, 1}, 0 < ω < 1, and μ = E(X) In this setting, Xi is the event denoting when Rec feeds the i−th ciphertext which encrypts a random message m sampled from D, the box B returns the plaintext correctly It follows that, if the traitor indices are all smaller than the pivot, B works with δ-correctness, Pr[Xi = 1] ≥ δ After repeating N times, the probability that at most n0 = (δ − α 2 )N correct answers are returned by B is bounded by e−α2N/8|,Non-data,102
| On the other hand, if the traitor indices are all larger than the pivot, B works with only probability δ − α The probability that B returns more than n0 correct answers is bounded by e−α2N/12 Setting parameters N = α−2log2 λ, n0 = (δ − α 2 )N , less than n0 correct answers means that there must be a traitor index larger than the pivot; more than n0 correct answers means there must be a traitor index smaller than the pivot Now we are ready to proceed to prove the theorem|,Non-data,102
| We can represent all users as leaves in a complete binary tree indexed by {1,    , 2(cid:96)}; given this Rec moves a pivot per- forming a binary search in this tree by selecting a sequence of subtrees S0, S1, |,Non-data,102
|   in the following fashion: at move j ≥ 1, the pivot pj defines the subtree Sj−1 as the subtree of the complete binary tree that is rooted at a node v that has pj as the index of the rightmost leaf of the left subtree of Sj−1 Observe that S0 is the whole tree|,Non-data,102
| We will prove by strong induction that for all j ≥ 0, Sj contains a traitor The base, j = 0, is straightforward Suppose that the statement is true for S0, S1,  |,Non-data,102
|  , Sj−1 We will prove for Sj Case 1|,Non-data,102
| Suppose that Sj is a left subtree of Sj−1 This means that there is a traitor with index at most pj (oth- erwise, if all traitors had a bigger index, then by lemma 42 the pirate box would be unsuccessful and the recovering algorithm would move to the right subtree of Sj−1) Now suppose that none of the traitors belong to Sj and let u be the largest index of a traitor that has index at most pj|,Non-data,102
| By the fact that u does not belong to Sj we know that at least one of the subtrees S1,    , Sj−1 is a right subtree of its containing parent subtree|,Non-data,102
| Let Sk be such a subtree with the largest k ≤ j − 1 Now note that when the recovering algorithm used pivot pk (which lies in the center of subtree Sk−1) it holds that: u ≤ pk Observe that there is no traitor with index in the set {pk + 1,  |,Non-data,102
|  , pj} Based on lemma 43 the decision of Rec when testing with pivot pj and pivot pk should be the same (with overwhelming probability)|,Non-data,102
| This leads to a contradiction as Rec moved to the right (resp left) when testing with index pk (resp pj) Similarly, we can argue for the case that Sj is a right subtree of Sj−1|,Non-data,102
 We can conclude that S(cid:96) is a single leaf node and it also denotes a traitor 42 Instantiations of CPE Next we will give concrete constructions of CPE support- ing an exponentially large attribute space,Non-data,102
| We first note that, a straightforward instantiation can be obtained from general functional encryption (FE) which can be constructed using indistinguishability obfuscation (iO) [13] The result- ing TDS will have only a constant size ciphertext however it will rely on assumptions related to multilinear maps [13] We now present an instantiation from standard assump- tions Note that there exists a bounded collusion FE from standard assumptions|,Non-data,102
 In a TDS there is only a potentially small (and in any case polynomially bounded) subset of users that is colluding to produce a pirate box We show how to construct a CPE from bounded collusion FE Instantiation-I General FE secure for a single key query with succinct ciphertext was constructed in [14],Non-data,102
| To am- plify [14] to a q-query secure FE, one simply runs q indepen- dent 1-query secure FE schemes in parallel Each secret key is generated using a different master secret key (this step will require that the authority maintains and updates a private state to keep track of which master secret keys have been used), while each master public key will be used to encrypt the message resulting in a vector of q ciphertexts encrypting the same message Unfortunately using this scheme to in- stantiate the CPE for a TDS would force q = n To see this, even if we choose q = n − 1, there exist a pair of users i, j such that their secret keys are generated using a same mas- ter secret key (say the k-th master secret key)|,Non-data,102
| When user i, j are corrupted together, no security can be guaranteed for the k-th 1-query secure FE instance, and the CPE scheme cannot be shown secure Thus the resulting TDS will have ciphertext size O(n · poly(λ)) which is not preferable espe- cially given that the collusion t might be much smaller than n We then show how to improve the ciphertext complexity Instantiation-II|,Non-data,102
| A stateless q bounded FE was constructed in [15] from a 1-query secure FE using techniques from se- 238ij =i1 cure computation, and their scheme guarantees security un- der arbitrary collusion with size q, even if more keys are issued (say n) We can use such a t-bounded FE to instan- tiate a CPE facing t corrupted users Unfortunately, the parameters in [15] were chosen in a way that the ciphertext size is as big as O(D2t6λτ ), where D is the maximum de- gree of the polynomial representing the circuits describing the functions that FE supports, and τ is the ciphertext size of the underlying 1-query secure FE For some parameters d, N , in the construction, there are N 1-query secure FE in- stances|,Non-data,102
| The encryption algorithm will do a (d+1, N ) secret sharing on the message and will encrypt each share indepen- dently under the N 1-query FE instances Each user will be assigned a random subset (denoted by Γi, and ||Γi|| = dD+1) of keys each of which is generated using the corresponding master secret key Note that prior to encrypting each share is padded with additional randomness to ensure the simu- lation can succeed In total there are N ciphertexts each encrypting O(t2λ) plaintext elements|,Non-data,102
| (See [15] for details) Reference [15] requires that the collusion of size t can not break enough 1-query secure FE instances to get d+1 shares and obtain extra information about the message More specifically, it requires ||∪i(cid:54)=j(Γi∩Γj)|| ≤ d We observe that if we can replace this condition to be ||∪i1,|,Non-data,102
|,ia (∩ia Γij )|| ≤ d, for any integer a ≥ 2, through a probabilistic analysis, we can bring down N to O((Dt)1+eλ) (for e = 1/(a − 1)) Do- ing this optimization requires us to use an a-query secure FE as the underlying building block|,Non-data,102
 We can obtain a succinct a-query secure FE for some polynomially bounded a by ap- plying the technique of [15] to the succinct 1-query secure FE of [14] In this way we obtain a a-query FE that has ciphertext size O(poly(λ)) which is independent from the number of users Then we can apply the extended proba- bilistic analysis explained above and to obtain a t-query FE with ciphertext O(t3+epoly(λ)) Note that we are using cir- cuits for the comparison predicate only and thus the degree D of the polynomial representing the circuits is at most λ,Non-data,102
| Our CPE instantiation Our final CPE instantiation will be a hybrid of the two instantiations above When t ≤ 1 3+e , we use instantiation-II, the optimized t-FE; when t > n 1 3+e , we simply use instantiation-I of n-query secure FE n The resulting TDS will be with ciphertext size min[O(t3+e · poly(λ)), O(n · poly(λ))]|,Non-data,102
| As the succinct 1-query FE can be built on fully homomorphic encryption [6] and attribute based encryption [16], both of which can be based on the LWE assumption [29] efficiently We summarize the above, and refer detailed analysis to the appendix Corollary 45 Under the subexponential LWE assumption, there exists a TDS satisfying: fully collusion resilient, black- box traitor deterring w|,Non-data,102
|rt to any message distribution D with H∞(D) ≥ − log(δ− α) for some non-negligible α, where δ is the correctness probability provided by the pirate box and δ ≥ 15α, and the parameters N = α−2log2 λ, n0 = (δ − α 2 )N  It has ciphertext length min[O(t3+e · poly(λ)), O(n· poly(λ))], where n, t are total number of users and corrupted users, e = 1/poly(λ), and λ the security parameter|,Non-data,102
| 5 TRAITOR DETERRING IN THE KNOWN CIPHERTEXT MODEL In the known ciphertext model for TDS, the adversary has a weaker goal: it aims to produce a pirate box that works wrt|,Non-data,102
| a given sequence of ciphertexts Because the sequence of ciphertexts is fixed there is a triv- ial way to implement the pirate decoder: simply store a database of all the plaintexts Thus, in the known cipher- text model, the adversary should only win when the size of the decoder is smaller than the trivial attack; formally, we will associate an attack in this model with a “space rate” that is equal to the size of the pirate box divided by the length of the total plaintext contained in the known cipher- text An ideally secure scheme should work with respect to any space rate o(1)|,Non-data,102
| The known ciphertext model is applicable to the setting of distributing content via CDs, or granting access to an encrypted database, since in these cases, the attack occurs after the target ciphertexts become known (In contrast, the original traitor deterring model is applicable to all other set- tings, eg, online streaming, and movie distribution in Pay- TV etc|,Non-data,102
) Traitor deterring in the known ciphertext model reformulates in the black-box public-key setting the prob- lem of constructing digital signets as posed in [12] In [12] a construction for any space rate o(1) is presented however it requires the unfalsifiable assumption that the function f (x) = gx is incompressible (as well as they assume non-black-box recoverability) They leave as open question whether a construction exists that is secure under a falsifiable assumption; using our TDS’s we resolve this open question in this section,Non-data,102
| 51 Definition: the known ciphertext model 2||||  |,Non-data,102
| ||||gx 1||||gx (cid:96) We provide the formal definition of the known ciphertext model that strengthens our traitor deterring definition (1 − )-correctness Since the pirate box B may work only for the fixed set of ciphertext SC = {c1, |,Non-data,102
|   , cn}, we require for SC, it almost always works, ie|,Non-data,102
|, Pr[B(i, ci) = mi] ≥ 1− negl(λ), where mi is the Θ(λ) bit plaintext that is encrypted in ci (note we also allow B to receive the index of ci) Privacy: This is the same as in section 2 Traitor Deterring for Known Ciphertexts The main differ- ence with the traitor deterring property is that the adversary is aware of the ciphertexts before making the device B, and hence can embed some information into B so that B is able to check the decryption queries and only works for the given ciphertexts|,Non-data,102
| Formally, • The challenger C simulates the Setup algorithm and the adversary A receives pk A then sends to C a vec- tor of secret information s1,   |,Non-data,102
| , sn, an arbitrary subset T ⊆ {1,    , n} as well as a distribution Pk with sup- port set that contains k-long vectors of plaintexts for some k = O(poly(λ))|,Non-data,102
| 3 A receives the secret keys of all users in T , {ski || i ∈ T} as well as the public parameter para • C samples (m1,   |,Non-data,102
| , mk) from Pk and sends A, the se- quence of ciphertexts SC = (cid:104)c1,    , ck(cid:105) where ci = Enc(pk, mi); finally, A outputs an implementation B|,Non-data,102
| • C outputs 1 if and only if RecB(pk, para) (cid:54)∈ {si1 ,    , sit}|,Non-data,102
| A We denote the event that C outputs 1 in the above game by (1λ) We say a scheme achieves black-box traitor SuccKCdeter deterring for known ciphertexts with space rate s(k, λ) if for any PPT adversary A, 3This includes the case of encrypting one single long message (eg, a movie file): it is first divided into k blocks and each block is encrypted individually|,Non-data,102
| 239A (1λ)] kλ Pr[B is (1 − )-correct wrt SC∧||B|| ≤ s(k, λ)∧SuccKCdeter is a negligible function on λ, where ||B|| denotes the size of the program B Note that for s(k, λ) = Θ(1) it is trivial to construct a device B that allows the adversary to win the above game — simply store all plaintexts m1, |,Non-data,102
|   , mk in B Thus, the question that is raised is whether it is possible to deter with space rate that is o(1)|,Non-data,102
| 52 Feasibility and infeasibility for the known ciphertext model At first sight, it may seem impossible to have a black- box recovering algorithm in the known ciphertext setting, since the Rec algorithm is restricted by the fact that the adversarial box is only guaranteed to work for a fixed set of ciphertexts Indeed, although the size of B can be smaller than the size of the ciphertexts it is supposed to work for, there are ways for the adversary to embed some information and check whether a submitted ciphertext belongs to the targeted sequence, while reject all other ciphertexts submit- ted to it|,Non-data,102
| We formalize this intuition and we show a simple attack following this principle that rules out the possibility of black-box traitor deterring for known ciphertexts for a range of space rates However, we also observe that in order for the box B to perform a membership test in the tar- geted ciphertext sequence, the false positive probability of the testing algorithm increases as the storage used by B gets smaller When the false positive probability becomes suffi- ciently high, a random sample of ciphertext will be answered by the box B with non-negligible probability δ, and thus B becomes a δ−correct box in the regular model (as defined section 2); in this way, we can still apply our constructions of TDS’s against known ciphertext type of attacks For ease of presentation, we consider only the 1-correct case, while all results will also follow for the case of (1 − )-correctness|,Non-data,102
| The intuition behind the proof of the following theorem is that when the suitable space bound is imposed on the pi- rate device, it will have to resort to using the secret-key in a sufficiently large plaintext distribution that can be sampled with a non-negligible probability from the plaintext space As a result, the decryption box, is a general purpose decryp- tion box that is δ-correct for some non-negligible δ and thus our recoverability algorithms developed for traitor deterring can be applied in the known ciphertext model as well Theorem 51 There exists a TDS with superpolynomial in λ plaintext space that satisfies black-box traitor deterring for known ciphertexts with space rate s(k, λ) = O(log(λ)/λ) = o(1) for any k = Ω(λ)|,Non-data,102
| Proof We will show that a TDS satisfying black-box traitor deterring with any pirate box with λ−c-correctness is also a TDS with black-box traitor deterring in the known ciphertext model for any c ∈ N for the stated space rate First, we recall a lower bound of the false positive proba- bility in the approximate membership testing problem (see definition A1 in the appendix) fwhen the space of the tester is upper bounded|,Non-data,102
| For a universe U with size u, and V ⊂ U with size v, and v (cid:28) u, using space τ , the false positive η of any membership tester satisfies 2τ ≤ (2η)v (see Lemma A2 in the appendix)Applying logarithm to both sides, we v −1, thus if τ ≤ c· v · log λ, we have η ≥ λ−c|,Non-data,102
| can get η ≥ 2− τ Next, we will use the above result to show that a useful de- cryption box B with size O(k· log λ) will have non-negligible correctness wrt uniform distribution over the message space|,Non-data,102
| Specifically, we will build an approximate member- ship tester T (using B) for V = {(m1, c1),    , (mk, ck)}, a subset of the universe U of all plaintext/ciphertext pairs, with a similar storage as follows|,Non-data,102
| Whenever queried a uni- formly random pair (m, c), T queries B with c, if B outputs m, T outputs 1, otherwise T outputs 0 It is easy to see that if (m, c) ∈ V , T always accepts; if (m, c) (cid:54)∈ V , T accepts with probability δ, where δ = Pr[B(c) = m ∧ (m, c) (cid:54)∈ V ] Furthermore, T only needs an extra storage of O(λ) bits to store the query and compare whether the answer of B is valid In the setting that k = Ω(λ), the storage of T is still O(k · log(λ))|,Non-data,102
| Observe that if δ is negligible, T is a membership tester which violates the bound in Lemma A2 With the above claim, we can see that for a randomly sampled ciphertext, the box B will answer with some prob- ability δ and thus we can run the Rec algorithm and retrieve the corresponding secret information of one of the colluders assuming that the TDS works for δ wr|,Non-data,102
|t any distribution D for which it holds that δ ≥ 2−H∞(D) + α where α is an arbitrary non-negligible function Impossibility results Next we will show that the above bound of the size of B is essentially tight, by describing a generic attack against any traitor deterring scheme for known ciphertexts The attacking strategy is simple: using Bloom filters [1] the adversary produces a box that contains a membership tester built in so that it will answer only when the decryption query belongs to the ciphertext set|,Non-data,102
| This makes two boxes implemented using different keys indistin- guishable via only oracle access, thus black-box recoverabil- ity will contradict privacy in this setting For details of the proof we refer to the appendix Proposition 52 There does not exist any, even 1-resilient, black-box TDS in the known ciphertext model for space rate s(k, λ) = Ω(log2 λ/λ) for any k|,Non-data,102
 6 USING BITCOIN AS COLLATERAL Bitcoin is a decentralized cryptocurrency [25] that uses a publicly maintained ledger to store transactions and record transfers between bitcoin accounts Each bitcoin account is essentially a hash of a public-key and the owner of the secret-key has the ability to transfer funds from the account by posting a transaction in the bitcoin network that con- tains a signature generated by the account’s secret-key The characteristic of bitcoin accounts is that the secret-keys rep- resent complete ownership of the account,Non-data,102
| We consider a TDS deployment for a broadcast service where a service provider (SP) wants to use a certain amount of bitcoin as collateral Upon initiation of the service the SP generates bitcoin accounts corresponding to each of the n users setting si = (ai, ki) where ai is the bitcoin address and ki is the associated secret-key When a user joins the system it requests from the user to transfer some amount of x bitcoin to the ai bitcoin account The SP shares the account information (ai, ki) with the user so that it is en- sured that the x bitcoin is a collateral and the user has the option to obtain the collateral back whenever she wishes (and cancel her subscription)|,Non-data,102
| The SP then embeds si into the public directory At the same time the SP gives to the user the secret-key ski that corresponds to the account, and sets a service agreement that the account should be “frozen” such that no outgoing transaction is allowed until the user 240unsubscribes the service The user from this point on can use the service and decrypt ciphertexts associated with the service In regular intervals the SP checks the public ledger to see whether any active account has an outgoing transac- tion (no matter to who is transferred)|,Non-data,102
| If there is such a case the subscription of the user should be cancelled (this would require the revocation of the key ski an issue that we do not explicitly deal here but can be handled generically via eg, a re-key operation where the SP at regular intervals refreshes the keys of the system keeping the same collaterals for all the remaining subscribers) Observe that due to the properties of TDS for as long as the user respects the service agreement and does not share her secret-key her collateral bitcoin remain safe|,Non-data,102
| The user can collect her collateral bit- coin whenever she wants to terminate the service 7 CONCLUSION AND OPEN PROBLEMS We formalize and construct the new cryptographic prim- itive of TDS that achieves proactive deterrence of unautho- rized device distribution and we show how bitcoin can be used as a collateral for a TDS deploymentWe also revisit the open problem of digital signets and reformulate as TDS in the known ciphertext model, and show how we can uti- lize TDS to solve it under parameter choices that allow a possibility result|,Non-data,102
| There are many interesting open problems that remain The first one is how to construct a TDS with constant size ciphertext under standard assumptions This may require a fuzzy locker for, eg|,Non-data,102
|, Tardos code [31] which currently uses a secret tracing algorithm Also, a construction of unbounded collusion secure CPE is another alternative which will be of independent interest Furthermore, combining a TDS with a revocation system as in [27] to obtain a “Trace Deterring and Revoke scheme” would be an important advance Acknowledgements This work was supported by Euro- pean Research Council Project CODAMODA|,Non-data,102
|ABSTRACT In this paper, we initiate a formal study of transparency, which in recent years has become an increasingly critical requirement for the systems in which people place trust We present the abstract concept of a transparency overlay, which can be used in conjunction with any system to give it provable transparency guarantees, and then apply the over- lay to two settings: Certificate Transparency and Bitcoin In the latter setting, we show that the usage of our trans- parency overlay eliminates the need to engage in mining and allows users to store a single small value rather than the entire blockchain Our transparency overlay is generically constructed from a signature scheme and a new primitive we call a dynamic list commitment, which in practice can be instantiated using a collision-resistant hash function|,Non-data,103
| 1 INTRODUCTION In the past decade, the trust that society places in cen- tralized mechanisms run by government, network operators, and financial institutions has been eroding, with various in- cidents demonstrating that high integrity cannot be achieved solely through trust in one or a handful of parties As a re- action to this erosion in trust, two alternative architectures have emerged: users have either taken matters into their own hands and flocked to systems that have no central point of trust, or they have increased pressure on central entities to provide more openness and accountability A prominent example of a system with no central point of trust is Bitcoin [28], which was deployed in January 2009|,Non-data,103
| Bitcoin is a monetary system that is not backed by any government and is managed through a consensus mecha- nism over a peer-to-peer network; there is thus no single entity that issues bitcoins or validates individual transac- tions, and users of Bitcoin operate using pseudonyms that are not inherently tied to their real-world identity Bitcoin has achieved staggering success: as of this writing, its mar- ket capitalization is over 8 billion USD and its underlying structure has inspired hundreds of alternative cryptocurren- Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page Copyrights for components of this work owned by others than the author(s) must be honored Abstracting with credit is permitted|,Non-data,103
| To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acmorg CCS ’16, October 24–28, 2016, Vienna, Austria|,Non-data,103
 c(cid:13) 2016 Copyright held by the owner/author(s) Publication rights licensed to ACM ISBN 978-1-4503-4139-4/16/10 ,Non-data,103
  $1500 DOI: http://dxdoi,Non-data,103
|org/101145/29767492978404 cies; payment gateways such as Bitpay and Coinbase allow thousands of vendors to accept it; a number of governments have taken steps to legitimize Bitcoin via interfaces with traditional financial and regulatory infrastructures; and ma- jor financial institutions such as JPMorgan Chase [30] and Nasdaq [29] have announced plans to develop Bitcoin-based technologies Bitcoin and its variants have achieved a large degree of success, but denying all forms of central authority arguably limits their ability to achieve widespread adoption|,Non-data,103
| Thus, technological solutions have emerged that instead seek to provide more visibility into currently centralized systems One key example of such a system is Certificate Trans- parency (CT) [21], which addresses shortcomings with SSL certificate authorities (CAs) — which have ranged from fail- ing to verify the identity of even major website owners such as Google before issuing a cryptographic certificate [10, 19] to suffering major hacks [25] that result in hundreds of forged certificates being issued [22] — and empowers users to ver- ify for themselves the correct functioning of a system with which they interact many times a day (eg, any time they log in to a secure website, such as their email provider)|,Non-data,103
| Un- like Bitcoin’s approach, CT does not substantially alter the underlying infrastructure (ie, the issuance of a certificate is largely unchanged), but instead provides a way for anyone to monitor and audit the activities of CAs to ensure that bad certificates can be detected quickly, and misbehaving authorities identified and excluded While Bitcoin and Certificate Transparency provide solu- tions in different settings, they in fact share some common features; most notably, they rely on transparency as a means to achieve integrity|,Non-data,103
| In Bitcoin, the ledger of transactions — called the blockchain — is completely transparent, meaning all Bitcoin transactions are globally visible A similar prop- erty is provided in Certificate Transparency, in which a dis- tributed set of servers each maintain a globally visible log of all the issued certificates of which they are aware Furthermore, both Bitcoin and CT adopt a distributed so- lution, which is essential to avoid placing trust in any single entity Indeed, relying on one party creates (at worst) a sys- tem in which this central party has unilateral control over the information that is released, or (at best) a system with one central point of failure on which attackers could target their efforts|,Non-data,103
| By using a solution that is both transparent and distributed, these systems intuitively provide some no- tion of public auditability: individual users can check for themselves that only “good” events have taken place (eg, in the case of Bitcoin, that all bitcoins have been spent at 168most once) and detect misbehavior on the part of all actors within the system Understanding the link between trans- parency and the types of misbehavior that can be detected across a variety of settings is one of the main motivations behind this work|,Non-data,103
| 11 Our contributions Systems such as Bitcoin and CT seem to provide impor- tant transparency benefits (namely, the public auditability mentioned above), but the similarities and differences be- tween their benefits are not well understood, and no formal analysis has demonstrated either the level of transparency that they provide or how this transparency provides the in- tended benefits In this paper, we initiate such a formal study|,Non-data,103
| In doing so, we seek to not only compare the dif- ferent guarantees provided by these systems (although our analysis does accomplish this), but more importantly to cre- ate an abstract transparency overlay that may be used to provide these guarantees in a variety of applications beyond financial transactions and certificate issuance Before we can analyze these protocols or construct a trans- parency overlay, we must first consider the crucial compo- nents that make up these systems Our first step is thus to formalize — in Section 32 — a primitive that we call a dynamic list commitment (DLC); a DLC can be thought of as a generalization of a rolling hash chain or hash tree, and serves as the foundation for our construction of a trans- parency overlay|,Non-data,103
| After defining this underlying primitive, we then go on to present transparency overlays in Section 4; here our design is heavily inspired by the design of CT We begin with a formal model for transparency overlays, and then go on to present an abstract transparency overlay and prove its security Armed with this abstract secure transparency overlay, we go on in Section 5 to demonstrate that CT is a secure trans- parency overlay We also demonstrate that our formal no- tion of security implies more intuitive notions of security in this setting (i|,Non-data,103
|e, that users should accept only “good” cer- tificates) and discuss some practical considerations In Section 6, we continue by turning our attention to the Bitcoin protocol Here, we do not use the protocol directly (as we argue that it clearly cannot satisfy our notions of se- curity), but rather plug crucial components of the protocol into our abstract transparency overlay|,Non-data,103
| While this allows us to achieve a provably secure transparency overlay for Bit- coin, it more importantly also implies that “regular” Bitcoin users (ie, users interested only in transacting in bitcoin, rather than engaging in the mining process) can operate significantly more efficiently, provided they are willing to outsource some trust to a distributed set of parties This result demonstrates that, in any setting in which users are willing to trust any distributed set of parties, the full de- centralization of Bitcoin is not needed, and the same goals can in fact be accomplished by a CT-like structure, in which regular users store significantly less information about the transaction ledger and the mining process is superfluous; i|,Non-data,103
|e, the quadrillion hashes per second expended on Bitcoin mining (as of March 2016) can be eliminated without sacri- ficing security Our formal analysis thus reveals the fine line separating fully decentralized (and expensive) solutions like Bitcoin from distributed (and relatively cheap) solutions like CT, and we hope that our results can help to inform future decisions about which protocol to adopt 1|,Non-data,103
|2 Related work We consider research that is related both in terms of the applications of Bitcoin and Certificate Transparency, and in terms of the underlying primitives used to construct our transparency overlay An emerging line of work has both formalized some of the properties provided by the Bitcoin network and boot- strapped Bitcoin to obtain provably secure guarantees in other settings Garay et al|,Non-data,103
| [17] analyzed the so-called “back- bone” protocol of Bitcoin and prove that it satisfies two im- portant properties as long as the adversary controls some non-majority percentage of the hashing power Similarly, Bentov and Kumaresan [8] provided a two-party compu- tation built on top of (an abstracted version of) Bitcoin that provably achieves a notion of fairness, and Andrychow- icz et al [3] used Bitcoin to build a provably fair system for multi-party computation Andrychowicz and Dziem- bowski [2] further formalized some of the fairness proper- ties they require from Bitcoin (and more generally from sys- tems based on proof-of-work) and used them to construct a broadcast protocol|,Non-data,103
| Finally, on the privacy side, the Zero- cash project [6] provides a cryptocurrency that has provable anonymity guarantees, and Garman et al [18] showed how to adapt the decentralized approach of Bitcoin to achieve anonymous credentials To the best of our knowledge, ours is the first paper to focus on the transparency property of Bitcoin, rather than its privacy or fairness guarantees Aside from CT, a number of other solutions exist for changing the way we interact with certificate authorities; many of these solutions require a ground-up redesign of the CA ecosystem, which is why we chose to examine CT in- stead and use it as our inspiration for an overlay system|,Non-data,103
| Fromknecht et al [16] propose a decentralized PKI, based on Bitcoin and Namecoin, that eliminates the trust in cen- tralized authorities altogether CONIKS [24] provides an approach to logging certificates that differs from CT in two key ways: it focuses on user rather than website certificates, and largely because of this it provides a privacy-preserving solution, in which certain aspects of the stored certificates (eg|,Non-data,103
|, usernames) are kept hidden The Accountable Key Infrastructure [20] and the related ARPKI [4] both require a distributed infrastructure for not only the storage of is- sued certificates (as CT does), but also for their issuance, thus focusing on the prevention rather than just detection of misbehavior Ryan [33] demonstrated how to extend CT to handle revocation of certificates In a concurrent work, Dowling et al|,Non-data,103
| [15] provided a different security model for CT and demonstrated that if various properties of the underly- ing Merkle trees are satisfied then CT is provably secure in their model Although somewhat overlapping with our own work, their paper is focused firmly on CT and not on the abstract properties of transparency overlays and how they can be applied across a variety of settings Finally, the main primitive underlying our transparency overlay (a dynamic list commitment) is primarily a general- ization of a Merkle tree [26], and is similar to the definition of a tamper-evident log given by Crosby and Wallach [13] It is also related to the notion of an authenticated data structure (ADS) [1, 32, 31] and the notion of a cryptographic accu- mulator [7, 12, 11, 23]; indeed the application of ADSs to Bitcoin has already been touched on in previous work [27] (but from the perspective of programming languages, and thus without any consideration of security)|,Non-data,103
| Dynamic list 169(a) Certificate issuance (b) Bitcoin Figure 1: The basic structure for each of the settings in which we apply transparency commitments differ from these related primitives in terms of the security model, however, and as a result we can provide more efficient constructions while still satisfying a notion of provable security|,Non-data,103
| 2 BACKGROUND 21 Certificate Transparency Certificate Transparency (CT) was proposed in 2011 by Ben Laurie and Adam Langley as a way to increase trans- parency in the process of issuing certificates, so that cer- tificate authorities (CAs) can be held responsible for their actions and bad certificates can be caught and revoked early on The basic process of issuing certificates operates as de- picted in Figure 1a: a CA issues a certificate to a website operator, who then publishes this certificate so that users can check it|,Non-data,103
| Certificate Transparency then provides an ex- tra layer on top of this basic interaction to provide trans- parency; in fact, as we will see in Section 4, our design of a transparency overlay is heavily inspired by the CT design Briefly, CT introduces three additional actors: a log server, who is responsible for keeping track of issued certificates, an auditor, who is responsible (on behalf of the client) for keeping track of whether given certificates are in the log or not, and a monitor, who is responsible for checking the quality of the certificates in the log As we use these addi- tional actors in our general transparency overlay, we defer further discussion of their roles and actions to Section 41|,Non-data,103
| In Section 5, we prove that CT provides a provably secure transparency overlay, thus (provably) providing the intuitive security properties that one would hope to achieve 22 Bitcoin Bitcoin is a decentralized cryptocurrency that was intro- duced in 2008 [28] and deployed on January 3 2009 We briefly sketch the main properties of Bitcoin and its under- lying blockchain technology here, and refer the reader to Bonneau et al|,Non-data,103
| [9] for a more comprehensive overview Briefly, Bitcoin operates as depicted in Figure 1b A sender, identified using a pseudonym or address, has some number of bitcoins stored with this address; ie|,Non-data,103
|, within the Bitcoin network, this address is acknowledged as the owner of these bitcoins To transfer ownership of these bitcoins to some receiver, the sender first creates a transaction to send them to the receiver, as identified by whichever address she has given to the sender The transaction is signed to ensure that only the sender can give away his own bitcoins After forming this transaction, the sender broadcasts it to the Bitcoin network, where it eventually reaches a miner, who acts to seal the transaction into a block|,Non-data,103
| The miner broadcasts this block, containing the transaction, to the network, where it eventually reaches the receiver, who can confirm the transaction and its position within the Bitcoin ledger (ie, the blockchain) to satisfy herself that she is now the owner of the bitcoins Because the Bitcoin blockchain is globally visible, it al- ready provides a degree of transparency that is higher than that of traditional financial transactions|,Non-data,103
| In Section 6, we apply a transparency overlay on top of Bitcoin and demon- strate that it provides a significantly more efficient way for Bitcoin users to participate in transactions and allows hash- ing to be eliminated from the system 3 DEFINITIONS AND NOTATION In this section, we define various notions that will be used throughout the rest of the paper In particular, we formal- ize dynamic list commitments in Section 3|,Non-data,103
|2, which can be thought of as a generalization of Merkle trees and allow us to construct high-integrity logs 31 Preliminaries If x is a binary string then ||x|| denotes its bit length If S is a finite set then ||S|| denotes its size and x r←− S denotes sampling a member uniformly from S and assigning it to x|,Non-data,103
 λ ∈ N denotes the security parameter and 1λ denotes its unary representation ε denotes the null value Algorithms are randomized unless explicitly noted other- wise “PT” stands for “polynomial-time,Non-data,103
|” By y ← A(x1,    , xn; R) we denote running algorithm A on inputs x1, |,Non-data,103
|   , xn and random coins R and assigning its output to y By y r←− A(x1, |,Non-data,103
|   , xn) we denote y ← A(x1,  |,Non-data,103
|  , xn; R) for coins R sampled uniformly at random By [A(x1,  |,Non-data,103
|  , xn)] we de- note the set of values that have positive probability of being output by A on inputs x1,   |,Non-data,103
| , xn Adversaries are algo- rithms For interactive protocols, we use the notation of Bellare and Keelveedhi [5] For completeness, we include the for- mal notion of defining and executing interactive protocols in the full version of the paper|,Non-data,103
| Briefly, the behavior of a stateful participant party that is given m during the i-th round of the j-th execution of a protocol Prot can be defined r←− Prot[party, i, j](1λ, stateparty, m), as (stateparty, m(cid:48), p, out) where p indicates the party to which it is sending m(cid:48); the execution of the entire interactive protocol can be defined by outputs r←− Run(1λ, Prot, Parties, inputs); and the message sent during the protocol (ie, the transcript) can be defined by M r←− Msgs(1λ, Prot, Parties, inputs) We use games in security definitions and proofs|,Non-data,103
| A game G has a main procedure whose output is the output of the game Pr[G] denotes the probability that this output is true 32 Dynamic list commitments We define a dynamic list commitment (DLC), which al- lows one to commit to a list of elements in such a way that (1) the list represented by the commitment can be updated only by having new elements appended to the end, and (2) given just the list commitment, one can efficiently prove both the append-only property of the list and that a given element is in the list|,Non-data,103
| One common example of a DLC is a hash tree, and in particular a Merkle tree, in which the root hash acts as the commitment and one can use the hashes of intermediate nodes to prove the above properties (Indeed, this is what CT uses) Our basic formalization is similar to the definition CAsiteusercertcertminersenderreceivertxtxblockCAsiteusercertcertminersenderreceivertxtxblock170of the following algorithms: of a tamper-evident history system [13], but we also include an augmented version that considers additional properties one can use when operating on ordered lists 3|,Non-data,103
|21 A basic formalization for general lists We define a dynamic list commitment DLC as a collection • c ← Com(list) creates the commitment c and 0/1 ← CheckCom(c, list) checks that c is a commitment to list; • cnew ← Append(list∆, cold) updates the commitment • π ← ProveAppend(cold, cnew, list) proves that cnew was obtained from cold solely by appending elements to an earlier version of list and 0/1 ← CheckAppend(cold, cnew, π) checks this proof; • π ← ProveIncl(c, elmt, list) proves that elmt is in list (as represented by c); and 0/1 ← CheckIncl(c, elmt, π) checks this proof We say that a DLC is compact if Com(list)|| (cid:28) ||list|| for all sufficiently long lists list|,Non-data,103
| Formal definitions of the basic security properties of a DLC can be found in the full version of the paper Informally, a DLC should be to take into account the new elements in list∆; 1 binding, which means that a commitment cannot rep- resent two different lists, so an adversary should be un- able to output a commitment c and two lists list1 and list2 such that c represents both lists (ie|,Non-data,103
|, CheckCom(c, list1) = CheckCom(c, list2) = 1) but they are not equal; 2 sound, which means that it should be hard to produce a proof of inclusion for an element not in the list, so an adversary should be unable to output a commitment c, list list, element elmt, and proof π such that c rep- resents list, CheckIncl(c, elmt, π) = 1, but elmt /∈ list; and 3 append-only, which means that it should be hard to produce a proof that a list has been only appended to, so an adversary should be unable to produce a list list2, two commitments c1 and c2, and a proof π such that c2 represents list2, CheckAppend(c1, c2, π) = 1, but c1 is not a commitment to any prefix of list2 3|,Non-data,103
|22 An augmented formalization for ordered lists It will also be useful for us to consider a special type of DLC, in which the elements in the list have some kind of or- der imposed on them In particular, this allows us to more efficiently perform two additional operations: demonstrate that two DLCs are inconsistent (i|,Non-data,103
|e, that they are commit- ments to strictly distinct or forking lists), and demonstrate that a given element is not in the list represented by a given commitment As we will see in our applications later on, these operations are crucial for providing evidence that cer- tain types of misbehavior have taken place In addition to the algorithms required for a basic DLC, we now require a notion of timing (which may not be the actual time, but rather any representation that allows us to for every element elmt in a list, we impose an ordering): assume there exists a function time(·) that returns a value t, and that a global ordering exists for this function, so that we can also define a Boolean function 0/1 ← isOrdered(list)|,Non-data,103
| Using this, we define a notion of consistency for DLCs as follows: Definition 31 A tuple (c, t, list) is consistent if c is a commitment to the state of list at time t Formally, we con- sider a function isConsistent such that isConsistent(c, t, list) = 1 if and only if there exists a j, 1 ≤ j ≤ len(list), such that (1) CheckCom(c, list[1 : j]) = 1, (2) time(list[j]) ≤ t, (3) j = len(list) or time(list[j + 1]) ≥ t), and (4) isOrdered(list)|,Non-data,103
| inconsistent with c(cid:48) at time t(cid:48) and We can now define four additional algorithms as follows: • π ← DemoInconsistent(list, c(cid:48), t(cid:48)) proves that list is • 0/1 ← CheckInconsistent(c(cid:48), t(cid:48), c, π) checks this proof; • π ← DemoNotIncl(list, elmt) proves that elmt is not • 0/1 ← CheckNotIncl(c, elmt, π) checks this proof Formal definitions of the augmented security properties can be found in the full version of the paper Informally, in the augmented setting a DLC should satisfy in the ordered list list; and 1 provable inconsistency, which means any inconsistent tuple should be demonstrably inconsistent, so an ad- versary should be unable to produce a tuple (c, t, list) such that the tuple is inconsistent but an honestly gen- erated proof of inconsistency fails verification; 2|,Non-data,103
| provable non-inclusion, which means it should be pos- sible to demonstrate that an element is not in a list, so an adversary should be unable to produce a list list and an element elmt such that elmt /∈ list but the honestly generated proof of non-inclusion fails verification; 3 unforgeable inconsistency, which means it should be impossible to demonstrate an inconsistency that does not exist, so an adversary should be unable to produce (c1, t, c2, list2, π) such that c2 represents list2, c1 is con- sistent with list2 at time t, and CheckInconsistent(c1, t, c2, π) = 1; and 4 unforgeable non-inclusion, which means it should be impossible to prove non-inclusion of an element that is in a list, so an adversary should be unable to produce (c, list, elmt, π) such that c represents list, elmt ∈ list, and CheckNotIncl(c, elmt, π) = 1 3|,Non-data,103
|23 Two instantiations of augmented DLCs To demonstrate that dynamic list commitments exist, we provide two instantiations; both can be found in the full ver- sion of the paper and derive their security from the collision resistance of a hash function Briefly, our first instantiation is essentially a rolling hash chain: new elements appended to the list are folded into the hash (i|,Non-data,103
|e, cnew ← H(cold(cid:107)elmtnew)), and proofs about (in)consistency and (non-)inclusion reveal selective parts of the list This first instantiation thus demon- strates the feasibility of dynamic list commitments (and is conceptually quite simple), but the proofs are linear in the size of the list, which is not particularly efficient Thus, our second instantiation is essentially a Merkle tree, which al- lows us to achieve proofs that are logarithmic in the size of the list|,Non-data,103
| 4 TRANSPARENCY OVERLAYS In this section, we present our main contributions First, in Sections 41 and 4|,Non-data,103
|2, we introduce both basic and aug- mented formal models for reasoning about transparency 171Then, in Sections 43 and 44 we present a generic trans- parency overlay and prove its security|,Non-data,103
| To instantiate this securely (as we do in Sections 5 and 6), one then need only provide a simple interface between the underlying system and the overlay 41 Basic overlays In order for a system to be made transparent, we must provide an efficient mechanism for checking that the system is running correctly Our setting overlays three additional parties on top of an existing system Sys: a log server LS, an auditor Auditor, and a monitor Monitor|,Non-data,103
| The role of the log server is to take certain events in the system’s operation and enter them into a publicly available log The role of the auditor is to check — crucially, without having to keep the entire contents of the log — that specific events are in the log Finally, the role of the monitor is to flag any problematic entries within the log Collectively then, the auditor and monitor act to hold actors within the system responsible for the creation of (potentially conflicting) events|,Non-data,103
| We assume that each of these parties is stateful: the log server maintains the log as state, so stateLS = log; the audi- tor maintains a snapshot (ie, some succinct representation of the current log) as state, so stateAu = snap; and the mon- itor maintains a snapshot, a list of bad events, and a list of all events, so stateMo = (snap, eventsbad, events) A transparency overlay then requires five interactive pro- tocols; these are defined abstractly as follows:1 GenEventSet is an interaction between the actor(s) in the system that produces the events to be logged|,Non-data,103
| The protocol is such that eventset r←− Run(1λ, GenEventSet, Sys, aux) Log is an interaction between one or more of the actors in the system and LS that is used to enter events into the r←− Run(1λ, Log, log The protocol is such that (b, ε) (Sys, LS), (eventset, ε)), where b indicates whether or not the system actor(s) believes the log server behaved hon- estly CheckEntry is an interaction between one or more of the actors in the system, Auditor, and LS that is used to check whether or not an event is in the log|,Non-data,103
| The protocol is such r←− Run(1λ, CheckEntry, (Sys, Auditor, LS), that (b, b(cid:48), ε) (event, ε, ε)), where b indicates whether or not the system actor(s) believes the event to be in the log and b(cid:48) indicates whether or not the auditor believes the log server behaved honestly in the interaction Inspect is an interaction between Monitor and LS that is used to allow the monitor to inspect the contents of the log and flag any suspicious entries The protocol is such that r←− Run(1λ, Inspect, (LS, Monitor), (ε, ε)), where b (b, ε) indicates whether or not the monitor believes the log server behaved honestly in the interaction Gossip is an interaction between Auditor and Monitor that is used to compare versions of the log and detect any inconsistencies|,Non-data,103
| If any misbehavior on behalf of the log server is found, then both parties are able to output evi- dence that this has taken place The protocol is such that 1In each protocol, we also allow the participants to output fail, which indicates that they believe they were given im- properly formatted inputs (evidence, evidence) (ε, ε)) r←− Run(1λ, Gossip, (Auditor, Monitor), We also require the following (non-interactive) algorithms: r←− GenLogID(1λ) is used to generate a public (pkLS, sk LS) and secret identifier for the log server; and 0/1 ← CheckEvidence(pkLS, evidence) is used to check if the evidence against the log server identified by pkLS is valid|,Non-data,103
| From a functionality standpoint, we would like the proto- cols to be correct, meaning all parties should be satisfied by honest interactions, and compactly auditable, meaning the size of a snapshot is much smaller than the size of the log We define security for a basic transparency overlay in terms of two properties: consistency, which says that a potentially dishonest log server cannot get away with pre- senting inconsistent versions of the log to the auditor and monitor, and non-frameability, which says that potentially dishonest auditors and monitors (and even actors in the orig- inal system) cannot blame the log server for misbehavior if it has behaved honestly Participants can thus be satisfied that they are seeing the same view of the log as all other participants, and that the interactions they have really are with the log server To formalize consistency, we consider a game in which the adversary takes on the role of the log server and is allowed to interact (via the MsgAu and MsgMo oracles, respectively) with the auditor and monitor|,Non-data,103
| The adversary wins if there is an event that is not in the list maintained by the monitor but that the auditor nevertheless perceives as being in the log (the third winning condition of Definition 41), yet the audi- tor and monitor are unable to produce valid evidence of this inconsistency (the first two winning conditions) For ease of formal exposition, we (1) assume that in the CheckEntry protocol the first message sent to the auditor is the event to be checked and the last message sent by the auditor is a bit indicating whether the event is in the log, and (2) require that the monitor must have a newer snapshot than the au- ditor, but can naturally extend our definition to cover other configurations as well Definition 4|,Non-data,103
|1 Define Advcons where GconsA (λ) is defined as follows: trans,A(λ) = Pr[GconsA (λ)], main GconsA (λ) events ← ∅; eventspass ← ∅ r←− AMsgAu,MsgMo(1λ) pkLS evidence r←− Run(1λ, Gossip, (Auditor, Monitor), (ε, ε)) return ((CheckEvidence(pkLS, evidence) = 0) ∧ (time(stateMo[snap]) ≥ time(stateAu[snap])) ∧ (eventspass \ stateMo[events] (cid:54)= ∅)) MsgAu(i, j, m) (stateAu, m(cid:48), p, out) r←− CheckEntry[Auditor, i, j](1λ, stateAu, m) if (i = 1) events[j] ← m if (out (cid:54)= ⊥) ∧ (m(cid:48) = 1) eventspass ← eventspass ∪ {events[j]} return m(cid:48) MsgMo(i, j, m) (stateMo, m(cid:48), p, out) r←− Inspect[Monitor, i, j](1λ, stateMo, m) return m(cid:48) 172Then the transparency overlay satisfies consistency if for all PT adversaries A there exists a negligible function ν(·) such that Advcons trans,A(λ) < ν(λ) Next, to formalize non-frameability, we consider an ad- versary that wants to frame an honest log server; ie|,Non-data,103
|, to produce evidence of its “misbehavior” In this case, we con- sider a game in which the adversary takes on the role of the auditor, monitor, and any actors in the system, and is al- lowed to interact (via the Msg oracle) with the honest log server The adversary wins if it is able to produce evidence that passes verification Definition 4|,Non-data,103
|2 Define Advframe (λ) is defined as follows: where GframeA trans,A(λ) = Pr[GframeA (λ)], (λ) main GframeA (pkLS, sk LS) r←− GenLogID(1λ) evidence r←− AMsg(1λ, pkLS) return CheckEvidence(pkLS, evidence) Msg(Prot, i, j, m) if (Prot /∈ {Log, CheckEntry, Inspect}) return ⊥ (stateLS, m(cid:48), p, out) r←− Prot[LS, i, j](1λ, stateLS, m) return m(cid:48) Then the transparency overlay satisfies non-frameability if for all PT adversaries A there exists a negligible function ν(·) such that Advframe trans,A(λ) < ν(λ) We then say that a basic transparency overlay is secure if it satisfies consistency and non-frameability Comparison with concurrent work|,Non-data,103
| With respect to the security model of Dowling et al [15], their model requires only that the monitor and auditor pro- duce evidence of misbehavior in the case where the log fails to include an event for which it has issued a receipt (which we consider in the next section) Our model, on the other hand, also produces evidence in the case where the log has given inconsistent views to the two parties; this type of ev- idence seems particularly valuable since this type of misbe- havior is only detected after the fact This difference allows them to present a simpler definition of non-frameability, as they do not have to worry about malicious monitors and auditors forging this type of evidence|,Non-data,103
| 42 Pledged overlays In the basic setting described, log servers can be held re- sponsible if they attempt to present different views of the log to the auditor and monitor If log servers simply fail to include events in the log in the first place, however, then there is currently no way to capture this type of misbehav- ior While in certain settings the log server could plausibly claim that it never received an event rather than ignoring it, if the log server issues promises or receipts to include events in the log then we can in fact enforce inclusion, or at least blame the log server if it fails to do so|,Non-data,103
| Formally, we capture this as an additional security prop- erty, accountability, which says that evidence can also be used to implicate log servers that promised to include events but then did not In the game (which we defer to the full version of the paper — included as supplemental material — due to the formal notational overhead), the adversary then takes on the role of the log server and is allowed to inter- act arbitrarily with the actor(s) in the system, auditor, and monitor It wins if there is an event that it has pledged to include but that the auditor and monitor do not believe to be in the log, yet the auditor and monitor are unable to produce evidence of this omission We then say that a pledged transparency overlay is secure if it satisfies consistency, non-frameability, and accountabil- ity|,Non-data,103
| 43 A generic pledged transparency overlay We now present a generic version of a pledged trans- parency overlay We begin by introducing algorithms for performing various operations in the overlay, and then de- scribe the interactive protocols from Section 41 in terms of these algorithms and the algorithms for a dynamic list com- mitment (DLC) and a signature scheme (KeyGen, Sign, Verify)|,Non-data,103
| For ease of exposition we assume that various objects (snap- shots, receipts, etc) contain only the fields necessary to make the protocol work, but could naturally extend our al- gorithms to cover more general configurations as well To start, an event set eventset contain (at least) a list of events events; a snapshot snap = (c, t, σ) contains a DLC, timing information, and an unforgeable signature; a receipt rcpt = (pk , t, σ) contains a public key, timing information, and an unforgeable signature; and a log log = (snap, events) contains a snapshot and a list of events We denote these subcomponents using bracket notation; e|,Non-data,103
|g, we use snap[c], or — where subscripts make it appropriately clear — use ci to denote snapi[c] To perform basic operations on these objects, we also in- troduce algorithms for forming and verifying snapshots and receipts, and for updating the log These are defined — with respect to a notion of timing t and a keypair (pk LS, sk LS) — as follows: FormSnap(c, t) return (c, t, Sign(sk LS, (c, t))) CheckSnap(snap) return Verify(pk LS, (snap[c], snap[t]), snap[σ]) FormRcpt(log, event) return (pk LS, t, Sign(sk LS, (t, event))) CheckRcpt(event, rcpt) return Verify(pk LS, (rcpt[t], event), rcpt[σ]) UpdateLog(log, events) events(cid:48) ← log[events](cid:107)events c(cid:48) ← Append(events, log[snap][c]) snap(cid:48) ← FormSnap(c(cid:48), t) return (snap(cid:48), events(cid:48)) Briefly, in the Log protocol (Figure 2), an event set is given as input to the actor(s) in the system; this is created by GenEventSet, which we describe for our individual ap- plications in Sections 5 and 6 but leave here as an abstract interaction|,Non-data,103
| This event set is sent to the log server, who first checks if it is well formed The log server then provides a receipt for every event in the set, and sends the receipts back to the system actor(s) If any of the receipts are in- valid, the system rejects the interaction, and otherwise it 173Sys(eventset) eventset LS(logLS) 1 2 3 4 5 6 if ∃(event, rcpt) st|,Non-data,103
| (CheckRcpt(event, rcpt) = 0) return 0 −→ rcpt if (isOrdered(eventset[events]) = 0) return fail if (time(eventset[events][1]) < time(log[events][max])) return fail rcpt r←− FormRcpt(event) ∀event ∈ eventset[events] logLS r←− UpdateLog(logLS, eventset[events]) return 1 return ε Figure 2: The Log protocol for pledged transparency overlays accepts Either way, the log server updates the log; in our protocol specification here, the log server updates the log immediately, but we discuss in Section 53 how this process can be batched and the promises of the log server altered accordingly|,Non-data,103
| Next, in the CheckEntry protocol (Figure 3), some actor in the system sends an event and a receipt to the auditor, who first checks that the receipt is valid If it is, then the auditor checks if the event already falls within its current purview; ie, if it falls within the log that the auditor al- ready knows about (according to its snapshot)|,Non-data,103
| If it does, then the auditor skips to asking the log server for a proof of inclusion of this event; if not, the auditor must update its snapshot and check that the new snapshot is consistent with the old one Once the auditor has the proof of inclusion (ei- ther after updating or not), it returns to the client whether or not the proof verifies; the client returns whatever it re- ceives from the auditor, and the auditor returns b = 0 if the protocol has failed in some way (ie, the updated snapshot was inconsistent with the old one) and b = 1 otherwise|,Non-data,103
| Next, in the Inspect protocol (Figure 4), the monitor sends its current snapshot to the log server, and the log server responds with all events that have been logged since then, along with an updated snapshot If this list of ap- pended events is valid (ie, ordered and consistent with the new snapshot), the monitor can update its records and look for any bad events in this new list|,Non-data,103
| It returns b = 1 if the protocol has gone smoothly; ie, if the new list and snapshot seem to have been formed appropriately Finally, in the Gossip protocol (Figure 5), the auditor and monitor begin by exchanging snapshots, and by en- suring that each snapshot is valid|,Non-data,103
| The monitor then at- tempts to demonstrate any inconsistencies between the two snapshots (ie, demonstrate that they represent forking or distinct logs) and — if any inconsistencies do exist — this is returned as evidence of the log server’s misbehavior To augment the protocol for pledged overlays, we include in Figure 5 a further optional interaction in which the audi- tor sends to the monitor all events for which the CheckEntry protocol failed, to see if they are being monitored; these are stored in a list eventsbad that is now part of the auditor’s state and updated in the CheckEntry protocol (line 15 of Figure 3)|,Non-data,103
| This allows the auditor and monitor to detect and provide evidence for the additional type of misbehavior in which the log server simply drops events from the log This means that the auditor and monitor can provide two types of evidence: evidence that the log server presented them with forked or distinct views of the log, or evidence that the log server reneged on the promise it gave in a re- ceipt We thus instantiate the algorithm CheckEvidence as follows: CheckEvidence(pk LS, evidence) if (evidence = ⊥) return 0 (snap1, snap2, (event, rcpt), π) ← evidence if (CheckSnap(snap1) = 0) return 0 if (CheckSnap(snap2) = 0) return 0 if ((event, rcpt) = (⊥,⊥)) return return (CheckRcpt(event, rcpt) ∧ (rcpt[t] ≤ t2)∧ (CheckInconsistent(c1, t1, c2, π) ∧ (t1 ≤ t2)) CheckNotIncl(c2, event, π) Finally, our gossip protocol assumes the monitor has a more up-to-date snapshot than the auditor, which protects against an adversarial log server trivially winning the con- sistency game (Definition 41) by ignoring the monitor|,Non-data,103
| One could also imagine a protocol in which the monitor pauses, updates (using the Inspect protocol), and then resumes its interaction with the auditor, in which case the extra winning condition in Definition 41 could be dropped Theorem 43|,Non-data,103
| If the DLC is secure in the augmented setting and the signature scheme is unforgeable (ie, EUF- CMA secure), then the protocols presented in Figures 2-5 and the algorithms presented above comprise a secure pledged transparency overlay, as defined in Section 42|,Non-data,103
| A proof of this theorem can be found in the full version of the paper Briefly, consistency follows from three prop- erties of the dynamic list commitment: provable inconsis- tency, append-only, and soundness Together, these ensure that if the log server presents an inconsistent view of the log to the auditor and monitor, then the commitment seen by the auditor in its snapshot — which, crucially, was updated using ProveAppend and used to demonstrate the inclusion of events — is inconsistent with the list seen by the moni- tor By provable inconsistency, the monitor can thus pro- vide a proof of inconsistency that comprises valid evidence of the log server’s misbehavior|,Non-data,103
| Non-frameability, on the other hand, follows from the unforgeability of the signature scheme and from the difficulty of forging either a proof of inconsistency or a proof of non-inclusion Finally, account- ability follows from the provable non-inclusion of the DLC, 174/ / o o Sys(event) Auditor(snapAu, eventsbad) LS(logLS) 1 2 3 4 (if update) event,rcpt b b ← CheckRcpt(event, rcpt) if (b = 0) return fail update ← (rcpt[t] > tAu) b b ← CheckSnap(snapLS) ∧ CheckAppend(cAu, cLS, π) snapAu snapLS,π π ← ProveAppend(cAu, cLS, eventsLS) 5 6 7 8 9 10 11 12 13 14 15 16 if (b = 0) return 0 snapAu ← snapLS b ← (rcpt[t] ≤ tAu) if (b = 0) return fail b b π(cid:48) b ← CheckIncl(cAu, event, π(cid:48)) event,snapAu π(cid:48) ← ProveIncl(cAu, event, eventsLS) return ε return b if (b = 0) eventsbad ← eventsbad(cid:107)(event, rcpt) return 1 Figure 3: The CheckEntry protocol for pledged transparency overlays The parts of the protocol that may not be carried out (depending on the ‘if’ clause) are marked with dashed lines as if an event is missing from the log then the auditor and monitor should be able to provide valid evidence of this (in the form of a receipt promising to include a given event and a proof of non-inclusion of that event)|,Non-data,103
| 44 A generic basic transparency overlay A basic transparency overlay is essentially a simpler ver- sion of a pledged transparency overlay, so we do not give a full description of the protocols here, but instead describe the necessary modifications that must be made The most obvious modification is that all of the parts that involve receipts do not exist in the basic variant Thus, the Log protocol for a basic transparency overlay omits lines 4-5 from Figure 2 but otherwise remains the same|,Non-data,103
| Next, in the CheckEntry protocol, the auditor now cannot use the receipt to check if it needs to update, so it must use time(event) in- stead The Inspect protocol contains no mention or usage of receipts, and thus is exactly the same in the basic variant This leaves the Gossip protocol, in which the only significant modification is that basic transparency overlays cannot pro- vide the second type of evidence (in which the auditor and monitor use the receipt to prove that the log server promised to include an event but then did not), so do not attempt to produce it (lines 9-12 of Figure 5) This also means that evidence consists only of the two snapshots and a proof|,Non-data,103
| As the basic transparency overlay thus involves only minor modifications to the pledged transparency overlay, we do not prove its security from scratch, but instead prove the following theorem as a special case of Theorem 43 Theorem 44|,Non-data,103
| If the DLC is secure in the augmented setting and the signature scheme is unforgeable (ie, EUF- CMA secure), then the modified protocols and algorithms de- scribed above comprise a secure basic transparency overlay, as defined in Section 41|,Non-data,103
| 5 CERTIFICATE TRANSPARENCY In this section, we describe how CT instantiates a pledged transparency overlay (as defined formally in Section 42), discuss how the formal notions of overlay security imply more intuitive notions of security specific to the setting of issuing certificates, and finally discuss the requirements of a practical deployment of CT 5|,Non-data,103
|1 CT is a secure pledged overlay As depicted in Section 2, Certificate Transparency has three actors in the system Sys: a certificate authority CA, a website owner Site, and a client Client One of the first two actors must participate in the Log protocol,2 to ensure that the certificate issued by CA to Site ends up in the log, and the client participates in the CheckEntry protocol to check that the certificate presented to it by a website is in the log In the parlance of CT, an event is a (basic) certificate cert = (pk name, σCA), where σCA is the CA’s signature on 2This means that either the website obtains the signed cer- tificate from the CA and then goes on to enter it into the log, or the CA signs the certificate and enters it into the log before returning the extended certificate to the website 175/ / o o / / o o o o o o / / o o o o 1 2 3 4 5 6 7 8 9 10 Monitor(snapMo, eventsbad, eventsMo) LS(log) snapMo snap,events∆ j ← min{i || CheckCom(cMo, events[1 : i])} events∆ ← events[j + 1 : ] if (CheckSnap(snap) = 0) ∨ (isOrdered(events∆) = 0) return 0 return ε if (time(events∆[1]) < tMo) return 0 c(cid:48) ← Append(events∆, cMo) if (c(cid:48) (cid:54)= snap[c]) return 0 snapMo ← snap; eventsMo ← eventsMo(cid:107)events∆ update eventsbad using out-of-band checks return 1 Figure 4: The Inspect protocol|,Non-data,103
| the site’s public key pk name,3 a receipt is a signed certifi- cate timestamp (SCT), and a snapshot is a signed tree head (STH) For the notion of timing needed for snapshots and receipts, one could pick the current local time of the log server and either use this value directly as t or incorporate into it some buffer period, which is referred to in the CT documentation as the maximum merge delay (MMD) We discuss this further in Section 53|,Non-data,103
| Finally, CT instantiates GenEventSet as follows: Site(pk name) pk name CA σ r←− Sign(sk CA, pk name) cert ← (pk name, σ) return {cert} cert return {cert} The rest of the protocols needed for the transparency over- lay can be instantiated exactly as in Section 43, so Theo- rem 43 carries over directly and we can see that CT provides a secure pledged transparency overlay 5|,Non-data,103
|2 Further security implications We have just demonstrated that CT provides a secure transparency overlay, but it is not clear what this means for the specific setting of certificate issuance To explore this, we first remind ourselves of the security of the underlying system (ie, the issuance of basic certificates), in which (1) it should be difficult to produce a basic certificate without con- tacting the CA, and (2) an honest client should accept only (basic) certificates that verify|,Non-data,103
| These are clearly satisfied as- suming the correctness and unforgeability of the signature scheme Combining the underlying issuance security with the se- curity of the overlay, we can argue that three more intuitive 3For simplicity, we include here only the most basic version of the information that needs to be checked for and included in a certificate security goals are largely satisfied First, an extended cer- tificate (i|,Non-data,103
|e, a certificate augmented with an SCT) should not pass verification if it has not been jointly produced by the CA and log server This holds because the underlying issuance security implies that it is difficult to produce cert without the CA, and non-frameability implies that it is difficult to produce rcpt without the log server, so it should be difficult to produce (cert, rcpt) without both the CA and the log server Second, honest clients shouldn’t accept “bad” cer- tificates; i|,Non-data,103
|e, certificates that are either improperly formatted or not being monitored The underlying is- suance security says that if cert does not verify then the client won’t accept Following this, the honest client ac- cepts only if the auditor indicates that the certificate is in the log|,Non-data,103
| By consistency, the auditor’s view of the log is consistent with the monitor’s view from the last time they engaged in the Gossip protocol (unless evidence has been produced to the contrary, at which point we can assume the auditor ceases communication with the log server) If the certificate is older than this, then the certificate is definitely being monitored; if it is newer, then it is not guaranteed that the certificate is being monitored, but if it is not then the auditor can at least detect this during its next iteration of the Gossip protocol Thus, honest clients never accept improperly formatted certificates, and are unlikely to ac- cept unmonitored certificates provided that the auditor and monitor are engaging in the Gossip protocol with sufficient frequency Finally, if a log server is misbehaving by omitting certificates from the log that it promised to include, it should be possible to blame it|,Non-data,103
| If a log server refuses to answer queries, then there is little we can do about this in the context of our overlay (although in a practical setting with more than one log server this problem could be miti- gated) If a log server does answer, then it can be formally blamed by accountability, as the SCT acts as non-repudiable evidence that the log server has promised to include a cer- tificate and the corresponding proof of non-inclusion demon- strates that it has not done so 176/ / o o / / o o bMo ← CheckSnap(snapMo) if (bMo = 0) return fail if (tAu > tMo) return fail π b ← CheckInconsistent(cAu, tAu, cMo, π) if (b = 1) return (snapAu, snapMo,⊥, π) (repeat for all (event, rcpt) ∈ events(Au) bad ) event,rcpt π b ← CheckNotIncl(cMo, event, π) 1 2 3 4 5 6 7 8 9 10 11 12 13 Auditor(snapAu, events(Au) bad ) Monitor(snapMo, events(Mo) bad , events) snapAu snapMo bAu ← CheckSnap(snapAu) if (bAu = 0) return fail if (tAu > tMo) return fail π ← DemoInconsistent(events, tAu) b ← CheckInconsistent(cAu, tAu, cMo, π) if (b = 1) return (snapAu, snapMo,⊥, π) π ← DemoNotIncl(cMo, events, event) b ← CheckNotIncl(cMo, event, π) if (b = 1) return (snapAu, snapMo, (event, rcpt), π) if (b = 1) return (snapAu, snapMo, (event, rcpt), π) return fail return fail Figure 5: The Gossip protocol for pledged transparency overlays The optional part of the protocol is marked with dashed lines|,Non-data,103
| 53 Practical considerations Finally, we discuss some necessary alterations that would be made to our protocol if used in a real deployment Batched additions to the log In Figure 2, the log server currently updates the log during the Log protocol, and as a result includes the exact current time in the SCT|,Non-data,103
| To avoid doing this operation every time, this process would be batched, so the time in the SCT would instead be some time in the near future (eg, the end of the current day) This gap between the current and promised times is referred to in the CT documentation as the maximum merge delay (MMD)|,Non-data,103
| Collapsing the overlay into the system As discussed in the CT documentation, in a real deployment we expect auditors to interact with many different log servers (as the certificates seen by clients may be logged in many differ- ent places), but expect monitors to focus on one log and the certificates it contains There are therefore two possible models: in one, the auditors and monitors are operated as separate services, and monitors can even be used as backup log servers In the other, the role of the auditor could col- lapse into the client (e|,Non-data,103
|g, it could be run as a browser ex- tension and responses could be cached), and the role of the monitor could collapse (at least partially) into the website, who could monitor the log to at least keep track of its own certificates Privacy concerns While SSL certificates are public and thus storing them in a public log presents no privacy con- cern, information might be revealed about individual users through the certificates queried by the auditor (to both the log server and monitor), as well as the choice of signed tree heads and SCTs|,Non-data,103
| We view this as an interesting area for future research, but mention briefly that some of these con- cerns can be mitigated — with minimal effect on the security of the transparency overlay — by omitting the optional part of Figure 5, in which the auditor reveals to the monitor some of the certificates that it has seen 6 AMPLIFYING BITCOIN’S SECURITY Although Bitcoin already provides a large degree of trans- parency — as its transaction ledger, called the blockchain, is globally visible — it does not satisfy the requirements of a transparency overlay In particular, the miners, who play a role analogous to the log server in producing the blockchain, are not known entities and thus cannot be held responsible; this in turn means that consistency and non-frameability cannot be satisfied|,Non-data,103
| In this section, we thus begin by pre- senting in Section 61 a secure basic transparency overlay for Bitcoin One might naturally wonder whether such a distinction is purely pedantic; ie|,Non-data,103
|, if overlaying transparency on top of a transparent system provides any actual benefits To answer this question in the affirmative, we discuss in Section 62 the benefits (in terms of both security and efficiency) that are achieved by applying the transparency overlay In par- ticular, we show that the addition of a secure transparency overlay relieves regular Bitcoin users (i|,Non-data,103
