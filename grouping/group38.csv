 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
|) (arith expr) l (cardinality constr) φ := l ≤ l || φ ∧ φ := ||S|| || ||O(cid:96)|| || t || l + l The syntax distinguishes between variables X that are drawn from a set X of names–that we will use to represent sets of shares of an encoding variable, and variables O, annotated with a label (cid:96), that are drawn from a disjoint set Ω of names–that we will use to represent sets of internal positions probed in the gadget used at instruction (cid:96)|,Non-data,94
| REMARK 1 Our syntax for set expressions and constraints is a fragment of the (decidable) theory of finite sets with cardinality constraints It would be possible to include other set-theoretical operations, as in [33, 3] However, we have found our core fragment sufficient for our purposes|,Non-data,94
| The semantics of assertions is defined using the notion of valuation A valuation μ is a mapping from names in X and Ω to finite sets, such that ∀ X ∈ X  μ(X) ⊆ {0,  |,Non-data,94
|  , t} and ∀ O(cid:96) ∈ Ω μ(O(cid:96)) ⊆ OG(cid:96), where G(cid:96) is the gadget called at instruction (cid:96) Every valuation μ defines, for every set expression S, a set of share indices μ(S) ⊆ {0, |,Non-data,94
|   , t} and for every arithmetic expression l an interpretation μ(l) ∈ N, using the intended interpetation of symbols (ie|,Non-data,94
| ∪ is interpreted as set union, + is interpreted as addition,    )|,Non-data,94
| DEFINITION 6 1 μ satisfies a cardinality constraint φ, written μ ||= φ, if (INTERPRETATION OF ASSERTIONS) μ(l1) ≤ μ(l2) for every conjunct l1 ≤ l2 of φ (cid:91) {aı || ı ∈ μ(Γ(a))} ∪(cid:91) (cid:74)(Γ, φ)(cid:75) = {μ(Γ) || μ ||= φ} O a 3|,Non-data,94
| The interpretation of (Γ, φ) is the set 2 The interpretation of Γ under μ is the set μ(Γ) = μ(O) We now turn to the definition of the type system DEFINITION 7 Algorithm P (a1, |,Non-data,94
|   , an) ::= s; return r has type (Γin, φin) ⇐= (Γout, φout) if the judgment (cid:96) s : (Γin, φin) ⇐= (Γout, φout) is derivable using the typing rules from Figure 3 We denote this fact (cid:96) P : (Γin, φin) ⇐= (Γout, φout)|,Non-data,94
 We briefly comment on the rules Rule (SEQ) is used for typing the sequential composition of gadget calls and is as expected The remaining rules are used for interpreting the non-interference prop- erties of gadgets We now detail them,Non-data,94
| Rule (SNI-GADGET) is used for typing calls to a SNI-gadget with an arbitrary post-assertion and a pre-assertion in which the mapping Γout is updated to reflect the dependencies created by the call, and the constraint is strenghtened with the cardinality constraint imposed by strong non-interference The rule has a side condition ||O(cid:96)|| + ||Γout(b)|| ≤ t ensuring that the total number of positions whose dependency set by G we are considering is bounded by t, where O(cid:96) is the name of the subset of positions that are observed in the current gadget (called at line (cid:96)), and Γout(b) is the set of shares of b the adversary has information about from positions probed in gadgets that use b later on in the algorithm This side condition is verified under the condition φout Note that the variables X (cid:96) k are fresh, and annotated with the label (cid:96) that identifies the current instruction, and an indice k that identifies the argument|,Non-data,94
| Rule (NI- GADGET) is similar but deals with NI-gadgets, and therefore extends k Γin with correspondingly weaker constraints on the X (cid:96) We now turn to the rule for affine gadgets Informally, we say that a gadget is affine if it manipulates its input encodings share by share; this includes standard implementations of ring addition, for example, but also of many other functions that are linear in K (for example, multiplication by a constant–or public–scalar, or shifts in the representation when addition is bitwise) Formally, we say that a gadget G with parameters (a1, |,Non-data,94
|   , an) is affine iff there exists a family of procedures f0,  |,Non-data,94
|  , ft such that G is an inlining of x0 ← f0(a0 1,   |,Non-data,94
| , a0 return (cid:104)x0,    , xt(cid:105); n); |,Non-data,94
|   ; xt ← ft(at 1,  |,Non-data,94
|  , at n); 1,   |,Non-data,94
| , aı Thus, one can define a mapping η : OG → {0,    , t} such that for every position π ∈ OG, η(π) = ı if π occurs in the computation of the ıth share (i|,Non-data,94
|e in the computation of fı(aı n)) The fine-grained information about dependencies given by this notion of affinity is often critical to proving the probing security of algorithms Therefore, it is important to capture affinity in our type system|,Non-data,94
| Let O = Oint (cid:93) Oext be a position set, split between internal and output positions The affine property ensures that the joint distribution of O depends only on input positions in η(Oint∪Oext), and furthermore that ||η(Oint ∪ Oext)|| = ||η(Oint)|| + ||η(Oext)|| = ||η(Oint)|| + ||Oext|| Rule (AFFINE) interprets this affine property into our type system, using Γout(b) and a fresh O(cid:96) for Oext and Oint, respectively, and encoding η(O(cid:96)) into an abstract existential set X (cid:96) The condition ||X (cid:96)|| ≤ ||O(cid:96)|| precisely captures the fact that ||η(O)|| ≤ ||O|| for all O|,Non-data,94
| DEFINITION 8 (TYPING OF AN ALGORITHM) Let P be an algorithm defined by P (a1,   |,Non-data,94
| , an) ::= s; return r 122(cid:96) b := G(a1,   |,Non-data,94
| , an) : (Γin, φin) ⇐= (Γ, φ) (cid:96) c : (Γ, φ) ⇐= (Γout, φout) (cid:96) b := G(a1,    , an); c : (Γin, φin) ⇐= (Γout, φout) (SEQ) G is t-NI φout ⇒ ||Γout(b)|| + ||O(cid:96)|| ≤ t (cid:96) b :=(cid:96) G(a1, |,Non-data,94
|   , an) : (Γin, φout ∧ ( φout ⇒ ||Γout(b)|| + ||O(cid:96)|| ≤ t G is t-SNI Γin := Γout{b,∀ k ak ← ∅,∀ k|,Non-data,94
| Γout(ak) ∪ X (cid:96) k} ||X (cid:96) k|| ≤ ||Γout(b)|| + ||O(cid:96)||)) ⇐= (Γout, φout) Γin := Γout{b,∀ k ak ← ∅,∀ k Γout(ak) ∪ X (cid:96) k} (cid:96) b :=(cid:96) G(a1,  |,Non-data,94
|  , an) : (Γin, φout ∧ ( k|| ≤ ||O(cid:96)||)) ⇐= (Γout, φout) Γin := Γout{b, ak ← ∅, Γout(ak) ∪ Γout(b) ∪ X (cid:96)} G is affine (cid:96) b :=(cid:96) G(a1,   |,Non-data,94
| , an) : (Γin, φout ∧ ||X (cid:96)|| ≤ ||O(cid:96)||) ⇐= (Γout, φout) 1≤k≤n ||X (cid:96) (AFFINE) (cid:94) 1≤k≤n (cid:94) (NI-GADGET) (SNI-GADGET) where Γ{∀ k vk ← ∀ k ek} stands for the map Γ where each vk is updated to map to ek and all other indices are left untouched Figure 3: Typing rules φin such that (cid:96) P : (Γin, φin) ⇐= (∅,(cid:80) (cid:80) φin ⇒ ||Γin(ai)|| ≤ (cid:80) P is well-typed for NI, written (cid:96)NI P , whenever there exist Γin, 1≤(cid:96)≤||P|| ||O(cid:96)|| ≤ t) and, for each i ∈ {1, |,Non-data,94
|   , n}, φin ⇒ ||Γin(ai)|| ≤ t P is well-typed for SNI, written (cid:96)SNI P , whenever there ex- ist Γin, φin such that (cid:96) P : (Γin, φin) ⇐= ([r ← O],||O|| + 1≤(cid:96)≤||P|| ||O(cid:96)|| ≤ t) and, for each i ∈ {1, |,Non-data,94
|   , n}, we have 1≤(cid:96)≤||P|| ||O(cid:96)|| (where [v ← x] is the map that associates x to v and is everywhere else undefined) When typing for NI, we start from the empty map for Γout and simply consider any output position observed as if they were internal|,Non-data,94
| However, the same cannot be done when typing for SNI since we need to distinguish clearly between internal positions in one of the O(cid:96), used to type the gadget at instruction (cid:96), and output positions in O, initially used as the set of position of the algorithm’s return encoding PROPOSITION 5 If (cid:96) s : (Γin, φin) ⇐= (Γout, φout) then also (SOUNDNESS OF THE TYPE SYSTEM) ||= P : (Γin, φin) ⇐= (Γout, φout) If (cid:96)NI P then P is t-NI If (cid:96)SNI P then P is t-SNI An Example: Rivain and Prouff’s inversion algorithm We now illustrate the type system by describing a typing deriva- tion on Rivain and Prouff’s algorithm for computing inversion in GF(28) [32, 16]|,Non-data,94
| An algorithm implementing this operation securely is shown in Figure 4, with some information relevant to its typing derivation We recall that the function x (cid:55)→ x2n is linear (for any n) in binary fields and rely on affine gadgets pow2, pow4, and pow16 to compute the corresponding functionalities We present the typing derivation in the slightly unusual form of a table, in Figure 4, which shows the code of the inversion algorithm along with the values of Γin and φin (φin shows only the part of the constraint that is added at that program point, not the entire constraint) at each program point By the sequence rule, these serve as Γout and φout for the immediately preceding program point|,Non-data,94
| The table also shows the side conditions checked during the application of gadget rules where relevant It is easier to understand the type- checking process by reading the table from the bottom up As per the definition of well-typedness for SNI, we start from a state where the output position set O is associated to the algorithm’s return encoding r5, and where the constraint contains only the global constraint that the whole position set O ∪(cid:83) (cid:96) O(cid:96) is of cardinality bounded by t When treating line 9, we know that SecMult is t-SNI and try to apply rule (SNI-GADGET)|,Non-data,94
| We check that the number of positions observed in this instance of SecMult is bounded by t (which trivially follows from the global constraint), and construct the new value of (Γin, φin) following the rule: since neither of the call’s input encodings are used below, new sets X 9 2 are associated to the call’s inputs and the SNI constraints are added to φin Applying the rules further until the top of the program is reached, and performing the appropriate set unions in Γ when an encoding variable is used more than once, we observe that the resulting pre-assertion is such that ||Γin(a)|| ≤ ||O1|| +||O2|| +||O3|| + (cid:96) O(cid:96), and therefore proves that this inversion algorithm ||O9|| ≤(cid:80) 1 and X 9 is t-SNI Finally, one can remark that the instances of SecMult at line 6 and 8 do not in fact need to be t-SNI As pointed out by Belaïd et al|,Non-data,94
| [9], using a t-NI multiplication gadget at these program points is sufficient to construct a type derivation for SNI 7 SNI CHECKER FOR GADGETS We present an automated method for proving that gadgets (or small algorithms, by inlining) are t-SNI at small fixed orders (up to t = 6 for ring multiplication) We then give some experimental results|,Non-data,94
| Verification algorithm We adapt to t-SNI the algorithmic con- tributions of Barthe et al [4] that support the automated verification, on small to medium gadgets and for small orders, of Ishai, Sahai and Wagner’s circuit privacy property [25], which is similar to our t-NI Their work builds on two observations: first, every probabilistic program P taking input x and performing a (statically) bounded number (say q) of uniform samplings over K is equivalent, in the sense below, to composing a deterministic program P † taking inputs x and r with random sampling over Kq|,Non-data,94
| Formally, for every x, Second, P satisfies (I,O)-NI iff there exists a function f such that for every x1, x2 and r, such that x1 ∼I x2 (cid:74)P(cid:75)(x) = mlet r = UKq in(cid:74)P †(cid:75)O(x1, r) =(cid:74)P (cid:74)P †(cid:75)O(x, r) †(cid:75)O(x2, f (x2, r)) and moreover f (x,·) is a bijection for every x The latter equality can be easily verified for all x and r using standard tools, therefore the key to proving non-interference is to exhibit a suitable func- tion f Their algorithm proceeds by incrementally defining bijec- 123Γin 1 ∪ X 1 2 ∪ X 9 2 ∪ X 2 a : X 3 2 ∪ X 2 2 ; z1 : X 9 a : X 3 1 z2 : X 3 2 ; z1 : X 9 a : X 3 2 ; 1 1 ∪ X 8 2 ∪ X 5 r1 : X 6 z1 : X 9 2 ; 1 ; w1 : X 8 z1 : X 9 r1 : X 6 2 ; 1 ; w1 : X 8 z1 : X 9 r1 : X 6 2 ; r2 : X 8 2 ; w1 : X 8 z1 : X 9 2 ; 2 ; w1 : X 8 z1 : X 9 r3 : X 8 2 ; 1 z1 : X 9 r4 : X 9 2 ; 1 r5 : O 1 ∪ X 4 2 ∪ X 5 2 ; w2 : X 6 2 1 ∪ X 7 1 φin ||X 1|| ≤ ||O1|| ||X 2 1|| ≤ ||O2|| ||X 3 k|| ≤ ||O3|| ||X 4|| ≤ ||O4|| ||X 5 1|| ≤ ||O5|| ||X 6 k|| ≤ ||O6|| ||X 7|| ≤ ||O7|| ||X 8 k|| ≤ ||O8|| ||X 9 k|| ≤ ||O9|| ||O|| +(cid:80) 1≤(cid:96)≤9 ||O(cid:96)|| ≤ t Instructions function invert(a) z1 :=1 pow2(a) z2 :=2 Refresh(z1) r1 :=3 SecMult(z2, a) w1:=4 pow4(r1) w2:=5 Refresh(w1) r2 :=6 SecMult(r1, w2) r3 :=7 pow16(r2) r4 :=8 SecMult(r3, w1) r5 :=9 SecMult(r4, z1) return r5 Side conditions ||X 6 1 ∪ X 8 2 ∪ X 5 ||X 6 ||X 3 1|| + ||O2|| ≤ t 1 ∪ X 4|| + ||O3|| ≤ t 2|| + ||O5|| ≤ t 1 ∪ X 7|| + ||O6|| ≤ t ||X 9 1|| + ||O8|| ≤ t ||O|| + ||O9|| ≤ t ||X 8 Figure 4: a−1 in GF(28) tions f1,  |,Non-data,94
|  , fn satisfying the two conditions above until evenutally (cid:74)P †(cid:75)O(x, fn(x, r)) can be rewritten into an expression that does not depend syntactically on secrets However, even with efficient algorithms to prove that a program P is (I,O)-NI for some position set O, proving that P is t-NI remains a complex task: indeed this involves proving (I,O)-NI for all O with ||O|| ≤ t Simply enumerating all possible position sets quickly becomes untractable as P and t grow|,Non-data,94
| Therefore, [4] uses the following fact: if P is (I,O(cid:48))-NI then it is also (I,O)-NI for all O ⊆ O(cid:48) Hence, checking that P is (I,O(cid:48))-NI for some large set O(cid:48) is sufficient to prove that P is (I,O)-NI for every O ⊆ O(cid:48), and this using only one proof of non-interference In particular, they exhibit algorithms that rely on the explicit construction of the bijec- tion fn to efficiently extend the set O from which it was constructed into a potentially much larger set O(cid:48) for which that bijection still proves (I,O(cid:48))-NI Further, they also exhibit algorithms that rely on such extensions to prove the existence of I such that (I,O)-NI for all position sets O much more efficiently than by considering all position sets individually|,Non-data,94
| We adapt their algorithms by changing the core bijection-finding algorithm in two ways: i rather than being applied to a modified program that includes the initial uniform sampling of secret encod- ings, our core algorithm works directly on the gadget description (this is necessary to ensure that we prove t-SNI instead of alterna- tive security notions); and ii our search for a bijection stops when (cid:74)P †(cid:75)O(x, fn(x, r)) can be simplified into an expression that syn- tactically depends on at most d shares of the secret (for the desired bound d on (cid:107)I(cid:107), that is d = ||Oint|| for SNI), rather than stopping when all syntactic dependencies on the secret input have been re- moved We note that replacing the bound d from the second point with d = t yields a verification algorithm for t-NI (by Lemma 3)|,Non-data,94
| Our full algorithm is given in the long version [5] Evaluation We evaluate the performance of our SNI verifier on some medium and small gadgets: SecMult, Coron’s linear-memory ring multiplication algorithm [13, Alg 6]; MultLin, Coron et al|,Non-data,94
|’s algorithm for the computation of functionalities of the form x(cid:12)g(x) for some linear g [16, Alg 5]; Add, the standard affine gadget for the addition of two encodings; RefreshA, the weakly secure mask refreshing algorithm from Rivain and Prouff [32]; RefreshIterk, the iterated additive refresh proposed by Coron [13, Alg 4] for sup- porting more efficient composition in his full model (we make ex- plicit the number of iterations k); WeakMult, the generic reduced- randomness multiplication algorithm proposed by Belaïd et al [9]|,Non-data,94
| Table 1 sums up our findings and some verification statistics 8 MASKING TRANSFORMATION As a proof of concept, we implement our type system for a com- fortable subset of C that includes basic operators, static for loops, table lookups at public indices, and mutable secret state, and ex- tended with libraries that implement core gadgets for some choices of K Moreover, we define a source-to-source certifying masking transformation, which takes an unprotected program and returns a masked algorithm accepted by our type system, selectively inserting refreshing gadgets as required for typing to succeed|,Non-data,94
| We note that the transformation itself need not be trusted, since its result is the final program on which typing is performed Furthermore, the choice of C as a supporting language is for con- venience, since many of the algorithms we consider have reference implementations written in C In particular, we do not claim that compiling and executing the C programs produced by our masking transformation will automatically yield secure executables: our veri- fication results are on algorithms described in the C language rather than on C programs in general Making use of these verification results in practice still requires to take into account details not taken into account in the probing model|,Non-data,94
| Although an important problem, this is out of the scope of this paper and a research area on its own: for example Balasch et al [2] consider some of the issues involved in securely implementing probing secure algorithms 81 Implementation We now give an overview of the different passes performed by our masking transformation|,Non-data,94
| The input programs use explicit typing annotations to distinguish public variables (for example, public inputs, or public loop indices) from sensitive or secret variables that must be encoded We call public type any type outside of those used for denoting variables that must be encoded Parsing and Pre-Typing This pass parses C code into our in- ternal representation, checks that the program is within the supported subset of C, performs C type-checking and checks that variables marked as sensitive (variables given type K) are never implicitly cast to public types|,Non-data,94
| Implicit casts from public types to K (when compat- ible, for example, when casting a public uint8_t to a protected variable in GF(28)) are replaced with public encoding gadgets (that set one share to the public value and all other shares to 0) Gadget Selection and Generic Optimizations This pass heuristically selects optimal gadgets depending on their usage For example, multiplication of a secret by a public value can be com- puted by an affine gadget that multiplies each share of the secret, 124Order 1 1-SNI Order 2 2-SNI Order 3 3-SNI Order 4 4-SNI Order 5 5-SNI Gadget SecMult MultLin RefreshA RefreshIter2 RefreshIter3 WeakMult Time 0|,Non-data,94
07s 007s 007s 008s – 0,Non-data,94
07s     –  Time 008s 008s 008s 0,Non-data,94
08s 009s 007s       Time 009s 0,Non-data,94
15s 008s 008s 008s 0,Non-data,94
09s       Time 086s 119s – 008s 0,Non-data,94
09s –   –   – Time 3640s 5413s – 013s 0,Non-data,94
14s –   –   – Order 6 6-SNI Time 37min 48min – 20s 54s –   –   – Table 1: Experimental Results for the SNI Verifier whereas the multiplication of two secrets must be performed using the SecMult gadget Further efforts in formally proving precise types for specialized core gadgets may also improve this optimiza- tion step,Non-data,94
| Since the encoding replaces scalar-typed variables (passed by value) with array-typed variables (passed by reference), it is also necessary to slightly transform the program to ensure the correctness of the resulting program In addition, we also transform the input program into a form that more closely follows the abstract language from Figure 1, which makes it easier to type-check Type Inference and Refresh Insertion This is the core of our transformation|,Non-data,94
| We implement a type inference algorithm for the type system of Section 6 The algorithm simplifies policies on the fly, supports inferred types on sub-algorithms as gadget- invocation types, and fails when the simplified policy is inconsistent Failure arises exactly when a refreshing operation is needed At the cost of tracking some more information and reinforcing the typing constraint on sub-algorithms, we use this observation to automatically insert Refresh gadgets where required|,Non-data,94
| When type inference fails, the variable whose masks need to be refreshed is duplicated and one of its uses is replaced with the refreshed duplicate To avoid having to re-type the entire program after insertion of a refresh gadget, our transformation keeps track of typing information for each program point already traversed and simply rewinds the typing to the program point immediately after the modification Code Generation Finally, once all necessary mask refresh- ing operations have been inserted and the program has been type- checked, we produce a masked C program|,Non-data,94
| This transformation is almost a one-to-one mapping from the instructions in the type- checked programs to calls to a library of verified core gadgets or to newly defined gadgets Some cleanup is performed on loops to clarify the final code whenever possible, and to remove initialization code on normalized gadgets Interestingly, our transformation pro- duces a (set of) C files that is parameterized by the masking order t Producing executable versions of that algorithm at a particular order, for example to evaluate its performance, is as easy as defining a pre-processor macro at compile-time|,Non-data,94
| 82 Practical Evaluation To test the effectiveness of our transformation, we apply it to different algorithms, generating equivalent masked algorithms at various orders We apply our transformation to the following pro- grams: AES ((cid:12)), a full computation (10 rounds including key sched- ule) of AES-128 masked using the multiplication gadget, and im- plemented in GF(28); AES (x (cid:12) g(x)), a full computation (10 rounds including key schedule) of AES-128 masked using Coron et al’s gadget for computing x (cid:12) g(x), and implemented in GF(28); Keccak, a full computation (24 rounds) of Keccak-f[1600], im- plemented in GF(264); Simon, a block of Simon(128,128), im- plemented in GF(264); Speck, a block of Speck(128,128), im- plemented in GF(2)64, and using one of the following modular addition algorithms; AddLin, Coron, Großschädl and Vadnala’s algorithm [15] for the computation of modular addition on boolean- masked variables (in GF(2)64); AddLog, Coron et al|,Non-data,94
|’s improved algorithm [14] for the computation of modular addition on boolean- masked variables (in GF(2)64) We first discuss the performance of our verifier and the verification results before discussing the practical significance, in terms of time, memory and randomness complexity of our masking transformation Finally, we discuss examples on which our tool implementation could be improved Verification Performance and Results|,Non-data,94
| Table 2 shows re- source usage statistics for generating the masked algorithms (at any order) from unprotected implementations of each algorithm The table shows the number of mask refreshing operations inserted in the program5, the compilation time, and the memory consumption For Keccak, we show two separate sets of figures: the first, marked “no refresh”, is produced by running our algorithm transformer on a bare implementation of the algorithm; the second, marked “refresh in χ”, is produced by running our tool on an annotated implemen- tation, where a mask refreshing operation is manually inserted in the χ function and the tool used for verification only We discuss discrepancies between the numbers on these two lines in Section 9, and consider the “refresh in χ” set of statistics in all discussions until then|,Non-data,94
| We first note the significant improvements these results represent over the state of the art in formal verification for probing security Indeed, our closest competitor [4] report the verification of all 10 rounds of AES (including key schedule) at order 1 in 10 minutes, and could not verify all 10 rounds for higher orders In contrast, our tool verifies the probing security of Rivain and Prouff’s algorithm [32] as fixed by Coron et al [16] at all orders in less than a second|,Non-data,94
|6 Further, we note that the masked algorithms our transfor- mation produce for modular addition are the first such algorithms known to be t-probing secure using only t + 1 shares Indeed, the original proofs [15, 14] rely on the ISW framework and make use of 2t + 1 shares to obtain t-probing security We further note that Coron, Großschädl and Vadnala’s algorithm [15] does not require the insertion of mask refreshing operations, and is thus t-probing secure with t + 1 shares as it was originally described Finally, we note that, to the best of our knowledge, the results obtained on Keccak, Simon and Speck constitute the first generic higher-order masking schemes for these algorithms|,Non-data,94
| 5Note that the number of mask refreshing operations executed dur- ing an execution of the algorithm may be much greater, since the sub-procedure in which the insertion occurs may be called multiple times 6This excludes the once-and-forall cost of proving the security of core gadgets 125Algorithm AES ((cid:12)) AES (x (cid:12) g(x)) AddLin AddLog Keccak (no refresh) Keccak (refresh in χ) Simon Speck (AddLin) Speck (AddLog) 0 0 0 # Refresh 2 per round Time 009s 0|,Non-data,94
05s 001s log2(k) − 1 001s 1 per round ∼20min 1820s 0,Non-data,94
38s 035s 021s 67 per round 61 per round 66 per round Mem 4MB 4MB 4MB 4MB 23GB 456MB 15MB 38MB 8MB Table 2: Resource usage during masking and verification Performance of Masked Algorithms,Non-data,94
| Table 3 reports the time taken to execute the resulting programs 10,000 times at various orders on an Intel(R) Xeon(R) CPU E5-2667 0 @ 290GHz with 64GB of memory running Linux (Fedora) As an additional test to assess the performance of the generated algorithms at very high orders, we masked an AES computation at order 100: computation took ∼011 seconds per block|,Non-data,94
| For AES and Speck, the figures shown in the “unmasked” column are execution times for the input to our transformation: a table-based implementation of AES or an implementation of Speck that uses machine arithmetic, rather than Coron, Großschädl and Vadnala’s algorithm would be much faster, but cannot be masked directly using our transformation Although these observations do highlight the cost of security, we note that using RefreshA when masking the AES SBox does not incur a significant timing gain for any of the masking orders we tested (t ≤ 20) However, the randomness cost is greatly reduced, which may be significant in hardware or embedded software settings Further research in reducing the randomness cost of SNI mask refreshing, or of other gadgets, serves to make security less costly [9, 1, 7]|,Non-data,94
| We also confirm the 15% timing improvements reported by Coron et al [16] when implementing the AES SBox using their gadget for computing x (cid:12) g(x) We now look more closely at statistics for the modular addition algorithms AddLin and AddLog and their effects on the perfor- mance of masked algorithms for Speck We first note that proving AddLog t-NI requires the addition of a mask refreshing gadget, whereas AddLin does not|,Non-data,94
| Despite this additional cost, however, AddLog is better than AddLin when word size k grows, since it saves k − log(k) multiplications and replaces them with a single mask refreshing operation These performance gains on modular ad- dition become overwhelming when seen in the context of a masked algorithm for Speck, which computes one 64-bit modular addition per round It would be interesting to consider using our transformer to produce masked algorithms for other efficient circuits for modu- lar addition [27] and measure their performance impact in terms of randomness, time and memory when masked 9|,Non-data,94
| DISCUSSIONS AND RELATED WORK Here, we further discuss the relation between the definitions and results reported here and existing and future work in theoretical and practical cryptography Our discussions focus mainly on: i adver- sary and leakage models; ii compositional security notions; iii|,Non-data,94
| the- oretical and practical masking transformations; and iv limitations of our definitions and tools Adversary and Leakage Models for Masking We have considered security in the probing model of Ishai, Sahai and Wag- ner [25], which is particularly well-suited to automated analysis due to its tight relation to probabilistic non-interference|,Non-data,94
| In particular, our notion of t-NI is equivalent to the notions of t-probing secu- rity and perfect t-probing security used by Carlet et al [11] and others [32, 16] Despite its broad usage in the literature, the practical relevance of the probing model is not immediately obvious: in practice, side- channel adversaries observe leakage traces, which contain noisy information about all intermediate computations, rather than precise information about some This threat model is much more closely captured by the noisy leakage model, first introduced by Chari et al|,Non-data,94
| [12] and extended by Prouff and Rivain [31] The noisy leakage model is much more complex and makes security proofs on masked algorithms significantly more involved, and much harder to verify Duc, Dziembowski and Faust [18] show that proving probing security allows one to estimate the practical (noisy leakage) secu- rity of a masked algorithm While Duc, Faust and Standaert [19] empirically show that some of the factors of Duc et al|,Non-data,94
|’s bound [18] are likely proof artefacts, the remainder of the bound, and in par- ticular a factor that includes the size of the circuit, seems to be tight Intuitively, Duc et al [19] essentially show that the probing security order gives an indication of the smallest order moment of the distribution over leakage traces that contains information about the secret, whereas the size of the circuit the adversary can probe is an indicator of how easy it is to evaluate higher-order moments Composition, and Region and Stateful Probing|,Non-data,94
| This ob- servation makes clear the importance of also considering more powerful probing adversaries that may place t probes in each of some (pre-determined) regions of an algorithm (the t-region probing model) For example, each core gadget (field operations and mask refreshing operation) could be marked off as a separate region (as in [18]) More recently, and in work contemporary with that pre- sented here, Andrychowicz, Dziembowski and Faust [1] consider a more general notion of region whose size must be linear in the security parameter (and masking order), and exhibit a mask refresh- ing gadget that is linear in size and fulfills, in the probing model, the reconstructibility and re-randomization properties from Faust et al [22]|,Non-data,94
| We now discuss the implications of reconstructibility and re- randomization, and their relation to our notion of SNI, based on the similarity of Prop 4 with Ishai et al’s remark on “Re-randomized outputs” [25], before discussing the applicability of SNI to security in the region and stateful probing models [25] Intuitively, a gadget is t-reconstructible whenever any t of its positions can be simulated using only its (shared) inputs and out- puts, and a gadget is re-randomizing whenever its output encoding is uniform and t-wise independent even if its input encoding is completely known|,Non-data,94
| Our SNI notions combines both considerations Formulating it in similar terms, a gadget is t-SNI whenever any t of its positions can be simulated using only its (shared) inputs, and if its output encoding is uniform and (t − d)-wise independent even if d shares of each of its inputs are known (for all d such that 0 ≤ d < t) Expressed in this way, it is clear that SNI is slightly weaker than “reconstructible and re-randomizable” in the probing model This allows us to automatically verify that a gadget is SNI for some fixed t, whereas reconstructibility and re-randomization are more complex|,Non-data,94
| In addition, the ability to combine the use of SNI and weaker (NI or affine) gadgets in a fine-grained way allows us to more precisely verify the security of large algorithms in mod- els where the adversary can place t probes in the entire algorithm We leave a formal investigation of the relation between SNI and “reconstructibility and re-randomization” as future work Based on reconstructibility and re-randomization, Faust et al [22, 1] prove elegant and powerful composition results that in fact apply 126Algorithm AES ((cid:12)) AES (x (cid:12) g(x)) Keccak Simon Speck (AddLin) Speck (AddLog) unmasked Order 1 Order 2 Order 3 Order 5 Order 10 Order 15 Order 20 59|,Non-data,94
567s 50588s 156050s 20140s 603,Non-data,94
261s 72358s 38007s 32552s 92,Non-data,94
476s 11551s 357153s 42032 21,Non-data,94
318s 17875s 42764s 6136s 231,Non-data,94
423s 19991s 3326s 3209s 3,Non-data,94
057s 0526s 10281s 1231s 4,Non-data,94
516s 4368s 5801s 0873s 20,Non-data,94
053s 2258s 8161s 7707s 13,Non-data,94
505s 1782s 47389s 5621 0,Non-data,94
078s 0078s 0238s 0053s 0,Non-data,94
022s 0022s 2697s 2278s 1,Non-data,94
|572s 0279s 4361s 0529s Table 3: Time taken by 10,000 executions of each program at various masking orders in the more powerful region probing and stateful probing mod- els [25], where the adversary may (adaptively) place t probes in each region (or in each subsequent iteration) of the algorithm|,Non-data,94
| It is worth noting that our SNI notion also enables composition in these two models: indeed, it is easy to see that any two 2t-SNI algorithms (our regions) can be composed securely when the adver- sary can place t probes in each of them Further, our composition techniques also support elegant constructions that support compo- sitional security proofs in the region and stateful probing models without doubling the number of shares computations are carried out on (instead, simply doubling the number of shares at region bound- aries) We give details of these robust composition results in the full version Depending on the size of regions that are considered, these robust composition results may bring significant performance gains in terms of randomness and time complexity|,Non-data,94
| Finally, our notion of SNI and the automated verification tech- niques presented allow the efficient, precise and automated verifica- tion of t-SNI inside each region, an issue which is not addressed by the works of Faust et al [22, 1] Existing Masking Transformations Ishai, Sahai and Wag- ner [25] and others [18, 1] also propose simple masking transfor- mations that turn unprotected algorithms (or boolean or arithmetic circuits) into protected masked algorithms|,Non-data,94
| Ishai, Sahai and Wag- ner [25] forgo the use of mask refreshing gadgets by doubling the number of shares on which masked computations occur–with a quadratic impact on performance and randomness complexity Faust et al [18, 1] rely on making sure that all gadgets used in the masked algorithm are reconstructible and re-randomizing This guarantees security in a stronger probing model, but incurs an even greater loss of performance|,Non-data,94
| By contrast, our transformation attempts to decide whether a mask refreshing operation is required to ensure security in the probing model, and our core contributions (the notion of SNI and the type-checker) do support composition in stronger probing models, whilst still allowing the proofs of security within regions to be handled precisely Coron [13] proposes schemes for masking lookups at secret or sensitive indices in public tables We have not investigated whether or not the proposed algorithms are SNI or simply NI, and whether or not establishing these properties can be done by adapting our type-system or if it should be done in a different way (either as a direct proof or using the checker from Section 7) We note in passing that part of the result by Coron [13], namely that using between each query to the masked S-box supports RefreshIter2t+1 security in the stateful probing model is subsumed and improved by the robust composition results described in the full version|,Non-data,94
| 2t The security analysis of masking schemes in the t-probing model is connected to techniques from multi-party computation, exploited in parallel lines of research by threshold implementations [29, 10] In particular, higher-order threshold implementations are exposed to similar security issues due to composition, although they offer additional protection against practical considerations not captured in standard probing models, namely glitches We believe that the results discussed here are in fact applicable to the compositional security analysis of threshold implementations but leave a formal investigation of these links as future work Refining SNI|,Non-data,94
| We now discuss some limitations of our current implementation, and leads for future theoretical work that may yield significant practical improvements Alg 7 Semi Public Modular Addition in GF(2)k function AddPub(x, y) w := x (cid:12) y a := x ⊕ y w := RefreshM(w) u := w (cid:28) 1 for i = 2 to k − 1 do ua := u (cid:12) a u := ua ⊕ w u := u (cid:28) 1 z := a ⊕ u return z function AddPub(x, y) w := x (cid:12) y a := x ⊕ y u := w (cid:28) 1 for i = 2 to k − 1 do a(cid:48) := RefreshM(a) ua := u (cid:12) a(cid:48) u := ua ⊕ w u := u (cid:28) 1 z := a ⊕ u return z (7a) Masked algorithm produced by (7b) Masked algorithm produced by our tool hand The first point we wish to discuss is the case of Keccak, for which algorithm transformation is prohibitively expensive This issue is due to our handling of static for loops: indeed, our tool unrolls them to perform type-checking and rolls them back up afterwards if possible (otherwise leaving them unrolled in the final algorithm)|,Non-data,94
| For smaller algorithms, this is not a problem, but unrolling all 24 rounds of Keccak-f, along with all the loops internal to each iteration, yields a very large program that is then backtracked over each time a mask refreshing operation is inserted Refining our non-interference notions to multi-output gadgets and algorithms would allow us to significantly improve our tool’s handling of loops and high-level composition, whilst gaining a better understanding of probing security in such scenarios This improved understanding may in turn help inform the design of primitives that are easier to protect against higher-order probing Second, we discuss our greedy policy for the insertion of mask re- freshing algorithms|,Non-data,94
| In our experiments, we consider a version of the linear-time modular addition algorithm [15] whose second argument is a public (non-shared) value (for example, a round counter, as in Speck) We show its code, as produced by our masking transformer, in Gadget 7a, and display a hand-masked variant in Gadget 7b, slightly abusing notations by denoting simple gadgets with the sym- bol typically used for their unprotected versions Notice that the variable w is used once per loop iteration, and that our tool refreshes each of them, while it is sufficient to mask only the first one Im- proving our gadget selection algorithm to detect and implement this optimization—and others—would be an interesting avenue for 127future work, that could help improve our understanding of the effect on security of compiler optimizations|,Non-data,94
| Acknowledgements The work presented here was supported by projects S2013/ICE-2731 N-GREENS Software-CM, ANR-10- SEGI-015 PRINCE and ANR-14-CE28-0015 BRUTUS, and ONR Grants N000141210914 and N000141512750, as well as FP7 Marie Curie Actions-COFUND 291803 10 |,Non-data,94
|ABSTRACT Process-based isolation, suggested by several research prototypes, is a cornerstone of modern browser security architectures Google Chrome is the first commercial browser that adopts this architec- ture Unlike several research prototypes, Chrome’s process-based design does not isolate different web origins, but primarily promises to protect “the local system” from “the web” However, as bil- lions of users now use web-based cloud services (e|,Non-data,96
|g, Dropbox and Google Drive), which are integrated into the local system, the premise that browsers can effectively isolate the web from the local system has become questionable In this paper, we argue that, if the process-based isolation disregards the same-origin policy as one of its goals, then its promise of maintaining the “web/local system (local)” separation is doubtful Specifically, we show that exist- ing memory vulnerabilities in Chrome’s renderer can be used as a stepping-stone to drop executables/scripts in the local file system, install unwanted applications and misuse system sensors|,Non-data,96
| These at- tacks are purely data-oriented and do not alter any control flow or import foreign code Thus, such attacks bypass binary-level pro- tection mechanisms, including ASLR and in-memory partitioning Finally, we discuss various full defenses and present a possible way to mitigate the attacks presented 1|,Non-data,96
| INTRODUCTION Web browsers were originally monolithic pieces of software with- out a principled way for separating their objects and resources [42] As a result, any successful binary-level exploit (eg, through a memory bug) would take over the entire browser|,Non-data,96
| For many years, this was an ordeal for browser security To confine malicious web sites, modern browser architectures adopt sandbox techniques to strongly enforce the separation between the web domain and the lo- cal domain The sandbox prevents malicious web sites from affect- ing local systems even when there are exploitable memory errors in browsers In addition, recent browser architectures have adopted a process-isolated design|,Non-data,96
| The goal is to further confine the dam- age of a security exploit within the boundary of the compromised Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page Copyrights for components of this work owned by others than the author(s) must be honored Abstracting with credit is permitted To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee|,Non-data,96
| Request permissions from permissions@acmorg CCS’16, October 24 - 28, 2016, Vienna, Austria c(cid:13) 2016 Copyright held by the owner/author(s) Publication rights licensed to ACM|,Non-data,96
 ISBN 978-1-4503-4139-4/16/10   $15,Non-data,96
00 DOI: http://dxdoiorg/101145/2976749,Non-data,96
|2978414 process, so that objects and resources in other processes are unaf- fected After initial research prototypes [52], Google Chrome is the first commercial browser to adopt this approach [43] Internet Ex- plorer (IE) has also adopted it since version 80|,Non-data,96
| As of July 2015, Google Chrome and IE (on desktop and mobile) are estimated to have over 80% of the worldwide web browser usage [37] In this paper, we revisit the security offered by this de-facto architecture, using Google Chrome as a representative The Google Chrome’s architecture uses privilege separation in two ways First, Chrome isolates the browser kernel process, which has access to the user’s local OS interfaces, from the renderer pro- cess, which is sandboxed and hosts the web page’s resources|,Non-data,96
| Sec- ond, Chrome isolates website instances [28] or tabs into separate renderer processes Chrome’s design highlights a clear deviation from the conceptual proposals in Gazelle [72] and OP2 [53] — a tradeoff between security and performance [50] A particular dif- ference is about enforcing the same-origin policy (SOP) [30] The same-origin policy prevents any accesses from a|,Non-data,96
|com to bcom in the browser, unless they communicate through certain explicit cross-domain channels (eg, PostMessage [36])|,Non-data,96
| In both of the aforementioned research prototypes, enforcing the same-origin pol- icy is an explicit goal of the process isolation They aim to place objects from different web domains in different processes, so that cross-domain accesses must take place as inter-process communi- cation (IPC) calls [21] However, when adopting this approach, Chrome makes a compromise between the sandboxing granularity and the affordable performance overhead: the goal of the sandbox- ing is only to restrict the accesses between contents from the web and those in the local file system, whereas SOP is not enforced by the sandboxing if the contents from different domains are loaded into one process It is the rendering engine that is responsible for enforcing SOP within a process|,Non-data,96
| However, there is a common misconception that Chrome’s sand- boxing granularity is per domain Actually, Google is upfront about this in an early paper about Chrome’s security architecture, in which “origin isolation” (essentially the SOP) is listed as one of the “out- of-scope goals” [43] Rather, the explicit goal of its process-based sandboxing is to separate “the web” from the “local system”1 The notion of web has evolved to include cloud services over the past a few years, which are increasingly integrated with local systems and devices|,Non-data,96
| For example, storage services like Dropbox, OneDrive, and Google Drive are pervasive These kinds of ser- 1Though there are on-going efforts to improve site-based isolation in the Chromium project, such as the roadmap outlined in [32] and the out-of-process iframes [26], they are not practically available to offer stronger protection 791vices integrate the cloud with the local file system, ie|,Non-data,96
|, a local folder is created to automatically synchronize with the storage in the cloud Similarly, source code repository services like GitHub also represent new usage scenario of cloud services, in which the user regularly pulls files into the local file system Likewise, ap- plication (app) stores, cloud VM management consoles and remote host-management apps are common scenarios in which cloud ser- vices install programs and manage privileges on the local system Therefore, the reality today is that the web (i|,Non-data,96
|e, the cloud) is an integral extension of the local system, not a foreign landscape that can only be viewed through a browser Considering this reality, we re-examine the trade-offs made in browser design Threat to web/local isolation|,Non-data,96
| In this paper, we present a study to question the effectiveness of such a coarse-grained “web/local” separation in practice We argue that, if the process-based sandbox- ing regards the same-origin policy as an “out-of-scope goal”, then its promise of maintaining the “web/local” boundary is in doubt By compromising the renderer process of a website, an attacker can access the contents of the site on behalf of the user However, to universally access the contents of arbitrary origins including sites of cloud services, the attacker has to bypass the SOP enforcement|,Non-data,96
| Once SOP is compromised, the attacker can further bypass web/lo- cal isolation for any files related to any cloud services the victim user has already authenticated to Essentially, with a coarse-grained “web/local” isolation enforced by the process-based sandboxing, the burden of the SOP enforcement entirely relies on the renderer logic We believe this is a dangerous choice, and to substantiate the claim, we revisit Chrome’s design and actual implementation for the SOP enforcement Specifically, we find several weaknesses in Chrome’s SOP design against a memory exploit in the renderer pro- cess|,Non-data,96
| We have explored several types of local-machine services that can be subverted if SOP is compromised For instance, we show at- tacks which in several cases (a) create data files with unrestricted file permissions, (b) remotely control virtual machines, (c) install apps on local system, (d) read device sensors such as geolocation and so on Many of these are hard to achieve via the direct renderer- kernel interface For example, files downloaded through Chrome are by default only readable, while the files imported via the Drop- box local folder interface can be executable|,Non-data,96
| After bypassing the SOP enforcement in Chrome, a memory exploit can leverage the web interfaces (websites) of cloud services to indirectly access the local system Bypassing SOP enforcement in Google Chrome In the presence of intra-process protections including internal address space layout randomization (ASLR) [2] and partitioning [27] in Chrome, as well as data execution prevention (DEP) [41] and control-flow integrity (CFI) [39] defenses, it is difficult to exploit memory bugs to change control flows and further bypass SOP in Chrome In contrast, we employ data-oriented attacks to corrupt SOP-related critical data to bypass the SOP enforcement|,Non-data,96
| In Google Chrome, we observe that the renderer process is responsible for performing SOP checks For instance, X-Frame-Options dictates whether a site bcom can be iframed by acom 2|,Non-data,96
| Such a specification is at the discretion of bcom, and its enforcement should ideally be done in the browser kernel (or outside acom’s renderer process) We find several in- stances of such policy enforcement logic that are instead done in the renderer|,Non-data,96
 The consequence of sharing a renderer process between distrusted origins is that all SOP checks must be done by a security monitor within the same process Protecting the security-sensitive state of the SOP-enforcing monitor is a difficult task in the presence of low-level memory corruption bugs We show that memory cor- 2acom loading b,Non-data,96
|com in an iframe ruption vulnerabilities can be used to corrupt the security-critical data in the renderer process to bypass SOP These attacks can tar- get purely non-control data, and do not require any foreign code injection or control flow hijacking That is, they remain agnostic to deployment of DEP and CFI defenses|,Non-data,96
| Chrome employs several best practices to minimize exploits via memory errors Chrome separates its heap memory into different partitions, and deploys ASLR on these partitions with its internal random address generator independent of that in the underlying OS We show that although such defenses are clearly useful, they are insufficient to block SOP bypasses This is because resource ob- jects of one origin can be manipulated to create pointers to objects of other origins|,Non-data,96
|ABSTRACT The surprising success of cryptocurrencies has led to a surge of inter- est in deploying large scale, highly robust, Byzantine fault tolerant (BFT) protocols for mission-critical applications, such as financial transactions Although the conventional wisdom is to build atop a (weakly) synchronous protocol such as PBFT (or a variation thereof), such protocols rely critically on network timing assumptions, and only guarantee liveness when the network behaves as expected We argue these protocols are ill-suited for this deployment scenario We present an alternative, HoneyBadgerBFT, the first practical asynchronous BFT protocol, which guarantees liveness without mak- ing any timing assumptions|,Non-data,97
| We base our solution on a novel atomic broadcast protocol that achieves optimal asymptotic efficiency We present an implementation and experimental results to show our system can achieve throughput of tens of thousands of transactions per second, and scales to over a hundred nodes on a wide area net- work We even conduct BFT experiments over Tor, without needing to tune any parameters Unlike the alternatives, HoneyBadgerBFT simply does not care about the underlying network|,Non-data,97
| 1 INTRODUCTION Distributed fault tolerant protocols are promising solutions for mission-critical infrastructure, such as financial transaction data- bases Traditionally, they have been deployed at relatively small scale, and typically in a single administrative domain where ad- versarial attacks might not be a primary concern As a representa- tive example, a deployment of Google’s fault tolerant lock service, Chubby [14], consists of five nodes, and tolerates up to two crash faults|,Non-data,97
| In recent years, a new embodiment of distributed systems called “cryptocurrencies” or “blockchains” have emerged, beginning with Bitcoin’s phenomenal success [44] Such cryptocurrency systems represent a surprising and effective breakthrough [12], and open a new chapter in our understanding of distributed systems Cryptocurrency systems challenge our traditional belief about the deployment environment for fault tolerance protocols Unlike the classic “5 Chubby nodes within Google” environment, cryptocur- rencies have revealed and stimulated a new demand for consensus protocols over a wide area network, among a large number of nodes Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page|,Non-data,97
| Copyrights for components of this work owned by others than the author(s) must be honored Abstracting with credit is permitted To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acm|,Non-data,97
|org CCS’16, October 24 - 28, 2016, Vienna, Austria © 2016 Copyright held by the owner/author(s) Publication rights licensed to ACM ISBN 978-1-4503-4139-4/16/10|,Non-data,97
   $1500 DOI: http://dx,Non-data,97
|doiorg/101145/29767492978399 that are mutually distrustful, and moreover, network connections can be much more unpredictable than the classical LAN setting, or even adversarial|,Non-data,97
| This new setting poses interesting new challenges, and calls upon us to rethink the design of fault tolerant protocols Robustness is a first-class citizen Cryptocurrencies demonstrate the demand for and viability of an unusual operating point that prior- itizes robustness above all else, even at the expense of performance In fact, Bitcoin provides terrible performance by distributed systems standards: a transaction takes on average 10 minutes to be commit- ted, and the system as a whole achieves throughput on the order of 10 transactions per second|,Non-data,97
| However, in comparison with tradi- tional fault tolerant deployment scenarios, cryptocurrencies thrive in a highly adversarial environment, where well-motivated and mali- cious attacks are expected (if not commonplace) For this reason, many of Bitcoin’s enthusiastic supporters refer to it as the “Honey Badger of Money” [41] We note that the demand for robustness is often closely related to the demand for decentralization — since decentralization would typically require the participation of a large number of diverse participants in a wide-area network Favor throughput over latency|,Non-data,97
| Most existing works on scalable fault tolerance protocols [6, 49] focus on optimizing scalability in a LAN environment controlled by a single administrative domain Since bandwidth provisioning is ample, these works often focus on reducing (cryptographic) computations and minimizing response time while under contention (ie, requests competing for the same object)|,Non-data,97
| In contrast, blockchains have stirred interest in a class of finan- cial applications where response time and contention are not the most critical factors, eg, payment and settlement networks [1] In fact, some financial applications intentionally introduce delays in committing transactions to allow for possible rollback/chargeback operations|,Non-data,97
| Although these applications are not latency critical, banks and financial institutions have expressed interest in a high-throughput alternative of the blockchain technology, to be able to sustain high volumes of requests For example, the Visa processes 2,000 tx/sec on average, with a peak of 59,000 tx/sec [1] 11 Our Contributions Timing assumptions considered harmful|,Non-data,97
| Most existing Byzan- tine fault tolerant (BFT) systems, even those called “robust,” assume some variation of weak synchrony, where, roughly speaking, mes- sages are guaranteed to be delivered after a certain bound ∆, but ∆ may be time-varying or unknown to the protocol designer We argue that protocols based on timing assumptions are unsuitable for decentralized, cryptocurrency settings, where network links can be 31unreliable, network speeds change rapidly, and network delays may even be adversarially induced First, the liveness properties of weakly synchronous protocols can fail completely when the expected timing assumptions are violated (eg|,Non-data,97
|, due to a malicious network adversary) To demonstrate this, we explicitly construct an adversarial “intermittently synchronous” network that violates the assumptions, such that existing weakly synchronous protocols such as PBFT [20] would grind to a halt (Section 3) Second, even when the weak synchrony assumptions are satis- fied in practice, weakly synchronous protocols degrade significantly in throughput when the underlying network is unpredictable Ide- ally, we would like a protocol whose throughput closely tracks the network’s performance even under rapidly changing network conditions|,Non-data,97
| Unfortunately, weakly asynchronous protocols require timeout parameters that are finicky to tune, especially in crypto- currency application settings; and when the chosen timeout values are either too long or too short, throughput can be hampered As a concrete example, we show that even when the weak synchrony assumptions are satisfied, such protocols are slow to recover from transient network partitions (Section 3) Practical asynchronous BFT We propose HoneyBadgerBFT, the first BFT atomic broadcast protocol to provide optimal asymptotic efficiency in the asynchronous setting|,Non-data,97
| We therefore directly refute the prevailing wisdom that such protocols a re necessarily impracti- cal We make significant efficiency improvements on the best prior- known asynchronous atomic broadcast protocol, due to Cachin et al [15], which requires each node to transmit O(N2) bits for each committed transaction, substantially limiting its throughput for all but the smallest networks This inefficiency has two root causes|,Non-data,97
| The first cause is redundant work among the parties However, a naïve attempt to eliminate the redundancy compromises the fairness property, and allows for targeted censorship attacks We invent a novel solution to overcome this problem by using threshold public- key encryption to prevent these attacks The second cause is the use of a suboptimal instantiation of the Asynchronous Common Subset (ACS) subcomponent|,Non-data,97
| We show how to efficiently instantiate ACS by combining existing but overlooked techniques: efficient reliable broadcast using erasure codes [18], and a reduction from ACS to reliable broadcast from the multi-party computation literature [9] HoneyBadgerBFT’s design is optimized for a cryptocurrency- like deployment scenario where network bandwidth is the scarce resource, but computation is relatively ample This allows us to take advantage of cryptographic building blocks (in particular, threshold public-key encryption) that would be considered too expensive in a classical fault-tolerant database setting where the primary goal is to minimize response time even under contention In an asynchronous network, messages are eventually delivered but no other timing assumption is made|,Non-data,97
| Unlike existing weakly synchronous protocols where parameter tuning can be finicky, Hon- eyBadgerBFT does not care Regardless of how network conditions fluctuate, HoneyBadgerBFT’s throughput always closely tracks the network’s available bandwidth Imprecisely speaking, HoneyBad- gerBFT eventually makes progress as long as messages eventually get delivered; moreover, it makes progress as soon as messages are delivered We formally prove the security and liveness of our HoneyBad- gerBFT protocol, and show experimentally that it provides better throughput than the classical PBFT protocol [20] even in the opti- mistic case|,Non-data,97
| Implementation and large-scale experiments We provide a full- fledged implementation of HoneyBadgerBFT, which will we release as free open source software in the near future1 We demonstrate experimental results from an Amazon AWS deployment with more than 100 nodes distributed across 5 continents To demonstrate its versatility and robustness, we also deployed HoneyBadgerBFT over the Tor anonymous relay network without changing any parameters, and present throughput and latency results|,Non-data,97
| 12 Suggested Deployment Scenarios Among numerous conceivable applications, we highlight two likely deployment scenarios that are sought after by banks, financial institutions, and advocates for fully decentralized cryptocurrencies Confederation cryptocurrencies The success of decentralized cryptocurrencies such as Bitcoin has inspired banks and financial institutions to inspect their transaction processing and settlement infrastructure with a new light|,Non-data,97
| “Confederation cryptocurrency” is an oft-cited vision [24, 25, 48], where a conglomerate of financial institutions jointly contribute to a Byzantine agreement protocol to allow fast and robust settlement of transactions Passions are running high that this approach will streamline today’s slow and clunky infrastructure for inter-bank settlement As a result, several new open source projects aim to build a suitable BFT protocol for this setting, such as IBM’s Open Blockchain and the Hyperledger project [40] A confederation cryptocurrency would require a BFT protocol deployed over the wide-area network, possibly involving hundreds to thousands of consensus nodes|,Non-data,97
| In this setting, enrollment can eas- ily be controlled, such that the set of consensus nodes are known a priori — often referred to as the “permissioned” blockchain Clearly HoneyBadgerBFT is a natural candidate for use in such confedera- tion cryptocurrencies Applicability to permissionless blockchains By contrast, decen- tralized cryptocurrencies such as Bitcoin and Ethereum opt for a “permissionless” blockchain, where enrollment is open to anyone, and nodes may join and leave dynamically and frequently|,Non-data,97
| To achieve security in this setting, known consensus protocols rely on proofs-of-work to defeat Sybil attacks, and pay an enormous price in terms of throughput and latency, eg, Bitcoin commits transac- tions every ∼ 10 min, and its throughput limited by 7 tx/sec even when the current block size is maximized Several recent works have suggested the promising idea of leveraging either a slower, external blockchain such as Bitcoin or economic “proof-of-stake” assumptions involving the underlying currency itself [32, 32, 35, 37] to bootstrap faster BFT protocols, by selecting a random committee to perform BFT in every different epoch|,Non-data,97
| These approaches promise to achieve the best of both worlds, security in an open enrollment, decentralized network, and the throughput and response time match- ing classical BFT protocols Here too HoneyBadgerBFT is a natural choice since the randomly selected committee can be geographically heterogeneous 2 BACKGROUND AND RELATED WORK Our overall goal is to build a replicated state machine, where clients generate and submit transactions and a network of nodes receives and processes them|,Non-data,97
| Abstracting away from application specific details (such as how to represent state and compute tran- sitions), it suffices to build a totally globally-consistent, totally- ordered, append-only transaction log Traditionally, such a primitive is called total order or atomic broadcast [23]; in Bitcoin parlance, we would call it a blockchain 1https://githubcom/amiller/HoneyBadgerBFT 32Fault tolerant state machine replication protocols provide strong safety and liveness guarantees, allowing a distributed system to provide correct service in spite of network latency and the failure of some nodes|,Non-data,97
| A vast body of work has studied such protocols, offering different performance tradeoffs, tolerating different forms of failures and attacks, and making varying assumptions about the underlying network We explain below the most closely related efforts to ours 21 Robust BFT Protocols While Paxos [36], Raft [46], and many other well-known proto- cols tolerate crash faults, Byzantine fault tolerant protocols (BFT), beginning with PBFT [20], tolerate even arbitrary (e|,Non-data,97
|g, maliciously) corrupted nodes Many subsequent protocols offer improved perfor- mance, often through optimistic execution that provides excellent performance when there are no faults, clients do not contend much, and the network is well-behaved, and at least some progress other- wise [2, 5, 33, 39, 51] In general, BFT systems are evaluated in deployment scenarios where latency and CPU are the bottleneck [49], thus the most effec- tive protocols reduce the number of rounds and minimize expensive cryptographic operations|,Non-data,97
| Clement et al [22] initiated a recent line of work [4, 6, 10, 21, 22, 50] by advocating improvement of the worst-case performance, providing service quality guarantees even when the system is under attack — even if this comes at the expense of performance in the optimistic case However, although the “Robust BFT” protocols in this vein gracefully tolerate compromised nodes, they still rely on timing assumptions about the underlying network Our work takes this approach further, guaranteeing good throughput even in a fully asynchronous network|,Non-data,97
| 22 Randomized Agreement Deterministic asynchronous protocols are impossible for most tasks [27] While the vast majority of practical BFT protocols steer clear of this impossibility result by making timing assumptions, ran- domness (and, in particular, cryptography) provides an alternative route Indeed we know of asynchronous BFT protocols for a variety of tasks such as binary agreement (ABA), reliable broadcast (RBC), and more [13, 15, 16]|,Non-data,97
| Our work is most closely related to SINTRA [17], a system im- plementation based on the asynchronous atomic broadcast protocol from Cachin et al (CKPS01) [15] This protocol consists of a re- duction from atomic broadcast (ABC) to common subset agreement (ACS), as well as a reduction from ACS to multi-value validated agreement (MVBA) The key invention we contribute is a novel reduction from ABC to ACS that provides better efficiency (by an O(N) factor) through batching, while using threshold encryption to preserve censorship resilience (see Section 4|,Non-data,97
|4) We also obtain better efficiency by cherry-picking from the literature improved instantiations of sub- components In particular, we sidestep the expensive MVBA primi- tive by using an alternative ACS [9] along with an efficient RBC [18] as explained in Section 44|,Non-data,97
 Table 1 summarizes the asymptotic performance of HoneyBad- gerBFT with several other atomic broadcast protocols Here “Comm compl” denotes the expected communication complexity (i,Non-data,97
|e, total bytes transferred) per committed transaction Since PBFT relies on weak synchrony assumptions, it may therefore fail to make progress at all in an asynchronous network Protocols KS02 [34] and RC05 [47] are optimistic, falling back to an expensive recovery mode based on MVBA|,Non-data,97
| As mentioned the protocol of Cachin et al (CKPS01) [15] can be improved using a more efficient ACS Table 1: Asymptotic communication complexity (bits per trans- action, expected) for atomic broadcast protocols PBFT no KS02 [34] yes RC05 [47] yes CKPS01 [15] yes CKPS01 [15]+ [9, 18] yes HoneyBadgerBFT (this work) yes Async? Comm compl Optim|,Non-data,97
| Worst O(N) ∞ O(N2) O(N3) O(N) O(N3) O(N3) O(N3) O(N2) O(N2) O(N) O(N) construction [9, 18] We also obtain another O(N) improvement through our novel reduction Finally, King and Saia [30,31] have recently developed agreement protocols with less-than-quadratic number of messages by routing communications over a sparse graph However, extending these results to the asynchronous setting remains an open problem|,Non-data,97
| 3 THE GAP BETWEEN ASYNCHRONOUS AND WEAKLY SYNCHRONOUS NET- WORK MODELS Almost all modern BFT protocols rely on timing assumptions (such as partial or weak synchrony) to guarantee liveness Purely asynchronous BFT protocols have received considerably less atten- tion in recent years Consider the following argument, which, if it held, would justify this narrowed focus: [X] Weak synchrony assumptions are unavoidable, since in any network that violates these assumptions, even asynchronous protocols would provide unacceptable performance|,Non-data,97
| In this section, we present make two counterarguments that refute the premise above First, we illustrate the theoretical separation between the asynchronous and weakly synchronous network models Specifically we construct an adversarial network scheduler that violates PBFT’s weak synchrony assumption (and indeed causes it to fail) but under which any purely asynchronous protocol (such as HoneyBadgerBFT) makes good progress Second, we make a practical observation: even when their assumptions are met, weakly synchronous protocols are slow to recover from a network partition once it heals, whereas asynchronous protocols make progress as soon as messages are delivered|,Non-data,97
| 31 Many Forms of Timing Assumptions Before proceeding we review the various standard forms of tim- ing assumptions In an asynchronous network, the adversary can deliver messages in any order and at any time, but nonetheless must eventually deliver every message sent between correct nodes Nodes in an asynchronous network effectively have no use for “real time” clocks, and can only take actions based on the ordering of messages they receive|,Non-data,97
 The well-known FLP [27] result rules out the possibility of de- terministic asynchronous protocols for atomic broadcast and many other tasks A deterministic protocol must therefore make some stronger timing assumptions A convenient (but very strong) net- work assumption is synchrony: a ∆-synchronous network guarantees that every message sent is delivered after at most a delay of ∆ (where ∆ is a measure of real time) Weaker timing assumptions come in several forms,Non-data,97
| In the un- known-∆ model, the protocol is unable to use the delay bound as a parameter Alternatively, in the eventually synchronous model, the message delay bound ∆ is only guaranteed to hold after some (unknown) instant, called the “Global Stabilization Time” Collec- tively, these two models are referred to as partial synchrony [26] 33Yet another variation is weak synchrony [26], in which the delay bound is time varying, but eventually does not grow faster than a polynomial function of time [20]|,Non-data,97
| In terms of feasibility, the above are equivalent — a protocol that succeeds in one setting can be systematically adapted for another In terms of concrete performance, however, adjusting for weak syn- chrony means gradually increasing the timeout parameter over time (eg, by an “exponential back-off” policy)|,Non-data,97
| As we show later, this results in delays when recovering from transient network partitions Protocols typically manifest these assumptions in the form of a timeout event For example, if parties detect that no progress has been made within a certain interval, then they take a corrective action such as electing a new leader Asynchronous protocols do not rely on timers, and make progress whenever messages are delivered, regardless of actual clock time|,Non-data,97
| Counting rounds in asynchronous networks Although the guar- antee of eventual delivery is decoupled from notions of “real time,” it is nonetheless desirable to characterize the running time of asynch- ronous protocols The standard approach (eg|,Non-data,97
|, as explained by Canetti and Rabin [19]) is for the adversary to assign each mes- sage a virtual round number, subject to the condition that every (r − 1)-message between correct nodes must be delivered before any (r + 1)-message is sent 32 When Weak Synchrony Fails We now proceed to describe why weakly synchronous BFT proto- cols can fail (or suffer from performance degradation) when network conditions are adversarial (or unpredictable) This motivates why such protocols are unsuited for the cryptocurrency-oriented applica- tion scenarios described in Section 1|,Non-data,97
| A network scheduler that thwarts PBFT We use Practical Byzan- tine Fault Tolerance (PBFT) [20], the classic leader-based BFT protocol, a representative example to describe how an adversarial network scheduler can cause a class of leader-based BFT proto- cols [4, 6, 10, 22, 33, 50] to grind to a halt At any given time, the designated leader is responsible for propos- ing the next batch of transactions If progress isn’t made, either because the leader is faulty or because the network has stalled, then the nodes attempt to elect a new leader|,Non-data,97
| The PBFT protocol critically relies on a weakly synchronous network for liveness We construct an adversarial scheduler that violates this assumption, and indeed prevents PBFT from making any progress at all, but for which Hon- eyBadgerBFT (and, in fact, any asynchronous protocol) performs well It is unsurprising that a protocol based on timing assumptions fails when those assumptions are violated; however, demonstrating an explicit attack helps motivate our asynchronous construction The intuition behind our scheduler is simple|,Non-data,97
| First, we assume that a single node has crashed Then, the network delays messages whenever a correct node is the leader, preventing progress and causing the next node in round-robin order to become the new leader When the crashed node is the next up to become the leader, the scheduler immediately heals the network partition and delivers messages very rapidly among the honest nodes; however, since the leader has crashed, no progress is made here either This attack violates the weak synchrony assumption because it must delay messages for longer and longer each cycle, since PBFT widens its timeout interval after each failed leader election|,Non-data,97
| On the other hand, it provides larger and larger periods of synchrony as well However, since these periods of synchrony occur at inconvenient times, PBFT is unable to make use of them Looking ahead, Honey- BadgerBFT, and indeed any asynchronous protocol, would be able to make progress during these opportunistic periods of synchrony To confirm our analysis, we implemented this malicious scheduler as a proxy that intercepted and delayed all view change messages to the new leader, and tested it against a 1200 line Python imple- mentation of PBFT|,Non-data,97
| The results and message logs we observed were consistent with the above analysis; our replicas became stuck in a loop requesting view changes that never succeeded In the on- line full version [42] we give a complete description of PBFT and explain how it behaves under this attack Slow recovery from network partitions Even if the weak syn- chrony assumption is eventually satisfied, protocols that rely on it may also be slow to recover from transient network partitions|,Non-data,97
| Consider the following scenario, which is simply a finite prefix of the attack described above: one node is crashed, and the network is temporarily partitioned for a duration of 2D∆ Our scheduler heals the network partition precisely when it is the crashed node’s turn to become leader Since the timeout interval at this point is now 2D+1∆, the protocol must wait for another 2D+1∆ interval before beginning to elect a new leader, despite that the network is synchronous during this interval The tradeoff between robustness and responsiveness|,Non-data,97
| Such be- haviors we observe above are not specific to PBFT, but rather are fundamentally inherent to protocols that rely on timeouts to cope with crashes Regardless of the protocol variant, a practitioner must tune their timeout policy according to some tradeoff At one extreme (eventual synchrony), the practitioner makes a specific esti- mate about the network delay ∆ If the estimate is too low, then the system may make no progress at all; too high, and it does not utilize the available bandwidth|,Non-data,97
| At the other extreme (weak synchrony), the practitioner avoids specifying any absolute delay, but nonetheless must choose a “gain” that affects how quickly the system tracks varying conditions An asynchronous protocol avoids the need to tune such parameters 4 THE HoneyBadgerBFT PROTOCOL In this section we present HoneyBadgerBFT, the first asynch- ronous atomic broadcast protocol to achieve optimal asymptotic efficiency|,Non-data,97
| 41 Problem Definition: Atomic Broadcast We first define our network model and the atomic broadcast prob- lem Our setting involves a network of N designated nodes, with distinct well-known identities (P0 through PN−1) The nodes re- ceive transactions as input, and their goal is to reach common agree- ment on an ordering of these transactions|,Non-data,97
| Our model particularly matches the deployment scenario of a “permissioned blockchain” where transactions can be submitted by arbitrary clients, but the nodes responsible for carrying out the protocol are fixed The atomic broadcast primitive allows us to abstract away any application-specific details, such as how transactions are to be inter- preted (to prevent replay attacks, for example, an application might define a transaction to include signatures and sequence numbers) For our purposes, transactions are simply unique strings In prac- tice, clients would generate transactions and send them to all of the nodes, and consider them committed after collecting signatures from a majority of nodes|,Non-data,97
| To simplify our presentation, we do not explicitly model clients, but rather assume that transactions are cho- sen by the adversary and provided as input to the nodes Likewise, a transaction is considered committed once it is output by a node • (Purely asynchronous network) We assume each pair of nodes is connected by a reliable authenticated point-to-point channel Our system model makes the following assumptions: 34that does not drop messages2 The delivery schedule is entirely determined by the adversary, but every message sent between correct nodes must eventually be delivered|,Non-data,97
| We will be inter- ested in characterizing the running time of protocols based on the number of asynchronous rounds (as described in Section 2) As the network may queue messages with arbitrary delay, we also assume nodes have unbounded buffers and are able to process all the messages they receive • (Static Byzantine faults) The adversary is given complete control of up to f faulty nodes, where f is a protocol parameter Note that 3 f + 1 ≤ N (which our protocol achieves) is the lower bound for broadcast protocols in this setting|,Non-data,97
| • (Trusted setup) For ease of presentation, we assume that nodes may interact with a trusted dealer during an initial protocol- specific setup phase, which we will use to establish public keys and secret shares Note that in a real deployment, if an actual trusted party is unavailable, then a distributed key generation protocol could be used instead (cf, Boldyreva [11])|,Non-data,97
| All the distributed key generation protocols we know of rely on timing assumptions; fortunately these assumptions need only to hold during setup DEFINITION 1 An atomic broadcast protocol must satisfy the following properties, all of which should hold with high probabil- ity (as a function 1 − negl(λ ) of a security parameter, λ ) in an asynchronous network and in spite of an arbitrary adversary: • (Agreement) If any correct node outputs a transaction tx, then • (Total Order) If one correct node has output the sequence of trans- every correct node outputs tx output actions 0, tx(cid:48) (cid:104)tx(cid:48) 1, |,Non-data,97
|tx(cid:48) (cid:104)tx0, tx1, |,Non-data,97
|tx j(cid:105) and has i for i ≤ min( j, j(cid:48)) j(cid:48)(cid:105), then txi = tx(cid:48) another • (Censorship Resilience) If a transaction tx is input to N− f correct nodes, then it is eventually output by every correct node The censorship resilience property is a liveness property that prevents an adversary from blocking even a single transaction from being committed|,Non-data,97
| This property has been referred to by other names, for example “fairness” by Cachin et al [15], but we prefer this more descriptive phrase Performance metrics We will primarily be interested in analyzing the efficiency and transaction delay of our atomic broadcast protocol|,Non-data,97
| • (Efficiency) Assume that the input buffers of each honest node are sufficiently full Ω(poly(N,λ )) Then efficiency is the expected communication cost for each node amortized over all committed transactions Since each node must output each transaction, O(1) efficiency (which our protocol achieves) is asymptotically optimal The above definition of efficiency assumes the network is under load, reflecting our primary goal: to sustain high throughput while fully utilizing the network’s available bandwidth|,Non-data,97
| Since we achieve good through- put by batching, our system uses more bandwidth per committed transaction during periods of low demand when transactions ar- rive infrequently A stronger definition without this qualification would be appropriate if our goal was to minimize costs (eg, for usage-based billing)|,Non-data,97
| In practice, network links have limited capacity, and if more transactions are submitted than the network can handle, a guarantee on confirmation time cannot hold in general Therefore we define transaction delay below relative to the number of transactions that 2Reliable channels can be emulated on top of unreliable channels by resending transmissions, at the expense of some efficiency have been input ahead of the transaction in question A finite transaction delay implies censorship resilience|,Non-data,97
| • (Transaction delay) Suppose an adversary passes a transaction tx as input to N − f correct nodes Let T be the “backlog”, ie the difference between the total number of transactions previously input to any correct node and the number of transactions that have been committed|,Non-data,97
| Then transaction delay is the expected number of asynchronous rounds before tx is output by every correct node as a function of T  42 Overview and Intuition In HoneyBadgerBFT, nodes receive transactions as input and store them in their (unbounded) buffers The protocol proceeds in epochs, where after each epoch, a new batch of transactions is appended to the committed log|,Non-data,97
| At the beginning of each epoch, nodes choose a subset of the transactions in their buffer (by a policy we will define shortly), and provide them as input to an instance of a randomized agreement protocol At the end of the agreement protocol, the final set of transactions for this epoch is chosen At this high level, our approach is similar to existing asynch- ronous atomic broadcast protocols, and in particular to Cachin et al [15], the basis for a large scale transaction processing sys- tem (SINTRA)|,Non-data,97
| Like ours, Cachin’s protocol is centered around an instance of the Asynchronous Common Subset (ACS) primitive Roughly speaking, the ACS primitive allows each node to propose a value, and guarantees that every node outputs a common vector containing the input values of at least N − 2 f correct nodes It is trivial to build atomic broadcast from this primitive — each node simply proposes a subset of transactions from the front its queue, and outputs the union of the elements in the agreed-upon vector However, there are two important challenges|,Non-data,97
| Challenge 1: Achieving censorship resilience The cost of ACS depends directly on size of the transaction sets proposed by each node Since the output vector contains at least N − f such sets, we can therefore improve the overall efficiency by ensuring that nodes propose mostly disjoint sets of transactions, thus committing more distinct transactions in one batch for the same cost Therefore instead of simply choosing the first element(s) from its buffer (as in CKPS01 [15]), each node in our protocol proposes a randomly chosen sample, such that each transaction is, on average, proposed by only one node|,Non-data,97
| However, implemented naïvely, this optimization would compro- mise censorship resilience, since the ACS primitive allows the adver- sary to choose which nodes’ proposals are ultimately included The adversary could selectively censor a transaction excluding whichever node(s) propose it We avoid this pitfall by using threshold encryp- tion, which prevents the adversary from learning which transac- tions are proposed by which nodes, until after agreement is already reached The full protocol will be described in Section 4|,Non-data,97
|3 Challenge 2: Practical throughput Although the theoretical feasibility of asynchronous ACS and atomic broadcast have been known [9, 15, 17], their practical performance is not To the best of our knowledge, the only other work that implemented ACS was by Cachin and Portiz [17], who showed that they could attain a through- put of 0|,Non-data,97
|4 tx/sec over a wide area network Therefore, an interesting question is whether such protocols can attain high throughput in practice In this paper, we show that by stitching together a carefully chosen array of sub-components, we can efficiently instantiate ACS and attain much greater throughput both asymptotically and in practice Notably, we improve the asymptotic cost (per node) of ACS from O(N2) (as in Cachin et al|,Non-data,97
| [15, 17]) to O(1) Since the components 35we cherry-pick have not been presented together before (to our knowledge), we provide a self-contained description of the whole construction in Section 44 Modular protocol composition|,Non-data,97
| We are now ready to present our constructions formally Before doing so, we make a remark about the style of our presentation We define our protocols in a modu- lar style, where each protocol may run several instances of other (sub)protocols The outer protocol can provide input to and re- ceive output from the subprotocol|,Non-data,97
| A node may begin executing a (sub)protocol even before providing it input (eg, if it receives messages from other nodes) It is essential to isolate such (sub)protocol instances to ensure that messages pertaining to one instance cannot be replayed in another|,Non-data,97
| This is achieved in practice by associating to each (sub)protocol instance a unique string (a session identifier), tagging any messages sent or received in this (sub)protocol with this identifier, and routing messages accordingly We suppress these message tags in our proto- col descriptions for ease of reading We use brackets to distinguish between tagged instances of a subprotocol For example, RBC[i] denotes an ith instance of the RBC subprotocol|,Non-data,97
| We implicitly assume that asynchronous communications be- tween parties are over authenticated asynchronous channels In reality, such channels could be instantiated using TLS sockets, for example, as we discuss in Section 5 To distinguish different message types sent between parties within a protocol, we use a label in typewriter font (eg|,Non-data,97
|, VAL(m) indi- cates a message m of type VAL) 43 Constructing HoneyBadgerBFT from Asynchronous Common Subset Building block: ACS Our main building block is a primitive called asynchronous common subset (ACS)|,Non-data,97
| The theoretical feasibility of constructing ACS has been demonstrated in several works [9, 15] In this section, we will present the formal definition of ACS and use it as a blackbox to construct HoneyBadgerBFT Later in Section 44, we will show that by combining several constructions that were somewhat overlooked in the past, we can instantiate ACS efficiently! More formally, an ACS protocol satisfies the following properties: • (Validity) If a correct node outputs a set v, then ||v|| ≥ N − f and v contains the inputs of at least N − 2 f correct nodes|,Non-data,97
| • (Agreement) If a correct node outputs v, then every node outputs • (Totality) If N − f correct nodes receive an input, then all correct v nodes produce an output Building block: threshold encryption A threshold encryption scheme TPKE is a cryptographic primitive that allows any party to encrypt a message to a master public key, such that the network nodes must work together to decrypt it|,Non-data,97
| Once f + 1 correct nodes compute and reveal decryption shares for a ciphertext, the plain- text can be recovered; until at least one correct node reveals its decryption share, the attacker learns nothing about the plaintext A threshold scheme provides the following interface: • TPKESetup(1λ ) → PK,{SKi} generates a public encryption • TPKEEnc(PK,m) → C encrypts a message m • TPKE|,Non-data,97
|DecShare(SKi,C) → σi produces the ith share of the de- cryption (or ⊥ if C is malformed) • TPKEDec(PK,C,{i,σi}) → m combines a set of decryption shares {i,σi} from at least f + 1 parties obtain the plaintext m (or, if C contains invalid shares, then the invalid shares are identified) key PK, along with secret keys for each party SKi In our concrete instantiation, we use the threshold encryption scheme of Baek and Zheng [7] This scheme is also robust (as required by our protocol), which means that even for an adversarially generated ciphertext C, at most one plaintext (besides ⊥) can be recovered|,Non-data,97
| Note that we assume TPKEDec effectively identifies invalid de- cryption shares among the inputs Finally, the scheme satisfies the obvious correctness properties, as well as a threshold version of the IND-CPA game3 Atomic broadcast from ACS|,Non-data,97
| We now describe in more detail our atomic broadcast protocol, defined in Figure 1 As mentioned, this protocol is centered around an instance of ACS In order to obtain scalable efficiency, we choose a batching policy We let B be a batch size, and will commit Ω(B) transactions in each epoch|,Non-data,97
| Each node proposes B/N transactions from its queue To ensure that nodes propose mostly distinct transactions, we randomly select these transactions from the first B in each queue As we will see in Section 44, our ACS instantiation has a total communication cost of O(N2||v|| + λ N3 logN), where ||v|| bounds the size of any node’s input|,Non-data,97
| We therefore choose a batch size B = Ω(λ N2 logN) so that the contribution from each node (B/N) absorbs this additive overhead In order to prevent the adversary from influencing the outcome we use a threshold encryption scheme, as described below In a nutshell, each node chooses a set of transactions, and then encrypts it Each node then passes the encryption as input to the ACS subroutine|,Non-data,97
 The output of ACS is therefore a vector of ciphertexts The ciphertexts are decrypted once the ACS is complete This guarantees that the set of transactions is fully determined before the adversary learns the particular contents of the proposals made by each node This guarantees that an adversary cannot selectively prevent a transaction from being committed once it is in the front of the queue at enough correct nodes,Non-data,97
| 44 Instantiating ACS Efficiently Cachin et al present a protocol we call CKPS01 that (implic- itly) reduces ACS to multi-valued validated Byzantine agreement (MVBA) [15] Roughly speaking, MVBA allows nodes to propose values satisfying a predicate, one of which is ultimately chosen|,Non-data,97
| The reduction is simple: the validation predicate says that the output must be a vector of signed inputs from at least N − f parties Un- fortunately, the MVBA primitive agreement becomes a bottleneck, because the only construction we know of incurs an overhead of O(N3||v||) We avoid this bottleneck by using an alternative instantiation of ACS that sidesteps MVBA entirely The instantiation we use is due to Ben-Or et al|,Non-data,97
| [9] and has, in our view, been somewhat overlooked In fact, it predates CKPS01 [15], and was initially developed for a mostly unrelated purpose (as a tool for achieving efficient asynch- ronous multi-party computation [9]) This protocol is a reduction from ACS to reliable broadcast (RBC) and asynchronous binary Byzantine agreement (ABA) Only recently do we know of efficient constructions for these subcomponents, which we explain shortly|,Non-data,97
| At a high level, the ACS protocol proceeds in two main phases In the first phase, each node Pi uses RBC to disseminate its proposed value to the other nodes, followed by ABA to decide on a bit vector that indicates which RBCs have successfully completed We now briefly explain the RBC and ABA constructions before explaing the Ben-Or protocol in more detail 3The Baek and Zheng threshold scheme also satisfies (the threshold equivalent of) the stronger IND-CCA game, but this is not required by our protocol|,Non-data,97
| 36Algorithm HoneyBadgerBFT (for node Pi) Let B = Ω(λ N2 logN) be the batch size parameter Let PK be the public key received from TPKESetup (executed by a dealer), and let SKi be the secret key for Pi Let buf := [ ] be a FIFO queue of input transactions|,Non-data,97
| Proceed in consecutive epochs numbered r: // Step 1: Random selection and encryption • let proposed be a random selection of (cid:98)B/N(cid:99) transactions from • encrypt x := TPKEEnc(PK, proposed) the first B elements of buf // Step 2: Agreement on ciphertexts • pass x as input to ACS[r] //see Figure 4 • receive {v j} j∈S, where S ⊂ [1N], from ACS[r] // Step 3: Decryption • for each j ∈ S: let e j := TPKE|,Non-data,97
|DecShare(SKi,v j) multicast DEC(r, j,i,e j) wait DEC(r, j,k,e j,k) decode y j := TPKEDec(PK,{(k,e j,k)}) to receive at least f + 1 messages of the form • let blockr := sorted(∪ j∈S{y j}), such that blockr is sorted in a • set buf := buf − blockr canonical order (eg, lexicographically) Figure 1: HoneyBadgerBFT|,Non-data,97
| Communication-optimal reliable roadcast An asynchronous re- liable broadcast channel satisfies the following properties: • (Agreement) If any two correct nodes deliver v and v(cid:48), then v = v(cid:48) • (Totality) If any correct node delivers v, then all correct nodes • (Validity) If the sender is correct and inputs v, then all correct deliver v nodes deliver v While Bracha’s [13] classic reliable broadcast protocol requires O(N2||v||) bits of total communication in order to broadcast a mes- sage of size ||v||, Cachin and Tessaro [18] observed that erasure cod- ing can reduce this cost to merely O(N||v|| + λ N2 logN), even in the worst case This is a significant improvement for large messages (i|,Non-data,97
|e, when ||v|| (cid:29) λ N logN), which, (looking back to Section 43) guides our choice of batch size The use of erasure coding here induces at most a small constant factor of overhead, equal to N N−2 f < 3|,Non-data,97
| If the sender is correct, the total running time is three (asynch- ronous) rounds; and in any case, at most two rounds elapse between when the first correct node outputs a value and the last outputs a value The reliable broadcast algorithm shown in Figure 2 Binary Agreement Binary agreement is a standard primitive that allows nodes to agree on the value of a single bit|,Non-data,97
| More formally, binary agreement guarantees three properties: • (Agreement) If any correct node outputs the bit b, then every • (Termination) If all correct nodes receive input, then every correct • (Validity) If any correct node outputs b, then at least one correct correct node outputs b node outputs a bit node received b as input The validity property implies unanimity: if all of the correct nodes receive the same input value b, then b must be the decided value|,Non-data,97
| On the other hand, if at any point two nodes receive different inputs, Algorthm RBC (for party Pi, with sender PSender) • upon input(v) (if Pi = PSender): let {s j} j∈[N] be the blocks of an (N − 2 f ,N)-erasure coding scheme applied to v let h be a Merkle tree root computed over {s j} send VAL(h,b j,s j) to each party P j, where b j is the jth Merkle tree branch • upon receiving VAL(h,bi,si) from PSender, • upon receiving ECHO(h,b j,s j) from party P j, multicast ECHO(h,bi,si) check that b j is a valid Merkle branch for root h and leaf s j, and otherwise discard • upon receiving valid ECHO(h,·,·) messages from N − f distinct parties, – interpolate {s(cid:48) j} from any N − 2 f leaves received – recompute Merkle root h(cid:48) and if h(cid:48) (cid:54)= h then abort – if READY(h) has not yet been sent, multicast READY(h) • upon receiving f + 1 matching READY(h) messages, if READY • upon receiving 2 f + 1 matching READY(h) messages, wait for has not yet been sent, multicast READY(h) N − 2 f ECHO messages, then decode v Figure 2: Reliable broadcast algorithm, adapted from Bracha’s broadcast [13], with erasure codes to improve efficiency [18] then the adversary may force the decision to either value even before the remaining nodes receive input We instantiate this primitive with a protocol from Moustefaoui et al [43], which is based on a cryptographic common coin We defer explanation of this instantiation to the online full version [42]|,Non-data,97
| Its expected running time is O(1), and in fact completes within O(k) rounds with probability 1− 2−k The communication complexity per node is O(Nλ ), which is due primarily to threshold cryptography used in the common coin Agreeing on a subset of proposed values Putting the above pieces together, we use a protocol from Ben-Or et al|,Non-data,97
| [9] to agree on a set of values containing the entire proposals of at least N − f nodes At a high level, this protocol proceeds in two main phases In the first phase, each node Pi uses Reliable Broadcast to disseminate its proposed value to the other nodes In the second stage, N concurrent instances of binary Byzantine agreement are used to agree on a bit vector {b j} j∈[1|,Non-data,97
|N], where b j = 1 indicates that P j’s proposed value is included in the final set Actually the simple description above conceals a subtle challenge, for which Ben-Or provide a clever solution A naïve attempt at an implementation of the above sketch would have each node to wait for the first (N − f ) broadcasts to complete, and then propose 1 for the binary agreement instances corresponding to those and 0 for all the others|,Non-data,97
| However, correct nodes might observe the broadcasts complete in a different order Since binary agreement only guarantees that the output is 1 if all the correct nodes unaninimously propose 1, it is possible that the resulting bit vector could be empty To avoid this problem, nodes abstain from proposing 0 until they are certain that the final vector will have at least N − f bits set To provide some intuition for the flow of this protocol, we narrate several possible scenarios in Figure 3|,Non-data,97
| The algorithm from Ben-Or et al [9] is given in Figure 4 The running time is O(logN) in expectation, since it must wait for all binary agreement instances to 37PROOF These two properties follow immediately from proper- ties of the high-level protoocls, ACS and TPKE|,Non-data,97
 Each ACS instance guarantees that nodes agree on a vector of ciphertexts in each epoch (Step 2) The robustness of TPKE guarantees that each correct node decrypts these ciphertexts to consistent values (Step 3) This suffices to ensure agreement and total order THEOREM 2,Non-data,97
| (Complexity) Assuming a batch size of B = Ω(λ N2 logN), the running time for each HoneyBadgerBFT epoch is O(logN) in expectation, and the total expected communication complexity is O(B) PROOF The cost and running time of ACS is explained in Sec- tion 4|,Non-data,97
|4 The N instances of threshold decryption incur one ad- ditional round and an additional cost of O(λ N2), which does not affect the overall asymptotic cost The HoneyBadgerBFT protocol may commit up to B transactions in a single epoch However, the actual number may be less than this, since some correct nodes may propose overlapping transaction sets, others may respond too late, and corrupted nodes may propose an empty set|,Non-data,97
| Fortunately, we prove (in the online full version [42]) that assuming each correct node’s queue is full, then B/4 serves as an lower bound for the expected number of transactions committed in an epoch5 THEOREM 3 (Efficiency) Assuming each correct node’s queue contains at least B distinct transactions, then the expected number of transactions committed in an epoch is at least B 4 , resulting in constant efficiency|,Non-data,97
| Finally, we prove (in the online full version [42]) that the ad- versary cannot significantly delay the commit of any transaction THEOREM 4 (Censorship Resilience) Suppose an adversary passes a transaction tx as input to N − f correct nodes|,Non-data,97
| Let T be the size of the “backlog”, ie the difference between the total number of transactions previously input to any correct node and the number of transactions that have been committed Then tx is commited within O(T /B + λ ) epochs except with negligible probability|,Non-data,97
| 5 IMPLEMENTATION AND EVALUATION In this section we carry out several experiments and performance measurements using a prototype implementation of the HoneyBad- gerBFT protocol Unless otherwise noted, numbers reported in this section are by default for the optimistic case where all nodes are behaving honestly First we demonstrate that HoneyBadgerBFT is indeed scalable by performing an experiment in a wide area network, including up to 104 nodes in five continents|,Non-data,97
| Even under these conditions, Honey- BadgerBFT can reach peak throughputs of thousands of transactions per second Furthermore, by a comparison with PBFT, a represen- tative partially synchronous protocol, HoneyBadgerBFT performs only a small constant factor worse Finally, we demonstrate the feasibility of running asynchronous BFT over the Tor anonymous communication layer Implementation details|,Non-data,97
| We developed a prototype implementa- tion of HoneyBadgerBFT in Python, using the gevent library for concurrent tasks 5The actual bound is (1− e−1/3)B > B/4, but we use the looser bound B/4 for readability Figure 3: (Illustrated examples of ACS executions) Each exe- cution of our protocol involves running N concurrent instances of reliable broadcast (RBC), as well as N of byzantine agree- ment (BA), which in turn use an expected constant number of common coins|,Non-data,97
| We illustrate several possible examples of how these instances play out, from the viewpoint of Node 0 (a) In the ordinary case, Node 0 receives value V1 (Node 1’s proposed value) from the reliable broadcast at index 1 Node 0 therefore provides input “Yes” to BA1, which outputs “Yes” (b) RBC2 takes too long to complete, and Node 0 has already received (N− f ) “Yes” outputs, so it votes “No” for BA2|,Non-data,97
| However, other nodes have seen RBC2 complete successfully, so BA2 results in “Yes” and Node 0 must wait for V2 (c) BA3 concludes with “No” before RBC3 completes finish 4 When instantiated with the reliable broadcast and binary agreement constructions described above, the total communication complexity is O(N2||v|| + λ N3 logN) assuming ||v|| is the largest size of any node’s input|,Non-data,97
