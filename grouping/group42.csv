 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
|e, users wishing only to spend and receive bitcoins) from having to store and ver- ify the entire Bitcoin blockchain, which as of this writing is over 80GB4 To go even further, we argue that if one is will- ing to adopt a distributed rather than a fully decentralized solution (ie|,Non-data,103
|, if one is willing to trust any set of named par- ties), then the entire Bitcoin system collapses into a CT-like 4https://blockchaininfo/charts/blocks-size 177/ / o o o o / / o o transparency overlay and the need for hash-based mining is eliminated 61 A transparency overlay for Bitcoin As depicted in Section 2, Bitcoin has three actors in the system Sys: a sender Sender, a receiver Receiver, and a miner Miner|,Non-data,103
| The sender and the miner must participate in the Log protocol to enter transactions into the log (although really this can be done by only the miner, after it has collected all relevant transactions), and the receiver participates in the CheckEntry protocol to check that the transaction in which it should be receiving bitcoins is in the log Our trans- parency overlay for Bitcoin then instantiates GenEventSet as follows: Receiver Sender(tx) Miner(headold, hgt, txset) return ε return ε tx txset ← txset ∪ {tx} head r←− Mine(headold, txset) return (head, hgt, txset) An event is a transaction tx, which must have a certain structure (ie, lists of input and output addresses) and sat- isfy certain requirements (i|,Non-data,103
|e, that is does not represent double-spending) A set of events eventset is a block, which contains not only a list of transactions txset but also a hash head, a pointer headprev to the previous block, and a height hgt; combining events in an event set also allows us to impose the required notion of timing, which is the block height hgt By combining GenEventSet with the modified protocols de- scribed in Section 4|,Non-data,103
|4, we can thus apply Theorem 44 to get a secure basic transparency overlay in the setting of Bitcoin 62 Further security implications By applying a transparency overlay to Bitcoin, we have provided a method for achieving provable transparency guar- antees in this setting|,Non-data,103
| We have also achieved (in a manner similarly observed by Miller et al [27], although they did not provide any security guarantees) a much more efficient version of the system: senders and receivers now store noth- ing (or, if the auditor collapses into the users as discussed in Section 53 for CT, they store a snapshot), as compared to the entire blockchain or set of block headers that they were required to store previously While this goal was of course already achievable by Bitcoin senders and receivers using web solutions (i|,Non-data,103
|e, storing their bitcoins in an online wallet), our system is the first to achieve this goal with any provable security guarantees, thus minimizing the trust that such users must place in any third party Our analysis also has implications beyond users’ storage of the blockchain To go beyond our initial attempt at an over- lay (which we dub the “na ̈ıve overlay” in Table 1), one might observe that the miner provides no additional value beyond that of the log server: whereas in CT the CA was necessary to provide a signature (and more generally is assumed to perform external functions such as verifying the owner of a website), here the miner just collates the transactions and sends them to the log server|,Non-data,103
| By having senders contact log servers directly, one could therefore eliminate entirely the role of mining without any adverse effects on security Thus, Bitcoin Na ̈ıve overlay CT-like overlay Hashing Set of miners Broadcast Provable security decentralized yes yes no yes hybrid* yes yes* no distributed no yes Table 1: The different tradeoffs between Bitcoin, our na ̈ıve over- lay, and a “CT-like” overlay in which log servers completely re- place miners Our na ̈ıve solution provides the same openness that Bitcoin has for miners but also provable security guarantees for those who make (optional) use of distributed log servers, while our CT-like solution requires trust in the set of log servers but achieves both provable security and significantly better efficiency if users are willing to make the trust assumptions necessary for our transparency overlay — namely, to assume that some honest majority of a distributed set of log servers provide the correct response about the inclusion of a transaction — then the system can collapse into a distributed structure (the “CT-like overlay” in Table 1) in which no energy is ex- pended to produce the ledger, and users have minimal stor- age requirements|,Non-data,103
| Moreover, if users communicate directly with the log server, then we could add a signed acknowl- edgment from the log server that would allow us to satisfy accountability Interestingly, this solution closely resembles the recent RSCoin proposal [14] (but with our additional con- sistency and non-frameability guarantees), which achieves linear scaling in transaction throughput; this provides addi- tional validation and suggests that this distributed approach presents an attractive compromise between the two settings 7 CONCLUSIONS AND OPEN PROBLEMS In this paper, we initiated a formal study of transparency overlays by providing definitions and a generic secure con- struction of this new primitive|,Non-data,103
| To demonstrate the broad applicability of our generic formalization, we proved that Certificate Transparency (CT) is a secure transparency over- lay, and presented a Bitcoin-based transparency overlay that achieves provable notions of security and significantly re- duces the storage costs of regular Bitcoin users Our com- parison reveals that in any settings where distributed trust is possible (ie, one is willing to trust any set of known par- ticipants), Bitcoin can collapse into CT and the need for both mining and the storage of the blockchain disappears|,Non-data,103
| On the other hand, if one is not willing to trust anyone, then on a certain level these requirements seem inevitable While our constructions provide provably secure proper- ties concerning integrity, it is not clear how our transparency overlay could provide this same value to any system in which a meaningful notion of privacy is required It is thus an in- teresting open problem to explore the interaction between transparency and privacy, and in particular to provide a transparency overlay that preserves any privacy guarantees of the underlying system Acknowledgments Sarah Meiklejohn is supported in part by EPSRC Grant EP/M029026/1|,Non-data,103
|ABSTRACT The low-level C++ programming language is ubiquitously used for its modularity and performance Typecasting is a fundamental concept in C++ (and object-oriented pro- gramming in general) to convert a pointer from one object type into another However, downcasting (converting a base class pointer to a derived class pointer) has critical security implications due to potentially different object memory lay- outs Due to missing type safety in C++, a downcasted pointer can violate a programmer’s intended pointer seman- tics, allowing an attacker to corrupt the underlying memory in a type-unsafe fashion|,Non-data,105
| This vulnerability class is receiving increasing attention and is known as type confusion (or bad- casting) Several existing approaches detect different forms of type confusion, but these solutions are severely limited due to both high run-time performance overhead and low detection coverage This paper presents TypeSan, a practical type-confusion detector which provides both low run-time overhead and high detection coverage Despite improving the coverage of state-of-the-art techniques, TypeSan significantly reduces the type-confusion detection overhead compared to other solutions|,Non-data,105
| TypeSan relies on an efficient per-object meta- data storage service based on a compact memory shadowing scheme Our scheme treats all the memory objects (ie, globals, stack, heap) uniformly to eliminate extra checks on the fast path and relies on a variable compression ratio to minimize run-time performance and memory overhead|,Non-data,105
| Our experimental results confirm that TypeSan is practical, even when explicitly checking almost all the relevant typecasts in a given C++ program Compared to the state of the art, TypeSan yields orders of magnitude higher coverage at 4– 10 times lower performance overhead on SPEC and 2 times on Firefox As a result, our solution offers superior protec- ∗ † ‡ Vrije Universiteit Amsterdam Amsterdam Department of Informatics Purdue University Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page Copyrights for components of this work owned by others than the author(s) must be honored|,Non-data,105
| Abstracting with credit is permitted To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acmorg|,Non-data,105
| CCS’16, October 24 - 28, 2016, Vienna, Austria © 2016 Copyright held by the owner/author(s) Publication rights licensed to ACM ISBN 978-1-4503-4139-4/16/10 |,Non-data,105
  $1500 DOI: http://dxdoi,Non-data,105
|org/101145/29767492978405 tion and is suitable for deployment in production software Moreover, our highly efficient metadata storage back-end is potentially useful for other defenses that require memory object tracking|,Non-data,105
| CCS Concepts •Security and privacy → Systems security; Software and application security; Keywords Type safety; Typecasting; Type confusion; Downcasting 1 INTRODUCTION Type confusion bugs are emerging as one of the most im- portant attack vectors to compromise C++ applications C++ is popular in large software projects that require both the modularity of object-oriented programming and the high efficiency offered by low-level access to memory and system intrinsics Examples of large C++ programs are Google Chrome, large parts of Microsoft Windows and Firefox, and the Oracle Java Virtual Machine|,Non-data,105
| Unfortunately, C++ en- forces neither type nor memory safety This lack of safety leads to type confusion vulnerabilities that can be abused to attack certain programs Type confusion bugs are an inter- esting mix between lack of type safety and lack of memory safety Generally, type confusion arises when the program interprets an object of one type as an object of a different type due to unsafe typecasting—leading to reinterpretation of memory areas in different contexts|,Non-data,105
| For instance, it is not uncommon for a program to cast an instance of a parent class to a descendant class, even though this is not safe if the par- ent class lacks some of the fields or virtual functions of the descendant class When the program subsequently uses the fields or functions of the descendant class that do not exist for the given object, it may use data, say, as a regular field in one context and as a virtual function table (vtable) pointer in another Exploitable type confusion bugs have been found in a wide range of software products, such as Adobe Flash (CVE-2015-3077), Microsoft Internet Explorer (CVE-2015- 6184), PHP (CVE-2016-3185), and Google Chrome (CVE- 2013-0912) This paper shows how to detect type confusion with higher detection coverage and better performance than existing solutions|,Non-data,105
| TypeSan: always-on type checking Current defenses against type confusion [20, 17] are impractical for production systems, because they are too slow, suffer from low coverage, 517Checker CaVer TypeSan xalancbmk 24 thousand soplex omnetpp dealII 0 0 0 254 mln 209 thousand 20 bln 36 bln Checker CaVer TypeSan xalancbmk 296% 7|,Non-data,105
1% soplex 200% 18% Table 1: Coverage achieved by the type checkers on SPEC The numbers represent the number of downcasts verified by each of these systems while executing the reference workloads,Non-data,105
 The CaVer numbers are from the original paper to ensure a fair comparison Table 2: Performance overhead achieved by the type checkers on SPEC The CaVer numbers are taken from the original paper to ensure a fair comparison The com- parison only uses the applications CaVer has been eval- uated on by its authors,Non-data,105
| and/or only support non-polymorphic classes The greatest challenge in building an always-on type checker is the need for per-object metadata tracking which quickly becomes a bottleneck if the program allocates, frees, casts, and uses objects at high frequency (eg, on the stack)|,Non-data,105
| To address the high overhead and the low coverage of ex- isting solutions, we present TypeSan, an explicit type check- ing mechanism that uses LLVM-based instrumentation to enforce explicit type checks Compared to previous work, TypeSan provides extended coverage and massively reduced performance overhead Our back-end uses a highly efficient metadata storage service (based on a shadowing scheme with a variable compression ratio) to look up types from pointers This limits the amount of data written for large allocations (such as arrays of objects) while at the same time supporting efficient and scalable lookups, requiring only 3 memory reads to look up a type|,Non-data,105
| We envision this new type of metadata storage to be also useful for other sanitizers, eg, to verify memory safety, and we plan to explore further applications in future work We primarily envision TypeSan as an always-on solution, making explicit type checks practical for commodity soft- ware|,Non-data,105
| Used in attack prevention mode, TypeSan-hardened binaries are shipped to end users and terminate the pro- gram on bad casts, thereby preventing zero-day type con- fusion exploits Combined with liveness reports for modern software (like the Google Chrome and Mozilla Firefox crash reporters), such a deployment signals the developers about potentially missing type checks In addition, TypeSan can be used in software testing where TypeSan identifies po- tential bad casting in the source code In relaxed mode, TypeSan simply logs all bad casts to scan for underlying vulnerabilities, e|,Non-data,105
|g, when running a test suite We have implemented a prototype of TypeSan for Linux on top of LLVM 39|,Non-data,105
| Our prototype implementation is com- patible with large source code bases We have evaluated TypeSan with the SPEC CPU2006 C++ programs and the Firefox browser Compared to CaVer [17], the current state- of-the-art type confusion detector, we decrease overhead by a factor 3–6 for the SPEC benchmarks they reported on while simultaneously increasing the number of typecasts covered by checks by several orders of magnitude (see Table 1 and Table 2 for more details) Contributions We make the following contributions: • A design for high-performance, high-coverage typecast verification on legacy C++ code that is 3–6 times faster than the state-of-the-art detector with lower memory overhead and orders of magnitude more typecasts|,Non-data,105
| • A thorough evaluation that shows how our design de- livers both nearly complete coverage and performance that is suitable for production usage • An automatically generated test suite for typecasting verification to ensure that all different combinations of C++ types are properly handled • An open-source implementation of our TypeSan de- sign, available at https://githubcom/vusec/typesan|,Non-data,105
| 2 BACKGROUND In this section, we first explain typecasting in C++ and how doing so incorrectly can lead to vulnerabilities After- wards, we discuss existing defenses against type confusion 2|,Non-data,105
|1 Type confusion Object-oriented programming languages such as C++ al- low object pointers to be converted from one type into an- other type, for example by treating an instance of a derived class as if it were an instance of one of its ancestor classes Doing so allows code to be reused more easily and is valid because the data layout is such that an object from a de- rived class contains the fields of its parent classes at the same relative offsets from each other In our discussion on the safety of type conversions (or typecasts), we will use the following terminology: the run- time type refers to the type of the constructor used to create the object, the source type is the type of the pointer that is converted, and the target type is the type of the pointer after the type conversion Since the program may treat objects as if they are instances of their ancestor types, an object pointer should always refer to an object with a run-time type that is either equal to or a descendant of the pointer type|,Non-data,105
| Therefore, a type conversion is always permissible when the target type is an ancestor of the source type A compiler can verify such casts statically, because if the source type is a descendant of the target type it implies that the run-time type is also a descendant We refer to this type of conversion as an upcast If, on the other hand, the target type is a descendant of the source type, the conversion may or may not be permissible depending on whether the run-time type is either equal to or a descendant of the target type|,Non-data,105
| This is impossible to verify in the general case at compile time because the run-time type is not known to the compiler, due to inter-procedural/inter- component data flows We refer to this type of conversion as a downcast Downcasts require run-time verification to ensure type safety Incorrect downcasts may allow attackers to exploit differences in the memory layout or semantics of the fields between the target type and run-time type|,Non-data,105
| The C++ programming language permits both upcasts and downcasts and allows the programmer to specify whether downcasts should be checked at run time Specifically, the language provides three fundamental types of casts: rein- terpret_cast, dynamic_cast, and static_cast Dynamic casts are enforced at run time with an explicit type check 518and are therefore a safe but expensive way to ensure type safety Static casts on the other hand only verify whether the conversion could be a valid upcast or downcast based on the source and target types|,Non-data,105
| This lack of an online check can easily lead to type confusion when the underlying type observed at run time differs from the expected type in the source code As an example, in V8Clipboard in Chrome 2601410|,Non-data,105
|64, we find the following static cast: static_cast<HTMLImageElement*>(node)->cachedImage() Here, the program explicitly casts an image node to an HTMLImageElement without properly checking that it is of the right type Unfortunately, node could be an SVG im- age, which is of a sibling class and has a much smaller vtable than HTMLImageElement Note that the program im- mediately calls cachedImage() on the invalid object which leads to a virtual function call that erroneously interprets the memory adjacent to the SVG image’s vtable as code pointers If the program would check all static casts dynamically, we would not run into the type confusion problem (except for explicitly forced “problems” through reinterpreted casts)|,Non-data,105
| However, casting is such a common operation that the over- head of checking all static casts dynamically is significant and therefore, C++ allows the programmer to choose an explicit run-time cast only where “needed” (according to the programmer) For completeness, we mention that the last form of cast- ing, reinterpret_cast, forces a reinterpretation of a mem- ory area into a different type It allows a programmer to explicitly break underlying type assumptions 2|,Non-data,105
|2 Defenses against type confusion In recent years, several projects have tried to address the type confusion problem There are two main types of ap- proaches: those based on vtable pointers embedded in the objects and those based on disjoint metadata Solutions based on vtable pointers have the advantage that they do not need to track active objects but they have the fundamen- tal limitation that they cannot support non-polymorphic classes, which do not have vtables, without breaking binary compatibility Examples of vtable-based solutions are UBSan [20] and Clang Control-Flow Integrity [4] (CFI)|,Non-data,105
| UBSan instruments static casts to execute an explicit run-time check, effectively turning them into dynamic casts UBSan requires manual blacklisting to prevent failure on non-polymorphic classes Unfortunately, the existing type check infrastructure that is available in C++ compilers is inherently slow (as it was designed under the assumption that only few dynamic checks would be executed with the majority of checks being static) This is another reason why type-safety solutions did not see wide adoption|,Non-data,105
| Therefore, UBSan is intended as a testing tool and not as an always-on solution due to its prohibitive overhead Clang CFI is designed to be faster but has not published performance numbers Moreover, like all solutions in this group, it cannot support non-polymorphic classes CaVer [17], on the other hand, uses disjoint metadata to support non-polymorphic classes without blacklisting|,Non-data,105
| Un- fortunately, the overhead is still prohibitively high due to inefficient metadata tracking (especially on the stack) and slower checks, reaching up to 100% for some browser bench- marks Because CaVer cannot rely on vtables (present only Checker Poly Non-poly No blacklist Tracking Threads (cid:88) UBSan Clang CFI (cid:88) (cid:88) CaVer (cid:88) TypeSan limited (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) Table 3: High-level feature overview of checkers Checker stack CaVer TypeSan NO PARTIAL (cid:88) (cid:88) global new/new[] malloc family (cid:88) (cid:88) NO (cid:88) Table 4: Allocation types tracked by checkers, see Section 51 for a detailed discussion|,Non-data,105
| in polymorphic objects), it must track all live objects In particular, CaVer uses red-black trees to track stack-allocated objects and a direct mapping scheme based on a custom memory allocator for heap-based objects As a consequence, it has to determine the correct memory region for each pointer to be checked and it cannot handle stack objects shared be- tween threads even if proper synchronization is used in the application In addition, as shown in Section 9|,Non-data,105
|2, CaVer has poor object allocation coverage in practice, ultimately lead- ing to reduced type-confusion detection coverage For ex- ample, CaVer reports only 24k verified casts on xalancbmk and none on all other SPEC CPU2006 C++ benchmarks, while we show that four benchmarks actually have a large amount of relevant casts with their total numbers is in the billions As such, TypeSan is the first solution that provides efficient and comprehensive protection against type confu- sion attacks in the field, protecting users from vulnerabilities not found during testing In this paper we introduce TypeSan, a generic solution for typecast verification based on object tracking, that supports all types of classes with no need for blacklisting|,Non-data,105
| Moreover, we cover a very large percentage of all relevant casts at an acceptable overhead Table 3 gives a high-level comparison of the typecast verification solutions presented here UBSan and Clang CFI are restricted to polymorphic types, with UBSan requiring further blacklisting to handle certain code bases CaVer and TypeSan also support non-polymorphic types, but this comes at the cost of needing to track the type for each object|,Non-data,105
 CaVer further comes with the limita- tion that threads cannot share stack objects safely even with proper synchronization Table 3 and Table 4 show which al- location types are tracked in practice by tracking solutions See Section 51 for a more in-depth discussion of the various allocation types,Non-data,105
| CaVer officially supports stack and global data, but missed such bad casts in our coverage tests (see Section 92) 3 THREAT MODEL We assume that the attacker can exploit any type confu- sion vulnerability but is unable to perform arbitrary memory writes otherwise|,Non-data,105
 Our type safety defense mechanism exclu- sively focuses on type confusion Other types of vulnerabil- ities such as integer overflows or memory safety vulnerabili- ties are out of scope and we assume that orthogonal defense mechanisms protect against such vulnerabilities Our de- fense mechanism tolerates arbitrary reads as we do not rely on secret information that is hidden from the attacker 5194,Non-data,105
| OVERVIEW TypeSan is an extension to the Clang/LLVM compiler [15] that detects invalid static_casts (ie, all instances in the program where an object is cast into a different type without using an explicit run-time check through dynamic_cast or an explicit override through reinterpret_cast) in legacy C++ programs Upon detection of an invalid cast, the program is terminated, optionally reporting the cause of the bad type- cast|,Non-data,105
| TypeSan is a compiler-based solution and any C/C++ source code can be hardened, without modification, by re- compiling it with our modified clang++ compiler with the -fsanitize=type option and linking against the tcmalloc memory allocator [7] using the -ltcmalloc linker flag As we show in Section 9, TypeSan has reasonable performance for usage in production software Figure 1 presents an overview of TypeSan The instru- mentation layer consists of hooks inserted by the compiler to monitor object allocations and potentially unsafe casts, as well as a static library containing the implementations of those hooks|,Non-data,105
| To perform its task, this layer makes use of two services The type management service encodes type infor- mation and performs the actual typecast verification It in- cludes type information for all the types that may be used at run time The instrumentation layer uses it to look up type information for new allocations and informs it whenever a cast needs to be checked|,Non-data,105
| Finally, the metadata storage ser- vice stores a pointer-to-type mapping and can look up the type information of an object about to be typecast This service allocates a memory area to store the mapping at run time It provides an operation to bind type information to a pointer and to lookup a previous binding for a pointer All mechanisms that explicitly protect from type confu- sion will incur two forms of run-time overhead: overhead for maintaining metadata (allocating and deallocating ob- jects) and overhead for explicit type checks at cast locations|,Non-data,105
| We designed TypeSan to minimize the allocation/dealloca- tion time overhead C++ programs are heavily affected by allocator performance, as implicitly shown by how large projects tend to replace the standard memory allocator with high-performance allocators (tcmalloc and other allocators in Chrome, jealloc in Firefox) Many of the objects being allocated may also never be subject to downcasts, making it even more important to minimize the impact of type track- ing on such objects In order to meet these requirements, TypeSan relies on a clean, uniform front-end design that flags allocations and casts to the back-end system but introduces a completely different mechanism to track type information, called the metadata storage service in our design|,Non-data,105
| Our metadata stor- age service builds on the memory layout and structure in- herently provided by the allocator and uses this structure Figure 1: Overview of TypeSan components to reduce the access overhead (“aligning” objects with their metadata) Compared to existing disjoint metadata stor- age layers that use different forms of lookup functions from red-black trees to hashing for pointer range queries, our ap- proach offers fast constant-time updates and lookups For the type checking instrumentation and related data structures, we use a design focused on simplicity and cache- efficient traversal|,Non-data,105
| This design is effective even for workloads with an extremely high number of casting operations Fur- thermore, for performance-sensitive applications, safe oper- ations can be blacklisted or an approach like ASAP [24] can trade off security against acceptable overhead This is an- other key motivation to minimize allocation-time overhead, as it does not scale with the number of instrumented casts in a program, acting as residual overhead instead Lastly, the instrumentation layer and the metadata stor- age service are connected by the instrumentation layer, which uses the Clang/LLVM compiler framework [15] to track al- locations, instrument cast operations and extract type in- formation|,Non-data,105
| The instrumentation was designed with com- pleteness in mind, following code patterns discovered in real- world programs as well as basic C/C++ constructs expected to be supported Our instrumentation also allows full C- C++ inter-operability, a novelty compared to state-of-the- art solutions This is important as some SPEC programs mix C-style allocation with C++ classes and browsers also use a mixture of C and C++ code 5|,Non-data,105
| INSTRUMENTATION LAYER In this section we discuss the design of TypeSan’s instru- mentation layer The instrumentation layer interacts with the TypeSan-hardened program by inserting hooks at rel- evant locations We first consider the instrumentation of allocations, including the types of allocations we support to be able to track run-time object types with high coverage Then, we discuss the instrumentation of typecasts to be able to introduce type checks|,Non-data,105
| 51 Instrumenting allocations TypeSan adds a compiler pass to LLVM [15] to detect object allocations and insert instrumentation to store the corresponding pointer-to-type mapping For each allocated object we store a pointer corresponding to the type layout of the object as a whole However, keep in mind that down- casts in C++ might be applied not just to the allocated object pointer, but also to pointers internal to a given al- location range, specifically in the case of composite types (arrays, multiple inheritance, nested structs/classes)|,Non-data,105
| For example, an object of class A containing objects of classes B and C can be cast to B* using the original pointer while a cast to C* requires an offset to reference the correct member of class A In this scenario, the type of the internal pointer differs from the type associated at the allocation time, which we need to account for in the design For performance rea- sons, we chose to keep the instrumentation of the allocations as simple as possible and to defer handling composite types to the check operation itself (discussed in Section 6) This approach still introduces two additional requirements to our design|,Non-data,105
| First, the metadata storage service must be able to retrieve the mapping for internal pointers (discussed in Sec- tion 7) Second, the checker needs access to the offset within the class definition corresponding to the internal pointer To support the latter, we also track the base pointer of the al- instrumentationprogramtype managementtype informationgettypeinfocheckcastmetadata storagepointer mappingbindlookup520location besides the type mapping This design results in simple and low-impact instrumentation, using the metadata storage service to only store two pointers for each allocation in the program|,Non-data,105
| In the following, we describe the allocation types we support as well as their motivation In C++, objects may reside in global memory, stack mem- ory, or on the heap These three kinds of objects have differ- ent lifetimes and we therefore instrument them differently However, other than the location where we insert the hooks to instrument the allocation, the single uniform metadata storage service allows us to to treat objects in different mem- ory areas equally|,Non-data,105
| This simplifies our solution and improves performance because TypeSan must not determine where a pointer lives before looking it up The initialization and reuse of the mappings in object metadata depend on the object’s memory area For instance, we can initialize the mappings for global objects once using global constructors However, for stack and heap objects, we need a dynamic approach|,Non-data,105
| In the case of stack objects, we need to notify the metadata storage service to take control over the object These ob- jects are not put on the regular stack but are instead moved to a specific memory area where metadata tracking is en- abled (see Section 7 for details on this operation) With this change, we can use the metadata storage service to create a mapping from the new object pointer to its metadata at allocation time This design decision of moving the objects of interest to a separate location brings additional benefits from a tracking perspective, since the memory location occu- pied by a previously tracked stack object will only be reused for another tracked object|,Non-data,105
| During allocation, the new ob- ject will overwrite the old metadata, removing it from the system permanently This allows us to persist the metadata mapping after the lifetime of a stack object, removing the need for explicit cleanup A special class of stack objects (often ignored in existing solutions) arises when the program passes classes or structs by value as function arguments To address this special case, TypeSan uses the same approach applied by the current SafeStack implementation in LLVM, moving such objects to a separate stack1|,Non-data,105
| Not all stack objects need tracking and we optimize our so- lution by omitting allocation instrumentation wherever we can prove that the program will never cast the allocated stack objects To be conservative, we verify whether the function itself or the functions it may call perform any rele- vant casts We assume that any indirect (including virtual) or cross-module function calls may perform downcasts, be- cause for these cases we cannot statically determine that they do not Using this approach, we reduce overhead with- out missing any checks|,Non-data,105
| It is worth noting that our approach is more conservative than CaVer’s, which optimistically con- siders that such callees never attempt casts within their re- spective call-graphs2 For heap objects, we add instrumentation after calls to the new and new[] operators as well as the traditional malloc family of allocation functions Although C++ structs and classes are expected to be allocated using new (to ensure calls to the appropriate constructors), we observed that one of the four SPEC benchmarks with downcasts, uses mal- 1http://reviewsllvm|,Non-data,105
|org/D14972 2We reported this issue to the authors of CaVer loc/realloc for allocating its C++ objects Specifically, the soplex benchmark uses malloc/realloc to handle al- locations within its core DataSet class, which acts like an object pool Other classes, such as SVSet, maintain point- ers to objects managed by a particular DataSet|,Non-data,105
| As these pointers are also subject to downcasting, it is critical to track malloc/realloc in order to have type information available for checking Tracking heap deallocation is not necessary as we built the metadata storage service to be robust and to clean stale metadata This ensures that such metadata can- not influence type checks in case of an accidentally missed deallocation More details can be found in Section 7|,Non-data,105
| While inferring the allocation type and array size is trivial for new and new[] (as it is part of the syntax), this is more complicated for the malloc family of functions We traverse the intermediate representation code to look for cast opera- tions applied to the resulting pointer to find the allocation type This method might fail for type-agnostic allocation wrappers, but such wrappers can easily be added to the set of allocation functions which we track Array allocations can be tricky when trying to infer the element count from a mal- loc-like call-site, but our tracking scheme was designed to be agnostic to array sizes, thus mitigating potential issues|,Non-data,105
| In practice we found no coverage issues when evaluating Type- San against SPEC, showcasing our ability to track relevant heap objects with our solution An interesting point in heap allocations is support for al- locations within the standard template library (STL), which countless applications use for their core data structures Luck- ily, STL’s template-based design means that all the code re- lated to data structures is located within headers included into every source file This includes all their allocation wrap- pers, which are also templated and instantiated on a per- type basis|,Non-data,105
| We confirmed that our instrumentation correctly picks up the allocations within the STL data structures and we successfully check the downcasting operations applied to the individual elements 52 Instrumenting typecasts Whenever TypeSan encounters a downcast operation (from a base class to a derived class), it inserts a call to our type- casting verification function Such a cast is present in the code either when performing a static_cast operation be- tween appropriate type or when using an equivalent con- struct such as static C-style casts|,Non-data,105
| In practice, downcast- ing can exhibit two types of behavior and we optimize our checker to support each one specifically In the general case, the result of the static cast is the source pointer itself (with no added offset), but with a new source-level type This happens when the source base type is the primary base class of the derived type, which is always the case when casting without multiple inheritance In this case, the TypeSan in- strumentation calls the checker with the value of the pointer and an identifier corresponding to the destination type|,Non-data,105
| If classes use multiple inheritance it can happen that a cast operation occurs from a secondary base class to a derived type In this scenario, a negative offset is added to the source pointer as transformation from an internal pointer (to the secondary base) to the base pointer of the object The checker needs information about the resulting pointer to infer the appropriate offset within the structure layout, but in case of type confusion the negative offsets might make a valid pointer go out of bounds, making it impossible to in- 521fer the appropriate type information for the object pointed to For this reason, TypeSan calls a second version of the checker in this instance, which takes both the source and destination pointers as well as the type identifier for the re- sulting type|,Non-data,105
| 6 TYPE MANAGEMENT SERVICE TypeSan manages metadata on a per-allocation basis Ev- ery block allocated by a single malloc call, new operator, global variable, or stack variable is associated with at most a single pointer to a type information data structure This data structure therefore encodes all permissible casts using pointers pointing into the allocated block|,Non-data,105
| Any object can be cast back to itself using the original pointer, but com- position and inheritance create additional opportunities for casts For example, a pointer to an object can be cast to any of its base classes and a pointer to a field of an object can be cast to the type of the field (and transitively to any type on the inheritance chain) In this section, we discuss the data structures used to encode this information The type management service is responsible for associat- ing type layouts with allocation sites and using these layouts to validate downcast operations|,Non-data,105
| Type checking at its core can be divided into two steps The first one is the ability to infer the allocation-time type associated with the pointer resulting from the typecast This is the most derived type associated with the particular offset (from the pointer to the allocation base) within the original allocation Once this information is known, the second part of the type check involves the comparison of the allocation-time type with the type specified in the cast|,Non-data,105
| The layout of the latter must be compatible with the former for the cast to be valid The data structures employed by this service share the same purpose as the THTable structure in CaVer, but we further optimize the type checks by dividing it in in two phases In the following sections, we describe the data structures TypeSan uses to perform these operations 6|,Non-data,105
|1 Type layout tables Type layout tables describe each relevant offset within an allocation to enable fast lookups of the offset-specific type information during a check Specifically, a type layout table is a list of mappings of unique offsets to data fields corre- sponding to nested types The list (array) starts with an entry for offset 0 containing the unique hash corresponding to the type as a data field The layout tables incorporate nested types in one of two ways|,Non-data,105
| As a first option, the nested types can be flattened into a type layout for good cache effi- ciency during traversal Alternatively, they can be separated via an indirection for better space efficiency Flattening a nested type involves injecting an offset-adjusted copy of its type layout into the containing type, where its type layout is copied and adjusted into the layout of the containing type An avid reader may notice that flattening can invalidate the property mentioned earlier that offsets in the type layout table are unique|,Non-data,105
| After all, a nested class might occur at off- set 0 (for example with primary base classes) This is where the second part of our type check, the layout compatibility check, comes into play A class which includes a nested class at offset 0 is practically layout compatible with the latter Intuitively, if the next type class has another class at offset 0 of object, then we can always use the object as representa- tive for both types|,Non-data,105
| TypeSan tracks this relationship in type relationship tables (see Section 62) Thus, the type layout table only needs to track the (unique) ”derived-most” type for matching offsets As mentioned earlier, flattening is not compulsory, since the type layout table also supports indirection|,Non-data,105
| In this mode, the data element of a particular entry includes a pointer to the type layout table corresponding to the nested type In addition, TypeSan adds a sentinel element to the type table to mark the end of the nested type This allows the traversal code to infer quickly whether or not it should follow the indirection It skips the sentinel element if its offset overlaps with an existing entry in the table to maintain uniqueness|,Non-data,105
| Flattening generally improves performance at the cost of space While TypeSan mostly uses the flattened mode, it uses the non-flattened mode to generate an efficient array abstraction as the array length may be dynamic (in the lack of a way to optimize for performance we optimize for space) In particular, it replaces each nested array with a single indirect entry to the type layout table of the array element type, allowing TypeSan to support nested arrays of any size, without degrading checking speed The property of enforcing unique offsets in the type layout table allows us to implement efficient traversal by ordering the entries by offset|,Non-data,105
| During indirection, the type manage- ment service updates the offset that is being searched to match the follow-up type layout table (which is just a subset of the original type) In the case of a nested array, it updates the offset to represent the offset into the corresponding array element, instead of the array itself—using the array-stride as input This is supported, by including the overall size of the type (including requested alignment) as part of the type layout table When the instrumentation adds metadata at an allocation site, it simply requests a type layout table that corresponds to the type that is allocated|,Non-data,105
| Type layout tables are gener- ated once for each type, by recursively traversing the type information in LLVM to find all nested elements For poten- tial array allocations, it marks the pointer to the type lay- out table to signal additional processing of the offset This processing is identical to how we deal with nested arrays Accidentally marking an allocation as being of type array does not affect correctness, it just involves a couple of extra instructions being executed during type lookup|,Non-data,105
 As such our static analysis does not have to be complete as long as it is conservative in identifying allocations of single elements 62 Type relationship tables In the second stage of the type check we check for raw pointer compatibility between the type identified for the pointer and the type defined in the cast Such compati- bility typically happens between derived classes and their primary base class,Non-data,105
| As mentioned earlier, another case of compatibility happens between unrelated types if one of the types is nested in the other at offset 0 Furthermore, CaVer defined the concept of phantom classes: derived classes with no additional members compared to their base class Sometimes the program downcasts base classes to such phantom classes, resulting in benign bad casts Thus we also include phantom classes in our compat- ibility model|,Non-data,105
| Using the compatibility model, we generate a set of type hashes corresponding to the compatible types for each class in the program and refer to it as a type rela- tionship table Once TypeSan has extracted the type of a 522pointer from the type layout table, it checks the correspond- ing type relationship table for the membership of the type defined in the cast The operation needs to find an exact match to verify a cast If it finds no match, it reports an error of a mismatched type|,Non-data,105
| Currently we implement sets as simple vectors, with hashes ordered according to the type hierarchy We found this so- lution to be adequate in terms of speed, but we can easily replace it with alternative set implementations, such as the fast LLVM bitset variant Doing so is easy as the type re- lationships table is conceptually nothing more than a set as a result of the split of the type information into separate layout and relationship tables By having the phantom classes be first-class members of the type relationship tables, we ensure uniform support for them without performance degradation|,Non-data,105
| In contrast, the publicly released CaVer code requires a type check restart for every phantom class if normal inheritance fails to find a match 63 Merging type information across source files Generating large amounts of type information may ne- cessitate merging across different source files—an expensive and potentially difficult operation We rely on the One Def- inition Rule (ODR) in C++ to minimize the need to merge information across the project|,Non-data,105
| ODR states that every class definition across all source files linked together needs to be identical C++ also requires nested and base types to be fully defined in the source files that use them As a result, the type layout information for the same type within dif- ferent source files is always identical The same is true for the type relationship tables—except their phantom class en- tries|,Non-data,105
| Since the phantom classes represent derived classes, the set of phantom classes can easily change from one source file to another, and merging may be necessary TypeSan uses a strategy where it only needs to merge these entries in the type relationship tables to minimizing the merging cost Any program violating the ODR would trigger error reports in TypeSan This would be correct, since violating the ODR is type confusion in itself|,Non-data,105
| 7 METADATA STORAGE SERVICE In this section, we discuss the metadata storage service, which handles storage of metadata at run time This service allows us to map from object base addresses to type lay- out tables at run time Key requirements for our metadata storage service are (i) fast update operations and (ii) range- based lookups (to support interior pointers due to compo- sition)|,Non-data,105
| Related work [17, 2] has used alignment-based di- rect mapping schemes to track complex metadata, relying on dedicated custom memory allocators Such systems often run into problems for stack-based memory allocations [17] where the allocator has no detailed knowledge of allocations As a result we designed METAlloc [12], a novel object track- ing scheme, based on variable compression ratio memory shadowing, which solves these issues and allows us to have an efficient and uniform metadata storage service for all al- location types Variable compression ratio memory shadowing relies on the assumption that all objects on a certain memory page share the same alignment|,Non-data,105
| A uniform alignment guarantees that every alignment-sized slot within the page corresponds to a single object, enabling the tracking of metadata at the level of slots instead of objects, while preserving correctness Each page can thus be associated with an alignment and a metadata range, including as many entries as the number of alignment-sized slots in the page Such a mapping simplifies storage of metadata and allows us to assume a certain lay- out for objects on a per-page basis Given a page table-like infrastructure, the mapping allows finding metadata corre- sponding to any particular pointer in constant time, by us- ing the alignment to look up the slot index and to retrieve the metadata stored for the appropriate slot|,Non-data,105
 This mapping also mirrors traditional page tables as the alignment and the base address of the metadata range can be compressed into a single 64-bit value (since pointers only require 48 bits) We call this data-structure the metadata directory Figure 2 shows the mapping operation from any pointer to the cor- responding object metadata An update operation with this metadata results in finding the metadata for the base address of the object and then up- dating all entries which correspond to the object range,Non-data,105
| The number of entries which need to be updated is the number of alignment-size slots that the object spans across, making it critical to select the largest possible alignment to improve update performance This is where the variable compres- sion ratio comes into play, with large objects having larger alignments, thus their metadata is compressed relative to their size The system also works with the default 8-byte alignment of objects in existing systems, but the update op- eration would end up too costly for stack and heap objects Using alignments which are too large can also generate in- creased memory fragmentation resulting in unnecessary per- formance overhead, making it critical to select the most ap- propriate alignments|,Non-data,105
| In the case of global memory, the overhead introduced by the update operations rarely affects the performance of a running program, thus we decided to leverage the existing 8- byte alignment applicable for global objects We update the metadata directory entries to track all loaded sections when- ever we detect that a new shared object has been loaded into the address space of the program For heap allocations, tcmalloc [7] (the allocator used by the Chrome browser and other Google products) already ensures that every memory page under its control contains only objects of the same size-class and alignment It enforces this property to efficiently generate free lists, thus ensuring our assumptions for free, without needing to perform any changes to the allocation logic|,Non-data,105
| We only extended tcmalloc to track the metadata directory entries whenever a memory page is associated with a certain size-class, which happens rarely in practice Stack allocations are challenging, as they can be subject to ABI restrictions We mitigate this limitation by mov- ing relevant objects to a secondary stack similar to the op- erating principles of SafeStack [14] SafeStack is effective at moving dangerous stack allocations to a secondary stack with practically no overhead and minimal impact on ap- plication compatibility|,Non-data,105
| We use the instrumentation layer, as mentioned earlier, to tell the metadata storage service about stack objects, which are then moved to a secondary stack tracked by the metadata directory, where we enforce a 64-byte alignment for each object ABI restrictions are not applicable, since all tracked stack objects are local vari- ables, whose location can be freely chosen by the compiler The 64-byte alignment is reasonable as we only move a small 523Figure 2: Mapping from a pointer to a metadata entry The page component is used to look up the start address of the metadata region and the align- ment|,Non-data,105
| While the latter together with the page offset is used to compute the offset within the metadata region subset of stack objects, thus overall memory fragmentation of the program is limited As mentioned earlier in Section 5, deallocation of heap objects is handed internally by the metadata storage service and no extra instrumentation is needed While the stack contains only tracked objects, thus metadata will always be up to date with allocations, tcmalloc does manage all heap objects, including untracked ones|,Non-data,105
| As such, we extended tc- malloc to conservatively assume that every new allocation is untracked and to clear stale metadata associated with any new allocation if it detects such This approach mini- mizes the overhead when metadata is used sparingly, while ensuring that stale metadata can never affect untracked al- locations Moreover, our solution is not affected by thread concur- rency The metadata directory is only updated when mem- ory is mapped in from the system|,Non-data,105
| At this point all the entries read/written during this operation are the ones cor- responding to the allocation range, which is still in sole con- trol of the running thread The metadata entries are also updated only during object allocation and the entries writ- ten are unique to the allocation range, thus they do not interfere with concurrent lookups The update operation de- pends only on the metadata directory entry corresponding to the pointer itself, which cannot be subject to a concurrent write 8|,Non-data,105
| LIMITATIONS Our approach is based on an LLVM-instrumentation pass that reasons on the clang and LLVM IR level, therefore source code in either C or C++ is required Any alloca- tions or casts in assembly are not supported As stated in our treat model (and similar to related work), we assume that the attacker has no unrestricted write primi- tive at their disposal We therefore do not protect our meta- data against malicious writes|,Non-data,105
| Any metadata protection mechanism is orthogonal to this work and equally applies to other protection systems which complement TypeSan To support combined protections, TypeSan deliberately imposes as few restrictions and changes in the memory lay- out as possible It already integrates with SafeStack, a fast stack protection solution offered by compilers today Similarly, while TypeSan makes a design assumption about the heap allocator, it is compatible with arguably the two most commonly used custom memory allocators: tcmalloc (Chromium) and jemalloc (Firefox and Facebook)|,Non-data,105
| When combined with other memory safety solutions, TypeSan can preserve metadata integrity by construction When deployed standalone, our design is amenable to existing low-overhead metadata protection techniques, such as APM [8] or write- side SFI (eg, pointer masking)|,Non-data,105
| The overhead of such tech- niques is amortized across all defense solutions For exam- ple, if we employ SafeStack and we expect SafeStack (already in clang) to be adequately protected moving forward due to recent attacks [8, 19], TypeSan can benefit from the same metadata protection guarantees at no additional cost Note that TypeSan tolerates arbitrary reads as we do not rely on secret information hidden from the attacker Custom memory allocators (CMAs) can prohibit Type- San from appropriately tracking heap allocations|,Non-data,105
| Unfortu- nately, this is a fundamental limitation for instrumentation systems which rely on object information tracking TypeSan uses tcmalloc as the back-end allocator This is a suitable replacement for other general purpose allocators, but objects allocated within CMAs (such as pool or SLAB allocators) will not be tracked by our system 9|,Non-data,105
| EVALUATION To show that TypeSan achieves higher coverage and lower overhead than previous solutions, we evaluated our proto- type using a number of demanding CPU-intensive (and cast- intensive) workloads We test Firefox because browsers are a common target for attackers of type confusion vul- nerabilities, given the fact that they are usually written in C++ for performance reasons and have a large attack sur- face because of the fact that they provide a substantial API to foreign Javascript code We benchmarked Firefox us- ing the Octane [9], SunSpider [10], and Dromaeo [6] bench- marks Octane and SunSpider focus on Javascript perfor- mance, while Dromaeo has subtests for both Javascript and the DOM|,Non-data,105
| Moreover, we implemented our own microbench- marks to isolate the overhead and report worst-case figures for TypeSan and existing solutions In addition, we run the SPEC CPU2006 C++ benchmarks, which all heavily stress our allocator instrumentation and some (eg, dealII and om- netpp) our typecast instrumentation|,Non-data,105
| In our evaluation, we consider a number of different sys- tem configurations Our baseline configuration compiles with Clang 39 [15] at the default optimization levels The base- line is not instrumented but does use the tcmalloc [7] alloca- tor to report unbiased results, given that tcmalloc generally introduces a speedup that should not be attributed to Type- San|,Non-data,105
| In addition to the baseline, we have the TypeSan and TypeSan-res configurations The former instruments every possible cast while the latter does not instrument any casts The TypeSan-res configuration shows to what extent a sys- tem like ASAP [24] can reduce the performance impact of our instrumentation (trading off security) when only a small performance budget is available We ran our benchmarks on an Intel Core i7-4790 CPU with 16 GB of RAM, using the Ubuntu 15|,Non-data,105
10 Linux distribution 91 Performance 91,Non-data,105
|1 Microbenchmarks To verify that TypeSan provides low allocation-time and typecast-time overhead, we created microbenchmarks that measure how long these operations take, both on the stack and on the heap To compare our results against state-of- 524Figure 3: Allocation performance as a function of allocated object size Figure 4: Allocation performance as a function of allocated object count the-art solutions, we compiled CaVer [17] from source [16] and configured in the same way as TypeSan—except that we do not use tcmalloc since CaVer ships with its own cus- tom allocator|,Non-data,105
| To prevent the target operations from being removed by optimizations, we switched to the -O1 optimiza- tion level for this experiment To isolate the overhead, we measured the impact of (i) the number of allocated stack objects and (ii) the object size The former is important since CaVer tracks stack objects with red-black trees, whose performance degrades with the number of objects The lat- ter is important since TypeSan needs to initialize multiple metadata entries for large objects, incurring more overhead|,Non-data,105
| Figure 3 depicts the impact of the object size on alloca- tion performance when no other stack objects are present Allocating an object on the stack is almost instantaneous for the baseline and takes a fixed but long time for CaVer For TypeSan, allocation time on the stack is proportional to the object size as multiple metadata entries need to be initial- ized for large objects However, even for objects as large as 8KB, TypeSan is still faster than CaVer|,Non-data,105
| Small objects up to 128 bytes take only 05ns extra to allocate with TypeSan, while CaVer adds at least 488ns even for these small (and common) allocations On the heap, allocation time grows linearly with the allocation size in all cases|,Non-data,105
| Overall, Type- San is close in performance to the baseline while CaVer adds considerable overhead For heap allocations up to 128 bytes, TypeSan adds at most 70ns overhead while CaVer adds at least 267ns|,Non-data,105
| We believe that it is unlikely for programs to frequently allocate large, bloated classes without using them and thus hiding the allocation overhead As further mitigation to the scaling based on the stack object size, it is possible to extend TypeSan to use additional secondary stacks with increased alignments for such large classes These results support our claims that TypeSan is particularly suitable for applications that allocate many objects, especially on the stack Figure 4 and Figure 5 show the impact of the number of allocated stack objects on allocation and typecast perfor- mance (respectively), using an object size of 16 bytes|,Non-data,105
| The overhead patterns are in the same region for both scenarios CaVer’s overhead on the stack increases with the logarithm of the number of objects (due to the use of red-black trees) Figure 5: Typecast performance as a function of al- located object count while TypeSan’s does not depend on the number of allocated objects Even at relatively low allocation counts, CaVer’s stack allocations are much more expensive than TypeSan’s|,Non-data,105
| For every typecast, in turn, TypeSan adds an overhead of only 38ns, regardless of whether the object is allocated on the stack or on the heap and regardless of the number of allocated objects CaVer’s typecast overhead is higher in all cases In particular, the heap overhead is a constant 13|,Non-data,105
|6ns, while the stack overhead starts at 110ns and increases with the number of allocated objects 91|,Non-data,105
|2 Performance overhead Table 5 reports our performance on the SPEC CPU2006 C++ benchmarks [13] and Firefox The first four SPEC benchmarks perform static typecasts while the others do not In the latter case, the overhead stems from TypeSan having to still track objects that cannot be statically and conservatively proven not be typecast during the execution In the default configuration, overheads range from negligi- ble to moderate and the overheads on the benchmarks re- ported by CaVer [17] are much lower|,Non-data,105
| In particular, CaVer 525dealII soplex omnetpp xalancbmk namd povray astar geomean geomean ff-sunspider ff-octane ff-drom-js ff-drom-dom geomean casts TypeSan yes yes yes yes no no no yes both (02) (07) (17) (0|,Non-data,105
4) (01) (03) (05) 30,Non-data,105
8 18 272 71 -0,Non-data,105
6 239 -02 132 12,Non-data,105
1 406 186 124 71,Non-data,105
2 339 (14) (51) (1,Non-data,105
5) (15) TypeSan-res (01) (08) (3,Non-data,105
0) (03) (01) (02) (0,Non-data,105
5) 36 15 24 4,Non-data,105
4 -05 226 01 6,Non-data,105
4 46 114 28 4,Non-data,105
0 435 143 (11) (0,Non-data,105
|9) (17) (06) Table 5: Performance overhead on the SPEC CPU2006 C++ benchmarks and Firefox (%), stdev in parentheses reported four times our overhead (29|,Non-data,105
6%) on xalancbmk and 200% on soplex while ours is negligible Povray stands out for having high overhead despite its lack of casts This is mostly due to the many stack objects allocated in a recur- sion between the functions Ray_In_Bounds and Intersec- tion,Non-data,105
| Other than this special case, overheads are lowered by reducing the number of checks (a la ASAP [24]) The negative overhead for namd may be explained by variations in memory layout [18] For example, in all but one case, our TypeSan-res configuration can greatly bring down the over- head The overhead for Firefox is unfortunately somewhat higher, especially for the Dromaeo DOM workload|,Non-data,105
| The high overload is most likely due to the fact that Firefox performs many object allocations, especially on the stack On aver- age, however, our overhead is close to half of the overhead reported by CaVer (646%) The results for the TypeSan-res configuration show that this overhead can be reduced even further by selectively instrumenting casts|,Non-data,105
| Note that our coverage on Firefox is considerably lower than on the other benchmarks mostly due to the use of CMAs (though still much higher than the competition, see Table 8), so extend- ing our solution to cover the remaining casts could increase the overheads reported here 913 Memory overhead Table 6 reports our memory usage on the SPEC CPU2006 C++ benchmarks and Firefox, measured in terms of binary size (static) and the maximum resident set size (dynamic)|,Non-data,105
| While TypeSan generally introduces nontrivial memory over- head, we believe this is worthwhile (and acceptable in prac- tice), given the security it offers with negligible performance overhead Moreover, compared to CaVer [17], our relative run-time memory overhead is much lower for the two SPEC benchmarks they considered (9% vs 56% on xalancbmk and 1% vs 150% on soplex)|,Non-data,105
| It is unfortunately impossible to compare our memory overhead on Firefox as we measured a different version than the one reported by CaVer The negative memory overhead for Dromaeo-DOM may be ex- plained by the fact that this benchmark runs for a fixed amount of time, completing fewer runs when the browser is slowed down through our instrumentation Our memory overhead is mostly due to the metadata storage service it- binary size base ts 03 3|,Non-data,105
1 04 10 06 0,Non-data,105
0 41 06 52 0,Non-data,105
8 14 12 03 7,Non-data,105
6 namd dealII soplex povray omnetpp astar xalancbmk geomean 1591 ff-sunspider 1591 ff-octane ff-drom-js 1591 ff-drom-dom 159,Non-data,105
1 geomean 3186 3186 3186 318,Non-data,105
6 inc% base resident set ts 816 693 1127 45,Non-data,105
2 904 5971 858 118,Non-data,105
0 1002 1002 1002 100,Non-data,105
2 1002 509 8186 560,Non-data,105
9 87 1578 3104 451,Non-data,105
3 4911 8444 5722 4232,Non-data,105
0 569 14531 5684 18,Non-data,105
8 2245 3144 4927 928,Non-data,105
2 15344 10058 40157 inc% 11,Non-data,105
7 775 13 1174 42,Non-data,105
3 13 92 317 89,Non-data,105
0 817 758 -51 19,Non-data,105
|9 Table 6: Memory usage for the SPEC CPU2006 C++ benchmarks and Firefox (MB), ts=TypeSan self As future work, it is possible to share this infrastructure and its memory overhead with other defenses that maintain per-object metadata (eg|,Non-data,105
|, bounds checking), reducing the memory usage of the combined system 92 Coverage 92|,Non-data,105
|1 Typecast coverage test suite To test the correctness of TypeSan and future type-confusion detection systems, we developed a test suite for a wide range of different code constructs that might affect typecast saniti- zation The test cases covered by the test suite are inspired by our extensive experience with real-world C++ programs Our test suite is available as part of the open source repos- itory of TypeSan to help future researchers in testing their systems The test suite verifies correctness using three differ- ent dimensions: allocation type, composition type, and cast type|,Non-data,105
| The test suite allows different configurations from each dimension to be combined and tested simultaneously Every test allocates an object of type AllocationType using the desired configuration It then sends a pointer to the allocated object to a function, which derives a pointer to a member of type BaseType nested into AllocationType with the desired composition type configuration Finally, we downcast the pointer to a type derived from BaseType, called DerivedType|,Non-data,105
| We implement the functions in different source files to uncover any potential bugs in interprocedural cross-module static analysis in the checker Other than false negatives, the test suite also checks for false positives, by replacing the BaseType with a derived type of DerivedType in AllocationType Our test suite considers the following allocation types: stack object, stack array, struct argument passed by value, global object, global array, new / new[] (including over- loaded operator), and malloc/calloc/realloc (including ar- rays) For array types, we also consider multidimensional arrays where possible|,Non-data,105
| We consider the following composi- tion types (the relationship of BaseType with respect to Al- locationType): equivalence, nested, nested array element, and inheritance (primary, secondary, and virtual) Finally, we support the following cast types: from primary base to derived type, from secondary base to derived type, and from primary base to a phantom class of the real type TypeSan successfully passes all combinations of these con- figurations, showcasing our coverage on a wide range of 526stack allocations heap 322 40 441 414 10 36 13 2,458 5,231 447 85 3,216 18 255 11 185,908 global 1,125 161 623 2,263 4 200 7 42,710 casts types 716 2 449 2,688 0 0 0 68,369 1,238 311 568 1,768 16 257 18 38,764 dealII soplex omnetpp xalancbmk namd povray astar firefox Table 7: Instrumentations code constructs|,Non-data,105
| For comparison, we also tested CaVer [16] and found that it only passes the following allocation types: global object and new / new[] (including overloaded opera- tor) CaVer also reported false positives when nested arrays were used for the composition We contacted the authors about all the tests that failed, but we have not received an explanation or a fix for these issues 9|,Non-data,105
22 Coverage on benchmarks Table 7 shows the number of code locations where we in- sert instrumentation Note that the information about al- locations is based on the source code because it cannot be easily recognized in the binary due to inlining The num- ber of cast checks and types are based on the final binary to make them comparable to CaVer [17],Non-data,105
| The number of checks in the source code is considerably lower (for example 19,578 for Firefox), presumably due to optimizations that cause code to be duplicated Compared to CaVer, we insert slightly fewer checks in Firefox, more in Xalanc and the same number in Soplex This may be due to differences in versions or compiler (settings) We generate more type information than CaVer on Firefox and Soplex, but less on Xalanc|,Non-data,105
| This may be due to differences in representation of type infor- mation In all cases, we insert more instrumentation than UBSan does [17] Table 8 shows the typecast coverage of TypeSan compared to state-of-the-art solutions, CaVer [17] in particular Cov- erage percentages are computed as the fraction of non-null casts correctly checked by the system—missing checks are due to inability to correctly track the corresponding ob- ject|,Non-data,105
| As such, it is an indication of the security provided by the system TypeSan reports over 89% coverage on each of the relevant SPEC benchmarks, and 1000% on all but one Unfortunately, coverage is not as high on Firefox|,Non-data,105
| We have found that this is due to the widespread use of pool al- locators, which violate the assumption made by our system (as well as other object tracking systems) that objects are allocated individually This issue could be solved by modi- fying Firefox to allocate objects directly This may be viable performance-wise due to the allocation performance offered by tcmalloc While CaVer does not report per-benchmark results, they report a total of 1,077k verified casts|,Non-data,105
| As such, our coverage is approximately more than 300,000 times as high For both SPEC and Firefox, Table 8 shows that we track many more allocated objects than CaVer This ex- plains that we are able to check more casts despite a similar number of instrumentation sites—casts can only be checked if type information metadata was stored at allocation time As shown in Table 8, we provide security far superior to the allocations TypeSan CaVer casts non-null TypeSan % 597m dealII 21m soplex 264m omnetpp 4,538m xalancbmk 463m ff-sunspider 967m ff-octane ff-drom-js 15,824m ff-drom-dom 301,540m ff-total 318,793m 15,530k 1,058 278k 209k 3,596m 3,596m 100|,Non-data,105
|00 10000 209k 2,014m 10000 2,014m 254m 8952 284m 92m 31|,Non-data,105
|43 293m 122m 1235 991m 12,976m 3,032m 2337 46,961m 21,253m 4526 61,222m 24,500m 40|,Non-data,105
02 CaVer % 0 0 0 24k 000 000 000 0,Non-data,105
|01 1,077k 000 Table 8: Typecast coverage current state of the art while improving performance at the same time 10|,Non-data,105
| RELATED WORK To the best of our knowledge, UBSan [20] and CaVer [17] are the only other systems that perform verification at cast time like TypeSan Our system is inspired by CaVer and has considerable similarities with it In particular, it shares the same benefits with regard to UBSan: we do not rely on run- time type information (RTTI) and therefore we can handle non-polymorphic classes and protect binaries without the need for manually maintained blacklists Moreover, as we have shown in our evaluation, we introduce less overhead than CaVer, which in turn has shown by its authors to be more efficient than UBSan|,Non-data,105
| Compared to CaVer, we have a similar instrumentation layer based on an LLVM instrumentation pass, but we have completely redesigned the metadata storage mechanism In particular, we use a uniform variable compression ratio mem- ory shading scheme with off-the-shelf allocation strategies, rather than a purpose built custom memory allocator of the heap and the red-black trees used for the stack in CaVer Our approach is more efficient for both insertions (object allocations) and lookups (typecast checks) because it does not require identifying the type of the allocation (due to its uniform nature) and it does not incur the significant and non-linear overhead that red-black trees bring to trivial stack allocations Moreover, our solution is not affected by thread concurrency|,Non-data,105
| This is a major simplification compared to CaVer, which uses per-thread red-black trees Another solution that achieves similar goals as ours is pre- venting calls through incorrect virtual method tables (vta- bles) For example, Bounov et al [3] present an approach that can efficiently verify for each virtual call that the vtable is valid for the static type through which the call is per- formed|,Non-data,105
| This mitigates some type confusion vulnerabilities, but such solutions cannot protect non-polymorphic classes because they do not have vtables Moreover, this solution only detects type confusion when the object is subjected to a virtual call, thus missing potential memory corruption from a mismatched layout in other parts of the code Clang CFI [4] uses such a system to check cast operations involv- ing polymorphic classes, but there is no publicly available evaluation of the system and it is still restricted to a subset of downcast operations On binaries without source code, Dewey and Giffin [5] show how data flow (reaching definition) analysis may help to determine bounds on vtables and detect type confusion statically by ensuring that a virtual function call does not stray beyond the bounds of the vtable|,Non-data,105
| As noted by the authors, their analysis is prone to false positives and false 527negatives and therefore more suited to reducing the number of type confusion bugs prior to deployment Finally, CFI [1] and other advanced protection mecha- nisms for forward edges in C++ programs [21, 23, 22, 14] limit the wiggle room that attackers have to divert control via indirect control transfers However, as type confusion is mostly a data problem, such solutions only address it partly Similarly, VTable protection schemes [25, 11], may check the types of virtual calls or the sanity of vtable pointers, but do not prevent the misuse of type confusion in general|,Non-data,105
| 11 CONCLUSION Type confusion vulnerabilities play an important role in modern exploits as shown in recent attacks against Google Chrome or Mozilla Firefox Existing solutions that detect type confusion exploits are (i) incomplete, missing a large number of typecasts and (ii) prohibitively slow, thereby hin- dering general adoption We presented TypeSan, an LLVM-based type-confusion detector that leverages an optimized allocator to store meta- data in an efficient way to reduce the overhead for updating metadata|,Non-data,105
| Building on several optimizations for both the underlying type checks and the metadata handling, we re- duce the performance overhead by a factor 3–6 compared to the state of the art Our performance figures suggest Type- San can be used as an always-on solution in practical set- tings In addition, TypeSan is complete and no longer misses typecasts on either the stack or between C and C++ object interactions As we show in the SPEC CPU2006 bench- marks, such interoperability issues between programming languages cause prior work to miss a large number of casts|,Non-data,105
| 12 ACKNOWLEDGMENTS We thank the anonymous reviewers for their feedback This work was supported, in part, by NSF CNS-1464155 and CNS-1513783, the European Commission through project H2020 ICT-32-2014 “SHARCS” under Grant Agreement No 64457, and the Netherlands Organisation for Scientific Re- search through the grant NWO 639|,Non-data,105
023309 VICI “Dowsing” 13 ,Non-data,105
|ABSTRACT With the progress in mobile computing, web services are increasingly delivered to their users through mobile apps, instead of web browsers However, unlike the browser, which enforces origin-based security policies to mediate the interactions between the web content from different sources, today’s mobile OSes do not have a comparable security mechanism to control the cross- origin communications between apps, as well as those between an app and the web As a result, a mobile user’s sensitive web resources could be exposed to the harms from a malicious origin  In this paper, we report the first systematic study on this mobile cross-origin risk|,Non-data,106
| Our study inspects the main cross-origin channels on Android and iOS, including intent, scheme and web- accessing utility classes, and further analyzes the ways popular web services (eg, Facebook, Dropbox, etc) and their apps utilize those channels to serve other apps|,Non-data,106
| The research shows that lack of origin-based protection opens the door to a wide spectrum of cross-origin attacks These attacks are unique to mobile platforms, and their consequences are serious: for example, using carefully designed techniques for mobile cross-site scripting and request forgery, an unauthorized party can obtain a mobile user’s Facebook/Dropbox authentication credentials and record her text input We report our findings to related software vendors, who all acknowledged their importance To address this threat, we designed an origin-based protection mechanism, called Morbs, for mobile OSes|,Non-data,106
| Morbs labels every message with its origin information, lets developers easily specify security policies, and enforce the policies on the mobile channels based on origins Our evaluation demonstrates the effectiveness of our new technique in defeating unauthorized origin crossing, its efficiency and the convenience for the developers to use such protection  Categories and Subject Descriptors D4|,Non-data,106
|6 [Operating Systems]: Security and Protection – access controls, invasive software Keywords: Android, iOS, same-origin policy, mobile platform  1 INTRODUCTION The popularity of smartphones, tablets and other mobile devices has brought in a plethora of software applications designed for  Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page Copyrights for components of this work owned by others than ACM must be honored|,Non-data,106
| Abstracting with credit is permitted To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acmorg|,Non-data,106
| CCS’13, November 4–8, 2013, Berlin, Germany Copyright © 2013 ACM 978-1-4503-2477-9/13/11|,Non-data,106
$1500 http://dxdoi,Non-data,106
|org/101145/25088592516727  systems  iOS), whose  in developing  (eg|,Non-data,106
|, Android,  running on these devices Such applications, commonly known as apps, are typically used to deliver web services (data storage, social networking, web mails, etc) through their compact user interfaces and simple program logic, which are tailored to mobile platforms Moreover, other than interactions with their own web services, many of those apps are also built to work with other apps and services, leveraging the third-party’s resources to enrich their functionalities|,Non-data,106
| This is a trend that echoes web-API integrations extensively utilized traditional, browser-based web applications Examples include the apps that support social login and data sharing through the services offered by Facebook, Twitter, Google Plus, etc  Mobile origin-crossing hazard Those mobile apps essentially play the same role as traditional web browsers at the client side|,Non-data,106
| However, different from conventional web applications, which enjoy browse-level protection for their sensitive data and critical resources (eg, cookies), apps are hosted directly on mobile operating security mechanisms (such as Android’s permission and sandbox model) are mainly designed to safeguard those devices’ local resources (GPS locations, phone contacts, etc)|,Non-data,106
| This naturally calls into question whether the apps’ web resources are also sufficiently protected under those OSes More specifically, web browsers enforce the same origin policy (SOP), which prevents the dynamic web content (eg, scripts) of one domain from directly accessing the resources from a different domain|,Non-data,106
| When the domain boundary has to be crossed, a designated channel needs to go through to ensure proper mediation An example is the postMessage channel [5], which a domain uses to send a message to another domain by explicitly specifying the recipient’s origin,  and the browser mediates to ensure that only the content from that origin gets the message and the recipient is also well informed of the sender’s origin Such origin-based protection has become a de facto security standard for a modern browser However, it is not present on any channels provided by mobile OSes for apps to communicate with each other or the web|,Non-data,106
| As a result, the web content or apps from an untrusted domain may gain unauthorized access to the web resources of other apps/websites through those channels, causing serious security consequences  As an example, consider the scheme mechanism [25][26] supported by Android and iOS, through which an app on phone/tablet can be invoked by a URL once it registers the URL’s scheme (eg, the “youtube” part of “youtube://watch?token=xxx”, with “xxx” as the input parameter for the app)|,Non-data,106
| What an adversary can do is to post on Facebook a link that points to a malicious script hosted on his website Once this link is clicked by the victim through the Facebook app on her iOS device, the script starts to run within the app’s WebView instance, which is then redirected to a dynamically generated URL with the scheme of another app that the adversary wants to run on the victim’s device and the parameters he chooses As a result, the target app will be  635invoked to blindly act on the adversary’s command, such as logging into his Dropbox account to record the victim’s inputs (Section 33|,Non-data,106
|2), since the app is given no clue the origin (the adversary’s site) of the request In another case, the Android mobile browser processing a URL with the “fbconnect://” scheme from the Facebook server will deliver the secret token on the URL to an app from an arbitrary origin, as long as it claims to be able to handle that scheme (Section 331)|,Non-data,106
|  Such unauthorized origin crossing is related to the confused deputy problem [24] on mobile devices Prior research on this subject, however, focuses on permission redelegation [10], which happens when an app with a permission requires sensitive system resources (eg, a phone’s GPS location) on behalf of another app without that permission|,Non-data,106
| The interactions between the two apps go through an Inter-Process Call (IPC) that delivers a message called intent from one app to invoke the other app’s Activity for services such as getting GPS coordinates This intent channel can also be used to cross origins: for example, it allows an app from one origin to send intents to another app when the latter’s related Activity is accidentally made public, a mobile cross-site request forgery (CSRF) attack [27] However, given that those prior studies primarily aim at protecting mobile devices’ local resources, the general problem has not been dug deeper: for example, it is not clear whether an app’s private Activity can still be invoked by the intent message from an unauthorized origin, not to mention the security implications of other channels (such as the URL scheme) that can also be used for crossing domains  Our findings|,Non-data,106
| To better understand this critical security issue, we conducted the first systematic study on unauthorized origin- crossing over mobile OSes, including Android and iOS  In our study, we investigated all known channels that allow apps to cross domains, such as intent, scheme and utility classes for web communications, by dissecting popular apps like Facebook, Dropbox, Google Plus, Yelp, and their SDKs, to understand how they utilize these channels to serve other apps on different mobile OSes Our study found 5 generic cross-origin weaknesses in those high-profile apps and SDKs, which can be exploited through CSRF, login CSRF and cross-site scripting (XSS) Many of those problems affect multiple apps and web services|,Non-data,106
| They are unique to the communication channels on mobile OSes, which are fundamentally different from those within the browsers The root cause of the vulnerabilities is the absence of origin-based protection More specifically, due to missing origin information, an app or a mobile web service is often left with little clue about the true origin of an incoming message, nor does it have any control on where its outgoing message will be delivered to The consequences of these cross-origin attacks are dire|,Non-data,106
| They allow a malicious app to steal the mobile device owner’s Facebook, Dropbox authentication credentials, or even directly perform arbitrary operations on her Dropbox account (sharing, deleting, etc) on Android On iOS, a remote adversary without direct access to any app on the victim’s device can stealthily log the phone into the adversary’s Dropbox account through Google Plus, Facebook apps As a result, the victim’s text input on iPhone and iPad, her contacts and other confidential information are all exposed to the adversary once she uses popular editing and backup apps (e|,Non-data,106
|g, PlainText, TopNotes, Nocs, Contacts Backup, etc) that integrate Dropbox iOS SDK We reported those problems to related parties, who all acknowledged the importance of our discoveries|,Non-data,106
| We received over $7000 bounty for these findings, most of which were donated to charity The details of  such recognition together with demos of our attacks are posted online [31]  Origin-based defense Without any OS-level support, not only does app development become highly error-prone, but software manufacturers can also have hard time fixing the problems after they are discovered|,Non-data,106
| As examples, both Dropbox and Facebook need to spend a significant amount of effort to fix the security problems we discovered, which involves changing software architecture (Section 321) or deprecating some core features within their apps and SDKs (Section 33|,Non-data,106
|1) To address these issues and facilitate convenient development of securer apps, we present in this paper the design of the first mobile origin-based defense mechanism, called Morbs Our approach mediates all the cross-origin channels on Android and iOS, including intent, scheme and the utility classes for web communications, and enables a developer to specify to the OS authorized origins her app/website can receive requests from and/or send responses to We implemented Morbs on Android in a way that fully preserves its compatibility with existing apps|,Non-data,106
| Moreover, we show that through our mechanism, the developers can easily gain controls on all cross-origin events, avoiding the ordeal experienced by Facebook, Dropbox, and other companies Our evaluation on the implementation also shows that it is both effective, stopping all the exploits we found, and efficient, incurring only a negligible impact on performance (< 1% overhead)  The source code of Morbs is publicly available on GitHub [40]  Contributions|,Non-data,106
| We summarize the paper’s contributions here:   New problem Up to our knowledge, the research reported here is the first attempt to systematically understand unauthorized origin crossing on mobile OSes The discovery made by our study brings to light the presence of such vulnerabilities in high-profile apps and more importantly, the seriousness and pervasiveness of the problem   New techniques|,Non-data,106
| We developed new origin-based protection for existing mobile OSes, which works with apps/websites to oversee the communication channels on these systems Implementation and evaluation We implemented our design on Android, and evaluated its effectiveness, efficiency, compatibility, and usability to the app developer    Roadmap|,Non-data,106
|  The rest of the paper is organized as follows:   Section 2 describes the mobile channels used for apps to communicate with each other or the web; Section 3 elaborates our study on mobile cross-origin problems and our findings; Section 4 presents our defense mechanism Morbs, Section 5 reports the evaluation of our techniques; Section 6 compares our work with other related research; Section 7 concludes the paper and discusses the future research  2 MOBILE CHANNELS Today’s mobile OSes (including Android and iOS) provide various channels for apps to communicate with each other or the web Those channels include intent, scheme, and web-accessing utility classes (which we elaborate later in the section)|,Non-data,106
| As shown in , an app communicates with other apps through the intent or scheme channel It can also invoke the browser to load a webpage using an intent and be triggered by the web content rendered in the browser through a URL scheme Moreover, the app can simply acquire and display any web content through the WebView class, which embeds a browser-like widget within the app, and directly talks to a web server using the methods provided  636by the HttpClient classes Note that the intent channel is Android- specific, while others are also available on iOS|,Non-data,106
| Unlike the domain-crossing mechanisms within (eg, postMessage), these mobile channels are not under the origin- based protection: messages exchanged do not carry any origin information inspect, and are completely unmediated with regard to where they come from  the sender/receiver can  browser  that  a  Mobile Device App callbacks HttpClient classes WebView class mobile browser intents schemes App App Apps Web   Figure 1 Mobile communication channels  Here we elaborate how those channels work:    Intent|,Non-data,106
| An intent is an inter-process message delivered through an IPC  It is a channel only supported by Android Through intent messaging, one app on Android can activate the background Services, Activities (application components with user interfaces) or Broadcast-Receivers of another app, as well as the Activities/Services of its own Intent invocation is conducted through APIs such as startActivity, startActivityForResult, and startService|,Non-data,106
| An app developer can specify a set of intents the app can receive from other apps in its manifest file However, the intent channel never labels the origin of each message (ie, who created it)|,Non-data,106
 This causes the problem we elaborate in Section 321   URL scheme,Non-data,106
| As discussed before, scheme is supported by both Android and iOS, which allows an app or website to use a URL to invoke another app (on iOS) or its Activity/Service components (on Android) that claim the scheme of that URL For example, the URL “youtube://watch?token=xxx” can be used to start the YouTube app to play the video “xxx” When such a URL is loaded in the mobile browser or a WebView instance, the OS will launch the target app with this URL as input In addition, an app can also invoke other apps through the schemes they registered|,Non-data,106
| On Android, scheme invocation is implemented through the intent channel: a scheme URL is wrapped in an intent instance, and invoked by an app through the same set of APIs that also serve intent messages, such as startActivity On iOS, this is done through openURL API Again, the OSes do not mediate the scheme-based invocations using origins   Web-accessing utility classes|,Non-data,106
| Mobile platforms provide several utility classes for apps to communicate with the web We call them web-accessing utility classes For example, both Android and iOS support the WebView class (called UIWebView on iOS), which an app can embed for displaying webpages An app can interact with its WebView instance through a set of  method calls or callbacks|,Non-data,106
| For example, it can call loadURL on Android (loadRequest on iOS) with a URL to load a page into the instance; it can also register events, like URL loading, to inspect every URL its WebView instance processes through a callback shouldStartLoadWithRequest (iOS) or shouldOverrideUrlLoading (Android) In addition, the mobile platforms provide utility classes for an app to directly talk to a web server without loading its web content HttpClient [36] or HttpURLConnection [37] (Android) and NSURLConnection [38] [39] (iOS) are such examples We call those classes (for direct communication with web servers) HttpClient classes|,Non-data,106
| Origin-based protection is not in the picture here: eg, a WebView/HttpClient instance never labels which app is the origin of an HTTP request 3|,Non-data,106
| ATTACKS In this section, we elaborate our study on unauthorized origin crossing on mobile OSes What we want to understand here are whether the ways real-world apps utilize those channels for cross- origin communications indeed expose them to attackers, and whether those apps have proper means to mitigate such a threat and safeguard their operations over those channels For this purpose, we systematically analyzed high-profile apps on both Android and iOS, including the official apps of Facebook and Dropbox and their SDKs, and the official Google Plus and Yelp app Note that these SDKs are very popular|,Non-data,106
| They have been integrated into many real-world apps Problems discovered there may have a broad impact In our research, we looked into how those apps use the aforementioned cross-origin channels to interact with other apps, or the web The study reveals the pervasive presence of cross-origin vulnerabilities, allowing an unauthorized party to activate an app remotely with arbitrary internal Activities, steal user’s authentication credentials and even directly manipulate its operations|,Non-data,106
|  Such discoveries were made through an in-depth analysis on the code and operations of those apps Specifically, for Android apps, we decompiled the binary code of their latest versions using apktool [33] and AndroChef Java Decompiler [34] in order to analyze their program logic related to the mobile channels When it comes to iOS apps, decompiling their executables is often hard Therefore, we resorted to a black-box traffic analysis to understand those apps’ interactions with other parties (apps, web services, etc|,Non-data,106
|) We also studied the SDKs provided by Facebook and Dropbox, whose source code is publically available In the rest of the section, we report our findings The demos of our exploits on those apps and other supplementary materials are posted on the web [31]|,Non-data,106
|  input parameters, call  subtle yet  serious  its  31 Adversary Model Our adversary model describes practical threats to different mobile platforms On Android, we consider an adversary who can trick a user into installing a malicious app on her device That app, however, may not have any permission considered to be dangerous by Android|,Non-data,106
| Also, threats to Android can come directly from the web, when the victim uses her mobile app or browser to view malicious web content posted by the adversary on a website On iOS, we only consider this remote threat (from a malicious website), not the malicious app, given the fact that Apple’s vetting process on iOS apps is more restrictive than that of Android apps, and few malicious apps have been reported so far  Note that we treated Android and iOS differently to respect the realistic threats those systems face: we could have found more  637login Activity before proceeding with  issues had we assumed the presence of malicious apps on iOS Finally, we do not consider an adversary with OS-level controls|,Non-data,106
|  32 Exploiting the Intent Channel The security implication of the intent channel on Android has been studied in prior research [10][27] All existing work, however, focuses on how such a channel can be leveraged by a malicious app to invoke a legitimate app’s Activities that are accidentally made public by the app’s developer In our research, we found that even the private Activities not exposed to the public, which is meant to be called only by the app itself, can be triggered by an app from an unauthorized origin|,Non-data,106
| This problem has a serious consequence, letting the malicious app gain great control of the victim app We discovered this vulnerability on both the Facebook app and the Dropbox app  Here we use the Dropbox app as an example to explain where the problem is 3|,Non-data,106
|21 Next Intent (Android) An Android app can have two types of Activities, private or public By default, an Activity is private, meaning that only the code inside the app can invoke it When the app developer sets the “exported” property of the Activity to true, or she declares at least one intent for the Activity in the manifest of the app, the Activity becomes public, in which case other apps can invoke the Activity with an intent instance as an argument|,Non-data,106
| Our analysis on the Dropbox app reveals that the app exposes a few Activities, such as login, which is meant to be public  An interesting observation is that when any of its public Activities are invoked by an intent instance, the Activity first needs to check whether the user is in a logged-in status If not, it redirects him to the task Specifically, the Activity creates a new intent instance, in which the current intent, the one it receives from another app, is saved under the key “com|,Non-data,106
dropboxactivityextraNEXT_INTENT” (called “NEXT_INTENT” here),Non-data,106
| The new intent instance is then issued by the app itself to invoke LoginOrNewAcctActivity (the login Activity) Once the user completes her login, the login Activity from “NEXT_INTENT”, and uses it to invoke the unfinished public Activity to fulfill its task The cross-origin exploit It turns out that this next-intent feature can be exploited by a malicious app to cross origins and invoke the Dropbox app’s private Activity|,Non-data,106
| Since the login Activity is public, a malicious app can trigger it with an intent instance, in which the attacker puts another intent instance under the “NEXT_INTENT” key The second instance points to a private Activity of the Dropbox app This login intent will not be noticed by the user if she is already in the logged-in status, and cause little suspicion if she is not, simply because it is the authentic Dropbox app that asks the user to log in Either way, once the login is done, LoginOrNewAcctActivity retrieves the intent content under the “NEXT_INTENT” key and use it to call the startActivity API|,Non-data,106
| Since startActivity is now invoked by the Dropbox app itself, all of its Activities, including those private ones, can be executed, even though the next-intent actually comes from a different origin, the malicious app The root cause of this problem is that the startActivity API never checks (and also has no means to check) the provenance of the intent under the “NEXT_INTENT” key, due to the lack of origin-based protection on the mobile OS In the absence of the origin information (here, the app creating the intent), even an app’s private Activity can be exposed to unauthorized parties  its own  retrieves  instance  original  intent  the  to  the  requests  the user  the origin  injected can make arbitrary AJAX  to run LoggedOutWebViewActivity with  The problem goes beyond a single app|,Non-data,106
| In the Facebook app, we discovered the same problem in a public Activity called UriAuthHandler The Facebook app also checks the login status, and directs login Activity, and uses “CALLING_INTENT” (equivalent to “NEXT_INTENT”) as a key to store the current intent instance This channel is equally vulnerable and can be abused in the same way, as found in our study We suspect that other apps with this type of next-intent feature are also subject to the same exploit|,Non-data,106
| Attacks and consequences Once is crossed illegitimately, the door is open to all kinds of abuses In our research, we implemented two attacks (one against the Dropbox app, another one against the Facebook app) to demonstrate the serious security consequences of the problem  Our attack on the Facebook app leverages a private Activity LoggedOutWebViewActivity|,Non-data,106
