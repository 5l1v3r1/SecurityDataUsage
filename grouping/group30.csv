 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| • If mode = trans, update the record with TC ← TC∪{S} • If mode = perm, update the record with PC ← PC ∪ {S} • If TC ∪ PC = {LS, S1,  |,Non-data,75
|  , Sn} then set guesses ← ∞ • If S = LS, then assemble L ← {(ssid i, uid i, pwdi)} for all ongoing sessions, ie|,Non-data,75
|, extract the passwords from all setup records (setup, ssid i, uid i, pwdi, proceed i, finished i) with finished i = 0 and all stored login records (login, ssid i, uid ,pwdi, proceed i) If S (cid:54)= LS, set L ← ∅ • Send (CORRUPT, sid, L) to A 9|,Non-data,75
| Server Refresh date the record to (corrupt, ∅, PC) On input (REFRESH, sid) from LS: • Look up the corruption record (corrupt, TC, PC) and up- • Delete all setup records with finished = 0 and all login • Send (REFRESH, sid, S) to A records|,Non-data,75
| 10 Password Guessing up the setup proceed, finished) with finished = 1 On input of (PWDGUESS, sid, uid, pwd∗) from adversary A: • Look • If guesses = 0 set pwdok ← ⊥|,Non-data,75
| • Else, set guesses ← guesses − 1 and, if pwd∗ = pwd, set pwdok ← 1 , otherwise set pwdok ← 0 • Send (PWDGUESS, sid, uid, pwdok ) to A (setup, ssid, uid, pwd, record Figure 2: Ideal Functionality Fdpv with sid = (LS,S1,  |,Non-data,75
|  ,Sn, sid(cid:48)) login server LS The adversary can do so only for those login sessions for which all servers already gave the ok to proceed, i|,Non-data,75
|e, the login record for ssid(cid:48) contains proceed(cid:48) = 1 (set via the 3PROCEED interface) Note that here the check whether proceed(cid:48) = 1 is also required for a corrupt LS, as otherwise a corrupt login server could offline attack the user passwords|,Non-data,75
| If all servers agreed to proceed, the ideal functionality then looks up the corresponding setup record (setup, ssid , uid , pwd, proceed , 1) for uid and sets the verification result to pwdok ← 1 if the password match, ie, pwd = pwd(cid:48), and pwdok ← 0 otherwise If at least one back-end server Si ∈ {S1, |,Non-data,75
|   ,Sn} is corrupt, or the account was created by a corrupt LS, then A can enforce a negative result pwdok ← 0, by passing fail = 1 as extra input However, the adversary can only turn a successful result into a failed one, but not vice versa, i|,Non-data,75
|e, he cannot make a mismatch of the passwords look like a match Further, if the login result is delivered to a corrupt LS, then the global guesses counter is decreased Recall that guesses gets increased in the PROCEED interface when LS is corrupt and all servers want to proceed with ssid(cid:48)|,Non-data,75
| Thus, for lo- gin, the adversary can basically choose whether it wants to use that “guess” to complete the login request, or to per- form a password guess at an arbitrary user account via the PWDGUESS interface Note that for the latter, the LS can already be honest again (if a refresh took place), ie, that the adversary can keep the password guess for a later time|,Non-data,75
| Finally, when a login session is completed, the correspond- ing login record is deleted This is important for corrup- tion, because an adversary who corrupts the LS learns the passwords of all ongoing (or interrupted) setup and login sessions Time Out 7: The TIMEOUT interface allows the login server to termi- nate ongoing account creation or login sessions|,Non-data,75
| The ideal functionality then deletes the login or setup record for the specified ssid  For setup accounts this is only possible for incomplete records, ie, where finished = 0|,Non-data,75
| This models the desired ability of a real world LS to abandon sessions when it hasn’t received all server responses in an appropri- ate time, eg, if a server refuses to proceed, or the response got intercepted by the adversary 186(Un)Corruption & Password Guessing|,Non-data,75
| Our functionality supports adaptive and transient as well as permanent corruptions The environment can, at any time, decide to corrupt any initially honest server LS or Si and specify the corruption type In a transient corruption, the party remains corrupted until the next refresh of that server Parties that are permanently corrupted cannot be recovered and remain corrupted until the end of the game|,Non-data,75
| As long as not all parties are corrupted at the same time (regardless of whether they are transiently or permanently corrupted), the adversary has only very limited power for attacking the stored passwords, which is modeled by the password guessing interface Note that we do not follow the standard UC corruption model which, upon corruption of a party, gives all past in- and outputs to the adversary This is clearly not desirable in the given context of protecting bulk user passwords that are processed by the login server Thus, we aim at stronger security guarantees, despite adaptive cor- ruptions, which is modeled by the following interfaces|,Non-data,75
| 8: The CORRUPT interface allows the adversary to transiently (mode = trans) or permanently (mode = perm) corrupt any party S ∈ {LS,S1,    ,Sn}|,Non-data,75
| If S = LS, ie, the adversary decided to corrupt the login server, it learns the passwords of all ongoing setup and login sessions When all parties are corrupted at the same time, the adversary is still not given the stored passwords|,Non-data,75
| Instead, the functionality sets guesses ← ∞, which gives the adversary unlimited access to the PWDGUESS interface described below 9: By invoking the REFRESH interface, all transiently cor- rupted servers become honest again From then on, inputs and outputs of non-permanently-corrupted servers go to the environment, instead of to the adversary (until a server is corrupted again) Once the adversary has corrupted all par- ties at the same time, however, the unlimited capabilities for offline attacks remain|,Non-data,75
| Further, the functionality deletes all records of incomplete setup or login sessions 10: The PWDGUESS interface is the only possibility of the adversary to attack the stored user passwords The access to this interface is limited by the guesses counter As long as not all parties got corrupted at the same time, guesses is only increased when a corrupt login server started a new setup or login session, and all servers agreed to proceed|,Non-data,75
| For each such session, the adversary gets one more guess against a password for a uid of his choice is G(uid , pwd, H(uid , pwd)K ), where K = (cid:80)n LS can compute v ← (cid:81)n 4 OUR FIRST CONSTRUCTION The basic idea of the protocol is so simple that it can ac- tually be explained in a couple of lines Each server Si ∈ {LS = S0,S1, |,Non-data,75
|   ,Sn} has its own secret exponent Ki The “password hash” stored by LS for user uid and password pwd i=0 Ki mod q and G and H are hash functions|,Non-data,75
| To compute this value, LS chooses a random nonce N ←R Zq and sends u ← H(uid , pwd)N to Si, who responds with vi ← uKi so that = H(uid , pwd)K  This computation is performed at account creation and again at each login to check that the recomputed value matches the stored hash To refresh their keys, all servers add a pseudo- randomly and non-interactively generated share of zero to their Ki so that the individual keys are independent of those i=0 v1/N i in the previous epoch, but their sum K = (cid:80)n remains constant i=0 Ki mod q i There are two problems that slightly complicate the pro- tocol, however|,Non-data,75
| First, to obtain proactive security for ar- bitrarily many epochs, it is crucial that previous protocol messages do not commit a server Si to its secret key Ki Non-committing encryption [7] doesn’t help, because the ad- versary could corrupt LS and decrypt the elements vi that commit Si to its key Ki Instead, we apply a clever com- bination of blinding factors to each protocol message that preserve the overall result of the protocol, but that avoid honest servers from having to commit to their keys Second, a corrupt server Si may misbehave and use a (cid:54)= Ki during its computation of vi|,Non-data,75
| different exponent K (cid:48) This isn’t much of a problem if it happens during login: at most, it could make an honest LS erroneously conclude that a correct password was incorrect, but our functional- ity explicitly tolerates such “true negatives” A server us- ing a different exponent during account creation is more problematic, however While there doesn’t seem to be an obvious attack, the reduction to the gap one-more Diffie- Hellman problem ceases to go through Normally, the re- duction works by inserting CDH target points as responses to H(·) queries and observing the adversary’s G(·) queries for CDH solutions H(uid , pwd)K |,Non-data,75
| When LS stores a pass- word hash G(uid , pwd, H(uid , pwd)K(cid:48) ) for K (cid:48) (cid:54)= K , however, the reduction can no longer extract H(uid , pwd)K when the adversary guesses the password To prevent this, LS must verify at account creation that the obtained value v is indeed H(uid , pwd)K  In our second construction, the LS can do so using a pairing computa- In our first protocol, we let the servers engage in a tion distributed interactive zero-knowledge protocol allowing LS to check that the “overall” exponent K was correct, but with- out committing servers to their individual exponents Ki|,Non-data,75
| 41 Scheme Let G be a multiplicative group of prime order q > 22κ with generator g Let H : {0, 1}∗×{0, 1}∗ → G, G : {0, 1}∗× {0, 1}∗ × G → {0, 1}2κ, C : Zq → {0, 1}2κ, B0 : {0, 1}κ × N → G, B1 : {0, 1}κ × N → G, B2 : {0, 1}κ × N → G, and B3 : {0, 1}κ ×N → Zq be hash functions modeled as random oracles Let PRG : {0, 1}κ → {0, 1}κ × Zq ×{0, 1}κ ×{0, 1}κ be a pseudo-random generator and MAC : {0, 1}κ×{0, 1}∗ → T be a message authentication code|,Non-data,75
| Initialization takes place in a secure environment where all parties are uncorrupted and can communicate securely over a secure message transmission functionality Fsmt Dur- ing initialization and refresh, each party additionally has read/write access to a backup tape backup As the backup tape is not used during account creation and login, it is eas- ier to protect by disconnecting it during regular operation The difference between a transient and a permanent corrup- tion in the real world is that, in a transient corruption, the adversary is given control of that party and its current state information, but not its backup tape|,Non-data,75
| In a permanent cor- ruption, the adversary is additionally given the content of the backup tape Rather than assuming that parties revert to a fixed default state when recovering from corruption, as done in previous works [1], we assume that a party refreshes by starting from a clean copy of its code and deriving its new state information from its backup tape and its last state be- 187fore refresh (which may have been tampered with by the adversary) Once initialization is finished, the servers LS,S1,  |,Non-data,75
|  ,Sn communicate over an untrusted network, where messages can be arbitrarily observed, modified, and delayed by the adversary, but all messages are integrity-protected with a MAC Our protocol provides LS with a shared MAC key μ{0,i} with each server Si, i = 1,  |,Non-data,75
|  , n Whenever the de- scription below says that “LS sends m to Si”, it actually means that LS computes τ ← MAC(μ{0,i}, (m,LS)) and sends (m, τ ) to Si Whenever it says that “Si receives m from LS”, it actually means that Si receives (m, τ ) and checks that τ = MAC(μ{0,i}, (m,LS)), ignoring the message m if that is not the case|,Non-data,75
| The communication in the other direction from server Si back to LS is protected in the same way with the same MAC key μ{0,i} In the protocol below, the state information of each server Si ∈ {LS = S0,S1,   |,Non-data,75
| ,Sn} contains a list of blinding seeds s{i,j} for j = 1,    , n, j (cid:54)= i that are used to generate random shares of the unity element in G or of zero in Zq using the combinatorial secret sharing scheme recalled in the prelimi- naries|,Non-data,75
| All servers S1,    ,Sn maintain an associative array USED to keep track of previously used subsession identifiers ssid |,Non-data,75
| In each account creation or login session, the servers derive fresh shares βi,0,    , βi,3 of unity or zero using the random oracles B0, |,Non-data,75
|   , B3 applied to s{i,j} and ssid , and use these shares as blinding factors for their protocol mes- i=0 βi,3 = 0 mod q More precisely, Si’s blinding factors are computed j=0,j(cid:54)=i Bk(s{i,j}, ssid )∆i,j for k = 0, 1, 2 and as j=0,j(cid:54)=i ∆i,jB3(s{i,j}, ssid ) mod q, where ∆i,j = 1 i=0 βi,k = 1 for k = 0, 1, 2 and (cid:80)n sages so that (cid:81)n as βi,k ←(cid:81)n βi,3 ←(cid:80)n if i < j and ∆i,j = −1 otherwise|,Non-data,75
| Initialization During initialization, all servers are uncor- rupted and can communicate through the secure message transmission functionality Fsmt 1 LS: The LS generates and distributes master keys mk{i,j} for all servers in the system|,Non-data,75
| It also generates a secret key K for a joint public key L It uses the master keys to compute the initial key share K0 of K for LS, as well as its initial blinding seeds s{0,j} The key share and blind- ing seeds are kept in the initial state of LS, the master keys mk{0,j} are written to the backup tape • On input (INIT, sid ), check that sid = (LS,S1, |,Non-data,75
|   , Sn, sid(cid:48)) for his own identity LS and server identities S1,  |,Non-data,75
|  ,Sn • For all 0 ≤ i < j ≤ n, choose a master key mk{i,j} ←R {0, 1}κ The master key mk{i,j} will be known only to servers Si and Sj, so that each pair of servers {i, j} ⊆ {0, |,Non-data,75
|   , n} will have a common master key that is un- known to the other servers Si by providing input (mk{i,j})n μ{0,j}) ← PRG(mk{0,j})|,Non-data,75
| • For i = 1,    , n, securely send (mk{i,j})n j=0,j(cid:54)=i) to Fsmt for i = 1, |,Non-data,75
|   , n • For all j = 1, |,Non-data,75
|   , n, compute (mk(cid:48) {0,j}, δ{0,j}, s{0,j}, • Choose K ←R Zq and set L ← gK  Compute K0 ← • Initialize BUSY , USED 0, and the password hash ta- ble PH as empty associative arrays and store st 0 = (K0, (s{0,j})n j=1, L, PH , BUSY , USED 0) as initial state and store backup0 ← (K0, (mk(cid:48) j=1, L, PH ) on the backup tape|,Non-data,75
| j=0,j(cid:54)=i to server (SEND, (LS,Si, sid ),LS,Si, K +(cid:80)n j=1 δ{0,j} mod q j=1, (μ{0,j})n {0,j})n Si: −−−−−−−−−→ u, ch vi ← uKi · βi,0 ri ←R Zq R1,i ← gri · βi,1 ←−−−−−−−−− R2,i ← uri · βi,2 vi, R1,i, R2,i −−−−−−−−−→ Check C(c) = ch si←−−−−−−−−− si ← Kic + ri + βi,3 mod q c LS: N ←R Zq u ← H(uid, pwd)N c ←R Zq , ch ← C(c) v0 ← uK0 · β0,0 r0 ←R Zq R1,0 ← gr0 · β0,1 R2,0 ← ur0 · β0,2 s0 ← K0c + r0 v ←(cid:81)n R1 ←(cid:81)n s ←(cid:80)n + β0,3 mod q i=0 v1/N i=0 R1,i, R2 ←(cid:81)n i i=0 si mod q i=0 R2,i If gs = LcR1 and us = vN cR2 then PH [uid] ← G(uid, pwd, v) Figure 4: The account creation protocol All com- munication between LS and Si is integrity-protected with a MAC key μ{0,i} See the text for more infor- mation on the blinding factors βi,k|,Non-data,75
| 2 Si: Each server stores the received master keys mk{i,j} in backup memory and derives the initial state for Si • Upon input (SENT, (LS,Si, sid ),LS, (mk{i,j})n from Fsmt, for all j = 0,  |,Non-data,75
|  , n, j (cid:54)= i, compute (mk(cid:48) δ{i,j}, s{i,j}, μ{i,j}) ← PRG(mk{i,j}) • Compute the initial key share as Ki ← (cid:80)n j=0,j(cid:54)=i ∆i,j • Initialize USED i as an empty associative array and j=0,j(cid:54)=i, μ{0,i}, USED i) as ini- j=0,j(cid:54)=i) δ{i,j} mod q, where ∆i,j is as defined above store st i ← (Ki, (s{i,j})n tial state and store backupi ← (Ki, (mk(cid:48) on the backup tape|,Non-data,75
| j=0,j(cid:54)=i) {i,j}, {i,j})n Account creation To create an account for user uid with password pwd, the LS runs the following protocol with all n servers S1,   |,Non-data,75
| ,Sn: 1 LS: The LS sends a blinded password hash and a chal- lenge hash to all servers • On input (CREATE, sid , ssid , uid , pwd), check whether PH [uid ], BUSY [uid ] or USED 0[ssid ] is already defined If so, abort|,Non-data,75
| Else, set and store BUSY [uid ] ← 1 and USED 0[ssid ] ← 1 (Note that we already assumed that servers check that ssid is locally unique, but since it is crucial for the security of our protocol, we make these checks explicit here) • Generate a random nonce N ←R Zq and a random challenge c ←R Zq  Compute u ← H(uid , pwd)N and ch ← C(c)|,Non-data,75
| • Send (ssid , u, ch) to all servers for i = 1,    , n|,Non-data,75
| • Store (uid , pwd, N , u, c) associated with ssid  2 Si: Each server sends a blinded response using its secret key share and the blinded first move of a zero-knowledge proof • On input (PROCEED, sid , ssid ) from the environment and after having received (ssid , u, ch) from LS, check that USED i[ssid ] is undefined|,Non-data,75
| If not, abort set and store USED i[ssid ] ← 1 • Compute vi ← uKi ·(cid:81)n • Compute R1,i ← gri ·(cid:81)n R2,i ← uri ·(cid:81)n j=0,j(cid:54)=iB1(s{i,j}, ssid )∆i,j and B2(s{i,j}, ssid )∆i,j where ri ←R Zq  j=0,j(cid:54)=i B0(s{i,j}, ssid )∆i,j and j=0 j(cid:54)=i 188(mk(cid:48) LS: For 0 ≤ i < j ≤ n do mk{i,j} ←R {0, 1}κ For j = 1, |,Non-data,75
|   , n do {0,j}, δ{0,j}, s{0,j}, μ{0,j}) ← PRG(mk{0,j}) K ←R Zq , L ← gK , PH , BUSY , USED 0 ← empty backup0 ← (K0, (mk(cid:48) st 0 ← (K0, (s{0,j})n K0 ← K +(cid:80)n {0,j})n j=1, (μ{0,j})n j=1 δ{0,j} mod q j=1, L, PH ) j=1, L, PH , BUSY , USED 0) (mk{i,j})n j=0,j(cid:54)=i −−−−−−−−−−−−−→ Si: {i,j}, δ{i,j}, s{i,j}, μ{i,j}) ← PRG(mk{i,j}) (mk(cid:48) Ki ←(cid:80)n For j = 0,  |,Non-data,75
|  , n, j (cid:54)= i do USED i ← empty backupi ← (Ki, (mk(cid:48) st i ← (Ki, (s{i,j})n j=0,j(cid:54)=i ∆i,j δ{i,j} mod q j=0,j(cid:54)=i) {i,j})n j=0,j(cid:54)=i, μ{0,i}, USED i) Figure 3: The initialization protocol All communication takes place via Fsmt • Respond by sending (ssid , vi, R1,i, R2,i) to LS|,Non-data,75
| • Store (ri, ch) associated with ssid  i=1) mod q 3|,Non-data,75
| LS: The LS sends the challenge for the zero-knowledge proof • After having received (ssid , vi, R1,i, R2,i) from servers S1,   |,Non-data,75
| ,Sn, retrieve (uid , pwd, N , u, c) associated with ssid  Abort if it doesn’t exist • Update the information stored with ssid to (uid , pwd, • Send (ssid , c) to all servers S1,  |,Non-data,75
|  ,Sn N , u, c, (vi, R1,i, R2,i)n mation associated to ssid  sociated with ssid |,Non-data,75
| Abort if it doesn’t exist 4 Si: Each server checks the challenge hash from the pre- vious round and sends the blinded last move of a zero- knowledge proof • When receiving (ssid , c) from LS, retrieve (ri, ch) as- • If C(c) (cid:54)= ch, abort|,Non-data,75
| • Compute si ← Kic + ri +(cid:80)n j=0,j(cid:54)=i ∆i,jB3(s{i,j}, ssid ) • Respond by sending (ssid , si) to LS Remove all infor- 5 LS: The LS verifies aggregated server responses through the zero-knowledge proof and computes final password hash • After having received (ssid , si) from all servers S1, |,Non-data,75
|   , i=1) stored Sn, retrieve (uid , pwd, N , u, c, (vi, R1,i, R2,i)n for ssid  Abort if it doesn’t exist|,Non-data,75
| • Compute v0 ← uK0 ·(cid:81)n r0 ←R Zq , compute R1,0 ← gr0 ·(cid:81)n and R2,0 ← ur0 ·(cid:81)n s0 ← K0c + r0 +(cid:80)n , R1 ← (cid:81)n • Compute v ← (cid:81)n i=0 R2,i, and s ←(cid:80)n (cid:81)n j=1 B0(s{0,j}, ssid ) Choose j=1 B1(s{0,j}, ssid ) j=1 B2(s{0,j}, ssid ) Also compute j=1 ∆i,jB3(s{0,j}, ssid ) mod q i=0 v1/N i=0 R1,i, R2 ← • Verify that gs = LcR1 and us = vN cR2; if not, set BUSY [uid ] to undefined in the state information and abort|,Non-data,75
| • Store PH [uid ] ← G(uid , pwd, v) as the password hash • Remove all information associated to ssid  for uid and output (CREATEOK, sid , ssid ) i i=0 si mod q Login request|,Non-data,75
| The login protocol is a simplified version of account creation, without zero-knowledge proof 1 LS: The LS sends a blinded password hash to all servers • Upon input (LOGIN, sid , ssid , uid , pwd(cid:48)), first check that PH [uid ] is defined and USED 0[ssid ] is not defined|,Non-data,75
| Abort otherwise • Set and store USED 0[ssid ] ← 1 • Generate a random nonce N ←R Zq and compute u ← H(uid , pwd(cid:48))N  Send (ssid , u) to all servers S1, |,Non-data,75
|   ,Sn LS: N ←R Zq u ← H(uid, pwd(cid:48))N v0 ← uK0 · β0,0 i=0 v1/N v ←(cid:81)n i Si: u −−−−−−−−−→ vi←−−−−−−−−− vi ← uKi · βi,0 If PH [uid] = G(uid, pwd(cid:48), v) then accept else reject Figure 5: The login protocol|,Non-data,75
| All communication be- tween LS and Si is integrity-protected with a MAC key μ{0,i} See the text for more information on the blinding factors βi,k • Store (uid , pwd(cid:48), N , u) associated with ssid  2|,Non-data,75
| Si: Each server sends a blinded response using its secret key share • On input (PROCEED, sid , ssid ) from the environment and after receiving (ssid , u) from LS, first check whether USED i[ssid ] = 1 If so, abort set and store USED i[ssid ] ← 1|,Non-data,75
| • Compute vi ← uKi ·(cid:81)n j=0,j(cid:54)=i B0(s{i,j}, ssid )∆i,j and • Respond by sending (ssid , vi) to LS 3 LS: The LS verifies the re-computed final password hash • Compute v0 ← uK0 ·(cid:81)n (cid:81)n against the stored password • After having received (ssid , vi) from all servers S1, |,Non-data,75
|   , Sn, retrieve (uid , pwd(cid:48), N , u) associated to ssid  Abort if it doesn’t exist|,Non-data,75
| j=1 B0(s{i,j}, ssid )∆i,j ) and v ← • If PH [uid ] = G(uid , pwd(cid:48), v), then set pwdok ← 1, else • Output (RESULT, sid , ssid , pwdok ) and delete the stored i=0 v1/N  pwdok ← 0 tuple (uid , pwd(cid:48), N , u) for ssid  i Timeout|,Non-data,75
| The LS interrupts a creation or login protocol LS: • Upon input (TIMEOUT, sid , ssid ), retrieve record (uid , • If ssid is an unfinished account creation, set BUSY [uid ] to undefined and delete all information stored for ssid  • If ssid is an unfinished login, then delete all information pwd,  |,Non-data,75
 ) for ssid  stored for ssid  Refresh,Non-data,75
| Refresh is a non-interactive process where each server has access to its backup memory We assume that all servers synchronize to refresh simultaneously, eg, by per- forming refreshes at regular time intervals, or by agreeing on the timing through out-of-band communication|,Non-data,75
| 189(mk(cid:48) j=0,j(cid:54)=i, L, PH ) i ← Ki +(cid:80)n {i,j}, δ{i,j}, s{i,j}, μ{i,j}) ← PRG(mk{i,j}) Si: ∈ {LS = S0, S1,    , Sn} Let backupi = (Ki, (mk{i,j})n For j = 0, |,Non-data,75
|   , n, j (cid:54)= i do K (cid:48) PH (cid:48) ← PH Let PH (cid:48)(cid:48) be as in st 0 For all uid where PH [uid] = ⊥ and PH (cid:48)(cid:48)[uid] (cid:54)= ⊥ do j=0,j(cid:54)=i δ{i,j} mod q i , (mk(cid:48) PH (cid:48)[uid] ← PH (cid:48)(cid:48)[uid] i ← (K (cid:48) {i,j})n , BUSY ← empty i , (s{i,j})n backup(cid:48) USED i i ← (K (cid:48) st(cid:48) L, PH (cid:48), BUSY , USED i) j=0,j(cid:54)=i , L, PH (cid:48) ) j=0,j(cid:54)=i, μ{0,i} (μ{0,j})n j=1 , Figure 6: The refresh protocol Items in dark gray apply to Si = S0 = LS only, items in light gray apply to Si (cid:54)= S0 only|,Non-data,75
| {i,j})n j=0,j(cid:54)=i) 1 Si ∈ {LS = S0,S1,  |,Non-data,75
|  ,Sn}: Based on the backup backupi and the current state st i, Si computes its new state st(cid:48) i • If Si = LS, on input (REFRESH, sid ) recover the backup j=1, L, PH ) and obtain • If Si ∈ {S1,  |,Non-data,75
|  ,Sn}, recover the backup backupi = (Ki, • For all j = 0,   |,Non-data,75
| , n, j (cid:54)= i compute (mk(cid:48) tape backup0 = (K0, (mk{0,j})n the password hashes PH (cid:48)(cid:48) from st 0 (mk(cid:48) {i,j}, δ{i,j}, s{i,j}, μ{i,j}) ← PRG(mk{i,j}) and compute the new key share K (cid:48) • If Si = LS, first set PH (cid:48) ← PH  For all uid that were newly created during the past epoch, set PH (cid:48)[uid ] ← j=1, L, PH (cid:48)) PH (cid:48)(cid:48)[uid ] Store backup(cid:48) and set the new state st(cid:48) j=1, (μ{0,j})n j=1, L, PH (cid:48), BUSY , USED 0)|,Non-data,75
| i ← • If Si ∈ {S1,    ,Sn}, store the new backup backup(cid:48) i ← j=0,j(cid:54)=i) and set the new state to st(cid:48) (K (cid:48) (K (cid:48) i ← Ki +(cid:80)n 0, (mk(cid:48) 0, (s{0,j})n 0 ← (K (cid:48) 0 ← (K (cid:48) j=0,j(cid:54)=i δ{i,j} mod q|,Non-data,75
| j=0,j(cid:54)=i, μ{0,i}, USED i) {0,j})n {i,j})n i , (mk(cid:48) i , (s{i,j})n 42 Security The security properties of our first construction are sum- marized in the following theorem Theorem 4|,Non-data,75
|1 If the gap one-more Diffie-Hellman assump- tion holds in G, PRG is a secure pseudo-random genera- tor, and MAC is an unforgeable MAC, then the protocol π of Section 4 securely implements the functionality F in the (Fsmt,Fro)-hybrid model For any polynomial-time al- gorithms E,A, there exist polynomial-time algorithms SIM and B,B1,B2 such that (cid:12)(cid:12)(cid:12) ≤ nen2 · AdvprB1,PRG(κ) (cid:12)(cid:12)(cid:12)RealπE,A(κ) − Ideal F E,SIM + Advgomcdh B,G (κ) + nen · Advufcma B2,MAC(κ) + 7(qro + nqc + ql)2 22κ + 2n2ne(qro + n2ne) 2κ , where n, ne, qro, qc, ql are the number of back-end servers, epochs, random-oracle queries, account creation sessions, and login sessions, respectively|,Non-data,75
| As mentioned earlier, the Cheon attack [8] on the (gap) one-more Diffie-Hellman assumption potentially reduces se- √ d) if the adversary is given gxd  curity with a factor O( For our construction, we have that d ≤ qc + ql, so it would be advisable to use a group order q that is log(qc + ql) bits longer than usual to compensate for the attack Due to space limitations, we only sketch the simulator SIM for the above theorem and the reduction from the gap one-more Diffie-Hellman problem Simulator 4|,Non-data,75
|21 The simulator interacts as adversary with the functional- ity F and internally runs simulated versions “LS”,“S1”,   |,Non-data,75
| , “Sn” of all honest servers against the real-world adversary A, who also plays the role of all corrupt servers Initialization K = (cid:80)n The initialization procedure takes place in a trusted envi- ronment and hence is completely under control of the sim- ulator SIM It generates the initial keys so that it knows i=0 Ki mod q and sets L ← gK |,Non-data,75
| Rather than gen- erating blinding seeds s{i,j} and MAC keys μi through the pseudo-random generator PRG, SIM chooses them truly at random Values are assigned consistently across machines, though, in the sense that if different machines Si,Sj use the same master key mk{i,j} to derive a value, then the same random value will be assigned in both cases The simulation is aborted whenever an honest login server “LS” receives a network message for which the MAC tag verifies correctly under μi but that was never sent by “Si” and vice versa Random Oracles|,Non-data,75
| SIM simulates random oracles B0,    , B3, C by return- ing random values from the appropriate ranges, storing the values in tables for consistency|,Non-data,75
| It responds to random- oracle queries H(uid , pwd) so that it knows the discrete log- arithm of all responses, ie, choosing HTL[uid , pwd] ←R Zq and returning HT[uid , pwd] ← gHTL[uid,pwd] Random- oracle queries G(uid , pwd, v) are answered with the help of the PWDGUESS interface; we provide details in a moment|,Non-data,75
| The simulator aborts when a collision is detected between out- puts of C, H, or G Account creation The simulator executes simulated versions of all honest back-end servers “S1”,  |,Non-data,75
|  ,“Sn” by following the real proto- col after receiving (PROCEED, sid , ssid ,Si) from F It can do so because it knows all of the relevant secrets K1,  |,Non-data,75
|  , Kn and s{i,j} If LS is corrupt and A delivers (ssid , u) to an honest server “Si” for a new ssid , then SIM sends (CREATE, sid , ssid , uid = ⊥, pwd = ⊥) to F on behalf of LS and (PROCEED, sid , ssid ) on behalf of all corrupt servers Si ∈ C To simulate the honest “LS”, however, it must perform an honest-looking protocol without knowing the actual pass- word|,Non-data,75
| When SIM receives (CREATE, sid , ssid , uid ) from F, SIM uses u ← gN in the first round If at the end of the i=0 vi (cid:54)= −c i = R2, i=0 vi = uK , then it it assigns a random value as pass- word hash PH [uid ] ←R {0, 1}2κ and sends (CREATEOK, ssid , sid , uid ) to F To make sure that the password hash looks correct when LS gets corrupted, it answers A’s queries G(uid , pwd, v) as follows If v (cid:54)= H(uid , pwd)K , then it simply returns a ran- protocol gsL−c = R1 and us(cid:81)n uK , then SIM aborts|,Non-data,75
| If gsL−c = R1, us(cid:81)n and(cid:81)n i = R2 but(cid:81)n i=0 v i=0 v −c 190If v = H(uid , pwd)K , then SIM decreases a dom value counter guesses that mirrors the counter maintained by F, ie, it is initially zero, is increased each time the last honest server in a subsession ssid receives (PROCEED, sid , ssid ,Si), and is set to infinity when all servers get corrupted in the same epoch|,Non-data,75
| If guesses < 0, then SIM aborts the simula- tion and gives up; we will later show how this event gives rise to solving the gap one-more Diffie-Hellman problem If guesses ≥ 0, it sends (PWDGUESS, sid , uid , pwd) to F to ob- tain a response (PWDGUESS, sid , uid , pwdok ) If pwdok = 1, then it returns PH [uid ] as hash output, else it returns a random value whether (cid:81)n exponent K in (cid:81)n Login|,Non-data,75
| Login protocols for a corrupt LS are simulated similarly as account creations above: SIM sends (LOGIN, sid , ssid , uid = ⊥, pwd = ⊥) to F whenever the first honest server “Si” receives a message for a protocol ssid , and otherwise runs the honest code of Si Login protocols with an honest LS are simulated differ- ently depending on whether the account for uid was created when LS was honest or corrupt In the first case, the value PH [uid ] may not be assigned to any output G(uid , pwd, v) yet, but we are sure that at the time of account creation, the corrupt servers (if any) behaved “honestly overall”, in the sense that they did not affect the computation of the overall i=0 vi = uK , because the zero-knowledge proof was verified by the honest “LS” Since there is no such proof during login, real-world corrupted servers can use a different overall exponent K (cid:48), causing LS to conclude that the password was false even though it was correct|,Non-data,75
| The sim- ulator forces the same outcome in the ideal world by setting the fail flag in the RESULT interface Namely, it lets “LS” use u ← gN and, after having received all values vi, checks i=0 vi = uK  If so, it sets fail ← 0, otherwise it sets fail ← 1 In the second case, the password hash PH [uid ] was stored by a corrupt LS|,Non-data,75
| If there is no registered output G(uid , pwd, v) = PH [uid ], then for a successful login to take place, A must “predict” an output of G, which can happen only with negligible probability In this case, “LS” runs the pro- tocol using u ← gN but always sets fail ← 1 at the end If there is one (and only one, as SIM aborts on collisions) out- put G(uid , pwd, v) = PH [uid ], then we still cannot be sure that v = H(uid , pwd)K  The corrupt LS could for exam- ple have stored PH [uid ] = G(uid , pwd, v) = H(uid , pwd)K(cid:48) for K (cid:48) (cid:54)= K , and during login, corrupt servers Si could bias the overall exponent to K (cid:48) again, causing the honest LS to recompute v(cid:48) = v and conclude that login succeeded|,Non-data,75
| For any other overall exponent, however, login must fail, even if the correct password was used The simulator therefore lets “LS” perform the honest protocol with the correct pass- word pwd, which it knows from the entry in GT, and checks whether the recomputed value is equal to v If not, it sets fail ← 1, otherwise it sets fail ← 0 Corruption|,Non-data,75
| When A transiently corrupts a back-end server Si, SIM can hand over the full state of Si as it knows all the secret keys and subsession states When it corrupts LS, SIM knows the long-term state st 0 = (K (cid:48) j=1, L, PH (cid:48), BUSY , USED 0), but does not necessarily know the state of ongoing subsessions that contain the password pwd j=1, (μ{0,j})n 0, (s{0,j})n and the nonce N such that u = H(uid , pwd)N  It obtains the actual passwords for all ongoing protocols (CORRUPT, sid , L) from F It can then compute simulated nonces N(cid:48) for the correct password using the discrete logarithms of H(uid , pwd) stored in HTL|,Non-data,75
| When A permanently corrupts a server Si ∈ {LS = S0, S1,    ,Sn}, it additionally chooses master keys mk{i,j} ←R {0, 1}κ for j = 0, |,Non-data,75
|   , n, j (cid:54)= i, to simulate the contents of the backup tape backupi Refresh|,Non-data,75
| When the environment instructs all (non-permanently- corrupted) servers to refresh, the simulator SIM computes (mk{i,j}, δ{i,j}, s{i,j}, μ{i,j}) ← PRG(mk{i,j}) for all servers i = 0,    , n and all permanently corrupted servers Sj ∈ PC, where mk{i,j} are the values given to A as part of the backup tape when Sj was permanently corrupted|,Non-data,75
| For all other servers Sj (cid:54)∈ PC, SIM chooses random values for δ{i,j}, s{i,j}, μ{i,j} It otherwise computes the new state of Si as in the real protocol For all new entries uid that were added to the final state PH (cid:48) of a corrupt LS but were not yet defined at the begin- ning of the epoch, SIM checks whether there exists an out- put G(uid , pwd, v) = PH (cid:48)[uid ], setting pwd ← ⊥ if not The simulator registers a new account for each such uid by send- ing (CREATE, sid , ssid , uid , pwd) and (CREATEOK, sid , ssid ) to F for a fresh ssid |,Non-data,75
| 422 Reduction from Gap One-More DH Suppose we are given an adversary A and an environment E that cause the event guesses < 0 to occur, where guesses is initially zero, is decreased at each random-oracle query G(uid , pwd, v) with v = H(uid , pwd)K , is increased for each protocol session ssid where all honest servers participate, and is set to infinity when all servers are corrupted in the same epoch We show how such E,A give rise to a solver B for the gap one-more Diffie-Hellman problem|,Non-data,75
| Algorithm B is given input (g, X) and has access to oracles T, CDH, and DDH It sets L ← X, thereby implicitly set- i=0 Ki = x, and answers random-oracle queries H(uid , pwd) with target points generated by its T oracle It only fixes values of the individual Ki and blinding seeds s{i,j} at the moment that Si gets corrupted, however, avoid- ing that B has to guess a server that will remain uncorrupted in the next epoch Note that B never needs to simulate val- ues for Ki for all servers within the same epoch, because then the event guesses < 0 cannot occur|,Non-data,75
| ting K =(cid:80)n Account creation When E instructs an honest LS to create an account uid with password pwd, B first LS honestly perform step 1 of the real protocol, but it lets all honest servers Si choose random values for vi, Ri,1, Ri,2, si These are correctly distributed because, if at least one of S1,  |,Non-data,75
|  ,Sn is honest, then at least one of the blinding factors Bk(s{i,j}, ssid ) remains unknown to A, and if all S1,   |,Non-data,75
| ,Sn are corrupt, then v0, R0,1, R0,2 remains internal to the honest LS anyway Only when Si later gets corrupted will we program the random oracles Bk so that these responses make sense The LS cannot verify the zero-knowledge proof as usual, but, because it previously assigned values to the secrets Ki and s{i,j} of corrupt servers Si ∈ C = PC ∪ TC, it can check whether they behaved “honestly overall”, meaning, in a way that would have made 191the zero-knowledge proof work out if the honest Si would have responded correctly If so, then LS accepts the creation but stores a random string in PH [uid ]|,Non-data,75
| When A later makes a query G(uid , pwd(cid:48), v(cid:48)) with v(cid:48) = H(uid , pwd(cid:48))x, which B can test using its DDH oracle, then B decreases guesses and adds (H(uid , pwd(cid:48)), v(cid:48)) to a set Sol of CDH solutions If pwd(cid:48) is the password pwd used at creation for uid , then B responds with PH [uid ], otherwise it returns a random string If a corrupt LS initiates an account creation, then the honest servers Si ∈ C = {LS,S1,  |,Non-data,75
|  ,Sn} \ C must behave “honestly overall” to ensure that LS computes the correct value v = H(uid , pwd)K and a correct zero-knowledge proof if it chooses to follow the protocol honestly They do so by returning random values vi, except for the last honest server to respond Sl, where B increases guesses and uses one query to its CDH oracle to compute a response vl so that (cid:89) Si∈C (cid:89) (cid:89) Si∈C uκi i uκi i n(cid:89) (cid:89) Sj =1,j(cid:54)=i vi = B(s{i,j}, ssid )∆i,j = B(s{i,j}, ssid )∆i,j Si∈C Sj∈C for some random exponents κi ∈ Zq so that (cid:80) (cid:80) Si∈C κi + Si∈C Ki = x mod q, where ui is the value for u that Si received in subsession ssid  It simulates the zero-knowledge proof for honest Si in a similar way, choosing random values for R1,i, R2,i, si except for the last server, where B uses a simulated zero-knowledge proof using the challenge ci that it can look up from a response C(ci) = ch i|,Non-data,75
| Login When E instructs the honest LS to perform a login with password pwd(cid:48) for account uid that was created by an honest LS with password pwd, B lets LS run the honest protocol with uid , pwd(cid:48), but lets honest Si return random values vi At the end, LS checks whether the corrupt servers behaved honestly overall as defined earlier If so, and pwd(cid:48) = pwd, then LS outputs pwdok = 1, else it outputs pwdok = 0|,Non-data,75
| The LS proceeds similarly for accounts uid created by a corrupt LS if there exists no output G(uid , pwd, v) = PH [uid ], or if such output exists but pwd (cid:54)= pwd(cid:48) At the end of the protocol, however, it always outputs pwdok = 0 For an account created by a corrupt LS with an existing entry G(uid , pwd, v) = PH [uid ] with pwd = pwd(cid:48), things are slightly more complicated because, as explained for the simulator above, we cannot be sure that v = H(uid , pwd)K , yet login may still succeed if corrupt servers Si ∈ C apply the same bias to the overall exponent during login as during account creation The LS detects whether a real protocol would have reconstructed v(cid:48) = v by checking whether n(cid:89) (cid:18) (cid:89) i=0 (cid:18) (cid:89) vi · (cid:89) vi · ux−(cid:80)Si∈C Ki (cid:89) (cid:89) Si∈C Si∈C = v1/N i vi v = = (cid:19) 1 N Si∈C Si∈C Sj∈C (cid:19) 1 N B(s{i,j}, ssid )∆i,j Note that here too, B will make one CDH oracle query to compute the last honest server’s response for each ssid |,Non-data,75
| ·(cid:81)n Corruption and refresh If A corrupts all servers during the same epoch, guesses gets set to infinity, so B can abort without affecting its suc- cess probability When A transiently corrupts Si, B chooses a random key Ki and random blinding seeds (s{i,j})n j=0,j(cid:54)=i, and programs the entries Bk(s{i,j}, ssid ) of all previous sub- sessions ssid so that the previous responses make sense, j=0,j(cid:54)=i B0(s{i,j}, ssid ) As A i|,Non-data,75
|e, so that vi = uKi i cannot corrupt all servers, there is at least one seed s{i,j} that is unknown to A, so that B can program the entries B0(s{i,j}, ssid ) to satisfy the above equation It proceeds similarly for the values R1,i, R2,i, si in account creation pro- tocols For ongoing account creation protocols, B addi- tionally chooses ri ←R Zq and programs B1, B2 so that gs(cid:48) i = vci = i j=0,j(cid:54)=i ∆i,jB3(s{i,j}, ssid ) mod q, so that it can hand ri to A as part of the state of Si|,Non-data,75
| When A permanently corrupts Si, then B additionally chooses random master keys mk{i,j} for all j = 0,    , n, j (cid:54)= i, to simulate the backup tape of Si|,Non-data,75
| When a non- permanently-corrupted server Si is refreshed, B takes back control of Si and forgets all previously chosen values for Ki and s{i,j} (cid:81)n j=0,j(cid:54)=i B1(s{i,j}, ssid )−∆i,j and us(cid:48) s(cid:48) (cid:81)n j=0,j(cid:54)=i B2(s{i,j}, ssid )−∆i,j , where si −(cid:80)n i = gciKi · R1,i · R2,i i i CDH solutions When the event guesses < 0 occurs, B just added one more CDH solution to Sol than the number of times that it invoked its CDH oracle Indeed, B only invokes the CDH oracle only once for each account creation or login protocol with a corrupt LS where all honest servers participate|,Non-data,75
| The counter guesses is increased immediately before B invokes its CDH oracle and is only decreased when a valid CDH solution is detected in a G(·) query Therefore, B wins its game by returning Sol  5 CONSTRUCTION WITH PAIRINGS We now present an even more efficient scheme based on pairings|,Non-data,75
| It is almost identical to the discrete-logarithm scheme, except that the interactive zero-knowledge proof is replaced by a pairing computation by LS Let G1, G2, Gt be multiplicative groups of prime order q with generators g1, g2, gt, respectively, and an efficiently computable pairing function e : G1 × G2 → Gt Let H : {0, 1}∗×{0, 1}∗ → G1, G : {0, 1}∗×{0, 1}∗×G1 → {0, 1}2κ, and B0 : {0, 1}κ × N → G1 be hash functions modeled as random oracles Initialization, login, timeout, and refresh are identical to the discrete-logarithm scheme, except that L ← gK 2 and that group operations during login take place in G1|,Non-data,75
| Ac- count creation is considerably simpler, as the two-round zero-knowledge protocol is now replaced with a pairing com- putation, as depicted in Figure 7 which B can test using its DDH oracle If so, then LS out- puts pwdok = 1, otherwise it outputs pwdok = 0 Login protocols with a corrupt LS are simulated similarly as account creation, but without the zero-knowledge proof|,Non-data,75
| Account creation To create an account for user uid with password pwd, the LS runs the following protocol with all n servers S1,   |,Non-data,75
| ,Sn: 1 LS: The LS sends a blinded password hash to all servers 192LS: N ←R Zq u ← H(uid, pwd(cid:48))N v0 ← uK0 · β0,0 i=0 v1/N v ←(cid:81)n i Si: u −−−−−−−−−→ v←−−−−−−−−− vi ← uKi · βi,0 6 Si ? S (0) i If e(v, g2) = e(H(uid, pwd), L) Then PH [uid] ← G(uid, pwd, v)  ̄Si  6 6 ? ? S (j)  |,Non-data,75
  S (j−1) Cloud Platform i i 6   ,Non-data,75
| Internet Demilitarized Zone Figure 7: The account creation protocol for the pairing-based scheme Figure 8: The different components of server Si • On input (CREATE, sid , ssid , uid , pwd), check if PH [uid ], If so, BUSY [uid ] or USED 0[ssid ] is already defined abort|,Non-data,75
| • Set BUSY [uid ] ← 1 and USED 0[ssid ] ← 1 • Compute u ← H(uid , pwd)N and send (ssid , epoch 0, u) • Store (uid , pwd, N , u) associated with ssid  to all servers Si for i = 1,  |,Non-data,75
|  , n 2 Si: Each server sends a blinded response using its secret key share|,Non-data,75
| • On input (PROCEED, sid , ssid ) from the environment, and after having received (ssid , epoch 0, u) from LS, check whether USED i[ssid ] = 1 or epoch 0 (cid:54)= epoch i If so, abort USED[ssid ] ← 1 • Compute vi ← uKi ·(cid:81)n j=0,j(cid:54)=i B(s{i,j}, ssid )∆i,j and set • Respond by sending (ssid , vi) to LS|,Non-data,75
| 3 LS: The LS verifies the server contributions and com- putes final password hash • After having received (ssid , vi) from Si for all i = 1,  |,Non-data,75
|  , n, retrieve (uid , pwd, N , u) stored for ssid  Abort if it doesn’t exist j=1 B(s{0,j}, ssid )∆0,j and v ← • Compute v0 ← uK0 ·(cid:81)n (cid:81)n BUSY [uid ] to undefined and abort|,Non-data,75
| • Verify that e(v, g2) = e(H(uid , pwd), L); if not, set • Store PH [uid ] ← G(uid , pwd, v) as the password hash • Remove all information associated to ssid  for uid and output (CREATEOK, sid , ssid ) i=0 v1/N i  Theorem 5|,Non-data,75
|1 If the one-more Diffie-Hellman assumption holds in (G1, G2), then the protocol π in Section 5 securely realizes the functionality F in the (Fsmt,Fro)-hybrid model 6 DEPLOYMENT OF OUR SCHEME As discussed, our scheme requires the initialization to be run in a trusted execution environment and, to warrant the difference between transient and permanent corruptions, re- quires the backup tape to be better protected from attacks than normal state information|,Non-data,75
| The initialization could be run on a single trusted machine who then distributes the keys to the other servers, eg, by smart cards which then can also act as backup tapes A bet- ter alternative seems to make use of cloud platforms which will make it also easier to recover from corruption by starting a fresh virtual machine|,Non-data,75
| We discuss this in the following The features of modern cloud computing platforms such as Openstack [23] can be nicely exploited to realize proactive security for protocols Such platforms offer strong separa- tion between the virtual machines that are exposed to the Internet, and are thus subject to attacks, and the cloud man- agement interfaces that run in a protected, de-militarized zone New virtual machines can be created on the fly from images, machines can be shut down, and the routing of traf- fic to machines be dynamically configured|,Non-data,75
| The platforms also virtualize the storage for the virtual machines, ie, they offer different kinds of abstraction of hard-disks such as file system, block store, object store, etc The management of all of this is typically a manual process via a web interface in the de-militarized zone, but can easily be automated with scripts, which is how it should be done for our protocol|,Non-data,75
| i i i i ,S (j) ,    ,S (j−1) The main idea to implement our scheme in this setting is that each server is realized with its own cloud platform (cf|,Non-data,75
| Figure 8) Thus, each server Si (and analogously LS) consists of a cloud platform, a number of virtual machines S (0) ,   |,Non-data,75
| that are run on the cloud platform on a (physical) machine ̄Si The cloud platform is usually a single physical machine or a cluster of them The virtual machines are exposed to the internet while the cloud plat- form and ̄Si are run in the de-militarized zone, ie|,Non-data,75
|, in a protected environment For each epoch j, a fresh virtual machine S (j) is started on the cloud platform These virtual machines run the account creation and the login protocols and access their states from the virtual storage provided by the cloud platform The machine ̄Si controls the cloud platform, maintains the images for the virtual machines S (j) , and prepares the state (storage) that is given to each S (j) in order for them to run the account creation and the login request protocols|,Non-data,75
| Indeed, ̄Si needs to be connected only to the cloud soft- ware platform and in practice such connections are typically physically isolated To prepare the state for the S (j) ’s, the machine ̄Si runs the initialization protocol, which requires LS to securely send a message to each of the Si’s As this is a one-time event that will be part of setting up the overall system, this communication can for instance be realized by writing the messages to a physical medium such as a USB drive and distribute it by courier In fact, the master keys could even be written on paper and entered manually, as each server in our protocol receives only n·κ bits, amounting to about 18n alphanumeric (7-bit) characters for practical scenarios with κ = 128|,Non-data,75
| The master keys for Si are stored in backup memory that is available to ̄Si but not to any of the instances S (j)  During refresh, ̄Si derives the initial state for S (j) for the next epoch from the master keys and updates the master keys in the backup memory i i i i i 7 IMPLEMENTATION To demonstrate the practical feasibility and test the per- formance of our protocols, we created a prototype imple- 193Table 1: Performance figures of our first protocol over the NIST P-256 elliptic curve|,Non-data,75
 # dedicated cores S3 S2 n LS 2 1 1 4 8 1 16 1 16 1 16 2 3 16 S1 2 4 8 8 16 16 16 throughput (logins/s) mean 94 71 53 90 50 59 53 delay (ms) 99% 155 111 79 153 86 94 85 40 80 157 214 310 293 285 16 16 16 mentation in Java We implemented our first construction (without pairings) over the NIST P-256 elliptic curve using SHA-256 as a hash function All elliptic-curve operations are performed using the Bouncy Castle cryptographic library We expect that performance can be considerably improved by using other libraries or implementation languages,Non-data,75
| We tested our implementation on a commercial cloud in- frastructure for different numbers of dedicated 29 GHz com- puting cores for each server Selected performance numbers for login protocols, the most relevant operation, are sum- marized in Table 1 Roughly, our prototype implementa- tion handles about 20 logins per second and per server core dedicated to the LS|,Non-data,75
| The mean computation and commu- nication delay incurred from the moment that LS receives the request until it reaches a decision is always below 100 milliseconds, with a 99 percentile well below 200 ms, small enough to not be noticeable to the user Since the LS performs two exponentiations in each login protocol, versus only one for each Si, each Si takes slightly more than half of the computational resources of the LS It would therefore make sense to assign more computational power to the LS than to each Si Because all servers Si operate in parallel, increasing the number of servers n has only a minor impact on the throughput and delays|,Non-data,75
| Acknowledgements This work was supported by the European Commission’s Seventh Framework Programme under the PERCY grant (agreement #321310) and the FutureID project (agreement #318424) We are very grateful to Daniel Kovacs and Franz- Stefan Preiss for their work on the prototype implemen- tation and performance testing, as well as for their valu- able feedback We would also like to thank Marc B ̈utikofer, Robin K ̈unzler, Christoph Lucas, and Adrian Schneider for their feedback and implementing our protocol at Ergon 8|,Non-data,75
|Abstract In the setting of secure multiparty computation, a set of parties with private inputs wish to compute some function of their inputs without revealing anything but their output Over the last decade, the efficiency of secure two-party com- putation has advanced in leaps and bounds, with speedups of some orders of magnitude, making it fast enough to be of use in practice In contrast, progress on the case of multiparty computation (with more than two parties) has been much slower, with very little work being done Currently, the only implemented efficient multiparty protocol has many rounds of communication (linear in the depth of the circuit being computed) and thus is not suited for Internet-like settings where latency is not very low|,Non-data,76
| In this paper, we construct highly efficient constant-round protocols for the setting of multiparty computation for semi- honest adversaries Our protocols work by constructing a multiparty garbled circuit, as proposed in BMR (Beaver et al, STOC 1990) Our first protocol uses oblivious transfer and constitutes the first concretely-efficient constant-round multiparty protocol for the case of no honest majority|,Non-data,76
| Our second protocol uses BGW, and is significantly more efficient than the FairplayMP protocol (Ben-David et al, CCS 2008) that also uses BGW We ran extensive experimentation comparing our differ- ent protocols with each other and with a highly-optimized implementation of semi-honest GMW Due to our protocol being constant round, it significantly outperforms GMW in Internet-like settings|,Non-data,76
| For example, with 13 parties situated in the Virginia and Ireland Amazon regions and the SHA256 ∗ Supported by Israel Science Foundation grant 544/13, the cyber se- curity research center at Ben Gurion University, and by the Frankel center for computer science † Supported by the European Research Council under the ERC con- solidators grant agreement n 615172 (HIPS) and by the BIU Center for Research in Applied Cryptography and Cyber Security in conjunc- tion with the Israel National Cyber Bureau in the Prime Minister’s Office ‡ istry and by Israel Science Foundation grant 544/13|,Non-data,76
| Supported by a grant from the Israeli Science and Technology min- Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita- tion on the first page Copyrights for components of this work owned by others than ACM must be honored Abstracting with credit is permitted To copy otherwise, or re- publish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee|,Non-data,76
| Request permissions from Permissions@acmorg CCS’16, October 24-28, 2016, Vienna, Austria c(cid:13) 2016 ACM ISBN 978-1-4503-4139-4/16/10|,Non-data,76
   $1500 DOI: http://dx,Non-data,76
|doiorg/101145/29767492978347 circuit with 90,000 gates and of depth 4000, the overall run- ning time of our protocol is 25 seconds compared to 335 seconds for GMW|,Non-data,76
| Furthermore, our online time is under half a second compared to 330 seconds for GMW 1 INTRODUCTION 11 Background In the setting of secure multiparty computation (MPC), a set of parties wish to compute a joint function of their private inputs without revealing anything but the output|,Non-data,76
| Protocols for secure computation guarantee privacy (mean- ing that the protocol reveals nothing but the output) and correctness (meaning that the correct function is computed), in the presence of adversarial behavior There are two classic adversary models that are typically considered: semi-honest (where the adversary follows the protocol specification but may try to learn more than is allowed from the protocol transcript) and malicious (where the adversary can run any arbitrary polynomial-time strategy in its attempt to breach security) In this paper, we focus on the multiparty setting and semi-honest adversaries Our focus is on the construc- tion of concretely efficient protocols for this case (where by “concrete efficiency” we mean faster run time in practice)|,Non-data,76
| Two paradigms for secure computation There are two main paradigms for constructing general secure two- party and multiparty computation protocols that can be used to securely compute any function The GMW (Goldreich- Micali-Wigderson) paradigm [15] works by having the par- ties interact to compute every (AND) gate in the circuit (this approach is also followed for information-theoretic protocols and arithmetic circuits) Such protocols typically send very little bandwidth per gate, but suffer from multiple rounds of communication, being linear in the depth of the circuit|,Non-data,76
| They are therefore very fast in LAN settings, but very slow when communicating over the Internet In contrast, in the garbled-circuit paradigm [32] an entire circuit is constructed in a way that enables it to be evaluated without reveal- ing anything but the output The original construction by Yao [32] worked only for two parties, and the notion of a multiparty garbled circuit was later shown by BMR (Beaver- Micali-Rogaway) in [5] Such protocols are typically slower in LAN settings since they require much more bandwidth, but have the potential to be much faster on slower net- works like the Internet since they have a constant number of rounds|,Non-data,76
| 578Concrete efficiency and the last decade Secure two- party computation has progressed in the past decade in leaps and bounds It has progressed from a notion of theoretical interest only, into a technology that is even being commer- cialized by multiple companies In order to demonstrate this progress, we go back to the first implementation of Yao’s gar- bled circuits in Fairplay [29] in 2004|,Non-data,76
| In this paper, they ran a secure computation on a “large circuit” with 4383 gates overall, with security in the presence of semi-honest adver- saries On a LAN, their protocol ran in 709 seconds In 2014, it takes approximately 16 milliseconds to run an anal- ogous execution on a circuit that is about 5 times the size with over 22,000 gates, of which 6800 are AND gates [17]|,Non-data,76
|1 This therefore constitutes a multiplicative improvement of approximately 2000 (or over 3 orders of magnitude) Ob- serve that Moore’s law (the version saying that computing power doubles every 2 years) can only account for a speedup of a factor of 32 This amazing progress was due to a long series of works that focused on all cryptographic and algo- rithmic aspects of the problem, as well as the advent of ubiq- uitous crypto hardware acceleration in the form of AES-NI and more; see [25, 20, 18, 3, 6, 31, 33] for just some exam- ples The current situation is that we now have a very good understanding of the cost of secure two-party computation in practice|,Non-data,76
| We stress that not only did these works yield impressive progress for protocols that are secure for semi-honest adver- saries, they also fueled progress for protocols that are se- cure for malicious adversaries In particular, the techniques and methods used to speed up garbled circuit generation and evaluation were directly incorporated in protocols for malicious adversaries, and fast OT extensions for the semi- honest case served as a basis for fast OT extensions for the malicious case Analogously, the first implementation of a multiparty pro- tocol (with more than two parties) was FairplayMP [7] in 2008, which followed the multiparty garbled circuit approach of [5] The largest circuit they computed had 1024 gates, and the time it took to run the protocol ranged from approxi- mately 10 seconds for 5 parties to 55 seconds for 10 parties|,Non-data,76
| In 2012, [10] implemented the GMW protocol for the multi- party setting For a circuit with 5,500 AND gates (about 5 times that of FairplayMP), they reported times ranging from approximately 7 seconds for 5 parties to about 10 seconds for 10 parties2 Surprisingly, to the best of our knowledge, there has been no additional work on general (circuit-based) multiparty secure computation for the case of semi-honest adversaries and no honest majority3 In particular, there have been no improvements to the multiparty garbled circuit approach since FairplayMP, and the time that it takes to run multiparty computations is orders of magnitude more than for two-party computations|,Non-data,76
| Furthermore, the FairplayMP 1 Indeed, we are comparing the total number of gates, since the in- vention of free-XOR is one of the factors involved in the progress that took place over this decade 2 The implementation of [10] is actually highly optimized and per- forms far better than reported This is because they included the initial synchronization of communication in their times, which can include large delays unless done carefully We use their code for our comparisons, but run the timer only once the actual MPC protocol be- gins|,Non-data,76
| 3 In contrast, work has been done for malicious adversaries; eg [12, 27, 28] However, the basic semi-honest case has been skipped over, and along with it techniques and understanding that are extremely valuable for the malicious case as well|,Non-data,76
| protocol is only secure for an honest majority Thus, no concretely-efficient constant-round multiparty protocol for the case of no honest majority semi-honest adversaries has ever been described or implemented We remark that the multiparty setting is needed for many applications like auctions, trading, elections, privacy-preser- ving surveys and more Thus, we believe that it is of great importance to remedy the current situation where efficient multiparty computation lags so far behind efficient two-party computation|,Non-data,76
| 12 Our contributions In this paper, we study the problem of multiparty com- putation with semi-honest adversaries We have three main contributions: 1 We present the first concretely-efficient constant-round multiparty protocol that is secure for any number of cor- rupted parties|,Non-data,76
| Our protocol is based on the multiparty garbled-circuit approach of [5], and requires each party to run an oblivious transfer with every other party per gate in order to construct the garbled circuit 2 Following FairplayMP [7], we also present protocols for constructing a multiparty garbled circuit based on BGW [8] (BenOr-Goldwasser-Wigderson), that are secure for an honest majority Our protocols are far more efficient than those presented in [7]|,Non-data,76
| 3 We ran extensive experiments comparing the performance of our different protocols to each other and to multi- party GMW We ran experiments over 3 different net- works, with different numbers of parties, and with dif- ferent circuits Our results deepen our understanding of the impact of round complexity on efficiency, and which protocols are suited to low and high latency networks|,Non-data,76
| Our protocols are all secure for semi-honest adversaries Semi- honest security is sufficient when parties somewhat trust each other, but are concerned with inadvertent leakage or cannot share their raw information due to privacy regula- tions It is also sufficient in cases where it is reasonable to as- sume that the parties running the protocol are unable to re- place the installed code Nevertheless, security against mali- cious adversaries is preferable, providing far higher guaran- tees|,Non-data,76
| However, such protocols will always be far less efficient In addition, we argue that the first step towards obtaining highly efficient protocols for malicious adversaries is to un- derstand the semi-honest case and how it can be made very efficient This was indeed the case for two-party compu- tation, where optimizations and work carried out for the semi-honest case was an important factor towards obtaining efficient protocols for the case of malicious adversaries Before proceeding, we remark that the garbled-circuit ap- proach in the multiparty case is fundamentally different to the two-party case and introduces many difficulties|,Non-data,76
| In the two-party case, one party constructs the garbled circuit and the other evaluates it Thus, the computation involved in constructing and evaluating the garbled circuit is local In contrast, in the multiparty case, it is not possible for one party to construct the garbled circuit on its own This is due to the fact that if that party colludes with one of the parties evaluating the circuit, then the parties’ inputs will all be revealed (since the party who constructed the circuit knows all of the keys)|,Non-data,76
| Rather, it is necessary for all of the 579parties to collaboratively construct the circuit via a secure protocol Thus, an efficient instantiation of this approach requires (a) an efficient garbled-circuit approach, and (b) an efficient way of collaboratively generating it Note that the construction of the garbled circuit (which is the more expensive part of the protocol) can be carried out in an of- fline phase Then, once inputs are received, an online phase can be run with very minimal communication and just local evaluation of the multiparty garbled circuit|,Non-data,76
| We will now elaborate on each of our major contributions Dishonest majority As we have mentioned, [7] designed a protocol for securely computing a multiparty garbled cir- cuit using the BGW protocol Since the construction of a garbled gate requires multiplication between a large value and a bit, this lends itself naturally to an arithmetic cir- cuit approach|,Non-data,76
| However, this introduces many complica- tions in [7], especially since they work over a prime-order finite field In contrast, we observe that multiplication of a string by a bit can actually be carried out with a single string oblivious transfer (OT) Furthermore, bit and string OT is very cheap today, due to the extremely fast OT exten- sion protocols that exist that reach rates of approximately only one microsecond per oblivious transfer on a LAN and whatever the latency is on slower networks [20, 3] In addi- tion to our basic protocol, we show how approximately 1/4 of the OT cost can be removed|,Non-data,76
| This uses a novel approach that enables us to compute one of the entries in each garbled gate by sending a single message and combining it with the results of the OTs used to compute the other entries in the garbled gate We then further reduce the cost by utilizing the fact that we actually only need a variant of OT, called correlated OT, which is even more efficient [3] Finally, we are the first to incorporate free-XOR [25] into a multiparty garbled circuit Previous works did not utilize free-XOR [7, 28] since they work over a prime-order finite field|,Non-data,76
| Needless to say, as in the two-party case, this optimization is crucial for obtaining high performance We remark that the incorporation of garbled-circuit opti- mizations that exist for the two-party case is not necessarily straightforward This is because the circuit must itself be computed via a secure protocol For example, we do not know how to efficiently perform garbled row-reduction when building a multiparty garbled circuit|,Non-data,76
 This makes the half- gates optimization for Yao’s garbled circuits [33] unsuitable since it is less efficient when there is no row reduction We conjecture that row reduction (and thus half-gates) is not suitable for the multiparty setting Honest majority The FairplayMP multiparty garbled- circuit construction used BGW and worked over a prime- order finite field,Non-data,76
| As we have mentioned, this has some dis- advantages: first, it is not compatible with the free-XOR op- timization; second it requires an additional multiplication to convert shares of values which may be {−1, +1} into shares of bits in {0, 1} In contrast, we work over GF (2128) which is of characteristic 2 This enables us to incorporate free- XOR and to save the multiplication to convert {−1, +1} to {0, 1} As another benefit of using free-XOR, we were able to define a formula for computing each value in each gar- bled gate that saves an additional multiplication|,Non-data,76
| Thus, [7] require 4 secure multiplications per element per gate inside BGW, whereas we only require 2 secure multiplications per element per gate inside BGW Beyond computational costs, this reduces the round complexity from 6 to 4 Experimental evaluations We ran multiple experiments to compare our different constant-round protocols to each other as well as to a highly optimized implementation of GMW [10]|,Non-data,76
| These are described in depth in Section 4 Our code is open-source and available in the SCAPI library [2] to enable others to reproduce our results and compare to future work Our results show that for computing deep circuits on Internet-like networks, our protocols way outperform GMW For example, in executions ran on Amazon with ma- chines communicating between Virginia and Ireland (with a 75ms round-trip) on the SHA256 circuit with 90,000 AND gates and depth 4,000, the GMW protocol took over 5 min- utes (for 3 to 13 parties) whereas our protocol ranged from about 6 seconds for 3 parties to 25 seconds for 13 parties|,Non-data,76
| Furthermore, the vast majority of the time in GMW is the online time whereas the vast majority of the time in our pro- tocol is the offline time Thus, we obtain online times rang- ing from 170ms to 455ms for 3 and 13 parties, respectively, while the online time for GMW is approximately 5 minutes To our surprise, our protocol that is secure without an honest majority and uses oblivious transfer is almost al- ways more efficient than our protocols based on BGW This was unexpected since oblivious transfer uses cryptographic operations, whereas BGW uses only simpler information- theoretic operations|,Non-data,76
| However, a closer look shows that the number of field multiplications in BGW is actually cubic in the number of parties, whereas the cost in the oblivious- transfer protocol is quadratic Combining this with the fact that the best oblivious transfer extension protocols today [3, 24, 22] are so fast, the BGW protocol only outperforms the oblivious transfer a small number of parties Another interesting outcome from our experiments is that the GMW protocol actually performs very well on low-depth circuits or in very fast networks This is due to the fact that when the circuit is shallow then the number of rounds in GMW is also small|,Non-data,76
| In this case, the small bandwidth is a big advantage over the garbled circuit approach which requires large message transmission In addition, in fast networks with very low latency, GMW’s many rounds does not significantly affect the running time Conclusions In the setting of secure multiparty compu- tation over the Internet (which is the natural setting for the aforementioned applications of auctions, elections, privacy- preserving surveys and so on), our protocol following the garbled circuit approach is much faster than all previous protocols|,Non-data,76
| Furthermore, our protocol has an extremely fast online time, making it suitable for scenarios where prepro- cessing is possible and fast response time is needed It is important to also note that the complexity of GMW grows linearly in the number of parties, in contrast to the multiparty garbled-circuit approach which is quadratic in the number of parties (we count the complexity per party, and thus linear complexity for GMW means that each party’s work is linear in the number of parties per gate) Thus, when the number of parties is very large, this cost can be significant A very interesting open question coming out of our work is whether or not it is possible to construct and evaluate a multiparty garbled circuit in time that is linear in the number of parties, with concrete efficiency|,Non-data,76
| 58013 Related Work As we have mentioned, there has been a long line of work optimizing secure two-party computation, both in the semi- honest and malicious settings; cf [25, 20, 18, 3, 6, 31, 33] The first protocol implemented for the multiparty setting with semi-honest adversaries was that of FairplayMP [7] in 2008|,Non-data,76
| Later, in 2012, a highly optimized version of the mul- tiparty GMW protocol for semi-honest adversaries was pre- sented by [10] This implementation uses oblivious transfer extensions [20], making the cost of the oblivious transfers in- significant In addition, [10] run all of the oblivious transfers on random input in an offline phase, and then only need to send a single bit in each direction per oblivious transfer in the online phase This makes the online phase very fast with very little bandwidth|,Non-data,76
| For the specific case of three parties, the Sharemind protocol achieves fast computation [9], but only for 3 parties and only for an honest majority In addi- tion, their protocol also has many rounds, like GMW, and so is not suitable for Internet-like settings The recent work of [30] achieves malicious security for 3 parties with an hon- est majority using Yao garbled-circuits, but does not extend to beyond 3 parties In addition to the work on semi-honest multiparty compu- tation, there has been work on multiparty computation that is secure in the presence of malicious adversaries The SPDZ protocol [13, 12], with improvements in [23], is the state- of-the-art in this area|,Non-data,76
| The offline phase of these works is over an order of magnitude slower than ours, which is fully justified by the fact that they achieve security for malicious adversaries which is much more difficult More significantly, the SPDZ protocol’s online time follows the GMW paradigm (but is somewhat more expensive due to the necessity to en- force correctness) Thus, in a slow network, it suffers from the same problems as the GMW protocol that we compare with here Other protocols for the multiparty setting that fo- cus on efficiency include [21] and [27]; however, these proto- cols have not been implemented and seem to be considerably slower in practice|,Non-data,76
| The closest comparison to our protocol in the malicious setting is that of [28] which uses SPDZ in order to build a multiparty garbled circuit Thus, [28] is expected to have an online time similar to that of our proto- col However, its offline time is estimated at over 400 seconds for 3 parties computing the AES circuit (over two orders of magnitude slower than ours) We stress that this discussion regarding protocols secure for malicious adversaries is not for the purpose of comparing our protocol (since we only achieve semi-honest security) but to stress that the semi- honest model yields far more efficient protocols and is thus important to study for applications where semi-honest se- curity suffices|,Non-data,76
| The comparison also highlights that much progress is needed in this area; our belief is that improve- ments for the semi-honest case will significantly help in the malicious case as well 2 THE BMR PROTOCOL 21 Background As we have mentioned, in the BMR protocol the par- ties construct a multiparty analog of Yao’s garbled circuit|,Non-data,76
| In Yao’s garbled circuit construction, random labels (which are just keys) are assigned to each wire; one label repre- sents the 0-value and the other label represents the 1-value Then, each gate is constructed by encrypting the appropri- ate output-wire label with the appropriate input-wire label For example, let g be an AND gate with input wires u, v and output wire w, and let κ denote the security parame- ter Furthermore, let ku,0, ku,1 ∈ {0, 1}κ denote the labels on wire u, and likewise for wires v and w|,Non-data,76
| Then, kw,0 is double encrypted under ku,0, kv,0, under ku,0, kv,1, and un- der ku,1, kv,0, while kw,1 is double encrypted under ku,1, kv,1 Observe that given a single label on each input wire, it is pos- sible to compute the correct output-wire label by decrypting the single ciphertext that can be decrypted with one label on each input wire Furthermore, by providing these cipher- texts in random order, the party computing the gate has no idea whether it obtained kw,0 or kw,1 (since they are both just random values) Thus, the party evaluating the circuit learns nothing at all from the computation|,Non-data,76
| In the setting of two parties, one party prepares the garbled circuit and the other evaluates it In the multiparty setting, all the parties must prepare the garbled circuit together, and it must have the property that no subset of colluding parties can learn anything about what value is being computed The multiparty garbled circuit is therefore constructed by having all parties contribute to the garbling of every gate In particular, all n parties choose their own random 0-labels and random 1-labels on every wire, and the output wire labels are encrypted separately under every single party’s input wire labels|,Non-data,76
| Thus, a single honest party’s input-wire labels hide the output-wire labels from all other parties Let ki u,b be the input-label that party Pi holds for value b ∈ {0, 1} on wire u; likewise for wires v and w Since there are n parties and n output-wire labels for each value b ∈ {0, 1}, the encryption works by masking all of k1 v,1) and v,0) To be more exact, let F 2 denote a double-key (ki pseudorandom function that takes two keys k, k(cid:48) and main- tains security as long as at least one key is secret|,Non-data,76
| Abusing notation and denoting the gate function by g(·,·) (as well as the gate index by g), we have that for every a, b ∈ {0, 1} the output labels of all parties P1,    , Pn associated with the bit g(a, b) are encrypted by w,0 with each pair (ki w,0, |,Non-data,76
|   , kn u,1, ki u,0, ki v,0), (ki u,0, ki (cid:33) (cid:41)n (cid:40)(cid:32) n(cid:77) i=1 F 2 u,a,ki ki v,b (g ◦ j) ⊕ kj w,g(a,b) (1) j=1 w,g(a,b),  |,Non-data,76
|  , kn where ◦ denotes string concatenation Observe that the keys on the input wires of all of the parties are needed in or- der to learn k1 w,g(a,b) (the concatenation of all keys/labels is called the “superseed” in [5, 7]) We remark that the value input to the PRF is the gate number followed by the index of the label being masked|,Non-data,76
| This ensures that all output-wire labels are masked with independent values In order to hide which values of a and b are being dealt with, the “point-and-permute technique” (that was originally invented by BMR) is used According to this technique, a random secret “permutation bit” λu is associated with every wire u (this is achieved by each party Pi choosing a random u and setting λu = ⊕n λi u) Then, if the actual bits on inputs wire u and v to gate g are a and b, then the parties see λu ⊕ a and λv ⊕ b, and this guides them as to which ciphertext to decrypt|,Non-data,76
| In addition, they obtain the output λw ⊕ g(a, b) that enables them to proceed to the next gate i=1λi Constructing the multiparty garbled circuit In the first part of the protocol, the parties run a secure protocol 581to compute the garbled circuit This phase is independent of the parties’ actual inputs and so can therefore be run in a separate offline phase|,Non-data,76
| The important property that is the “BMR claim-to-fame” is the fact that the entire circuit can be constructed in a constant number of rounds, inde- pendently of the depth of the circuit This is due to the fact that the circuit computing a multiparty garbled gate is very shallow, and all garbled gates can be computed in parallel (since given the garbled labels on all wires, each gate can be independently computed) Thus, it is possible to use any protocol for general secure computation with round com- plexity linear in the depth of the circuit in order to securely compute a multiparty garbled circuit in a constant number of rounds (irrespective of its depth) Intuitively, each party (g ◦ j) for every a, b ∈ {0, 1} Pi locally computes F 2 u,a,ki ki and j ∈ [n], and these are input to a circuit that computes the gate|,Non-data,76
| Observe that this means that each party must carry out 4n double-key PRF computations per gate v,b u,a and k1 v,b,   |,Non-data,76
| , kn u,a,    , kn w,g(a,b), |,Non-data,76
|   , kn Evaluating the BMR circuit As with Yao’s garbled cir- cuits, given the sets of n keys k1 v,b, it is possible to decrypt a single row in the garbled gate and obtain k1 w,g(a,b)|,Non-data,76
| This method can therefore be used to evaluate the entire circuit Furthermore, once the parties receive the sets of keys on every circuit-input wire, they can each locally compute the entire circuit and obtain the output Thus, the online running-time of the protocol is very small: parties send a very small amount of information, and then the entire circuit is just locally computed Observe that in order to carry out the gate computation, each party (g ◦ n), for needs to compute F 2 u,a,ki ki i = 1, |,Non-data,76
|   , n Thus, evaluation of the multiparty garbled circuit requires n2 PRF computations per gate|,Non-data,76
| 22 Free XOR (g ◦ 1),   |,Non-data,76
| , F 2 u,a,ki ki v,b v,b In this section, we describe how we incorporated the free- XOR optimization into the multiparty garbled circuit The original work by BMR [5], and the FairplayMP [7] system were both published before the free-XOR technique [25] This technique enables XOR gates to be computed for free in Yao’s garbled circuits, and has become standard for use in that setting In the recent BMR-SPDZ protocol of [28] that uses BMR to achieve security in the presence of mali- cious adversaries, free XOR was also not incorporated|,Non-data,76
| This seems to be due to the fact that they work in a finite field of prime order (in order to optimize the SPDZ portion of the protocol) and this does not lend itself to free XOR Our first optimization in this work is to incorporate free-XOR into BMR This is important for two reasons First, and most obviously, free-XOR reduces the number of AES op- erations in garbling and evaluating the circuit|,Non-data,76
| Since eval- uation requires n2 AES operations per gate (for n parties), this is significant Second, free-XOR significantly reduces the bandwidth of the garbled circuit since only AND gates require encryptions The large amount of communication in BMR is problematic and so this is important Intuitively, the free XOR in BMR works in the same way as in Yao|,Non-data,76
| For every i = 1,    , n, a fixed (random) differ- ence parameter Ri ∈ {0, 1}κ is chosen (known only to Pi)|,Non-data,76
| Then, for every wire w, the label ki w,0 is random whereas w,0 ⊕ Ri Due to this relation, the label k1 XOR gates can be computed by simply XORing the garbled labels on the input wires, and taking the garbled label on w,1 is set to equal ki the output wire to be the result We formally describe the functionality that outputs a BMR circuit in Figure 1; this functionality needs to be securely computed in the offline phase We design the functionality in a way that minimizes the computation necessary within the secure computation protocol (thus, all shares of all values are prepared by par- ties before running FGC )|,Non-data,76
| Functionality FGC for Constructing a Multiparty Garbled Circuit Inputs: All parties hold the circuit C, the number of parties n, and the security parameter κ In addition, each party Pi has the following private inputs: 1 A global difference string Ri ∈ {0, 1}κ 2|,Non-data,76
| A share λi w ∈ {0, 1} of the permutation bit for every w,1 ∈ {0, 1}κ of the garbled labels for w ∈ w,1 ∈ {0, 1}κ values are chosen in every wire w ∈ W  (As described in Section 23 (Figure 2), the λi {0, 1} and ki a special way to enable free XOR) 3|,Non-data,76
| Its parts ki w,0, ki w,0, ki wire w Computation: The functionality computes the garbled circuit GC For every AND gate g ∈ C with input wires u, v and output wire w, every α, β ∈ {0, 1}, and every j ∈ [n], compute: (cid:33)  ̃gj α,β = (cid:32) n(cid:77) ⊕(cid:16) i=1 (g ◦ j) ⊕ kj v,β w,0 F 2 u,α ,ki ki Rj · ((λu ⊕ α) · (λv ⊕ β) ⊕ λw) α,β ◦ · · · ◦ ̃gn ̃g1 (cid:16) (cid:17) (2) (cid:17) α,β Outputs: The functionality outputs for every g and every α, β ∈ {0, 1} to all parties Figure 1: Functionality FGC We explain the computation of ̃gj α,β in Figure 1|,Non-data,76
| The permutation bits λu, λv, λw randomly permute the values on each wire In particular, the parties see α, β on the input wires, but the actual value on wires u and v are α ⊕ λu and β⊕λv, respectively (Since λu, λv are random, it follows that α, β reveal nothing about the actual values, as required) Now, it follows that the output of the AND gate is exactly (λu ⊕ α) · (λv ⊕ β) since this is the product of the actual values|,Non-data,76
| Assume for a moment that λw = 0 Then, ̃gj α,β will w,0 if (λu ⊕ α) · (λv ⊕ β) = 0, and be an encryption of kj otherwise it will be an encryption of kj w,1, as required In contrast, if λw = 1, then the result will be reversed Thus, this preserves the invariant that the parties hold the key kj w,b where b equals the XOR of the actual value on the wire with λw|,Non-data,76
| w,0 ⊕ Rj = kj In the full version of this paper, we formally prove security of the free-XOR construction in the context of BMR, under a correlation-robust circularity assumption as in [11] (which holds for a random oracle) 23 MPC Using Multiparty Garbled Circuits Given the functionality FGC , we now show how any multi- party functionality can be securely computed in a constant number of rounds We have already explained informally how the protocol works in Section 2|,Non-data,76
|1, and we now present the formal specification of the offline protocol and of the on- line phases These specifications assume an implementation of FGC which is the main protocol challenge, as we will see below in Section 3 582The MPC protocol that we describe is a variant of the BMR protocol and is designed in the FGC -hybrid model The main difference between this variant and the original BMR protocol is the fact that our BMR circuit incorporates free-XOR|,Non-data,76
| (Of course, our full protocol has additional dif- ferences in the efficient computation of FGC ) The protocol consists of two phases: Part 1 - the Offline Phase: In this phase, the parties first run a local computation to prepare their inputs to FGC  A formal specification of this local computation is given in Figure 2 Observe that the parties choose the wire labels in a special way in order to ensure that the free-XOR prop- erty works|,Non-data,76
| Next, the parties securely compute Functional- ity FGC in order to obtain the garbled circuit Finally, each party Pi sends its shares of the permutation bits λw on every circuit-output wire w In addition, all parties send Pi their shares of the permutation bits on the circuit-input wires as- sociated with Pi’s private input (Recall that a formal spec- ification of Functionality FGC appears above in Figure 1|,Non-data,76
|) The BMR Offline Phase 1 Each Pi chooses a random key offset Ri ∈R {0, 1}κ 2 For every wire w that is not the output of a XOR gate, each party Pi works as follows: (a) Pi chooses a random bit λi (b) Pi chooses its part of the 0-garbled label ki w as a share of λw|,Non-data,76
| w,0 ∈ {0, 1}κ at random w,0 ⊕ Ri w,1 = ki ki (c) Pi sets its part of the 1-garbled label to be 3 For every wire w that is the output of a XOR gate (in topological order over the circut) with input wires u, v and output wire w, each party Pi works as follows: (a) Pi sets its share of the permutation bit λi w = u ⊕ λi λi v|,Non-data,76
| (b) Pi sets its part of the garbled labels on wire w as ki w,0 = ki u,0 ⊕ ki v,0, and ki w,1 = ki w,0 ⊕ Ri w,0, ki 4 Each party Pi calls FGC with the inputs Ri, and λi w, ki w,1 for every wire w The parties receive back all garbled gates as output|,Non-data,76
| (This step involves running one of the protocols described in Section 3 for securely computing FGC ) all other parties, who all compute λw = ⊕n 5 For every circuit-output wire w, each Pi sends λi i=1λw w to w to Pi|,Non-data,76
| Party Pi computes λw = ⊕n 6 For every circuit-input wire w, if Pi’s is the party whose input is associated with wire w, then each Pj sends λj As in [7], this step can be skipped by having all parties Pj with j (cid:54)= i set λj w = 0 for all circuit-input wires w Figure 2: Offline phase – BMR circuit construction i=1λw Part 2 - the Online Phase: Given their private inputs, this phase begins with the parties broadcasting the XOR of their private input with the permutation bit on the asso- ciated wire|,Non-data,76
| Next, the other parties send the appropriate garbled labels Finally, each party locally computes the gar- bled circuit and obtains the output (using knowledge of λw on the output wire to convert the output garbled value into an actual output bit) Thus, the online phase consists of very little communication and primarily local computation A formal specification of this phase is given in Figure 3|,Non-data,76
| The BMR Online Phase 1 Send garbled labels associated with inputs: For every circuit-input wire w: (a) Let Pi be the party whose input is associated with wire w and let xiw be Pi’s input bit as- sociated with the wire Then, Pi sends αw = xiw ⊕ λw to all parties, where λw = ⊕n i=1λi w For every wire w, we denote by αw the XOR of the actual value on the wire (based on the input) and λw; we call this the public value|,Non-data,76
| (b) Each party Pj sends its part kj w,αw of the gar- bled label on w to all other parties (c) At this point, each party holds k1 w,αw ,   |,Non-data,76
| , kn w,αw for every circuit-input wire 2 Local circuit computation: Each party locally evaluates the garbled circuit The circuit is evaluated by traversing the circuit in topological order, comput- ing the garbled labels on the output wire of each gate one at a time|,Non-data,76
| Each gate is computed as follows Let g be the cur- rent gate with input wires u, v and output wire w Let α and β be the public values on wires u and v, respectively (a) If g is a XOR gate, then each party computes the public value on the output wire w to be γ = α ⊕ β|,Non-data,76
| In addition, for every j = 1,    , n it computes kj u,α ⊕ kj w,γ = kj v,β |,Non-data,76
| (b) If g is an AND gate, then each party computes (cid:33) kj w,γ = ̃gj α,β ⊕ F 2 u,α,ki ki v,β (g ◦ j) (cid:32) n(cid:77) i=1 for every j ∈ [n], and for α, β which are the public values on wires u, v as above Given k1 w,γ ,   |,Non-data,76
| , kn w,γ , each party Pi compares the ith value to the garbled labels ki w,1 that it in- put in the offline phase on this wire If it equals ki w,0 then it sets the public value on wire w to be γ = 0; otherwise it sets γ = 1 w,0, ki 3 Output determination: For every output wire w, each party computes the actual output bit of wire w to be αw ⊕ λw, where αw is the public value on wire w and λw is as received in the offline phase|,Non-data,76
| Figure 3: Online phase – BMR circuit evaluation The following theorem follows directly from the security of the multiparty garbled circuit and how to use it, as proven in [5] (with our addition of free-XOR), and from the fact that FGC securely computes the circuit: Theorem 21 Let f be an n-party functionality Then, the Protocol in Figures 2 and 3 securely computes f in the presence of a semi-honest adversary corrupting any number of parties|,Non-data,76
| 24 The Double Key PRF Both the offline and the online phases use the double- key PRF F 2 We implemented F 2 in two ways: (1) by concatenating the two 128-bit keys and using it as a a single AES-256 key, as proposed by [26], (2) using fixed-key AES, as proposed by [6] Since the online time is dominated by the AES computations (with very little communication), fixed- key AES is considerably faster than the first method, even when AES-NI is used in both|,Non-data,76
| For the offline times, the difference between these 2 methods was minor 5833 SECURELY COMPUTING FGC It is clear that the online phase of the protocol is fast, as it is essentially n2 times the cost of locally computing a standard Yao garbled circuit, where the latter is known to be extremely fast [6] Thus, the main challenge in making the protocol concretely efficient is in constructing an efficient protocol that securely computes the multiparty garbled cir- cuit|,Non-data,76
| Stated differently, the goal is to construct an efficient protocol that securely computes the FGC functionality The original BMR protocol [5] considered an honest ma- jority of parties, although this is only needed for achieving security in the presence of malicious adversaries In any case, [5] did not specify a concrete protocol for securely comput- ing FGC (or, more exactly their version of it), but rather stated that any secure protocol can be used In [7], they use the BGW protocol [8] for an honest majority in order to securely compute FGC |,Non-data,76
| Surprisingly, no concretely effi- cient protocol has been suggested to securely compute FGC without an honest majority We will present two main pro- tocols here: (1) a protocol for a dishonest majority using oblivious transfer (OT) as a black box, (2) several variants of the protocol based on BGW (with significant protocol improvements over [7]) 31 Protocol for No Honest Majority In this section, we present a protocol that securely com- putes FGC in the OT-hybrid model, in the presence of semi- honest adversaries|,Non-data,76
| As we have mentioned, this is the first concretely-efficient constant-round protocol for this setting Our protocol securely computes Eq (2) in Figure 1 for every j = 1,  |,Non-data,76
|  , n and all four choices of α, β ∈ {0, 1} Intuitively, in order to compute Eq (2), the parties will need to generate shares of Rj · ((λu ⊕ α) · (λv ⊕ β) ⊕ λw) for all j|,Non-data,76
| Observe that Pj holds Rj, and the other values are all shared (ie, each party holds λi u, and so on) As we will see, this computation can be reduced to a computation whereby parties securely compute XOR shares of the prod- uct of two parties’ input bits|,Non-data,76
 311 Secure Multiplication u and λu = ⊕n i=1λi Secure bit-bit multiplication The main operation that we use is the secure computation of XOR shares of the product of input bits,Non-data,76
