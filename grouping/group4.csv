 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| Specifically, Tendermint assumes all identities are known before the protocol starts, thus is not applicable in decen- tralized environments like cryptocurrencies Besides, Tendermint is essentially a variant of PBFT 4, which has its own scalability lim- itation if the network size grows as we discussed in Section 2 Plus, the network nodes in Ripple and Stellar are permissioned, hence it faces no challenges of establishing identities For instance, identi- ties in Stellar need financial agreements or reputations of others to form their “slices" (or committees)|,Non-data,4
| In Elastico, these have to be chosen randomly based on computational assumptions 4http://tendermintcom/posts/tendermint-vs-pbft/ 63 Prior Byzantine Consensus Protocols There have been significant efforts devoted to developing scal- able communication-efficient consensus protocols|,Non-data,4
| The idea of di- viding the users into committees (as we do in this paper) is preva- lent in the existing literature; first introduced by Bracha [46] If the users are honest, but crash prone, there exists an optimal algorithm with Θ(n) communication complexity based on the idea of universe reduction, ie, choosing a small committee to manage the process [47]|,Non-data,4
| If the users are malicious, it is much more difficult to achieve good communication complexity For many years, the best known protocols had exponential communication complexity [11, 12] A key improvement was made by Srikanth et al [14], who developed an efficient algorithm with polynomial communication complexity|,Non-data,4
| While the preceding algorithms generally assumed a synchronous network, there was also significant work on consensus in asyn- chronous and partially synchronous networks In a seminal paper, Castro et al [13] implemented a replicated state machine based on Byzantine agreement, often described as the first practical BFT sys- tem It led to a floor of work on Byzantine agreement, with many attempts to improve the efficiency and trade-off different aspects of the performance (e|,Non-data,4
|g, [48–51]) Despite these significant efforts, these protocols remained band- width limited, typically requiring Θ(n2) messages (or more) Over the last several years, there has been an exciting breakthrough [52– 55], reducing the communication complexity of agreement to O(n· polylog(n)) for a system with n players|,Non-data,4
| The basic idea is to first solve almost everywhere agreement, convincing most of the users to agree on a single value Then, a secondary almost-everywhere- to-everywhere protocol is used to spread the information to the re- maining laggards To achieve almost everywhere agreement, they assign the users to committees, and organize the committees into a tree with a guarantee that almost all the committees have a majority of honest users (using an adapted version of Feige’s leader election algorithm [56]) A leader is elected at the root of the tree, and then information is propagated down the tree to everyone|,Non-data,4
| Later, to cope with an adaptive adversary, secret sharing and additional informa- tion hiding techniques are needed [57] However, the protocols are complex and practical implementations are yet to be demonstrated ELASTICO is not directly comparable to these newer communi- cation efficient protocols: ELASTICO is simpler and works in open networks like cryptocurrencies where identities are unknown Its key advantage is in using computational power to tune the paral- lelization of network, yet detaining security on bounded computa- tional assumption|,Non-data,4
| ELASTICO is related to other protocols which use proof of work for processors to establish their identities [58–61] The main differ- ence here is that ELASTICO is a sharding protocol, and establishing identities is just the first step of the 5 major steps in the protocol 277 CONCLUSION We present ELASTICO, the first candidate for a secure shard- ing protocol for permissionless blockchains|,Non-data,4
| At its core, ELAS- TICO scales up the agreement throughput near linearly with the computational power of the network and tolerates byzantine adver- saries which controls up to one-forth computation capacity, in the partially synchronous network It offers promising scalability in experiments and suggest strong usability in next-generation cryp- tocurrencies 8 ACKNOWLEDGMENT We thank Dawn Song, Elaine Shi, Christian Cachin, Andrew Miller, Jason Teutsch, Shweta Shinde, Shruti Tople, Alex Zikai Wen, Hung Dang, Xiao Liu and Vincent Gramoli for useful dis- cussions and feedback on the early version of the paper|,Non-data,4
| This research is supported by the National Research Foundation, Prime Minister’s Office, Singapore under its National Cybersecu- rity R&D Program (Award No NRF2014NCR-NCR001-21) and administered by the National Cybersecurity R&D Directorate All opinions expressed in this work are solely those of the authors 9|,Non-data,4
|ABSTRACT We present a software approach to mitigate access-driven side-channel attacks that leverage last-level caches (LLCs) shared across cores to leak information between security do- mains (eg, tenants in a cloud) Our approach dynami- cally manages physical memory pages shared between secu- rity domains to disable sharing of LLC lines, thus prevent- ing “Flush-Reload” side channels via LLCs|,Non-data,5
| It also man- ages cacheability of memory pages to thwart cross-tenant “Prime-Probe” attacks in LLCs We have implemented our approach as a memory management subsystem called CacheBar within the Linux kernel to intervene on such side channels across container boundaries, as containers are a common method for enforcing tenant isolation in Platform- as-a-Service (PaaS) clouds Through formal verification, principled analysis, and empirical evaluation, we show that CacheBar achieves strong security with small performance overheads for PaaS workloads Keywords Cache-based side channel; prime-probe; flush-reload 1|,Non-data,5
| INTRODUCTION An access-driven side channel is an attack by which an at- tacker computation learns secret information about a victim computation running on the same computer, not by violat- ing the logical access control implemented by the isolation software (typically an operating system (OS) or virtual ma- chine monitor (VMM)) but rather by observing the effects of the victim’s execution on microarchitectural components it shares with the attacker Overwhelmingly, the components most often used in these attacks are CPU caches Early cache-based side channels capable of leaking fine-grained in- formation (eg|,Non-data,5
|, cryptographic keys) across security bound- aries used per-core caches (eg, [28, 10, 34]), though the need for the attacker to frequently preempt the victim to observe its effects on per-core caches renders these attacks Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page Copyrights for third-party components of this work must be honored|,Non-data,5
| CCS’16 October 24-28, 2016, Vienna, Austria c(cid:13) 2016 Copyright held by the owner/author(s) ACM ISBN 978-1-4503-4139-4/16/10 DOI: http://dxdoi|,Non-data,5
org/101145/29767492978324 relatively easy to mitigate in software (eg,Non-data,5
|, [37, 29]) Of more concern are side channels via last-level caches (LLCs) that are shared across cores and, in particular, do not require preemption of the victim to extract fine-grained information from it (eg, [33, 35, 12, 20])|,Non-data,5
| Two varieties of LLC-based side channels capable of ex- tracting fine-grained information from a victim have been demonstrated The first such attacks were of the Flush- Reload variety [33, 35], which requires the attacker to share a physical memory page with the victim—a common situa- tion in a modern OS, due to shared libraries, copy-on-write memory management, and memory deduplication mecha- nisms that aim for smaller memory footprints The attacker first Flushes a cache-line sized chunk of the shared page out of the cache using processor-specific instructions (eg|,Non-data,5
|, clflush in x86 processors) and later measures the time to Reload (or re-Flush [9]) it to infer whether this chunk was touched (and thus loaded to the shared cache already) by the victim More recently, so-called Prime-Probe at- tacks have been demonstrated via LLCs [12, 20]; these do not require page sharing between the attacker and victim Rather, Prime-Probe attacks can be conducted when the two programs share the same CPU cache sets The attacker Primes the cache by loading its own memory into certain cache sets|,Non-data,5
| Later it Probes the cache by measuring the time to load the same memory into the cache sets and inferring how many cache lines in each cache set are absent due to conflicts with the victim’s execution In this paper we propose a software-only defense against these LLC-based side-channel attacks, based on two seem- ingly straightforward principles First, to defeat Flush- Reload attacks, we propose a copy-on-access mechanism to manage physical pages shared across mutually distrust- ing security domains (ie|,Non-data,5
|, processes, containers1, or VMs) Specifically, temporally proximate accesses to the same phys- ical page by multiple security domains results in the page being copied so that each domain has its own copy In this way, a victim’s access to its copy will be invisible to an attacker’s Reload in a Flush-Reload attack When accesses are sufficiently spaced in time, the copies can be deduplicated to return the overall memory footprint to its original size|,Non-data,5
| Second, to defeat Prime-Probe attacks, we design a mechanism to manage the cacheability of memory pages so as to limit the number of lines per cache set that an attacker may Probe In doing so, we limit the visibil- ity of the attacker into the victim’s demand for memory that maps to that cache set Of course, the challenge in 1https://linuxcontainersorg/ 871these defenses is in engineering them to be effective in both mitigating LLC-based side-channels and supporting efficient execution of computations|,Non-data,5
| To demonstrate these defenses and the tradeoffs between security and efficiency that they offer, we detail their design and implementation in a memory management subsystem called CacheBar (short for “Cache Barrier”) for the Linux kernel CacheBar supports these defenses for security do- mains represented as Linux containers That is, copy-on- access to defend against Flush-Reload attacks makes page copies as needed to isolate temporally proximate accesses to the same page from different containers Moreover, mem- ory cacheability is managed so that the processes in each container are collectively limited in the number of lines per cache set they can Probe|,Non-data,5
| CacheBar would thus be well- suited for use in Platform-as-a-Service (PaaS) clouds that isolate cloud customers in distinct containers; indeed, cross- container LLC-based side channels have been demonstrated in such clouds in the wild [35] Our security evaluations show that CacheBar mitigates cache-based side-channel attacks, and our performance evaluation indicates that CacheBar imposes very modest overheads on PaaS workloads To summarize, we contribute: • A novel copy-on-access mechanism to manage physical memory pages shared by distrusting tenants to prevent Flush-Reload side-channel attacks, and its formal verification using model checking • A novel mechanism to dynamically maintain queues of cacheable memory pages so as to limit the cache lines a malicious tenant may access in Prime-Probe attacks, and a principled derivation of its parameters to balance security and performance|,Non-data,5
| • Implementation of both mechanisms in a mainstream Linux operating system kernel and an extensive secu- rity and performance evaluation for PaaS workloads 2 RELATED WORK Numerous proposals have sought to mitigate cache-based side channels with low overhead through redesign of the cache hardware, eg|,Non-data,5
|, [31, 13, 19] Unfortunately, there is little evidence that mainstream CPU manufacturers will de- ploy such defenses in the foreseeable future, and even if they did, it would be years before these defenses permeated the installed computing base Other proposals modify appli- cations to better protect secrets from side-channel attacks These solutions range from tools to limit branching on sen- sitive data (e|,Non-data,5
|g, [4, 5]) to application-specific side-channel- free implementations (eg, [15])|,Non-data,5
| However, the overheads of these techniques tend to grow with the scope of programs to which they apply and can be very substantial (eg, [25]) It is for this reason that we believe that systems-level (i|,Non-data,5
|e, OS- or VMM-level) defenses are the most plausible for de- ployment in the foreseeable future, and many have been pro- posed With attention to cache-based side-channels specifi- cally, several works provide to each security domain a limited number of designated pages that are never evicted from the LLC (eg|,Non-data,5
|, [14, 18]), thereby rendering their contents im- mune to Prime-Probe and Flush-Reload attacks These approaches, however, require the application developer to determine what data/instructions to protect and then to modify the application to organize the sensitive content into the protected pages; in contrast, CacheBar seeks to protect applications holistically and requires no application modifi- cations CacheBar also differs in several design choices that free it from limitations of prior approaches (eg|,Non-data,5
|, the limitation of only one protected page per core [14] or de- pendence on relatively recent, Intel-specific cache optimiza- tions [18]) Other systems-level solutions manage memory so as to partition the use of the LLC by different security domains (eg, [24, 26]), though these approaches preclude memory-page and CPU-cache sharing entirely and hence can underutilize these resources considerably|,Non-data,5
| Others have sug- gested disabling or selectively enabling memory sharing [22, 35, 3] for countering various side-channel attacks exploiting shared memory, while stopping short of exploring a complete design for doing so Our copy-on-access design provides an efficient realization of this idea for addressing Flush- Reload attacks, and extends this idea with cacheability management for Prime-Probe defense, as well LLC-based side channels are a particular instance of tim- ing side channels, and so defenses that seek to eliminate timing side channels are also relevant to our problem Ex- amples include fuzzing real-time sources (e|,Non-data,5
|g, [30]), though this impinges on legitimate uses of real time Since real-time counters are not the only way to time memory fetches [32], other efforts have sought to eliminate side-channel risks more holistically via altering the CPU scheduler (eg|,Non-data,5
|, [27, 17]) and managing how tenants co-locate (eg, [16, 36, 2, 17]) In contrast, here we focus specifically on LLC-based side channels (vs|,Non-data,5
| a larger subset of timing side-channels), which again are arguably the most potent known side-channel vec- tors [33, 35, 12, 20], and restrict our modifications to the memory management subsystem 3 COPY-ON-ACCESS The Flush-Reload attack is a highly effective LLC-based side channel that was used, eg|,Non-data,5
|, by Zhang et al [35] to mount fine-grained side-channel attacks in commercial PaaS clouds It leverages physical memory pages shared between an attacker and victim security domains, as well as the abil- ity to evict those pages from LLCs, using a capability such as provided by the clflush instruction on the x86 architec- ture clflush is designed to maintain consistency between caches and memory for write-combined memory [11]|,Non-data,5
| The attacker uses clflush, providing a virtual address as an ar- gument, to invalidate the cache lines occupied by the backing physical memory After a short time interval (the “Flush- Reload interval”) during which the victim executes, the at- tacker measures the time to access the same virtual address Based on this duration, the attacker can infer whether the victim accessed that memory during the interval 3|,Non-data,5
|1 Design Modern operating systems, in particular Linux OS, often adopt on-demand paging and copy-on-write mechanisms [7] to reduce the memory footprints of userspace applications In particular, copy-on-write enables multiple processes to share the same set of physical memory pages as long as none of them modify the content If a process writes to a shared memory page, the write will trigger a page fault and a sub- sequent new page allocation so that a private copy of page will be provided to this process In addition, memory merg- ing techniques like Kernel Same-Page Merging (KSM) [1] are also used in Linux OS to deduplicate identical memory pages|,Non-data,5
| Memory sharing, however, is one of the key factors that enable Flush-Reload side channel attacks Disabling 872An accessed page will be reset to the shared state if it is not accessed for ∆accessed seconds This timeout mechanism ensures that only recently used pages will remain in the ac- cessed state, limiting chances for unnecessary duplication Page merging may also be triggered by deduplication ser- vices in a modern OS (e|,Non-data,5
|g, KSM in Linux) This effect is reflected by a dashed line in Fig 1 from state exclusive to shared|,Non-data,5
| A page at any of the mapped states (ie, exclu- sive, shared, accessed) can transition to unmapped state for the same reason when it is a copy of another page (not shown in the figure) Merging duplicated pages requires some extra bookkeep- ing|,Non-data,5
| When a page transitions from unmapped to exclu- sive due to copy-on-access, the original page is tracked by the new copy so that CacheBar knows with which page to merge it when deduplicating If the original page is un- mapped first, then one of its copies will be designated as the new “original” page, with which other copies will be merged in the future The interaction between copy-on- access and existing copy-on-write mechanisms is also implic- itly depicted in Fig 1: Upon copy-on-write, the triggering process will first unmap the physical page, possibly inducing a state transition (from shared to exclusive)|,Non-data,5
 The state of the newly mapped physical page is maintained separately 32 Implementation At the core of copy-on-access implementation is the state machine depicted in Fig 1,Non-data,5
| unmapped ⇔ exclusive ⇔ shared Conventional Linux kernels maintain the relationship between processes and the physical pages they use However, CacheBar also needs to keep track of the relationship between containers and the physical pages that each container’s processes use There- fore, CacheBar incorporates a new data structure, counter, which is conceptually a table used for recording, for each physical page, the number of processes in each container that have Page Table Entries (PTEs) mapped to this page|,Non-data,5
| The counter data structure is updated and referenced in multiple places in the kernel Specifically, in CacheBar we instrumented every update of _mapcount, a data field in the page structure for counting PTE mappings, so that every time the kernel tracks the PTE mappings of a physical page, counter is updated accordingly The use of counter greatly simplifies maintaining and determining the state of a physical page: (1) Given a container, access to a single cell suffices to check whether a physical page is already mapped in the container This operation is very commonly used to decide if a state transition is required when a page is mapped by a process|,Non-data,5
| Without counter, such an operation requires performing reverse mappings to check the domain of each mapping (2) Given a physical page, it takes N accesses to counter, where N is the total number of containers, to tell which containers have mapped to this page This operation is commonly used to determine the state of a physical page shared ⇒ accessed|,Non-data,5
| To differentiate shared and ac- cessed states, one additional data field, owner, is added (see Fig 2) to indicate the owner of the page (a pointer to a PID_namespace structure) When the page is in the shared state, its owner is NULL; otherwise it points to the container that last accessed it All PTEs pointing to a shared physical page will have a reserved Copy-On-Access (COA) bit set|,Non-data,5
| Therefore, any Figure 1: State transition of a physical page memory page sharing entirely will eliminate Flush-Reload side channels but at the cost of much larger memory foot- prints and thus inefficient use of physical memory CacheBar adopts a design that we call copy-on-access, which dynamically controls the sharing of physical memory pages between security domains We designate each phys- ical page as being in exactly one of the following states: unmapped, exclusive, shared, and accessed An un- mapped page is a physical page that is not currently in use|,Non-data,5
| An exclusive page is a physical page that is currently used by exactly one security domain, but may be shared by multiple processes in that domain A shared page is a physical page that is shared by multiple security domains, ie, mapped by at least one process of each of the sharing domains, but no process in any domain has accessed this physical page recently|,Non-data,5
| In contrast, an accessed page is a previously shared page that was recently accessed by a security domain The state transitions are shown in Fig 1 An unmapped page can transition to the exclusive state either due to normal page mapping, or due to copy-on-access when a page is copied into it|,Non-data,5
| Unmapping a physical page for any reason (eg, process termination, page swapping) will move an exclusive page back to the unmapped state How- ever, mapping the current exclusive page by another secu- rity domain will transit it into the shared state|,Non-data,5
| If all but one domain unmaps this page, it will transition back from the shared state to the exclusive state, or accessed state to the exclusive state A page in the shared state may be shared by more domains and remain in the same state; when any one of the domains accesses the page, it will transition to the accessed state An accessed page can stay that way as long only the same security domain accesses it If this page is accessed by another domain, a new physical page will be allocated to make a copy of this one, and the current page will transition to either exclusive or shared state, depending on the remaining number of domains mapping this page|,Non-data,5
| The new page will be assigned state exclusive 873on each of the memory blocks of any virtual page that maps to this physical page State transition upon clflush The clflush instruc- tion is subject to the same permission checks as a memory load, will trigger the same page faults, and will similarly set the ACCESSED bit in the PTE of its argument [11]|,Non-data,5
| As such, each Flush via clflush triggers the same transi- tions (eg, from shared to accessed, and from accessed to an exclusive copy) as a Reload in our implementation, meaning that this defense is equally effective against both Flush-Reload and Flush-Flush [9] attacks Page deduplication|,Non-data,5
| To mitigate the impact of copy-on- access on the size of memory, CacheBar implements a less frequent timer (every ∆copy = 10 × ∆accessed seconds) to pe- riodically merge the page copies with their original pages Within the timer interrupt handler, original_list and each copy_list are traversed similarly to the “accessed ⇒ shared” transition description above, though the AC- CESSED bit in the PTEs of only pages that are in the ex- clusive state are checked If a copy page has not been accessed since the last such check (ie|,Non-data,5
|, the ACCESSED bit is unset in all PTEs pointing to it), it will be merged with its original page (the head of the copy_list) The AC- CESSED bit in the PTEs will be cleared afterwards When merging two pages, if the original page is anonymous- mapped, then the copy page can be merged by simply up- dating all PTEs pointing to the copy page to instead point to the original page, and then updating the original page’s reverse mappings to include these PTEs If the original page is file-mapped, then merging is more intricate, additionally involving the creation of a new virtual memory area (vma structure) that maps to the original page’s file position and using this structure to replace the virtual memory area of the (anonymous) copy page in the relevant task structure|,Non-data,5
| For security reasons, merging of two pages requires flush- ing the original physical page from the LLC We will elabo- rate on this point in Sec 33|,Non-data,5
| Interacting with KSM Page deduplication can also be triggered by existing memory deduplication mechanisms (eg, KSM)|,Non-data,5
| To maintain the state of physical pages, CacheBar instruments every reference to _mapcount within KSM and updates counter accordingly KSM is capable of merg- ing more pages than our built-in page deduplication mecha- nisms However, CacheBar still relies on the built-in page deduplication mechanisms for several reasons First, KSM can merge only anonymous-mapped pages, while CacheBar needs to frequently merge an anonymous-mapped page (a copy) with a file-mapped page (the original)|,Non-data,5
| Second, KSM may not be enabled in certain settings, which will lead to ever growing copy_lists Third, KSM must compare page contents byte-by-byte before merging two pages, whereas CacheBar deduplicates pages on the same copy_list, avoiding the expensive page content comparison 33 Security Copy-on-access is intuitively secure by design, as no two security domains may access the same physical page at the same time, rendering Flush-Reload attacks seemingly im- possible|,Non-data,5
| To show security formally, we subjected our design to model checking in order to prove that copy-on-access is secure against Flush-Reload attacks Model checking is an approach to formally verify a specification of a finite-state Figure 2: Structure of copy-on-access page lists access to these virtual pages will induce a page fault When a page fault is triggered, CacheBar checks if the page is present in physical memory; if so, and if the physical page is in the shared state, the COA bit of the current PTE for this page will be cleared so that additional accesses to this physical page from the current process will be allowed without page faults|,Non-data,5
| The physical page will also transition to the accessed state accessed ⇒ exclusive/shared If the page is already in the accessed state when a domain other than the owner accesses it, the page fault handler will allocate a new physi- cal page, copy the content of the original page into the new page, and change the PTEs in the accessing container so that they point to the new page Since multiple same-content copies in one domain burdens both performance and mem- ory but contributes nothing for security, the fault handler will reuse a copy belonging to that domain if it exists|,Non-data,5
| After copy-on-access, the original page can either be exclusive or shared All copy pages are anonymous-mapped, since only a single file-mapped page for the same file section is allowed A transition from the accessed state to shared or ex- clusive state can also be triggered by a timeout mechanism CacheBar implements a periodic timer (every ∆accessed = 1s)|,Non-data,5
| Upon timer expiration, all physical pages in the ac- cessed state that were not accessed during this ∆accessed interval will be reset to the shared state by clearing its owner field, so that pages that are infrequently accessed are less likely to trigger copy-on-access If an accessed page is found for which its counter shows the number of domains mapped to it is 1, then the daemon instead clears the COA bit of all PTEs for that page and marks the page exclusive Instead of keeping a list of accessed pages, CacheBar maintains a list of pages that are in either shared or ac- cessed state, denoted original_list (shown in Fig 2)|,Non-data,5
| Each node in the list also maintains a list of copies of the page it represents, dubbed copy_list These lists are at- tached onto the struct page through track_ptr When- ever a copy is made from the page upon copy-on-access, it is inserted into the copy_list of the original page Whenever a physical page transitions to the unmapped state, it is re- moved from whichever of original_list or copy_list it is contained in|,Non-data,5
| In the former case, CacheBar will des- ignate a copy page of the original page as the new original page and adjust the lists accordingly For security reasons that will be explained in Sec 33, we further require flushing the entire memory page out of the cache after transitioning a page from the accessed state to the shared state due to this timeout mechanism|,Non-data,5
| This page-flushing procedure is implemented by issuing clflush 874concurrent system expressed as temporal logic formulas, by traversing the finite-state machine defined by the model In our study, we used the Spin model checker, which offers effi- cient ways to model concurrent systems and verify temporal logic specifications the memory block (sets pages[virt] to 0) before Reloading it (setting pages[virt] to 1), if the non-interference prop- erty holds, then the attacker should always find pages[virt] to be 0 upon Reloading the page The model checker checks for violation of this property|,Non-data,5
| System modeling We model a physical page in Fig 1 us- ing a byte variable in the Promela programming language, and two physical pages as an array of two such variables, named pages We model two security domains (e|,Non-data,5
|g, con- tainers), an attacker domain and a victim domain, as two processes in Promela Each process maps a virtual page, virt, to one of the physical pages The virtual page is mod- eled as an index to the pages[] array; initially virt for both the attacker and the victim point to the first physical page (i|,Non-data,5
|e, virt is 0) The victim process repeatedly sets pages[virt] to 1, simulating a memory access that brings pages[virt] into cache The attacker process Flushes the virtual page by assigning 0 to pages[virt] and Reloads it by assigning 1 to pages[virt] after testing if it already equals to 1|,Non-data,5
| Both the Flush and Reload operations are modeled as atomic to simplify the state exploration We track the state and owner of the first physical page using another two variables, state and owner The first page is initially in the shared state (state is shared), and state transitions in Fig 1 are implemented by each process when they access the memory|,Non-data,5
| For example, the Reload code snippet run by the attacker is shown in Fig 3 If the attacker has access to the shared page (Line 3), versus an exclusive copy (Line 16), then it simulates an access to the page, which either moves the state of the page to accessed (Line 10) if the state was shared (Line 9) or to exclusive (Line 14) after making a copy (Line 13) if the state was al- ready accessed and not owned by the attacker (Line 12) Leakage is detected if pages[virt] is 1 prior to the at- tacker setting it as such (Line 19), which the attacker tests in Line 18|,Non-data,5
| 1 atomic { 2 if 3 ::(virt == 0) -> 4 5 6 7 8 9 10 11 12 13 14 15 if ::(state == UNMAPPED) -> assert(0) ::(state == EXCLUSIVE && owner != ATTACKER) -> assert(0) ::(state == SHARED) -> state = ACCESSED owner = ATTACKER ::(state == ACCESSED && owner != ATTACKER) -> virt = 1 /* copy-on-access */ state = EXCLUSIVE fi 16 ::else -> skip 17 fi 18 assert(pages[virt] == 0) 19 pages[virt] = 1 20 } Figure 3: Code snippet for Reload To model the dashed lines in Fig 1, we implemented an- other process, called timer, in Promela that periodically transitions the physical page back to shared state from ac- cessed state, and periodically with a longer interval, merges the two pages by changing the value of virt of each domain back to 0, owner to none, and state to shared The security specification is stated as a non-interference property|,Non-data,5
| Specifically, as the attacker domain always Flushes Automated verification We checked the model using Spin Interestingly, our first model-checking attempt sug- gested that the state transitions may leak information to a Flush-Reload attacker The leaks were caused by the timer process that periodically transitions the model to a shared state|,Non-data,5
| After inspecting the design and implemen- tation, we found that there were two situations that may cause information leaks In the first case, when the timer transitions the state machine to the shared state from the accessed state, if the prior owner of the page was the vic- tim and the attacker reloaded the memory right after the transition, the attacker may learn one bit of information In the second case, when the physical page was merged with its copy, if the owner of the page was the victim before the page became shared, the attacker may reload it and again learn one bit of information Since in our implementation of CacheBar, these two state transitions are triggered if the page (or its copy) has not been accessed for a while (roughly ∆accessed and ∆copy seconds, respectively), the infor- mation leakage bandwidth due to each would be approxi- mately 1/∆accessed bits per page per second or 1/∆copy bits per page per second, respectively|,Non-data,5
 We improved our CacheBar implementation to prevent this leakage by enforcing LLC flushes (as described in Sec 32) upon these two periodic state transitions We adapted our model accordingly to reflect such changes by adding one more instruction to assign pages[0] to be 0 right after the two timer -induced state transitions,Non-data,5
| Model checking this refined model revealed no further information leakage 4 CACHEABILITY MANAGEMENT Another common method to launch side-channel attacks via caches is using Prime-Probe attacks, introduced by Os- vik et al [21]|,Non-data,5
| These attacks have recently been adapted to use LLCs to great effect, eg, [20, 12] Unlike a Flush- Reload attack, Prime-Probe attacks do not require the at- tacker and victim security domains to share pages|,Non-data,5
| Rather, the attacker simply needs to access memory so as to evict (Prime) the contents of a cache set and later access (Probe) this memory again to determine (by timing the accesses) how much the victim evicted from the cache set A potentially effective countermeasure to these attacks, accordingly, is to remove the attacker’s ability to Prime and Probe the whole cache set and to predict how a victim’s demand for that set will be reflected in the number of evictions from that set 41 Design Suppose a w-way set associative LLC, so that each cache set has w lines|,Non-data,5
| Let x be the number of cache lines in one set that the attacker observes having been evicted in a Prime- Probe interval The Prime-Probe attack is effective today because x is typically a good indicator of the demand d that the victim security domain had for memory that mapped to that cache set during the Prime-Probe interval In partic- ular, if the attacker Primes and Probes all w lines, then it can often observe the victim’s demand d exactly, unless d > w (in which case the attacker learns at least d ≥ w) 875Figure 4: A cacheable queue for one page color in a domain: (a) access to page 24 brings it into the queue and clears NC bit (“← 0”) in the PTE trig- gering the fault; periodically, (b) a daemon counts the ACCESSED bits (“+0”, “+1”) per page and (c) re- orders pages accordingly; to make room for a new page, (d) NC bits in PTEs pointing to the least recently used page are set, and the page is re- moved from the queue|,Non-data,5
| Here we propose to periodically and probabilistically re- configure the budget ki of lines per cache set that the se- curity domain i can occupy After such a reconfiguration, the attacker’s view of the victim’s demand d is clouded by the following three effects First, if the attacker is allotted a budget ka < w, then the attacker will be unable to observe any evictions at all (ie|,Non-data,5
|, x = 0) if d < w −ka2 Second, if the victim is given allotment kv, then any two victim demands d, d′ satisfying d > d′ ≥ kv will be indistinguishable to the attacker Third, the probabilistic assignment of kv results in extra ambiguity for the attacker, since x evictions might reflect the demand d or the budget kv, since x ≤ min{d, kv} (if all x evictions are caused by the victim) To enforce the budget ki of lines that security domain i can use in a given cache set, CacheBar maintains for each cache set a queue per security domain that records which memory blocks are presently cacheable in this set by pro- cesses in this domain|,Non-data,5
| Each element in the queue indicates a memory block that maps to this cache set; only blocks listed in the queue can be cached in that set The queue is maintained with a least recently used (LRU) replacement al- gorithm That is, whenever a new memory block is accessed, it will replace the memory block in the corresponding queue that is the least recently used 4|,Non-data,5
|2 Implementation Implementation of cacheable queues is processor micro- architecture dependent Here we focus our attention on Intel x86 processors, which appears to be more vulnera- ble to Prime-Probe attacks due to their inclusive last- level cache [20] As x86 architectures only support mem- ory management at the page granularity (eg|,Non-data,5
|, by manip- ulating the PTEs to cause page faults), CacheBar con- trols the cacheability of memory blocks at page granularity CacheBar uses reserved bits in each PTE to manage the cacheability of, and to track accesses to, the physical page to which it points, since a reserved bit set in a PTE in- duces a page fault upon access to the associated virtual page, for which the backing physical page cannot be retrieved or cached (if it is not already) before the bit is cleared [11, 23] We hence use the term domain-cacheable to refer to a phys- ical page that is “cacheable” in the view of all processes in a particular security domain, which is implemented by modi- fying all relevant PTEs (to have no reserved bits set) in the 2This statement assumes a LRU replacement policy and that the victim is the only security domain that runs in the Prime-Probe interval If it was not the only security do- main to run, then the ambiguity of the observable evictions will additionally cause difficulties for the attacker|,Non-data,5
| processes of that security domain By definition, a physi- cal page that is domain-cacheable to one container may not necessarily be domain-cacheable to another To ensure that no more than ki memory blocks from all processes in container i can occupy lines in a given cache set, CacheBar ensures that no more than ki of those pro- cesses’ physical memory pages, of which contents can be stored in that cache set, are domain-cacheable at any point in time Physical memory pages of which contents can be stored in the same cache set are said to be of the same color, and so to implement this property, CacheBar maintains, per container and per color (rather than per cache set), one cacheable queue, each element of which is a physical mem- ory page that is domain-cacheable in this container|,Non-data,5
| Since the memory blocks in each physical page map to different cache sets, limiting the domain-cacheable pages of a color to ki also limits the number of cache lines that blocks from these pages can occupy in the same cache set to ki To implement a non-domain-cacheable memory, CacheBar uses one reserved bit, which we denote by NC, in all PTEs within the domain mapped to that physical page As such, accesses to any of these virtual pages will be trapped into the kernel and handled by the page fault handler Upon detect- ing page faults of this type, the page fault handler will move the accessed physical page into the corresponding cacheable queue, clear the NC bit in the current PTE3, and remove a least recently used physical page from the cacheable queue and set the NC bits in this domain’s PTEs mapped to that page|,Non-data,5
| A physical page removed from the cacheable queue will be flushed out of the cache using clflush instructions on all of its memory blocks to ensure that no residue remains in the cache CacheBar will flush the translation lookaside buffers (TLB) of all processors to ensure the correctness of page cacheabilities every time PTEs are altered In this way, CacheBar limits the number of domain-cacheable pages of a single color at any time to ki To maintain the LRU property of the cacheable queue, a daemon periodically re-sorts the queue in descending order of recent access count|,Non-data,5
| Specifically, the daemon traverses the domain’s PTEs mapped to the physical frame within that domain’s queue and counts the number having their ACCESSED bit set, after which it clears these ACCESSED bits It then orders the physical pages in the cacheable queue by this count (see Fig 4) In our present implementation, this daemon is the same daemon that resets pages from the 3We avoid the overhead of traversing all PTEs in the con- tainer that map to this physical page|,Non-data,5
 Access to those virtual pages will trigger page faults to make these updates without altering the cacheable queue 876security domain i This drawing is memoryless and inde- pendent of the draws for other security domains Let Ki denote the random variable distributed according to how ki is determined,Non-data,5
| The random variables that we presume can be observed by the attacker domains include K1,    , Km; let Ka = min(cid:8)w,Pm i=1 Ki(cid:9) denote the number of cache lines allocated to the attacker domains|,Non-data,5
| We also presume the at- tacker can accurately measure the number X of its cache lines that are evicted during the victim’s execution Let Pd (E) denote the probability of event E in an exe- cution period during which the victim’s cache usage would populate d lines (of this color) if it were allowed to use all w lines, ie, if k0 = w|,Non-data,5
| We (the defender) would like to dis- tribute K0,    , Km so as to minimize the statistical distance between eviction distributions observable by the attacker for different victim demands d, d′, i|,Non-data,5
|e, to minimize X0≤d<d′≤wXx ||Pd (X = x) − Pd′ (X = x) || (1) We begin by deriving an expression for Pd (X = x) Below we make the conservative assumption that all evictions are caused by the victim’s behavior; in reality, caches are far noisier We first consider the case x = 0, i|,Non-data,5
|e, that the attacker domains observe no evictions Pd(cid:16)X = 0(cid:12)(cid:12)(cid:12) K0 = k0 ∧ Ka = ka(cid:17) =(cid:26)1 if w ≥ ka + min{k0, d} 0 otherwise “min{k0, d}” is used above because any victim demand for memory blocks that map to this cache set beyond k0 will back-fill the cache lines invalidated when CacheBar flushes other blocks from the victim’s cacheability queue, rather than evicting others Since K0 and Ka are independent, Pd (X = 0) = P (K0 = k0) · P (Ka = ka) P (K0 = k0) · P (Ka = ka) (2) Note that we have dropped the “d” subscripts from the prob- abilities on the right, since K0 and Ka are distributed inde- pendently of d|,Non-data,5
| And, since K1,    , Km are independent, m m if ka < w P (Ki = ki) P (Ki = ki) Yi=1 Yi=1  Xk1+|,Non-data,5
+km=ka Xk1+,Non-data,5
|+km≥w  ∧ Ka = ka(cid:17) =(cid:26)1 if x+w = ka +min{k0, d} 0 otherwise K0 = k0 if ka = w (3) P (Ka = ka) = Similarly, for x ≥ 1, Pd(cid:16)X = x(cid:12)(cid:12)(cid:12) and so for x ≥ 1, Pd (X = x) = P (K0 = k0) · P (Ka = x+w−k0) d w−k0 Xk0=0 Xka=0 Xka =0 Xk0=d+1 w−d w + d Xk0 =0 Xk0=d+1 w + P (K0 = k0) · P (Ka = x+w−d) (4) From here, we proceed to solve for the best distribution for K0,   |,Non-data,5
| , Km to minimize Eqn 1 subject to constraints Figure 5: Page fault handler for CacheBar accessed state to shared state (see Sec 3), which already checks and resets the ACCESSED bits in copies’ PTEs|,Non-data,5
| Again, this daemon runs every ∆accessed = 1s seconds in our implementation This daemon also performs the task of re- setting ki for each security domain i, each time it runs Interacting with copy-on-access The cacheable queues work closely with the copy-on-access mechanisms|,Non-data,5
| In partic- ular, as both the COA and NC bits may trigger a page fault upon page accesses, the page handler logic must incorporate both (see Fig 5) First, a page fault is handled as normal unless it is due to one of the reserved bits set in the PTE As CacheBar is the only source of reserved bits, it takes over page fault handling from this point|,Non-data,5
| CacheBar first checks the COA bit in the PTE If it is set, the correspond- ing physical page is either shared, in which case it will be transitioned to accessed, or accessed, in which case it will be copied and transitioned to either shared or exclusive CacheBar then clears the COA bit and, if no other re- served bits are set, the fault handler returns Otherwise, if the NC bit is set, the associated physical page is not in the cacheable queue for its domain, and so CacheBar enqueues the page and, if the queue is full, removes the least-recently- used page from the queue|,Non-data,5
| If the NC bit is clear, this page fault is caused by unknown reasons and CacheBar turns control over to the generic handler for reserved bits 43 Security Recall that ki is the number of cache lines in a certain cache set that is available to domain i for a period While the budget ki is in effect, each access to a memory block that maps to this cache set, beyond the in-queue ki memory blocks, will incur a page fault (because they are all in dif- ferent pages)|,Non-data,5
| Because the page-fault processing time will overwhelm the timing granularity of modern Prime-Probe attacks by an order of magnitude, the attacker i realistically needs to restrict himself to accessing ki pages in his Probe phase and hence to occupying ki lines in that cache set The security of this design hinges critically on how each ki is set by the daemon When ki is reset, it is drawn from a distribution In the remainder of this section we present how this distribution is determined|,Non-data,5
| Suppose there are (at most) m domains on a host that are owned by the attacker—which might be all domains on the host except the victim—and let w be the number of cache lines per LLC set Below we consider domain 0 to be the “victim” domain being subjected to Prime-Probe attacks by the “attacker” domains 1,   |,Non-data,5
| , m Of course, the attacker i=1 ki cache lines available to them for conducting their Prime-Probe attacks domains make use of all Pm Periodically, CacheBar draws a new value ki for each 877Eqns 2–4|,Non-data,5
| That is, we specify those constraints, along with ∀i, i′, k : P (Ki = k) = P (Ki′ = k) w ∀i : P (Ki = ki) = 1 Xki =0 ∀i, ki : P (Ki = ki) ≥ 0 (5) (6) (7) and then solve for each P (Ki = ki) to minimize Eqn 1 Unfortunately, solving to minimize Eqn 1 alone simply results in a distribution that results in no use of the cache at all (e|,Non-data,5
|g, P (Ki = 0) = 1 for each i) As such, we need to rule out such degenerate and “unfair” cases: ∀i : P (Ki < w/(m + 1)) = 0 (8) Also, to encourage cache usage, we counterbalance Eqn 1 with a second goal that values greater use of the cache|,Non-data,5
| We express this goal as minimizing the earth mover’s distance [6] from the distribution that assigns P (Ki = w) = 1, ie, w (w − k) · P (K0 = k) Xk=0 (9) As such, our final optimization problem seeks to balance Eqn 1 and Eqn|,Non-data,5
| 9 Let constant γ denote the maximum (ie, worst) possible value of Eqn|,Non-data,5
| 1 (ie, when P (Ki = w) = 1 for each i) and δ denote the maximum (ie|,Non-data,5
|, worst) possible value of Eqn 9 (ie, when P (Ki = 0) = 1 for each i)|,Non-data,5
| Then, given a parameter ǫ, 0 < ǫ < 1, our optimization computes distributions for K0,    , Km so as to minimize u subject to u = u ≥ 1 γ   X0≤d<d′≤wXx δ(1 + ǫ)  w Xk=0 1 ||Pd (X = x) − Pd′ (X = x) ||  (w − k) · P (K0 = k)! and constraints Eqns|,Non-data,5
 2–8 Our evaluation in Sec 52,Non-data,5
2 and Sec 531 empirically char- acterizes the security and performance that result from set- ting ǫ = 0,Non-data,5
|01 the default setting in CacheBar Of course, other balances could be chosen between these concerns, though as we will see below, this setting achieves convincing secu- rity while inducing only a modest performance overhead for most PaaS workloads 5 EVALUATION In this section, we evaluate the security and performance of CacheBar to validate its design and implementation|,Non-data,5
 51 Setup Our testbed is a rack mounted DELL server equipped with two 267GHz Intel Xeon 5550 processors Each processor contains 4 physical cores (hyperthreading disabled) sharing an 8MB last-level cache (L3),Non-data,5
 Each core has a 32KB L1 data and instruction cache and a 256KB L2 unified cache The rack server is equipped with 128GB DRAM and 1000Mbps NIC connected to a 1000Mbps ethernet We implemented CacheBar as a kernel extension for Linux kernel 313,Non-data,5
116 that runs Ubuntu 1404 server edi- tion Our implementation adds ∼7000 lines of code to this Linux kernel,Non-data,5
 We set up containers using Docker 171  250 200 150 100 s e l c y c  U P C unshared shared  250 200 150 100 s e l c y c  U P C unshared shared (a) CacheBar disabled (b) CacheBar enabled Figure 6: Reload timings in Flush-Reload attacks on a shared address vs,Non-data,5
 on an unshared address 52 Security Evaluation We evaluated the effectiveness of CacheBar in defending against both Flush-Reload and Prime-Probe attacks 52,Non-data,5
|1 Flush-Reload Attacks Although we used Spin model checker to validate the security of our copy-on-access design (Sec 3), we empiri- cally tested our implementation to validate its effectiveness To do so, we constructed a Flush-Reload covert channel between sender and receiver processes, which were isolated in different containers Both the sender and receiver were linked to a shared library, libcrypto|,Non-data,5
|so100, and were pinned to run on different cores of the same socket, thus sharing the same last-level cache|,Non-data,5
| The sender ran in a loop, repeatedly accessing one memory location (the beginning address of function AES_decrypt()) The receiver exe- cuted Flush-Reload attacks on the same memory address, by first Flushing the memory block out of the shared LLC with an clflush instruction and then Reloading the block by accessing it directly while measuring the access latency The interval between Flush and Reload was set to 2500 cycles The experiment was run for 500,000 Flush-Reload trials|,Non-data,5
| We then repeated this experiment with the sender accessing an unshared address, to form a baseline Fig 6(a) shows the results of this experiment, when run over unmodified Linux The three horizontal lines forming the “box” in each boxplot represents the first, second (me- dian), and third quartiles of the Flush-Reload measure- ments; whiskers extend to cover all points that lie within 1|,Non-data,5
|5× the interquartile range As can be seen in this figure, the times observed by the receiver to Reload the shared ad- dress were clearly separable from the times to Reload the unshared address, over unmodified Linux With CacheBar enabled, however, these measurements are no longer separa- ble (Fig 6(b))|,Non-data,5
| Certain corner cases are not represented in Fig 6 For example, we found it extremely difficult to con- duct experiments to capture the corner cases where Flush and Reload takes place right before and after physical page mergers, as described in Sec 3|,Non-data,5
|3 As such, we rely on our manual inspection of the implementation in these cases to check correctness and argue these corner cases are very dif- ficult to exploit in practice 52|,Non-data,5
|2 Prime-Probe Attacks We evaluated the effectiveness of CacheBar against Prime- Probe attacks by measuring its ability to interfere with a simulated attack Because the machine architecture on which we performed these tests had a w-way LLC with w = 16, we limited our experiments to only a single at- tacker container (ie, m = 1), but an architecture with a larger w could accommodate more|,Non-data,5
|4 4For example, on an Itanium 2 processor with a 64-way LLC, 878In our simulation, a process in the attacker container repeatedly performed Prime-Probe attacks on a specific cache set, while a process in a victim container accessed data that were retrieved into the same cache set at the rate of d accesses per attacker Prime-Probe interval The cache lines available to the victim container and attacker container, ie, kv and ka respectively, were fixed in each ex- periment|,Non-data,5
| The calculations in Sec 43 implied that kv and ka could take on values from {4, 5, 6,  |,Non-data,5
|  , 14} In each test with fixed kv and ka, we allowed the victim to place a demand of (ie|,Non-data,5
|, retrieve memory blocks to fill) d ∈ {0, 1, 2, , 16} cache lines of the cache set undergoing the Prime-Probe attack by the attacker|,Non-data,5
| The attacker’s goal was to classify the victim’s demand into one of six classes: none = {0}, one = {1}, few = {2, 3, 4}, some = {5, 6, 7, 8}, lots = {9, 10, 11, 12}, and most = {13, 14, 15, 16} To make the attack easier, we permitted the attacker to know ka; ie, the attacker trained a different classifier per value of ka, with knowledge of the demand d per Prime- Probe trial, and then tested against additional trial re- sults to classify unknown victim demands|,Non-data,5
| Specifically, after training a na ̈ıve Bayes classifier on 500,000 Prime-Probe trials per (d, ka, kv) triple, we tested it on another 500,000 trials To filter out Probe readings due to page faults, ex- cessively large readings were discarded from our evaluation The tests without CacheBar yielded the confusion matrix in Table 7(a), with overall accuracy of 675%|,Non-data,5
| In this table, cells with higher numbers have lighter backgrounds, and so the best attacker would be one who achieves white cells along the diagonal and dark-gray cells elsewhere As can be seen there, classification by the attacker was very accurate for d falling into none, one, or lots; eg, d = 1 resulted in a classification of one with probability of 0|,Non-data,5
|80 Other de- mands had lower accuracy, but were almost always classified into adjacent classes; ie, every class of victim demand was classified correctly or as an adjacent class (e|,Non-data,5
|g, d ∈ few was classified as one, few, or some) at least 96% of the time In contrast, Fig 7(b) shows the confusion matrix for a na ̈ıve Bayes classifier trained and tested using Prime-Probe trials conducted with CacheBar enabled|,Non-data,5
| Specifically, these values were calculated using P(cid:0)class = c(cid:12)(cid:12) d ∈ c′(cid:1) = X4≤ka,kv≤14 P(cid:16)class = c(cid:12)(cid:12)(cid:12) · P (Ka = ka) · P (Kv = kv) ! d ∈ c′ ∧ Kv = kv ∧ Ka = ka(cid:17) where class denotes the classification obtained by the adver- sary using the na ̈ıve Bayes classifier; c, c′ ∈ {none, one, few, some, lots, most}; and P (Ka = ka) and P (Kv = kv) are calculated as described in Sec 43 The factor P(cid:0)class = c(cid:12)(cid:12) d ∈ c′ ∧ Kv = kv ∧ Ka = ka(cid:1) was measured em- pirically|,Non-data,5
| Though space limits preclude reporting the full class confusion matrix for each kv, ka pair, the accuracy of the na ̈ıve Bayes classifier per kv, ka pair, averaged over all classes c, is shown in Fig 8 As in Fig 7, cells with larger values in Fig|,Non-data,5
| 8 are more lightly colored, though in this case, the diagonal has no particular significance Rather, we would expect that when the attacker and victim are each CacheBar could accommodate m = 3 or larger That said, we are unaware of prior works that have successfully con- ducted Prime-Probe attacks from multiple colluding at- tackers, which would itself face numerous challenges (eg|,Non-data,5
|, coordinating Probes by multiple processes) m i t c i V d n a m e d m i t c i V d n a m e d Classification by attacker none one 04 80 |,Non-data,5
16 00 00 00 ,Non-data,5
96 01 00 00 ,Non-data,5
00 00 few some 00 19 ,Non-data,5
50 07 00 00 ,Non-data,5
00 01 30 54 ,Non-data,5
03 03 lots most 00 00 ,Non-data,5
04 34 84 56 ,Non-data,5
00 00 00 04 ,Non-data,5
13 41 d none one few some lots most (a) Without CacheBar Classification by attacker none one 16 36 ,Non-data,5
14 10 06 07 ,Non-data,5
33 16 13 09 ,Non-data,5
08 10 few some 26 19 ,Non-data,5
40 16 10 18 ,Non-data,5
18 19 19 37 ,Non-data,5
16 18 lots most 04 06 ,Non-data,5
09 20 46 18 ,Non-data,5
02 04 05 07 ,Non-data,5
13 29 d none one few some lots most (b) With CacheBar Figure 7: Confusion matrix of na ̈ıve Bayes classifier a k 4 5 6 7 8 9 10 11 12 13 14 4 18 19 ,Non-data,5
17 17 33 20 ,Non-data,5
41 45 55 55 ,Non-data,5
53 5 17 17 31 ,Non-data,5
33 35 26 31 ,Non-data,5
45 50 53 56 6 ,Non-data,5
17 30 24 22 ,Non-data,5
32 31 27 40 ,Non-data,5
59 68 45 7 17 ,Non-data,5
32 18 22 23 ,Non-data,5
28 35 45 63 ,Non-data,5
68 65 8 17 27 ,Non-data,5
21 19 43 44 ,Non-data,5
50 47 49 54 ,Non-data,5
46 kv 9 17 27 17 ,Non-data,5
31 37 38 55 ,Non-data,5
54 48 65 62 10 ,Non-data,5
17 20 20 33 ,Non-data,5
43 34 53 54 ,Non-data,5
54 52 48 11 17 ,Non-data,5
26 27 33 42 ,Non-data,5
34 31 57 49 ,Non-data,5
56 68 12 36 33 ,Non-data,5
43 46 32 46 ,Non-data,5
53 67 56 57 ,Non-data,5
55 13 22 46 39 ,Non-data,5
48 38 39 50 ,Non-data,5
50 58 66 57 14 ,Non-data,5
33 39 41 54 ,Non-data,5
49 56 62 50 ,Non-data,5
57 66 53 Figure 8: Accuracy per values of kv and ka limited to fewer lines in the cache set (ie,Non-data,5
|, small values of ka and kv, in the upper left-hand corner of Fig 8) the accuracy of the attacker will suffer, whereas when the attacker and victim are permitted to use more lines of the cache (ie, in the lower right-hand corner) the attacker’s accuracy would improve|,Non-data,5
| Fig 8 supports these general trends Returning to Fig 7(b), we see that CacheBar substan- tially degrades the adversary’s classification accuracy, which overall is only 33%|,Non-data,5
| Moreover, the adversary is not only wrong more often, but is also often “more wrong” in those cases That is, whereas in Fig 7(a) shows that each class of victim demand was classified as that demand or an adjacent demand at least 96% of the time, this property no longer holds true in Fig 7(b)|,Non-data,5
| Indeed, the attacker’s best case in this regard is classifying victim demand lots, which it clas- sifies as some, lots, or most 75% of the time In the case of a victim demand of most, this number is only 47% 53 Performance Evaluation In this section we describe tests we have run to evalu- ate the performance impact of CacheBar relative to an unmodified Linux kernel|,Non-data,5
| As mentioned previously, we are motivated by side-channel prevention in PaaS clouds, and so we focused our evaluation on typical PaaS applications In order to increase server utilization and reduce cost, most public PaaS clouds isolate tenants within the same operating system using Linux containers While a web ap- plication may contain web servers, programming language runtimes, databases, and a set of middleware that enrich its 879PaaS cloud Supported server engines (+ application languages) Table 1: Server+language support in selected PaaS clouds AppFog Azure Elastic Beanstalk Engine Yard Google Cloud Heroku HP Stackato OpenShift Tomcat, Apache, Nginx, IIS (Java, Python, PHP, Nodejs, Ruby, Go) Tomcat, Jetty, Apache, Nginx, GlassFish, Wildfly, IIS (Java, Python, PHP, Node|,Non-data,5
|js, Ruby, NET) Tomcat, Apache, Nginx, Passenger, Puma, IIS (Java, Python, PHP, Nodejs, Ruby, Go, NET) Nginx, Rack, Passenger, Puma, Unicorn, Trinidad (Java, PHP, Node|,Non-data,5
|js, and Ruby) JBoss, Wildfly, Tomcat, Apache, Nginx, Zend, Passenger, Mongrel, Thin, IIS (Java, Python, PHP, Nodejs, Ruby, ASPNET, Go) Jetty, Tomcat, Tornado, Nginx, Apache, Mongrel, Thin, Puma, Unicorn, Hypnotoad, Starman, Mongoose, Yaws, Mochiweb (Java, Python, PHP, Nodejs, Ruby, Go, Perl, C, Erlang, Scala, Clojure) Apache, Apache TomEE, Nginx (Java, Python, PHP, Node|,Non-data,5
|js, Ruby, Perl, Erlang, Scala, Clojure, ASPNET) JBoss, Wildfly, Tomcat, Apache, Spring, Tornado, Zend, Vertx (Java, Python, PHP, Nodejs, Ruby, Perl, Ceylon) rate w/o CacheBar rate w CacheBar time w/o CacheBar time w CacheBar rate w/o CacheBar rate w CacheBar time w/o CacheBar time w CacheBar c e s  r e p  s e s n o p s e R  160  120  80  40  0 130  3  2  1 142  0 144 ) s m (  e m i t  e s n o p s e R c e s  r e p  s e s n o p s e R  40  30  20  10  0  5  4  3  2  1  0 ) s m (  e m i t  e s n o p s e R 30 31 32 33 34 35 36 37 Requests per second 132 134 140 Requests per second 138 136 ) c e s / s t s e u q e r (  t u p h g u o r h T rate w/o CacheBar rate w CacheBar time w/o CacheBar time w CacheBar  160  120  80  40  0 4  5  4  3  2  1  0 ) s m (  e m i t  e s n o p s e R 16 8 6 14 Number of containers 10 12 (a) 4 webservers (b) 16 webservers (c) different numbers of webservers Figure 9: Average throughput and response time per Apache+PHP-FPM server, each in a separate container ) c e s / s t s e u q e r (  t u p h g u o r h T  40  30  20  10  0 w/o CacheBar w CacheBar w/o CacheBar w CacheBar 34 32 36 34 34 32 34 24 33 27 28 34 36 32 java-tomcat ruby-puma python-tornado python-apache+cgi ruby-unicorn ruby-passenger ruby-mongrel ruby-thin ) s m (  e m i t  e s n o p s e R  0|,Non-data,5
8  06  04  02  0 15,Non-data,5
0% 84% 119% 117% 2,Non-data,5
4% 94% 279%747% 33,Non-data,5
8% Browse Login PostSelfWall AddFriend SendMessage Register ReceiveMessage Update Logout rate w/o CacheBar rate w CacheBar time w/o CacheBar time w CacheBar c e s  r e p  s e s n o p s e R  8  6  4  2  0 03% -30% 13% -0,Non-data,5
9% 12% 24% 27% 4 16 1 Number of containers 8  12 4,Non-data,5
|2% ) s m (  e m i t  e s n o p s e R  8  4  0 Figure 10: By webserver+language Figure 11: By operation Figure 12: Media streaming functionality, in all PaaS clouds we have studied, language runtimes and web servers are located on different servers from databases and middleware; web/app servers controlled by different tenants may share the same OS, however Be- cause users of PaaS clouds do not have the permission to ex- ecute arbitrary code on databases and middleware that are typically shared by multiple tenants, the targets of the side- channel attacks we consider in this paper are primarily web servers that supports various language runtimes, which may be co-located with the adversary-controlled malicious web servers on which arbitrary code can be executed We con- ducted a survey to understand the popular web/app servers that are used in major PaaS clouds, and the programming languages they support; see Table 1 5|,Non-data,5
|31 Runtime and Throughput Overhead Our experiments explored CacheBar’s performance (1) per the number of container (and webserver) instances; (2) for different combinations of webserver and application lan- guage; (3) for complex workloads characteristic of a social networking website; and (4) for media-streaming workloads Webserver performance In the first experiments, each container ran an Apache 2|,Non-data,5
|47 web server with PHP-FPM and SSL enabled We set up one client per server using autobench; clients were spread across four computers, each with the same networking capabilities as the (one) server computer (not to mention more cores and memory than the server computer), to ensure that any bottlenecks were on the server machine Each client repeatedly requested a web page and recorded its achievable throughputs and response times at those throughput rates|,Non-data,5
| The content returned to each client request was the 86KB output of phpinfo() Fig 9 shows the throughputs and response times when clients sent requests using SSL without reusing connections In particular, Fig|,Non-data,5
| 9(a) shows the achieved response rates (left axis) and response times (right axis), averaged over all containers, as a function of offered load when there were four containers (and so four web servers) Bars depict av- erage response rates running over unmodified Linux (“rate w/o CacheBar”) or CacheBar (“rate w CacheBar”), and lines depict average response times running over unmodi- fied Linux (“time w/o CacheBar”) or CacheBar (“time w CacheBar”) Fig 9(b) shows the same information for 16 containers|,Non-data,5
| As can be seen in these figures, the throughput impact of CacheBar was minimal, while the response time increased by around 20% Fig 9(c) shows this information in another way, with the number of containers (and hence servers) increasing along the horizontal-axis In Fig|,Non-data,5
| 9(c), each bar represents the largest request rate at which the responses could keep up Webserver+language combinations Next, we selected other common webserver+app-language combinations, namely Java over a Tomcat web server, Python over Apache+cgi, Python over Tornado, and Ruby over Puma For each con- 880figuration, we instantiated 16 containers and set each up to dynamically generate 80KB random strings for clients|,Non-data,5
| We also did tests using another four web servers running the same Ruby application, namely Passenger, Unicorn, Thin, and Mongrel Fig 10 shows the throughput that resulted in each case, over Linux and over CacheBar As shown there, the throughput overheads were modest for most of the server+language combinations that we considered|,Non-data,5
| The worst case was Python over Apache+cgi, which suf- fered a throughput degradation with CacheBar of 25%; other degradations were much more modest Impact on a more complex workload To test effects on more complex workloads, we used the webserver instance in CloudSuite [8] that implements a social community website written in PHP over Nginx on our CacheBar-protected machine This implementation queries a MySQL database and caches results using Memcached; in keeping with PaaS architectures, the database and Memcached server were im- plemented on another machine without protection, since ten- ants cannot typically execute directly on these machines|,Non-data,5
| We used the Faban tool to generate a mix of requests to the webserver, including browse (79%), login (75%), post (249%), addFriend (7|,Non-data,5
|3%), sendMsg (440%), register (08%), and logout (75%)|,Non-data,5
| In addition, a background ac- tivity happened on the webserver every 10s, which was ei- ther receiveMsg or update with equal likelihood Fig 11 shows that the responsiveness of the various common op- erations suffered little with CacheBar, between 2% and 15% overhead Three operations (register, update, and logout) suffered over 25% overhead, but these operations were rare in the Faban workload (and presumably in prac- tice)|,Non-data,5
| Media streaming in CloudSuite In addition to the webserver benchmark setup used above, CloudSuite offers a media streaming server running over Nginx that serves 31GB static video files at different levels of quality We set up a client process per server to issue a mix of requests for videos at different quality levels and, through a binary search, to find the peak request rate the server can sustain while keeping the failure rate below a threshold|,Non-data,5
| Fig 12 shows that CacheBar affected this application least of all, in both throughput and response time SPEC CPU 2006 benchmarks For completeness, we measured the impact of CacheBar on nine SPEC CPU 2006 benchmarks|,Non-data,5
| Six resulted in reasonable overheads: hmmer (133% overhead), gamess (35%), gromacs (131%), namd (14|,Non-data,5
|3%), povray (04%), and tonto (168%) How- ever, three exhibited substantially higher overheads: perl- bench (225%), bzip2 (76%), and h264ref (143%)|,Non-data,5
 (Over- heads caused by copy-on-access alone were below 5%) It is not surprising that limiting cache usage using cacheable queue can interfere with some workloads CacheBar is not a panacea and is best suited for the PaaS workloads that formed the core of our evaluation 5,Non-data,5
|32 CacheBar’s Memory Savings To measure the memory savings that copy-on-access offers over disabling memory sharing between containers, we mea- sured the total unique physical memory pages used across various numbers of webservers, each in its own container, when running over (i) unmodified Linux, (ii) Linux with- out cross-container memory sharing, and (iii) CacheBar- ) B M (  d a e h r e v o   y r o m e M  600  450  300  150  0 Non-cross-shared-busy Non-cross-shared-idle CacheBar-busy CacheBar-idle 4 8 12 16 20 24 28 32 36 42 Number of containers Figure 13: Memory overhead comparison enabled Linux We used the system diagnosis tool smem for memory accounting, specifically by accumulating the PSS (proportional set size) field output by smem for each pro- cess, which reports the process’ shared memory pages di- vided by the number of processes sharing these pages, plus the process’ unshared memory pages and all kernel pages Fig|,Non-data,5
| 13 shows the memory overhead of Linux without cross- container sharing and with CacheBar, computed by sub- tracting the memory measured for unmodified Linux from the memory measured for each of these systems We grew the number of containers to 16 in each case, and then extrap- olated to larger numbers of containers using best-fit lines As can be seen in Fig 13, the overhead of CacheBar is vir- tually zero (“CacheBar-idle”) with negligible query load|,Non-data,5
| “Non-cross-shared-busy” and “CacheBar-busy” shows the same measures in an experiment where every fourth server was subjected to a slightly more active load of four requests per second This was enough to induce CacheBar’s copy- on-access mechanism to copy some memory pages Again, however, the memory overhead of CacheBar was much less than of disabling cross-container sharing altogether 6|,Non-data,5
| CONCLUSION We have presented two techniques to defend against side- channel attacks via LLCs, namely (i) copy-on-access for phys- ical pages shared among multiple security domains, to in- terfere with Flush-Reload attacks, and (ii) cacheability management for pages to limit the number of cache lines per cache set that an adversary can occupy simultaneously, to mitigate Prime-Probe attacks We described the im- plementation of these techniques in a memory-management subsystem called CacheBar for Linux, to interfere with LLC-based side-channel attacks across containers Using formal analysis (model checking for copy-on-access, and prob- abilistic modeling for cacheability management), we devel- oped designs that mitigate side-channel attacks in our em- pirical evaluations Our experiments also confirmed that the overheads of our approach are modest for PaaS workloads|,Non-data,5
 Acknowledgments This work was supported in part by NSF grants 1330599 and 1566444 7 ,Non-data,5
|ABSTRACT Differential privacy is a promising formal approach to data privacy, which provides a quantitative bound on the privacy cost of an al- gorithm that operates on sensitive information Several tools have been developed for the formal verification of differentially private algorithms, including program logics and type systems However, these tools do not capture fundamental techniques that have emerged in recent years, and cannot be used for reasoning about cutting-edge differentially private algorithms Existing techniques fail to handle three broad classes of algorithms: 1) algorithms where privacy de- pends on accuracy guarantees, 2) algorithms that are analyzed with the advanced composition theorem, which shows slower growth in the privacy cost, 3) algorithms that interactively accept adaptive inputs|,Non-data,8
| We address these limitations with a new formalism extending apRHL [6], a relational program logic that has been used for proving differential privacy of non-interactive algorithms, and incorporating aHL [11], a (non-relational) program logic for accuracy properties We illustrate our approach through a single running example, which exemplifies the three classes of algorithms and explores new variants of the Sparse Vector technique, a well-studied algorithm from the privacy literature We implement our logic in EasyCrypt, and for- mally verify privacy We also introduce a novel coupling technique called optimal subset coupling that may be of independent interest|,Non-data,8
| 1 INTRODUCTION Differential privacy, a rigorous and quantitative notion of sta- tistical privacy, is one of the most promising formal definitions of privacy to date Since its initial formulation by Dwork et al [19], differential privacy has attracted substantial attention throughout ∗The at https://arxiv|,Non-data,8
|org/abs/160607143 †Partially supported by NSF grants CNS-1237235 and CNS- 1565365, and by EPSRC grant EP/M022358/1 ‡Partially supported by NSF grants TC-1065060 and TWC-1513694, and a grant from the Simons Foundation (#360368 to Justin Hsu)|,Non-data,8
| available version paper this full of is Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page Copyrights for components of this work owned by others than the author(s) must be honored Abstracting with credit is permitted To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee|,Non-data,8
| Request permissions from permissions@acmorg CCS’16, October 24 - 28, 2016, Vienna, Austria c(cid:13) 2016 Copyright held by the owner/author(s) Publication rights licensed to ACM|,Non-data,8
 ISBN 978-1-4503-4139-4/16/10   $15,Non-data,8
00 DOI: http://dxdoiorg/101145/2976749,Non-data,8
|2978391 computer science, including areas like databases, machine learning, and optimization, and more There are several reasons for this success For one, differential privacy allows a formal trade-off between privacy and accuracy: differentially private algorithms come with a privacy guarantee expressed in terms of two parameters  (expressing the privacy cost) and δ (expressing the probability of violating the privacy cost) For both parameters, smaller values offer stronger privacy guarantees|,Non-data,8
| Another important advantage differential privacy is that it com- poses well: differentially private algorithms can be easily combined to build new private algorithms The differential privacy literature offers several composition theorems, differing in how the privacy parameter of the larger algorithm depends on the parameters of the components These composition properties can also be used in inter- active and adaptive scenarios where an adversary can decide which algorithm to run depending on the outputs of previous algorithms Differential privacy’s clean composition properties also make it an attractive target for an unusually diverse array of formal verifi- cation techniques|,Non-data,8
| By now, there are tools that formally guarantee differential privacy via relational program logics [2, 6], linear type systems [25, 29, 42], interactive automata [50, 51], product pro- grams [7], satisfiability modulo theories [28], refinement type sys- tems [9], and more While these systems formalize privacy through a wide variety techniques, most of these approaches analyze a com- position of private algorithms using the sequential composition theorem of differential privacy, which guarantees that the resulting algorithms have parameter  and δ equal to the sum of the parameters of their components Recently, Barthe et al [10] highlighted a close connection be- tween approximate couplings and differential privacy which enables formal verification beyond sequential composition|,Non-data,8
| Barthe et al [10] work with the relational program logic apRHL [6], extended with a new composition principle called pointwise privacy The idea is to first prove a restricted case of privacy—corresponding roughly to privacy for a single output—and then combine the results to prove the full differential privacy property Combined with the composition principle for approximate couplings, which generalizes the sequential composition theorem, apRHL can express simple, compositional proofs of algorithms like the one-side Laplace im- plementation of the Exponential mechanism [17] and the Above Threshold algorithm [17] while abstracting away reasoning about probabilistic events|,Non-data,8
| Existing privacy proofs for these algorithms, even on paper, involve ad hoc computation of probabilities While apRHL substantially expands the range of formal verifi- cation in differential privacy, there are still private algorithms that apRHL cannot verify Roughly, there are three missing pieces: 55• Accuracy-dependent privacy Some algorithms are only pri- vate if an accuracy property holds|,Non-data,8
| • Advanced composition This principle shows slower growth in the privacy cost, in exchange for a small probability of violating privacy The proof involves an technical martingale concentration argument • Interactive privacy|,Non-data,8
| Some private algorithms are interactive, receiving a continuous sequence of adaptive inputs while producing intermediate outputs These three missing pieces correspond to three fundamental prin- ciples of differential privacy While there are many algorithms from the privacy literature that use one (or more) of these three features, to structure our presentation we will work with a variant of the Sparse Vector technique based on the Between Thresholds algorithm [13], a single unifying example that uses all three features (§ 2) After reviewing some technical preliminaries about differential privacy, approximate couplings, and the logic apRHL (§ 3), we describe extensions to apRHL to verify privacy for new classes of algorithms|,Non-data,8
| • New proof rules that allow reasoning within apRHL while assuming an accuracy property, incorporating accuracy proofs from the Hoare logic aHL [11] (§ 4) We demonstrate these rules on a classic example of accuracy-dependent privacy: the Propose-test-release framework [16, 48] • A proof rule that analyzes loops using the advanced composi- tion principle; soundness relies on a novel generalization of advanced composition to approximate couplings (§ 5) • New proof rules for adversaries, external procedure calls that model an adaptive source of inputs (§ 6)|,Non-data,8
| • Orthogonal to reasoning about accuracy, advanced composi- tion, and adversarial inputs, we introduce a general construc- tion that may be of independent interest called the optimal subset coupling This construction gives an approximate lift- ing relating subsets that yields the best possible , and we use this construction to give a new interval coupling rule for the Laplace distribution (§ 7) We then show how to combine these ingredients to verify our main running example, the Between Thresholds algorithm (§ 8) We finish with related work (§ 9) and some concluding thoughts (§ 10)|,Non-data,8
