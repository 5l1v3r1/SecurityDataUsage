 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
|g, 8GB), and thus, we leverage new AES instructions in mod- ern CPUs (eg, Intel AES-NI)|,Non-data,50
| AES-NI offers significant per- formance boost (eg, about six times in one test [8]) Al- 951though several crypto libraries now enable easy-to-use sup- port for AES-NI, we cannot use such libraries, or the kernel- shipped library, as we do not have the OS/run-time sup- port|,Non-data,50
| We use Intel’s AES-NI library [52], with minor but non-trivial modifications (discussed in our tech report [71]) OS-less multi-core processing Outside the OS, no easy- to-use parallel processing interface is available With one processor core, we achieved 3|,Non-data,50
|3–4GB/s with AES-NI, which would require more than 2 seconds for 8GB RAM (still less satisfactory, considering 3 cores being idle) Thus, to lever- age multiple cores, we develop our own multi-core processing engine, mostly following the Intel MultiProcessor Specifica- tion [32] Our choice of decrypting in TXT is non-essential, as SK is generated per sleep-wake cycle and requires no TXT protection; however, the current logic is simpler and requires no post-TXT cleanup for native multi-core processing Modes of operation|,Non-data,50
| Intel’s AES-NI library offers ECB, CTR and CBC modes We use AES in CTR mode as the default option (with a random value as the initial counter); compared to CBC, CTR’s performance is better, and sym- metric between encryption and decryption speeds (recall that CBC encryption cannot be parallelized due to chain- ing) In our test, CBC achieves 45GB/s for encryption and 8|,Non-data,50
|4GB/s for decryption In CTR mode, a more satisfac- tory performance is achieved: 87GB/s for encryption and 85GB/s for decryption (approximately)|,Non-data,50
| When ciphertext integrity is required to address content modification attacks, AES-GCM might be a better trade-off between security and performance We have implemented a Hypnoguard variant with a custom, performance-optimized AES-GCM mode; for implementation details and challenges, see our tech report [71] 52 Performance analysis Relationship between number of CPU cores and per- formance|,Non-data,50
| For AES-CTR, we achieved 33–4GB/s (37GB/s on average), using a single core After a preliminary evalua- tion, we found the performance is not linear to the number of processor cores, i|,Non-data,50
|e, using 4 cores does not achieve the speed of 16GB/s, but at most 87GB/s (83GB/s on 3 cores and 7|,Non-data,50
|25GB/s on 2 cores) A potential cause could be Intel Turbo Boost [9] that temporarily increases the CPU frequency when certain lim- its are not exceeded (possibly when a single core is used) Suspecting the throughput of the system RAM to be the primary bottleneck (DDR3), we performed benchmark tests with user-space tools, eg|,Non-data,50
|, mbw [28], which simply measures memcpy and variable assignment for an array of arbitrary size The maximum rate did not surpass 83GB/s, possibly due to interference from other processes During the tests with GCM mode, our observation demon- strates the incremental improvement of our implementation: 2|,Non-data,50
|5GB/s (1-block decryption in C using one core), 322GB/s (1-block decryption in C using four cores), 33GB/s (4-block decryption in C using four cores), 5GB/s (4-block decryp- tion in assembly using four cores), and 68GB/s (4-block decryption in assembly with our custom AES-GCM [71])|,Non-data,50
| The encryption function in assembly provided by Intel al- ready works satisfactorily, which we do not change further The performance numbers are listed in Table 1 At the end, when ciphertext integrity is not considered (the default option), 87GB/s in CTR mode satisfies our requirement of not affecting user experience, specifically, for systems up to 8GB RAM|,Non-data,50
| When GCM is used for ciphertext integrity, we achieve 74GB/s for encryption and 68GB/s for decryption (ie|,Non-data,50
|, 108 seconds for entering sleep and 118 seconds for waking up, which is very close to our 1-second delay limit) Note that, we have zero run-time overhead, after the OS is resumed|,Non-data,50
| 6 VARIANTS For systems with larger RAM (eg, 32GB), Hypnoguard may induce noticeable delays during sleep-wake cycles, if the whole memory is encrypted|,Non-data,50
| For example, according to our current performance (see Section 5), if a gaming system has 32GB RAM, it will take about four seconds for both enter- ing sleep and waking up (in CTR mode), which might be unacceptable To accommodate such systems, we propose two variants of Hypnoguard, where we protect (i) all mem- ory pages of selected processes—requires no modifications to applications; and (ii) selected security-sensitive memory pages of certain processes—requires modifications Note that, these variants require changes in HypnoOSService, but HypnoCore and HypnoDrivers remain unchanged (ie|,Non-data,50
|, un- affected by the OS-level implementation mechanisms) (i) Per-process memory encryption Compared to the design in Section 3, this variant differs only at the choice of the encryption scope It accepts a process list (e|,Non-data,50
|g, supplied by the user) and traverses all memory pages al- located to those processes to determine the scope of encryp- tion We retrieve the virtual memory areas (VMA, of type vm area struct) from task −−> mm −−> mmap of each pro- cess Then we break the areas down into memory pages (in our case, 4K-sized) before converting them over to physical addresses|,Non-data,50
| This is necessary even if a region is continuous as VMAs, because the physical addresses of corresponding pages might not be continuous We store the page list in Hypnoguard-reserved memory Our evaluation shows that the extra overhead of mem- ory traversal is negligible This holds with the assumption that the selected apps are allocated a small fraction of a large memory; otherwise, the full memory or mmap-based variant might be a better choice|,Non-data,50
| For smaller apps such as bash (38 VMAs totaling 1,864 pages, approximately 7MB), it takes 5 microseconds to traverse through and build the list For large apps such as Firefox (723 VMAs totaling 235,814 pages, approximately 1GB), it takes no more than 253 microseconds Other apps we tested are Xorg (167 mi- croseconds) and gedit (85 microseconds) We are yet to fully integrate this variant into our implementation (requires a more complex multi-core processing engine)|,Non-data,50
| (ii) Hypnoguard-managed memory pages via mmap() There are also situations where a memory-intensive appli- cation has only a small amount of secret data to protect Assuming per-application changes are acceptable, we imple- ment a second variant of Hypnoguard that exposes a file system interface compliant with the POSIX call mmap(), allowing applications to allocate pages from a Hypnoguard- managed memory region The mmap() function is defined in the file operations struc- ture, supported by kernel drivers exposing a device node in the file system|,Non-data,50
| An application can request a page to be mapped to its address space on each mmap call, eg, instead of calling malloc() On return, a virtual address mapped 952CTR (1-core) Encryption Decryption 3|,Non-data,50
7GB/s 37GB/s CTR 87GB/s 87GB/s CBC GCM-C1 (1-core) GCM-C1 GCM-C4 GCM-A4 GCM-A4T 4,Non-data,50
5GB/s 84GB/s — — — — 25GB/s 322GB/s 3,Non-data,50
|3GB/s 5GB/s 74GB/s 68GB/s Table 1: A comparative list of encryption/decryption performance Column headings refer to various modes of operation, along with the source language (when applicable; A represents assembly); the trailing number is the number of blocks processed at a time|,Non-data,50
| A4T is our adapted GCM implementation in assembly processing 4 blocks at a time, with delayed tag verification (see [71]); — means not evaluated into the application’s space is generated by Hypnoguard us- ing remap pfn range() An application only needs to call mmap(), and use the returned memory as its own, eg|,Non-data,50
|, to store its secrets Then the page is automatically protected by Hypnoguard the same way as the full memory encryption, ie, encrypted before sleep and decrypted at wakeup|,Non-data,50
| The application can use multiple pages as needed We currently do not consider releasing such pages (ie, no unmap()), as we consider a page to remain sensitive once it has been used to store secrets|,Non-data,50
| Note that, no kernel patch is required to support this variant We tested it with our custom appli- cation requesting pages to protect its artificial secrets We observed no latency or other anomalies 7|,Non-data,50
| SECURITY ANALYSIS Below, we discuss potential attacks against Hypnoguard; see also Sections 23 and 33 for related discussion (a) Cold-boot and DMA attacks|,Non-data,50
| As no plaintext se- crets exist in memory after the system switches to sleep mode, cold-boot or DMA attacks cannot compromise mem- ory confidentiality; see Section 33, under G1 Also, the password evaluation process happens inside the TPM (as TPM receives it through one command and compares with its preconfigured value; see Section 32), and thus the cor- rect password is not revealed in memory for comparison|,Non-data,50
| At wakeup-time, DMA attacks will also fail due to memory access restrictions (TXT/VT-d) (b) Reboot-and-retrieve attack The adversary can simply give up on waking back to the original OS session, and soft-reboot the system from any media of his choice, to dump an arbitrary portion of the RAM, with most content unchanged (the so-called warm boot attacks, eg|,Non-data,50
|, [10, 66, 65]) Several such tools exist, some of which are applicable to locked computers, see eg, [16]|,Non-data,50
| With Hypnoguard, as the whole RAM is encrypted, this is not a threat any more (c) Consequence of key deletion The deletion of HGpriv severely restricts guessing attacks on lost/stolen computers For coercive situations, deletion is needed so that an attacker cannot force users to reveal the Hypnoguard password after taking a memory dump of the encrypted content|,Non-data,50
| Although we use a random AES key SK for each sleep-wake cycle, simply rebooting the machine without key deletion may not suffice, as the attacker can store all encrypted memory con- tent, including SK encrypted by HGpub If HGpriv can be learned afterwards (eg, via coercion of the user password), the attacker can then decrypt SK, and reveal memory con- tent for the target session|,Non-data,50
| If a boot-time anti-coercion tool, eg, Gracewipe [70] is integrated with Hypnoguard, the deletion of HGpriv may also require triggering the deletion of Gracewipe secrets Hypnoguard can easily trigger such deletion by overwrit- ing TPM NVRAM indices used by Gracewipe, which we have verified in our installation|,Non-data,50
| From a usability perspec- tive, the consequence of key deletion in Hypnoguard is to reboot and rebuild the user secrets in RAM, eg, unlock- ing an encrypted disk, password manager, or logging back into security-sensitive websites With Gracewipe integra- tion, triggering deletion will cause loss of access to disk data|,Non-data,50
| (d) Compromising the S3 resume path We are un- aware of any DMA attacks that can succeed when the system is in sleep, as such attacks require an active protocol stack (eg, that of FireWire)|,Non-data,50
| Even if the adversary can use DMA attacks to alter RAM content in sleep, bypassing Hypno- guard still reveals no secrets, due to full memory encryption and the unforgeability of TPM measurements Similarly, replacing the Hypnoguard waking vector with an attacker chosen one (as our waking vector resides in memory unen- crypted), eg, by exploiting vulnerabilities in UEFI resume boot script [33, 67] (if possible), also has no effect on memory confidentiality|,Non-data,50
| Any manipulation attack, eg, insertion of malicious code via a custom DRAM interposer, on the en- crypted RAM content to compromise the OS/applications after wakeup is addressed by our GCM mode implementa- tion (out of scope for the default CTR implementation) (e) Interrupting the key deletion|,Non-data,50
| There have been a few past attacks about tapping TPM pins to detect the dele- tion when it is triggered (for guessing without any penalty) Such threats are discussed elsewhere (eg, [70]), and can be addressed, e|,Non-data,50
|g, via redundant TPM write operations (f ) Other hardware attacks Ad-hoc hardware attacks to sniff the system bus for secrets (e|,Non-data,50
|g, [7]) are generally inapplicable against Hypnoguard, as no secrets are processed before the correct password is entered For such an example attack on Xbox, see [29], which only applies to architectures with LDT (HyperTransport) bus, not Intel’s FSB However, more advanced hardware attacks may allow di- rect access to the DRAM bus, and even extraction of TPM secrets with an invasive decapping procedure (e|,Non-data,50
|g, [59], see also [26] for more generic physical attacks on security chips) Note that the PC platform (except the TPM chip to some extent) cannot withstand such attacks, as components from different manufactures need to operate through common in- terfaces (vs more closed environment such as set-top boxes)|,Non-data,50
| With TPMs integrated into the Super I/O chip, and specif- ically, with firmware implementation of TPM v20 (fTPM as in Intel Platform Trust Technology), decapping attacks may be mitigated to a significant extent (see the discussion in [50] for discrete vs firmware TPMs) Hypnoguard should be easily adapted to TPM v2|,Non-data,50
|0 8 RELATED WORK In this section, we primarily discuss related work on mem- ory attacks and preventions Proposals for addressing change of physical possession (e|,Non-data,50
|g, [55, 17]) are not discussed, as they do not consider memory attacks Protection against cold-boot and DMA attacks So- lutions to protecting keys exposed in system memory have been extensively explored in the last few years, apparently, due to the feasibility of cold-boot attacks [25]|,Non-data,50
| There have 953been proposals based on relocation of secret keys from RAM to other “safer” places, such as SSE registers (AESSE [43]), debug registers (TRESOR [45]), MSR registers (Amne- sia [56]), AVX registers (PRIME [18]), CPU cache and debug registers (Copker [23]), GPU registers (PixelVault [63]), and debug registers and Intel TSX (Mimosa [24]) A common limitation of these solutions is that specific cryptographic operations must be offloaded from the pro- tected application to the new mechanism, mandating per- application changes They are also focused on preventing leakage of only cryptographic keys, which is fundamentally limited in protecting RAM content in general Also, some solutions do not consider user re-authentication at wakeup- time (e|,Non-data,50
|g, [18, 23]) Several of them (re)derive their master secret, or its equivalent, from the user password, eg|,Non-data,50
|, [43, 45]; this may even allow the adversary to directly guess the master secret in an offline manner Memory encryption An ideal solution for memory ex- traction attacks would be to perform encrypted execution: instructions remain encrypted in RAM and are decrypted right before execution within the CPU; see XOM [36] for an early proposal in this domain, and Henson and Taylor [27] for a comprehensive survey Most proposals for memory en- cryption deal with data in use by an active CPU|,Non-data,50
| Our use of full memory encryption involves the sleep state, when the CPU is largely inactive Most systems require architectural changes in hardware/OS and thus remain largely unadopted, or designed for specialized use cases, eg, bank ATMs|,Non-data,50
| Us- ing dedicated custom processors, some gaming consoles also implement memory encryption to some extent, eg, Xbox, Playstation Similar to storing the secrets in safer places, memory encryption schemes, if implemented/adopted, may address extraction attacks, but not user re-authentication|,Non-data,50
| Forced hibernation YoNTMA [34] automatically hiber- nates the machine, ie, switch to S4/suspend-to-disk, when- ever it detects that the wired network is disconnected, or the power cable is unplugged|,Non-data,50
| In this way, if the attacker wants to take the computer away, he will always get it in a powered-off state, and thus memory attacks are mitigated A persistent attacker may preserve the power supply by us- ing off-the-shelf hardware tools (eg, [39])|,Non-data,50
| Also, the at- tacker can perform in-place cold-boot/DMA attacks BitLocker Microsoft’s drive encryption tool BitLocker can seal the disk encryption key in a TPM chip, if avail- able Components that are measured for sealing include: the Core Root of Trust Measurement (CRTM), BIOS, Op- tion ROM, MBR, and NTFS boot sector/code (for the full list, see [42])|,Non-data,50
| In contrast, Hypnoguard measures compo- nents that are OS and BIOS independent (may include the UEFI firmware in later motherboard models) In its most secure mode, Microsoft recommends to use BitLocker with multi-factor authentication such as a USB device containing a startup key and/or a user PIN, and to configure the OS to use S4/suspend-to-disk instead of S3/suspend-to-RAM [41] In this setting, unattended computers would always resume from a powered-off state (cf YoNTMA [34]), where no se- crets remain in RAM; the user needs to re-authenticate with the PIN/USB key to restore the OS|,Non-data,50
| BitLocker’s limitations include the following (1) It un- dermines the usability of sleep modes as even with faster SSDs it still takes several seconds to hibernate (approx 18 seconds in our tests with 8GB RAM in Windows 10 ma- chine with Intel Core-i5 CPU and SSD) Wakeup is also more time-consuming, as it involves the BIOS/UEFI POST screen before re-authentication (approx|,Non-data,50
| 24 seconds in our tests) On the other hand, RAM content remains unpro- tected if S3 is used (2) It is still vulnerable to password guessing to some extent, when used with a user PIN (but not with USB key, if the key is unavailable to the attacker) Based on our observation, BitLocker allows many attempts, before forcing a shutdown or entering into a TPM lockout (manufacturer dependent)|,Non-data,50
| A patient adversary can slowly test many passwords We have not tested if offline password guessing is possible (3) BitLocker is not designed for coer- cive situations, and as such, it does not trigger key deletion through a deletion password or fail counter If a user is cap- tured with the USB key, then the disk and RAM content can be easily accessed|,Non-data,50
| (4) Users also must be careful about the inadvertent use of BitLocker’s online key backup/escrow feature (see eg, [4]) Recreating trust after S3 sleep|,Non-data,50
| To re-establish a se- cure state when the system wakes up from S3, Kumar et al [35] propose the use of Intel TXT and TPM for recreat- ing the trusted environment, in the setting of a VMM with multiple VMs Upon notification of the S3 sleep, the VMM cascades the event to all VMs Then each VM encrypts its secrets with a key and seal the key with the platform state|,Non-data,50
| The VMM also encrypts its secrets and seals its con- text Thereafter, the VMM loader (hierarchically higher than the VMM) encrypts the measurement of the whole memory space of the system with a key that is also sealed At wakeup-time, all checks are done in the reversed order If any of the measurements differ, the secrets will not be unsealed|,Non-data,50
| This proposal does not consider re-authentication at wakeup-time and mandates per-application/VM modifi- cations More importantly, sealing and unsealing are per- formed for each sleep-wake cycle for the whole operating context: VMM loader, VMM, VMs Depending on how the context being sealed is defined, this may pose a severe perfor- mance issue, as TPM sealing/unsealing is time-consuming; according to our experiment, it takes more than 500ms to process only 16 bytes of data Unlocking with re-authentication at S2/3/4 wakeup|,Non-data,50
| When waking up from one of the sleep modes, a locked de- vice such as an FDE hard drive, may have already lost its security context (eg, being unlocked) before sleep Ro- driguez and Duda [51] introduced a mechanism to securely re-authenticate the user to the device by replacing the origi- nal wakeup vector of the OS with a device specific S3 wakeup handler|,Non-data,50
| The user is prompted for the credential, which is di- rectly used to decrypt an unlock key from memory to unlock the device (eg, the hard drive) This approach does not use any trusted/privileged execution environment, such as Intel TXT/AMD SVM|,Non-data,50
| Without the trusted measurement (ie, no sealed master key), the only entropy comes from the user password, which may allow a feasible guessing attack Secure deallocation|,Non-data,50
| To prevent exposure of memory- bound secrets against easy-to-launch warm-reboot attacks, Chow et al [10] propose a secure deallocation mechanism (eg, zeroing freed data on the heap) to limit the lifetime of sensitive data in memory|,Non-data,50
| This approach avoids modifi- cations in application source, but requires changes in com- pilers, libraries, and OS kernel in a Linux system (and also cannot address cold-boot attacks) Our solution is also effec- 954tive against warm-reboot attacks, but requires no changes in applications and the OS stack Relevant proposals on mobile platforms Considering their small sizes and versatile functionalities, mobile devices are more theft-prone and more likely to be caught with sen- sitive data present when the user is coerced|,Non-data,50
| CleanOS [58] is proposed to evict sensitive data not in active use to the cloud and only retrieve the data back when needed Sensitive in- formation is pre-classified and encapsulated into sensitive data objects (SDOs) Access to SDOs can be revoked in the case of device theft and audited in normal operations Tin- Man [69] also relies on a trusted server, but does not decrypt confidential data in the device memory to avoid physical attacks|,Non-data,50
| Keypad [19], a mobile file system, provides fine- grained access auditing using a remote server (which also hosts the encryption keys) For lost devices, access can be easily revoked by not releasing the key from the server All these proposals require a trusted third party Also, under coercion, if the user is forced to cooperate, sensitive data will still be retrieved|,Non-data,50
| Moreover, the protected secrets in Hypnoguard might not be suitable for being evicted as they may be used often, eg, an FDE key Gracewipe|,Non-data,50
| For handling user secrets in the trusted execution environment, we follow the methodology from Gracewipe [70], which operates at boot-time and thus can rely on BIOS and tboot In contrast, Hypnoguard oper- ates during the sleep-wake cycle, when no BIOS is active, and tboot cannot be used for regular OSes (tboot assumes TXT-aware OS kernel) Gracewipe assumes that the at- tacker can get physical possession of a computer, only when it is powered-off, in contrast to Hypnoguard’s sleep state, which is more common Gracewipe securely releases sensi- tive FDE keys in memory, but does not consider protecting such keys against memory extraction attacks during sleep- wake|,Non-data,50
| Gracewipe addresses an extreme case of coercion, where the data-at-rest is of utmost value We target unat- tended computers in general, and enable a wakeup-time se- cure environment for re-authentication and key release Intel SGX Intel Software Guard Extensions (SGX [3]) al- lows individual applications to run in their isolated context, resembling TXT with similar features but finer granular- ity (multiple concurrent secure enclaves along with the in- secure world)|,Non-data,50
| Memory content is fully encrypted outside the CPU package for SGX-enabled applications Consider- ing the current positioning of Hypnoguard, we believe that TXT is a more preferable choice, as running either the pro- tected programs or the entire OS in SGX would introduce per-application/OS changes TXT also has the advantage of having been analyzed over the past decade, as well as its counterpart being available in AMD processors (SVM) 9|,Non-data,50
| CONCLUDING REMARKS As most computers, especially, laptops, remain in sleep while not actively used, we consider a comprehensive list of threats against memory-resident user/OS data, security- sensitive or otherwise We address an important gap left in existing solutions: comprehensive confidentiality protec- tion for data-in-sleep (S3), when the attacker has physical access to a computer in sleep We design and implement Hypnoguard, which encrypts the whole memory very quickly before entering sleep under a key sealed in TPM with the integrity of the execution environment We require no per- application changes or kernel patches|,Non-data,50
| Hypnoguard enforces user re-authentication for unlocking the key at wakeup-time in a TXT-enabled trusted environment Guessing attacks bypassing Hypnoguard are rendered ineffective by the prop- erties of TPM sealing; and guessing within Hypnoguard will trigger deletion of the key Thus, Hypnoguard along with a boot-time protection mechanism with FDE support (eg|,Non-data,50
|, BitLocker, Gracewipe [70]) can enable effective server-less guessing resistance, when a computer with sensitive data is lost/stolen We plan to release the source code of Hypno- guard at a later time, and for now it can be obtained by contacting the authors Acknowledgements This paper was significantly improved by the insightful com- ments and suggestions from the anonymous reviewers of CCS 2016, USENIX Security 2016 and EuroSys 2016, as well as Jonathan McCune We also appreciate the help we received from the members of Concordia’s Madiba Security Research Group|,Non-data,50
|ABSTRACT Mobile device losses and thefts are skyrocketing The sen- sitive data hosted on a lost/stolen device are fully exposed to the adversary Although password-based authentication mechanisms are available on mobile devices, many users re- portedly do not use them, and a device may be lost/stolen while in the unlocked mode This paper presents the de- sign and evaluation of iLock, a secure and usable defense against data theft on a lost/stolen mobile device|,Non-data,51
| iLock automatically, quickly, and accurately recognizes the user’s physical separation from his/her device by detecting and analyzing the changes in wireless signals Once significant physical separation is detected, the device is immediately locked to prevent data theft iLock relies on acoustic sig- nals and requires at least one speaker and one microphone that are available on most COTS (commodity-off-the-shelf) mobile devices Extensive experiments on Samsung Galaxy S5 show that iLock can lock the device with negligible false positives and negatives|,Non-data,51
| CCS Concepts •Human-centered computing → Mobile devices; •Security and privacy → Mobile and wireless security; Keywords Device locking, FMCW, audio ranging, smartphone security 1 INTRODUCTION The human society is in a wireless and mobile era Accord- ing to the Cisco Virtual Networking Index [2], 497 million mobile devices (mainly tablets, smartphones, and laptops) were added in 2014, and the number of global mobile de- vices in 2014 reached 74 billion and will reach 11|,Non-data,51
|5 billion by 2019 at a CAGR of 9% People are using mobile devices in every aspect of life, including work, education, voice/video Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita- tion on the first page Copyrights for components of this work owned by others than ACM must be honored Abstracting with credit is permitted|,Non-data,51
| To copy otherwise, or re- publish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acmorg CCS ’16, October 24–28, 2016, Vienna, Austria|,Non-data,51
 c(cid:2) 2016 ACM ISBN 978-1-4503-4139-4/16/10  ,Non-data,51
 $1500 DOI: http://dxdoiorg/10,Non-data,51
|1145/29767492978294 communications, Internet browsing, web transactions, on- line banking, reading, multimedia playing, etc Mobile device losses/thefts are skyrocketing and posing severe threats to data security According to a 2012 Kensing- ton study [1], one laptop is stolen every 53 seconds; 70 mil- lion smartphones are lost each year, with only 7% recovered; and 4|,Non-data,51
|3% of company-issued smartphones are lost/stolen ev- ery year The true cost of a lost/stolen mobile device goes far beyond the device cost due to the lost productivity, the loss of intellectual property, data breaches, and legal fees The most common defense against device losses/thefts is to set a password on the mobile device Unfortunately, the 2015 Kaspersky Lab survey [4] shows that 31% of smart- phones and 41% of tablets are not password-protected|,Non-data,51
| In addition, the time window for a password-protected device going from the unlocked mode to the locked mode may be long enough for a capable attacker to access all the sensi- tive information on the lost/stolen device For example, the auto-lock options on iPad 2 include 2 min, 5 min, 10 min, 15 min, and NEVER Many users choose a longer time period or even NEVER for convenience If an unlocked device is lost/stolen, the user’s sensitive information is fully accessible to whoever possesses the device|,Non-data,51
| Continuous authentication aims to continuously verify the identity of the user using a mobile device and is natural- ly a candidate defense against device losses/thefts This line of work aims to verify the behavioral biometrics of the user exhibited in his keystrokes [18], finger touches on the screen [14], or app usage [12] In addition to their relative- ly high false positives and negatives, these approaches often require a relatively long time window to collect sufficient data for capturing the behavioral biometrics The attack- er, however, may quickly access the user’s private data and then completely wipe out the device for reinstallation, rather than using the device for an extended period of time|,Non-data,51
| In this paper, we present iLock, a secure and usable de- fense against device losses/thefts iLock immediately and automatically locks a mobile device once it leaves the vicin- ity of its user The key motivation behind iLock is that the departure of a user from his device causes the physi- cal environment to change and thus noticeable changes in nearby wireless signals So we can let the mobile device automatically, quickly, and accurately recognize its physical separation from its owner by detecting and analyzing the changes in wireless signals|,Non-data,51
| Once significant physical sepa- ration from its user is detected, the device can immediately and automatically lock itself iLock cannot help retrieve a 933lost/stolen device, but it can help prevent data theft Spe- cially, after iLock locks the device, the user can use various apps such as Find My Phone to track the device, remotely disable it, and even completely erase it iLock relies on acoustic signals and requires at least one s- peaker and one microphone that are available on most COTS mobile devices, such as smartphones, tablets, laptops, and all-in-one PCs|,Non-data,51
| Once a user-defined vulnerable context (eg, out of home) is automatically detected, the speaker keep- s transmitting high-frequency acoustic signals inaudible to human ears The signals are reflected by the user’s body and finally reach the microphone after some delay|,Non-data,51
| The de- vice can then estimate its distance from the user based on the received signals and automatically lock itself once the distance estimation exceeds a user-defined threshold How could the user-device distance be estimated? One may simply let the speaker transmit an acoustic signal, which reaches the microphone via the speaker-user-microphone path After computing the time-of-flight (ToF) as the difference between signal transmission and reception time, the device can estimate the user-device distance as c × ToF/2, where c denotes the speed of sound about 340 m/s This seemingly simple method unfortunately does not work because of very coarse-grained timestamps on mobile devices, which can be due to many reasons such as various delays between the ap- plication and physical layers [23]|,Non-data,51
| For example, an error of 001 s may cause a distance-measurement error about 17 m which is obviously not acceptable for device locking iLock adopts a technique called FMCW (frequency modu- lated carrier wave) [16] to avoid computing the ToF directly based on inaccurate timestamps on mobile devices|,Non-data,51
| FMCW transforms the time differences to frequency shifts between transmitted and received signals With FMCW, the speaker changes the acoustic signal frequency linearly The device computes Δf , the frequency difference between the signal transmitted at the speaker and the signal received by the microphone at the same time Since the slope of the linear FMCW function is known, the ToF is roughly Δf slope , and the user-device distance can still be estimated as c ∗ ToF/2|,Non-data,51
| Implementing FMCW-based iLock on COTS mobile de- vices faces two critical challenges First, the device must compute the frequency drift Δf as the frequency difference between the signals simultaneously transmitted at the s- peaker and arriving at the microphone This seemingly sim- ple requirement is difficult to fulfill on COTS mobile devices because the timestamps obtained from the OS are highly inaccurate Second, the signal arriving at the microphone is actually a linear combination of multi-path signals com- ing from the direct speaker-microphone path, the speaker- user-microphone path, and other paths involving many other physical objects|,Non-data,51
| The device thus should be able to separate the signal from the speaker-user-microphone path from oth- er multi-path signals Our contributions in this paper are summarized as follows • We design iLock, the first system to immediately and automatically lock a COTS mobile device once its phys- ical separation from its owner is significant iLock can effectively thwart data theft on a lost/stolen mobile device without any user involvement|,Non-data,51
| • We propose a novel method to implement iLock based on the FMCW technique, which is applicable to almost all COTS mobile devices with at least one speaker and one microphone • We implement iLock and conduct extensive experi- ments on Samsung Galaxy S5 against various attack- ers Our evaluation results show that iLock can imme- diately lock the device with negligible false positives and negatives The rest of the paper is organized as follows|,Non-data,51
 Section 2 introduces the adversary model and our design goals Sec- tion 3 details the iLock design Section 4 presents the ex- perimental evaluations Section 5 discusses the energy con- sumption of iLock and other possible solutions,Non-data,51
 Section 6 briefs the related work Section 7 concludes this paper 2 ADVERSARY MODEL AND DESIGN GOALS Adversary Model,Non-data,51
| We assume that the mobile device to protect is unlocked This can be because the auto-lock op- tion is disabled or has not taken effect if a long time window (eg, 5 min) is chosen|,Non-data,51
| The attacker possesses the device and tries to access sensitive information stored there We consider three types of attackers according to their initial distance from the device relative to the (legitimate) user • Type-I attacker: This kind of attackers find the device the legitimate user accidentally lost in public places such as streets, restrooms, coffee shops, and subways Type-I attackers are initially much farther away from the device than the user|,Non-data,51
| • Type-II attacker: Such attackers are still farther away from the device than the user, but the distance dif- ference is very small For example, the attacker can be a thief trying to steal the device from the user on a crowded bus/subway, and the attacker may also be a malicious coworker who just sat with the user for a meeting and saw the user leave without taking the device on the conference table • Type-III attacker: These attackers are closer to the device than the user For example, the user may acci- dently put the device closer to the malicious coworker on the conference table and leave the meeting without taking the device|,Non-data,51
| Since iLock relies on acoustic signal transmissions and re- ceptions, one may think about defeating iLock by letting the attacker jam the acoustic channel Such jamming at- tacks are very easy to detect and mitigate So we focus on dealing with the three types of attackers above Design Goals|,Non-data,51
| iLock cannot help retrieve a lost/stolen device, but it can help prevent data theft on a lost/stolen device We have the following design goals • iLock should be device-free and does not rely on any auxiliary device It should also be applicable to most COTS mobile devices|,Non-data,51
| • iLock should immediately lock the device once the user- device distance exceeds a pre-defined threshold to min- imize the time opportunity for data theft 934f1 y c n e u q e r F f0 ∆f  ∆t (cid:17)(cid:17)(cid:17) Sweep 1 Sweep 2 Time Figure 1: FMCW illustration The frequency of the trans- mitted signal (red solid line) repeatedly increases from f0 to f1 After a time delay Δt, the signal arrives at the receiver (blue dashed line)|,Non-data,51
 The frequency shift Δf can be extracted by performing FFT over each sweep (cid:44)(cid:81)(cid:76)(cid:87)(cid:76)(cid:68)(cid:79)(cid:3)(cid:54)(cid:76)(cid:74)(cid:81)(cid:68)(cid:79)(cid:3) (cid:36)(cid:79)(cid:76)(cid:74)(cid:81)(cid:80)(cid:72)(cid:81)(cid:87) (cid:48)(cid:76)(cid:91)(cid:72)(cid:85) (cid:41)(cid:41)(cid:55) (cid:37)(cid:68)(cid:70)(cid:78)(cid:74)(cid:85)(cid:82)(cid:88)(cid:81)(cid:71)(cid:3) (cid:54)(cid:88)(cid:69)(cid:87)(cid:85)(cid:68)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81) (cid:50)(cid:88)(cid:87)(cid:79)(cid:76)(cid:72)(cid:85)(cid:3)(cid:53)(cid:72)(cid:77)(cid:72)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3) (cid:68)(cid:81)(cid:71)(cid:3)(cid:41)(cid:76)(cid:79)(cid:87)(cid:72)(cid:85)(cid:76)(cid:81)(cid:74) (cid:56)(cid:86)(cid:72)(cid:85)(cid:3) (cid:55)(cid:85)(cid:68)(cid:70)(cid:72) Figure 2: The system framework of iLock • iLock should be automatic and user-friendly It should not require any explicit interaction between the user and device,Non-data,51
| Nor does the user’s device-use habit need to be changed • iLock should be very accurate in detecting the user- device distance, which can translate into very low false positives and negatives for triggering device locking 3 ILOCK This section details the iLock design|,Non-data,51
| We start by in- troducing FMCW in Section 31 Then we discuss how to defend against Type-I, Type-II, and Type-III attackers in Sections 32, 3|,Non-data,51
|3, and 34, respectively 31 Frequency-Modulated Carrier Waves Fig|,Non-data,51
| 1 gives a high-level overview of FMCW, and we refer the reader to [16] for a more detailed illustration FMCW operations proceed in rounds In each round referred to as a sweep, the transmitter linearly increases the transmis- sion frequency from f0 to f1, where f0 and f1 are prede- termined minimum and maximum frequencies Each signal arrives at the receiver after some delay Δt (the so-called ToF)|,Non-data,51
| The transmitted and received signal frequencies for each sweep are depicted by red solid and blue dashed lines in Fig 1, respectively According to Fig 1, it is clear that Tsweep, where Tsweep is the duration of each Δt = sweep|,Non-data,51
| Finally, we can estimate the signal-travel distance d = cΔt, where c is the signal propagation speed 32 Defeating Type-I Attackers: When Attack- (cid:2)f f1−f0 ers Are Initially Farawy iLock relies on FMCW to dynamically estimate the user- device distance and automatically locks the device once the user-defined safe distance is exceeded iLock uses acoustic signals so that it can work on most COTS mobile devices with standard build-in microphones and speakers|,Non-data,51
| Thus c is the speed of sound of about 340 m/s The minimum FMCW frequency f0 is set to be sufficiently high (eg, 18 kHz) so that the signal is almost inaudible to human ears, and the maximum FMCW frequency f1 can be set to half the high- est sampling frequency of the microphone|,Non-data,51
| For example, most COTS smartphones support the sampling frequency up to 441 kHz, so we can set f1 equal to 22 kHz Tsweep is a design parameter dictating the tradeoff between maxi- mum detection range and frequency drift resolution, which becomes clear shortly The implementation of FMCW-based iLock on COTS mo- bile devices faces two critical challenges|,Non-data,51
| First, the device must compute the frequency drift Δf as the frequency differ- ence between the signals simultaneously transmitted at the speaker and arriving at the microphone, as shown in Fig 1 To do so, the transmitted and received signals for the same sweep should be properly aligned This seemingly simple goal is difficult to achieve on COTS mobile devices because the timestamps obtained from the OS are highly inaccurate in contrast to the short sweep duration|,Non-data,51
| Specifically, there are many reasons for the skew between the sending times- tamp and actual signal-emission time [23] For example, the transmission instructions have to be transferred from the ap- plication layer to the physical layer, which may be delayed by many system events such as system interrupts Similar reasons can also account for the skew between the receiving timestamp got from the OS and the actual receiving time by the microphone circuit More accurate time measure- ments can be obtained from the kernel, but this option is not feasible on mobile devices|,Non-data,51
| Second, the signal arriv- ing at the microphone is actually a linear combination of multi-path signals coming from the direct path between the speaker and microphone, the speaker-user-microphone path, and other paths involving many other physical objects The device thus should be able to separate the signal from the speaker-user-microphone path from other signals Below we illustrate how iLock tackles these two challenges with the system diagram in Fig 2|,Non-data,51
| We assume Type-I at- tackers in this section such that the signals are reflected by only one human object (the user him/herself) The Signal Alignment module is designed to deal with the first challenge Specifically, the speaker transmits acoustic signals with the frequencies sweeping from f0 to f1, which arrive at the microphone after some delay In ideal situations with accurate timestamps and static signal propagation en- vironments, the time gap between transmitted and received signal vectors for the sweep that can be obtained from the transmitted and received timestamps should be constant, as shown in Fig|,Non-data,51
| 1 Such gaps, however, may vary a lot across each sweep mainly due to inaccurate timestamps Our design leverages the observation that the physical dis- tance between the speaker and microphone is fixed and usu- ally very short relative to the user-device distance,1 so the signals arriving from the direct speaker-microphone path dominate other multi-path components If the sweep du- ration is so short that signal propagation environments are approximately static, the time gap between transmitted and received signal vectors on the direct path should be constant across each sweep regardless of inaccurate timestamps|,Non-data,51
| Let 1For example, the distances of the speaker to two micro- phones on a Samsung Galaxy S5 are 45 cm and 123 cm, respectively 935sin(ftxt) and sin(frxt) denote the transmitted and received signals at the same timestamp, respectively|,Non-data,51
| The Signal 2 (cos[(ftx− Alignment module computes sin(ftxt) sin(frxt) = 1 frx)t] − cos[(ftx + frx)t]) and then uses a low-pass filter to get cos[(ftx − frx)t] Then we advance the received signal vector by an offset k to minimize the frequency difference ftx − frx If the microphone only receives the signals from the direct speaker-microphone path, there can be an almost perfect overlap between the transmitted and received sig- nal vectors after the shifting with ftx − frx ≈ 0 Due to the presence of the user and other physical objects, the transmit- ted and received signals cannot overlap each other|,Non-data,51
| Finally, the transmitted signals correspond to the red solid line in Fig 1, and the advanced received signals correspond to the blue dashed line in Fig 1 Then the Mixer module is invoked to compute cos[(ftx − frx)t] in the same way as in the Alignment module for the transmitted and received signals at the same instant in the same sweep|,Non-data,51
| Different physical objects lead to different re- flection paths, each corresponding to a different time shift So the FFT module is subsequently used in each sweep to extract these different frequency shifts Since each frequency shift corresponds to a different ToF measurement and thus a different signal-travel distance, we plot the received signal powers at different distances in Fig 3a, which are obtained from a microphone on a Samsung Galaxy S5 with f0 = 18 kHz, f1 = 22 kHz, and Tsweep = 20 ms|,Non-data,51
| There are many horizontal strips with each corresponding to a different path the signal traveled from the speaker to microphone Some strips are not stable with time, as user movements change the multi-path propagation environment The strips around distance zero are the brightest, corresponding to the direct speaker-microphone path We then use the Background Substraction module to high- light the effect of user movements|,Non-data,51
| Specifically, the physi- cal objects other than the user (eg, doors and walls) can be assumed to be static relative to user movements, which generally holds given the very short duration to detect user movements and then lock the device Therefore, the reflec- tion paths due to these static objects are static across the sweeps, so we can easily remove their effects via subtrac- tion|,Non-data,51
| Fig 3b shows the substraction result, where the signal power decreases as the distance increases Next, we use the Kalman filter in the Outlier Rejection and Filtering module to smooth out the data Fig|,Non-data,51
| 3c shows the user’s movement trace before and after outlier rejection and filtering In this experiment, the user initially sits on the chair with the smartphone on the table Then he stands up and turns around to move away from the table and thus his smartphone As we can see, his distance to the smart- phone decreases when he stands up (around 2,000 ms) and increases when he moves away (after 2,000 ms)|,Non-data,51
| When should the device be locked? In everyday life, the device is often placed within the arm’s reach, so the user can set a threshold δ1 about the arm length when installing iLock We also define another distance threshold δ2, beyond which the user can hardly put his device iLock immediately and automatically locks the device when the user-device distance starts below δ1 and then exceedsδ 2 We set δ1 = 60 cm and δ2 = 1 m in the experiments, and the user can freely adjust them in practice|,Non-data,51
| How accurate are the distance measurements in iLock? The resolution of distance measurements relies on that of ToF measurements which further depends on that of frequency measurements The minimum frequency drift in iLock equals 1/Tsweep (ie, the size of one FFT bin), which translates into a ToF resolution of |,Non-data,51
| So the 2(f1−f0) , user-device distance resolution can be derived as for which we assume that the user-device distance is half of the speaker-user-microphone path length With f1 = 22 kHz, f0 = 18 kHz, and c = 340 m/s, the user-device distance resolution is about 425 cm, which is sufficient to detect the user’s significant departure from the device 1/Tsweep∗Tsweep f1−f0 c The maximum detection range for the user-device distance depends on both the sweep duration and also the speaker volume|,Non-data,51
| Considering the sweep duration alone, we can com- pute the maximum user-device distance as cTsweep/2, which equals 34 m if Tsweep = 20 ms The speaker volume corre- sponds to transmission power and thus distance: the larger the speaker volume, the larger the transmission power con- sumption, the larger the detectable user-device distance, and vice versa In our experiments, the 71% volume level leads to a maximum detection range at about 1|,Non-data,51
|5 m Another issue worth mentioning is the impact of initial signal alignment on distance measurements The net effect of initial signal alignment is to virtually place the speaker and microphone together So each subsequent microphone- = d − object-speaker distance measurement is actually d dsm, where d is the actual signal travel distance, and dsm means the distance between the speaker and microphone|,Non-data,51
| For most portable mobile devices, dsm is relatively small in contrast to user movements and can be safely ignored For larger mobile devices such as laptops and all-in-one PCs, dsm can be easily estimated and then used to obtain d (cid:2) 33 Defeating Type-II Attackers: When At- tackers Get Closer The basic iLock design in Section 3|,Non-data,51
|2 assumes that the at- tacker is initially faraway from the device, so only the move- ment of the user him/herself needs to be tracked In this section, we discuss how to defeat Type-II attackers which are initially also close to the device but still at a greater dis- tance than the user-device distance There are many such scenarios in daily life For example, the user leaves a confer- ence room without taking his/her device on the table, where malicious coworkers or conference attendees try to access sensitive data on the user’s device|,Non-data,51
| The device may also slip out of the user’s pocket or suitcase on public transport tools and be picked up by malicious passengers nearby The exis- tence of multiple persons (including the target user) nearby causes the target device to detect multiple movement traces So the essential challenge is to identify the movement trace associated with the legitimate user, based on which to make salient device-locking decisions To begin with, we consider a common scenario that only one person near the device moves away from it|,Non-data,51
| Even if other persons do not move, they may still have minor body movements which can be detected by the device Since the target user is assumed to be initially closer to his/her device than other persons, his/her movement trace can be easily singled out based on the initial closer distance measurement Fig 4 shows an exemplary scenario where the target user leaves but the attacker stays, and Fig|,Non-data,51
 5 corresponds to the case that the attacker leaves but the user stays It is very clear that the target user’s movement trace can be easily 93616 14 1,Non-data,51
2 1 08 06 ) m ( (cid:3) e c n a t s D i 60 50 40 30 16 1,Non-data,51
4 12 1 08 06 ) m ( (cid:3) e c n a t s D i 6000 (cid:1)105 3 2,Non-data,51
5 2 15 1 05 2 15 1 0,Non-data,51
5 ) m ( (cid:3) e c n a t s D i 6000 0 0 2000 4000 Time(cid:3)(ms) 2000 4000 Time(cid:3)(ms) Raw Trace Processed Trace 2000 4000 Time(cid:3)(ms) 6000 (a) Spectrogram (b) Spectrogram after Background Sub- traction (c) User Leaving Trace Figure 3: Single user tracking with FMCW Figure (a) plots the spectrogram after we take FFT on each sweep Figure (b) eliminates static multipath by subtracting the power of a previous sweep from the current sweep Figure (c) illustrates the user’s moving traces before and after outlier rejection and filtering,Non-data,51
| identified, based on which the device can determine whether to lock itself according to the same rules in 32 There can be ambiguity if the user-device distance is not much smaller than the attacker-device distance, especially when there are more than two persons near the device who may leave or stay with the device around the same time For example, multiple passengers (including/excluding the tar- get user) may exit at the same bus stop|,Non-data,51
| As a result, there can be multiple movement traces corresponding to leaving persons and also multiple ones for staying persons Leav- ing traces are easier to be distinguished from staying traces because the latter correspond to relative stable and smaller distances But the leaving traces themselves may intersect, so may the staying traces themselves The limited resources on COTS mobile devices make it impossible to accurately identify the movement trace for each individual person|,Non-data,51
| For- tunately, our goal is to preserve data security in the case of device thefts/losses, so it makes more sense to weigh false positives over false negatives Under the assumption that the target user is initially closer to the device than other persons nearby, we can take an aggressive approach as fol- lows We first construct a set of candidate leaving traces from the distance measurements For example, if two per- sons leave the device with their leaving traces intersecting each other, we can construct four candidate leaving traces|,Non-data,51
| Among the candidate traces satisfying the locking condi- tion (ie, starting below δ1 and exceeding δ2), we select the one whose minimum distance measurement is the smallest, denoted by dL Similarly, we construct a set of candidate staying traces, from which to select the one whose minimum distance measurement is the smallest, denoted by dS|,Non-data,51
| Let ω denote the maximum possible distance measurement error As long as dL ≤ dS + 2ω, iLock associates the leaving trace with the target user and immediately locks the device 34 Defeating Type-III Attackers: When At- tackers Are Closer than the User Now we illustrate how iLock withstands a Type-III at- tacker, the strongest one who is even closer to the device than its legitimate user (e|,Non-data,51
g two scenarios in Fig 6) Such attack scenarios are not unusual,Non-data,51
| For example, the user sits very close to the attacker in a conference room and acciden- 15 1 05 ) m ( (cid:3) e c n a t s D i Target user Attacker 2000 4000 6000 8000 10000 12000 Time(cid:3)(ms) Figure 4: The scenario where the user leaves and attacker stays The user departs from about 0|,Non-data,51
|2m from the device The attacker stays at 05m from the device with small move- ments In this case, the device should be locked|,Non-data,51
 15 1 05 ) m ( (cid:3) e c n a t s D i Attacker Target user 2000 4000 6000 8000 10000 12000 Time(cid:3)(ms) Figure 5: The scenario where the user stays and attacker leaves The attacker departs from about 0,Non-data,51
|5m from the de- vice The user stays at 03m from the device with small movements In this case, the device should not be locked|,Non-data,51
| 937Mic1 Mic2 Attacker (cid:71)(cid:21)(cid:10) (cid:71)(cid:20)(cid:10) (cid:71)(cid:20) (cid:71)(cid:21) User Attacker (cid:71)(cid:20)(cid:10) (cid:71)(cid:21)(cid:10) Mic1 Mic2 (cid:71)(cid:20) (cid:71)(cid:21) User Figure 6: Two scenarios in which the attacker is closer to the device than the target user In the left scenario, the attacker and target user are easier to be differentiated, be- cause they are closer to Mic1 and Mic2, respectively In the right scenario, the attacker and target user are difficult to be differentiated, because each of them have same distance to both microphones tally puts the device closer to the attacker|,Non-data,51
| The previous defenses against Type-I and Type-II attackers thus fail The fact that more and more COTS mobile devices have two or more microphones enables possible defenses against Type-III attackers For example, Fig 6 shows dual micro- phones on one smartphone, where Mic2 at the bottom is mainly used for voice recording, and Mic1 at the top is de- signed for noise cancellation|,Non-data,51
| Such dual-microphone config- urations are very typical on current smartphones The left sub-figure in Fig 6 depicts a scenario where the user and attacker are closer to Mic2 and Mic1, respectively In this s- cenario, the user’s significant departure from the device can still be identified based on the distance measurements at the two microphones, in which case the device can be im- mediately locked|,Non-data,51
| In contrast, the right sub-figure in Fig 6 corresponds to a scenario in which the attacker and target user have similar distance to both microphones The system will also lock the device immediately to ensure strong data security when there is an ambiguity in the right scenario Relying on dual microphones, our solution applies to Type- III attackers with arbitrary locations with regard to the mi- crophones and the user|,Non-data,51
| We additionally assume that the relative orientation changes between the device and user be- fore user movements can be automatically estimated with high precision through existing techniques For example, the ◦ latest result we are aware of [30] can reach a precision of 5 based on IMU sensors Since the initial relative orientation when the user is using the device is known (ie|,Non-data,51
|, either land- scape or portrait mode), we can calculate the final relative orientation when the user stop using the device As a result, we just need to compare the orientation of candidate leaving user measured by two microphones with the orientation of target user calculated by IMU sensors We also notice that the relative user-device orientation is approximately fixed, as a normal user typically walks along a straight line with a short distance from the device instead of in a zigzag fashion Our solution uses the distance measurements at Mic1 and Mic2 in a cohesive way|,Non-data,51
| Specifically, every moving phys- ical object near the device can lead to a speaker-object- microphone distance measurement at both Mic1 and Mic2 according to the FMCW technique Let d1(t) andd 2(t) de- note the distance measurements of Mic1 and Mic2 at time t, respectively Note that COTS devices allow these two (cid:19)(cid:124)(cid:3) (cid:22)(cid:20)(cid:24)(cid:124)(cid:3) (cid:48)(cid:76)(cid:70)(cid:20) (cid:48)(cid:76)(cid:70)(cid:21) (cid:21)(cid:26)(cid:19)(cid:124)(cid:3) (cid:23)(cid:24)(cid:124)(cid:3) (cid:28)(cid:19)(cid:124)(cid:3) (cid:20)(cid:22)(cid:24)(cid:124)(cid:3) (cid:21)(cid:21)(cid:24)(cid:124)(cid:3) (cid:20)(cid:27)(cid:19)(cid:124)(cid:3) (cid:56)(cid:86)(cid:72)(cid:85)(cid:3)(cid:79)(cid:72)(cid:68)(cid:89)(cid:76)(cid:81)(cid:74) Figure 7: Mic1 is at the top of the phone, and Mic2 is at the bottom The red center of the circle corresponds to the center of the phone|,Non-data,51
| The phone is rotated around the center counterclockwise We assume the with an interval of 45 user’s leaving direction is fixed ◦ measurements to be perfectly aligned in time, ie|,Non-data,51
|, with the same sampling clock Consecutive distance measurements of the same object at the same microphone lead to a move- ment trace, either staying or leaving Since Mic1 and Mic2 are very close to each other on the device in contrast to the user-device distance, they produce highly correlated move- ment traces for the same object Assume that iLock finds two such correlated traces, so the next step is to determine whether these leaving traces should be associated with the user and triggers device lock if so|,Non-data,51
| However, the distance measurement isn’t accurate and stable enough to discover the orientation of candidate leaving trace, so we introduce a new metric as follows, ⎧⎨ ⎩ η(t) = −1 if d1(t) − d2(t) > δdual, 0 if ||d1(t) − d2(t)|| ≤ δdual, 1 if d2(t) − d1(t) > δdual, (cid:5)N where δdual is a system threshold and set to the theoret- ical distance resolution of 425 cm We proceed to com- pute ˆη = 1 t=1 η(t), where N denotes the number of dis- tance measurements Obviously, ˆη always belongs to [−1, 1]|,Non-data,51
| N When ˆη is closer to 1 (-1), the object is closer to Mic1 (Mic2) If ˆη is closer to 0, the object is about the same distance from Mic1 and Mic2 We conjecture that ˆη is closely tied to the device-object orientation and confirm it by experiments on a Samsung Galaxy S5 As shown in Fig|,Non-data,51
|7, we fix the user’s moving ◦ direction and evaluate ˆη in eight different orientations (45 separation) by rotating the phone around its fixed center 20 experiments are done for each orientation, and the distri- bution of ˆη is shown in Fig 8 We can observe that the data for symmetric orientations with regard to the vertical axis ◦ ) overlap|,Non-data,51
| So do the data for adjacent (eg, 225 ◦ ) This observation is antici- orientations (e|,Non-data,51
|g, 45 pated due to distance measurement errors and also because ˆη relates to only relative distance measurements But there is a clear distinction between the data for orientations far apart (eg|,Non-data,51
|, 0 vs 135 vs 180 vs 90 and 45 vs|,Non-data,51
| 225 ) ◦ ◦ ◦ ◦ ◦ ◦ The above observation can be explored as follows First, we obtain a more fine-grained ˆη-orientation distribution than that in Fig 8, which can be device-specific|,Non-data,51
| The obtainment of this distribution is a one-time process and can be done when the user installs and enrolls into iLock Once two correlated leaving traces are detected, iLock computes ˆη as 9381 05 (cid:1)(cid:1) 0 -05 -1 0 45 90 135 180 225 270 315 Orientation (Degree) Figure 8: We calculate ˆη in eight different orientations as illustrated in Fig|,Non-data,51
| 7 The red line is the median, and the bottom and top edges of the box indicate the 25 and 75 percentiles, respectively The whiskers extend to the most extreme data points not considered as outliers, and the out- liers are plotted individually using the ’+’ symbol above, based on which to find the most probable orientation ˆη corresponds to|,Non-data,51
| If the likelihoods for multiple orientations are sufficiently close, all of them are candidate orientations Recall that the initial user-device orientation can be pre- cisely obtained beforehand, and the user normally works in the same orientation within a short distance where iLock targets If any candidate orientation is within a predefined threshold from the initial user-device orientation, the leaving traces are determined to be associated with the legitimate user, so iLock immediately locks the device δ2 = 1 m beyond which a typical user does not put the de- vice|,Non-data,51
| In our experiments, a male user uses the phone for a while and then leaves it unlocked on the table, in which case iLock is automatically activated Note that the triggering events for iLock can be automatically detected by many ex- isting methods, eg, through detecting when the user stops touching/holding the unlocked phone via inertial gyroscope and accelerometer sensors|,Non-data,51
| False Negatives We first evaluate the false-negative rate of iLock through 400 experiments In each experiment, the user puts his phone in a random position and an arbitrary orientation within δ1 The user leaves the device in his usual way|,Non-data,51
| As soon as the user-phone distance exceeds 1 m (ie, δ2), iLock theoretically should lock the phone The results are quite encouraging|,Non-data,51
| Specifically, the phone is successfully locked 395 times, which lead to a locking rate (true-positive rate) of 9875% or a false-negative rate of 125% False Positives|,Non-data,51
| We then evaluate the false-positive rate of iLock In this experiment, we put the unlocked phone ran- domly on the desk just besides the user (within δ1) Instead of leaving the desk and phone, the user performs regular mi- nor movements such as typing, writing, drinking, rotating his head/shoulder, and swinging back-and-forth Zero false device locking occurs in the entire 15 minutes, indicating an extremely low false-positive rate in practice|,Non-data,51
 Impact of Phone Orientations The next experiment is to investigate the effect of phone orientations We change the phone’s relative orientation to the user by rotating it according to Fig 7,Non-data,51
| For each orientation, the user moves away from the phone 50 times in his own way, for which each movement starts from a random position within δ1 and goes beyond δ2 from the phone 4 IMPLEMENTATION AND EVALUATION We implement iLock and obtain similar evaluation results in several COTS Android devices such as Samsung Galaxy S5 and Xiaomi Redmi 2 For lack of space, only the ex- perimental data on Samsung Galaxy S5 are reported in this paper|,Non-data,51
| The Samsung Galaxy S5 phone has a Quad-core 25 GHz Krait 400 CPU, 2 GB RAM, and a 51-inch display There are also two microphones, Mic1 at the top and Mic2 at the bottom|,Non-data,51
| The speaker-Mic1, speaker-Mic2, and Mic1- Mic2 distances are 45 cm, 123 cm, and 14 cm, respectively By default, the FMCW frequencies range from f0 = 18 kHz to f1 = 22 kHz; the sweep duration is Tsweep = 20 ms; and the speaker volume is 71%|,Non-data,51
| One experiment is done in the university library, and all the others are done in a typical research office with desks, cabinets, computers, and 12 six students Unless specifically noticed, our experiment be- low is done on a table of 72cm height in our office with ; and the user stands up, turns around, the orientation 0 and walks away with normal speed about 151 steps/second Below we report the performance of iLock against Type-I, Type-II, and Type-III attackers, respectively|,Non-data,51
 41 Evaluation with Type-I Attackers (cid:5)×24 ◦ (cid:5) Recall that Type-I attackers are far away from the device when the user moves away iLock in this scenario just needs to recognize the movement trace of the user alone and then locks the device if the trace starts below the near-distance threshold δ1 and exceeds the far-distance threshold δ2 The office with six PhD experiments are conducted in a 12 students,Non-data,51
| We set δ1 = 06 m (a typical arm’s reach) and (cid:5) × 24 (cid:5) ◦ ◦ (180 Fig 9 illustrates the maximum detection ranges of Mic1 and Mic2 for different phone orientations When the phone ), Mic2 (Mic1) yields a larger orientation is around 0 maximum detection range due to the closer distance between the user and Mic2 (Mic1)|,Non-data,51
| On the Samsung Galaxy S5, Mic2 is the master microphone, and Mic1 is designed for noise cancellation So we can see that the average maximum detection range of Mic2 is larger than that of Mic1 Finally, combing the distance measurements from Mic1 and Mic2, iLock can always detect the user movement up to 14 m for any orientation|,Non-data,51
| ◦ and 0 Fig 10 plots the true-positive rates for each orientation based on Mic1, Mic2, and their combination Mic1+Mic2 As expected, the peak performance for using Mic1 alone and ◦ orientations, respec- Mic2 alone occur around 180 tively In addition, Mic2 shows better performance overall due to its higher capability as the master microphone|,Non-data,51
| Fi- nally, if we lock the phone as long as either one microphone detects a leaving trace, the true-positive rate is always above 90% regardless of initial phone orientations Impact of Initial Phone Positions We also evaluate the impact of initial phone positions In this experiment, the initial phone-user distance changes from 10 cm to 20 cm, 30 cm, 40 cm, and 50 cm, and the phone orientation is |,Non-data,51
| Fig 11 and Fig 12 show the maximum detection fixed to 0 ranges and true-positive rates, respectively We can see that the true-positive rate with Mic2 alone or Mic2 and Mic1 together can yield very high true-positive rates up to 100% for all distance settings|,Non-data,51
 So initial phone positions have very little impact on iLock Impact of Departing Gestures The user may leave the ◦ 939) m ( (cid:3) 15 e g n a R n o    t i t c e e D m u m x a M i 1 0,Non-data,51
5 0 Mic1 Mic2 0 45 90 135 180 225 270 315 Phone Orientation(cid:3)(degree) Figure 9: Maximum detection range vs orientations   e t a R e v i t i s o P e u r T   1 09 0,Non-data,51
8 07 06 05 0,Non-data,51
4 0 45 Mic1 Mic2 Mic1+Mic2 90 135 180 225 270 315 Phone Orientation (degree) 15 ) m ( (cid:3) e g n a R  n o i t c e t e D m u m x a M   i 1 05 0 0 0(cid:20) Mic1 Mic2 0,Non-data,51
(cid:24) 0(cid:22) 04 02 Distance(cid:3)(m) Figure 11: Maximum detection range vs,Non-data,51
 phone-user dis- tance 1 08 e t   a R e v i t i s o P e u r T   06 0,Non-data,51
4 02 0 01 Mic1(cid:3) Mic2(cid:3) Mic1+Mic(cid:21) 02 0,Non-data,51
3(cid:3) Distance(cid:3)(m) 04 05 Figure 10: True-positive rates vs orientations,Non-data,51
| Figure 12: True-positive rate vs phone-user distance device with different gestures Intuitively speaking, the de- parting gesture should not affect the detection performance, as iLock only measures the user-device distance|,Non-data,51
| We confirm this intuition by experimenting three common gestures In the first gesture which is the default in our experiments, the user stands up, turns around, and walks away In the second gesture, the user initially stands facing the phone and then steps back to leave In the final gesture, the user rotates the chair, stands up, and then moves away|,Non-data,51
| Each gesture is performed 20 times, and the average maximum detection ranges and true-positive rates are shown in Fig 13 We can see that Mic2 and Mic1+Mic2 produce very high and stable true-positive rates for all three gestures Impact of Departing Speeds|,Non-data,51
| To evaluate the impact of moving speeds, we let the user perform the second gesture above with slow, normal, and fast speeds, corresponding to about 115, 151, and 20 steps/second, respectively|,Non-data,51
| In this experiment, the user leaves 20 times for each speed setting, relative while the phone is initially 20 cm away at the 0 orientation As we can see from Fig 14, the performance of iLock becomes non-satisfactory when the user steps back at 20 steps/second|,Non-data,51
| The main reason is that the fast speed reduces the time span for the same distance range, which in turn reduces the number of distance measurements given that the microphones have the constant sampling frequency Fortunately, a normal user does not step back as fast as 20 steps/second So the true performance of iLock is more reflected under the relatively slow and normal speeds|,Non-data,51
| Impact of Vertical Positions The phone’s vertical posi- ◦ tion may be different in various scenarios For example, we tend to leave the phone on the desk around 70 cm high while in an office, on a chair about 40 cm high while on a subway, and the bar table about 100 cm high while in a bar Fig|,Non-data,51
| 15 shows the performance of iLock under different heights: 36 cm, 72 cm, 92 cm For each height, the user moves away with the second gesture above for 20 times We can see that different heights have very little impact on the true-positive rates of iLock Impact of Speaker Volumes|,Non-data,51
| iLock detects the leaving movement by signal reflections, so the signal strength can potentially affect its performance We conduct the experi- ment under three volume levels corresponding to three sig- nal strengths: low (26%), medium (52%), and large (71%) From Fig 16, it is of no surprise to see that the performance via Mic2 alone or Mic1+Mic2 are quite high for medium and high volume settings|,Non-data,51
 Impact of Different Users We also ask six PhD students to use iLock Each student leaves in his own way for 20 times with the gesture and speed he likes As shown in Fig,Non-data,51
| 17, iLock achieves a true-positive rate of 85% for student 2, 95% for student 5, and 100% for the rest It is worth noting that student 2 walks much faster than others in the experiments, leading to the similar observation as in Fig 14 Impact of Experimental Environments We finally evaluate iLock in the lobby of the university library|,Non-data,51
| The lobby is about 32,000 square feet and contains many tables, sofas and public desktop computers During our experiment, there is a lot of noise from the vending machines, public 940e t a R  e v i t i s o P  e u r T 1 08 06 0|,Non-data,51
4 02 0 ) m ( (cid:3) 15 e g n a R n o    i t c e t e D m u m x a M i Mic1 Mic2 Mic1+Mic2 1 2 Gesture # 3 (a) True-positive rate Mic1 Mic2 1 05 0 1 2 Gesture # 3 (b) Maximum-detection range t   e a R e v i t i s o P e u r T   1 0,Non-data,51
8 06 04 02 0 Mic1 Mic2 Mic1+Mic2 Slow Normal Speed Fast Figure 14: True-positive rate vs,Non-data,51
 leaving speeds e t a R  e v i t i s o P e u r T   1 08 06 0,Non-data,51
4 02 0 Mic1 Mic2 Mic1+Mic2 36 72(cid:3) Height(cid:3)(cm) 92 Figure 13: Performance of three leaving gestures Figure 15: True-positive rates vs phone heights,Non-data,51
| computers, and student talks In addition, the students walk around without our control, but we make sure that they are at least 1 m from the phone The user puts the phone randomly on a table and leaves it 20 times with a normal speed under gesture 2 We obtain a true-positive rate of almost 100% by using Mic2 alone or Mic1+Mic2|,Non-data,51
| So iLock can work very well in noisy and uncontrolled environments 42 Evaluation with Type-II Attackers We also evaluate iLock against Type-II attackers who get closer to but are still farther away from the device than the legitimate user With the presence of Type-II attack- ers, iLock can detect multiple movement traces and needs to decide which trace is associated with the user|,Non-data,51
| For this experiment, we use the Precision and Recall metrics defined as follows, Precision = #TP #TP + #FP and Recall = #TP #TP + #FN , (1) where #TP is the number of user departures correctly as- sociated with the user, #FP is the number of other users’ departures incorrectly associated with the user, and #FN refers to the number of user departures not associated with the user by mistake The experiment involves the user and one attacker, and their distance difference to the device varies from 20 cm to 30 cm, 40 cm, 50 cm, and 60 cm For each distance differ- ence, the user leaves 20 times while the attacker stays, and then the attacker leaves 20 times while the user stays The Precision and Recall results based on Mic1+Mic2 are shown in Fig|,Non-data,51
| 18 We can see that precision is always above 95%, corresponding to very low false-alarm rates In contrast, the recall increases from 80% to 95% when the distance differ- ence becomes larger, as larger distance difference makes it easier to distinguish the user’s trace from the attacker’s 4|,Non-data,51
|3 Evaluation with Type-III Attackers Now we report the performance of iLock against Type-III attackers This experiment involves the user and one attack- er who is always closer to the phone than the user As shown in Fig 20, we use five representative scenarios in which the user and attacker are in different positions and orientation- s relative to the phone|,Non-data,51
| In each scenario, the user leaves the device 20 times while the attacker stays, and then the attacker leaves 20 times while the user stays In addition, the initial orientation of the device relative to the user can be accurately estimated with existing techniques [30] Once two highly correlated leaving traces are detected, the metric ˆη is computed according to the description in Section 34|,Non-data,51
| Then we find the most probable orientation for ˆη based on a fine-grained ˆη-orientation distribution, which we obtain be- forehand for the Samsung Galaxy S5 Next, we compare the discovered orientation with the device’s initial orienta- tion relative to the user Note that, in Fig 8, ˆη distributions of adjacent orientations overlap with each other, so we as- sociate the traces discovered in nearby orientations to the target user to improve true positive rate|,Non-data,51
| For example, if ◦ , the device’s initial orientation relative to the user is 180 ] will be as- the leaving traces discovered between [135 sociated to the target user and the system locks the device , 225 ◦ ◦ 941t   e a R e v i t i s o P e u r T   1 08 06 04 0|,Non-data,51
2 0 Mic1 Mic2 Mic1+Mic2 (cid:21)(cid:25)(cid:8) (cid:24)(cid:21)(cid:8)(cid:3) Volume (cid:26)(cid:20)(cid:8) l l / a c e R n o s c e r P i i 1 08 06 04 0,Non-data,51
2 0 Precision Recall 06 Distance Difference to the Phone(cid:3)(m) 02 03 0,Non-data,51
4 05 Figure 16: True-positive rates vs different volumes Figure 18: Precision and Recall with a Type-II attacker,Non-data,51
 t   e a R e v i t i s o P e u r T   1 08 06 04 0,Non-data,51
2 0 1 2 3 5 6 4 User # (cid:48)(cid:76)(cid:70)(cid:20) (cid:48)(cid:76)(cid:70)(cid:21) (cid:56)(cid:86)(cid:72)(cid:85) (cid:36)(cid:87)(cid:87)(cid:68)(cid:70)(cid:78)(cid:72)(cid:85) (cid:20)(cid:27)(cid:19)(cid:124)(cid:3) (cid:20)(cid:22)(cid:24)(cid:124)(cid:3) (cid:28)(cid:19)(cid:124)(cid:3) (cid:21)(cid:21)(cid:24)(cid:124)(cid:3) (cid:21)(cid:26)(cid:19)(cid:124)(cid:3) (cid:19)(cid:124)(cid:16)(cid:20)(cid:27)(cid:19)(cid:124) (cid:19)(cid:124)(cid:16)(cid:20)(cid:22)(cid:24)(cid:124) (cid:23)(cid:24)(cid:124)(cid:3) (cid:22)(cid:20)(cid:24)(cid:124)(cid:3) (cid:19)(cid:124)(cid:3) Figure 17: True-positive rates vs different users immediately to ensure data security Users can devise their own mechanism to balance Precision and Recall,Non-data,51
| As we can see in Fig 20, the Precision and Recall results are overall quite acceptable for all five scenarios The worst performance is observed when there is a small orientation d- ifference between the user and attacker relative to the phone ◦ ) This result is expected, as the (i|,Non-data,51
|e, 0 smaller orientation difference makes it harder to distinguish the user’s movement from the attacker’s and 180 -270 -270 ◦ ◦ ◦ 5 DISCUSSION 5|,Non-data,51
|1 Energy Consumption iLock incurs additional energy consumption on a mobile device in two main aspects First, iLock needs to transmit high-frequency modulated acoustic signals and also record the signals reflected by physical objects It is shown [28] that such acoustic transmitting and recording on Samsung Galaxy S5 may incur an energy consumption of about 800mW with Monsoon Power Monitor Secondly, iLock consumes energy in data processing such as filtering, FFT, and mix- ing|,Non-data,51
| In practice, iLock does not need to be activated all the time In particular, iLock can only be activated when the device enters a vulnerable context One such context is when the user stops using the device while the screen is still unlocked, and it is can be easily detected by exploring iner- tial sensors such as touchscreen, gyroscope, and accelerom- eter Also note that many users spend most of the time in a (cid:19)(cid:124)(cid:16)(cid:21)(cid:26)(cid:19)(cid:124) (cid:23)(cid:24)(cid:124)(cid:16)(cid:20)(cid:27)(cid:19)(cid:124) (cid:20)(cid:27)(cid:19)(cid:124)(cid:16)(cid:21)(cid:26)(cid:19)(cid:124) Figure 19: Representative scenarios with Type-III attack- ers, where x-y corresponds to the user’s orientation x and attacker’s orientation y in the shown orientation graph|,Non-data,51
 safe zone such as home and office Sophisticated localization techniques allow the device to accurately determine whether it is in a predefined safe zone iLock is only activated when the device is out of the safe zone So the energy consump- tion of iLock is quite amenable in contrast to its potentially huge benefits,Non-data,51
| 52 Other Potential Solutions We also investigate and experiment other potential so- lutions The most intuitive alternative is to directly ana- lyze the received signals which can be perturbed by leaving movements In the experiment, we indeed find some poten- tial signal patterns for specific leaving gestures|,Non-data,51
| So one may think about training a classifier to detect a user’s leaving gesture However, different users have different gestures, so every user who wants to use the system has to train a clas- sifier, a time-consuming and clumsy process In addition, even the same user may leave the device in a different way in different scenarios As a result, it is almost impossible to train a classifier that can differentiate all possible gestures of the same user|,Non-data,51
| So we give up this method Another candidate approach is to rely on the Doppler ef- fect caused by user movements In particular, the speaker 942l l / a c e R n o s c e r P i i 1 08 0|,Non-data,51
|6 04 02 0 Precision Recall 0-180(cid:3) 0-135(cid:3) 0-270(cid:3)45-180180-270(cid:3) Relative Position to the Phone(cid:3)(degree) Figure 20: Precision and Recall with a Type-III attacker It follows that fr = c−vr c−vs transmits acoustic signals with a fixed high frequency f0, and the microphone records the reflected signals with fre- f0, where vs is the quency fr|,Non-data,51
| speed of the reflection object (user), and c is the speed of sound Since the receiver is stationary, vr = 0 Then we can do an integration over vs to get the distance the user moves The Doppler shift, however, is very sensitive and can be induced by any body movement|,Non-data,51
| Also, the frequency shifts by different body movements at different distances to the device are mixed together As a result, we can hardly extract the user’s movement pattern based on the Doppler effect and give up this idea as well Finally, one may think about implementing iLock based on WiFi or Bluetooth signals rather than acoustic signals There are two primary reasons for not doing so|,Non-data,51
| First, WiFi and Bluetooth interfaces are often very busy and occupied for data communications, while the speaker and microphone have much more idle time Second, WiFi and Bluetooth sig- nals propagate in the speed of light and have much higher re- quirement for time/frequency measurement accuracy, which is not attainable on COTS mobile devices This is also the reason why existing FMCW implementations on WiFi sig- nals use complicated and customized hardware not available on COTS mobile devices 6|,Non-data,51
 RELATED WORK There are three ways to prevent the attackers’ illegal ac- cess to mobile devices and the sensitive data therein The first one is one-time authentication that authenticates users when they try to unlock and use the device The second one is to authenticate users continuously when they are using the device The third one is to lock the device immediately once the current user has left,Non-data,51
| We will analyze advantages and disadvantages of each method in what follows There are significant research and practice related to one- time authentication Typically, one-time authentication schemes can be classified into three categories: Something-You-Know, Someone-You-Are, and Something-You-Have In the Something- You-Know paradigm, users are asked to input a simple PIN, an alphanumeric password, or a gesture/graphical password|,Non-data,51
 This method is vulnerable to shoulder-surfing attacks The Something-You-Have paradigm requires auxiliary hardware (eg Signet Ring [29]) which is possessed only by the le- gitimate user,Non-data,51
| We note that the non-COTS hardware is a potential obstacle for the wide adoption of this paradigm A growing body of work follows the Someone-You-Are paradig- m [3, 7, 27] This approach relies on physiological or behav- ioral biometrics which are unique to each person Com- mon physical features consist of fingerprints, facial features, retina patterns, etc|,Non-data,51
| Physiological authentication methods may be vulnerable to spoofing attacks [3] Behavioral bio- metrics may include keystroke patterns [17, 19], touching gestures [24, 25], gaits [10, 13], etc As said, a significant number of mobile users do not password-protect their de- vices, not to mentioning adopting more advanced one-time authentication techniques In addition, the time window for a password-protected device going from the unlocked mode to the locked mode may be long enough for a capable attack- er to access all the sensitive information on the lost/stolen device|,Non-data,51
| If an unlocked device is missing or stolen, the user’s sensitive information is completely exposed Continuous authentication can complement one-time au- thentication by continuously authenticating the current us- er In this way, after the attacker uses the device for a while, the device can detect the unauthorized user and log out In [18], the user needs to wear a bracket with a built-in accelerometer, a gyroscope, and a radio|,Non-data,51
| When using a desk- top computer(typing the keyboard and using the mouse), the bracket records and sends the movement data to the computer The computer checks whether the input to the computer matches the data from the bracket A recent pa- per [11] points out attacks on the technique in [18] The technique in [9] continuously authenticates users based on behavioral biometrics with 30 features|,Non-data,51
