 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| Moreover, since CSI is very sensitive to location es- pecially in indoor environment, the authentication distance for all existing proximity-based methods (eg, Amigo [24], ProxiMate [15]) should be less than 01λ (1|,Non-data,53
|25cm@24GHz) using CSI, which is not practical for WiFi devices To over- come these limitations, our solution uses substitution-based key delivery instead of quantization-based key extraction, which is highly robust for secret bit agreement We name this method as The Dancing Signals (TDS)|,Non-data,53
|1 Besides fast key generation, another unique feature of TD- S is that the secret key can be an arbitrary bit string spec- ified by one of the devices, while in existing methods the agreed key completely depends on common wireless chan- nel information This feature brings three important advan- tages: i) TDS can always build a key with strong randomness and avoid keys with low entropy [8] ii) TDS can built a key among more than two devices In previous pairing methods, it is hard for more than two devices to simultaneously gen- erate a same key, since mismatched bits between every pair of keys lead an unaffordable agreement overhead and signif- icant risk of key leakage|,Non-data,53
| TDS allows a key to be directly delivered from one device to others, saving huge amount of overhead from interactive agreement iii) TDS is very ro- 1The name was inspired by the story “The Adventure of the Dancing Men” written by Arthur Conan Doyle In the story Sherlock Holmes receives a paper with a sequence of dancing men figures from a client He later realizes each dancing man is a substitution of an English letter and cracks the code|,Non-data,53
| bust to the predictable channel attack [8] In such an attack, an adversary uses planned movements to cause desired and predictable changes in the channel between the two devices and further predict the key generated from the channel We summarize the advantages of TDS as follows: • TDS achieves both device authentication and key a- greement Compared with prior methods that only focus on one of them such as [1] [23] [28], TDS is more robust to various attacks|,Non-data,53
| • The secret bit generation rate of TDS is faster than existing solutions [24] [15] by over an order of mag- nitude Our implementation on COTS devices show generation rates of hundreds bits/sec • Previous device pairing protocols can only support two • TDS can be used to transmit any confidential bit se- quence specified by the sender, including self-generated session keys, which avoids keys with low entropy • TDS can effectively defend against predictable channel devices|,Non-data,53
 TDS works well for more devices attacks The rest of this paper is organized as follows Section 2 presents the system model and observations from our exper- iments,Non-data,53
 Section 3 details the protocol design of TDS We provide the analysis for the security and efficiency of TDS in Section 4 Section 5 shows the evaluation results based on the implementation of TDS on off-the-shelf mobile devices We present the related work in Section 6 and conclude our work in Section 7,Non-data,53
| 2 SYSTEM MODEL AND OBSERVATION In this section, we first define the system and security model of TDS We then use analysis and experiments to demonstrate the feasibility and challenges of using CSI mea- surement to make key agreement among multiple devices 2|,Non-data,53
|1 System and security model We assume that multiple legitimate wireless devices, Al- ice, Bob, and Calvin, are interested in securely exchanging their private information They are able to communicate via the standard IEEE 80211 protocols with OFDM, such as WiFi They have no prior shared secret|,Non-data,53
| When per- forming key agreement, the devices need to be placed by their users in a physical proximity such that the distance from any device to Alice is less than a authentication dis- tance (04λ ≈ 5cm@24GHz where λ is the wavelength) A malicious device Eve is located beyond a safe distance (λ ≈ 12|,Non-data,53
|5cm for WiFi) to Alice If Eve moves into the safe distance, it will be easily seen by the users of Alice and Bob Eve can sense the wireless environment, inject new traffic, and replay packets Alice, Bob, Calvin and Eve can hear a public wireless source Peter|,Non-data,53
| Eve can perform var- ious attacks including spoofing, eavesdropping, and man- in-the-middle In the most extreme case, Eve may control Peter that Alice, Bob and Calvin are using for key agreemen- t Then Eve can turn the signal strength into any pattern she desires Eve has complete knowledge of the proposed method and algorithms|,Non-data,53
| The goal of this system is to instantly make Alice, Bob, and Calvin agree on a strong symmetric key without letting 6171 08 06 04 0|,Non-data,53
2 Indoor Outdoor i n e c i f f e o c  n o i t a e r r o C l 0 −02  0 (cid:16)(cid:14)(cid:21)(cid:76) (cid:76) (cid:17)(cid:14)(cid:21)(cid:76) (cid:18)(cid:76) (cid:18)(cid:14)(cid:21)(cid:76) 0 0 Distance 0 1 e t a r  h c t a m s M i 0 0,Non-data,53
 0 08 06 0,Non-data,53
4 e t a r   G H G U D F V ' L MismatchUDWH 'LVFDUGHG UDWH 02  $EDQGRQHG=RQH 2(cid:1) 3 0 4 i s e m 7  k c e h C  f o   # 250 200 150 100 50 0 RISDVVHV 5 RISDVVHV  RISDVVHV  0 5 10 15 20 25 30 35 40 # of Error %its e t a R  l l a c e R 1 08 06 0,Non-data,53
4 02 0 5 times 6 times 7 times 0 5 10 15 20 25 30 35 40 # of Error Bits Figure 1: Pearson corre- lation coefficient decreas- es with growing distance Figure 2: Dilemma of mis- match rate and discarded rate Figure 3: Mismatched bits cause high cost in er- ror correction Information Figure 4: reconciliation fails more seriously with increasing error bits Eve know about the key We have the following security requirements • Authenticity,Non-data,53
 A device needs to ensure that it is mak- ing key agreement with other legitimate devices Any spoofer will be detected • Confidentiality Any information of the key should not be exposed to Eve,Non-data,53
| • Integrity The key should be consistent at all legiti- mate devices We do not consider availability in this work If Eve block all WiFi signals, devices may not agree on any key|,Non-data,53
| 22 Feasibility of CSI-based key generation In this paper, we use CSI as the proof of authenticity and source of common secret information The intuition of us- ing CSI is that it is a unique and correlated measurement for devices around a particular physical location CSI mea- surements at different devices are rapidly de-correlated with distance between them|,Non-data,53
| In addition, CSI is unpredictable due to its random property caused by the multipath effect of signal propagation CSI is a much richer source of secret information than the one of RSS, because it contains the information of 56 subcarriers in each measurement sample We demonstrate the properties using experimental vali- dation We use two laptop computers Alice and Bob, each equipped with COTS wireless NIC model Intel 5300 oper- ating in the 802|,Non-data,53
11n 24GHz channel2 They then collect measurement results of the CSI amplitude values indepen- dently from a public WiFi while varying their distance from 01λ to 2,Non-data,53
|5λ, where the wavelength λ = 125cm for 24GHz Figure 1 shows the Pearson product-moment correlation co- efficient of the CSI samples from the two devices|,Non-data,53
| We found that when the distance is smaller than 05λ, the samples are highly correlated The correlation drops quickly with the distance growth When the distance > 2λ, the samples are uncorrelated|,Non-data,53
| The above properties of CSI are important for device au- thentication and key agreement Only if the samples from different devices nearby are similar, CSI can be a proof of 2We use laptops for the ease of programming The method can be applied to any devices with 80211 NICs|,Non-data,53
| physical proximity Only if the samples are rapidly de- correlated with distance between the devices, CSI can be a common secure information 23 Challenges of CSI-based key generation Suppose two devices, Alice and Bob both listen to a public WiFi source|,Non-data,53
| For each of them, the CSI amplitude value h(t) at time t can be directly obtained from an existing API of the Intel 5300 network card To extract secret information from two similar measurements of CSI amplitude values, a simple approach is to determine a cut-off amplitude level h and use 0 to represent samples smaller than h and 1 to represent samples larger than h For example, h can be 05 for CSI amplitude varying in [0, 1]|,Non-data,53
| This method is called reciprocal quantization Reciprocal quantization may cause mismatched bits at t- wo devices For example, if Alice gets a CSI value 053 for a particular bit, Bob gets 0|,Non-data,53
|48, and the cut-off is 05, then they will have a different bit To reduce these mismatched bits, existing quantization methods often use an abandoned zone For example, if the abandoned zone is [0|,Non-data,53
|4, 06], then only if a CSI value is less than 04 (or larger than 06), it can be converted to a 0-bit (or 1-bit)|,Non-data,53
| Selecting the size of the abandoned zone is a dilemma: if the zone is small, mismatched bits still occur; if the zone is large, too many CSI samples will be discarded, slowing secret bit generation Figure 2 shows the bit mismatch rate versus the discarded bit rate by varying the abandoned zone from 0 to 4σ, where σ is the standard deviation of the Gaus- sian noise We find that when the abandoned zone is smaller than σ, the discarded rate is low but it causes more than 10% mismatched bits When the zone is large, e|,Non-data,53
|g, 3σ, the mis- match rate is negligible but more than 80% samples will be discarded To further demonstrate the harm of mismatched bits, we use an existing method, information reconciliation [3] [8], to fix mismatched bits by iterative parity checks Figure 3 shows that the rounds of parity checks increase sig- nificantly with growing mismatched bits, for generation of a 256-bit key|,Non-data,53
| For 20 mismatched bits, it requires more than 70-150 parity check bits to correct them Besides tremen- dous communication and time cost, the number of secret bits is also reduced from 256 to < 150 due to privacy am- plification [17] Additionally, information reconciliation is a 618                                        " # #	!#             (cid:37)(cid:82)(cid:69)(cid:3)(cid:54)(cid:16)(cid:69)(cid:82)(cid:91)       (cid:36)(cid:79)(cid:76)(cid:70)(cid:72)(cid:3)(cid:54)(cid:16)(cid:69)(cid:82)(cid:91)       (cid:40)(cid:89)(cid:72)(cid:3)(cid:54)(cid:16)(cid:69)(cid:82)(cid:91) (cid:37)(cid:82)(cid:69)(cid:3) 	 "  !"                 (cid:37)(cid:82)(cid:69)(cid:3)(cid:85)(cid:72)(cid:70)(cid:82)(cid:89)(cid:72)(cid:85)(cid:86)(cid:3) (cid:87)(cid:75)(cid:72)(cid:3)(cid:78)(cid:72)(cid:92)(cid:29)(cid:3)(cid:19)(cid:3)(cid:20)(cid:3)(cid:20)(cid:3)(cid:19)(cid:3)(cid:17)(cid:17)(cid:17) (cid:15)(cid:15)(cid:15)  (cid:86) (cid:36)(cid:79)(cid:76)(cid:70)(cid:72)(cid:3)(cid:74)(cid:72)(cid:81)(cid:72)(cid:85)(cid:68)(cid:87)(cid:72)(cid:86)(cid:3) (cid:86)(cid:86)(cid:86)(cid:86) (cid:92)(cid:92) (cid:29)(cid:73)(cid:72)(cid:68)(cid:87)(cid:88)(cid:85)(cid:72) (cid:68)(cid:3)(cid:85)(cid:68)(cid:81)(cid:71)(cid:82)(cid:80)(cid:3)(cid:78)(cid:72)(cid:92)(cid:3)(cid:29)(cid:3) (cid:92) (cid:29) (cid:3)(cid:3) (cid:19)(cid:3)(cid:20)(cid:3)(cid:20)(cid:3)(cid:19)(cid:3)(cid:17)(cid:17)(cid:17)(cid:3)                 (cid:41)(cid:72)(cid:68)(cid:87)(cid:88)(cid:85)(cid:72)(cid:86)(cid:3244)         (cid:40)(cid:89)(cid:72)(cid:3)(cid:74)(cid:82)(cid:87)(cid:3)(cid:81)(cid:82)(cid:87)(cid:75)(cid:76)(cid:81)(cid:74)(cid:4) (cid:15)(cid:15)(cid:15)  Figure 5: Main steps of TDS: channel sampling, S-box generation, key generation, key delivery The final step information reconciliation is not shown|,Non-data,53
| probabilistic technique, it fails occasionally Figure 4 shows that recall rate of information reconciliation reduces with growing mismatched bits, even a large number of passes is chosen Therefore 10% mismatched bits for a 256-bit key would cause huge time/communication cost and secret bit loss More importantly, in reciprocal quantization, the two de- vices have no ability to decide which bits to generate|,Non-data,53
| In some cases, the generated key may have low entropy [8] In addition, it has been observed that near-by subcarriers of OFDM may have correlated CSI measurements [28], which reduces the security level of the generated keys As a conclusion, directly converting CSI or RSS sample values to secret bits does not work It is the reason that some existing work, such as ProxiMate [15] has to use FM and TV signals which have very long wavelengths, rather than WiFi signals, to generate robust secret keys|,Non-data,53
| 3 PROTOCOL DESIGN We present the design of our protocol TDS in this section 31 Basic idea of TDS Instead of asking all devices to perform quantization sepa- rately, we allow one device, say Alice, to decide an arbitrary key and distribute it to other legitimate devices with con- fidentiality|,Non-data,53
| Since extracted key of Calvin are identical to Bob’s, we use Alice, Bob and Eve to sketch our idea shown in Figure 5, which includes the following steps: 1) Channel sampling The users first place Alice and Bob and the distance between their NIC cards is < 5cm A user then starts the TDS program on Alice and makes Alice an initiator Alice sends a message to other devices and ask them (including Alice) to start listening to a same public WiFi source|,Non-data,53
| Current WiFi standard uses orthogonal frequency-division multiplexing (OFDM) and there are 56 orthogonal subcarrier signals to carry data on parallel data streams Hence at a same time, the CSI measurement of a WiFi source includes up to 56 sample values from different sub-carriers Figure 5 shows samples of amplitude values from three sub-carriers of a same WiFi source Note that Alice and Bob have highly correlated sample values, but Eve’s measurement is very different to theirs|,Non-data,53
| 2) S-box Generation After obtaining enough number of samples, Alice will ask other devices to synchronize the sampled data Then each device will construct an S-box, which includes a number of blocks Each block contains a number of samples and represents a bit 0 or 1|,Non-data,53
| Note blocks are organized in pairs In Figure 5 we show the first four pairs of blocks of each S-box, representing four 0-bits and four 1-bits Later we will introduce the mechanism that guarantees every legitimate device will generate an S-box in which the samples in the blocks are consistent to Alice’s S-box 3) Key generation|,Non-data,53
| Alice may use any sophisticated key generation method to determine a strong secret key with high randomness and entropy In the Figure 5 example, she uses a key starting with 0110 4) Key delivery For every bit of the key, Alice select a block from every pair to represent whether this bit is 0 or 1|,Non-data,53
| For example, in Figure 5 the first four bits are 0110 Hence Alice selects the first 0-block, the second 1-block, the third 1-block and the fourth 0-block Then Alice broadcasts these blocks to other devices Since Bob’s measurement is similar to Alice’s, Bob can obtain a similar S-box|,Non-data,53
| When Bob re- ceives the blocks sent from Alice, it can easily recover these blocks to a bit stream Bob only needs to decide whether the ith block is more similar to his ith 0-block or his ith 1-block Eve, which is out of the safe distance from Alice, cannot obtain an S-box with any correlation to Alice’s Even if Eve can hear all blocks sent from Alice, she is not able to match any block to a 0-bit or 1-bit|,Non-data,53
| 5) Information reconciliation Finally, Alice and Bob need to ensure that they obtain a same key and correct the mismatch bits, which are very few in TDS TDS uses an in- formation reconciliation method, as presented in prior work [3, 28] Note that the protocol has a threshold T such only 619t i n e c i f f e o c  n o i t l a e r r o C 1 0|,Non-data,53
5 0 -05 -1 1 10 5 25 CSI subcarrier index 15 20 003 y t i l i b a b o r P 002 0,Non-data,53
|01 30 0 1 80 40 Singular value  120 %D %E %F    \ W L O L E D E R U 3 ΔσA ΔσA    7KHGLIIHUHQFHRIVLQJXODUYDOXH     150 180 210 90 120 60  40  20 240 300 270 30 0 330 Figure 6: CSI correlations Figure 7: Distributions of ˆσ2 Figure 8: Distributions of Δˆσ2 Figure 9: Feature distri- butions of two group sets a device with error bits fewer than T can start information reconciliation with Alice 32 Sampling and S-box generation All devices measure the CSI samples simultaneously using an existing synchronization protocol Note that complete synchronization is not necessary, as long as all three devices can have a large number of CSI samples in common|,Non-data,53
| For example, Alice can send a sequence of samples and ask all devices to construct their S-boxes after this sequence 321 Block and group allocation Block allocation divides all CSI measurement samples into blocks representing 0 and 1 bits|,Non-data,53
| Therefore if Alice wants to deliver a 256-bit key, she should construct at least 256 pairs of blocks first and then use a block from every pair to present the bit value The intuition to use a block of samples rather than a single one is to reduce the mismatch rate The block size n influences the performance of key delivery A small n leads to unstable blocks whose features are prone to the ambient noise, while a large n reduces the efficiency of key delivery|,Non-data,53
| Based on our empirical results, we select n = 6 in our implementation for WiFi For OFDM signals, each sample includes m subcarriers and each subcarrier has one CSI value Therefore, one block has m ∗ n CSI values, which are divided into two groups And then, the features of these two groups represent 0 and 1 respectively|,Non-data,53
| Group allocation is challenging due to the following two main requirements Reliability Requirement (R1): The features of two groups in a same block, representing 0 and 1 respectively, should be sufficiently distinct to each other, to avoid mis- matched bits Security Requirement (R2): The features from all 0- groups and 1-groups should be identically distributed across different groups Otherwise given a feature, an eavesdrop- ping could improve its guess on the bit by studying the dis- tributions of 0-groups and 1-groups|,Non-data,53
| We reuse each measurement sample in S-box generation to improve the utilization of measurement results and reduce channel measurement time Assuming there are N samples, we use the following construction method: 1 Every n successive samples are put into one block, for i ∈ {1 : (cid:5) N n (cid:6)} ^ƵďĐĂƌƌŝĞƌƐ 4 5 1 2 3 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 *D *0 *E *1 *F 2 — 1 4 — 2 6 — 3 3 — 2 6 —  9 — 6 Figure 10: Group allocation 20 — 10 30 — 20 2|,Non-data,53
| In addition, for j = 1 : (cid:5) N (cid:6), the jth, (n + j)th, ··· and (cid:6) −1)n + j)th samples are put into one block n (((cid:5) N n The number of blocks is about 2N/n Using Intel 5300 NIC, each sample includes 30 CSI amplitude values from 30 subcarriers3 Hence each block is a 30 × n matrix|,Non-data,53
| To represent 0 and 1, we divide a block into two groups In each block, we denote the measurements of the ith subcarri- er as Si, a vector including n values An intuitive solution is to let G0 = {S1, S3, S5, |,Non-data,53
|, S29} and G1 = {S2, S4, S6, , S30}, where G0 represents 0 and G1 represents 1 We find that this allocation does not satisfy the reliability requirement R1|,Non-data,53
| From our experiments, we find an important property of CSI samples from different subcarriers The adjacent sub- carriers have very strong CSI correlation, and the correlation oscillates with increasing the difference of two subcarriers’ indexes Figure 6 shows the correlation between two differ- ent subcarriers The yellow curve plots the CSI correlation between the 1st subcarrier and the xth subcarrier|,Non-data,53
| The 1st subcarrier has strongest correlation with 2nd subcarrier, and has little correlation with 11th subcarrier Red and green curves plot the correlation about 15th and 30th subcarriers to the xthh subcarrier respectively The difference between any pair of subcarriers that are with a fixed difference of in- dexes is very close For example, subcarrier pairs {2, 4} and {7, 9} will have a similar difference, i|,Non-data,53
|e, S2 − S4 ≈ S7 − S9 Given the above observations, the group allocation G0 = {S1, S3, S5, |,Non-data,53
|, S29} and G1 = {S2, S4, S6, , S30} will result in similar G0 and G1 It is because S1 and S2 are very 3Technically there are 56 subcarriers (52 data subcarriers and 4 pilots) for 802|,Non-data,53
|11n, but the current CSI tool can only provide 30 of them 620close, S3 and S4 are close, and so on As the consequence, the groups for 0-bit and 1-bit are not distinct Similar- ly, the group allocation G0 = {S1, S2, |,Non-data,53
|, S15} and G1 = {S16, S17, , S30} is also not acceptable, because S16 − S1 ≈ S17 − S2 ≈ |,Non-data,53
| ≈ S30 − S15 We then attempt to select subcarriers with varying in- tervals among them For every block, we construct three groups, Ga = {S1, S2, S3,··· , S10}, Gb = {S2, S4, ··· , S20}, and Gc = {S3, S6, S9,··· , S30}|,Non-data,53
| These three group- s show significant difference and then can be used to repre- sent different bit values 322 Feature extraction Each group Ga, Gb, or Gc is then an m × n matrix|,Non-data,53
| In our implementation m = 10, n = 6 To efficiently deliver the secret key to other devices, Alice will send a feature repre- senting the block of the bit rather than the entire matrix Due to the noise interference, CSI variations among Alice and other close devices always exist In TDS, we leverage the singular value decomposition (SVD) to solve this issue|,Non-data,53
| SVD provides a convenient way to characterize a matrix Each group G is expressed as Gm×n = Um×m ˆΣm×nV T n×n, where the diagonal matrix ˆΣ is uniquely determined byG  The diagonal elements of ˆΣ, ˆσ1, ˆσ2, |,Non-data,53
|, ˆσn (assuming n ≤ m), are called singular values In TDS, we extract the feature from ˆΣ to characterize each group It is well known that large singular values preserve the internal properties of a matrix in a low dimensional space [9]|,Non-data,53
| We propose to use the second and third largest singular values in each group, denoted as ˆσ2 and ˆσ3, as the feature of the group that will be broadcast by Alice instead of the whole matrix We do not use the largest singular values in each group because empir- ical results show that they are hard to differentiate After receiving ˆσ2 and ˆσ3 from Alice, Bob will compare them with the singular values of his G0 and G1 groups and determine whether this bit is 0 or 1 The small singular values is mainly due to noise in the data, which are discarded|,Non-data,53
| Unfortunately, the above features cannot satisfy the secu- rity requirement Figure 7 plots the distributions of singular value ˆσ2 of three types of blocks Ga, Gb, and Gc We find that their distributions are distinct, although there is still a large overlapped area However, utilizing this knowledge, an eavesdropper can improve its guess on the value of this bit, given the singular value it received|,Non-data,53
| For example if it receives a large singular value ˆσ2, then it is more likely to represent Gc 323 Final feature computation The final solution to select a feature that satisfying all requirements specified in Subsection 3|,Non-data,53
|21 is presented as follows For every block of samples constructed, we first compute Ga, Gb, and Gc and compute their 2nd and 3rd largest singular values: ˆσa 2, ˆσb 3 We let two difference values (Δˆσ0 3) to represent the bit 0 and (Δˆσ1 2, Δˆσ1 3) to represent the bit 1 as shown in Figure 2 − 10, where Δˆσ0 2 = ˆσb 3 − ˆσb ˆσb 2, and Δˆσ1 3|,Non-data,53
| Figure 8 shows the distributions of Δˆσ0 2 We can find that their distributions are almost identical The distributions of Δˆσ0 3 are also identical, which is not shown In this way, the attacker 3 , ˆσb 2, Δˆσ0 3 and Δˆσ1 2 and Δˆσ1 2, and ˆσc 3 − ˆσa 2 − ˆσa 2 = ˆσc 2 , Δˆσ0 3 = ˆσb 3 , Δˆσ1 3 = ˆσc 2 , ˆσa 3, ˆσc cannot improve its guess of a bit based on the feature sent from Alice|,Non-data,53
| 33 Key generation and delivery Key generation Alice, the initiator, is in charge of generating a key with strong randomness, using any existing algorithm The bit string for the secret key should be (1) sufficient long, i|,Non-data,53
|e, more than 128 bits in common, and (2) statistically random Feature pairing After computing the features for 0/1 bits and generating the key, TDS needs to perform feature pairing, i|,Non-data,53
|e, choosing one from features of 0-bit and one from features of 1-bits and making them a pair to represent a bit The simplest solution is to make the two features computed from a same group of samples to be a pair However, one disadvantage is that it is possible that in some pairs the two features are close and hence make it easier to produce mismatched bits|,Non-data,53
 Hence this feature pairing step is to find an optimal strategy of making the difference of feature values for each 0/1 pair larger than a certain threshold θ We take a paring algorithm based on Max-Weighted Bi- partite Matching to solve this problem We assemble all the features extracted from G0 and G1 into two sets C 0 f and C 1 f to represent 0 and 1 bits respectively The above problem can be formalized as a Max-Weighted Bipartite Matching problem,Non-data,53
| Then we can leverage Kuhn-Munkras algorith- m [10] to solve this problem, and map the 0 and 1 bits to the features f × We construct a complete bipartite graph G(C 0 f ) with weights w(eij) =||c 0 || The feasible vertex C 1 (cid:3) labeling l is defined as − c1 (cid:4) f , C 1 f , C 0 (cid:2) fj fi l(c0 fi ) = max w c0 fi , c1 fj l(c1 fj ) = 0 ∀c0 ∀c1 fi ∈ C 0 ∈ C 1 f f fj The Equality Subgraph Gl is a spanning subgraph of G which is defined as Gl = {(xi, yj)||Gl ⊆ G, w (xi, yj) = l (xi) +l (yi)} (1) where (cid:5) xi ∈ X ⊆ C 0 yj ∈ Y ⊆ C 1 f f The algorithm execution time is much shorter than CSI measurement time b c and S−1 Key delivery and information reconciliation|,Non-data,53
| To represent the sequence of generated bits Ka whose length is l, Alice selects l features from l pairs in her S-box Sa She then sends the features to Bob and Calvin Bob and Calvin use their S-boxes S−1 to decode the key TDS uses existing information reconciliation method [3] [28] to create consistent keys on difference devices|,Non-data,53
| After information rec- onciliation, Bob’s key will be corrected to Alice’s If there are more than two devices, Alice will run information rec- onciliation to every of them in order Information reconcil- iation includes an information-theoretically secure authen- tication using universal hashing [17] Secure authentication can also defend against impersonation attack, in which an attacker pretends to be Alice and send a sequence of feature values, and substitution attack, in which an attacker replace the correct feature values by other values|,Non-data,53
| The process is 621Algorithm 1: KM based feature mapping Input: C 0 Output: Perfect matching bipartite graph GL with f ,C 1 f ,θ; maximum difference 1 Build Equality Subgraph GL via Equation (1); 2 Find the maximum matching graph Gl utilizing 3 for GL is not the perfect matching graph do 4 5 6 Hungarian algorithm [10]; S ← the free node in X; H = hungarian trees of S; f j||eij = (c0 T = {c1 S = S ∪ (X ∩ H); for ei,j is not an augmenting path do f j(cid:2) , GL ← ei(cid:2),j(cid:2) ; f j) ∈ GL f i /∈ H}; c0 f i, c1 (cid:6) end S ← c0 f i(cid:2) , T ← c1 7 8 9 10 end 11 GD = {eij||eij ∈ GL ∧ eij < θ}; 12 GL = GL − GD; called privacy amplification [17] Note that to preserve the confidentiality of the key, privacy amplification will remove some bits from the key after each round of parity check Hence in key generation, Alice can reserve some addition- al bits for information reconciliation For example, she will generate 300 bits for a 256-bit secret key|,Non-data,53
| Alice will termi- nate information reconciliation after a specified number of rounds In fact, in our experiments, the bit error rate is very low (< 001 for two devices within 4cm distance in outdoor environments) Hence the cost of information reconciliation is low|,Non-data,53
| 4 ANALYSIS AND DISCUSSION In this section, we discuss and analyze the security and efficiency of TDS 41 Security of TDS The authenticity, confidentiality, and integrity of TDS can be guaranteed under the framework of information reconcil- iation [3] [22]|,Non-data,53
| In the cascade protocol [3], both Alice and Bob have a version of a key and the two versions contain mis- matched bits They use parity checking via a public chan- nel to correct the errors The model completely describes our protocol It has been shown that information recon- ciliation is essentially source coding with side information|,Non-data,53
| The amount of information to be exchanged in optimal in- formation reconciliation is the conditional Shannon entropy and information reconciliation and privacy amplification are information-theoretically secure [22] [17] We present the au- thenticity and confidentiality protection in other steps than information reconciliation Authenticity Eve, located out of the safe distance from Alice, may want to pretend to be a legitimate device and run information reconciliation|,Non-data,53
| The authenticity is protect- ed because Alice will only run information reconciliation for a fixed number of rounds for every other device Hence only if the bit error rate is smaller than a reasonable threshold, eg, 7%, Eve can get the key obtained by Alice|,Non-data,53
| According to results in Section 53, the bit error rate of any device with > 12cm distance from Alice is around 50%, the maximum bit error rate In addition, any bit exposed during informa- tion reconciliation will be removed from the key Hence Eve cannot perform spoofing|,Non-data,53
| Confidentiality In addition to the above framework, we need to demonstrate that the singular values broadcast by Alice reveal no information about the secret bits As shown in Figure 8, the singular values of 0-blocks and 1-blocks have identical distributions Hence given two singular values, the eavesdropper still cannot improve its guess on this bit|,Non-data,53
 42 Predictable channel attack A significant concern about reciprocal quantization is that an adversary can use deliberately planned movements to generate desired or predictable changes in the channel be- tween the legitimate devices Unfortunately prior works can- not defend against such a predictable channel attack [8] TDS does not use reciprocal quantization,Non-data,53
| The key of TD- S is generated by Alice using sophisticated algorithms Even if the adversary performs deliberate actions, eg, interfere the channel, it cannot yield any predictable patten on gen- erated key bits|,Non-data,53
| We should guarantee that the key delivery process is also resilient to the predictable channel attacks TDS uses S-box for key delivery, in which the features used to represent secrete information should be unpredictable As we discussed above, the features representing 0s and 1s are independent and identically distributed After block al- location, the measurements have been sufficiently diffused and confused, as to meet the Shannon’s diffusion and con- fusion properties in conventional cryptography ciphers|,Non-data,53
| In this case, the adversary cannot generate a predictable pat- tern over the measurements in TDS’s blocks, even if she is able to manipulate predictable patterns in the channel by de- liberate actions, such as blocking the channel periodically Therefore, TDS can effectively defend against predictable channel attacks We will show our experimental study of this point in Subsection 55|,Non-data,53
| 43 Stability of KM based feature paring al- gorithm In Subsection 33, we have discussed the KM based feature pairing algorithm, which can generate a maximum matching graph In Algorithm 1, we discard all pairs whose difference is less than θ, which is about 5%|,Non-data,53
| In this section, we will demonstrate that KM algorithm is stable, ie, the remaining graph excluding minimal edge is also a maximum matching graph We have no need to re-carry the Algorithm 1|,Non-data,53
| Denote the maximum weight of graph G before discarding to be M , and the maximum weight after discarding edge ei0j0 , , to be M −w(ei0j0 ) Assuming that the maximum named G(cid:2) , we have M(cid:2) > M − w(ei0j0 ) ⇒ M < weight of G(cid:2) M(cid:2) +w(ei0j0 ), ie, there exists another matching weigh M(cid:2) + w(ei0j0 ) of G is larger than M |,Non-data,53
| This result derived from that assumption, obviously, is inconsistent with the fact that M is the maximum weight of G Hence, that assumption is false and Algorithm 1 is stable 44 Fault tolerance is M(cid:2) 622Due to the presence of noises and manufacture variations, there may be a difference of CSI measurements hi in the ith sample, denoted as δi|,Non-data,53
| When δ is larger than ε, Δˆσ begins to incur mismatched bits, which leads to a wrong information delivery Using multiple samples in a block can reduce the variance of the represented features According to Chebyshev inequality, we have P{||δ − E(δ)|| ≥ ε} ≤ D(δ) ε2  Block-based information delivery can efficiently reduce the variance of average δ, and then reduce the secret bit error rate|,Non-data,53
| TDS extracts the feature of block based on SVD As afore- mentioned in Section 32, the block size is 10 × n (typi- (cid:7)β cally n = 6) SVD can be expressed as G = U ˆΣV T = i , where ˆσ is the singular value of G, and Ui, Vi are the ith column vectors of U and V , respectively|,Non-data,53
| The is the ith sin- power of noise isP N = gular value of noise matrix TDS uses the second or third singular values ˆσ2 and ˆσ3 to represent the signal features and discards the singular value smaller than ˆσ4 which are mainly relevant to noises Therefore, the noise is decreased by i )2 through SVD i=1 ˆσiUiV T 1 (σw i )2, where σw i (cid:7)β (cid:7)β i=4 (σw 4|,Non-data,53
|5 Information delivery rate We use the number of delivered secret bits per sample as the information delivery rate In order to further improve the information delivery rate, TDS can divide one block in- to two orthogonal sets of samples to transfer two bits In Figure 6, we find that for a given subcarrier, the correla- tions between it and other subcarriers vary gradually, and there should be another subcarrier with the lowest correla- tion coefficient, ie|,Non-data,53
| most uncorrelated to it For example, the correlation between the 1st subcarrier and the 13th sub- carrier is almost zero TDS divides all subcarriers two sets: H1: ({1, 2,··· , 10}, {1, 3,··· , 19}, and {1, 4,··· , 28}), and H2: ({13, 14,··· , 22}, {13, 15,··· , 29, 1}, and{ 14, 17, ··· , 29, 2,··· , 11}) The distributions of Δˆσ in the two sets are plotted in Figure 9|,Non-data,53
| The blue and red points are the Δˆσ0 and Δˆσ1 distributions in H1, while the black and green points are the distributions in H2 These two sets are inde- pendent Their Δˆσ can be used to deliver two bits in one block Therefore, the delivery rate of TDS can be doubled|,Non-data,53
| In our system, we set n = 4 in mobile scenarios and n = 6 in static scenarios, and their delivery rate is 6 6  That is, each sample can confidentially deliver 15 bits and 067 bit in mobile scenarios and static scenarios, respectively|,Non-data,53
| 4 and 4 46 Distance constraint and multi-user key a- greement To agree on a shared secret key with reliability, all de- vices need to be located close to each other Therefore, the authentication distance will impact the scalability of TDS TDS allows a key to be directly delivered from one device to others, saving huge amount of overhead from interactive a- greement|,Non-data,53
| The requirement is that all devices are located in the close proximity centered at the sender When the num- ber of legitimate devices increases, their distance between each other may also increase due to space limit, which will reduce the consistency of channel measurements due to fast fading channel Table 1: Experiments scenarios Index A B C D State Static Static Mobile Mobile Environment Indoor Outdoor Indoor Outdoor Table 2: NIST statistical test results To pass this test, p-value must be greater than 0|,Non-data,53
01 Test Monobit Frequency Longest Run of Ones FFT Approximate Entropy Cumulative Sums (Fwd) Cumulative Sums (Rev) Block Frequency Runs Serial A 0611 0724 0,Non-data,53
553 0708 0530 0787 0,Non-data,53
725 0734 0421 0590 B 0,Non-data,53
757 0660 0848 0897 0,Non-data,53
776 0749 0819 0723 0,Non-data,53
401 0530 C 0900 0861 0,Non-data,53
757 0899 0905 0955 0,Non-data,53
874 0883 0841 0913 D 0,Non-data,53
784 0883 0752 0719 0,Non-data,53
681 0919 0977 0846 0,Non-data,53
|885 0642 In order to make TDS work well for many devices, eg, more than three, we propose a new communication model to beyond the space limitation|,Non-data,53
| Instead of using a public wireless source, Alice and Bob ping each other to generate symmetric random channel variations Other legitimate de- vices are located near Alice and Bob within authentication distance to hear the communication between Alice and Bob This model can double the authentication space to support key agreement for more users 5|,Non-data,53
| IMPLEMENTATION AND EVALUATION In this section, we present the prototype implementation, experiment setup, and performance evaluation of TDS 51 Methodology We conduct extensive experiments with five laptop com- puters, named Alice, Bob, Calvin, Eve, and Peter The laptops are all equipped with commodity off-the-shelf wire- less NICs model Intel 5300|,Non-data,53
 Peter is configured as an AP The wireless connection among five laptops operates in the 80211n 24GHz channel,Non-data,53
| Antennas of Alice, Bob and Calvin are located in less than 5cm (04λ) distance, while Eve is deployed at least 25cm (2λ) away from Alice As the AP, Peter broadcasts beacons every 50ms In two users mode, Alice pings Bob every 50ms and receives Bob’s ACK after 1-5ms|,Non-data,53
| Alice broadcasts Timing Synchronization Function (TSF) timestamp to synchronize all legitimate devices with- in 25 microseconds Eve turns itself into the monitor mode to be an eavesdropper We conduct our experiments in a large variety of envi- ronmental settings and under different scenarios as listed in Table 1 In our experiments in static environments (A and B), there is no line of sight between Alice and Bob, and all the objects are keeping still|,Non-data,53
| In the other experiments in mobile environments (C and D), with several intermediate 623F D C 1 08 06 04 0|,Non-data,53
|2 0 "0" A "1" A "0" B "1" B "0" C "1" C "0" D "1" D -20 0 20 40 60 80 Δσ(cid:63)(cid:63)  (cid:63) Δσ(cid:17)(cid:0)íΔσ(cid:16) (cid:63) Figure 11: Distribution of Δˆσ0 and Δˆσ1 Figure 12: Distribution of differences between Δˆσ0 and Δˆσ1 objects, the presence or the absence of line of sight changes with time In different scenarios, we use the following met- rics for performance evaluation: Bit generation rate is defined as the number of secure bits of the key over the overall time for key agreement Note the time is for the entire process including CSI measurement, S-box construction, and key delivery Bit error rate is the number of mismatched bits over the number of all bits generated|,Non-data,53
 Randomness and entropy is used to evaluate the quality of keys We measure the randomness of the keys generated by TDS using the standard NIST test We also compute the entropy of the key generated All results are the average value from at least 20 indepen- dent experiments,Non-data,53
| 50 0 < σ Δ 0 −50 0 50 1 < σ Δ 0 −50 0 50 50 100 Index 150 200 250 100 Index 150 200 250 Figure 13: The distribution of Δˆσ0 and Δˆσ1 for mul- tiple users 52 Randomness of key and block features Since we assume Eve has complete information of the pro- tocol, any non-random behavior in the bit sequences or block features can be exploited by the adversary to reduce the time-complexity of cracking the key Although Alice can generate an arbitrary key, the key may also be slightly changed after privacy amplification|,Non-data,53
| We em- ploy a widely used randomness test suit, NIST to verify the randomness of the secret-bit generated by TDS In this test, we use 200 bit sequences generated from our experiments in scenarios A, B, C, and D, and compute their p-values for 8 types of tests According to the specification in this suite, if all p-values are greater than 005, the sequence is random|,Non-data,53
| We list the p-values of TDS in Table 2 From the results, we find that the bit streams generated by TDS pass all the tests with high values TDS uses Δˆσ to transmit secret information, Δˆσ0 and Δˆσ1 is the feature of CSI measurements in one block used to represent 0 and 1 respectively They should have inde- pendent and identical distribution to avoid information leak- age|,Non-data,53
| Figure 11 shows the distribution of Δˆσ0 and Δˆσ1 in scenarios A, B, C, and D The distributions in different scenarios are slightly different In the same scenario, Δˆσ0 and Δˆσ1 have extremely similar distributions Therefore, the adversary can hardly obtain any information from the Δˆσ delivered in public wireless channels|,Non-data,53
| In addition, the differences between Δˆσ0 and Δˆσ1 for each 0/1 pair influence bit error rate A large differentiation of “0/1” for each bit will enhance the fault tolerance We take a paring algorithm based on Max-Weighted Bipartite Match- ing to solve this problem Figure 12 shows the distribution of the differences between Δˆσ0 and Δˆσ1 for each 0/1 pair|,Non-data,53
 The differences for original 0/1 pair are nearly a linear dis- tribution There are about 9% pairs with the differences less than 10 We introduce a filtered perfect matching method to filter the pairs with small differentiation 5,Non-data,53
|3 How distance influences performance Figure 14(a) shows the bit generation rate by varying the distance between two devices (Alice and another receiver of the key) We find that when the distance is smaller than 4cm, the bit generation rate is always higher than 100 bit- s/sec Hence it only takes a couple of seconds to get a 256-bit key The bit generation rate in mobile scenarios is higher than that in static scenarios|,Non-data,53
| The bit generation rate in outdoor environments is higher than that in indoor environments It is because mobile and outdoor environ- ments provide more channel diversity Compared with an- other method ProxiMate [15] that only generate a few bits per second, the bit generation rate of TDS is higher by more than an order of magnitude Figure 14(b) shows the bit error rate by varying the dis- tance between devices, for ProxiMate and TDS|,Non-data,53
| Even if the distance of two device antennas is 1cm, the bit error rate of ProxiMate is about 5%-10% For TDS, when the dis- tance is less than 3cm, the mismatch rate of TDS is 0 for outdoor environments and < 0015 for indoor environments When the distance is 5cm, the mismatch rate of TDS is still smaller than 7%|,Non-data,53
| We mark the authenticate distance and safe distance in the figure Here the safe distance can be set to 125cm but a user can easily check a much longer safe distance such as 25cm or even 50cm Out side of the safe dis- tance, a device has bit error rate equal to 0|,Non-data,53
|5, the maximum bit error rate Figure 14(c) shows the parity check counts with increas- ing the distance between devices, for ProxiMate and TDS The number of passes is 5 When the distance is more than 1cm, parity check counts of ProxiMate are larger than 130, which might not work properly|,Non-data,53
| For TDS, as long as the dis- tance is less than 5cm, the parity check counts are less than 20 in both indoor and outdoor scenarios The devices with- in 5cm can achieve pairing without user intervention For large civilian or military transceivers, we may use external antennas which can be easily placed in 5cm 624200 150 100 50 ) c e s / s t i b (  t e a r − t i B 0    A B C D 1 2 3 4 5 6 7 8 9 10 Alice−Bob distance (cm) H W D U  U R U U H  W L % 0|,Non-data,53
7 06 05 04 0,Non-data,53
3 02 01 0 ProxiMate$ ProxiMate% TDS$ TDS% H F Q D W V G L   Q H K W X D H F Q D W V G H  L I D V s t n u o c  k c e h c  y t i r a P 100 50 150 003 y t l i b a b o r P 0,Non-data,53
02 001 ProxiMateB ProxiMateA TDSB TDSA 8 10  σΔ(cid:0) ^  σΔ(cid:0) ^  Δσ^   Δ(cid:0) σ^  1 2 3 4 5 6 7 8 9 1011121314 'HYLFHGLVWDQFHFP 0   2 4 Device distanceFP 6 (a) Bit generation rate of TDS (b) Bit error rate (c) Rounds of parity checks Figure 14: Key generation performance vs distance for TDS & ProxiMate 0 −40 −20 0 20 40 60 80 100 Feature value Figure 15: Distribution- s of the features without and under attacks 54 Group key agreement TDS supports group key agreement,Non-data,53
| For the situation with more than two devices, devices adopt the new com- munication model to deal with fast fading channel proposed in Section 46 Figure 13 plots the distribution of Δˆσ0 and Δˆσ1 for 4 users Four colors of points represent four devices|,Non-data,53
 The points in the same column are Δˆσ0 or Δˆσ1 of four de- vices for the same 0/1 pair Two devices Alice and Bob are 30cm away from each other Alice pings Bob every l00ms and receives Bob’s ACK after 1-5ms Calvin and Peter are near to Alice and Bob within 4cm respectively,Non-data,53
| The Δˆσ0 and Δˆσ1 of four users are almost identical for the same bit, which can be used to represent secret bits reliably among the group (a) I S C 40 30 20 (b) (c) (d) ) 1 / 0 ( s t i B / ) 1 0 ( s t i B ) 1 / 0 ( s t i B 1 0 1 0 1 0 20 40 60 80 100 120 140 160 180 200 20 40 60 80 100 120 140 160 180 200 20 40 60 80 100 120 140 160 180 200 20 40 60 80 100 Index 120 140 160 180 200 Figure 16: CSI measurements when an intermediate object moving between Alice and Bob 55 Robust against predictable channel attack The attacker Eve can perform some deliberately planned movements to block the LOS between Alice and Bob, such that the bits extracted from the CSI measurements with manipulated changes, in hope that it can predict the features for 0 and 1 bits as well as the key|,Non-data,53
| Figure 16(a) shows that CSI measurements from the 1st subcarrier display periodical changes under predictable chan- nel attacks The CSI values increase when Eve blocks LOS or decrease when Eve moves away Figure 16(b), (c) and (d) plot the bits of the agreed key by reciprocal quantization, TDS, and KEEP, respectively The blue parts and white parts represent “1” and “0”|,Non-data,53
| For reciprocal quantization, the generated bits present an predictable pattern When the channel is blocked, the bits are generated as 0s, otherwise, they are 1s In contrast, the variations of extracted bits by KEEP and TDS are indepen- dent of the blocking pattern It is because TDS do not rely on the channel condition to generate keys and KEEP ex- tracts keys by randomly picking up discrete fragments from all the subcarriers of OFDM|,Non-data,53
| Therefore, an attacker can- not infer the pattern of the secret bits by TDS based on his interference pattern In addition, we should guarantee that the feature distri- butions are also resilient to the predictable channel attack- s Figure 15 compares the distribution of delivering value with/without predictable channel attack (denoted by Δˆσ(cid:2) and Δˆσ, respectively) It reveals that the features represent- ed 0s and 1s are almost identically distributed regardless of predictable channel attack|,Non-data,53
| This is because that the block allocation sufficiently diffuse and confuse the CSI measure- ments In this case, the adversary cannot generate a pre- dictable pattern over those measurements, even if it is able to manipulate predictable patterns in the channel by deliber- ate actions, such as blocking the channel periodically More interesting, the distribution range of Δˆσ(cid:2) grows wider, since the predictable channel attack introduce more variance of measurements It increases the difference between Δˆσ(cid:2)0 and Δˆσ(cid:2)1 for each bit, which improves fault-tolerance of S-box|,Non-data,53
| Therefore, TDS can effectively defend against predictable channel attacks 56 Comparison of key extraction approaches We compare TDS with existing key generation and agree- ment approaches for mobile networks, including KEEP [28], Mathur et al [16], ASBG [8], CGC [12]|,Non-data,53
 Note these solu- tions assume an authenticated channel between two devices Hence they are weaker in security than TDS We align the baseline of comparison as follows In the scheme proposed by Mathur et al,Non-data,53
|, there are two parameters α and m We set α = 035 and m = 2 to ensure most fractions of mea- surements are used for bit extraction For ASBG, CGC, and KEEP, we choose α = 0|,Non-data,53
|35 and fragment size is 50, where the mismatch ratio is low For TDS, we choose block size β = 6 in static scenarios and β = 4 in mobile scenarios The distance between Alice and another device is within 4cm We compare the entropy of keys generated by different ap- proaches in Figure 17|,Non-data,53
| The entropy can reflect the random- ness of keys from the perspective of uncertainty TDS and KEEP have the highest entropy in all methods, and CGC has the lowest Figure 18 shows the bit error rates In this 625y p o r t n E 1 0|,Non-data,53
8 06 04 02 0 0,Non-data,53
|04 e t 003 a r  h c t a m s M i 002 001 A B C 6FHQDULRV D 0   A B C Scenarios     F H V  V W L E   t e a r  t i b  t e r c e S 0 0 0 0 TDS KEEP ASBG Mathur CGC D 40 30 20 10 0 s t n u o c  n o i t a l i c n o c e r  n o i t a m r o f n I A B C Scenarios D A B C Scenarios D Figure 17: Entropy of the keys Figure 18: Bit error rate Figure 19: Secret bit gen- eration rate Figure 20: reconciliation counts Information distance, TDS has no mismatched bit, while other methods may cause around 2% to 4% mismatched bits|,Non-data,53
| Figure 19 shows the bit generation rates Obviously TDS has signifi- cantly higher generation speed Note the bit generation rate of TDS is slower than previous results It is because in this set of experiments, Alice and Bob do not listen to a public WiFi but use the communication among them for sampling|,Non-data,53
| This is the only model that the other protocols can work but TDS is not restricted to it Figure 20 shows the num- ber of rounds for information reconciliation Since there are no mismatched bit, TDS only uses 4 times pass check to guarantee the consistency of transmitted secret bits 6|,Non-data,53
| RELATED WORK To ensure data confidentiality, creating keys based on the physical layer information of wireless channels is promising due to its efficiency and security [18] [25] [5] [7] [26] Most of existing methods focus on pairwise key generation by mea- suring the time-varying channel [11] [29] [21] Exploiting temporal and spatial variations of wireless channels, RSS based techniques are widely used [16][20][8] They tend to transform the RSS values to a sequence of bits, and create secrets based on the reconciled bits|,Non-data,53
| However, RSS may vary at different receivers, so the key generation rate of RSS based methods is low For example, Radiotelepathy [16] extracts secret keys using the channel impulse response (CIR) in the wireless channel and its key generation rate is only around 1 bit per second Pinpoint [27] can fast exchange informa- tion exploiting CIR with reversed jamming noise between two devices, yet with little scalability Contrast with RSS, CSI is much richer source of secret in- formation|,Non-data,53
 It can be obtained via the Orthogonal Frequency- Division Multiplexing (OFDM) Liu et al [14] theoretically prove the feasibility of CSI and high key generation using CSI A practical CSI based key exaction system [12] has been implemented which works in both static and mobile environments,Non-data,53
| However, CSI measurements among adjacent subcarriers have strong correlations, so the key generated from nearby subcarriers also have correlation, which is vul- nerable to key cracking attacks To avoid such a risk, KEEP [28] introduces a validation-recombination mechanism that combines the information of all subcarriers and is resilient to the key cracking attack In many applications, it is necessary to establish a col- laborative key among a group of wireless devices Key es- tablishment concerning the shared group key is discussed in [13]|,Non-data,53
| In a group key establishment scheme, each node keeps a matrix, which includes the values measured from all its channels to its neighbors In summary, none of existing methods can achieve instant and robust key agreement among multiple devices 7 CONCLUSION TDS is a device authentication and key agreement proto- col that helps multiple devices to agree on a secret key in a couple of seconds|,Non-data,53
| Compared with prior solutions for mobile networks, it has four important advantages: i) its key gen- eration rate is faster by more than an order of magnitude; ii) it supports more than two devices; iii) it can agree on an arbitrary key with strong randomness; iv) it can effective- ly defend against predictable channel attacks We conduct rigorous analysis to show the feasibility and security of our protocol We also implement TDS in commodity off-the- shelf WiFi devices The experiment results demonstrate the high efficiency and robustness of TDS|,Non-data,53
| We believe the idea of TDS can be extended in other communication scenarios 8 ACKNOWLEDGMENTS This work is supported by the National Natural Science Foundation of China under Grant No 61325013, 61190112, 61572396, and 61402359|,Non-data,53
| Chen Qian is supported by UC Santa Cruz Startup Grant and National Science Foundation grant CNS-1464335 Sheng Zhong is supported in part by the Jiangsu Province Double Innovation Talent Program and in part by the Na- tional Natural Science Foundation of China under Grant No 61300235, 61321491, 61402223, and 61425024 Xiang-Yang Li is partially supported by NSF ECCS-1247944, NSF CMMI 1436786, NSF CNS 1526638, National Natural Science Foundation of China under Grant No|,Non-data,53
|ABSTRACT We show that equivocation, ie, making conflicting state- ments to others in a distributed protocol, can be monetar- ily disincentivized by the use of crypto-currencies such as Bitcoin To this end, we design completely decentralized non-equivocation contracts, which make it possible to pe- nalize an equivocating party by the loss of its money|,Non-data,56
| At the core of these contracts, there is a novel cryptographic primitive called accountable assertions, which reveals the party’s Bitcoin credentials if it equivocates Non-equivocation contracts are particularly useful for dis- tributed systems that employ public append-only logs to protect data integrity, eg, in cloud storage and social net- works|,Non-data,56
| Moreover, as double-spending in Bitcoin is a special case of equivocation, the contracts enable us to design a payment protocol that allows a payee to receive funds at several unsynchronized points of sale, while being able to penalize a double-spending payer after the fact Categories and Subject Descriptors C24 [Computer-communication networks]: Distributed systems; K44 [Computers and society]: Electronic com- merce—cybercash, digital cash, payment schemes, security Keywords crypto-currencies; Bitcoin; equivocation; append-only logs; accountability; double-spending; payment channels 1|,Non-data,56
| INTRODUCTION Making conflicting statements to others, or equivocation, is a simple yet remarkably powerful tool of malicious par- ticipants in distributed systems of all kinds [4, 19, 20, 33] In distributed computing protocols, equivocation leads to Byzantine faults and fairness issues When feasible, equivo- cation is handled by assuming an honest majority (ie|,Non-data,56
|, larger ∗The work was done while the author was still at Saarland University Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page Copyrights for components of this work owned by others than the author(s) must be honored Abstracting with credit is permitted|,Non-data,56
| To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from Permissions@acmorg CCS’15, October 12–16, 2015, Denver, Colorado, USA|,Non-data,56
 Copyright is held by the owner/author(s) Publication rights licensed to ACM ACM 978-1-4503-3832-5/15/10 ,Non-data,56
$1500 DOI: http://dx,Non-data,56
doiorg/101145/28101032813686,Non-data,56
| replication factors [27]), synchrony assumptions and digital signatures [26], or trusted hardware [4, 19, 20, 33] Moreover, publicly verifiable append-only logs [22, 23, 24, 35] make it possible to detect equivocation after the fact but they do not suffice to stop or penalize equivocation Decentralized crypto-currency systems such as Bitcoin [10, 36] and its derivatives follow a novel approach to handle equivocation To protect against equivocation in the form of double-spending, i|,Non-data,56
|e, spending the same funds to differ- ent parties, Bitcoin employs a special decentralized public append-only log based on proof of work called the blockchain: In a decentralized crypto-currency, users transfer their funds by publishing digitally signed transactions Transactions are confirmed only when they are included in the blockchain, which is generated by currency miners that solve proof-of- work puzzles Although a malicious owner can sign over the same funds to multiple receivers through multiple transac- tions, eventually only one transaction will be approved and added to the publicly verifiable blockchain|,Non-data,56
| As a result, to stop equivocation, it is possible to record all messages in a distributed system that are vulnerable to equiv- ocation in a blockchain Nevertheless, due to proof-of-work computations and the decentralized nature of blockchain sys- tems, the process of reaching consensus is not only expensive but also only slowly converging In Bitcoin, it takes tens of minutes to reach consensus on the set of valid transactions To enable transactions be performed faster, a contractual solution in the form of payment channels [45, 48] is emerging in the Bitcoin community [39, 47]|,Non-data,56
| Here, a payer makes a time-locked deposit for his predetermined payee such that double-spending (or equivocation) is excluded even when pay- ments are performed offline and without waiting However, payment channels are not secure against double-spending when the payee runs several geographically distributed and unsynchronized points of sale, eg, a bus company selling tickets on buses with only sporadic Internet connectivity|,Non-data,56
 Our goal in this paper is to address these equivocation issues by a generic solution that disincentives paltering and is applicable to various distributed systems and scenarios including the aforementioned payment channels with unsyn- chronized points of sale 11 Contributions Our key idea towards preventing equivocation is to use Bitcoin to prescribe a monetary penalty for equivocation Accountable Assertions,Non-data,56
| As a first step, we establish a cryptographic connection between equivocation and the loss of funds by introducing a cryptographic primitive called 219accountable assertions (Section 4) The main idea of this primitive is to bind statements to contexts in an accountable way: if the attacker equivocates, ie, asserts two contradict- ing statements in the same context, then any observer can extract the attacker’s Bitcoin secret key and, as a result, use it to force the loss of the attacker’s funds|,Non-data,56
| We present a construction of accountable assertions based on chameleon hash functions [30] and prove it secure in the random oracle model under the discrete logarithm as- sumption (Section 5) A performance evaluation of our construction demonstrates its practicality with respect to computation, communication, and storage costs Non-equivocation Contracts To ensure that a secret key obtained through equivocation is indeed associated with funds, every party that should be prevented from equivo- cating is required to put aside a certain amount of funds in a deposit [2, 6, 32, 40]|,Non-data,56
| These funds are time-locked in the deposit, ie, the depositor cannot withdraw them during a predetermined time period This prevents an attacker from spending the funds and thus rendering the secret key useless just before equivocating|,Non-data,56
| Accountable assertions and deposits together enable us to design non-equivocation contracts, a generic method to penalize paltering in distributed systems (Section 6) We propose several applications of non-equivocation contracts to ensure the linearity of append-only logs [22, 23, 24, 35] Asynchronous Payment Channels Bitcoin payment channels protocols [45, 48] enable a user to perform pay- ments to a predetermined party offline and without waiting for the consensus process|,Non-data,56
| However, if a payee is a distributed entity (eg, a bus service with several buses as points of sale with only spo- radic Internet connectivity) then even payment channels do not prevent double-spending Since double-spending is an instance of equivocation, non-equivocation contracts enable us to design asynchronous payment channels, which make it possible to penalize double-spending payers (Section 7)|,Non-data,56
| Double-Authentication-Preventing Signatures Of in- dependent interest, we observe that accountable assertions are similar to double-authentication-preventing signatures (DAPS) as proposed by Poettering and Stebila [38] While accountable assertions are in general a weaker primitive, cer- tain accountable assertions are DAPS It was left as an open problem to construct DAPS based on trees or chameleon hash functions [38]|,Non-data,56
| We solve these problems, and our account- able assertion scheme based on Merkle tress and chameleon hash functions in the random oracle model yields the first DAPS scheme secure under the discrete logarithm assump- tion (Appendix A) For practical parameters, it is two orders of magnitude faster than the original DAPS construction [38], and uses one order of magnitude less communication 2 OVERVIEW We conceptualize decentralized non-equivocation contracts and discuss their potential applications|,Non-data,56
| Problem Statement Equivocation, ie, making conflict- ing statements to different protocol parties, is a universal problem in malicious fault-tolerant security protocols involv- ing three or more parties [4, 19, 20, 33]|,Non-data,56
| In all bounded or partial synchronous communication settings, equivocation can be detected using digital signatures (together with a public-key infrastructure) and some interaction among the parties [20]: two recipients who are expected to receive the same message from a sender can exchange the received signed messages to expose and prove equivocation This principle underlies many append-only logs [22, 23, 24, 35] However, it is often not possible to impose a penalty on the maliciously or carelessly equivocating sender after the fact, as the sender may be anonymous or pseudonymous Even when the sender is not anonymous and may lose her reputation once a case of equivocation is detected, the effect of such paltering on the recipient can be damaging|,Non-data,56
| Key Idea Our key idea is to let the sender create a time- locked Bitcoin deposit [2, 6, 32, 40] that can be opened by the recipients if the sender equivocates In case of an equivocation, the funds will be given either to a predefined beneficiary or, once the expiry time of the deposit is reached, to the miners If the expected loss is high enough, the attacker has no incentive to make conflicting statements|,Non-data,56
| Threat Model The attacker is a malicious sender whose goal is to equivocate without losing the deposit To achieve that goal, the attacker can deviate arbitrarily from the pre- scribed protocol but she does not risk to lose her deposit if the expected loss is higher than the expected gain We assume that the attacker cannot break the fundamental security of Bitcoin, e|,Non-data,56
|g, the attacker does not have the majority of computing power in the Bitcoin network Non-equivocation Contracts We describe the main idea of non-equivocation contracts, which are a form of smart contracts [11, 29, 40], in more detail|,Non-data,56
| The sender A creates a time-locked deposit as a guarantee for her honest behavior The deposit is secured by the sender’s secret key sk A; the corresponding public key is pk A  Furthermore, the deposit expires at some point T in the future That is, even though A owns the secret key sk A, she cannot access the funds in the deposit until time T |,Non-data,56
| Before time T , only A together with a predefined beneficiary P can access the funds This beneficiary will be given the funds if A equivocates (There is also a variant of deposits for which the beneficiary is a randomly selected miner We will explain this later|,Non-data,56
|) Once the deposit is confirmed by the Bitcoin network, parties are ready to receive statements from the sender A Non-equivocating contracts are built on the idea that it is possible to learn the key sk A if the sender A equivocates To enforce this cryptographically, we introduce accountable assertions, which allow the user A to produce assertions τ of statements st in contexts ct (where st and ct can be arbitrary bitstrings) under the public key pk A The sender A is held accountable in the following sense: If A behaves honestly, sk A will stay secret, and A can use it to withdraw the deposit once time T has been reached However, if A equivocates to some honest users B and C, i|,Non-data,56
|e, A asserts two different statements st0 6= st1 in the same context ct, then B and C can use st0, st1, ct and the two corresponding assertions τ0 and τ1 to extract the sender’s secret key sk A Due to the way the deposit is created, the recipients B and C alone cannot make use of sk A However, B and C can send sk A to the beneficiary P , who can use sk A together with his credentials to withdraw the deposit and thereby penalize the malicious sender A|,Non-data,56
| Note that B, C and P could as well be protocol parties that belong to essentially the same distributed entity but are just not synchronized when receiving statements from A  2203 BACKGROUND ON BITCOIN Bitcoin is an online digital cryptographic currency run by a decentralized peer-to-peer network|,Non-data,56
| In this section, we explain the basics of Bitcoin that are relevant to our work For a detailed explanation of the mechanics of Bitcoin, we refer the reader to the Bitcoin developer guide [7] A user in the Bitcoin network is identified using one or more pseudonymous addresses Technically, an address is the hash of a public key pk of the ECDSA signature scheme such that the owner of the corresponding secret key sk can use it to transfer bitcoins (symbol: B) associated with her address to another address by signing transactions|,Non-data,56
| Blockchain Miners include transactions in blocks By solving a proof-of-work (POW) puzzle, a block including its transactions is added to the blockchain Once added, a block and its transactions are difficult to modify because blocks are cryptographically chained together, and modifying a block involves re-doing the POW for this and all sequential blocks|,Non-data,56
| A transaction that has been included in the blockchain and backed up by the POW computations of several blocks is thus difficult to invalidate Most users consider a transaction confirmed if it has has been backed up by least six blocks, and the Bitcoin network takes 10 min on average to perform the POW of one block Scripts Bitcoin employs a scripting language to specify under which conditions an unspent output, i|,Non-data,56
|e, some unspent funds in the blockchain, can be spent The language is a simple stack-based language It is intentionally not Turing- complete to avoid complexity and the possibility of creating scripts that are expensive to execute, and could consequently lead to denial-of-service attacks, because every node in the Bitcoin network must execute them|,Non-data,56
| Each transaction sends funds to a script (called ScriptPub- Key), ie, a small program that specifies the conditions that must be fulfilled to spend the funds To spend the funds, the spender must provide an initial execution stack with input values|,Non-data,56
| The transaction is valid if the script terminates successfully on this initial stack 31 Deposits Using specially-crafted scripts, funds can be locked away in a so-called deposit, where they can only be accessed under a set of predetermined conditions While scripts can express a variety of such conditions [7], we focus on time-locked deposits with the property that the depositor cannot access the funds in the deposit until a specified expiry time|,Non-data,56
| With non-equivocation contracts in mind, we consider two types of deposits that differ in the beneficiary, ie, the party that receives the funds in case of equivocation The deposits of the first type do not specify a beneficiary|,Non-data,56
| In this case, the beneficiary will be a randomly selected miner Deposits of the second type are associated with an explicitly beneficiary P identified by his public key pk P Creating Deposits To create time-locked deposits, we use an upcoming feature [17] in Bitcoin, which introduces a new script command denoted by CHECKLOCKTIMEVERIFY [48]1 This command takes one argument T , the expiry time, from the execution stack and compares it to the nLockTime data field of the transaction|,Non-data,56
| If nLockTime < T , the evaluation 1Deposits with explicit beneficiaries and payment channels as described in the following paragraphs are possible even without CHECKLOCKTIMEVERIFY [1, 40, 45]  impl conf fails and the transaction is consequently invalid Thus, only transactions with nLockTime ≥ T can spend the funds cov- ered by such a script|,Non-data,56
| By the semantics of nLockTime, those transactions are valid only in blocks found after time T , and consequently, the funds protected by CHECKLOCKTIMEVERIFY are spendable only after T  We remark that the value of nLockTime can be specified either by a UNIX timestamp or a height of a block, which is the number of blocks that precede it in the blockchain Throughout the paper, we use timestamps, and to simplify presentation, we ignore that miners have some flexibility to lie about the current time [8]; an safety-margin of at least 120 min must be added to T to account for that issue Deposits Without Explicit Beneficiary|,Non-data,56
| Suppose that some user A wishes to create a deposit with expiration time T without an explicit beneficiary Then, A sends the desired amount B d to the following script: (T + T pkA CHECKSIG in the script denote push The literals (T + T operations that push a constant value on the stack The value T is a safety margin; we postpone its discussion to the analysis of non-equivocation contracts (Section 61)|,Non-data,56
| impl conf ) CHECKLOCKTIMEVERIFY DROP conf ) and pk A impl The first line of the script ensures that the deposit cannot be spent before time T as explained (DROP just drops the constant value from the stack) In the second line, CHECKSIG takes the key pk A and a signature σ from the stack; σ is supposed to be provided by the spender on the initial stack CHECKSIGVERIFY verifies that σ is a valid signature of the spending transaction under the key pk A , pushing the boolean result of the verification on the stack|,Non-data,56
| This boolean value is the output of the script Thus, if the check succeeds, the transaction is valid; otherwise it is invalid In sum, the script ensures that the funds can only be spent after T and only by a transaction signed under pk A If the corresponding secret key sk A is revealed, everybody can create transactions that try to spend the funds from time (T + T conf ) on Whenever this happens, each miner impl has a large incentive to include a transaction in a block that sends the money to him|,Non-data,56
| Consequently, the miner that finds the next block will claim the funds Deposits with Explicit Beneficiary Suppose that a user A wishes to create a deposit with an explicit beneficiary P  Then, A sends the desired amount B d to the following script: IF |,Non-data,56
| pkP CHECKSIGVERIFY ELSE (T + T expl conf + T expl net ) CHECKLOCKTIMEVERIFY DROP conf and T expl ENDIF pkA CHECKSIG In this script T net are safety margins, which will expl be discussed below IF obtains its condition from the stack, allowing the spender to choose the branch to be executed CHECKSIGVERIFY is like CHECKSIG but causes the whole script to fail immediately if the signature is not valid (instead of pushing the result of the signature verification to the stack) This script ensures that before time T , the funds can be spent only if the spending transaction is signed under both pk A |,Non-data,56
| Thus, if P learns sk A before time T , he can spend the funds Otherwise, A is refunded after time conf + T (T + T expl and pk P net ), even if P disappears expl 221The safety margins are necessary because the closing trans- action must have been broadcast to the Bitcoin network and confirmed by it before the deposit can be spent by A alone For the broadcast, T net = 10 min is more than sufficient [21]|,Non-data,56
| expl For the confirmations, we except the network to find 24 blocks in T conf = 240 min Since their arrival is Poisson-distributed, expl the probability that fewer than six desired blocks have been found is Pr[X ≤ 5] < 2−18 for X ∼ Pois(24) 32 Payment Channels Payment channels [45, 48] allow a user A to perform many transactions to a predefined recipient B up to a predefined amount B d of money|,Non-data,56
| Although establishing a channel be- tween A and B involves waiting for a transaction to be confirmed, the advantages of a payment channels are various: First, no matter how many payments are sent, only two transactions have to be included in the blockchain, namely one to establish and one to close the channel This makes payment channels a promising method to scale the Bitcoin network to many more transactions [39, 47] Second, A can perform payments to B even if both parties are offline, once the channel has been established Third, fast transactions are possible through the payment channel, because B does not have to wait for the transaction to be confirmed|,Non-data,56
| Creating a Payment Channel To create a payment channel from A to B with maximal payment value B d and expiry time T , A follows the procedure for creating a deposit with explicit beneficiary B B waits until the deposit is confirmed by the Bitcoin network From now on, the funds can only be spent if both A and B agree because any spending transaction must be signed by both A and B to be valid|,Non-data,56
| Since B will only endorse transactions that send funds to him, B is protected from attempts by A to send funds to another party (or back to herself), ie, B is protected from double-spending attempts Paying Through the Channel|,Non-data,56
| The channel has an asso- ciated state b that specifies how many of the B d have been paid so far to B In the beginning, b = 0, ie, all money in the channel belongs to A and none belongs to B|,Non-data,56
| To pay through the channel, ie, to raise b to b0, A creates an ordinary Bitcoin transaction that sends B b0 fron the deposit to B She signs this transaction with her secret key sk A, and sends the transaction to B, who validates the transaction and the correctness of the signature|,Non-data,56
| However, the transaction is not yet signed by B or published to the Bitcoin network Closing the Channel The channel has to be closed before time T  If B wants to close the channel at some state ˆb, he sends the most recently received transaction, i|,Non-data,56
|e, the one with the value ˆb, to the Bitcoin network Once the network confirms the transaction, B has received Bˆb If B does not close the channel by time T , e|,Non-data,56
|g, as B has disappeared, A can claim the whole channel of value B d 4 ACCOUNTABLE ASSERTIONS In this section we introduce accountable assertions|,Non-data,56
| In- tuitively, this primitive allows users to assert statements in contexts such that users can be held accountable for equiv- ocation: On the one hand, if the user asserts two different statements st0 6= st1 in the same context ct, then a public algorithm can extract the secret key ask of the user from the two assertions On the other hand, secrecy of the secret key ask remains intact for a well-behaved non-equivocating user Accountable assertions are supposed to be attached to other public-key primitives, ie|,Non-data,56
|, the key pairs are supposed to correspond to key pairs of the other primitive For example, the key pairs of our scheme will be valid ECDSA key pairs as used in Bitcoin Attaching accountable assertions to other primitives is crucial in practice because the concrete secret key used in accountable assertions needs to be worth something, eg|,Non-data,56
|, for redeeming funds Otherwise, the user has no incentive to keep it secret in the first place Definition 1 (Accountable Assertions) An ac- countable assertion scheme Π is a tuple of ppt algorithms Π = (Gen, Assert, Verify, Extract) as follows: • (apk, ask, auxsk) ← Gen(1λ): The key generation algo- rithm outputs a key pair consisting of a public key apk and a secret key ask, and auxiliary secret information auxsk|,Non-data,56
| It is required that for each public key, there is exactly one secret key, ie, for all λ and all outputs (apk, ask) and (apk0, ask0) of Gen(1λ) with apk = apk0, we have ask = ask0 • τ /⊥ ← Assert(ask, auxsk, ct, st): The stateful assertion algorithm takes as input a secret key ask, auxiliary secret in- formation auxsk, a context ct, and a statement st|,Non-data,56
| It returns either an assertion τ or ⊥ to indicate failure • b ← Verify(apk, ct, st, τ): The verification algorithm out- puts 1 if and only if τ is a valid assertion of a statement ct in the context st under the public key apk • ask/⊥ ← Extract(apk, ct, st0, st1, τ0, τ1): The extraction algorithm takes as input a public key apk, a context ct, two statements st0, st1, and two assertions τ0, τ1 It outputs either the secret key ask or ⊥ to indicate failure|,Non-data,56
| The accountable assertion scheme Π is correct if for all se- curity parameters λ, all keys (apk, ask, auxsk) ← Gen(1λ), all statements st, all contexts ct, and all assertions τ 6= ⊥ result- ing from a successful assertion τ ← Assert(ask, auxsk, ct, st), we have Verify(apk, ct, st, τ) = 1 In case of equivocation, only the secret key ask will be guar- anteed to be extractable, but not the auxiliary secret infor- mation auxsk Completeness Our definition of accountable assertions allows the assertion algorithm to fail|,Non-data,56
| We do not consider such failure a problem if it happens only with small (but not necessarily negligible) probability, because failure hurts only the liveness of the system that makes use of the accountable assertions However, liveness is typically not guaranteed anyway due to unreliable networks As a consequence, we do not insist generally on accountable assertions fulfilling a completeness criterion At first glance, this might look a bit contrived, but the purpose of this is to trade off reliability against efficiency|,Non-data,56
| Accountable assertions are, unlike signatures, not required to be unforgeable, and it turns out that setting unforgeability aside will enable a more efficient construction To understand how failing and unforgeability are related, suppose an attacker asks a user to assert a statement st0 in a context ct0, ie, to output τ0 ← Assert(ask, auxsk, ct0, st0)|,Non-data,56
| Due to the lack of unforgeability, the attacker might use τ0 to obtain another assertion τ1 that is valid for some related but different context ct1 6= ct0 and the same statement st0 So far, this is not a problem: the attacker cannot use the extraction algorithm to obtain the secret key ask from τ0 and τ1, because the two assertions are valid in different contexts ct0 6= ct1 However, the attacker can now ask the user to assert another statement st1 6= st0 in the context 2221, τ1, τ0 1 ← Assert(ask, auxsk, ct1, st1) Observe ct1, i|,Non-data,56
|e, to output τ0 that this is a valid request: the attacker does not ask the user to equivocate because the user has not asserted any statement in the context ct1 so far But if the user replied to the request, the attacker could run the extraction algorithm Extract(apk, ct1, st1, st0 1) to extract the secret key ask To avoid this attack, while allowing for a construction that is “forgeable” as just described, the stateful assertion algorithm may fail if it detects that the context ct1, for which an assertion is requested, is related to a previously used context ct0|,Non-data,56
| Nevertheless, the ability of the attacker to force failure may be a problem in certain scenarios, eg, if it allows the attacker to perform a denial-of-service attack In those cases, it is possible to consider complete accountable assertions, which are guaranteed to succeed on all honestly chosen inputs|,Non-data,56
| Definition 2 (Completeness) An accountable asser- tion scheme Π = (Gen, Assert, Verify, Extract) is complete if for all security parameters λ, all key pairs (apk, ask) output by Gen(1λ), all statements st, and all contexts ct, we have Assert(ask, auxsk, ct, st) 6= ⊥ Note that the definition of accountable assertions additionally demands correctness whenever Assert(ask, auxsk, ct, st) 6= ⊥ 4|,Non-data,56
|1 Security of Accountable Assertions Accountable assertions need to fulfill two security proper- ties The first security property is extractability, which states that whenever two distinct statements have been asserted in the same context, the secret key can be extracted Definition 3 (Extractability) An accountable as- sertion scheme Π = (Gen, Assert, Verify, Extract) is extractable if for all ppt attackers A, Pr[Extract(apk, ct, st0, st1, τ0, τ1) 6= ask ∧ ∀b ∈ {0, 1}, Verify(apk, ct, stb, τb) = 1 ∧ st0 6= st1 : (apk, ct, st0, st1, τ0, τ1) ← A(1λ)] is negligible in λ|,Non-data,56
| Here, ask is the unique secret key corre- sponding to apk The second security property secrecy is opposed to ex- tractability Secrecy prevents the extraction of the secret key against an attacker who can ask the challenger to assert chosen statements in chosen contexts Since accountable assertions are extractable, the attacker’s success is excluded after requesting the assertion of two different statements in the same context|,Non-data,56
| Definition 4 (Secrecy) An accountable assertion scheme Π = (Gen, Assert, Verify, Extract) is secret if for all ppt attackers A, the probability that the experiment SecΠA(λ) returns 1 is negligible in λ, where the experiment SecΠA(λ) is defined as follows Experiment SecΠA(λ) ∧ ((cid:64)ct, st0, st1 st0 6= st1 ∧ {(ct, st0), (ct, st1)} ⊆ Q) (apk, ask, auxsk) ← Gen(1λ) Q := ∅ ask∗ ← AAssert00(ask,auxsk,·,·)(apk) return 1 iff ask∗ = ask Oracle Assert00(ask, auxsk, ct, st) Q := Q ∪ {(ct, st)} return Assert(ask, ask, ct, st) Limitations of the Secrecy Definition|,Non-data,56
| Recall that a secret key used with accountable assertions must be worth something, eg, a valid ECDSA secret key that protects funds in Bitcoin We would like to draw the reader’s attention to the fact that the definition of secrecy does not take into account the other usages of the secret key|,Non-data,56
| That is, while our secrecy definition of accountable assertions is meaningful in itself, it is only a heuristic for analyzing their security when combined with other primitives, and it is formally not guaranteed that the use of secret accountable assertions keeps the security of the other primitives intact2 While we are confident that the combined use of our accountable assertions construction (Section 5) together with ECDSA does not render ECDSA insecure in practice, a more formal treatment of the composability of accountable assertions with other properties is desirable We leave this for future work Relation to DAPS|,Non-data,56
| Double-authentication-preventing sig- natures (DAPS) [38] have similar properties as accountable assertions, but are additionally required to be unforgeable We have discussed an informal relation between the unforge- ability of accountable assertions and their completeness This intuition can be formalized, and it turns out that a slightly modified variant of our accountable assertions construction (Section 5) and is an efficient DAPS scheme We refer the reader to Appendix A for a discussion|,Non-data,56
| 5 CONSTRUCTION AND ANALYSIS In this section, we propose a construction of accountable assertions based on chameleon hash functions Our construc- tion builds upon the idea of chameleon authentication trees (CATs), as suggested by Schröder and Schröder [42] and improved in followup schemes [31, 43] As opposed to these schemes, the novelty of our construction is the extractability|,Non-data,56
| Chameleon Hashes A chameleon hash function is a ran- domized hash function that is collision-resistant but provides a trapdoor to efficiently compute collisions [30] Formally, a chameleon hash function CH is a tuple of ppt algorithms (GenCh, Ch, Col) The key generation algorithm GenCh(1λ) returns a key pair (cpk, csk) consisting of a public key cpk and a trapdoor csk|,Non-data,56
| The evaluation function Ch(cpk, x; r) produces a hash value for a message x and a random value r; we typically write just Ch(x; r) when cpk is clear from the context The collision-finding algorithm Col(csk, x0, r0, x1) takes as input a trapdoor csk and a triple (x0, r0, x1); it outputs some value r1 such that Ch(x0; r0) = Ch(x1; r1) Chameleon hash functions need to fulfill collision-resistance and uniformity as defined by Krawczyk and Rabin [30] In addition to these standard security properties, we re- quire the trapdoor to be extractable from a collision|,Non-data,56
| While this extractability is typically considered a problem [3, 18, 42], it turns out to be a crucial requirement for our construction Definition 5 (Chameleon Hash Extractability) A chameleon hash function CH = (GenCh, Ch, Col) with unique keys is extractable if there exists a polynomial-time algorithm ExtractCsk with the following property: For all key pairs (cpk, csk) output by GenCh, and for all input pairs 2Indeed, given an unforgeable signature scheme and a secret accountable assertion scheme, one can construct a pathologi- cal unforgeable signature scheme that is insecure when f(ask) is leaked for a one-way function f, and one can construct a secure accountable assertion scheme that leaks f(ask) 223A1,1, B1,1, C1,1 A2,1, B2,1, C2,1 A2,2, B2,2, C2,2 A2,3, B2,3, C2,3 A3,4, B3,4, C3,4 A3,5, B3,5, C3,5 A3,6, B3,6, C3,6 Figure 1: A tree as in our construction (x0, r0) and (x1, r1) with x0 6= x1 and Ch(x0; r0) = Ch(x1; r1), we have ExtractCsk(cpk, x0, r0, x1, r1) = csk|,Non-data,56
| 51 Intuition First Approach One obvious but flawed approach to construct accountable assertions is to let the assertion al- gorithm output a random value r such that ct = Ch(st; r) The intuition is that if the attacker does this for two dif- ferent statements st0, st1 in the same context ct, then this would yield a collision Ch(st0; r0) = ct = Ch(st1; r1) in the chameleon hash function, and one could extract the trapdoor|,Non-data,56
| This simple idea does not work: ct would live in the output space of the chameleon hash function, but in most of the chameleon hash functions, the trapdoor can only be used to find collisions efficiently, not to invert the function Full Idea Observe that the aforementioned approach works, however, as a scheme that supports only one assertion in an arbitrary but fixed context, for which inverting the chameleon hash is not necessary If the public key of the accountable assertions scheme includes Ch(x∗; r∗) for randomly chosen x∗ and r∗, then one can use the trapdoor to compute r as an assertion for a statement st such that Ch(x∗; r∗) = Ch(st; r)|,Non-data,56
| The basic idea of our construction is to generalize this ap- proach to many contexts by applying it recursively, resulting in a Merkle-style tree based on chameleon hash functions The contexts are associated with the leafs of the tree, and a digest of the root node is part of the public key Let n denote the arity and ‘ denote the depth of the tree We explain the main steps with the help of Fig|,Non-data,56
| 1 for n = 3 In our construction (a digest of) the context defines its position in the tree That is, the context with the lowest digest is stored in the leftmost leaf and the context with the highest digest in the rightmost node Since the tree is of exponential size, storing or computing the entire tree at once is not possible|,Non-data,56
