 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| Based on these conditions, we introduce staged commit, a secure scheduling protocol for federated transactions This proto- col avoids insecure information channels by dividing transactions into distinct stages We implement a compiler that statically checks code to ensure it meets our conditions, and a system that schedules these transactions using the staged commit protocol Experiments on this implementation demonstrate that realistic federated transac- tions can be scheduled securely, atomically, and efficiently|,Non-data,86
| 1 INTRODUCTION Many modern applications are distributed, operating over data from multiple domains Distributed protocols are used by applica- tions to coordinate across physically separate locations, especially to maintain data consistency However, distributed protocols can leak confidential information unless carefully designed otherwise|,Non-data,86
| Distributed applications are often structured in terms of transac- tions, which are atomic groups of operations For example, when ordering a book online, one or more transactions occur to ensure that the same book is not sold twice, and to ensure that the sale of a book and payment transfer happen atomically Transactions are ubiquitous in modern distributed systems Implementations include Google’s Spanner [11], Postgres [29], and Microsoft’s Azure Stor- age [9]|,Non-data,86
| Common middleware such as Enterprise Java Beans [26] and Microsoft NET [1] also support transactions Many such transactions are distributed, involving multiple au- tonomous participants (vendors, banks, etc)|,Non-data,86
| Crucially, these par- ticipants may not be equally trusted with all data Standards such as X/Open XA [2] aim specifically to facilitate transactions that span Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita- tion on the first page Copyrights for components of this work owned by others than ACM must be honored Abstracting with credit is permitted|,Non-data,86
| To copy otherwise, or re- publish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acmorg CCS’16, October 24–28, 2016, Vienna, Austria © 2016 ACM|,Non-data,86
 ISBN 978-1-4503-4139-4/16/10   $15,Non-data,86
00 DOI: http://dxdoiorg/101145/2976749,Non-data,86
|2978415 multiple systems, but none address information leaks inherent to transaction scheduling Distributed transaction implementations are often based on the two-phase commit protocol (2PC) [17] We show that 2PC can cre- ate unintentional channels through which private information may be leaked, and trusted information may be manipulated We expect our results apply to other protocols as well|,Non-data,86
| There is a fundamental tension between providing strong consis- tency guarantees in an application and respecting the security re- quirements of the application’s trust domains This work deepens the understanding of this trade-off and demonstrates that providing both strong consistency and security guarantees, while not always possible, is not a lost cause Concretely, we make the following contributions in this paper: • We describe abort channels, a new kind of side channel through which confidential information can be leaked in transactional systems (§2) • We demonstrate exploitation of abort channels on a distributed system (§2|,Non-data,86
|3) • We define an abstract model of distributed systems, trans- actions, and information flow security (§ 3), and introduce relaxed observational determinism, a noninterference-based security model for distributed systems (§371)|,Non-data,86
| • We establish that within this model, it is not possible for any protocol to securely serialize all sets of transactions, even if the transactions are individually secure (§4) • We introduce and prove a sufficient condition for ensuring serializable transactions can be securely scheduled (§5) • We define the staged commit protocol, a novel secure schedul- ing protocol for transactions meeting this condition (§6) • We implement our novel protocol in the Fabric system [24], and extend the Fabric language and compiler to statically en- sure transactions will be securely scheduled (§7)|,Non-data,86
| • We evaluate the expressiveness of the new static checking discipline and the runtime overhead of the staged commit protocol (§8) We discuss related work further in § 9, and conclude in § 10 For brevity, we present proof sketches of the results in this paper; full proofs can be found in the technical report [34] 2|,Non-data,86
| ABORT CHANNELS Two transactions working with the same data can conflict if at least one of them is writing to the data Typically, this means that one (or both) of the transactions has failed and must be aborted 229Rainforest order order Gloria purchase purchase d e b it d e bit Fred Figure 1: Rainforest example Gloria and Fred each buy an Outel chip via Rainforest’s store|,Non-data,86
| Gloria’s transaction is in red, dashed arrows; Fred’s is in blue, solid arrows In many transaction protocols, including 2PC, a participant1 in- volved in both transactions can abort a failed transaction by send- ing an abort message to all other participants in the failed transac- tion [17] These abort messages can create unintended abort chan- nels, through which private information can be leaked, and trusted information can be manipulated An abort message can convey secret information if a participant aborts a transaction otherwise likely to be scheduled, because an- other participant in the same transaction might deduce something about the aborting participant|,Non-data,86
| For example, that other partici- pant might guess that the abort is likely caused by the presence of another—possibly secret—conflicting transaction Conspirators might deliberately use abort channels to covertly transfer information within a system otherwise believed to be se- cure Although abort channels communicate at most one bit per (attempted) transaction, they could be used as a high-bandwidth covert channel for exfiltration of sensitive information Current transactional systems can schedule over 100 million transactions per second, even at modest system sizes [15]|,Non-data,86
| It is difficult to know if abort channels are already being exploited in real systems, but large-scale, multi-user transactional systems such as Spanner [11] or Azure Storage [9] are in principle vulnerable Abort messages also affect the integrity of transaction schedul- ing An abort typically causes a transaction not to be scheduled Even if the system simply retries the transaction until it is sched- uled, this still permits a participant to control the ordering of trans- actions, even if it has no authority to affect them|,Non-data,86
| For example, a participant might gain some advantage by ensuring that its own transactions always happen after a competitor’s Transactions can also create channels that leak information based on timing or termination [5, 8] We treat timing and termination channels as outside the scope of this work, to be handled by mech- anisms such as timing channel mitigation [22, 4, 7] Abort channels differ from these previously identified channels in that information leaks via the existence of explicit messages, with no reliance on timing other than their ordering|,Non-data,86
| Timing mitigation does not con- trol abort channels 21 Rainforest Example A simple example illustrates how transaction aborts create a chan- nel that can leak information Consider a web-store application for the fictional on-line retailer Rainforest, illustrated in Fig|,Non-data,86
| 1 Rain- forest’s business operates on data from suppliers, customers, and banks Rainforest wants to ensure that it takes money from cus- tomers only if the items ordered have been shipped from the sup- pliers As a result, Rainforest implements purchasing using serial- izable transactions|,Non-data,86
| Customers expect that their activities do not in- fluence each other, and that their financial information is not leaked 1Transaction participants are often processes or network nodes r0 r1 Rainforest b1 b0 Gloria r2 r3 b2 b3 Fred r4 b4 r5 b5 Figure 2: The events of the transactions in Fig 1 Gloria’s trans- action consists of r0, r1, r2, r3, r4, and r5|,Non-data,86
| Bob’s consists of b0, b1, b2, b3, b4, and b5 Happens-before ((cid:95)) relationships are ar- rows The shaded blocks around events indicate locations, and are labeled with participants from Fig 1|,Non-data,86
| to suppliers These expectations might be backed by law In Fig 1, Gloria and Fred are both making purchases on Rain- forest at roughly the same time|,Non-data,86
| They each purchase an Outel chip, and pay using their accounts at CountriBank If Rainforest uses 2PC to perform both of these transactions, it is possible for Gloria to see an abort when Outel tries to schedule her transaction and Fred’s The abort leaks information about Fred’s purchase at Outel to Gloria Alternatively, if Gloria is simultane- ously using her bank account in an unrelated purchase, scheduling conflicts at the bank might leak to Outel, which could thereby learn of Gloria’s unrelated purchase|,Non-data,86
| These concerns are about confidentiality, but transactions may also create integrity concerns The bank might choose to abort transactions to affect the order in which Outel sells chips Rain- forest and Outel may not want the bank to have this power 2|,Non-data,86
|2 Hospital Example As a second, running example, we use two small programs with an abort channel Suppose Patsy is a trusted hospital employee, running the code in Fig 3a to collect the addresses of HIV-positive patients in order to send treatment reminders Patsy runs her trans- action on her own computer, which she fully controls, but it in- teracts with a trusted hospital database on another machine|,Non-data,86
| Patsy starts a transaction for each patient p, where transaction blocks are indicated by the keyword atomic If p does not have HIV, the transaction finishes immediately Fig 3c shows the resulting trans- action in solid blue|,Non-data,86
| (Events in the transaction are represented as ovals; arrows represent dependencies between transaction events) Otherwise, if the patient has HIV, Patsy’s transaction reads the pa- tient’s address and prints it (the blue transaction in Fig 3c, includ- ing dashed events) Suppose Mallory is another employee at the same hospital, but is not trusted to know each patient’s HIV status|,Non-data,86
| Mallory is, however, trusted with patient addresses Like Patsy, Mallory’s code runs on her own computer, which she fully controls, but interacts with the trusted hospital database on another machine She runs the code in Fig 3b to update each patient’s address in a separate transaction, resulting in the red transaction in Fig|,Non-data,86
| 3c When Mallory updates the address of an HIV-positive patient, her transaction might con- flict with one of Patsy’s, and Mallory would observe an abort Thus Mallory can learn which patients are HIV-positive by updating each patient’s address while Patsy is checking the patients’ HIV statuses Each time one of Mallory’s transactions aborts, private information leaks: that patient has HIV|,Non-data,86
| One solution to this problem is to change Patsy’s transaction: instead of reading the address only if the patient is HIV positive, $$230Read HIV Print address Read HIV Print address x = paddress(cid:105); 1 atomic { 2 (cid:104)h = phasHiv(cid:107) 3 4 if (h) { 5 6 } 7 } print(x); High Security (H) Low Security (L) Update address ? Mallory start 1 atomic { 2 h = phasHiv; 3 if (h) { 4 5 6 } 7 } x = p|,Non-data,86
|address; print(x); Read address Patsy start (c) Resulting transactions (a) Patsy’s code 1 atomic { 2 paddress+="␣"; 3 } (b) Mallory’s code Figure 3: Insecure hospital scenario Patsy runs a program (3a) for each patient p If p has HIV (which is private information), she prints out p’s address for her records|,Non-data,86
| The resulting transaction takes one of two forms Both begin with the event Patsy start If p is HIV negative, the transaction ends with Read HIV Otherwise, it includes the blue events with dashed outlines|,Non-data,86
| Meanwhile, Mallory updates the p’s (less secret) address (3b), resulting in the transac- tion with red, solid-bordered events This conflicts with Patsy’s transaction, requiring the system to order the update and the read, exactly when p has HIV (“?” in 3c) Patsy reads every patient’s address This illustrates a core goal of our work: identifying which programs can be scheduled securely|,Non-data,86
| In Fig 4a, lines 3 and 4 of Patsy’s code have been switched As Fig 4c shows, both possible transactions read the patient’s address|,Non-data,86
| Since Mallory cannot distinguish which of Patsy’s transactions has run, she cannot learn which patients have HIV 23 Attack Demonstration Using code resembling Fig 3, we implemented the attack de- scribed in our hospital example (§2|,Non-data,86
|2) using the Fabric distributed system [3, 24] We ran nodes representing Patsy and Mallory, and a storage node for the patient records To improve the likelihood of Mallory conflicting with Patsy (and thereby receiving an abort), we had Patsy loop roughly once a sec- ond, continually reading the address of a single patient after veri- fying their HIV-positive status Meanwhile, Mallory attempted to update the patient’s address with approximately the same frequency as Patsy’s transaction|,Non-data,86
| Like many other distributed transaction systems, Fabric uses two- phase commit Mallory’s window of opportunity for receiving an abort exists between the two phases of Patsy’s commit, which ordi- narily involves a network round trip However, both nodes were run on a single computer To model a cloud-based server, we simulated a 100 ms network delay between Patsy and the storage node|,Non-data,86
| We ran this experiment for 90 minutes During this time, Mal- lory received an abort roughly once for every 20 transactions Patsy attempted As a result, approximately every 20 seconds, Mallory learned that a patient had HIV In principle, many such attacks could be run in parallel, so this should be seen as a minimal, rather than a maximal, rate of information leakage for this setup|,Non-data,86
| As described later, our modified Fabric compiler (§ 7) correctly rejects Patsy’s code We amended Patsy’s code to reflect Fig 4, and our implementation of the staged commit protocol (§ 6) was able to schedule the transactions without leaking information Mallory was no more or less likely to receive aborts regardless of whether the patient had HIV|,Non-data,86
| 3 SYSTEM MODEL We introduce a formal, abstract system model that serves as our framework for developing protocols and proving their security prop- erties Despite its simplicity, the model captures the necessary fea- High Security (H) Low Security (L) Update address ? Read address Patsy start (a) Patsy’s code 1 atomic { 2 paddress+="␣"; 3 } (b) Mallory’s code Figure 4: Secure hospital scenario|,Non-data,86
| A secure version of Fig 3, in which lines 3 and 4 of Patsy’s code (3a) are switched, and the resulting lines 2 and 3 can be run in parallel ((cid:104) (cid:107) (cid:105)) Thus the trans- action reads p’s address regardless of whether p has HIV, and so Mallory cannot distinguish which form Patsy’s transaction takes (c) Resulting transactions Mallory start tures of distributed transaction systems and protocols|,Non-data,86
| As part of this model, we define what it means for transactions to be serializ- able and what it means for a protocol to serialize transactions both correctly and securely 31 State and Events Similarly to Lamport [23], we define a system state to include a finite set of events, representing a history of the system up to a moment in time An event (denoted e) is an atomic native action that takes place at a location, which can be thought of as a physical computer on the network|,Non-data,86
| Some events may represent read oper- ations (“the variable x had the value 3”), or write operations (“2 was written into the variable y”) In Figures 3 and 4, for example, events are represented as ovals, and correspond to lines of code Also part of the system state is a causal ordering on events Like Lamport’s causality [23], the ordering describes when one event e1 causes another event e2|,Non-data,86
| In this case, we say e1 happens before e2, written as e1(cid:95)e2 This relationship would hold if, for example, ((cid:95)) is a strict partial order: irreflexive, asymmetric, and transitive Therefore, e1(cid:95)e2 and e2(cid:95)e3 together imply e1(cid:95)e3 e1 is the sending of a message, and e2 its receipt|,Non-data,86
| The ordering The arrows in Figures 2 to 4 show happens-before relationships for the transactions involved 32 Information Flow Lattice We extend Lamport’s model by assigning to each event e a se- curity label, written (cid:96)(e), which defines the confidentiality and in- tegrity requirements of the event Events are the most fine-grained unit of information in our model, so there is no distinction between the confidentiality of an event’s occurrence and that of its contents|,Non-data,86
| Labels in our model are similar to high and low event sets [30, 10] In Figures 3 and 4, two security labels, High and Low (H and L for short), are represented by the events’ positions relative to the dashed line For generality, we assume that labels are drawn from a lattice [12], depicted in Fig 5|,Non-data,86
| Information is only permitted to flow upward in the lattice We write “(cid:96)(e1) is below (cid:96)(e2)” as (cid:96)(e1)(cid:118)(cid:96)(e2), mean- ing it is secure for the information in e1 to flow to e2 For instance, in Fig 3, information should not flow from any events labeled H to any labeled L|,Non-data,86
| Intuitively, we don’t want secret information to determine any non-secret events, because unautho- rized parties might learn something secret However, information can flow in the reverse direction: reading the patient’s address (la- beled L) can affect Patsy’s printout (labeled H): L (cid:118) H Like events, each location has a label, representing a limit on events with which that location can be trusted No event should 231secret untrusted secret trusted public untrusted C A B (cid:118) inte grity public trusted confidentiality Figure 5: Security lattice: The dot represents a label in the lattice, and the dashed lines divide the lattice into four quadrants relative to this label|,Non-data,86
| If the label represents an event, then only events with labels in quadrant B may influence this event, and this event may only influence events with labels in quadrant A If the label rep- resents a location, then only events with labels in quadrant C may occur at that location have more integrity than its location Similarly, no event should be too secret for its location to know|,Non-data,86
| Thus, in Fig 5, only events to the left of a location’s label (ie, region C in the figure) may take place at that location|,Non-data,86
| For example, consider Gloria’s payment event at CountriBank in the Rainforest example Fig 1 This event (r5 in Fig 2) represents money moving from Gloria’s account to Outel’s|,Non-data,86
| The label (cid:96) of r5 should not have any more integrity than CountriBank itself, since the bank controls r5 Likewise, the bank knows about r5, so (cid:96) cannot be more confidential than the CountriBank’s label This would put (cid:96) to the left of the label representing CountriBank in the lattice of Fig 5|,Non-data,86
| Our prototype implementation of secure transactions is built us- ing the Fabric system [24], so the lattice used in the implementation is based on the Decentralized Label Model (DLM) [27] However, the results of this paper are independent of the lattice used 33 Conflicts Two events in different transactions may conflict|,Non-data,86
| This is a prop- erty inherent to some pairs of events Intuitively, conflicting events are events that must be ordered for data to be consistent For exam- ple, if e1 represents reading variable x, and e2 represents writing x, then they conflict, and furthermore, the value read and the value written establish an ordering between the events Likewise, if two events both write variable x, they conflict, and the system must decide their ordering because it affects future reads of x|,Non-data,86
| In our hospital example (Figures 3 and 4), the events Read ad- dress and Update address conflict Specifically, the value read will change depending on whether it is read before or after the update Thus for any such pair of events, there is a happens-before ((cid:95)) ordering between them, in one direction or the other We assume that conflicting events have the same label|,Non-data,86
| This as- sumption is intuitive in the case of events that are reads and writes to the same variable (that is, storage location) Read and write op- erations in separate transactions could have occurred in either or- der, so the happens-before relationship between the read and write events cannot be predicted in advance Our notion of conflict is meant to describe direct interaction be- tween transactions Hence, we also assume any conflicting events happen at the same location|,Non-data,86
| r2 r0 b1 p r1 b2 b0 Figure 6: An example system state The events r0, r1, and r2 form transaction R, and the events b0, b1, and b2 form transaction B Event p is not part of either transaction It may be an input, such as a network delay event, or part of a protocol used to schedule the transactions|,Non-data,86
| In this state, r1(cid:95)p(cid:95)b1, which means that r1 happens before b1, and so the transactions are ordered: R(cid:95)B 34 Serializability and Secure Information Flow Traditionally a transaction is modeled as a set of reads and writes to different objects [28] We take a more abstract view, and model a transaction as a set of events that arise from running a piece of code|,Non-data,86
| Each transaction features a start event, representing the decision to execute the transaction’s code Start events, by definition, happen before all others in the transaction Multiple possible transactions can feature the same start event: the complete behavior of the trans- action’s code is not always determined when it starts executing, and may depend on past system events Fig|,Non-data,86
| 4c shows two possible transactions, in blue, that can result from running the secure version of Patsy’s code They share the three events in solid blue, including the start event (Patsy start); one transaction contains a fourth event, Print address The figure also shows in red the transaction resulting from Mallory’s code Fig|,Non-data,86
| 6 is a more abstract example, in which r0 is the start event of transaction R, and b0 is the start event of transaction B In order to discuss what it means to serialize transactions, we need a notion of the order in which transactions happen We obtain this ordering by lifting the happens-before relation on events to a tion T2 directly depends on T1, written T1 ≺ T2, if an event in T1 happens before an event in T2: happens-before ((cid:95)) relation for transactions We say that transac- T1 ≺ T2 ≡ T1 (cid:54)= T2 ∧ ∃e1 ∈ T1, e2 ∈ T2 |,Non-data,86
| e1(cid:95)e2 closure of this direct dependence relation ≺ Thus, in Fig 6, the The happens-before relation on transactions ((cid:95)) is the transitive ordering R(cid:95)B holds Likewise, Fig|,Non-data,86
| 7 is a system state featur- Patsy(cid:95)Mallory holds ing the transactions from our hospital example (Fig 4), in which DEF 1 (SERIALIZABILITY)|,Non-data,86
 Transactions are serializable ex- actly when happens-before is a strict partial order on transactions ordering would represent a serial order of transactions Any total order consistent with this strict partial order would then respect the happens-before ordering ((cid:95)) of events Such a total formation-flow secure if happens-before ((cid:95)) relationships between (SECURE INFORMATION FLOW),Non-data,86
| A transaction is in- transaction events—and therefore causality—are consistent with permitted information flow: DEF 2 e1(cid:95)e2 =⇒ (cid:96)(e1)(cid:118)(cid:96)(e2) This definition represents traditional information flow control within each transaction Intuitively, each transaction itself can- not cause a security breach (although this definition says noth- ing about the protocol scheduling them) In our hospital example, 232Read HIV Print address High Security Low Security Mallory releases lock Update address Mallory acquires lock Patsy releases lock Read address Patsy acquires lock Patsy start Mallory start Figure 7: A possible system state after running transactions from Fig|,Non-data,86
| 4c, assuming the patient has HIV, and an exclusive lock is used to order the transactions (Events prior to everything in both trans- actions are not shown) Because Patsy acquires the lock first, the transactions are ordered Patsy(cid:95)Mallory While each transaction is information-flow secure (a property of events within a transac- tion), when Patsy releases the lock after her transaction, a high se- curity event happens before a low security one|,Non-data,86
| We discuss secure scheduling protocols in §6 Patsy’s transaction in Fig 3c is not information-flow secure, since Read HIV happens before Read address, and yet the label of Read HIV, H, does not flow to the label of Read address, L However, in the modified, secure version (Fig|,Non-data,86
| 4c), there are no such insecure happens-before relationships, so Patsy’s transaction is secure 35 Network and Timing Although this model abstracts over networks and messaging, we consider a message to comprise both a send event and a receive event We assume asynchronous messaging: no guarantees can be made about network delay|,Non-data,86
| Perhaps because this popular assump- tion is so daunting, many security researchers ignore timing-based attacks There are methods for mitigating leakage via timing chan- nels [22, 4, 7] but in this work we too ignore timing To model nondeterministic message delay, we introduce a net- work delay event for each message receipt event, with the same label and location The network delay event may occur at any time after the message send event|,Non-data,86
| It must happen before ((cid:95)) the cor- responding receipt event In Fig 6, event r1 could represent send- ing a message, event p could be the corresponding network delay event, which is not part of any transaction, and event b1 could be the message receipt event Fig|,Non-data,86
| 6 does not require p to be a network delay event It could be any event that is not part of either transac- tion For example, it might be part of some scheduling protocol 3|,Non-data,86
|6 Executions, Protocols, and Inputs An execution is a start state paired with a totally ordered se- quence of events that occur after the start state This sequence must be consistent with happens-before ((cid:95)) Recall that a system state is a set of events (§31)|,Non-data,86
| Each event in the sequence therefore cor- responds to a system state containing all the events in the start state, and all events up to and including this event in the sequence View- ing an execution as a sequence of system states, an event is sched- uled if it is in a state, and once it is scheduled, it will be scheduled in all later states Two executions are equivalent if their start states are equal, and their sequences contain the same set of events, so they finish with equal system states (same set of events, same(cid:95)) A full execution represents the entire lifetime of the system, so its start state contains no events|,Non-data,86
| For example, Fig 8 illustrates two equivalent full executions ending in the system state from Fig 6 A transaction scheduling protocol determines the order in which each location schedules the events of transactions|,Non-data,86
| Given a set of possible transactions, a location, and a set of events representing a system state at that location, a protocol decides which event is scheduled next by the location: protocol : set(cid:104)Transactions(cid:105) × Location × State → event Protocols can schedule an event from a started (but unfinished) transaction, or other events used by the protocol itself In order to schedule transaction events in ways that satisfy certain constraints, like serializability, protocols may have to schedule additional events, which are not part of any transaction These can include message send and receipt events For example, in Fig|,Non-data,86
| 7, the locking events are not part of any transaction, but are scheduled by the protocol in order to ensure serializability Certain kinds of events are not scheduled by protocols, because they are not under the control of the system Events representing external inputs, including the start events of transactions, can hap- pen at any time: they are fundamentally nondeterministic We also treat the receive times of messages as external inputs|,Non-data,86
| Each mes- sage receive event is the deterministic result of its send event and of a nondeterministic network delay event featuring the same secu- rity label as the receive event We refer to start and network delay events collectively as nondeterministic input events (NIEs) Protocols do not output NIEs Instead, an NIE may appear at any point in an execution, and any prior events in the execution can happen before ((cid:95)) the NIE|,Non-data,86
| Recall that an execution features a sequence of events, each of which can be seen as a system state featuring all events up to that point An execution E is consistent with a protocol p if every event in the sequence is either an NIE, or the result of p applied to the previous state at the event’s location We sometimes say p results in E to mean “E is consistent with p” As an example, assume all events in Fig|,Non-data,86
| 6 have the same location L, and no messages are involved Start events r0 and b0 are NIEs Every other event has been scheduled by a protocol Fig|,Non-data,86
| 8 shows two different executions, which may be using different protocols, determining which events to schedule in each state We can see that in the top execution of Fig 8, the protocol maps: {R, B,  |,Non-data,86
| }, L,{r0} (cid:55)→ r1 {R, B,   |,Non-data,86
|}, L,{r0, r1} (cid:55)→ r2 {R, B,   }, L,{r0, r1, r2, b0} (cid:55)→ p {R, B, |,Non-data,86
|  }, L,{r0, r1, r2, b0, p} (cid:55)→ b1 {R, B,  |,Non-data,86
| }, L,{r0, r1, r2, b0, p, b1} (cid:55)→ b2 The protocol in the bottom execution of Fig 8 maps: {R, B,  |,Non-data,86
| }, L,{r0, b0} (cid:55)→ r1 {R, B,   |,Non-data,86
|}, L,{r0, b0, r1} (cid:55)→ p {R, B,   }, L,{r0, b0, r1, p} (cid:55)→ b1 {R, B, |,Non-data,86
|  }, L,{r0, b0, r1, p, b1} (cid:55)→ b2 {R, B,  |,Non-data,86
| }, L,{r0, b0, r1, p, b1, b2} (cid:55)→ r2 Ultimately, a protocol must determine the ordering of transac- tions If the exact set of start events to be scheduled (as opposed 233Event Scheduled: r0 r1 r1 r0 r2 r0 r2 r1 r1 r1 r2 r0 b0 r1 p p r1 p r2 r2 b0 r0 p r1 b1 b1 p b0 r0 b1 b1 p r1 b2 b1 p b0 b2 r2 r0 r2 b2 b1 p r1 r2 b1 p r1 r1 r1 b2 b0 b2 b0 Resulting State: Event Scheduled: Resulting State: {} {} r0 r0 b0 b0 r0 b0 r0 b0 r0 b0 r0 b0 r0 b0 r0 Figure 8: Two equivalent full executions for the system state from Fig 6|,Non-data,86
| Each begins with a start state (the empty set for full executions), followed by a sequence of events, each of which corresponds to the resulting system state to start events possible) were always known in advance, scheduling would be trivial A protocol should not require one transaction to run before another a priori: start events from any subset of pos- sible transactions may be scheduled at any time No protocol should result in a system state in which such a start event cannot be scheduled, or an incomplete transaction can never finish|,Non-data,86
| 37 Semantic Security Properties Conditioning the premise of the security condition on the indis- tinguishability of information that is allowed to be released is an idea that has been used earlier [32], but not in this way, to our knowledge also be leaked through the order or timing of start events This problem is beyond the scope of this work|,Non-data,86
| Consider an observer who can only “see” events at some security level (cid:96) or below If two states S1 and S2 are indistinguishable to the observer, then after a program runs, noninterference requires that the resulting executions remain indistinguishable to the observer Secret values, which the observer cannot see, may differ in S1 and S2, and may result in different states at the end of the executions, but the observer should not be able to see these differences 3|,Non-data,86
|71 Relaxed Observational Determinism Semantic conditions for information security are typically based on some variant of noninterference [19, 31] These variants are often distinguished by their approaches to nondeterminism How- ever, many of these semantic security conditions fail under refine- ment: if some nondeterministic choices are fixed, security is vio- lated [37]|,Non-data,86
| However, low-security observational determinism [30, 37] is a strong property that is secure under refinement: intuitively, if an observer with label (cid:96) cannot distinguish states S and S(cid:48), that observer must not be able to distinguish any execution E beginning with S from any execution E(cid:48) beginning with S(cid:48): (cid:0)S ≈(cid:96) S (cid:48)(cid:1) ⇒ E ≈(cid:96) E (cid:48) This property is too strong because it rules out two sources of non- determinism that we want to allow: first, the ability of any transac- tion to start at any time, and second, network delays Therefore, we relax observational determinism to permit certain nondeterminism We only require that executions be indistinguishable to the observer if their NIEs are indistinguishable to the observer: (cid:48) ∧ NIE(E) ≈(cid:96) NIE(cid:0)E (cid:48)(cid:1)(cid:1) ⇒ E ≈(cid:96) E (cid:0)S ≈(cid:96) S (cid:48) We call this relaxed property relaxed observational determinism It might appear to be equivalent to observational determinism, but with the NIEs encoded in the start states|,Non-data,86
| This is not the case If NIEs were encoded in the start states, protocols would be able to read which transactions will start and when messages will arrive in the future Therefore relaxed observational determinism captures something that observational determinism does not: unknowable but “allowed” nondeterminism at any point in an execution By deliberately classifying start events and network delays as in- put, we allow certain kinds of information leaks that observational determinism would not|,Non-data,86
| Specifically, a malicious network could leak information by manipulating the order or timing of message delivery However, such a network could by definition communi- cate information to its co-conspirators anyway Information can In our hospital example, as illustrated in Fig 4, the system de- termines which of Patsy’s transactions (the one with the dashed events, or the one without the dashed events) will run based on whether p|,Non-data,86
hasHiv is true We can consider phasHiv’s value to be a high-security event that happens before all reads of phasHiv,Non-data,86
| If we classify this past high-security event as input, and all low- security events as low-observable for Mallory, then we must en- sure that when Patsy’s code runs, the low-security projections of resulting executions are always the same, regardless of whether phasHiv Patsy’s possible transactions in Fig 4 allow for ob- servational determinism, while her transactions in Fig|,Non-data,86
| 3 do not, since whether or not Read address occurs depends on phasHiv Whether or not the system actually maintains observational deter- minism, however, depends on the protocol scheduling the events DEF|,Non-data,86
| 3 (PROTOCOL SECURITY) A protocol is considered se- cure if the set of resulting executions satisfies relaxed observational determinism for any allowed sets of information-flow secure trans- actions and any possible NIEs 4 IMPOSSIBILITY One of our contributions is to show that even in the absence of timing channels, there is a fundamental conflict between secure noninterference and serializability|,Non-data,86
| Previous results showing such a conflict, for example the work of Smith et al [36] consider only confidentiality and show only that timing channels are unavoidable THEOREM 1 (IMPOSSIBILITY) No secure protocol2 can se- rialize all possible sets of information-flow secure transactions|,Non-data,86
3 We assume protocols cannot simply introduce an arbitrarily trusted third party; a protocol must be able to run using only the set of locations that have events being scheduled PROOF SKETCH Consider the counterexample shown in Fig 9,Non-data,86
| Alice and Bob are both cloud computing providers who keep strict logs of the order in which various jobs start and stop Highly trusted (possibly government) auditors may review these logs, and check for consistency, to ensure cloud providers are honest and fair As 2barring unforeseen cryptographic capabilities (§41) 3In fact, what we prove is stronger|,Non-data,86
| Our proof holds for even pos- sibilistic security conditions [25], which are weaker than relaxed observational determinism (see technical report [34]) No proto- col whose resulting traces satisfy even this weaker condition can serialize all sets of information-flow secure transactions 234? r2 b2 ? r3 b3 Dave r0 r1 Bob Alice Carol b0 b1 Figure 9: Transactions that cannot be securely serialized Dave’s transaction includes r0, r1, r2, and r3|,Non-data,86
| Carol’s includes b0, b1, b2, and b3 Cloud providers Alice and Bob must decide how to order their events Alice and Bob may not influence each other, and Carol and Dave may not influence each other, as represented by the wall For these transactions to be serializable, Alice’s ordering of r2 and b2 must agree with Bob’s ordering of r3 and b3|,Non-data,86
| competitors, Alice and Bob do not want each other to gain any in- formation about their services, and do not trust each other to affect their own services Carol and Dave are presently running jobs on Alice’s cloud Both Carol and Dave would like to stop their jobs on Alice’s cloud, and start new ones on Bob’s cloud Each wants to do this atomically, effectively maintaining exactly one running job at all times|,Non-data,86
| Carol and Dave consider their jobs to be somewhat confidential; they do not want each other to know about them Unlike the example from Fig 1, Dave and Carol’s transactions do not go through a third party like Rainforest For the transactions to be serializable, Alice’s ordering of the old jobs stopping must agree with Bob’s ordering of the new jobs starting|,Non-data,86
| In any system with an asynchronous network, it is possible to reach a state in which Carol’s message to Alice has arrived, but not her message to Bob, and Dave’s message to Bob has arrived, but not his message to Alice In this state, neither Alice nor Bob can know whether one or both transactions have begun It is impossi- ble for either to communicate this information to the other without violating relaxed observational determinism Specifically, any pro- tocol that relayed such information from one cloud provider to the other would allow the recipient to distinguish the order of message delivery to the other cloud provider|,Non-data,86
| That ordering is considered se- cret input, and so this would be a security violation All executions with identical start states, and identical inputs visible to Alice, but differently ordered network delay events at Bob, which are inputs invisible to Alice, would become distinguishable to Alice 41 Cryptography This essentially information-theoretic argument does not account for the possibility that some protocol could produce computation- ally indistinguishable traces that are low-distinguishable with suffi- cient computational power (e|,Non-data,86
|g, to break encryption) However, we are unaware of any cryptographic protocols that would permit Al- ice and Bob to learn a consistent order in which to schedule events without learning each other’s confidential information 5|,Non-data,86
| ANALYSIS Although secure scheduling is impossible in general, many sets of transactions can be scheduled securely We therefore investigate which conditions are sufficient for secure scheduling, and what pro- tocols can function securely under these conditions 51 Monotonicity A relatively simple condition suffices to guarantee schedulabil- ity, while preserving relaxed observational determinism: DEF|,Non-data,86
 4 (MONOTONICITY) A transaction is monotonic if it is information-flow secure and its events are totally ordered by happens-before ((cid:95)) THEOREM 2 (MONOTONICITY ⇒ SCHEDULABILITY) A protocol exists that can serialize any set of monotonic transac- tions and preserve relaxed observational determinism,Non-data,86
| PROOF SKETCH Monotonicity requires that each event must be allowed to influence all future events in the transaction A simple, pessimistic transaction protocol can schedule such transactions se- curely In order to define this protocol, we need a notion of locks within our model|,Non-data,86
 Locks A lock consists of an infinite set of events for each al- lowed transaction A transaction acquires a lock by scheduling any event from this set It releases a lock by scheduling another event from this set,Non-data,86
| Thus, in a system state S, a transaction T holds a lock if S contains an odd number of events from the lock’s set cor- responding to T  No correct protocol should result in a state in which multiple transactions hold the same lock All pairs of events in a lock conflict, so scheduled events that are part of the same lock must be totally ordered by happens-before ((cid:95)) All events in a lock share a location, which is considered to be the location of the lock itself|,Non-data,86
| Likewise, all events in a lock share a label, which is considered to be the label of the lock itself A critical property for transaction scheduling is deadlock free- dom [17, 35], which requires that a protocol can eventually sched- ule all events from any transaction whose start event has been sched- uled A system enters deadlock when it reaches a state after which this is not the case For example, deadlock happens if a protocol re- quires two transactions each to wait until the other completes: both will wait forever|,Non-data,86
| If all transactions are finite sets of events (ie, all transactions can terminate), then deadlock freedom guarantees that a system with a finite set of start events eventually terminates, a liveness property We now describe a deadlock-free protocol that can securely se- rialize any set of monotonic transactions, and preserve relaxed ob- servational determinism: • Each event in each transaction has a corresponding lock, ex- cept start events|,Non-data,86
| • Any events that have the same label share a lock, and this lock shares a location with at least one of the events Con- flicting events are assumed to share a label (§34) • A transaction must hold an event’s lock to schedule that event|,Non-data,86
| • A transaction acquires locks in sequence, scheduling events as it goes Since all events are ordered according to a global security lattice, all transactions that acquire the same locks do so in the same order Therefore they do not deadlock • If a lock is already held, the transaction waits for it to be released|,Non-data,86
| 235• When all events are scheduled, the transaction commits, re- leasing locks in reverse order Any messages sent as part of the transaction would thus receive a reply, indicating only that the message had been received, and all its repercussions committed We call these replies commit messages • For each location, the protocol rotates between all uncommit- ted transactions, scheduling any intermediate events (such as lock acquisitions) until it either can schedule one event in the transaction or can make no progress, and then rotates to the next transaction|,Non-data,86
| Security Intuition Acquiring locks shared by multiple events on different locations requires a commit protocol between those loca- tions However, this does not leak information because all locations involved are explicitly allowed to observe and influence all events involved Therefore several known commit protocols will do, in- cluding 2PC|,Non-data,86
| Since the only messages sent as part of the protocol are commit messages, and each recipient knows it will receive a commit message by virtue of sending a message in the protocol, no information (other than timing) is transferred by the scheduling mechanism itself 52 Relaxed Monotonicity Monotonicity, while relatively easy to understand, is not the weak- est condition we know to be sufficient for secure schedulability It can be substantially relaxed|,Non-data,86
| In order to explain our weaker condi- tion, relaxed monotonicity, we first need to introduce a concept we call visibility: DEF 5 (VISIBLE-TO) An event e in transaction T is visible to a location L if and only if it happens at L, or if there exists another event e(cid:48) ∈ T at L, such that e(cid:95)e(cid:48) DEF|,Non-data,86
| 6 (RELAXED MONOTONICITY) A transaction T satis- fies relaxed monotonicity if it is information-flow secure and for each location L, all events in T visible to L happen before all events in T not visible to L In §6, we demonstrate that relaxed monotonicity guarantees schedu- lability Specifically, we present a staged commit protocol, and prove that it schedules any set of transactions satisfying relaxed monotonicity, while preserving relaxed observational determinism (Thm|,Non-data,86
| 4) 53 Requirements for Secure Atomicity Monotonicity and relaxed monotonicity are sufficient conditions for a set of transactions to be securely schedulable Some sets of transactions meet neither condition, but can be securely serialized by some protocol|,Non-data,86
| For example, any set of transactions that each happen entirely at one location can be securely serialized if each location schedules each transaction completely before beginning the next We now describe a relatively simple condition that is necessary for any set of transactions to be securely scheduled Decision Events and Conflicting Events In order to understand this necessary condition, we first describe decision events and conflicting events Borrowing some terminology from Fischer, Lynch, and Pater- son [18], for a pair of transactions T1 and T2, any system state is either bivalent or univalent|,Non-data,86
| A system state is bivalent with respect to T1 and T2 if there exist two valid executions that both include that state, but end with opposite orderings of T1 and T2 A sys- tem state is univalent with respect to T1 and T2 otherwise: for one ordering of the transactions, no valid execution ending with that ordering contains the state We can define a similar relationship for start events: for any pair of distinct start events s1 and s2, a system state is bivalent with re- spect to those events if it features in two valid executions, both of which have s1 and s2 in scheduled transactions, but those transac- tions are in opposite order A system state is univalent with respect to s1 and s2 otherwise|,Non-data,86
| All full executions (ie, those starting with an empty state) that order a pair of transactions begin in a bivalent state with respect to their start events, before either is scheduled By our definition of se- rializability and transaction ordering, once transactions are ordered, they cannot be un-ordered|,Non-data,86
| Any execution that orders the transac- tions therefore ends in a univalent state with respect to their start events Any such execution consists of a sequence of 0 or more bi- valent states followed by a sequence of univalent states The event that is scheduled in the first univalent state, in a sense, decides the ordering of the transactions We call it the decision event|,Non-data,86
| We call any event in T1 or T2 that conflicts with an event in the other transaction a conflicting event LEMMA 1 (DECISION EVENT(cid:95) CONFLICTING EVENTS) For any univalent state S with T1(cid:95)T2, there exists a full execution ((cid:95)) all conflicting events in T1 and T2 (other than ed itself, if ed is E ending in S featuring a decision event ed that happens before a conflicting event) PROOF SKETCH|,Non-data,86
| We show that the contradiction implies an in- finite chain of equivalent executions with earlier and earlier non- decision conflicting events, which is impossible given that system states are finite We show that two fundamental system state properties are nec- essary for secure scheduling: DEF 7 (FIRST-PRECEDES-DECISION) State S satisfies First- Precedes-Decision if, for any pair of transactions T1 and T2 in S with T1(cid:95)T2, there is a full execution E ending in S with a decision event ed that either is in T1, or happens after an event in T1|,Non-data,86
| DEF 8 (DECISION-PRECEDES-SECOND) A state S satisfies Decision-Precedes-Second if, for any pair of transactions T1 and a decision event e(cid:48) T2 in S with T1(cid:95)T2, there is a full execution E(cid:48) ending in S with d, such that no event in T2 happens before e(cid:48) d Therefore, for a protocol to be secure, it must ensure resulting system states have these properties|,Non-data,86
| THEOREM 3 (NECESSARY CONDITION) Any secure, dead- lock-free protocol p must ensure that all full executions consistent with p feature only states satisfying both First-Precedes-Decision and Decision-Precedes-Second PROOF Given T1(cid:95)T2, any execution E(cid:48) ending in S features a decision event ed|,Non-data,86
| Decision events for the same pair of transactions in equivalent executions must agree on ordering, by the definition of equivalent execution If T1 does not contain E’s decision event, ed, or any event that happens before ed, then there exists an equiv- alent execution in which ed is scheduled before any events in T1 or T2 This execution would imply the existence of a system state in which no event in either transaction is scheduled, but it is im- possible to schedule T2 before T1, regardless of inputs after that state If, after this state, the start event for T2 were scheduled, but not the start event for T1, then T2 cannot be scheduled|,Non-data,86
| This con- tradicts a the deadlock-freedom requirement: no protocol should 236which is impossible, by the definition of happens-before, or ∃e1 ∈ T1e(cid:48) (cid:48) d ∈ T1, and d ⇒ T2(cid:95)T1 e2(cid:95)e d(cid:95)e1 ⇒ e2(cid:95)e1 ⇒ T2(cid:95)T1 d(cid:95)e1, and e2(cid:95)e (cid:48) result in a system state in which a supported transaction can never be scheduled Therefore some event in T1 either is or happens before ed for If T1 and T2 conflict, then e(cid:48) some full execution E ending in S d either is an event in T1 or happens before an event in T1, by Lemma 1|,Non-data,86
| If an event e2 ∈ T2 happens before e(cid:48) d, then either e(cid:48) which is also impossible, by the definition of happens-before If T1 and T2 do not conflict, then the only way T1(cid:95)T2 implies that there exists some chain T1(cid:95)T3(cid:95)T4(cid:95)   |,Non-data,86
|(cid:95)Tn(cid:95)T2 such that and each transaction in the chain conflicts with the next Therefore, by the above proof, an equivalent execution exists in which each transaction in the chain contains the decision event for ordering it- self and the following transaction, and no events in the following transaction are before that decision event Therefore there exists some equivalent execution E(cid:48) in which no event in T2 happens before the decision event e(cid:48) d deciding the ordering between T1 and T2 Although Thm|,Non-data,86
| 3 may seem trivial, it represents some impor- tant conclusions: No protocol can make any final ordering decision until at least one transaction involved has begun Furthermore, it is impossible for the later transaction to determine the decision Truly atomic transactions cannot include any kind of two-way interaction or negotiation for scheduling 6|,Non-data,86
| THE STAGED COMMIT PROTOCOL We now present the staged commit protocol (SC) and prove that it is secure, given transactions satisfying relaxed monotonicity SC is a hybrid of traditional serialization protocols, such as 2PC, and the simple pessimistic protocol described in the proof of Thm 2 Compared to our simple pessimistic protocol, it allows a broader variety of transactions to be scheduled (relaxed monotonicity vs|,Non-data,86
| regular monotonicity), which in turn allows more concurrency A transaction is divided into stages, each of which can be securely committed using a more traditional protocol The stages them- selves are executed in a pessimistic sequence Each event scheduled is considered to be either precommitted or committed|,Non-data,86
| We express this in our model by the presence or absence of an “isCommitted” event corresponding to every event in a transaction Intuitively, a precommitted event is part of some ongoing transaction, so no conflicting events that happen after a precommitted event should be scheduled A committed event, on the other hand, is part of a completed transaction; conflicting events that happen after a committed event can safely be scheduled Once an event is precommitted, it can never be un-scheduled|,Non-data,86
| It can only change to being committed Once an event is committed, it can never change back to being precommitted • The events of each transaction are divided into stages Each stage will be scheduled using traditional 2PC, so aborts within a stage will be sent to all locations involved in that stage|,Non-data,86
| To divide the events into stages, we establish equivalence classes of the events’ labels Labels within each class are equivalent in the following sense: when events with equiva- lent labels are aborted, those aborts can securely flow to the same set of locations An event’s abort can always flow to the event’s own location, so locations involved in a stage can se- curely ensure the atomicity of the events in that stage Since conflicting events have the same security labels, they will be in the same equivalence class|,Non-data,86
| We call these equivalence classes conflict labels (cl) • Each stage features events of the same conflict label, and is scheduled with 2PC One location must coordinate the 2PC All potential aborts in the stage must flow to the coordina- tor, and some events on the coordinator must be permitted to affect all events in the stage|,Non-data,86
| Relaxed monotonicity implies that at least one such location exists for each conflict label When a stage tries to schedule an event, but finds a precom- mitted conflicting event, it aborts the entire stage Because conflicting events have the same label, these aborts cannot affect events on unpermitted locations When a stage’s 2PC completes, the events in the stage are scheduled, and considered precommitted|,Non-data,86
| • Each transaction precommits its stages as they occur To avoid deadlock, we must ensure that whenever two transac- tions feature stages with equal conflict labels, they precom- mit those stages in the same order Therefore, the staged commit protocol assumes an ordering of conflict labels This can be any arbitrary ordering, so long as (1) it totally orders the conflict labels appearing in each transaction, and (2) all transactions agree on the ordering|,Non-data,86
| • When all stages are precommitted, all events in the trans- action can be committed Commit messages to this effect are sent between locations, backwards through the stages Whenever an event in one stage triggers an event in the next, the locations involved can be sure a commit message will take the reverse path The only information conveyed is timing|,Non-data,86
| Because events in a precommitted stage cannot be un-scheduled or “rolled back”, a participant that is involved only in an earlier stage is prevented from gleaning any information about later stages The participant will only learn, eventually, that it can commit Patsy’s transaction in Fig 4c has at least two stages when the patient has HIV: 1|,Non-data,86
| Patsy begins the transaction (Patsy start), and reads the ad- dress (Read Address) This stage will be atomically precom- mitted, and this precommit process will determine the rela- tive ordering of Patsy’s transaction and Mallory’s, indepen- dent of more secret events 2 Patsy finds that the patient has HIV (Read HIV), and prints the patient’s address (Print address)|,Non-data,86
 THEOREM 4 (SECURITY OF SC) Any set of transactions sat- isfying relaxed monotonicity are serialized by SC securely without deadlock PROOF SKETCH Security,Non-data,86
| SC preserves relaxed observational determinism Intuitively, any information flows that it adds are al- ready included in the transaction SC adds no communication affecting security: • Communication within each stage is strictly about events that all participants can both observe • For each pair of consecutive stages, at least one participant from the first stage can notify a participant in the second 237stage securely, when it is time for the second stage to be- gin|,Non-data,86
| Relaxed monotonicity ensures the second stage contains an event that happens after an event in the first stage, repre- senting a line of communication • Communication for commits can safely proceed in reverse order of stages Each participant knows when it precommits exactly which commit messages it will receive Serializability|,Non-data,86
| Our proof is built around the following lemma: any execution in which an event in a transaction is committed fea- tures a system state in which all events in the transaction are pre- committed This lemma is used to show that SC guarantees a strict partial order of transactions, and therefore serializability Deadlock Freedom Deadlock cannot form within any stage, since stages use 2PC, which preserves deadlock freedom|,Non-data,86
| The stages themselves, like locks in our proof of Thm 2, are precom- mitted in a consistent order, guaranteeing deadlock freedom The Importance of Optimism SC specifies only a commit protocol Actual computation (which generates the set of events) for each transaction can be done in advance, optimistically|,Non-data,86
| If one stage precommits and the next is blocked by a conflicting transaction, optimistically precomputed events would have to be rolled back However, no precommit- ted event need be rolled back In fact, it would be insecure to do so Thus SC allows for partially optimistic transactions with partial rollback|,Non-data,86
| Our model requires only that a transaction be a set of events In many cases, however, it is not possible to know which transaction will run when a start event is scheduled For example, a transaction might read a customer’s banking information from a database and contact the appropriate bank It would not be possible to know which bank should have an event in the transaction beforehand|,Non-data,86
| If a system attempted to read the banking information prior to the transaction, then serializability is lost: the customer might change banks in between the read and the transaction, and so one might contact the wrong bank Optimism solves this problem: events are precomputed, and when an entire stage is completed, that stage’s 2PC begins This means that optimism is not just an optimization; it is required for secure scheduling in cases where the transactions’ events are not known in advance 7|,Non-data,86
| IMPLEMENTATION We extended the Fabric language and compiler to check that transactions can be securely scheduled, and we extended the Fabric runtime system to use SC Fabric and IFDB [33] are the two open- source systems we are aware of that support distributed transac- tions on persistent, labeled data with information flow control Of these, we chose Fabric for its static reasoning capabilities IFDB checks labels entirely dynamically, so it cannot tell if a transaction is schedulable until after it has begun|,Non-data,86
| 71 The Fabric Language The Fabric language is designed for writing distributed programs using atomic transactions that operate on persistent, Java-like ob- jects [24] It has types that label each object field with information flow policies for confidentiality and integrity The compiler uses these labels to check that Fabric programs enforce a noninterfer- ence property|,Non-data,86
| However, like all modern systems built using 2PC, Fabric does not require that transactions be securely scheduled ac- cording to the policies in the program Consequently, until now, abort channels have existed in Fabric PC Possible conflictors String{(cid:96)} p = postread(); ⊥ {Alice, Bob, Carol} ⊥ Comments{(cid:96)(cid:48)} c; if (p|,Non-data,86
|contains("fizz")) { ⊥ (cid:96) if (pcontains("buzz")) { ⊥ (cid:96) {Alice, Carol} {Alice, Carol} cwrite("buzz"); cwrite("fizz"); - - - 1 atomic { 2 3 4 5 6 7 8 9 } } Figure 10: Carol’s program in our Blog example: Carol reads a post with label (cid:96), and depending on what she reads, writes a com- ment with label (cid:96)(cid:48)|,Non-data,86
| Label (cid:96) permits Alice, Bob, and Carol to read the post, while (cid:96)(cid:48) keeps the Comments more private and allows only Alice and Carol to view or edit We leverage these security labels and extend the compiler to ad- ditionally check that transactions in a Fabric program are mono- tonic (§ 5) This implementation prevents confidentiality breaches via abort channels Preventing integrity breaches would require further dynamic checks, which we leave to future work|,Non-data,86
 72 Checking Monotonicity Our modification to the Fabric compiler enforces relaxed mono- tonicity (Def 6) Our evaluation (§ 8) shows that enforcing this condition does not exclude realistic and desirable programs,Non-data,86
 Our changes to the Fabric compiler and related files include 41k lines of code (out of roughly 59k lines) 72,Non-data,86
|1 Events and Conflict Labels in Fabric The events in the system model (§ 3) are represented in our im- plementation by read and writes on fields of persistent Fabric ob- jects The label of the field being read or written corresponds to the event labels in our model SC (§6) divides events into stages based on conflict labels (cl) In our implementation, we define the cl of an event e to correspond to the set of principals authorized to read or write the field that is being accessed by e|,Non-data,86
| If e is a write event, this set contains ex- actly those principals that can perform a conflicting operation (and thereby receive an abort); if e is a read event, the set is a conserva- tive over-approximation, since only the writers can conflict Fig 10 presents a program in which Carol schedules two events within a single transaction First, she reads a blog post with security label (cid:96)|,Non-data,86
| Second, she writes a comment (whose content depends on that of the post) with label (cid:96)(cid:48) Since (cid:96) permits Alice, Bob, or Carol to read the post, the cl of the first event includes all three principals However, only Alice and Carol can read or write the comment, so when Carol goes to write it, only Alice or another transaction acting on behalf of Carol could cause conflicts The cl of the write therefore includes only Alice and Carol|,Non-data,86
| 722 Program Counter Label The program counter label (pc) [13] labels the program context For any given point in the code, the pc represents the join (least upper bound) of the labels of events that determine whether or not execution reaches that point in the code|,Non-data,86
| These events include those occurring in if-statement and loop conditionals For instance, in Fig 10, whether line 5 runs depends on the value of p, which has label (cid:96) Therefore, the fact that line 5 is executing is as secret as p, and the pc at line 5 is (cid:96)|,Non-data,86
| SC requires that when events with the same cl are aborted, those aborts can securely flow to the same set of locations When an event causes an abort, the resulting abort messages carry informa- tion about the context in which the event occurs Therefore, we enforce the requirement by introducing a constraint on the program 238context in which events may occur: the pc must flow to the princi- pals in the conflict label pc (cid:118) cl (1) Eliding the details of how Fabric’s labels are structured, in Fig|,Non-data,86
| 10, ⊥ flows to everything, and (cid:96), the label of the blog post, does flow to the conflict label, indicating that both Alice and Carol can cause a conflict Therefore, Eqn (1) holds on lines 2, 5, and 7 7|,Non-data,86
|23 Ordering Stages Each stage consists of operations with the same cl To ensure all transactions precommit conflicting stages in the same order, we adopt a universal stage ordering: principals(cli) (cid:41) principals(cli+1) (2) The set of principals in each stage must be a strict superset of the principals in the next one This ensures that unrestricted infor- mation can be read in one stage and sensitive information can be modified in a later stage in the same transaction|,Non-data,86
| In the hospital example (Fig 4), Read HIV has a conflict label that only includes trusted personnel, while Read address has a conflict label that in- cludes more hospital staff As a result, our implementation requires that Read address be staged before Read HIV in Patsy’s transaction In Fig|,Non-data,86
| 10, our stage ordering means that the read on line 2, with a cl of {Alice, Bob, Carol} belongs in an earlier stage than the write, which features a cl of only {Alice, Carol} 724 Method Annotations To ensure modular program analysis and compilation, each method is analyzed independently|,Non-data,86
| Fabric is an object-oriented language with dynamic dispatch, so it is not always possible to know in advance which method implementation a program will execute Therefore, the exact conflict labels for events within a method call are not known at compile time In order to ensure each atomic pro- gram can divide into monotonic stages, we annotate each method with bounds on the conflict labels of operations within the method These annotations are the security analogue of argument and return types for methods|,Non-data,86
| 73 Implementing SC We extended the Fabric runtime system to use SC instead of tra- ditional 2PC, modifying 24k lines of code out of a total of 24k lines of code in the original implementation Specifically, we changed Fabric’s 2PC-based transaction protocol so that it leaves each stage prepared until all stages are ready, and then commits|,Non-data,86
| Since Fabric labels can be dynamic, the compiler statically deter- mines potential stagepoints—points in the program that may begin a new stage—along with the conflict labels of the stages immedi- ately surrounding the potential stagepoint If the compiler cannot statically determine whether the conflict labels before and after a stagepoint will be different, it inserts a dynamic equivalence check for the two labels At run time, if the two labels are not equivalent, then a stage is ending, and the system precommits all operations made thus far To precommit a stage, we run the first (“prepare”) phase of 2PC|,Non-data,86
| If there is an abort, the stage is re-executed until it eventually precommits In Fig 10, there is a potential stagepoint before lines 4 and 6, where the next operation in each case will not include Bob as a possible conflictor The conflict labels surrounding the potential stagepoint are {Alice, Bob, Carol} (from reading the post on line 2) and {Alice, Carol} (from writing the comment on either line 4 or 6)|,Non-data,86
| If another transaction caused the first stage to abort, then Data item Readers Gloria’s account balance Bank, Gloria Item price Inventory (public) Outel Writers Bank Outel Outel Figure 11: Example policies for the Rainforest application Carol’s code would rerun up to line 4 or 6 until it could precommit, and then the remainder of the transaction would run 8 EVALUATION To evaluate our implementation, we built three example Fabric applications, and tested them using our modified Fabric compiler: • an implementation of the hospital example from §2; • a primitive blog application (from which Fig|,Non-data,86
| 10 was taken), in which participants write and comment on posts with pri- vacy policies; and • an implementation of the Rainforest example from §2 81 Hospital We implemented the programs described in our hospital example (Fig 3)|,Non-data,86
| In the implementation, Patsy’s code additionally appends the addresses of HIV-positive patients to a secure log In a third program, another trusted participant reads the secure log With our changes, the compiler correctly rejects Patsy’s code We amended her code to reflect Fig|,Non-data,86
| 4 Of the 350 lines of code, we had to change a total of 113 to satisfy relaxed monotonicity and compile Of these 113 lines, 23 were additional method annotations and the remaining 90 were the result of refactoring the transaction that retrieves the addresses of HIV-positive patients SC scheduled the transactions without leaking information|,Non-data,86
| The patient’s HIV status made Mallory neither more nor less likely to receive aborts 82 Blog In our primitive blog application, a store holds API objects, each of which features blog posts (represented as strings) with some se- curity label, and comments with another security label These la- bels control who can view, edit, or add to the posts and comments|,Non-data,86
| In one of our programs, the blog owner atomically reads a post and updates its text to alternate between “fizz” and “buzz” In an- other program, another user comments on the first post (Fig 10) To keep this comment pertinent to the content of the post, reading the post and adding the comment are done atomically|,Non-data,86
| Since posts and comments have different labels, this transaction has at least two stages: one to read the post, and another to write the comment We were able to compile and run these programs with our mod- ified system with relatively few changes Of the 352 lines of code, we had to change a total of 50, primarily by adding annotations to method signatures (§72|,Non-data,86
4) 83 Rainforest We implemented the Rainforest example from §21,Non-data,86
| In our code, two nodes within Rainforest act with Rainforest’s authority They perform transactions representing the orders of Gloria and Fred from Fig 1 Each transaction updates inventory data stored at one location, and banking data stored at another|,Non-data,86
| Fig 11 gives examples of the policies for price, inventory, and banking data While attempting to modify this code to work with SC, we dis- covered that the staging order chosen in § 72|,Non-data,86
|3 makes it impossi- ble to provide the atomicity of the original application while both meeting its security requirements and ensuring deadlock freedom To illustrate, suppose Gloria is purchasing an item from Outel To ensure she is charged the correct price, the event that updates 239Example Program Hospital Blog patsy post comment SC 2PC # stages Dyn checks Total time Total time 6|,Non-data,86
38 ms 101 ms 101 ms 917 ms 1,Non-data,86
03 ms 130 ms 045 ms 011 ms 0,Non-data,86
|29 ms 3 2 3 Figure 12: Performance overhead of SC Reported times are per-transaction averages, across three 5-minute runs of the blog application and three 20-minute runs of the hospital application Relative standard error of all measurements is less than 2% the inventory must share a transaction with the one that debits Glo- ria’s bank account|,Non-data,86
| The conflict label for the inventory event cor- responds to {Outel}, whereas the conflict label for the debit event corresponds to {Bank, Gloria} Since neither is a subset of the other, the compiler cannot put them in the same transaction These difficulties in porting the Rainforest application arise be- cause Fabric is designed to be an open system, and so an a pri- ori choice of staging order must be chosen If the application were written as part of a closed system, deadlock freedom can be achieved by picking a staging order that works for this particular application (e|,Non-data,86
|g, {Outel} before {Bank, Gloria}), but it might be difficult to extend the system with future applications 84 Overhead The staged commit protocol adds two main sources of overhead compared to traditional 2PC|,Non-data,86
| First, each stage involves a round trip to prepare the data manipulated during the stage, leading to over- head that scales with the number of stages and with network la- tency Second, as described in § 73, dynamic labels result in po- tential stagepoints, which must be resolved using run-time checks The number of checks performed depends on how well the com- piler’s static analysis predicts potential stagepoints|,Non-data,86
| We measured this overhead in our implementation on an Intel Core i7-2600 machine with 16 GiB of memory, using the transac- tions in our examples The post and comment transactions in the blog example were each run continually for 15 minutes, and Patsy’s transaction in the hospital example was run continually for 1 hour Fig 12 gives the overall execution times for both the original system and the modified system|,Non-data,86
| For the modified system, it also shows the number of stages for each transaction and the average time spent in dynamic checks for resolving potential stagepoints The comment transaction in our experiments has one more stage than as described in Fig 10, because in all transactions, there is an initial stage performed to obtain the principals involved in the application By running the nodes on a single machine and using in-memory data storage, we maximize the fraction of the transaction run time occupied by dynamic checks|,Non-data,86
| Nevertheless, this fraction remains small While the effective low latency of communication between nodes reduces the overhead due to communication round-trips for staging precommits, we report the number of stages, from which this overhead can be calculated for arbitrary latency 9 RELATED WORK Various goals for atomic transactions, such as serializability [28] and ACID [20], have long been proposed and widely studied, and are still an active research topic|,Non-data,86
| While much of the recent interest has been focused on performance, we focus on security Information leaks in commonly used transaction scheduling pro- tocols have been known for at least two decades [36, 6] Kang and Keefe [21] explore transaction processing in databases with multi- ple security levels Their work focuses on a simpler setting with a global, trusted transaction manager|,Non-data,86
| They assume each trans- action has a single security level, and can only “read down” and “write up” Smith et al [36] show that strong atomicity, isola- tion, and consistency guarantees are not possible for all transac- tions in a generalized multilevel secure database They propose weaker guarantees and give three different protocols that meet var- ious weaker guarantees|,Non-data,86
| Their Low-Ready-Wait 2PL protocol is similar to SC, and provides only what the authors call ACIS−– correctness Specifically, “aborted operations at a higher level may prevent all lower level operations from beginning” [36, p37] Al- though our implementation is conservative and would not allow such a thing, the theory behind SC could allow a later stage with less trustworthy participants to hold up earlier, precommitted stages indefinitely Duggan and Wu [16] observe that aborts in high- security subtransactions can leak information to low-security par- ent transactions|,Non-data,86
| Their model of a single, centralized multilevel se- cure database with strictly ordered security levels is more restrictive than our distributed model and security lattice Our abort channels generalize their observation They arrive at a different solution, building a theory of secure nested transactions Atluri, Jajodia, and George [5] describe a number of known protocols requiring weaker guarantees or a single trusted coordinator|,Non-data,86
| Our work in- stead focuses on securely serializing transactions in a fully decen- tralized setting Our analysis is also the first in this vein to consider liveness: SC can guarantee deadlock freedom of transactions with relaxed monotonicity In this work, we build on a body of research that uses lattice- based information flow labels and language-based information flow methods [12, 14, 31] Relatively little work has studied informa- tion flow in transactional systems|,Non-data,86
| Our implementation is built on Fabric [24, 3], a distributed programming system that controls in- formation flow over persistent objects The only other information- flow-sensitive database implementation appears to be IFDB [33], which also does not account for abort channels 10 CONCLUSION There is a fundamental trade-off between strong consistency guar- antees and strong security properties in decentralized systems|,Non-data,86
| We investigate the secure scheduling of transactions, a ubiquitous build- ing block of modern large-scale applications Abort channels offer a stark example of an unexplored security flaw: existing transac- tion scheduling mechanisms can leak confidential information, or allow unauthorized influences of trusted data While some sets of transactions are impossible to serialize securely, we demonstrate the viability of secure scheduling We present relaxed monotonicity, a simple condition under which secure scheduling is always possible|,Non-data,86
| Our staged commit protocol can securely schedule any set of transactions with relaxed mono- tonicity, even in an open system To demonstrate the practical ap- plicability of this protocol, we adapted the Fabric compiler to check transactional programs for conditions that allow secure scheduling These checks are effective: the compiler identifies an intrinsic se- curity flaw in one program, and accepts other, secure transactions with minimal adaptations This work sheds light on the fundamentals of secure transac- tions|,Non-data,86
| However, there is more work to be done to understand the pragmatic implications We have identified separate necessary and sufficient conditions for secure scheduling, but there remains space 240between them to explore Ultimately, abort channels are just one in- stance of the general problem of information leakage in distributed systems Similar channels may exist in other distributed settings, and we expect it to be fruitful to explore other protocols through the lens of information flow analysis|,Non-data,86
| Acknowledgments The authors would like to thank the anonymous reviewers for their suggestions This work was supported by MURI grant FA9550- 12-1-0400, by NSF grants 1513797, 1422544, 1601879, by gifts from Infosys and Google, and by the Department of Defense (DoD) through the National Defense Science & Engineering Graduate Fel- lowship (NDSEG) Program 11 |,Non-data,86
|ABSTRACT Large numbers of smart connected devices, also named as the In- ternet of Things (IoT), are permeating our environments (homes, factories, cars, and also our body—with wearable devices) to collect data and act on the insight derived Ensuring software integrity (in- cluding OS, apps, and configurations) on such smart devices is then essential to guarantee both privacy and safety A key mechanism to protect the software integrity of these devices is remote attestation: A process that allows a remote verifier to validate the integrity of the software of a device This process usually makes use of a signed hash value of the actual device’s software, generated by dedicated hardware|,Non-data,87
| While individual device attestation is a well-established technique, to date integrity verification of a very large number of devices remains an open problem, due to scalability issues In this paper, we present SANA, the first secure and scalable pro- tocol for efficient attestation of large sets of devices that works under realistic assumptions SANA relies on a novel signature scheme to allow anyone to publicly verify a collective attestation in constant time and space, for virtually an unlimited number of devices We substantially improve existing swarm attestation schemes [5] by sup- porting a realistic trust model where: (1) only the targeted devices are required to implement attestation; (2) compromising any device does not harm others; and (3) all aggregators can be untrusted|,Non-data,87
| We implemented SANA and demonstrated its efficiency on tiny sensor devices Furthermore, we simulated SANA at large scale, to assess its scalability Our results show that SANA can provide efficient attestation of networks of 1, 000, 000 devices, in only 25 seconds|,Non-data,87
| 1 INTRODUCTION Smart devices are rapidly spreading into every domain of our life These devices range from tiny wearables to larger industrial devices, which could be also integrated among them, eg|,Non-data,87
|, setting up building automation (which involves physical access control, lighting, sheath- ing, ventilating, and air conditioning) Unlike traditional computing devices, smart devices that are deployed in massive numbers are ∗Corresponding author Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page Copyrights for components of this work owned by others than ACM must be honored|,Non-data,87
| Abstracting with credit is permitted To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acmorg|,Non-data,87
| CCS’16, October 24-28, 2016, Vienna, Austria c(cid:13) 2016 ACM ISBN 978-1-4503-4139-4/16/10  |,Non-data,87
 $1500 DOI: http://dxdoiorg/10,Non-data,87
|1145/29767492978335 often limited in cost, computing power, and size Moreover, embed- ded devices are often security and privacy critical, since they sense the environment, collect private information, or controls physical equipment, possibly causing damages also in the physical world Unfortunately, smart devices usually lack the security capabilities of general purpose computers|,Non-data,87
| Indeed, an adversary can easily attack such devices, and compromise both their privacy and safety One common attack is to modify or replace a device’s firmware, as part of a larger attack scenario [2, 1] In order to prevent such attacks and ensure the safe and secure operation of a device, it is important to guarantee its software integrity, eg|,Non-data,87
|, via remote software attestation Remote software attestation is an interactive protocol that allows a prover to prove its software integrity to a remote verifier The prover demonstrates to the verifier that its software is in a known “good state”, which has not been modified This is usually achieved by signing integrity-protected memory regions|,Non-data,87
| Attestation of indi- vidual smart devices is a well established research area However, to date there is a lack of viable approaches to securely scale device attestation to a very large number of devices: Indeed, today’s Inter- net of Things (IoT) infrastructures often rely on a cloud backend to handle each individual device However, this traditional approach has some shortcomings, in particular in terms of communication and computation cost for the cloud infrastructure, which is linear in the number of attested devices Recently, one proposed approach, SEDA [5], moved a first step towards a more scalable and efficient protocol for attesting a large population of devices|,Non-data,87
| SEDA assumes a software-only adversary, ie, an adversary that can compromise only the software of the target device It uses (symmetric key based) hop-by-hop attestation within a group of devices, transitively collect- ing and aggregating attestation responses along an aggregation tree|,Non-data,87
| SEDA merely reports the number of devices that passed attestation, and does not provide additional information about the identity of devices that failed attestation Unfortunately, while SEDA substantially increased the scalability of network attestation, it also requires trust in all intermediaries As a consequence, all devices involved in the attestation protocol are required to: (1) be equipped with a trusted execution environment; and (2) participate in the attestation process These requirements represent a significant limitation when not all the devices in a given area are “trusted" to the same single entity (e|,Non-data,87
|g, to the entity that acts as a verifier of the attestation process) Moreover, in presence of a stronger adversary capable of physical attacks, ie|,Non-data,87
|, capable of tampering with the hardware of even a limited number of devices, SEDA fails to guarantee the security of all other devices Contributions In this paper, we propose SANA, the first attesta- tion scheme for large collections of devices that: (i) is scalable, ie|,Non-data,87
|, it efficiently verifies the integrity of a large collection of devices 731Figure 1: Collective attestation in a network of seven devices (four aggregators and five provers) by means of a novel signature scheme, which allows aggregation of attestation proofs; (ii) is publicly verifiable, ie, the produced aggregate signature can be verified by any one knowing the (ag- gregate) public key; and (iii) enables untrusted aggregation, ie|,Non-data,87
|, compromise (including physical tampering) of aggregating nodes does not affect the integrity of the attestation process Similar to all other conventional attestation schemes, SANA does not deal with privacy concerns, such as linking the software configuration with a device’s identity Our main focus is providing standard attestation capabilities for large IoT deployments Required privacy can be provided using secure channels|,Non-data,87
| Our new approach brings the following three technical contributions: Novel Optimistic Aggregate Signature Scheme We present a novel signature scheme, called Optimistic Aggregate Signature (OAS) OAS allows the aggregation of signatures on different attestation responses, while having a verification overhead that is constant in the size of the network The idea of combining aggregate and multi- signature is to take the best-of-both-worlds|,Non-data,87
| This has been necessary since none of the existing schemes satisfied the novel requirements we identified for secure collective attestation Secure Collective Attestation Scheme We designed SANA, the first collective attestation scheme for networks of embedded devices that supports high dynamicity and adheres to common assumptions made in single-prover attestation SANA leverages OAS over ag- gregation trees to provide highly scalable attestation of large device populations, in a single round-trip|,Non-data,87
| SANA is applicable in settings consistent with large scale IoT device deployments, where aggrega- tor devices can be untrusted routers or cloud servers and is secure in presence of a strong adversary capable of physical attacks Evaluation and Performance Analysis We analyze the perfor- mance of SANA on three state-of-the-art security architectures for low-end embedded devices (eg|,Non-data,87
|, SMART [12], TrustLite [17], and TyTAN [11]), and present the simulation results for networks of up to 1, 000, 000 devices, in order to demonstrate its scalability Outline We introduce SANA in Section 2 and we present our nota- tion in Section 3 We describe our signature scheme in Section 4, and present the SANA protocol in Section 5|,Non-data,87
| We describe an imple- mentation of SANA in Section 6, and report performance results in Section 7 In Section 8, we describe an extension of SANA In Section 9 we overview the related work, and the paper concludes in Section 10 2|,Non-data,87
| SANA 21 System Model We consider large groups of embedded devices, eg, industrial control systems, IoT devices in smart environments, and prospecting robots|,Non-data,87
| Each group consists of a number of interconnected devices Di forming a network G, with either static or dynamic topology G may not have a routing protocol in place However, devices in G are able to identify and communicate to their direct neighbors, which is a minimal assumption in such networks [29] We formally define SANA as a protocol between the following logical entities: prover (P), aggregator (A), owner (O), and veri- fier (V)|,Non-data,87
| As shown in Figure 1, a prover Pi composes a proof of integrity of its software configuration, ie, an attestation response, to be delivered via aggregators to a remote verifier In our setting, provers can have different software and hardware configuration|,Non-data,87
| However, we expect the majority of them to have a good software configuration (ie, the latest non-compromised software version) We refer to this type of provers as good provers(cid:101)Pi, while we refer to the rest of the provers as bad provers(cid:98)Pi (i|,Non-data,87
|e, devices with mali- cious or outdated software) An aggregator Ai has the purpose of relaying messages between entities, and collecting and aggregating attestation responses from provers, or other aggregators The entity O represents the network owner or operator, responsible for the deployment, as well as the maintenance, of every prover Pi in G|,Non-data,87
| Note that, a physical device in G can embed the functionalities of every logical component described above, or a combination of them As an example, in Figure 1 device D3 acts both as a prover(cid:98)P3, and an aggregator A2, while D5 acts only as a prover(cid:98)P4 The goal of a collective attestation protocol is to assure a verifier V, which is typically, but not necessarily, the same entity as O, of the overall integrity of G, ie|,Non-data,87
|, the software integrity of every prover Pi in G Provided that none of the provers is physically attacked, G is considered trustworthy if all the provers in G are good, ie, have the latest non-compromised software version approved by V|,Non-data,87
| How- ever, unlike existing attestation schemes that assume a software-only attacker, SANA also considers the presence of physically tampered devices, which may evade their detection Consequently, we con- sider G to be trustworthy, if at least all but physically tampered provers are good SANA can identify bad devices, as well as their current software configuration 2|,Non-data,87
|2 Protocol Overview Figure 1 illustrates the concept of SANA, in a setting where G is composed of seven physical devices D1, D2, D3, D4, D5, D6, and D7 SANA is executed between the following (logical) entities: four aggregators, A1, A2, A3, and A4, five provers,(cid:101)P1,(cid:98)P2,(cid:101)P3,(cid:101)P4, and(cid:98)P5, the owner O, and a verifier V Each prover Pi is initialized attestation protocol (operation 1 shown for (cid:101)P1 in Figure 1) The with the cryptographic material needed to execute SANA collective initialization is performed in a secure environment, and preferably, but not necessarily, by O|,Non-data,87
| At a given time, a verifier V, which possesses an appropriate attestation token generated by O, may attest G Note that, if V and O are two distinct entities, the token is securely exchanged offline (operation 2 in Figure 1) In order to attest the network, V chooses an aggregator (randomly or based on physical proximity with the corresponding device; A1 in Figure 1) and sends it an attestation request containing an attestation 732token (operation 3 in Figure 1) The request is flooded in the network forming a logical aggregation tree, that has provers as leaf nodes, and aggregators as intermediate nodes|,Non-data,87
| Leaf nodes of the aggregation tree, ie, provers(cid:101)P1,(cid:98)P2,(cid:101)P3,(cid:98)P4 and(cid:101)P5, create their attestation response and send it to their parent nodes (operation 4 in Figure 1) Aggregators, i|,Non-data,87
|e, non-leaf nodes (A1, A2, A3 and A4), in turn, aggregate the attestation responses received from their child nodes (operation 5 in Figure 1), and forward the result to their parents Finally, the aggregated report is received and verified by V 2|,Non-data,87
