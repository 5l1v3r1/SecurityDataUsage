 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
|3 Requirements and Assumptions Objectives Following the collective attestation literature and the discussion in Section 1, a scalable attestation protocol for collections of devices should, under a strong adversary model, possess the following properties: • Unforgeability and Freshness If the attestation hardware of a prover is unchanged and a correct verifier was able to validate the aggregate attestation result including a given prover, then the claimed integrity measurement reflects an actual software configuration of this prover at a time during this protocol run • Completeness|,Non-data,87
| If the attestation hardware of provers is un- changed and a correct verifier was able to validate the ag- gregate attestation result for a given set of provers, then all provers actually reported their software configuration in the given protocol run • Scalablity The protocol allows a verifier to attest a large network of devices The communication and computational complexity for prover and verifier must be at most logarithmic in the number of devices in the collection|,Non-data,87
| • Public Verifiability In a public key domain, the collective attestation evidence collected by a verifier can be verified by any party In this case, the Unforgeability requirement only proves the state of the prover within the time window between generation of the challenge by the owner, and the receipt of the evidence from the verifier • Privacy Preservation|,Non-data,87
| Verification does not require detailed knowledge of the configuration of G (eg, its topology ) • Heterogeneity|,Non-data,87
 The protocol is applicable to networks with heterogeneous devices The scheme can use any integrity measurement mechanism used by devices in G • Availability If all participants are honest and the network is available then the protocol produces collective attestation evidence,Non-data,87
| • Limiting DoS It should not be possible to run a global DoS attack over the whole network through one device Unforgeability, completeness, and scalability are the main ob- jectives of collective attestation However, a collective attestation scheme should also be DoS limiting|,Non-data,87
| These four properties form the crux of SANA’s contribution Public verifiability and privacy preservation are required in scenarios where network configuration should not be disclosed to the verifying entity (eg, when the mainte- nance in a smart factory is outsourced), and can be achieved through digital signatures and aggregation|,Non-data,87
| Heterogeneity, on the other hand, is needed to support new device types and future attestation schemes, and is achieved by separating the measurement and the reporting mechanisms used for attestation [5] Adversary Model During initial key exchange, we assume the existence of secure channels between any two honest participants Afterwards, we assume an adversary A can eavesdrop, insert, or modify all messages exchanged between all devices in G|,Non-data,87
| Further- more, we assume two types of attacker: (1) a software only attacker, as common in the attestation literature, which can manipulate (ie, compromise) the software of all provers in G, but not physically attack them; and (2) an attacker capable of physically tampering with aggregator devices, ie|,Non-data,87
|, extract their cryptographic material or modify their software However, in both cases we assume A is not capable of forging an Optimistic Aggregate Signature (OAS) according to Definition 3 Finally, while we consider DoS attacks in general to be out of scope, we aim to limit these attacks by prevent- ing A from running a global DoS on the whole network through one single device Security Assumptions|,Non-data,87
| We assume all provers in G correctly im- plement the minimal hardware features required for secure remote attestation described in [12], and adapted in [5] A potential imple- mentation of Pi could have: (1) a Read Only Memory (ROM) that stores the protocol code and the related cryptographic key(s); and (2) a simple Memory Protection Unit (MPU), that restricts access to cryptographic key(s) to protocol code only, and ensures secrecy of the key(s) through non-interruptible, and clean execution of the pro- tocol code We also assume the owner O to be trusted Finally, we assume all cryptographic schemes used in our protocol are secure|,Non-data,87
| 3 PRELIMINARIES AND NOTATIONS Let ||M|| denote the number of elements in a finite set M If n is an integer (or a bit-string), (cid:96)n indicates the bit-length of n Let m ←R M denote the assignment of a uniformly sampled element of M to variable m|,Non-data,87
| Furthermore, let {0, 1}(cid:96) be the set of all bit-strings of length (cid:96) If E is some event (eg, the result of a security experiment), then Pr[E] denotes the probability that E occurs|,Non-data,87
| Probability ((cid:96)) is called negligible if, for all polynomials f, ((cid:96)) ≤ 1/f ((cid:96)) for all sufficiently large (cid:96) ∈ N Let A be a probabilistic algorithm Then y ← A(x) means that on input x, A assigns its output to variable y We occasionally overload notation to let A(x) denote the set of all outputs y that have non-zero probability of being returned by A on input x|,Non-data,87
| K is the set of key pairs (pk , sk ) that have non-zero probability of being returned by KeyGen((cid:96)Sign) We denote with AB an algorithm A that arbitrarily inter- acts with algorithm B while it The term prot [A : xA; B : xB; ∗ : xpub] → [A : yA; B : yB] denotes an in- teractive protocol prot between two probabilistic algorithms A and B Hereby, A (resp B) gets private input xA (resp|,Non-data,87
| xB) and public input xpub While A (resp B) is operating, it can interact with B (resp A)|,Non-data,87
| As a result, A (resp B) outputs yA (resp yB) is executing|,Non-data,87
| A multi-signature scheme [15, 23] allows n different signers to sign the same message m in a constant-size signature, ie, with signature length independent of n Most multi-signature schemes also have verification time quasi-independent of n, meaning that the number of core cryptographic operations (e|,Non-data,87
|g, exponentiations or pairing computations) is independent of n An aggregate signature scheme [10] allows n different signers to sign n different messages m1,  |,Non-data,87
|  , mn with a constant-size signature, but all known schemes have verification time linear in n 4 PROPOSED OAS SCHEME We propose Optimistic Aggregate Signatures (OAS) as a general- ization of aggregate and multi-signatures, where n different signers can sign different messages m1, |,Non-data,87
|   , mn, but most signers are ex- pected to sign the “default” message M  Individual signatures can be aggregated into an aggregate signature that, in the optimistic case where most signers sign M , is significantly shorter and can be verified significantly faster than n separate signatures|,Non-data,87
| In particular, aggregate signature size and verification time should be independent of the number of signers who signed M  Our construction has aggre- 733gate signature size linear in the number of messages different from M and in the number of signers signing those messages Verification time is linear in the number of different messages that were signed, but independent of the number of signers 4|,Non-data,87
|1 Definition of an OAS Schemes An OAS scheme provides both scalability and heterogeneity and is thus applicable for secure collective attestation Definition 1 provides a formal definition of OAS schemes, while Definition 3 defines the unforgeability property for OAS schemes tuple of polynomial probabilistic DEFINITION 1 (OAS) time (OPTIMISTIC AGGREGATE SIGNATURES) is An Optimistic Aggregate Signature scheme a algorithms the se- (KeyGen, AggPK, Sign, AggSig, Verify)|,Non-data,87
| On input of curity parameter (cid:96)Sign ∈ N, KeyGen outputs a secret signing key sk i and a public verification key pk i, for each device Di, ie, (sk i, pk i) ← KeyGen(1(cid:96)Sign ) On input a set of public keys {pk 1, |,Non-data,87
|   , pk n}, the public key aggregation algorithm AggPK outputs an aggregate public key apk On input a secret key sk, a message m ∈ {0, 1}∗, and the default message M ∈ {0, 1}∗, Sign outputs a signature α on m, i|,Non-data,87
|e, α ← Sign(sk , m, M ) Note that, the signature α is already considered an aggregate signature, containing only pk’s signature on m On input two aggregate signatures α1, α2 and the default message M , the signature aggregation algorithm AggSig outputs a new aggregate signature α that includes all signatures in α1 and α2|,Non-data,87
| To verify an aggregate signature, the Verify algorithm takes an aggregate public key apk, a set of public keys S⊥ of signers who did not contribute a signature to the aggregate, an aggregate signature α, and the default message M as input, and outputs either ⊥ to indicate that the signature is invalid, or a set B = {(mi, Si) : i = 1,    , μ}, indicating that the signers with public key pk i ∈ Si signed message mi, and that all other signers whose keys were included in the aggregated public key apk but not in any of S⊥, S1, |,Non-data,87
|   , Sμ signed the default message M  Intuitively, the correctness of an OAS scheme is defined as fol- lows: if all signers behave honestly and contribute at most one signature to the aggregate, then the verification algorithm pro- duces the output that attributes the correct message to the cor- rect signer|,Non-data,87
| Defining this formally is a bit tedious, however, due to the many different orders in which signatures can be aggre- gated To simplify notation, for two sets B1,B2 containing tu- ples (m, S) ∈ {0, 1}∗ × ({0, 1}∗)∗, let B = B1 (cid:116) B2 be the “merged” set of tuples (m, S) where S = S1∪S2 if ∃(m, S1) ∈ B1 and ∃(m, S2) ∈ B2, where S = S1 if ∃(m, S1) ∈ B1 and (cid:54) ∃(m, S2) ∈ B2, and where S = S2 if ∃(m, S2) ∈ B2 and (cid:54) ∃(m, S1) ∈ B1 (CORRECTNESS OF OAS) An OAS scheme is DEFINITION 2 correct if: (i) signing works, i|,Non-data,87
|e, for all (cid:96)Sign ∈ N, all m, M ∈ {0, 1}∗, all (pk , sk ) ← KeyGen((cid:96)Sign), all sets S⊥ such that pk (cid:54)∈ S⊥, it holds that Verify(apk , S⊥, α, M ) returns ∅ if m = M and returns {m,{pk}} if m (cid:54)= M whenever apk ← AggPK(S⊥ ∪ {pk}) and α ← Sign(sk , m, M ) (ii) aggregation works, ie|,Non-data,87
|, for all aggregate signatures α1, α2, all disjoint sets S1, S2, all subsets S⊥,1 ⊆ S1 and S⊥,2 ⊆ S2, and all messages M ∈ {0, 1}∗, if Verify(apk 1, S⊥,1, α1, M ) = B1 and Verify(apk 2, S⊥,2, α2, M ) = B2 for apk 1 ← AggPK(S1), apk 2 ← AggPK(S2), and apk ← AggPK(S1 ∪ S2), then it holds that Verify(apk , S⊥,1 ∪ S⊥,2, α, M ) = B1 (cid:116) B2 DEFINITION 3 (UNFORGEABILITY OF OAS) Unforgeability of an OAS scheme requires that, even if all other signers are dishonest, an adversary cannot produce an aggregate signature that attributes a message to an honest signer that never signed such message More formally, for any polynomial-time adversary A, the following experiment must return 0 with negligible probability: (pk , sk ) ← KeyGen((cid:96)Sign) (α, S⊥, (pk 1, |,Non-data,87
|   , pk n), (sk 1,  |,Non-data,87
|  , sk n)) ← ASign(sk ,·)(pk ) If ∃ i : pk i (cid:54)= pk ∧ (pk i, sk i) (cid:54)∈ KeyGen((cid:96)Sign) then return 0 Let S ← {pk 1,   |,Non-data,87
| , pk n} apk ← AggPK(S) B ← Verify(apk , S⊥, α, M ) If S⊥ (cid:54)⊆ S or ∃(mi, Si) ∈ B : Si (cid:54)⊆ S then return 0 If ∃(mi, Si) ∈ B : pk ∈ Si and mi (cid:54)∈ Q then return 1 (mi,Si)∈B Si If pk ∈ SM and M (cid:54)∈ Q then return 1 Else return 0 Let SM ← S \(cid:0)S⊥ ∪(cid:83) (cid:1) where Q is the set of messages that A queried from its Sign(sk ,·) oracle The unforgeability notion in Definition 3 requires the adversary to know the secret keys of all corrupt signers, which is modeled in the game by requiring the adversary to output those secret keys as part of his forgery In practice, this can either be realized by letting a trusted entity generate the keys of all signers, or by letting all signers perform an extractable proof of knowledge of their secret key, either interactively with a trusted entity, or non-interactively and include it in their public keys Alternatively, Ristenpart and Yilek [28] showed that with minor modifications to some schemes, including Boldyreva’s multi-signature scheme [9], it suffices to let signers create a simpler proof of possession, that is essentially a signature on a challenge message|,Non-data,87
| Therefore, being our OAS construction in Section 42 based on Boldyreva’s multi-signature scheme, this technique can be applied to our scheme as well Also, note that the above definition insists that the sets of public keys S⊥ and Si are subsets of S = {pk 1,  |,Non-data,87
|  , pk n} It is up to the verifier to perform this check, either by looking up the relevant keys in S, or, if the verifier does not know S, by letting signers prove that their keys were included in apk, eg|,Non-data,87
|, through a certificate 42 Our OAS Scheme from pairings In what follows, we introduce our OAS construction from pair- ings Our scheme can be seen as a combination of Boldyreva’s multi-signature scheme [9] and Boneh et al|,Non-data,87
|’s aggregate signature scheme [10] In a multi-signature scheme, all signers sign the same message and the signature can be verified in constant time In the aggregate signature scheme of Boneh et al, all signers have to sign different messages and verification is linear in the number of ag- gregated signatures|,Non-data,87
| Our construction essentially uses Boldyreva’s multi-signature scheme to compress the signatures of those signers who sign the same message, and uses Boneh et al’s scheme on top of it to aggregate the multi-signatures Even though anyone familiar with these schemes immediately sees that the algebra works out, one has to tread very carefully in terms of security Indeed, aggre- gate signatures are notorious for having subtle restrictions on key setup, signer composition, and the messages being signed, which, when not adhered to, can ruin the scheme’s security [7]|,Non-data,87
| We refer the reader to Appendix B for a formal proof that our construction indeed does satisfy the security notion of Definition 3 We note that Syta et al [32] already suggested to use Boneh et al’s aggregate sig- nature scheme in distributed signing applications, but they require all nodes to sign the same message and lacked a detailed security proof, which, given the subtleties mentioned above, is more than just a formality|,Non-data,87
| 734Let G1, G2, Gt be multiplicative groups of prime order p with generators g1, g2, gt, respectively, with an efficiently computable bilinear map e : G1 × G2 → Gt so that e(gx for all x, y ∈ Zp, and with an efficiently computable isomorphism ψ : G2 → G1 so that ψ(g2) = g1 Let H : {0, 1}∗ → G1 be a hash function modeled as a random oracle [8] Key generation Each signer chooses random secret key x ←R Zp 2 ) = gxy 1 , gy t Public key aggregation|,Non-data,87
| The aggregate public key for individual and sets its public key to pk ← gx 2  public keys pk 1,   |,Non-data,87
| , pk n is apk =(cid:81)n i=1 pk i Signing The signature on a message m is α ← (H(m)x,∅) if m = M and is α ← (H(m)x,{(m,{pk})}) otherwise Signature aggregation|,Non-data,87
| Aggregating two aggregate signatures α1 = (τ1,B1) and α2 = (τ2,B2) can be done by computing τ ← τ1 · τ2 and “merging” B1 and B2 into B ← B1 (cid:116) B2 The resulting aggregate is α = (τ,B) Verification To verify an aggregate signature α = (τ,B = {(m1, S1), |,Non-data,87
|   , (mμ, Sμ)}) under aggregate public key apk, non-contributing public keys S⊥, and default message M , let  (1) pk(cid:1) |,Non-data,87
| (2) pk (cid:89) pk∈Si apk M ← apk (cid:81) pk∈S⊥ pk ·(cid:81)μ (cid:1) · μ(cid:89) (cid:81) e(cid:0)H(mi), i=1 pk∈Si Verify that e(τ, g2) = e(cid:0)H(M ), apk M If so, then return B, otherwise return ⊥ i=1 As mentioned earlier, and as is the case for other multi-signature schemes [9, 20], the signers’ keys either have to be generated by a trusted entity, or the signers have to prove possession of their secret keys For our scheme, the latter is most easily achieved by signing an arbitrary message using a different hash function than for normal signatures [28]1 and adding it to the public key, or by including a Schnorr signature from which the corresponding secret keys can be extracted by applying the generalized forking lemma of Bagherzandi et al [6]|,Non-data,87
| 5 PROTOCOL DESCRIPTION SANA consists of algorithms and protocols executed by a verifier V, the owner O, and a set of aggregators and provers in the network G Table 1 provides an overview of the variables and parameters used in the protocol specification At its core, SANA distributes a challenge, asks each prover to produce a signed attestation, and aggregates the resulting attestation signatures|,Non-data,87
| Since Denial of Service (DoS) attacks on tiny devices are easy, SANA additionally provides an authorization scheme that allows only authorized verifiers to execute this protocol Initialization Each prover Pi is initialized in a trusted environment by the network owner O with an OAS key pair (sk i ←R Zp, pk i ← 2 ), and an identity certificate cert(pk i), signed by O, certifying gsk i that pk i is a valid OAS public key of Pi with identity id i Formally: init(1(cid:96)) → (sk i, pk i, cert(pk i)) |,Non-data,87
| Token request In order to attest a network G, a verifier V must possess a valid authorization token T generated and signed by the 1The same hash function also works as long as the message space for proofs of possession is separated from that of regular signatures Table 1: Variables, parameters and procedures Entities O V Di (cid:101)Pi (cid:98)Pi Ai Network G parameters a n gi pi ≤ gi − 1 Prover Pi parameters id i h (sk i, pk i) skO (resp V ) pkO (resp|,Non-data,87
| V ) cert(pk i) cert(pkO) (resp V ) (c1, v1)   |,Non-data,87
| (cs, vs) SANA parameters T N H texp δt Ch apk Si S⊥ mi M α Procedures Enc(), Dec() Sign() Verify() checkPolicy() getFreeCounter() checkCounter() getSoftConf() getGoodConfigs() Owner or operator of the network Verifier (entity attesting the network) Device i Good prover i, ie, a prover with one of the latest non- compromised software configurations Bad prover i, ie|,Non-data,87
|, a prover with an outdated or malicious software configuration Untrusted aggregator i Total number of aggregators in G Total number of provers in G Number of neighbors of Ai Number of children of Ai in the aggregation tree ID of Pi Platform software configuration (eg, hash digest of bi- nary code) OAS secret and public key pair of Pi Secret signing key of O (resp|,Non-data,87
| V) (not based on OAS) Public signature verification key O (resp V) (not based on OAS) Identity certificate of Pi (issued by O) Public key certificates for O (resp V) (issued by a trusted third party) List of attestation counters and corresponding values Token used by V to perform attestation (T = {H, cl , vl , texp , σ1}) A random nonce The set of software configurations for the latest software versions of all devices in G Expiry time of a token T Expiry period of a token T An attestation challenge (Ch = {N, T}) Aggregate public key of all provers in G Set of public keys grouped by same message signed mi Set of public keys that did not participate in generating the OAS signature Software configuration on which public keys are grouped The default message signed by OAS An OAS signature Public key encryption and decryption Creating a digital (or OAS) signature Verification of a digital (or OAS) signature Application specific procedure that determines whether to accept a token request Outputs δt > 0 if the request is accepted Searches for an unused counter cl in c1 |,Non-data,87
|   cs Sets cl status to “busy”, increments vl and outputs cl and vl Checks whether the value of the received counter is greater than the value of the local counter; in this case, sets value of local counter to value of received ones Measures the software configuration Retrieves the set H of software configuration for the latest software versions of all devices in G owner O of the network|,Non-data,87
| V acquires T = {H, cl , vl , texp, σ1} by executing an offline protocol tokenReq (see Figure 2) with O The main purpose of tokenReq is at the same time mitigating DoS at- tacks (that are based on the attestation protocol, and can be launched through one single device on the entire network), while allowing attestation service to be public The network owner O keeps a list of counters c1,  |,Non-data,87
|  , cs with values v1,   |,Non-data,87
| , vs A counter can be assigned by O to a valid token request until an expiry time texp, associated to the request, ie, the counter is marked as “busy” until texp|,Non-data,87
| After receiving a valid token 735Figure 2: Protocol tokenReq request from V, O searches for a free (ie, not busy) counter cl, with value vl, increments vl by one, and returns the tuple (cl , vl ) to the requesting verifier – getFreeCounter() Counters are necessary to protect the network against replay attacks: Indeed, each prover Pi also keeps a list of s counters with corresponding values; once it received an attestation request, Pi checks whether the counter value associated with the request is greater than the value locally stored, and, only in this case, updates its local value and proceeds with the evaluation of the attestation request – checkCounter()|,Non-data,87
| The details of tokenReq are as follows: V initiates the protocol by sending O a random challenge NV, showing its interest in attesting G Upon receiving NV, O creates a random challenge NO and sends it to V V then creates a signature σV 2 on NO and a protocol parameter δt and sends it back to O along with δt, and its identity certificate cert(pkV ) Parameter δt indicates the required expiration period of the requested T |,Non-data,87
| Based on idV and the requested δt, O decides whether to accept V’s request, according to an application specific policy – checkPolicy() If the request is accepted and σV verified correctly, O retrieves the set H = {h1,   |,Non-data,87
| , hz} of software configuration of benign software in G (ie, the software configuration of latest software version on different devices in G) – getGoodConfigs() The list is then hashed into one single good configuration hg = hash(h1|| |,Non-data,87
|  ||hz) Finally, O sends to V: (1) the aggregate public key apk of all provers in G; (2) A signature σ2 over apk; and (3) An encrypted 3 token |,Non-data,87
| Finally, V verifies σ2, decrypts and verifies T , and stores it along with apk Formally: tokenReq[V : δt , skV ; O : skO, apk ; ∗ : cert(pkO), cert(pkV )] → [V : T , apk ; O : texp]  Attestation: After obtaining an attestation token T , V can attest the network Before texp, V chooses a random (gateway) aggregator A1, through which it runs the collective attestation attest of the whole network (see Figure 3)|,Non-data,87
| In detail, V sends A1 an attestation request 2Signatures in tokenReq are not based on our OAS scheme, but use an existing public key infrastructure (PKI) between O and V 3Encryption is based on the public key pkV of V Ch = {N, T} including a random challenge N Upon receiving this request, A1 verifies the counter value vl – checkCounter(), and the signature σO using owner’s O public key|,Non-data,87
| We denote this procedure by verifyChallenge() If the verification succeeds, A1 forwards the request to its neighbors Each neighbor, in turn, verifies and forwards the request to its neighbors, and so forth, until the request is received by all provers in the network Consequently an aggregation tree rooted at A1 is formed|,Non-data,87
| As a next step in the protocol, each prover Pi (at the leaf nodes) in the generated aggregation tree, generates its own software config- uration hi – getSoftConf() If hi is a benign software configuration (ie, hi ∈ H), Di creates an Optimistic Aggregate Signature (OAS) αi over the good software configuration hg, the challenge N, the counter id cl, and the counter value vl (using its OAS secret key ski), Otherwise (if hi /∈ H), αi is created over Di’s software con- figuration hi|,Non-data,87
| αi is then sent to Di’s parent in the aggregation tree We denote this procedure as createResponse() Aggregators at intermediate nodes of the tree aggregate responses coming from their children according to the procedure AggSig de- fined in Definition 1, which we denote as aggregateResponse(), ie|,Non-data,87
|, signatures are aggregated by M = hg||N||cl||vl being the de- fault message Consequently, attestation responses from provers are propagated, in reverse, along the aggregation tree toward the root A1 Upon receiving all the responses from its children, node A1 forwards the final aggregated signature α1 to V Finally, V verifies α1 according to Verify in Definition 1|,Non-data,87
| If the verification succeeds and B = φ, V concludes that the network is trustworthy If B (cid:54)= φ, V learns the identity and the software configuration of all bad devices (ie, with malicious or outdated software)|,Non-data,87
| Formally: attest1 [V : T , apk ; A1 : −; ∗ : pkO] → [V : r; A1 : Ch]  attest2 [Ai : Ch; Dj : (sk j ); ∗ : pkO] → [Ai : αj ; Dj : Ch]  The reader may refer to Appendix A for the security analysis of SANA 736Figure 3: Protocol attest (attest1 and attest2) 6|,Non-data,87
| SANA IMPLEMENTATION We implemented SANA based on three recently proposed se- curity architecture for low end embedded devices: SMART [12], TrustLite [17], and TyTAN [11] In this section, we discuss our implementation based on TyTAN shown in Figure 4 Figure 4: Implementation of SANA based on TyTAN [11] TyTAN [11] is a security architectures for embedded systems, that is based on TrustLite [17]4 TyTAN provides hardware-assisted isolation of system components with real-time execution|,Non-data,87
| Isolation is fundamental to protect critical components against unintended ac- cess by other potentially malicious components In TyTAN, a Mem- ory Protection Unit (MPU) restricts access to data, to the task that owns this data Moreover, both authenticity and confidentiality of the 4TrustLite is based on Intel’s Siskiyou Peak research platform tasks’ code and data are based on secure boot|,Non-data,87
| We implemented the components of SANA (ie, verifyChallenge(), createResponse(), and aggregateResponse()) on TyTAN as isolated tasks, which are protected via secure boot Further, we configured the MPU such that only SANA’s tasks can access the protocols secret data|,Non-data,87
| For example, according to rule #2 in the MPU table in Figure 4, the OAS secret key sk i (which resides in memory address Addr 6 to Addr 7) is only read accessible to createResponse() (ie, code re- siding in memory address Addr 3 to Addr 4) Finally, we developed a proof-of-concept implementation of our OAS scheme for both the low-end device in exam (i|,Non-data,87
|e, TyTAN [11]), and for commodity hardware Our OAS scheme implementation uses the library in [34] for pairing-based cryptographic operations, which we found particu- larly suitable for our target platforms OAS operations are defined over the BN254 pairing-friendly elliptic curve [34], which provides a strong security level of 128-bit|,Non-data,87
| 7 PERFORMANCE EVALUATION We now evaluate computational, memory, communication, and energy costs of SANA based on our implementation in Section 6 Computational cost The major part of the computational cost on provers and aggregators, is due to the cryptographic operations, i|,Non-data,87
|e, creating and aggregating Optimistic Aggregate Signature (OAS) signatures, and creating the good software configuration hg The gateway aggregator A1, which directly communicates to the verifier V, aggregates at most g1 signatures, where g1 is the number of neighbors of A1 and creates one hash Every aggregator Ai also creates one hash, and aggregates at most pi signatures, where pi ≤ gi − 1 and gi is the number of neighbors of Ai in the network|,Non-data,87
| Finally, each Pi creates one OAS signature and one hash 737Communication cost Our OAS implementation has a signature size of (cid:96)Sign = 256 bits We also use (cid:96)N = 160, (cid:96)c = 64, and (cid:96)(cid:48) Sign = 320|,Non-data,87
| Consequently, counter values are 8 bytes, counter ids are 2 bytes, nonces are 20 bytes, OAS signatures are 32 bytes, public keys are 32 bytes, digital signatures are 40 bytes, and software configurations are 20 bytes A token T with z good configurations consists of 20z + 58 bytes, and a challenge Ch of 20z + 78 bytes A response αi has size 32 + 32w + 20μ bytes, where μ is the number of distinct bad software configurations h1,  |,Non-data,87
|  , hμ and w is the number of distinct OAS public keys of bad provers The communication overhead of the each aggregator Ai is, sending at most 32 + (20z + 78)gi + 32w + 20μ bytes and receiving at most 20z + 78 + 32gi + 32w + 20μ bytes Finally, every prover Pi sends 84 bytes and receives 20z + 78 bytes|,Non-data,87
 Memory cost Each Pi in G stores the ids (c1   ,Non-data,87
| cs) and values (v1    vs) of s counters, its OAS secret key (sk i), its identity cer- tificate (cert(pk i)), and the public key pkO of O|,Non-data,87
| The storage overhead for every Pi is estimated as 10s + 228 bytes, where s is the number of counters used by O Low-end embedded devices targeted by SANA (eg, the TI MSP430) have at least 1024 bytes of non-volatile memory|,Non-data,87
| SANA consumes less than 32% of this memory, assuming that ten verifiers could attest G within the same time frame Run-time SANA is optimized so that the communication overhead is constant when all provers are correctly configured On the other hand, the aggregation tree approach allows provers, and aggrega- tors on the same depth of the tree, to perform their computations in parallel|,Non-data,87
| However, the OAS signature aggregation at depth d depends on the signature creation computations at depth d + 1 Consequently, the overall run-time of the SANA depends on the depth (d = f (n + a) ∈ O(log(n + a))) of the aggregation tree generated for the graph of the network, the number of neighbors of each aggregator, and the number of bad provers Let tsign, tagg, tver, thash and ttx be the times needed to create and aggregate an OAS sig- natures, verify a digital signature, create the good configuration hg, and transmit a single byte to a neighbor, respectively The run-time t of SANA is estimated as: t ≤(cid:2)110d + +(cid:0) d(cid:88) d(cid:88) (32wi + 20mi)(cid:3) · ttx+ (cid:1) · tagg + d · (tver + thash) + tsign|,Non-data,87
| i=0 pi i=0 Table 2 presents an evaluation of the cryptographic operations required by our OAS, on both TyTAN [11] and a t2micro Ama- zon EC2 instance [3]5 Results are an average over 100 executions Table 3 shows the estimated execution time for each of the OAS algo- rithms we presented in Section 4, where pi is the number of children of a node in the aggregation tree, μ is the number of configurations in G, and n is the number of provers in G|,Non-data,87
| Energy costs Let Esend, Ercv, Esign, Eagg, Ever, and Ehash be the energy required to send one byte, receive one byte, create or aggre- gate OAS signatures, verify a digital signature, and create the good configuration hg respectively Then the energy consumption E(Ai) of each aggregator in G is: E(Ai) ≤(cid:0)32 + (20z + 78)gi + 32w + 20m(cid:1) · Esend +(cid:0)20z + 78 + 32gi + 32w + 20m(cid:1) · Ercv + + + pi · Eagg + Ever + Ehash And the energy consumption E(Pi) of each prover in G is: E(Pi) ≤ 84 · Esend + (20z + 78) · Ercv + Esign + Ehash|,Non-data,87
| Table 2: Performance of cryptographic operations Function TyTAN [11] Run-time (ms) EC2 t2micro [3] Run-time (ms) (*) 92152 128271 H : {0, 1}l → G1 gx, g ∈ G1 gx, g ∈ G2 ab, a, b ∈ G1 ab, a, b ∈ G2 ab, a, b ∈ GT e : G1 · G2 → GT (*) Operation not performed by provers or aggregators in SANA 3|,Non-data,87
39 471 1160 032 0,Non-data,87
33 007 767 8648 (*) (*) (*) Table 3: Performance of OAS algorithms,Non-data,87
 EC2 t2micro [3] Run-time (ms) TyTAN [11] Run-time (ms) Function Sign PubKeyGen PubKeyAggr SignatureAggr AggregateVerify 220423 (*) (*) 8648 · pi (*) 8,Non-data,87
1 1160 033 · n 032 · pi 0,Non-data,87
|33 ·(cid:80)μ 2 (||Si|| − 1) + (816) · μ (*) Operation not performed by provers or aggregators in SANA Simulation results We simulated SANA for large networks using the OMNeT++ [25] event simulator We implemented our protocol at the application layer and used delays, based on measurements for TyTAN (Table 2), to simulate the different cryptographic operations|,Non-data,87
| We set the communications rate for links between two devices to 250 Kbps, which is the defined data rate of ZigBee – a common communication protocol for IoT devices We simulated different network topologies including trees (with fan-out degree 2, 4, 8, and 12), and networks with fixed number of neighbors (4, 8 and 12) We varied the size of the network from ten to 1, 000, 000 devices For a fair comparison with SEDA [5], we carried out our simulations assuming all devices in the network to be low-ended devices that needs to be attested|,Non-data,87
| Figure 5 and Figure 6 show the results of our simulations To better assess the performance of SANA, we also simulated it in its targeted setting, where untrusted aggregator devices are more powerful, ie, 50% Raspberry Pi devices6, 30% Intel Galileo devices7, and 20% t2|,Non-data,87
|micro EC2 instances [3], and the communication rate is 5 Mbps We also simulated the extension of SEDA, described in [5], that is capable of identifying malicious devices We denote this extension by SEDA-ID From our results, we can see that, if the number of bad provers is fixed, then the run- time of SANA, for a tree topologies (Figure 5(a)) and for networks with fixed number of neighbors (Figure 5(b)), is logarithmic in the size of the network|,Non-data,87
| As shown in Figure 6(a), SEDA shows better performance com- pared to SANA However, while SEDA imposes a strong require- ment on the devices participating in the attestation protocol, which are low-end devices equipped with trusted hardware, SANA gives a significantly improved flexibility in the type of devices that can act as aggregators, and resiliency to a stronger attacker model In fact, SANA does not impose any constraint or requirement on the devices acting as aggregators, which can be completely untrusted This better serves typical practical deployments, where data ag- 5Amazon EC2 is running Ubuntu server 14|,Non-data,87
|04 equipped with an Intel Xeon Processor CPU (up to 33 GHz), and 1 Gbyte of RAM 6Raspberry Pi has a 700 MHz CPU and 512 MByte of RAM 7Intel Galileo has a 400MHz CPU and 256 MByte of RAM 738(a) Tree topologies (b) Fixed number of neighbors Figure 5: Performance evaluation of SANA (a) Low-end only devices (b) Realistic setting for SANA Figure 6: Performance comparison between SANA and SEDA gregation is performed by more powerful but untrusted devices in the network, such as routers or cloud servers Figure 6(b) further stresses the advantage of SANA in more realistic scenarios, showing its run-time adopting more powerful devices as aggregators|,Non-data,87
| As can be seen from Figure 6(b), the difference in the run-time of the two schemes in such scenario, can become as little as 15 seconds Finally, while SEDA merely reports the number of devices that failed attestation, SANA enables the verifier to identify bad provers as well as their software configuration Figure 6(b) shows the per- formance of SEDA when modified to report the ids of devices that failed attestation as suggested in the original paper [5]|,Non-data,87
| Our perfor- mance analysis demonstrates that, in its targeted setting, SANA can perform as good as SEDA, regardless of the digital signature, and DoS mitigation included Note that, digital signatures may leverage hardware acceleration (as already done for base symmetric crypto operations) leading to a better performance than SEDA 8 THRESHOLD ATTESTATION Although constant in the size of the network, the overhead of SANA is linear in the number of bad provers (i|,Non-data,87
|e, malicious de- vices) However, as described in Section 1, we aim at providing a constant-time network attestation protocol, through which a re- source constrained verifier V (eg|,Non-data,87
|, a smartphone) can verify a very large (eg, in order of millions) network of devices In this section we briefly discuss a possible extension of SANA that allows such a constant-time verification|,Non-data,87
| We base this extension on the following observation: While in some applications the number of malicious devices might be linear in the size of the network (ie, a certain percentage), typically the maximum number of accepted compromise is fixed We believe that this assumption is reasonable, since the number of devices to tolerate is related to the redundancy rather than to the size of the network|,Non-data,87
| Consequently, we can set a threshold (ie, an upper bound) for the number of bad devices to verify The threshold is set by V, and embedded inside the token T |,Non-data,87
| During attestation responses aggregation, aggregators keep aggregating signatures on bad software configurations only until the threshold is reached Ev- ery signature received afterwards is simply dropped Consequently, since dropping signatures renders the final report unverifiable, if report verification fails, V deduces that the number of bad devices has exceeded the threshold As shown in Figure 7, threshold attestation run in constant- time|,Non-data,87
| However, besides reaching the upper bound in the number of al- lowed bad configurations, other factors, such as benign errors and active (DoS) attacks, may cause a failure in the verification of the aggregate attestation response For this reason, it is important to verify that this result is indeed due to the existence of too many bad devices In order to tackle this problem, a potential solution is to split the OAS signature into two parts: An aggregate signature (over bad configurations), and a multi-signature (over the good configu- ration) In this way, verifying the aggregate signature (in constant time), gives V an assurance that the number of devices with bad configuration has exceeded the threshold|,Non-data,87
| Additionally, V learns identities and software configurations of such bad devices Figure 7: Run-time of SANA on an EC2 t2micro [3] verifier 9 BACKGROUND AND RELATED WORK Individual Device Attestation is a well-established research area|,Non-data,87
| The main goal of an attestation process is to allow a verifier to check the integrity of the software running on a (potentially remote) device (prover) We can distinguish three main approaches of attestation: software-based, co-processor-based, and hybrid Software-based attestation [16, 31, 14, 19] requires no secure hardware and does not rely on cryptographic secrets, making it particularly attractive for low-end devices with limited resources Unfortunately, the se- curity of software-based attestation has been challenged [35], since it is based on strong assumptions that are hard to achieve in prac- tice [4]|,Non-data,87
| As an example, software-based attestation assumes that the attestation algorithm and its implementation are optimal, and that the adversary is passive during the whole execution of the at- testation protocol Moreover, software-based attestation relies on strict estimation of round trip times, requires an out-of-band authen- tication channel, and is thus restricted to one hop communication, and not suitable for remote attestation Co-processor based attes- tation schemes [27, 33, 18, 30, 22, 21], on the other hand, offer improved security guarantees However, they are more suitable for general-purpose computing platforms, since their underlying secu- rity hardware is often too complex and/or expensive for low-end embedded devices|,Non-data,87
| A third recently presented approach for attes- tation is based on a hardware/software co-design [12, 17, 13, 11], and aims for minimizing the hardware security features required for enabling secure remote attestation Such security features can be as simple as a Read Only Memory (ROM), and a simple Memory Protection Unit (MPU) SANA requires the same minimal hardware support to implement collective attestation on the attested devices Collective Attestation|,Non-data,87
| SEDA, the solution recently proposed in [5], made a first step towards a collective attestation, ie, the scalable attestation of large groups of interconnected devices The main focus of SEDA is efficiency and applicability to low-end de- vices, rather than security in the presence of a strong adversary|,Non-data,87
| To that end, SEDA extends the software-only attacker assumed by most 739single-prover attestation schemes to, so-called, swarms of devices With this in mind, security hardware, used for protecting attesta- tion code, is exploited to enable: (1) neighbors’ verification, which decreases the load on the verifier; and (2) secure hop-by-hop aggre- gation, which reduces the communication overhead SEDA achieves high efficiency and scalability through the distribution of the attesta- tion burden across the whole network It merely reports the number of devices in the network that passed attestation|,Non-data,87
| SEDA requires (minimal) trust anchor in hardware for all involved nodes [5], and therefore, it cannot operate in presence of a stronger attacker, ie, an attacker capable of physically tampering devices Indeed, if an attacker violates the hardware security of one node, it may break the overall security of the scheme for all other devices|,Non-data,87
| Our proposed collective attestation protocol SANA overcomes the limitations of SEDA by: (i) requiring minimal trust anchor in hardware only for the attested devices, (ii) allowing aggregation to be performed by largely untrusted nodes, which are only required for availability, and (iii) limiting the effect of successful attacks on the hardware of an attested device to the device itself, ie, it will not affect the attestation of other devices Similarly, Denial-of- Service attacks on one device in SANA will not affect other devices|,Non-data,87
| Finally, SANA informs the verifier with ids as well as software configurations of the devices that failed attestation In Network Aggregation To meet the aforementioned goals, SANA employs in network aggregation Several secure in network aggregation protocols have been proposed in the sensor network area, and in wireless sensor networks in particular, to provide scal- able data collection from sensors [26]|,Non-data,87
| In general, such aggregation schemes allow a collection of sensors to collaboratively and securely compute arbitrary aggregation functions on collected data, to reduce message complexity However, all these protocols have either a verification complexity which is linear in the number of nodes in the network, or are built in multiple protocol rounds Aggregate Multi-Signatures SANA requires a scalable aggregat- able signature scheme, to allow attested devices in the network to sign their state|,Non-data,87
| Such scheme allows different signers with different public keys to sign distinct messages Moreover, it allows inter- mediate nodes to securely aggregate individual signatures into a single verifiable short signature Unfortunately, all known aggregate signature schemes have a verification overhead that is linear in the number of messages and signers, which renders them unsuitable for scalable attestation Additionally, they either require all messages to be distinct, or a complex key agreement protocol [24], require a se- quential order [9, 20], or all the signatures to be created on the same message [6]|,Non-data,87
| As a consequence, we consider none of the known scheme as suitable for our collective attestation scheme Recently, the work in [32] proposed CoSi, a scalable witness cosigning system for certification, logging, and timestamping authorities that com- bines existing multi-signature schemes with communication trees However, the protocol proposed in [32] considers static communica- tion trees, constitutes multiple round-trips, and has communication and computational overhead that are also linear in the number of signers Moreover, CoSi does not allow signing different messages, and is thus not applicable to large scale network attestation|,Non-data,87
| For the reasons above, in this paper we present a new signature scheme, Optimistic Aggregate Signature (OAS), that: (1) allows signatures on distinct messages to be aggregated; and (2) provides a signature verification algorithm that is constant in the number of signers The communication overhead of the scheme is linear in the number of different messages, while the computational overhead is linear in the number signers who signed a different message than the default one However, this number is assumed limited To the best of our knowledge, our proposed OAS is the first scheme that satisfies the requirements of a secure collective attestation|,Non-data,87
| Finally, we present a pairings-based construction of OAS, and combine it with aggregation trees, providing unlimited scalability Our OAS construction is also applicable to witness cosigning at certification, logging, and timestamping authorities [32] 10 CONCLUSIONS Collective attestation is a key building block for securing the Internet of Things|,Non-data,87
| For very large numbers of devices, to enable enterprises to validate the configuration and software and ensure that all devices are indeed up-to-date In this paper, we have pro- posed the first practical and secure collective attestation scheme SANA It substantially improves the state of the art (eg|,Non-data,87
| SEDA [5]) in three aspects: (1) it is easy to deploy since it can use any untrusted aggregator; (2) its output is publicly verifiable since a short aggregate attestation can be publicly verified by anyone; (3) it provides superior security since it ensures that if a device is fully compromised (including its hardware and keys), then other devices are not affected at all; and (4) it allows a realistic trust model, where only the attested devices are required to be trusted We have demon- strated that the protocol is truly scalable and can be implemented on lightweight devices Acknowledgements We thank anonymous reviewers for their useful comments This research was co-funded by the German Science Foundation, as part of project S2 within CRC 1119 CROSSING, EC-SPRIDE, the Eu- ropean Union’s 7th Framework Programme, under grant agreement No|,Non-data,87
| 609611, PRACTICE project, and Intel Collaborative Research Institute for Secure Computing (ICRI-SC) This work is also par- tially supported by the EU TagItSmart! Project (agreement H2020- ICT30-2015-688061), and the EU-India REACH Project (agree- ment ICI+/2014/342-896) Mauro Conti is supported by a Marie Curie Fellowship funded by the European Commission (agreement PCIG11-GA-2012-321980) 11|,Non-data,87
|ABSTRACT Recent literature on iOS security has focused on the ma- licious potential of third-party applications, demonstrating how developers can bypass application vetting and code- level protections In addition to these protections, iOS uses a generic sandbox profile called “container” to confine ma- licious or exploited third-party applications In this paper, we present the first systematic analysis of the iOS container sandbox profile We propose the SandScout framework to extract, decompile, formally model, and analyze iOS sand- box profiles as logic-based programs|,Non-data,88
 We use our Prolog- based queries to evaluate file-based security properties of the container sandbox profile for iOS 902 and discover seven classes of exploitable vulnerabilities These attacks affect non-jailbroken devices running later versions of iOS,Non-data,88
| We are working with Apple to resolve these attacks, and we expect that SandScout will play a significant role in the develop- ment of sandbox profiles for future versions of iOS 1 INTRODUCTION The sale of smartphones has out-paced the sale of PCs [15] The two dominant platforms for these smart phones are Android and iOS [16]|,Non-data,88
| There has been a sig- nificant amount of academic research on Android, in part, because of its open-source nature In contrast, iOS is not open-source, and studies of iOS may require significant re- verse engineering effort Prior research on iOS security has focused on the follow- ing three areas First, works have demonstrated methods for creating iOS malware [48, 22, 33, 52, 40, 47]|,Non-data,88
| Second, others emphasize methods to detect malicious behavior ei- ther statically [29] or dynamically [28] Third, new security mechanisms [22, 26, 50] have been proposed that hook into Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita- tion on the first page Copyrights for components of this work owned by others than ACM must be honored Abstracting with credit is permitted|,Non-data,88
| To copy otherwise, or re- publish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acmorg CCS’16, October 24-28, 2016, Vienna, Austria c(cid:13) 2016 ACM|,Non-data,88
 ISBN 978-1-4503-4139-4/16/10   $15,Non-data,88
00 DOI: http://dxdoiorg/101145/2976749,Non-data,88
2978336 application code to provide additional security All of these works rely on interacting with the code of third-party iOS applications We investigate something different: iOS sandbox profiles These sandbox profiles define access control policies for sys- tem calls made by processes,Non-data,88
| There are 117 sandbox profiles in the iOS 902 kernel, and many system daemons and ap- plications have dedicated profiles However, all third-party applications, and some system applications, are confined us- ing the shared “container” sandbox profile|,Non-data,88
| The container sandbox profile is large and complex, leading to the research question: what flaws in the container sandbox profile can third-party iOS applications exploit? Goals and Contributions: In this paper, we present the SandScout framework to answer this research question First, we create a tool, SandBlaster, which automatically extracts compiled profiles from a firmware image and de- compiles them into their original SandBox Profile Language (SBPL) Second, we formally model sandbox profiles using Prolog by creating a compiler that automatically translates SBPL policies into Prolog facts Third, we develop Prolog queries that test critical security properties of the container sandbox policy|,Non-data,88
| The queries identify potential security vul- nerabilities in the policy Finally, we create an iOS applica- tion that provides assisted verification of potential vulnera- bilities on iOS devices We use SandScout to evaluate the container sandbox pro- file for iOS 90|,Non-data,88
|2 Sandbox profiles mediate all system calls including file access and inter-process communication (IPC) For this evaluation, we limit our security queries to file-based sandbox policy rules for two reasons First, non-file-based sandbox policy rules require additional semantics that are not available in the policy|,Non-data,88
| Second, we find significant se- curity vulnerabilities within the file-based sandbox policy rules We plan to expand our analysis to non-file-based pol- icy rules in future work Our analysis of the file-based policy rules in the iOS 90|,Non-data,88
2 container sandbox profile identified seven broad vul- nerabilities that are exploitable by third-party applications: (1) methods of bypassing iOS’s privacy settings for Con- tacts; (2) methods of learning a user’s location search his- tory; (3) methods of inferring sensitive information by ac- cessing metadata of system files; (4) methods of obtaining 704the user’s name and media library; (5) methods of consum- ing disk storage space that cannot be recovered by unin- stalling the malicious app; (6) methods of preventing access to system resources such as the AddressBook; (7) methods for colluding applications to communicate without using iOS sanctioned IPC We have reported all of these vulnerabili- ties to Apple and are working with them to ensure they are fixed in future versions of iOS This paper makes the following contributions: • We develop the first methods to automatically produce human readable SBPL policies Prior work was unable to produce SBPL policies for human review or auto- mated analysis,Non-data,88
| Our tool extracts and decompiles all sandbox profiles in firmwares for iOS 7, 8, and 9 • We formally model SBPL policies using Prolog We create an SBPL to Prolog compiler based on a context free grammar we have defined for SBPL • We perform the first systematic evaluation of the con- tainer sandbox profile for recent versions of iOS and discover vulnerabilities|,Non-data,88
| We develop Prolog queries representing security requirements When applied to the iOS 902 container sandbox profile, we discover seven classes of security vulnerabilities|,Non-data,88
 The remainder of the paper proceeds as follows Section 2 provides background information Section 3 provides an overview of SandScout Section 4 discusses our design,Non-data,88
 Sec- tion 5 presents our results Section 6 provides discussion of our limitations Section 7 presents related work Section 8 concludes,Non-data,88
| 2 BACKGROUND iOS is the operating system of the iPhone, iPod, iPad, and older versions of AppleTV (newer AppleTV devices run TVOS) iOS is based largely on Apple’s desktop operating system, OS X, and the two share many internal similarities 2|,Non-data,88
|1 iOS Security Mechanisms iOS relies on four broad types of security mechanisms: ap- plication vetting, code signing, memory protection, and sand- boxing When developers submit an application to the App Store [7] for vetting, they sign the application using their de- veloper key While the specific details of the vetting process are only known to Apple, it is assumed that they use a com- bination of static and dynamic analysis to detect malicious behavior If Apple approves of the application, it adds its own signature to the application and makes the application available on the App Store|,Non-data,88
| An iOS device will only execute code pages coming from binaries with valid signatures Generally, having a valid sig- nature means the application is signed by Apple However, devices provisioned for developers or enterprises may also run applications signed by specific developer and enterprise keys Finally, immutable capabilities called entitlements are stored inside an application’s signature|,Non-data,88
| Apple grants devel- opers a certificate that determines which entitlements they may apply to their applications In addition to code signing, iOS uses data execution prevention (DEP) and address space layout randomization (ASLR) to mitigate memory attacks DEP prevents code injection attacks by ensuring that no code page is writable and executable at the same time ASLR mitigates code- reuse attacks by randomizing code and data segments in memory|,Non-data,88
| Interestingly, code signing complicates the ASLR design and limits its protection, because shuffling code re- gions may invalidate signatures [2] Prior work [48, 22, 42, 34] has demonstrated several techniques for bypassing ap- plication vetting and memory protections iOS sandboxes all applications using a mandatory access control policy to limit the abilities of exploited or malicious code Sandbox policies are enforced by the Trusted BSD mandatory access control framework [18] using a kernel ex- tension called Sandbox|,Non-data,88
|kext iOS uses different sandbox poli- cies (called profiles) for different applications Many system applications and daemons have their own profile However, all third-party applications are controlled by a generic sand- box profile called container|,Non-data,88
| The container sandbox profile is also used by several system applications In order to sup- port the functionality of many different applications, it is the largest and most complex sandbox profile Sandbox profile rules define access to system calls (eg|,Non-data,88
|, file read and write) To be generic, the container sandbox profile uses conditional rules that may require capabilities There are two primary types of capability considered by the sandbox: entitlements and sandbox extensions Mentioned above, entitlements are static capabilities assigned by ap- plication’s developer during development|,Non-data,88
| Entitlements are key-value pairs, which are stored in a dictionary structure embedded in an application’s code signature Note that en- titlement keys are not cryptographic keys, and they simply map to values in the entitlement dictionary Once the ap- plication has been signed, its entitlements cannot be mod- ified without invalidating the signature In contrast, sand- box extensions are dynamic capabilities that can be granted or revoked at run time|,Non-data,88
| System daemons such as the tccd daemon, which helps enforce iOS’s user specified Privacy Settings, can grant sandbox extensions Finally, while the vast majority of iOS’s access control policy is enforced in Sandboxkext using sandbox profiles, there are various access control checks within system dae- mons These system daemons maintain their own policies based on user p|,Non-data,88
|ABSTRACT Differential power analysis (DPA) is a side-channel attack in which an adversary retrieves cryptographic material by measuring and analyzing the power consumption of the device on which the crypto- graphic algorithm under attack executes An effective countermea- sure against DPA is to mask secrets by probabilistically encoding them over a set of shares, and to run masked algorithms that com- pute on these encodings Masked algorithms are often expected to provide, at least, a certain level of probing security Leveraging the deep connections between probabilistic infor- mation flow and probing security, we develop a precise, scalable, and fully automated methodology to verify the probing security of masked algorithms, and generate them from unprotected descrip- tions of the algorithm|,Non-data,94
| Our methodology relies on several contribu- tions of independent interest, including a stronger notion of probing security that supports compositional reasoning, and a type system for enforcing an expressive class of probing policies Finally, we validate our methodology on examples that go significantly beyond the state-of-the-art 1 INTRODUCTION Differential power analysis, or DPA [26], is a class of side-channel attacks in which an adversary extracts secret data from the power consumption of the device on which a program manipulating the data executes|,Non-data,94
| One practical countermeasure against DPA, called ∗Preliminary and long versions of this work appear as revisions of IACR ePrint report 2015/506 [5] Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page Copyrights for components of this work owned by others than the author(s) must be honored Abstracting with credit is permitted|,Non-data,94
| To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acmorg CCS’16, October 24 - 28, 2016, Vienna, Austria c(cid:13) 2016 Copyright held by the owner/author(s)|,Non-data,94
 Publication rights licensed to ACM ISBN 978-1-4503-4139-4/16/10  ,Non-data,94
 $1500 DOI: http://dxdoiorg/10,Non-data,94
|1145/29767492978427 masking [12, 23], transforms an algorithm that performs computa- tions over a finite ring K into a randomized algorithm that manip- ulates probabilistic encodings1At an abstract level, any masking transformation performs two tasks First, it replaces every algebraic operation performed by the original algorithm by a call to a gadget, i|,Non-data,94
|e a probabilistic algorithm that simulates the behavior of algebraic operations on probabilistic encodings Second, it inserts refreshing gadgets, ie|,Non-data,94
| gadgets that take a probabilistic encoding of v and rerandomizes its shares in order to produce another probabilistic encoding w of v Inserting refreshing gadgets does not change the functional behavior of the masked algorithm, and increases the ran- domness complexity and execution time of the masked program However, it is also compulsory for achieving security Therefore, an important line of research is to find suitable trade-offs that ensure security while minimizing the performance overhead of masking; see [9] for recent developments in this direction|,Non-data,94
| The baseline notion of security for masked algorithms is t-probing security Informally, an algorithm P is t-probing secure if the values taken by at most t intermediate variables of P during execution do not leak any information about secrets (held by its inputs) More formally, an algorithm P achieves t-probing security iff for every set of at most t intermediate variables, the joint distributions of the values taken by these intermediate variables coincide for any two executions initiated from initial inputs that agree on t shares of each input encoding Stated in this form, probing security is an instance of probabilistic information flow, universally quantified over all position sets that meet a cardinality constraint, and is there- fore potentially amenable to formal analysis using a well-developed body of work on language-based security and program verification|,Non-data,94
| Indeed, the connection between probing security and information flow has been instrumental in a promising line of research, initiated in [28] and further developed in [8, 21, 20, 4], which uses type sys- tems, program logics, SMT solvers and other methods for verifying 1A t-encoding of an element v ∈ K is a (t + 1)-tuple v = = v0 ⊕    ⊕ vt = v|,Non-data,94
| Each of the vı ∈ K in an encoding v of v is called a share Moreover, t is called the masking order A probabilistic encoding of v is a distribution over encodings of v (cid:104)v0, |,Non-data,94
|   , vt(cid:105) such that(cid:74)v(cid:75) (cid:52) 116or synthesizing masked algorithms at small (≤ 5) orders However, none of these works addresses the problem of composition, and all fail to scale either to higher orders or to larger algorithms|,Non-data,94
| Contributions We develop precise and scalable techniques for synthesizing masked algorithms that achieve probing security Our techniques apply to a wide range of probing policies, including existing policies and new policies defined in this paper, and deliver masked algorithms that outperform (in terms of randomness com- plexity and computational efficiency) prior approaches In more detail, we make the following broad contributions: 1|,Non-data,94
| Strong non-interference We introduce a stronger notion of probing security, which we call strong non-interference, and prove that it is in fact satisfied by many (but not all) gadgets from the literature Furthermore, we justify that strong non-interference is the desired property for refreshing gadgets, by reconsidering known negative and positive results [16] for a simplified example extracted from Rivain and Prouff’s inversion algorithm [32] We first observe that the refreshing gadget used in the original, flawed, algorithm does not enjoy strong non-interference|,Non-data,94
| Second, we note that the refreshing gadget used in the fixed, secure, algorithm is indeed strongly non-interfering, and we show that one can prove the probing security of the fixed algorithm, based simply on the assumption that the refreshing gadget is strongly non-interfering Generalizing these observations, we prove that every non-interfering algorithm can be turned into a strongly non-interfering algorithm, by processing its inputs or its output with a strongly non-interfering refreshing gadget We also provide more general results about the composition of strongly non-interfering gadgets 2|,Non-data,94
| Formal proofs We develop and implement an automated method, inspired from [4], for checking strong non-interference We apply our automated verifier for strong non-interference to several gadgets from the literature and some other interesting compositions, for orders t ≤ 6 For several more widely-used gadgets, we further use EasyCrypt [6] to provide machine-checked proofs of t-probing security for all t|,Non-data,94
| 3 Type-based enforcement of probing security We define an expressive language for specifying a large class of non-interference properties with cardinality constraints Our language can be seen as a variant of the first-order theory of finite sets with cardinality constraints [33, 3], and can be used to specify baseline probing security and strong non-interference, among others|,Non-data,94
| Then, we define a type system that enforces probing policies and prove its soundness Furthermore, we show how to model in our language of probing policies the notion of affine gadget, and we show how it helps improve the precision of type-checking 4 Certifying Masking Transformation|,Non-data,94
| As a proof of concept, we implement a type inference algorithm and a certifying masking trans- formation that takes as input an arithmetic expression and returns a masked algorithm typable by our type system2 Our transforma- tion improves over prior works by selectively inserting refreshing gadgets only at points where type-checking would otherwise fail This strategy leads to improved efficiency while retaining provable soundness 5|,Non-data,94
| Practical evaluation We evaluate our type system and mask- ing transformation on complete algorithms at various orders, often achieving provable t-probing security levels far beyond the state-of- the-art for algorithms of those sizes, and with better performance 2The cryptography literature often refers to such transformations as masking compilers We purposely avoid this terminology, since the terms is used in programming languages for transformations that output executable code than most known (provably secure) algorithms in terms of time, memory and randomness complexity Related work|,Non-data,94
| Section 9 discusses related work in more detail Here we focus on recent work on automated tools for the verifi- cation of synthesis of masked algorithms, starting with Moss et al [28], who point out and leverage connections between probing security and probabilistic information-flow for first-order boolean masking schemes Subsequent works in this direction accommodate higher-order and arithmetic masking, using type systems and SMT solvers [8], or model counting and SMT solvers [21, 20]|,Non-data,94
| Although approaches based on model counting are more precise than early ap- proaches based on type systems and can be extended to higher-order masking schemes, their algorithmic complexity constrains their ap- plicability In particular, existing tools based on model counting can only analyze first or second order masked implementations, and can only deal with round-reduced versions of the algorithms they con- sider (for instance, only analyzing a single round of Keccak at order 1, and algorithms for field operations at orders 2 and higher) Break- ing away from model counting, Barthe et al [4] develop efficient algorithms for analyzing the security of masked algorithms in the probing model|,Non-data,94
| Their approach outperforms previous work and can analyze a full block of AES at first-order, reduced-round (4 rounds) AES at the second-order, and several S-box computation algorithms masked at the third and fourth orders However, their work does not readily scale either to higher orders or to larger algorithms, mainly due to the lack of composition results Our work also bears some connections with language-based secu- rity, and in particular with work on the specification and the enforce- ment of confidentiality policies using techniques from programming languages For instance, our work has similarities with the work of Pettai and Laud [30], who develop techniques for proving security of multi-party computations in the presence of strong adversaries, and work by Zdancewic et al|,Non-data,94
| [34], who propose a compiler that partitions programs for secure distributed execution Mathematical preliminaries A function μ : B → R≥0 is a (discrete) distribution over B if the subset supp(μ) of B with non- b∈supp(μ) μ(b) = 1 We let D(B) denote the set of discrete distributions over B|,Non-data,94
| Equality of distributions is defined as pointwise equality of functions Dis- tributions can be given a monadic structure with the two operators munit(·) and mlet · = · For every b ∈ B, munit(b) is the unique distribution μ such that μ(b) = 1 Moreover, given μ : D(B) and M : B → D(C), mlet x = μ inM x is the unique distribution μ(cid:48) zero weight under μ is discrete and moreover(cid:80) over C such that μ(cid:48)(c) =(cid:80) b μ(b) M (b)(c)|,Non-data,94
| We often use the notion of marginals The first and second marginals of a distribution μ ∈ D(B1 × B2) are the distributions π1(μ) ∈ D(B1) and π2(μ) ∈ D(B2) given by π1(μ)(b1) = μ(b1, b2) π2(μ)(b2) = μ(b1, b2) The notion of marginal readily extends to distributions over finite maps (rather than pairs) 2|,Non-data,94
| A BIRD’S EYE VIEW OF STRONG NON- INTERFERENCE Before formalizing our definitions, we give an intuitive descrip- tion of our language for gadgets and of our security notions, based on simple examples (cid:88) b2∈B2 (cid:88) b1∈B1 117(cid:74)a(cid:75) =(cid:74)c(cid:75) The gadget first makes local copies of individual input Gadgets and Positions Gadget RefreshM2 (Gadget 1) shows the description in our language of a mask refreshing gadget for t = 2|,Non-data,94
| The gadget takes as input an encoding variable a ∈ K3, where K is some finite ring and returns a new encoding c ∈ K3 such that shares aı (for 0 ≤ ı ≤ 2) of a into local variables cı (for 0 ≤ ı ≤ 2) After this first step, we sample uniform random elements from K into a local variable r and perform some ring operations Finally, the algorithm returns a vector in K3, constructed from the final value of local variables c0, c1 and c2 Gadget 1 SNI Mask Refreshing with t = 2 function RefreshM2(a) c0,0 ← a0; c1,0 ← a1; c2,0 ← a2; r0 r1 r2 return (cid:104)c0,2, c1,2, c2,2(cid:105) $← K; c0,1 ← c0,0 ⊕ r0; c1,1 ← c1,0 (cid:9) r0; $← K; c0,2 ← c0,1 ⊕ r1; c2,1 ← c2,0 (cid:9) r1; $← K; c1,2 ← c1,1 ⊕ r2; c2,2 ← c2,1 (cid:9) r2; Note that the gadget is written in single static assignment (SSA) form, an intermediate representation in which each variable is de- fined exactly once|,Non-data,94
| Having gadgets written in SSA form allows us to easily refer to the value of a particular variable at a partic- ular point in the program–simply by referring to its name, which corresponds to a unique definition In this paper, we refer to po- sitions in gadgets and algorithms, which correspond exactly to in- termediate variables We distinguish between three different kinds of positions: input positions, which correspond to shares of the gadget’s input (here, IRefreshM2 = {a0, a1, a2}), output positions, which correspond to the variables that appear in the gadget’s re- RefreshM2 = {c0,2, c1,2, c2,2}), and internal turn vector (here, Oint positions, which refer to all other positions (here, Oext RefreshM2 = {c0,0, c1,0, c2,0, c0,1, c1,1, c2,1, r0, r1, r2}) Intuitively, this separa- tion allows us to distinguish between direct observations made by the adversary into a gadget (as internal positions), output shares about which the adversary may have learned some information by probing gadgets that use them as input (as output positions), and shares of the gadget’s inputs (as input positions) about which the adversary is now learning information|,Non-data,94
| In the following, we often write “the joint distribution of a set of positions” to discuss the joint distribution of the variables defined at these positions in the gadget (in order) For example, referring to RefreshM2, the joint distribution of the ordered set O = (cid:104)c0,1, c2,2(cid:105) of positions can be described as the following function of a, where we use $ to denote a fresh uniform random sample in K (using indices to denote distinct (cid:52) = (cid:104)a0 ⊕ $0, (a2 (cid:9) $1) (cid:9) $2(cid:105) samples):(cid:74)RefreshM2(cid:75)O(a) Probing Security and Non-Interference The RefreshM2 gadget is known to be 2-probing secure, or 2-non-interfering (2-NI) in our terminology, in the sense that the joint distribution of any set of at most 2 of its positions, corresponding to adversary probes, depends on at most 2 shares of the gadget’s inputs|,Non-data,94
| This guarantees, if the input encoding is uniform, that no information about it leaks through any 2 probes in the circuit Considering again the set O = (cid:104)c0,1, c2,2(cid:105) of positions and its distribution(cid:74)RefreshM2(cid:75)O, it is easy to see–purely syntactically– that it depends, at most, on shares a0 and a2 of the gadget’s input encoding Similarly considering all possible pairs of positions, we can prove that each of them has a joint distribution that depends on at most two shares of a Strong Non-Interference|,Non-data,94
| Probing security is generally not composable: combining t-probing secure gadgets does not necessar- ily yield a t-probing secure algorithm [16] Our main contribution is a new and stronger notion of security for gadgets, which we dub strong non-interference (or SNI), which does support some com- positional reasoning SNI reinforces probing security by requiring that the number of input shares on which the distribution of a given position set may depend be determined only by the number of in- ternal positions present in that set For example, consider again position set O = (cid:104)c0,1, c2,2(cid:105) in RefreshM2, and note that it contains only one internal position (c0,1)|,Non-data,94
| We have seen that the joint dis- tribution(cid:74)RefreshM2(cid:75)O of that position set syntactically depends (cid:74)RefreshM2(cid:75)O(a) = (cid:104)$0, (a2 (cid:9) $1) (cid:9) $2(cid:105) (since the ring addition on two shares of a However, it can be equivalently expressed as ⊕ is a bijection of each of its arguments and $0 is a fresh and uni- form ring element) This shows that the distribution in fact depends on at most one share of a (here a2) In fact, it can be shown that RefreshM2 is 2-SNI|,Non-data,94
| More generally, surprisingly many gadgets from the literature achieve SNI However, and not unexpectedly, some gadgets from the literature do not satisfy SNI Consider for instance RefreshA2 (Gadget 2) It is easy to see that the gadget is 2-NI (each position cı, depends only on input share aı, and each position ri is completely independent from the input encoding)|,Non-data,94
| Still, looking at position set O(cid:48) = (cid:104)c0,1, c1,1(cid:105), which is composed of one internal position and one external one, (cid:52) = (cid:104)a0 ⊕ $0, a1 ⊕ $0(cid:105) does depend on more than one share of a RefreshA2 is therefore not 2-SNI we see that the distribution(cid:74)RefreshA2(cid:75)O(cid:48) Gadget 2 NI Mask Refreshing with t = 2 function RefreshA2(a) c0,0 ← a0; c1,0 ← a1; c2,0 ← a2; r0 r1 return (cid:104)c0,2, c1,1, c2,1(cid:105) $← K; c0,1 ← c0,0 ⊕ r0; c1,1 ← c1,0 (cid:9) r0; $← K; c0,2 ← c0,1 ⊕ r1; c2,1 ← c2,0 (cid:9) r1; Compositional Probing Security This small difference be- tween NI and SNI has a significant effect on security when used in larger circuits|,Non-data,94
| Indeed, the output positions of a strongly non- interfering gadgets do not depend on any of its input positions: when considered independently from internal positions (in the absence of internal probes), their distribution is uniform; and in the presence of internal probes, their joint distribution is entirely determined by that of the probed internal positions This is essential in supporting compositional reasoning about the probing security of larger algo- rithms In particular, this makes algorithms of the form shown in Algorithm 3 (for some gadgets R and G of the appropriate types that work on 2-encodings) easy to prove t-NI if R is RefreshM2, and illustrates why composition might fail if R is instantiated with RefreshA2 Alg|,Non-data,94
| 3 An abstract algorithm function Alg2(a) b := R(a); c := G(a, b); return c A key observation to make is that an adversary that observes 2 positions internal to G may learn 2 shares of both a and b If R is instantiated with RefreshA2 (and is thus only 2-probing secure), the 1182 shares of b can be used to infer information about 2 further shares of a, which may give the adversary full knowledge of all 3 shares of a On the other hand, if R is instantiated with RefreshM2 (and is thus 2-SNI), the adversary’s knowledge of 2 shares of b does not propagate any further back to a, and the algorithm remains secure Broader uses of SNI|,Non-data,94
| The notion of strong non-interference, and the masking transformation we define here have already found applications in follow-up work Belaïd et al [9] prove using our compositional techniques that their new non-interfering multiplica- tion can be securely combined with the strongly non-interfering one of Rivain and Prouff [32] to build a strongly non-interfering AES S-box with reduced randomness complexity Similarly, Goudarzi and Rivain [24] use our method to ensure the compositional secu- rity of their bitsliced software implementation of AES|,Non-data,94
| Battistelo et al [7] use and prove t-SNI for their O(n · log n) mask refreshing gadget, allowing further randomness complexity reductions without loss of probing security Coron et al [17] use and prove t-SNI for their efficient parallel algorithms for the evaluation of SBoxes|,Non-data,94
| Outline The rest of the paper is organized as follows Section 3 formalizes our two-tier language for masked gadgets and algorithms, the notion of position, and their semantics, as well as the joint dis- tribution of a set of positions Sections 4, and 5 formalize probing security as t-non-interference, and formally define our new notion of t-strong-non-interference before illustrating it more generally with simple examples|,Non-data,94
| In Section 6, we define a language to describe probing policies, and define a simple type system for enforcing probing policies of algorithms, formalizing and generalizing the simple compositional arguments outlined here In Section 7, we present an automated method to verify the strong non-interference of arbitrary gadgets at small fixed orders, that follows the approach used above in arguing that RefreshM2 is 2-SNI, and adapts algo- rithms by Barthe et al [4] to reduce the number of position sets to consider In Section 8, we extend our type system into a masking transformation which automatically builds a masked algorithm from an unprotected program, carefully choosing the proper locations for strongly non-interfering refreshing gadgets|,Non-data,94
| We evaluate on full cryptographic algorithms the performance of the type system, of the resulting transformation, and of the transformed algorithms Sec- tion 9 discusses related work on leakage models, composition for probing security, and other masking transformations We interleave discussions of interesting leads for future work 3|,Non-data,94
| MASKED ALGORITHMS The formal development of this paper is based on a minimalist 2-tier language3 The lower tier models gagdets as sequences of probabilistic and (three-address code) deterministic assignments, whereas the upper tier models algorithms as sequences of gadget calls (we assume that each gadget call is tagged with its instruction number (cid:96) ∈ N) The formal definition of the language is given in Figure 1, where we use vector notations ((cid:126)x,  |,Non-data,94
|  ) to denote (t + 1)- tuples of scalar variables, ı to denote indices (such that 0 ≤ ı ≤ t) in such a tuple or in encoding variables, and exponents ·ı to denote the projection of a component out of a (t + 1)-tuple (for example aı, or (cid:126)xı) We require gadgets and algorithms to be well-formed, 3However, the verification tool supports richer settings to which the theory extends smoothly and our examples are written in a more general language, closer to our implementation, that supports static for loops, direct assignments to shares (aı ← e), arbitrary expressions on the right-hand side of assignments, and a broader return syntax For example, Gadget 4 shows generic descriptions of the mask refreshing algorithms from Section 2|,Non-data,94
| algorithm alg body gadget gadget body P (a1,   |,Non-data,94
| , an) ::= s; return a s ::= b :=(cid:96) G(a1,    , an) || s; s G(a1, |,Non-data,94
|   , an) ::= c; return (cid:126)x c ::= x $← K || x ← e || c; c expressions e ::= x, y,  |,Non-data,94
|  || aı || x (cid:63) y gadget call call seq prob|,Non-data,94
 assign det assign assign,Non-data,94
| seq variable ıth-share of a ring operation Figure 1: Syntax of masked algorithms in the following sense A gadget G is well-formed if its body is in SSA form, ie|,Non-data,94
| its scalar variables appear at most once on the left-hand side of an assignment An algorithm P is well-formed if all its gadgets are defined and well-formed, and if, in all gadget calls b := G(a1,   |,Non-data,94
| , an), variables b, a1,    , ak are pairwise disjoint|,Non-data,94
| We now turn to the semantics of gadgets and algorithms Cru- cially, the semantics of gadgets and algorithms is instrumented to keep track of the joint distribution of all intermediate values computed during execution Formally, we assume that scalar and encoding variables take values in K and Kt+1, where K is the carrier set of a finite ring (K, 0, 1,⊕,(cid:9),(cid:12)) We let Val = Kt+1 denote the set of encoded values|,Non-data,94
| Furthermore, we let A denote the set of encoding variables and define the set of global memories as Mem = A → Kt+1 Likewise, we let V denote the set of scalar variables and define the set of local memories as LMem = V (cid:42) K and extended local memories as ELMem = (N × V) (cid:42) K Then, the semantics of a gagdet G is a function(cid:74)G(cid:75) that takes as input a function(cid:74)P(cid:75) that takes as input a global memory and returns a dis- global memory and returns a distribution over pairs of local mem- ories and values Likewise, the semantics of an algorithm P is a tribution over extended local memories and values|,Non-data,94
| The semantics is outlined in Figure 2 In order to define probing security, we first define a notion of position that corresponds to the intuition illustrated in Section 2 First, we define the set I (cid:52) = {aı || a ∈ A, 0 ≤ ı ≤ t} of input positions (these correspond to shares of encodings used in the gadget or algorithm), the set O (cid:52) = I ∪ V of positions (composed of input positions and scalara variables) and the set O+ (cid:52) = I ∪ (N × V) of extended positions (where scalar variables are tagged with a label in N to differentiate between uses of a variable in different gadgets) The input positions of a gadget G and of an algorithm P are denoted by IG and IP respectively and contain exactly those elements of I that correspond to encoding variables that occur in G or P |,Non-data,94
| Likewise, the set of positions of a gadget G and of an algorithm P are denoted by OG ⊆ O and OP ⊆ O+ respectively and consist of all positions that occur in a gadget G, and all extended positions that occur in an algorithm P  To capture the joint distribution of a set of positions O in a gadget G or an algorithm P (with O ⊆ OG, resp O ⊆ OP ), we take the marginal of the gadget or algorithm’s semantics with respect to O These are denoted by(cid:74)G(cid:75)O : Mem → D(O → K) and (cid:74)P(cid:75)O : Mem → D(O → K) respectively|,Non-data,94
|4 that one can refine the type of(cid:74)G(cid:75) given in Figure 2 to Mem → 4In order to justify that the marginals have the required type, observe 119with m ∈ Mem and lm ∈ LMem : K : D(Mem × LMem) with m ∈ Mem and lm ∈ LMem (cid:74)e(cid:75)(m, lm) (cid:74)x(cid:75)(m, lm) = lm(x) (cid:74)aı(cid:75)(m, lm) = m(a)ı (cid:74)x (cid:63) y(cid:75)(m, lm) = lm(x) (cid:63) lm(y) (cid:74)c(cid:75)(m, lm) (cid:74)x ← e(cid:75)(m, lm) = munit(m, lm{x ←(cid:74)e(cid:75)(m, lm)}) (cid:74)x $← K(cid:75)(m, lm) = mlet v = UK in munit(m, lm{x ← v}) (cid:74)c1; c2(cid:75)(m, lm) = mlet (m1, lm1) =(cid:74)c1(cid:75)(m, lm) in(cid:74)c2(cid:75)(m1, lm1) (cid:74)G(cid:75)(m) (cid:74)G(cid:75)(m) = mlet (m1, lm1) =(cid:74)c(cid:75)(m,∅) in munit(lm1, lm1((cid:126)x)) (cid:74)s(cid:75)(m, elm) (cid:74)s1; s2(cid:75)(m, elm) = mlet (m1, elm1) =(cid:74)s1(cid:75)(m, elm) in(cid:74)s2(cid:75)(m1, elm1) (cid:74)P(cid:75)(m) (cid:74)P(cid:75)(m) = mlet (m1, elm1) =(cid:74)s(cid:75)(m,∅) in munit(elm1, m1(b)) : D(Mem × ELMem) : D(ELMem × Val) : D(LMem × Val) with m ∈ Mem and G(a1,    , an) ::= c; return (cid:126)x with m ∈ Mem and P (a1, |,Non-data,94
|   , an ::= s; return b (cid:74)b :=(cid:96) G(c1,  |,Non-data,94
|  , cn)(cid:75)(m, elm) = mlet (lm1, v) =(cid:74)G(cid:75)(m{a0,   |,Non-data,94
| , at ← m(c0),    , m(ct)}) in munit(m{b ← v}, elm (cid:93) elm1) with m ∈ Mem, elm ∈ ELMem and G(a1, |,Non-data,94
|   , an) ::= c; return (cid:126)x where elm1 is the map defined by setting only elm1((cid:96), v) = lm(v) for all v ∈ dom(lm) where m{x1,  |,Non-data,94
|  , xn ← v1,   |,Non-data,94
| , vn} denotes the map m where xi is updated with vi for each i in increasing order, and (cid:93) denotes the disjoint union of partial maps Figure 2: Semantics of gadgets and algorithms 4 BASELINE PROBING SECURITY We first review the basic notion of probabilistic non-interference and state some of its key properties As usual, we start by introduc- ing a notion of equivalence on memories|,Non-data,94
| DEFINITION 1 Let G be a gadget, and let I ⊆ IG Two memo- ries m, m(cid:48) ∈ Mem are I-equivalent, written m ∼I m(cid:48), whenever m(a)ı = m(cid:48)(a)ı for every aı ∈ I Next, we define probabilistic non-interference|,Non-data,94
| DEFINITION 2 Let I ⊆ IG and O ⊆ OG A gadget G is (I,O)-non-interfering (or (I,O)-NI), iff(cid:74)G(cid:75)O(m) =(cid:74)G(cid:75)O(m(cid:48)) dency set of O as depsetG(O) =(cid:84){ I || G is (I,O)-NI }; thus, for every m, m(cid:48) ∈ Mem st|,Non-data,94
| m ∼I m(cid:48) For every gadget G and every position set O, we define the depen- depsetG(O) is the smallest set I ⊆ IG such that G is (I,O)-NI LEMMA 1 Let G be a gadget and O ⊆ OG be a set of positions in G|,Non-data,94
| G is (depsetG(O),O)-NI We conclude this section by providing an alternative definition of non-interference, in the style of simulation-based security LEMMA 2 A gadget G is (I,O)-NI iff there exists a simulator Sim ∈ (I → K) → D(O → K) such that for every m ∈ Mem, (cid:74)G(cid:75)O(m) = Sim(m||I) where m||I is the restriction of m to elements in I|,Non-data,94
| This observation is useful to connect the information-flow based for- mulation of probing security introduced below with the simulation- based formulations of probing security often used by cryptographers Indeed, the dependency set depsetG(O) can be interpreted as a set of G’s input shares that is sufficient to perfectly simulate the joint distribution of positions in O to an adversary Next we define our baseline notion of probing security, which we call t-non-interference, and state some of its basic properties D(Val × (OG → K))|,Non-data,94
| Similarly, one can refine the type of(cid:74)P(cid:75) to Mem → D(Val × (OP → K))  The notion of t-non-interference is based on the notion of degree of an input set, which we define first Given an input set I and an (cid:52) encoding variable a, we define the set I||a = I ∩ a of positions in I that correspond to shares of a Further, we define the degree of an input set I as (cid:107)I(cid:107) (cid:52) = maxa ||I||a|| (where || · || is the standard notion of cardinality on finite sets)|,Non-data,94
| This notion captures the intuition that the adversary should not learn all shares of any single encoding variable, by bounding the information an adversary may learn about any of a gadget’s shared inputs through positions probed internally to that gadget (PROBING SECURITY) A gadget G is t-non- DEFINITION 3 interfering (or t-NI) if (cid:107)depsetG(O)(cid:107) ≤ ||O|| for every O ⊆ OG such that ||O|| ≤ t The next lemma establishes that t-NI is already achieved under a weaker cardinality constraint on the dependency set|,Non-data,94
| Variants of Lemma 3 in simulation-based settings appear in [11, 9] LEMMA 3 A gadget G is t-NI iff (cid:107)depsetG(O)(cid:107) ≤ t for every O ⊆ OG st|,Non-data,94
| ||O|| ≤ t The notion of t-non-interference extends readily to algorithms In addition, one can prove that an algorithm is secure iff the gadget obtained by fully inlining the algorithm is secure LEMMA 4|,Non-data,94
| A program P is t-NI iff the gadget inline(P ) ob- tained by full inlining is t-NI The lemma sheds some intuition on the definition of t-NI for algo- rithms However, we emphasize that verifying fully inlined algo- rithms is a bad strategy; in fact, previous work indicates that this approach does not scale, and that composition results are needed 5|,Non-data,94
| STRONG NON-INTERFERENCE We introduce strong non-interference, a reinforcement of prob- ing security based on a finer analysis of cardinality constraints for dependency sets Informally, strong non-interference distinguishes between internal and output positions, and requires that the depen- dency set of a position set O has degree ≤ k, ie contains at most 120k shares of each encoding input, where k is the number of internal positions in O|,Non-data,94
| Formally, a local variable is an output position for G if it appears in the return tuple of G, and an internal position otherwise Let Oint (resp Oext) denote the subset of internal (resp output) positions of a set O|,Non-data,94
| Strong t-non-interference requires that the degree of depset(O) is smaller than ||Oint||, rather than ||O|| Intuitively, a t-SNI gadget information-theoretically hides de- pendencies between each of its inputs and its outputs, even in the presence of internal probes This essential property is what supports compositional reasoning DEFINITION 4 (STRONG PROBING SECURITY)|,Non-data,94
| A gadget G is t-strongly non-interfering (or t-SNI) if (cid:107)depsetG(O)(cid:107) ≤ ||Oint|| for every position set O such that ||O|| ≤ t Gadget 4 Mask Refreshing Gadgets 0: function RefreshA(a) 1: c0 ← a0 for i = 1 to t do 2: r $← K 3: c0 ← c0 ⊕ r 4: ci ← ai (cid:9) r 5: return c 6: (4a) Addition-Based Mask Refreshing for i = 0 to t do ci ← ai for i = 0 to t do for j = i + 1 to t do r $← K ci ← ci ⊕ r cj ← cj (cid:9) r 0: function RefreshM(a) 1: 2: 3: 4: 5: 6: 7: 8: (4b) Multiplication-Based Mask return c Refreshing Fortunately, many gadgets from the literature achieve strong non- interference (see Table 1 and Section 7) First, we note that gad- get RefreshM (Gadget 4b) generalized from Ishai, Sahai and Wag- ner [25] is t-SNI for all t (A proof sketch for this proposition is given in Appendix A|,Non-data,94
|) PROPOSITION 1 RefreshM (Gadget 4b) is t-SNI On the contrary, the additive refreshing gadget RefreshA (Gad- get 4a) achieves NI but fails to achieve SNI Interestingly, Coron’s linear-space variant of Ishai, Sahai and Wagner’s multiplication [13, Alg|,Non-data,94
| 6] (Gadget 5a) and the MultLin gadget for securely multiplying linearly dependent inputs [16, Alg 5] (Gadget 5b) are both strongly non-interfering The proof of SNI for Gadget 5a is easy to adapt to the more standard quadratic-space multiplication gadget, since they compute the same intermediate values in different orders PROPOSITION 2|,Non-data,94
| The SecMult gadget (Gadget 5a) is t-SNI PROPOSITION 3 The MultLin gadget (Gadget 5b) is t-SNI The proofs of Propositions 1, 2 and 3 have been machine-checked using EasyCrypt [6]|,Non-data,94
| We also provide more detailed game-based proof sketches in the full version of this paper Strong Non-Interference for Mask Refreshing We now show how choosing a t-SNI refreshing gadget over a t-NI refreshing gadget critically influences the security of algorithms Concretely, we provide a separating example, which captures the essence of the flaw in the inversion algorithm of Rivain and Prouff [32]|,Non-data,94
| The example considers two algorithms (Algorithm 6) which compute a cube in GF(28) by squaring and multiplying (using, for illustration purposes, some t-NI gadgets Square and Mult for squaring and multiplication) Both algorithms use a refreshing gadget between the two operations, but they differ in which gadget they use: BadCube Gadget 5 Some arithmetic gadgets 0: function SecMult(a, b) 1: 2: 3: 4: 5: 6: 7: 8: 9: 10: 11: 12: (5a) Masked multiplication [13] for i = 0 to t do ci ← ai (cid:12) bi for i = 0 to t do for j = i + 1 to t do r $← K ci ← ci (cid:9) r t ← ai (cid:12) bj r ← r ⊕ t t ← aj (cid:12) bi r ← r ⊕ t cj ← cj ⊕ r return c 0: function MultLin(a) for i = 0 to t do 1: ci ← ai (cid:12) g(ai) 2: for i = 0 to t do 3: for j = i + 1 to t do 4: r $← K 5: r(cid:48) $← K 6: ci ← ci (cid:9) r 7: t ← ai ⊗ g(r(cid:48)) ⊕ r 8: t ← t ⊕ (r(cid:48) ⊗ g(ai)) 9: t ← t ⊕ (ai ⊗ g(aj (cid:9) r(cid:48)) 10: t ← t⊕((aj(cid:9)r(cid:48))⊗g(ai)) 11: cj ← cj ⊕ t 12: 13: (5b) x⊗ g(x) with linear g [16, Alg 5] return c (Gadget 6a) uses the additive refreshing gagdet RefreshA, which is t-NI but not t-SNI, and Cube (Gadget 6b) uses the RefreshM gadget, which is t-SNI This simple difference is fundamental for the security of the two algorithms|,Non-data,94
| Alg 6 Cubing procedures (with K = GF(28)) function BadCube(x) y1 := Square(x) y2 := RefreshA(y1) z := Mult(x, y2) return z (6a) Insecure Cubing function Cube(x) y1 := Square(x) y2 := RefreshM(y1) z := Mult(x, y2) return z (6b) Secure Cubing LEMMA 5 is t-NI for all t ([16]) BadCube is not t-NI for any t ≥ 2|,Non-data,94
| Cube Coron et al [16] exhibit proofs for both statements In Appendix A, we give a compact proof of t-NI for Cube that does not exhaustively consider all (t + 1)-tuples of positions in Cube The key argu- ment is that RefreshM being t-SNI essentially renders useless any information on y2 the adversary may have learned from observing positions in Mult: those do not add any shares of y1 to the depen- dency set we compute for RefreshM, and therefore do not influence the shares of x that appear in the final dependency set for Cube|,Non-data,94
| On the other hand, using a simple t-NI mask refreshing gadget (such as RefreshA) in its place breaks the proof by allowing us to deduce only that each position in the multiplication may depend on 2 shares of x In Section 6, we show how the proof of Lemma 5 can be improved and extended into a compositional proof for the (repaired) inversion algorithm of Rivain and Prouff [32], and, in fact, outlines a general mehodology for proving algorithms t-NI or t-SNI A Generic Composition Result Before formalizing and au- tomating this proof process to obtain precise probing security proofs for large circuits, we now give a coarse but simple composition result that illustrates the generality of SNI|,Non-data,94
| Informally, an algorithm is t-NI if all its gadgets verify t-NI and every non-linear usage of an encoding variable is guarded by t-SNI refreshing gadgets In addition, it shows that processing all inputs, or the output of a t-NI algorithm with a t-SNI gadget (here RefreshM) suffices to make the algorithm t-SNI 121PROPOSITION 4 An algorithm P is t-NI provided all its gad- gets are t-NI, and all encoding variables are used at most once as argument of a gadget call other than RefreshM|,Non-data,94
| Moreover P is t-SNI if it is t-NI and one of the following holds: • its return expression is b and its last instruction is of the form b := RefreshM(a); • its sequence of encoding parameters is (a1,    , an), its ith instruction is b :=i RefreshM(ai) for 1 ≤ i ≤ n, and ai is not used anywhere else in the algorithm|,Non-data,94
| 6 ENFORCING PROBING POLICIES We first define an expressive assertion language for specifying sets of position sets, and then introduce probing policies, which yield a convenient formalism for defining a large class of information flow policies with cardinality constraints (PROBING POLICY) DEFINITION 5 1|,Non-data,94
| A probing assertion is a pair (Γ, φ), where Γ is a map from encoding variables to expressions in the theory of finite sets, and φ is a cardinality constraint Each probing assertion (Γ, φ) defines a set of subsets of positions for a fixed algorithm P , denoted by(cid:74)(Γ, φ)(cid:75) (The syntax and semantics of set expressions and cardinality constraints is explained below) 2|,Non-data,94
| A probing policy is a pair of assertions (Γin, φin) ⇐= (Γout, φout) where (Γout, φout) is the post-assertion and (Γin, φin) is the pre-assertion 3 Algorithm P satisfies the policy (Γin, φin) ⇐= (Γout, φout), written P ||= (Γin, φin) ⇐= (Γout, φout), if for every posi- tion set O ∈ (cid:74)(Γout, φout)(cid:75), P is (I,O)-NI for some input position set I ∈(cid:74)(Γin, φin)(cid:75) The syntax of set expressions and cardinality constraints is given by the following grammar: S := X || ∅ || S ∪ S (set expr|,Non-data,94
