 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| However, this is of little consequence when considering the efficiency of the protocol since our protocol requires only sending a single element per multiplication gate In addi- tion, the computation consists merely of two multiplications and two additions In comparison, the BGW protocol [2, 1] requires transmit- ting two field elements per multiplication gate by each party when using [21] method (with a single round of communi- cation) In addition, when considering Boolean circuits, at least two bits are needed per field element, since there are 3 parties|,Non-data,47
| Furthermore, the computation requires polynomial evaluations which are far more expensive In the Sharemind protocol [4, 5], the parties transmit five ring elements per AND gate over two communication rounds, and compute 3 multiplications and 8 additions We remark that our method for generating correlated random- ness can be used to reduce the number of elements sent in the Sharemind protocol from 5 to 2 and to reduce the num- ber of communication rounds to 1 3|,Non-data,47
| SECURITY FOR SEMI-HONEST ADVERSARIES In this section, we prove that our protocol is secure in the presence of one semi-honest adversarial party (in Section 4 we prove that the protocol is private in the presence of one malicious adversary) Semi-honest security is sufficient when parties somewhat trust each other, but are concerned with inadvertent leakage or cannot share their raw information due to privacy regulations It is also sufficient in cases where it is reasonable to assume that the parties running the pro- tocol are unable to replace the installed code Nevertheless, security against covert or malicious adversaries is preferable, providing far higher guarantees; we leave extensions of our protocol to these settings for future work|,Non-data,47
| Since the protocol for Boolean circuits is a special case of the protocol for the ring modulo 2n, we prove the security 809for the case of the ring modulo 2n The proof is identical in the case of fields with more than 3 elements Throughout, in order to simplify notation, when we use an index (say, i) to denote the ith party (with i ∈ {1, 2, 3}), we will write i − 1 and i + 1 to mean the “previous” and “subsequent” party, respectively That is, when i = 1 then i − 1 = 3 and when i = 3 then i + 1 = 1|,Non-data,47
| 31 Preliminaries We use the definition of security in the presence of semi- honest adversaries as in [6, 11], making the necessary changes to formalize perfect security as well Perfect security in the presence of semi-honest ad- versaries Loosely speaking, a protocol is secure in the presence of one corrupted party if the view of the corrupted party in a real protocol execution can be generated by a simulator given only the corrupted party’s input and out- put|,Non-data,47
| The view of party i during an execution of a protocol π on inputs (cid:126)x, denoted Viewπ i ((cid:126)x), consists of its input xi, its internal random coins ri and the messages that were re- ceived by i in the execution The output of all parties from an execution of π is denoted by Outputπ((cid:126)x) Definition 31|,Non-data,47
| Let f : ({0, 1}∗)3 → ({0, 1}∗)3 be a prob- abilistic 3-ary functionality and let π be a protocol We say that π computes f with perfect security in the presence of one semi-honest corrupted party for f if there exists a proba- bilistic polynomial-time algorithm S such that for every cor- rupted party i ∈ {1, 2, 3}, and every (cid:126)x ∈ ({0, 1}∗)3 where ||x1|| = ||x2|| = ||x3||: (cid:110) (cid:111) (cid:111) ≡(cid:110) (S(xi, fi((cid:126)x)), f ((cid:126)x)) (Viewπ i ((cid:126)x), Outputπ((cid:126)x)) (3) If Eq (3) holds with computational indistinguishability, then we say that π computes f with computational security in the presence of one semi-honest corrupted party The above definition is for the general case of probabilis- tic functionalities, where we consider the joint distribution of the output of S and of the parties|,Non-data,47
| For the case of deter- ministic functionalities, however, we can separate the cor- rectness and privacy requirements, and use a simpler and easier to prove definition As shown in [11](see section 731), any probabilistic functionality can be privately computed in the presence of t corrupted parties using a general proto- col which computes any deterministic functionality in the presence of t corrupted parties|,Non-data,47
| Therefore, in order to prove the security of our protocol we can use the definition for deterministic functionalities stated below Definition 32 Let f : ({0, 1}∗)3 → ({0, 1}∗)3 be a de- terministic 3-ary functionality and let π be a protocol|,Non-data,47
| We say that π computes f with perfect security in the presence of one semi-honest corrupted party for f , if for every (cid:126)x ∈ ({0, 1}∗)3 where ||x1|| = ||x2|| = ||x3||, the following two prop- erties hold: (a) Outputπ((cid:126)x) = f ((cid:126)x), and (b) there exists a probabilistic polynomial-time algorithm S such that for every corrupted party i ∈ {1, 2, 3}, and every (cid:126)x ∈ ({0, 1}∗)3 where ||x1|| = ||x2|| = ||x3||: {S(xi, fi((cid:126)x))} ≡ {Viewπ i ((cid:126)x)} We prove the security of our protocols using the hybrid model, where parties run a protocol with real messages and also have access to a trusted party computing a subfunction- ality for them The modular sequential composition theorem of [7] states that replacing the trusted party computing the subfunctionality with a real secure protocol results in the same output distribution When the subfunctionality is g, we say that the protocol works in the g-hybrid model Universal composability|,Non-data,47
| Protocols that are proven se- cure in the universal composability framework [7] have the property that they maintain their security when run in par- allel and concurrently with other secure and insecure proto- cols In [17, Theorem 15], it was shown that any protocol that is proven secure with a black-box non-rewinding simu- lator and also has the property that the inputs of all parties are fixed before the execution begins (called input availabil- ity or start synchronization in [17]), is also secure under uni- versal composability Since the input availability property holds for all of our protocols and subprotocols, it is suffi- cient to prove security in the classic stand-alone setting and automatically derive universal composability from [17]|,Non-data,47
| We remark that this also enables us to call the protocol and subprotocols that we use in parallel and concurrently (and not just sequentially), enabling us to achieve more efficient computation (eg, by running many executions in parallel or by running each layer of a circuit in parallel) Proof outline|,Non-data,47
| We denote a protocol π in the g-hybrid model by πg, and the real protocol obtained by replacing calls to g by invocations of subprotocol ρ by πρ We abuse notation and write πg ≡ f to say that π securely computes f in the g-hybrid model, and write πρ ≡ f to say that the real protocol πρ securely computes f  Denote by σ the protocol that computes the correlated randomness functionality Fcr, by ρ the protocol that computes the multiplication function- ality Fmult in the Fcr-hybrid model, and by π the protocol that computes the functionality f in the Fmult-hybrid model Our goal is to prove that πρσ securely computes f in the presence of one static semi-honest corrupted party|,Non-data,47
| Let f be a 3-ary functionality We begin by proving that πFmult computes f with perfect security in the presence of one static semi-honest party Next, we prove that ρFcr com- putes Fmult with perfect security in the presence of one static semi-honest party in the Fcr-hybrid model Finally, we prove that σ computes Fcr with computational security in the presence of one static semi-honest party|,Non-data,47
| The reason for achieving only computational security for the correlated ran- domness protocol is that we use a pseudorandom function to compute the random values The proof in this case, thereby, works by making a reduction to a distinguisher between a pseudorandom function and a random function Once we have proved that f ≡ πFmult , that Fmult ≡ ρFcr c≡ σ, we can apply the composition theorem and that Fcr of [7] (using the fact that universal composability is implied via [17]) to conclude that πρFcr ≡ f ; that is, πρσ computes f with computationl security in the presence of one static semi-honest adversary 3|,Non-data,47
|2 Computing f in the Fmult-Hybrid Model We define the multiplication functionality Fmult that re- ceives input shares of two values va, vb as input and outputs shares of the product vavb, according to the secret-sharing Intuitively, Fmult should scheme described in Section 23 be defined by receiving the shares of all parties, reconstruct- ing the values v1, v2 from the shares, and then generating a 810random resharing of the v1v2 Indeed, if secure coin tossing were used instead of the method that we use for correlated randomness, then Fmult would be defined in this natural way|,Non-data,47
| However, this would require additional communication and would affect performance We therefore need to define a more complex multiplication functionality In order to understand why this is needed, recall the real protocol and consider the specific case that P1 is corrupted In order to simplify this explanation, consider the Boolean case|,Non-data,47
| Party P1 computes r1 = x1y1 ⊕ a1b1 ⊕ α and receives r3 from P3 Observe that α is not random to the corrupted P1 and is fixed by a very specific computation (specifically, Fk1 (id) ⊕ Fk2 (id); see Section 22) Thus, P1’s computation of r1 is deterministic|,Non-data,47
| Now, P1’s output from the multi- plication protocol is the pair (z1, c1) where z1 = r1 ⊕ r3 and c1 = r1 Since r3 is received from P3 and is masked with the correlated randomness that P3 receives (which is generated using a pseudorandom function with a key not known to P1) this value is random However, c1 is fixed (since it equals r1) Stated differently, given that r1 is fixed, there are exactly two possible values for (z1, c1) based on z1 = 0 or z1 = 1|,Non-data,47
| In contrast, a random secret sharing has four possible values for (z1, c1), with all four combinations of z1, c1 ∈ {0, 1} Thus, it is not true that the multiplication protocol generates a new random sharing of the product In order to solve this problem, we take a different ap- proach We allow the corrupted party to completely de- termine its share (zi, ci)|,Non-data,47
| The functionality Fmult then de- termines the other parties’ shares based on (zi, ci) and the product vavb Interestingly, in this secret sharing method, a single share together with the secret fully determines all other shares This is because each ci = zi−1 − vavb Thus, (zi, ci) and vavb determines zi−1 = ci + vavb, which in turn determines zi+1 since z1 + z2 + z3 = 0|,Non-data,47
| Finally, all z values together with vavb determine all c values Formally: FUNCTIONALITY 33 (Fmult – multiplication) 1|,Non-data,47
| Fmult receives ((xj , aj ), (yj , bj )) from each Pj and re- ceives a pair (zi, ci) ∈ Z2n × Z2n from the adversary controlling Pi 2 Fmult computes va = x1 − a2 and vb = y1 − b2 and 3 Fmult sets zi−1 = ci + vc and zi+1 = −zi − zi−1, and 4|,Non-data,47
| Fmult sends each Pj the pair (zj , cj ) (for j ∈ {1, 2, 3}) vc = vavb sets ci−1 = zi+1 − vc and ci+1 = zi − vc We denote the protocol for securely computing f that is defined in Section 2|,Non-data,47
3 by Protocol 23 We now prove the security of Protocol 23 according to Definition 3,Non-data,47
2 Theorem 34 Let f : ((Z2n )∗)3 → ((Z2n )∗)3 be a 3-ary functionality,Non-data,47
| Then, Protocol 23 computes f with perfect security in the Fmult-hybrid model, in the presence of one semi-honest corrupted party Proof Sketch: Since the circuit C computes functional- ity f the first (correctness) requirement of Definition 32 is immediately fulfilled|,Non-data,47
| We now proceed to the second (pri- vacy) requirement of the definition Intuitively, the protocol is private since the corrupted party receives nothing in the execution beyond shares on the input wires which are uni- formly distributed and the shares on the output wires In particular, addition gates consist of local computation only, and multiplication gates are computed using the Fmult func- tionality However, in Fmult, the adversary defines the cor- rupted party’s share (zi, ci) as it likes and receives nothing back (formally, it receives back (zi, ci) but this is already known)|,Non-data,47
| Thus, this can reveal nothing whatsoever about the actual values on the wires in the computation Finally, for each output wires in which Pi receives output, given its share (zi, ci) on the output wire and given the real output value v, the simulator can generate the exact shares that Pi would receive from the other parties This is due to the fact mentioned above that a single share plus the actual secret fully determines the other two shares (and can be computed efficiently in the same way as the functionality) It follows that we can construct a simulator that simply defines the view of the corrupted party to be shares of arbitrary values for the input wires, and provide the shares received on the output wires (after running the adversary and receiving the shares it chooses for its output wires)|,Non-data,47
| By Lemma 21, the simulator-generated view of the corrupted party is identi- cally distributed to that of a real execution 33 Computing Fmult in the Fcr-Hybrid Model In this section, we prove that the multiplication protocol described in Section 2|,Non-data,47
|3 computes the Fmult functionality with perfect security in the presence of one semi-honest cor- rupted party Recall that we use correlated randomness in the form of random α1, α2, α3 such that α1 + α2 + α3 = 0 Background – correlated randomness First, we for- mally define the ideal functionality Fcr|,Non-data,47
| A naive definition would be to have the ideal functionality choose α1, α2, α3 and send αi to Pi for i ∈ {1, 2, 3} However, securely realiz- ing such a functionality would require interaction (as in the information-theoretic method first described in Section 22) In order to model our computational method described in Section 2|,Non-data,47
|2 (which is the same as used for the ring case) we need to take into account that the corrupted party’s value is generated in a very specific way using a pseudorandom func- tion In order for the Fmult protocol to be secure, all that is needed is that the corrupted party knows nothing about the honest party’s values (beyond the given constraint that all values sum to zero) In particular, there is no requirement regarding how the corrupted party’s value is generated Re- call that in our protocol each party holds two keys which are used to locally compute the correlated randomness|,Non-data,47
| In or- der for the view of the corrupted party to be like in the real protocol, we define the functionality Fcr so that it gener- ates the corrupted party’s value in this exact same way (ie, Fk(id) − Fk(cid:48) (id) for keys k, k(cid:48); see Section 23)|,Non-data,47
| As we have mentioned, the honest parties’ values are chosen randomly, under the constraint that all values sum to zero The functionality is described formally in Functionality 35 The functionality chooses two keys k, k(cid:48) for a pseudorandom function F and sends them to the corrupted party|,Non-data,47
| We de- note by κ the computational security parameter, and thus the length of the keys k, k(cid:48) FUNCTIONALITY 35 (Fcr – corr randomness)|,Non-data,47
| Let F : {0, 1}∗ ×{0, 1}∗ → Z2n be a keyed function Upon invocation, Fcr chooses a pair of keys k, k(cid:48) ∈ {0, 1}κ and sends them to the adversary controlling party Pi Then: • Upon receiving input id from all parties, functionality Fcr computes αi = Fk(id)−Fk(cid:48) (id) and chooses random values αi−1, αi+1 ∈ Z2n under the constraint that α1 + α2 + α3 = 0 mod 2n Fcr sends αj to Pj for every j|,Non-data,47
 811The multiplication protocol A formal description of the protocol that securely computes the multiplication func- tionality Fmult in the Fcr-hybrid model appears in Proto- col 36 (Computing Fmult),Non-data,47
| PROTOCOL 36 • Inputs: Each party Pj (with j ∈ {1, 2, 3}) holds two (cid:1)- pairs of values (xj , aj ) , (yj , bj ) which are valid (cid:0)3 sharings of the values that are on the input wires • Auxiliary input: The parties hold the same unique identifier id (in the protocol using Fmult this identifier can be the index of the multiplication gate being com- puted) 2 • The protocol: 1|,Non-data,47
| Correlated randomness: Each party Pj (with j ∈ {1, 2, 3}) sends id to Fcr and receives back αj from Fcr 2 Local computation: Each party Pj locally com- putes: rj = aj bj−xj yj +αj  3 3|,Non-data,47
| Communication: Party Pj sends rj to party Pj+1 (recall that Pj+1 = P1 when j = 3) • Output: Each Pj outputs (zj , cj ) where zj = rj−1− rj and cj = −2rj−1 − rj ; recall rj−1 = r3 when j = 1 We now prove that the protocol is secure in the presence of one static semi-honest corrupted party Theorem 3|,Non-data,47
7 Protocol 36 computes Fmult with perfect security in the Fcr-hybrid model in the presence of one semi- honest corrupted party Proof,Non-data,47
| In the protocol, the corrupted party receives a single message This message is an element from Z2n which is uniformly distributed over Z2n , due to the fact that each party masks its message using a random value received from the Fcr functionality Intuitively, the protocol is secure because all the corrupted party sees is a random element (Note that the corrupted party also receives output from Fcr but this is fully determined to be αi = Fk(id)−Fk(cid:48) (id)|,Non-data,47
|) We now prove this claim formally The Fmult functionality as we have defined it is determin- istic, and we therefore prove security via the simpler Defi- nition 32 In order to show correctness, we need to show that the actual values (z1, c1), (z2, c2), (z3, c3) output by all three parties from Protocol 3|,Non-data,47
|6 are exactly the same values as those computed by Fmult In order to see that this holds, recall that in Section 23 we showed that z1 + z2 + z3 = 0 and ∀j ∈ {1, 2, 3} cj = zj−1 − vavb (4) We claim that given a fixed (zi, ci) and vavb, Eq|,Non-data,47
| (4) im- plies that all values zi−1, ci−1, zi+1, ci+1 are fully determined Specifically, let (zi, ci) be fixed and let vavb be the output value Since for all j ∈ {1, 2, 3} we have cj = zj−1 − vavb, this implies that zi−1 = ci + vavb is determined, which in turn determines zi+1 = −zi − zi−1 Finally, this determines ci+1 = zi − vavb and ci−1 = zi+1 − vavb|,Non-data,47
| This is exactly the way that Fmult computes the output values, and thus these are identical in the protocol and in the functionality output We now prove privacy by defining the simulator The sim- ulator S receives the input and output of the corrupted party Pi from Fmult as well as the auxiliary input id and (k, k(cid:48)), and needs to compute the messages Pi sees during the execu- tion The input of the corrupted party Pi consists of two pair 3 where αi = Fk(id) − Fk(cid:48) (id) as of shares (xi, ai), (yi, bi) and it has no output|,Non-data,47
| Intuitively, S chooses a random element ri−1 ∈ Z2n and uses it to define the pair (zi, ci) that it sends to the trusted party comput- ing Fmult Formally, the simulator receives (((xi, ai), (yi, bi)) and works as follows: 1 S chooses a random ri−1 ∈ Z2n  2|,Non-data,47
 S sets ri = aibi−xiyi+αi would be computed by Fcr in the protocol 3 S sets zi = ri−1 = ri and ci = −2ri−1 − ri 4,Non-data,47
| S sends (zi, ci) to Fmult 5 S adds αi and ri−1 to the view of the corrupted party The values αi and ri are computed by S exactly as by Pi in a real execution|,Non-data,47
| The only difference is how ri−1 is computed; Pi receives ri−1 = ai−1bi−1−xi−1yi−1+αi−1 from Pi−1 in a real execution, whereas S chooses ri−1 ∈ Z2n uni- formly at random in the simulation The distribution over these two values is identical by the fact that Fcr chooses αi−1, αi+1 Specificaly, Fcr chooses these at random under the constraint that α1 + α2 + α3 = 0 However, this is equiv- alent to choosing αi−1 ∈ Z2n uniformly at random and then setting αi+1 = −αi − αi−1|,Non-data,47
| Now, since αi−1 is uniformly random, this implies that ri−1 is uniformly random (since it is independent of all other values used in the generation of ri−1) Thus, the distribution over the real ri−1 received by Pi in the protocol execution and over the simulated ri−1 generated by S is identical This completes the proof 3|,Non-data,47
|4 Computing Fcr in the Plain Model In this section, we prove that our protocol privately com- putes the Fcr functionality in the presence of one semi- honest corrupted party We have already presented the Fcr functionality in Functionality 35 The protocol for comput- ing it appears in Protocol 3|,Non-data,47
|8 3 PROTOCOL 38 (Computing Fcr) • Auxiliary input: Each party holds a security pa- rameter κ, a description of a pseudorandom function F : {0, 1}κ × {0, 1}κ → Z2n |,Non-data,47
| • Setup (executed once): 1 Each party Pj chooses randomly kj ∈ {0, 1}κ 2 Each party Pj sends kj to party Pj+1|,Non-data,47
| • Generating randomness: Upon input id, each party Pj computes αj = Fkj (id)− Fkj−1 (id) and outputs it Theorem 39 If Fk() is a pseudorandom function, then Protocol 3|,Non-data,47
|8 computes Fcr with computational security in the plain model, in the presence of 1 semi-honest corrupted party Proof Sketch: Since the functionality is probabilistic, we need to use Definition 31 Unlike the previous security proofs we have seen, the security of this protocol is compu- tational and it relies on the assumption that Fk is a pseu- dorandom function|,Non-data,47
| Thus, we will show that the ability to distinguish between the outputs in the real and ideal execu- tions can be used to distinguish between the pseudorandom function and a truly random function, in contradiction to the assumption Let Pi be the corrupted party We define the simulator S who simulates Pi’s view S is invoked on the security parameter 1κ and works as follows: 8121|,Non-data,47
| S receives k, k(cid:48) from Fcr when it is first invoked (see Functionality 35) 2 S sets the random tape of Pi (used by Pi to sample ki) to be the key k received from Fcr|,Non-data,47
| 3 S simulates the setup phase by writing the key k(cid:48) as the key ki−1 received by Pi from Pi−1 4 From this point on, every time that Pi receives id for input, S sends it to the trusted party computing Fcr|,Non-data,47
| (Pi receives back αi but this equals Fk(id) − Fk(cid:48) (id) = Fki (id)−Fki−1 (id) and is known to Pi Also, this value is computed locally by Pi in the protocol and not received Thus, S does not include it in Pi’s view) It is easy to see that the view generated by the simulator which consists of the Pi’s random tape and the incoming message ki−1 is distributed identically to its view in a real execution|,Non-data,47
| However, this is not sufficient, as we need to prove indistinguishability of the joint distribution of both the corrupted party’s view and the honest parties’ outputs Observe that in the real protocol execution, the honest par- ties’ outputs are generated using the pseudorandom func- tion, whereas in the ideal world they are chosen randomly by Fcr Intuitively, the proof follows from the fact that both Pi−1 and Pi+1 generate their values using the pseudorandom func- tion F with key ki+1 that is independent of ki and ki−1 Thus, replacing Fki+1 with a truly random function f re- sults in Pi−1 and Pi+1 generating values αi−1 and αi+1 that are random under the constraint that α1 + α2 + α3 = 0|,Non-data,47
| (Specifically, Pi−1 generates αi−1 = Fki−1 (id) − f (id) and Pi+1 generates αi+1 = f (id)− Fki (id) Thus, αi−1 + αi+1 = Fki−1 (id) − f (id) + f (id) − Fki (id) = Fki−1 (id) − Fki (id) = −αi, as required) The full proof follows via a straightfor- ward reduction 3|,Non-data,47
|5 Wrapping Up In the previous sections, we have proven that Protocol 23 computes any 3-ary functionality with perfect security in the Fmult-hybrid model, and that Protocol 36 computes the Fmult functionality with perfect security in the Fcr-hybrid model Finally, we have proved that Protocol 3|,Non-data,47
|8 computes Fcr with computational security (in the plain model) under the assumption that pseudorandom functions exist (All of the above holds for a single corrupted party in the semi- honest model) Using the fact that all our protocols are UC secure from [17] and thus applying the UC composition theorem of [7], we conclude with the following theorem: Theorem 310|,Non-data,47
| Assume that F is a pseudorandom func- tion, and let f be a 3-ary functionality Then, Protocol 23 computes f with computational security, in the presence of one semi-honest corrupted party 4|,Non-data,47
| PRIVACY: MALICIOUS ADVERSARIES IN THE CLIENT-SERVER MODEL In this section, we consider the “client-server” model where the parties running the multiparty computation protocol are servers who receive the input shares of multiple clients and compute the output for them This is the model used by Cy- bernetica in their Sharemind product [4] In this model, the servers do not see any of the inputs nor any of the outputs Rather, they receive shares of the inputs and send the clients shares of their output|,Non-data,47
| Since the parties running the multi- party protocol do not have any input or output, it is possible to formulate an indistinguishability-based definition of secu- rity, saying that a corrupted server learns nothing In this section, we present such a definition, and we prove that our protocol fulfills this definition of privacy even in the pres- ence of a malicious corrupted party We believe that this formalization is of independent interest, and could be used to make similar claims regarding other information-theoretic protocols like [2] and [4, 5]; namely, that although they are only secure in the presence of semi-honest adversaries, they are in fact private in the presence of malicious adversaries Before proceeding, we stress that a definition of privacy is strictly weaker than standard definitions of security for ma- licious adversaries|,Non-data,47
| Most notably, correctness is not guar- anteed and a malicious server may tamper with the output In settings where the adversary may receive some feedback about the output, this may also reveal information about the input Thus, our claim of privacy is only with respect to a malicious server who receives no information about the output Defining security|,Non-data,47
| Let ViewA,I,π((cid:126)v, κ) denote the view of an adversary A who controls parties {Pi}i∈I (with I ⊂ [n]) in a real execution of the n-party protocol π, with inputs (cid:126)v = (v1,    , vN ) and security parameter κ|,Non-data,47
| We stress that in this setting, the vector of inputs (cid:126)v is of length N and N may be much longer (or shorter) than the number of par- ties n running the protocol This is because N refers to the number of inputs and so the number of clients, whereas n denotes the number of servers running the actual proto- col In addition, the servers do not receive for input any of the values in (cid:126)v but rather they each receive secret shares of the value Formally, one should specify the secret sharing method|,Non-data,47
| However, for generality, we do not define any spe- cific secret sharing scheme and rather define that for every vj in (cid:126)v, random v1 j are chosen under the constraint j = vj, and each server Pj is given the share v(cid:96) (for every 1 ≤ j ≤ N ) j that(cid:80)n j ,   |,Non-data,47
| , vn (cid:96)=1 v(cid:96) Loosely speaking, a protocol is private in the presence of one malicious corrupted party if the view of the corrupted party when the input is (cid:126)v is computationally indistinguish- able from its view when the input is (cid:126)v(cid:48) In order to rule out a trivial protocol where nothing is exchanged, we also require correctness, which means that when all parties are honest they obtain the correct output Definition 41|,Non-data,47
| Let f : ({0, 1}∗)N → ({0, 1}∗)N be an N -party functionality and let π be an n-party protocol We say that π t-privately computes f in the client-server model in the presence of malicious adversaries if it is correct and if for every non-uniform probabilistic polynomial-time adversary A, every I ⊂ [n] with ||I|| ≤ t, and every two series of length- N vectors V1 = {(cid:126)v1 κ}, V2 = {(cid:126)v2 κ} (cid:8)ViewA,I,π((cid:126)v1 κ, κ)(cid:9) κ∈N c≡(cid:8)ViewA,I,π((cid:126)v2 κ, κ)(cid:9) κ∈N where for every κ ∈ N, (cid:126)v1 of (cid:126)v1 κ and (cid:126)v2 κ are of the same length κ ∈ ({0, 1}∗)N and all elements κ, (cid:126)v2 We now prove that Protocol 23 fulfills Definition 4|,Non-data,47
|1, when making the appropriate changes to the input (con- 813verting vectors of length N into 3-way additive shares for the parties running Protocol 23) Theorem 42|,Non-data,47
| Let f : ((Z2n )∗) → ((Z2n )∗) be an N - party functionality and define the 3-party functionality gf to be the function that receives 3 length-N input vectors that constitute additive-shares of the input vector (cid:126)v to f and out- puts 3 length-N vectors that constitute additive-shares of f ((cid:126)v) If F is a pseudorandom function, then Protocol 23 applied to function gf 1-privately computes f in the client- server model in the presence of malicious adversaries Proof Sketch: Correctness is also required for the semi-honest setting and this is therefore already implied by Theorem 3|,Non-data,47
|4 In order to prove privacy, we need to show that the view of a malicious A controlling one party when the input is (cid:126)v is indistinguishable from its view when the input is (cid:126)v(cid:48) We first prove that the views are identical when information-theoretic correlated randomness is used (as de- scribed in the beginning of Section 22)|,Non-data,47
| First, intuitively, the views are identical with information- theoretic correlated randomness since all the adversary sees in every rounds is a random share In order to see that this holds even when A is malicious, observe that each share sent to the adversary is masked by a new value obtained from the correlated randomness Thus, irrespective of what A sends in every round, the value that it receives is a random element Thus, its view is actually independent of the values that it sends|,Non-data,47
| Second, consider the view when Protocol 38 is used for computing Fcr In the setup phase, A sends some value ki and receives ki−1 However, the security of the protocol is proven based on the pseudorandomness of the function keyed by ki+1 that A does not see|,Non-data,47
| Importantly to this case of ma- licious adversaries, ki+1 is chosen independently of what A sends Furthermore, the parties generate randomness from this point on using local computation only Thus, the val- ues generated by the honest parties are pseudorandom, irre- spective of what A sent More formally, consider a reduction where Fki+1 is replaced by a truly random function f |,Non-data,47
| Then, Pi−1 computes αi−1 = Fki−1 (id)− f (id) and Pi+1 computes αi+1 = f (id)−Fki (id) Since ki and ki−1 are fixed and inde- pendent of f , it follows that αi−1, αi+1 are random under the constraint that αi−1 +αi+1 = −(Fki (id)−Fki−1 (id)) = −αi, as required As we have stated, this holds irrespective of what value ki that A sent, and A cannot influence the αi−1, αi+1 values computed since they involve local com- putation by the honest parties alone Thus, the view in this case is indistinguishable from the view when the parties use information-theoretic correlated randomness|,Non-data,47
 5 EXPERIMENTAL RESULTS 51 Implementation and Bit-Slicing We implemented the protocol for Boolean circuits in C++ using standard optimizations known for multiparty compu- tation One specific optimization that we found to be of great importance was the use of Intel intrinsics for bit slicing operations; we describe this in more detail here,Non-data,47
| Since our protocol is extremely simple, running a single computation is very wasteful both with respect to CPU and network uti- lization A significant portion of this waste is due to the fact that our protocol processes single bits only, whereas mod- ern processors work on larger objects We ran our protocol on 12800 operations in parallel by batching 128 operations together and running 100 of these in parallel This batch- ing works by bit-slicing: the ith bit of input in 128 different inputs are sliced into a single string of length 128 (for each i)|,Non-data,47
| Likewise, the batched output bits need to be de-sliced into 128 separate outputs This is a type of “matrix trans- pose” – see Figure 1 – and turns out to be very expensive Indeed, a straightforward implementation of this bit slicing and de-slicing turned out to greatly dominate the overall execution time Hence, we implemented fast bit-slicing and bit-deslicing methods using Intel SIMD intrinsics in order to reduce this cost|,Non-data,47
| Figure 1: Bit-slice The unit of our bit-slicing is 16 messages of length 8 bytes each (overall 128 bytes) Thus, we start with: m0 = (m0,0, m0,1, m0,2, m0,3, m0,4, m0,5, m0,6, m0,7) m1 = (m1,0, m1,1, m1,2, m1,3, m1,4, m1,5, m1,6, m1,7)   |,Non-data,47
| m15 = (m15,0, m15,1, m15,2, m15,3, m15,4, m15,5, m15,6, m15,7) Then, we apply the Intel intrinsics “unpack” instruction 32 times to obtain 8 messages, each of length 16 bytes: (cid:48) 0 = (m0,0, m1,0,   |,Non-data,47
| , m15,0) (cid:48) 1 = (m0,1, m1,0,    , m15,1) m m |,Non-data,47
|   (cid:48) 7 = (m0,7, m1,7,  |,Non-data,47
|  , m15,7) m The unpack instruction treats the 128 bit register as 16 single-byte values (8 low and 8 high), and has instructions to interleave either the low or the high bytes This process is actually byte-slicing (since the “transpose”-type operation is carried out at the byte level and not the bit level)|,Non-data,47
 See Figure 2 for a graphic description of this operation Figure 2: Unpack operation of AVX instruction set 814The next step is to further slice the messages to the bit level We do this applying the Intel movmskb 64 times to obtain the bit-sliced inputs This instruction creates a 16-bit mask from the most significant bits of 16 signed or unsigned 8-bit integers in a register and zeroes the upper bits,Non-data,47
| Thus, we are able to take the MSB of 16 bytes in a register in a single cycle, which is very fast The movmskb instruction is depicted in Fig 3 Recall that each core processed 12800 AES computations in parallel, and observe that with a latency of 129ms approx- imately 7 calls can be processed per second by each core|,Non-data,47
| Thus, the approximate 100,000 AES computations per core per second are achieved in this way See Figures 4 and 5 for graphs showing the behavior of the implementation as higher throughputs are achieved Figure 3: Moving masked bit operation of AVX instruction set We apply the movmskb operation to each m(cid:48) i from the first step (note that each m(cid:48) i consists of 16 bytes, exactly as needed for movmskb) These optimizations were crucial for obtaining the high performance reported in this paper|,Non-data,47
 52 Fast AES We ran our implementation on a cluster of three mid-level servers connected by a 10Gbps LAN with a ping time of 013 ms Each server has two Intel Xeon E5-2650 v3 2,Non-data,47
|3GHz CPUs with a total of 20 cores We ran the implementation utilizing a different number of cores, from 1 through to 20 Each core was given 12800 computations which were carried out in parallel (Since Intel intrinsics works on 128-bit reg- isters, this means that inputs were sliced together in groups of 128 and then 100 of these were run in parallel by each core|,Non-data,47
|) These computations can be with different keys since each MPC can have different inputs; this will be used in Section 53 Observe that up to 10 cores, the throughput is stable at approximately 100,000 AES/sec per core However, beyond 10 cores this begins to deteriorate|,Non-data,47
| This is due to queuing between the kernel and the Network Interface Card (NIC) Specifically, when a single process utilizing a single CPU is used, that process has full control over the NIC However, when multiple processes are run, utilizing high bandwidth, requests from each process are handled in a queue between the kernel and the NIC This queuing increases network la- tency, and as each process spends more time waiting for communication, CPU usage drops by a noticeable percent- age|,Non-data,47
 It is possible to overcome this by bypassing the kernel layer and communicating directly with the NIC One ap- proach for achieving this appeared in [20] We ran each experiment 5 times; this was sufficient due to the very low variance as can be seen in Table 2 The results represent a 95% confidence interval,Non-data,47
| Cores 1 5 10 16 20 AES/sec 100,103 ± 1632 530,408 ± 7219 975,237 ± 3049 1,242,310 ± 4154 1,324,117 ± 3721 Latency 1285 ± 21 1212 ± 1|,Non-data,47
7 1319 ± 04 1657 ± 0,Non-data,47
4 1942 ± 09 CPU % Network 733% 62,Non-data,47
2% 540% 495% 496% 0,Non-data,47
572 299 547 695 7,Non-data,47
|38 Table 2: Experiment results running AES-CTR The CPU col- umn shows the average CPU utilization per core, and the network column is in Gbps per server Latency is given in milliseconds Figure 4: Throughput per core (AES computations) Figure 5: Latency versus throughput (AES) Microbenchmarking|,Non-data,47
| We measured the time spent on each part of the protocol, with the following results Protocol part Server bitslice and deslice AND and XOR gate computation Randomness generation Comm delays between MPC servers Communication delays for input/output Percentage 870% 49|,Non-data,47
82% 954% 2787% 407% We remark that the long communication delays are due to the fact that the communication topology of our imple- mentation is a ring,Non-data,47
| Thus, each party waits for two other messages to be processed before it receives its next message In order to reduce this waste, the randomness generation is run during this delay Thus, if the randomness genera- tion was “free”, the communication delay would increase to 3741% and it would not be any faster|,Non-data,47
| This demonstrates that the efficiency improvements could be achieved by com- municating in every step 53 Kerberos KDC with Shared Passwords In order to demonstrate the potential of our protocol, we incorporate it into a real application Kerberos is used 815for user authentication in many systems, most notably it is used by all Windows systems since Windows 2000|,Non-data,47
| Kerberos uses the hashed user password as a key to encrypt a Ticket- Granting-Ticket (TGT) which contains a high-entropy cryp- tographic key which is used for all communications after the user logs in In Kerberos, a server breach is particularly devastating since the hashed password is all that is needed for impersonating a user This is because the TGT is en- crypted with the hashed user password and sent to the user Thus, an attacker knowing the hashed password alone can decrypt the TGT|,Non-data,47
| Microsoft’s Active Directory has suffered breaches in the past, and such a breach enables an attacker to impersonate every user in the organization In order to mitigate this risk, we consider a system where the hashed user passwords are XOR-shared between two servers (with different administrators), and secure multi- party computation is used to carry out the login authen- tication without ever reconstructing the hashed password This makes it harder for an attacker to steal hashed pass- words (needing to breach both servers) and also mitigates insider threats since no single administrator has access to the hashed user passwords Since the ticket-granting-server’s long-term key is also very sensitive, this is also protected in the same way|,Non-data,47
| The architecture of the Kerberos solution is depicted in Figure 6 Figure 6: The Kerberos authentication using MPC We took the Open Source MIT Kerberos and modified the encryption mode used to encrypt the TGT to counter mode This is important since CBC mode does not enable parallel encryption and this would slow the encryption down significantly In more detail, the authentication process in Kerberos has the following steps: 1|,Non-data,47
| Pre-authentication: We use the pa-enc-timestamp method, which means that the user encrypts the date using his hashed password as the key This is a single AES block (and so ECB is used) 2 TGT encryption: A session key to be used by the user and ticket-granting server (TGS) to communicate later is generated|,Non-data,47
| Then, the TGT (containing the client infor- mation and the session key) is generated and encrypted under the long-term key of the TGS The TGT is 15 blocks of AES 3 Session-key and TGT encryption: The session key and TGS are AES-encrypted with the user’s hashed password|,Non-data,47
| Overall, the number of encryption blocks for a single user authentication is 33: one block for pre-authentication, 15 blocks for TGT encryption under the long-term key of the TGS, and 17 blocks for session-key and TGT encryption under the user key (this last encryption is 17 blocks due to the addition of the session key and header information) In all of the above encryptions, when using the Kerberos encryption type aes128-cts-hmac-sha1-96, all of the en- cryption above is without HMAC authentication (HMAC is only used for communication following these initial steps) As we have mentioned, we implemented a Kerberos exten- sion that uses counter mode instead of CBC (cts is CBC mode with ciphertext stealing)|,Non-data,47
| This is important for two reasons First, CBC encryption cannot be parallelized and so each block must be encrypted after the previous block has been encrypted In addition, the TGT cannot be encrypted under the user key until it has been encrypted under the long-term key of the TGS However, when using counter mode, all of the AES computations can be carried out in parallel|,Non-data,47
| Specifically, upon receiving a user authentication request together with a pre-authentication ciphertext, the following is carried out: 1 The servers running the secure computation protocol load the shares of the long-term key of the TGS and the shares of the user’s key ie, hash of the user’s password)|,Non-data,47
| 2 Two random counters ctr1 and ctr2 are chosen 3 33 AES computations are run in parallel: a single AES decryption of the pre-authentication ciphertext, 15 AES encryptions of ctr1 + 1, |,Non-data,47
|   , ctr1 + 15, and 17 AES encryp- tions of ctr2 + 1,  |,Non-data,47
|  , ctr2 + 16 4 The preauthentication value is verified; if it is valid, then the server proceeds to the next step|,Non-data,47
 5 The output of the 15 AES encryptions using ctr1 is XORed with the TGT 6 The encrypted TGT from the previous step is concate- nated with the session key and some header information,Non-data,47
| This is treated as a plaintext and XORed with the result of the 17 AES encryptions using ctr2 7 The result of the previous step along with ctr1 and ctr2 is sent to the user This flow enables all of the AES computations to be car- ried out in parallel, yielding a latency of approximately 120 milliseconds|,Non-data,47
| We remark that in order for the server to be able to process requests in bulk, a new set of AES encryp- tions is begun every 100 milliseconds Thus, authentication requests are queued for at most 100 milliseconds (and on average 50ms) and then processed This ensures that the overall latency (of a client) of processing an authentication request is approximately 200 milliseconds This is a very reasonable time for an application like Kerberos where a user is involved in the authentication process|,Non-data,47
| Experimental results In order to test our implementa- tion, we ran the complete Kerberos login using the aforemen- tioned cluster of three servers computing AES The number of logins per second with a single core was 2,970, with 10 cores was 28,723 and with 16 cores was 36,521 Thus, our Kerberos implementation (that incorporates the extension 816[13] S|,Non-data,47
| Gueron, Y Lindell, A Nof and B Pinkas|,Non-data,47
| Fast Garbling of Circuits Under Standard Assumptions In 22nd ACM CCS, pages 567–578, 2015 [14] Y Ishai and E|,Non-data,47
| Kushilevitz On the Hardness of Information-Theoretic Multiparty Computation In EUROCRYPT 2004, Springer (LNCS 3027), pages 439–455, 2004 [15] M|,Non-data,47
| Keller, E Orsini and P Scholl Actively Secure OT Extension with Optimal Overhead|,Non-data,47
| In CRYPTO 2015, Springer (LNCS 9215), pages 724–741, 2015 [16] L Kerik, P Laud and J|,Non-data,47
| Randmets Optimizing MPC for robust and scalable integer and floating-point arithmetic In 4th WAHC, 2016 [17] E|,Non-data,47
| Kushilevitz, Y Lindell and T Rabin Information-Theoretically Secure Protocols and Security Under Composition|,Non-data,47
| In the SIAM Journal on Computing, 39(5): 2090-2112, 2010 [18] J Launchbury, IS|,Non-data,47
| Diatchki, T DuBuisson and A Adams-Moran Efficient lookup-table protocol in secure multiparty computation|,Non-data,47
| In ACM ICFP’12, pages 189–200, 2012 [19] S Laur, R Talviste and J|,Non-data,47
| Willemson From Oblivious AES to Efficient and Secure Database Join in the Multiparty Setting In ACNS’13, Springer (LNCS 7954), pages 84–101, 2013 [20] J|,Non-data,47
| Perry, A Ousterhout, H Balakrishnan, D Shah and H Fugal|,Non-data,47
| Fastpass: a centralized “zero-queue” datacenter network In SIGCOMM 2014, pages 307–318, 2014 [21] T Rabin, M Ben-Or|,Non-data,47
 Verifiable Secret Sharing and Multiparty Protocols with Honest Majority (Extended Abstract) STOC 1989 : 73-85 [22] J Randmets Personal comm,Non-data,47
| – AES performance on the new Sharemind cluster May, 2016 [23] R Talviste|,Non-data,47
| Applying Secure Multi-Party Computation in Practice PhD dissertation, Univ of Tartu, 2016|,Non-data,47
| [24] A Shamir How to Share a Secret Communications of the ACM, 22(11):612–613, 1979|,Non-data,47
| [25] A Yao How to Generate and Exchange Secrets In the 27th FOCS, pages 162–167, 1986|,Non-data,47
| [26] S Zahur, M Rosulek and D Evans|,Non-data,47
| Two Halves Make a Whole - Reducing Data Transfer in Garbled Circuits Using Half Gates EUROCRYPT, pages 220–250, 2015 [27] Sharemind, Cybernetica https://sharemind|,Non-data,47
|cyberee described above in MIT-Kerberos) is able to support a sig- nificant login storm of over 35,000 user logins per second This is sufficient even for very large organizations (if more is needed, then this can be achieved by simply using two clusters instead of one)|,Non-data,47
| Beyond the number of logins per second, it is important to ensure that the latency is low; otherwise, users will have to wait too long at login This is the reason that we designed the TGT-generation process in a way that enables full parallelism of the AES operations Our results give an average latency of the AES encryption via MPC at 110ms, and an average latency at the client (over a LAN) of 232ms The increased time in the client is due to additional work carried out both by the client and the KDC, and due to the fact that requests are processed every 100ms|,Non-data,47
|ABSTRACT Back and Bentov (arXiv 2014) and Andrychowicz et al (Security and Privacy 2014) introduced techniques to perform secure multi- party computations on Bitcoin Among other things, these works constructed lottery protocols that ensure that any party that aborts after learning the outcome pays a monetary penalty to all other par- ties Following this, Andrychowicz et al|,Non-data,49
| (Bitcoin Workshop 2014) and concurrently Bentov and Kumaresan (Crypto 2014) extended the solution to arbitrary secure function evaluation while guaran- teeing fairness in the following sense: any party that aborts after learning the output pays a monetary penalty to all parties that did not learn the output Andrychowicz et al (Bitcoin Workshop 2014) also suggested extending to scenarios where parties receive a pay- off according to the output of a secure function evaluation, and out- lined a 2-party protocol for the same that in addition satisfies the notion of fairness described above In this work, we formalize, generalize, and construct multiparty protocols for the primitive suggested by Andrychowicz et al|,Non-data,49
| We call this primitive secure cash distribution with penalties Our for- mulation of secure cash distribution with penalties poses it as a multistage reactive functionality (ie, more general than secure func- tion evaluation) that provides a way to securely implement smart contracts in a decentralized setting, and consequently suffices to capture a wide variety of stateful computations involving data and/or money, such as decentralized auctions, markets, and games such as poker, etc|,Non-data,49
| Our protocol realizing secure cash distribution with penalties works in a hybrid model where parties have access to a claim-or-refund transaction functionality F (cid:63) CR which can be effi- ciently realized in (a variant of) Bitcoin, and is otherwise indepen- dent of the Bitcoin ecosystem We emphasize that our protocol is dropout-tolerant in the sense that any party that drops out during the protocol is forced to pay a monetary penalty to all other parties Our formalization and construction generalize both secure compu- tation with penalties of Bentov and Kumaresan (Crypto 2014), and secure lottery with penalties of Andrychowicz et al (Security and Privacy 2014)|,Non-data,49
| Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita- tion on the first page Copyrights for components of this work owned by others than ACM must be honored Abstracting with credit is permitted To copy otherwise, or re- publish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee|,Non-data,49
| Request permissions from Permissions@acmorg CCS’15, October 12-16, 2015, Denver, CO, USA Copyright 2015 ACM 978-1-4503-3832-5/15/10 |,Non-data,49
$1500,Non-data,49
 http://dxdoiorg/101145/2810103,Non-data,49
2813712 Categories and Subject Descriptors C20 [Computer-Communication Networks]: General—Secu- rity and protection Keywords Secure Computation; Bitcoin; Smart Contracts; Markets; Poker,Non-data,49
 1 INTRODUCTION Once there were two “mental chess” experts who had become tired of their favorite pastime Let’s play “men- tal poker” for some variety suggested one “Sure” said the other,Non-data,49
| “Just let me deal!” Motivated by this anecdote, Shamir, Rivest, and Adleman set forth in their seminal paper [1] to propose protocols that allow a pair of parties to play “fair” mental poker Arguably their paper gave birth to the concept of secure multiparty computation (MPC), a primi- tive that allows a set of mutually distrusting parties to carry out a distributed computation without compromising on the privacy of inputs or the correctness of the end result [2] Indeed mental poker has since been used as a metaphor for MPC [3] Clearly, MPC can be used to allow a set of parties to play poker over the Internet with- out having to trust a third party|,Non-data,49
| However this comes with certain caveats The obvious problem is that secure computation as defined can only allow players to play mental poker (ie, without involving real money)|,Non-data,49
| Another serious problem is that secure computation in the presence of a dishonest majority (including the important two-party case) does not provide dropout-tolerant solutions to mental poker Players may wait until the end of the hand to decide whether they want to drop out, ie, after they have a much better idea of whether they are going to win or lose|,Non-data,49
| As [4] points out, an even more fundamental issue is to get parties to respect the outcome of the protocol and distribute the money as dictated by the output Tying payments to secure computation More generally, there are many cases in which we would like to tie real-world payments to secure computation, eg|,Non-data,49
|, decentralized fair exchange of digi- tal goods or services for money in online marketplaces, decentral- ized multistage auctions, decentralized online gambling, etc Cur- rently, these tasks are delegated to a trusted third party (such as a bank, escrow service, or a court system) For “traditional” cur- rency systems, any payment—whether or not it is based on secure computation— requires trust in a third party (as the currency it- self is based on a trusted party, such as a central bank) However, the introduction of cryptocurrencies, such as Bitcoin [5], opens the possibility of handling payments in a decentralized manner [6, 7]|,Non-data,49
| 195Indeed cryptocurrencies are a natural choice for combining MPC with “real money” Andrychowicz et al [4] and Back and Ben- tov [8] introduced techniques to perform secure multiparty com- putations on Bitcoin Among other things, these works constructed lottery protocols that ensure that any party that aborts after learning the outcome pays a monetary penalty to all other parties|,Non-data,49
| Following this, Andrychowicz et al [9] and concurrently Bentov and Kumare- san [10] extended the solution to arbitrary secure function evalua- tion while guaranteeing fairness in the following sense: any party that aborts after learning the output pays a monetary penalty to all parties that did not learn the output Andrychowicz et al [9] also suggested extending to scenarios where parties receive a payoff ac- cording to the output of a secure function evaluation, and outlined a 2-party protocol for the same that in addition satisfies the notion of fairness described above|,Non-data,49
| Our contributions in a nutshell In this work, we formalize, gen- eralize, and construct multiparty protocols for the primitive sug- gested by [9] We call this primitive secure cash distribution with penalties Our formulation of secure cash distribution with penal- ties poses it as a multistage reactive functionality (i|,Non-data,49
|e, more gen- eral than secure function evaluation) that suffices to capture a wide variety of stateful computations involving data and/or money, such as decentralized auctions, games, markets, etc Our protocol re- alizing secure cash distribution with penalties works in a hybrid model where parties have access to a claim-or-refund transaction functionality F (cid:63) CR which can be efficiently realized in (a variant of) Bitcoin, and is otherwise independent of the Bitcoin ecosystem We emphasize that our protocol is dropout-tolerant in the sense that any party that drops out during the protocol is forced to pay a mon- etary penalty to all other parties|,Non-data,49
| Our formalization and construc- tion simultaneously generalize secure computation with penalties of Bentov and Kumaresan [10], and secure lottery with penalties of Andrychowicz et al [4] Below we describe our contributions in more detail Defining SCD|,Non-data,49
| We define SCD as a bounded reactive functional- ity, ie, the computation proceeds in a finite number of stages In an initial “deposit” stage, parties deposit sums of money|,Non-data,49
| In each succeeding stage, parties provide inputs and obtain outputs for that stage Then in the last stage, the money deposited by the parties is redistributed among them according to the output of the last stage Any party that aborts during any stage of the computation will be forced to pay penalties to all parties Thus SCD guarantees that honest parties either complete the entire computation or are com- pensated financially|,Non-data,49
| Implementing SCD Note that while in the standard setting, reac- tive secure computation reduces to non-reactive secure computa- tion by secret sharing the state between successive stages, a similar reduction does not carry over when we are in the penalty setting since a malicious party may abort between successive stages of a re- active computation and go unpenalized We design a protocol that realizes SCD (ie|,Non-data,49
|, with full simulation security [11]) in a hybrid model where parties have access to a claim-or-refund transaction functionality F (cid:63) CR The main technical idea in our solution is the construction of a see-saw transaction mechanism which is a novel extension of the ladder transaction mechanism of [10] Loosely speaking, the ladder mechanism implements fair exchange with penalties in the following sense: each party has their (digital) item at the beginning of the protocol, and at the end if one party receives all items, then it pays a penalty to parties which have not received all items In contrast the see-saw mechanism implements the fol- lowing variant of fair exchange with penalties: the exchange pro- ceeds in multiple rounds, and in each round, parties can adaptively choose their input item they want exchanged based on the items put up for exchange by other parties in previous rounds|,Non-data,49
| Penalties are now enforced across the entire exchange process That is, if a party decides to terminate the exchange process, then it pays a penalty to all other parties Note in particular that penalties are enforced even when no party receives all items Contrast this with the ladder mechanism that enforces penalties to all parties only when some party received all items|,Non-data,49
 See Section 5 for the implementation of the see-saw mechanism Our protocol for secure cash distribution makes non-black-box use of an underlying MPC protocol (cf Sec- tion 4) Practical applications,Non-data,49
| Consider a group of servers that agree to carry out an intensive computation task that spans several days Furthermore, assume that the computation requires multiple rounds of interactions and the full participation of all participating servers, and otherwise fails Here, we would like to guarantee that the servers exchange information as agreed upon without defaulting In such a setting, it is critical to ensure that the computation is carried out as intended, and that no server invests computational effort only to learn that a different server abruptly decided to not continue the computation any more|,Non-data,49
| Observe that the problem description as is does not involve money Still our formulation of SCD allows us to capture such a setting and offers a meaningful solution to this prob- lem, namely that a defaulting server will be forced to pay a penalty to everyone else Such a solution can be achieved by a straightfor- ward use of a verifiable computation scheme in combination with our see-saw transaction mechanism Next, consider a group of agents who participate in a set of fi- nancial transactions over the internet|,Non-data,49
| For example, these could be agents in a prediction market (possibly with dark pool trading ca- pabilities) who place bets on the occurrence of sets of events, and may adaptively vary their choices depending on whether a previous event in the set happened or not One must also consider what hap- pens when a malicious agent stops participating during the process A naïve solution would require that the agents make a deposit at the beginning of the protocol which they would forfeit when they abort To make this idea work in a decentralized setting, one must develop a method to put the deposits in escrow, and make sure that in the event of an abort (1) honest agents can always retrieve their de- posits from the escrow, and (2) honest agents obtain penalties from the escrow when a dishonest agent aborts|,Non-data,49
| Implementing such a de- centralized escrow when a majority of agents are dishonest is not straightforward Our formulation of SCD exactly allows the capa- bility to maintain a decentralized escrow across multiple stages of a computation and hence our protocol implementing SCD provides a solution to the prediction market problem described above More generally, since SCD models stateful reactive functional- ities it provides a way to securely implement smart contracts in a decentralized setting, and consequently captures a wide variety of games, including poker (assuming that the strategy space of the players includes variables that cannot be clearly defined and may depend on side information that cannot be completely captured) Limitations|,Non-data,49
| Note that the plain model realizations of F (cid:63) CR rely on Bitcoin scripts While we explicitly specify the checks that the scripts need to perform, the current Bitcoin scripting language is quite conservative (many opcodes became blacklisted [12]), and therefore some of the required checks are not currently supported in Bitcoin More concretely, our construction requires signature verification of arbitrary messages (ie|,Non-data,49
|, not more burdensome than the supported signature verification for the entire transaction data) In addition it requires scripts to support calculations whose com- plexity depends on the specific application For instance, in the application to poker, we require Bitcoin scripts to support simple 196arithmetic calculations that verify whether a transcript of a poker protocol follows the rules of poker In the most general setting, the validation complexity [13] (which corresponds to the complexity of script verification) equals the complexity of verifying validity of partial transcripts of an underlying secure computation proto- col that realizes the reactive functionality|,Non-data,49
| As suggested in [13], validation complexity may also accurately reflect additional trans- action fees that may be levied to include “unordinary” transactions (ie, transactions of the kind that our constructions need) into the blockchain Currently, only a small fraction of miners (e|,Non-data,49
|g, Eligius mining pool) accept transactions that make use of the entire Bit- coin scripting language In any case, our constructions require that new opcodes be added to the Bitcoin scripting language (eg|,Non-data,49
|, the opcode mentioned above for verifying signatures of arbitrary messages) While we expect Bitcoin to be less conservative in the scripts it supports in the future, our protocols can be deployed on alt-coins with Turing complete scripts However, Turing complete scripts are an overkill for our constructions This is because the number of rounds until the final cash distribution must be bounded (cf|,Non-data,49
| Section 4), hence miners can levy a suitable transaction fee by easily assessing the verification complexity of a certain SCD (eg, poker of some fixed number of rounds) script By contrast, a full-fledged Turing-complete cryptocurrency (like the Ethereum project) has to resort to extra mechanisms in order to protect itself from DoS attacks [14]|,Non-data,49
| Our main goal in this work is to show feasibility of realizing SCD As mentioned earlier, our SCD protocol makes non-black- box use of an underlying MPC protocol and can be inefficient in practice We note that this limitation can be removed for some applications For example, in Section 6, we show how to obtain a protocol for decentralized poker with dropout tolerance that makes only black-box use of MPC|,Non-data,49
| Related work The general problem of secure computation was solved in the 2-party setting by Yao [15], and in the multiparty set- ting in [3] Besides not handling payments, none of the schemes above can guarantee fairness in the presence of a dishonest major- ity [16] [4] designed a multiparty lottery protocol in the penalty model|,Non-data,49
| [9] designed a secure computation protocol in the penalty model but their protocol handles only the two-party setting Secure multiparty computation with penalties and secure multiparty lot- tery with penalties were formalized, and protocols realizing these were constructed in [10] [13] shows applications of Bitcoin to var- ious other interesting cryptographic primitives The work of [17] also shows how to enforce smart contracts with financial privacy but with different trust assumptions|,Non-data,49
| Relation to [9] The extension to a setting where payoffs depend on the output of a secure function evaluation was proposed in [9, Sec- tion 6] The authors then show how to modify the Bitcoin scripts that implements two-party secure function evaluation with penal- ties and obtain a solution for the extended setting with payoffs We emphasize that [9] handles the two-party case, with a non-reactive functionality, and outlines a solution using ad-hoc Bitcoin transac- tions|,Non-data,49
| In contrast, we provide formal definitions for secure cash distribution with penalties which we define as a stateful reactive functionality, then construct a multiparty protocol that securely re- alize this definition, and provide formal proofs Furthermore, our protocol works in a clean hybrid model where parties have access to a claim-or-refund transaction functionality F (cid:63) CR and is otherwise independent of the Bitcoin ecosystem That is, our protocol can be easily adapted to any setting (eg|,Non-data,49
|, alt-coins, PayPal) that can support an implementation of F (cid:63) CR In a sense, our work shows that F (cid:63) CR is a complete primitive for secure computations involving money Finally, a technique that we use in our cash distribution mechanism was previously outlined in [9] Specifically, we use the idea from [9] that allows the parties to transfer arbitrary amounts of money by dividing a large amount into “power of 2 fractions|,Non-data,49
|” Note that it is possible to replace this technique with a naïve mechanism and still obtain our feasibility results 2 PRELIMINARIES A function μ(·) is negligible in λ if for every positive polynomial p(·) and all sufficiently large λ’s it holds that μ(λ) < 1/p(λ) A probability ensemble X = {X(a, λ)}a∈{0,1}∗,n∈N is an infinite sequence of random variables indexed by a and λ ∈ N|,Non-data,49
| Two dis- tribution ensembles X = {X(a, λ)}λ∈N and Y = {Y (a, λ)}λ∈N c≡ Y are said to be computationally indistinguishable, denoted X if for every non-uniform polynomial-time algorithm D there exists a negligible function μ(·) such that for every a ∈ {0, 1}∗, ||Pr[D(X(a, λ)) = 1] − Pr[D(Y (a, λ)) = 1]|| ≤ μ(λ) All parties are assumed to run in time polynomial in the security parameter λ We prove security in the “secure computation with coins” (SCC) model proposed in [10] Note that the main difference from standard definitions of secure computation [18] is that now the view of Z contains the distribution of coins|,Non-data,49
| Let IDEALf,S,Z (λ, z) denote the output of environment Z initialized with input z after interacting in the ideal process with ideal process adversary S and (standard or special) ideal functionality Gf on security parameter λ Recall that our protocols will be run in a hybrid model where parties will have access to a (standard or special) ideal functionality Gg We denote the output of Z after interacting in an execution of π in such a model with A by HYBRIDg π,A,Z (λ, z), where z denotes Z’s input We are now ready to define what it means for a protocol to SCC realize a functionality|,Non-data,49
| Definition 1 Let n ∈ N Let π be a probabilistic polynomial- time n-party protocol and let Gf be a probabilistic polynomial- time n-party (standard or special) ideal functionality We say that π SCC realizes Gf with abort in the Gg-hybrid model (where Gg is a standard or a special ideal functionality) if for every non- uniform probabilistic polynomial-time adversary A attacking π there exists a non-uniform probabilistic polynomial-time adversary S for the ideal model such that for every non-uniform probabilistic polynomial-time adversary Z, {IDEALf,S,Z (λ, z)}λ∈N,z∈{0,1}∗ c≡ {HYBRIDg π,A,Z (λ, z)}λ∈N,z∈{0,1}∗ |,Non-data,49
| ♦ Ideal functionality F (cid:63) CR [10, 19, 20] This special ideal func- tionality has been employed in the design of multiparty fair secure computation and lottery protocols [10] See Figure 1 for a formal description At a high level, F (cid:63) CR allows a sender Ps to condition- ally send coins(x) to a receiver Pr|,Non-data,49
| The condition is formalized as the revelation of a satisfying assignment (ie, witness) for a sender- specified circuit φs,r( · ; z) (ie|,Non-data,49
|, relation) that may depend on some public input z Further, there is a “time” bound, formalized as a round number τ, within which Pr has to act in order to claim the coins An important property that we wish to stress is that the sat- isfying witness is made public by F (cid:63) CR In the Bitcoin realization of F (cid:63) CR, sending a message with coins(x) corresponds to broad- casting a transaction to the Bitcoin network, and waiting according to some time parameter until there is enough confidence that the transaction will not be reversed|,Non-data,49
| 197F (cid:63) CR with session identifier sid, running with parties Ps and Pr, a parameter 1λ, and adversary S proceeds as follows: • Deposit phase Upon receiving the tuple (deposit, sid, ssid, s, r, φs,r, τ, coins(x)) from Ps, record the message (deposit, sid, ssid, s, r, φs,r, τ, x) and send it to all par- ties Ignore any future deposit messages with the same ssid from Ps to Pr • Claim phase|,Non-data,49
| In round τ, upon receiving (claim, sid, ssid, s, r, φs,r, τ, x, w) from Pr, check if (1) a tuple (deposit, sid, ssid, s, r, φs,r, τ, x) was recorded, and (2) if φs,r(w) = 1 If both checks pass, send (claim, sid, ssid, s, r, φs,r, τ, x, w) to all parties, send (claim, sid, ssid, s, r, φs,r, τ, coins(x)) to Pr, and delete the record (deposit, sid, ssid, s, r, φs,r, τ, x) • Refund phase: In round τ + 1, if the record (deposit, sid, ssid, s, r, φs,r, τ, x) was not deleted, then send (refund, sid, ssid, s, r, φs,r, τ, coins(x)) to Ps, and delete the record (deposit, sid, ssid, s, r, φs,r, τ, x) Figure 1: The ideal functionality F (cid:63) CR|,Non-data,49
| 3 SECURE CASH DISTRIBUTION In this section, we introduce secure cash distribution with penal- ties Loosely speaking, secure cash distribution with penalties (or simply “secure cash distribution”) allows each party to first make a cash deposit and then supply additional inputs to a function The deposited cash is then distributed back to the parties depending on (and along with) the output of the function evaluation|,Non-data,49
| Any ma- licious party that aborts the protocol after learning output and/or receiving coins must pay a monetary penalty to all honest parties Clearly, such a primitive generalizes both secure computation with penalties [10, 9] and secure lottery with penalties [10, 4] As it turns out, this informal definition of secure cash distribution is not strong enough to enable applications that we are interested in What is needed is to handle the reactive setting, i|,Non-data,49
|e, allowing multiple “stages” of computation with parties providing inputs to each stage and receiving outputs at the end of each stage Let F be a reactive functionality, ie|,Non-data,49
|, one that keeps state across eval- uations and proceeds in multiple stages To keeps things simple, we assume an upper bound ρ on the number of stages of F  That is, we assume F = (f1,  |,Non-data,49
|  , fρ) is a collection of functionalities which accumulate state with each evaluation More concretely, let x(cid:96) = (x(cid:96),1,  |,Non-data,49
|  , x(cid:96),n) denote the parties’ input to the (cid:96)-th stage for (cid:96) ∈ [ρ], and let state0 be initialized as state0 := NULL Then over the course of the computation, parties successively eval- uate f(cid:96)(x(cid:96); state(cid:96)−1) to obtain (z(cid:96), state(cid:96)) for (cid:96) = 1,  |,Non-data,49
|  , ρ Here z(cid:96) = (z(cid:96),1,  |,Non-data,49
|  , z(cid:96),n) represents the parties’ output, ie, party Pi obtains z(cid:96),i|,Non-data,49
| The value state(cid:96) represents the state saved for the ((cid:96) + 1)-th computation stage, and is kept private from the parties (via use of secret sharing) Although we now handle a reactive functionality, we stress that the cash that is deposited at the beginning of the protocol is dis- tributed only at the end (ie, no cash distribution occurs in any intermediate stage)|,Non-data,49
| That is, secure cash distribution provides a means to keep the cash deposited in escrow while parties’ learn output from each stage’s function evaluation, and thus can revise their inputs to a later stage The capability to maintain an escrow turns out to be crucial in enabling the applications we are interested in i∈[n] d(cid:63) 1 ,  |,Non-data,49
|  , z(cid:63) We now proceed to the formal details Let d(cid:63) = (d(cid:63) all the deposited coins, ie|,Non-data,49
|, coins((cid:80) 1,    , d(cid:63) n) be the initial cash deposit from the parties, i|,Non-data,49
|e, party Pi deposits i ) into the computation Then at the end of the protocol coins(d(cid:63) i ), are distributed back to the parties according to the evaluation of the reactive function- ality F on the parties’ inputs More precisely, let zρ denote the parties’ output at the end of the last stage of the computation|,Non-data,49
| We assume that zρ specifies how the coins are (re)distributed at the end of the entire computation That is, we can parse zρ = (z = n)) where zi represents the parties’ (z1,   |,Non-data,49
| , zn), z(cid:63) = (z(cid:63) output, and z(cid:63) i represents the amount of cash that Pi is supposed to get back We are now ready to define bounded zero-sum reactive distribution Definition 2 (Bounded zero-sum reactive distribution) For all (cid:96) ∈ [ρ], let fi : ({0, 1}∗)n × {0, 1}∗ → ({0, 1}∗)n × {0, 1}∗ be a n) ∈ Nn be a vector|,Non-data,49
| We say that function Let d(cid:63) = (d(cid:63) (F = (f1,   |,Non-data,49
| , fρ), d(cid:63)) is a bounded zero-sum reactive distribution if ∀ x1,    , xρ ∈ ({0, 1}∗)n it holds that the value zρ = ((z1, |,Non-data,49
|   , n)) ∈ ({0, 1}∗)n×Nn obtained from the sequence: zn), (z(cid:63) (z1, state1) ← f1(x1; NULL); (z2, state2) ← f2(x2; state1); 1 ,  |,Non-data,49
|  , z(cid:63) 1,   |,Non-data,49
| , d(cid:63)  satisfies(cid:80) i =(cid:80) i z(cid:63) (zρ, stateρ) ← fρ(xρ; stateρ−1), i |,Non-data,49
| i d(cid:63) i > d(cid:63) ♦ Observation 1 The coins earned by Pi, namely z(cid:63) i may be such i (eg, when F represents the lottery functionality [4, that z(cid:63) 10])|,Non-data,49
| To simplify exposition, we make use of a “helper” function g which on input (d(cid:63), z(cid:63)) returns a matrix A whose (i, j)-th entry denoted ai,j specifies the amount of coins that need to be trans- ferred from Pi to Pj In particular, it must hold for all i ∈ [n] that j  Ob- serve that it is easy to design g for a zero-sum distribution (F, d(cid:63)) i , and for all j ∈ [n] that(cid:80) j∈[n] ai,j = d(cid:63) i∈[n] ai,j = z(cid:63) (cid:80) Next we formally define F (cid:63) F,d(cid:63) which idealizes SCD|,Non-data,49
| Ideal functionality F (cid:63) F,d(cid:63) See Figure 2 for the formal defnition In an initial cash deposit phase, the functionality F (cid:63) F,d(cid:63) receives r) from each honest Pr, where d represents a param- coins(d + d(cid:63) eterizable safety deposit and d(cid:63) r represents the cash that will be stored in escrow In addition, F (cid:63) F,d(cid:63) allows the ideal world adver- sary S to deposit some coins which may be used to compensate honest parties if S aborts after receiving the outputs|,Non-data,49
| If there is an abort at this stage, that is, S does not submit the necessary amount of cash then the protocol terminates, and the honest parties get their deposit back Note that at this stage there is no penalty for aborts; the penalties enter the picture only after this stage Once the de- posit phase ends, parties enter the computation phase In the (cid:96)-th stage of the computation phase, the honest parties supply their in- puts to (cid:96)-th stage of the computation|,Non-data,49
| The functionality then waits to receive corrupt parties’ inputs for this stage If S aborts at this stage, then the honest parties receive coins(q) penalty in addition to getting their deposit coins(d) back (and may also obtain some extra coins(qr)), and the computation phase is terminated Now honest parties receive the amount that they deposited at the beginning of the protocol in the cash distribution phase However, if S does con- tinue (i|,Non-data,49
|e, provide inputs to this stage), then the functionality com- putes the output of the (cid:96)-th stage Now the simulator gets a chance to look at the output first, and then decide if it wants to continue or not If it decides to continue then the honest parties receive the output as well, and proceed to the next stage of the computation|,Non-data,49
| 1981,    , d(cid:63) n)) be a bounded Let (F = (f1, |,Non-data,49
|   , fn), d(cid:63) = (d(cid:63) zero-sum reactive distribution (cf Definition 2)|,Non-data,49
| F (cid:63) F,d(cid:63) with session identifier sid running with parties P1,    , Pn, a pa- rameter 1λ, and an ideal adversary S that corrupts parties {Ps}s∈C proceeds as follows: Let H = [n]\ C and h = ||H|||,Non-data,49
| Let d represent the safety deposit, and let q denote the penalty amount Initialize state0 := NULL and flag = 1 • Deposit phase: Wait to receive a message (deposit, sid, r)) from Pr for all r ∈ H Then wait s∈C d(cid:63) s)) to receive (deposit, sid, ssid, d(cid:63), coins(hq + (cid:80) ssid, r, d(cid:63), coins(d + d(cid:63) from S|,Non-data,49
| • Computation phase: For each (cid:96) = 1,    , ρ, do: – Wait to receive a message (input, sid, ssid, r, x(cid:96),r) from Pr for all r ∈ H|,Non-data,49
| – If S sends (abort, sid, ssid,{coins(qr)}r∈H ), send (payback, sid, ssid, coins((cid:80) send (penalty, sid, ssid, coins(q + qr)) to Pr for all r ∈ H, r∈H qr)) to S, set flag = 0, and terminate phase – Else if S sends (input, sid, ssid,{x(cid:96),s}s∈C ), set x(cid:96) = s −(cid:80) s∈C d(cid:63) (x(cid:96),1,   |,Non-data,49
| , x(cid:96),n) – Compute (z(cid:96), state(cid:96)) ← f(cid:96)(x(cid:96); state(cid:96)−1), and parse z(cid:96) to obtain (z(cid:96),1,   |,Non-data,49
| , z(cid:96),n) – Send (output, sid, ssid,{zs,(cid:96)}s∈C ) to S – If S returns (continue, sid, ssid), then send (output, sid, ssid, z(cid:96),r) to Pr for all r ∈ H send (payback, sid, ssid, coins((cid:80) – Else if S sends (abort, sid, ssid,{coins(qr)}r∈H ), send (penalty, sid, ssid, coins(q + qr)) to Pr for all r ∈ H, r∈H qr)) to S, set flag = 0, and terminate phase|,Non-data,49
| s −(cid:80) s∈C d(cid:63) • Distribution phase: If flag = 0, send (return, sid, ssid, r)) to Pr for all r ∈ H, and terminate Else, n), and send (pay, sid, r )) to Pr for all r ∈ H, and send (pay, s )) to S sid, ssid, z(cid:63), coins(hq +(cid:80) coins(d + d(cid:63) parse zρ to obtain z(cid:63) = (z(cid:63) ssid, z(cid:63), coins(d + z(cid:63) 1 ,  |,Non-data,49
|  , z(cid:63) s∈C z(cid:63) Figure 2: Secure cash distribution with penalties F (cid:63) F,d(cid:63) On the other hand, if S decides to abort, then the honest parties get compensated as before, ie|,Non-data,49
|, with coins(d+d(cid:63) r +q+qr) in total, and the protocol is terminated The computation phase terminates after the ρ-th stage ends Note that upon successful completion of the ρ-th stage, all parties receive their final outputs After this, parties enter the cash distribution phase; the cash is distributed according to the output of the ρ-th stage, i|,Non-data,49
|e, zρ The functionality parses zρ to obtain z(cid:63) which dictates how the cash is distributed among the parties Using z(cid:63), the functionality distributes the cash among the parties, and returns their original deposits as well|,Non-data,49
| In addition, the functionality also sends the value z(cid:63) to all parties, ie, the way the cash gets distributed at the end is not private How to use F (cid:63) F,d(cid:63) to implement poker|,Non-data,49
| We now describe a naïve implementation of how to play poker hand via F (cid:63) (In Sec- tion 6 we provide an optimized poker protocol) We assume that there is a bound on the maximum number of betting stages within a single hand Players start the protocol by depositing their “chips” or equivalently cash to F (cid:63) F,d(cid:63) This ends the deposit phase|,Non-data,49
| Now players supply inputs to the first stage function whose purpose is to deal players’ hole cards They do this by each picking uniform F,d(cid:63) F,d(cid:63) Then F (cid:63) random string and sending it to F (cid:63) and sends ̃ri to F (cid:63) the following way: first compute ̃r =(cid:76)n F,d(cid:63)|,Non-data,49
| That is player Pi picks F,d(cid:63) computes f1( ̃r1,    , ̃rn) in i=1 ̃ri (note: no coalition of malicious players can influence ̃ri in any way), then interpret uniform random string ̃r in a natural way to generate players’ hole cards as well as the community cards|,Non-data,49
| This value ̃r is then saved to the private state Now note that any player that aborts with- out supplying ̃ri pays a penalty to every honest player Otherwise, players get their hole cards (the community cards still remain hid- den), and can start to place bets Again note that any player that aborts after seeing its hole cards pays a penalty to every honest player|,Non-data,49
| Each move by a single player is considered as a computa- tion stage In the stage corresponding to player Pi’s turn, Pi simply submits its next move (eg, “match,” “fold,” “raise by $1”) as the input to the stage|,Non-data,49
| (Other players have no inputs to this stage) Then the stage computation is simply to append player Pi’s move to the saved transcript of bets made so far (ie, the state of the pre- vious stage), and then send Pi’s move to all players|,Non-data,49
| It is possible that a player Pi submits an illegal move (ie, inconsistent with the transcript, or simply overbets) in which case the last stage compu- tation will reconstruct an illegal transcript, and ensure that the cash distribution phase compensates every honest party with coins(q) Note that players never submit any additional coins (other than at the beginning, i|,Non-data,49
|e, the deposit phase) In the stage corresponding to revealing community cards (say after the last player has placed its bet), the stage function simply uses ̃r to regenerate the commu- nity cards that need to be revealed, and additionally broadcasts the last player’s move Again a player that aborts after seeing the com- munity cards pays a penalty to every honest player|,Non-data,49
| Players keep continuing to make their moves during their turn until it’s time for the last move to be made Once this move is made, F (cid:63) F,d(cid:63) first de- termines the pot (using the bets made in the game that can be found in the saved state containing the transcript), and then send the pot earnings to the winner(s), and the remaining cash (from that de- posited initially) back to the players To play the next hand, players execute the above all over again It is instructive to note why just secure computation with penal- ties does not seem powerful enough to implement poker|,Non-data,49
