 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| trying to recover the target message X given the tweaks and ciphertexts The auxiliary information a represents partial information about the messages X1,   |,Non-data,64
| , XQ that may be known to the adversary A common cryptanalytic setting is a known-message at- tack This would be captured in our setting by letting a be a list of all the non-target messages, meaning all Xi different from X But our framework is more general, allowing us to capture attacks where the information the adversary has about the example messages is partial, for example their first halves|,Non-data,64
| Different distributions on the data, as well as rela- tions between the example and target message, are captured by different choices of XS The mg advantage captures the a priori probability of guessing the target message given the tweaks and auxiliary information The mr advantage is the excess of the adver- sary’s probability of winning the mr game over this mg ad- vantage To explain the distinctness condition on the mes- sage sampler, associate to XS the Q by Q matrix M whose (i, j)-th entry M [i, j] is the boolean ((Ti, Xi) = (Tj, Xj))|,Non-data,64
| Given Y1,    , YQ, an adversary can immediately compute the entire matrix M because F|,Non-data,64
|E is deterministic and a per- mutation for each fixed key and tweak If we put no restric- tions on the message sampler, we should thus give S the matrix M  A simpler alternative, and the one we adopted, is the distinctness condition, which effectively says that all non-diagonal entries of the matrix M are false In their work giving the first theoretical treatment of FPE, BRRS [1] gave a definition of message recovery security that we overviewed in Section 1|,Non-data,64
| Here examples (T1, X1),    , (TQ−1, XQ−1) are chosen by the adversary and submitted to an oracle that encrypts them under the target key and returns ciphertexts Y1, |,Non-data,64
|   , YQ−1 The adversary also knows a target tweak T ∗ and an encryption Y ∗ of the target mes- sage X ∗ under T ∗, and wins if it finds X ∗|,Non-data,64
| Its advantage is relative to a simulator who gets Q − 1 queries to an oracle that, given X returns the boolean (X = X ∗) A weakness of their definition is that the simulator’s test queries may use different tweaks than the ones in the examples obtained by the adversary BRRS is concerned only with the number of queries, not their type As a result, the definition indi- cates that any attack with a number of examples in excess of the domain size has zero advantage and is thus trivial and un-interesting|,Non-data,64
| But many attacks using a number of ex- amples more than the domain size are interesting and can be captured in our framework In particular, the advantage ought to remain low if qe is low, even if Q is high Also, in the BRRS definition, the target message is encrypted un- der only one tweak In our terminology, this means there is exactly one target tweak, q∗ = 1|,Non-data,64
| Our definition covers the target message being encrypted under multiple tweaks Indeed, our attacks are for a situation where the number of target tweaks is large Finally, the BRRS definition in- herently captures only a chosen-plaintext attack, meaning the adversary knows the example messages in their entirety There is no language to express the difference between at- tacks that know the example messages in their entirety and ones that do not, yet such a difference is important in prac- tice|,Non-data,64
| The determinant of attack quality and non-triviality is exactly the mr-advantage as we have defined it That an at- tack might be considered non-trivial, despite Q being larger than the domain, if qe and q∗ are small, is a good rule of thumb, but one must be careful in using it alone We will 448discuss these parameters for our attacks but also bound the mr-advantage In our framework, attacks are non-adaptive, meaning ex- amples cannot depend on prior ciphertexts|,Non-data,64
| This reflects that in practice, it is such attacks that matter much more It is much harder to mount an adaptive attack Definition- ally, the adaptive case is more complex We can extend the mr game quite easily to this case but there are subtle issues in trying to extend the mg game that we are not sure how to address|,Non-data,64
| We view meeting our definition as a necessary but not suf- ficient condition for a scheme to be considered secure That is, a feasible attack with high advantage under our defini- tion indicates the scheme is insecure, but absence of such an attack does not necessarily mean the scheme is secure, in particular because there could be a feasible adaptive attack In the full version of this paper, we discuss the BRRS definition in more detail We also show that the tweakable PRP notion [1, 8] implies our mr notion|,Non-data,64
| 5 THE LEFT-HALF RECOVERY ATTACK The attack Our first attack is given encryptions of two samples X and X ′ under q tweaks T1,  |,Non-data,64
|  , Tq (for an ap- propriately large q), together with X ′, where X and X ′ have equal right segment, whereas their left segments dif- fer We do not make any assumptions on the distribution of T1,  |,Non-data,64
|  , Tq, X ′, but assume the left segment of X is uniform, conditioned on being distinct from the left segment of X ′ Our first attack will recover X, and thus in particular its (unknown) left segment We formalize this using our message-recovery framework|,Non-data,64
| We want to characterize under what conditions the attack works This is done by specifying a class SC1q of samplers, and then lower bounding the mr-advantage of the attack for any sampler in this class We first let DC1q be the class of all algorithms D that output X ′ ∈ ZM × ZN and distinct T1,  |,Non-data,64
|  , Tq ∈ {0, 1}∗ To any such D we associate the sampler Sampler XS[D] (X ′, T1,  |,Non-data,64
|  , Tq) ←$ D ; (L′, R) ← X ′ L ←$ ZN\{L′} ; X ← (L, R) ; a ← X ′ Return ((T1, X ′), (T1, X),   |,Non-data,64
| , (Tq, X ′), (Tq, X), X, a) The sampler XS[D] above chooses a target message X that has the same right segment as the message X ′ produced by D The number of examples is Q = 2q; the number of tweaks is qt = q; the number of target tweaks is q∗ = q; and the number of examples per tweak is qe = 2 Since X 6= X ′, each sampler in SC1q satisfies the distinctness condition Finally we define SC1q = {XS[D] || D ∈ DC1q]|,Non-data,64
| Note that we do not prescribe any particular behavior for D Thus, we are considering a large class of samplers, as D ranges over DC1q Since qe is small, we would expect and desire that adver- saries have low mr-advantage, even if Q is big Indeed, an ideal FPE scheme has this property|,Non-data,64
 Our LHR attack shows that Feistel-based FPE fails to have this property The Left- Half Recovery (LHR) attack LHR against SC1q is given in Fig 5 It can recover the left segment of X from the cipher- texts and the left segment of X ′,Non-data,64
| Since our mr notion asks for full message recovery, the right segment of X is included in a, but this information is not needed for recovering the left segment of X Theorem 51 below gives a lower bound on the mr advantage of LHR; this bound is illustrated in Fig 6|,Non-data,64
| 1), (T1, C1),    , (Tq, C′ q), (Tq, Cq), a) Adversary LHR((T1, C′ X ′ ← a ; L ← 0 ; (L′, R) ← X ′ For s ∈ ZM do Vs ← 0 For i = 1 to q do (A, B) ← Ci; (A′, B′) ← C′ i ; s ← A⊟A′ ⊞L′; Vs ← Vs+1 For s ∈ ZM do If Vs > VL then L ← s X ← (L, R) ; Return X Figure 5: The Left-Half Recovery attack|,Non-data,64
  1  08  06 FF1 8 bits 9 bits 10 bits 11 bits 12 bits  30  35  40  45  50  55  60  04  0,Non-data,64
2  0  25  1  08  06 FF3  04  0,Non-data,64
|2  0  15 8 bits 9 bits 10 bits 11 bits 12 bits  20  25  30  35  40  45 Figure 6: The mr advantage of the Left-Half Recov- ery attack for binary strings of 8–12 bits The x-axis shows the log, base 2, of the number q of ciphertext pairs, and the y-axis shows Advmr Feistel[r,M,N,⊞],XS(LHR), for XS ∈ SC1q On the top, we use the parameters of the FF1 standard, meaning that r = 10, and for l-bit strings, M = 2⌊l/2⌋ and N = 2⌈l/2⌉ At the bottom, we use parameters of FF3, meaning that r = 8, and for l-bit strings, M = 2⌈l/2⌉ and N = 2⌊l/2⌋|,Non-data,64
| Theorem 51 Let M ≥ 3, N ≥ 2 and q ≥ 1 be integers, and let r ≥ 4 be an even integer such that N (r−2)/2 ≥ 2M  M N(cid:17) and F = Feistel[r, M, N, ⊞]|,Non-data,64
| Let λ =(cid:16)1− 1 M −1(cid:17)2(cid:16)1− 1 Then for any sampler XS in the class SC1q, Advmr 12·N r−2(cid:17) F,XS(LHR) ≥ 1 − exp(cid:16) −λM q − M · exp(cid:16) −λM q 9·N r−2(cid:17) − 1 M −1  Ideas of the attack The key idea of our Left-Half Re- covery attack relies on the following fact, formalized and proved in Lemma 53, which strengthens a previous result by Patarin [9], as we explain below|,Non-data,64
| Suppose that we en- crypt both X = (L, R) and X ′ = (L′, R) under the same tweak T  Let Lt and Rt be the left and right segments of the round-t output of X Define L′ t for X ′ likewise Then, we show that Lt ⊟L′ t is most likely to be L ⊟L′, where the probability is taken over a uniformly random choice of t and R′ 449Indeed, 1 = L ⊟ L′ with probability 1, and moreover, L2 = L1 2 = L ⊟ L′ is also always 2 = L′ the key K|,Non-data,64
| This is clear for t = 1 and t = 2 L1 ⊟ L′ and L′ true For t = 3, let F3 be the third round function Then 2 |,Non-data,64
| 1, and therefore L2 ⊟ L′ 3 = F3(K, T, R′ 2) ⊞ L′ L3 = F3(K, T, R2) ⊞ L2, and L′ If R2 6= R′ as L3 and L′ 2 then L3 ⊟ L′ 3 is uniformly distributed over ZM , 3 are uniform However, if R2 = R′ 2, then L3 ⊟ L′ 3 = L2 ⊟ L′ 2 = L ⊟ L′  Therefore, at round t = 3, while much closer to uniform, the distribution of Lt ⊟L′ t still remains slightly biased toward the point L ⊟ L′ A bias remains as the round number increases, although it will decrease exponentially in t|,Non-data,64
| Lemma 53 will concretely quantify this bias From the observation above, if we have ciphertexts C = (A, B) and C ′ = (A′, B′) of X and X ′ = (L′, R) under a single tweak T , and we know X ′, we can recover the left segment of X via L = A ⊟ A′ ⊞ L′ This is exactly the message-recovery attack in [1]|,Non-data,64
| However, compared to ran- dom guessing the left segment of X, this strategy only fares a little better, with advantage about 1−1/(M −1) N (r−2)/2  To am- plify the advantage, we need ciphertexts of X and X ′ under many tweaks Hence if we have ciphertexts (Ai, Bi) ← Ci and (A′ i, for i = 1,  |,Non-data,64
|  , q, then the Left-Half Re- ⊞ L′, and covery attack simply computes all values Ai ⊟ A′ i output the majority value In order to properly analyze the amplification process, we will need to develop a fine-grained understanding of the probability distribution of Lt⊟L′ t which was not necessary in [1] i) ← C ′ i, B′ As mentioned above, we’ll need to study Pr[Lt ⊟ L′ t = Z] for Z ∈ ZM |,Non-data,64
 The point Z = 0 is an outlier; it needs a sepa- rate Lemma 52 below This lemma will also be used several times in subsequent proofs for different purposes Lemma 5,Non-data,64
|2 generalizes a result in [9] for the boolean case; the proof is in the full version Lemma 52 Let F = Feistel[r, M, N, ⊞]|,Non-data,64
| Fix distinct X, X ′ ∈ ZM × ZN , a tweak T ∈ FTwk, and an even t ∈ {2, 4,   |,Non-data,64
| , r} Pick K ←$ FKeys Let Lt be the left segment of the round-t output of X under F|,Non-data,64
|E(K, T, ·) Define L′ t for X ′ likewise (a) If X and X ′ have the same right segment then N −1 M N −1 − 1 M ·(M N )(t−2)/2 ≤ Pr[Lt = L′ t] ≤ N −1 M N −1 (b) If X and X ′ have different right segments then N −1 M N −1 ≤ Pr[Lt = L′ t] ≤ N −1 M N −1 + 1 (M N )t/2  1 Proof of Theorem 5|,Non-data,64
|1 First we’ll show that Advmg XS ≤ M −1  Consider an arbitrary simulator S The simulator is given X ′ = (L′, R), and has to guess X = (L, R), where L ←$ ZM\{L′}|,Non-data,64
| The chance that the simulator can guess M −1  L correctly is at most Since this bound holds for any simulator, M −1 , and thus Pr[Gmg XS (S)] ≤ 1 1 Advmg XS = max S Pr[Gmg XS (S)] ≤ 1 M − 1  What’s left is to bound Pr[Gmr F,XS(LHR)] Recall that in the Left-Half Recovery attack, we’ll iterate q times, and in the ith iteration, we’ll compute a number Si ← A ⊟ A′ ⊞ L′, where A and A′ are the left segments of the ciphertexts Ci and C ′ i, respectively|,Non-data,64
| For each number s ∈ ZM , let Vi,s be the Bernoulli random variable such that Vi,s = 1 if and only if Si = s The attack computes Vs = V1,s + · · · + Vq,s, finds a number z such that Vz = maxs∈ZM {Vs}, and then outputs z as the left segment of the target message X Note that for any fixed s ∈ ZM , the random variables V1,s,  |,Non-data,64
|  , Vq,s are independent and identically distributed Let s∗ be the left segment of X and p = N M N −1  If we use an ideal FPE instead of F, then for each s ∈ ZM , Pr[V1,s = 1] is exactly p|,Non-data,64
| In Lemma 53 below, we’ll show that although F is not ideal, for any s ∈ ZM\{s∗}, Pr[V1,s = 1] ≤ p Yet the attack succeeds, because Pr[V1,s∗ = 1] ≥ p + ∆, where ∆ = 1−1/(M −1) N (r−2)/2  We give the proof of Lemma 5|,Non-data,64
|3 further below (b) Pr[Lt ⊟ L′ Lemma 53 Let F = Feistel[r, M, N, ⊞]|,Non-data,64
| Fix distinct X, X ′ ∈ ZM × ZN of the same right segment, T ∈ FTwk, and an even integer t ∈ {2, 4,   |,Non-data,64
| , r} Pick K ←$ FKeys Let Lt and L′ t be the the left segment of the round-t output of X and X ′ under F(K, T, ·), respectively|,Non-data,64
| Then (a) Pr[Lt ⊟ L′ t = L0 ⊟ L′ t = Z] ≤ N M N −1 + 1−1/(M −1) N (t−2)/2  0] ≥ N M N −1 , for any Z ∈ ZM\{L0 ⊟ L′ 0} The probabilities above are taken over a random sampling K ←$ FKeys|,Non-data,64
| To analyze the advantage, our goal is to give (i) an up- per bound bound for the probability that Vs < q(p + ∆/2) for every s ∈ ZM\{s∗}, and (ii) a lower bound for the probability that Vs∗ > q(p + ∆/2) By standard Chernoff 12·N r−2(cid:17), whereas bounds, Pr[Vs∗ ≤ q(p + ∆/2)] ≤ exp(cid:16) −λM q 9·N r−2(cid:17) We’ll elaborate the Pr[Vs ≥ q(p + ∆/2)] ≤ exp(cid:16) −λM q details in the full version Hence the adversary LHR can correctly guess s∗ with prob- ability at least 1 − Pr[Vs∗ ≤ q(p + ∆/2)] − Xs∈ZM \{s∗} Pr[Vs ≥ q(p + ∆/2)] 12·N r−2(cid:17) − M · exp(cid:16) −λM q 9·N r−2(cid:17) ≥ 1 − exp(cid:16) −λM q as claimed|,Non-data,64
| Proof of Lemma 53 Let Hitt(Z) denote the event that Lt ⊟ L′ t = Z Recall that we’d like to give a lower bound for Pr[Hitt(L0 ⊟ L′ 0)], and an upper bound for Pr[Hitt(Z)], for every Z ∈ ZM\{L0 ⊟ L′ 0}|,Non-data,64
| Lemma 52 already gives the bound for Pr[Hitt(0)] For the rest, we use the follow- ing Lemma 54; its proof is deferred to further below|,Non-data,64
| This lemma shows that (i) Pr[Hitt(Z)] is the same for any Z ∈ ZM\{0, L0 ⊟ L′ 0}, and (ii) the gap between Pr[Hitt(L0 ⊟ L′ 0)] and Pr[Hitt(Z)] is at least 1/N (r−2)t for any Z ∈ ZM\{0, L0⊟ L′ 0} Combining these properties with Lemma 52, we have the complete picture of the distribution of Lt ⊟ L′ t, and thus can derive the desired bounds Lemma 5|,Non-data,64
|4 Let F = Feistel[r, M, N, ⊞] Fix distinct X, X ′ ∈ ZM × ZN , T ∈ FTwk, and an even t ∈ {2, 4, |,Non-data,64
|   , r} Pick K ←$ F|,Non-data,64
|Keys Let Lt and Rt be the left and right seg- ments of the round-t output of X under FE(K, T, ·), respec- t for X ′ likewise Let Hitt(Z) denote tively|,Non-data,64
| Define L′ the event that Lt ⊟ L′ t = Z; the distribution is taken over a random sampling of K ←$ FKeys Then t and R′ 4501 Pr[Hitt(Z)] = Pr[Hitt(Z ′)] for all Z and Z ′ in the set ZM\{0, L0 ⊟ L′ 2|,Non-data,64
| Pr[Hitt(L0 ⊟ L′ ZM\{0, L0 ⊟ L′ 0} 0)] ≥ Pr[Hitt(Z)] + 1 0} N (r−2)t , for any Z ∈ Back to the proof of Lemma 53, from Lemma 5|,Non-data,64
|4, for any Z ∈ ZM\{0, L0 ⊟ L′ 0}, the probability Pr[Hitt(Z)] is the same Then for any Z ∈ ZM\{0, L0 ⊟ L′ 0)](cid:17)  Pr[Hitt(Z)] = M − 2(cid:16)1− Pr[Hitt(0)]− Pr[Hitt(L0 ⊟ L′ Hence, once we establish the lower bound of the probability Pr[Hitt(Lt ⊟ L′ t)], using the lower bound of Pr[Hitt(0)] as given in Lemma 52, the upper bound of Pr[Hitt(Z)] will automatically follow|,Non-data,64
| Next, from Lemma 54, 0}, 1 Pr[Hitt(L0 ⊟ L′ 0)] ≥ Pr[Hitt(Z)] + 1 N (r−2)t , for any Z ∈ ZM\{0, L0 ⊟ L′ 0}, and thus 1 − Pr[Hitt(L0 ⊟ L′ 0)] = Pr[Hitt(0)] + XZ∈ZM \{0,L0⊟L′ 0} Pr[Hitt(Z)] N − 1 M N − 1 + (M − 2)(cid:16)Pr[Hitt(L0 ⊟ L′ 0)] − 1 N (r−2)t(cid:17) ≤ Hence Pr[Hitt(L0 ⊟ L′ 0)] ≥ N M N − 1 + 1 − 1/(M − 1) N (r−2)t , giving the claimed lower bound for Pr[Hitt(L0 ⊟ L′ 0)] Proof of Lemma 5|,Non-data,64
|4 Let Fi be the round function of F at round i, and let Gi(·, ·) be Fi(K, ·, ·) We’ll prove that for any Z in ZM\{0}, if t ≥ 4 then Pr[Rt−26=R′ t−2] + Pr[Hitt−2(Z)]  N (1) Pr[Hitt(Z)] = M We postpone justifying Equation (1)|,Non-data,64
| We now show that our claims are implied by Equation (1), via induction on t Proceeding to details, let’s first prove the first claim Fix Z, Z ′ in ZM\{0, L0 ⊟L′ 0} First, consider the base case t = 2|,Non-data,64
| Since R0 = R′ 0, and recall that 2 Hence Pr[Hit2(Z)] and Pr[Hit2(Z ′)] L2 = L1 and L′ 2 = L′ are 0, and the first claim holds for the base case Suppose that it holds for t − 2, we’ll show that it holds for t as well From Equation (1), 0, we have L1 ⊟ L′ 1 = L0 ⊟ L′ Pr[Hitt(Z)] = 1 M · Pr[Rt−2 6= R′ t−2] + 1 N · Pr[Hitt−2(Z)] |,Non-data,64
| Likewise, Pr[Hitt(Z ′)] = 1 M · Pr[Rt−2 6= R′ From the induction hypothesis, t−2] + 1 N · Pr[Hitt−2(Z ′)]  Pr[Hitt−2(Z)] = Pr[Hitt−2(Z ′)]  Hence Pr[Hitt(Z)] = Pr[Hitt(Z ′)]  Next, we’ll prove the second claim|,Non-data,64
| Fix Z ∈ ZM\{0, L0 ⊟ L′ 0} Again, we’ll prove by induction on t First consider the base case t = 2 As above, Pr[Hit2(Z) = 0], while Pr[Hit2(L0 ⊟ L′ 0)] = 1|,Non-data,64
| Then the second claim holds for the base case Suppose that it holds for t − 2, we’ll show that it holds for t as well From Equation (1), Pr[Hitt(Z)] = 1 M · Pr[Rt−2 6= R′ t−2] + 1 N · Pr[Hitt−2(Z)], whereas Pr[Hitt(L0⊟L′ 0)] = Pr[Rt−2 6= R′ t−2] M + From the induction hypothesis, Pr[Hitt−2(L0 ⊟ L′ 0)] ≥ Pr[Hitt−2(Z)] + Pr[Hitt−2(L0 ⊟ L′ 0)] , N 1 N (r−2)(t−2)  Hence the second claim also holds for t|,Non-data,64
| We now prove Equation (1) Fix Z ∈ ZM\{0} Note that Lt = Lt−1 = Gt−1(T, Rt−2) ⊞ Lt−2, and L′ t−1 = Gt−1(T, R′ t = L′ t−2) ⊞ L′ t−2  On the one hand, since Gt−1 is a truly random function Pr[Hitt(Z)∧ (Rt−2 6= R′ On the other hand, if Rt−2 = R′ L′ t−2, and thus t−2)] = 1 M · Pr[(Rt−2 6= R′ t−2 then Lt ⊟ L′ t−2)]|,Non-data,64
| (2) t = Lt−2 ⊟ Pr[Hitt(Z) ∧ (Rt−2 = R′ t−2)] = Pr[Hitt−2(Z) ∧ (Rt−2 = R′ t−2 = Z then Lt−3 6= L′ t−2, and thus t−2)] (3) t−3, because Lt−3 = Lt−2 If Lt−2 ⊟ L′ and L′ t−3 = L′ Pr[Rt−2 = R′ t−2 || Hitt−2(Z)] = 1 N , since Rt−2 = Gt−2(T, Lt−3) ⊞Rt−3, R′ R′ t−3, and Gt−2 is independent of Lt−3 and L′ t−2 = Gt−2(T, L′ t−3 Hence t−3) ⊞ 1 Pr[Hitt−2(Z) ∧ (Rt−2 = R′ N · Pr[Hitt−2(Z)]  (4) Combining Equations (2), (3), and (4) yields Equation (1)|,Non-data,64
| t−2)] = Comparison with prior attacks Our attack is inspired by previous distinguishing attacks by Patarin [9, 10, 11] for the case where M = N = 2n, and ⊞ is the xor opera- tor In the first attack [9], given ciphertexts C = (A, B) and C ′ = (A′, B′) of two known messages X = (L, R) and X ′ = (L′, R), the distinguisher outputs 1 (meaning the ci- phertexts are indeed encrypted via Feistel[r, 2n, 2n, ⊕]) if A⊕A′ = L⊕L′, and outputs 0 (meaning the ciphertexts are encrypted via an ideal FPE) otherwise This attack wins with advantage about ∆ = 1−1/(2n−1) 2(r−2)n/2 |,Non-data,64
| The later at- tacks [10, 11] improved the advantage to constant by having ciphertexts of X and X ′ under many tweaks1 His analy- ses (see below for a detailed discussion) suggest Θ(2(r−2)n) tweaks are sufficient to distinguish with constant advantage Compared with Patarin’s attack, our Left-Half Recovery at- tack is better in every front: (i) it can recover the left segment of the target message, while Patarin’s attack only distinguishes the ciphertexts from random strings, (ii) it handles any domain ZN × ZN and any operator ⊞, (iii) 1Note that tweakable block ciphers were introduced by LRW [8] after Patarin’s work, and Patarin’s wording was of attacking “independent permutations” His attacks are however easily translated to tweakable block ciphers|,Non-data,64
| 451our analysis shows that O(n · 2(r−3)n) ciphertexts are suf- ficient, whereas Patarin’s only showed the attack succeeds (in achieving a weaker goal) with a larger number of cipher- text, namely Θ(2(r−2)n) 2(r−2)n 6= C ′ 1),   |,Non-data,64
| , (Tq, Cq, C ′ q)) To justify our comparison, we give a concise description of the most refined of Patarin’s attacks [11], and sketch an analysis of the resulting advantage following Patarin’s approach (The original paper does not spell out many of these details, thus some of the following is our own in- In this distinguishing attack, one is given terpretation) ((T1, C1, C ′ In the real game, Ci and C ′ i are pairs ciphertexts under tweak Ti of the known mes- sages X = (L, R) and X ′ = (L′, R), respectively|,Non-data,64
| In the ideal game, Ci and C ′ i are uniformly chosen from {0, 1}2n subject to the constraint that Ci i Let Vi = 1 if i = L⊕L′, and Vi = 0 otherwise, where Ai and A′ Ai⊕A′ i are left segments of Ci and C ′ i in the real game, respectively Define Ui for the ideal game likewise Let p = 2n 22n−1 and ∆ = 1−1/(2n−1) |,Non-data,64
| Patarin shows that V1,    , Vq are indepen- dent and identically distributed Bernoulli random variables, with Pr[V1] ≥ p + ∆|,Non-data,64
| Moreover, U1,    , Uq are independent and identically distributed Bernoulli random variables, with Pr[U1] = p|,Non-data,64
| Let V = V1 + · · · Vq and U = U1 + · · · + Uq Patarin suggests that q should be picked so that E[V ] − E[U ] ≥ √2 ·(cid:0)pVar[U ] +pVar[V ](cid:1), meaning q ≈ 2 · 2(r−2)n (the additional factor √2 was not present in the original paper, but it makes calculations somewhat easier) The distin- guisher receives (T1, C1, C ′ q) and lets Zi = 1 i = L⊕L′, and Zi = 0 otherwise, where Ai and A′ if Ai⊕A′ i are left segments of Ci and C ′ It outputs 1 if Z1 + · · · + Zq ≥ E[V ] − √2 · pVar[V ], and outputs 0 1 − PrhV < E[V ] − PrhU ≥ E[U ] + √2 ·pVar[U ]i ≤ otherwise In the real game, by Chebyshev’s inequality, the chance that the distinguisher outputs 1 is at least √2 ·pVar[V ]i ≥ 1 − In the ideal game, the chance it outputs 1 is at most Hence, the distinguisher wins with advantage 1/3|,Non-data,64
| We note that the attack complexity can in fact be reduced by using a better concentration bound (like Chernoff) to match what achieved by our attacks – however, we recall the reader that we target message recovery 1),   |,Non-data,64
| , (Tq, Cq, C ′ i respectively =  1 3 =  2 3 1 1 + 2 1 1 + 2 In the same work, Patarin also suggests an improved distin- guishing attack, where l > 2 messages per tweak are queried|,Non-data,64
| The distinguisher picks l distinct messages X1,    , Xl and q tweaks T1, |,Non-data,64
|   , Tq It then asks to get the correspond- ing ciphertexts (C1,1, |,Non-data,64
|   , C1,l),  |,Non-data,64
|  , (Cq,1,   |,Non-data,64
| , Cq,l) for each message-tweak pair Let Li be the left segment of Xi, and As,i be the left segments of Cs,i In the real game, for s ∈ {1,  |,Non-data,64
|  , q} and i, j ∈ {1,   |,Non-data,64
| , l} such that i < j and Xi and Xj have identical right segments, let Vs,i,j = 1 if As,i⊕As,j = Li⊕Lj, and let Vs,i,j = 0 otherwise Now, the random variables Vs,i,j are dependent Bernoulli ran- dom variables, as multiple queries are made on the same tweak However, Patarin conjectures that there is sufficient independence to apply the above Chebyshev argument while at the same time choosing l to be sufficiently large, up to l = Θ(22n) This would allow for (at best) Θ(23n) possible pairs i, j such that Xi and Xj have identical right segment, giving us Θ(q23n) random variables Vs,i,j|,Non-data,64
| Under Patarin’s conjecture, we can choose q = Θ(2(r−5)n) to have more than 2(r−2)n variables, and apply the above argument This would however also result in Θ(2(r−3)n) ciphertexts, as in our attack, at the cost of an unproved conjecture, and still for the simpler goal of distinguishing2 6 THE RIGHT-HALF RECOVERY ATTACK In the Left-Half Recovery attack, the target message X and the known message X ′ must have the same right seg- ment, and the attack recovers the left segment of X|,Non-data,64
| In contrast, in the Right-Half Recovery attack, we have no re- quirement on the relationship between X and X ′, and the attack will recover the right segment of X The attack Fix an integer q ≥ 1 Let DC2q be the class of all algorithms D that output X ′ ∈ ZM × ZN and distinct T1, |,Non-data,64
|   , Tq ∈ {0, 1}∗ Let SC2 = {XS[D] || D ∈ DC2], where each sampler XS[D] in SC2q behaves as follows|,Non-data,64
| Sampler XS[D] (X ′, T1,    , Tq) ←$ D ; (L′, R′) ← X ′ (L, R) ← X ←$ (ZM × ZN )\{X ′} ; a ← (L, R′) Return ((T1, X ′), (T1, X), |,Non-data,64
|   , (Tq, X ′), (Tq, X), X, a) Here the sampler XS[D] picks a target X that is different from the message X ′ produced by D The number of exam- ples Q = 2q; the number of tweaks is qt = q; the number of target tweaks is q∗ = q; and the number of examples per tweak is qe = 2|,Non-data,64
| Since X 6= X ′, each sampler in SC2q sat- isfies the distinctness condition The Right-Half Recovery attack RHR against SC2q is shown in Fig 7 Since qe is small, we would expect and desire that adversaries have low mr-advantage, even if Q is big|,Non-data,64
| Indeed, an ideal FPE scheme has this property Our RHR attack shows that Feistel-based FPE fails to have this property It can recover the right seg- ment of X from the ciphertexts and the right segment R′ of X ′; the left segment of X ′ is not needed Since our mr no- tion asks for full message recovery, the auxiliary information contains the left segment L of X, but this information is not needed for recovering the right segment of X|,Non-data,64
 Theorem 61 below gives a lower bound on the mr advantage of RHR; this bound is illustrated in Fig 8 Theorem 6,Non-data,64
|1 Let M ≥ 2, N ≥ 3 and q ≥ 1 be inte- gers, and let r ≥ 6 be an even integer such that M (r−2)/2 ≥ 36M 2(cid:17) and F = 2N  Let λ = (cid:16)1 − 1 Feistel[r, M, N, ⊞] Then for any sampler XS ∈ SC2q, N −1(cid:17)2(cid:16)1 − 2 N(cid:17)(cid:16)1 − 1 Advmr F,XS(RHR) ≥ 1 − N · exp(cid:16) −λqN 9 · M r−1(cid:17) − exp(cid:16) −λqN 12 · M r−1(cid:17) − 1 N − 1 |,Non-data,64
| Ideas of the attack The key idea of our Right-Half Re- covery attack is based on the observation specified and proved 2We note that Patarin appears to claim a lower attack com- plexity, but this seems to be due to a small error assuming that all pairs i, j give two inputs Xi and Xj with equal right segment for l = Θ(22n), which is easily seen not to be pos- sible 4521), (T1, C1),  |,Non-data,64
|  , (Tq, C′ Adversary RHR((T1, C′ (L, R′) ← a ; R ← 0 ; l ← 0 ; p ← 1 For s ∈ ZN do Vs ← 0 For i = 1 to q do q), (Tq, Cq), a) N −1 ; ∆ ← 1−1/(N −1) M (r−2)/2 (A, B) ← Ci ; (A′, B′) ← C′ i If A = A′ then s ← B ⊟ B′ ⊞ R′ ; l ← l + 1 ; Vs ← Vs + 1 For s ∈ ZN do If Vs > VR then R ← s If VR ≤ l(p + ∆/2) then R ← R′ X ← (L, R) ; Return X Figure 7: The Right-Half Recovery attack  1  08  0|,Non-data,64
6 FF1 8 bits 9 bits 10 bits 11 bits 12 bits  35  40  45  50  55  60  65  04  02  0  30  1  08  0,Non-data,64
|6 FF3  04  02  0  20 8 bits 9 bits 10 bits 11 bits 12 bits  25  30  35  40  45  50  55 Figure 8: The mr advantage of the Right-Half Recovery attack for binary strings of 8–12 bits The x-axis shows the log, base 2, of the num- ber q of ciphertext pairs, and the y-axis shows Advmr Feistel[r,M,N,⊞],XS(RHR), for XS ∈ SC2q|,Non-data,64
| On the top, we use the parameters of FF1 At the bottom, we use parameters of FF3 by Lemma 62 below|,Non-data,64
| Now, instead of requiring the known message X ′ and the target message X to have the same right segment, we only consider ciphertexts C and C ′ of X = (L, R) and X ′ = (L′, R′) such that C and C ′ have the same left segment (Of course on average, if one encrypts X and X ′ under q tweaks then we only have q/M such pairs of ciphertexts) For those C = (A, B) and C ′ = (A, B′), the value of B ⊟ B′ is most likely to be R ⊟ R′ In some sense, this observation is the dual of the idea in Lemma 5|,Non-data,64
|3 for the Left-Half Recovery To give an intuitive (but not quite correct) explanation for this duality, note that in the boolean case, the decryption of F1 = Feistel[r, M, N, ⊕] is the encryption of F2 = Feistel[r, N, M, ⊕], but pre- and post-processed by a rotation Then, one can imagine that, the process of encrypting X and X ′ via F1 to get C an C ′ is effectively “encrypting” C and C ′ via F2 (with additional pre- and post-processing) to get X and X ′ Then, if we have ciphertexts Ci and C ′ i of a target message X and a known message X ′ ← (L′, R′) under several tweaks, i i = (Ai, B′ i) such that Ci and C ′ N −1 and ∆ = 1−1/(N −1) M (r−2)/2 |,Non-data,64
| then we can recover the right segment of X as follows First, keep only pairs (Ci, C ′ i agree on their left segments, and suppose that there are l such pairs Then, ⊞ R′ for all such pairs, where Ci = compute Pi ← Bi ⊟ B′ (Ai, Bi) and C ′ i) Let P be the most frequent value of those Pi|,Non-data,64
| Let p = 1 If X and X ′ agree on their right segments then expectedly, P appears lp times In contrast, if X and X ′ differ in their right segments then P is most likely to be the right segment of X, and expectedly, it appears at least l(p + ∆) times Hence if P appears at most (p + ∆/2)l times then we’ll output R′, otherwise we’ll output P  Proof of Theorem 6|,Non-data,64
|1 First we’ll show that Advmg XS ≤ N −1  Consider an arbitrary simulator S The simulator is given the right segment R′ of X ′ and the left segment L of X ←$ (ZM × ZN )\{X ′}, and has to guess the right segment of X|,Non-data,64
| We’ll give entire X ′ to the simulator instead of just the right segment; it only improves the simulator’s advantage If L is also the left segment of X ′, then the right segment R of X is uniformly distributed over ZN\{R′}, and one can guess R with probability at most 1/(N − 1) If L is not the left segment of X ′ then R is uniformly distributed over ZN , and one can guess it with probability at most 1/N ≤ 1/(N−1) Hence Pr[Gmg N −1 |,Non-data,64
| Since this bound holds for any simulator, Advmg XS (S)] ≤ 1 XS = maxS Pr[Gmg 1 XS (S)] ≤ 1 N −1  i i) ← C ′ 1),   |,Non-data,64
| , (Cl, C ′ i For each s ∈ ZN , N −1 and ∆ = 1−1/(N −1) What’s left is to bound Pr[Gmr F,XS(RHR)] Recall that in the Right-Half Recovery attack, we only keep pairs (Ci, C ′ i) such that Ci and C ′ agree on their left segments The num- ber of such pairs is a Binomial random variable, but for now, suppose that there are l such pairs|,Non-data,64
| By reindexing, let (C1, C ′ l) be the pairs of ciphertexts that we keep In the attack, we iterate l times, and in the i-th itera- ⊞ R′, where (Ai, Bi) ← Ci tion, we’ll compute Si ← Bi ⊟ B′ and (Ai, B′ let Vi,s be the Bernoulli random variable such that Vi,s = 1 if and only if Si = s Let p = 1 M (r−2)/2  The attack computes Vs = V1,s + · · · + Vl,s, and finds P ∈ ZN such that VP = maxs∈ZN {Vs}|,Non-data,64
| If VP ≤ l(p + ∆/2) then we output R′ as the right segment of the target message X Otherwise, we’ll output P  Our goal is to bound the probability of Pr[Vs ≥ l(p + ∆/2)] for every s ∈ ZN  This can be done via Chernoff bounds, if we know the distribution of each Vi,s|,Non-data,64
| For the unlikely case that X and X ′ have the same right segment (meaning that R ⊟ R′ = 0), Lemma 62 below shows Pr[Vi,s = 1] = p for every s ∈ ZN\{0} Intuitively, since X and X ′ are different, for each given tweak, they must have different ciphertexts Since we consider only Ci and C ′ i of the same left segment, they must differ in the right segment|,Non-data,64
| So Bi ⊟ B′ i can’t be 0 in this case, but it’s equally likely to be any other value in ZN  In this case, we’re already given the right segment R of X via R′; the purpose of the ciphertexts is to help us realize that we’re lucky For the “usual” case that X and X ′ have different right segments, Lemma 62 shows that for any s ∈ ZN\{R ⊟ R′}, Pr[Vi,s = 1] is still bounded by p|,Non-data,64
| However, for s∗ = R ⊟ R′, the probability Pr[Vi,s∗ = 1] jumps beyond p + ∆, making the attack possible The proof of Lemma 62 is in the full version Lemma 6|,Non-data,64
|2 Let F = Feistel[r, M, N, ⊞] Fix distinct X, X ′ ∈ ZM,N , Z ∈ ZN\{0}, T ∈ FTwk, and an even in- teger t ∈ {4, 5, |,Non-data,64
|   , r} Pick K ←$ F|,Non-data,64
|Keys Let Lt and Rt 453denote the left and right segment of the round-t output of X under FE(K, T, ·) Define L′ t for X ′ likewise|,Non-data,64
| t and R′ (a) If R0 = R′ 0 then Pr[Rt ⊟ R′ t = Z || Lt = L′ t] = 1 N − 1  (b) For R0 6= R′ 0, Pr[Rt ⊟ R′ 1 N −1 if Z 6= R0 ⊟ R′ otherwise t = Z || Lt = L′ t] is at most N −1 + 1−1/(N −1) M (t−2)/2 1 0, but at least As explained above, we consider two cases for whether X and X ′ agree on their right segments Case 1: X and X ′ differ in their right segments|,Non-data,64
| From Lemma 62, for any s ∈ ZN\{s∗}, the random variables V1,s,   |,Non-data,64
| , Vq,s are independent and identically distributed, with Pr[Vi,s = 1] ≤ p Likewise, V1,s∗ ,   |,Non-data,64
| , Vq,s∗ are inde- pendent and identically distributed, with Pr[V1,s = 1] ≥ p + ∆ The chance that the adversary RHR can correctly guess s∗ is at least the probability that Vs < l(p + ∆/2) for every s ∈ ZN\{s∗}, and Vs∗ > l(p + ∆/2) By using Chernoff bounds, Pr[Vs ≥ l(p + z · ∆)] ≤ e−zl/9 for any s ∈ ZN\{s∗}, and Pr[Vs∗ ≤ l(p + ∆/2)] ≤ e−zl/12, where z = ∆2/p Now, given q pairs of ciphertexts, the number of pairs (C,C ′) among such that C and C ′ agree on their left segments is not a constant l, but a random variable U |,Non-data,64
| From Lemma 52, U is a Binomial random variable B(q, θ), with θ ≥ N −1  Hence the adversary RHR can correctly guess s∗ with probability at least M N −1 ≥ 1−1/(N −1) M q q q − 1 − Pr[Vs ≥ l(p + ∆/2)] Pr[U = l] · Pr[Vs∗ ≤ l(p + ∆/2)] Xl=0 Xl=0 Pr[U = l] · Xs6=s∗ l!θl(1 − θ)q−l(cid:16)e−zl/12 + N · e−zl/9(cid:17) Xl=0 q ≥ 1 − = 1 −(cid:16)θe−z/12 + 1 − θ(cid:17)q − N(cid:16)θe−z/9 + 1 − θ(cid:17)q We first bound the term(cid:16)θe−z/12+1−θ(cid:17)q From the fact that (1 − x)q ≤ e−qx for every 0 < x < 1, ≤ exp(cid:16)−qθ(1 − e−z/12)(cid:17)  (cid:16)θe−z/12 + 1 − θ(cid:17)q |,Non-data,64
| Next, from the hypothesis that r ≥ 6 and M (r−2)/2 ≥ 2N , (5) (6) in Equation (5) 1 z ≤ M r−2/N ≤ 1 2 · M (r−2)/2 ≤ 1 2M 2  Therefore, by using the fact that 1 − e−x ≥ x − x2/2 for every 0 < x < 1, (1 − e−z/12) ≥ z 12(cid:16)1 − z 24(cid:17) ≥ z 12(cid:16)1 − 1 36M 2(cid:17)  Then θ(1 − e−z/12) ≥ 1 θz 12(cid:16)1 − ≥ (cid:16)1 − 1 36M 2(cid:17) N −1(cid:17)2(cid:16)1 − 2 = λN 12 · M (r−1) N(cid:17)(cid:16)1 − 1 36M 2(cid:17) · N 12 · M (r−1) |,Non-data,64
| (7) (8) (9) From Equation (6) and Equation (7), Analogously, we can show that (cid:16)θe−z/12 + 1 − θ(cid:17)q (cid:16)θe−z/9 + 1 − θ(cid:17)q ≤ exp(cid:16) −λqN ≤ exp(cid:16) −λqN 12 · M r−1(cid:17)  9 · M (r−1)(cid:17)  From Equation (5), Equation (8), and Equation (9), we ob- tain the claimed result Case 2: X and X ′ agree in the right segments|,Non-data,64
| This case can be handled similar to Case 1 We’ll elaborate the details in the full version 7 THE FULL-MESSAGE RECOVERY AT- TACK Recall that the LHR attack recovers the left segment of the target message X, while the RHR attack recovers the right segment of X|,Non-data,64
| By combining them, one can fully re- cover X as follows We require ciphertexts of three messages X, X ′, X ∗ for q tweaks, with sufficiently large q, to recover X The message X ′ is fully known but has no relation with the target X; this is already enough to recover the right seg- ment of X, according to the RHR attack The message X ∗ is required to have the same right segment as the target, but it’s only partially known: only the left segment of X ∗ is included in the auxiliary information|,Non-data,64
| For example, X ∗ is the “default” version of X, in which the left segment is 0 Although X ∗ is only partially known, as mentioned above, we already recovered the right segment of X (and also X ∗) Then the LHR attack gives us the left segment of X The attack|,Non-data,64
| Fix integer q ≥ 1 Let DC3q be the class of all algorithms D that output (L′, R′) ← X ′ ∈ ZM × ZN , L∗ ∈ ZM\{L′} and distinct tweaks T1,   |,Non-data,64
| , Tq ∈ FTwk Let SC3q = {XS[D] || D ∈ DC3q], where each sampler XS[D] in SC3q behaves as follows Sampler XS[D] (X ′, L∗, T1,  |,Non-data,64
|  , Tq) ←$ D ; (L′, R′) ← X ′ L ←$ ZM\{L′, L∗} ; R ←$ ZN ; X ← (L, R) X ∗ ← (L∗, R) ; a ← (X ′, L∗) For i = 1 to q do Zi ← ((Ti, X ∗), (Ti, X ′), (Ti, X)) Return (Z1,   |,Non-data,64
| , Zq, X, a) The sampler above picks the left segment L of the target X uniformly random, with the condition that L must be dif- ferent from both L∗ and the left segment L′ of the known message X ′ produced by D It then picks the right segment R of X uniformly, and let X ∗ = (L∗, R) be another partially known message The auxiliary information contains X ′ and the left half L∗ of X ∗ The number of examples is Q = 3q; the number of tweaks is qt = q; the number of target tweaks is q∗ = q; and the number of examples per tweak is qe = 3|,Non-data,64
| 454i ), (Ti, C′ Adversary FMR(U1,    , Uq, a) For i = 1 to q do ((Ti, C∗ (X ′, L∗) ← a ; (L′, R′) ← X ′ ; a1 ← (L∗, R′) X ∗ ← RHR((T1, C′ a2 ← X ∗ X ← LHR((T1, C∗ Return X 1 ), (T1, C1), |,Non-data,64
|   , (Tq, C∗ 1), (T1, C1),  |,Non-data,64
|  , (Tq, C′ i), (Ti, Ci)) ← Ui q), (Tq, Cq), a1) q ), (Tq, Cq), a2) Figure 9: The Full-Message Recovery attack  1  08  0|,Non-data,64
6 FF1 8 bits 9 bits 10 bits 11 bits 12 bits  35  40  45  50  55  60  65  04  02  0  30  1  08  0,Non-data,64
|6 FF3  04  02  0  20 8 bits 9 bits 10 bits 11 bits 12 bits  25  30  35  40  45  50  55 Figure 10: The mr advantage of FMR attack for bi- nary strings of 8–12 bits The x-axis shows the log, base 2, of the number q of ciphertext pairs, and the y-axis shows Advmr Feistel[r,M,N,⊞],XS(FMR), for XS ∈ SC3q|,Non-data,64
| On the top, we use the parameters of the FF1 At the bottom, we use parameters of FF3 Since X, X ′, and X ∗ are distinct, each sampler in SC3q sat- isfies the distinctness condition The Full-Message Recovery attack FMR against SC3q is shown in Fig|,Non-data,64
| 9 Since qe is small, we would expect and desire that adversaries have low mr-advantage, even if Q is big Indeed, an ideal FPE scheme has this property Our FMR attack shows that Feistel-based FPE fails to have this property|,Non-data,64
 Theorem 71 below gives a lower bound on the mr advantage of FMR; this bound is illustrated in Fig 10 Theorem 7,Non-data,64
|1 Let N, M ≥ 3 and q ≥ 1 be integers, and let r ≥ 6 be an even integer such that M (r−2)/2 ≥ 2N and 36M 2(cid:17) N (r−2)/2 ≥ 2M  Let λ1 =(cid:16)1 − 1 M N(cid:17) Let F = Feistel[r, M, N, ⊞]|,Non-data,64
| and λ2 =(cid:16)1− 1 Then for any sampler XS in the class SC3q, M −1(cid:17)2(cid:16)1− 1 N −1(cid:17)2(cid:16)1 − 2 N(cid:17)(cid:16)1 − 1 Advmr F,XS(FMR) ≥ 1 − N · exp(cid:16) −λ1qN M · exp(cid:16) −λ2M q 9 · M r−1(cid:17)− 9 · N r−2(cid:17) − exp(cid:16) −λ2M q 12 · M r−1(cid:17) − exp(cid:16) −λ1qN 12 · N r−2(cid:17)− 1  N (M − 2) Acknowledgments We thank the CCS reviewers for their insightful comments Bellare was supported in part by NSF grant CNS-1526801, ERC Project ERCC FP7/615074 and a gift from Microsoft Hoang and Tessaro were supported in part by NSF grants CNS-1423566 and CNS-1553758 (CAREER), and by the Glen and Susanne Culler Chair|,Non-data,64
|ABSTRACT We present an approach to enforce access revocation on re- sources stored at external cloud providers The approach relies on a resource transformation that provides strong mu- tual inter-dependency in its encrypted representation To revoke access on a resource, it is then sufficient to update a small portion of it, with the guarantee that the resource as a whole (and any portion of it) will become unintelligible to those from whom access is revoked The extensive experi- mental evaluation on a variety of configurations confirmed the effectiveness and efficiency of our solution, which showed excellent performance and compatibility with several imple- mentation strategies|,Non-data,66
| Keywords Access control; Policy revocation; Resource encryption; Mix&Slice 1 INTRODUCTION With the considerable advancements in ICT solutions, users and companies are finding increasingly appealing to rely on external services for storing resources and making them available to others In such contexts, a promising approach to enforce access control to externally stored re- sources is via encryption: resources are encrypted for storage and only authorized users have the keys that enable their de- cryption There are several advantages that justify the use of encryption for enforcing access control|,Non-data,66
| First, robust en- cryption has become computationally inexpensive, enabling its introduction in domains that are traditionally extremely sensitive to performance (like cloud-based applications and management of large resources) Second, encryption pro- vides protection against the service provider itself, which - while trustworthy for providing access - cannot typically be considered authorized to know the content of the resources Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita- tion on the first page Copyrights for components of this work owned by others than ACM must be honored Abstracting with credit is permitted|,Non-data,66
| To copy otherwise, or re- publish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acmorg CCS’16, October 24-28, 2016, Vienna, Austria c(cid:13) 2016 ACM|,Non-data,66
 ISBN 978-1-4503-4139-4/16/10   $15,Non-data,66
00 DOI: http://dxdoiorg/101145/2976749,Non-data,66
|2978377 it stores (honest-but-curious scenario) and hence also to en- force access control Third, encryption solves the need of having a trusted party for policy enforcement: resources en- force self-protection, since only authorized users, holding the keys, will be able to decrypt them One of the complex aspects in using encryption to enforce access control policy concerns access revocation If granting an authorization is easy (it is sufficient to give the newly au- thorized user access to the key), revoking an authorization is a completely different problem|,Non-data,66
| There are essentially two approaches to enforce revocation: i) re-encrypt the resource with a new key or ii) revoke access to the key itself Re- encryption of the resource entails, for the data owner, down- loading the resource, decrypting it and re-encrypting it with a new key, re-uploading the resource, and re-distributing the key to the users who still hold authorizations If de- cryption, re-encryption, and even key management (for this specific context) can today be considered not an issue, the big problem is represented by the need of downloading and re-uploading the resource, with a considerable overhead for the data owner This overhead, already an obstacle today, will become even more so in emerging big data contexts|,Non-data,66
| The alternative approach of enforcing revocation on the resource by preventing access to the key with which the resource is encrypted cannot be considered a solution As a matter of fact, it protects the key, not the resource itself, and it is inevitably fragile against a user who - while having been re- voked from an access - has maintained a local copy of the key Since keys are compact in size, such a threat is indeed real Our approach|,Non-data,66
| In this paper, we present a novel approach to enforce access revocation that provides efficiency, as it does not require expensive upload/re-upload of (large) re- sources, and robustness, as it is resilient against the threat of users who might have maintained copies of the keys pro- tecting resources on which they have been revoked access The basic idea of our approach is to provide an encrypted representation of the resources that guarantees complete in- terdependence (mixing) among the bits of the encrypted content Such a guarantee is ensured by using different rounds of encryption, while carefully selecting their input to provide complete mixing, meaning that the value of each bit in the resulting encrypted content depends on every bit of the original plaintext content In this way, unavailabil- ity of even a small portion of the encrypted version of a resource completely prevents the reconstruction of the re- 217source or even of portions of it|,Non-data,66
| Brute-force attacks guess- ing possible values of the missing bits are possible, but even for small missing portions of the encrypted resource, the re- quired effort would be prohibitive The all-or-nothing trans- form (AONT) [16] considers similar requirements, but the techniques proposed for it are not suited to our scenario, because they are based on the assumption that keys are not known to users, whereas in our scenario revoked users can know the encryption key and may plan ahead to locally store critical pieces of information Trading off between the potentially clashing need of con- necting all bits of a resource to provide the wished interde- pendency of the content on one side, and the potential huge size of the resources and need to maintain a possible fine- granularity of access within the resource itself on the other side, we apply the idea of mixing content within portions of the resource, enforcing then revocation by overwriting encrypted bits in every such portion Before mixing, our approach partitions the resource in different, equally sized, chunks, called macro-blocks|,Non-data,66
| Then, as the name hints, it is based on the following concepts • Mix: the content of each macro-block is processed by an iterative application of different encryption rounds together with a carefully designed bit mixing, that en- sures, at the end of the process, that every individual bit in the input has had impact on each of the bits in the encrypted output • Slice: the mixed macro-blocks are sliced into fragments so that fragments provide complete coverage of the re- source content and each fragment represents a minimal (in terms of number of bits of protection, which we call mini-block ) unit of revocation: lack of any single frag- ment of the resource completely prevents reconstruc- tion of the resource or of portions of it To revoke access from a user, it is sufficient to re-encrypt one (any one) of the resource fragments with a new key not known to the user|,Non-data,66
| The advantage is clear: re-encrypting a tiny chunk of the resource guarantees protection of the whole resource itself Also, the cloud provider simply needs to provide storage functionality and is not required to play an active role for enforcing access control or providing user authentication Our Mix&Slice proposal is complemented with a convenient approach for key management that, based on key regression, avoids any storage overhead for key dis- tribution Outline|,Non-data,66
 The remainder of the paper is organized as fol- lows Section 2 illustrates our approach to produce an en- crypted representation with the desired guarantees Sec- tion 3 presents the enforcement of access revocation Sec- tion 4 discusses the effectiveness of our solution in providing revocation,Non-data,66
| Section 5 illustrates our implementation and the extensive experimental evaluation confirming its advantages and applicability Section 6 discusses related work Finally, Section 7 presents our conclusions 2|,Non-data,66
| MIX & SLICE 21 Blocks, mini-blocks, and macro-blocks The basic building block of our approach is the appli- cation of a symmetric block cipher A symmetric crypto- graphic function operating on blocks guarantees complete dependency of the encrypted result from every bit of the in- put and the impossibility, when missing some bits of an en- crypted version of a block, to retrieve the original plaintext block (even if parts of it are known) The only possibility to retrieve the original block would be to perform a brute-force attack attempting all the possible combinations of values for the missing bits|,Non-data,66
| For instance, modern encryption functions like AES guarantee that the absence of i bits from the input (plaintext) and of o bits from the output (ciphertext) does not permit, even with knowledge of the encryption key k, to properly reconstruct the plaintext and/or ciphertext, apart from performing a brute-force attack generating and verify- ing all the 2min(i,o) possible configurations for the missing bits [1] Clearly, the larger the number of bits that are missing in the encrypted version of a block, the harder the effort required to perform a brute-force attack, which requires at- tempting 2x possible combinations of values when x bits are missing Such security parameter is at the center of our ap- proach and we explicitly identify a sequence of bits of its length as the atomic unit on which our approach operates, which we call mini-block  Applying block encryption with explicit consideration of such atomic unit of protection, and extending it to a coarser-grain with iterative rounds, our approach identifies the following basic concepts|,Non-data,66
| • Block : a sequence of bits input to a block cipher (it corresponds to the classical block concept) • Mini-block : a sequence of bits, of a specified length, contained in a block It represents our atomic unit of protection (ie|,Non-data,66
|, when removing bits, we will operate at the level of mini-block removing all its bits) • Macro-block : a sequence of blocks It allows extend- ing the application of block cipher on sequences of bits larger than individual blocks In particular, our ap- proach operates mixing bits at the macro-block level, extending protection to work against attacks beyond the individual block|,Non-data,66
| Our approach is completely parametric with respect to the size (in terms of the number of bits) that can be con- sidered for blocks, mini-blocks, and macro-blocks The only constraints are for the size of a mini-block to be a divisor of the size of the block (aspect on which we will elaborate later on) and for the size of a macro-block to be a product of the size of a mini-block and a power of the number of mini-blocks in a block (ie, the ratio between the size of a block and the size of a mini-block)|,Non-data,66
| In the following, for concreteness and simplicity of the figures, we will illustrate our examples assuming the application of AES with blocks of 128 bits and mini-blocks of 32 bits, which corresponds to having 4 mini-blocks in every block and therefore operating on macro-blocks of size 32 · 4x, with x arbitrarily set In the following, we will use msize, bsize, Msize to denote the size (in bits) of mini-blocks, blocks, and macro-blocks, re- spectively We will use bj [i] (Mj[i], resp) to denote the i-th mini-block in a block bj (macro-block Mj, resp|,Non-data,66
|) We will simply use notation [i] to denote the i-th mini-block in a generic bit sequence (be it a block or macro-block), and [[j]] to denote the j-th block In the encryption process, a sub- script associated with a mini-block/block denotes the round that produced it 218[0] 0 [1] 0 [2] 0 [3] 0 [4] 0 [5] 0 [6] 0 [7] 0 [8] 0 [9] 0 [10] [11] 0 0 [12] [13] 0 [14] [15] 0 0 0 E E E E [0] 1 [1] 1 [2] 1 [3] 1 [4] 1 [5] 1 [6] 1 [7] 1 [8] 1 [9] 1 [10] [11] 1 1 [12] [13] 1 [14] 1 1 [15] 1 E E E E [0] 2 [1] 2 [2] 2 [3] 2 [4] 2 [5] 2 [6] 2 [7] 2 [8] 2 [9] 2 [10] [11] 2 2 [12] [13] 2 [14] [15] 2 2 2 Figure 1: An example of mixing of 16 mini-blocks assuming m = 4 2|,Non-data,66
|2 Mixing The basic step of our approach (on which we will iter- atively build to provide complete mixing within a macro- block) is the application of encryption at the block level This application is visible at the top of Figure 1, where the first row reports a sequence of 16 mini-blocks ([0],   |,Non-data,66
| , [15]) composing 4 blocks The second row is the result of block encryption on the sequence of mini-blocks As visible from the pattern-coding in the figure, encryption provides mixing within each block so that each mini-block in the result is dependent on every mini-block in the same input block In other words, each [i]1 is dependent on every [j]0 with (i div 4) = (j div 4)|,Non-data,66
| One round of block encryption provides mixing only at the level of block With reference to our example, mix- ing is provided among mini-blocks [0]0   |,Non-data,66
| [3]0, [4]0    [7]0, [8]0 |,Non-data,66
|   [11]0, and [12]0  |,Non-data,66
|  [15]0, respectively Absence of a mini-block from the result will prevent reconstruction only of the plaintext block including it, while not preventing the reconstruction of all the other blocks For instance, with reference to our example, absence of [0]1 will prevent recon- struction of the first block (mini-blocks [0]0, |,Non-data,66
|   , [3]0) but will not prevent reconstruction of the other three blocks (mini-blocks [4]0,  |,Non-data,66
|  , [15]0) Protection at the block level is clearly not sufficient in our context, where we expect to manage resources of arbitrarily large size and would like to provide the guarantee that the lack of any individual mini- block would imply the impossibly (apart from performing a brute-force attack) of reconstructing any other mini-block of the resource The concept of macro-block, and accurate extension of block ciphering to operate across blocks, allows us to provide mixing on an arbitrarily long sequence of bits (going much above the size of the block)|,Non-data,66
| The idea is to extend mixing to the whole macro-block by the iterative application of block encryption on, at each round, blocks composed of mini-blocks that are represen- tative (ie, belong to the result) of different encryptions in the previous round Before giving the general defini- tion of our approach, let us discuss the simple example of two rounds illustrated in Figure 1, where [0]1, |,Non-data,66
|   , [15]1 are the mini-blocks resulting from the first round The second round would apply again block encryption, con- sidering different blocks each composed of a representa- tive of a different computation in the first round|,Non-data,66
| To Mix(M) 1: for i := 1,    , x do 2: span := mi distance := mi−1 for j := 0, |,Non-data,66
|   , b − 1 do 3: 4: 5: 6: 7: 8: /* at each round i */ /* number of mini-blocks in a mixing */ /* leg of mini-blocks input to an encryption */ /* each j is an encryption */ /* identify the input to the j-th encryption picking, */ /* within each span, mini-blocks at leg distance */ let block be the concatenation of all mini-blocks [l] st|,Non-data,66
| (l mod distance) = j and (j · m) div span = l div span [[j]]i := E(k, block) /* write the result as the j-th block in output */ Figure 2: Mixing within a macro-block M guarantee such a composition, we define the blocks input to the four encryption operations as composed of mini- blocks that are at distance 4 (=m) in the sequence, which corresponds to say that they resulted from different en- cryption operations in the previous round The blocks considered for encryption would then be h[0]1[4]1[8]1[12]1i, h[1]1[5]1[9]1[13]1i,h[2]1[6]1[10]1[14]1i,h[3]1[7]1[11]1[15]1i The result would be a sequence of 16 mini-blocks, each of which is dependent on each of the 16 original mini-blocks, that is, the result provides mixing among all 16 mini-blocks, as vis- ible from the pattern-coding in the figure With 16 mini- blocks, two rounds of encryption suffice for guaranteeing mixing among all of them|,Non-data,66
| Providing mixing for larger se- quences clearly requires more rounds This brings us to the general formulation of our approach operating at the level of macro-block of arbitrarily large size (the example just il- lustrated being a macro-block of 16 mini-blocks) To ensure the possibility of mixing, at each round, blocks composed of mini-blocks resulting from different encryption operations of the previous round, we assume a macro-block composed of a number of mini-blocks, which is the power of the number (m) of mini-blocks in a block For instance, with reference to our running example where blocks are composed of 4 mini-blocks (i|,Non-data,66
|e, m=4), macro-blocks can be composed of 4x mini-blocks, with an arbitrary x (x=2 in the example of Figure 1) The assumption can be equivalently stated in terms of blocks, where the number of blocks b will be 4x−1 Any classical padding solution can be employed to guarantee such a requirement, if not already satisfied by the original bit sequence in input|,Non-data,66
| Providing mixing of a macro-block composed of b blocks with b=mx−1 requires x rounds of encryption each composed of b encryptions Each round allows mixing among a num- ber span of mini-blocks that multiplies by m at every round At round i, each encryption j takes as input m mini-blocks that are within the same span (ie|,Non-data,66
|, the same group of m i mini-blocks to be mixed) and at a distance (m i−1) Figure 2 illustrates the mixing procedure To illustrate, consider the example in Figure 1, where blocks are composed of 4 mini- blocks (m=4) and we have a macro-block of 16 mini-blocks, that is, 4 blocks (b=4) Mixing requires x = 2 rounds of encryption (16 = 42), each composed of 4 (b) encryptions operating on 4 (m) mini-blocks|,Non-data,66
| At round 1, the span is 4 (ie, mixing operates on chunks of 4 mini-blocks) and mini- blocks input to an encryption are taken at distance 1 within each span At round 2, the span is 16 (all mini-blocks are mixed) and mini-blocks input to an encryption are taken at distance 4 within each span|,Non-data,66
| Let us consider, as an an- other example, a macro-block composed of 64 mini-blocks (ie, 16 blocks) Mixing requires 3 rounds|,Non-data,66
| The first two rounds would work as before, with the second round pro- 219[0][1][2][3] E [0] [4] [8] [12] [60] [61] [62] [63] [51] [55] [59] [63] E E E [0] [15][16] [31][32] [47][48] [63] E E round 1 span: 4 distance: 1 round 2 span: 16 distance: 4 round 3 span: 64 distance: 16 Figure 3: Propagation of the content of mini-blocks [0] and [63] in the mix process ducing mixing within chunks of 16 mini-blocks The third round would then consider a span of all the 64 mini-blocks and mini-blocks input to an encryption would be the ones at distance 16 At each round i, mini-blocks are mixed among chunks of m i mini-blocks, hence ensuring at round x, mixing of the whole macro-block composed of m x mini-blocks Figure 3 captures this concept by showing the mixing of the content of the first ([0]) and last ([63]) mini-blocks of the macro-block at the different rounds, given by the en- cryption to which they (and those mini-blocks mixed with them in previous rounds) are input, showing also how the two meet at the step that completes the mixing|,Non-data,66
| While for simplicity the figure pictures only propagation of the con- tent of two mini-blocks, note that at any step they (just like other mini-blocks) actually carry along the content of all the mini-blocks with which they mixed in previous rounds Given a macro-block M with mx mini-blocks (corresponding to b blocks), the following two properties hold: 1) a generic pair of mini-blocks [i] and [j] mix at round r with i div mr = j div mr; and 2) x rounds bring complete mixing In other words, the number of encryption rounds needed to mix a macro-block with m · b mini-blocks is logm (m · b) An important feature of the mixing is that the number of bits that are passed from each block in a round to each block in the next round is equal to the size of the mini-block|,Non-data,66
| This guarantees that the uncertainty introduced by the absence of a mini-block at the first round (2msize ) maps to the same level of uncertainty for each of the blocks involved in the second round, and iteratively to the next rounds, thanks to the use of AES at each iteration This implies that a com- plete mixing of the macro-block requires at least logm (m · b) rounds, that is, the rounds requested by our technique Another crucial aspect is that the representation after each round has to be of the same size as the original macro- block In fact, if the transformation produced a more com- pact representation, there would be a possibility for a user to store this compact representation and maintain access to the resource even after revocation (this is a weakness of other solutions discussed in Section 6)|,Non-data,66
| Since, in our ap- proach, each round produces a representation that has the same macro-block size, the user has no benefit in aiming to attack one round compared to another (see Section 4) We note that an interpretation of the proposed mixing is that it extends the ability of protecting the correspondence between input and output of a block cipher to blocks of ar- bitrary size An alternative approach that we considered to obtain this result was based on the use of a Feistel archi- tecture [14], which is known to be an effective technique for the construction of block ciphers The approach uses, as the round function of the Feistel architecture, a block cipher|,Non-data,66
| The approach can be applied iteratively, doubling the block size at every iteration The analysis we performed showed that this approach would lead to less efficiency compared to the solution proposed in this paper, with a number of invo- cations of the basic block cipher equal to 2 · logm (m · b) The Feistel-based approach can be adopted when the mini-block size desired for security goes beyond the block size of the available block cipher Similarly, symmetric cryptosystems operating on large blocks can support larger mini-blocks and also reduce the number of rounds of our approach|,Non-data,66
| For in- stance, AESQ [3, 4] shuffles 4 AES blocks and could be used as a 512-block cipher in our structure When resources are extremely large (or when access to a resource involves only a portion of it) considering a whole resource as a single macro-block may be not desirable Even if only with a logarithmic dependence, the larger the macro- block the more the encryption (and therefore decryption to retrieve the plaintext) rounds required Also, encrypting the whole resource as a single macro-block implies its complete download at every access, when this might actually not be needed for service|,Non-data,66
| Accounting for this, we do not assume a resource to cor- respond to an individual macro-block, but assume instead that any resource can be partitioned into M macro-blocks, which can then be mixed independently The choice of the size of macro-blocks should take into consideration the per- formance requirements of both the data owner (for encryp- tion) and of clients (for decryption), and the possible need to serve fine-grained retrieval of content This requirement can be then efficiently accommodated independently encrypting (ie|,Non-data,66
|, mixing) different portions of the resource, which can be downloaded and processed independently (we will dis- cuss this in Section 52) Encryption of a resource would then entail a preliminary step cutting the resource in different, equally sized, macro- blocks on which mixing operates To ensure the mixed 220• • • M 1 |,Non-data,66
| IV 1 IV 0 M 1 resource cutting M 0 XOR-ing M 0 mixing • • • • • • • • • • • • M M-1 M M-1 IVM-1 [0] x [m -1] M M-1 Encrypt 1: cut R in M macro-blocks M0,    , MM −1 2: apply padding to the last macro-block MM −1 3: IV := randomly choose an initialization vector 4: for i = 0, |,Non-data,66
|   , M − 1 do 5: Mi[[1]] := Mi[[1]] ⊕ IV 6: Mix(Mi) 7: IV := IV + 1 for j = 0,  |,Non-data,66
|  , m x − 1 do /* encrypt macro-blocks */ /* xor the first block with the IV */ /* encrypt the macro-block */ 8: 9: M 1 M 0 F0 Fm -1 x /* initialization vector for the next macro-block */ /* slicing */ Fj[i] := Mi[j] Figure 5: Algorithm for encrypting a resource R (a) (b) Figure 4: From resource to fragments versions of macro-blocks be all different, even if with the same original content, the first block of every macro-block is xored with an initialization vector (IV ) before starting the mixing process Since mixing guarantees that every block in a macro-block influences every other block, the adoption of a different initialization vector for each macro-block guar- antees indistinguishability among their encrypted content The different initialization vectors for the different blocks can be obtained by randomly generating a vector for the first macro-block and then incrementing it by 1 for each of the subsequent macro-blocks in the resource, in a way similar to the CTR mode [9]|,Non-data,66
| Figure 4(a) illustrates such process 23 Slicing The starting point for introducing mixing is to ensure that each single bit in the encrypted version of a macro-block de- pends on every other bit of its plaintext representation, and therefore that removing any one of the bits of the encrypted macro-block would make it impossible (apart from brute- force attacks) to reconstruct any portion of the plaintext macro-block Such a property operates at the level of macro- block|,Non-data,66
| Hence, if a resource (because of size or need of effi- cient fine-grained access) has been partitioned into different macro-blocks, removal of a mini-block would only guarantee protection of the macro-block to which it belongs, while not preventing reconstruction of the other macro-blocks (and therefore partial reconstructions of the resource) Resource protection can be achieved if, for each macro-block of which the resource is composed, a mini-block is removed This observation brings to the second concept giving the name to our approach, which is slicing Slicing the encrypted re- source consists in defining different fragments such that a fragment contains a mini-block for each macro-block of the resource, no two fragments contain the same mini-block, and for every mini-block there is a fragment that contains it|,Non-data,66
| To ensure all this, as well as to simplify management, we slice the resource simply putting in the same fragment the mini-blocks that occur at the same position in the different macro-blocks Slicing and fragments are defined as follows Definition 21 (Slicing and fragments)|,Non-data,66
| Let R be a resource and M0,    , MM −1 be its (individually mixed) macro-blocks, each composed of (m · b) mini-blocks|,Non-data,66
| Slicing produces (m·b) fragments for R where Fi = hM0[i],    , MM −1[i]i, with i = 1, |,Non-data,66
|   , (m · b) Figure 4(b) illustrates the slicing process and Figure 5 il- lustrates the procedure for encrypting a resource R|,Non-data,66
| R is first cut into M macro-blocks and an initialization vector is randomly chosen The first block of each macro-block is then xor-ed with the initialization vector, which is in- cremented by 1 for each macro-block The macro-block is then encrypted with a mixing process (Figure 2) Encrypted macro-blocks are finally sliced into fragments|,Non-data,66
| 3 ACCESS MANAGEMENT Accessing a resource (or a macro-block in the resource, resp) requires availability of all its fragments (its mini- blocks in all the fragments, resp), and of the key used for encryption|,Non-data,66
| Policy changes corresponding to granting access to new users can be simply enforced, as usual, by giving them the encryption key In principle, policy changes cor- responding to revocation of access would instead normally entail downloading the resource, re-encrypting it with a new key, re-uploading the resource, and distributing the new en- cryption key to all the users who still hold authorizations Our approach permits to enforce revocation of access to a resource by simply making any of its fragments unavailable to the users from whom the access is revoked Since lack of a fragment implies lack of a mini-block for each macro-block of a resource, and lack of a mini-block prevents reconstruc- tion of the whole macro-block, lack of a fragment equates to complete inability, for the revoked users, to reconstruct the plaintext resource or any portion of it|,Non-data,66
| In other words, it equates to revocation Access revocations are then enforced by the data owner by randomly picking a fragment, which is then downloaded, re- encrypted with a new key (which will be made known only to users still authorized for the access), and re-uploaded at the server overwriting its previous version While still requesting some download/re-upload, operating on a fragment clearly brings large advantages (in terms of throughput) with re- spect to operating on the whole resource (see Section 5) Revocation can be enforced on any randomly picked frag- ment (even if already re-written in a previous revocation) and a fresh new key is employed at every revoke operation|,Non-data,66
| Figure 6 illustrates an example of fragments evolution due to the enforcement of a sequence of revoke operations Fig- ure 6(a) is the starting situation with the original fragments computed as illustrated in Section 2 Figure 6(b-d) is the se- quence of rewriting to enforce revocations, which involve, re- spectively, fragment F10, re-encrypted with key k1, fragment F4, re-encrypted with key k2, and fragment F10 again, now re-encrypted with key k3 In the following, we use notation Fj i to denote a version of fragment Fi encrypted with key kj, being F0 i the version of the fragment obtained through the mixing process|,Non-data,66
| In the figure, the resource is represented in 2210 0 F15 F14 0 F 0 0 F 1 0 F 2 0 F 3 0 F 4 0 F 5 0 F 6 0 0 F 8 F 7 macroblock k 0 key k 1 (b) 0 F 0 0 F 1 0 F 2 0 F 3 0 F 5 0 F 6 0 0 F 8 F 7 0 F 0 0 F 1 0 F 2 0 F 3 0 F 4 0 F 5 0 F 6 macroblock 0 0 F 8 F 7 (a) 0 F 0 0 F 1 0 F 2 0 F 3 0 F 5 0 F 6 0 0 F 8 F 7 0 F 9 0 F10 0 F 9 0 0 F12 F11 0 0 F12 F11 0 F13 0 F13 macroblock k 0 key k 1 k 2 1 F10 2 F 4 (c) t n e m g a r f t n e m g a r f 0 0 F15 F14 0 F 9 0 F 9 0 0 F12 F11 1 F10 0 0 F12 F11 0 F13 0 F13 0 0 F15 F14 0 0 F15 F14 t n e m g a r f t n e m g a r f macroblock k 0 key k 1 k 2 k 3 2 F 4 (d) 3 F10 Figure 6: An example of fragments evolution a three-dimensional space, with axes corresponding to frag- ments, macro-blocks, and keys The re-writing of a fragment is represented by placing it in correspondence to the new key used for its encryption The shadowing in correspondence to the previous versions of the fragments denote the fact that they are not available anymore as they are overwritten by the new versions Each revoke operation requires the use of a fresh new key and, due to policy changes, fragments of a resource might be encrypted with different keys|,Non-data,66
| Such a situation does not cause any complication for key management, which can be conveniently and efficiently handled with a key regression technique [10] Key regression is an RSA-based crypto- graphically strong technique (the generated keys appear as pseudorandom) allowing a data owner to generate, start- ing from a seed s0, an unlimited sequence of symmetric keys k0,   |,Non-data,66
| , ku, so that simple knowledge of a key ki (or the com- pact secret seed si of constant size related to it) permits to efficiently derive all keys kj with j ≤ i Only the data owner (who knows the private key used for generation) can perform forward derivation, that is, from ki, derive keys following it in the sequence (ie, kz with z ≥ i)|,Non-data,66
| Note instead that, not knowing the private key, users cannot perform forward derivation The cost that users must pay for key derivation is small On a single core, the computer we used for the ex- periments is able to process several hundred thousand key derivations per second With key regression, every user authorized to access a resource just needs to know the seed corresponding to the most recent key used for it (s0 if the policy has not changed, s3 in the example of Figure 6(d))|,Non-data,66
| To this end, there is no need for key distribution, rather, such a seed can be stored in the resource descriptor and protected (encrypted) with a key corresponding to the resource’s acl (ie, known or derivable by all authorized users) [2, 6] Enforcing revoca- tion entails then, besides re-encrypting a randomly picked fragment with a fresh new key ki, rewriting its correspond- ing seed si, encrypted with a key associated with the new acl of the resource|,Non-data,66
| Figure 7 illustrates the revocation process To access a resource, a user then first downloads the re- source descriptor, to retrieve the most recent seed sl, and all the fragments With the seed, she computes the keys nec- essary to decrypt fragments that have been overwritten, to retrieve their version encrypted with k0 Then, she combines the mini-blocks in fragments to reconstruct the macro-blocks in the resource|,Non-data,66
| She then applies mixing in decrypt mode to macro-blocks to retrieve the plaintext resource Figure 8 illustrates the process to access a resource Note that the size of macro-blocks influences the perfor- mance of both revoke and access operations Larger macro- blocks naturally provide greater policy update performance as they decrease policy update cost linearly, with limited im- pact on the efficiency of decryption, since its cost increases logarithmically (Section 5)|,Non-data,66
| 4 EFFECTIVENESS OF THE APPROACH In this section, we elaborate on the effectiveness of our approach for enforcing revocation For the discussion, we recall that msize is the size of individual mini-blocks, m is the number of mini-blocks in a block, b is the number of blocks in a macro-block, and M is the number of macro- blocks Also, we denote with f the number of fragments, that is, f = m · b|,Non-data,66
| We consider the threat coming from a user whose access to the resource has been revoked, and who downloads the resource from the server With access policy enforced by encryption, not being authorized for an access should not prevent downloading the resource but rather it should pre- vent reconstruction of its plaintext representation We then evaluate the protection against the user’s attempts to recon- 222/* fragment to be rewritten */ /* version of the fragment stored */ i has been overwritten in a revocation */ /* derive kc using key regression */ /* retrieve the original version of the fragment */ Revoke 1: randomly select a fragment Fi of R 2: download Fc 3: if c > 0 then 4: i from the server /* F0 derive key kc F0 i := D(kc, Fc i ) 5: 6: determine the last key kl−1 used 7: generate new key kl 8: Fl 9: upload Fl 10: encrypt sl with the key of acl(R) 11: update R’s descriptor i overwriting Fc i := E(kl, F0 i ) i /* it is stored in R’s descriptor */ /* overwrite previous version */ /* limits it to authorized users */ /* including the new sl */ Figure 7: Revoke on resource R struct the plaintext resource In doing so, we consider the worst case scenario, with respect to key management, where the user has maintained memory of the last key (or the cor- responding seed) used for the resource up to the point in which she was authorized for the access|,Non-data,66
| In other words, we assume the user to be able to decrypt the fragments that have been overwritten before she has been revoked access, and hence to know the original version encrypted with k0 of the fragments that have not been overwritten since she has been revoked access Since seeds are compact, such a threat is indeed realistic To reconstruct the resource when missing a fragment, the user would have to perform a brute force attack attempting all possible combinations of values of the missing bits, that is, 2msize attempts for each of the M macro-blocks If more fragments, let’s say fmiss, are missing, the user would have to perform 2msize ·fmiss attempts for each of the M macro-blocks|,Non-data,66
| The inability of the user to reconstruct a resource if some fragments have been overwritten is because, without such fragments, the user cannot retrieve the corresponding origi- nal version (the one encrypted with k0) needed to correctly reconstruct the resource plaintext A potential threat can then come if the user maintains a local storage with the origi- nal version of part of the resource We distinguish two cases, depending on whether the user stores complete fragments or portions of them across the whole resource Local storage of fragments|,Non-data,66
| Suppose a user locally stores (when authorized) some fragments of the resource Even if such fragments are later overwritten for revoking access to the user, and then their most recent version stored at the server is unintelligible to her, she has them available for reconstructing the resource However, the fragment to be overwritten in a policy revocation is chosen randomly by the owner Therefore, the user can still reconstruct the resource after one fragment has been overwritten if the frag- ment that the owner has overwritten is the same fragment that the user has also stored locally, which has probabil- ity 1/f to occur|,Non-data,66
| Generalizing the reasoning to the con- sideration of the user locally storing more than one frag- ment and the policy naturally changing even after the spe- cific user revocation, we determine the probability PA of the user’s ability to access the resource assuming local storage of floc fragments to be PA = (floc/f)fmiss  The probability clearly increases with the number of fragments stored lo- cally, but quickly reaches extremely low values after a few updates of the policy, approximating zero even for high per- centage of fragments locally stored The low probability (and the high storage effort requested to the user) essen- tially makes such attack not suitable: if the user has to Access 1: download R’s descriptor and all its fragments 2: retrieve seed sl used for the last encryption 3: compute keys k0,  |,Non-data,66
|  , kl 4: for each downloaded fragment Fx 5: 6: F0 i 7: for j = 0,   |,Non-data,66
| , M − 1 do 8: Mj := concatenation of mini-blocks F0 9: := D(kx, Fx i ) if x > 0 then decrypt Mj i do /* retrieve the original version of fragments */ /* reconstruct and decrypt macro-blocks */ i [j ], i = 0,    , (m · b) − 1 Figure 8: Access to resource R pay a storage cost that approaches the maintenance of the whole resource, then the user would have stored the plain- text resource when authorized in the first place|,Non-data,66
| We note also that a possible extension of our approach could consider overwriting, instead of pre-defined fragments, a randomly chosen set of mini-blocks (ensuring coverage of all macro- blocks), to enforce a revocation In this case, the probabil- ity of the user storing mloc mini-blocks per macro-block (also randomly chosen) to be able to access the resource immedi- ately after her revocation would be (mloc/(m · b))M , which would become (mloc/(m · b))M ·mmiss , (ie, negligible), if she misses mmiss mini-blocks per macro-block|,Non-data,66
| We note how- ever that overwriting randomly picked mini-blocks across the resource would considerably increase the complexity in the management of fragments, and it would make it harder to provide an efficient physical structure for fragments (Sec- tion 5) Given the observations above about the high storage cost that would be required to the user and the low prob- ability of her success as policy changes, we argue that the regular structure for the fragments is preferable Keeping portions of all mini-blocks Instead of locally storing some selected fragments, a user can opt for using storage to maintain portions of all the mini-blocks in each fragment|,Non-data,66
| In this case, whatever the fragment overwritten in the revocation, the user will have to perform some effort to realize a brute-force attack to retrieve the missing bits (she does not have the complete fragment), but such an effort will be lower, given the availability of the locally stored bits For instance, assuming the user to keep 50% (ie, half of the bits) of each mini-block, the effort for reconstructing the resource given a missing fragment would now be 2(msize/2) attempts for each of the M macro-blocks (in contrast to the 2msize required if all the bits in the fragment were unknown)|,Non-data,66
| However, again, if more fragments are missing, the required effort would quickly escalate, being equal to 2(msize/2)·fmiss when fmiss fragments are missing For each attempt, the verification that a guess is correct would require to apply all the decryption rounds until the plaintext is reconstructed, with a great cost We note that the user can cut down on such cost if she locally maintains, in addition to the portions of the original mini-blocks, also some bits of the partial re- sults of the computation (which would allow her to test cor- rectness of a guess without performing all the encryption rounds) Availability of such partial results can help testing the guesses for a mini-block if the other mini-blocks in the same block are available (i|,Non-data,66
|e, when the user misses only one fragment per block) However, from the birthday paradox, we note that the probability of two revocations hitting the same block (but a different fragment) quickly increases with the number of revocations Then, after a few updates the advantage of the user keeping partial results of the compu- 223tation will become ineffective|,Non-data,66
| In addition to this, we note that, in this case as well, the storage and computational ef- forts required to the user do not seem to make this attack much preferable for her with respect to the choice of locally storing the whole plaintext resource itself in the first place A note on collusion Collusion can happen when two users join effort to gain access to a resource that neither of them can access (we do not consider collusions with the server, which is assumed trustworthy to enforce the re- writing requested by the owner) In fact, if one of the users is authorized for the resource, she has no incentive and there- fore there is no collusion|,Non-data,66
| Also, the case of users getting together to grant each other access to resources on which they individually have authorization cannot be considered collusion, since merging their knowledge they collectively do not go beyond their privileges Collusion is then represented by users who join effort in maintaining portions of the re- source (eg, fragments or parts of mini-blocks as discussed above)|,Non-data,66
| For instance, each of the users could keep half of the fragments and they can merge their knowledge to patch for missing fragments Such a situation does not add any complication with respect to the previous discussion, as it simply reduces to consider the group of colluding users as an individual attacker We then note again that the collective effort, in terms of storage and/or computation, required to gain access would easily approximate the effort of maintain- ing the original plaintext resource itself In other words, the attack strategy does not bring advantage to the user|,Non-data,66
| 5 IMPLEMENTATION In this section, we discuss the realization of our approach for its practical deployment The components that have to be considered are the client, who decrypts resources to access them (Section 51), and the protocol used for the in- teraction between client and server|,Non-data,66
| The protocol has a sig- nificant impact on the profile of the server responsible for hosting the resources and for authenticating the data owner who is the only party authorized to modify the data In particular, we will consider two options for the realization of the interaction protocol: i) Overlay (Section 52), which operates on top of a common cloud object service (the server is unaware of the adoption of our approach and is a standard object server); and ii) Ad-hoc (Section 53), which directly supports the primitives to update a fragment and to get the current state of the resource (the server is aware of the fea- tures of our approach and attention will have to be paid to its internal structure)|,Non-data,66
| We found from this analysis that the client is able to make use of our approach without restrictions, with a performance in the application of the technique for a common personal computer that makes it compatible with any network band- width For the protocol, when the technique is applied in a transparent way on top of existing object storage solu- tions (Overlay), we observe several orders of magnitude in performance improvement for some configurations The re- alization of the technique using an ad-hoc protocol further improves the benefits with its greater flexibility, but it also requires to consider the mapping of the logical structure to its physical representation, and we show how to identify an adequate solution All these results prove the applicabil- ity of the technique in the current technological landscape and the benefits that it can provide for many application domains|,Non-data,66
| It is important to observe that the parameters that mainly influence the performance are the size msize of mini-block and the number f of fragments While the size of mini-blocks represents our security parameter and must be chosen by the data owner based on her security requirements, the number of fragments is chosen considering performance only In the following, we will then focus on the tuning of the number of fragments, considering resources of variable sizes (Note that the choice of the number of fragments implies also the definition of the number of macro-blocks, as the product of the number of macro-blocks by the number of fragments is equal to the number of mini-blocks of the resource|,Non-data,66
|) The evaluation of the best value for the number of frag- ments will have to consider a number of aspects that char- acterize the application domain The major ones are: fre- quency of policy updates; frequency and average size of get requests; network bandwidth, for the upload and download direction All these aspects have a direct impact on the over- all throughput offered by our solution, which confirms its advantage in the prompt enforcement of revoke operations, measured by the average transfer rate for get requests The experimental results illustrated in this section have been obtained using, for the client, a machine with Linux Ubuntu 16|,Non-data,66
|04 LTS, Intel i7-4770K, 350 GHz, 4 cores For the server, we used an Amazon EC2 m4large instance, with 4 CPUs and 8 GB of RAM|,Non-data,66
 The client was connected to the Internet by a symmetric 100 Mbps connection 51 Client Our approach requires the client to execute a more com- plex decryption compared to the use of AES with a tradi- tional encryption mode (eg,Non-data,66
|, CTR or CBC) The cost of decryption (which is comparable to the cost of encryption by the data owner) is nearly logm (m · b) times the cost of applying a single AES decryption, while the impact of reor- ganizing the data structure at each round is limited Thanks to the high performance provided by modern processors in the execution of block ciphers, this logarithmic cost factor is not critical Also, decryption can be parallelized on multi- core CPUs, making the client processing even more efficient|,Non-data,66
| An aspect that has to be considered in the implementation of the client is the possible need to keep large amounts of data in memory This may occur when fragments are down- loaded one after the other and decryption can start only after the last fragment has been downloaded, which, for ex- ample, happens with the Overlay solution If the resource size exceeds the available memory at the client, this leads to an extremely significant performance hit The configura- tion of the system can (and should) avoid this possibility by splitting the resource into sub-resources (Section 5|,Non-data,66
|2) 511 Experiments on the client All code has been written in Python, because for all the functions the computational performance is not a constraint|,Non-data,66
| The only component written in C was the invocation of the mixing for encryption and decryption functions Since most current Intel x86 CPUs offer the support for a hardware implementation of AES, named AES-NI, we considered its adoption in our experiments Figure 9 shows that the cost of decryption is compatible with all reasonable scenarios for the application of our technique In particular, the figure 224) s / B M (  t u p h g u o r h t  10000  1000  100  10  1 1 AES-NI, msize=32, Msize=4096 AES-NI, msize=64, Msize=4096 AES, msize=32, Msize=4096 AES, msize=64, Msize=4096 2 4 number of threads 8 Figure 9: Throughput varying the number of threads illustrates the throughput obtained, varying the number of threads, by the application of our approach in different con- figurations characterized by macro-blocks of size (Msize) 4 KiB, mini-blocks of size (msize) 32 and 64 bits (which im- ply 5 and 9 encryption rounds, resp|,Non-data,66
|), when using AES- NI and when not using it (AES) Mixing was applied on data that were already available in memory We notice that even the single-threaded 9-round non-hardware-supported implementation (line ‘AES, msize=64, Msize=4096’) offers a throughput that is greater than 100 Mbps For the AES- NI multi-threaded 5-round implementation we reach a 2|,Non-data,66
|5 GB/s throughput (line ‘AES-NI, msize=32, Msize=4096’) The figure also shows that, increasing the number of threads, we reach a performance level that is 4 times the one obtained by the single-threaded implementation This is consistent with the presence of 4 physical cores in the CPU we used, each with a dedicated AES-NI circuitry The performance, even for a large number of fragments, shows to be orders of magnitude better than the band- width of current network connections|,Non-data,66
| Even without the hardware support (lines ‘AES, msize=32, Msize=4096’ and ‘AES, msize= 64, Msize=4096’), the application of the cryp- tographic transformation shows greater throughput than the data transfer rate of most Internet connections An exper- iment on 1 GiB size macro-blocks and 32 bit mini-blocks showed the expected slow down in throughput, managing the decryption in less than 5 seconds (still above the band- width of long-distance connections) 52 Overlay solution The Overlay solution is analyzed using as a reference the Swift service|,Non-data,66
| Swift has been selected due to its popularity, availability as open source, and technical features that are good representatives of what is offered by a modern object storage service for the cloud (resources are called objects in this discussion, to align with the Swift terminology) The Swift server instance has been installed on the Amazon EC2 platform We consider two main alternatives for the realiza- tion of our approach on Swift1 without any changes to the 1Swift organizes objects within containers The current structure of Swift supports access control only at the level of containers|,Non-data,66
 The analysis we present can be immediately adapted to the management of the access policy at the con- tainer granularity rather than the object granularity We server2 The first option assumes to manage each fragment as a separate object The second option makes use of the ability to access portions of objects and specifically considers the use of Dynamic Large Objects (DLOs),Non-data,66
| Our experiments show that this latter option provides significant benefits in performance with respect to managing fragments as separate objects DLOs deserve then to be used when available Fragments as atomic separate objects This approach is the most adaptable one, as it can be used with any ob- ject storage service|,Non-data,66
| Also, the support for a policy update will be immediate, as it will be mapped to a single update to the object containing the corresponding fragment How- ever, these advantages come together with some potential restrictions The client would be responsible for managing mixing and slicing The approach requires the introduction of some metadata associated with each of the fragments or stored in a dedicated supporting object|,Non-data,66
