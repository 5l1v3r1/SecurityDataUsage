 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| The Activity takes a URL as an input parameter and loads the content pointed by the URL into a WebView instance What can happen here is that a malicious app running on the same device can drop a Javascript file onto its SD card (Secure Digital memory card) and exploit the next-intent feature the URL pointing to that Javascript file Since the SD card is viewed as a local storage by Android, the script is allowed to access contents from all Internet domains [32] Specifically in our attack, the script to facebook|,Non-data,106
|com and read the contents of the responses Given that all such requests carry the user’s Facebook cookie, this cross- origin scripting ends up allowing the adversary to perform arbitrary operations on the user’s account, and obtain all private data  For the Dropbox app, we exploited a private Activity VideoPlayerActivity, which has an input parameter “EXTRA_ METADATA_URL” that specifies a URL from which to fetch the metadata for a video file In a normal situation, this URL points to a file kept by dropbox|,Non-data,106
|com However, our next-intent exploit enables a malicious app to set the URL to arbitrary web domain, such as “http://attackercom” When the Dropbox app makes a request with that URL, it always assumes the recipient to be dropbox|,Non-data,106
|com and attaches to the request an authentication header, as opposed to applying the conventional origin-based cookie policy Since right now, EXTRA_METADATA_URL points to “http://attackercom”, the adversary gets the header and can use it to gain a full access to the user’s Dropbox account  Vendor responses|,Non-data,106
| Fixing this problem turns out to be much more complicated than it appears to be Specifically, the Dropbox security team told us they were “working on changing the architecture in our Android app to make that API secure”, but the next-intent feature is “unfortunately also very useful for us” Facebook also said that this problem “will take some time to fix” As an acknowledgement to the importance of our work, Facebook awarded us $5000 bounty for finding this vulnerability, which we donated to charity|,Non-data,106
| Dropbox also awarded us 100GB free storage for each author, and included our names on their special thanks page  The details of those software vendors’ responses can be found here [31] From our communications with the vendors, it can be seen that addressing this next-intent problem from the developer side alone can be hard In Section 4, we show how a well-thought-out OS-level support can make this type of flaws more convenient to fix|,Non-data,106
|  63833 Abusing the Scheme Channel As discussed in Section 2, scheme is an important cross-origin channel supported by both Android and iOS Through this channel, an app on those OSes can be invoked by a URL (with the scheme the app claims) from another app or from a webpage in a WebView instance or a browser (see  in Section 2)  In our research, we found that this channel can be easily abused for unauthorized origin crossing, enabling a malicious app to acquire a user’s authentication token with Facebook or perform a login CSRF on iOS, as described below|,Non-data,106
|  331 Fbconnect (Android) Facebook provides a Dialog mechanism [35] through its apps and SDKs for both Android and iOS Using the mechanism, an app can send through the Facebook official app a Dialog request to query the Facebook server for sensitive user data (e|,Non-data,106
|g, access token) or operate on the user’s account (eg, sharing a post)|,Non-data,106
| Among all the arguments carried by the Dialog request are client_id, the ID assigned to the sender app by Facebook, and redirect_uri, which is set to “fbconnect://success”  In the case that the user’s access token is requested, the Facebook server displays a dialog within Facebook app’s WebView instance to ask for the user’s consent, and upon receiving it, the server redirects the WebView instance to “fbconnect://success#|,Non-data,106
|”, where the secret token is attached to the “” part of the message|,Non-data,106
| This token is then extracted by the Facebook app, which later dispatches it to the target app (ie, the sender of the Dialog request) associated with the client_id  The URL “fbconnect://success#|,Non-data,106
|” is just used for delivering data from the Facebook server to its official app However, if this URL is loaded in the mobile browser, a serious attack can happen|,Non-data,106
| More specifically, a malicious app on the device first registers this fbconnect:// scheme, and then invokes the browser to load a Dialog URL, in an attempt to request the sensitive data of another app (eg, the TexasHoldem app) from the Facebook server This can be easily done by setting client_id in the URL to that of TexasHoldem because an app’s client_id is public|,Non-data,106
| Also, within the browser, the dialog may not even show up to alert the user, if it is already in the logged-in status As a result, Facebook will redirect the browser to “fbconnect://success#|,Non-data,106
|”  Unlike the Facebook app, the browser treats this URL as a scheme invocation, and therefore will trigger the scheme’s handler (ie, the malicious app) with the URL as an argument|,Non-data,106
| This exposes to the malicious app the victim’s Facebook secret token for the TexasHoldem app We tested the attack on an Android device (Galaxy Tab 2) and confirmed that the malicious app can get the user’s access token, authorization code and other secrets In this case, we can see that although the Facebook server is the sender of the scheme message, it cannot control which app to receive the message through the mobile browser This is different from what happens within a web browser: for example, if a script from a|,Non-data,106
|com sends a message to bcom through the postMessage API, it can specify the recipient domain and the browser then guarantees that only bcom gets the message On today’s mobile OS, however, there is no way that the Facebook server can specify the authorized receiver of its scheme URL, not to mention any mechanism to enforce this security policy|,Non-data,106
|  Also note that the fbconnect problem here is present on both Android and iOS However, given that iOS malware is rare, the risk it poses is mainly to Android (see our adversary model)  Vendor response Without the OS support, this problem turns out to be even harder to fix than the next-intent issue|,Non-data,106
| We reported it  to Facebook on Sept 11, 2012 On Jan 22, 2013, Facebook security team told us that they took steps to “ensure that popular app stores block apps that attempt to register this URI schema”|,Non-data,106
| Moreover, they were “crafting a formal deprecation plan for the fbconnect schema”, but this plan needs a “several month deprecation period” because “all of our embedded SDKs currently depend upon this functionality” On March 20, 2013, Facebook informed us that they “crafted a plan for the deprecation of the fbconnect schema in the next major release” They expect to “see this disappear entirely as users continue to upgrade” They awarded us a bounty of $1500 for this finding, which we donated to charity|,Non-data,106
|  332 Invoking Apps from the Web (Android and iOS) In this section, we elaborate a new security threat that comes from a malicious website the user visits with a mobile device The root cause of the problem has been confirmed to exist on both Android and iOS|,Non-data,106
| For the simplicity of presentation, here we just use iOS as an example to explain the problem  Mobile apps typically use their WebView instances to render web content Such content could come from less trustworthy web sources, such as public posts on Facebook and restaurant reviews from the strangers on Yelp In our research, we found that during such rendering of web content, whenever the WebView instance of an app is directed by the content to a URL with a scheme registered by another app on the same device, the latter will be automatically invoked, without being noticed by the user, and act on the parameters given by the URL|,Non-data,106
| This is dangerous because the app receiving the scheme message which carries the URL cannot distinguish whether this message comes from the sender app itself or from the web content within the app’s WebView instance, which causes the confusion about the message’s true origin Here we use two examples to show the consequences of this confusion Login CSRF attacks on Dropbox iOS SDK We studied the latest version (v|,Non-data,106
|133) of Dropbox iOS SDK, which enables a 3rd-party app on iOS to link to the device owner’s Dropbox account, using Dropbox as the app’s storage Here, we use PlainText [41], a popular text-editing app, as an example to explain what can go wrong, though apps using Dropbox iOS SDK are all vulnerable|,Non-data,106
| Specifically, after the mobile user authorizes this account linking, the Dropbox app delivers to the PlainText app a scheme URL, which is in the following format: db- <APP_ID>://1/connect?oauth_token&oauth_token_secret&uid The URL includes 3 arguments, oauth_token, oauth_token_secret, and uid, which the PlainText app uses to communicate with the Dropbox server to complete the account linking However, we found that the linking process can be exploited to launch a serious login CSRF attack, without any malicious app running on the user’s device Specifically, in our attack, the adversary uses the 3 URL arguments collected from his own device to build a URL: db-<APP_ID>://1/connect?oauth_token’&oauth_token_ secret’ & uid’, where oauth_token’, oauth_token _secret’, and uid’ are the adversary’s Dropbox credentials, and APP_ID identifies the PlainText app|,Non-data,106
 The attacker shares a malicious web URL (eg pointing to attackercom) on his Google Plus status updates or comments,Non-data,106
| Once the victim user clicks it within the Google Plus app on her device, attackercom is loaded in the app’s WebView instance, and redirects the WebView to the scheme URL As a result, the PlainText app is invoked with the URL as input The app treats the URL as part of the scheme message from the Google Plus app, without knowing that it actually comes from the  639web content of attacker|,Non-data,106
|com rendered in the Google Plus app’s WebView It is then unknowingly linked to the attacker's Dropbox account When this happens, the app automatically sends the user's text input to the attacker's account A demo of this attack is posted online [31]|,Non-data,106
| We also checked a few other popular iPad apps using Dropbox SDK, including TopNotes, Nocs, and Contacts Backup to Dropbox They are all found vulnerable Bypassing Facebook’s app authentication mechanism Many apps using Facebook iOS SDK, such as Yelp and TripAdvisor, may also render untrusted web contents within their WebView instances|,Non-data,106
| Below we show that an attacker who posts a malicious link on Yelp can bypass an important mechanism Facebook uses to authenticate 3rd-party iOS apps Specifically, when app A invokes the Facebook app through schemes such as “fbauth://”, the Facebook app sends the app ID specified by app A and its bundle ID retrieved from the OS to the Facebook server for authentication This prevents app A from impersonating another app to communicate with the Facebook server because it cannot manipulate the bundle ID However, this protection does not work when a malicious page is loaded to the WebView instance of the Yelp app because the Facebook app cannot distinguish whether an incoming scheme message is from the Yelp app or a webpage in its WebView (the bundle ID from the OS always points to the Yelp app)|,Non-data,106
| Therefore, whoever posts a comment on Yelp acquires the same privilege as Yelp has on the victim’s Facebook account Vendor response We reported these problems to Dropbox, Google, and Facebook For the first problem (login CSRF through Dropbox SDK), Dropbox started its investigation immediately after receiving our report|,Non-data,106
| They have implemented a fix that needs to change both the SDKs and the Dropbox official apps on all platforms (including Android and iOS) Facebook mitigated the threat by deploying a whitelist inside the WebView instance of its official app, which only allows http, https, and ftp schemes Google has not taken any actions so far [31] Facebook awarded us $1000 for this finding|,Non-data,106
| We also reported to Facebook the second case (bypassing its app authentication mechanism on iOS), which is still under investigation 34 Attacks on Web-Accessing Utility Classes As shown in , besides intent and scheme, origins can also be crossed on a mobile OS when an app directly calls the methods of the WebView/HttpClient classes or registers their callback events Here we show how this channel can be abused|,Non-data,106
|  341 Exploiting Callbacks (iOS) On iOS, we studied a WebView callback method the Facebook app registers, shouldStartLoadWithRequest, which is triggered each time the app’s WebView instance is navigated to a link If this link is in the form “fbrpc://appID=xyz&foo=123”,  the callback method (provided by Facebook) creates a new URL “fbxyz://foo=123” to invoke an app with the appID “xyz” and set its input argument to “123”|,Non-data,106
| Note that this operation is different from the scheme-based invocation (from a web domain) described in Section 332, as in that case, a website directly runs a URL to invoke the target app on the mobile device (the sender of the scheme message is the website), while here such a URL is actually created by the callback method, which is implemented by the Facebook app (the sender is the Facebook app) This mechanism can be exploited when a malicious link such as attacker|,Non-data,106
|com is clicked by the user through her Facebook app When this happens, the malicious content loaded to the WebView  instance redirects to the fbrpc URL Then the callback of the Facebook app generates a new scheme URL to launch any app the adversary wants to run on the victim’s device with any argument value he sets For example, we found that in this way, a popular app Pinterest can be activated by the adversary to sign onto the adversary’s account on the victim’s device, so as to dump the user’s data with Pinterest into the adversary’s account|,Non-data,106
|  342 Exploiting Header-attachment (Android) We also studied the HttpClient class, which is used by Android apps for direct HTTP communications with web servers HttpClient allows a developer to specify the URL of a request and an HTTP header|,Non-data,106
| The header is attached to the request In the absence of origin-based protection, any header, including the one used for authentication, can be attached to a request sent to any website A prominent example is the attack case described in Section 32|,Non-data,106
|1: the adversary invokes the Dropbox app’s Activity VideoPlayerActivity, which utilizes an HttpClient instance to load metadata from a URL with the user’s authentication header attached Since the URL is manipulated by the adversary to point to attackercom, without origin checks, the authentication header goes to the adversary  Note that this header-attachment issue by itself is a security flaw, as admitted by the Dropbox security team (“Attaching the Authorization header to non-Dropbox URLs was definitely a serious security bug” [31])|,Non-data,106
| Actually the attack on a phone user’s Dropbox account as described in Section 321 is built upon two security flaws, ie|,Non-data,106
|, the next-intent and header-attachment issue 4 ORIGIN-BASED DEFENSE As described in the prior section, unlike web browsers, today’s mobile OSes (ie|,Non-data,106
|, Android and iOS) do not offer origin protection to the channels used by apps to communicate with each other or the web As a result, cross-origin interactions on those systems can be easily abused to undermine the user’s security and privacy, which even happens to highly popular apps built by security- savvy developers Moreover, even after the problems were reported, the developers still had hard time in fixing them This makes us believe that a generic solution to the problem should be built into mobile OSes, which have the observations of messages’ origins, and the means to mediate the communication over those channels|,Non-data,106
|  In this section, we elaborate the first design for such protection, called Morbs (mobile origin based security), and its implementation on Android We released the source code of the Android implementation on GitHub [40] 41 Design Overview|,Non-data,106
| Morbs is generic to iOS and Android It is designed to achieve browser-like origin protection: 1) it exposes to the developers the true origins of the messages their apps/websites receive, enabling them to build protections based on such information; 2) it allows the developers to specify their intentions, in the form of whitelists of origins their apps/websites can get messages from and send messages to, and enforces policies transparently within the OS  More specifically, an app or a web service that asks for origin protection first communicates its intended sender/recipient origins (the whitelists) to the OS These policies are enforced by a reference monitor that mediates different mobile channels|,Non-data,106
|  The reference monitor is triggered by the messages delivered through these channels Once invoked, it identifies the origins of the messages, which are either apps or web domains, and checks their  640for  for example, “app://comfacebookkatana”  policy compliance against the whitelists|,Non-data,106
| Those running against the policies are blocked by Morbs  A unique feature of Morbs is its capability to connect web activities (within WebView instances or the mobile browser) to the events that happen within the OS For example, it exposes the true origin of a message to a recipient app when confusion arises on whether the message comes from another app or the web domain visited by that app’s WebView instance It also helps a web server specify to a mobile device a designate app on the device that can receive the server’s scheme message|,Non-data,106
| This capability is crucial for defeating unauthorized origin crossing on mobile devices Following we elaborate our design Defining mobile origin For web content, an origin is defined as a combination of scheme, host name, and port number [4]|,Non-data,106
| However, this definition is insufficient for the origin protection on mobile platforms: here we need to consider not only web origins but also app identities and other local origins  To maintain the consistency with the web origins, we adopted a URL-like representation for those new origins, such as “app://<appID>”,  where <appID> is an app’s package name (Android) or bundle ID (iOS), the Facebook app on Android and “app://comgetdropboxDropbox” for the Dropbox app on iOS|,Non-data,106
| Likewise, messages from trusted sources like the OS are given a local origin “local://” For web domains, we adhere to the traditional origin definition [4] Exposing origins When a message is created by an app/website, Morbs sets the origin attribute (added by our approach) of the message to its creator (i|,Non-data,106
|e, an app, a web domain, or local) This attribute always goes with the message within the OS, until it gets to its recipient app/website, where we remove the attribute To help developers build their own protection, our design exposes the origin of a message through existing and new APIs|,Non-data,106
| For example, on iOS, we can enhance the API for retrieving the bundle ID of the sender of a scheme message by returning the true origin of the message, which could be the domain of the web content within that app’s WebView instance In this way, Facebook will be able to find out that the scheme message it gets from the Yelp app actually comes from a webpage Yelp displays, not the app itself Therefore, the exploit described in Section 33|,Non-data,106
|2 will be defeated Default policy It is well known that the browser by default enforces the SOP to the web content it hosts, but the same policy cannot be applied to all the apps on mobile platforms as it may disrupt their legitimate cross-origin communications Our strategy is to implement the SOP only on the totally unexpected and insecure channel|,Non-data,106
| An example is the next-intent communication described in Section 321, which is unexpected, since the private Activity of an app should only be invoked by the app’s own intent when calling the startActivity API Therefore, in this scenario, the SOP is always enforced|,Non-data,106
|  Setting policies Morbs allows a policy to be specified on a channel between an app and a web domain (web policy), as well as between two apps (app policy) An app policy defines legitimate inter-app communication, which goes through intent or scheme A web policy is about app-web interactions, through scheme or web-accessing utility classes|,Non-data,106
| An app or a website sets a policy on a specific channel to notify Morbs the list of senders authorized to send messages to it, and the list of recipients allowed to receive the messages it sends  Setting a policy can be done through a new API setOriginPolicy, which an app can directly call Here is its specification:  void setOriginPolicy(type, senderOrRecipient, channelID, origins)   Here, type identifies the type of the channel (intent, scheme, or utility class), senderOrRecipient specifies sender or recipient, channelID indicates the channel ID, and origins is the whitelist Once invoked, setOriginPolicy first identifies a channel by type, and channelID, which is an OS-wide unique string|,Non-data,106
| For example, the ID for the intent channel that triggers LoginActivity within the Facebook app is “comfacebookkatanaLoginActivity”, in which “com|,Non-data,106
|facebookkatana” is the Facebook app’s package name For a scheme, its channel ID is the corresponding scheme field on a URL For web-accessing utility classes, they are identified by their class instances within an app|,Non-data,106
| After a channel is identified, the API then extracts the whitelist that regulates the sender or the recipient (specified in senderOrRecipient) through this channel from the origins parameter Although setOriginPolicy offers a generic interface for policy specification, it cannot be directly invoked by a website to set its policies To address this problem, Morbs provides mechanisms for indirectly accessing this API, including a JavaScript API setMobileAllowedOrigins, through which the dynamic content from a website can set policies within the mobile browser or a WebView instance, and a header mobile-allowed-origins in HTTP responses that inform the browser or a WebView instance of the parties on the device allowed to get the message The app developer can also leverage other indirect mechanisms to define her policies whenever she is building the app’s functionality over a mobile channel|,Non-data,106
| Specifically, Morbs allows the developer to set her policies regarding a scheme/intent her app claims within the app’s manifest file (for Android) or plist (for iOS), under a new property allowedOrigins In this way, she can turn on our origin protection for her app without changing its code Other ways for policy setting include a new argument allowedOrigins for the API that delivers scheme/intent messages, and a new API setAllowedOrigins used to define policies for utility classes such as WebView and HttpClient|,Non-data,106
| An advantage of using these indirect ways is that they only require one argument (ie, origins) from the developer because other arguments are set by default Enforcing policies|,Non-data,106
|  Morbs runs a reference monitor to enforce security policies on different channels Whenever a message is delivered over a channel, the reference monitor is triggered to identify its origin and calls a function checkOriginPolicy to check its policy compliance The function’s specification is as follows:  channel  (type  and  bool checkOriginPolicy(type, senderOrRecipient, channelID, from, to)  channelID) Note   Intuitively, the function searches Morbs policy base to find out whether the current sender (specified in the from argument) is allowed to deliver the message to the recipient (to) through the specific that checkOriginPolicy needs to be called twice (one for checking the sender origin against the recipient’s policy and the other for checking the recipient origin against the sender’s policy)|,Non-data,106
| The message is allowed to go through only if both checks succeed  Both setOriginPolicy and checkOriginPolicy operate on the Morbs policy base that keeps all policies setOriginPolicy inserts a policy into the database and checkOriginPolicy searches the database for an applicable policy, checking whether a sender/recipient origin is on the whitelist included in the policy The performance of this compliance check is critical because it needs to be invoked for every message going through these  641channels|,Non-data,106
| To make it efficient, Morbs leverages the hash-table search to quickly locate a target within the database 42 Implementation We implemented our design on Android (Figure 2) At the center of our the ReferenceMonitor class, in which the most important function is checkOriginPolicy|,Non-data,106
| They were built into the Thread class of the Dalvik Virtual Machine The setOriginPolicy API is open to all apps, while ReferenceMonitor is kept for the OS, which is only accessible to the code running inside the Android OS kernel  setOriginPolicy API and  system are  the  intents/schemes AppApp Apps calls/schemes class Activity { startActivityForResult() } Dalvik VM C h e c k p o   l i c y class Thread { class WebViewCore { handleMessage() } S e t  p o l i c y S e t  p o l i c y C h e c k p o   l i c y setOriginPolicy() API class ReferenceMonitor { checkOriginPolicy () } } Mobile Device callbacks class CallbackProxy { handleMessage() } Check policy Web   Figure 2 The framework of Morbs on Android  In the presence of the centralized policy compliance check (checkOriginPolicy), the task of ReferenceMonitor (ie|,Non-data,106
|, policy enforcement) becomes trivial: all we need to do here is pulling invoking checkOriginPolicy and raising an the arguments, exception to drop a message when the check fails In our implementation, the ReferenceMonitor class is used in the OS components related to these channels to conduct mediation  Specifically, for intent and scheme, the enforcement code was placed within the API startActivityForResult, which needs to be called by startActivity, when a message delivered through those channels attempts to start an Activity Note that we chose not to do the security checks within the IPC mechanism: Android does not recommend inspecting intent data in IPC because the intent instances are serialized for high performance data transport [29]|,Non-data,106
| For mediating web-app communications, we changed the handleMessage method within both the WebViewCore class and the CallbackProxy class The two methods are the focal point of mobile browsers and WebView instances: all method invocations and callback handling from apps need to go through them In addition, the execute method of HttpClient class was used to mediate apps’ direct communication with web servers Challenge I: origin identification|,Non-data,106
|  Morbs attaches an origin attribute to every message exchanged through the mobile channels On Android, both intent and scheme channels utilize the intent messages (Section 2) The constructor for generating an intent instance is hooked in our implementation to label an intent message with its app origin Specifically, we added an origin property to the intent class|,Non-data,106
| When the constructor is creating a new intent instance, it retrieves the package name of the app initiating the intent and fills in the origin property with the package name For example, when the initiator is the Facebook app, the origin property should be marked as “app://com facebookkatana”, in which “com|,Non-data,106
|facebookkatana” is the package  there  to understand  name of Facebook app However, this origin is not easy to identify in practice, since there is no API to help us find out the initiator directly A simple solution is to get the whole call stack from the OS through getStackTrace API, and then inspect it to find out the caller|,Non-data,106
| This approach turns out to be very expensive: in our test, extracting the call stack takes 135 ms in average Our solution is to add an origin property to each thread that hosts an app When the thread is created, the app’s origin is attached to the property|,Non-data,106
| Once an intent is initiated, the constructor then copies the origin information from the thread to the intent instance  Challenge II: response inspection To enable a web server to set its policies to a mobile device, Morbs needs to inspect the HTTP response to find the header mobile-allowed-origins The response is processed by Android’s native C++ libraries|,Non-data,106
| Morbs (written in Java) cannot directly access it In our implementation, we managed to get access to the header using Java Native Interface (JNI) [30] JNI provides an API called onReceivedData through which C++ code can send messages to Java code To inform Morbs of the content of the header, we modified the C++ code to the header mobile-allowed-origins within HTTP identify responses, and then call onReceivedData to deliver all policies described to WebViewCore, where Morbs uses setOriginPolicy to complete this policy setting process|,Non-data,106
| 5 EVALUATION We evaluated the general design of Morbs and its implementation on Android its effectiveness, performance, compatibility and utility to the app developers 51 Effectiveness We ran our implementation against the aforementioned cross- origin attacks (Section 3)|,Non-data,106
| Specifically, our experiment was conducted on Android 43 with Morbs running within an emulator We installed both the vulnerable apps discovered in our research and the attacker apps In the experiments, we first ran the attacker apps, and then checked whether the exploits were blocked by Morbs or not|,Non-data,106
| Note that in some situations, we also need the developers to explicitly specify their whitelists of origins within their apps, in addition to the default policies In the absence of those apps’ source code, we had to directly enter those app-specific policies (whitelists) into the OS Preventing the exploits on intent As described in Section 3|,Non-data,106
|21, a malicious app can use the next-intent trick to invoke any private Activities of the victim app (the Dropbox app and the Facebook app) The content saved under the NEXT-INTENT key is essentially an intent, which needs to be first created by the malicious app before it is embedded into another intent (the one delivered to Dropbox app’s login Activity) Under Morbs, the intent constructor sets the origins of both intents to the malicious app, which cannot be changed by the app|,Non-data,106
| As a result, when startActivity is called to start the target private Activity, our reference monitor immediately finds that the origin of the next- intent is not the victim app itself, and stops this invocation according to the default policy (the SOP) Our tests confirmed that the vulnerabilities in both Dropbox app and Facebook app are fixed in this manner, without changing the apps’ code Defeating the attacks on scheme For the fbconnect problem described in Section 3|,Non-data,106
|31, what Facebook wants to do is to return the data (eg, secret tokens) from its server to the app associated with the client_id parameter within the Dialog request, not anyone that claims is  scheme|,Non-data,106
| This  fbconnect://  intention  the  642into  communicated by the Facebook server to the mobile OS through a list of legitimate recipient origins specified using its HTTP response header or the JavaScript API provided by Morbs Specifically in our experiment, we inserted the header “mobile- allowed-origins: app://comfacebookkatana” the HTTP response from the Facebook server, indicating that only the Facebook app can receive the data, and observed that the scheme invocation was stopped when the app that registered the fbconnect:// scheme was not the Facebook app|,Non-data,106
| A video demo about this case can be found at [31] When it comes to the apps using Dropbox iOS SDK (the first vulnerability described in Section 332), it is clear that their schemes associated with Dropbox are only supposed to be invoked by the Dropbox app|,Non-data,106
|  Using Morbs, the Dropbox SDK embedded in the apps specifies “app://comgetdropboxDropbox” (ie|,Non-data,106
|, the Dropbox app) as the only legitimate sender origin for these schemes As a result, our reference monitor ensures that any invocation of the schemes comes only from the Dropbox app, which defeats the attacks from a malicious webpage (through Facebook app or the Google Plus app) In the case of the attack using the Yelp app (second vulnerability described in Section 33|,Non-data,106
|2), the problem comes from that the recipient of the scheme message, the Facebook app, cannot tell whether the origin of the message is indeed Yelp or a malicious website visited by the Yelp app’s WebView instance In the presence of Morbs, the true origin of the message is revealed as the website’s domain, which enables Facebook to thwart the attack Note that we did not actually run those fixes as the problems were found on iOS Mediating issues in web-accessing utility classes|,Non-data,106
| For the case of the WebView callback within the Facebook app (Section 341), this callback should only respond to the event (ie|,Non-data,106
|, processing the fbrpc URL) when this URL comes from the domains under Facebook’s control Let’s assume Facebook app specifies “https://*facebookcom” as the whitelist associated with the callback class UIWebViewDelegate, an operation that can be easily done using Morbs|,Non-data,106
| As a result, the event initiated from “attackercom” is ignored by the WebView, without triggering the callback from facebookcom continue to be handled We further evaluated our implementation against the exploit on the HttpClient class (Section 3|,Non-data,106
|42) This time, we set “https://*dropbox|,Non-data,106
|com” as the legitimate origin on the whitelist for the instance of the HttpClient class used in the Dropbox app After that, we found that even after the adversary crossed the origins through the next-intent channel, he still cannot steal the Dropbox authentication header by sending requests to a non-dropboxcom URL, because it was blocked by our reference monitor according to the whitelist 5|,Non-data,106
|2 Performance We evaluated the performance of our implementation on a Nexus 4 development phone We compared the overhead of Morbs with the overall delay the user experiences in the absence of Morbs, to understand the performance impact that our approach can have on cross-origin communications In the experiments, we call a Java API nanoTime to collect timing measurements at a precision of 1 nanosecond (ie|,Non-data,106
|, 10-9 s) To measure the performance of a Morbs operation, we repeated it 10 times to get its average execution time The operations we studied include setting policies and checking policy compliance Among them, the compliance check is the focus of our evaluations, as the policy setting is just a one- time task|,Non-data,106
| More specifically, we measured the delays for sending messages through intent, scheme, and utility classes in the absence of Morbs, and then compared them with the time spent on  shouldStartLoadWithRequest, while  those  a policy compliance check In all the cases, the impact of Morbs was found to be negligible (below 1%) Performance of Morbs operations On the Android OS with our Morbs implementation, we ran a test app to invoke the setOriginPolicy API, and measured the time for setting a policy|,Non-data,106
| On average, this operation took 0354 ms, which involves storing the content of the policy to a policy database maintained by the OS To check the compliance with the policies, Morbs needs to search the database to find out whether the origin of the current sender or recipient is whitelisted As described in Section 4|,Non-data,106
|1, we leverage the hash-table search to quickly locate the policies To understand the performance of this operation, we utilized a test app to invoke another test app through an intent message, which triggered the checkOriginPolicy function We found that the whole compliance check process took 0219 ms on average|,Non-data,106
| Note that policy enforcement over other channels all utilizes the same ReferenceMonitor class, which is expected to bring in similar average delay Impacts on mobile communications As described above, the performance impact of setting policies should be minimum, since it just incurs a one-time cost Also for the policies declared within a manifest file, they are set when the app is installed, which does not affect its operations|,Non-data,106
| Therefore, our focus was policy compliance check  In the study, we measured the overall delays for sending a message through intent, scheme, and web-accessing utility classes without the policy compliance check Table 1 shows the average delays for such communication, and their comparison with the overhead for a compliance check (0219 ms)|,Non-data,106
| This gives a pretty good picture about the impact the check can have on such channels Specifically, for the intent channel, we measured the time interval between the invocation of startActivity and the execution of performCreate (the first API the target Activity needs to call) After repeating the operation for 10 times, we observed an average delay of 42142 ms when the sender and recipient were the same app, and 46|,Non-data,106
|267 ms when they were not (see Table 1) On the other hand, the compliance check took only an average 0219 ms Therefore, the impact of this mediation on the intent communication was around 0|,Non-data,106
|5%  For the scheme message delivered between two apps, it goes through the same intent mechanism The mediation impact of Morbs on this communication was found to be 03% on average|,Non-data,106
| We further measured the time a webpage takes to invoke an app through scheme, between the event when the method handleMessage in WebViewCore class is triggered to process the scheme URL, and when the performCreate API for the target test app is called We found that this whole process took 115301 ms and the impact of the policy checking there was 02%|,Non-data,106
| When we take into account the delays incurred by web-related operations, particularly those performed by the methods and callbacks of WebView and HttpClient class, the extra time spent on the policy compliance check can be comfortably ignored  Specifically, we measured the waiting time for loading a URL (specifically, googlecom) through HttpClient, and WebView  For HttpClient, we measured the time interval between the creation of a class instance and the point when the instance receives the HTTP response, which took 225|,Non-data,106
|035 ms on average For WebView, we measured the interval between the start of page loading completion (onPageFinished took 692955 ms By  called) is called), which  (onPageStarted  and  is  its  643comparison, the time Morbs spends on the compliance check (0|,Non-data,106
219 ms) become unnoticeable  Table 1 Impact of policy compliance check  Table 2 Comparison of current fixes and the fixes with Morbs  Problems  Fix w/o Morbs  Fix w Morbs  Channel  Type of Communication  intent  scheme  utility classes  in-app cross-app app-app web-app HttpClient WebView  Communication Delay w/o Morbs (ms) 42142 46,Non-data,106
267 64077 115301 225035 692,Non-data,106
955  Impact of Morbs policy checking  052% 047% 034% 0,Non-data,106
19% 010% 003%  53 Compatibility and Developer’s Effort An important goal of Morbs is to maintain compatibility when possible and minimize the developer’s effort to use its protection,Non-data,106
| Following we elaborate our study on these two issues Compatibility To see whether our implementation can work with existing apps, we loaded Android with Morbs into a Nexus 4 development phone and evaluated the operations of top 20 free apps downloaded from Google Play market Those apps were first analyzed: we disassembled their binary code and found that all of them use intent, 12 claim various schemes and all need to use the web through WebView and HttpClient classes|,Non-data,106
| We then analyzed their functionalities in the presence or absence of Morbs mediation, by clicking on all buttons and using all of the services we could find During the test, we did not observed any deviation of those apps’ behaviors with and without our mechanism Developer’s effort  As discussed before, to use Morbs, the developer only need to specify her whitelists through the interfaces (e|,Non-data,106
|g, the setOriginPolicy API) we provide, which is straightforward for them to act on This is compared to the case- by-case fixes that app developers are currently doing in response to our vulnerability reports In Table 1, we give a comparison with regard to the vulnerabilities described in Section 3|,Non-data,106
|  The ways they are fixed (or to be fixed) (“Fix w/o Morbs”) come from our conversations with corresponding software vendors Here, how to fix the problem 4 (the exploit through Yelp app) and 5 (the callback loophole) is still unknown As we can see from the table, these vulnerabilities are much easier to fix with the support of Morbs Specifically, for the next- intent problem (Section 3|,Non-data,106
|21), both Dropbox and Facebook informed us that an effective fix takes time to build Particularly, Dropbox explained that they need to “change the architecture” of their app, which involves non-trivial effort In the presence of our origin-based protection, however, this next-intent cross-origin loophole is fixed without requiring any modification to the apps|,Non-data,106
|  As another example, for the fbconnect issue described in Section 331, Facebook chose to deprecate the use of fbconnect, which is a core feature in all of its native SDKs and official apps This effort needs “a several month deprecation period”, according to Facebook|,Non-data,106
| Using Morbs, however, Facebook could easily fix the problem without touching any of its SDKs and apps, by simply adding an extra header, including the origins of the apps supposed to receive its message, to the HTTP response its server sends to mobile devices Overall, as shown in the table, the current fixes to these problems are all case by case, while our solution is consistent in the way to set origin-based security policies (whitelist of authorized origins) and enforce the policies  next-intent (Section 32|,Non-data,106
|1)  fbconnect (Section 331)  Change architecture of the Dropbox app and the Facebook app  this  Deprecate feature (affecting all apps with Facebook SDKs, and taking several months)  Dropbox SDK 33|,Non-data,106
2)  iOS (Section  Change both the Dropbox apps and SDKs  Yelp (Section 332)  issue  Unknown  callback exploit (Section 34,Non-data,106
|1)  Unknown  HTTPClient exploit (Section 342)  Change to the Dropbox app, adding code for checking whether a URL is from dropbox com when attaching authorization header  No modification  Facebook server specifies recipient whitelist by setting a header in HTTP response “mobile- allowed-origins: app://com|,Non-data,106
facebookkatana”  Dropbox SDK specifies sender whitelist by adding an entry “allowedOrigins: app://comgetdropboxDropbox” under “URL scheme” in ,Non-data,106
plist file  No modification  Facebook app specifies sender whitelist by calling WebViewClient:setAllowedOrigi ns(“https://*facebookcom”)  Dropbox app specifies recipient whitelist by calling HTTPClient,Non-data,106
setAllowedOrigins(“ https://*dropboxcom”)  6,Non-data,106
| RELATED WORK Origin-based protection in web browsers  Origin-based protection is a cornerstone for browser security All modern web browsers enforce the same-origin policy (SOP) [4] to protect the web content from one origin against unauthorized access from a different origin Always at the center of browser security is the attacks that circumvent this protection, such as XSS, CSRF, login CSRF, and the defense that reinforces the browser and makes the protection hard to bypass [1][2][3]|,Non-data,106
| Our research shows that serious cross-origin attacks can also happen on mobile platforms and therefore the origin-based protection is equally important to mobile security Under the SOP, cross-origin communication needs to go through designated channels with proper mediation A prominent example is the postMessage channel [5], through which the web content of one origin can send messages to another domain, and the browser ensures that the recipient knows the true origin of the sender  However, the web developer of the recipient domain still needs to come up with her own policy enforcement logic, which could be error-prone|,Non-data,106
| Alternatively, the browser can act on whitelisted origins specified by the developer An example is the Cross- Origin Resource Sharing mechanism [6], through which the content from acom can request resources from bcom server using XMLHttpRequest [7]|,Non-data,106
| The server authorizes this cross- origin activity to the browser by attaching to its HTTP response a header “Access-Control-Allow-Origin: acom”, a whitelist for the requestor acom The browser then enforces this policy, sending the message only to a|,Non-data,106
|com webpages  The design of Morbs is pretty much in line with those browser- based security mechanisms We bring in this origin-based protection to mobile platforms, making the true origin of each message observable to app/web developers and also helping them enforce their policies at the OS level  644from  the  proper  consents  Security on mobile platforms|,Non-data,106
| The security framework of Android is built on i) the sandbox model [8], which separates an app’s data and code execution from that of the rest of the system, and 2) the permission model [9], which grants each app different level of privileges to access system resources under the user’s consent Prior studies mainly focus on circumventing such protection to obtain private user data (eg, GPS location, phone contacts) or perform privileged operations (e|,Non-data,106
|g, sending SMS messages) without user [10][11][12][13][14][27] Most related to our work here is permission re-delegation [10], in which an unprivileged app sends an intent to another app with a proper permission to act on its behalf, operating on the resources (eg|,Non-data,106
|, GPS, user contacts, etc) it is not supposed to touch However, this problem has been studied mainly for understanding the threat to mobile devices’ local resources What we investigated is the protection of an app’s web resources, which has not been explicitly included in Android’s security models|,Non-data,106
| Luo et al conducted two studies specifically about security issues related to WebView: in [42], they categorized existing issues raised by other researchers and a number of issues discovered by them Many of these issues were shown to affect Android applications that use the open-source package DroidGap; in [43], they proposed a type of attack called “touchjacking”, which targets the weaknesses of WebView’s handling of touch events To address those problems, numerous defense mechanisms have been proposed [17][18][19][20]|,Non-data,106
| Particularly, information-flow techniques, such as TaintDroid [15] and Vision [16], are used to track the propagation of sensitive user data across a suspicious app at the instruction level Different from those existing techniques, our protection mechanism is designed to keep track of the origin of the message exchanged between the initiator and the recipients for origin-based mediation For this purpose, we only need to work on the API level (given that the OS is trusted), which is much more efficient A related technique called Quire [21] enables Android to trace and sign the whole IPC chain observed by the OS during intent messaging, so that the recipient of an intent can find out its initiator|,Non-data,106
| However, this approach is not designed to determine a request’s web origin: for example, when an app is activated through a scheme URL generated by a malicious webpage displayed in the WebView instance of the Facebook app, looking at the IPC chain does not tell the recipient app that it is actually originated from the malicious domain  Similar call-sequence analyses have been done on iOS to detect information leaks through iOS apps [22][23] The focus of these analyses is on malicious apps, while our focus is on protecting benign apps 7|,Non-data,106
| CONCLUSION AND FUTURE WORK Unlike traditional web applications, which enjoy browser-level origin-based protection, apps are hosted on mobile OSes, whose security models (eg, sandbox and permission models) are not designed to safeguard resources based their web origins Our research shows that in the absence of such protection, the mobile channels can be easily abused to gain unauthorized access to a user’s sensitive web resources|,Non-data,106
| We found 5 cross-origin issues in popular SDKs and high-profile apps such as Facebook and Dropbox, which can be exploited their users’ authentication credentials and other confidential information such as text input Moreover, without the OS support for origin-based protection, not only is app development shown to be prone to such cross-origin flaws, but the developer may also have trouble fixing the flaws even after they are discovered This points to the urgent need of building origin-based protection into mobile  to steal  platforms In our research, we designed and implemented the first such protection mechanism, Morbs, for mediating cross-origin communications at the OS level|,Non-data,106
| Our evaluation shows that the new technique effectively and efficiently controls the risks that come with the communications, and can also be conveniently utilized by the app and web developers  Our current implementation is for Android Building this new protection on iOS is equally important Also interesting is the effort to automatically analyze existing apps, to identify their cross-origin vulnerabilities and defend them using the origin protection we provided|,Non-data,106
| More generally, given the trend that web services are further investigations are needed to understand how to better protect users’ web resources on mobile OSes, which were originally designed to safeguard a device’s local resources 8 ACKNOWLEDGEMENTS We thank Seungyeop Han, Ravi Bhoraskar, and Jaeyeon Jung for their help on monitoring HTTPS traffic of Android emulator Authors from Indiana University are supported in part by National Science Foundation CNS-1117106 and CNS-1223477|,Non-data,106
|ABSTRACT The ubiquity of modern smartphones means that nearly ev- eryone has easy access to a camera at all times In the event of a crime, the photographic evidence that these cam- eras leave in a smartphone’s memory becomes vital pieces of digital evidence, and forensic investigators are tasked with recovering and analyzing this evidence Unfortunately, few existing forensics tools are capable of systematically recov- ering and inspecting such in-memory photographic evidence produced by smartphone cameras In this paper, we present VCR, a memory forensics technique which aims to fill this void by enabling the recovery of all photographic evidence produced by an Android device’s cameras|,Non-data,110
| By leveraging key aspects of the Android framework, VCR extends existing memory forensics techniques to improve vendor-customized Android memory image analysis Based on this, VCR tar- gets application-generic artifacts in an input memory image which allow photographic evidence to be collected no matter which application produced it Further, VCR builds upon the Android framework’s existing image decoding logic to both automatically recover and render any located evidence Our evaluation with commercially available smartphones shows that VCR is highly effective at recovering all forms of photo- graphic evidence produced by a variety of applications across several different Android platforms|,Non-data,110
 Categories and Subject Descriptors D46 [Operating Systems]: Security and Protection General Terms Security Keywords Memory Forensics; Android; Digital Forensics Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page Copyrights for components of this work owned by others than the author(s) must be honored,Non-data,110
| Abstracting with credit is permitted To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from Permissions@acmorg|,Non-data,110
| CCS’15, October 12–16, 2015, Denver, Colorado, USA Copyright is held by the owner/author(s) Publication rights licensed to ACM c(cid:13) 2015 ACM|,Non-data,110
 ISBN 978-1-4503-3832-5/15/10 $15,Non-data,110
00 DOI: http://dxdoiorg/10,Non-data,110
1145/28101032813720 1 INTRODUCTION Photographs and videos have served as essential evidence in criminal investigations and legal proceedings,Non-data,110
| Further, law enforcement agents rely on photographic evidence as clues during on-going investigations Today, smartphones provide easy access to a camera at all times, and not sur- prisingly, photographic evidence from smartphone cameras has become commonplace in real-world cases During an investigation, digital forensics investigators ex- tract such evidence from a device Historically, investigators focused on evidence recovery from non-volatile storage such as disk-drives, removable storage, etc|,Non-data,110
| Investigators make forensic copies (images) of storage devices from a crime scene and perform analysis on the images back at the forensics lab This analysis recovers a bulk of saved files (such as pictures and videos) that the investigator examines for evidence More recently, investigators have realized that non-volatile storage alone only reveals a subset of the evidence held in a system The contextual evidence held in a system’s volatile storage (i|,Non-data,110
|e, memory) can prove essential to an investiga- tion [4, 9] Memory forensics research has made it possible to uncover much of an operating system kernel’s data from a context free memory image [8, 15, 21, 34] Other work has focused on recovering data structure instances from appli- cations using known in-memory value-patterns [15,26,30] or with the assistance of program analysis [22,28,29]|,Non-data,110
| Unfortu- nately, the rapid pervasion of Android devices has rendered many tools inapplicable to smartphone investigations Like other digital evidence, photographic evidence which persists on non-volatile storage also lacks context or simply portrays an incomplete picture of a crime — again requir- ing memory forensics to fill the gaps To this end, we have developed VCR1, a memory forensics technique which in- tegrates recovery and rendering capabilities for all forms of in-memory evidence produced by an Android device’s cam- eras VCR is based on the observation that all accesses to a device’s camera are directed through one intermediate ser- vice|,Non-data,110
| By designing VCR’s evidence recovery function to tar- get this intermediate service, VCR can automatically recover all forms of photographic evidence regardless of the app that requests it This trend of centralizing critical services into intermediary processes (which we term intermediate service architecture) is widely used in the Android framework, and this paper examines the digital forensics and security impli- cations of such design with regard to the camera framework 1VCR stands for “Visual Content Recovery” and is a refer- ence to the ancient videocassette recorder device 146VCR’s evidence recovery faces challenges, however, be- cause the Android framework (known as the Android Open Source Project or AOSP) is often customized by smartphone vendors|,Non-data,110
| To overcome this, VCR involves novel structure definition inference techniques which apply to the Android vendor customization domain — called Vendor-Generic Sig- natures To the best of our knowledge, VCR is among the first to handle vendor-customized data structures inline as part of targeted evidence recovery Additionally, VCR-recovered evidence must be reviewed, cataloged as evidence, and presented to any (not techni- cally trained) lawyer or official Thus, VCR must trans- form the unintelligible in-memory photographic data into human-understandable images|,Non-data,110
| Using an instrumentation based feedback mechanism within existing image processing routines, VCR can automatically render all recovered evi- dence as it would have appeared on the original device We have performed extensive experimentation with VCR using a wide range of real-world commodity apps running on different versions of the Android framework and two new, commercially available smartphones Our results show that VCR can automatically and generically recover and render photographic evidence from the phones’ memory images — a capability previously not available to investigators — with high accuracy and efficiency 2|,Non-data,110
| MOTIVATION Smartphone cameras are employed in a variety of apps which we use everyday: taking photographs, video chatting, and even sending images of checks to our banks Criminals too have found many uses for smartphone cam- eras To motivate the need for VCR, we quote Riley vs California [1], a United States Supreme Court case involv- ing smartphone photographic evidence: At the police station about two hours after the arrest, a detective specializing in gangs fur- ther examined the contents of the phone|,Non-data,110
| The detective testified that he “went through” Riley’s phone “looking for evidence, because  gang members will often video themselves with guns or take pictures of themselves with the guns|,Non-data,110
|”  Although there was “a lot of stuff” on the phone, particular files that “caught [the detec- tive’s] eye” included videos of young men spar- ring while someone yelled encouragement using the moniker “Blood|,Non-data,110
”  The police also found photographs of Riley standing in front of a car they suspected had been involved in a shooting a few weeks earlier,Non-data,110
| [1] In the above quote, the detective explains how essential smartphone photographic evidence is to ongoing investiga- tions Further, our collaborators in digital forensics practice describe many other crimes in which such evidence can prove invaluable In Section 4, we will consider smartphone pho- tographic evidence in a (mock) case based on an invited talk at Usenix Security 2014 on battling against human traffick- ing [23] Let us strengthen our adversary model by considering a more tech-savvy criminal than Riley — someone who deletes the image files from the device’s storage or even removes the storage (e|,Non-data,110
|g, external SD-card) and destroys it Current digital forensics techniques would not recover any photo- graphic evidence in such a case Luckily, regardless of how tech-savvy the criminal may be, photographic evidence from the camera’s most recent use remains in the system’s mem- ory|,Non-data,110
| VCR gives investigators access to these last remaining pieces of photographic evidence A smartphone camera produces three distinct pieces of evidence: photographs, videos, and preview frames Pho- tographs are left in a device’s memory when a user explicitly captures an image When a smartphone records a video, in- dividual frames are captured and sent to the requesting app — again leaving frames behind in memory|,Non-data,110
| Preview frames, however, are of particular forensic inter- est for a number of reasons Preview frames are a smart- phone’s analog to a standard camera’s view finder When an app uses the camera, the app will, by default, display the camera’s current view on the screen, allowing the user to accurately position the device for capturing the intended picture Importantly, whether the user captures a photo or not the app will display the preview|,Non-data,110
| This leads to the forensically important feature that: Any app which only opens the camera, immediately leaves photographic evidence in memory Further, preview frames (and video frames) are captured continuously and buffered until the app retrieves them Thus many frames will be present in a mem- ory image representing a time-lapse of what the camera was viewing Building from the scenario in Riley vs|,Non-data,110
| California, imagine that Riley had carefully removed all photograph files from the smartphone’s non-volatile storage or (more likely) was using an app which does not save photograph files such as a Skype video-call In this case, the smartphone’s non-volatile storage will not contain any evidence of the car suspected in the earlier shooting [1] However, investigators could now use VCR to analyze the smartphone’s memory image and recover the last images, videos, and preview frames left in the memory, which are likely the evidence the criminal is trying to hide Figure 1 shows some preview frames which VCR recov- ered from a smartphone’s memory image|,Non-data,110
| Notice that mul- tiple frames are recovered and show the action of the per- petrator’s car driving away (ie, temporal evidence for in- vestigators) Also note that these are preview frames and the smartphone user was not actively recording video at that time|,Non-data,110
| Simply having the camera-using app open left photo- graphic evidence in this memory image It’s easy to see how such evidence links the smartphone’s owner to the car in the images (and hence to the shooting) Our study reveals that this photographic evidence always persists in the smartphone’s memory — without being erased or overwritten — until a new app uses the camera (filling the previous image buffers with new evidence) Thus, VCR will always have some evidence to recover|,Non-data,110
| Note that these buffers are not app-specific, only containing frames from the most recent app which used the camera More importantly, the buffers storing other media data (eg, audio) are allo- cated from separate memory pools than the camera’s buffers and thus cannot interfere with photographic evidence|,Non-data,110
| Fur- ther, VCR is not specific to suspects’ smartphones, investi- gators can apply VCR to memory images from a witness or victim’s Android device as well, for instance to collect proof of the user’s whereabouts 147Figure 1: Time-lapse effect in recovered preview frames without explicitly taking a photo VCR recovers and renders these images as they would have appeared on the app’s camera preview screen — the smartphone analog to a standard camera’s view finder more robust, generic way than tools that must recover data from individual (highly diverse) Android apps|,Non-data,110
| In fact, the mediaserver also delegates audio requests (ac- cesses to speakers and microphones) and most media stream- ing We note that photographic evidence is only part of the mediaserver’s potential forensic value VCR can be extended to extract other evidence formats from the mediaserver’s memory 2|,Non-data,110
|2 Assumptions and Setup VCR assumes that an investigator has already captured a memory image from an Android device Previous research has designed both hardware [10] and software [33] acquisi- tion tools to obtain a forensic image of a device’s memory VCR operates on memory images captured by any standard memory acquisition tool Similar to previous memory forensics projects [21, 26, 29, 34], VCR assumes the kernel’s paging structures are intact in the memory image|,Non-data,110
| This is required because VCR oper- ates only on the mediaserver process’ memory session Tools (eg, [34]) exist to rebuild a process’ memory space from a whole-system memory image|,Non-data,110
| 3 SYSTEM DESIGN VCR consists of two phases: 1) identify and recover photo- graphic data from an input memory image, and 2) transform the unintelligible recovered data into photographic evidence which investigators can review and present 31 Recovering Evidentiary Data Since photographic image buffers are encoded and indis- tinguishable from random data, brute-force scanning for the buffers would return countless false results|,Non-data,110
| VCR adopts a more robust algorithm: for each type of evidence (preview frames, photographs, and video frames), VCR locates and recovers a distinct group of interconnected data structures, one of which contains the image data For simplicity, we re- fer to such groups of interconnected data structures as “data structure networks” Ideally, VCR would only need to verify the points-to in- variants between the targeted data structures (ie|,Non-data,110
|, each pointer field within each structure points to another struc- ture in the network) In this way, each recovered data struc- ture attests to the validity of the network, thus the located network is not a false positive However, for key reasons de- scribed below, points-to invariants alone are insufficient in this scenario Figure 2: Intermediate service architecture|,Non-data,110
| The mediaserver acts as a mediator between the apps and the camera device Also, some apps utilize the camera by requesting the default camera app to per- form actual image captures (such as the Facebook app shown here) 21 Centralized Photographic Evidence For many core services, Android has adopted an interme- diate service architecture|,Non-data,110
| Specifically, accesses to periph- eral devices and system services are mediated by an inter- mediate process For the camera(s) this process is called the mediaserver Figure 2 presents a high level view of the intermediate service architecture, specifically for the medi- aserver’s components: Apps, the mediaserver process, and camera hardware abstraction layer (HAL) This high-level intermediate service design makes app development easier and abstract regarding the hardware back-end|,Non-data,110
| Intermediate services present a standard interface to the apps Each service is designed to generically handle any vendor/hardware specific implementation beneath it Most importantly, the AOSP defines generic data structures for the vendor’s code to use in order to conform with the stan- dard interface presented to the apps The key observation behind VCR’s design is that any app which uses the camera must transitively use the generic data structures to retrieve photographic data from the medi- aserver|,Non-data,110
| This creates a unique opportunity for VCR2 By lo- cating and recovering these generic “middleware” data struc- tures, VCR is able to reconstruct and render evidence with- out any app-specific knowledge More importantly, VCR can remain mostly generic to any hardware-specific implemen- tations because the camera HAL must also use the generic data structures to return photographic data to the apps This is beneficial to VCR, which can now be designed in a 2However, as we point out later, this also centralizes privacy- critical components and may benefit attackers as well|,Non-data,110
| Camera HALmediaserverCameraDiverse Android AppsIntermediate Service ArchitectureHardware Devices148Figure 3: AOSP vs Vendor Customized Structure The structures which VCR recovers form a closed network which is unfortunately too small to derive a viable points-to invariant signature Instead, VCR must also employ value- invariant signatures for each data structure|,Non-data,110
| However, due to vendor customizations, the structures’ field positions and value-invariants cannot be fully known a priori Nearly every Android device uses a customized (possibly close-source) version of the AOSP Device vendors make a proprietary copy of the AOSP repository and customize the low level framework (kernel, drivers) and high level utilities (GUI, standard apps) For data structures, vendors may add fields to store custom data, move existing fields to dif- ferent offsets within the structure, or change the values that existing fields can be assigned (such as adding a new enumer- ation value)|,Non-data,110
| Specific to VCR, vendors modify the camera’s allocation pools and internal operation (specific drivers, im- age processing, etc) These modifications lead to different definitions of the data structures that VCR must recover Luckily, although vendors may customize the data struc- tures, they must still conform to a “gold standard” in order to interact with unmodified portions of the AOSP|,Non-data,110
| We use the term “gold standard” to refer to the many components of the AOSP that are not customizable (eg, middleware li- braries, core functionality, etc), and thus vendor customiza- tions must not remove structures and data fields at the source code level which other components rely on|,Non-data,110
| As an example, Figure 3 shows the CameraClient class from the AOSP versus the LG vendor customized version The vendor customizations change the offset of the mPre- viewWindow field, but in order to interact with unmodified AOSP components all the “gold standard” fields (which VCR relies on) must remain in the structure In our evaluation we observed vastly different implementations of several data structures which VCR must recover After the vendor-customized source code is compiled, VCR loses access to the mapping between source code definitions and binary data structure layouts|,Non-data,110
| Essentially we know that the fields exist, but cannot know where they are when lo- cating data structures in a new memory image To over- come this, VCR is prepackaged with Vendor-Generic Sig- natures (Section 32) for the customizable data structures VCR then dynamically derives Vendor-Specific Signatures (Section 3|,Non-data,110
|3) during data structure location and recovery Beyond vendor customization, VCR’s generic signatures are also robust to changes between AOSP versions When Google updates features in the AOSP, this also leads to changes in data structure layouts In fact, several fields were added to the CameraClient class between AOSP versions 4|,Non-data,110
|4 and 50 VCR’s signatures however do not need to be up- dated because they can adapt to the input memory image Further, it is easy to add additional signatures in the event that Google fully redesigns some data structure network|,Non-data,110
 Figure 4: Illustration of a partial CameraClient sig- nature (an unordered set of field constraints) 32 Vendor-Generic Signature Derivation VCR operates on only an input memory snapshot and assumes no source code availability Thus VCR must adapt signatures for any necessary data structures dynamically,Non-data,110
| To this end, VCR comes packaged with a set of Vendor-Generic Signatures Vendor-Generic Signatures are data structure signatures which contain invariants on the structure’s fields but do not have set locations (offsets in the structure) for those fields Specifically, we preprocessed the AOSP “gold standard” version of each data structure Di which VCR must recover For each field fj within the “gold standard” Di, a field constraint (described below) is built|,Non-data,110
| Field Constraints We define 4 primitive constraints to describe each field: 1) A Type/Size constraint defines the field’s type definition (eg, floating point, pointer, etc) and in-memory byte size|,Non-data,110
 Since VCR operates on binary data these constraints are essentially sanity-checks on the discov- ered memory locations 2) Value Range constraints are value invariants specific to field fj 3) Field Offset constraints de- fine where fj is likely to be in Di For some fields (e,Non-data,110
|g, inherited from a superclass) we know the byte offset in Di for certain, but for most fields we cannot know where the vendor’s modifications moved them 4) For pointer fields, Pointer Target constraints define a set of other primitive constraints on the pointer’s target Specifically, our confi- dence in fj being a pointer to a data structure depends on the validity of the target data structure|,Non-data,110
| Therefore, based on the AOSP definition of fj in Di, we automatically build a probability match function pi(v, o) for each primitive constraint pi(v, o) defines the probability that a value v at byte offset o in a discovered data struc- ture matches that constraint We can then define a field constraint for fj as: fj(v, o) = p1(v, o)w1 × p2(v, o)w2 × |,Non-data,110
| × pn(v, o)wn (1) where pi is the ith primitive constraint for field fj, and wi is a corresponding weight to adjust for stronger constraints (the sum of all weights must be 1) Therefore, the signature of the structure Di is an un- ordered set of field constraints The set is unordered because VCR cannot know the offsets of those fields in a vendor customized data structure a priori|,Non-data,110
| During memory image scanning, VCR will order the field constraints to adapt to the vendor customizations (described in the next section) Figure 4 shows part of a CameraClient signature Notice that each field constraint includes a number of primitive constraints — for instance, the mCameraId field has con- straints on its type and size (a 32-bit integer), value range (between 0 and 1 with high probability), and offset (with high probability in the top 16 bytes of the data structure) Not all data structures which VCR recovers are vendor customizable|,Non-data,110
 For these we rely on existing points-to and value invariant signature generation techniques to build a “hard signature” When a signature contains a pointer to class CameraClient {      ,Non-data,110
0xC:  int mCameraId;       0x14: const String16 mClientPackageName;0x18: pid_t mClientPid;       ,Non-data,110
0x64: ANativeWindow* mPreviewWindow;      ,Non-data,110
}class CameraClient {      ,Non-data,110
0xC:  int mCameraId;      0x14: const String16 mClientPackageName;0x18: pid_t mClientPid;      ,Non-data,110
    0x5C: ANativeWindow* mPreviewWindow;     }Vendor Customized FieldsAOSP Data StructureVendor Customized Data StructureVendor Customized FieldsCameraClient = {  ,Non-data,110
|}mCameraId(v,o) = p1(v,o)02   *  p2(v,o)04  *  p3(v,o)0|,Non-data,110
|4mPreviewWindow(v,o) = p1(v,o)01  *  p2(v,o)091, if size(v)=40, otherwise085, if v=0 or 10|,Non-data,110
|15, otherwise095, if o<=16005, otherwise1, if size(v)=40, otherwiseANativeWindow(*v)149one of these structures, we set that pointer field’s Pointer Target constraint value to 10 (i|,Non-data,110
|e, pointing to a valid hard signature provides full confidence in that pointer field) Field Dependence We notice that not all fields in a data structure are independent For simplicity, we only consider dependence based on two (or more) fields’ location in a data structure: (1) Non-pointer fields of the same type tend to be clustered (e|,Non-data,110
|g, floating point width and height fields) and (2) Fields accessed consecutively in a C++ class’s member function are likely to be defined next to one another For these two cases, a scaling factor (α) is applied to in- crease the match probability of the dependent fields when a signature matching maps them consecutively Simply put, if VCR locates these fields next to each other in a potential sig- nature match then we can be more confident in that match — compared to matching those fields in separate locations|,Non-data,110
| Fields dependent by (1) above are given α = 02 scaling factor (ie, matching such fields consecutively increases the probability of the entire signature matching by a factor of 0|,Non-data,110
|2) Conversely, we assume stronger correlation for fields dependent by (2) and thus set α = 08 Based on the signatures generated before, we update each field constraint of any dependent fields to account for the scaling factor|,Non-data,110
| Here we use the function dep(ca, cb) to denote that the field constraints ca and cb are dependent Consider two matches for those field constraints ai and aj where each an is the nth field in a potentially matching data structure instance We define Pmatch(ca, ai) as follows (where c → a denotes “c matches to a”): (cid:40) P (ca → ai||∀cb : dep(ca, cb) ∧ cb → aj) = Pmatch(ca, ai) if i = j − 1 or j + 1 otherwise (ca(ai))α ca(ai) where Pmatch(ca, ai) = (2) Essentially, Equation 2 applies the scaling factor to ca if ca and cb are dependent and cb has previously mapped to a neighbor of ai Otherwise, the formula simplifies to the field constraint probability defined in Equation 1|,Non-data,110
| 33 Memory Image Scanning To use VCR to recover photographic evidence, investiga- tors need only input a context-free memory image VCR then employs a two-pass scanning algorithm In the first pass, VCR marks all memory locations which match hard signatures (i|,Non-data,110
|e, not vendor customizable and do not re- quire probabilistic inference) — we refer to these as “hard matched” data structures During the second pass, VCR uses probabilistic inference with our previously generated Vendor-Generic Signatures to construct Vendor-Specific Sig- natures to identify and recover true data structure instances Starting from the hard-matched data structures, VCR backward propagates confidence to all potential matches to Vendor-Generic Signatures|,Non-data,110
| To calculate a match for a sig- nature S, VCR first converts a candidate memory region (the region we want to map to S) into a set A of tuples: A = {(v0, o0), (v1, o1),    (vn, on)} (3) where vi is the ith value at offset oi in the candidate memory region A|,Non-data,110
| To match Vendor-Generic Signature fields, VCR may combine adjacent tuples to satisfy the field’s type/size constraint If no such match can be made, then the type/size constraint will yield a 0 probability Later, we will use ai to denote (vi, oi) Figure 5: Matching a candidate CameraClient in- stance via field constraint computation|,Non-data,110
| VCR then creates a permutation of the vendor-generic sig- nature by computing the best fit mapping S → A, using the following greedy algorithm: For each randomly chosen field constraint ci, VCR matches a binary tuple aj (from the re- maining unmatched tuples in A) which maximizes ci’s match probability (ie, Pmatch(ci, aj)) This repeats for each ci un- til all field constraints have been matched|,Non-data,110
| Yielding the final match probability equation for a signature S to a candidate structure A: S(A) = Pmatch(c0, a0) × Pmatch(c1, a1) ×    Pmatch(cn, an) (4) where the subscripts indicate order of matching (not or- der in the signature)|,Non-data,110
 Computing Equation 4 for a single S → A mapping yields VCR’s confidence in that particular permutation of S for that candidate A Figure 5 shows an example of matching the CameraClient signature’s field constraints to a candidate memory loca- tion Computing each field constraint for the best matching ai yields one permutation of the CameraClient signature’s fields for that candidate memory location Computing the match probability of Pointer Target con- straints requires knowing the probability of the pointer tar- get’s match,Non-data,110
| Because matching is done via backward prop- agation, VCR only computes a signature’s match proba- bility once all of its Pointer Target constraints have been computed Recall that if the target is a hard-match then this confidence is 10 Thus, VCR requires recoverable data structure networks to have hard-signatures at the leaves (which can be ensured automatically during signature gen- eration)|,Non-data,110
| VCR repeats the above greedy algorithm and Equation 4 computation independently for all candidate memory re- gions for a single signature Note that the first greedy matching may not result in the correct mapping of ci to ai (resulting in different S → A mappings for different can- didate memory locations) We observe that: for a final mapping of ci constraints to be correct, it must be con- stant across all discovered instances of that data structure Thus only a single mapping of S → A can be correct for all candidate memory locations (i|,Non-data,110
|e, A sets) for that signature VCR iteratively repeats the above process for all candi- date memory locations (choosing the S → A mapping which maximizes the probability of a match), until an optimal mapping is found across all candidates for a single signa- ture This final signature which VCR selects is referred to as a Vendor-Specific Signature (i|,Non-data,110
|e, the Vendor-Generic Signa- ture with set field locations) VCR will recover all candidate data structures which match the Vendor-Specific Signatures to a certain threshold In our evaluation, we use a threshold of 0|,Non-data,110
75 since most candidates polarize with invalid candi- dates near 03 and valid matches near 08 CameraClient = {  ,Non-data,110
|   mCameraId(v,o)  |,Non-data,110
|  mPreviewWindow(v,o)  |,Non-data,110
   }Vendor-Generic SignatureCameraClient {    0xc: mCameraId = 1;  ,Non-data,110
  0x5c: mPreviewWindow        = 0xa28c7e34;  ,Non-data,110
|}Vendor-Specific SignaturemCameraId(v,o) = 0918mPreviewWindow(v,o) = (ANativeWindow(*v))09 = 0|,Non-data,110
|856Candidate Signature Match(v = 1, o = 0xc)(v = 0xa28c7e34, o = 0x5c)150(a) YUV Buffer (b) RGBA Buffer Figure 6: Reading (a) YUV and (b) RGBA buffers with different decoding algorithms Correct decod- ing algorithms will minimize the area under the noise curve In fact, we can hardly see the YUV curve in (a) because its noise is always close to 0 3|,Non-data,110
|4 Rendering Evidence Once VCR has recovered the structures containing pho- tographic evidence, the data must be reconstructed into human-understandable images This is essential as the raw contents of these photographic buffers would be unintelligi- ble to forensic investigators Photographic data may be in any format that the app re- quests (eg|,Non-data,110
|, NV21, ARGB, etc) We observe, however, that apps (ie|,Non-data,110
|, image buffer consumers) must have access to de- coding logic for any format supported by the AOSP Based on this, VCR automatically reuses the existing AOSP image decoding logic, but which decoding algorithm to use cannot be known a priori VCR must determine (specifically avoid- ing burdening human users) which decoding is appropriate for each recovered image Image buffers, specifically photographs, are highly peri- odic|,Non-data,110
| That is, the data values follow regular periods across the image’s strides, height, and width Based on this, im- age processing techniques often compute the spacial locality of the image’s pixel values when performing image analy- sis [14] VCR builds on this idea to validate image decoding by enforcing a periodic constraint on the image data as it is read by the decoding algorithm VCR instruments each decoding algorithm to verify that the values read from the input buffer follow a periodic data constraint (i|,Non-data,110
|e, the spacial locality between each pixel value should be small and form a smooth curve) VCR attempts to decode each recovered image buffer with each available algorithm During image decoding, VCR computes the Eu- clidean distance between the pixel values read from the input buffer [14] which we refer to as the decoding “noise|,Non-data,110
|” Ideally, decoding an image buffer with the correct decod- ing algorithm should produce very little noise (ie, the pixel values closely follow the periodic data constraint) In prac- tice, images may contain local, sharp changes of color or brightness (which is particularly obvious when encoded in YUV format), so VCR computes a moving average of the noise values as a noise threshold|,Non-data,110
| The algorithm which pro- duces the smallest noise threshold is marked and the output of that decoding is presented to investigators as evidence For empirical comparison, Figure 6 shows graphs of two image buffers being decoded by the correct and incorrect algorithms For simplicity, we only compare two algorithms, but VCR considers all 19 decoding algorithms used by the AOSP camera framework Figure 6(a) plots the noise values for a buffer encoded in YUV format being decoded using the RGBA algorithm (red curve) and YUV algorithm (blue curve)|,Non-data,110
| We can see that decoding the YUV buffer with an RGBA decoder produces a large amount of noise, whereas decoding with the YUV (ie, correct) algorithm produces so little noise that the blue curve is hardly visible We also plot the noise threshold from the YUV decoding, but this too is always near 0|,Non-data,110
| In Figure 6(b), we plot an RGBA buffer being decoded as YUV (red curve) and RGBA (blue curve) In this case, we see that the correct decoding (RGBA) contains some noise but the incorrect decoding (YUV) induces 3 to 4 times more noise Further, the RGBA noise threshold (plotted in black) is again always near 0 Finally, all recovered buffers of a single type (i|,Non-data,110
|e, preview frames, photographs, or video frames) must use the same en- coding — because an app only specifies this encoding once Thus as a final sanity check, VCR ensures that the chosen decoding algorithm minimizes the decoding noise across all image buffers Because of the large noise disparity between correct and incorrect algorithms, in our evaluation VCR was able to identify the correct decoding algorithm in all of our test cases|,Non-data,110
| 4 EVALUATION Our evaluation tested a variety of different Android de- vices as “devices under investigation” We performed evalu- ations with two new commercially available Android smart- phones: an LG G3 and a Samsung Galaxy S4 Both smart- phones run two different, highly vendor-customized versions of the AOSP|,Non-data,110
| Further, we set up unmodified Android em- ulators running AOSP versions 43, 442, and 5|,Non-data,110
|0 These are the most recent major versions of Android and repre- sent nearly half of all the Android market-share [16] In total, this allows us to stage “crimes” involving 5 vastly dif- ferent Android devices to evaluate VCR’s effectiveness and generality We first installed each app on our test devices and inter- acted with its camera features (i|,Non-data,110
|e, taking photos, videos, and simply watching the preview screen) We then closed the app and used gdb to capture a memory snapshot from the mediaserver process To attain ground truth, we man- ually instrumented the mediaserver to log allocations and deallocations of data structures containing photographic ev- idence|,Non-data,110
| This log was later processed to measure false posi- tives (FP) and false negatives (FN) We used VCR to analyze the previously captured mem- ory images and recorded the output photographic evidence Despite the variety of different and customized AOSP ver- sions tested, all evaluation was conducted using VCR with the same set of Vendor-Generic Signatures (generated from Google’s AOSP 44|,Non-data,110
|2 repository) which VCR automatically adapted to each input memory image In a real-world law enforcement scenario, in-the-field investigators obtain im- ages of a device’s volatile RAM and non-volatile storage, and the collected memory images are later analyzed using VCR by forensic lab staff Also note that VCR is a lightweight, efficient tool and could even be operated at the scene of a crime from an investigator’s laptop In all of our tests, VCR produced fully-rendered results from an input memory im- age in under 5 minutes (except for two specially noted cases at the end of this section)|,Non-data,110
| 41 App-Agnostic Evidence Recovery This section presents the results of applying VCR to mem- ory images containing photographic evidence generated by the following seven apps on our two smartphone devices 050100150200250050100150200250Noise Pixel Reads RGBA (incorrect)YUV (correct)Threshold050100150200250050100150200250Noise Pixel Reads YUV (incorrect)RGBA (correct)Threshold151Device App Instagram Facebook Chase Banking LG G3 Skype LG Default Camera Google Camera Instagram Facebook Samsung Galaxy S4 Chase Banking Skype S4 Default Camera Google Camera 32 1 20 32 1 20 32 1 32 9 32 1 20 32 1 20 32 1 16 32 1 16 32 1 32 9 32 1 16 32 1 16 Evidence Live Instances w/ Image Data Recovered FP FN Preview Photo Video Preview Photo Video Preview Photo Preview Video Preview Photo Video Preview Photo Video Preview Photo Video Preview Photo Video Preview Photo Preview Video Preview Photo Video Preview Photo Video 11 1 20 11 1 20 2 1 9 9 10 1 20 11 1 20 7 1 8 7 1 8 8 1 7 8 7 1 8 7 1 8 11 1 20 11 1 20 2 1 9 9 10 1 20 11 1 20 7 1 8 7 1 8 8 1 7 8 7 1 8 7 1 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Table 1: Results from recovering photographic evidence from apps on commodity Android smartphones Five of the apps have features for taking individual pho- tographs, videos, and displaying preview frames: the two smartphones’ pre-installed camera apps, Google’s Google Camera app, the Facebook app, and Instagram app|,Non-data,110
| Each of these apps accesses and uses the camera device in different and forensically interesting ways We also investigated evi- dence from the Skype app, which employs only video capture and preview functionalities We also analyzed the Chase Bank app’s check image and upload feature In the next sections we will highlight some of these apps as case studies|,Non-data,110
| Table 1 shows a summary of our evaluation results Col- umn 1 shows the device on which the evaluation was per- formed Columns 2 and 3 show the app’s name and which types of photographic evidence it can generate, respectively The number of “live” frames (i|,Non-data,110
|e, frames which were allo- cated and not yet freed) in the memory image is shown in Column 4 Column 5 shows the subset of those image frames which the camera HAL had filled when the memory image was captured3 Column 6 shows the number of images (i|,Non-data,110
|e, photograph, video frames, or preview frames) which VCR recovered and rendered Columns 7 and 8 show false posi- tives (image frames which VCR wrongly reported) and false negatives (image frames which VCR missed) From Table 1, we can make a number of key observations|,Non-data,110
| First, VCR is highly effective at recovering and rendering photographic evidence left behind by a variety of Android apps This confirms that VCR’s Vendor-Generic Signatures ensure that the recovery mechanism is highly accurate Ta- 3The information in Columns 4, 5, and 6 was obtained via manual instrumentation only for the purpose of evaluation VCR does not have access to such runtime information and operates on only the input static memory image|,Non-data,110
