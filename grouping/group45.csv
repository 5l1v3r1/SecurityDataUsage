 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| Compute r(cid:48) such that cchal · Compk∗ (b, rb) = Compk∗ (chal · x + b, r(cid:48)) // r(cid:48) can be efficiently computed using rb and rx Send r(cid:48) to Seller tion 3|,Non-data,118
|2, we describe our implementation of the protocol, which is instantiated using Pedersen commitments and the Naor-Pinkas OT protocol To get a theoretical estimate of the protocol’s efficiency we count the most expensive operations — those that domi- nate the protocol’s overall cost Exponentiations are the most expensive computation required, while the main com- munications requirement is for parties to exchange several group elements and hashes For each URL transmitted, the Seller must compute 34 exponentiations, while transmit- ting 10 group elements and 2 hashes to the Buyer|,Non-data,118
| Meanwhile, the Buyer’s computa- tion load is a bit lighter but the communications requirements are slightly higher The Buyer computes just 24 exponentiations, in addition to sending 39 group elements and log||U|| + 1 hashes to the Seller The complete costs, broken down according to each protocol component, are given in Table 2 3|,Non-data,118
|2 Implementation performance We implemented an elliptic-curve (EC) based version of the protocol in Java, using the Bouncy Castle Crypto API4 for basic EC operations In our implementation the entire Merkle hash-tree was kept entirely in memory (rather than on disk) This is feasible even for moderately large URL lists (eg|,Non-data,118
|, in one of the experiments the tree consisted of about 18 000 URLs) Our experiments used the NIST-recommended EC curve P-256 [15] as the group over which both the Pedersen commitments and Naor-Pinkas OT were implemented, and SHA-1 in place of a “random oracle” Both sides of the protocol were simulated on a single server with one dual-core 24GHz Intel Xeon processor and 2GB of mem- ory (the main bottleneck in the protocol is CPU — one transaction requires less than 4 http://www|,Non-data,118
|bouncycastleorg/ 12 Tal Moran and Tyler Moore Protocol 3c Fake Proof of Committed Value: Buyer Input: Commitment c and claimed value x // Commitment uses public key pk∗ Input: Trapdoor Commitment public and secret keys pk, sk // Used to fake coin flipping 1: Choose r(cid:48) chal ∈R Zp chal, Buyer can open cchal to any value chal) 2: Choose chal ∈R Zp, b ∈R Zp and r(cid:48) ∈R Zp|,Non-data,118
| Let cchal ← Compk (0, r(cid:48) Send cchal to Seller // Using sk and r(cid:48) Let ctarget ← Compk∗ (chal · x + b, r(cid:48)) Let cb ← ctarget cchal  Send (b, cb) to Seller|,Non-data,118
 // Buyer does not know how to open cb 3: Wait to receive chal1 from Seller 4: Let chal0 ← chal − chal1 Compute rchal st,Non-data,118
| cchal = Compk (chal0, rchal) // rchal can be efficiently computed using sk and r(cid:48) Send (chal0, rchal) to Seller 5: Send r(cid:48) to Seller // cb and b were computed at step 2 such that cchal · cb = Compk∗ (chal · x + b, r(cid:48)) chal protocol Seller 5a OT 3a 1a Seller total Buyer 5b OT 3b/3c 1a Buyer total comp|,Non-data,118
| cost exponentiations group elements communication cost hashes 2 4 24 4 34 2 2 16 4 24 2 2 4 2 10 2 1 24 2 39 0 2 0 0 2 0 0 0 log||U|| + 1 log||U|| + 1 Fig 2 Theoretical computation and communication costs of the Phish Market proto- col (left); observed cumulative distribution function of the time required to share each phishing URL (right) 3kB of communication — so running both sides on one server would only cause us to overestimate the running time)|,Non-data,118
| To test the protocol’s performance under real-world conditions, we used the URL feeds from two large take-down companies during the first two weeks of April 2009 We assigned one of the take-down companies to be the Seller, while making the other the Buyer (we ran experiments using both assignments) For the two-week sample period, one company found 8 582 unique URLs while the other discovered 17 721 URLs The first company was interested in obtaining phishing URLs for 59 banks, and the second for 54 banks, according to the client lists shared with the authors|,Non-data,118
| The primary metric we use to measure the performance of our implementation is the time required to process and transmit each phishing URL from the seller to the buyer The less time required for processing URLs, the closer the URL sharing is to instantaneous On average, each URL faced a very acceptable delay of 513 seconds to complete the exchange (3|,Non-data,118
|19 second median) Two main factors affect the total delay First is the processing time required to execute the protocol This computational time was very consistent, taking an average of 2|,Non-data,118
|37 seconds, but never more than 402 sec- 147101316192225283134Time in seconds000%2000%40|,Non-data,118
00%6000%8000%10000%Per-transaction processing timeQueue delayTotal delayThe Phish Market Protocol: Securely Sharing Attack Data Between Competitors 13 onds,Non-data,118
| The other, less predictable, reason for delay happens whenever many phishing URLs are discovered around the same time Whenever a clump of URLs were reported, some URLs had to wait for other URLs to be processed, leading to a longer delay While a multi-threaded implementation could minimize these ‘queue delays’ (by uti- lizing more CPU cores), we chose to implement the protocol using a single thread to demonstrate its feasibility even with modest hardware Moreover, note that the protocol implementation was optimized for clarity and generality of the source code rather than speed|,Non-data,118
| The average queue delay caused by waiting on other URLs to finish processing was 276 seconds, while the longest delay was 346 seconds To get a better feel for how the processing time varies, Figure 2 (right) plots the cumulative distribution functions for the time taken to process each URL, the time that URL spent waiting in the Seller’s queue, and the total delay between the time the URL entered the Seller’s queue and the time the Buyer received it|,Non-data,118
| 484% of URLs were pro- cessed in under 3 seconds, yet 97% took more than 10 seconds Despite the variation, no URL took more than 37 seconds to process|,Non-data,118
| Given that phishing website removal requires human intervention, a 37 second delay is negligible, and certainly much better than the many days longer unknown sites currently take to be removed! In addition to the total delay (red dash-dot line), Figure 2 (right) plots the two key components of delay The green dash line appears nearly vertical around 2 seconds, suggesting that the per-URL processing time is very consistent Meanwhile, the blue solid line plots the queue delay, which accounts for the stretched tail of the overall delay Hence, if the queue delay were reduced by using multiple processors or threads, the total delay might approach the consistently shorter processing time|,Non-data,118
| 4 Related Work Sharing Attack Data The academic work on phishing has been diverse, with a useful starting point being Jakobsson and Myers’ book [10] However, there has been only limited examination of the take-down process employed by the banks and specialist companies, even though it is the primary defense employed today Moore and Clayton estimated the number and lifetimes of phishing websites and demonstrated that timely removal reduced user exposure [12] Subsequently, they presented evidence (repeated in Section 1) showing that take-down companies do not share data on phishing websites with each other, and they calculated that website lifetimes might be halved if companies shared their URL feeds|,Non-data,118
| They appealed to the greater good in advocating that take-down companies voluntarily exchange URL feeds with each other at no charge By contrast, this paper proposes a mechanism for sharing where net contributors are compensated by net receivers of phishing URLs Information sharing has long been recognized as necessary for improving infor- mation security Gordon and Ford discussed early forms of sharing in the anti-virus industry and contrasted it with sharing when disclosing vulnerabilities [9]|,Non-data,118
| Some have worried that firms might free-ride off the security expenditures of other firms by only ‘consuming’ shared security information (eg, phishing feeds) and never providing any data of their own [8], while others have argued that there can also be positive economic incentives for sharing security information [6] 14 Tal Moran and Tyler Moore Cryptographic Protocols The Phish Market protocol is an instance of secure multiparty computation (MPC)|,Non-data,118
| MPC has been a major area of work in theoretical cryptography, and general techniques are known for securely computing any functionality [17,7,3,1] These techniques, however, are not practical for computing functions that have large input size (eg, an optimized implementation of Yao’s protocol for general two-party computation can take seconds to evaluate a simple function with 32-bit inputs [11])|,Non-data,118
| In our case, one of the inputs to the function is a database of previously-known URLs containing thousands of entries, making general techniques completely impractical For many specific functionalities, efficient protocols are known We use some of these as subroutines in our protocol We make use of the Naor-Pinkas OT protocol [14], which is itself a more efficient version of the Bellare-Micali OT protocol [2]|,Non-data,118
| We also use a generalization of the Chaum-Pedersen protocol for proving in zero-knowledge the value of a commitment [5] 5 Concluding remarks Sharing data between competing firms is hard Yet security mechanisms are becoming increasingly data-driven, from identifying malware hosts to blocking spam and shut- ting down phishing websites Consequently, sharing data is now essential as no single defender has a complete view of attacker behavior|,Non-data,118
| In this paper, we have devised a mechanism to make it easier for take-down com- panies to interact: by compensating net contributors of phishing URLs, we can bolster the incentive to share while rewarding investment into better discovery techniques As a bonus, our protocol has the desirable property of being provably secure and allowing parties to share data without relying on a trusted third party to mediate Crucially, the protocol is also efficient: our elliptic-curve-based implementation easily processed the phishing URLs in a two-week sample from two take-down companies while introducing average delays of 5 seconds before sharing Of course, to cut phishing website lifetimes in half and reduce the annual financial exposure due to phishing by several hundred million dollars, we must still convince the take-down companies that sharing is a good idea|,Non-data,118
| We feel that the security guarantees our protocol provides will make it easier for companies to at least explore the idea of sharing data with their competitors At present, many companies still cling to the view that their feed is best Fortunately, our protocol offers companies the chance to put their claims to the test while avoiding the potential for public embarrassment if they happen to find that sharing can indeed help |,Non-data,118
|Abstract Defenders of today’s critical cyber-infrastructure (eg, the Internet) are equipped with a wide array of security techniques including network-based intrusion detection sys- tems (IDS), host-based anti-virus systems (AV), and decoy or reconnaissance systems such as host-based honeypots or network-based telescopes While effective at detecting and mitigating some of the threats posed to critical infrastruc- ture, the ubiquitous nature of malicious activity (e|,Non-data,141
|g, phish- ing, spam, DDoS) on the Internet indicates that the cur- rent deployments of these tools do not fully live up to their promise Over the past 10 years our research group has investigated ways of detecting and stopping cyber-attacks by using the context available in the network, host, and the environment In this paper, we explain what exactly we mean by context, why it is difficult to measure, and what one can do with context when it is available|,Non-data,141
| We illustrate these points by examining several studies in which context was used to enable or enhance new security techniques We conclude with some ideas about the future of context-aware security 1 Introduction Internet has significantly simplified public communica- tion and collaboration As a result, individuals now use it for a variety of activities that including shopping, banking, reading blogs, and social networking|,Non-data,141
| Many of these ac- tivities require end users to divulge personal information, which is then automatically stored and processed by remote software services With the increasingly ubiquitous nature of the Internet in individual’s lives, the vulnerabilities in software have become an easy medium for information theft and abuse There is no doubt that threats in the form of worms, viruses, botnets, spyware, spam, and denial of ser- vice [2, 5, 27, 13] are rampant on today’s Internet To counter these threats, a number of systems have been developed to protect host and network resources|,Non-data,141
| One ap- proach that has gained significant popularity in recent years is the use of network-based security systems These sys- tems are deployed on the network for threat monitoring, de- tection, and mitigation They are easy to deploy and re- quire little modifications to the end hosts These include anomaly detection systems, intrusion detection and preven- tion systems (e|,Non-data,141
|g, Snort [19]), honeypot systems (eg, hon- eyd [18]), and spam detection systems (e|,Non-data,141
|g, SpamAssas- sin [12]) While network-based security systems themselves have improved considerably over time, their deployment model in most networks continue to take a “one-size fits all” ap- proach These systems are typically viewed as generic solu- tions and they do leverage the contextual information avail- able in the networks to customize their deployment|,Non-data,141
| Unfor- tunately, this information may be critical to the performance and accuracy of these systems as the networks they are de- ployed in differ significantly with each other in terms of policy, the topological layout, the vulnerability landscape, the exploits observed, the traffic characteristics, etc Many network-based security systems acknowledge the need to adapt to the network However, such adaptation is often decided in an ad hoc fashion or left to be manu- ally configured For example, honeypot systems like hon- eyd [18] come with a default configuration file for the op- erating system and vulnerability configuration of the hon- eypots|,Non-data,141
| While such systems can be manually configured by a network administrator, the scale of configuration and the diversity among different networks make it very chal- lenging For example, configuring honeynet in a network may require one to come up with operating system and ap- plication configuration for thousands of hosts In addition, the diversity among networks make it difficult for people to share their configurations and mitigate this effort Over the last several years, our group’s thesis has been that the automatic adaptation to the network context will significantly improve the performance and accuracy of network-based security systems|,Non-data,141
| The general idea of adding 1 Operating System Windows Cisco IOS Apple Linux HP printer Solaris *BSD Networks A/16 B/16 C#1/17 D#1/19 44 14 9 9 3 9 1 76 - - 15 - 1 8 25 7 36 7 13 7 - 77 - - 6 - 2 15 Networks TCP Port A/16 B/16 C#1/17 D#1/19 139 22 135 23 445 80 25 21 427 497 110 42 41 39 27 27 21 12 8 4 3 1 - 30 42 4 - 93 70 77 - - 39 - 25 69 5 - 96 83 79 - - 17 17 53 10 34 11 26 10 24 26 28 - Operating Systems TCP ports Table 1 Comparing the vulnerable population in four networks, by operating systems and TCP ports(from [21]) Different networks have different vulnerability profiles context to computing so that they can better serve human need has received significant attention from the academic community|,Non-data,141
| As explicitly adding context for each user is too cumbersome, most of these efforts have tried to lever- age user group activities to automatically infer the context In the mobile computing community, context in the form of location, role and time has been used to automatically adapt a mobile device [16] For example, a cell phone can vibrate instead of ringing if it knows that a person is in a meeting This automatic adaptation reduces human com- puter interaction and makes it easier to manage a mobile de- vice|,Non-data,141
| Search engine technologies have leveraged user click through to determine the context for a query and improve search ranking [11] These techniques do not require each user to provide explicit feedback but automatically deter- mine the context for a query by exploiting the large amount of user data In this paper, we explore different types of context in- formation that are not currently used by current security solutions and show how such information can be used to improve the performance and accuracy of these systems We begin in section 2 by explaining what we mean by con- text, why the measurement of context is difficult, and what can be accomplished with context if it can be captured|,Non-data,141
| In section 3, we highlight several examples of our previous work which quantify the effects of context, utilize different forms of context to improve performance and accuracy, and aggregate context to solve difficult security problems We conclude in section 4 with a discussion of interesting future directions for context-aware security 2 Context Context can mean a variety of things to computer sci- entists, from one’s physical location, to one’s current desk- top environment, the task being performed, etc We begin, therefore, by providing a definition of what we mean by context and more specifically, context-aware security|,Non-data,141
| We show that the properties important to context-aware security are, in fact, non-trivial to measure However, we argue that, if they can be measured, context can be used in a variety of ways that improve performance and accuracy of existing and new security applications 21 What is security context? Short of unplugging our computers from the network and locking them in a room, there is no absolute security|,Non-data,141
| At its most fundamental level, then, security is a risk analysis activity in which practitioners decide what they wish to pro- tect from whom and at what cost The key to understand- ing these tradeoffs are three properties, which we define to make up a network’s security context: • Vulnerability profile: The vulnerability profile repre- sents the space of all possible targets and ideally all methods of unauthorized access to those services In the traditional sense, this is a mapping between the device (ie|,Non-data,141
|, machine), operating system, applications, and the list of known vulnerabilities for each More broadly, this encompasses unknown vulnerabilities in server software and the social engineering path for ac- cess acquisition in client software 2 Table 2 (Left) Packet rate as seen by each sensor normalized by /24 (from [7]|,Non-data,141
|) (Right) The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame (from [4]) Different networks have different attack surfaces • Attack surface: The attack surface represents the unique threats posed by attackers to the defenders of a particular network|,Non-data,141
| In a traditional sense, it is a mea- sure of the remote network exploits (either attempted or successful) directed at a particular network In a broader sense, it encompasses the notion of who the at- tackers are, what resources they are interested in, and the current techniques for acquiring those resources For example, while a network might run a large num- ber of (potentially vulnerable) printer services, attack- ers may avoid these services due to their uniqueness (and hence difficulty in exploiting), as well as the lim- ited value in compromising them Of course, other at- tackers may feel just the opposite about having access to printed documents–the context matters|,Non-data,141
| • Usage model: While the attack surface helps priori- tize the potential targets specified in the vulnerability surface by defining what the attackers are interested in and the current tools used to achieve them, the us- age model helps defenders prioritize the importance of the services on the network This prioritization can be as simple as defining what services are most used on a network, but may layer in notions of data impor- tance, disclosure liability, opportunity costs on failure in availability, etc 22 Why is context hard? In the previous section, we defined security context to in- clude a network’s attack surface, vulnerability profile, and usage model|,Non-data,141
| Unfortunately, obtaining this context for most networks is not a trivial exercise In this section, we ex- amine the two main hurdles for context measurement: the diversity among networks and the dynamic nature of con- text 22|,Non-data,141
|1 One size does not fit all As network and security practitioners, it should come as no surprise that different networks exhibit different traits or characteristics What we have found during our research, however, is that these differences are surprisingly large, per- vasive, and have significant impacts on all aspects of the security in an organization For example, consider the is- sue of an organization’s vulnerability profile Table 1 com- pares the vulnerable population in these of four networks networks in two ways: by the operating system and the TCP ports|,Non-data,141
| Of the four production networks (A/16, B/16, C/17 and D/19), two of these networks (A/16 and B/16) are academic networks and two (C/17 and D/19) are web server farms The second largest operating system in net- work A/16 is surprisingly Cisco IOS, which is found in the wireless access points and routers in the academic campus On the other hand, Apple Mac OS is the dominant operating system in network B/16 As expected, the web-server farms were dominated by Windows servers|,Non-data,141
| While SSH seems to be predominant service found in A/16 and B/16, HTTP, FTP and SMTP seems to be the dominant services in the web server farms Therefore, the vulnerability profile may differ significantly depending on the network 3 010203040Port ID010203040Number of Sensors Reporting Port1 Day1 Month1 WeekAPPL RTSP DOMAIN HTTPS SMTP LOTUS NOTES Hospital IN 96|,Non-data,141
25 169 349 199 1,Non-data,141
73 OUT 191 185 001 1,Non-data,141
|32 158 IN Library Regional Network APPL OUT 2,200 HTTP 11639 HTTPS 13|,Non-data,141
|13 FLASH 28716 TCP/81 SMTP 16651 17,590 6516 706|,Non-data,141
|02 1641 10083 Government IN 1,390 1185 108|,Non-data,141
49 9897 5572 OUT 23143 195,Non-data,141
87 9811 3264 7300 Small College IN APP,Non-data,141
| HTTP FLASH HTTPS XBOX 58,420 4,080 1,280 1,010 UNIDATA-LDM 94791 OUT 13,710 8475 1,400 1,610 95088 APPL|,Non-data,141
| HTTP SSH HTTPS ESP SMTP Table 3 The network application usage (Kbps) at 4 different networks Different networks have dif- ferent usage models Today’s attacks are global and everyone see the ”same stuff” right? Unfortunately, the threat landscape also dif- fers significantly for different networks|,Non-data,141
| Cooke et al [7] monitored unused address spaces (darknets) in different net- works Since unused addresses do not have any legitimate services, the traffic directed to these addresses are suspi- cious Figure 2 shows the packet rates observed by different sensors and normalized by /24 address range|,Non-data,141
| It shows that some networks receive significantly more suspicious traffic than others In Bailey et al [4], we examined, for 31 dark- nets, the top 10 destination ports, based on the number of packets, and compared these lists across darknets Figure 2 shows the number of darknets that had a particular desti- nation port in their top 10 list|,Non-data,141
| The analysis is performed for the top 10 destination ports over a day, top 10 destina- tion ports over a week, and top 10 destination ports over a month This figure shows that there are over 30 destination ports that appear on at least one darknet’s top 10 list A small handful of these destination ports appear across most darknets (1433, 445, 135, 139), but most of the destination ports appear at less then 10 of the darknets Not only are there more or less attacks based on where you are, those attacks are targeting different services as well|,Non-data,141
| The traffic characteristics of a network may also be sig- nificantly different than others For example, the list of IP addresses that legitimately access services on a given network may be different from other networks Similarly, HTTP may be the most prominent protocol in web server farms and SMTP may be the most prominent protocol in a mail service provider network Consider the data in Ta- ble 3|,Non-data,141
| While some applications (eg, web) are global pop- ular, many are not (eg|,Non-data,141
|, Lotus Notes, XBox) Note also the stark differences in the magnitude of traffic as well as the different behavior as either servers (eg, high in bound traffic) or clients (i|,Non-data,141
|e, high outbound traffic) of a particular service 22|,Non-data,141
|2 Dynamic Nature of Context Another interesting observation of our work is that these unique individual contexts are highly dynamic in nature Attack surfaces, usage models, and even vulnerability pro- files change rapidly as new attacks are released, flash crowds are formed, or new application emerge As an ex- ample, consider Table 4 which shows the top five TCP ports and the number of packets observed over a day for five months on the a /24 darknet in the B/16 network We find that new services were targeted heavily each month|,Non-data,141
| The TCP ports 6000 and 1080 were the unusual ones targeted in April, the TCP port 5000 was targeted in May, the TCP ports 22 and 5900 were targeted in June, and TCP port 4444 in July The highly variable nature of this threat landscape makes chasing exploits difficult for the defenders, who must adjust their vision of the attack surface to today’s or this week’s most popular attacks 23 What do we do with context? In the previous section, we argued that our elements of context-aware security (attack surface, vulnerability profile, and usage model) are in fact difficult to measure due to their dynamic nature and the large degree of diversity in each across networks|,Non-data,141
| This argued strongly for automated techniques for capturing and updating the unique security context for individual organizations, but such mechanisms are only useful if the security context can be applied to do something useful Perhaps the most straight forward appli- cation is in the area of configuration Most modern security devices (eg|,Non-data,141
|, IDS, Firewalls, anti-virus software) have a be- wildering array of configuration options, from the mundane display and alerting features, to update frequency, sensitiv- ity parameters, and detection techniques Setting these op- tions correctly and optimizing them for the individual secu- rity context of a network is one such interesting application Perhaps slightly less obvious is the application of these methods to the placement of security devices within a net- work Many network centric security devices rely on mon- itoring or shaping traffic as seen on a particular network or connection|,Non-data,141
| As modern networks become increasingly flat- tened and porous, the placement of these devices becomes less and less obvious (ie, the death of the DMZ and the walled garden) and the need for informed placement in- creasingly important While configuration and placement are interesting applications of context, they still treat an in- 4 dividual security device as a black box|,Non-data,141
| One of the most interesting applications of context is to modify the black box itself to suit the context of the net- work For example, by understanding the unique way in which users make use of network resources, we can reorder rule evaluation to save space, time, and increase accuracy We can suggest that a security detection device currently op- erating at the host might best be used in the cloud, while a network policy device, might be be used on the host Con- figuration, placement, modifying key assumptions are just some of the applications of context we have explored, and many other such applications certainly exist|,Non-data,141
| In the next section, we examine some examples of our work in this area 3 Examples The emergent definition of context and its application areas in the previous section were the direct result of 10 years of research in security and distributed systems in our research group In this section, we highlight some of the more interesting classes of projects including: quantifying the scope of context, applying different forms of context, and aggregating multiple contexts to solve difficult prob- lems 3|,Non-data,141
|1 Quantifying Context As network-based threats become increasingly promi- nent, characterizing, monitoring, and tracking these threats is critical to the smooth running of individual organizations and to the Internet as a whole To increase their view of these threats, researchers and network operators started in- strumenting unused address space Because there are no legitimate hosts in an unused address block, traffic must be the result of misconfiguration, backscatter from spoofed source addresses, or scanning from worms and other net- work probing The most common application of this tech- nique is the global announcement and routing of unused space to a collection infrastructure that records incoming packets [14]|,Non-data,141
| Using these techniques, researchers have suc- cessfully characterized and classified the traffic observed at unused blocks [15] In this work [7, 3] we demonstrated that achieving a rep- resentative sample may not be as simple as monitoring a few unused address blocks To better understand how ob- served traffic is affected by sensor placement, we used data from the Internet Motion Sensor [8] The Internet Motion Sensor (IMS) is a distributed collection of blackhole sen- sors|,Non-data,141
| These sensors are deployed in networks belonging to service providers, large enterprises, and academic insti- tutions representing a diverse sample of the IPv4 address space We presented empirical evidence that different ad- dress blocks observe significantly different traffic volumes and patterns(eg, Table 2(left))|,Non-data,141
| This evidence was then combined with additional experimentation to build a list of sensor properties providing plausible explanations for these differences Using these properties, we concluded with rec- ommendations for understanding the implications of sensor placement 32 Applying Different Forms of Context Applying allocation policy This vast pool of unallocated, unrouted, and unassigned addresses sitting idle across the Internet can be used to provide intelligence on malicious and misconfigured Internet activity [17]|,Non-data,141
| There are a range of techniques for monitoring contiguous ranges of unused addresses, including honeypots [1, 25, 26], virtual honey- pots [4, 10, 28], emulators [18, 29], simple responders [3], and passive packet capture [9, 20] We refer to these tech- niques together as honeynet monitoring Existing honeynet monitoring systems only cover a very small percentage of the available unused address space Two fundamental problems limit monitoring more ad- dresses|,Non-data,141
| First, address allocation information is distributed across many devices, applications, and administrative do- mains For example, address registries like ARIN can pro- vide information on what addresses are assigned to an orga- nization, but not on what addresses are routed or reachable The second challenge is that address allocations can change quickly For example, wireless devices can enter and leave a network, and instability in routing information can impact address reachability|,Non-data,141
| The result is that honeynet monitoring systems today monitor only easily obtainable, contiguous blocks of addresses This work [6] presented an architecture that automated the process of discovering these non-productive addresses by participating directly with allocation, routing, and pol- icy systems The goal was to pervasively discover unused and unreachable (“dark”) addresses inside a network so that traffic sent to those addresses can be forwarded to hon- eynet monitoring systems To demonstrate our approach, we constructed the Dark Oracle, a system designed to dis- cover unused and unreachable addresses within a network|,Non-data,141
| The system integrated external routing data like BGP, in- ternal routing data like OSPF, and host configuration data like DHCP server logs to construct a locally accurate map of dark addresses The Dark Oracle automated address dis- covery, significantly simplifying the process of finding dark addresses It also provided unique local visibility into inter- nal threats and targeted attacks We deployed a pervasive honeynet detector that uses the addresses from the Dark Or- acle and showed how unused addresses from a DHCP server reveal almost 80,000 unique source addresses compared to 5 04/19/2006 05/19/2006 06/19/2006 07/19/2006 08/19/2006 6000 445 1433 1080 135 445 139 5000 1433 80 22 5900 3128 8080 80 135 80 4444 445 1433 1433 1080 445 5900 1521 Table 4|,Non-data,141
| The top 5 TCP ports observed in a /24 sensor in network B/16, over a period of 5 months (from [21]) The attack surface changes quickly over time 4,000 found by a traditional /24 monitor Because we were also able to monitor outgoing addresses, we discover al- most 2,000 locally infected or misconfigured hosts in an academic network|,Non-data,141
| These experiments demonstrated the ef- fectiveness of the Dark Oracle in discovering highly dis- tributed local and global dark addresses, thereby enabling quick detection of targeted and internal attacks Applying work load Intrusion detection and prevention systems take a set of signatures and detect intrusions by matching them with network traffic Existing approaches to signature evaluation apply statically-defined optimizations that do not take into account the network in which the IDS or IPS is deployed or the characteristics of the signature database In this work [24] we argued that for higher per- formance, IDS and IPS systems should adapt according to the workload, which includes the set of input signatures and the network traffic characteristics|,Non-data,141
| We developed an adaptive algorithm that systematically profiles attack signatures and network traffic to generate a high performance and memory-efficient packet inspection strategy We implemented our idea by building two dis- tinct components over Snort: a profiler that analyzes the input rules and the observed network traffic to produce a packet inspection strategy, and an evaluation engine that pre-processes rules according to the strategy and evaluates incoming packets to determine the set of applicable signa- tures We have conducted an extensive evaluation of our workload-aware Snort implementation on a collection of publicly available datasets and on live traffic from a border router at a large university network Our evaluation shows that the workload-aware implementation outperforms Snort in the number of packets processed per second by a factor of up to 1|,Non-data,141
|6x for all Snort rules and 27x for web-based rules with reduction in memory requirements Similar compari- son with Bro shows that the workload-aware implementa- tion outperforms Bro by more than six times in most cases Applying vulnerability profiles A Honeynet is a collec- tion of sacrificial hosts explicitly deployed to be scanned, compromised, and used in attacks|,Non-data,141
| Honeynets have recently become popular to detect and characterize threats such as worms, botnets, and malware Unfortunately, existing ap- proaches to deploying honeynets largely ignore the problem of configuring operating systems and applications on indi- vidual hosts, leaving the user to configure them in a manual and often ad hoc fashion In this work [21], we demonstrate that such ad hoc configurations are inadequate: they mis- represent the security landscape of the networks they are trying to protect and are relatively easy for attackers to dis- cover Therefore, a honeynet configuration should take the deployment context i|,Non-data,141
|e, the network in which it is deployed to provide visibility into attacks and resistance to finger- printing We showed that manually building honeynet configura- tions for each network is hard, as each network has its own unique threat and vulnerability spaces, and the potential number of hosts to configure in the honeynet is quite large We argued that honeynets with individually consistent hosts and proportional representation of the network will achieve the two desired goals of visibility into network attacks and resistance to discovery|,Non-data,141
| We developed an automated tech- nique based on profiling the network and random sampling to generate these honeynet configurations Through experi- mental evaluation and deployment of configurations gener- ated by our technique, we demonstrated significantly more visibility and higher resistance to discovery than current methods 33 Aggregating context Aggregating to solve global problems In order to ad- dress globally scoped Internet threats, threat detection and classification systems are needed to provide detailed foren- sic information on new threats in a timely manner|,Non-data,141
| In this work bailey:2005:filter, we investigated the problem of fil- tering darknet traffic in order to identify connections wor- thy of further investigation In particular, we analyzed data from a large, distributed system of darknet monitors We characterized the traffic seen by these monitors to under- stand the scalability bounds of a hybrid monitoring system that consists of distributed darknet monitors and a central- 6 ized collection of honeypots (or honeyfarm) We found that a small fraction of the total source IPs observed at a sin- gle darknet are responsible for the overwhelming majority of the packets and that most behavior consists of sources, and to some extent target services, that are not observable across darknets|,Non-data,141
| From these characterizations we show that source-based filtering is an effective method of reduction for individual darknets, but fails to provide additional ben- efits when multiple darknets are combined together There- fore we created an algorithm that is both very effective in reducing the large amount of traffic seen by darknets to a small handful of events and is easily within the capabili- ties of the most modest honeyfarms A broad production deployment of this algorithm over a three month period in 2005 provided analysis of five major global events, includ- ing the MySQL Worm and the scanning associated with the WINS vulnerability, as well as the Veritas Backup vulnera- bilities Aggregating to solve a local problem Blacklists have be- come popular among the operational community to filter or block the explosive growth of unwanted traffic on the Internet|,Non-data,141
| Blacklists generated from firewall logs are used to block compromised hosts and blacklists generated from spamtraps are used to block spam While these techniques have gained prominence, little is known about their effec- tiveness or potential drawbacks We performed a preliminary study [22] on the effective- ness of reputation-based blacklists–namely those that are used for spam detection We examined the effectiveness, in terms of false positives and negatives, of four blacklists, namely NJABL, SORBS, SpamHaus and SpamCop and in- vestigated into the sources of the reported inaccuracy|,Non-data,141
| We found that the blacklists studied in our network exhibited a large false negative rate NJABL had a false negative rate of 98%, SORBS had 65%, SpamCop had 35% and SpamHaus had roughly 36% The false positive rate of all blacklists were low except that of SORBS, which had an overall false positive rate of 10% The false positive of SORBS came mostly from blacklisting six Google mail servers that sent significant amount of ham to our network|,Non-data,141
| However, since very little is known about the approaches taken by these ser- vices to generate their blacklists, and only the results of the generation are available (not the raw data), no one has ex- plored in depth the reasons for these failures To solve this problem, we proposed [23] a new context- aware approach to blacklist generation By making use of local usage and reachability information as well as the global information provided by blacklists, we showed that we can provide a significant improvement over existing ap- proaches In particular, this context aware paradigm en- abled two specific techniques: ratio-based blacklisting and speculative aggregation|,Non-data,141
| In the ratio-based blacklisting ap- proach, the traffic on the live network is compared to the traffic on the spamtraps to determine if it is safe to black- list an IP address We called this approach the ratio-based approach as the ratio of email messages on the live network to the email messages on the spamtrap is used as a measure to blacklist an IP address In the second approach, specula- tive aggregation, we used local reachability information as well as application history to predict where new spam mes- sages will come while limiting the chance that these pre- dicted hosts or networks are of use to the local network A deployment of context aware blacklists for over a month in a large academic network demonstrated significant improve- ment in blacklist accuracy|,Non-data,141
| 4 Discussion In this paper, we have taken a retrospective look at some of our research group’s output and characterized this work in terms of context-aware security We defined context to be the unique attack surface, vulnerability profile, and us- age models that underly the unique risk tradeoffs embodied by each organization Context-aware security, then, is the application of this context to improve the accuracy, perfor- mance (in time or space), or reliability of security software devices, algorithms, or techniques In its most basic form, our thesis has been that ”one size does not fit all”|,Non-data,141
| Security is not something that can be applied uniformly as if encryp- tion, intrusion detection, honeypots, etc are security in and of themselves They must be applied differently in each unique context if they are to be effective While the notion of context-aware security strikes at the core of nearly all modern security problems, we do believe that several areas of context-aware security provide particu- larly interesting and relevant areas for future research|,Non-data,141
| First, while the previous research examples included both diverse sources of contextual information and the notion of aggre- gation, they stopped short of a unified framework for lo- cal context By explicitly representing the various aspects of context (eg, attack surface) and the multiple represen- tations of that data (e|,Non-data,141
|g, snort, honeypots, av logs, etc) we hope to automate the configuration, placement, and op- eration of various security devices in the network Sec- ond, we believe that context-aware risk assessment offers perhaps the epitome of context aware application domains|,Non-data,141
| While previous theoretic work on assessing the security of networks has focused on vulnerability profiles (eg, attack graphs), we believe that a unifying context framework can help develop concrete metrics for assessing (and mitigat- ing) risk within one’s network Finally, we believe context- aware security interfaces are necessary, not only to man- age the increasingly ubiquitous and mobile computing en- vironments of today, but to manage the complexity inherent in managing one’s context as they move through numerous 7 such environments|,Non-data,141
 5 Acknowledgements We would like to thank all of the students in our research group and especially Evan Cooke for their efforts in the original research that was highlighted here This work was supported in part by the US Department of Homeland Se- curity Science & Technology Directorate under Contracts No,Non-data,141
|Abstract I/O virtualization (SRIOV) Single root is a hard- ware/software interface that allows devices to “self virtu- alize” and thereby remove the host from the critical I/O path SRIOV thus brings near bare-metal performance to untrusted guest virtual machines (VMs) in public clouds, enterprise data centers, and high-performance comput- ing setups We identify a design flaw in current Ethernet SRIOV NIC deployments that enables untrusted VMs to completely control the throughput and latency of other, unrelated VMs The attack exploits Ethernet ”pause” frames, which enable network flow control functional- ity|,Non-data,150
| We experimentally launch the attack across sev- eral NIC models and find that it is effective and highly accurate, with substantial consequences if left unmiti- gated: (1) to be safe, NIC vendors will have to mod- ify their NICs so as to filter pause frames originating from SRIOV instances; (2) in the meantime, administra- tors will have to either trust their VMs, or configure their switches to ignore pause frames, thus relinquishing flow control, which might severely degrade networking per- formance We present the Virtualization-Aware Network Flow Controller (VANFC), a software-based SRIOV NIC prototype that overcomes the attack VANFC filters pause frames from malicious virtual machines without any loss of performance, while keeping SRIOV and Ethernet flow control hardware/software interfaces intact 1 Introduction A key challenge when running untrusted virtual ma- chines is providing them with efficient and secure I/O|,Non-data,150
| Environments running potentially untrusted virtual ma- chines include enterprise data centers, public cloud com- puting providers, and high-performance computing sites There are three common approaches to providing I/O services to guest virtual machines: (1) the hypervisor emulates a known device and the guest uses an unmod- ified driver to interact with it [71]; (2) a paravirtual hypervisor (a) Traditional Virtualization (b) Direct I/O Device Assignment Figure 1: Types of I/O Virtualization driver is installed in the guest [20, 69]; (3) the host as- signs a real device to the guest, which then controls the device directly [22, 52, 64, 74, 76] When emulating a device or using a paravirtual driver, the hypervisor in- tercepts all interactions between the guest and the I/O device, as shown in Figure 1a, leading to increased over- head and significant performance penalty The hypervisor can reduce the overhead of device em- ulation or paravirtualization by assigning I/O devices di- rectly to virtual machines, as shown in Figure 1b|,Non-data,150
| Device assignment provides the best performance [38,53,65,76], since it minimizes the number of I/O-related world switches between the virtual machine and its hypervisor However, assignment of standard devices is not scalable: a single host can generally run an order of magnitude more virtual machines than it has physical I/O device slots available One way to reduce I/O virtualization overhead fur- ther and improve virtual machine performance is to of- fload I/O processing to scalable self-virtualizing I/O de- vices The PCI Special Interest Group (PCI-SIG) on I/O Virtualization proposed the Single Root I/O Virtu- alization (SRIOV) standard for scalable device assign- ment [60]|,Non-data,150
| PCI devices supporting the SRIOV standard present themselves to host software as multiple virtual interfaces The host can assign each such partition di- rectly to a different virtual machine With SRIOV de- vices, virtual machines can achieve bare-metal perfor- USENIX Association  24th USENIX Security Symposium 335 mance even for the most demanding I/O-intensive work- loads [38, 39] We describe how SRIOV works and why it improves performance in Section 2|,Non-data,150
| New technology such as SRIOV often provides new capabilities but also poses new security challenges Be- cause SRIOV provides untrusted virtual machines with unfettered access to the physical network, such machines can inject malicious or harmful traffic into the network We analyze the security risks posed by using SRIOV in environments with untrusted virtual machines in Sec- tion 3 We find that SRIOV NIC, as currently deployed, suffers from a major design flaw and cannot be used se- curely together with network flow control|,Non-data,150
| We make two contributions in this paper The first contribution is to show how a malicious virtual machine with access to an SRIOV device can use the Ethernet flow control functionality to attack and completely con- trol the bandwidth and latency of other unrelated VMs using the same SRIOV device, without their knowledge or cooperation The malicious virtual machine does this by transmitting a small number of Ethernet pause or Pri- ority Flow Control (PFC) frames on its host’s link to the edge switch If Ethernet flow control is enabled, the switch will then shut down traffic on the link for a spec- ified amount of time|,Non-data,150
| Since the link is shared between multiple untrusted guests and the host, none of them will receive traffic The details of this attack are discussed in Section 4 We highlight and experimentally evaluate the most notable ramifications of this attack in Section 5 Our second contribution is to provide an understand- ing of the fundamental cause of the design flaw lead- ing to this attack and to show how to overcome it|,Non-data,150
| We present and evaluate (in Section 6 and Section 7) the Virtualization-Aware Network Flow Controller (VANFC), a software-based prototype of an SRIOV NIC that suc- cessfully overcomes the described attack without any loss in performance With SRIOV, a single physical endpoint includes both the host (usually trusted) and multiple untrusted guests, all of which share the same link to the edge switch The edge switch must either trust all the guests and the host or trust none of them The former leads to the flow con- trol attack we show; the latter means doing without flow control and, consequently, giving up on the performance and efficient resource utilization flow control provides|,Non-data,150
| With SRIOV NICs modeled after VANFC, cloud users could take full advantage of lossless Ethernet in SRIOV device assignment setups without compromising their se- curity By filtering pause frames generated by the mali- cious virtual machine, VANFC keeps these frames from reaching the edge switch The traffic of virtual machines and host that share the same link remains unaffected; thus VANFC is 100% effective in eliminating the attack VANFC has no impact on throughput or latency compared to the baseline system not under attack|,Non-data,150
| VANFC is fully backward compatible with the current hardware/software SRIOV interface and with the Ether- net flow control protocol, with all of its pros and cons Controlling Ethernet flow by pausing physical links has its fundamental problems, such as link congestion prop- agation, also known as the ”congestion spreading” phe- nomenon [13] The attack might also be prevented by completely redesigning the Ethernet flow control mech- anism, making it end-to-end credit-based, as in Infini- Band [18], for example But such a pervasive approach is not practical to deploy and remains outside the scope of this work|,Non-data,150
| Instead, VANFC specifically targets the de- sign flaw in SRIOV NICs that enables the attack VANFC prevents the attack without any loss of performance and without requiring any changes to either Ethernet flow control or to the SRIOV hardware/software interfaces One could argue that flow control at the Ethernet level is not necessary, since protocols at a higher level (eg|,Non-data,150
|, TCP) have their own flow control We show why flow control is required for high performance setups, such as those using Converged Enhanced Ethernet, in Section 8 In Section 9 we provide some notes on the VANFC im- plementation and on several aspects of VM-to-VM traf- fic security We present related work in Section 10|,Non-data,150
| We offer concluding remarks on SRIOV security as well as remaining future work in Section 11 2 SRIOV Primer Hardware emulation and paravirtualized devices impose a significant performance penalty on guest virtual ma- chines [15, 16, 21, 22, 23] Seeking to improve vir- tual I/O performance and scalability, PCI-SIG proposed the SRIOV specification for PCIe devices with self- virtualization capabilities The SRIOV spec defines how host software can partition a single SRIOV PCIe device into multiple PCIe “virtual” devices|,Non-data,150
| Each SRIOV-capable physical device has at least one Physical Function (PF) and multiple virtual partitions called Virtual Functions (VFs) Each PF is a standard PCIe function: host software can access it as it would any other PCIe device A PF also has a full configuration space Through the PF, host software can control the en- tire PCIe device as well as perform I/O operations|,Non-data,150
| Each PCIe device can have up to eight independent PFs VFs, on the other hand, are “lightweight” (virtual) 336 24th USENIX Security Symposium  USENIX Association guest VM0 hypervisor Figure 2: SRIOV NIC in a virtualized environment PCIe functions that implement a subset of standard PCIe device functionalities Virtual machines driving VFs per- form only I/O operations through them For a virtual ma- chine to use a VF, the host software must configure that VF and assign it to the virtual machine|,Non-data,150
| Host software often configures a VF through its PF VFs have a partial configuration space and are usually presented to virtual machines as PCIe devices with limited capabilities In theory, each PF can have up to 64K VFs Current In- tel implementations of SRIOV enable up to 63 VFs per PF [42] and Mellanox ConnectX adapters usually have 126 VFs per PF [57]|,Non-data,150
| While PFs provide both control plane functionality and data plane functionality, VFs provide only data plane functionality PFs are usually controlled by device drivers that reside in the trusted, privileged, host operat- ing system or hypervisor As shown in Figure 2, in virtu- alized environments each VF can be directly assigned to a VM using device assignment, which allows each VM to directly access its corresponding VF, without hypervisor involvement on the I/O path Studies show that direct assignment of VFs provides virtual machines with nearly the same performance as direct assignment of physical devices (without SRIOV) while allowing the same level of scalability as software- based virtualization solutions such as device emulation or paravirtualization [33, 38, 41, 77]|,Non-data,150
| Furthermore, two VMs that share the same network device PF can com- municate efficiently since their VM-to-VM traffic can be switched in the network adapter Generally, SRIOV de- vices include embedded Ethernet switch functionality ca- pable of efficiently routing traffic between VFs, reducing the burden on the external switch The embedded switch in SRIOV capable devices is known as a Virtual Ethernet Bridge (VEB) [51] SRIOV provides virtual machines with I/O perfor- mance and scalability that is nearly the same as bare metal|,Non-data,150
| Without SRIOV, many use cases in cloud comput- ing, high-performance computing (HPC) and enterprise data centers would be infeasible With SRIOV it is pos- sible to virtualize HPC setups [24, 37] In fact, SRIOV is considered the key enabling technology for fully virtu- alized HPC clusters [54] Cloud service providers such as Amazon Elastic Compute Cloud (EC2) use SRIOV as the underlying technology in EC2 HPC services|,Non-data,150
| Their Cluster Compute-optimized virtual machines with high performance enhanced networking rely on SRIOV [2] SRIOV is important in traditional data centers as well Oracle, for example, created the Oracle Exalogic Elastic Cloud, an integrated hardware and software system for data centers Oracle Exalogic uses SRIOV technology to share the internal network [40]|,Non-data,150
| 3 Analyzing SRIOV Security Until recently, organizations designed and deployed Lo- cal Area Networks (LANs) with the assumption that each end-station in the LAN is connected to a dedicated port of an access switch, also known as an edge switch The edge switch applies the organization’s security policy to this dedicated port according to the level of trust of the end-station connected to the port: some machines and the ports they connect to are trusted and some are not But given a port and the machine connected to it, the switch enforcing security policy must know how trusted that port is With the introduction of virtualization technology, this assumption of a single level of trust per port no longer holds|,Non-data,150
| In virtualized environments, the host, which is of- ten a trusted entity, shares the same physical link with untrusted guest VMs When using hardware emulation or paravirtualized devices, the trusted host can intercept and control all guest I/O requests to enforce the relevant security policy Thus, from the point of view of the net- work, the host makes the port trusted again Hardware vendors such as Intel or Mellanox imple- ment strict VF management or configuration access to SRIOV devices|,Non-data,150
| Often they allow VFs driven by un- trusted entities to perform only a limited set of manage- ment or configuration operations In some implemen- tations, the VF performs no such operations; instead, it sends requests to perform them to the PF, which does so after first validating them On the data path, the situation is markedly different SRIOV’s raison d’ˆetre is to avoid host involvement on USENIX Association  24th USENIX Security Symposium 337 the data path|,Non-data,150
| Untrusted guests with directly assigned VFs perform data path operations—sending and receiv- ing network frames—directly against the device Since the device usually has a single link to the edge switch, the device aggregates all traffic, both from the trusted host and from the untrusted guests, and sends it on the single shared link As a result, untrusted guests can send any network frames to the edge switch Giving untrusted guests uncontrolled access to the edge switch has two implications|,Non-data,150
| First, since the edge switch uses its physical resources (CAM tables, queues, processing power) to process untrusted guests’ traffic, the switch becomes vulnerable to various denial of ser- vice attacks Second, sharing the same physical link be- tween trusted and untrusted entities exposes the network to many Ethernet data-link layer network attacks such as Address Resolution Protocol (ARP) poisoning, Media Access Control (MAC) flooding, ARP spoofing, MAC address spoofing, and Spanning Tree Protocol (STP) at- tacks [14, 17, 47, 56, 73, 75] Therefore, the edge switch must never trust ports connected to virtualized hosts with an SRIOV device Although the problem of uncontrolled access of un- trusted end-points is general to Ethernet networks, using SRIOV devices imposes additional limitations|,Non-data,150
| As we will see in the next few subsections, not trusting the port sometimes means giving up the required functionality 31 Traditional Lossy Ethernet Traditional Ethernet is a lossy protocol; it does not guar- antee that data injected into the network will reach its destination Data frames can be dropped for different reasons: because a frame arrived with errors or because a received frame was addressed to a different end-station|,Non-data,150
| But most data frame drops happen when the receiver’s buffers are full and the receiving end-station has no mem- ory available to store incoming data frames In the origi- nal design of the IEEE 8023 Ethernet standard, reliabil- ity was to be provided by upper-layer protocols, usually TCP [63], with traditional Ethernet networks providing best effort service and dropping frames whenever con- gestion occurs 3|,Non-data,150
|2 Flow Control in Traditional Ethernet Ethernet Flow Control (FC) was proposed to control con- gestion and create a lossless data link medium FC en- ables a receiving node to signal a sending node to tem- porarily stop data transmission According to the IEEE 8023x standard [6], this can be accomplished by sending a special Ethernet pause frame|,Non-data,150
| The IEEE 8023x pause link speed, Gbps 1 10 40 single frame pause time, ms 336 336 0|,Non-data,150
|85 frame rate required to stop transmission, frames/second 30 299 1193 Table 1: Pause frame rate for stopping traffic completely frame is defined in Annex 31B of the spec [9] and uses the MAC frame format to carry pause commands When a sender transmits data faster than the receiver can process it and the receiver runs out of space, the receiver sends the sender a MAC control frame with a pause request Upon receiving the pause frame, the sender stops transmitting data The pause frame includes information on how long to halt the transmission|,Non-data,150
| The pause time is a two byte MAC Control parameter in the pause frame that is mea- sured in units of pause quanta It can be between 0 to 65535 pause quanta The receiver can also tell the sender to resume transmission by sending a special pause frame with the pause time value set to 0 Each pause quanta equals 512 “bit times,” defined as the time required to eject one bit from the NIC (i|,Non-data,150
|e, 1 divided by the NIC speed) The maximal pause frame pause time value can be 65535 pause quanta, which is 65535× 512 = 336 million bit times|,Non-data,150
| one pause frame with pause time value 65535 pause quanta will tell the sender to stop transmitting for 336 million bit times, ie, 33|,Non-data,150
6 ms A sender operating at 10 Gbps speed will pause for 336 ms A sender operating at 40 Gbps speed will pause for 0,Non-data,150
|85 ms For 1Gbps networks, of Table 1 shows the rate at which a network device should receive pause frames to stop transmission com- pletely The pause time value of each frame is 0xFFFF Sending 30 pause frames per second will tell the sender to completely stop transmission on a 1Gbps link|,Non-data,150
| For a sender operating at 10 Gbps speed to stop transmission requires sending 299 frames/second For a sender operating at 40 Gbps speed to stop transmission requires sending 1193 frames/second 33 Priority Flow Control in Ethernet To improve the performance and reliability of Ethernet and make it more suitable for data centers, the IEEE 802|,Non-data,150
|1 working group proposed a new set of standards, known as Data Center Bridging (DCB) or Converged En- 338 24th USENIX Security Symposium  USENIX Association hanced Ethernet (CEE) In addition to the IEEE 8023x Ethernet pause, the new IEEE 8021Qbb standard proposed to make Ethernet truly “lossless” in data center environments by adding Priority-based Flow Control (PFC) [8]|,Non-data,150
| Similar to the 8023x FC, PFC is a link-level flow con- trol mechanism, but it is implemented on a per traffic- class basis While 8023x FC pauses all traffic on the link, PFC makes it possible to pause a specific class of traffic using the same pause frame structure|,Non-data,150
| PFC oper- ates on individual traffic classes, as defined by Annex I of the IEEE 8021Q standard [7] Up to 8 traffic classes can be defined for PFC per link 3|,Non-data,150
|4 Attacking VMs via Flow Control Direct device assignment enables malicious guests to attack the Ethernet network via well-known Layer 2 attacks [14, 17, 47, 56, 73, 75] Even when using virtualization-aware switching extensions such as the Virtual Edge Port Aggregator (VEPA) [30,31], all guests with direct access to the VFs of the same PF still share the same physical link to the edge switch, and the edge switch still allocates processing resources per link Since both 8023x and 802|,Non-data,150
|1Qbb perform flow control on a link-level basis, and the link is shared between VMs, any flow control manipulation by a single VM will affect the PF and all VFs associated with this PF This means that a malicious VM is capable of controlling the band- width and latency of all VMs that share the same adapter The malicious VM can pause all traffic on the link by sending 8023x pause frames and can stop a specific traf- fic class by sending 802|,Non-data,150
|1Qbb pause frames To stop all traffic on a 10 Gbps Ethernet link, an attacker needs to transmit pause frames at a rate of 300 frames/second, which is about 155 Kbps of bandwidth The attacker can fully control the bandwidth and latency of all tenant VMs with minimal required resources and without any coop- eration from the host or from other guest VMs 4 Attack Evaluation 4|,Non-data,150
|1 Experimental Setup We constructed a lab setup in which we perform and evaluate the flow-control attack described in the previous section We use a Dell PowerEdge R420 server, which is a dual socket with six cores per socket, with Intel Xeon E5-2420 CPUs running at 190GHz The chipset is the Intel C600 series|,Non-data,150
 The server includes 16GBs of mem- ory and an SRIOV-capable Intel NIC (10GbE 82599 or 1GbE I350) installed in PCIe generation 3 slots with two VFs enabled We use the KVM Hypervisor [50] and Ubuntu server 1310 with 311,Non-data,150
|0 x86 64 kernel for the host, guest VMs, and the client Each guest is created with 2GBs of mem- ory, two virtual CPUs, and one VF directly assigned to it Client and host machines are identical servers connected to the same dedicated switch, as shown in Figure 3 To achieve consistent results, the server’s BIOS profile is performance optimized, all power optimizations are tuned off, and Non-Uniform Memory Access (NUMA) is enabled|,Non-data,150
| The guest virtual CPUs are pinned to the cores on the same NUMA node to which the Intel PF is con- nected The host allocates to the guest memory from the same NUMA node as well For our 1GbE environment, we use an Intel Ethernet I350-T2 network interface connected to a Dell Power- Connect 6224P 1Gb Ethernet switch For our 10GbE environment, we use an Intel 82599 10 Gigabit TN net- work interface connected to an HP 5900AF 10Gb Ether- net switch|,Non-data,150
 Host and client use their distribution’s default drivers with default configuration settings Guest VMs use ver- sion 2142 of the ixgbevf driver for the Intel 10G 82599 Ethernet controller virtual function and the default igbvf version 2,Non-data,150
02-k for the Intel 1G I350 Ethernet controller virtual function Ethernet flow control IEEE 8023x is enabled on switch ports,Non-data,150
| We set the Ethernet Maximal Transfer Unit (MTU) to 1500 bytes on all Eth- ernet switches and network interfaces in our tests 42 Benchmark Methodology We conduct a performance evaluation according to the methodology in RFC 2544 [25] For throughput tests, we use an Ethernet frame size of 1518 bytes and measure maximal throughput without packet loss|,Non-data,150
| Each through- put test runs for at least 60 seconds and we take the aver- age of 5 test cycles To measure latency, we use 64 and 1024 byte messages Each latency test runs at least 120 seconds and we measure the average of at least 15 test cycles (While RFC 2544 dictates running 20 cycles, we obtained plausible results after 15 cycles; thus, we de- cided to reduce test runtime by running each test only 15 cycles|,Non-data,150
|) Benchmark Tools: We measure throughput and la- tency with two well-known network benchmark utilities: iperf [3] and netperf [45] We use the iperf TCP stream test to measure throughput and the netperf TCP RR test to measure latency The iperf and netperf clients are run on the client machine, while USENIX Association  24th USENIX Security Symposium 339 host SRIOV NIC VF1 Figure 3: Setup scheme the iperf and netperf servers are run on VM1 We measure on the client the bandwidth and latency from the client to VM1|,Non-data,150
| Traffic Generators: In addition to the traffic gener- ated by the benchmark tools, we use tcpdump [44] to capture traffic and tcpreplay [5] to send previously captured and modified frames at the desired rate Testbed Scheme: The testbed scheme is shown in Fig- ure 3 Our testbed consists of two identical servers, one acting as client and the other as the host with SRIOV ca- pable NIC We configure two VFs on the host’s SRIOV PF|,Non-data,150
 We assign VF1 to guest VM1 and VF2 to guest VM2 Client and host are connected to the same Ethernet switch We generate traffic between VM1 and the client using iperf and netperf VM2 is the attacking VM,Non-data,150
| 43 Flow-Control Attack Implementation it We use tcpreplay [5] to send specially crafted 8023x pause frames at the desired rate from the malicious VM21 When the switch receives a pause frame from VM2, inhibits transmission of any traffic on the link between the switch and the PF, including the traf- fic between the client and VM1, for a certain num- ber of pause time quanta|,Non-data,150
| Sending pause frames from VM2, we can manipulate the bandwidth and la- tency of the traffic between VM1 and the client The value of pause time of each pause frame is 0xFFFF pause quanta units Knowing the link speed, we can calculate the pause frame rate, as described in Section 3, and impose precise bandwidth limits and latency delays on VM1 The results of the attack in both 1GbE and 10GbE environments are presented in Section 4|,Non-data,150
|4 1 We use 8023x pause frames for the sake of simplicity, but we could have used PFC frames instead PFC uses exactly the same flow control mechanism and has the same MAC control frame format|,Non-data,150
 The only difference between PFC frames and pause frames is the addition of seven pause time fields in PFC that are padded in 8023x frames 44 Attack Results Figures 4 and 5 show the results of the pause frame at- tack on victim throughput in the 1GbE and 10GbE en- vironments respectively,Non-data,150
| Figures 4a and 5a show victim (VM1) throughput under periodic attack of VM2 Every 10 seconds, VM2 transmits pause frames for 10 seconds at 30 frames/second (as shown in Figure 4a) and at 300 frames/second (as shown in Figure 5a) In this test we measure the throughput of the victim system, VM1 The figures clearly show that VM2 can gain complete control over VM1 throughput: starting from the tenth second, the attacker completely stops traffic on the link for ten seconds|,Non-data,150
| Figure 6 shows the results of the pause frame attack on victim latency in the 10GbE environment Figure 6a shows victim latency under the same periodic attack de- scribed above In this test we use 64B and 1024B mes- sages For better result visualization, we lowered the at- tack rate to 150 pause frames/second|,Non-data,150
| Figure 6a shows that the attacker can increase victim latency to 250% by running the attack at a rate of only 150 frames/second Victim throughput Figures 4b and 5b display throughput of VM1 as a function of the rate of pause frames VM2 sends From Figure 4b we can see that VM2 can pause all traffic on the 1GbE link with al- most no effort, by sending pause frames at a rate of 30 frames/second For the 10GbE link, VM2 needs to work a little bit harder and raise its rate to 300 frames/second|,Non-data,150
| This test’s results confirm the calculations shown in Ta- ble 1 Figures 7a and 7b confirm that the measured vic- tim throughput is exactly as predicted In other words, it is easily and completely controlled by the attacker These tests show that a malicious VM can use the pause frame attack to control the throughput of other VMs with precision|,Non-data,150
| Furthermore, we see that the pause frame attack requires minimal effort from the attacker and will be hard to detect amid all the other network traffic To halt all transmissions on the 10GbE link, the attacker only needs to send 64B pause frames at 300 frames/second 300 frames/second is approximately 0002% of the 14|,Non-data,150
|88 million frames/second maximum frame rate for 10GbE2 Discovering such an attack can be quite challenging, due to the low frame rate involved, especially on a busy high-speed link such as 10GbE or 40GbE Victim latency Figure 6b shows the victim’s latency as a function of the attacker’s pause frame rate In this test we measure the latency of 64 byte messages and 1024 byte messages|,Non-data,150
| We see that the figures for both 64B 2 The maximum frame rate equals the link speed divided by the sum of sizes of the preamble, frame length and inter-frame gap 340 24th USENIX Security Symposium  USENIX Association 1000 800 600 400 200 0 r e d n u  t u p h g u o r h t  m i t c v i ] s / b M [  s k c a t t a  c d o i r e p  i 10 8 6 4 2 0 r e d n u  t u p h g u o r h t  m i t c v i ] s / b G [  s k c a t t a i  c d o i r e p   t u p h g u o r h t  m i t c v i ] s / b M [  1000 800 600 400 200 0  0  50  100  150  200  250  300 pause frames attacker sends each second [frames/second] (b)  0  10  20  30  40  50  60  70 time [seconds] (a) Figure 4: Pause frame attack: victim throughput in 1GbE environment t u p h g u o r h t  m i t c v i ] s / b G [  10 8 6 4 2 0  0  100  200  300 pause frames attacker sends each second [frames/second] (b)  10  20  30  40  50  60  70 time [seconds] (a) Figure 5: Pause frame attack: victim throughput in 10GbE environment r e d n u  y c n e t a l  m i t c v i ] s μ [  k c a t t a i  c d o i r e p   250  200  150  100  50 ] s μ [  y c n e t a l  m i t c v i  2000  1500  1000  500  0  0 message size 64B 1024B  50  100  150  200  250  300 pause frames attacker sends each second [frames/second] (b)  0  20  40  60  80  100  120 time [seconds] (a) Figure 6: Pause frame attack: victim latency in 10GbE environment and 1024B are barely distinguishable and almost con- verge; the latency is the same for small and large size messages under attack In Figure 7c we see that measured latency and ex- pected latency differ somewhat In practice, this differ- ence means that an attacker can control the victim’s la- tency with slightly less precision than it can control its throughput, but it can still control both with high preci- sion and relatively little effort|,Non-data,150
| In back-to-back configuration, without a switch, la- tency behaves as expected We believe this difference is caused by the switch’s internal buffering methods— in addition to storing frames internally, the Ethernet switch prevents the possible side effects of such buffering eg, head-of-line blocking [70] and congestion spread- ing [13]|,Non-data,150
| To accurately explain this phenomenon, we need access to the switch internals; unfortunately, the Ethernet switch uses proprietary closed software and hardware Experiments with Non-Intel Devices We performed an identical experiment on same setup with an SRIOV Broadcom NetXtreme II BCM57810 10GbE NIC [26] and got the same results Our attack is valid for this NIC as well USENIX Association  24th USENIX Security Symposium 341 1000 800 600 400 200 ] s / b M [  t u p h g u o r h t  d e r u s a e m  0 200 400 600 800 1000 expected throughput [Mb/s] (a) 10 8 6 4 2 0 t u p h g u o r h t  d e r u s a e m ] s / b G [  0  2  4  6  8  10 expected throughput [Gb/s] (b) 2000 1500 1000 500 0 ] s μ [  y c n e t a l  d e r u s a e m message size 64B 1024B  0  500 1000 1500 2000 expected latency [μs] (c) Figure 7: Pause frame attack: expected vs|,Non-data,150
| measured throughput and latency We also tried the attack described above on another vendor’s 40GbE SRIOV adapter Whenever the attack- ing VM transmitted MAC control frames (pause frames) through its VF, the adapter completely locked up and be- came unresponsive It stopped generating both transmit and receive interrupts, and required manual intervention to reset it, by reloading the PF driver on the host This lockup appears to be a firmware issue and has been com- municated to the adapter vendor|,Non-data,150
| Clearly, with this adapter and this firmware issue, a malicious VM could trivially perform a straightforward denial of service attack against its peer VMs that use this adapter’s VFs and against the host But since this attack is trivial to discover, we focus instead on the stealthier pause frame attack, which is much harder to discover and protect against 5 Attack Ramifications The consequences of the attack are substantial If Eth- ernet flow control is enabled on the SRIOV device, the host’s VMs’ security is compromised and the VM’s are susceptible to the attack|,Non-data,150
| The attack cannot be prevented using the filtering ca- pabilities of currently available SRIOV Ethernet devices due to their minimal filtering capability At best, mod- ern SRIOV NICs are capable of enforcing anti-spoofing checks based on the source MAC address or VLAN tag of the VM, to prevent one VM from pretending to be another In the attack we describe, the adversary gener- ates flow control frames with the malicious VM’s source MAC and VLAN tag, so anti-spoofing features cannot block the attack Since the attack cannot be prevented with current NICs and switches, cloud providers must either be con- tent with flawed security and fully trust the guest VMs or disable the Ethernet flow control in their networks|,Non-data,150
| Nei- ther option is palatable The former is unrealistic for the public cloud and unlikely be acceptable to private cloud providers The latter means giving up the performance benefits of lossless Ethernet, increasing overall resource utilization, and reducing performance We discuss in greater detail the performance advantages that Ethernet flow control provides in Section 8|,Non-data,150
| 6 Improving SRIOV Security The attack described in the previous sections is the result of a fundamental limitation of SRIOV: from the network point of view, VFs and their associated untrusted VMs are all lumped together into a single end-station To se- cure SRIOV and eliminate the attack while keeping flow control functionality, we propose to extend SRIOV Eth- ernet NIC filtering capability to filter traffic transmitted by VFs, not only on the basis of source MAC and VLAN tags—the method currently employed by anti-spoofing features—but also on the basis of the MAC destination and Ethernet type fields of the frame This filtering can- not be done by the host without some loss of perfor- mance [39] and has to be done before traffic hits the edge switch Hence it must be done internally in the SRIOV NIC|,Non-data,150
| We built a software-based prototype of an SRIOV Ethernet NIC with pause frame filtering Before present- ing the prototype, we begin by describing the internals of an SRIOV NIC 61 SRIOV NIC Internals Figure 8a shows a detailed schema of an SRIOV Ether- net NIC|,Non-data,150
| The SRIOV device is connected to the external adjacent Ethernet switch on the bottom side and to the host’s PCIe bus, internal to the host, on the top side Switching The NIC stores frames it receives from the external switch in its internal buffer The size of this buffer is on the order of hundreds of KBytes, depending on the NIC model: 144KB in Intel I350 [43] and 512KB in Intel 82599 [42] After receiving a packet, the SRIOV NIC looks up the frame’s MAC in its MAC address table, 342 24th USENIX Security Symposium  USENIX Association finds the destination VF according to the frame’s desti- nation MAC address, and copies the frame (using DMA) over the PCIe bus to the VF’s buffer ring, which is allo- cated in the host’s RAM|,Non-data,150
| This is analogous to a standard Ethernet switch that receives a packet on an ingress port, looks up its MAC address, and chooses the right egress port to send it to The data path of the frame is marked with a red dashed line in Figure 8a In addition, SRIOV NIC is able to perform VM-to-VM switching internally, without sending the frames to the external switch Internal Buffer When Ethernet flow control is en- abled, the SRIOV NIC starts monitoring its internal buffer|,Non-data,150
| If the NIC cannot process received frames fast enough, for example due to an overloaded or slow PCIe link, the buffer fills up Once it reaches a predefined threshold, the SRIOV NIC generates and sends pause frames to the external Ethernet switch The switch then holds transmissions to the NIC for the requested time, storing these frames in its own internal buffers While the switch is buffering frames, the NIC should continue copying the frames it buffered into the each VF’s ring buffer, clearing up space in its internal buffer|,Non-data,150
| Ring Buffer The final destination for a received frame is in its VF’s ring buffer, located in host RAM The net- work stack in the VM driving the VF removes frames from its ring buffers at a rate that is limited by the CPU If the VM does not get enough CPU cycles or is not ef- ficient enough, the NIC may queue frames to the ring buffer faster than the VM can process them When the ring buffer fills up, most Ethernet NICs (e|,Non-data,150
|g, those of In- tel’s and Mellanox’s) will simply drop incoming frames Less commonly, a few NICs, such as Broadcom’s NetX- treme II BCM57810 10GbE, can monitor each VF’s ring buffer When the ring buffer is exhausted, the NIC can send pause frames to the external switch to give the host CPU a chance to catch up with the sender|,Non-data,150
| When avail- able, this functionality is usually disabled by default Outbound Security Some SRIOV Ethernet NICs (eg, Intel 82599 10GbE [42] or I350 1GbE [43] NICs) include anti-spoofing functionality|,Non-data,150
| They can verify that the source MAC address and/or VLAN tag of each frame transmitted by the VF belongs to the transmitting VF To this end, these NICs have an internal component that can inspect and even change frames transmitted from the VF In addition, Intel SRIOV NICs have advanced in- bound filtering capabilities, storm control, rate limiting, and port mirroring features, very much like any standard Ethernet switch As we can see, Ethernet SRIOV devices implement on-board a limited form of Ethernet switching|,Non-data,150
| That is why such devices are also known as virtual Ethernet bridges (VEBs) 62 The VANFC design The key requirement from VANFC is to filter outbound traffic transmitted by a VF Ideally, VANFC would be implemented in a production SRIOV NIC|,Non-data,150
| Unfortu- nately, all tested SRIOV NICs are proprietary with closed firmware Furthermore, most frame processing logic is implemented in high speed ASIC hardware We opted instead to build VANFC as a software-based prototype of an SRIOV NIC that filters outbound traffic VANFC takes advantage of the following two observa- tions: (1) VEB embedded into the SRIOV NIC device replicates standard Ethernet switching behavior and can be considered as a virtual Ethernet switch; (2) all valid pause frames are generated by the NIC’s hardware and have the PF’s source MAC address, whereas invalid— malicious—pause frames are sent with source address of a VF|,Non-data,150
| Should the adversary VM attempt to generate pause frames with the PF’s source MAC address, the NIC’s anti-spoofing will find and drop these frames In order to filter transmitted malicious pause frames, we first need to identify pause frames In such frames the Ethernet type field is 0x8808 (MAC con- trol type), the MAC opcode field is 0x0001 (pause opcode), and the destination MAC address is multi- cast 01-80-C2-00-00-01 For any such packet, the VANFC filter should drop the frame if the source MAC is different than the PF’s MAC address|,Non-data,150
| As mentioned previously, most SRIOV NICs already have a component that can filter outbound traffic; this component is a part of the SRIOV device’s internal Eth- ernet switch and cannot be modified Our prototype ex- tends this switch in software by running the extension on the wire between the SRIOV NIC and the external switch Filtering Component For our Ethernet filtering de- vice we use the standard Linux bridge configured on an x86-based commodity server running Ubuntu server 1310 and equipped with two Intel 82599 10 Gigabit TN Network controllers installed in PCIe gen 2 slots|,Non-data,150
| One NIC is connected to the host PF and the other is con- nected to the external Ethernet switch, as displayed in Figure 8b Ethernet switching is performed by the Linux bridge [4] and filtering is done by the ebtables [32] Performance model Bridge hardware is fast enough not to be a bottleneck for 10Gb Ethernet speed How- ever, by adding to the setup an Ethernet device imple- mented in software, we increased latency by a constant delay of approximately 55μs|,Non-data,150
 An eventual implementa- USENIX Association  24th USENIX Security Symposium 343 (a) (b) Figure 8: Fig (a) shows schema of current SRIOV NIC internals; Fig (b) shows VANFC schema tion of VANFC in hardware will eliminate this overhead; we therefore discount it in latency oriented performance tests,Non-data,150
| We wanted to make this bridge completely transparent and not to interfere with passing traffic: the host should keep communicating with the external switch and the switch should keep communicating with the host as in the original setup without VANFC VANFC should change neither the SRIOV software/hardware interface nor the Ethernet flow control protocol To ensure this, we made a few modifications in Linux bridge code and in the Intel 82599 device driver used by the bridge device Bridge Modification The standard Ethernet bridge should not forward MAC control frames that are used to carry pause commands since MAC control frames are designed to be processed by Ethernet devices|,Non-data,150
| Since we want the bridge to deliver all of the traffic be- tween the SRIOV device and the external switch, in- cluding the pause frames sent by the PF, we modify the Linux bridging code to forward MAC control frames and use ebtables to filter pause frames not sent from the PF Our experiments use a static configuration for ebtables and for the Linux bridge Device Driver Modification We use a modified ixgbe driver version 321|,Non-data,150
|2 for Intel 10G 82599 net- work controllers on the bridge machine According to the Intel 82599 controller data-sheet [42], the flow con- trol mechanism of the device receives pause frames when flow control is enabled; otherwise the device silently drops pause frames In our setup, we disable the flow control feature of Intel NICs installed in the bridge ma- chine and we configure them to forward pause frames up to the OS, where they should be processed by the bridge and ebtables We do this by enabling the Pass MAC Control Frames (PMCF) bit of the MAC Flow Control (MFLCN) register, as described in section 3|,Non-data,150
|772 of the Intel 82599 data-sheet [42] Ring Buffer Exhaustion As mentioned, some SRIOV devices are capable of monitoring a VF’s ring buffer and automatically generating pause frames when it is ex- hausted|,Non-data,150
| In such a scenario, pause frames will be gen- erated with the source MAC address of the PF and will not be recognized by the VANFC We argue that such pause frame generation should be disabled in any SRIOV based setup, regardless of whether the VMs are trusted Since the VM fully controls the VF’s ring buffer, a ma- licious VM can modify its software stack (eg|,Non-data,150
|, the VF device driver) to manipulate the ring buffer so that the SRIOV device monitoring the ring buffer will generate pause frames on the VM’s behalf Such pause frames will reach the external switch, which will stop its trans- missions to the host and other VMs, leaving us with the same attack vector Automatic generation of pause frames on VF ring buffer exhaustion is problematic even if all VMs are trusted Consider, for example, a VM that does not have enough CPU resources to process all incoming traffic and exhausts the VF’s ring buffer|,Non-data,150
| Sending pause frames to the switch may help this VM process the buffer but will halt the traffic to other VMs Thus, to keep the SRIOV device secure, an SRIOV NIC should not automatically send pause frames when the VF’s ring buffer is exhausted regardless of whether the VM is trusted Nevertheless, monitoring VF ring buffers can be use- 344 24th USENIX Security Symposium  USENIX Association ful for keeping the Ethernet network lossless and avoid- ing dropped frames We propose that the SRIOV device monitor ring buffers, but instead of automatically gener- ating pause frames on ring buffer exhaustion, it should notify the hypervisor|,Non-data,150
| The hypervisor, unlike the device, could then carefully consider whether the VM is mali- cious or simply slow If the VM is simply slow, the hy- pervisor could give it a scheduling boost or assign more CPU resources to it, thereby giving it a chance to process its ring buffer before it fills up We plan to explore this avenue in future work 7 Evaluating VANFC We evaluate VANFC in several scenarios|,Non-data,150
| The base- line scenario includes an unprotected system, as shown in Figure 3, and no attack is performed during the test In this scenario we measure the system’s baseline through- put and latency The baseline system under attack in- cludes the same unprotected system but here VM2 runs the attack during the test, sending pause frames at a con- stant rate of 150 frames/sec In this scenario we measure the effectiveness of the attack on an unprotected system|,Non-data,150
| In the protected system scenario, VANFC, shown in Figure 8b, replaces the unprotected system In this scenario VM2 does not perform any attack during the test We use this scenario to measure the performance overhead introduced by VANFC compared to the base- line In the protected system under attack scenario, we also use VANFC, but here the attacker VM2 sends pause frames at a constant rate of 150 frames/sec|,Non-data,150
| In this sce- nario we verify that VANFC indeed overcomes the attack We perform all tests on the 10GbE network with the same environment, equipment, and methodology as de- scribed in Section 41 As explained in Section 6|,Non-data,150
|2, to filter malicious pause frames, our solution uses a software-based filtering de- vice, which adds constant latency of 55μs A produc- tion solution would filter these frames in hardware, ob- viating this constant latency overhead of software-based model Thus, in latency-oriented performance tests of the VANFC, we reduced 55μs from the results Evaluation Tests To evaluate the performance of the described scenarios, we test throughput and latency using iperf and netperf, as previously described|,Non-data,150
| In addition, we configure the apache2 [34] web server on VM1 to serve two files, one sized 1KB and one sized 1MB We use apache2 version 246 installed from the Ubuntu repository with the default configura- tion|,Non-data,150
| We run the ab [1] benchmark tool from the client to test the performance of the web server on VM1 VM1 also runs memcached [35] server version installed from the Ubuntu repository with 1414, the default configuration file|,Non-data,150
| On the client we run the memslap [78] benchmark tool, part of the libmemcached client library, to measure the perfor- mance of the memcached server on VM1 Figure 9 displays normalized results of the performed tests We group test results into two categories: through- put oriented and latency oriented Throughput oriented tests are iperf running pure TCP stream and apache2 serving a 1MB file|,Non-data,150
| These tests are limited by the 10GbE link bandwidth During the tests, the client and server CPUs are almost idle From Figure 9 we conclude that VANFC completely blocks VM2’s attack and introduces no performance penalty 8 Necessity of Flow Control One can argue that flow control is not required for proper functionality of high level protocols such as TCP|,Non-data,150
| It then follows from this argument that SRIOV can be made “se- cure” simply by disabling flow control The TCP protocol does provide its own flow control mechanism However, many studies have shown that TCP’s main disadvantage is high CPU utilization [28,36, 46, 55, 66] Relying on TCP alone for flow control leads to increased resource utilization|,Non-data,150
| In public cloud environments, users pay for computa- tional resources Higher CPU utilization results in higher charges In enterprise data centers and high-performance computing setups, resource consumption matters as well Ultimately, someone pays for it|,Non-data,150
| In clouds, especially, effective resource utilization will become increasingly more important [12] Certain traffic patterns that use the TCP protocol in high-bandwidth low-latency data center environments may suffer from catastrophic TCP throughput collapse, a phenomenon also known as the incast problem [58] This problem occurs when many senders simultaneously transmit data to a single receiver, overflowing the net- work buffers of the Ethernet switches and the receiver, thus causing significant packet loss Studies show that Ethernet flow control functionality, together with con- gestion control protocol, can mitigate the incast problem, thus improving the TCP performance [27, 62]|,Non-data,150
| As part of a recent effort to converge current net- work infrastructures, many existing protocols were im- plemented over Ethernet, eg, Remote DMA over Con- verged Ethernet (RoCE) [19] RoCE significantly re- duces CPU utilization when compared with TCP|,Non-data,150
 USENIX Association  24th USENIX Security Symposium 345 baseline system baseline system under attack protected system protected system under attack  1  08  06  04  0,Non-data,150
|2  0 t u p h g u o r h t  d e z i l a m r o n ] m e t s y s  e n i l e s a b   o t  e v i t l a e r [ iperf stream [Mb/s] apache 1MB [req/s] netperf RR 64B [packets/s] netperf RR 1024B [packets/s] memcached [req/s] apache 1KB [req/s] throughput oriented      latency oriented     Figure 9: VANFC performance evaluation results ] s / b G [  t e a r  r e f s n a r t 5 4 3 2 1 0  1 2 4 8 16 32 64 128 256 512 1K 2K 4K 8K 16K32K ] s / b G [  e t a r  r e f s n a r t 5 4 3 2 1 0 transmit queue depth 1 2 4 8 16 32 64 128 256  1 2 4 8 16 32 64 128 256 5121K 2K 4K 8K 16K32K message size [KB] (a) message size [KB] (b) Figure 10: Performance of a single RoCE flow in the system with two competing RoCE flows Graph (a) shows performance with enabled flow control; graph (b) shows performance with disabled flow control A few recent studies that evaluate performance of dif- ferent data transfer protocols over high speed links have been published [48, 49, 67, 72] Kissel et al|,Non-data,150
| [49] com- pare TCP and RoCE transfers over 40GbE links using the same application they developed for benchmarking Using TCP, they managed to reach a speed of 22Gbps while the sender’s CPU load was 100% and the receiver’s CPU load was 91% With OS-level optimizations, they managed to reach a speed of 395 Gbps and reduce the sender’s CPU load to 43%|,Non-data,150
| Using the RoCE protocol, they managed to reach 392 Gbps while the CPU load of the receiver and sender was less than 2%! These results clearly show that RoCE significantly reduces CPU uti- lization and thus the overall cost of carrying out compu- tations It is especially important when a large amount of data is being moved between computational nodes in HPC or data center environments, where virtualiza- tion is becoming prevalent and increasing in popular- ity [24, 37, 54] Studies show that RoCE cannot function properly without flow control [48, 49, 67, 72]|,Non-data,150
| Figure 10, taken from Kissel et al [49], with the authors’ explicit permis- sion, shows the performance effect of flow control on two competing data transfers using the RoCE protocol Fig- ure 10a shows the performance of a single RoCE data transfer while another RoCE data transfer is competing with it for bandwidth and flow control is enabled Both transfers effectively share link bandwidth|,Non-data,150
| Figure 10b shows the performance of the same RoCE data transfer when flow control is disabled As can be seen in the fig- ure, without flow control the RoCE data transfer suffers, achieving a fraction of the performance shown in Fig- ure 10a We have also independently reproduced and verified these results Kissel et al|,Non-data,150
| also show [49] that the same problem is relevant not only to RoCE but can be generalized to TCP as well Thus we conclude that disabling flow control would cause less effective resource utilization and lead to higher cost for cloud customers and for any organization deploying SRIOV Conversely, securing SRIOV against flow control attacks would make it possible for SRIOV and flow control to coexist, providing the performance 346 24th USENIX Security Symposium  USENIX Association benefits of both without relinquishing security 9 Discussion Notes on Implementation VANFC can be implemented as part of an SRIOV device already equipped with an embedded Ethernet switch or it can be implemented in the edge Ethernet switch, by programming the edge switch to filter flow control frames from VFs’ MAC ad- dresses|,Non-data,150
| Adding VANFC functionality to the NIC requires less manufacturing effort; it is also more convenient and cheaper to replace a single NIC on a host than to replace an edge switch Nevertheless, in large-scale virtualiza- tion deployments, such as those of cloud providers or corporate virtual server farms, a single 10GbE Ethernet switch with high port density (for example, the 48 port HP 5900AF 10Gb Ethernet switch in our testbed) serves many host servers with SRIOV capable devices In such scenarios, upgrading 48 SRIOV devices connected to the 48 port switch requires considerably more resources than single switch upgrade Having said that, we argue that proper implementation of the solution to the described problem is in the SRIOV NIC and not in the edge Ethernet switch|,Non-data,150
| The problem we discuss is strictly related to the virtualization plat- form and caused by a design flaw in the SRIOV NIC’s internal switching implementation Mitigating the prob- lem in the edge switch, an external device whose purpose is not handle virtualization problems of the host, would force the edge switch to learn about each VF’s MAC ad- dress and to distinguish PFs from VFs, coupling the edge switch too closely with the NICs VEB and VEPA Another important security aspect of SRIOV is VM-to-VM traffic In SRIOV devices with an embedded VEB switch, VM-to-VM traffic does not leave the host network device and is not visible to the external edge switch, which enforces the security policy on the edge of the network|,Non-data,150
| To make all VM traffic visible to the external switch, the VEB switch should act as a VEPA and send all VM traffic to the adjacent switch A properly configured Ethernet switch and the use of a VEPA device can enforce a security policy (ACL, port security) on malicious VM traffic and prevent most L2 attacks However, while VEPA solves many manage- ability and security issues that pertain to switching in virtualized environments [29], it does not address the flow control attack we presented earlier This is because VEPA still shares the same single link between multi- ple untrusted guests and the host and does not manage flow control per VF|,Non-data,150
| Besides not solving the flow control attack, it uses, again, the edge Ethernet switch, which is external to the source of the problem–SRIOV NIC Thus, a VEPA extension should not be considered for the so- lution and the problem should be solved in the SRIOV NIC 10 Related Work Several recent works discussed the security of self- virtualizing devices P ́ek et al|,Non-data,150
| [61] described a wide range of attacks on host and tenant VMs using directly assigned devices They performed successful attacks on PCI/PCIe configuration space, on memory mapped I/O, and by injecting interrupts They also described an NMI injection attack Most of the attacks they discussed can be blocked by a fix in the hypervisor or by proper hard- ware configuration|,Non-data,150
| Richter et al [68] showed how a malicious VM with a directly attached VF can perform DoS attacks on other VMs that share the same PCIe link by overloading its own Memory Mapped I/O (MMIO) resources and flood- ing the PCIe link with write request packets As the au- thors mention, this attack can be mitigated by using the QoS mechanisms defined by the PCIe standard [59] All of the attacks discussed in the aforementioned pa- pers are based on weak security implementations of soft- ware (e|,Non-data,150
|g, a hypervisor) or hardware (a chipset system error reporting mechanism) that are internal to the host Our attack exploits different design aspects of SRIOV devices: it targets the interoperability of SRIOV devices with software and hardware external to the host There are ongoing efforts of the Data Center Bridging Task Group, which is a part of the IEEE 802|,Non-data,150
|1 Working Group, to standardize configuration, management and communication of virtual stations connected to the adja- cent bridge The working group proposed the 8021Qbg Edge Virtual Bridging [10] and 8021BR Bridge Port Extension [11] standards|,Non-data,150
| Both standards concentrate on configuration and management of the bridge services for virtual stations, leaving the flow control of virtual stations out of their scope To the best of our knowl- edge, our work is the first to present the problem of self- virtualizing devices in converged enhanced Ethernet en- vironments with flow control, and the first to suggest a solution for it 11 Conclusions and Future Work Self-virtualizing devices with SRIOV lie at the founda- tion of modern enterprise data centers, cloud comput- ing, and high-performance computing setups We have USENIX Association  24th USENIX Security Symposium 347 shown that SRIOV, as currently deployed on current Eth- ernet networks, is incompatible with required function- ality such as flow control|,Non-data,150
| This is because flow control relies on the assumption that each endpoint is trusted, whereas with SRIOV, each network endpoint is com- prised of multiple, possibly untrusted, virtual machines We show how to overcome this flaw by teaching the NIC about virtual functions We present the prototype of such a system, VANFC, and its evaluation Our prototype is 100% effective in securing SRIOV against this flaw while imposing no overhead on throughput or latency- oriented workloads|,Non-data,150
| Future work includes continuing to investigate the security of SRIOV devices; extending our work from Ethernet to other networking technologies such as In- finiBand and Fiber Channel; looking at the security of direct-assigned self-virtualizing devices other than NICs, such as high-end NVMe SSDs and GPGPUs; develop- ing VF co-residency detection techniques; and using the hypervisor to solve the problem of VM ring buffer ex- haustion Handling this with software without losing per- formance will be challenging On VANFC specifically, we plan to continue our evaluation and to explore what an eventual hardware-based implementation would look like Acknowledgments We would like to thank the anonymous reviewers, our shepherd, Srdjan Capkun, Shachar Raindel from Mel- lanox, David H|,Non-data,150
| Lorenz and Ilya Lesokhin from Tech- nion, and Sharon Kessler for insightful comments This research was supported, in part, by the Ministry of Sci- ence and Technology, Israel, grant #3-9609 Any opin- ions, findings, and conclusions in this paper are those of the authors only and do not necessarily reflect the views of our sponsors |,Non-data,150
|Abstract We describe a largely automated and systematic analysis of TLS implementations by what we call ‘protocol state fuzzing’: we use state machine learning to infer state ma- chines from protocol implementations, using only black- box testing, and then inspect the inferred state machines to look for spurious behaviour which might be an indica- tion of flaws in the program logic For detecting the pres- ence of spurious behaviour the approach is almost fully automatic: we automatically obtain state machines and any spurious behaviour is then trivial to see Detecting whether the spurious behaviour introduces exploitable security weaknesses does require manual investigation Still, we take the point of view that any spurious func- tionality in a security protocol implementation is danger- ous and should be removed|,Non-data,151
| We analysed both server- and client-side implemen- tations with a test harness that supports several key ex- change algorithms and the option of client certificate au- thentication We show that this approach can catch an interesting class of implementation flaws that is appar- ently common in security protocol implementations: in three of the TLS implementations analysed new security flaws were found (in GnuTLS, the Java Secure Socket Extension, and OpenSSL) This shows that protocol state fuzzing is a useful technique to systematically analyse security protocol implementations As our analysis of different TLS implementations resulted in different and unique state machines for each one, the technique can also be used for fingerprinting TLS implementations|,Non-data,151
| 1 Introduction TLS, short for Transport Layer Security, is widely used to secure network connections, for example in HTTPS Being one of the most widely used security protocols, TLS has been the subject of a lot of research and many issues have been identified These range from crypto- graphic attacks (such as problems when using RC4 [4]) to serious implementation bugs (such as Heartbleed [13]) and timing attacks (for example, Lucky Thirteen and variations of the Bleichenbacher attack [3, 30, 9]) To describe TLS, or protocols in general, a state ma- chine can be used to specify possible sequences of mes- sages that can be sent and received|,Non-data,151
| Using automated learning techniques, it is possible to automatically ex- tract these state machines from protocol implementa- tions, relying only on black-box testing In essence, this involves fuzzing different sequences of messages, which is why we call this approach protocol state fuzzing By analysing these state machines, logical flaws in the protocol flow can be discovered An example of such a flaw is accepting and processing a message to per- form some security-sensitive action before authentica- tion takes place|,Non-data,151
| The analysis of the state machines can be done by hand or using a model checker; for the anal- yses discussed in this paper we simply relied on manual analysis Both approaches require knowledge of the pro- tocol to interpret the results or specify the requirements However, in security protocols, every superfluous state or transition is undesirable and a reason for closer inspec- tion The presence of such superfluous states or transi- tions is typically easy to spot visually|,Non-data,151
| 11 Related work on TLS Various formal methods have been used to analyse dif- ferent parts and properties of the TLS protocol [33, 16, 22, 32, 20, 31, 26, 24, 28] However, these analyses look at abstract descriptions of TLS, not actual implementa- tions, and in practice many security problems with TLS have been due to mistakes in implementation [29] To bridge the gap between the specification and implemen- tation, formally verified TLS implementations have been proposed [7, 8]|,Non-data,151
| Existing tools to analyse TLS implementations mainly focus on fuzzing of individual messages, in particular the USENIX Association  24th USENIX Security Symposium 193 certificates that are used These certificates have been the source of numerous security problems in the past An automated approach to test for vulnerabilities in the processing of certificates is using Frankencerts as pro- posed by Brubaker et al [10] or using the tool x509test1|,Non-data,151
| Fuzzing of individual messages is orthogonal to the tech- nique we propose as it targets different parts or aspects of the code However, the results of our analysis could be used to guide fuzzing of messages by indicating proto- col states that might be interesting places to start fuzzing messages Another category of tools analyses implementations by looking at the particular configuration that is used Examples of this are the SSL Server Test2 and sslmap3|,Non-data,151
| Finally, closely related research on the implementation of state machines for TLS was done by Beurdouche et al [6] We compare their work with ours in Section 5 1|,Non-data,151
|2 Related work on state machine learn- ing When learning state machines, we can distinguish be- tween a passive and active approach In passive learning, only existing data is used and based on this a model is constructed For example, in [14] passive learning tech- niques are used on observed network traffic to infer a state machine of the protocol used by a botnet This approach has been combined with the automated learn- ing of message formats in [23], which then also used the model obtained as a basis for fuzz-testing|,Non-data,151
| When using active automated learning techniques, as done in this paper, an implementation is actively queried by the learning algorithm and based on the responses a model is constructed We have used this approach before to analyse implementations of security protocols in EMV bank cards [1] and handheld readers for online banking [11], and colleagues have used it to analyse electronic passports [2] These investigations did not reveal new security vulnerabilities, but they did provide interesting insights in the implementations analysed In particular, it showed a lot of variation in implementations of bank cards [1] – even cards implementing the same Master- Card standard – and a known attack was confirmed for the online banking device and confirmed to be fixed in a new version [11]|,Non-data,151
 13 Overview We first discuss the TLS protocol in more detail in Sec- tion 2 Next we present our setup for the automated learning in Section 3 The results of our analysis of nine 1https://github,Non-data,151
com/yymax/x509test 2https://wwwssllabscom/ssltest/ 3https://wwwthesprawl,Non-data,151
|org/projects/sslmap/ TLS implementations are subsequently discussed in Sec- tion 4, after which we conclude in Section 5 2 The TLS protocol The TLS protocol was originally known as SSL (Secure Socket Layer), which was developed at Netscape SSL 10 was never released and version 2|,Non-data,151
|0 contained numer- ous security flaws [37] This lead to the development of SSL 30, on which all later versions are based After SSL 3|,Non-data,151
|0, the name was changed to TLS and currently three versions are published: 10, 11 and 12 [17, 18, 19]|,Non-data,151
| The specifications for these versions are published in RFCs issued by the Internet Engineering Task Force (IETF) To establish a secure connection, different subproto- cols are used within TLS: • The Handshake protocol is used to establish session keys and parameters and to optionally authenticate the server and/or client • The ChangeCipherSpec protocol – consisting of only one message – is used to indicate the start of the use of established session keys • To indicate errors or notifications, the Alert protocol is used to send the level of the alert (either warning or fatal) and a one byte description|,Non-data,151
| In Fig 1 a normal flow for a TLS session is given In the ClientHello message, the client indicates the desired TLS version, supported cipher suites and optional exten- sions A cipher suite is a combination of algorithms used for the key exchange, encryption, and MAC computa- tion|,Non-data,151
