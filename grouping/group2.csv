 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| Hence we used the M-test to detect dependencies between keystream bytes To determine which values are biased between dependent bytes, we perform proportion tests over all value pairs We reject the null hypothesis only if the p-value is lower than 10−4 Holm’s method is used to control the family-wise error rate when performing multiple hypoth- esis tests|,Non-data,143
| This controls the probability of even a single false positive over all hypothesis tests We always use the two-sided variant of an hypothesis test, since a bias can be either positive or negative Simply giving or plotting the probability of two depen- dent bytes is not ideal After all, this probability includes the single-byte biases, while we only want to report the strength of the dependency between both bytes|,Non-data,143
| To solve this, we report the absolute relative bias compared to the expected single-byte based probability More precisely, say that by multiplying the two single-byte probabilities of a pair, we would expect it to occur with probability p Given that this pair actually occurs with probability s, we then plot the value ||q|| from the formula s = p· (1 +q) In a sense the relative bias indicates how much information is gained by not just considering the single-byte biases, but using the real byte-pair probability|,Non-data,143
| 32 Generating Datasets In order to generate detailed statistics of keystream bytes, we created a distributed setup We used roughly 80 stan- dard desktop computers and three powerful servers as workers The generation of the statistics is done in C|,Non-data,143
| Python was used to manage the generated datasets and control all workers On start-up each worker generates a cryptographically random AES key Random 128-bit RC4 keys are derived from this key using AES in counter mode Finally, we used R for all statistical analysis [34]|,Non-data,143
| Our main results are based on two datasets, called first16 and consec512 The first16 dataset esti- mates Pr[Za = x∧ Zb = y] for 1 ≤ a ≤ 16, 1 ≤ b ≤ 256, and 0 ≤ x,y < 256 using 244 keys Its generation took 100 24th USENIX Security Symposium  USENIX Association 4 2−65 2−7 s a b i   (0,  0) (0,  1) (0,i+1) ( i+1,255) (255, i+1) (255, i+2) (255,255) e v i t l a e r  2−7|,Non-data,143
|5 l t e u o s b A 2−8 2−85 1 32 64 96 128 160 192 224 256 288 Digraph position Figure 4: Absolute relative bias of several Fluhrer- McGrew digraphs in the initial keystream bytes, com- pared to their expected single-byte based probability roughly 9 CPU years This allows detecting biases be- tween the first 16 bytes and the other initial 256 bytes|,Non-data,143
| The consec512 dataset estimates Pr[Zr = x∧ Zr+1 = y] for 1 ≤ r ≤ 512 and 0 ≤ x,y < 256 using 245 keys, which took 16 CPU years to generate It allows a detailed study of consecutive keystream bytes up to position 512 We optimized the generation of both datasets The first optimization is that one run of a worker generates at most 230 keystreams|,Non-data,143
| This allows usage of 16-bit inte- gers for all counters collecting the statistics, even in the presence of significant biases Only when combining the results of workers are larger integers required This low- ers memory usage, reducing cache misses To further re- duce cache misses we generate several keystreams before updating the counters|,Non-data,143
| In independent work, Paterson et al used similar optimizations [30] For the first16 dataset we used an additional optimization Here we first generate several keystreams, and then update the coun- ters in a sorted manner based on the value of Za|,Non-data,143
 This optimization caused the most significant speed-up for the first16 dataset 33 New Short-Term Biases By analysing the generated datasets we discovered many new short-term biases We classify them into several sets,Non-data,143
 331 Biases in (Non-)Consecutive Bytes By analysing the consec512 dataset we discovered nu- merous biases between consecutive keystream bytes Our first observation is that the Fluhrer-McGrew biases are also present in the initial keystream bytes,Non-data,143
| Excep- tions occur at positions 1, 2 and 5, and are listed in Ta- Probability Second byte First byte Consecutive biases: Z15 = 240 Z16 = 240 Z31 = 224 Z32 = 224 Z47 = 208 Z48 = 208 Z63 = 192 Z64 = 192 Z79 = 176 Z80 = 176 Z95 = 160 Z96 = 160 Z111 = 144 Z112 = 144 Non-consecutive biases: 2−1594786(1− 2−4894) 2−1596486(1− 2−5|,Non-data,143
427) 2−1597595(1− 2−5963) 2−1598363(1− 2−6,Non-data,143
469) 2−1599020(1− 2−7150) 2−1599405(1− 2−7,Non-data,143
740) 2−1599668(1− 2−8331) 2−1600243(1 + 2−7,Non-data,143
912) 2−1599543(1 + 2−8700) 2−1599347(1− 2−9,Non-data,143
511) 2−1599918(1 + 2−8208) 2−1599349(1 + 2−9,Non-data,143
941) 2−1600191(1 + 2−11279) 2−1596637(1− 2−10,Non-data,143
904) 2−1596574(1 + 2−9493) 2−1595021(1 + 2−8,Non-data,143
996) 2−1594976(1 + 2−9261) 2−1594960(1 + 2−10,Non-data,143
516) 2−1594976(1 + 2−10933) 2−1594989(1 + 2−10,Non-data,143
832) 2−1592619(1− 2−10965) 2−1593357(1− 2−11,Non-data,143
|229) Table 2: Biases between (non-consecutive) bytes Z5 = 4 Z131 = 3 Z131 = 131 Z6 = 255 Z16 = 14 Z17 = 16 Z32 = 224 Z32 = 224 Z31 = 63 Z32 = 16 Z33 = 16 Z40 = 32 Z48 = 16 Z48 = 208 Z64 = 192 Z3 = 4 Z3 = 131 Z3 = 131 Z4 = 5 Z14 = 0 Z15 = 47 Z15 = 112 Z15 = 159 Z16 = 240 Z16 = 240 Z16 = 240 Z16 = 240 Z16 = 240 Z16 = 240 Z16 = 240 ble 1 (note the extra conditions on the position r) This is surprising, as the Fluhrer-McGrew biases were gener- ally not expected to be present in the initial keystream bytes [13] However, these biases are present, albeit with different probabilities|,Non-data,143
| Figure 4 shows the absolute rela- tive bias of most Fluhrer-McGrew digraphs, compared to their expected single-byte based probability (recall Sect 31) For all digraphs, the sign of the relative bias q is the same as its long-term variant as listed in Table 1|,Non-data,143
| We observe that the relative biases converge to their long- term values, especially after position 257 The vertical lines around position 1 and 256 are caused by digraphs which do not hold (or hold more strongly) around these positions A second set of strong biases have the form: Pr[Zw16−1 = Zw16 = 256− w16] (2) with 1 ≤ w ≤ 7 In Table 2 we list their probabilities|,Non-data,143
| Since 16 equals our key length, these are likely key- length dependent biases Another set of biases have the form Pr[Zr = Zr+1 = x] Depending on the value x, these biases are either nega- tive or positive Hence summing over all x and calcu- lating Pr[Zr = Zr+1] would lose some statistical informa- USENIX Association  24th USENIX Security Symposium 101 5 s a b i   e v i t l a e r  l t e u o s b A 2−7 2−8 2−9 2−10 2−11 1 Bias 1 Bias 3 Bias 5 Bias 2 Bias 4 Bias 6 y t i l i b a b o r P 0|,Non-data,143
00390649 000390637 000390625 000390613 0,Non-data,143
00390601 000390589 000390577 Position 272 Position 304 Position 336 Position 368 0 32 64 96 128 160 192 224 256 Keystream byte value Figure 6: Single-byte biases beyond position 256 256 64 96 32 224 Position other keystream byte (variable i) 128 160 192 Figure 5: Biases induced by the first two bytes,Non-data,143
 The num- ber of the biases correspond to those in Sect 332,Non-data,143
| tion In principle, these biases also include the Fluhrer- McGrew pairs (0,0) and (255,255) However, as the bias for both these pairs is much higher than for other values, we don’t include them here Our new bias, in the form of Pr[Zr = Zr+1], was detected up to position 512|,Non-data,143
| We also detected biases between non-consecutive bytes that do not fall in any obvious categories An overview of these is given in Table 2 We remark that the biases induced by Z16 = 240 generally have a position, or value, that is a multiple of 16 This is an indication that these are likely key-length dependent biases|,Non-data,143
| 332 Influence of Z1 and Z2 Arguably our most intriguing finding is the amount of information the first two keystream bytes leak In partic- ular, Z1 and Z2 influence all initial 256 keystream bytes|,Non-data,143
| We detected the following six sets of biases: 1) Z1 = 257− i∧ Zi = 0 4) Z1 = i− 1∧ Zi = 1 Z2 = 0∧ Zi = 0 5) 2) Z1 = 257− i∧ Zi = i 6) Z2 = 0∧ Zi = i 3) Z1 = 257− i∧ Zi = 257− i Their absolute relative bias, compared to the single-byte biases, is shown in Fig 5 The relative bias of pairs 5 and 6, ie|,Non-data,143
|, those involving Z2, are generally negative Pairs involving Z1 are generally positive, except pair 3, which always has a negative relative bias We also de- tected dependencies between Z1 and Z2 other than the Pr[Z1 = Z2] bias of Paul and Preneel [33] That is, the following pairs are strongly biased: A) Z1 = 0∧ Z2 = x C) Z1 = x∧ Z2 = 0 B) Z1 = x∧ Z2 = 258− x D) Z1 = x∧ Z2 = 1 Bias A and C are negative for all x (cid:29)= 0, and both ap- pear to be mainly caused by the strong positive bias Pr[Z1 = Z2 = 0] found by Isobe et al|,Non-data,143
 Bias B and D are positive We also discovered the following three biases: Pr[Z1 = Z3] = 2−8(1− 2−9617) Pr[Z1 = Z4] = 2−8(1 + 2−8590) Pr[Z2 = Z4] = 2−8(1− 2−9,Non-data,143
|622) (3) (4) (5) Note that all either involve an equality with Z1 or Z2 333 Single-Byte Biases We analysed single-byte biases by aggregating the consec512 dataset, and by generating additional statis- tics specifically from single-byte probabilities|,Non-data,143
| The ag- gregation corresponds to calculating Pr[Zr = k] = 255 ∑ y=0 Pr[Zr = k∧ Zr+1 = y] (6) We ended up with 247 keys used to estimate single-byte probabilities For all initial 513 bytes we could reject the hypothesis that they are uniformly distributed In other words, all initial 513 bytes are biased Figure 6 shows the probability distribution for some positions|,Non-data,143
| Manual inspection of the distributions revealed a significant bias towards Z256+k·16 = k· 32 for 1 ≤ k ≤ 7 These are likely key-length dependent biases Following [26] we conjec- ture there are single-byte biases even beyond these posi- tions, albeit less strong 3|,Non-data,143
|4 New Long-Term Biases To search for new long-term biases we created a variant of the first16 dataset It estimates Pr[Z256w+a = x∧ Z256w+b = y] (7) for 0 ≤ a ≤ 16, 0 ≤ b < 256, 0 ≤ x,y < 256, and w ≥ 4 It is generated using 212 RC4 keys, where each key was used to generate 240 keystream bytes This took roughly 8 CPU years|,Non-data,143
| The condition on w means we always 102 24th USENIX Security Symposium  USENIX Association 6 dropped the initial 1023 keystream bytes Using this dataset we can detect biases whose periodicity is a proper divisor of 256 (eg, it detected all Fluhrer-McGrew bi- ases)|,Non-data,143
| Our new short-term biases were not present in this dataset, indicating they indeed only occur in the initial keystream bytes, at least with the probabilities we listed We did find the new long-term bias Pr[(Zw256,Zw256+2) = (128,0)] = 2−16(1 + 2−8) (8) for w ≥ 1 Surprisingly this was not discovered earlier, since a bias towards (0,0) at these positions was already known [38] We also specifically searched for biases of the form Pr[Zr = Zr(cid:29)] by aggregating our dataset|,Non-data,143
| This revealed that many bytes are dependent on each other That is, we detected several long-term biases of the form Pr[Z256w+a = Z256w+b] ≈ 2−8(2± 2−16) (9) Due to the small relative bias of 2−16, these are difficult to reliably detect That is, the pattern where these biases occur, and when their relative bias is positive or nega- tive, is not yet clear We consider it an interesting future research direction to (precisely and reliably) detect all keystream bytes which are dependent in this manner|,Non-data,143
| 4 Plaintext Recovery We will design plaintext recovery techniques for usage in two areas: decrypting TKIP packets and HTTPS cookies In other scenarios, variants of our methods can be used 41 Calculating Likelihood Estimates Our goal is to convert a sequence of ciphertexts C into predictions about the plaintext|,Non-data,143
 This is done by exploit- ing biases in the keystream distributions pk = Pr[Zr = k] These can be obtained by following the steps in Sect 32,Non-data,143
| All biases in pk are used to calculate the likelihood that a plaintext byte equals a certain value μ To accom- plish this, we rely on the likelihood calculations of Al- Fardan et al [2] Their idea is to calculate, for each plaintext value μ, the (induced) keystream distributions required to witness the captured ciphertexts|,Non-data,143
| The closer this matches the real keystream distributions pk, the more likely we have the correct plaintext byte Assuming a fixed position r for simplicity, the induced keystream dis- tributions are defined by the vector Nμ = (Nμ 255) Each Nμ k represents the number of times the keystream byte was equal to k, assuming the plaintext byte was μ: 0 ,  |,Non-data,143
|  ,N μ Nμ k = ||{C ∈ C || C = k⊕ μ}|| (10) Note that the vectors Nμ and Nμ(cid:29) are permutations of each other Based on the real keystream probabilities pk we calculate the likelihood that this induced distribution would occur in practice This is modelled using a multi- nomial distribution with the number of trails equal to ||C||, and the categories being the 256 possible keystream byte values|,Non-data,143
| Since we want the probability of this sequence of keystream bytes we get [30]: Pr[C || P = μ] = ∏ k∈{0,,255} (pk)Nμ k (11) Using Bayes’ theorem we can convert this into the like- lihood λμ that the plaintext byte is μ: λμ = Pr[P = μ || C] ∼ Pr[C || P = μ] (12) For our purposes we can treat this as an equality [2]|,Non-data,143
| The most likely plaintext byte μ is the one that maximises λμ This was extended to a pair of dependent keystream bytes in the obvious way: λμ1,μ2 = ∏ k1,k2∈{0,|,Non-data,143
|,255} Nμ1,μ2 k1,k2 (pk1,k2) (13) We found this formula can be optimized if most key- stream values k1 and k2 are independent and uniform More precisely, let us assume that all keystream value pairs in the set I are independent and uniform: ∀(k1,k2) ∈ I : pk1,k2 = pk1 · pk2 = u (14) where u represents the probability of an unbiased double- byte keystream value Then we rewrite formula 13 to: λμ1,μ2 = (u)Mμ1,μ2 · ∏ k1,k2∈Ic Nμ1,μ2 k1,k2 (pk1,k2) (15) where Mμ1,μ2 = ∑ k1,k2∈I Nμ1,μ2 k1,k2 = ||C||− ∑ k1,k2∈Ic Nμ1,μ2 k1,k2 (16) and with Ic the set of dependent keystream values If the set Ic is small, this results in a lower time-complexity|,Non-data,143
| For example, when applied to the long-term keystream setting over Fluhrer-McGrew biases, roughly 219 opera- tions are required to calculate all likelihood estimates, in- stead of 232 A similar (though less drastic) optimization can also be made when single-byte biases are present 42 Likelihoods From Mantin’s Bias We now show how to compute a double-byte plaintext likelihood using Mantin’s ABSAB bias|,Non-data,143
| More formally, we want to compute the likelihood λμ1,μ2 that the plain- text bytes at fixed positions r and r + 1 are μ1 and μ2, respectively To accomplish this we abuse surrounding known plaintext Our main idea is to first calculate the USENIX Association  24th USENIX Security Symposium 103 7 (17) r as: (cid:31)Zg likelihood of the differential between the known and un- r to denote the differential over ciphertext and plaintext bytes, respectively The ABSAB bias can then be written as: r and(cid:31)Pg r = (Zr ⊕ Zr+2+g,Zr+1 ⊕ Zr+3+g) known plaintext|,Non-data,143
| We define the differential(cid:31)Zg Similarly we use(cid:31)Cg Pr[(cid:31)Zg When XORing both sides of(cid:31)Zg Pr[(cid:31)Cg r =(cid:31)Pg r = (0,0)] = 2−16(1 + 2−8e −4−8g Hence Mantin’s bias implies that the ciphertext differen- tial is biased towards the plaintext differential We use r = (0,0) with (cid:31)Pg 256 ) =α (g) r ] = α(g) r we get ease of notation we assume a fixed position r and a fixed this to calculate the likelihood λ(cid:31)μ of a differential(cid:31)μ For ABSAB gap of g Let (cid:31)C be the sequence of captured ci- phertext differentials, and μ(cid:27)1 and μ(cid:27)2 the known plaintext bytes at positions r + 2 + g and r + 3 + g, respectively|,Non-data,143
| Similar to our previous likelihood estimates, we calcu- late the probability of witnessing the ciphertext differen- (20) (21) Pr[(cid:31)C ||(cid:31)P =(cid:31)μ] = ∏ (cid:31)k∈{0,,255}2 tials (cid:31)C assuming the plaintext differential is(cid:31)μ: N(cid:31)μ Pr[(cid:31)Z =(cid:31)k] (cid:31)k =(cid:30)(cid:30)(cid:30)(cid:29)(cid:31)C ∈ (cid:31)C ||(cid:31)C =(cid:31)k⊕(cid:31)μ(cid:28)(cid:30)(cid:30)(cid:30) N(cid:31)μ (cid:31)k where Using this notation we see that this is indeed identical to an ordinary likelihood estimation|,Non-data,143
| Using Bayes’ theorem pair is biased, we can apply and simplify formula 15: we get λ(cid:31)μ = Pr[(cid:31)C || (cid:31)P =(cid:31)μ] Since only one differential where we slightly abuse notation by defining ||(cid:31)μ|| as (23) (22) λ(cid:31)μ = (1− α(g))||C||−||(cid:31)u|| · α(g)||(cid:31)μ|| ||(cid:31)μ|| =(cid:30)(cid:30)(cid:30)(cid:29)(cid:31)C ∈ (cid:31)C ||(cid:31)C =(cid:31)μ(cid:28)(cid:30)(cid:30)(cid:30) λμ1,μ2 = λ(cid:31)μ⊕(μ(cid:27)1,μ(cid:27)2) To estimate at which gap size the ABSAB bias is still detectable, we generated 248 blocks of 512 keystream bytes Based on this we empirically confirmed Mantin’s ABSAB bias up to gap sizes of at least 135 bytes The theoretical estimate in formula 1 slightly underestimates the true empirical bias|,Non-data,143
 In our attacks we use a maximum gap size of 128 Finally we apply our knowledge of the known plaintext bytes to get our desired likelihood estimate: (24) (18) (19) Combined FM only ABSAB only e t a r  y r e v o c e r  e g a r e v A 100% 80% 60% 40% 20% 0% 227 229 231 233 235 237 239 Number of ciphertexts Figure 7: Average success rate of decrypting two bytes using: (1) one ABSAB bias; (2) Fluhrer-McGrew (FM) biases; and (3) combination of FM biases with 258 ABSAB biases Results based on 2048 simulations each 4,Non-data,143
|3 Combining Likelihood Estimates Our goal is to combine multiple types of biases in a likeli- hood calculation Unfortunately, if the biases cover over- lapping positions, it quickly becomes infeasible to per- form a single likelihood estimation over all bytes In the worst case, the calculation cannot be optimized by rely- ing on independent biases Hence, a likelihood estimate over n keystream positions would have a time complex- ity of O(22·8·n)|,Non-data,143
| To overcome this problem, we perform and combine multiple separate likelihood estimates We will combine multiple types of biases by multi- plying their individual likelihood estimates For exam- ple, let λ(cid:27)μ1,μ2 be the likelihood of plaintext bytes μ1 and μ2 based on the Fluhrer-McGrew biases Similarly, let λ(cid:27)g,μ1,μ2 be likelihoods derived from ABSAB biases of gap g|,Non-data,143
| Then their combination is straightforward: λμ1,μ2 = λ(cid:27)μ1,μ2 ·∏ g λ(cid:27)g,μ1,μ2 (25) While this method may not be optimal when combining likelihoods of dependent bytes, it does appear to be a general and powerful method An open problem is de- termining which biases can be combined under a single likelihood calculation, while keeping computational re- quirements acceptable Likelihoods based on other bi- ases, eg|,Non-data,143
|, Sen Gupta’s and our new long-term biases, can be added as another factor (though some care is needed so positions properly overlap) To verify the effectiveness of this approach, we per- formed simulations where we attempt to decrypt two bytes using one double-byte likelihood estimate First this is done using only the Fluhrer-McGrew biases, and using only one ABSAB bias Then we combine 2· 129 ABSAB biases and the Fluhrer-McGrew biases, where we use the method from Sect|,Non-data,143
| 42 to derive likelihoods from ABSAB biases We assume the unknown bytes are surrounded at both sides by known plaintext, and use a 104 24th USENIX Security Symposium  USENIX Association 8 maximum ABSAB gap of 128 bytes Figure 7 shows the results of this experiment|,Non-data,143
| Notice that a single ABSAB bias is weaker than using all Fluhrer-McGrew biases at a specific position However, combining several ABSAB biases clearly results in a major improvement We con- clude that our approach to combine biases significantly reduces the required number of ciphertexts 4|,Non-data,143
|4 List of Plaintext Candidates In practice it is useful to have a list of plaintext candi- dates in decreasing likelihood For example, by travers- ing this list we could attempt to brute-force keys, pass- words, cookies, etc (see Sect 6)|,Non-data,143
| In other situations the plaintext may have a rigid structure allowing the removal of candidates (see Sect 5) We will generate a list of plaintext candidates in decreasing likelihood, when given either single-byte or double-byte likelihood estimates First we show how to construct a candidate list when given single-byte plaintext likelihoods|,Non-data,143
| While it is trivial to generate the two most likely candidates, beyond this point the computation becomes more tedious Our solu- tion is to incrementally compute the N most likely can- didates based on their length That is, we first compute the N most likely candidates of length 1, then of length 2, and so on Algorithm 1 gives a high-level implemen- tation of this idea|,Non-data,143
| Variable Pr[i] denotes the i-th most likely plaintext of length r, having a likelihood of Er[i] The two min operations are needed because in the initial loops we are not yet be able to generate N candidates, ie, there only exist 256r plaintexts of length r|,Non-data,143
| Picking the μ(cid:30) which maximizes pr(μ(cid:30)) can be done efficiently using a priority queue In practice, only the latest two versions of lists E and P need to be stored To better maintain numeric stability, and to make the computation more efficient, we perform calculations using the loga- rithm of the likelihoods We implemented Algorithm 1 and report on its performance in Sect|,Non-data,143
| 5, where we use it to attack a wireless network protected by WPA-TKIP To generate a list of candidates from double-byte like- lihoods, we first show how to model the likelihoods as a hidden Markov model (HMM) This allows us to present a more intuitive version of our algorithm, and refer to the extensive research in this area if more efficient im- plementations are needed The algorithm we present can be seen as a combination of the classical Viterbi algo- rithm, and Algorithm 1|,Non-data,143
| Even though it is not the most optimal one, it still proved sufficient to significantly im- prove plaintext recovery (see Sect 6) For an introduc- tion to HMMs we refer the reader to [35] Essentially an HMM models a system where the internal states are not observable, and after each state transition, output is (probabilistically) produced dependent on its new state|,Non-data,143
| We model the plaintext likelihood estimates as a first- Algorithm 1: Generate plaintext candidates in de- creasing likelihood using single-byte estimates Input: L : Length of the unknown plaintext λ1≤r≤L, 0≤μ≤255: single-byte likelihoods N: Number of candidates to generate Returns: List of candidates in decreasing likelihood P0[1] ← ε E0[1] ← 0 for r = 1 to L do for μ = 0 to 255 do for i = 1 to min(N,256r) do pos(μ) ← 1 pr(μ) ← Er−1[1] +log(λ r,μ ) μ ← μ(cid:30) which maximizes pr(μ(cid:30)) Pr[i] ← Pr−1[pos(μ)](cid:26) μ Er[i] ← Er−1[pos(μ)] + log(λr,μ ) pos(μ) ← pos(μ) +1 pr(μ) ← Er−1[pos(μ)] + log(λr,μ ) if pos(μ) > min(N,256r−1) then pr(μ) ← −∞ return PN order time-inhomogeneous HMM The state space S of the HMM is defined by the set of possible plaintext val- ues {0,  |,Non-data,143
|  ,255} The byte positions are modelled using the time-dependent (ie|,Non-data,143
|, inhomogeneous) state transition probabilities Intuitively, the “current time” in the HMM corresponds to the current plaintext position This means the transition probabilities for moving from one state to another, which normally depend on the current time, will now depend on the position of the byte More formally: Pr[St+1 = μ2 || St = μ1] ∼ λt,μ1,μ2 (26) where t represents the time|,Non-data,143
 For our purposes we can treat this as an equality In an HMM it is assumed that its current state is not observable This corresponds to the fact that we do not know the value of any plaintext bytes In an HMM there is also some form of output which depends on the current state,Non-data,143
| In our setting a par- ticular plaintext value leaks no observable (side-channel) information This is modelled by always letting every state produce the same null output with probability one Using the above HMM model, finding the most likely plaintext reduces to finding the most likely state se- quence This is solved using the well-known Viterbi al- gorithm|,Non-data,143
| Indeed, the algorithm presented by AlFardan et al closely resembles the Viterbi algorithm [2] Similarly, finding the N most likely plaintexts is the same as find- ing the N most likely state sequences Hence any N-best variant of the Viterbi algorithm (also called list Viterbi USENIX Association  24th USENIX Security Symposium 105 9 Algorithm 2: Generate plaintext candidates in de- creasing likelihood using double-byte estimates|,Non-data,143
| Input: L : Length of the unknown plaintext plus two m1 and mL: known first and last byte λ1≤r<L, 0≤μ1,μ2≤255: double-byte likelihoods N: Number of candidates to generate Returns: List of candidates in decreasing likelihood for μ2 = 0 to 255 do E2[μ2,1] ← log(λ1,m1,μ2) P2[μ2,1] ← m1 (cid:29) μ2 for μ2 = 0 to 255 do for r = 3 to L do for μ1 = 0 to 255 do pos(μ1) ← 1 pr(μ1) ← Er−1[μ1,1] +log(λ r,μ1,μ2) for i = 1 to min(N,256r−1) do μ1 ← μ which maximizes pr(μ) Pr[μ2,i] ← Pr−1[μ1, pos(μ1)](cid:29) μ2 Er[μ2,i] ← Er−1[μ1, pos(μ1)] + log(λr,μ1,μ2) pos(μ1) ← pos(μ1) +1 pr(μ1) ← Er−1[μ1, pos(μ1)] + log(λr,μ1,μ2) if pos(μ1) > min(N,256r−2) then pr(μ1) ← −∞ return PN[mL,:] algorithm) can be used, examples being [42, 36, 40, 28] The simplest form of such an algorithm keeps track of the N best candidates ending in a particular value μ, and is shown in Algorithm 2 Similar to [2, 30] we assume the first byte m1 and last byte mL of the plaintext are known During the last round of the outer for-loop, the loop over μ2 has to be executed only for the value mL|,Non-data,143
 In Sect 6 we use this algorithm to generate a list of cookies Algorithm 2 uses considerably more memory than Al- gorithm 1 This is because it has to store the N most likely candidates for each possible ending value μ,Non-data,143
| We remind the reader that our goal is not to present the most optimal algorithm Instead, by showing how to model the problem as an HMM, we can rely on related work in this area for more efficient algorithms [42, 36, 40, 28] Since an HMM can be modelled as a graph, all k-shortest path algorithms are also applicable [10] Finally, we remark that even our simple variant sufficed to significantly im- prove plaintext recovery rates (see Sect|,Non-data,143
| 6) 5 Attacking WPA-TKIP We use our plaintext recovery techniques to decrypt a full packet From this decrypted packet the MIC key can be derived, allowing an attacker to inject and decrypt pack- ets The attack takes only an hour to execute in practice|,Non-data,143
| 51 Calculating Plaintext Likelihoods We rely on the attack of Paterson et al to compute plain- text likelihood estimates [31, 30] They noticed that the first three bytes of the per-packet RC4 key are public|,Non-data,143
| As explained in Sect 22, the first three bytes are fully determined by the TKIP Sequence Counter (TSC) It was observed that this dependency causes strong TSC- dependent biases in the keystream [31, 15, 30], which can be used to improve the plaintext likelihood estimates|,Non-data,143
| For each TSC value they calculated plaintext likelihoods based on empirical, per-TSC, keystream distributions The resulting 2562 likelihoods are combined by multi- plying them over all TSC pairs In a sense this is sim- ilar to combining multiple types of biases as done in Sect 4|,Non-data,143
|3, though here the different types of biases are known to be independent We use the single-byte vari- ant of the attack [30, §41] to obtain likelihoods λr,μ for every unknown byte r The downside of this attack is that it requires detailed per-TSC keystream statistics|,Non-data,143
| Paterson at al generated statistics for the first 512 bytes, which took 30 CPU years [30] However, in our attack we only need these statistics for the first few keystream bytes We used 232 keys per TSC value to estimate the keystream distribu- tion for the first 128 bytes|,Non-data,143
| Using our distributed setup the generation of these statistics took 10 CPU years With our per-TSC keystream distributions we obtained similar results to that of Paterson et al [31, 30] By run- ning simulations we confirmed that the odd byte posi- tions [30], instead of the even ones [31], can be recov- ered with a higher probability than others|,Non-data,143
| Similarly, the bytes at positions 49-51 and 63-67 are generally recov- ered with higher probability as well Both observations will be used to optimize the attack in practice the generation of identical packets Injecting Identical Packets 5|,Non-data,143
|2 We show how to fulfil the first requirement of a success- ful attack: If the IP of the victim is know, and incoming connections to- wards it are not blocked, we can simply send identical packets to the victim Otherwise we induce the victim into opening a TCP connection to an attacker-controlled server This connection is then used to transmit identical packets to the victim A straightforward way to accom- plish this is by social engineering the victim into visit- ing a website hosted by the attacker|,Non-data,143
| The browser will open a TCP connection with the server in order to load the website However, we can also employ more sophis- ticated methods that have a broader target range One 106 24th USENIX Security Symposium  USENIX Association 10 such method is abusing the inclusion of (insecure) third- party resources on popular websites [27] For example, an attacker can register a mistyped domain, accidentally used in a resource address (e|,Non-data,143
|g, an image URL) on a popular website Whenever the victim visits this website and loads the resource, a TCP connection is made to the server of the attacker In [27] these types of vulnerabil- ities were found to be present on several popular web- sites|,Non-data,143
| Additionally, any type of web vulnerability that can be abused to make a victim execute JavaScript can be utilised In this sense, our requirements are more relaxed than those of the recent attacks on SSL and TLS, which require the ability to run JavaScript code in the victim’s browser [9, 1, 2] Another method is to hijack an exist- ing TCP connection of the victim, which under certain conditions is possible without a man-in-the-middle posi- tion [17] We conclude that, while there is no universal method to accomplish this, we can assume control over a TCP connection with the victim|,Non-data,143
| Using this connection we inject identical packets by repeatedly retransmitting identical TCP packets, even if the victim is behind a fire- wall Since retransmissions are valid TCP behaviour, this will work even if the victim is behind a firewall We now determine the optimal structure of the injected packet A naive approach would be to use the shortest possible packet, meaning no TCP payload is included|,Non-data,143
| Since the total size of the LLC/SNAP, IP, and TCP header is 48 bytes, the MIC and ICV would be located at posi- tion 49 up to and including 60 (see Fig 2) At these locations 7 bytes are strongly biased In contrast, if we use a TCP payload of 7 bytes, the MIC and ICV are lo- cated at position 56 up to and including 60|,Non-data,143
| In this range 8 bytes are strongly biased, resulting in better plaintext likelihood estimates Through simulations we confirmed that using a 7 byte payload increases the probability of successfully decrypting the MIC and ICV In practice, adding 7 bytes of payload also makes the length of our injected packet unique As a result we can easily identify and capture such packets|,Non-data,143
| Given both these advantages, we use a TCP data packet containing 7 bytes of payload 53 Decrypting a Complete Packet Our goal is to decrypt the injected TCP packet, including its MIC and ICV fields Note that all these TCP pack- ets will be encrypted with a different RC4 key|,Non-data,143
| For now we assume all fields in the IP and TCP packet are known, and will later show why we can safely make this assump- tion Hence, only the 8-byte MIC and 4-byte ICV of the packet remain unknown We use the per-TSC key- stream statistics to compute single-byte plaintext likeli- hoods for all 12 bytes However, this alone would give a very low success probability of simultaneously (cor- rectly) decrypting all bytes|,Non-data,143
| We solve this by realising          y r e v o c e r  y e k  C M  y t i l i I 100% 80% 60% 40% 20% 0% b a b o r P 230 candidates 2 candidates 1 3 9 7 5 Ciphertext copies times 220 11 13 15 Figure 8: Success rate of obtaining the TKIP MIC key using nearly 230 candidates, and using only the two best candidates Results are based on 256 simulations each 226 222 218 214 210 V C I  t c e r r o c  n o i t i s o p   i n a d e M 1 3 7 5 Ciphertext copies times 220 11 9 13 15 Figure 9: Median position of a candidate with a correct ICV with nearly 230 candidates Results are based on 256 simulations each|,Non-data,143
| that the TKIP ICV is a simple CRC checksum which we can easily verify ourselves Hence we can detect bad candidates by inspecting their CRC checksum We now generate a plaintext candidate list, and traverse it until we find a packet having a correct CRC This drastically im- proves the probability of simultaneously decrypting all bytes|,Non-data,143
| From the decrypted packet we can derive the TKIP MIC key [44], which can then be used to inject and de- crypt arbitrary packets [48] Figure 8 shows the success rate of finding a packet with a good ICV and deriving the correct MIC key For comparison, it also includes the success rates had we only used the two most likely candidates Figure 9 shows the median position of the first candidate with a correct ICV|,Non-data,143
| We plot the median instead of average to lower in- fluence of outliers, ie, at times the correct candidate was unexpectedly far (or early) in the candidate list The question that remains how to determine the con- tents of the unknown fields in the IP and TCP packet|,Non-data,143
| More precisely, the unknown fields are the internal IP and port of the client, and the IP time-to-live (TTL) field One observation makes this clear: both the IP and TCP header contain checksums Therefore, we can apply ex- actly the same technique (ie|,Non-data,143
|, candidate generation and pruning) to derive the values of these fields with high USENIX Association  24th USENIX Security Symposium 107 11 success rates This can be done independently of each other, and independently of decrypting the MIC and ICV Another method to obtain the internal IP is to rely on HTML5 features If the initial TCP connection is created by a browser, we can first send JavaScript code to obtain the internal IP of the victim using WebRTC [37]|,Non-data,143
| We also noticed that our NAT gateway generally did not modify the source port used by the victim Consequently we can simply read this value at the server The TTL field can also be determined without relying on the IP checksum Using a traceroute command we count the number of hops between the server and the client, allowing us to derive the TTL value at the victim|,Non-data,143
| 54 Empirical Evaluation To test the plaintext recovery phase of our attack we cre- ated a tool that parses a raw pcap file containing the cap- tured Wi-Fi packets It searches for the injected packets, extracts the ciphertext statistics, calculates plaintext like- lihoods, and searches for a candidate with a correct ICV From this candidate, i|,Non-data,143
|e, decrypted injected packet, we derive the MIC key For the ciphertext generation phase we used an OpenVZ VPS as malicious server The incoming TCP connection from the victim is handled using a custom tool written in Scapy|,Non-data,143
 It relies on a patched version of Tcpreplay to rapidly inject the identical TCP packets The victim machine is a Latitude E6500 and is connected to an Asus RT-N10 router running Tomato 128 The victim opens a TCP connection to the malicious server by visiting a website hosted on it,Non-data,143
| For the attacker we used a Compaq 8510p with an AWUS036nha to capture the wireless traffic Under this setup we were able to generate roughly 2500 packets per second This number was reached even when the victim was actively brows- ing YouTube videos Thanks to the 7-byte payload, we uniquely detected the injected packet in all experiments without any false positives|,Non-data,143
| We ran several test where we generated and captured traffic for (slightly more) than one hour This amounted to, on average, capturing 95·220 different encryptions of the packet being injected Retransmissions were filtered based on the TSC of the packet|,Non-data,143
| In nearly all cases we successfully decrypted the packet and derived the MIC key Recall from Sect 22 that this MIC key is valid as long as the victim does not renew its PTK, and that it can be used to inject and decrypt packets from the AP to the victim|,Non-data,143
| For one capture our tool found a packet with a correct ICV, but this candidate did not correspond to the actual plaintext While our current evaluation is limited in the number of captures performed, it shows the attack is practically feasible, with overall success probabilities appearing to agree with the simulated results of Fig 8 Listing 3: Manipulated HTTP request, with known plain- text surrounding the cookie at both sides|,Non-data,143
 1 GET / HTTP/11 2 Host: sitecom 3 User-Agent: Mozilla/50 (X11; Linux i686; rv:32,Non-data,143
|0) Gecko/20100101 Firefox/320 4 Accept: text/html,application/xhtml+xml,application/ xml;q=09,*/*;q=08 5 Accept-Language: en-US,en;q=0|,Non-data,143
|5 6 Accept-Encoding: gzip, deflate 7 Cookie: auth=XXXXXXXXXXXXXXXX; injected1=known1; injected2=knownplaintext2;  6 Decrypting HTTPS Cookies We inject known data around a cookie, enabling use of the ABSAB biases|,Non-data,143
| We then show that a HTTPS cookie can be brute-forced using only 75 hours of ciphertext Injecting Known Plaintext 61 We want to be able to predict the position of the targeted cookie in the encrypted HTTP requests, and surround it with known plaintext To fix ideas, we do this for the se- cure auth cookie sent to https://site|,Non-data,143
|com Similar to previous attacks on SSL and TLS, we assume the at- tacker is able to execute JavaScript code in the victim’s browser [9, 1, 2] In our case, this means an active man- in-the-middle (MiTM) position is used, where plaintext HTTP channels can be manipulated Our first realisa- tion is that an attacker can predict the length and con- tent of HTTP headers preceding the Cookie field|,Non-data,143
| By monitoring plaintext HTTP requests, these headers can be sniffed If the targeted auth cookie is the first value in the Cookie header, this implies we know its position in the HTTP request Hence, our goal is to have a layout as shown in Listing 3 Here the targeted cookie is the first value in the Cookie header, preceded by known headers, and followed by attacker injected cookies|,Non-data,143
| To obtain the layout in Listing 3 we use our MiTM po- sition to redirect the victim to http://sitecom, ie, to the target website over an insecure HTTP channel|,Non-data,143
| If the target website uses HTTP Strict Transport Secu- rity (HSTS), but does not use the includeSubDomains attribute, this is still possible by redirecting the victim to a (fake) subdomain [6] Since few websites use HSTS, and even fewer use it properly [47], this redirection will likely succeed Against old browsers HSTS can even be bypassed completely [6, 5, 41] Since secure cookies guarantee only confidentiality but not integrity, the in- secure HTTP channel can be used to overwrite, remove, or inject secure cookies [3, 4|,Non-data,143
|125] This allows us to remove all cookies except the auth cookie, pushing it to the front of the list|,Non-data,143
 After this we can inject cookies that 108 24th USENIX Security Symposium  USENIX Association 12 will be included after the auth cookie An example of a HTTP(S) request manipulated in this manner is shown in Listing 3 Here the secure auth cookie is surrounded by known plaintext at both sides This allows us to use Mantin’s ABSAB bias when calculating plaintext likeli- hoods,Non-data,143
| 62 Brute-Forcing The Cookie In contrast to passwords, many websites do not protect against brute-forcing cookies One reason for this is that the password of an average user has a much lower en- tropy than a random cookie Hence it makes sense to brute-force a password, but not a cookie: the chance of successfully brute-forcing a (properly generated) cookie is close to zero|,Non-data,143
| However, if RC4 can be used to con- nect to the web server, our candidate generation algo- rithm voids this assumption We can traverse the plain- text candidate list in an attempt to brute-force the cookie Since we are targeting a cookie, we can exclude cer- tain plaintext values As RFC 6265 states, a cookie value can consists of at most 90 unique characters [3, §4|,Non-data,143
11] A similar though less general observation was already made by AlFardan et al [2],Non-data,143
| Our observation allows us to give a tighter bound on the required number of cipher- texts to decrypt a cookie, even in the general case In practice, executing the attack with a reduced character set is done by modifying Algorithm 2 so the for-loops over μ1 and μ2 only loop over allowed characters Figure 10 shows the success rate of brute-forcing a 16- character cookie using at most 223 attempts For compar- ison, we also include the probability of decrypting the cookie if only the most likely plaintext was used|,Non-data,143
| This also allows for an easier comparison with the work for AlFardan et al [2] Note that they only use the Fluhrer- McGrew biases, whereas we combine serveral ABSAB biases together with the Fluhrer-McGrew biases We conclude that our brute-force approach, as well as the inclusion of the ABSAB biases, significantly improves success rates|,Non-data,143
| Even when using only 223 brute-force at- tempts, success rates of more than 94% are obtained once 9· 227 encryptions of the cookie have been captured We conjecture that generating more candidates will further increase success rates 63 Empirical Evaluation The main requirement of our attack is being able to col- lect sufficiently many encryptions of the cookie, i|,Non-data,143
|e, hav- ing many ciphertexts We fulfil this requirement by forc- ing the victim to generate a large number of HTTPS re- quests As in previous attacks on TLS [9, 1, 2], we ac- complish this by assuming the attacker is able to execute JavaScript in the browser of the victim|,Non-data,143
| For example,                  e c r o − e f b a b o r P 100% 80% 60% 40% 20% 0% t u r b  l u f s s e c c u s  y t i l i 223 candidates 1 candidate 1 3 9 7 5 Ciphertext copies times 227 11 13 15 Figure 10: Success rate of brute-forcing a 16-byte cookie using roughly 223 candidates, and only the most likely candidate, dependent on the number of collected cipher- texts Results based on 256 simulations each when performing a man-in-the-middle attack, we can in- ject JavaScript into any plaintext HTTP connection We then use XMLHttpRequest objects to issue Cross-Origin Requests to the targeted website|,Non-data,143
| The browser will auto- matically add the secure cookie to these (encrypted) re- quests Due to the same-origin policy we cannot read the replies, but this poses no problem, we only require that the cookie is included in the request The requests are sent inside HTML5 WebWorkers Essentially this means our JavaScript code will run in the background of the browser, and any open page(s) stay responsive|,Non-data,143
| We use GET requests, and carefully craft the values of our in- jected cookies so the targeted auth cookie is always at a fixed position in the keystream (modulo 256) Recall that this alignment is required to make optimal use of the Fluhrer-McGrew biases An attacker can learn the re- quired amount of padding by first letting the client make a request without padding Since RC4 is a stream cipher, and no padding is added by the TLS protocol, an attack can easily observe the length of this request|,Non-data,143
| Based on this information it is trivial to derive the required amount of padding To test our attack in practice we implemented a tool in C which monitors network traffic and collects the nec- essary ciphertext statistics This requires reassembling the TCP and TLS streams, and then detecting the 512- byte (encrypted) HTTP requests Similar to optimizing the generation of datasets as in Sect|,Non-data,143
| 32, we cache sev- eral requests before updating the counters We also cre- ated a tool to brute-force the cookie based on the gen- erated candidate list It uses persistent connections and HTTP pipelining [11, §6|,Non-data,143
|32] That is, it uses one con- nection to send multiple requests without waiting for each response In our experiments the victim uses a 3|,Non-data,143
1 GHz Intel Core i5-2400 CPU with 8 GB RAM running Windows 7 Internet Explorer 11 is used as the browser For the server a 34 GHz Intel Core i7-3770 CPU with 8 GB RAM is USENIX Association  24th USENIX Security Symposium 109 13 used,Non-data,143
| We use nginx as the web server, and configured RC4-SHA1 with RSA as the only allowable cipher suite This assures that RC4 is used in all tests Both the server and client use an Intel 82579LM network card, with the link speed set to 100 Mbps With an idle browser this setup resulted in an average of 4450 requests per second|,Non-data,143
| When the victim was actively browsing YouTube videos this decreased to roughly 4100 To achieve such num- bers, we found it’s essential that the browser uses persis- tent connections to transmit the HTTP requests Other- wise a new TCP and TLS handshake must be performed for every request, whose round-trip times would signif- icantly slow down traffic generation In practice this means the website must allow a keep-alive connec- tion|,Non-data,143
| While generating requests the browser remained re- sponsive at all times Finally, our custom tool was able to test more than 20000 cookies per second To execute the attack with a success rate of 94% we need roughly 9· 227 ciphertexts With 4450 requests per seconds, this means we require 75 hours of data|,Non-data,143
| Compared to the (more than) 2000 hours required by AlFardan et al [2, §533] this is a significant improvement|,Non-data,143
| We remark that, similar to the attack of AlFardan et al [2], our attack also tolerates changes of the encryption keys Hence, since cookies can have a long lifetime, the generation of this traffic can even be spread out over time With 20000 brute-force at- tempts per second, all 223 candidates for the cookie can be tested in less than 7 minutes|,Non-data,143
| We have executed the attack in practice, and success- fully decrypted a 16-byte cookie In our instance, cap- turing traffic for 52 hours already proved to be sufficient At this point we collected 62·227 ciphertexts|,Non-data,143
| After pro- cessing the ciphertexts, the cookie was found at position 46229 in the candidate list This serves as a good exam- ple that, if the attacker has some luck, less ciphertexts are needed than our 9· 227 estimate These results push the attack from being on the verge of practicality, to feasible, though admittedly somewhat time-consuming al|,Non-data,143
| searched for dependencies between initial keystream bytes by empirically estimating Pr[Zr = y∧ Zr−a = x] for 0 ≤ x,y ≤ 255, 2 ≤ r ≤ 256, and 1 ≤ a ≤ 8 [20] They did not discover any new biases using their approach Mironov modelled RC4 as a Markov chain and recom- mended to skip the initial 12· 256 keystream bytes [26] Paterson et al|,Non-data,143
| generated keystream statistics over con- secutive keystream bytes when using the TKIP key struc- ture [30] However, they did not report which (new) bi- ases were present Through empirical analysis, we show that biases between consecutive bytes are present even when using RC4 with random 128 bit keys The first practical attack on WPA-TKIP was found by Beck and Tews [44] and was later improved by other re- searchers [46, 16, 48, 49]|,Non-data,143
| Recently several works stud- ied the per-packet key construction both analytically [15] and through simulations [2, 31, 30] For our attack we replicated part of the results of Paterson et al [31, 30], and are the first to demonstrate this type of attack in prac- tice In [2] AlFardan et al|,Non-data,143
| ran experiments where the two most likely plaintext candidates were generated us- ing single-byte likelihoods [2] However, they did not present an algorithm to return arbitrarily many candi- dates, nor extended this to double-byte likelihoods The SSL and TLS protocols have undergone wide scrutiny [9, 41, 7, 1, 2, 6] Our work is based on the attack of AlFardan et al|,Non-data,143
|, who estimated that 13· 230 ci- phertexts are needed to recover a 16-byte cookie with high success rates [2] We reduce this number to 9· 227 using several techniques, the most prominent being us- age of likelihoods based on Mantin’s ABSAB bias [24] Isobe et al used Mantin’s ABSAB bias, in combination with previously decrypted bytes, to decrypt bytes after position 257 [20]|,Non-data,143
| However, they used a counting tech- nique instead of Bayesian likelihoods In [29] a guess- and-determine algorithm combines ABSAB and Fluhrer- McGrew biases, requiring roughly 234 ciphertexts to de- crypt an individual byte with high success rates 7 Related Work 8 Conclusion Due to its popularity, RC4 has undergone wide crypt- analysis Particularly well known are the key recovery attacks that broke WEP [12, 50, 45, 44, 43]|,Non-data,143
| Several other key-related biases and improvements of the orig- inal WEP attack have also been studied [21, 39, 32, 22] We refer to Sect 21 for an overview of various biases discovered in the keystream [25, 23, 38, 2, 20, 33, 13, 24, 38, 15, 31, 30]|,Non-data,143
| In addition to these, the long-term bias Pr[Zr = Zr+1 || 2· Zr = ir] = 2−8(1 + 2−15) was dis- covered by Basu et al [4] While this resembles our new short-term bias Pr[Zr = Zr+1], in their analysis they as- sume the internal state S is a random permutation, which is true only after a few rounds of the PRGA Isobe et While previous attacks against RC4 in TLS and WPA- TKIP were on the verge of practicality, our work pushes them towards being practical and feasible|,Non-data,143
| After cap- turing 9· 227 encryptions of a cookie sent over HTTPS, we can brute-force it with high success rates in negligi- ble time By running JavaScript code in the browser of the victim, we were able to execute the attack in practice within merely 52 hours Additionally, by abusing RC4 biases, we successfully attacked a WPA-TKIP network within an hour We consider it surprising this is possi- ble using only known biases, and expect these types of attacks to further improve in the future|,Non-data,143
| Based on these results, we strongly urge people to stop using RC4 110 24th USENIX Security Symposium  USENIX Association 14 9 Acknowledgements We thank Kenny Paterson for providing valuable feed- back during the preparation of the camera-ready paper, and Tom Van Goethem for helping with the JavaScript traffic generation code This research is partially funded by the Research Fund KU Leuven Mathy Vanhoef holds a Ph|,Non-data,143
|ABSTRACT Secure multilinear maps (mmaps) have been shown to have remarkable applications in cryptography, such as multi-input functional encryption (MIFE) and program obfuscation To date, there has been little evaluation of the performance of these applications In this paper we initiate a systematic study of mmap-based constructions We build a general framework, called 5Gen, to experiment with these applica- tions|,Non-data,3
| At the top layer we develop a compiler that takes in a high-level program and produces an optimized matrix branching program needed for the applications we consider Next, we optimize and experiment with several MIFE and obfuscation constructions and evaluate their performance The 5Gen framework is modular and can easily accommo- date new mmap constructions as well as new MIFE and obfuscation constructions, as well as being an open-source tool that can be used by other research groups to experiment with a variety of mmap-based constructions 1|,Non-data,3
| INTRODUCTION A multilinear map (mmap) [12] is an extremely power- ful tool for constructing advanced cryptographic systems numbers, is available at https://eprintiacrorg/2016/619 ∗The full version of this paper, with up-to-date performance †Portion of work done while at University of Maryland ‡Portion of work done while at Yale University|,Non-data,3
| Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page Copyrights for components of this work owned by others than the author(s) must be honored Abstracting with credit is permitted To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee|,Non-data,3
| Request permissions from permissions@acmorg CCS’16, October 24 - 28, 2016, Vienna, Austria c(cid:13) 2016 Copyright held by the owner/author(s) Publication rights licensed to ACM|,Non-data,3
 ISBN 978-1-4503-4139-4/16/10   $15,Non-data,3
00 DOI: http://dxdoiorg/101145/2976749,Non-data,3
|2978314 including program obfuscation [24], n-party non-interactive key exchange [12], multi-input functional encryption [30, 10], optimal broadcast encryption [13], witness encryption [26], and many others The recent emergence of candidate mmaps [23, 19, 20, 28] bring these proposals closer to re- ality, although several of the current candidates have been shown to be too weak for some of these applications, as dis- cussed in §5 Despite the remarkable power of mmaps, few published works study the efficiency of the resulting applications, pri- marily due to the rapid pace of development in the field and the high resource requirements needed for carrying out ex- periments In this paper we develop a generic framework called 5Gen1 (available at https://github|,Non-data,3
|com/5GenCrypto) that lets us experiment with powerful applications of current and future mmaps We focus on two applications in particu- lar: multi-input functional encryption (MIFE) and program obfuscation, both of which can be instantiated with some of the existing mmap candidates (see §5) Our framework is built as a multi-layer software stack where different layers can be implemented with any of the current candidates or replaced altogether as new constructions emerge The top layer of our framework is a system to compile a high-level program written in the Cryptol language [21] into a matrix branching program (MBP), as needed for the most efficient MIFE and obfuscation constructions|,Non-data,3
| We introduce several novel optimizations for obtaining efficient MBPs and show that our optimizations reduce both the dimension and the total number of matrices needed The next layer implements several variants of MIFE and obfuscation using a provided MBP This lets us experi- ment with several constructions and to compare their per- formance 1The name 5Gen comes from the fact that multilinear maps can be considered the “fifth generation” of cryptography, where the prior four are: symmetric key, public key, bilinear maps, and fully homomorphic encryption|,Non-data,3
| 981The lowest layer is the multilinear map library, libmmap We demonstrate our framework by experimenting with two leading candidate mmaps: GGHLite [23, 32, 2] and CLT [19, 20] Our experiments show that for the same level of se- curity, the CLT mmap performs considerably better than GGHLite in all the applications we tried, as explained in §8 (Although the GGH15 multilinear map [28] was not in- cluded in our implementation or experiments, we hope that future work might integrate this multilinear map into our framework|,Non-data,3
|) Our framework makes it possible to quickly plug in new mmaps as new proposals emerge, and easily measure their performance in applications like MIFE and obfuscation MIFE experiments Recall that functional encryption [11] is an encryption scheme where the decryption key skf is as- sociated with a function f  If c is the encryption of mes- sage m then decrypting c with the key skf gives the de- cryptor the value f (m) and nothing else|,Non-data,3
| An n-input MIFE scheme is the same, except that the function f now takes n inputs Given independently created ciphertexts c1,   |,Non-data,3
| , cn, with each ci an encryption of a message mi and associated with “slot” i, decrypting these ciphertexts using skf reveals f (m1,    , mn) and nothing else|,Non-data,3
| One important application of 2-input MIFE is order- revealing encryption (ORE) [30, 10] Here the function f (x, y) outputs 1 if x < y and 0 otherwise Thus, the key skf applied to ciphertexts c1 and c2 reveals the relative order of the corresponding plaintexts ORE is useful for respond- ing to range queries on an encrypted database|,Non-data,3
| For large domains, the only known constructions for secure ORE are based on mmaps We conduct experiments on ORE using real-world security parameters where mmaps give the best known secure construction We also experiment with 3-input MIFE Here, we choose a DNF formula f that operates on triples of inputs, which is useful in the context of privacy-preserving fraud detec- tion where a partially trusted gateway needs to flag suspi- cious transactions without learning anything else about the transactions (see the full version for details)|,Non-data,3
| Again, the best known construction for such a scheme uses mmaps We use our framework to evaluate the implementation of these schemes using existing mmaps for which they are cur- rently believed to be secure Clearly these systems are too inefficient to be used in practice Nevertheless, our exper- iments provide a data point for the current cost of using them|,Non-data,3
| Moreover, our framework makes it possible to eas- ily plug in better or more secure mmaps as they become available Obfuscation experiments Roughly speaking, an obfus- cator takes as input a program and outputs a functionally equivalent program such that the only way to learn infor- mation about the program is to run it We experiment with several obfuscators built on the obfuscator described by Barak et al|,Non-data,3
| [7], including those inspired by Sahai and Zhandry [39] and Ananth et al [3] These improvements allow for obfuscation of a point function with increased se- curity at less than half the total obfuscation size reported by Apon et al [4]|,Non-data,3
| We also implemented the Zimmerman [40] obfuscator, but we ultimately found that it was too ineffi- cient for the settings that we consider in our experiments 11 Our Contributions Summarizing, we make the following contributions: • An optimizing compiler from programs written in the Cryptol language to MBPs, which are used in many mmap applications including MIFE and obfuscation Our compiler uses optimizations such as dimension reduction, matrix pre-multiplication, and condens- ing the input representation, and solves a constraint- satisfaction problem needed to obtain the most effi- cient MBP|,Non-data,3
| See §4 for details • A library providing a clean API to various underly- ing mmap implementations This allows researchers to experiment with different mmaps, as well as to eas- ily plug future mmaps into our framework See §5 for more details|,Non-data,3
| • A general MIFE construction based on the scheme of Boneh et al [10] using real-world security parame- ters We contribute optimized implementations of two- input MIFE (in particular, order-revealing encryption) and three-input MIFE (in particular, a functionality needed for privacy-preserving fraud detection), as well as performance results that characterize our construc- tions See §6 for details and §8 for evaluation results|,Non-data,3
| • Obfuscation constructions [7, 39, 3, 40] using real- world security parameters We experiment with obfus- cating point functions and evaluate their performance See §7 for details and §8 for evaluation results 1|,Non-data,3
|2 Related Work Several groups have previously implemented mmaps [2, 19, 20] to experiment with their performance However, they did not go so far as experimenting with cryptographic applications of mmaps beyond direct applications such as multi-party non-interactive key exchange The goal of our work is to explore the performance of more advanced ap- plications such as MIFE and obfuscation An earlier work implementing obfuscation [4] experimented with obfuscating point functions, and was only able to successfully obfuscate a 14-bit point function|,Non-data,3
| Our work builds on the vast amount of previous work showing applications of mmaps—most notably, MIFE [30, 10] and obfuscation [15, 7, 38, 3, 40, 5, 29, 6, 34, 35, 27, 37, 22] 2 PRELIMINARIES In this section, we introduce notation and also define the various cryptographic constructions that we use in the rest of this work Notation|,Non-data,3
| For an integer n > 0, we use [n] to denote the set of integers {1,    , n}|,Non-data,3
| We use λ to represent the secu- rity parameter, where “λ-bit security” means that security should hold up to 2λ clock cycles We assume that all of our procedures run efficiently, or more formally, in polynomial- time with respect to the size of the input to the procedure, and polynomial in the security parameter λ Multilinear maps Boneh and Silverberg [12] first pro- posed the concept of multilinear maps (mmaps), but it was only in 2013 that Garg, Gentry, and Halevi [23] introduced the first plausible construction of an mmap|,Non-data,3
| Since then, mmaps have been shown to be powerful tools in solving nu- merous problems in cryptography 982Figure 31: Framework architecture We use cryfsm to compile a Cryptol program (here denoted by prog|,Non-data,3
|cry) to an MBP, which can either be used as input into our MIFE implementation or our obfuscation implementation Both these implementations use libmmap as a building block, which supports both the CLT (libclt) and GGH- Lite (libgghlite) mmaps A multilinear map [12, 23] (or graded encoding scheme) is a primitive for producing randomized encodings of plaintexts that may be publicly added, multiplied, and zero-tested but otherwise “do not reveal any information” Encodings are associated with a “level” that restricts the types of operations that may be performed on that encoding|,Non-data,3
| More formally, a degree-κ multilinear map is a tuple of algorithms (Setup, Encode, Add, Mult, ZeroTest) where: • Setup takes as input the security parameter, and out- puts a private parameter sp and a public parameter pp that, in particular, specifies a ring R • Encode takes sp, an element x ∈ R, and a level S ⊆ [κ], and outputs a level-S encoding of x denoted(cid:74)x(cid:75)S • Add takes pp and two encodings(cid:74)x(cid:75)S,(cid:74)y(cid:75)S at the same level S, and outputs an encoding(cid:74)x + y(cid:75)S • Mult takes pp and two encodings(cid:74)x(cid:75)S1 ,(cid:74)y(cid:75)S2 joint levels S1, S2, and outputs an encoding(cid:74)x · y(cid:75)S1∪S2 • ZeroTest takes pp and an encoding (cid:74)x(cid:75)U for U = [κ]|,Non-data,3
| It outputs 1 if and only if x = 0 for dis- Informally, an mmap is secure if the only information that an attacker can figure out from the encodings of random elements is exactly the information that can be obtained from running Add, Mult, and ZeroTest, and no more (We omit any formal definitions since we do not directly rely on them in this work but instead inherit them from prior work) Matrix branching programs|,Non-data,3
| A matrix branching pro- gram (MBP) on length-n, base-d inputs is a collection of variable-dimension matrices Bi,j for i ∈ [n] and j ∈ {0,    , d − 1}, along with a “final matrix” P|,Non-data,3
| We require that, for each i ∈ [2, n] and j ∈ {0,    , d− 1}, the number of columns of Bi−1,j is equal to the number of rows of Bi,j, so that the product of these matrices is well-defined|,Non-data,3
| The evaluation of an MBP on input x ∈ {0,    , d − 1}n is defined as (cid:40) if (cid:81)n MBP(x) = 1, 0, otherwise|,Non-data,3
| i=1 Bi,xi = P, We note that numerous generalizations and extra proper- ties [10, 39] of MBPs have been explored in the literature— however, we will only need to use our simplified definition of MBPs for the remainder of this work 3 FRAMEWORK ARCHITECTURE Our framework incorporates several software components that together enable the construction of applications using mmaps and MBPs In particular, we use our framework to develop implementations of MIFE and program obfuscation|,Non-data,3
| See Figure 31 for the framework architecture The top layer of our framework, cryfsm, takes as input a program written in Cryptol [21], a high-level language de- signed to express manipulations over bitstreams in a con- cise syntax, and compiles the program into an MBP This process, and the various optimizations we introduce, are de- scribed in more detail in §4|,Non-data,3
| The bottom layer of our framework, libmmap, provides an API for using various mmaps, which in our case includes the CLT (through the libclt library) and GGHLite (through the libgghlite library) mmaps The libmmap library, which we describe in §5, is also designed to allow for a straightfor- ward integration of future mmap implementations We combine the above components to realize various ap- in particular, MIFE and plications of mmaps and MBPs: program obfuscation We demonstrate the applicability of our MIFE implementation (cf|,Non-data,3
| §6) through two examples: order-revealing encryption (ORE) and, in the full version, three-input DNF (3DNF) encryption We implement pro- gram obfuscation based on two main approaches: the tech- niques described by Sahai and Zhandry [39], and also the scheme by Zimmerman [40], which operates over arithmetic circuits, but only applies to the CLT mmap 4 FROM PROGRAMS TO MBPS One of our key contributions in this work is a compiler, cryfsm, that takes as input a program written in Cryp- tol [21], a domain-specific language for specifying algorithms over generic streams of bits, and produces an MBP for the given input program|,Non-data,3
| cryfsm does this by translating a Cryptol specification into a layered state machine, which can then be transformed into an optimized corresponding MBP Our toolchain proceeds as follows The user writes a Cryp- tol function of type [n] -> Bit for some n (that is, the function takes n input bits and produces one output bit) This function is interpreted as deciding membership in a lan- guage|,Non-data,3
| The toolchain symbolically evaluates this function to produce a new version of the function suitable for input to an SMT solver, as explained in detail below Queries to the SMT solver take the form of deciding the prefix equivalence relation between two initial bitstrings, which is sufficient to build the minimal layered state machine, which we then con- vert to an MBP Our solver-based approach results in a substantial dimen- sion reduction of the corresponding output MBPs that we tested In contrast, the traditional approach would be to heuristically optimize the state machine design in an at- tempt to achieve a best-effort optimization|,Non-data,3
| The dimen- sion reduction we achieve recovers the most efficient known MBPs for several previously studied bit-string functions, including MBPs for point functions that are smaller than the MBPs constructed from boolean formulas using exist- ing techniques (eg, [39]) In the remainder of this section, we describe the key steps in this toolchain, along with sev- eral optimizations to the MBPs that we use throughout the remainder of this work|,Non-data,3
| Specifying functions in Cryptol Cryptol is an existing language widely used in the intelligence community for de- scribing cryptographic algorithms A well-formed Cryptol program looks like an algorithm specification, and is exe-  983cutable|,Non-data,3
| The Cryptol tool suite supports such execution, along with capabilities to state, verify, and formally prove properties of Cryptol specifications, and capabilities to both prove equivalence of implementation in other languages to Cryptol specifications and automatically generate such im- plementations In our work, a user specifies an MBP in Cryptol, and then we use cryfsm to transform the high- level specification into a minimal layered state machine, and further transform it into an efficient MBP Minimal layered state machines There is a standard translation from traditional finite state machines to MBPs: create a sequence of matrix pairs (or matrix triples for three- symbol alphabets, etc|,Non-data,3
|) that describe the adjacency relation between states If state i transitions to state j on input symbol number b, then the bth MBP matrix will have a 1 in the ith row and jth column and 0 elsewhere For many languages of interest, this is inefficient: for an automaton with ||S|| states, each matrix must be of size ||S||2, even though many states may be unreachable In the applications of mmaps that we study in this work, we consider functions on inputs of a fixed length|,Non-data,3
| Hence, for a positive integer n, we can take advantage of this property by restricting ourselves to layered state machines of depth n, which are simply (deterministic) finite state machines that only accept length-n inputs Here, the ith “layer” of transi- tions in the machine is only used when reading the ith digit of the input As a result, layered state machines are acyclic To generate minimal layered state machines, our compiler must introduce machinery to track which states are reach- able at each layer, which allows us to reduce the overall MBP matrix dimensions|,Non-data,3
| To do this, cryfsm computes the quotient automaton of the layered state machine using an SMT solver to decide the state equivalence relation The quotient automaton is then used as the new minimal lay- ered state machine for the specified function Then, from a layered state machine of depth n, we construct the cor- responding MBP on base-d inputs of length n in a manner essentially equivalent to the techniques of Ananth et al [3] for constructing layered branching programs|,Non-data,3
| Intuitively, for each i ∈ [n] and j ∈ [d], the ith matrix associated with the jth digit is simply the adjacency matrix corresponding to the transitions belonging to the ith layer of the machine, associated with reading the digit j Then, the “final matrix” (that defines the output of the MBP being 1) is simply the adjacency matrix linking the initial state to the final state of the layered state machine Optimizations for MBP creation Boneh et al|,Non-data,3
| [10] de- scribe a simple five-state finite state machine appropriate for ORE applications, and describe the translation to MBPs that produces 5 × 5 matrices at each depth The MBP we build and use for our ORE application differs from this one via three transformations that can be generalized to other programs: change of base, matrix premultiplication, and di- mension reduction Of these, matrix premultiplication and dimension reduction are a direct consequence of the tech- nique used by cryfsm for constructing MBPs and therefore automatically apply to all programs, whereas choosing an input base remains a manual process because it must be guided by outside knowledge about the performance char- acteristics of the mmap used to encode the MBPs While the change of base and matrix pre-multiplication optimiza- tions are described by Boneh et al|,Non-data,3
|, we introduce dimension reduction as a new optimization that is useful for ORE yet generalizable to other applications For each optimization, we use the integer d to represent the “input base”, the integer n to represent the length (num- ber of digits) of each input, the integer N to represent the input domain size (so, we have that dn ≥ N ), the integer m to represent the length of the MBP, and the integer M to represent the total number of elements across all the matri- ces of the MBP At a high level, the optimizations are as follows • Condensing the input representation corresponds to processing multiple bits of the input, by increasing d, to reduce the length of the MBP, at the expense of increasing the number M of total elements|,Non-data,3
| • Matrix premultiplication also aims to reduce the parameter m, but without increasing the parameter M  • Dimension reduction aims to directly reduce the number M of total elements, but may not be fully compatible with matrix premultiplication, depending on the function To help with the understanding of the intuition behind these optimizations, we use the simple comparison state ma- chine as a running example—however, we stress that these optimizations are in no way specific to the comparison func- tion, and can be applied more generally to any function ex- pressed as a layered state machine Condensing the input representation|,Non-data,3
| The most imme- diate optimization that we apply is to condense the repre- sentation of inputs fed to our state machines MBPs are tra- ditionally defined as operating on bitstrings, so it is natural to begin with state machines that use bits as their alphabet, but using larger alphabets can cut down on the number of state transitions needed (at the potential cost of increasing the state space) As an example, for evaluating the comparison state ma- chine, this optimization translates to representing the input strings in a larger base d > 2, and to adjust the comparison state machine to evaluate using base-d representations The resulting state machine consists of d + 3 total states|,Non-data,3
| A naive representation of an input domain of size N with a state machine that processes the inputs bit-by-bit (in other words, d = 2) would induce an MBP length of m = 2 · (cid:100)log2(N )(cid:101) and M = 50 · m total elements (in two 5 × 5 matrices) However, by using the corresponding comparison state machine that recognizes the language when the inputs are in base-d, we can then set m = 2 · (cid:100)logd(N )/ log2(d)(cid:101) and M = 2 · (d + 3)2 · m Concretely, setting N = 1012, without condensing the in- put representation, we require m = 80 and M = 2000 for the resulting MBP However, if we represent the input in base-4, we can then obtain m = 20 and M = 1960, a strict improvement in parameters|,Non-data,3
| Matrix premultiplication Boneh et al [10] informally describe a simple optimization to the comparison state ma- chine, which we explain in more detail here The natural state machine for evaluating the comparison function on two n-bit inputs x and y reads the bits of x and y in the order x1y1x2y2 ··· xnyn|,Non-data,3
| However, Boneh et al show that a slight reordering of the processing of these input bits can result in reduced MBP length without compromising in correctness When the in- 984puts are instead read in the following order: vtable function comments x1y1y2x2x3y3 ··· ynxn, (1) mmap_pp_vtable fread/fwrite clear read/write public parameters clear public params then, rather than producing one matrix for each input bit position during encryption, the two matrices corresponding to y1 and y2 can be pre-multiplied, and the result is a sin- gle matrix representing two digit positions Naturally, this premultiplication can be performed for each pair of adjacent bit positions belonging to the same input string (such as for x2x3, y3y4, and so on), and hence the number of matrices produced is slightly over half of the number of matrices in the naive ordering of input bits|,Non-data,3
| As a result, for evaluating the comparison state machine, where n is the length of the base-d representation of an in- put, applying this optimization implies m = n + 1, a re- duction from the naive input ordering, which would result in m = 2n, and a reduction from M = 2 · (d + 3)2 · m to M = (d + 3)2 · m When applying this optimization in conjunction with representing the input in base d = 4, for example, setting N = 1012 only requires m = 21 and M = 1029, a huge reduction in cost that was emphasized by Boneh et al, and another strict improvement in parameters A new optimization: dimension reduction|,Non-data,3
| We now describe a more sophisticated optimization that can be ap- plied to general MBPs which also results in a reduced ci- phertext size As an example, we describe this optimization, called dimension reduction, as it applies to the comparison function state machine (without applying the reordering of input bits from matrix premultiplication), but we emphasize that the technique does not inherently use the structure of this state machine in any crucial way, and can naturally be extended to general MBPs Our new optimization stems from the observation that, for each bit position in the automaton evaluation, the tran- sitions in the automaton do not involve all of the states in the automaton This is the same observation that motivates the use of layered state machines over finite state machines|,Non-data,3
| In particular, for the even-numbered bit positions, the transitions map from a set of d states to a set of only 3 states Similarly, for the odd-numbered bit positions, the transitions map from a set of (at most) 3 states to a set of d states As a result, the corresponding matrices for each bit position need only be of dimension d × 3 or 3 × d (depend- ing on the parity), as opposed to the naive interpretation of the Boneh et al construction which requires matrices of dimension (d + 3) × (d + 3)|,Non-data,3
| Note, however, that the dimension reduction optimization is not fully compatible with matrix premultiplication, since the effectiveness of dimension reduction can degrade if ma- trix premultiplication is also applied In particular, when applying matrix premultiplication to the comparison state machine, we notice that there is less room for improvements with dimension reduction, as the transitions for the position y1y2 correlate from a domain of d states to a range of also d states In §61, we concretely show how to apply a mixture of these optimizations to the comparison automaton, and then use these optimizations to obtain asymptotically shorter ci- phertexts for order-revealing encryption|,Non-data,3
| mmap_sk_vtable init/clear fread/fwrite initialize/clear secret key read/write secret key mmap_enc_vtable init/clear fread/fwrite set add mul is_zero encode initialize/clear encoding read/write encoding copy encoding implements Add implements Mult implements ZeroTest implements Encode Table 51: Interfaces exported by the libmmap library 5 A LIBRARY FOR MULTILINEAR MAPS In this section we describe our library, libmmap, which provides an API for interacting with different mmap back- ends|,Non-data,3
| In this work we implement GGHLite (libgghlite) and CLT (libclt) backends2, although we believe that it should be relatively straightforward to support future mmap implementations The libmmap library exports as its main interface a virtual method table mmap_vtable, which in turn contains virtual method tables for the public parameters (mmap_pp_vtable), the secret key (mmap_sk_vtable), and the encoded values (mmap_enc_vtable) Table 51 lists the available functions within each table|,Non-data,3
| Each underlying mmap library must ex- port functions matching these function interfaces and write a wrapper within libmmap to match the virtual method table interface A user of libmmap then defines a pointer const mmap_vtable * which points to the virtual method table corresponding to the mmap of the user’s choice (in our case, either clt_vtable or gghlite_vtable) In the following, we describe the two mmap schemes we support within libmmap: libgghlite (§51) and libclt (§5|,Non-data,3
2) Figure 51 presents estimates for the size of an encoding using GGHLite and CLT for security parameters λ = 80 and λ = 40 We describe our parameter choices for arriving at these estimates in the full version,Non-data,3
| As we can see, the CLT mmap produces smaller encodings than GGHLite as we vary both λ and κ This appears to be due to the growth of the lattice dimension in GGHLite compared to the number of secret primes required by the CLT scheme, among other factors 51 The GGHLite Multilinear Map Building off of the original mmap candidate construction of Garg et al|,Non-data,3
| (GGH) [23], Langlois et al [32] proposed a modification called GGHLite, along with parameter and performance estimates for the resulting encodings of the scheme More recently, Albrecht et al [2] proposed further modifications and optimizations on top of GGHLite, along with an implementation of their scheme under an open- source license|,Non-data,3
| In this work, we refer to GGHLite as the construction from the work of Albrecht et al, as opposed to the original work of Langlois et al Our GGHLite implementation We use as our start- ing point the implementation of GGHLite3 released by Al- brecht et al|,Non-data,3
 [2] We modified this implementation to add 2We also have a “dummy” mmap implementation for testing purposes 3https://bitbucketcom/malb/gghlite-flint 985) B M ( e z i S i g n d o c n E 100 10 1 0,Non-data,3
|1 001 GGHLite (λ = 80) GGHLite (λ = 40) CLT (λ = 80) CLT (λ = 40) 2 5 10 15 20 25 30 Degree κ Figure 51: Estimates for the size of a single encoding in megabytes (MB) produced for security parameters λ = 80 and λ = 40 and varying the multilinearity degree κ ∈ [2, 30] for the GGHLite and CLT mmaps functionality for handling the reading and writing of encod- ings, secret parameters, and public parameters to disk|,Non-data,3
| We also extended the implementation to handle more expres- sive index sets, which are used in MIFE and obfuscation, as follows Typically, multilinear maps only support “levels”, where each encoding is created with respect to an integer i ∈ [κ] (for an mmap of degree κ) The GGHLite implementation supports more advanced labelings of encodings, by allowing for a universe U of κ indices to be defined, and each encoding can be created with respect to a singleton subset (contain- ing only one element) of this universe U  Multiplication of two encodings with respect to sets of indices S1 and S2 pro- duces an encoding with respect to the multiset union of S1 and S2|,Non-data,3
| The zero-testing parameter is then created to test for encodings which are labeled with respect to U  How- ever, this functionality is still not sufficiently expressive to match the needs of our implementation and our definition of mmaps Consequently, we upgraded the handling of these encod- ings to support labelings of an encoding with respect to any subset S of indices of the universe U  Then, when two en- codings labeled with two different subsets are multiplied, the resulting encoding is labeled with respect to their multi-set union|,Non-data,3
| Finally, as before, the zero-testing parameter allows to check for encodings of 0 labeled at U , only Finally, we isolated and rewrote the randomness gener- ation procedures used by GGHLite, since the original im- plementation relied on the randomness obtained from the GMP library, which is not generated securely We split this into a separate library, libaesrand, which uses AES-NI for efficient randomness generation, and which may be useful in other contexts Attacks on GGHLite|,Non-data,3
| Recently, Hu and Jia [31] showed how to perform “zeroizing” attacks on GGHLite, to recover the secret parameters given certain public encodings of 0 However, since neither MIFE nor obfuscation publish any encodings of 0, these applications seem to be unaffected by the zeroizing attacks More recently, Albrecht, Bai, and Ducas [1] gave a quantum break for GGHLite without us- ing any encodings of 0 or the public zero-testing parameter Subsequently, Cheon, Jeong, and Lee [17] showed how to give a (classical) polynomial-time attack on GGHLite, again without using any encodings of 0|,Non-data,3
| However, their attack re- quires exponential time if the parameters of GGHLite are sufficiently increased (by a polynomial amount) In concurrent work, Miles, Sahai, and Zhandry [36] gave a completely different form of attack, known as an “annihila- tion” attack, on applications of GGHLite, specifically, MIFE and program obfuscation They show that provably secure instantiations of these primitives from mmaps are in fact insecure when the mmap is instantiated with GGHLite De- spite the annihilation attacks, our implementations of these primitives from GGHLite still serve as a useful benchmark for the efficiency of GGHLite and for the efficiency of future GGH-like schemes resistant to annihilation attacks, which will inevitably arise from improvements to the GGH frame- work|,Non-data,3
| 52 The CLT Multilinear Map Coron, Lepoint, and Tibouchi [19] proposed a candidate multilinear map over the integers, which works over a com- posite modulus that is assumed to be hard to factor Our CLT implementation Our implementation started with the implementation4 of CLT in C++ by Coron et al|,Non-data,3
| [19] We rewrote it in C and added functionality to save and re- store encodings and the public parameters As in the GGH- Lite case, we also modified its basic functionality to support indices instead of levels Furthermore, in our extension of CLT, we improve the ef- ficiency of the encoding process which allows for us to apply the CLT multilinear map to the large parameter settings that we consider in the remainder of this work|,Non-data,3
| The original CLT implementation applies the Chinese Remainder Theo- rem in the procedure that produces encodings of plaintext elements Our implementation employs a certain trade-off that allows for the application of the Chinese Remainder Theorem in a recursive manner, resulting in more multi- plications to compute the encoding, but with the efficiency gain that the elements being multiplied are much smaller Experimentally, this yields a large speedup in the encoding time, more noticeably with larger parameters In particular, for λ = 80 and κ = 19, without this optimization, it takes 134 seconds to produce a CLT encoding, whereas with our optimization, this time drops to 33 seconds|,Non-data,3
| Attacks on CLT Similarly to other candidate construc- tions for multilinear maps, the CLT construction was not based on an existing hardness assumption but rather intro- duced a new assumption Subsequently Cheon et al [16] demonstrated a zeroizing attack against the construction of CLT, which succeeds in recovering the secret parame- ters of the scheme|,Non-data,3
| This attack was further extended in the work of Coron et al [18], which demonstrated how it can be generalized and applied against some proposed countermea- sures [14, 25] to the attack by Cheon et al [16] But again, as with the zeroizing attacks on GGHLite, these results do not apply directly to the constructions we consider in this work|,Non-data,3
| 6 MULTI-INPUT FUNCTIONAL ENCRYPTION The notion of multi-input functional encryption (MIFE), introduced by Goldwasser et al [30], extends the concept of functional encryption [11] so that a decryption key is asso- 4https://githubcom/tlepoint/multimap 986ciated with a multi-input function which is evaluated over multiple ciphertexts|,Non-data,3
| More formally, a secret-key, fixed-key MIFE scheme for a function f , on m inputs and with output in a range R, is a tuple of algorithms (keygen, encrypt, eval) such that: • keygen(1λ) → (pp, sk) The algorithm takes as input the security parameter and generates the public pa- rameters pp and a secret key sk • encrypt(sk, i, x) → ct The algorithm takes as input the secret key sk, an input position index i, and an input x, and outputs a ciphertext ct|,Non-data,3
| • eval(pp, ct1,    , ctm) → z|,Non-data,3
| The algorithm takes as in- put a secret key sk and m ciphertexts ct1,    , ctm, and produces an output z ∈ R|,Non-data,3
| Correctness requires that for any inputs x1,    , xm, for (pp, sk) ← keygen(1λ), letting cti = encrypt(sk, i, xi) for each i ∈ [m], we have that eval(pp, ct1, |,Non-data,3
|   , ctm) = f (x1,  |,Non-data,3
|  , xm) Informally, an MIFE scheme is secure if the information revealed by a collection of ciphertexts is exactly the infor- mation that can be obtained by running eval, and no more We omit formal security definitions since we do not directly rely on them in this work|,Non-data,3
 Goldwasser et al [30] gave a general MIFE construc- tion that uses indistinguishability obfuscation in a black- box manner Boneh et al [10] proposed a secret-key MIFE construction that is based directly on mmaps (instead of ob- fuscation) in order to obtain better efficiency,Non-data,3
| A particular instantiation of this MIFE construction, where the function used in the decryption key is the comparison function, re- sults in a construction for order revealing encryption (ORE), which allows comparisons over ciphertexts while hiding all other information about the encrypted messages More specifically, an ORE scheme is a MIFE scheme with the function f (x, y) that outputs the ordering between x and y This ORE scheme achieves the optimal security definition for a scheme that allows the comparison functionality over encrypted data, improving over the security level provided by order-preserving encryption schemes MIFE implementation|,Non-data,3
| We implemented the Boneh et al [10] MIFE construction on top of the libmmap library, and provide interfaces for keygen, encrypt, and eval, which perform the respective operations supported by MIFE We parallelize the computation performed during keygen, but for encrypt, we choose to sequentially construct the encod- ings belonging to the ciphertext, and instead defer the par- allelism to the underlying mmap implementation for pro- ducing encodings, in the interest of reducing memory usage at the cost of potentially increased running times We note that, since CLT enjoys much more parallelism than GGH- Lite when constructing encodings, this optimization causes the encrypt time for GGHLite to be less efficient|,Non-data,3
| Finally, for eval, we multiply encodings in parallel for CLT, since the multiplication of CLT encodings natively does not support parallelism However, for GGHLite, we choose to multiply encodings sequentially, and instead rely on the parallelism afforded by GGHLite encoding multiplication The ciphertexts produced by a call to encrypt on an (cid:96)- length input are split into (cid:96) components (one for each input slot), which can be easily separated and combined with dif- ferent components from other ciphertexts in a later call to eval Hence, with a collection of full ciphertexts, an eval- uator can specify which components from each ciphertext should be passed as input to eval, in order to evaluate the function on components originating from different sources|,Non-data,3
| 61 Optimizing Comparisons In this section, we describe a case study of applying the optimizations detailed in §4 to the comparison function We establish two distinct “variants” of the comparison function which result in shorter ciphertext sizes Both variants are built from a combination of condensing the input represen- tation into a larger base d > 2, followed by dimension re- duction, and optionally applying matrix pre-multiplication|,Non-data,3
| • DC-variant The degree-compressed optimization is to first apply matrix pre-multiplication to re-order the reading of the input bits as in Equation (1) Then, the dimensions of the resulting matrices from the layered state machine are slightly reduced • MC-variant|,Non-data,3
| The matrix-compressed optimization is to directly apply dimension reduction in the normal in- terleaved ordering of the bits (as x1y1x2y2 ··· xnyn) Here, the dimensions of the matrices can be reduced to depend only linearly in the base representation d, as opposed to quadratically We now discuss each optimization in more detail The degree-compressed variant (DC-variant)|,Non-data,3
| By op- timizing the (layered) comparison state machine, we obtain that not all matrices need to be of dimension (d+3)×(d+3) For example, the first matrix need only be of dimension 1×d, and the second matrix need only be of dimension d× (d + 2) Also, the last matrix can be of dimension (d + 2)× 3 And fi- nally, each of the remaining intermediate matrices need only be of dimension (d + 2)× (d + 2)|,Non-data,3
