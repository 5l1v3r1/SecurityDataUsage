 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
 45 Analysis First we observe that the agreement and total order properties follow immediately from the definition of ACS and robustness of the TPKE scheme THEOREM 1 (Agreement and total order),Non-data,97
| The HoneyBad- gerBFT protocol satisfies the agreement and total order properties, except for negligible probability 4The expected running time can be reduced to O(1) (cf [8]) by run- ning several instances in parallel, though this comes at the expense of throughput|,Non-data,97
| Algorithm ACS (for party Pi) Let {RBCi}N refer to N instances of the reliable broadcast pro- tocol, where Pi is the sender of RBCi Let {BAi}N refer to N instances of the binary byzantine agreement protocol • upon receiving input vi, input vi to RBCi // See Figure 2 • upon delivery of v j from RBC j, if input has not yet been pro- vided to BA j, then provide input 1 to BA j See the online full version [42] • upon delivery of value 1 from at least N − f instances of BA, provide input 0 to each instance of BA that has not yet been provided input|,Non-data,97
| • once all instances of BA have completed, let C ⊂ [1N] be the indexes of each BA that delivered 1 Wait for the output v j for each RBC j such that j ∈ C|,Non-data,97
 Finally output ∪ j∈Cv j Figure 4: Common Subset Agreement protocol (from Ben-Or et al [9]) RBC2RBC3RBC1BA1BA2BA3YesNoV1CoinCoinCoinCoinCoinCoinCoinYes(a) NormalYesV2(b) Wait for slow broadcast(c) Broadcast failsNo,Non-data,97
,Non-data,97
|Time38For deterministic erasure coding, we use the zfec library [52], which implements Reed-Solomon codes For instantiating the com- mon coin primitive, we implement Boldyreva’s pairing-based thresh- old signature scheme [11]|,Non-data,97
| For threshold encryption of transactions, we use Baek and Zheng’s scheme [7] to encrypt a 256-bit ephemeral key, followed by AES-256 in CBC mode over the actual payload We implement these threshold cryptography schemes using the Charm [3] Python wrappers for PBC library [38] For threshold sig- natures, we use the provided MNT224 curve, resulting in signatures (and signature shares) of only 65 bytes, and heuristically providing 112 bits of security6 Our threshold encryption scheme requires a symmetric bilinear group: we therefore use the SS512 group, which heuristically provides 80 bits of security [45]|,Non-data,97
|7 In our EC2 experiments, we use ordinary (unauthenticated) TCP sockets In a real deployment we would use TLS with both client and server authentication, adding insignificant overhead for long- lived sessions Similarly, in our Tor experiment, only one endpoint of each socket is authenticated (via the “hidden service” address) Our theoretical model assumes nodes have unbounded buffers|,Non-data,97
| In practice, more resources could be added dynamically to a node whenever memory consumption reaches a watermark, (eg, when- ever it is 75% full) though our prototype implementation does not yet include this feature Failure to provision an adequate buffer would count against the failure budget f |,Non-data,97
| 51 Bandwidth Breakdown and Evaluation We first analyze the bandwidth costs of our system In all exper- iments, we assume a constant transaction size of mT = 250 bytes each, which would admit an ECDSA signature, two public keys, as well as an application payload (ie|,Non-data,97
|, approximately the size of a typical Bitcoin transaction) Our experiments use the parameter N = 4 f ,8 and each party proposes a batch of B/N transactions To model the worst case scenario, nodes begin with identical queues of size B We record the running time as the time from the beginning of the experiment to when the (N − f )-th node outputs a value|,Non-data,97
| Bandwidth and breakdown findings The overall bandwidth con- sumed by each node consists of a fixed additive overhead as well as a transaction dependent overhead For all parameter values we considered, the additive overhead is dominated by an O(λ N2) term resulting from the threshold cryptography in the ABA phases and the decryption phase that follows The ABA phase involves each node transmitting 4N2 signature shares in expectation|,Non-data,97
| Only the RBC phase incurs a transaction-dependent overhead, equal to the erasure coding expansion factor r = N N−2 f  The RBC phase also contributes N2 logN hashes to the overhead because of Merkle tree branches included in the ECHO messages The total communication cost (per node) is estimated as: mall = r(BmT + NmE) + N2((1 + logN)mH + mD + 4mS) where mE and mD are respectively the size of a ciphertext and decryption share in the TPKE scheme, and mS is the size of a TSIG signature share 6Earlier reports estimate 112 bits of security for the MNT224 curve [45]; however, recent improvements in computing discrete log suggest larger parameters are required [28, 29]|,Non-data,97
| 7We justify the relatively weak 80-bit security level for our parame- ters because the secrecy needs are short-lived as the plaintexts are revealed after each batch is committed To defend against precompu- tation attacks, the public parameters and keys should be periodically regenerated 8The setting N = 4 f is not the maximum fault tolerance, but it is convenient when f divides N Figure 5: Estimated communication cost in megabytes (per node) for varying batch sizes|,Non-data,97
| For small batch sizes, the fixed cost grows with O(N2 logN) At saturation, the overhead factor approaches N N−2 f < 3 Figure 6: Throughput (transactions committed per second) vs number of transactions proposed Error bars indicate 95% confidence intervals|,Non-data,97
| The system’s effective throughput increases as we increase the proposed batch size B, such that the transaction-dependent portion of the cost dominates As Figure 5 shows, for N = 128, for batch sizes up to 1024 transactions, the transaction-independent bandwidth still dominates to overall cost However, when when the batch size reaches 16384, the transaction-dependent portion begins to dominate — largely resulting from the RBCECHO stage where nodes transmit erasure-coded blocks|,Non-data,97
| 52 Experiments on Amazon EC2 To see how practical our design is, we deployed our protocol on Amazon EC2 services and comprehensively tested its performance We ran HoneyBagderBFT on 32, 40, 48, 56, 64, and 104 Amazon EC2 t2medium instances uniformly distributed throughout its 8 regions spanning 5 continents|,Non-data,97
| In our experiments, we varied the batch size such that each node proposed 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536, or 131072 transactions Throughput Throughput is defined as the number of transactions committed per unit of time In our experiment, we use “confirmed transactions per second” as our measure unit if not specified oth- erwise|,Non-data,97
 Figure 6 shows the relationship between throughput and total number of transactions proposed by all N parties The fault tolerance parameter is set to be f = N/4 100101102103104105Batch size (Tx) in log scale10-210-1100101102Communication cost per node (MB)Nodes / Tolerance8/216/432/864/16128/32ideal105106Batch size (Tx) in log scale102103104Throughput (Tx per second) in log scaleNodes / Tolerance32/840/1048/1256/1464/16104/2639HoneyBadgerBFT PBFT ·104 2 ) d n o c e s r e p x T ( t u p h g u o r h T m u m i x a M 15 1 0,Non-data,97
|5 0 8 nodes 16 nodes 32 nodes 64 nodes Figure 8: Comparison with PBFT on EC2s tributes this load evenly among the network links, whereas PBFT bottlenecks on the leader’s available bandwidth Thus PBFT’s at- tainable throughput diminishes with the number of nodes, while HoneyBadgerBFT’s remains roughly constant Note that this experiment reflects only the optimistic case, with no faults or network interruptions Even for small networks, HoneyBad- gerBFT provides significantly better robustness under adversarial conditions as noted in Section 3|,Non-data,97
| In particular, PBFT would achieve zero throughput against an adversarial asynchronous scheduler, whereas HoneyBadgerBFT would complete epochs at a regular rate 53 Experiments over Tor To demonstrate the robustness of HoneyBadgerBFT, we run the first instance (to our knowledge) of a fault tolerant consensus proto- col carried out over Tor (the most successful anonymous communi- cation network) Tor adds significant and varying latency compared to our original AWS deployment|,Non-data,97
| Regardless, we show that we can run HoneyBadgerBFT without tuning any parameters Hiding Hon- eyBadgerBFT nodes behind the shroud of Tor may offer even better robustness Since it helps the nodes to conceal their IP addresses, it can help them avoid targeted network attacks and attacks involving their physical location Brief background on Tor|,Non-data,97
| The Tor network consists of approxi- mately 6,500 relays, which are listed in a public directory service Tor enables “hidden services,” which are servers that accept con- nections via Tor in order to conceal their location When a client establishes a connection to a hidden service, both the client and the server construct 3-hop circuits to a common “rendezvous point” Thus each connection to a hidden service routes data through 5 randomly chosen relays|,Non-data,97
| Tor provides a means for relay nodes to advertise their capacity and utilization, and these self-reported met- rics are aggregated by the Tor project According to these metrics,9 the total capacity of the network is ∼145Gbps, and the current utilization is ∼65Gbps Tor experiment setup We design our experiment setup such that we could run all N HoneyBadgerBFT nodes on a single desktop machine running the Tor daemon software, while being able to re- alistically reflect Tor relay paths|,Non-data,97
| To do this, we configured our machine to listen on N hidden services (one hidden service for each HoneyBadgerBFT node in our simulated network) Since each HoneyBadgerBFT node forms a connection to each other node, we construct a total of N2 Tor circuits per experiment, beginning and ending with our machine, and passing through 5 random relays In summary, all pairwise overlay links traverse real Tor circuits con- 9https://metricstorproject|,Non-data,97
|org/bandwidthhtml as of Nov 10, 2015 Figure 7: Latency vs throughput for experiments over wide area networks Error bars indicate 95% confidence intervals|,Non-data,97
| Findings From Figure 6 we can see for each setting, the through- put increases as the number of proposed transactions increases We achieve throughput exceeding 20,000 transactions per second for medium size networks of up to 40 nodes For a large 104 node network, we attain more than 1,500 transactions per second|,Non-data,97
| Given an infinite batch size, all network sizes would eventually converge to a common upper bound, limited only by available bandwidth Although the total bandwidth consumed in the network increases (linearly) with each additional node, the additional nodes also con- tribute additional bandwidth capacity Throughput, latency, and scale tradeoffs Latency is defined as the time interval between the time the first node receives a client request and when the (N − f )-th node finishes the consensus pro- tocol|,Non-data,97
| This is reasonable because the (N − f )-th node finishing the protocol implies the accomplishment of the consensus for the honest parties Figure 7 shows the relationship between latency and throughput for different choices of N and f = N/4 The positive slopes indi- cate that our experiments have not yet fully saturated the available bandwidth, and we would attain better throughput even with larger batch sizes Figure 7 also shows that latency increases as the number of nodes increases, largely stemming from the ABA phase of the protocol|,Non-data,97
| In fact, at N = 104, for the range of batch sizes we tried, our system is CPU bound rather than bandwidth bound because our implementation is single threaded and must verify O(N2) thresh- old signatures Regardless, our largest experiment with 104 nodes completes in under 6 minutes Although more nodes (with equal bandwidth provisioning) could be added to the network without affecting maximum attainable throughput, the minimal bandwidth consumed to commit one batch (and therefore the latency) increases with O(N2 logN) This con- straint implies a limit on scalability, depending on the cost of band- width and users’ latency tolerance|,Non-data,97
| Comparison with PBFT Figure 8 shows a comparison with the PBFT protocol, a classic BFT protocol for partially synchronous networks We use the Python implementation from Croman et al [24], running on 8, 16, 32, and 64 nodes evenly distributed among Amazon AWS regions|,Non-data,97
| Batch sizes were chosen to saturate the network’s available bandwidth Fundamentally, while PBFT and our protocol have the same asymptotic communication complexity in total, our protocol dis- 05000100001500020000Throughput (Tx per second)101102Latency (seconds) in log scaleNodes / Tolerance32/840/1048/1256/1464/16104/2640MACS/Simons Collaboration in Cryptography through NSF grant CNS-1523467 7 |,Non-data,97
|ABSTRACT Thanks to their anonymity (pseudonymity) and elimina- tion of trusted intermediaries, cryptocurrencies such as Bit- coin have created or stimulated growth in many businesses and communities Unfortunately, some of these are crim- inal, eg, money laundering, illicit marketplaces, and ran- somware|,Non-data,99
| Next-generation cryptocurrencies such as Ethereum will include rich scripting languages in support of smart con- tracts, programs that autonomously intermediate transac- tions In this paper, we explore the risk of smart contracts fueling new criminal ecosystems Specifically, we show how what we call criminal smart contracts (CSCs) can facilitate leakage of confidential information, theft of cryptographic keys, and various real-world crimes (murder, arson, terror- ism) We show that CSCs for leakage of secrets (`a la Wikileaks) are efficiently realizable in existing scripting languages such as that in Ethereum|,Non-data,99
| We show that CSCs for theft of crypto- graphic keys can be achieved using primitives, such as Suc- cinct Non-interactive ARguments of Knowledge (SNARKs), that are already expressible in these languages and for which efficient supporting language extensions are anticipated We show similarly that authenticated data feeds, an emerging feature of smart contract systems, can facilitate CSCs for real-world crimes (eg, property crimes)|,Non-data,99
| Our results highlight the urgency of creating policy and technical safeguards against CSCs in order to realize the promise of smart contracts for beneficial goals Keywords Criminal Smart Contracts; Ethereum The Ring of Gyges is a mythical magical artifact men- tioned by the philosopher Plato in Book 2 of his Republic It granted its owner the power to become invisible at will —Wikipedia, “Ring of Gyges” Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita- tion on the first page|,Non-data,99
| Copyrights for components of this work owned by others than ACM must be honored Abstracting with credit is permitted To copy otherwise, or re- publish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acm|,Non-data,99
|org CCS’16, October 24-28, 2016, Vienna, Austria © 2016 ACM ISBN 978-1-4503-4139-4/16/10 |,Non-data,99
  $1500 DOI: http://dxdoi,Non-data,99
|org/101145/29767492978362 “[On wearing the ring,] no man would keep his hands off what was not his own when he could safely take what he liked out of the market, or go into houses and lie with anyone at his pleasure, or kill or release from prison whom he would|,Non-data,99
| ” —Plato, The Republic, Book 2 (2360b) (trans Benjamin Jowett) 1|,Non-data,99
| INTRODUCTION Cryptocurrencies such as Bitcoin remove the need for trusted third parties from basic monetary transactions and offer anonymous (more accurately, pseudonymous) transactions between individuals While attractive for many applica- tions, these features have a dark side Bitcoin has stimu- lated the growth of ransomware [6], money laundering [38], and illicit commerce, as exemplified by the notorious Silk Road [31] New cryptocurrencies such as Ethereum (as well as sys- tems such as Counterparty [45] and SmartContract [1]) of- fer even richer functionality than Bitcoin|,Non-data,99
| They support smart contracts, a generic term denoting programs written in Turing-complete cryptocurrency scripting languages In a fully distributed system such as Ethereum, smart con- tracts enable general fair exchange (atomic swaps) without a trusted third party, and thus can effectively guarantee pay- ment for successfully delivered data or services Given the flexibility of such smart contract systems, it is to be expected that they will stimulate not just new beneficial services, but new forms of crime We refer to smart contracts that facilitate crimes in dis- tributed smart contract systems as criminal smart contracts (CSCs)|,Non-data,99
| An example of a CSC is a smart contract for (private-)key theft Such a CSC might pay a reward for (confidential) delivery of a target key sk, such as a certifi- cate authority’s private digital signature key We explore the following key questions in this paper Could CSCs enable a wider range of significant new crimes than earlier cryptocurrencies (Bitcoin)? How practical will such new crimes be? And What key advantages do CSCs pro- vide to criminals compared with conventional online sys- tems? Exploring these questions is essential to identifying threats and devising countermeasures|,Non-data,99
| 11 CSC challenges Would-be criminals face two basic challenges in the con- struction of CSCs First, it is not immediately obvious whether a CSC is at all feasible for a given crime, such as key theft This is because it is challenging to ensure 283that a CSC achieves a key property in this paper that we call commission-fair, meaning informally that its execution guarantees both commission of a crime and commensurate payment for the perpetrator of the crime or neither|,Non-data,99
| (We formally define commission-fairness for individual CSCs in the paper) Fair exchange is necessary to ensure commission- fairness, but not sufficient: We show how CSC constructions implementing fair exchange still allow a party to a CSC to cheat Correct construction of CSCs can thus be delicate Second, even if a CSC can in principle be constructed, given the limited opcodes in existing smart contract sys- tems (such as Ethereum), it is not immediately clear that the CSC can be made practical|,Non-data,99
| By this we mean that the CSC can be executed without unduly burdensome compu- tational effort, which in some smart contract systems (eg, Ethereum) would also mean unacceptably high execution fees levied against the CSC The following example illustrates these challenges|,Non-data,99
| Example 1a (Key compromise contract) Contractor C posts a request for theft and delivery of the signing key skV of a victim certificate authority (CA) CertoMart C of- fers a reward $reward to a perpetrator P for (confidentially) delivering the CertoMart private key skV to C To ensure fair exchange of the key and reward in Bitcoin, C and P would need to use a trusted third party or communi- cate directly, raising the risks of being cheated or discovered by law enforcement|,Non-data,99
| They could vet one another using a reputation system, but such systems are often infiltrated by law enforcement authorities [55] In contrast, a decentral- ized smart contract can achieve self-enforcing fair exchange For key theft, this is possible using the CSC Key-Theft in the following example: Example 1b (Key compromise CSC) C generates a private / public key pair (skC, pkC) and initializes Key-Theft with public keys pkC and pkV (the CertoMart public key)|,Non-data,99
| Key-Theft awaits input from a claimed perpetrator P of a pair (ct, π), where π is a zero-knowledge proof that ct = encpkC [skV ] is well-formed Key-Theft then verifies π and upon success sends a reward of $reward to P The contractor C can then download and decrypt ct to obtain the compro- mised key skV  Key-Theft implements a fair exchange between C and P, paying a reward to P if and only if P delivers a valid key (as proven by π), eliminating the need for a trusted third party|,Non-data,99
| But it is not commission-fair, as it does not ensure that skvict actually has value The CertoMart can neutralize the contract by preemptively revoking its own certificate and then itself claiming C’s reward $reward! As noted, a major thrust of this paper is showing how, for CSCs such as Key-Theft, criminals will be able to bypass such problems and still construct commission-fair CSCs (For key compromise, it is necessary to enable contract cancella- tion should a key be revoked) Additionally, we show that these CSCs can be efficiently realized using existing cryp- tocurrency tools or features currently envisioned for cryp- tocurrencies (e|,Non-data,99
|g, zk-SNARKS [22]) 12 This paper We show that it is or will be possible in smart contract systems to construct commission-fair CSCs for three types of crime: 1|,Non-data,99
| Leakage / sale of secret documents; 2 Theft of private keys; and 3 “Calling-card” crimes, a broad class of physical-world crimes (murder, arson, etc) The fact that CSCs are possible in principle is not surpris- ing|,Non-data,99
| Previously, however, it was not clear how practical or extensively applicable CSCs might be As our constructions for commission-fair CSCs show, constructing CSCs is not as straightforward as it might seem, but new cryptographic techniques and new approaches to smart contract design can render them feasible and even practical Furthermore, crim- inals will undoubtedly devise CSCs beyond what this paper and the community in general are able to anticipate Our work therefore shows how imperative it is for the community to consider the construction of defenses against CSCs|,Non-data,99
| Criminal activity committed under the guise of anonymity has posed a major impediment to adoption for Bitcoin Yet there has been little discussion of criminal contracts in public forums on cryptocurrency [16] and the launch of Ethereum took place in July 2015 It is only by recognizing CSCs early in their lifecycle that the community can develop timely countermeasures to them, and see the promise of distributed smart contract systems fully realized In summary, our contributions are: While our focus is on preventing evil, happily the tech- niques we propose can also be used to create beneficial con- tracts|,Non-data,99
| We explore both techniques for structuring CSCs and the use of cutting-edge cryptographic tools, eg, Suc- cinct Non-interactive ARguments of Knowledge (SNARKs), in CSCs Like the design of beneficial smart contracts, CSC construction requires a careful combination of cryptography with commission-fair design [34]|,Non-data,99
| • Criminal smart contracts: We initiate the study of CSCs as enabled by Turing-complete scripting languages in next- generation cryptocurrencies We explore CSCs for three different types of crimes: leakage of secrets in Section 4 (eg, pre-release Hollywood films), key compromise / theft (of, e|,Non-data,99
|g, a CA signing key) in Section 5, and “calling-card” crimes, such as assassination, that use data sources called “authenticated data feeds” (described below) in Section 6 We explore the challenges involved in crafting such crimi- nal contracts and demonstrate (anticipate) new techniques to resist neutralization and achieve commission-fairness We emphasize that because commission-fairness means in- formally that contracting parties obtain their “expected” utility, an application-specific metric, commission-fairness must be defined in a way specific to a given CSC|,Non-data,99
| We thus formally specify commission-fairness for each of our CSC constructions in the online full version [42] • Proof of concept: To demonstrate that even sophisticated CSC are realistic, we report (in their respective sections) on implementation of the CSCs we explore Our CSC for leakage of secrets is efficiently realizable today in existing smart contract languages (eg|,Non-data,99
|, that of Ethereum) Those for key theft and “calling-card” crimes rely respectively for efficiency and realizability on features currently envisioned by the cryptocurrency community • Countermeasures: We briefly discuss in Section 7 how our work in this paper can help prevent a proliferation of CSCs Briefly, to be most effective, CSCs must be ad- vertised, making them detectible given community vigi- lance|,Non-data,99
| Miners have an economic incentive not to include 284CSC transactions in blocks, as CSCs degrade the market value of a cryptocurrency Consequently, awareness and robust detection strategies may offer an effective general defense A key contribution of our work is to show the need for such countermeasures and stimulate exploration of their implementation in smart contract systems such as Ethereum We also briefly discuss in the online full version [42] how maturing technologies, such as hardware roots of trust (e|,Non-data,99
|g, Intel SGX [40]) and program obfuscation can enrich the space of possible CSCs—as they can, of course, beneficial smart contracts 2 BACKGROUND AND RELATED WORK Emerging decentralized cryptocurrencies [52, 59] rely on a novel blockchain technology where miners reach consensus not only about data, but also about computation|,Non-data,99
| Loosely speaking, the Bitcoin blockchain (ie, miners) verifies trans- actions and stores a global ledger, which may be modeled as a piece of public memory whose integrity relies on correct execution of the underlying distributed consensus protocol Bitcoin supports a limited range of programmable logic to be executed by the blockchain|,Non-data,99
| Its scripting language is re- strictive, however, and difficult to use, as demonstrated by previous efforts at building smart contract-like applications atop Bitcoin [23, 17, 7, 53, 46] When the computation performed by the blockchain (ie, miners) is generalized to arbitrary Turing-complete logic, we obtain a more powerful, general-purpose smart contract system|,Non-data,99
| The first embodiment of such a decentralized smart contract system is the recently launched Ethereum [59] In- formally, a smart contract in such a system may be thought of as an autonomously executing piece of code whose inputs and outputs can include money (We give more formalism below) Hobbyists and companies are already building atop or forking off Ethereum to develop various smart contract applications such as security and derivatives trading [45], prediction markets [5], supply chain provenance [11], and crowd fund raising [2, 47]|,Non-data,99
| Figure 1 shows the high-level architecture of a smart con- tract system instantiated over a decentralized cryptocur- rency such as Bitcoin or Ethereum When the underlying consensus protocol employed the cryptocurrency is secure, a majority of the miners (as measured by computational resources) are assumed to correctly execute the contract’s programmable logic Gas Realistic instantiations of decentralized smart con- tract systems rely on gas to protect miners against denial-of- service attacks (e|,Non-data,99
|g, running an unbounded contract) Gas is a form of transaction fee that is, roughly speaking, pro- portional to the runtime of a contract In this paper, although we do not explicitly express gas in our smart contract notation, we attempt to factor pro- gram logic away from the contract as an optimization when possible, to keep gas and thus transactional fees low|,Non-data,99
| For example, some of the contracts we propose involve program logic executed on the user side, with no loss in security 21 Smart contracts: the good and bad Decentralized smart contracts have many beneficial uses, including the realization of a rich variety of new financial instruments As Bitcoin does for transactions, in a decen- Figure 1: Schematic of a decentralized cryptocur- rency system with smart contracts, as illustrated by Delmolino et al|,Non-data,99
| [34] A smart contract’s state is stored on the public blockchain A smart contract program is exe- cuted by a network of miners who reach consensus on the outcome of the execution, and update the contract’s state on the blockchain accordingly Users can send money or data to a contract; or receive money or data from a contract|,Non-data,99
| tralized smart contract system, the consensus system en- forces autonomous execution of contracts; no one entity or small set of entities can interfere with the execution of a contract As contracts are self-enforcing, they eliminate the need for trusted intermediaries or reputation systems to re- duce transactional risk Decentralized smart contracts offer these advantages over traditional cryptocurrencies such as Bitcoin: • Fair exchange between mutually distrustful parties with rich contract rules expressible in a programmable logic This feature prevents parties from cheating by aborting an exchange protocol, yet removes the need for physical rendezvous and (potentially cheating) third-party inter- mediaries|,Non-data,99
| • Minimized interaction between parties, reducing opportu- • Enriched transactions with external state by allowing as input authenticated data feeds (attestations) provided by brokers on physical and other events outside the smart- contract system, eg, stock tickers, weather reports, etc These are in their infancy in Ethereum, but their avail- ability is growing and use of trusted hardware promises to stimulate their deployment [61]|,Non-data,99
| nities for unwanted monitoring and tracking Unfortunately, for all of their benefit, these properties have a dark side, potentially facilitating crime because: • Fair exchange enables transactions between mutually dis- trustful criminal parties, eliminating the need for today’s fragile reputation systems and/or potentially cheating or law-enforcement-infiltrated third-party intermediaries [55, 39] • Minimized interaction renders illegal activities harder for law enforcement to monitor In some cases, as for the key- theft and calling-card CSCs we present, a criminal can set up a contract and walk away, allowing it to execute autonomously with no further interaction|,Non-data,99
 • Enriched transactions with external state broaden the scope ContractsMined BlockMinersBlock # iBlock # i+ 1Block # i+ 2TimeBlockchain,Non-data,99
|CodeStorageDataUsersMoney285of possible CSCs to, eg|,Non-data,99
|, physical crimes (terrorism, ar- son, murder, etc) As decentralized smart contract systems typically inherit the anonymity (pseudonymity) of Bitcoin, they offer similar secrecy for criminal activities Broadly speaking, therefore, there is a risk that the capabilities enabled by decentral- ized smart contract systems will enable new underground ecosystems and communities|,Non-data,99
 22 Digital cash and crime Bitcoin and smart contracts do not represent the earliest emergence of cryptocurrency Anonymous e-cash was intro- duced in 1982 in a seminal paper by David Chaum [29] Nac- cache and von Solms noted that anonymous currency would render “perfect crimes” such as kidnapping untraceable by law enforcement [57],Non-data,99
| This observation prompted the design of fair blind signatures or “escrow” for e-cash [26, 58], which enables a trusted third party to link identities and payments Such linkage is possible in classical e-cash schemes where a user identifies herself upon withdraw of anonymous cash, but not pseudonymous cryptocurrencies such as Bitcoin Ransomware has appeared in the wild since 1989 [18] A major cryptovirological [60] “improvement” to ransomware has been use of Bitcoin [44], thanks to which CryptoLocker ransomware has purportedly netted hundreds of millions of dollars in ransom [25]|,Non-data,99
| Assassination markets using anony- mous digital cash were first proposed in a 1995-6 essay en- titled “Assassination Politics” [19] There has been extensive study of Bitcoin-enabled crime, such as money laundering [51], Bitcoin theft [49], and ille- gal marketplaces such as the Silk Road [31] Meiklejohn et al [49] note that Bitcoin is pseudonymous and that mixes, mechanisms designed to confer anonymity on Bitcoins, do not operate on large volumes of currency and in general today it is hard for criminals to cash out anonymously in volume|,Non-data,99
| On the other hand, Ron and Shamir provide evidence that the FBI failed to locate most of the Bitcoin holdings of Dread Pirate Roberts (Ross Ulbricht), the operator of the Silk Road, even after seizing his laptop [56] M ̈oser, B ̈ohome, and Breuker [51] find that they cannot success- fully deanonymize transactions in two of three mixes under study, suggesting that the “Know-Your-Customer” princi- ple, regulators’ main tool in combatting money laundering, may prove difficult to enforce in cryptocurrencies Increas- ingly practical proposals to use NIZK proofs for anonymity in cryptocurrencies [20, 33, 50], and at least one currently in the early stages of commercial deployment [13], promise to make stronger anonymity available to criminals 3|,Non-data,99
| NOTATION AND THREAT MODEL We adopt the formal blockchain model of Kosba et al [43] As background, we give a high-level description of that model in this section We use the model to specify cryptographic protocols in our paper; these protocols encompass criminal smart contracts and corresponding user-side protocols|,Non-data,99
| Protocols in the smart contract model Our model treats a contract as a special party that is entrusted to en- force correctness but not privacy, as noted above (In real- ity, of course, a contract is enforced by the network) All messages sent to the contract and its internal state are pub- licly visible|,Non-data,99
| A contract interacts with users and other con- tracts by exchanging messages (also referred to as transac- tions) Money, expressed in the form of account balances, is recorded in the global ledger (on the blockchain) Con- tracts can access and update the ledger to implement money transfers between users, who are represented by pseudony- mous public keys 3|,Non-data,99
|1 Threat Model We adopt the following threat model in this paper • Blockchain: Trusted for correctness but not privacy We assume that the blockchain always correctly stores data and performs computations and is always available The blockchain exposes all of its internal states to the public, however, and retains no private data|,Non-data,99
| • Arbitrarily malicious contractual parties We assume that contractual parties are mutually distrustful, and they act solely to maximize their own benefit Not only can they deviate arbitrarily from the prescribed protocol, they can also abort from the protocol prematurely • Network influence of the adversary|,Non-data,99
| We assume that mes- sages between the blockchain and players are delivered within a bounded delay, ie, not permanently dropped (A player can always resend a transaction dropped by a malicious miner|,Non-data,99
|) In our model, an adversary immedi- ately receives and can arbitrarily reorder messages, how- ever In real-life decentralized cryptocurrencies, the win- ning miner sets the order of message processing An adver- sary may collude with certain miners or influence message- propagation among nodes As we show in Section 5, for key-theft contracts, message-reordering enables a rushing attack that a commission-fair CSC must prevent|,Non-data,99
 The formal model we adopt (reviewed later in this section and described in full by Kosba et al [43]) captures all of the above aspects of our threat model 32 Security definitions For a CSC to be commission-fair requires two things: • Correct definition of commission-fairness,Non-data,99
| There is no universal formal definition of commission fairness: It is application-specific, as it depends on the goals of the crim- inal (and perpetrator) Thus, for each CSC, we specify in the online full version [42] a corresponding definition of commission-fairness by means of a UC-style ideal func- tionality that achieves it Just specifying a correct ideal functionality is itself often challenging! We illustrate the challenge in Section 5 and the online full version [42] with a naive-key functionality that represents seemingly correct but in fact flawed key-theft contract • Correct protocol implementation|,Non-data,99
| To prove that a CSC is commission-fair, we must show that its (real-world) pro- tocol emulates the corresponding ideal functionality We prove this for our described CSCs in the standard Univer- sally Composable (UC) simulation paradigm [28] adopted in the cryptography literature, against arbitrarily mali- cious contractual counterparties as well as possible net- work adversaries Our protocols are also secure against aborting adversaries, eg|,Non-data,99
|, attempts to abort without pay- ing the other party Fairness in the presence of aborts is well known in general to be impossible in standard models of distributed computation [32] Several recent works show that a blockchain that is correct, available, and aware of the progression of time can enforce finan- cial fairness against aborting parties [23, 43, 17] Specifi- 286cally, when a contract lapses, the blockchain can cause the aborting party to lose a deposit to the honest parties|,Non-data,99
 33 Notational Conventions We now explain some notational conventions for writing contracts The online full version [42] gives a warm-up example • Currency and ledger,Non-data,99
| We use ledger[P] to denote party P’s balance in the global ledger For clarity, variables that begin with a $ sign denote money, but otherwise behave like ordinary variables Unlike in Ethereum’s Serpent language, in our formal no- tation, when a contract receives some $amount from a party P, this is only message transfer, and no currency transfer has taken place at this point Money transfers only take effect when the contract performs operations on the ledger, denoted ledger|,Non-data,99
| • Pseudonymity Parties can use pseudonyms to obtain better anonymity In particular, a party can generate arbitrarily many public keys In our notational system, when we refer to a party P, P denotes the party’s pseudonym|,Non-data,99
 The formal blockchain model [43] we adopt provides a contract wrapper that manages the pseudonym genera- tion and the message signing necessary for establishing an authenticated channel to the contract These details are abstracted away from the main contract program • Timer Time progresses in rounds,Non-data,99
| At the beginning of each round, the contract’s Timer function will be in- voked The variable T encodes the current time • Entry points and variable scope A contract can have various entry points, each of which is invoked when re- ceiving a corresponding message type|,Non-data,99
| Thus entry points behave like function calls invoked upon receipt of mes- sages All variables are assumed to be globally scoped, with the following exception: When an entry point says “Upon receiving a message from some party P,” this allows the registration of a new party P In general, contracts are open to any party who interacts with them When a message is received from P (without the keyword “some”), party P denotes a fixed party – and a well-formed contract has already defined P|,Non-data,99
| This notational system [43] is not only designed for con- venience, but is also endowed with precise, formal mean- ings compatible with the Universal Composability frame- work [28] We refer the reader to [43] for formal modeling details While our proofs in the online full version [42] rely on this supporting formalism, the main body can be under- stood without it 4|,Non-data,99
| CSCS FOR LEAKAGE OF SECRETS As a first example of the power of smart contracts, we show how an existing type of criminal contract deployed over Bitcoin can be made more robust and functionally enhanced as a smart contract and can be practically implemented in Ethereum Among the illicit practices stimulated by Bitcoin is payment- incentivized leakage, ie, public disclosure, of secrets|,Non-data,99
| The recently created web site Darkleaks [3] (a kind of subsidized Wikileaks) serves as a decentralized market for crowdfunded public leakage of a wide variety of secrets, including, “Hol- lywood movies, trade secrets, government secrets, propri- etary source code, industrial designs like medicine or de- fence, [etc]” Intuitively, we define commission-fairness in this setting to mean that a contractor C receives payment iff it leaks a secret in its entirety within a specified time limit (See the online full version [42] for a formal definition|,Non-data,99
|) As we show, Darkleaks highlights the inability of Bitcoin to sup- port commission-fairness We show how a CSC can in fact achieve commission-fairness with high probability 41 Darkleaks In the Darkleaks system, a contractor C who wishes to sell a piece of content M partitions it into a sequence of n segments {mi}n i=1|,Non-data,99
| At a time (block height) Topen pre- specified by C, a randomly selected subset Ω ⊂ [n] of k segments is publicly disclosed as a sample to entice donors / purchasers—those who will contribute to the purchase of M for public leakage When C determines that donors have col- lectively paid a sufficient price, C decrypts the remaining seg- ments for public release The parameter triple (n, k, Topen) is set by C (where n = 100 and k = 20 are recommended defaults) To ensure a fair exchange of M for payment without direct interaction between parties, Darkleaks implements a (clever) protocol on top of the Bitcoin scripting language|,Non-data,99
| The main idea is that for a given segment mi of M that is not revealed as a sample in Ω, donors make payment to a Bitcoin account ai with public key pki The segment mi is encrypted under a key κ = H(pki) (where H = SHA-256) To spend its re- ward from account ai, C is forced by the Bitcoin transaction protocol to disclose pki; thus the act of spending the reward automatically enables the community to decrypt mi We give further details in the online full version [42]|,Non-data,99
| Shortcomings and vulnerabilities The Darkleaks pro- tocol has three major shortcomings / vulnerabilities that ap- pear to stem from fundamental functional limitations of Bit- coin’s scripting language when constructing contracts with- out direct communication between parties The first two undermine commission-fairness, while the third limits func- tionality1 1|,Non-data,99
| Delayed release: C can refrain from spending purchasers’ / donors’ payments and releasing unopened segments of M until after M loses value Eg, C could withhold segments of a film until after its release in theaters, of an industrial design until after it is produced, etc|,Non-data,99
| 2 Selective withholding: C can choose to forego payment for selected segments and not disclose them For example, C could leak and collect payment for all of a leaked film but the last few minutes (which, with high probability, will not appear in the sample Ω), significantly diminishing the value of leaked segments 3|,Non-data,99
| Public leakage only: Darkleaks can only serve to leak secrets publicly It does not enable fair exchange for pri- vate leakage, ie, for payment in exchange for a secret M encrypted under the public key of a purchaser P|,Non-data,99
| 1That these limitations are fundamental is evidenced by calls for new, time-dependent opcodes One example is CHECKLOCKTIMEVERIFY; apart from its many legiti- mate applications, proponents note that it can facilitate se- cret leakage as in Darkleaks [35] 287Additionally, Darkleaks has a basic protocol flaw: 4 Reward theft: In the Darkleaks protocol, the Bitcoin pri- vate key ski corresponding to pki is derived from mi; specif- ically ski = SHA-256(mi)|,Non-data,99
| Thus, the source of M (eg, the victimized owner of a leaked film) can derive ski and steal rewards received by C (Also, when C claims a reward, a malicious node that receives the transaction can decrypt mi, compute ski = SHA-256(mi), and potentially steal the reward by flooding the network with a competing transac- tion [36]|,Non-data,99
|) This last problem is easily remedied by generating the i=1 of segment encryption keys pseudorandomly or set {κi}n randomly, which we do in our CSC designs Remark: In any protocol in which goods are represented by a random sample, not just Darkleaks, C can insert a small number of valueless or duplicate segments into M  With non-negligible probability, these will not result in an invalid-looking sample Ω, so Ω necessarily provides only a weak guarantee of the global validity of M  The larger k and n, the smaller the risk of such attack|,Non-data,99
| Formal analysis of human-verified proofs of this kind and/or ways of au- tomating them is an interesting problem beyond the scope of this paper, but important in assessing end-to-end security in a CSC of this kind 42 A generic public-leakage CSC We now present a smart contract that realizes public leak- age of secrets using blackbox cryptographic primitives (We later present efficient realizations|,Non-data,99
) This contract overcomes limitation 1 of the Darkleaks protocol (delayed release) by enforcing disclosure of M at a pre-specified time Tend—or else immediately refunding buyers’ money It addresses lim- itation 2 (selective withholding) by ensuring that M is re- vealed in an all-or-nothing manner,Non-data,99
| (We later explain how to achieve private leakage and overcome limitation 3) Again, we consider settings where C aims to sell M for public release after revealing sample segments M∗ Informal protocol description Informally, the protocol involves the following steps: • Create contract|,Non-data,99
| A seller C initializes a smart contract with the encryption of a randomly generated master secret key msk The master secret key is used to generate (sym- metric) encryption keys for the segments {mi}n i=1 C pro- vides a cryptographic commitment c0 := Enc(pk, msk, r0) of msk to the contract (To meet the narrow technical re- quirements of our security proofs, the commitment is an encryption with randomness r0 under a public key pk cre- ated during a trusted setup step|,Non-data,99
|) The master secret key msk can be used to decrypt all leaked segments of M  • Upload encrypted data For each i ∈ [n], C generates en- := PRF(msk, i), and encrypts the i-th cryption key κi segment as cti = encκi [mi] C sends all encrypted seg- ments {cti}i∈[n] to the contract (or, for efficiency, provides hashes of copies stored with a storage provider, e|,Non-data,99
|g, a peer-to-peer network) Interested purchasers / donors can download the segments of M , but cannot decrypt them yet • Challenge|,Non-data,99
| The contract generates a random challenge set Ω ⊂ [n], in practice today in Ethereum based on the hash of a recent block Another future possibility is some well known randomness source, eg, the NIST randomness beacon [9], perhaps relayed through an authenticated data feed|,Non-data,99
| • Response C reveals the set {κi}i∈Ω to the contract, and gives ZK proofs that the revealed secret keys {κi}i∈Ω are generated correctly from the msk encrypted as c0 • Collect donations During a donation period, potential purchasers / donors can use the revealed secret keys {κi}i∈Ω to decrypt the corresponding segments|,Non-data,99
| If they like the de- crypted segments, they can donate money to the contract as contribution for the leakage If enough money has been collected, C decom- mits msk for the contract (sends the randomness for the ciphertext along with msk) If the contract verifies the decommitment successfully, all donated money is paid to C The contract thus enforces a fair exchange of msk for money|,Non-data,99
| (If the contract expires at time Tend without re- lease of msk, all donations are refunded) • Accept The contract Our proposed CSC PublicLeaks for imple- menting this public leakage protocol is given in Figure 2|,Non-data,99
| The corresponding user side is as explained informally above (and inferable from the contract) Contract PublicLeaks Init: Set state := init, and donations := {} Let crs := KeyGennizk(1λ), pk := KeyGenenc(1λ) denote hard- coded public parameters generated through a trusted setup leaker C: Create: Upon receiving (“create”, c0, {cti}n i=1, Tend) from some Set state := created|,Non-data,99
| Select a random subset Ω ⊂ [n] of size k, and send (“challenge”, Ω) to C Confirm: Upon receiving (“confirm”, {(κi, πi)}i∈Ω) from C: Assert state = created Assert that ∀i ∈ S: πi is a valid NIZK proof (under crs) for the following statement: ∃(msk, r0), st|,Non-data,99
| (c0 = Enc(pk, msk, r0)) ∧ (κi = PRF(msk, i)) Set state := confirmed Donate: Upon receiving (“donate”, $amt) from some purchaser P: Assert state = confirmed Assert ledger[P] ≥ $amt Set ledger[P] := ledger[P] − $amt|,Non-data,99
| donations := donations ∪ {($amt, P)} Accept: Upon receiving (“accept”, msk, r0) from C: Assert state = confirmed Assert c0 = Enc(pk, msk, r0) ledger[C] := ledger[C] + sum(donations) Send (“leak”, msk) to all parties Set state := aborted Timer: If state = confirmed and T > Tend: ∀($amt, P) ∈ donations: let ledger[P] := ledger[P]+$amt|,Non-data,99
| Set state := aborted Figure 2: A contract PublicLeaks that leaks a secret M to the public in exchange for donations 43 Commission-fairness: Formal definition and proof In the online full version [42], we give a formal definition of commission-fairness for public leakage (explained infor- mally above) as an ideal functionality|,Non-data,99
| We also prove that PublicLeaks realizes this functionality assuming all revealed segments are valid—a property enforced with high (but not 288overwhelming) probability by random sampling of M in Pub- licLeaks 44 Optimizations and Ethereum implemen- tation The formally specified contract PublicLeaks uses generic cryptographic primitives in a black-box manner We now give a practical, optimized version, relying on the random oracle model (ROM), that eliminates trusted setup, and also achieves better efficiency and easy integration with Ethereum [59]|,Non-data,99
| A practical optimization During contract creation, C chooses random κi $←{0, 1}λ for i ∈ [n], and computes c0 := {H(κ1, 1),   |,Non-data,99
| , H(κn, n)} The master secret key is simply msk := {κ1,   |,Non-data,99
| , κn}, ie, the set of hash pre-images As in PublicLeaks, each segment mi will still be encrypted as cti := encκ[mi]|,Non-data,99
| (For technical reasons—to achieve simulatability in the security proof— here encκ[mi] = mi ⊕ [H(κi, 1,“enc”)|||| H(κi, 2,“enc”)    , |||| H(κi, z,“enc”)] for suitably large z|,Non-data,99
|) C submits c0 to the smart contract When challenged with the set Ω, C reveals {κi}i∈Ω to the contract, which then verifies its correctness by hashing and comparing with c0 To accept donations, C reveals the entire msk This optimized scheme is asymptotically less efficient than our generic, black-box construction PublicLeaks—as the mas- ter secret key scales linearly in the number of segments n|,Non-data,99
| But for typical, realistic document set sizes in practice (eg, n = 100, as recommended for Darkleaks), it is more efficient Ethereum-based implementation|,Non-data,99
| To demonstrate the feasibility of implementing leakage contracts using currently available technology, we implemented a version of the con- tract PublicLeaks atop Ethereum [59], using the Serpent con- tract language [10] We specify the full implementation in detail in the online full version [42] The version we implemented relies on the practical opti- mizations described above As a technical matter, Ethereum does not appear at present to support timer-activated func- tions, so we implemented Timer in such a way that pur- chasers / donors make explicit withdrawals, rather than re- ceiving automatic refunds|,Non-data,99
| This public leakage Ethereum contract is highly efficient, as it does not require expensive cryptographic operations It mainly relies on hashing (SHA3-256) for random number generation and for verifying hash commitments The total number of storage entries (needed for encryption keys) and hashing operations is O(n), where, again, Darkleaks recom- mends n = 100 (A hash function call in practice takes a few micro-seconds, e|,Non-data,99
|g, 392 μsecs measured on a core i7 processor) 4|,Non-data,99
|5 Extension: private leakage As noted above, shortcoming 3 of Darkleaks is its inability to support private leakage, in which C sells a secret exclu- sively to a purchaser P In the online full version [42], we show how PublicLeaks can be modified for this purpose The basic idea is for C not to reveal msk directly, but to provide a ciphertext ct = encpkP [msk] on msk to the contract for a pur- chaser P, along with a proof that ct is correctly formed|,Non-data,99
| We describe a black-box variant whose security can be proven in essentially the same way as PublicLeaks We also describe Contract KeyTheft-Naive Init: Set state := init Let crs := KeyGennizk(1λ) denote a hard-coded NIZK common reference string generated during a trusted setup process contractor C := (pkC, |,Non-data,99
|  ): Create: Upon receiving (“create”, $reward, pkV , Tend) from some Assert state = init Assert ledger[C] ≥ $reward|,Non-data,99
| ledger[C] := ledger[C] − $reward Set state := created Claim: Upon receiving (“claim”, ct, π) from some purported per- petrator P: Assert state = created Assert that π is a valid NIZK proof (under crs) for the following statement: ∃r, skV s|,Non-data,99
|t ct = Enc(pkC, (skV , P), r) and match(pkV , skV ) = true Timer: If state = created and current time T > Tend: ledger[P] := ledger[P] + $reward Set state := claimed ledger[C] := ledger[C] + $reward state := aborted Figure 3: A na ̈ıve, flawed key theft contract (lacking commission-fairness) a practical variant that combines a verifiable random func- tion (VRF) of Chaum and Pedersen [30] (for generation of {κi}n i=1) with a verifiable encryption (VE) scheme of Ca- mensich and Shoup [27] (to prove correctness of ct)|,Non-data,99
| This variant can be deployed today using beta support for big number arithmetic in Ethereum 5 A KEY-COMPROMISE CSC Example 1b in the paper introduction described a CSC that rewards a perpetrator P for delivering to C the stolen key skV of a victim V—in this case a certificate authority (CA) with public key pkV  Recall that C generates a private / public key encryption pair (skC, pkC)|,Non-data,99
| The contract accepts as a claim by P a pair (ct, π) It sends reward $reward to P if π is a valid proof that ct = encpkC [skV ] and skV is the private key corresponding to pkV  Intuitively, a key-theft contract is commission-fair if it re- wards a perpetrator P for delivery of a private key that: (1) P was responsible for stealing and (2) Is valid for a substan- tial period of time (See the online full version [42] for a formal definition|,Non-data,99
|) This form of contract can be used to solicit theft of any type of private key, eg, the signing key of a CA, the private key for a SSL/TLS certificate, a PGP private key, etc (Sim- ilar contracts could solicit abuse, but not full compromise of a private key, e|,Non-data,99
|g, forged certificates) Figure 3 shows the contract of Example 1b in our notation for smart contracts We let crs here denote a common refer- ence string for a NIZK scheme and match(pkV , skV ) denote an algorithm that verifies whether skV is the corresponding private key for some public key pkV in a target public-key cryptosystem|,Non-data,99
| As noted above, this CSC is not commission-fair Thus we refer to it as KeyTheft-NaiveWe use KeyTheft-Naive as a helpful starting point for motivating and understanding the construction of a commission-fair contract proposed later, called KeyTheft 2895|,Non-data,99
1 Flaws in KeyTheft-Naive The contract KeyTheft-Naive fails to achieve commission- fairness due to two shortcomings Revoke-and-claim attack The CA V can revoke the key skV and then itself submit the key for payment The CA then not only negates the value of the contract but actually profits from it! This revoke-and-claim attack demonstrates that KeyTheft-Naive is not commission-fair in the sense of ensuring the delivery of a usable private key skV ,Non-data,99
| Rushing attack Another attack is a rushing attack As noted in Section 3, an adversary can arbitrarily reorder messages—a reflection of possible attacks against the net- work layer in a cryptocurrency (See also the formal blockchain model [43]|,Non-data,99
|) Thus, given a valid claim from perpetrator P, a corrupt C can decrypt and learn skV , construct another valid-looking claim of its own, and make its own claim ar- rive before the valid one 52 Fixing flaws in KeyTheft-Naive We now show how to modify KeyTheft-Naive to prevent the above two attacks and achieve commission-fairness Thwarting revoke-and-claim attacks|,Non-data,99
| In a revoke-and- claim attack against KeyTheft-Naive, V preemptively revokes its public key pkV and replaces it with a fresh one pk(cid:48) V  As noted above, the victim can then play the role of perpetrator P, submit skV to the contract and claim the reward The result is that C pays $reward to V and obtains a stale key We address this problem by adding to the contract a fea- ture called reward truncation, whereby the contract accepts evidence of revocation Πrevoke|,Non-data,99
| This evidence Πrevoke can be an Online Certificate Status Protocol (OCSP) response indicating that pkV is no longer valid, a new certificate for V that was unknown at the time of contract creation (and thus not stored in Contract), or a certificate revocation list (CRL) containing the certificate with pkV  C could submit Πrevoke, but to minimize interaction by C, KeyTheft could provide a reward $smallreward to a third- party submitter The reward could be small, as Πrevoke would be easy for ordinary users to obtain The contract then provides a reward based on the inter- val of time over which the key skV remains valid|,Non-data,99
| Let Tclaim denote the time at which the key skV is provided and Tend be an expiration time for the contract (which must not ex- ceed the expiration of the certificate containing the targeted key) Let Trevoke be the time at which Πrevoke is presented (Trevoke = ∞ if no revocation happens prior to Tend) Then the contract assigns to P a reward of f (reward, t), where t = min(Tend, Trevoke) − Tclaim We do not explore choices of f here|,Non-data,99
| We note, however, that given that a CA key skV can be used to forge certificates for rapid use in, eg, malware or falsified software updates, much of its value can be realized in a short interval of time which we denote by δ (A slant toward up-front realization of the value of exploits is common in general [24]|,Non-data,99
|) A suitable choice of reward function should be front-loaded and rapidly decaying A natural, simple choice with this property is (cid:26) 0 f ($reward, t) = $reward(1 − ae−b(t−δ)) : t < δ : t ≥ δ for a < 1/2 and some positive real value b Note that a majority of the reward is paid provided that t ≥ δ Thwarting rushing attacks|,Non-data,99
| To thwart rushing attacks, we separate the claim into two phases In the first phase, P expresses an intent to claim by submitting a commitment of the real claim message P then waits for the next round to open the commitment and reveal the claim message (Due to technical subtleties in the proof, the commitment must be adaptively secure; in the proof, the simulator must be able to simulate a commitment without knowing the string s being committed to, and later, be able to claim the com- mitment to any string s|,Non-data,99
|) In real-life decentralized cryp- tocurrencies, P can potentially wait multiple block intervals before opening the commitment, to have higher confidence that the blockchain will not fork In our formalism, one round can correspond to one or more block intervals Figure 4 gives a key theft contract KeyTheft that thwarts revoke-and-claim and the rushing attacks 5|,Non-data,99
3 Target and state exposure An undesirable property of KeyTheft-Naive is that its tar- get / victim and state are publicly visible V can thus learn whether it is the target of KeyTheft-Naive V also observes successful claims—ie,Non-data,99
|, whether skV has been stolen—and can thus take informed defensive action For example, as key revocation is expensive and time-consuming, V might wait until a successful claim occurs and only then perform a revoke-and-claim attack To limit target and state exposure, wenote two possible enhancements to KeyTheft The first is a multi-target con- tract, in which key theft is requested for any one of a set of multiple victims|,Non-data,99
| The second is what we call cover claims, false claims that conceal any true claim Our implementa- tion of KeyTheft, as specified in Figure 4, is a multi-target contract, as this technique provides both partial target and partial state concealment Multi-target contract A multi-target contract solicits the private key of any of m potential victims V1,V2, |,Non-data,99
|   ,Vm There are many settings in which the private keys of different victims are of similar value|,Non-data,99
| For example, a multi-target contract KeyTheft could offer a reward for the private key skV of any CA able to issue SSL/TLS certificates trusted by, eg, Internet Explorer (of which there are more than 650 [37]) A challenge here is that the contract state is public, thus the contract must be able to verify the proof for a valid claim (private key) skVi without knowing which key was fur- nished, i|,Non-data,99
|e, without learning i Our implementation shows that constructing such proofs as zk-SNARKs is practical (The contractor C itself can easily learn i by decrypting skVi , generating pkVi , and identifying the corresponding victim|,Non-data,99
|) Cover claims As the state of a contract is publicly vis- ible, a victim V learns whether or not a successful claim has been submitted to KeyTheft-Naive This is particularly problematic in the case of single-target contracts Rather than sending the NIZK proof π with ct, it is pos- sible instead to delay submission of π (and payment of the reward) until Tend|,Non-data,99
| (That is, Claim takes as input (“claim”, ct)) This approach conceals the validity of ct Note that even without π, C can still make use of ct A contract that supports such concealment can also sup- 290Contract KeyTheft Init: Set state := init|,Non-data,99
| Let crs := KeyGennizk(1λ) denote a hard-coded NIZK common reference string generated during a trusted setup process Create: Same as in Contract KeyTheft-Naive (Figure 3), except that an additional parameter ∆T is additionally sub- mitted by C petrator P: Intent: Upon receiving (“intent”, cm) from some purported per- Assert state = created Assert that P has not sent “intent” earlier Store cm, P Claim: Upon receiving (“claim”, ct, π, r) from P: Assert state = created Assert P submitted (“intent”, cm) earlier such that cm = comm(ct||||π, r) Continue in the same manner as in contract KeyTheft- Naive, except that the ledger update ledger[P] := ledger[P] + $reward does not take place immediately|,Non-data,99
| Revoke: On receive (“revoke”, Πrevoke) from some R: Assert Πrevoke is valid, and state (cid:54)= aborted ledger[R] := ledger[R] + $smallreward If state = claimed: Let t := (time elapsed since successful Claim) Let P := (successful claimer)|,Non-data,99
| rewardP := f ($reward, t) ledger[P] := ledger[P] + rewardP  Else, rewardP := 0 ledger[C] := ledger[C] + $reward −$smallreward − rewardP Set state := aborted Timer: If state = claimed and at least ∆T time elapsed since Claim: ledger[P] := ledger[P] + $reward; Set state := aborted|,Non-data,99
 ledger[C] := ledger[C] + $reward Set state := aborted Else if current time T > Tend and state (cid:54)= aborted: // P should not submit claims after Tend − ∆T  Figure 4: Key compromise CSC that thwarts the revoke- and-claim attack and the rushing attack,Non-data,99
| port an idea that we refer to as cover claims A cover claim is an invalid claim of the form (“claim”, ct), ie, one in which ct is not a valid encryption of skV |,Non-data,99
| Cover claims may be submitted by C to conceal the true state of the contract So that C need not interact with the contract after creation, the contract could parcel out small rewards at time Tend to third parties that submit cover claims We do not implement cover claims in our version of KeyTheft nor include them in Figure 4 5|,Non-data,99
4 Commision-fairness: Formal definition and proof We define commission-fairness for key theft in terms of an ideal functionality in the online full version [42] and also provide a formal proof of security there for KeyTheft 55 Implementation We rely on zk-SNARKs for efficient realization of the protocols above zk-SNARKs are zero-knowledge proofs of knowledge that are succinct and very efficient to verify,Non-data,99
| zk- SNARKs have weaker security than what is needed in UC- style simulation proofs We therefore use a generic transfor- mation described in the Hawk work [43] to lift security such that the zero-knowledge proof ensures simulation-extractable soundness (In brief, a one-time key generation phase is 1-Target Key Gen[C] Eval|,Non-data,99
 Key Ver Key Prove[P] Proof #threads RSA-2048 ECDSA P256 1 4 1 4 12488 sec 3353 sec 215,Non-data,99
93 MB 609 KB 4102 sec 157 sec 711 B 242,Non-data,99
30 sec 7338 sec 44824 MB 515 KB 83,Non-data,99
63 sec 3219 sec 711 B Verification [Contract] 00089 sec 00087 sec 500-Target Key Gen,Non-data,99
[C] Eval Key Ver Key Prove[P] Proof #threads RSA-2048 ECDSA P256 1 4 1 4 16156 sec 43,Non-data,99
35 sec 27941 MB 499 KB 5415 sec 23,Non-data,99
54 sec 711 B 26307 sec 7831 sec 49085 MB 4,Non-data,99
99 KB 8469 sec 3349 sec 711 B Verification [Contract] 00087 sec 0,Non-data,99
|0087 sec Table 1: Performance of the key-compromise zk-SNARK circuit for Claim in the case of a 1-target and 500-target contracts [] refers to the entity performing the computational work needed to generate two keys: a public evaluation key, and a public verification key|,Non-data,99
| To prove a certain NP statement, an untrusted prover uses the evaluation key to compute a suc- cinct proof; any verifier can use the public verification key to verify the proof The verifier in our case is the contract) In our implementation, we assume the key generation is ex- ecuted confidentially by a trusted party; otherwise a prover can produce a valid proof for a false statement To mini- mize trust in the key generation phase, secure multi-party computation techniques can be used as in [21]|,Non-data,99
| zk-SNARK circuits for Claim To estimate the proof computation and verification costs required for Claim, we implemented the above protocol for theft of RSA-2048 and ECDSA P256 keys, which are widely used in SSL/TLS cer- tificates currently The circuit has two main sub-circuits: a key-check circuit, and an encryption circuit 2 The en- cryption circuit was realized using RSAES-OAEP [41] with a 2048-bit key|,Non-data,99
| Relying on compilers for high-level imple- mentation of these algorithms may produce expensive cir- cuits for the zk-SNARK proof computation Instead, we built customized circuit generators that produce more effi- cient circuits We then used the state-of-the-art zk-SNARK library [22] to obtain the evaluation results Table 1 shows the results of the evaluation of the circuits for both single- target and multi-target contracts|,Non-data,99
| The experiments were conducted on an Amazon EC2 r32xlarge instance with 61GB of memory and 25 GHz processors The results yield two interesting observations: i) Once a perpetrator obtains the secret key of a TLS public key, computing the zk-SNARK proof would require less than two minutes, costing less than 1 USD [4] for either single or multi-target contracts; ii) The overhead introduced by using a multi-target contract with 500 keys on the prover’s side is only 13 seconds in the worst case|,Non-data,99
| In the same time, the verification overhead by the contract is still the same as in the single-target case This is achieved by the use of an efficient Merkle tree circuit that proves the membership of 2The circuit also has other commitment and encryption sub- circuits needed for simulation extractability – see the online full version [42] 291the compromised public key in the target key set, while using the same components of the single-target circuit as is Validation of revoked certificates|,Non-data,99
| The reward function in the contract above relies on certificate revocation time, and therefore the contract needs modules that can process certificate revocation proofs, such as CRLs and OCSP re- sponses, and verify the CA digital signatures on them As an example, we measured the running time of openssl verify -crl_check command, testing the revoked certificate at [12] and the CRL last updated at [8] on Feb 15th, 2016, that had a size of 143KB On average, the verification executed in about 0016 seconds on a 2|,Non-data,99
|3 GHz i7 processor The sig- nature algorithm was SHA-256 with RSA encryption, with a 2048-bit key Since OCSP responses can be smaller than CRLs, the verification time could be even less for OCSP The case of multi-target contracts|,Non-data,99
| Verifying the re- vocation proof for single-target contracts is straightforward: The contract can determine whether a revocation proof cor- responds to the targeted key In multi-target contracts, though, the contract does not know which target key corre- sponds to the proof of key theft P submitted Thus, a proof is needed that the revocation corresponds to the stolen key, and it must be submitted by C We built a zk-SNARK circuit through which C can prove the connection between the ciphertext submitted by the per- petrator and the compromised target key|,Non-data,99
| For efficiency, we eliminated the need for the key-check sub-circuit in Revoke by forcing P to append the secret index of the compromised public key to the secret key before applying encryption in Claim The evaluation in Table 2 illustrates the efficiency of the verification done by the contract receiving the proof, and the practicality for C of constructing the proof In con- trast to the case for Claim, the one-time key generation for this circuit must be done independently from C, so that C cannot cheat the contract We note that the Revoke circuit we built is invariant to the cryptosystem of the target keys|,Non-data,99
 #threads RSA-2048 ECDSA P256 Key Gen Eval Key Ver Key Prove[C] Proof 1 4 1 4 124,Non-data,99
64 sec 3352 sec 21541 MB 551 KB 41,Non-data,99
08 sec 1594 sec 711 B 12435 sec 3338 sec 214,Non-data,99
81 MB 488 KB 4096 sec 1559 sec 711 B Verification [Contract] 0,Non-data,99
0087 sec 00086 sec Table 2: Performance of the key-compromise zk-SNARK circuit for Revoke needed in the case of multi-target contract [] refers to the entity performing the computational work,Non-data,99
| 6 CALLING-CARD CRIMES As noted above, decentralized smart contract systems (eg, Ethereum) have supporting services that provide authenti- cated data feeds, digitally signed attestations to news, facts about the physical world, etc|,Non-data,99
| While still in its infancy, this powerful capability is fundamental to many applications of smart contracts and will expand the range of CSCs very broadly to encompass events in the physical world, as in the following example: (Assassination CSC) Contractor C posts a contract Assassinate for the assassination of Senator X The contract rewards the perpetrator P of this crime Example 2 The contract Assassinate takes as input from a perpetra- tor P a commitment vcc specifying in advance the details (day, time, and place) of the assassination|,Non-data,99
| To claim the reward, P decommits vcc after the assassination To verify P’s claim, Assassinate searches an authenticated data feed on current events to confirm the assassination of Senator X with details matching vcc This example also illustrates the use of what we refer to as a calling card, denoted cc A calling card is an unpre- dictable feature of a to-be-executed crime (e|,Non-data,99
|g, in Exam- ple 2, a day, time, and place) Calling cards, alongside au- thenticated data feeds, can support a general framework for a wide variety of CSCs A generic construction for a CSC based on a calling card is as follows|,Non-data,99
| P provides a commitment vcc to a calling card cc to a contract in advance After the commission of the crime, P proves that cc corresponds to vcc (eg, decommits vcc)|,Non-data,99
| The contract refers to some trustworthy and authenticated data feed to verify that: (1) The crime was committed and (2) The calling card cc matches the crime If both conditions are met, the contract pays a reward to P Intuitively, we define commission fairness to mean that P receives a reward iff it was responsible for carrying out a commissioned crime (A formal definition is given in the online full version [42]|,Non-data,99
|) In more detail, let CC be a set of possible calling cards and cc ∈ CC denote a calling card As noted above, it is anticipated that an ecosystem of authenticated data feeds will arise around smart contract systems such as Ethereum We model a data feed as a sequence of pairs from a source S, where (s(t), σ(t)) is the emission for time t The value s(t) ∈ {0, 1}∗ here is a piece of data released at time t, while σ(t) is a corresponding digital signature; S has an associated private / public key pair (skS , pkS ) used to sign / verify signatures|,Non-data,99
| Note that once created, a calling-card contract requires no further interaction from C, making it hard for law enforce- ment to trace C using subsequent network traffic 61 Example: website defacement contract As an example, we specify a simple CSC SiteDeface for website defacement The contractor C specifies a website url to be hacked and a statement stmt to be displayed|,Non-data,99
| (For example, stmt = ”Anonymous We are Legion We do not Forgive|,Non-data,99
|” and url = whitehousegov) We assume a data feed that authenticates website con- tent, i|,Non-data,99
|e, s(t) = (w, url, t), where w is a representation of the webpage content and t is a timestamp, denoted for sim- plicity in contract time (For efficiency, w might be a hash of and pointer to the page content) Such a feed might take the form of, e|,Non-data,99
|g, a digitally signed version of an archive of hacked websites (eg, zone-h|,Non-data,99
|com) The function SigVer denotes the signature verification operation As example parameterization, we might let CC = {0, 1}256, ie|,Non-data,99
|, cc is a 256-bit string A perpetrator P simply se- lects a calling card cc $← {0, 1}256 and commitment vcc := commit(cc,P; ρ), where commit denotes a commitment scheme, and ρ ∈ {0, 1}256 a random string (In practice, HMAC- SHA256 is a suitable choice for easy implementation in Ethereum, given its support for SHA-256) P decommits by revealing all arguments to commit|,Non-data,99
| The CSC SiteDeface is shown in Figure 5 The example we use is simplified for clarity We assume in this example 292that the published webpage will only contain the calling card and the statement, but it is possible to support arbitrarily rich content in the published webpage Contract SiteDeface Init: On receiving ($reward, pkS , url, stmt) from some C: Store ($reward, pkS , url, stmt) Set i := 0, Tstart := T Commit: Upon receiving commitment vcc from some P: Store vcci := vcc and Pi := P ; i := i + 1|,Non-data,99
| P: Claim: Upon receiving as input a tuple (cc, ρ, σ, w, t) from some Find smallest i such that vcci = commit(cc, P; ρ), abort if not found Assert w = cc |||| stmt Assert t ≥ Tstart Assert SigVer(pkS , (w, url, t), σ) = true Send $reward to Pi and abort Figure 5: CSC for website defacement Remarks SiteDeface could be implemented alternatively by having P generate cc as a digital signature|,Non-data,99
| Our imple- mentation, however, also accommodates short, low-entropy calling cards cc, which is important for general calling-card CSCs See the online full version [42] Implementation Given an authenticated data feed, im- plementing SiteDeface would be straightforward and effi- cient|,Non-data,99
| The main overhead lies in the Claim module, where the contract computes a couple of hashes and validates the feed signature on retrieved website data As noted in Section 4, a hash function call can be computed in very short time (4μsec), while checking the signature would be more costly For example, if the retrieved content is 100KB, the contract needs only about 10msec to verify an RSA-2048 signature 6|,Non-data,99
|2 Commission-fairness: Formal definition We give a formal definition of commission-fairness for a general calling-card CSC in the online full version [42] We do not provide a security proof, as this would require modeling of physical-world systems, which is outside the scope of this paper 63 Other calling-card crimes / data feed cor- ruption Using a CSC much like SiteDeface, a contractor C can solicit many other crimes, e|,Non-data,99
|g, assassination, assault, sab- otage, hijacking, kidnapping, denial-of-service attacks, and terrorist attacks A perpetrator P must be able to designate a calling card that is reliably reported by an authenticated data feed A natural countermeasure to a calling-card-based CSC, however, is for an adversary, i|,Non-data,99
|e, party trying to neutral- ize the CSC, to corrupt an authenticated data feed or data source such that it furnishes invalid data In cases involve highly dangerous CSCs, such approaches might be work- able For example, if there is a well-funded CSC calling for the assassination of a public official, a data feed provider or news source might be persuaded to issue a false report of the target’s death|,Non-data,99
ABSTRACT Smart contracts are programs that execute autonomously on blockchains Their key envisioned uses (eg financial instruments) require them to consume data from outside the blockchain (e,Non-data,101
g stock quotes) Trustworthy data feeds that support a broad range of data requests will thus be critical to smart contract ecosystems We present an authenticated data feed system called Town Crier (TC),Non-data,101
| TC acts as a bridge between smart contracts and existing web sites, which are already commonly trusted for non-blockchain applications It combines a blockchain front end with a trusted hardware back end to scrape HTTPS- enabled websites and serve source-authenticated data to re- lying smart contracts TC also supports confidentiality It enables private data requests with encrypted parameters|,Non-data,101
| Additionally, in a gen- eralization that executes smart-contract logic within TC, the system permits secure use of user credentials to scrape access-controlled online data sources We describe TC’s design principles and architecture and report on an implementation that uses Intel’s recently in- troduced Software Guard Extensions (SGX) to furnish data to the Ethereum smart contract system We formally model TC and define and prove its basic security properties in the Universal Composibility (UC) framework Our results in- clude definitions and techniques of general interest relating to resource consumption (Ethereum’s “gas” fee system) and TCB minimization|,Non-data,101
 We also report on experiments with three example applications We plan to launch TC soon as an online public service Keywords: Authenticated Data Feeds; Smart Contracts; Trusted Hardware; Intel SGX; Ethereum; Bitcoin Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita- tion on the first page Copyrights for components of this work owned by others than ACM must be honored,Non-data,101
| Abstracting with credit is permitted To copy otherwise, or re- publish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acmorg|,Non-data,101
| CCS’16, October 24-28, 2016, Vienna, Austria © 2016 ACM ISBN 978-1-4503-4139-4/16/10  |,Non-data,101
 $1500 DOI: http://dxdoiorg/10,Non-data,101
|1145/29767492978326 1 INTRODUCTION Smart contracts are computer programs that autonomously execute the terms of a contract For decades they have been envisioned as a way to render legal agreements more precise, pervasive, and efficiently executable|,Non-data,101
| Szabo, who popular- ized the term “smart contact” in a seminal 1994 essay [35], gave as an example a smart contract that enforces car loan payments If the owner of the car fails to make a timely payment, a smart contract could programmatically revoke physical access and return control of the car to the bank Cryptocurrencies such as Bitcoin [29] provide key tech- nical underpinnings for smart contracts: direct control of money by programs and fair, automated code execution through the decentralized consensus mechanisms underlying blockchains The recently launched Ethereum [14, 37] sup- ports Turing-complete code and thus fully expressive self- enforcing decentralized smart contracts—a big step toward the vision of researchers and proponents|,Non-data,101
| As Szabo’s ex- ample shows, however, the most compelling applications of smart contracts—such as financial instruments—additionally require access to data about real-world state and events Data feeds (also known as “oracles”) aim to meet this need Very simply, data feeds are contracts on the blockchain that serve data requests by other contracts [14, 37] A few data feeds exist for Ethereum today that source data from trust- worthy websites, but provide no assurance of correctly re- laying such data beyond the reputation of their operators (typically individuals or small entities)|,Non-data,101
| HTTPS connection to a trustworthy website would seem to offer a solution, but smart contracts lack network access, and HTTPS does not digitally sign data for out-of-band verification The lack of a substantive ecosystem of trustworthy data feeds is frequently cited as critical obstacle to the evolution of Ethereum and decentralized smart contracts in general [20] Town Crier We introduce a system called Town Crier (TC) that addresses this challenge by providing an authen- ticated data feed (ADF) for smart contracts|,Non-data,101
 TC acts as a high-trust bridge between existing HTTPS-enabled data websites and the Ethereum blockchain It retrieves website data and serves it to relying contracts on the blockchain as concise pieces of data (eg stock quotes) called datagrams,Non-data,101
| TC uses a novel combination of Software Guard Extensions 270(SGX), Intel’s recently released trusted hardware capabil- ity, and a smart-contract front end It executes its core functionality as a trusted piece of code in an SGX enclave, which protects against malicious processes and the OS and can attest (prove) to a remote client that the client is in- teracting with a legitimate, SGX-backed instance of the TC code The smart-contract front end of Town Crier responds to requests by contracts on the blockchain with attestations of the following form: “Datagram X specified by parameters params is served by an HTTPS-enabled website Y during a specified time frame T ” A relying contract can verify the correctness of X in such a datagram assuming trust only in the security of SGX, the (published) TC code, and the validity of source data in the specified interval of time|,Non-data,101
| Another critical barrier to smart contract adoption is the lack of confidentiality in today’s ecosystems; all blockchain state is publicly visible, and existing data feeds publicly ex- pose requests TC provides confidentiality by supporting private datagram requests, in which the parameters are en- crypted under a TC public key for ingestion in TC’s SGX enclave and are therefore concealed on the blockchain TC also supports custom datagram requests, which securely ac- cess the online resources of requesters (eg|,Non-data,101
| online accounts) by ingesting encrypted user credentials, permitting TC to securely retrieve access-controlled data We designed and implemented TC as a complete, highly scalable, end-to-end system that offers formal security guar- antees at the cryptographic protocol level TC runs on real, SGX-enabled host, as opposed to an emulator (eg|,Non-data,101
| [10, 32]) We plan to launch a version of TC as an open-source, production service atop Ethereum, pending the near-future availability of the Intel Attestation Service (IAS), which is needed to verify SGX attestations Technical challenges Smart contracts execute in an ad- versarial environment where parties can reap financial gains by subverting the contracts or services on which they rely|,Non-data,101
| Formal security is thus vitally important We adopt a rig- orous approach to the design of Town Crier by modeling it in the Universal Composibility (UC) framework, build- ing on [27, 34] to achieve an interesting formal model that spans a blockchain and trusted hardware We formally de- fine and prove that TC achieves the basic property of data- gram authenticity—informally that TC faithfully relays cur- rent data from a target website We additionally prove fair expenditure for an honest requester, informally that the fee paid by a user contract calling TC is at most a small amount to cover the operating costs of the TC service, even if the TC host is malicious|,Non-data,101
| Another contribution of our work is introducing and show- ing how to achieve two key security properties: gas sustain- ability and trusted computing base (TCB) code minimization within a new TCB model created by TC’s combination of a blockchain with SGX Because of the high resource costs of decentralized code execution and risk of application-layer denial-of-service (DoS) attacks, Ethereum includes an accounting resource called gas to pay for execution costs Informally, gas sustainabil- ity means that an Ethereum service never runs out of gas, a general and fundamental availability property We give a formal definition of gas sustainability applicable to any Ethereum service, and prove that TC satisfies it|,Non-data,101
| We believe that the combination of blockchains with SGX introduced in our work will prove to be a powerful and gen- eral way to achieve confidentiality in smart contract sys- tems and network them with off-chain systems This new security paradigm, however, introduces a hybridized TCB that spans components with different trust models We introduce techniques for using such a hybridized TCB se- curely while minimizing the TCB code size In TC, we show how to avoid constructing an authenticated channel from the blockchain to the enclave—bloating the enclave with an Ethereum client—by instead authenticating enclave outputs on the blockchain|,Non-data,101
 We also show how to minimize on-chain signature-verification code These techniques are general; they apply to any use of a similar hybridized TCB Other interesting smaller challenges arise in the design of TC One is deployment of TLS in an enclave,Non-data,101
| Enclaves lack networking capabilities, so TLS code must be carefully parti- tioned between the enclave and untrusted host environment Another is hedging in TC against the risk of compromise of a website or single SGX instance, which we accomplish with various modes of majority voting: among multiple websites offering the same piece of data (eg stock price) or among multiple SGX platforms|,Non-data,101
| Applications and performance We believe that TC can spur deployment of a rich spectrum of smart contracts that are hard to realize in the existing Ethereum ecosystem We explore three examples that demonstrate TC’s capabilities: (1) A financial derivative (cash-settled put option) that con- sumes stock ticker data; (2) A flight insurance contract that relies on private data requests about flight cancellations; and (3) A contract for sale of virtual goods and online games (via Steam Marketplace) for Ether, the Ethereum currency, us- ing custom data requests to access user accounts Our experiments with these three applications show that TC is highly scalable|,Non-data,101
| Running on just a single SGX host, TC achieves throughputs of 15-65 tx/sec TC is easily paral- lelized across many hosts, as separate TC hosts can serve re- quests with no interdependency (For comparison, Ethereum handles less than 1 tx/sec today and recent work [19] sug- gests that Bitcoin can scale safely to no more 26 tx/sec with reparametrization) For these same applications, ex- perimental response times for datagram requests range from 192-1309 ms—much less than an Ethereum block interval (12 seconds on average)|,Non-data,101
| These results suggest that a few SGX-enabled hosts can support TC data feed rates well be- yond the global transaction rate of a modern decentralized blockchain Contributions We offer the following contributions: • We introduce and report on an end-to-end implementa- tion of Town Crier, an authenticated data feed system that addresses critical barriers to the adoption of decen- tralized smart contracts TC combines a smart-contract front end in Ethereum and an SGX-based trusted hard- ware back end to: (1) Serve authenticated data to smart contracts without a trusted service operator and (2) Sup- port private and custom data requests, enabling encrypted requests and secure use of access-controlled, off-chain data sources|,Non-data,101
| We plan to launch a version of TC soon as an open-source service • We formally analyze the security of TC within the Uni- 271versal Composibility (UC) framework, defining function- alities to represent both on-chain and off-chain compo- nents We formally define and prove the basic properties of datagram authenticity and fair expenditure as well as gas sustainability, a fundamental availability property for any Ethereum service • We introduce a hybridized TCB spanning the blockchain and an SGX enclave, a powerful new paradigm of trust- worthy system composition|,Non-data,101
| We present generic tech- niques that help shrink the TCB code size within this model as well as techniques to hedge against individual SGX platform compromises • We explore three TC applications that show TC’s abil- ity to support a rich range of services well beyond those in Ethereum today Experiments with these applica- tions also show that TC can easily meet the latency and throughput requirements of modern decentralized blockchains Due to space constraints, a number of details on formal- ism, proofs, implementation, and applications are relegated to the paper appendices with pointers in the paper body|,Non-data,101
| Appendices may be found in the supplementary materials 2 BACKGROUND In this section, we provide basic background on the main technologies TC incorporates, namely SGX, TLS / HTTPS, and smart contracts SGX|,Non-data,101
