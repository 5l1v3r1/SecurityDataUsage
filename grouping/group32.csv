 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| To answer a range query, the server performs binary search to find the lower and upper bound- aries in the encrypted database corresponding to its query and returns all ciphertexts lying within those bounds The client then decrypts the ciphertexts to learn the response More formally, we define our range query scheme Πrq = (RQSetup, RQ|,Non-data,77
|Range, RQInsert, RQDelete) as follows: • RQSetup(1λ, D) → (t, st)|,Non-data,77
| The setup algorithm between the client and server proceeds as follows: – Client(1λ, D) → (sk, t) The client, on input the secu- rity parameter λ and database D, generates a secret key sk ← ORESetup(1λ) Then, the client sorts the database D, and for each sequential element xi ∈ D, the client computes cti ← ORE|,Non-data,77
|EncryptR(sk, xi), and sends the token t = (ct1,    , ctM ) to the server|,Non-data,77
| – Server(t) → st The server simply sets st = t • RQRange(sk, q, st) → (t, st(cid:48))|,Non-data,77
| The range query algorithm between the client and server proceeds as follows: – Client(sk, q = (x, y)) → t The client, on input the se- cret key sk and a query representing a range query for the range [x, y], produces the token t = (OREEncryptL(sk, x), OREEncryptL(sk, y)) which is sent to the server|,Non-data,77
| – Server(st, t) → (st(cid:48), r) The server takes as input its current state st = (ct1,   |,Non-data,77
| , ctM(cid:48) ) for some integer M(cid:48), and the token t = (ctx, cty) Using ORECompare, it performs a binary search to find the ciphertexts in st that are “at least” ctx and “at most” cty Let r be the set of ciphertexts lying in this interval|,Non-data,77
| The server outputs the response r and an updated state st(cid:48) = st – Client(sk, r) → S The client, on input the secret key sk and the response r = (ct1,  |,Non-data,77
|  , ctm) for some integer m, outputs the tuple S = (OREDecrypt(sk, ct1),  |,Non-data,77
|  , OREDecrypt(sk, ctm)) (Recall from Remark 2|,Non-data,77
|1 that any ORE scheme can be augmented with a decryption algorithm) • RQInsert(sk, q, st) → (t, st(cid:48)) The insert algorithm be- tween the client and server proceeds as follows: – Client(sk, q = x) → t|,Non-data,77
| The client, on input the se- cret key sk and a query representing an insertion of the value x, produces a token t = (OREEncryptL(sk, x), OREEncryptR(sk, x)) which is sent to the server – Server(st, t) → (st(cid:48), r)|,Non-data,77
| The server takes as input its current state st and the token t = (ct1, ct2) Using ORECompare(ct1,·), it performs a binary search over the contents of its database st to find the index at which to insert the new value The server inserts ct2 at that position and outputs the updated database st(cid:48)|,Non-data,77
| • RQDelete(sk, q, st) → (t, st(cid:48)) The delete algorithm be- tween the client and server proceeds as follows: – Client(sk, q = x) → t The client, on input the secret key sk and a query representing a deletion of the value x, produces a token t = (ORE|,Non-data,77
|EncryptL(sk, x), OREEncryptR( sk, x)) which is sent to the server – Server(st, t) → (st(cid:48), r) The server takes as input its current state st and the token t = (ct1, ct2)|,Non-data,77
| Using ORECompare(ct1,·), it performs a binary search over the contents of its database st to find the indices of the elements in st equal to ct1 It removes the entries at the matching indices and outputs the updated database st(cid:48) Correctness|,Non-data,77
| By correctness of the ORE scheme, the state st maintained by the server after each query is a (sorted) list of right encryptions (under sk) of the values in the database D after the corresponding insertions and deletions Thus, 1174the response r returned by the server to the client in a range query for the range [x, y] is precisely the subset of ciphertexts whose plaintext values fall in the range [x, y] Correctness follows by correctness of ORE decryption (which in turn follows from correctness of the ORE scheme) Additional properties|,Non-data,77
| In addition to the core security and correctness properties that we want from a symmet- ric range query scheme, we also note several useful proper- ties that our construction Πrq achieves for handling efficient range queries in our client-server model • Stateless client and single-round protocols The client does not need to maintain state between queries, and each query is a single round trip between the client and the server Our protocol achieves optimal round com- plexity|,Non-data,77
| • Short query tokens The size of each query token t is asymptotically optimal They are approximately the same length as the inputs used to generate the query, and independent of the size of the database • Fast responses|,Non-data,77
| The running time of the server’s algo- rithms is sublinear (logarithmic) in the total number of elements in the database In the full version [43], we also describe how our techniques can be extended to databases with multiple columns Online security Here, we give a informal characterization of the online leakage of our range query scheme|,Non-data,77
| In the full version [43], we give a complete and formal specification of the scheme’s leakage In our description below, we refer to the leakage func- tion L(d) blk(m1, m2) as the “ORE leakage” between two equal- length values m1 and m2 Informally, the “ORE leakage” in our setting is the ordering of m1 and m2 and the index of the first differing digit in the d-ary representation of m1 and m2 Our range query leakage function Lrq then takes as input the database D = (d1, |,Non-data,77
|   , dM ), and a sequence of (cid:96) queries q1,  |,Non-data,77
|  , q(cid:96) and outputs: • For each i ∈ [M ] and j ∈ [(cid:96)], the ORE leakage between each database value di and query qj For a range query of the form q = (x, y), this includes the ORE leakage between both pairs (di, x) and (di, y) for i ∈ [M ] • For each query qi, and each insertion or deletion query q(cid:48) j, the ORE leakage between qi and q(cid:48) j|,Non-data,77
| Similarly, for a range query of the form qi = (xi, yi), this include the j) and (yi, q(cid:48) ORE leakage between both pairs (xi, q(cid:48) j) Roughly speaking, our range query scheme reveals the or- dering and the index of the first differing digit between every query and every message in the database We also leak some information between range queries and insertion/deletion queries We formalize these notions in the full version|,Non-data,77
| Offline security Offline security (Definition 52) of our range query scheme Πrq follows directly from the fact that the encrypted database stored on the server only contains a collection of right ciphertexts, which are simulatable given just the size of the collection (that is, the right ciphertexts are semantically secure encryptions of their values) We give the formal proof in the full version [43]|,Non-data,77
| Robustness against offline inference attacks Offline security for our protocol implies that the contents of the server’s database are always semantically secure Conse- quently, ciphertext-only inference attacks, such as those stud- ied by Naveed et al [46], do not directly apply|,Non-data,77
| In their model [46, §42], an attacker is able to obtain ac- cess to the “steady state” of an encrypted database, which describes the database in a state that includes all auxiliary information that is needed to perform encrypted searches efficiently In our scheme, no such auxiliary information is needed on top of the ORE scheme, and yet we are still able to achieve offline security In contrast, in other existing PPE-based schemes, comparisons are enabled by a underly- ing layer of OPE encryption, which is vulnerable to inference attacks|,Non-data,77
| Thus, even though these schemes can be modified to satisfy our notion of offline security, their “steady-state” representation is in the form of OPE ciphertexts which are vulnerable to inference attacks Our scheme achieves robust- ness against these ciphertext-only inference attacks because our steady-state representation is precisely our offline rep- resentation Finally, we note that we can always add addi- tional layers of encryption (eg|,Non-data,77
|, onion encryption [51]) with- out compromising the security of our range query scheme, which can serve as a useful countermeasure against general adversaries 6 IMPOSSIBILITY RESULT FOR OPE In the full version of this paper [43], we give matching up- per and lower bounds for stateless OPE schemes that satisfy the notion of best-possible semantic security Our results strengthen the lower bound given by Boldyreva et al|,Non-data,77
| [9, 10], and can be stated informally as follows: Theorem 61 (Informal) There are no efficient order- preserving encryption schemes that satisfy best-possible se- curity on a message space containing at least 3 elements Our lower bound shows that even in the small-domain set- ting, strong security is only possible with ORE, and not OPE|,Non-data,77
| 7 EXPERIMENTAL EVALUATION To assess the practicality of our order-revealing encryp- tion scheme from Section 4, we give a full implementation of our scheme and measure its performance on a wide range of parameter settings We then compare the performance against the Boldyreva et al [9] OPE scheme and the Ch- enette et al|,Non-data,77
| [22] ORE scheme In our implementation, we use the technique from Remark 31 to shrink the ciphertexts Instantiating primitives|,Non-data,77
| Our implementation is entirely written in C We operate at 128-bits of security (λ = 128) We instantiate the PRF with AES-128 To construct a PRP on 2d-bit domains (for d < 128), we use a 3-round Feistel network using a PRF on d-bit inputs [44]|,Non-data,77
| In our experi- ments, we only consider d < 128, and thus, can instantiate the PRF using AES (where the d-bit input is padded to 128-bits) For the random oracle, we consider two candi- date constructions In the first, we use SHA-256, a standard cryptographic hash function commonly modeled as a ran- dom oracle For our second instantiation of the random oracle, we use an AES-based construction|,Non-data,77
| This allows us to leverage the AES-NI instruction set for hardware-accelerated evaluation of AES Recall from Section 4 that our construction requires a random oracle mapping from a domain {0, 1}2λ = {0, 1}256 1175to Z2 (after applying the modification from Remark 31) On an input (k, x) ∈ {0, 1}128 ×{0, 1}128, we take the output of the random oracle to be the least significant bit of AES(k, x)|,Non-data,77
| Certainly, if we model AES as an ideal cipher, then this con- struction implements a random oracle We note that mod- eling AES as an idealized object such as a random permuta- tion or an ideal cipher has been used in many other recent works such as constructing efficient garbling schemes [5] or the Simpira family of permutations [36] In our implementation, we use the OpenSSL [55] imple- mentations of AES and SHA-256 as well as the GMP [35] library for big integer arithmetic Our full implementation contains approximately 750 lines of code|,Non-data,77
| For our imple- mentation of Boldyreva et al’s OPE scheme, we use the C++ implementation from CryptDB [51],6 and for our im- plementation of Chenette et al’s ORE scheme, we use the C implementation FastORE7 In our benchmarks, we sub- stitute AES for HMAC as the underlying PRF used in the FastORE library|,Non-data,77
 We believe this provides a more balanced comparison of the performance tradeoffs between the Ch- enette et al scheme and our new ORE scheme Benchmarks and evaluation We run all of our exper- iments on a laptop running Ubuntu 14,Non-data,77
|04 with a 23 GHz Intel Core i7 CPU (Haswell microarchitecture) and 16 GB of RAM Although our encryption algorithm is easily paral- lelizable, we do not leverage parallelism in our benchmarks The processor supports the AES-NI instruction set, hence our decision to base as many primitives as possible on AES|,Non-data,77
| Our micro-benchmarks for encrypting and comparing 32-bit integers are summarized in Table 1 In Figure 2, we com- pare the cost of encryption for the different schemes across different-sized message spaces From Table 1, the time needed to compare two ORE ci- phertexts is similar to the time needed to compare two in- tegers (in the OPE setting) Thus, while it is the case that deploying ORE in encrypted database systems would re- quire implementing a custom comparator in the database management system, in practice, this incurs a very small computational overhead|,Non-data,77
| Compared to OPE, our new ORE scheme is significantly faster For instance, when processing byte-size blocks, en- crypting a single 32-bit value requires just over 50 μs of computation and is over 65 times faster compared to vanilla OPE Even our SHA-256-based implementation is about 10x faster compared to OPE Moreover, as shown in [22, Re- mark 2|,Non-data,77
|6 and §4], an ORE scheme which leaks the first bit that differs between two encrypted messages is prov- ably more secure than any OPE scheme which behaves like a truly random order-preserving function Since our new ORE scheme leaks strictly less information than the Ch- enette et al scheme, we conclude that our new ORE scheme is both more secure and faster compared to OPE schemes Of course, when compared to the bit-by-bit construction of [22], our new ORE scheme is much slower|,Non-data,77
| However, in exchange, our new ORE scheme confers stronger security as well as lends itself nicely towards a range query system that provides robustness against inference attacks One of the main limitations of our new ORE scheme is the increase in the ciphertext size Both OPE and the Ch- enette et al ORE schemes are able to achieve ciphertexts 6https://github|,Non-data,77
|com/CryptDB/cryptdb 7https://githubcom/kevinlewi/fastore 10,000 1,000 100 10 1 ) s μ ( i e m T n o i t p y r c n E 0 16 32 48 64 Bit Length of Message Space Boldyreva et al Chenette et al Our scheme (SHA) Our scheme (AES) Figure 2: Performance comparison between our ORE scheme (Section 4) and existing OPE and ORE schemes|,Non-data,77
| We use a fixed base representation d = 8 for our ORE scheme in these experiments The two variants of our scheme, labeled SHA and AES, re- fer to how we instantiate the random oracle in our construction where the overhead is an additive or (small) multiplicative factor in the length of the messages In our setting, because our main construction relies critically on a small-domain ORE scheme that offers best-possible security, and the ex- isting small-domain ORE scheme have ciphertexts that grow linearly in the size of the message space, the size of the ci- phertexts in our composed scheme grows quickly in the block size|,Non-data,77
| Nonetheless, when encrypting byte-by-byte, encrypting a 32-bit integer requires just 224 bytes, which is quite mod- est for many practical applications An interesting direction for future work is to construct a more compact small-domain ORE with best-possible security Such a construction can be extended to a large-domain ORE with shorter ciphertexts by applying our techniques from Section 4 8|,Non-data,77
| RELATED WORK In this section, we survey some of the literature on order- revealing and order-preserving encryption, as well as the ex- isting work on searching over encrypted data OPE and ORE The concept of order-preserving encryp- tion was first introduced by Agrawal et al [2], who explored the application of OPE for performing encrypted database queries|,Non-data,77
| The first explicit OPE construction was formalized in the seminal work of Boldyreva et al [9], and has sub- sequently been expanded on in a multitude of works [10, 48, 50, 54, 41, 40, 45, 52, 8] Some of these works [10, 54] have focused on exploring the security properties of order- preserving encryption Others [50, 41, 40, 52, 8] have consid- ered stateful or interactive OPE solutions which avoid both the lower bounds in [9, 10, 50] as well as our strengthened lower bound from Section 6|,Non-data,77
| However, synchronizing state and coordinating multi-round interactions in distributed, large-scale execution environments is often difficult, and con- sequently, nearly all existing OPE deployments (eg, Sky- High Networks, CipherCloud) use stateless variants of OPE for sorting and filtering on encrypted data Numerous ad hoc OPE schemes [7, 38] have also been proposed in recent years, but they often lack a formal security analysis|,Non-data,77
| 1176Scheme Boldyreva et al OPE [9] Chenette et al ORE [22] Our ORE scheme (RO: SHA-256) Our ORE scheme (RO: AES) d – 1 4 8 12 4 8 12 Encrypt Compare ||ct|| Leakage 360182 μs 0|,Non-data,77
36 μs 8 bytes (Hard to quantify) 206 μs 048 μs 8 bytes First bit that differs 5448 μs 361,Non-data,77
04 μs 437064 μs 1650 μs 5487 μs 721,Non-data,77
37 μs 038 μs 098 μs 320 μs 0,Non-data,77
31 μs 063 μs 261 μs 192 bytes 224 bytes 1612 bytes 192 bytes 224 bytes 1612 bytes First block of d-bits that differs First block of d-bits that differs Table 1: Performance comparison between our ORE scheme from Section 4 and existing OPE and ORE schemes We consider two variants of our scheme: one where the random oracle is instantiated using an AES-based construction and one where the random oracle is instantiated with SHA-256,Non-data,77
| We describe these two instantiations in greater detail in Section 7 In these benchmarks, we use a 32-bit plaintext space, and measure the time needed to encrypt a (randomly chosen) message and the time needed to compare two ciphertexts The parameter d is the block size (in bits) in our ORE scheme Our micro-benchmarks are averaged over 50–107 iterations (the precise number is adjusted based on the approximate runtime of the algorithm)|,Non-data,77
| The notion of order-revealing encryption was first intro- duced by Boneh et al [12], who gave a construction from multilinear maps that satisfies best-possible security More generally, ORE is a special case of multi-input functional encryption (MIFE) [33] To date, the only constructions of general-purpose MIFE rely on heavy primitives such as indistinguishability obfuscation [4, 28] and are far too inef- ficient to deploy|,Non-data,77
| Chenette et al [22] recently proposed an efficient ORE scheme, which we improve upon and general- ize in our work In the small-domain setting, it is possible to construct ORE from either symmetric or public-key encryp- tion [3, 16] or bilinear maps [42], but these constructions are far less efficient compared to our small-domain ORE from Section 3, which just relies on PRFs Searching on encrypted data|,Non-data,77
| Numerous techniques, such as searchable symmetric encryption (SSE) [53, 24, 20], property-preserving encryption (PPE) [9, 48, 21], fully ho- momorphic encryption (FHE) [29], hidden vector encryp- tion [15], oblivious RAMs (ORAM) [32], and others have been proposed for tackling the general problem of searching and querying on encrypted data While tools such as FHE or ORAM can be used for searching on encrypted data [11, 57], these methods are prohibitively expensive for nearly all real- world deployments On the more practical side, numerous SSE schemes [53, 30, 19, 24, 20, 37, 47] have been proposed in the last 15 years, but these past works are limited to exact keyword searches, and generally do not handle the efficient computation of complex queries (such as range queries) over encrypted data More recently, several works [18, 17, 49, 25] describe constructions of SSE schemes that are able to han- dle more expressive queries|,Non-data,77
| We survey these works below Cash et al [18] give the first SSE scheme that supports Boolean queries (in time sublinear in the size of the database) with a small amount of leakage and security from the de- cisional Diffie-Hellman (DDH) assumption Subsequently, Cash et al|,Non-data,77
| [17] extend the construction to allow for up- dates to the encrypted database as well as support multi- ple, potentially dishonest clients Handling updates requires the client to maintain a small amount of state (or requires additional rounds of communication and leads to increased leakage) Boolean queries alone, however, do not suffice for range queries, so in another follow-up work, Faber et al [25] show how the Cash et al|,Non-data,77
| SSE scheme can be leveraged for range queries Their resulting construction leaks some addi- tional information about the database contents, namely the number of values that fall into certain subintervals within the requested range Moreover, due to the use of univer- sal covers, the size of the server’s response set to a range query may be up to 66% larger than the size of the true re- sponse set We do not know of any existing SSE scheme that can efficiently support range queries with optimal (minimal) leakage|,Non-data,77
| Concurrent to the work of Cash et al, Pappas et al [49] introduce BlindSeer, a private database management system that can support a wide-range of queries in sublinear time over an encrypted database Their construction leverages generic two-party computation tools such as Yao’s garbled circuits [56], and their construction provides security in the semi-honest model|,Non-data,77
| Comparison to our techniques To conclude, we high- light some of the key differences between existing SSE meth- ods and our ORE-based construction for implementing range queries over an encrypted database: • Like other PPE-based constructions, our ORE-based con- struction integrates well with existing database manage- ment systems—we just need to implement a custom com- parator With SSE, we would have to deploy a new, and oftentimes, complex database management system This lacks legacy compatibility, which is a barrier to deploy- ment in existing systems|,Non-data,77
| Our approach provides a fast, simple, and direct solution for supporting range queries on encrypted data without requiring significant infrastruc- tural changes • We explicitly model and analyze the leakage of our range query protocol assuming adaptive updates to the database • Our construction only requires symmetric primitives and does not require more expensive primitives such as public- key cryptography or oblivious transfer Acknowledgments We thank Dan Boneh, Mark Zhandry, and Joe Zimmerman for insightful discussions about this work|,Non-data,77
| We thank the members of the 2015 Stanford Theory Retreat for initiat- 1177ing our study of new OPE lower bounds This work was supported by the NSF, DARPA, the Simons foundation, a grant from ONR, and an NSF Graduate Research Fellow- ship Opinions, findings and conclusions or recommenda- tions expressed in this material are those of the author(s) and do not necessarily reflect the views of DARPA 9|,Non-data,77
|ABSTRACT Pseudo-random number generators (PRNGs) are a critical infrastructure for cryptography and security of many com- puter applications At the same time, PRNGs are surpris- ingly difficult to design, implement, and debug This paper presents the first static analysis technique specifically for quality assurance of cryptographic PRNG implementations The analysis targets a particular kind of implementation defect, the entropy loss|,Non-data,80
| Entropy loss occurs when the en- tropy contained in the PRNG seed is not utilized to the full extent for generating the pseudo-random output stream The Debian OpenSSL disaster, probably the most prominent PRNG-related security incident, was one but not the only manifestation of such a defect Together with the static analysis technique, we present its implementation, a tool named Entroposcope The tool of- fers a high degree of automation and practicality|,Non-data,80
| We have applied the tool to five real-world PRNGs of different de- signs and show that it effectively detects both known and previously unknown instances of entropy loss Keywords Pseudo-Random Number Generator; PRNG; entropy loss; information flow; OpenSSL; static analysis; bounded model checking 1 INTRODUCTION Motivation and goal Somewhat simplified, a pseudo-random number generator (PRNG) is a software module that is seeded with a small amount of externally-sourced entropy (read randomness)1 and “stretches” it into a stream that is indistinguishable from random to a computationally-bounded adversary|,Non-data,80
| The 1Entropy is, strictly speaking, a measure of uncertainty, but, as customary, we overload the term to denote data with high entropy, ie, data that is difficult to guess for an adversary Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita- tion on the first page|,Non-data,80
| Copyrights for components of this work owned by others than ACM must be honored Abstracting with credit is permitted To copy otherwise, or re- publish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acm|,Non-data,80
|org CCS’16, October 24-28, 2016, Vienna, Austria c(cid:13) 2016 ACM ISBN 978-1-4503-4139-4/16/10 |,Non-data,80
  $1500 DOI: http://dxdoi,Non-data,80
|org/101145/29767492978369 seed is typically obtained from outside the immediate sys- tem scope: A user-space PRNG, for instance, may query the OS, which derives it, among other things, from physical noise in the hardware The PRNG then produces a stream of pseudo-random data by, in cycles, permuting its internal state and deriving a fixed-length output chunk from a part of it|,Non-data,80
| The latter part of the PRNG code, with which we will be concerned in this paper, is deterministic and contains both cryptographic and non-cryptographic parts On the implementation level, of all things, the non-cryp- tographic parts have shown a history of defects causing fa- tal security incidents Many of these defects are entropy losses, where entropy supplied in the seed is overwritten with constant or predictable values, or otherwise remains unused during PRNG operation This kind of defect makes it unnecessarily easy for an attacker to predict the PRNG output|,Non-data,80
| The probably most prominent PRNG security incident, the Debian OpenSSL disaster [28], was caused by such an entropy loss While sufficient seed entropy was available (the code collecting entropy was working), only 15 bits of it (the ID of the current process) were used for generating output, resulting in merely 215 = 32768 distinct possible output streams (fixing endianness and native word size) As a consequence, for instance, only 215 key pairs could be gen- erated on any affected system, which allowed an attacker to easily brute-force the private key to any given public key generated on a vulnerable system For an attacker, a flawed PRNG is an attractive vector, as it constitutes a single point of failure for many services relying on cryptography|,Non-data,80
| The Debian OpenSSL disaster effectively demonstrated this point by affecting the secu- rity of—among other things—DNS (BIND), Email (postfix, cyrus, uw-imapd), FTP, VPN (StrongSWAN, OpenVPN), SSH (OpenSSH clients and servers), Kerberos authentica- tion, Tor, and WWW (Apache)2 For almost two years, the general public lacked awareness that cryptographic measures securing these services on Debian systems were essentially turned off Attacks based on PRNG flaws are also particularly insid- ious, as they often require only passive access to the vic- tim’s communications Breaking into the victim’s system is typically not necessary|,Non-data,80
| Such an attack leaves behind less evidence and is thus much more difficult to detect or, in af- termath, reconstruct This point was illustrated by a series of unsolved bitcoin thefts probably going back to an entropy loss in the Android PRNG [23] 2https://wikidebian|,Non-data,80
|org/SSLkeys 678Despite the gravity of the situation, there are very few ef- fective quality assurance techniques against implementation defects in cryptographic PRNGs The first testing technique claiming potential to have prevented the Debian OpenSSL disaster was proposed only recently [27] The overarching contribution of this work is the first static analysis technique for detecting entropy loss in PRNG im- plementations An entropy loss is detected when the anal- ysis finds two distinct seeds that produce the same output stream|,Non-data,80
| The technique is implemented in a highly auto- matic analysis tool building on program verification technol- ogy and effectively applies to real-world implementations Contributions in detail The paper identifies absence of entropy loss, a particular important correctness property of PRNGs, and formulates it within the popular semantical framework of information flow In contrast to functional specification, such a formu- lation is both succinct, easy to understand, and uniform across PRNGs|,Non-data,80
| In contrast to the majority of established security research scenarios, PRNG correctness is concerned with maximizing and not minimizing information flow, ren- dering most of the existing security analysis tools inapplica- ble The paper proposes a method to find deviations from flow maximality and thus instances of entropy loss A particular challenge in this context is the use of cryp- tographic primitives in PRNGs Since our analysis is purely information-theoretic, we propose a way to deal with the issue by replacing such primitives with idealizations|,Non-data,80
| Implementing the method, the paper presents a tool for PRNG analysis, built on top of the CBMC bounded model checker for C and Java Due to the carefully defined appli- cation scenario, the tool enables a fast feedback cycle, with counterexamples, ie, potential witnesses of entropy loss, aiding the developer in understanding the problem|,Non-data,80
| We have applied the analyzer to five popular PRNG im- plementations, including the OpenSSL PRNG and Apple’s version of Yarrow We report our experiences in detail us- ing the example of OpenSSL One result is that the tool detected a previously undiscovered (if small) entropy loss in the OpenSSL PRNG A larger previously undiscovered entropy loss was detected in the Libgcrypt PRNG|,Non-data,80
| The paper also includes a “mini-museum” of entropy loss with the goal to increase awareness of this kind of prob- lem This section presents and discusses several disparate instances of entropy loss, demonstrating the importance of the concept and the diversity of applications where the prob- lem occurs 2 ILLUSTRATION OF ENTROPY LOSS: ANDROID PRNG (2013) The origin of the Android PRNG lies in the Apache Har- mony project, a clean room reimplementation of the Java Core Libraries under the Apache License|,Non-data,80
| The Harmony PRNG was part of the Android platform up to and includ- ing Android 41 It was replaced when a problem with the PRNG became widely known [23], after a series of mysteri- ous bitcoin thefts Bitcoin transactions are ECDSA signatures and include a nonce that is often generated by a PRNG|,Non-data,80
| If the same nonce is used for two transactions signed by the same key, then anyone can reconstruct the private key of the victim from public information and divert their money without having to compromise their system Entropy loss in the PRNG increases the probability of nonce reuse The entropy loss occurred in the main method of the An- droid PRNG, engineNextBytes(byte[] bytes), which fills the caller-supplied array bytes with pseudo-random values The PRNG operates in cycles, each cycle generating 20 pseudo- random bytes|,Non-data,80
| If the caller requests more bytes, several cycles are performed; if the caller requests fewer bytes, the surplus generated bytes are stored for later usage The main component of the PRNG state is an int[] array of length 87, somewhat inappropriately named seed (Fig- ure 1) The front part of this array is populated with the externally-provided entropy (ie|,Non-data,80
|, the actual seed) The seed- ing can happen either manually by calling setSeed() or au- tomatically In the latter case, the PRNG is seeded with 20 bytes of entropy requested from the OS kernel on first invocation of engineNextBytes() This so-called self-seeding mode is typically considered preferable as less error-prone|,Non-data,80
| Figure 1(c) shows the essence of the PRNG’s operation in this scenario In cycle k, the 20 pseudo-random bytes are computed by combining the seed (words 0–4 in Figure 1(a)), the cycle counter k (as a 64-bit integer in words 5–6), and the output of cycle k−1 (resp SHA-1 initialization vector in the initial cycle) with the SHA-1 compression function The computation makes use of the scratch space in words 16– 79, and its result is stored in words 82–86|,Non-data,80
| The latter are subsequently unpacked into bytes that form the output of the cycle To compute the output, the seed and the cycle counter have to be suffixed by a standard-defined SHA-1 padding The PRNG keeps track of the length of the seed in word 80 The essence of the vulnerability is that a stale value of this length (i|,Non-data,80
|e, zero) is used after initializing the seed in the self-seeding mode As a consequence, the cycle counter and the SHA-1 padding constant overwrite words 0–2, leaving only two words of the original seed (Figure 1(b)) Twelve bytes of entropy are lost, and the actual amount of entropy in the PRNG amounts thus to 8 instead of 20 bytes|,Non-data,80
|3 The goal of our analysis is to detect that two seeds differ- ing in words 0–2 will produce the same output stream 3 FOUNDATIONS 31 The PRNG Model In this paper, we treat a PRNG as a function g : {0, 1}m → {0, 1}n , which translates a seed of m bits into a stream of n bits (m, n > 0)|,Non-data,80
| The fact that we only consider finite streams is inconsequential in the scope of this work Since PRNG implementations typically use bytes as an atomic unit of information exchange, we establish the following convention Whenever we use the parameters M and N , we are implying m = 8M and n = 8N  The above model of a PRNG as a function from seed to output goes hand in hand with the following assumptions that we make: 3The PRNG also contains a native backup component in case the kernel does not provide an entropy source|,Non-data,80
| Inciden- tally, this component contained two more instances of en- tropy loss, though these were much simpler technically [23] 679out 0 = sha1 ( seed (cid:124) 0 (cid:124) sha1 - iv ) out k = sha1 ( seed (cid:124) k (cid:124) out k−1 ) (c) Equations describing the output of the Android PRNG in each cycle (a) Intended operation (b) Effect of the bug Figure 1: Structure of the Android PRNG’s main array (1 word = 1 int = 4 bytes) 1 The PRNG is seeded before it starts producing output 2|,Non-data,80
| The seed is chosen uniformly at random from the set {0, 1}m for some m > 0 3 An attacker neither knows the seed nor has control over its choice 4|,Non-data,80
| The PRNG is not re-seeded, ie, the seed remains con- stant throughout the PRNG’s lifetime4 5|,Non-data,80
 An attacker knows the source code of the PRNG but cannot inspect or corrupt its internal state 6 We only consider sequential operation (ie,Non-data,80
|, no multi- threading) 32 PRNG Security Concerns Security of a PRNG means intuitively that a computation- ally-bounded attacker cannot predict its output with any practical probability We will not state a complete formal model of PRNG security|,Non-data,80
| Instead, we describe three major concerns that are its necessary prerequisites In this paper, we focus on Concern 2, but to delineate the problem prop- erly, we briefly discuss the others as well Concern 1 The entropy contained in the seed should be sufficiently large|,Non-data,80
| While we leave open what exactly is considered sufficient, the issue can be further broken down as follows First, the seed range 2m (ie, number of possible seeds) should be sufficiently large|,Non-data,80
| For instance, the cur- rent time of the day in milliseconds provides only slightly more than m = 26 bits of entropy Second, entropy is maxi- mal for the uniform distribution Skewed seed distributions will reduce entropy content Third, in practice, entropy ar- guments are only sound relative to attacker knowledge|,Non-data,80
| If one seeds the PRNG with current time but the attacker can roughly identify the moment when the seeding takes place, the effective unpredictability will be significantly below the theoretical 26 bits mentioned above5 Since, hardware noise is typically an important source of PRNG seeds, ensuring sufficient seed entropy requires 4Reseeding can be modeled by considering several PRNG functions An example featuring the Yarrow PRNG is shown in Figure 4(b), Section 6 5This circumstance was used in cracking the online poker PRNG in [2] or the hardware PRNG in encrypted hard drives [1]|,Non-data,80
| In the latter case, the hardwired seed was close to the manufacturing time embossed on the drive knowledge of said hardware (eg, rotating hard drive vs|,Non-data,80
| SSD) and its characteristics (eg, seek time distribution) In the meantime, it has become widely known that proper seeding can be a substantial challenge in virtual machines and embedded devices [15]|,Non-data,80
| Concern 2 Seed entropy should not be lost during PRNG operation For an unbounded attacker, predicting the PRNG output of length n (cid:62) m should not be easier than predicting the m-bit seed itself Since the output is a deterministic function of the seed, it is clear that it is impossible to keep unpredictable both the output and the seed after observing the output|,Non-data,80
| Barring permanent inflow of entropy, the only practical solution to this dilemma is to maximize the flow of information from the seed to the output and to prevent seed reconstruction by means of a cryptographic one-way function, shifting the adversary assumption from an unbounded to a computa- tionally bounded one This is indeed the way most crypto- graphic PRNGs operate Summarizing, absence of seed entropy loss (Concern 2), together with sufficient seed entropy (Concern 1), impedes an attacker at brute-forcing the seed resp a part of the seed sufficient to predict the output|,Non-data,80
| Concern 3 It should be computationally infeasible to analytically invert g A resource-bounded attacker should not be able to compute seed from an observed prefix of g(seed ) Examples of PRNGs susceptible to seed reconstruction are PRNGs that do not use cryptography, such as the linear congruential generators (LCG)|,Non-data,80
| A typical representative is the drand48 generator in the C standard library A different example is the Dual EC DRBG, which uti- lizes a supposedly one-way elliptic curve primitive incor- porating two parameters P and Q The parameters were chosen by the NSA in an opaque manner, even though the (non-)invertibility of g and thus the security of the PRNG hinges critically on their choice As [5] notes, “[|,Non-data,80
   ] it may be the case the adversary knows a d such that dQ = P  Then [,Non-data,80
|   ] a distinguisher could immediately recover the se- cret prestates from the output” When considering more elaborate PRNG security models such as [7], further concerns can be identified|,Non-data,80
 One can examine whether a PRNG can withstand an attacker that has some control over the choice of the seed or the capability 04567815167980818286seed000computationspace#0spaceforSHA1result(cid:124)(cid:123)(cid:122)(cid:125)20byte↑counter↑0x80000000045678seedcounter0x80000000,Non-data,80
012345678counter0x80000000seed(rest)0,Non-data,80
00,Non-data,80
|(cid:124)(cid:123)(cid:122)(cid:125)8byte680PX Y An attacker tries to guess the secret input X after observing program output Y  The secret X typically reflects some in- formation in the real world and has fixed entropy Reduced information flow between X and Y makes X harder to guess, increasing security (a) Classical information flow analysis scenario X PR NG X(cid:48) P Y An attacker tries to guess X(cid:48) after observing Y |,Non-data,80
| The secret X(cid:48) is generated by a PRNG, and its entropy depends on proper- ties of the generator Reduced information flow between the seed X and X(cid:48) makes X(cid:48) easier to guess, diminishing security (b) PRNG security scenario Figure 2: Information flow scenarios illustrated to temporarily inspect or corrupt the internal state of the PRNG We consider such further concerns out of scope for this paper|,Non-data,80
| Of the three concerns elaborated above, the first concern cannot be solved by means of (mere) code analysis, as it involves the larger system into which the PRNG is embed- ded The third concern has solution components in the form of widely-vetted one-way primitives, such as cryptographic hash functions of the SHA family For the second concern, this paper makes a contribution in supplementing the usual manual code review with a practical technical solution 3|,Non-data,80
|3 Entropy and Information Flow In general, entropy of a random variable X is a measure of an observer’s uncertainty about its value Information flow or leakage refers to the decrease of an (unbounded) attacker’s uncertainty about a secret part of a program’s initial state after observing a part of its final state Information flow in a deterministic terminating program can be identified with the degree of injectivity of the input-output function induced by the program [18] There is a vast body of work in information flow analysis, going back several decades|,Non-data,80
| The entropy loss problems with PRNGs have entered public awareness in 2008 at the latest, but as far as we are aware the two have never been previously brought together A part of the explanation is probably in the fact that information flow research concentrated on mini- mizing information flow for confidentiality, while maximizing information flow is needed for PRNG security (Figure 2) Various entropy metrics have been defined, such as Shan- non entropy, min-entropy, etc In this paper we will be con- centrating on min-entropy [25], which is a measure in bit of the probability to guess the value of X in one try|,Non-data,80
| Similar arguments can be made for other metrics Definition 1 (Min-entropy) The min-entropy of a random variable X H∞(X) := − log max x Pr[X = x] , where log is a logarithm to the base 2 We choose min-entropy for its clear operational guarantees w|,Non-data,80
|rt guessability By construction, the probability of an adversary successfully guessing the value of X in one try is not larger than 2−H∞(X)|,Non-data,80
| Proposition 1 If X follows a uniform distribution on a finite set of values, then H∞(X) = − log 1 ||{x ∈ X}|| = log ||{x ∈ X}||  Concretely, if X follows a uniform distribution on {0, 1}m, then H∞(X) = m bits In the PRNG setting, we are considering a pair of jointly distributed random variables X and Y , where Y = g(X)|,Non-data,80
| Proposition 2 Let X and Y be random variables with Y = g(X) and X following a uniform distribution H∞(Y ) = − log max y Pr[Y = y] = maxy∈Y ||{x ∈ X || g(x) = y}|| − log H∞(X) − log max y∈Y ||{x ∈ X}|| = ||{x ∈ X || g(x) = y}||  Corollary 3|,Non-data,80
| Under the assumptions of Proposition 2, H∞(Y ) (cid:54) H∞(X) with H∞(Y ) = H∞(X) if and only if g is injective In terms of information leakage, this result can be inter- preted as H∞(Y ) being maximal iff the information that g leaks about X is maximal Due to this constellation, many existing information flow analysis tools are not directly ap- plicable to the problem, as they inherently provide upper bounds on leakage only We, in contrast, need lower leakage bounds|,Non-data,80
| 4 THE ANALYSIS METHOD Per Corollary 3, assuring that no seed entropy is lost (ie, the PRNG output is at least as unpredictable as the seed) is synonymous to establishing that the function g induced by a PRNG is injective|,Non-data,80
| Thus, for a given PRNG implementa- tion, the analysis computes the above-described function g : {0, 1}m → {0, 1}n for given m and n (m (cid:54) n) and checks whether the entropy preservation condition g(seed 1) = g(seed 2) → seed 1 = seed 2 (1) holds In other words, we check whether two distinct seeds produce distinct pseudo-random streams While the condition (1) is quite concise on this level of abstraction, checking it with existing program verification technology is not without challenges Two major ones are: reasoning about cryptographic primitives and making the analysis practical|,Non-data,80
| 41 Modeling Cryptographic Primitives Used in a PRNG During its operation, a typical PRNG will invoke crypto- graphic primitives, such as, eg, the SHA-1 hash function|,Non-data,80
| The primitives are by design computationally hard to invert and are used, among other things, to prevent an attacker from calculating the seed from the observed PRNG output 681(Concern 3) As a consequence, it is also computationally infeasible to reason about them with verification technol- ogy6 For assuring absence of bugs in the implementation of the primitives, this infeasibility is not too problematic, as the primitives are standardized, with widely-available reference implementations and test suites The non-cryptographic PRNG code, on the other hand, is not standardized, error- prone, and cannot be easily tested|,Non-data,80
| Our goal is thus to check absence of entropy loss in the latter, non-cryptographic parts, while assuming that cryp- tographic primitives do not contribute to it We do not attempt this by considering only the code between the prim- itives, as reasoning about unstructured code is challenging and poorly supported in existing verification systems In- stead, we still consider a whole-program correctness prop- erty (ie|,Non-data,80
|, entropy flow through the whole PRNG, from seed to output) but replace the cryptographic primitives with idealizations We assume that the definition of g contains several occur- rences of a cryptographic function h: hi : {0, 1}ki → {0, 1}l  Instead of the function g, we henceforth consider the func- tion ̃g with the same signature, derived by replacing each hi in g with a function ̃hi of the same signature Altogether, we consider two types of idealizations ̃hi|,Non-data,80
| The first type of idealization replaces hi in g with a pro- jection, ie, a function of the form  ̃hi(x1,  |,Non-data,80
|  , xji ,   |,Non-data,80
| , xji+l−1,    , xki ) = (xji , |,Non-data,80
|   , xji+l−1) for some user-specified 1 (cid:54) ji (cid:54) ki Since the output of h is l bits long, we expect the input to contain at least l bits of entropy|,Non-data,80
| In practice, it suffices to assume that the l bits are supplied as one contiguous region xji ,    , xji+l−1; the other parts of the input can be discarded|,Non-data,80
| For each i, we let the user identify the entropic region start ji by visually matching bit patterns occurring in the seed to the inputs of hi In general, there is only a small fi- nite choice of possible values of ji, and in practice, the choice is often even smaller, as most PRNGs supply a concatena- tion of a few longer bitvectors to h, each with a distinct purpose (see Section 64 for an example) Now, while h and the above ̃h are both injections from xji , |,Non-data,80
|   , xji+l−1, they are otherwise incomparable functions, and the properties of ̃g need thus not carry over to g (though very often they do) In other words, this type of idealization is unsound|,Non-data,80
| The second type of idealization replaces hi in g with an un- interpreted function (ie, a fresh function symbol) ̃hi, while adding the following injectivity axiom for ̃hi, based on a user-supplied ji: (cid:0) ̃hi(x1,  |,Non-data,80
|  , xji ,   |,Non-data,80
| , xji+l−1,    , xki ) = ki )(cid:1) → (cid:48) ji+l−1, |,Non-data,80
|   , x (cid:48) ̃hi(x 1,  |,Non-data,80
|  , x (cid:48) (cid:48) ji ,   |,Non-data,80
| , x (cid:0)xji = x ji ∧    ∧ xji+l−1 = x (cid:48) (cid:1) |,Non-data,80
| (cid:48) ji+l−1 (2) We assume that the cryptographic primitive h satisfies (2), which, eg, for cryptographic hash functions, is a common 6More precisely, it is not feasible to establish properties re- lated to their injectivity (which we are interested in) In contrast, it is quite easy to prove, for instance, mere termi- nation of the SHA-1 implementation|,Non-data,80
| information-theoretical approximation of the collision-resis- tance property Since ̃h is otherwise uninterpreted, we are making strictly fewer assumptions about the nature of h in ̃g than in g The properties of ̃g thus carry over to g, which makes this type of idealization sound Theorem 4 (Soundness)|,Non-data,80
| Let ̃g be obtained from g by substituting each occurrence of h with an uninterpreted func- tion ̃h satisfying (2) If ̃g is injective and h satisfies (2), then g is injective Together with the soundness of the employed program ver- ification technology, the theorem implies that the analysis is guaranteed to detect all instances of entropy loss in the scope given by m and n The reason for also having unsound idealization is that it produces injectivity counterexamples (pairs of program traces) that are easier to interpret for the user, as the output of each ̃h is just a copy of a part of its input|,Non-data,80
| The user can thus easier track the flow of information in the PRNG by identifying occurrences of the same concrete bit pattern on the way from the seed to the output This does not hold for the sound idealization We typically perform the analysis with the unsound idealization first to find defects, and later automatically strengthen the idealization to the sound one to confirm their absence If no idealization can be synthesized to make (1) hold, then either the contiguous input region assumption is violated (we have not experienced this) or there is an entropy loss in the PRNG|,Non-data,80
| 42 Scope and Limitations While it is important to say what our analysis is designed to do, it is just as important to say what it is not designed to do The analysis does not consider entropy collection The analysis will detect entropy loss in the non-cryptographic portions of any entropy extraction code, but otherwise makes no claims about its function|,Non-data,80
| We are assuming that the pro- vided seed contains maximal entropy We are not discussing the size of the seed necessary for a desired level of security The analysis never examines the implementation of the cryptographic primitives, and cannot ensure that they are implemented correctly We assume, the risk in this area is sufficiently mitigated by using reference implementations and the appropriate test suites|,Non-data,80
| The analysis only detects loss of entropy in the first N bytes of output, given a seed of M bytes This limitation is key to achieving a tractable, automatic analysis that is sound and reasonably complete in its scope The parameters M and N can be trivially adjusted, but checking with higher bounds consumes more resources Values like M = N = 40, corresponding to 2–4 PRNG cycles are easily manageable (details in Section 6)|,Non-data,80
| The analysis is complete, except for the overapproxima- tion of the cryptographic primitive with its injectivity speci- fication (2) If a PRNG relies for its injectivity on properties of a primitive other than (2), the analysis will produce a false alarm This is a constellation that we yet have to encounter in practice If an entropy loss is detected, its severity and impact has to be established by a security analyst|,Non-data,80
| 6821 Complete the analysis driver template, fix m and n 2 If necessary, disable self-seeding|,Non-data,80
| 3 Configure the source code for analysis (complete the project-specific part of the Makefile) R A N D _ a d d ( in , M , M ) ; R A N D _ b y t e s ( out , N ) ; (a) For the OpenSSL PRNG 4 Provide cryptographic (choose j in each occurrence of (2))|,Non-data,80
| idealized implementation PrngRef ref ; p r n g I n i t i a l i z e (& ref ) ; 5 Run a sanity check, checking that CBMC can symbol- ically execute the code 6 Run the entropy loss analysis|,Non-data,80
| p r n g I n p u t ( ref , ( BYTE *) in , M , SYSTEM_SOURCE , M * 8) ; p r n g F o r c e R e s e e d ( ref ,0) ; p r n g O u t p u t ( ref , ( BYTE *) out , N ) ; 7 If analysis returns success, perform vacuity testing: in- troduce a bug in the implementation and repeat 8 If analysis returns a counterexample, run the coun- p r n g I n p u t ( ref , ( BYTE *) in2 , M , SYSTEM_SOURCE , M * 8) ; p r n g F o r c e R e s e e d ( ref ,0) ; p r n g O u t p u t ( ref , ( BYTE *) out2 , N ) ; terexample visualizer|,Non-data,80
| 9 If counterexample is spurious, refine the idealized cryp- tographic implementation and repeat the analysis 10 If counterexample is genuine, evaluate the defect’s severity and fix it as appropriate|,Non-data,80
| Figure 3: General analysis procedure 43 Checking Non-Invertibility (Concern 3) Though this is not our main concern in this paper, we can use a simple variation of the method above to check an- alytical non-invertibility of g To this end, we replace the top-level injectivity assertion (1) with one of non-injectivity: g(seed 1) = g(seed 2), and the assumption of injectivity of cryptographic primitives (2) with a corresponding non-in- jectivity assumption This approach implements a standard check that there is no information flow from the seed to the output, or the flow passes through a one-way primitive|,Non-data,80
 The one-way property of the primitive remains to be established by cryptanalysis (see the discussion of Dual EC DRBG in Section 32) 5 Entroposcope: A TOOL FOR DETECT- ING ENTROPY LOSS We have implemented our analysis in an automatic detec- tion tool named Entroposcope,Non-data,80
| The tool consists of an off-the-shelf verification tool (the bounded model checker CBMC [20]), a Java program for generating the injectivity verification condition and interpreting a potential satisfying assignment, an analysis driver template, an idealized hash function template, and a Makefile template The overall analysis procedure is outlined in Figure 3 The individual components are described in more detail in the following Relational reasoner|,Non-data,80
| Entroposcope relies on CBMC to generate for a given PRNG implementation a propositional formula in conjunc- tive normal form φ(seed , out, aux ) (3) that encodes the function g induced by the implementation The arguments of φ are vectors of propositional variables By construction, the formula ∃aux  φ(seed , out, aux ) is true iff the PRNG produces the output encoded by out from (b) For the Yarrow PRNG (incl|,Non-data,80
| reseeding) Figure 4: Analysis drivers (excerpts) the input encoded by seed  The auxiliary variables aux are used to represent intermediate states and for the Tseitin encoding7 Entroposcope generates from the formula (3) produced by CBMC a formula of the form ψ ∧ φ(seed , out, aux ) ∧ φ(seed (cid:48) (cid:48) , out seed (cid:54)= seed , aux (cid:48) ∧ out = out (cid:48) )∧ (cid:48)  (4) This formula (4) is essentially a negation of the correctness condition (1)|,Non-data,80
| Its satisfiability coincides with a loss of in- jectivity of g and thus entropy in the PRNG Satisfiability of (4) is checked with an off-the-shelf SAT solver (Minisat) The subformula ψ is a bit-level encoding of the idealization injectivity axiom (2) In logic-based verification, it is often customary to en- code a relational property such as (1) as a safety property via self-composition, a program transformation syntactically duplicating the program [4, 8]|,Non-data,80
| Self-composition is techni- cally challenging in presence of heap, pointer arithmetic, and complex global state To sidestep this problem, Entropo- scope operates on the logical formula level shown above rather than by transforming the program Analysis driver The starting point of the analysis is the analysis driver that defines the main function exercising the PRNG func- tionality|,Non-data,80
 The driver consists of two parts: a generic and a PRNG-specific part The PRNG-specific part is defined by the analyst in conformance with the PRNG API It is sup- posed to seed the PRNG with an M -byte seed and generate an N -byte output Figure 4 shows the PRNG-specific parts of the drivers for the OpenSSL and the Yarrow PRNG,Non-data,80
| The generic part of the driver is the same for all PRNGs (not shown) It contains the scaffolding establishing the naming convention for the seed and output buffers (needed for generating (4)), as well as the code for counterexample visualization 7A well-known method for encoding an arbitrary circuit as a formula in conjunctive normal form (CNF) required by a SAT solver 683SAT-based bounded model checker|,Non-data,80
| To generate the formula (3), Entroposcope uses the SAT-based model checker CBMC [20] CBMC is a very mature and popular bit-precise verification tool supporting almost all of ANSI C, including pointer constructs and dy- namic memory allocation Since recently, CBMC also sup- ports programs written in Java CBMC executes the program symbolically starting from the given function (in our case, the main function of the analysis driver)|,Non-data,80
| During this process, called functions are inlined and loops are unwound to the user-specified depth CBMC warns the user if the unwinding depth is insuffi- cient to cover all of the program behaviors (this is known as unwinding assertion checking) The unwound program is transformed into the static-single-assignment (SSA) form In this form, statements can be interpreted as equations over bitvectors|,Non-data,80
| The equations are combined and reduced to a formula of propositional logic in a process resembling syn- thesis of arithmetic circuits The formula is flattened into j Li,j, where each lit- eral Li,j is either a propositional variable or its negation The formula is exported in standard DIMACS format The metadata embedded in the formula allows us to identify the variables representing the seed and the output|,Non-data,80
| conjunctive normal form (CNF) (cid:86) (cid:87) i Verification condition generator The subformula φ(seed(cid:48), out(cid:48), aux (cid:48)) in (4) is obtained by syntactically duplicating φ(seed , out, aux ) with fresh vari- ables The schematic equality of bitvectors in (4) is, in re- ality, encoded on the individual bit level; for the inequality, Tseitin encoding is used to obtain an equisatisfiable formula in conjunctive normal form Counterexample visualizer|,Non-data,80
| If the SAT solver finds a satisfying assignment for (4), Entroposcope interprets it and outputs a pair of distinct seeds and a common PRNG output that form a suspected witness for entropy loss The user needs to analyze the coun- terexample to understand if it is spurious (ie, due to the in- sufficient choice of the cryptographic primitive idealization) or if it is a real problem in the PRNG|,Non-data,80
| To aid the user, the analyzer also generates C preambles from the satisfying as- signment and runs the PRNG once for each of the seeds The inputs and the idealized output of each cryptographic prim- itive invocation together with any other debugging output that the user may add are then displayed in a side-by-side diff 6 ANALYZING REAL-WORLD PRNGS: OPENSSL AND OTHERS We applied Entroposcope to a number of PRNGs, car- rying out the analysis according to the procedure outlined in Figure 3|,Non-data,80
| In cases where no defects were found, we injected and detected synthetic bugs Entroposcope finds the Android PRNG bug described in Section 2 and verifies the effectiveness of the official patch We found no entropy loss in the Yarrow PRNG [16] in the version used in Apple’s XNU kernel (part of iOS and OS X) One of the scenarios we analyzed included reseeding (Figure 4(b)): Entroposcope shows that the old and the new seed fully influence the output before and after reseed- ing respectively|,Non-data,80
| On the other hand, attempts to analyze Yarrow with M = 40, N = 40 (without reseeding) immedi- ately fail due to the fact that Yarrow’s generator state is only 20 bytes large (a restriction prominently declared in [16]) With Entroposcope, we found a previously undiscov- ered entropy loss in the Libgcrypt PRNG, which we briefly describe in Section 69 In the following we report in detail the results of our analy- sis of the OpenSSL PRNG|,Non-data,80
| We also analyzed the PRNG in BoringSSL, Google’s drop-in replacement for OpenSSL, and found no defects in the latter 61 Structure of the OpenSSL PRNG The relevant functions of the OpenSSL PRNG API are RAND_add(const void *buf, int num, double add_entropy) to add entropy and RAND_bytes(unsigned char *buf, int num) to generate output They are shown as pseudocode in Fig- ure 5|,Non-data,80
| The code has been simplified for presentation, elid- ing irrelevant features such as provisions for multi-threading (postponed as future work), function pointer indirection, etc The PRNG is also parametric in the choice of a crypto- graphic hash function; we present the default instantiation with SHA-1 Nonetheless, please note that, unless explic- itly mentioned otherwise below, we are analyzing the actual unmodified source code of OpenSSL OpenSSL PRNG maintains two entropy pools: a 20-byte buffer named md and a 1023-byte circular buffer named state|,Non-data,80
| Entropy added to the PRNG using RAND_add is split into 20- byte chunks and hashed chunkwise into state The chunks are chained together using local_md, a thread-local copy of the md buffer Output generation proceeds in chunks of 10 bytes First, a 20-byte hash is generated from the next 10 bytes of state and two counters; local_md is used for chain- ing|,Non-data,80
| Then, the hash is split, with 10 bytes forming output, while the other 10 bytes are XORed back into state This process is repeated until enough output bytes are generated If the requested amount of output bytes is not a multiple of 10, superfluous bytes are discarded 6|,Non-data,80
|2 Entropy Sources and the Analysis Driver The analysis driver is straightforward, containing a call to RAND_add followed by a call to RAND_bytes The core part of the driver is shown in Figure 4(a) A minor complication arises due to the fact that the OpenSSL PRNG self-seeds, ie|,Non-data,80
|, automatically incorporates entropy from several sources beyond what is supplied by the driver: (i) entropy collected by an OS-specific routine (RAND_poll) added on first call to RAND_bytes, (ii) PID, time of day, and hardware RNG entropy (if available) added at every call to RAND_bytes, and (iii) the content of the (potentially uninitialized) output buffer supplied to RAND_bytes We choose to ignore these auxiliary sources, as they offer little conceptual added value from the analysis perspective Technically, we set corresponding compilation flags (PURIFY, GETPID_IS_MEANINGLESS) and supply empty implementations for RAND_poll and time Alternatively, it is trivial to include the output of relevant functions and content of buffers as an extra part of the conceptual seed in an extended scenario|,Non-data,80
| 63 Pool Stirring After self-seeding, but before generating first output, the OpenSSL PRNG “stirs” state During the stirring process, RAND_add is called with a constant 20-byte input (literally 20 dot characters) for a total of at least 1023 bytes The 684= = 0; 0; 1 long m d _ c o u n t _ 0 2 long m d _ c o u n t _ 1 3 char state [1023] = {0}; = {0}; 4 char md [20] 5 int s t a t e _ i n d e x = 6 int s t i r r e d _ p o o l = 7 8 void R A N D _ a d d ( const void * buf , int num ) { 9 char l o c a l _ m d [] = copyOf ( md ) ; 0; 0; for ( int i = 0; i < num ; i += 20) { l o c a l _ m d = sha1 ( l o c a l _ m d (cid:124) state [ s t a t e _ i n d e x |,Non-data,80
 s t a t e _ i n d e x +20 >] (cid:124) buf [ i  i +20 <] (cid:124) m d _ c o u n t _ 0 (cid:124) m d _ c o u n t _ 1 ) ; m d _ c o u n t _ 1 ++; state [ s t a t e _ i n d e x ,Non-data,80
| s t a t e _ i n d e x +20 >] ^= l o c a l _ m d ; s t a t e _ i n d e x = ( s t a t e _ i n d e x + 20) % 1023; } md ^= l o c a l _ m d ; 20 21 } 22 23 void R A N D _ b y t e s ( const void * buf , int num ) { 24 if (! s t i r r e d _ p o o l ++) s t i r _ p o o l () ; char l o c a l _ m d [] = copyOf ( md ) ; m d _ c o u n t _ 0 ++; int i = 0; while ( num > 0) { 10 11 12 13 14 15 16 17 18 19 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 } l o c a l _ m d = sha1 ( l o c a l _ m d (cid:124) m d _ c o u n t _ 0 (cid:124) m d _ c o u n t _ 1 (cid:124) state [ s t a t e _ i n d e x  s t a t e _ i n d e x +10 >] ) ; state [ s t a t e _ i n d e x |,Non-data,80
 s t a t e _ i n d e x +10 >] ^= l o c a l _ m d [ 0   1 0 ] ; buf [ i ,Non-data,80
 i +10 <] = l o c a l _ m d [ 1 0   2 0 ] ; s t a t e _ i n d e x = ( s t a t e _ i n d e x + 10) % 1023; num -= 10; i += 10; } md = sha1 ( m d _ c o u n t _ 0 (cid:124) m d _ c o u n t _ 1 (cid:124) l o c a l _ m d (cid:124) md ) ; Notation: • We assume that every array has an associated implicit length,Non-data,80
 • buf[ab] denotes the sub-array of buf starting with a and ending with b (exclusive) • Array actions such as assignments and XORs are to be understood component-wise,Non-data,80
| If the right-hand side of an assignment denotes more locations than the left- hand side (Line 33), the superflous locations are ig- nored • buf[ab>] treats as cyclic amounts b<=len(buf), buf[a|,Non-data,80
len(buf)]∪buf[0b-len(buf)] otherwise,Non-data,80
| buf[ab], buf to if and and ie|,Non-data,80
|, it is equivalent to buf[amin(b,len(buf))] • buf[a|,Non-data,80
|b<] ignores accesses past the right array bound, • sha1(a (cid:124) b (cid:124) c) denotes the hash of the concatenation of a, b and c Figure 5: Simplified pseudocode of the OpenSSL PRNG purpose is to better distribute the entropy throughout the pool via the chunk chaining mechanism At the same time, stirring, obviously, does not increase the entropy content of the pool|,Non-data,80
| We abstract from pool stirring in the analysis scenario It is a small and relatively simple piece of code: a single loop repeatedly calling RAND_add At the same time, stir- ring imposes a prohibitively high computational tax on the analysis Instead, we assume that we are already sufficiently exercising the RAND_add functionality through the analysis driver|,Non-data,80
| Technically, we disable stirring by instructing the model checker to ignore the appropriate loop 64 Idealized Cryptographic Functionality Abstract description OpenSSL PRNG uses three static occurrences of a cryp- tographic primitive (SHA-1 hash per default)|,Non-data,80
| Each occur- rence can be invoked several times depending on the pa- rameters M, N  As described in Section 41, we replace the primitives by idealizations The first occurrence transfers the seed entropy into the pool and is invoked in RAND_add as: h1 ( l o c a l _ m d (cid:124) state [ s t a t e _ i n d e x |,Non-data,80
 s t a t e _ i n d e x +20 >] (cid:124) buf [ i  i +20 <] (cid:124) m d _ c o u n t _ 0 (cid:124) m d _ c o u n t _ 1 ) We idealize it as an injection from buf[i,Non-data,80
|i+20<] (third ar- gument), based both on its name and it carrying the seed material, as shown by the counterexample visualizer The second occurrence is for output generation and in- voked in RAND_bytes: h2 ( l o c a l _ m d (cid:124) m d _ c o u n t _ 0 (cid:124) m d _ c o u n t _ 1 (cid:124) state [ s t a t e _ i n d e x |,Non-data,80
| s t a t e _ i n d e x +10 >]) We discuss this occurrence in detail in Section 65 The third occurrence updates the global state upon com- pletion of RAND_bytes: h3 ( m d _ c o u n t _ 0 (cid:124) m d _ c o u n t _ 1 (cid:124) l o c a l _ m d (cid:124) md ) We idealize it as an injection from local_md, though it is only relevant, if one calls RAND_bytes more than once As the example shows, there is only a very limited choice of argument for the injection, and roughly half of them—the counters—can be eliminated outright|,Non-data,80
| For each invocation of a cryptographic primitive, Entroposcope’s counterex- ample visualizer shows the exact callsite and the arguments supplied to the primitive, its output, which argument po- tentially contains or is influenced by the seed material, and whether each invocation and the overall PRNG are currently injective This feedback effectively assists the user in synthe- sizing the appropriate idealized functionality, ie, choosing the right j in (2)|,Non-data,80
| Implementation On the implementation level, the hash function is imple- mented by a stateful object with a stream-based interface The hash object is initialized by calling MD_Init, data to be hashed is supplied via MD_Update, and finally, the hash value is obtained by calling MD_Final Passing a concatenation of several buffers as an argument to the hash function, which we use in the pseudocode, is implemented by repeated calls to MD_Update|,Non-data,80
 We instrument each call with a counter that makes it possible to distinguish the three logical occurrences of the primitive shown above even though they use the same interface 68565 OpenSSL PRNG Loses Entropy in Out- put by Design Attempts to synthesize an idealization for the hash func- tion invocation h2 shown in Section 64 show a peculiar problem,Non-data,80
| Abstracting away from details, the entropy flow from the 20 byte of state to the 20 byte of PRNG’s output in RAND_bytes can be represented as follows (see Figure 5 for notation): o1 o2 = h2 ( (cid:124) state [ 0|,Non-data,80
10]) ; = h2 (,Non-data,80
 (cid:124) state [ 1 0   2 0 ] ) ; out = o1 [ 1 0  ,Non-data,80
 2 0 ] (cid:124) o2 [ 1 0   2 0 ] ; Note that the entropy in state[0,Non-data,80
|10] and state[1020] is “spread” over o1 and o2 respectively, yet o1[0|,Non-data,80
|10] and o2[010] are discarded Thus, some of the entropy con- tained in state will not make it to the output in this com- putation|,Non-data,80
| The fact that this particular construction is prominent and pervasive throughout the PRNG suggests that it is not an accident but a design decision by OpenSSL While we do not agree with it, we choose to mask the issue and concen- trate on uncovering other problems We achieve the masking by defining h2 as injective from its last argument, state[state_index|,Non-data,80
|state_index+10>], to the last 10 byte of its output (as opposed to an injection from a 20-byte argument to the full 20-byte output as demanded by (2)) It is clear that the actual SHA-1 implementation does not have this property, but the unsound idealization makes the code fragment above injective from state[020] to out, as the discarded parts of o1 and o2 no longer contain entropy|,Non-data,80
| This deviation from (2) silences the alarm 66 Entroposcope Detects the Debian Incident The Debian incident occurred when the Debian OpenSSL maintainer, as part of a campaign against memory-related errors, patched OpenSSL to be memory-safe As mentioned above, OpenSSL uses uninitialized memory as an additional source of entropy for its PRNG, but the patch not only elim- inated that but unintentionally disabled all PRNG seeding|,Non-data,80
| Or rather almost all, as the current PID was still used as a source of entropy in RAND_bytes to prevent stream duplica- tion upon forking (this part is elided from Figure 5) The incident corresponds to the Debian maintainer hav- ing deleted Line 14 from the source code in Figure 5 This way, the entropy-containing buf[i|,Non-data,80
|i+20<] is no longer read from in the rest of the PRNG Defining an idealized hash function that ensures injectivity of the PRNG (like the first one in Section 64) becomes impossible For any given ide- alization, Entroposcope produces a counterexample to in- jectivity (any two seeds will produce the same output after invoking SHA-1 in RAND_add), which immediately leads to the detection of the problem|,Non-data,80
| The counterexample visualizer helps pinpoint the exact place where the problem occurs Once the idealized functionality is developed, Entropo- scope can also be included as a completely automatic check into the continuous integration process in order to prevent introduction of bugs during maintenance 67 Entroposcope Detects A Previously Undis- covered Anomaly in the OpenSSL PRNG When we applied Entroposcope to the OpenSSL PRNG, the tool immediately detected a bug in a piece of code that manages entropy in the large pool|,Non-data,80
| The defect is close in spirit to the one in the Android PRNG Even though it turned out not exploitable in the larger context, the inci- dent demonstrates that Entroposcope is effective at doing what it is designed to The problem occurs in the code implementing the circular buffer state that is the large entropy pool The following code is encountered towards the end of RAND_bytes: for ( i =0; i < M D _ D I G E S T _ L E N G T H /2; i ++) { state [ st_idx ++]^= l o c a l _ m d [ i ]; if ( st_idx >= st_num ) st_idx =0; if ( i < j ) *( buf ++) = l o c a l _ m d [ i + M D _ D I G E S T _ L E N G T H /2]; } In the pseudocode implementation of Figure 5, this code corresponds to Lines 32–33|,Non-data,80
| After the analysis driver has seeded the PRNG with M bytes, we reach this code for the first time with st_idx = st_num = M  The former variable is the current index into state, while the latter is the number of bytes in the pool that are filled with seed data The code above is itself part of an outer loop It is easy to see that the sequence of values of st_idx at inner loop entry is M, 9, 19, 29, |,Non-data,80
|   The correct sequence, in contrast, would have been 0, 10, 20,  |,Non-data,80
|  or at least M, 10, 20,   |,Non-data,80
 (a special case in the code reading from the pool treats st_num as zero) The significance of these values is that they are used to decom- pose the pool into chunks supplying entropy in each cycle of output generation The code above forces chunks of the form state[0,Non-data,80
|10], state[919], state[19|,Non-data,80
|29],    While each chunk is 10 bytes long, the first two chunks overlap by one byte|,Non-data,80
| Accordingly, the last byte of entropy in the pool (byte number M − 1) is never used for output generation The code above thus suffers from a small but real entropy loss, though this defect is masked during normal operation The bug can only manifest itself when the entropy pool is not full (st_num < 1023) In practice, though, the pool is full, alone by virtue of self-seeding and pool stirring|,Non-data,80
| Under these circumstances, another instance of wrapping code comes into effect, correctly wrapping the index at the right bound of the state buffer The bug can be fixed—which Entroposcope verifies—by prepending the loop shown above with if ( st_idx >= st_num ) st_idx =0; From a larger perspective, though, an overhaul of the con- voluted pool index manipulation in the whole PRNG could be beneficial 68 Statistics Entroposcope completes a single analysis run of the OpenSSL PRNG for M = N = 40 in 33 seconds on a modest desktop computer (Intel Core i7 860 2|,Non-data,80
|80GHz CPU) Of this time, translation of the PRNG behavior into a formula by CBMC took 7 seconds, generating the relational proof obli- gation 16 seconds, SAT solving 7 seconds, and generation of a counterexample from a satisfying assignment 3 seconds The size of the formula supplied to the SAT solver was 191 megabytes in DIMACS format OpenSSL is the largest and most complex PRNG we considered|,Non-data,80
| 69 Entroposcope Detects a Previously Undis- covered Entropy Loss in Libgcrypt PRNG For reasons of space, we can only superficially describe the problem here; details can be found in the extended version of the paper [11] 686The Libgcrypt PRNG describes itself as modeled after the one in [13] Its critical function mix_pool perturbs the state of the generator by repeatedly hashing overlapping re- gions of the entropy pool back into the pool|,Non-data,80
| The Libgcrypt implementation deviates from [13] in several ways In par- ticular, the region of the pool supplied to the hash function in Libgcrypt is not contiguous but contains a 20-byte “hole” The hole has the consequence that mixing a full pool reduces its entropy by at least 20 bytes Other deviations from [13] make the flow of entropy difficult to understand|,Non-data,80
 The prob- lem was fixed by the Libgcrypt developer after we reported it 7 A MINI-MUSEUM OF ENTROPY LOSS Entropy loss is not limited to (cryptographic) PRNGs All entropy-processing applications are susceptible,Non-data,80
| To demon- strate the importance of the concept, we briefly discuss three instances taken from different application domains While Entroposcope detects injectivity failures in all of these cases, we are not claiming that it is the best means to deal with the problem In scenarios like the third one (Linux kernel), the routine use of the tool, on the other hand, is probably advisable 7|,Non-data,80
|1 Debit Card PINs A requirement of the early eurocheque debit card system (“EC-Karte” in Germany) was that an ATM can check the card PIN offline To this end, the PIN was derived by en- crypting and transforming the public data stored on the card As the source of entropy the banks chose four hex digits of the ciphertext To obtain a decimal PIN, the hex digits A − F were replaced by 0 − 5 correspondingly|,Non-data,80
| In the final step, any occurrence of an initial zero was replaced by one, as the banks deemed a PIN beginning with a zero confusing for the customer This decimalization produced a skewed PIN distribution, with small digits more common than large digits Amplified by other features of the cards, the entropy loss resulted in four-digit PINs that were easier to guess than a uniformly distributed three-digit PIN [21] The problem was solved when offline PIN checking was re- tired and online checking became mandatory|,Non-data,80
| 72 Online Poker Card Deck Shuffling ASF Software Inc was one of the first online poker soft- ware providers Since cheating by the operator is a concern in online gambling, the company published its deck shuffling source code with the intent to increase client confidence in its software|,Non-data,80
| The analysis of the software reported in [2] has shown that it fails on all three security concerns Concern 1 was violated due to seeding the PRNG with current time, which was not only limited in range to 32 bits (a shuffled deck of cards contains nearly 226 bits of entropy) but also roughly known to the attacker The software furthermore also failed Concern 2 The shuffling process produced a skewed dis- tribution of decks containing less entropy than a properly shuffled deck or the PRNG output used to control the shuf- fle|,Non-data,80
 73 Linux ASLR Vulnerability Address space layout randomization (ASLR) is a popu- lar OS mechanism to mitigate buffer overflow attacks An entropy loss in the Linux kernel prior to version 319-rc3 reduces the effectiveness of the stack randomization by a factor of four,Non-data,80
|8 In the following code (assuming x86 64 architecture), the entropy source are the lowest 22 bits (STACK_RND_MASK=0x7ff) of the value obtained from get_random_int() (Line 7) In Line 8, the result is shifted left by PAGE_SHIFT = 12 bits, causing an unsigned overflow of the 32-bit random_variable 22 + 12 − 32 = 2 bits of entropy inadvertently never reach the return value of the function The solution is to declare random_variable as a 64-bit integer, as was intended|,Non-data,80
| 1 static u n s i g n e d long r a n d o m i z e _ s t a c k _ t o p ( u n s i g n e d long s t a c k _ t o p ) 2 { 3 4 5 6 7 8 9 u n s i g n e d int r a n d o m _ v a r i a b l e = 0; if (( current - > flags & P F _ R A N D O M I Z E ) && !( current - > p e r s o n a l i t y & A D D R _ N O _ R A N D O M I Z E ) ) { r a n d o m _ v a r i a b l e = g e t _ r a n d o m _ i n t () & S T A C K _ R N D _ M A S K ; r a n d o m _ v a r i a b l e < <= P A G E _ S H I F T ; } return P A G E _ A L I G N ( s t a c k _ t o p ) + r a n d o m _ v a r i a b l e ; return P A G E _ A L I G N ( s t a c k _ t o p ) - r a n d o m _ v a r i a b l e ; 10 # ifdef C O N F I G _ S T A C K _ G R O W S U P 11 12 # else 13 14 # endif 15 } Another entropy loss in the ASLR implementation on Linux has also been reported9 8 RELATED WORK AND ALTERNATIVES Previous own work This paper builds upon insights collected during the pilot study [10], where we proved correctness of the (fixed) An- droid PRNG in an interactive theorem prover|,Non-data,80
| The current paper significantly extends and improves this work, both in the information-theoretical development and in practicality The fact that proof construction previously took hours and required substantial user interaction motivated us to re- design the approach, changing the underlying program ver- ification architecture and the idealization of cryptographic primitives The result is a vastly improved pragmatics, with drastically reduced need for user interaction, counterexam- ples to PRNG correctness, and turnaround times in the mag- nitude of seconds rather than hours Functional verification and testing|,Non-data,80
| Of course, it is possible to state and verify a functional specification of the PRNG implementation with existing ver- ification technology However, since PRNG output lacks in- trinsic meaning, such a specification would have to closely mimic the implementation and thus be complex and tedious to write It would be difficult to understand it and ascer- tain its adequacy; neither would it be possible to reuse it for another PRNG The information flow specification (1), on the other hand, directly expresses the desired property, is compact and easy to understand, and is nearly independent of the PRNG implementation in question|,Non-data,80
| Functional testing is rare for similar reasons The only test suite containing reference seeds and corresponding out- 8H Marco, CVE-2015-1593, http://hmarcoorg/bugs/linux- ASLR-integer-overflow|,Non-data,80
|html 9http://hmarcoorg/bugs/linux-ASLR-reducing-mmap-by- halfhtml 687puts we are aware of is part of the NIST SP 800-90 standard for PRNGs implementing it Note that such a suite essen- tially constitutes a regression test, i|,Non-data,80
|e, it only assures that all implementations of the standard perform in the same way Unit testing of PRNGs is often impeded by the lack of modularity in implementations Statistical testing|,Non-data,80
| Several statistical test suites exist for assessing the qual- ity of random numbers Among the most popular are DIE- HARD with its open source counterpart DIEHARDER and the NIST SP800-22 test suite The suites scan a stream of pseudo-random numbers for certain predefined distribution anomalies At the same time, we are not aware of recommen- dations on how the stream is to be produced|,Non-data,80
| In practice, it appears customary to derive the stream from a single seed The tests are repeated multiple times (with different seeds) to increase the degree of confidence but the results between individual runs are not cross-correlated Given the single-stream nature of the mentioned tests, it is reasonably safe to expect that any modern cryptographic PRNG will pass them, even in presence of entropy loss In [27], it was empirically demonstrated that the defective Debian OpenSSL PRNG passes the NIST SP800-22 test|,Non-data,80
 The first significant advance in quality assurance for cryp- tographic PRNGs has been made only recently in the form of LIL testing [27] The test estimates the distance in a particular statistical metric between a set of bit sequences generated by running a PRNG and a similarly-sized set of truly random sequences The authors show that the de- fective Debian OpenSSL PRNG is associated with a signifi- cantly larger distance to uniform randomness than the intact PRNG when considering 1000 sequences of 2GB each The LIL test is agnostic of the exact way the sequences are generated,Non-data,80
| The advice given by the authors is to gen- erate them in a way reflecting the particular application of interest The advantage of such a test (as of testing in gen- eral) is that it can be made to reflect the actual deployment scenario, including the larger system, up to the hardware layer On the other hand, it requires insight into the ex- act planned PRNG usage pattern, as different patterns can produce significantly different results For example, a single-threaded Debian OpenSSL PRNG client fails the LIL test as carried out in [27]|,Non-data,80
| The test was run in a simulated environment on a Windows sys- tem, where PIDs are recycled with a substantial probability Since the PID is the only source of entropy in the broken De- bian PRNG (in the single-threaded case), many generated sequences were identical The same test on an actual Debian system would have (as far as we understand) succeeded, as Linux only recycles PIDs after they wrap around Finally, testing cannot detect less severe (but still cryptography- affecting) instances of entropy loss where the probability of repeated streams is sufficiently low|,Non-data,80
| Information flow analyses Many information flow analyses have been developed— most of them with the use case of minimizing information flow Maximizing information flow, in contrast, plays a much less prominent role The first appearance we are aware of is as required information release in [6]|,Non-data,80
| The concept has been revisited in [24] for the purpose of optimizing secure multi-party computation protocols The latter work devel- ops tooling based on symbolic execution and SMT solving and is the one closest in spirit to ours A research branch measuring the amount of information flowing in programs (rather than checking absence or max- imality of flows) is Quantitative Information Flow analysis (QIF) Several methods and tools for QIF exist, including our own for C programs [19]|,Non-data,80
