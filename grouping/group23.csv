 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
|   , b(j)) ∈ Fτ k be the deviation in P and δ(j,i) b Pj’s input with an honest Pi Let δ(i) a = δ(i) as a length τ vector b = with components in Fk (similarly to th, qh in the protocol)|,Non-data,60
| Now by analyzing the possible adversarial deviations and summing up shares, we can see that the h-th component of c (for h ∈ [τ ]), at the end of the Multiply stage, is b(i) · δ(i) c[h] =a[h] ·b+ {z X (cid:3)(a(i)[h])B, δ(i) || , and consider δ(i) b b [h](cid:4) } X || P {z a [h] δ(j,i) δ(j,i)  (2) j∈A j∈A i(cid:5)∈A i(cid:5)∈A } + a b =eah =ebh Intuitively, it is easy to see that any non-zero δ(i) a errors will be blown up by the random honest party’s share b(i), so should result in an incorrect triple with high probability On the other hand, the δ(i) errors can be chosen so that eah b only depends on single bits of the shares a(i) This means that a corrupt party can attempt to guess a few bits (or linear combinations of bits) of a(i)|,Non-data,60
| If this guess is incorrect then the resulting triple should be incorrect; however, if all guesses succeed then the triple is correct and the sacrifice step will pass, whilst the adversary learns the bits that were guessed This potential leakage (or selective failure attack ) is mit- igated by the Combine stage The intuition here is that, to be able to guess a single bit of the final shares a(i), ˆa(i), the adversary must have guessed many bits from the input vector a(i), which is very unlikely to happen To prove this 838intuition, we analyze the distribution of the honest party’s output shares using the Leftover Hash Lemma, and show that if τ is large enough, the combined output is statisti- cally close to uniform to the adversary|,Non-data,60
| opens ρ = s · a − ˆa and then checks that Regarding the Sacrifice stage, note that the check first s · c − ˆc − b · ρ = 0 which is equivalent to s · (c − a · b) = ˆc − ˆa · b If the triples are incorrect then this will only pass with probability 1/||F||, since s is random and unknown when the triples are authen- ticated The following results (proven in the full version [27]) state the security of our protocol The first requires the combining parameter set to τ = 4, to obtain a a general result for any k-bit field, whilst the second (which is evident from the proof of the theorem) shows that for k-bit fields and k/2-bit statistical security, τ = 3 suffices|,Non-data,60
| Theorem 3 If τ = 4 then the protocol ΠTriple (Protocol 4) securely implements FTriple in the (FROT,F(cid:2)·(cid:3))-hybrid model with statistical security parameter k Corollary 1 If τ = 3 then ΠTriple securely implements FTriple in the (FROT,F(cid:2)·(cid:3))-hybrid model with statistical secu- rity parameter k/2|,Non-data,60
| 6 PERFORMANCE We first analyse the complexity of our preprocessing pro- tocol, and then describe our implementation and experi- ments 61 Complexity We measure the communication complexity of our pro- tocol in terms of the total amount of data sent across the network|,Non-data,60
| Note that the number of rounds of communication is constant ((cid:16) 100), so is unlikely to heavily impact per- formance when generating large amounts of preprocessing data Throughout this section, we exclude the cost of the λ base OTs (between every pair of parties) in the initialization stages, as this is a one-time setup cost that takes less than a second using [12] Input tuple generation The main cost of authenticating one party’s field element in a k-bit field with Π(cid:2)·(cid:3) is the n − 1 calls to ΠCOPEe, each of which sends k2 bits, plus sending n − 1 shares of k bits, for a total of (n− 1)(k2 + k) bits|,Non-data,60
| We ignore the cost of authen- ticating one extra value and performing the MAC check, as this is amortized away when creating a large batch of input tuples Triple generation To generate a triple, each pair of parties makes τ k calls to FROT, followed by sending a further τ k2 bits in step (c) and then 5 calls to ΠCOPEe for authentication (ignoring FRand and sending the input shares as these are negligible) Since each call to FROT requires communicating λ bits, and ΠCOPEe requires k2 bits, this gives a total of n(n−1)(τ λk+(τ +5)k2) bits sent across the network|,Non-data,60
| Table 2 shows these complexities for a few choices of field size, with λ = 128 and τ chosen to achieve at least 64 bit statistical security We observe that as k increases, the cost of inputs scales almost exactly quadratically For triples, k = 64 is slightly less efficient as we require τ = 4 (instead of 3), whilst for larger k the cost reduces slightly as k becomes much larger than λ Note also that the cost of an input is much lower than a triple, as the input protocol does not require any of the expensive sacrificing or combining that we use to obtain active security with triples|,Non-data,60
| This is in contrast to the SPDZ protocol [15, 17], where creating input tuples requires complex zero-knowledge or cut-and-choose techniques Comparison with a passive protocol A passively secure (or semi-honest) version of our proto- col can be constructed by setting τ = 1 and removing the authentication step, saving 5 calls to ΠCOPEe for every pair of parties Note that for two parties this is essentially the same as the protocol in ABY [18]|,Non-data,60
| The communication cost of a single triple is then n(n − 1)(λk + k2) bits For triples where k ≥ 128, and 64-bit statistical security, the actively secure protocol achieves τ = 3, so is just 55 times the cost of the passive variant Field bit length 64 128 256 512 Input cost (kbit) 4|,Non-data,60
16(n − 1) 1651(n − 1) 6579(n − 1) 26266(n − 1) Triple cost (kbit) 53,Non-data,60
|25n(n − 1) 18022n(n − 1) 62259n(n − 1) 229376n(n − 1) Table 2: Communication cost of our protocols for various field sizes, with n parties|,Non-data,60
| 62 Implementation As part of our implementation, we have used the opti- mizations described below The first two apply to the OT extension by Keller et al [26]|,Non-data,60
 Bit matrix transposition Asharov et al [2] mention the bit matrix transposition as the most expensive part of the computation for their OT extension They propose Eklundh’s algorithm to reduce the number of cache misses,Non-data,60
| Instead of transposing a matrix bit by bit, the matrix is transposed with respect to increasingly small blocks while leaving the blocks internally intact Keller et al also use this algorithm However, for security parameter λ, the OT extension re- quires the transposition of a n × λ-matrix|,Non-data,60
| We store this matrix as list of λ × λ-blocks, and thus, we only have to transpose those blocks For λ = 128, one such block is 2 KiB, which easily fits into the L1 cache of most modern processors Furthermore, we use the PMOVMSKB instruction from SSE2 It outputs a byte consisting of the most significant bits of 16 bytes in a 128-bit register|,Non-data,60
| Together with a left shift (PSLLQ), this allows a 16 × 8-matrix to be trans- posed [33] with only 24 instructions (eight of PMOVSKB, PSLLQ, and MOV each) Pseudorandom generator and hashing Keller et al [26] used AES-128 in counter mode to imple- ment the PRG needed for the OT extension|,Non-data,60
| This allows to 839use the AES-NI extension provided by modern processors We have also implemented the hash function using AES- 128 by means of the Matyas–Meyer–Oseas construction [32], which was proven secure by Black et al [7] This construc- tion uses the compression function hi = Eg(hi−1)(mi) ⊕ mi, where mi denotes the i-th message block, hi is the state after the i-th compression, and g denotes a conversion func- tion|,Non-data,60
| In our case, the input is only one block long (as many bits as the computational security parameter of the OT ex- tension), and g is the identity This gives a hash function H(m) =E IV (m) ⊕ m for some initialization vector IV , which allows to precompute the key schedule This pre- computation in turn allows to easily take advantage of the pipelining capabilities of AES-NI in modern Intel proces- sors: While the latency of the AESENC instruction is seven clock cycles, the throughput is one per clock cycle [22] This means that the processor is capable of computing seven en- cryptions in parallel|,Non-data,60
|  Elements of both F Inner product computation Both ΠCOPEe and ΠTriple involve the computation of (cid:3)g, x(cid:4) for x ∈ Flog ||F|| 2k and Fp are commonly represented as elements of larger rings (F2[X] and Z, respec- tively), and some operations involves a modular reduction (modulo an irreducible polynomial or p) When computing, we defer this reduction until after computing the sum|,Non-data,60
| Fur- thermore, we use the mpn_* functions of MPIR [40] for the large integer operations for Fp For F 2k on the other hand, the computation before the modular reduction is straight- forward because addition in F2[X] corresponds to XOR Multithreading In order to make optimal use of resources, we have or- ganized the triple generation as follows: There are several threads independently generating triples, and every such thread controls n − 1 threads for the OTs with the n − 1 other players|,Non-data,60
| Operations independent of OT instances, such as amplification and sacrificing, are performed by the triple generation threads We found that performance is optimal if the number of generator threads is much larger than the number of processor cores This is an indication that the communication is the main bottleneck 6|,Non-data,60
|3 Experiments We have tested our implementation for up to five parties on off-the-shelf machines (eight-core i7 31 GHz CPU, 32 GB RAM) in a local network Fig 4 shows our results|,Non-data,60
| We could generate up to 4800 and 1000 F2128 triples per second with two and five parties, respectively, using 100 threads For Fp with p a 128-bit prime, the figures are the same These figures come close to the maximum possible throughput of the correlation steps, which is 5500 and 1400, respectively The maximum figures are computed from the analysis above, with τ = 3 and k = λ = 128|,Non-data,60
| Assuming a 1 Gbit/s link per party and unlimited routing capacity gives the desired result Using just a single thread, we can produce 2000 triples/s with two parties, which is still over 72 times faster than the single-threaded implementation of SPDZ [15] By increasing the bandwidth to 2 Gbit/s, we could in- crease the throughput to 9500 and 1600 triples per seconds for two and five parties, respectively This confirms the ob- servation that the communication is the main bottleneck|,Non-data,60
| F F 2k , 1 thread 2k , 10 threads 2k , 100 threads F Fp, 100 threads ) s / ( t u p h g u o r h T 5,000 4,000 3,000 2,000 1,000 0 2 3 4 5 Number of parties Figure 4: Triple generation throughput for 128-bit fields 12 1 08 0|,Non-data,60
|6 04 02 0 ) s / ( t u p h g u o r h T ·104 11,000 9,515 5,500 4,828 241 275 50Mbps WAN 1Gbps LAN 2Gbps LAN Actual Max possible Figure 5: Throughput and maximum possible throughput for different networks with two parties Fig|,Non-data,60
 5 shows the throughput for two parties in various net- work environments The WAN environment was simulated over a LAN by restricting bandwidth to 50 Mbit/s and a round-trip latency of 100 ms 63,Non-data,60
|1 Vickrey Auction To highlight the practicality of our protocol, we have im- plemented the Vickrey second-price auction Figure 6 shows the results for the offline and online phase run between two parties on a local network This clearly illustrates the 200- fold performance improvement of our protocol, compared with (actively secure) SPDZ Now the preprocessing phase in within 2–3 orders of magnitude of the online phase|,Non-data,60
| 840s d n o c e s n i e m T i 104 102 100 −2 10 100 101 102 103 Number of bids SPDZ offline phase MASCOT offline phase Online phase [8] Bogdanov, D, J ̃oemets, M, Siim, S, and Vaht, M|,Non-data,60
| How the Estonian tax and customs board evaluated a tax fraud detection system based on secure multi-party computation In Financial Cryptography and Data Security - 19th International Conference, FC 2015, Revised Selected Papers (2015), pp 227–234 [9] Bogdanov, D|,Non-data,60
|, Kamm, L, Kubo, B, Rebane, R, Sokk, V|,Non-data,60
|, and Talviste, R Students and taxes: a privacy-preserving social study using secure computation IACR Cryptology ePrint Archive (2015) [10] Burra, S|,Non-data,60
| S, Larraia, E, Nielsen, J B|,Non-data,60
|, Nordholt, P S, Orlandi, C, Orsini, E|,Non-data,60
|, Scholl, P, and Smart, N P High performance multi-party computation for binary circuits based on oblivious transfer|,Non-data,60
| Cryptology ePrint Archive, Report 2015/472, 2015 http://eprintiacrorg/|,Non-data,60
| [11] Canetti, R Universally composable security: A new paradigm for cryptographic protocols In 42nd Annual Symposium on Foundations of Computer Science, FOCS (2001), pp 136–145|,Non-data,60
| Figure 6: Vickrey auction run by two parties [12] Chou, T, and Orlandi, C The simplest protocol Acknowledgements We thank Claudio Orlandi and the anonymous reviewers for valuable feedback that helped to improve the presentation|,Non-data,60
|ABSTRACT A key requirement for most security solutions is to provide secure cryptographic key storage in a way that will easily scale in the age of the Internet of Things In this paper, we focus on providing such a solution based on Physical Unclon- able Functions (PUFs) To this end, we focus on microelec- tromechanical systems (MEMS)-based gyroscopes and show via wafer-level measurements and simulations, that it is fea- sible to use the physical and electrical properties of these sensors for cryptographic key generation After identifying the most promising features, we propose a novel quantiza- tion scheme to extract bit strings from the MEMS analog measurements|,Non-data,62
| We provide upper and lower bounds for the minimum entropy of the derived bit strings and fully analyze the intra- and inter-class distributions across the operation range of the MEMS device We complement these mea- surements via Monte-Carlo simulations based on the distri- butions of the parameters measured on actual devices We also propose and evaluate a complete cryptographic key gen- eration chain based on fuzzy extractors We derive a full en- tropy 128-bit key using the obtained min-entropy estimates, requiring 1219 bits of helper data with an (authentication) failure probability of 4 · 10−7|,Non-data,62
| In addition, we propose a dedicated MEMS-PUF design, which is superior to our mea- sured sensor, in terms of chip area, quality and quantity of key seed features Keywords Hardware security; IoT security; Mobile security and privacy 1 INTRODUCTION In 1991, Mark Weisser [1] set out the vision of ubiqui- tous computation, which promised to make our interaction with things to be seemless Today, this vision has already started to become reality through modern technologies that Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita- tion on the first page|,Non-data,62
| Copyrights for components of this work owned by others than ACM must be honored Abstracting with credit is permitted To copy otherwise, or re- publish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acm|,Non-data,62
|org CCS’16, October 24-28, 2016, Vienna, Austria c(cid:13) 2016 ACM ISBN 978-1-4503-4139-4/16/10 |,Non-data,62
  $1500 DOI: http://dxdoi,Non-data,62
|org/101145/29767492978295 allow for electronic systems to be embedded practically ev- erywhere with applications ranging from smart homes, to connected vehicles and smart factories More specifically, ubiquitous computation has been made tangible in the con- cept of the Internet of Things (IoT), which by some esti- mates is expected to surpass 50 billion devices by 2020 [2]|,Non-data,62
| Regardless of the exact numbers, it is widely acknowledged that to make the IoT a success the security of this super large distributed systems will have to be guaranteed and the privacy of the collected data protected The Internet of Things, made possible through the wide deployment of embedded devices, differs significantly from ”classical” systems, such as desktop (networked) PCs, in var- ious aspects, which include: severe computational, memory, and power constraints, lack of advanced user interfaces, an increased vulnerability with respect to physical or network attacks, and as mentioned previously, their tendency to col- lect potentially highly privacy sensitive data Until recently, there has been an inclination to assume the inability to pro- vide strong hardware security guarantees However, this is starting to change with new device architectures such as those presented in [3, 4, 5], which aim to provide more fun- damental security properties for embedded devices|,Non-data,62
| In this paper, we continued this line of work and we focus our at- tention on an even more constrained type of device, MEMS- based sensor devices, which are widely deployed today in smart phones, automotive applications (eg, crash detec- tion, airbag deployment), environmental condition assess- ment, pressure measurements, etc and for which security solutions have been until now overlooked|,Non-data,62
| As a starting point in the study security for MEMS sen- sors, we look at how to provide secure cryptographic key storage in such devices in a cheap and intrinsic manner, as keeping cryptographic keys secure is the basis for many higher level security mechanisms such as attestation, secure boot as well as any other cryptographic operation which might require a secret or private key (eg, encryption, sig- natures, message authentication generation, etc)|,Non-data,62
| In par- ticular, we look at the feasibility of creating a Physical Un- clonable Function based on the physical properties of MEMS devices themselves PUFs have received a lot of attention (see eg, [6, 7, 8, 9, 10]) as a technology for secure key stor- age|,Non-data,62
| One of PUF’s main advantages is that the device does not need to store secrets in non-volatile memory but rather it can generate the cryptographic key whenever it needs to 591process secrets and destroys it afterward, making the job of an attacker with physical access to the device more difficult1 While the possibility of deriving a fingerprint from MEMS- based devices has been explored in previous work[14], the feasibility of deriving a cryptographic key from MEMS char- acteristics is a more challenging undertaking and to the best of our knowledge, we are the first to propose such a design As with many PUFs, a MEMS-based PUF has the following requirements: the cryptographic key should be unique per device (similar to a fingerprint), (ii) the cryptographic key should be reproducible across the whole range of environ- mental conditions for which the device is designed, (iii) the cryptographic key should be hard to replicate even for the manufacturer of the device, (iv) the PUF properties should be hard to model and therefore a mathematical model that predicts the PUF responses should be infeasible to obtain, and (v) it is desirable that the particular PUF has tamper resistance or tamper evidence properties In this paper2, we show that MEMS gyroscopes can be used to this end and, moreover, we show via experimental evidence on actual de- vices and simulations that requirements (i)-(iv) are met by our design|,Non-data,62
| Furthermore, we present and simulate a fully functional MEMS device specifically designed for PUF ap- plications, which has smaller size than other gyroscopes and has more variation (allowing for the derivation of more full entropy bits) In short, our contributions are as follows: • Physical Modelling: In contrast to previous work, which use the response of MEMS accelerometers and derive signal processing features suitable for identifi- cation, we identify suitable properties (mechanical and electrical) of the MEMS gyroscopes and show that they can be used to derive a robust bit string suitable for cryptographic key generation, • Key Derivation: We propose a quantization method to derive binary keys from analog sensor data inspired by a method described by Chang et al [15] Then, we analyze via multiple methods the amount of en- tropy that such binary strings carry|,Non-data,62
| We also include min-entropy estimations, which are more conservative than state-of-the-art entropy estimations3 We pro- vide several helper data [16, 17] parameters for robust key extraction across a temperature range of 65 ◦C, with probabilities of failure less than 10−6 We also give a specific fuzzy extractor construction to create a uniformly distributed random 128-bit key • Uniqueness and Robustness: We analyze the intra- and inter-class distributions induced by our key deriva- tion procedure from 70 different physical MEMS sen- sors and verify the behavior of such distributions via Monte-Carlo simulations of the MEMS behavior using variability parameters measured on physical MEMS sensors|,Non-data,62
| This analysis includes the variability due to repeated measurements and environmental conditions, most prominantly, temperature 1The fact that memory is susceptible to invasive attacks has been demonstrated in [11, 12, 13] 2Full version of the paper: https://eprintiacr|,Non-data,62
|org/2016/261 3In the PUF literature, it is standard to use the Context Tree Weighing (CTW) compression algorithm to estimate entropy of the PUF responses We use CTW as an upper bound on the entropy of the MEMS-PUF responses but use the more conservative min-entropy estimations provided by the NIST tests for our final helper data sizes • Optimized MEMS for PUF Applications: We present a completely new MEMS design, which has been optimized to increase variability and thus, the ability to create unique/robust keys 11 Organization of the Paper We begin by providing basic background on MEMS tech- nology and explaining features of MEMS gyroscopes, their potential for PUFs and causes of variations in Section 2|,Non-data,62
| In Section 3, we show how a MEMS-PUF should be included in a package, to withstand probing attacks We then explain our requirements for robustness and uniqueness in Section 4, how we quantize the features, how our measurements are set up and the results for the most promising parameters From the learned insights, we then can simulate additional devices in Section 5 This allows to verify that the simulations are consistent with the measured data|,Non-data,62
| In Section 6, we provide upper and lower bounds for the min-entropy of the MEMS- PUF responses for both measured and simulated data In Section 7, we describe the last step in the key generation pro- cess, namely, information reconciliation via error correcting codes and randomness extraction Note that our construc- tions tend to require less public helper data (measured in bits) than recently published fuzzy extractor schemes, in spite of our constructions based on very conservative min- entropy estimations We propose a dedicated MEMS-PUF design in Section 8|,Non-data,62
| We conclude this article in Section 9 2 MEMS BACKGROUND MEMS sensors are silicon based devices which combine a microcontroller with a microelectromechanical structure used to measure a variety of different physical quantities ranging from acceleration and yaw rate to magnetic fields, pressure, humidity, etc In this work, we focus on MEMS gyroscopes which have a very complex structure providing a large number of mechanical as well as electrical properties|,Non-data,62
| MEMS gyroscopes are sensors for measuring the yaw rate and they typically consist of a combination of one or several oscillating spring-mass systems The detecting axis depends on the moving direction of an oscillating mass Hence, one oscillating spring-mass system typically exists for each detecting axis This means that the number of different spring-mass systems depends basically on the number of sensitive axis|,Non-data,62
| In this work, an experimen- tal 3-channel gyroscope design manufactured with standard MEMS fabrication processes was investigated For further background on gyroscopes and fabrication processes we refer the reader to [18, 19] 21 MEMS Parameters MEMS sensors offer many measurable mechanical as well as electrical parameters depending on the sensor type, which can be used to derive a suitable unique identifier and, after some processing, a secure cryptographic key|,Non-data,62
| In the case of MEMS gyroscopes, fundamental mechanical parameters include the different resonant frequencies of the microelec- tromechanical structure Because of the high complexity of the structure, a large number of frequency modes exist An- other interesting mechanical parameter are the quadrature signals that are a measure for the asymmetries of the sensor structure As the manufacturing process is subjected to vari- ations, the actual physical structures, i|,Non-data,62
|e, springs, masses 592and electrode gaps, differ slightly from the ideal case by dif- ferent types of asymmetries This results in a deflection of the moving directions and produces an error signal called the quadrature signal - which can be detected by electrodes in a capacitive manner Furthemore, an important feature are the quality factors|,Non-data,62
| However, we do not describe them in detail because they have not been proven to be suitable as PUF parameter in our evaluation Additionally, there are a lot of electrical parameters These are the capacitances and resistances that are induced between the different electrodes which are needed for driving and measuring the sensor 2|,Non-data,62
|2 Causes for Parameter Variability Although, it is difficult to determine all factors for the variability of the MEMS parameters, several of them are well-known and understood In what follows, we provide a short overview of these factors and explain their impact on parameter variation A main factor are the geometric dimensions (width and thickness of the structures) that vary in a small range caused by the nature of the etching process This includes a variation of the beam width of the springs which changes the spring rigidity|,Non-data,62
| This, in turn, leads to a shift of the resonant frequencies In addition, it affects the electrical parameters as well because it changes the gaps between the electrodes and the effective area of electrodes As mentioned previously, asymmetries cause slight vari- ations of the behavior from the ideal case generating the quadrature signal These asymmetries have four sources: • A difference of the side wall angles, causing a different deviation from the rectangular beam geometry of side walls that results in an out-of-plane force component|,Non-data,62
| • A local variation of the structure width that affects the • An imbalance of the inertial masses • The influence of mechanical stress caused by packag- ing, temperature and bending of the Printed Circuit Board (PCB) after soldering rigidities of the springs slightly different Note that MEMS sensors are actually designed and man- ufactured with the objective of minimal parameter varia- tions|,Non-data,62
| In principle, an amplification of the variation is easy to achieve and this is likely to result in an increase in the number of bits extracted from a particular parameter This could be used for the creation of a dedicated MEMS struc- ture to increase significantly the number of derivable bits 3 MEMS-BASED PUF MEMS sensors have an unique fingerprint based on in- herent variability in silicon manufacturing processes|,Non-data,62
| Since MEMS sensors are present in numerous applications, adding secure key storage capabilities would provide an additional value, making them enhanced sensors This means there would be no need for additional devices solely for the pur- pose of key storage Furthermore, considering resilience to different kinds of attacks, MEMS-PUFs offer several advan- tages MEMS sensors are very complex entities with many very different features and the behavior is hard to model|,Non-data,62
| Considering invasive attacks, a read-out is expected to be difficult, or in some cases even infeasible The reason for this is that tampering with a MEMS or even with the mold pack- age changes the properties of the MEMS and thus the key, eg, by changing the stress conditions inserted by the pack- aging process or by changing the internal pressure|,Non-data,62
| Hence, Figure 1: Schematic composite of MEMS sensor and ASIC in a system in package (SIP) MEMS could provide a tamper-proof PUF without any over- head which was identified as a major future research topic in [20] Fig 1 shows schematically an usual example for a system in package with a MEMS sensor and an ASIC that are en- cased by a mold package|,Non-data,62
| MEMS and ASIC are placed on the same level, connected by wire bonds and placed on a PCB substrate with a Ball Grid Array for the electrical con- tacts to the environment Alternatively, MEMS and ASIC could also be stacked vertically and connected by through- silicon vias [19] This would make it infeasible to tap the wires between the MEMS and the ASIC For high secu- rity applications, it is recommended to carry out all security relevant operations for authentication or encryption on the ASIC|,Non-data,62
| In this case, the secret key would never leave the package in order to make it infeasible for an attacker to get access to security-critical information On the basis of the above-mentioned assumptions, such a system would possess similar security properties as a hard- ware security module (HSM) [21] or a trusted platform mod- ule (TPM) [22] This could also be further enhanced by the development, eg|,Non-data,62
|, of specific package concepts, increasing system’s security Moreover, new MEMS concepts could be designed for the use as dedicated PUFs only 4 SUITABLE FEATURES In order to identify suitable features for the use as a PUF, we should identify the requirements that a feature has to fulfill|,Non-data,62
| These can be derived in principle from the PUF def- inition • Uniqueness Based on the used parameters, it must be possible to identify the device uniquely Measured variability of the used parameters has to be inherent in the system|,Non-data,62
| The particular value of a parameter must not be controllable even by the manufacturer in order for copying attacks to become infeasible • Robustness The parameters should be stable even when affected by different environmental conditions, ie|,Non-data,62
|, temperature, humidity, aging • High Bit Entropy In case of using several parame- ters to derive the final response, it is desirable that the correlation among the parameters be as small as possible4 This is important because, the stronger pa- rameters correlate, the less entropy they offer for the extracted cryptographic key|,Non-data,62
| 41 Quantization Scheme The generation of a binary key from the measured values requires a quantization procedure beforehand The general problem of converting such analog measured values into bi- nary strings is also known in the field of biometrics Thus, 4In the optimal case, the parameters should be independent of each other|,Non-data,62
| MEMSASICMoldPackage593Figure 2: Quantization scheme for one parameter a procedure is developed that is inspired by a method de- scribed by Chang et al [15] There, the authors proposed a procedure for cryptographic key generation from biometric features and verified it, as it applies to human face recogni- tion|,Non-data,62
| The modified procedure used in this work is explained below Fig 2 shows an example for the quantization scheme for a Gaussian distributed parameter The basic factors for this procedure are the mean value μ, the standard deviation σglobal of the global distribution of a parameter calculated from all devices and the local variation V (cid:48) which can be interpreted as the robustness of a parameter affected by temperature and measurement noise|,Non-data,62
| Ideally, the cumulative distribution function for a normal distribution with mean μ and deviation σglobal is given by Equation (1) The global distribution is divided into several ranges Ai with an equal probability of occurence until the whole distri- bution is covered with a very high probability (6− σ) Each range has a left bound Ai,l and a right bound Ai,r Initially, the width of the ranges A1 to the left and right of the global mean value μ are defined based on the value for V (cid:48)|,Non-data,62
| After- wards, additional ranges A2,    An are determined so that each range occurs with the same probability, Equation (2)|,Non-data,62
| (cid:90) x 1 σglobal √ 2π F (x) = dt F (Ai,r) − F (Ai,l) = F (Ai+1,r) − F (Ai+1,l) −∞ σglobal − 1 2 ( e t−μ )2 (1) (2) A bit combination is assigned to each range The number of bits that can be derived from a parameter in this way can be calculated by log2(2 × n) This procedure is carried out for all parameters and the key parts are concatenated to the cryptographic key seed 4|,Non-data,62
2 Experimental Setup We measured the sensors directly on the silicon wafer (wafer-level) with laboratory equipment using an electrical measurement method The mechanical parameters were de- termined in a way that is described comprehensively in [23] by measuring the ground current (flowing through the mov- able masses) using an impedance analyzer 4294A by Agilent Technologies The resistances and capacitances were mea- sured with the impedance analyzer as well We used the probe station PA 200 by S ̈uss Micro Tec which enables to measure a large number of sensors on wafer-level fully auto- mated and the setting of temperature by a heatable chuck,Non-data,62
| Furthermore, the test equipment consists of a multiplexer probe card for driving and measuring on the different elec- Figure 3: Percentage distribution of correlation co- effients ρ between the used parameters tordes For contacting the sensor pads, a device with several contact probes is mounted on the probe card The device under investigation was a 3-axis gyroscope ex- perimental design|,Non-data,62
| We measured all parameters that are mentioned in Section 21 for each channel As a result we had a large number of parameters for each of the 70 sensors under test For each sensor, we repeated the measurements at least 20 times at room temperature (RT) and at 85 ◦C to determine the repeatability of the measurements|,Non-data,62
| The mea- surements at 85 ◦C had as main aim to verify the robustness of the parameters at higher temperature 43 Parameter Measurement Results As a result of the repeated measurements and the temper- ature variation, we can describe the parameter robustness as a combination of a Gaussian distributed factor fnoise which is based on measurement noise and a temperature depen- dent shift factor fshif t Thus, the local variation V (cid:48) of a parameter can be estimated from a measured value V and this two factors in the following way: (cid:48) V (T ) = fnoiseV + fshif t(T ) (3) Hence, the maximum local variation V (cid:48) max occurs in case of the maximum temperature range (from RT to 85 ◦C) and an additive effect of the factors fnoise and fshif t|,Non-data,62
| Initially, we identify basic suitable parameters regarding the ratio τ of the maximum local variation V (cid:48) max to the global variation σglobal for each parameter The ratio τ = V (cid:48) max/σglobal should be significantly smaller than 1 and it determines the number of bits that can be derived from a parameter in a robust manner As mentioned above (Section 22), major influence factors on the parameter variability on different sensors are the vari- ation of the geometric dimensions|,Non-data,62
| Especially, the edge loss which depends essentially on the position of the sensor on the wafer plays a major role For this reason, some of the parameters are strongly correlated with this factor Because many measurement variables depend on them in a similar way, an appropriate measure to reduce this dependency is to calculate ratios Thus, other effects become more important such as small local differences on a sensor in the widths of the springs, for example|,Non-data,62
| Regarding the frequency modes, the use of ratios provides an additional advantage The frequency modes are shift- ing with temperature due to the temperature dependence of the Young’s modulus Thus, all frequency modes them- selves vary about temperature with an approximately con- 101100001000011010110111A1A1A2A2A3A3AnAn|,Non-data,62
,Non-data,62
global distributionofa parameter (global)6-sigma-6-sigma0 < ρ < 1418%14 < ρ < 2821%,Non-data,62
28 < ρ < 4214%42 < ρ < 5710%,Non-data,62
57 < ρ < 718%71 < ρ < 8510%,Non-data,62
85 < ρ < 119%594Table 1: Dependence of the number of derivable bits on the correlation upper limit ρmax ρmax bits 50 30 62 30 ,Non-data,62
|74 38 86 63 98 138 stant factor Hence, the the temperature influence can be significantly reduced by calculating ratios|,Non-data,62
| As a first result of the measurements, we can define the following parameters as potentially appropriate (in brackets is the number of different parameters of a particular type): • frequency modes (9), • capacitances (6), • quadrature signals (2) Whereby, the τ -values are in a range smaller than 01 for the ratios of frequency modes and the quadrature signals and they increase up to 057 for the ratios of capacitances that is mainly caused by their relatively low σglobal-values|,Non-data,62
| In terms of cryptographic key generation, the consider- ation of the correlation between the parameters is of fun- damental importance Especially due to the fact that we calculate all possible ratios of the frequency modes and the capacitances, there is some correlation between the param- eters Thus, we determine the correlations between all suit- able parameters The correlation coefficient RX,Y between two parameters X and Y with N measurement values is calculated by equa- (cid:18)Cov(X, X) Cov(X, Y ) (cid:19) tion (4), whereas C = Cov(Y, X) Cov(Y, Y ) is the co- variance matrix|,Non-data,62
| The covariance Cov(X, Y ) of X and Y is given by Equation (5) RX,Y = Cov(X, Y ) = CX,Y (cid:112)CX,X CY,Y N(cid:88) 1 N − 1 i=1 (Xi − μX )(Yi − μY ) (4) (5) Fig 3 shows the percentage distribution of correlation co- efficients ρ between the used parameters The stronger the parameters correlate, the less entropy they add to the key|,Non-data,62
 For this reason we define an upper limit ρmax for the cor- relation coefficients that we accept Parameters that are stronger correlated than this upper limit were rejected The choice of this limit affects the number of bits that can be derived in total Table 1 shows the dependence of the number of bits on ρmax,Non-data,62
| To analyze the effect of ρmax, we vary them in steps and estimate the entropy of the extracted keys by different methods (see Section 6) 5 SIMULATING PUF RESPONSES In order to generate an arbitrarily number of keys we make Monte-Carlo simulations Based on this, we are able to gen- erate keys from both different sensors and the key from a single sensor multiple times|,Non-data,62
| 51 PUF Responses from Different Sensors The simulation of PUF responses from different sensors allows us to test if the results of the entropy estimation are affected from the limited length of our measured bit streams For the simulation we assume that all of the parameters are Gaussian distributed Then, we have to consider the mean Table 2: BRRmax for different values of ρmax with the associated probabilities P (BRR > BRRmax)|,Non-data,62
 BRRmax BRRmax P P P ρmax BRRmax 50 62 74 ,Non-data,62
86 98 9 9 10 11 19 319e-6 126e-6 9,Non-data,62
05e-7 883e-7 344e-6 10 10 11 12 20 418e-7 1,Non-data,62
48e-7 118e-7 129e-7 939e-7 11 11 12 13 21 5,Non-data,62
02e-8 161e-8 142e-8 174e-8 2,Non-data,62
|45e-7 value μ and the standard deviation σglobal of the global dis- tribution of the parameters and the correlation matrix R that contains the correlation coefficients between all param- eters determined by our measurements The procedure is as follows: • generation of a normally distributed random number matrix Z with dimensions (number of keys i, number of parameters j) • Cholesky decomposition of the correlation matrix • multiplying matrix Z with G to receive the normally distributed random number matrix ZR considering the correlations of R ZR = ZG • generation of matrix PM C (i, j) with parameter values R = GGT PM C (i, j) = μ(j) + σglobal(j)ZR(i, j) 52 Maximal Bit Error Rate Estimation The estimation of a maximal Bit Error Rate (BRRmax) is of great significance The BRR denotes the difference be- tween two keys of the same device generated at different times or environmental conditions (e|,Non-data,62
|g, different tempera- tures) and it is also known as the intra distance which is a measure for the robustness of a key The BRR should be preferably 0, however, due to the noisy nature of physical measurements, this is not always achieved in practice Because of PUF variability across different environmental conditions and measuring inaccuracy, when a PUF is chal- lenged a noisy response is obtained|,Non-data,62
| In applications where the PUF response is used as a cryptographic key a noisy re- sponse is not acceptable To solve this problem, algorithms known as fuzzy extractors leverage non-secret helper data to work around the noisy nature of physical measurements typical of PUF applications (see Section 7) However, such a bit error correction results in an entropy loss and means a reduced key length The amount of reduction depends on the number of bit-flips that have to be corrected|,Non-data,62
| This has to be assessed by the BRRmax estimation In order to be able to estimate the robustness of a param- eter, we repeated our measurements multiple times and at 85 ◦C As we can describe the variability by Equation (3), we carry out a Monte-Carlo simulation to determine the prob- abilities for dedicated bit error rates Therefore, we create a normally distributed random number matrix Z with di- mensions (number of keys i, number of parameters j) to receive the local variation of the parameters for a device V (cid:48)(i, j)(T ) = fnoiseZ(j)V (i, j) + fshif t(j)(T )|,Non-data,62
 We estimate the BRRmax for different values of ρmax with the associated probabilities P (BRR > BRRmax) for a BRR above BRRmax The probabilities are calculated from a Poisson distribution fit (see Fig 4) The results are pre- sented in Table 2,Non-data,62
| The values of each row are based on 10,000 keys created by the Monte-Carlo simulation 595(a) ρmax = 62 (b) ρmax = |,Non-data,62
74 (c) ρmax = 86 Figure 4: Inter and intra Hamming distance distributions of measured data,Non-data,62
| 6 ENTROPY ESTIMATION An important aspect PUFs should show, besides robust- ness, is randomness This means that given all responses from all PUF devices, an attacker should have a negligible chance of estimating a future response of a PUF Also the bits in a response should be random and unpredictable, so that chances for two responses from two different PUFs to be ”close” are negligible small|,Non-data,62
| In order to assess the ran- domness of our PUF design, we use the following methods: Inter and Intra Hamming Distances To evaluate the potential of physical properties for PUF applications, the ability to uniquely identify each instance is essential This can be formally defined by the concept of inter and intra Hamming distances The inter distance HDinter depicts the difference between two keys of different sensors and it is a measure for key uniqueness|,Non-data,62
| The intra distance HDintra denotes the difference between two keys of the same sensor generated at different times or environ- mental conditions (eg, different temperatures) The intra distance is a measure for the robustness of a key and deter- mines directly the number of bit-flips|,Non-data,62
| An ideal PUF yields a HDintra = 0% and HDinter = 50% CTW Compression We try to compress our responses with CTW, a lossless compression algorithm [24, 25, 26] This method is optimal for stationary ergodic sources and gives an optimal compres- sion|,Non-data,62
| The resulting compression on bit strings is often used to estimate the entropy rate [27] The idea is that bit se- quences with full entropy cannot be compressed, meaning if a lossless compression is possible, then our responses do not have full entropy Thus, CTW gives an upper bound on entropy NIST Randomness Test|,Non-data,62
| We test the PUF responses with the NIST randomness test suite [28] Upon passing these tests this would indicate full entropy with high probability We configured each test in NIST SP800-22 in the same manner as in [29], meaning the significance level of each test is set to 1%, so that 99% of the test samples pass if the input was truly random Let the number of samples be n and the probability of passing each test is p, then the number of passing samples follow is then defined as p(cid:48) = p ± 3(cid:112)p(1 − p)/n|,Non-data,62
| Also the NIST a binomial distribution The value p(cid:48) of observed passings tests yield a P-value, generated by a χ2 test, which indicates randomness on an uniformly distributed assumption if the P-value is ≥ 00001 In order to pass a NIST test both conditions must be fulfilled – the proportion of passed tests should exceed the threshold defined above and the P-value should be above 0|,Non-data,62
|0001 NIST Min-Entropy Estimation Since CTW only gives us an upper bound on entropy and the NIST randomness test suite yield test results for full entropy or not, we try to estimate the min-entropy with tests mentioned in NIST’s special publication 800-90B [30], indicating a lower bound of entropy for our purposes Our source is not independent and identically distributed (non-IID), because we have seen so far in the previous sec- tions that there are correlations in the bit strings|,Non-data,62
| So, we tested our PUF responses with the following five estimations for non-IID sources [30] Each test yields an estimation on min-entropy and the overall estimated min-entropy is the minimum of these five values The tests are configured with a confidence level of 95% Collision Test: The collision test measures the mean time to the first collision in a dataset|,Non-data,62
| Based on these colli- sion times, the collision statistic tries to estimate the prob- ability of the most-likely state For biased noise sources toward an output or state the test will result in a low en- tropy estimate, say when there is a short mean time until a collision Longer mean times on collisions end up with in higher entropy estimates Partial Collection Test: The partial collection test computes the entropy of a dataset based on how many dis- tinct values in the output space are observed|,Non-data,62
| Low entropy estimates are output for datasets that contain a small num- ber of distinct symbols, and high entropy estimates are the output when the bit strings diversify quickly Markov Test: The Markov test consists of different Markov processes, from first-order up to nth-order In a first- order Markov process, the output state depends only on the current state and in an nth-order Markov process, the out- put state depends on the current and all previous n-1 states To detect dependencies, the test builds a Markov model to be used as a template for a given source|,Non-data,62
| The min-entropy estimates result from measuring the dependencies between 596Table 3: CTW compression rates on real sensor mea- surements for different upper correlation limits ρmax The data show an uncompressability, due to their small size and is mentioned for verification ρmax 50 |,Non-data,62
53 56 59 62 ,Non-data,62
65 68 71 74 ,Non-data,62
77 80 83 86 ,Non-data,62
89 92 95 98 (bytes) Size uncomp,Non-data,62
 to compressed 148 → 165 164 → 181 164 → 181 164 → 181 164 → 181 192 → 209 254 → 272 254 → 272 295 → 313 331 → 349 292 → 309 413 → 432 451 → 470 496 → 515 605 → 624 645 → 664 978 → 998 compression rate of measurements (bits/byte) compression rate random file (bits/byte) 825676 822561 822561 8,Non-data,62
22561 822561 820312 816929 8,Non-data,62
16929 815254 812991 813356 8,Non-data,62
12107 811973 810282 80843 8,Non-data,62
08062 805828 823649 818902 8,Non-data,62
18902 818902 818902 818229 8,Non-data,62
14173 814173 813559 812085 8,Non-data,62
13356 810412 810200 809476 8,Non-data,62
|08099 807752 805419 Compression Test: consecutive outputs from the noise source Thereby the es- timates are not based on an estimate of min-entropy per output, but on the entropy present in any chain of outputs|,Non-data,62
| The compression test estimates the entropy rate by compressing the input data set As compression method the Maurer Universal Statistic [31] is used It generates a dictionary of values, and then computes the average number of samples required to write an output based on the dictionary Frequency Test: The frequency statistic models the probability distribution of the given data set|,Non-data,62
 The entropy estimation is based on the occurrence of the most-likely sym- bol 61 Entropy Estimation of Measured Data We estimated the entropy of the responses with different upper correlation limits ρmax from the 70 measured sensors Inter and Intra Hamming Distances,Non-data,62
 Fig 4 shows the inter and intra Hamming distance dis- tributions of the measured data for three different values of ρmax The inter distance distribution is fitted by a normal distribution The mean of the fit is close to 50%,Non-data,62
| The intra distance distribution is based on the Monte Carlo simulation (10,000 runs) that we explained in Section 52 To be able to identify a sensor securely, it is important that the intra and inter distance distributions overlap just with negligible probability, which is the case here The best result do we receive for ρmax = |,Non-data,62
|86 CTW Compression The compression method was configured with a tree depth of 6 and we used a Krichevski-Trofimov estimator [24] It is important to note, that CTW compression does not work efficiently with the small sizes we give here as input, so all resulting compression rates are above 100%|,Non-data,62
| Still, would the bit strings have major statistical defects, then a compression would be possible even with these small input sizes For the purpose of verification we also tried to compress truly ran- dom bits with the same input sizes as our responses, yielding similar results Therefore, our bit strings show an uncom- pressability The results can be found in Table 3|,Non-data,62
| NIST Randomness Test We used the NIST randomness tests as described in Sec- tion 6 on our bit strings The minimum pass p(cid:48) rate for each statistical test is approximately 8, because we chose our number of samples n = 10 The results indicate a high entropy in our bit strings, since all tests up to ρmax = 0|,Non-data,62
|95 are passed Nevertheless, the tests are not meaningful be- cause the input size to these tests is very small NIST Min-Entropy Estimation Due to short overall bit strings we derived from our mea- surements, the NIST Min-Entropy Estimation gave no valid results|,Non-data,62
| So we omit these tests in this section 62 Entropy Estimation on Simulated PUF Re- sponses We estimated the entropy of bit strings, which offspring from our real sensor measurements However, the gener- ated bit strings are not long enough to generate meaningful results on entropy estimation|,Non-data,62
| Therefore, we repeat the en- tropy estimation on simulated data, too For a conservative estimate we choose the minimum of our estimated entropy value for further constructions We also validated our es- timations by concatenating and partly replacing simulated bits with real measurement bits, yielding the same results Inter and Intra Hamming Distances|,Non-data,62
| Fig 5 shows the inter and intra Hamming distance distri- butions of the simulated data (1,000 runs for both intra and inter distances) for the same values of ρmax The results are comparable to those from the measured data CTW Compression|,Non-data,62
| Again, we configured the compression method with a tree depth of 6 and we used a Krichevski-Trofimov estimator [24] The compression rate is given in bits per byte, meaning that bit strings with full entropy result in a compression rate of 8 bits/byte Our compression results indicate, that the quan- tized bit strings up a correlation upper limit ρmax of 071 have nearly full entropy|,Non-data,62
| With an increasing ρmax the com- pression rate drops CTW compression gives us an upper bound on entropy, meaning the entropy of our bit strings can be less, but not more This bound is also given in Fig 6|,Non-data,62
| NIST Randomness Test We used the NIST randomness tests as described in Sec- tion 6 on our simulated bit strings The minimum pass rate p(cid:48) for each statistical test is approximately 96, because we chose our number of samples n = 100 However, most of the NIST randomness tests failed, so we omit the actual results at this place|,Non-data,62
| We hypothesize the reasons are that our bit strings do not have full entropy, but nearly full entropy and that the random number generator used for generating the simulated bit strings is not truly random itself NIST Min-Entropy Estimation The five tests for a min-entropy estimation were config- ured to analyze 8-bit symbols, to have a comparable symbol size as the CTW compression Four tests gave invalid re- 597(a) ρmax = |,Non-data,62
62 (b) ρmax = 74 (c) ρmax = ,Non-data,62
|86 Figure 5: Inter and intra Hamming distance distributions of simulated data sults, so they are not included in Fig 6|,Non-data,62
| We also verified the estimated min-entropy values with a symbol size of 16 bits, where all results were valid, and the estimations were similar to the 8-bit symbol tests However, our results show that the Markov test always produces the lowest min-entropy es- timate, so the other tests do not come into account anyway The results for an estimated min-entropy give us an es- timated lower bound on entropy of our bit strings Fig|,Non-data,62
| 6 shows the upper and lower bounds on entropy depending on the chosen upper correlation limit ρmax as a combined result of CTW compression and min-entropy estimation 7 KEY DERIVATION Fuzzy Extractors [17] can be used to extract the same cryptographic keys from correlated measurements, ie|,Non-data,62
| noisy PUF measurements The keys are generated in an enroll- ment phase and, when the PUFs are in the field, can be re- constructed with a previously generated helper data P  The helper data leaks minimum information about the key [17], and therefore it can be stored in external memory on the PUF device itself or can be transmitted over the internet Our construction can be easily adapted to be secure against an active attacker on the helper data|,Non-data,62
| With a robust fuzzy extractor [32] we would introduce a message authentication code (MAC), which can be used to authenticate the helper data The correctness property of fuzzy extractors states that the construction outputs the exact same key if the distance between two measurements w and w(cid:48) is smaller than some error t, denoted as dis(w, w(cid:48)) ≤ t 71 Error Correction We choose the syndrome construction from [17] to recon- cile our measurements w and w(cid:48) and followed the idea of [33] to get parameters for our setting|,Non-data,62
| For example, the setting with ρmax = 086 we use a [n = 63, k = 10, t = 13]-BCH code, capable of correcting 13 errors in a 63-bit code word The entropy loss of this construction to an eavesdropper is at most n − k = 53 bits The extracted message has 10 bits after error correction|,Non-data,62
| We optimized the quantization process, so that the result- ing response w has at most t = 13 errors with a probability of 174 · 10−8, as given in Table 2 For a cryptographic 128- bit key, we need to combine the min-entropy results from Fig 6 and the chosen code, so that we need (cid:24) length key/min-entropy rate (cid:25) (cid:24) 128/0|,Non-data,62
|5725 (cid:25) = 23 = length message 10 PUF responses This means the overall PUF response, con- catenated from 23 sensors, has a length of 23 · 63 = 1449 bits and that our overall helper data P has a length of 23 · 53 = 1219 bits Putting it all together, we receive an overall authentication failure, due to decoding failure, with a probability of 1 − (1 − 174 · 10−8)23 = 4|,Non-data,62
|00 · 10−7 This is less than the common quality standard of at most one failure per one million uses Note that although our responses do not have full entropy, our parameters are an improvement (in terms of the number of bits required) compared to [33] while having roughly the same false rejection rate 7|,Non-data,62
|2 Randomness Extraction To meet the NIST requirements for extractors we would have needed to double the MEMS-PUFs to sample double the input entropy relative to the output So, to generate a strong key, we finally hash our corrected codeword along- side a public seed with a strong extractor The lightweight spongent hash function [34] seems to be a perfect candidate for a resource-constrained sensor device In particular, our construction uses spongent-128/256/128, which has full preimage and second-preimage security|,Non-data,62
| To carry on with the previous example, we input the corrected 1449-bit code word, containing 131 bits of entropy, to our extractor The public uniform random seed has 256 bits, following H ̊astad et al [35] and Aysu et al [36], to derive a final 128-bit key|,Non-data,62
 8 DEDICATED MEMS-PUF DESIGN We showed that there are several sensors necessary to de- rive a 128-bit key based on our used parameters This could be possible in applications in which several sensors are avail- able (eg,Non-data,62
|, 9-degrees-of-freedom sensor node) Another op- tion is to design a specific MEMS element for security pur- poses only Such a dedicated MEMS-based PUF could be realized in an area saving manner and it can be optimized providing at least the same number of suitable properties for the use as PUFs as an usual gyroscope Furthermore, the structures of such a specific MEMS could be designed in a way that increase the variability of the properties to derive more bits from a single parameter|,Non-data,62
 One example is the use of the minimum beam width for the springs in order 598Figure 6: Entropy upper and lower bounds as function of correlation coefficient The upper bound is the CTW compression rate and the lower bound is the min-entropy estimation result to increase the percentage influence of the beam width vari- ation The aim of increasing variability could be achieved by measures in the manufacturing process as well because this is optimized actually to keep variations at a minimum,Non-data,62
 Fig 7 illustrates our proposal for a dedicated MEMS- based PUF concept It is a 3-masses oscillator that is free to move in all spatial dimensions The masses are linked by doubling U-springs which are very sensitive to asymme- tries that should increase the quadrature signals and the whole structure is suspended by four doubling U-springs at the outside corners,Non-data,62
| The system can be driven and mea- sured by the electrode pairs CPX/CNX, CPY/CNY in case of in-plane movements and CPZ/CNZ in case of out-of-plane movements with respect to the potential of the masses (CM) The structure contains twelve frequency modes Three frequency modes are based on in-plane movements in y di- rection and three ones in x direction Furthermore, there are six frequency modes for out-of-plane movements|,Non-data,62
 Three fre- quency modes for translational motions and three frequency modes for rotational motions We are able to drive and mea- sure all of these modes The mechanical structure is designed in a way that the usable frequency modes are close together This is in contrast to the structure of a MEMS gyroscope where the focus is on the drive and detection modes and all further frequency modes are shifted as far as possible away from them,Non-data,62
| Additionally, there are two quadrature signals for each frequency mode and six pairs of electrodes, ie, the design provides in total 12 frequency modes, 24 quadrature signals and 6 electrical capacitances To estimate the number of bits that could be derived from our structure, we carry out FEM-simulations using AN- SYS to calculate the frequency modes|,Non-data,62
| Subsequently, we determine the capacitances between the electrodes and the quadrature signals with a reduced order model developed by Gugel [37] which is based on the principle of modal super- position This method transmits the equation of motion (6) used in the FEM-analysis to a description of the system with reduced complexity solving the eigenvalue problem (-ω2 i M + K)φi = 0 with the eigenvectors φi and the eigenvalues ωi As a result, we receive the transformation matrix Φ includ- ing the eigenvectors φi M is the mass matrix, K is the stiffness matrix and D is the damping matrix|,Non-data,62
| Equation (9) describes the system in the modal space with the deflections q whereby x = Φq M ̈x + D ̇x + Kx = F M Φ ̈q + DΦ ̇q + KΦq = F ΦT M Φ ̈q + ΦT DΦ ̇q + ΦT KΦq = ΦT F  ̃M ̈q + ̃D ̇q + ̃Kq = ̃F (6) (7) (8) (9) For simulations, we consider the following aspects of man- ufacturing process-related variations assuming typical pro- cess tolerances that can be found in [19]: • geometric dimensions (structure width and thickness), • slight differences of the beam widths locally on the legs • pressure inside the cavity, • differences in side wall inclination of the U-springs, We make 1,000 simulations of the design to estimate the key length that can be derived from the structure depending on the correlation upper limit For the key generation proce- dure, we assume the same measurement accuracies and tem- perature dependencies as determined by the measurements of gyroscopes in previous sections|,Non-data,62
| Table 4 shows that as expected, it is possible to derive more bits than from the investigated gyroscopes Note that we consider for these simulations only changes to the MEMS design A further lengthening of the key can be easily achieved by worsening of the manufacturing process Furthermore, due to the small dimensions of the structure it is conceivable to combine sev- eral of these structures in one unit concatenating their keys or to add such a structure to existing MEMS sensors for key storage purposes|,Non-data,62
| 9 CONCLUSION MEMS sensors exhibit great potential for the generation of cryptographic keys In this work, we show that MEMS gyroscopes, which have been developed for a broad range of capabilities, can be used to derive a high entropy crypto- graphic key We identify properties of MEMS gyroscopes, suitable for PUF applications by a large number of measure- ments on wafer-level|,Non-data,62
| In order to quantize the measurement values, we propose for an appropriate procedure We verify the uniqueness and reliability of the generated bit strings Furthermore, we estimate upper and lower bounds on the entropy of these bit strings and show how to implement a 02468CTW compression rateCollision testPartial collection testMarkov testCompression testFrequency testρmaxEntropy (bits/byte)599Table 4: Number of derivable bits depending on the correlation upper limit ρmax ρmax bits |,Non-data,62
50 62 62 73 74 89 86 110 ,Non-data,62
|98 199 sors The design and the manufacturing process can be op- timized to increase variability and thus deriving more bits per parameter Moreover, such a specific design can be opti- mized so that it provides more suitable parameters for PUF applications than a standard MEMS sensor Therefore a dedicated MEMS-PUF would present an excellent candidate for high security applications|,Non-data,62
| Due to the small size of such an element, it is also conceivable to add this structure to a MEMS sensor without making them significantly larger or affecting its functionality Besides the construction of an actual PUF, estimation on min-entropy is an open research direction State-of-the-art estimations, eg|,Non-data,62
|, CTW compression, focus on giving an up- per bound of entropy, leaving the problem of possible less entropy open Clearly, for high security applications a sound estimate of the enclosed lower entropy bound should be given 92 Related Work PUFs have been divided into two categories depending on the number of their uncorrelated CRPs|,Non-data,62
| These two cate- gories are strong and weak PUFs (also called obfuscating PUFs [38]), originally introduced in [9] and further devel- oped in [38, 39] The defined model by R ̈uhrmair et al [38] postulates that an attacker has access to an oracle, which replies to a challenge Ci with the same response Ri as the real system Thus, concepts that protect the access to the PUF are not taken into account, although they would lead to increased security|,Non-data,62
| Examples include concepts such as con- trolled PUFs which protect the access to the PUF with pre- and postprocessing steps [10] A strong PUF has so many CRPs that an attacker cannot measure all of them during a limited time period Furthermore, it should be infeasible to build a digital model that would allow an attacker to come up with the right response on a randomly chosen challenge In authentication applications, a strong PUF has the ad- vantage that the response of the system can be transmitted without any additional security because each CRP is only used once|,Non-data,62
| A promising candidate for an electrical strong PUF was the class of Arbiter PUFs They generate responses by ex- ploiting delay information of, eg, two identical constructed paths of ICs [8]|,Non-data,62
| Such an Arbiter PUF has a multi-bit in- put and computes a 1-bit output By concatenating the re- sponses, corresponding to different challenges, a unique key is extracted Variations of the Arbiter PUF presented in the literature include the XOR Arbiter PUF [8], the Lightweight PUF [40] and the Feed Forward Arbiter PUF [7], which aim for a higher security level than the original Arbiter PUF However, it has been shown several times that it is possible to model the Arbiter PUFs behavior based on a given set of CRPs by machine learning techniques [41, 42]|,Non-data,62
| Weak PUFs have only few CRPs, or in some cases, just one Hence, the key needs to be protected against unau- thorized access A popular candidate from this PUF class is the SRAM PUF, introduced by Guajardo et al [9]|,Non-data,62
| This ap- proach utilizes the power-up behavior of SRAM cells, where Figure 7: Dedicated MEMS-PUF design fuzzy extractor to derive a full entropy key from the most conservative entropy estimations Based on error correc- tion and randomness extraction we display the number of required devices for a 128-bit key generation from MEMS gyroscopes Additionally, we present a dedicated MEMS- PUF design, solely for usage as a primitive in security ap- plications|,Non-data,62
| This design is optimized in terms of potential features and chip area, allowing us to derive a full entropy 128-bit key from just a few of such structures, while still being able to fit in a single unit 91 Limitations and Further Research In this work, we showed that deriving a cryptographic key from a MEMS is feasible However, we are still in need to extract more bits from the MEMS structure itself, enhanc- ing following steps in the key generation process|,Non-data,62
| Regarding the implementation of MEMS-based PUFs in sensor systems and the achievement of a further key lengthening, two ap- proaches are possible • Use of several existent MEMS sensors in a sensor sys- tem, eg, 9 degree-of-freedom sensor nodes, and add- up of cryptographic key seeds which can be derived from the individual sensors|,Non-data,62
| • Development of a specific MEMS-based PUF design, optimized for PUF applications The first approach provides an additional value for ex- isting sensors and aims at its enhancement This requires further investigations of MEMS sensors On one hand, there could be more suitable parameters than that we have actu- ally measured|,Non-data,62
| For example in case of gyroscopes, there should be more frequency modes existent than nine Addi- tionally, it is possible to measure a quadrature signal for each frequency mode but we measured just two, because of con- straints on the measurement setup Especially, the quadra- ture signals are potentially able to lengthen the derivable keys, because they can be used to extract proportionally many bits and show little correlation with other parame- ters On the other hand, investigations of different MEMS sensors have to be done|,Non-data,62
| Besides, further tests should be carried out to analyze the reliability of different parameters For example, these could be tests on packaged devices as mechanical stress tests and aging tests The second approach aims at the development of a ded- icated MEMS-PUF which can benefit from the experiences gained from investigations on different existing MEMS sen- 600the bi-stable memory cells tend to either the same bit value with high probability or a random bit The PUF is formed out of SRAM cells, which behave in a robust manner on power up|,Non-data,62
| SRAM-based PUFs can deliver a large number of bits, with the size of an SRAM array as the only limit, and the memory cells do not correlate with each other Ad- vantageously, SRAM cells are inherent in most semiconduc- tor devices Hence, it does not require additional devices or modifications in the manufacturing process However, it has been already shown that it is possible to read out SRAM PUFs by invasive and semi-invasive attacks [43]|,Non-data,62
| Further- more, Helfemeier et al produced a physical clone of a SRAM PUF [44] Note that weak and strong PUFs aim at different pur- poses Strong PUFs could be compared with a physical hash function, whereas weak PUFs are used for safeguard a secret key [45]|,Non-data,62
| Until now, MEMS-based PUFs have received little atten- tion, unlike Arbiter or SRAM PUFs The first MEMS-based PUF was proposed by Rosenfeld et al [46] Their method uses an array of on-chip photodiodes and a translucent coat- ing|,Non-data,62
 The transmittance of the coating is not uniform and causes variations of the measured light level The key is generated by the variations between the amounts of light sensed by the photodiodes Another work focused on MEMS is from Aysu et al [14],Non-data,62
| They used the deviations of an accelerometer’s self-test and offset values for a low-cost device authentication However, they stated that their keys do not achieve the uniqueness as the keys of, eg, SRAM PUFs|,Non-data,62
|ABSTRACT Hardware Trojan detection has emerged as a critical chal- lenge to ensure security and trustworthiness of integrated circuits A vast majority of research efforts in this area has utilized side-channel analysis for Trojan detection Func- tional test generation for logic testing is a promising al- ternative but it may not be helpful if a Trojan cannot be fully activated or the Trojan effect cannot be propagated to the observable outputs Side-channel analysis, on the other hand, can achieve significantly higher detection cover- age for Trojans of all types/sizes, since it does not require activation/propagation of an unknown Trojan|,Non-data,63
| However, they have often limited effectiveness due to poor detection sensitivity under large process variations and small Trojan footprint in side-channel signature In this paper, we address this critical problem through a novel side-channel-aware test generation approach, based on a concept of Multiple Exci- tation of Rare Switching (MERS), that can significantly in- crease Trojan detection sensitivity The paper makes several important contributions: i) it presents in detail the statisti- cal test generation method, which can generate high-quality testset for creating high relative activity in arbitrary Tro- jan instances; ii) it analyzes the effectiveness of generated testset in terms of Trojan coverage; and iii) it describes two judicious reordering methods can further tune the testset and greatly improve the side channel sensitivity Simulation results demonstrate that the tests generated by MERS can significantly increase the Trojans sensitivity, thereby making Trojan detection effective using side-channel analysis|,Non-data,63
| CCS Concepts •Hardware → Hardware test; Very large scale integra- tion design; Hardware validation; Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita- tion on the first page Copyrights for components of this work owned by others than ACM must be honored Abstracting with credit is permitted To copy otherwise, or re- publish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee|,Non-data,63
| Request permissions from permissions@acmorg CCS’16, October 24-28, 2016, Vienna, Austria c(cid:13) 2016 ACM ISBN 978-1-4503-4139-4/16/10|,Non-data,63
   $1500 DOI: http://dx,Non-data,63
doiorg/101145/29767492978396 Keywords Hardware Security; Hardware Trojan Detection; Side-Channel Analysis; Statistical Test Generation,Non-data,63
| 1 INTRODUCTION Hardware Trojan attacks relate to malicious modifications in the design of Integrated Circuits (ICs) at different stages of the design or fabrication process [1] An adversary can introduce these modifications in a design in order to cause disruption in normal functional behavior and/or to leak se- cret information from a chip during operation in field With the emerging trend of increased globalization of IC design and fabrication process and consequently reduced control on these steps by a trusted chip manufacturer, ICs are becom- ing increasingly vulnerable to these attacks|,Non-data,63
| Since the threat of hardware Trojan in the form of a malicious implant in a design came into light about a decade ago through an US Department of Defense announcement [2], it has triggered wide array of research activities in threat analysis as well as design/validation solutions to evaluate this threat and protect against it Hardware Trojan attacks are also being increasingly recognized in the semiconductor industry as a serious security concern A Trojan is expected to be covert and difficult to detect, ie|,Non-data,63
| an intelligent adversary will likely insert a Trojan circuit in a way that evades detection during post-manufacturing functional/parametric testing, but manifests itself during long hour of in-field operation This can be achieved by externally triggering its operation or by making it depen- dent on rare circuit conditions inside an IC The condition of Trojan activation as commonly referred to as trigger con- dition, which can be purely combinational or sequential, ie|,Non-data,63
 related to the clock or a sequence of rare events in the state elements (eg flip-flops of registers) The internal circuit nodes affected by a Trojan activation are referred to as pay- load of a Trojan,Non-data,63
| Fig 1 shows some example Trojan circuits including a combinational and a sequential Trojan For ex- ample, a Trojan circuit could be triggered only when a data bus attains a unique rare value or when the number of times it attains the rare value equals to a particular count The malicious effects of Trojan payloads can range from passive, such as leakage of secret information to altering the original functionality of the chip in a critical or destructive fashion|,Non-data,63
| Protection against hardware Trojan attacks can be ac- complished in two broad ways: (1) design-for-security (DfS) techniques that make Trojan insertion difficult or make a 130(a) Combinational Trojan (b) Sequential Trojan Figure 1: Example of a combinational and a sequential Tro- jan with triggers from two rare internal nodes A and B Trojan easily detectable through post-silicon testing; and (2) manufacturing test approaches that aim at detecting an arbitrary Trojan by observing its effect into a circuit’s op- erational behavior The first class of techniques, primarily relies on different types of hardening approaches - eg|,Non-data,63
| in- sertion of dummy cells into empty spaces in a circuit layout; or key-based obfuscation of a design that make malicious alteration by an adversary provably hard DfS techniques, however, come at the cost of additional design, verification, and test time, as well as additional design overhead For example, key-based obfuscation, even though is capable of providing high level of robustness against Trojan attacks, come at a cost of 10% or more area overhead [3] More importantly, design solutions, however, only work for new designs and not legacy designs, and hence has limited ap- plicability|,Non-data,63
| Hence, efficient test/validation approaches that can provide high level of confidence regarding IC trustwor- thiness in presence of Trojan threat provides an attractive solution to the IC manufacturers Existing test solutions for hardware Trojan detection can be broadly classified into: 1) logic testing and 2) side-channel analysis approaches In logic testing approach, directed structural or functional tests are generated to activate rare events in a circuit and propagate the malicious effect of a Trojan in logic values to primary outputs Such approaches are known to be more effective in detecting ultra-small Tro- jans (typically a few gates in size) reliably under large pro- cess variations|,Non-data,63
| The main challenge with logic testing ap- proaches, however, is the difficulty to trigger a Trojan and observe its effect, particularly the complex sequential Tro- jans, and the inordinately large number of possible Trojan instances an adversary can exploit On the other hand, side- channel analysis approaches depend on measurement and analysis of physical “side-channel” parameters like power sig- nature or path delay of an IC in order to identify a structural change in the design Such approaches have the advantage that they do not require triggering a malicious change and observing its impact at the primary output Side-channel analysis (SCA), primarily based on supply current, has been extensively investigated by large number of research groups and various solutions to increase the signal-to-noise (SNR) have been proposed|,Non-data,63
| A disadvantage of SCA arises from the large process variations (eg 20X leakage power and 30% delay variations in 180nm technology [4]) which can poten- tially mask the minute effect of a Trojan in the measured side-channel parameter Even though SCA has shown tremendous promise in de- tecting unknown Trojans of various types during manufac- turing test of an IC, a major issue with SCA is the low detection sensitivity|,Non-data,63
| For a billion transistor modern IC, a Trojan with just a few logic gates would have a minuscule side-channel foot-print, which will require a measurement resolution and dynamic range in an instrument, that is hard to achieve For example, a delta shift in several nano or pico amp of transient current in ten’s of amp of background current, would be practically infeasible to detect even with most precise and expensive instrument The problem is ag- gravated by orders of magnitude due to presence of both systematic and random variations in device parameters due to intrinsic process variations A solution to the sensitivity problem can be achieved by judicious test generation approach that aims at maximizing the sensitivity for an arbitrary Trojan in unknown circuit location|,Non-data,63
| Through the remainder of the paper, we focus on transient current or power as our side-channel parameter of interest Some of the concepts however can be applied to other side-channel parameters To maximize sensitivity of a given Trojan, one needs to amplify activity inside the Trojan circuit and simultaneously minimize the background activity (ie|,Non-data,63
| activity in the original circuit) However, since the number of possible Trojan instances in a design can be inordinately large, a deterministic test generation method similar to conventional stuck-at fault test generation, cannot work To address this issue, in this paper, we present a novel test generation framework that can maximize the detection sensitivity for an arbitrary Trojan 1|,Non-data,63
|1 Main Idea and Our Contributions The goal of our work is to generate efficient test vectors for Trojan detection using side-channel analysis Functional test can detect Trojan effect only when it is fully triggered and its payload is propagated to the primary outputs, which makes functional test infeasible to detect Trojans in most cases Side channel analysis can detect well-hidden Trojans by inspecting the side channel signals, for example, transient current in the circuit If the switching effect introduced by the Trojan circuit is distinguishable, in the presence of pro- cess variation, the Trojan will get identified|,Non-data,63
 In this paper we propose a comprehensive test generation framework to assist side channel analysis for hardware Trojan detection We use the relative switching of the Trojan with respect to the whole circuit to indicate the sensitivity of the side channel signals The statistical test patterns can maximize relative Trojan detection sensitivity under any process noise Process variation is not expected to affect our side channel sensitivity computation since we consider switching activity instead of actual current or power values,Non-data,63
| The assumptions we have made are similar to the state-of-the-art side-channel analysis based Trojan detection approaches The proposed method can be combined with any existing process calibra- tion approaches (such as one in [21] or [22]) to minimize the false positives/negatives and maximize Trojan coverage To make side channel analysis successful in detecting Tro- 131jans, we need to: (1) maximize the switching activity in the Trojan circuit; (2) minimize the switching activity in other parts of the circuit so that the relative switching effect is maximized The main idea of this paper is to generate high quality test patterns which can achieve these two goals and increase the sensitivity of side channel analysis|,Non-data,63
| The follow- ing are the major contributions of this paper: 1 It presents, for the first time in our knowledge, a sta- tistical test generation approach for increasing side- channel analysis based Trojan detection sensitivity The proposed approach can be applicable to any transient current based Trojan detection approach 2|,Non-data,63
| The methodology, referred to as MERS (Multiple Ex- citation of Rare Switching) for statistical test gener- ation, is shown to derive a compact testset that can trigger each of the rare nodes to satisfy rare switching for multiple times MERS can have a good coverage of all rare nodes and greatly increase the switching effect inside arbitrary Trojans in unknown locations of the circuit 3 Two reordering methods are proposed to reduce the total switching of the circuit and thus further increase the sensitivity of side channel analysis|,Non-data,63
| First, a simple and low-cost method based on Hamming distance of input vector pairs is introduced to reorder the tests Next, we develop another simulation based method to more effectively balance switching in rare nodes and the total switching Our side-channel based approach is targeted towards de- tecting unknown Trojans, which means it will remain equally effective even if the adversary is aware of the proposed method This is due to the following two reasons: (1) the proposed test generation method is statistical in nature - so, unlike conventional deterministic test approaches, it maximizes the activation probability for arbitrary Trojans designed with any trigger condition; and (2) it maximizes the detection sensitivity of unknown Trojans, however “stealthy”, by am- plifying its effect in side-channel signature|,Non-data,63
 Our simulation platform inserts large number of arbitrary Trojans in a de- sign and shows that the proposed approach is highly effective in detecting them The rest of the paper is organized as follows Section 2 provides overview of hardware Trojan attacks and the broad classes of Trojan detection approaches Section 3 presents related work in side channel analysis and functional test gen- eration for Trojan detection,Non-data,63
 Section 4 presents the MERS test generation algorithm and the test reordering algorithms to improve sensitivity of side channel analysis Section 5 de- scribes the experiment setup and presents results on a set of ISCAS benchmarks with detailed analysis Section 6 con- cludes the paper 2,Non-data,63
| BACKGROUND AND PRELIMINARY In this section we briefly describe the growing threat of hardware Trojan attacks and discuss two broad classes of Trojan detection approaches 21 Hardware Trojan Attacks Malicious modification of IC at different stages of its life cycle, known as hardware Trojan attacks, is an impending threat in the electronics industry Increased reliance on third party hardware intellectual property (IP) blocks and design automation tools in the IC design flow as well as outsourc- ing of design/fabrication steps to external parties due to economic reasons are rapidly increasing the vulnerability to Trojan attacks|,Non-data,63
| An adversary can mount such an attack with an objective to cause in-field operational failure or to leak secret information from inside a chip - eg the key in a cryptographic IC Recent investigations have shown that an intelligent adversary can insert tiny Trojans of numer- ous forms and sizes into a million-transistor design, which can easily evade conventional manufacturing test that is not designed to isolate the stealthy Trojan attacks|,Non-data,63
| Depending on their mode of operation and structure, hard- ware Trojans can be grouped into several broad classes A common classification of Trojans [1][7] is based on the activa- tion mechanism (referred as Trojan trigger ) and the effect on the circuit functionality (referred as Trojan payload ) Tro- jans can be both combinationally and sequentially triggered Typically, an adversary would choose an extremely rare acti- vation condition so that it is highly unlikely for the Trojan to trigger during conventional manufacturing test|,Non-data,63
| Sequentially triggered Trojans (the so-called “time bombs”), on the other hand, are activated by the occurrence of a sequence, or after a period of continuous operation The simplest sequential Trojans are synchronous stand-alone counters, which trigger a malfunction on reaching a particular count The trigger mechanism can also be analog in nature, whereby on-chip sensors are used to trigger a malfunction For example, the Trojan gets activated when the temperature of a particular region of the IC exceeds a threshold [1]|,Non-data,63
| Trojans can also be classified based on their payload mechanisms into two main classes - digital and analog Digital payload Trojans can ei- ther affect the logic values at chosen internal payload nodes, or can modify the contents of memory locations Analog pay- load Trojans, on the other hand, affect circuit parameters such as performance, power and noise margin 2|,Non-data,63
|2 Trojan Detection Approaches Detecting hardware Trojan instances in an IC before it is used in an electronic system is of paramount importance Even though DfS approaches that aim at hardening a design with respect to Trojan insertion or facilitating Trojan detec- tion during manufacturing test are being actively researched [3], they have several major limitations: (1) they cannot provide provably robust defense against all forms of Trojan attacks; (2) they often incur unacceptable design overhead; and (3) they cannot be applied to legacy designs, which is difficult to change for incorporating DfS features Hence, a Trojan detection step for trust validation during post-silicon manufacturing test is becoming crucial to isolate ICs affected with Trojans It is worth noting that conventional post-manufacturing test using functional / structural test patterns performs poorly to reliably detect hardware Trojans|,Non-data,63
| This is because man- ufacturing test generation and application aim at detect- ing manufacturing defects with well-characterized behavior and model that cause deviation from functional or paramet- ric specifications They do not aim at detecting additional functionalities incorporated by a Trojan or deviation in cir- cuit behavior triggered by rare events Hence, conventional testing methods typically provide poor Trojan detection ca- pability, as observed by researchers [5] Destructive test- 132ing of a chip by de-packaging, de-metallization and micro- photography based reverse-engineering is highly expensive (in time and cost) and not a feasible solution because an attacker may selectively insert Trojan into a small subset of the manufactured ICs [8]|,Non-data,63
| Existing Trojan detection approaches fall into two major classes: (a)functional testing based, and (b) side-channel analysis based Most Trojan detection techniques proposed in the literature are characterized by their efficiency in de- tecting particular classes of Trojan These approaches typi- cally fail to provide high confidence in detecting an inserted Trojan of arbitrary operating mode The enormous vari- ety of Trojans and the inordinately large Trojan population that might be present in a circuit makes it difficult to de- vise deterministic test patterns for them|,Non-data,63
| The functional testing based Trojan detection approaches [5] aim to trig- ger rare events at internal nodes in the circuit to activate Trojans and then compare the obtained output logic val- ues of the circuit with the expected golden values of the IC On the other hand, the side-channel analysis based Trojan detection approaches [9][12][19] are based on observing the effect of an inserted Trojan on a physical parameter such as circuit transient current, power consumption or path de- lay, and then comparing it with the pre-characterized golden value for a Trojan-free IC (or a model of the IC) If the ob- served value of the measured parameter differs by more than a threshold from the golden value, the presence of a Trojan is suspected Both classes of Trojan detection techniques have their relative pros and cons|,Non-data,63
| The main challenge for functional testing based Trojan detection approaches is the enormously large Trojan design space, which makes com- plete enumeration and test generation for all feasible Trojan instances in a moderately-sized circuit computationally in- feasible This makes it extremely difficult to guarantee that an arbitrary inserted Trojan would be activated, cause cir- cuit malfunction and thus get detected during the test ap- plication phase On the other hand, the advantage of the side-channel analysis based approaches lies in the fact that even if the Trojan circuit does not cause observable mal- function in the circuit during test, the presence of the extra circuitry can be reflected in the measured side-channel pa- rameter Further, such techniques are suitable for arbitrarily complex Trojans because they do not need to make any as- sumption about the mode of operation of an inserted Trojan|,Non-data,63
| However, the main challenges associated with side-channel analysis are large process variation and design marginality induced effects in modern nanometer technologies [1], and measurement noise, which can mask the effect of an inserted Trojan circuit, especially for small Trojans 3 RELATED WORK The underlying assumption for Trojan insertion is that an adversary is fully aware of the design functionality and therefore can hide the Trojan in a hard-to-find place The adversary may use very rare internal transitions to trigger the Trojan, and it may be impossible to detect (due to ex- ponential state space) during traditional testing and valida- tion|,Non-data,63
| One way to address this issue is to obfuscate [3] or encrypt [14] the design such that the adversary cannot fig- ure out the actual functionality and therefore cannot insert the Trojan in a covert manner Unfortunately, smart at- tacker can effectively bypass both obfuscation [15] and en- cryption [16] methods A promising direction is to develop efficient techniques for hardware Trojan detection Prior re- search on Trojan detection can be classified into two broad categories: side-channel analysis and functional test gener- ation|,Non-data,63
| A vast majority of the Trojan detection approaches are based on analysis of side-channel signatures such as de- lay, transient and leakage power [8][9][10][11][12][13] The basic idea is to find a side-channel signature (if the Trojan activated) that is different from the normal signature Un- fortunately, these approaches are susceptible to thermal and process variations Therefore, it would be difficult to detect small combinational Trojans|,Non-data,63
 One promising direction to overcome process variation is to generate functional test patterns that are likely to acti- vate the Trojans These approaches rely on the fact that an adversary will choose a trigger condition for the Trojan using a set of rare nodes Various approaches tried to max- imize the rare node activation to increase the likelihood of activating Trojans Some approaches [18][19] use the design- for-test (DFT) infrastructure (such as additional scan flip- flop) to increase the transition probability of low-transition nets,Non-data,63
| MERO [5] takes the advantage of N-detect test [20] to maximize the trigger coverage by activating the rare nodes The test generation ensures that each of the nodes gets ac- tivated to their rare values for at least N times They have shown that if N is sufficiently large, a Trojan with trigger conditions from these rare nodes, will be highly likely to be activated by the generated test set Saha et al|,Non-data,63
| [6] improves the test pattern generation of MERO by using genetic algo- rithm and boolean satisfiability, which could more effectively propagate the payload of possible Trojan candidates How- ever, these functional test generation approaches are not de- signed for side-channel analysis Direct application of these test generation approaches for side-channel analysis would not be best for improving side-channel sensitivity for Trojan detection The objective of increasing side-channel sensitiv- ity is very different from the ones in both MERO as well as its enhanced version by Saha et al|,Non-data,63
| Unlike these existing approaches, a side-channel aware test generation approach, as proposed in our paper, requires maximizing switching ac- tivity in an unknown Trojan circuit while minimizing the background switching Instead of aiming on finding a vector to activate a set of rare nodes, we focus on creating a set of vector pairs to maximize switching in rare nodes Our algorithm creates multiple excitation of rare switching which is important in making side-channel based Trojan detection effective More- over, we also try to simultaneously minimize the background switching to maximize the relative switching|,Non-data,63
| 4 MERS METHODOLOGY In this section, we present the proposed methodology for side-channel aware test generation in detail The methodol- ogy is based on the concept of statistically maximizing the switching activity in all the rarely triggered circuit nodes The effectiveness of a test pattern for side channel analy- sis is measured in two ways: (1) the ability to create most switching inside a Trojan or to activate a Trojan; (2) the ability to create high Trojan-to-circuit switching|,Non-data,63
