 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
|e, changing the fluid quantity from 1 μL to 1000 μL) We use the term control-flow event to refer to any execution of a control-flow instruction (eg|,Non-data,17
|, branch, return, etc) In other words, a control- flow event is a traversal of an edge in the CFG Since C-FLAT executes its algorithm on every control-flow event, the overall attes- tation time varies depending on the number of control-flow events, as shown in Figure 8|,Non-data,17
| Figure 8: Attestation overhead (average over 20 repetitions) The attestation overhead is linearly proportional to the number of control-flow events This is as expected, since each control-flow event results in a trampoline invocation, a context switch, and an execution of the relevant Secure World algorithm The type of event also impacts the overhead (eg|,Non-data,17
|, loop handling is more costly), but this is not visible in Figure 8 due to the large number of events The variance of these measurements is negligible, since there is no other software running on the platform The attestation overhead can be decomposed into three categories: i) trampolines, ii) context switches, and iii) the Secure World algo- rithm For both the set-quantity and move-syringe paths, the relative percentage composition of the overhead remained roughly constant, irrespective of the state variable|,Non-data,17
| For the set-quantity path, 83% of the overhead came from the trampolines, 119% from the context switches, and 798% from the algorithm itself|,Non-data,17
| These ratios were similar for the move-syringe path at 102%, 175%, and 723% respectively|,Non-data,17
| As expected, the majority of the overhead is due to the algorithm itself Performance impact For the intended class of applications, this overhead would not necessarily have an impact on the real-world performance of the application In cyber-physical systems, the main timing requirements usually arise from the system’s physical processes and components (e|,Non-data,17
|g, sensors and actuators), which op- erate on comparatively slow physical timescales For example, in medical applications, typical flow rates for a syringe pump system could be 05 ml/h, 1|,Non-data,17
|0 ml/h, and 20 ml/h8 In our case study, the attestation overhead is 12 s for dispensing 0|,Non-data,17
|5 ml, 24 s for 10 ml, and 48 s for 2|,Non-data,17
|0 ml Therefore, the real-world attesta- tion overhead for these parameters ranges from 003% to 013%|,Non-data,17
| Timescales in the order of minutes or hours are common in cyber- physical systems, for example, a typical embedded humidity sensor could measure and report a value once every 15 minutes9, and an embedded thermostat would not switch on a compressor unit more than once every three minutes10 Even if the attestation overhead begins to affect the system’s tim- ing requirements, various strategies can be used to ameliorate this situation Firstly, we expect that the attestation would be run only occasionally, at a time determined by the verifier When the ap- plication is not being attested, the overhead decreases significantly (e|,Non-data,17
|g, by 72% to 80% for the syringe pump) This strategy could also be applied to other types of systems (eg|,Non-data,17
|, attesting an embed- ded system in a car while not in use) Secondly, the application could be adapted to accommodate this additional overhead The above measurements were obtained by applying C-FLAT to an unmodified application, but if the source code is available, minor modifications could be made to the appli- cation to compensate for the attestation overhead (eg|,Non-data,17
|, reducing the durations of application-defined delay loops) Implementation considerations An unavoidable side-effect of C-FLAT is that it may affect the way an application measures time If the application relies on time-calibrated loops to delay for a spe- cific duration, the calibration will change when the application is instrumented|,Non-data,17
| Since the time spent in the Secure World varies de- pending on the type of control-flow operation, more complicated and/or experimental calibration would be required However, this can be easily avoided by instead using well-defined timing capabil- ities, such as system timers 64 Second Case Study To further evaluate C-FLAT, we completed a second case study using a significantly larger application|,Non-data,17
 8http://wwwncbinlmnih,Non-data,17
|gov/pubmed/11032282 9http://vanderleevineyardcom/1/category/vinduino/1html 10https://githubcom/bbustin/climaduino/tree/develop 0102030405060012Control-flowevents(x103)Totaloverhead(seconds)750We applied C-FLAT to a soldering iron temperature controller, which allows users to specify a desired temperature and maintains the soldering iron at that temperature using a proportional-integral- derivative (PID) controller|,Non-data,17
|11 This type of system could also be used to control temperature in other settings, such as a building or an industrial process, and thus is representative of a large class of cyber-physical systems This application is significantly larger than the syringe pump as it consists of 70,000 instructions and has 1,020 static control-flow edges of which 40 are loops The security-critical functionality is the PID controller, which continuously reads the current temperature, compares it to the de- sired temperature, and calculates the PID output to adjust the tem- perature We instrumented the application to attest the control flow of this critical section, and verified that the correct hash values were obtained|,Non-data,17
| The total overhead added by C-FLAT to a single itera- tion of the PID controller was 237 μs (average over 100 runs) with a standard deviation of 1 μs As before, this overhead is signif- icantly lower than the physical timescales on which these cyber- physical systems operate (eg attesting the controller once per sec- ond results in 0|,Non-data,17
|03% overhead) For this attestation, the maximum length of Auth was 490 bytes 7 SECURITY CONSIDERATIONS In this section, we evaluate the security guarantees provided by C- FLAT based on practical embedded exploits and different runtime exploitation techniques|,Non-data,17
| Note that our discussion refers to the run- time attack threat model outlined in Figure 1 The security of C- FLAT itself is described alongside the implementation in Section 5 As explained in that section, the integrity of the Runtime Tracer is ensured through static attestation, and the integrity of the measure- ment engine is protected by the trust anchor (eg|,Non-data,17
|, the TrustZone Secure World) As usual, the freshness of the attestation is guaran- teed by the challenge-response protocol between Prv and Ver (as described in Section 3) Exploiting the syringe program We constructed three exploits that affect the move-syringe function|,Non-data,17
| Our first attack exploits a self-implanted memory error to trigger the movement of the sy- ringe pump although no movement has been requested As a con- sequence, liquid is dispensed at an unexpected time We imple- mented this attack by reverse-engineering the syringe program bi- nary and searching for return-oriented gadgets that allow us to load a function argument into ARM register r0 and transfer control to the move-syringe function We were able to construct a suit- able gadget chain to implement this attack|,Non-data,17
| With C-FLAT enabled, we could detect this attack since the gadget chain leads to an unex- pected hash measurement indicating to the verifier that a malicious program path has been executed Our second exploit is based on a non-control-data attack: it cor- rupts a local state variable that controls the amount of liquid to use This variable is used to determine the number of iterations of the critical loop in order to dispense the correct amount of fluid Hence, this attack does not violate the program’s CFG|,Non-data,17
| However, for the case of the syringe program, the loop iterations indicate to the verifier how much liquid has been dispensed Again, we can de- tect this attack with C-FLAT since the precise loop iteration counts are reported in the attestation response Our third exploit, a non-control-data attack, corrupts the static key-map array used for processing input from the keypad When a key is pressed, the keypad produces an analog value in a pre- defined range, which is read by the program|,Non-data,17
| The program iterates 11https://createarduinocc/projecthub/sfrwmaker/ soldering-iron-controller-for-hakko-907-8c5866 through a key-map array of known ranges, checking whether the analog input is the range for any recognized key By changing the pre-defined ranges in the key-map array, our attack misleads the program into believing that a physical key has been pressed, thus causing the program to perform the relevant action (e|,Non-data,17
|g the right key triggers the move-syringe function, causing the syringe to dispense liquid) This attack can be detected by C-FLAT because the number of iterations of the key processing loop reveals which key appears to have been pressed Assuming the verifier knows that the physical key has not been pressed, this can therefore be identified as unintended behavior|,Non-data,17
| Code Injection Conventional control-flow hijacking attacks rely on the injection and execution of malicious code [3] For this, the attacker needs to inject the malicious code into the data space of an application and corrupt control-flow information to redirect the execution to the injected code Since malicious code resembles a new unknown node NX (see Figure 1), C-FLAT can easily detect this attack|,Non-data,17
| The reported hash value will include node NX although it does not belong to the original control-flow graph (CFG) of the application To undermine C-FLAT detection, an attacker may at- tempt to overwrite an existing node, eg, replacing the benign Node N2 with NX|,Non-data,17
| However, such an attack is not directly possible as we target platforms (see Section 32) that enforce data execution prevention (DEP) Hence, the memory area of node N2 is not ex- ecutable and writable at the same time Furthermore, the so-called multi-stage exploits which deploy code-reuse attack techniques in the first place to mark the code region as writable and inject ma- licious code thereafter are not feasible under C-FLAT, because C-FLAT will report the execution of the corresponding memory modification system calls (hereafter denoted as mem-calls)|,Non-data,17
| For Case (ii), the attacker follows a control-flow path that is not The only possibility to launch a code injection attack requires a program that benignly mem-calls to change memory permissions of code pages For such cases, the attacker only corrupts input ar- guments to the mem-calls so that node N2 is eventually overwritten with NX These attacks resemble pure data-oriented exploits since they do not require any code pointer corruption As such, they can- not directly be detected by means of control-flow attestation|,Non-data,17
| On the other hand, if the injected code performs unexpected calls to benign code, C-FLAT can still detect this pure data-oriented at- tack since an unknown hash value would be calculated Return-oriented programming Code-reuse attacks that only ma- liciously combine benign code snippets from different parts of the program are more challenging to detect because they do not inject any new nodes The most prominent instantiation is return-oriented programming [39]|,Non-data,17
| It combines short code sequences, each end- ing in a return instruction, to generate a new malicious program C-FLAT is able to detect return-oriented programming (includ- ing just-in-time return-oriented programming [40]) since unknown control-flow edges are taken upon execution of a return In general, these attacks exploit return instructions to transfer control to either (i) an arbitrary instruction in the middle of a CFG node, (ii) the beginning of an arbitrary CFG node to which no valid control-flow edge exists, eg|,Non-data,17
|, the attack path from N3 to N2 in Fig- ure 1, or (iii) another valid CFG node that is not the actual caller, ie, originating node Case (i) is detected by C-FLAT since no valid measurement can be generated when a node is not executed from its original beginning; even for nodes to which valid control- flow edges exist|,Non-data,17
| For instance, if an attacker exploits the vulnera- bility in N3 to target an instruction in the middle of the otherwise valid node N6, the reported hash value will be different to the one expected This is due to the fact that our measurement includes source and end address of each node visited 751part of the CFG, eg|,Non-data,17
|, node N3 has no connection to node N2 Due to the missing control-flow edge, the measurement will output an unknown hash value The last case is challenging to handle since the attacker targets a valid CFG node, ie|,Non-data,17
|, there exists a valid control-flow edge but the current context indicates that the control-flow edge should not have been taken We already discussed such scenarios in Section 42 for the call-return matching C-FLAT indexes control-flow edges for function calls and returns to detect call-return mismatches|,Non-data,17
| While this strategy works without special effort for direct function calls, indirect calls still pose an extra obstacle since static analysis may fail in resolving their target nodes For those calls that static analy- sis cannot resolve, one can either leverage dynamic analysis or do an over-approximation by allowing each return instruction to target the instruction right after an unresolved indirect call Note that this trade-off is not specific to our scheme, but a general problem in control-flow analysis However, as we have shown in Section 6|,Non-data,17
|1, embedded codes are typically tailored to a specific use-case allow- ing us to perform precise CFG analysis In fact, basic dynamic analysis quickly allowed us to identify the valid paths in our sy- ringe pump example Jump-oriented programming Another variant of return-oriented programming are jump-oriented programming attacks [10, 7]|,Non-data,17
| These attacks exploit indirect jump and call instructions at the end of each invoked code sequence Similar to return-oriented programming, C-FLAT detects these attacks since they deviate the program’s control flow to an unintended CFG node As long as static or dy- namic analysis identifies the set of target addresses, we are able to determine valid measurements for each indirect jump and call thereby allowing C-FLAT to detect malicious control-flow devia- tions incurred by jump-oriented programming Function-reuse attacks|,Non-data,17
| Function-reuse attacks invoke a mali- cious chain of subroutines Typically, these attacks are leveraged to undermine mitigation schemes that specifically aim at detecting return-oriented programming attacks C-FLAT detects function- reuse attacks since it attests the program’s entire control flow, ie|,Non-data,17
|, it also captures the order in which functions are executing For in- stance, the counterfeit object-oriented programming (COOP) [36] exploitation technique abuses a loop gadget to invoke a chain of C++ virtual methods C-FLAT attests the execution within the loop, ie|,Non-data,17
|, the number of times the loop has executed, and the or- der of virtual methods being called Since the invoked chain does not resemble benign program execution, the resulting hash value will indicate to the verifier that a malicious path has been executed Non-control-data attacks Non-control-data attacks manipulate variables that affect the program’s control flow [12], e|,Non-data,17
|g, to exe- cute the privileged attack path (iii) in Figure 1 C-FLAT is able to detect these attacks as each individual control-flow path leads to a different measurement Hence, the verifier Ver can immediately recognize which path has been taken by the program at the prover’s device Prv|,Non-data,17
| Another example is our attack reported in Section 7 which only modifies a data variable to manipulate the amount of liquid dispensed through the syringe pump Since the amount of liquid dispensed is proportional to the number of times a loop has executed, and that number is reported in the attestation response, Ver can detect the malicious modification by validating the loop counters 8 DISCUSSION Towards control-flow attestation of MCUs|,Non-data,17
| The Raspberry Pi series of credit card-sized single-board computers have a become a popular platform among developers, researchers and hobbyists for building embedded applications Raspberry Pi 2 represents the higher-end of the embedded device spectrum The hardware trust anchor for the isolation of the C-FLAT Measurement Engine is TrustZone-A, an architectural feature in ARM application cores that has successfully been used as a hardware base for Trusted Exe- cution Environments in mobile phones for the last decade, and has also made inroads in the top-end Internet of Things (IoT) processor families The Microcontroller (MCU) market for embedded computing in industry, automotive and home is rapidly moving towards 32- bit processing cores at the expense of small 8- and 16 bit con- trollers|,Non-data,17
| For the latest version of its MCU core line (ARM-M), ARM introduced TrustZone-M [46] – hardware primitives for iso- lating security-critical functionality such as firmware upgrades or secure channel establishment from the rest of the controller soft- ware Intel’s TrustLite [24] provide very similar functionality Both TrustZone-M and TrustLite can provide the necessary hardware fundament to implement C-FLAT on IoT MCUs Reducing context switch overhead|,Non-data,17
| There are several optimiza- tion strategies depending on the properties of underlying secure hardware On platforms equipped with a full-featured TEE, the context switch into the Secure World is expensive In the case of TrustZone-A on an ARMv8 Cortex-A53 the context switch is ap- proximately 3700 cycles or 5μs at 800MHz [33] In the TrustZone- A architecture, the transition between the Secure and Non-Secure modes occurs via hardware exceptions mediated by a special ex- ception handler referred to as the Secure Monitor|,Non-data,17
| The transition can only be triggered from the Non-Secure World privileged mode Under these circumstances, overall performance can be increased by caching control-flow information in the Non-Secure World be- fore transferring it in bulk to Measurement Engine in the Secure World Hardware security architectures for highly resource constrained embedded devices, such as TrustLite or TrustZone-M, reduce the switching overhead associated with trusted application invocation to a few cycles For example, TrustZone-M has no need for a ded- icated Secure Monitor context|,Non-data,17
| The transition between Secure and Non-Secure Worlds is handled by the processor circuitry indepen- dently of software through a mechanism based on protection re- gions with marked call gates enforced by the Memory Protection Unit Embedded operating systems While the prover in our current prototype runs unassisted on bare-metal, many IoT devices feature embedded operating systems The main purpose of an embedded OS (e|,Non-data,17
|g, FreeRTOS12, Zephyr13, ChibiOS14) is to schedule tasks or functions, often based mainly on interrupt input The OS may also provide memory management for the tasks and support de- bugging A real-time OS adds pre-emptive scheduling to provide timing guarantees for individual tasks|,Non-data,17
| However, hardware in con- trollers traditionally do not support many processing contexts or memory protection to achieve isolation between tasks or even be- tween OS and application From a security perspective, C-FLAT on such devices should therefore consider a single isolation domain even if an OS is present, and instrument the OS as a single bare- metal program Thumb-2 instrumentation Modern ARM-M MCUs utilize the Thumb-2 instruction set because of its improved code density in order to maximize the usage off on-chip Flash memory|,Non-data,17
| In ongoing work, we enhance our instrumentation approach to include support for the variable-length Thumb-2 instructions 12http://wwwfreertosorg/ 13https://www|,Non-data,17
zephyrprojectorg/ 14http://wwwchibiosorg 752Data-flow attestation,Non-data,17
| As already mentioned in Section 2, we fo- cus on control-flow related attacks On the other hand, pure data- oriented attacks can lead to leakage of sensitive information, eg, a data pointer that is processed in a network operation is altered to point to sensitive information|,Non-data,17
| Hence, in our future work we will explore data-flow attestation, ie, mechanisms that allow us to track data pointers and validate function arguments and return values Probe-based runtime attestation|,Non-data,17
| In our ongoing work, we ex- plore control-flow attestation for larger and very complex programs, ie, programs with a complex control-flow graph that contains a large number of different program paths These might lead to a combinatorial explosion of valid hash values thereby rendering val- idation cumbersome|,Non-data,17
| To support such programs, we envision probe- based attestation that (i) generates and reports a cumulative hash for program segments, eg, reporting an authenticator for each subrou- tine, and (ii) allows probing a program during its execution The latter enables an interactive attestation protocol in which Ver can repeatedly validate the evolution of the program execution at arbi- trary time intervals|,Non-data,17
| 9 RELATED WORK Prior work on static attestation falls into three main categories: (1) TPM-based, (2) software-based, and (3) hybrid Although TPMs and subsequent techniques (eg|,Non-data,17
|, [30, 29]) are pervasive in PCs, they are not well-suited for low-end embedded devices due to their relatively high cost Meanwhile, software-based methods (eg, SWATT [38], Pioneer [37], and VIPER [28]) can be used – un- der some strict assumptions – for static attestation of certain legacy devices, such as peripherals|,Non-data,17
| Between these two extremes, hybrid schemes such as SMART [18], TrustLite [24], and TyTAN [8] re- quire minimal hardware trust anchors in order to provide strong re- mote attestation guarantees C-FLAT is complementary to all these schemes in that it attests runtime behavior, which is orthogonal to static attestation Mitigation of runtime exploits is an ongoing research field with many solutions proposed over the last few years [42] The main di- rections are control-flow integrity (CFI) [1] and fine-grained code randomization [13, 27]|,Non-data,17
| The former ensures that a program only follows a valid path in the program’s CFG Many improvements have been made in the last years making CFI an efficient and ef- fective mitigation technology [47, 43] On the other hand, CFI does not cover non-control-data attacks which lead to execution of unauthorized but valid CFG paths The latter randomizes the code layout by randomizing the order of memory pages, functions, ba- sic blocks, or instructions [27]|,Non-data,17
| However, the attacker can still ex- ploit branch instructions to jump at her target address of choice As such, code randomization cannot provide control-flow information which would allow Ver to attest the program’s execution Another scheme is code-pointer integrity (CPI) [26] which aims at ensur- ing the integrity of code pointers While it provides high assurance against control-flow hijacking attacks, it does not provide any in- formation on the actual control-flow path taken|,Non-data,17
| As such, similar to CFI, CPI does not cover non-control data attacks Property-based attestation explores behavioral characteristics be- yond hash values of applications’ binaries [35] However, such schemes typically require a trusted third-party Software-based at- testation enables remote attestation for embedded devices without requiring a trust anchor [38]|,Non-data,17
| The measurement is based on the cal- culation of a hash over the application’s code memory, where the attestation is only successful if the prover responds in a certain time interval However, this assumes no noise on the channel, and re- quires the hash function to be optimal Semantic remote attestation enables attestation of program behavior by enforcing local policies at the Java bytecode layer [20] Unlike C-FLAT, neither property- based, semantic, nor software-based attestation cover control-flow attacks at the binary level|,Non-data,17
| There also exist several approaches to enable dynamic remote attestation: ReDAS [22] explores runtime properties such as the in- tegrity of a function’s base pointer While checking against such properties enhances static remote attestation, it only captures spe- cific application fields and pointers rather than the whole control- flow path Trusted virtual containers [6] allow control-flow attes- tation but at a coarse-grained level That is, they only attest the launch order of applications modules, but not the internal control flows of an application|,Non-data,17
| Lastly, DynIMA [17] explores taint anal- ysis to achieve runtime attestation However, its implementation only validates invariants on return instructions such as the number of instructions executed between two consecutive returns 10 CONCLUSION Memory corruption attacks are prevalent on diverse computing plat- forms and can lead to significant damage on embedded systems that are increasingly deployed in safety-critical infrastructures|,Non-data,17
| In par- ticular, there is not yet a mechanism that allows precise verification of an application’s control flow to detect such attacks C-FLAT tackles this problem by means of control-flow attestation allow- ing a verifier to detect control-flow deviations launched via code injection, code-reuse, or non-control-data attacks Our prototype implementation on an ARM-based Raspberry Pi demonstrates that C-FLAT can be leveraged to detect different runtime exploitation techniques launched against embedded software such as a syringe pump program, ie|,Non-data,17
|, C-FLAT detects when an attacker manipulates the amount of liquid dispensed through the syringe The source code of C-FLAT is available at https://googl/pTiVdU 11|,Non-data,17
| ACKNOWLEDGMENTS This work was supported in part by the Intel Collaborative Insti- tute for Secure Computing at TU Darmstadt and Aalto University This work was also supported in part by the Academy of Finland (283135), Tekes (1226/31/2014), the German Science Foundation (project S2, CRC 1119 CROSSING), the European Union’s Sev- enth Framework Programme (643964, SUPERCLOUD), and the German Federal Ministry of Education and Research within CRISP At UC Irvine, this research was supported by funding from the Na- tional Security Agency (H98230-15-1-0276) and the Department of Homeland Security (under subcontract from the HRL Laborato- ries) 12|,Non-data,17
|ABSTRACT Automatically analyzing information flow within Android applications that rely on cryptographic operations with their computational security guarantees imposes formidable chal- lenges that existing approaches for understanding an app’s behavior struggle to meet These approaches do not distin- guish cryptographic and non-cryptographic operations, and hence do not account for cryptographic protections: f (m) is considered sensitive for a sensitive message m irrespective of potential secrecy properties offered by a cryptographic operation f  These approaches consequently provide a safe approximation of the app’s behavior, but they mistakenly classify a large fraction of apps as potentially insecure and consequently yield overly pessimistic results In this paper, we show how cryptographic operations can be faithfully included into existing approaches for automated app analysis|,Non-data,21
| To this end, we first show how cryptographic operations can be expressed as symbolic abstractions within the comprehensive Dalvik bytecode language These ab- stractions are accessible to automated analysis and can be conveniently added to existing app analysis tools using mi- nor changes in their semantics Second, we show that our abstractions are faithful by providing the first computational soundness result for Dalvik bytecode, ie|,Non-data,21
|, the absence of at- tacks against our symbolically abstracted program entails the absence of any attacks against a suitable cryptographic program realization We cast our computational soundness result in the CoSP framework, which makes the result mod- ular and composable Keywords Android, Computational Soundness, Secure Information Flow 1 INTRODUCTION Android constitutes an open-source project not only in terms of source code but also in terms of the whole ecosys- tem, allowing practically everyone to program new apps and Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita- tion on the first page|,Non-data,21
| Copyrights for components of this work owned by others than ACM must be honored Abstracting with credit is permitted To copy otherwise, or re- publish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acm|,Non-data,21
|org CCS’16 October 24–28, 2016, Vienna, Austria c(cid:13) 2016 ACM ISBN 978-1-4503-4139-4/16/10 |,Non-data,21
  $1500 DOI: http://dxdoi,Non-data,21
|org/101145/29767492978418 make them publicly available in Google Play This open na- ture of Android has facilitated a rapid pace of innovation, but it has also led to the creation and widespread deploy- ment of malicious apps [1, 2]|,Non-data,21
| Such apps often cause privacy violations that leak sensitive information such as location or the user’s address book, either as an intended function- ality or as a result of uninformed programming In some cases such apps can even extract sensitive information from honest apps A comprehensive line of research has, hence, strived to rigorously analyze how apps are accessing and processing sensitive information These approaches typically employ the concept of information flow control (IFC), i|,Non-data,21
|e, certain information sources such as GPS position and address book are declared to be sensitive, and certain information sinks are declared to be adversarially observable An IFC-based analysis then traces the propagation of sensitive information through the program, ie|,Non-data,21
|, if sensitive data m is input to a function f , then the result f (m) is considered sensitive as well IFC-based analyses thereby determine if information from sensitive sources can ever reach an observable sink, and in that case report a privacy violation A considerable number of apps rely on cryptographic op- erations, eg|,Non-data,21
|, for encrypting sensitive information before it is sent over the Internet However, analyzing information flow within Android apps that rely on such cryptographic opera- tions with their computational security guarantees imposes formidable challenges that all existing approaches for auto- mated app analysis struggle to meet, eg, [3–5]|,Non-data,21
| Roughly, these approaches do not distinguish cryptographic opera- tions from other, non-cryptographic functions Thus, the standard information-tracing mechanism for arbitrary func- tions applies: f (m) is considered sensitive for a sensitive message m irrespective of potential secrecy properties of- fered by a cryptographic function f , eg, the encryption of a sensitive message m is still considered sensitive such that sending this encryption over the Internet is considered a privacy breach|,Non-data,21
| These approaches consequently provide a safe approximation of the app’s behavior, but they mistak- enly classify a large fraction of apps as potentially insecure and consequently yield overly pessimistic results While ap- proaches based on manual declassification have successfully managed to treat cryptographic operations and their protec- tive properties more accurately, see the section on related work for more details, no concept for an accurate crypto- graphic treatment is known for automated analysis of An- droid apps 71711 Our Contributions In this paper, we show how cryptographic operations can be faithfully included into existing approaches for automated app analysis on Android, in the presence of malicious apps or network parties aiming to extract sensitive information from honest parties|,Non-data,21
| Our paper makes two main tangible contributions to this field: (i) we show how cryptographic operations can be expressed as symbolic abstractions within Dalvik bytecode, so that existing automated analysis tools can adopt them with only minor changes in their seman- tics; and (ii) we show that our abstractions are faithful by providing the first computational soundness result for the comprehensive Dalvik bytecode language, ie, the absence of attacks against our symbolically abstracted program entails the absence of any attacks against a suitable cryptographic program realization Symbolic abstractions in Dalvik bytecode|,Non-data,21
| We first show how cryptographic operations can be expressed as sym- bolic abstractions within Dalvik bytecode These symbolic abstractions – often also referred to as perfect cryptogra- phy or Dolev-Yao models – constitute idealizations of cryp- tographic operations as free algebras that lend themselves towards automated analysis Deriving such abstractions within the comprehensive Dalvik bytecode language con- stitutes a challenging task, since existing formalizations of Dalvik do not offer a distinction between honest and adver- sarially controlled components, which is crucial for defining the rules that the symbolic adversary has to adhere to To this end, we develop a novel semantic characterization of Dalvik bytecode that we call split-state semantics that pro- vides a clear separation between honest program parts and cryptographic API calls with their corresponding augmented adversarial symbolic capabilities|,Non-data,21
| Moreover, this split-state form is key to our proof of computational soundness, see below Existing tools for automated app analysis can con- veniently include our abstractions using minor changes in their underlying semantics, and thereby reason more accu- rately about cryptographic operations Computational soundness for Dalvik bytecode We show that our symbolic abstractions can be securely instan- tiated using suitable cryptographic primitives, and thereby provide the first computational soundness result for Dalvik bytecode|,Non-data,21
| More specifically, our result is grounded in the Abstract Dalvik Language (ADL) [4], which constitutes the currently most detailed and comprehensive operational se- mantics for Dalvik in the literature To this end, we first ex- tended ADL by probabilistic choices, as it otherwise would be inappropriate to express cryptographic operations We cast our computational soundness result in CoSP, a framework for establishing computational soundness results that decouples the process of embedding programming lan- guages into CoSP from the computational soundness proofs itself In particular, by casting our soundness results in CoSP, a rich body of computational soundness results for in- dividual cryptographic primitves [6–11] is immediately valid for Dalvik bytecode without any additional work|,Non-data,21
| Establishing computational soundness results for Dalvik bytecode imposed a series of technical challenges that many prior computational soundness works did not have to cope with We highlight one such challenge Computational soundness results struggle when confronted with situations in which binary operations are applied to outputs of crypto- graphic operations, eg|,Non-data,21
|, if the parity of a ciphertext should be checked, since such an operation would be undefined in the symbolic setting Prior computational soundness results simply excluded programs with such illegitimate operations; this exclusion introduced an additional proof obligation for the automated analysis tool While excluding such programs simplifies the soundness result, integrating these additional proof obligations in existing automated app analysis tools constitutes a tedious task, since the tools would need to check upfront whether any symbolically undefined opera- tions will be performed on symbolic terms, in any execution branch As a consequence, we hence decided to establish a computational soundness result that over-approximates such scenarios by sending information of such illegitimate opera- tions to the adversary and letting the adversary decide the result of such operations|,Non-data,21
| Finally, our proof reveals an additional result that we con- sider of independent interest: we show that any small-step semantics S in split-state form entails a canonical small-step semantics S∗ for a symbolic model that is computationally sound with respect to S Hence, for establishing a computa- tionally sound symbolic abstraction for any given program- ming language, it suffices to show that the interaction with the attacker and the cryptographic API can be expressed by means of our concept of split-state semantics 12 Summary of Our Techniques This section summarizes the techniques that we use to achieve these results|,Non-data,21
| We hope that this summary makes the paper better accessible, given that it was distilled from a technical report spanning over roughly 50 pages [12] Fi- nally, we discuss how our results can be used to extend in- formation flow tools The CoSP framework A central idea of our work is to reduce computational soundness of Dalvik bytecode to com- putational soundness in the CoSP framework [6,10]|,Non-data,21
| All def- initions in CoSP are cast relative to a symbolic model that specifies a set of constructors and destructors that symbol- ically represent the cryptographic operations and are also used for characterizing the terms that the attacker can derive (called symbolic attacker knowledge), and a computational implementation that specifies cryptographic algorithms for these constructors and destructors In CoSP, a protocol is represented by an infinite tree that describes the protocol as a labeled transition system Such a CoSP protocol contains actions for performing abstract computations (applying con- structors and destructors to messages) and for communicat- ing with an adversary A CoSP protocol is equipped with two different semantics: (i) a symbolic CoSP execution, in which messages are represented by terms; and (ii) a compu- tational CoSP execution, in which messages are bitstrings, and the computational implementation is used instead of applying constructors and destructors|,Non-data,21
| A computational implementation is said to be computationally sound for a class of security properties if any CoSP protocol that satis- fies these properties in the symbolic execution also satisfies these properties in the computational execution The advan- tage of expressing computational soundness results in CoSP is that the protocol model in CoSP is very general so that the semantics of other languages can be embedded therein, thereby transferring the various established soundness re- sults from CoSP into these languages [6–11] 718ADL Semantics s Π2(cid:104)s2(cid:105) Π1(cid:104)s1(cid:105)≈ADL Lemma 3 Symbolic Split-State Π1(cid:104)s1(cid:105)≈SS s Π2(cid:104)s2(cid:105) Lemma 4 Symbolic CoSP Execution e(Π1(cid:104)s1(cid:105))≈CoSP s e(Π2(cid:104)s2(cid:105)) Theorem 1 Computational Soundness in CoSP ADL Semantics Π1(cid:104)s1(cid:105)≈ADL c Π2(cid:104)s2(cid:105) Lemma 2 Computational Π1(cid:104)s1(cid:105)≈SS c Π2(cid:104)s2(cid:105) Split-State Lemma 5 Computational CoSP Execution e(Π1(cid:104)s1(cid:105))≈CoSP c e(Π2(cid:104)s2(cid:105)) Figure 1: Overview of the main technical lemmas, where e is the embedding into CoSP Symbolic ADL and probabilistic choices ADL as de- fined in [4] does not support probabilistic choices, and hence no generation of cryptographic keys and no executions of cryptographic functions|,Non-data,21
| We thus extended ADL with a rule that uniformly samples random values (more concretely: a register value from the set of numerical values) We consider attackers that are external to the app, eg, malicious parties or network parties with the goal of ex- tracting secrets from an honest app|,Non-data,21
 We characterize the interaction points of the attacker with our extended version of ADL by a set of so-called malicious functions that com- municate with the attacker The attacker itself is modeled as a probabilistic polynomial-time machine We introduce an additional semantic rule that is applied whenever a ma- licious function is called The rule invokes the attacker with the arguments of the function call and stores the response of the attacker as a return value,Non-data,21
| For defining the indistin- guishability of two ADL programs, we additionally require that the adversary can also send a single bit b as a final guess, similar to other indistinguishability definitions This entails the notions of symbolic equivalence (≈ADL , in the symbolic setting) and of computational indistinguishability (≈ADL , in the computational setting) of two ADL programs s c Split-state semantics for symbolic ADL Establishing a computational soundness proof for ADL requires a clear separation between honest program parts and cryptographic API calls with their corresponding augmented adversarial symbolic capabilities|,Non-data,21
| To achieve this, we characterize this partitioning by introducing the concept of a split-state form of an operational semantics The split-state form partitions the original semantics into three components, parallelly ex- ecuted asynchronously: (i) all steps that belong to comput- ing cryptographic operations (called the crypto-API seman- tics), (ii) all steps that belong to computing the malicious functions (called the attacker semantics), and (iii) all steps that belong to the rest of the program (called the honest- program semantics) Moreover, we define explicit transitions between each of these components, which gives rise to a pre- cise message-passing interface for cryptographic operations and for communicating with the attacker Our strategy for showing computational soundness is to use this split-state form for phrasing the symbolic variant as a small-step semantics by replacing the crypto-API seman- tics with the symbolic constructors and destructors from the symbolic model, and by replacing the attacker seman- tics by the symbolic characterization of the attacker|,Non-data,21
| With this symbolic semantics at hand, we define split-state sym- bolic equivalence (≈SS s ) as equivalence of (sets of) traces However, as explained before, we first have to resolve the problem that computational soundness results struggle to deal with situations in which binary operations are applied to outputs of cryptographic operations We decided not to exclude programs that exhibit such behaviors, but to per- form an over-approximation instead by letting the adversary determine the outcome of such operations This makes our abstractions conveniently accessible for existing tools, but it also complicates the computational soundness proof since we have to consider the operations of constructors and destruc- tors on non-symbolic terms as well|,Non-data,21
| To this end, we encode them as bitstrings and interpret these bitstrings symboli- cally again Fortunately, symbolic bitstring interpretations can be seamlessly combined with all previous CoSP results We finally define computational indistinguishability of two honest program semantics in the split-state computational execution of ADL (≈SS c ) As usual, the adversary we con- sider is a probabilistic polynomial-time machine, and all se- mantics constitute families of semantics that are indexed by a security parameter|,Non-data,21
| It might be of independent interest that our symbolic vari- ant of the semantics and the computational indistinguisha- bility can be defined on the split-state form independently of ADL We show that ADL can be brought into such a split-state form, then prove later that symbolic equivalence in ADL implies symbolic equivalence in the split-state form, and conclude by proving that computational indistinguisha- bility in the split-state form implies computational indistin- guishability in ADL Hence, for every two ADL programs Π1, Π2 and initial configurations s1, s2 (Πi(cid:104)si(cid:105) denoting Πi with initial configuration si) we have Π1(cid:104)s1(cid:105)≈ADL Π1(cid:104)s1(cid:105)≈SS s Π2(cid:104)s2(cid:105) =⇒ Π1(cid:104)s1(cid:105)≈SS c Π2(cid:104)s2(cid:105) =⇒ Π1(cid:104)s1(cid:105)≈ADL s Π2(cid:104)s2(cid:105), and c Π2(cid:104)s2(cid:105) Computational soundness proof|,Non-data,21
| We first construct an injective embedding e that maps every ADL program to a CoSP protocol We stress that within CoSP, the same CoSP protocol is used for the computational and the symbolic ex- ecution and that CoSP requires a separation of the attacker and the cryptographic operations from the rest of the pro- gram Our split-state form precisely satisfies these require- ments The embedding e uses the honest-program semantics to iteratively construct a CoSP protocol: a transition to the crypto-API semantics corresponds to a computation node; a 719transition to the attacker semantics corresponds to an out- put node followed by an input node; and whenever several possibilities exist, a control node is selected to let the adver- sary decide which possibility (which node) to take|,Non-data,21
| We prove this embedding sound in the symbolic model, and we prove it complete with respect to the range of e in the computational model, ie, for every two ADL programs Π1, Π2 and initial configurations s1, s2 we have Π1(cid:104)s1(cid:105)≈SS s Π2(cid:104)s2(cid:105) =⇒ e(Π1(cid:104)s1(cid:105))≈CoSP s e(Π2(cid:104)s2(cid:105)) and e(Π1(cid:104)s1(cid:105))≈CoSP c e(Π2(cid:104)s2(cid:105)) =⇒ Π1(cid:104)s1(cid:105)≈SS c Π2(cid:104)s2(cid:105), where ≈CoSP computational indistinguishability in CoSP and ≈CoSP s c denote symbolic equivalence and Figure 1 finally shows how all pieces are put together: Theorem 1 (computational soundness of Dalvik – simplified)|,Non-data,21
| Let Π1, Π2 be two ADL programs that use the same crypto-API and s1, s2 be two initial configurations Then we have Π1(cid:104)s1(cid:105)≈ADL s Π2(cid:104)s2(cid:105) =⇒ Π1(cid:104)s1(cid:105)≈ADL c Π2(cid:104)s2(cid:105) Extension of information flow tools To put our work in perspective, we elaborate on a possible application of our result|,Non-data,21
| We envision the extension of information flow (IF) methods with symbolic abstractions On a high-level, we en- vision the following approach for extending IF-tools: when- ever there is a potential information flow from High to Low and a cryptographic function is called, we extract a model of the app and query a symbolic prover to find our whether the attacker learns something about the High values As in symbolic ADL only a few semantic rules are changed wr|,Non-data,21
|t ADL, modifications to existing analyses are likely to be con- fined, thus simple to integrate This approach imposes the challenge of extracting a model of the app Our embedding of an ADL program into CoSP already extracts a symbolic model for the program|,Non-data,21
| How- ever, shrinking this extracted model to a manageable size and querying the symbolic prover in a way such that it scales to complex apps is a task far from simple that merits a paper on its own 13 Overview Section 3 reviews the CoSP framework for equivalence properties that we ground our computational soundness re- sult on Section 4 reviews the Abstract Dalvik Language (ADL)|,Non-data,21
| Sections 5 and 6 define the probabilistic execution of ADL and introduce our symbolic variant of ADL, includ- ing the symbolic abstractions of cryptographic operations and the capabilities of the symbolic adversary Section 7 defines the connections between ADL, symbolic ADL, and CoSP, and based on these connections proves the compu- tational soundness result Section 8 discusses related work We conclude in Section 9 with a summary of our findings and outline directions for future research|,Non-data,21
| 2 NOTATION Let N be the set of natural numbers and assume that they begin at 0 For indicating that function f from a set A to a set B is a partial function, we write f : A (cid:42) B We use squared brackets in two different ways: (i) m[pp] denotes the instruction with the number pp for a set of instructions m, and (ii) r[v (cid:55)→ val ] := (r\(v, r(v)))∪(v, val) is short-hand for the function mapping v to val and otherwise behaving like r|,Non-data,21
| Throughout the paper, we use η as the security parameter We use ε to denote the empty sequence, empty path, empty bitstring, or empty action depending on the context We write t for a sequence t1,  |,Non-data,21
|  , tn if n is clear from the context For any sequence l ∈ E∗, we use · to denote concatenation l1 · l2, as well as the result of appending (l · e) or prepending (e · l) an element, as long as the difference is clear from context We filter a sequence l by a set S, denoted l||S, by removing each element that is not in S|,Non-data,21
| As we represent the attacker as a transition system, we sometimes write TA and sometimes A for the attacker 3 COSP FRAMEWORK (REVIEW) The computational soundness proof developed in this pa- per follows CoSP [6,10], a general framework for conducting computational soundness proofs of symbolic cryptography and for embedding these proofs into programming languages with their given semantics This section reviews the CoSP framework|,Non-data,21
| Symbolic Model & Execution In CoSP, symbolic ab- stractions of protocols and the attacker are formulated in a symbolic model M = (C, N, T, D): a set of free functions C, a countably infinite set N of nonces, a set T of terms, and a set D of partial mappings from terms to terms (called destructors) To unify notation, we introduce eval F (t): if F is a constructor, eval F (t) ··= F (t) if F (t) ∈ T and eval F (t) ··= ⊥ otherwise If F is a nonce, eval F () ··= F |,Non-data,21
| If F is a destructor, eval F (t) ··= F (t) if F (t) (cid:54)= ⊥ and eval F (t) ··= ⊥ otherwise Protocols In CoSP, protocols are represented as infinite trees with the following nodes: computation nodes are used for drawing fresh nonces and for applying constructors and destructors; input and output nodes are used for send and receive operations; control nodes are used for allowing the attacker to schedule the protocol A computation node is annotated with its arguments and has two outgoing edges: a yes-edge, used for the application of constructors, for draw- ing a nonce, and for the successful application of a destruc- tor, and a no-edge, used if an application of a constructor or destructor F on a term t fails, i|,Non-data,21
|ABSTRACT Coverage-based Greybox Fuzzing (CGF) is a random testing approach that requires no program analysis A new test is generated by slightly mutating a seed input If the test exercises a new and interesting path, it is added to the set of seeds; otherwise, it is discarded We observe that most tests exercise the same few “high-frequency” paths and develop strategies to explore significantly more paths with the same number of tests by gravitating towards low-frequency paths|,Non-data,22
| We explain the challenges and opportunities of CGF using a Markov chain model which specifies the probability that fuzzing the seed that exercises path i generates an input that exercises path j Each state (ie, seed) has an energy that specifies the number of inputs to be generated from that seed|,Non-data,22
| We show that CGF is considerably more e cient if en- ergy is inversely proportional to the density of the stationary distribution and increases monotonically every time that seed is chosen Energy is controlled with a power schedule We implemented the exponential schedule by extending AFL In 24 hours, AFLFast exposes 3 previously unreported CVEs that are not exposed by AFL and exposes 6 previously unreported CVEs 7x faster than AFL|,Non-data,22
| AFLFast produces at least an order of magnitude more unique crashes than AFL CCS Concepts: •Security and privacy!Vulnerability scanners; •Software and its engineering!Software testing and debugging; 1 INTRODUCTION “Ultimately, the key to winning the hearts and minds of practitioners is very simple: you need to show them how the proposed approach finds new, interesting bugs in the software they care about” – Michal Zalewski [27] Recently, there has been much debate about the e ciency of symbolic execution-based fuzzers versus more lightweight fuzzers|,Non-data,22
| Symbolic execution is a systematic e↵ort to stress di↵erent behaviors and thus considerably more e↵ective Yet, today most vulnerabilities are exposed by particularly light- weight fuzzers that do not leverage any program analysis [27] Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page Copyrights for components of this work owned by others than the author(s) must be honored|,Non-data,22
| Abstracting with credit is permitted To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acmorg|,Non-data,22
| CCS’16, October 24 - 28, 2016, Vienna, Austria c 2016 Copyright held by the owner/author(s) Publication rights licensed to ACM ISBN 978-1-4503-4139-4/16/10 |,Non-data,22
  $1500 DOI: http://dxdoi,Non-data,22
org/101145/29767492978428 It turns out that even the most e↵ective technique is less e cient than blackbox fuzzing if the time spent generating a test case takes relatively too long [3] Symbolic execution is very e↵ective because each new test exercises a di↵erent path in the program,Non-data,22
| However, this e↵ectiveness comes at the cost of spending significant time doing program analysis and constraint solving Blackbox fuzzing, on the other hand, does not require any program analysis and generates several orders of magnitude more tests in the same time Coverage-based Greybox Fuzzing (CGF) is an attempt to make fuzzing more e↵ective at path exploration without sacrificing time for program analysis CGF uses lightweight (binary) instrumentation to determine a unique identifier for the path that is exercised by an input|,Non-data,22
| New tests are gener- ated by slightly mutating the provided seed inputs (we also call the new tests as fuzz ) If some fuzz exercises a new and interesting path, the fuzzer retains that input; otherwise, it discards that input The provided and retained seeds are fuzzed in a continuous loop, contributing even more seeds Compared to symbolic execution, CGF does not require program analysis which brings several benefits|,Non-data,22
| There is no imprecision, for instance, in the lifting of the control-flow graph from the program binary or the encoding of the path condition as SMT formula CGF is more scalable because the time to generate a test does not increase with the pro- gram size CGF is highly parallelizable because the retained seeds represent the only internal state AFL implements the state-of-the-art of CGF, is behind hundreds of high-impact vulnerability discoveries [21], has been shown to generate valid image files (JPEGs) from an initial seed that is vir- tually empty [24], and has also been integrated with sym- bolic execution (which helps where AFL “gets stuck”) [19]|,Non-data,22
| Clearly, increasing the e ciency of fuzzers, like AFL, has a real and practical impact on vulnerability detection We discuss challenges of existing CGFs and opportunities to boost their e ciency by an order of magnitude Our key observation is that most fuzz exercises the same few paths: Existing CGFs generate too many inputs which stress the same behavior More e cient CGFs exercise more paths with the same amount of fuzz|,Non-data,22
| For instance, suppose we want to expose vulnerabilities in libpng Fuzzing a valid image file, there may be a 90% chance that a mutated variant exercises a path ⇡ which rejects invalid image files Fuzzing an invalid image file, there may be a 99999% chance that a mutated variant exercises the same path ⇡|,Non-data,22
| So, independent of the initial seed image files, an above-average amount of fuzz is bound to exercise that path ⇡ which rejects invalid inputs Informally, we call ⇡ a high-frequency path 1032In this paper, we propose several strategies to focus most of the fuzzing e↵ort on low-frequency paths so as to explore more paths with the same amount of fuzz The results are very encouraging|,Non-data,22
 Our AFL extension AFLFast discovered 9 vulnerabilities in GNU binutils which are now listed as CVEs in the US National Vulnerability Database AFLFast exposes 6 CVEs up to 14 times faster than AFL and exposes 3 CVEs that are not exposed by AFL in eight runs of 24 hours AFLFast reports an order of magnitude more unique crashes than AFL1 We will argue that our strategies have no detrimental impact on the e↵ectiveness of AFL,Non-data,22
| So, given more than 24 hours, AFL is expected to report the same unique crashes and expose the three remaining CVEs To explain the remarkable performance gains of AFLFast, we model Coverage-based Greybox Fuzzing (CGF) as Markov chain The chain specifies the probability pij that fuzzing the seed exercising path i generates an input exercising path j We let each state (i|,Non-data,22
|e, seed) have an energy that specifies the amount of fuzz that is generated by fuzzing that seed when it is chosen next For instance, the minimum energy required to discover a new and interesting path j by fuzzing the seed which exercises path i is expected to be p 1 ij  How- ever, in practice pij is clearly unknown|,Non-data,22
| The energy of a state is controlled by a pre-defined power schedule AFL implements a power schedule that assigns an energy that is constant in the number of times s(i) the seed has been chosen for fuzzing Almost every time the seed is chosen, the same number of inputs are generated In some cases, AFL might assign significantly more than the minimum energy re- quired to discover a new and interesting path; in other cases, AFL might assign not enough energy|,Non-data,22
| In contrast, AFLFast implements a power schedule that assigns an energy that is exponential in s(i) When the seed is fuzzed for the first time, very low energy is assigned Every time the seed is chosen thereafter, exponentially more inputs are generated up to a certain bound This allows to rapidly approach the minimum energy required to discover a new path|,Non-data,22
| In fact, AFL implements a power schedule that assigns constantly high energy Often, 80k inputs are generated for each seed which takes about one minute This addresses the problem of rapid mixing: Independent of the initial seed inputs, after a (burn-in) time some paths will always be ex- ercised by significantly more fuzz than others Assigning a lot of energy to the inital seeds allows to discover many more “neighbors” that exercise low -frequency paths|,Non-data,22
| For instance, it makes sense to fuzz a valid image file for the longest time with the objective to generate many more valid image files It is also a good idea to assign a lot of energy to these neigh- bors and their neighbors However, after some time, as more seeds are discovered, many seeds will start to exercise high- frequency paths and AFL ends up assigning way too much energy The chance to generate a valid image file is signifi- cantly lower if the latest seed is an invalid image file|,Non-data,22
| In contrast, AFLFast implements a power schedule that assigns energy that is inversely proportional to the density of the stationary distribution In other words, it assigns low energy to seeds exercising high-frequency paths and high energy to seeds exercising low-frequency paths We approx- imate the density of the stationary distribution by counting the number of fuzz f (i) that exercises path i 1AFL reports an input that exercises a new and interesting path and crashes the program (i|,Non-data,22
|e, which would otherwise be retained as new seed) as a unique crash AFL chooses seeds in the order they are added Once all seeds have been fuzzed, AFL resumes with the first|,Non-data,22
| A new cycle begins AFLFast e↵ectuates a di↵erent search strategy It chooses seeds in the order of their likely progressiveness (while choosing a seed only once per cycle) In the same cycle, AFLFast chooses seeds earlier i) that exercise lower- frequency paths and ii) that have been chosen less often|,Non-data,22
| The search strategy allows to fuzz the best seeds early on However, independent of the search strategy and given the same power schedule, when a cycle is completed the same seeds will have been fuzzed We note that power schedules and search strategies merely impact AFL’s e ciency (ie|,Non-data,22
|, #paths explored per unit time), not its e↵ectiveness (ie, #paths explored in expectation) Since we do not modify the mutation operators2 that are being used for fuzzing, the probability pij to discover path j by fuzzing the input exercising path i does not change from AFL to AFLFast|,Non-data,22
| In other words, AFLFast exposes exactly the same vulnerabilities as AFL – only significantly faster In summary, we argue that the e↵ectivness of symbolic ex- ecution stems from the systematic enumeration of paths in the program This allows to expose vulnerabilities that hide deep in the program Unfortunately, most fuzzers trade this systematic path coverage for scalability|,Non-data,22
| However, coverage- based greybox fuzzers maintain some of this e↵ectiveness by retaining fuzz that exercises paths that have previously not been exercised Each new seed results in progress towards generating even more seeds that exercise even“deeper”paths Still, even coverage-based fuzzers tend to visit certain paths with high frequency, generating too much fuzz that exer- cises the same few paths Our main conceptual contribution is to smartly control the amount of fuzz generated from a seed, thereby veering the search towards paths that are ex- ercised with low frequency, towards paths where vulnerabil- ities may lurk|,Non-data,22
| Technically, we achieve this enhanced path coverage using power schedules and search strategies that do not require program analysis Since CGF is highly paralleliz- able, an e ciency improvement of one order of magnitude for one AFL instance should result in an improvement of about 1 + log10(N ) orders of magnitude for N instances Specifically, our paper makes the following contributions: • Markov Chain Model We model coverage-based greybox fuzzing as a systematic exploration of the state space of a Markov chain|,Non-data,22
| We provide insight about the machinery that drives AFL, which is arguably the most successful vulnerability detection tool to date We uti- lize the model to explain the challenges of AFL and the remarkable performance gains of our tool AFLFast • Power Schedules We introduce and evaluate several strategies to control the number of inputs generated from a seed, with the objective to exercise a larger number of low-frequency paths in the same time|,Non-data,22
| • Search Strategies We devise and evaluate several strategies to control the order in which seeds are chosen for fuzzing, with the same objective • Tool We publish AFLFast as a fork of AFL|,Non-data,22
| AFLFast was used by Team Codejitsu who came in 2nd in terms of number of bugs found 3 at the DARPA Cyber Grand Challenge: https://githubcom/mboehme/aflfast 2AFL’s mutation operators include bit flips, boundary value substitution, simple arithmetics & block deletion/insertion 3See red result bar for Galactica at http://bitdo/cgcresults|,Non-data,22
 1033⌥ ⌃ 2 BACKGROUND 21 Coverage-based Greybox Fuzzing Fuzz – an automated random testing tool was first devel- oped by Miller et al [13] in early 1990s to understand the re- liability of UNIX tools,Non-data,22
| Since then, fuzzing has evolved sub- stantially, become widely adopted into practice, and exposed serious vulnerabilities in many important software programs [23, 25, 26, 22] There are three major categories depend- ing on the degree of leverage of internal program structure: black-box fuzzing only requires the program to execute [23, 25, 28] while white-box fuzzing [5, 11, 8, 9] requires binary lifting and program analysis, for instance, to construct the control-flow graph Greybox fuzzing is situated inbetween and uses only lightweight binary instrumentation to glean some program structure Without program analysis, grey- box fuzzing may be more e cient than whitebox fuzzing|,Non-data,22
| With more information about internal structure, it may be more e↵ective than blackbox fuzzing Coverage-based greybox fuzzers (CGF) [22] use lightweight instrumentation to gain coverage information For instance, AFL’s instrumentation captures basic block transitions, along with coarse branch-taken hit counts A sketch of the code that is injected at each branch point in the program is shown in Listing 1: 1 cur_location = < COMPILE_TIME_RANDOM >; 2 shared_mem [ cur_location ^ prev_location ]++; 3 prev_location = cur_location >> 1; Listing 1: AFL’s instrumentation|,Non-data,22
| The variable cur_location identifies the current basic block Its random identifier is generated at compile time Variable shared_mem[] is a 64 kB shared memory region Every byte that is set in the array marks a hit for a particular tuple (A, B) in the instrumented code where basic block B is ex- ecuted after basic block A|,Non-data,22
| The shift operation in Line 3 preserves the directionality [(A, B) versus (B, A)] A hash computed over the elements in shared_mem[] is used as the path identifier A CGF uses the coverage information to decide which gen- erated inputs to retain for fuzzing, which input to fuzz next and for how long Algorithm 1 provides a general overview of the process and is illustrated in the following by means of AFL’s implementation|,Non-data,22
| If the CGF is provided with seeds S, they are added to the queue T ; otherwise an empty file is generated as a starting point (lines 1–5) The seeds are choosen in a continuous loop until a timeout is reached or the fuzzing is aborted (line 7) AFL classifies a seed as a favorite if it is the fastest and smallest input for any of the control-flow edges it exercises AFL’s implementation of chooseNext mostly ignores non-favorite seeds|,Non-data,22
| For each seed input t, the CGF determines the number of inputs that are generated by fuzzing t (ie, #fuzz for t; line 8) AFL’s implementation of assignEnergy uses the execution time, block transition coverage, and creation time of t|,Non-data,22
| Then, the fuzzer generates p new inputs by mutating t according to defined mutation operators (line 10) AFL’s im- plementation of mutate input uses bit flips, simple arith- metics, boundary values, and block deletion and insertion strategies to generate new inputs4 4https://lcamtufblogspot|,Non-data,22
|sg/2014/08/ binary-fuzzing-strategies-what-workshtml ⌅ ⇧ add empty file to T Algorithm 1 Coverage-based Greybox Fuzzing Input: Seed Inputs S 1: T7 = ; 2: T = S 3: if T = ; then 4: 5: end if 6: repeat 7: 8: 9: 10: 11: 12: 13: 14: 15: 16: 17: until timeout reached or abort-signal Output: Crashing Inputs T7 t = chooseNext(T ) p = assignEnergy(t) for i from 1 to p do t0 = mutate input(t) if t0 crashes then else if isInteresting(t0) then add t0 to T7 add t0 to T end if end for If the generated input t0 is considered to be “interesting”, it is added to the circular queue (line 14) AFL’s implementa- tion of isInteresting returns true depending on the num- ber of times the basic block transitions, that are executed by t0, have been executed by other seeds in the queue More specifically, t0 is interesting if t0 executes a path where tran- sition b is exercised n times and for all other seeds t00 2 T that exercise b for m times, we have that blog2 nc 6= blog2 mc where b·c is the floor function|,Non-data,22
| AFL uses this “bucketing” to address path explosion [19] Intuitively, AFL retains inputs as new seeds that execute a new block transition or a path where a block transition is exercised twice when it is nor- mally exercised only once At the same time, AFL discards inputs that execute a path where some transition is exer- cised 102 times when it has previously been exercised 101 times If the generated input t0 crashes the program, it is added to the set T7 of crashing inputs (line 12)|,Non-data,22
| A crashing input that is also interesting is marked as unique crash Binary instrumentation AFL supports both, source code instrumentation and binary instrumentation via QEMU [1] While QEMU does the instrumentation during interpreta- tion at runtime, AFLDynInst [20] injects the instrumenta- tion shown in Listing 1 directly into the binary|,Non-data,22
 Modifications Our changes of AFL concern only the func- tions chooseNext which implements the search strategy and assignEnergy which implements the power schedules 22 Markov Chain A Markov chain is a stochastic process that transitions from one state to another [14],Non-data,22
| At any time, the chain can be in only one state The set of all states is called the chain’s state space The process transitions from one state to an- other with a certain probability that is called the transition probability This probability depends only upon the current state rather than upon the path to the present state|,Non-data,22
| More formally, a Markov chain is a sequence of random variables {X0, X1,    , Xn} where Xi describes the state of the process at time i|,Non-data,22
| Given a set of states S = {1, 2,    , N} for some N 2 N, the value of the random variables Xi are taken from S|,Non-data,22
| The probability that the Markov chain starts out in state i is given by the initial distribution P(X0 = i) 1034The probability matrix PPP = (pij) specifies the transition rules If ||S|| = N , then PPP is a N ⇥N stochastic matrix where each entry is non-negative and the sum of each row is 1 The conditional probability pij defines the probability that the chain transitions to state j at time t + 1, given that it is in state i at time t, pij = P(Xt+1 = j || Xt = i) A Markov chain is called time-homogeneous if the proba- bility matrix (pij) does not depend on the time n|,Non-data,22
| In other words, every time the chain is in state i, the probability of jumping to state j is the same If a Markov chain is time homogeneous, then the vector ⇡⇡⇡ is called a stationary distribution of the Markov chain if for all j 2 S it satisfies 0  ⇡j  1 ⇡i 1 =Xi2S ⇡j =Xi2S ⇡ipij Informally, a Markov chain {X0, X1,   |,Non-data,22
| , Xn} is called rapidly mixing if Xn is “close” to the stationary distribution for a su ciently low number of steps n In other words, rapidly mixing Markov chains approach the stationary distribution within a reasonable time – independent of the initial state Random walkers sample the distribution that is described by a Markov chain A walker starts at a state according to the initial distribution and transitions from one state to the next according to the transition probabilities|,Non-data,22
| The state at which the walker arrives after n steps is considered a sample of the distribution There may be an ensemble of walkers that move around randomly For instance, the crawling of web pages can be modelled as Markov chain Pages are the states while the links are the transitions|,Non-data,22
| Given page i with qi links where one link goes to page j, the probability pij that a random surfer reaches j from i in one click is pij = 1/qi A crawler, like Google, seeks to index the important pages of the internet Brin and Page [4] developed an algorithm, called PageRank that assigns an importance score to each page Intuitively, the PageRank value of a page measures the chance that a random surfer will land on that page after a sequence of clicks|,Non-data,22
| More formally, the PageRank approximates the density of the stationary distribution of the Markov chain where important pages are located in high-density regions 3 MARKOV CHAIN MODEL In this paper, we model the probability that fuzzing a seed which exercises program path i generates a seed which exer- cises path j as transition probability pij in a Markov chain This allows us to discuss the objective of greybox fuzzing as the e cient exploration of the chain’s state space and to explain the challenges and opportunities of CGF and of AFL specifically|,Non-data,22
| We argue that a coverage-based greybox fuzzer exercises more distinct paths per unit time if it does focus on inputs in low-density regions of the Markov chain Hence, we devise several strategies to bias the traversal to- wards visiting more states in low-density regions and less states in high-density regions of the stationary distribution Before discussing these strategies, we introduce the Markov chain model 3|,Non-data,22
|1 Coverage-based Fuzzing as Markov Chain Time-inhomogeneous model Suppose, after providing the fuzzer with an initial seed input t0 that exercises path 0, the fuzzer immediately explores path i + 1 by randomly mu- tating the previous input ti which exercises path i Every input that is generated is directly chosen as next seed The sequence of paths that the fuzzer exercises is described by a Markov chain|,Non-data,22
| The transition probability pij is defined as the probability to generate an input that exercises path j by randomly mutating the previous input ti that exercises path i Clearly, this Markov chain is not time-homogeneous The transition probability pij depends on the path in the Markov chain by which the state i was reached Say, a di↵erent input t0i is fuzzed that also exercises path i, the probability pij to generate an input that exercises path j might be very di↵erent|,Non-data,22
| While this is still a Markov chain, it is not time-homogeneous The analysis is di cult and the existence of a stationary distribution is not guaranteed Time-homogeneous model A stationary distribution does exist for the following model of coverage-based fuzzing|,Non-data,22
| The state space of the Markov chain is defined by the discovered paths and their immediate neighbors Given seeds T , let S+ be the set of (discovered) paths that are exercised by T and S be the set of (undiscovered) paths that are exercised by inputs generated by randomly mutating any t 2 T 5 Then the set of states S of the Markov chain is given as S = S+ [ S  The probability matrix P = (pij) of the Markov chain is de- fined as follows If path i is a discovered path exercised by ti 2 T (i|,Non-data,22
|e, i 2 S+), then pij is the probability that ran- domly mutating seed ti generates an input that exercises the path j Else if path i is an undiscovered path that is not ex- ercised by some t 2 T (ie|,Non-data,22
|, i 2 S ), then pii = 1 Ptj2T pji and pij = pji for all tj 2 T  In other words, without loss of generality we make the following two assumptions We assume that generating an input that exercises path j from (undiscovered) seed ti is as likely as generating from seed tj an input that exercises (undiscovered) path i We also assume that i 2 S has no other undiscovered neighbors|,Non-data,22
| The stationary distribution ⇡⇡⇡ of the Markov chain gives the probability that a random walker that takes N steps spends roughly N⇡ i time periods in state i In other words, the proportion of time spent in state i converges to ⇡i as N goes to infinity We call a high-density region of ⇡⇡⇡ a neighborhood of paths I where μi2I (⇡i) > μtj2T (⇡j) and μ is the arithmetic mean Similarly, we call a low-density region of ⇡⇡⇡ a neighborhood of paths I where μi2I (⇡i) < μtj2T (⇡j)|,Non-data,22
 It is not di cult to see that a greybox fuzzer is more likely to exercise paths in a high-density region of ⇡⇡⇡ than in a low- density region Note that we get a new Markov chain once an undiscovered path i 2 S is discovered Energy & Power Schedules We let each state s 2 S+ have an energy,Non-data,22
| The energy of state i determines the number of inputs that should be generated by fuzzing the seed ti when ti is next chosen from the queue T  The energy of a state is controlled by a pre-defined power schedule Note that energy is a local property specific to a state (unlike temperature in simmulated annealing) In Algorithm 1, the power schedule is implemented by the function assignEnergy|,Non-data,22
| 5An input ti is randomly mutated using mutate_input on ti in Algorithm 1 1035s e s a C  t s e T  f o  r e b m u N 105 104 103 102 101 100 ●● ● ● ●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●● ●●●●●●●●●● ●●●●●●●●●● mean = 1288 0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 Path Index ●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●● Figure 1: #Fuzz exercising a path (on a log-scale) after running AFL for 10 minutes on the nm-tool Long tails In our experiments, we observe several notable properties of the Markov chain model of coverage-based grey- box fuzzing|,Non-data,22
| For one, the stationary distribution has a large number of very-low-density regions and a small number of very-high-density regions As shown in Figure 1, 30% of the paths are exercised by just a single generated test input while 10% of the paths are exercised by 1k to 100k generated test inputs In other words, most inputs exercise a few high- frequency paths Often, these inputs are invalid while the few inputs exercising the low-frequency paths are valid and interesting|,Non-data,22
| Basically, almost each valid input would exercise di↵erent behavior Hence, in this paper we devise strategies to explore such low-density regions more e ciently Rapid mixing Moreover, such Markov chains are mostly rapidly mixing|,Non-data,22
| Given our exploration objective, this is most unfortunate It takes only a few transitions to “forget” the initial state and arrive in a high-density region that is visited by most walkers After a few transitions, the probability that the current state corresponds to a high-frequency path is high, no matter whether the walker started with an initial seed that exercises a low-frequency path or not, or whether the walker started with a valid or an invalid input Benefits|,Non-data,22
| The Markov chain model of coverage-based grey- box fuzzing has several benefits For example, it opens fuzzing for the e cient approximation of numerical program properties, such as the worst-case or average execution time or energy consumption There exist several Markov Chain Monte Carlo (MCMC) methods, like Simulated Annealing [12] that o↵er guarantees on the convergence to the actual value In the context of vulnerabilty research, the Markov chain model allows to explain the challenges and opportuni- ties of existing coverage-based fuzzers, such as AFL|,Non-data,22
| 32 Running Example On a high level, we model the probability that fuzzing a test input t 2 T which exercises some path i generates an input which exercises path j as transition probabilities pij in a Markov chain We illustrate this model using the simple program in Listing 2 which takes as input a 4-character word and crashes for the input “bad!” ⌥ 1 void crashme ( char * s ) { 2 if ( s [0] == ’b ’) 3 4 5 6 7 }⌃ if ( s [1] == ’a ’) if ( s [2] == ’d ’) if ( s [3] == ’! ’) abort () ; Listing 2: Motivating example|,Non-data,22
 The program has five execution paths Path 0 (****) is executed by all strings that do not start with the letter ’b’ Path 1 (b***) is executed by all strings starting with “b” that do not continue with the letter ’a’ Path 2 (ba**) is executed by all strings starting with“ba” that do not continue with the letter ’d’,Non-data,22
| Path 3 (bad*) is executed by all strings starting with “bad” that do not continue with the letter ’ !’ Finally, Path 4 is executed only by the input “bad!” Now, let us specify the implementation of mutate input (MI ) in Algorithm 1 to modify a seed input s = hc0, c1, c2, c3i to generate new inputs MI chooses with equal probability a character c from s and substitutes it by a character that is randomly chosen from the set of 28 ASCII characters|,Non-data,22
| For example, the word “bill” exercises Path 1 With probability 1/4, MI chooses the second character c1 and with probabil- ity 1/28 it chooses the letter ’a’ for the substitution With a total probability of 210, MI generates the word “ball” from “bill” as the next test input which exercises Path 2 **** 1  2 10 2 10 b*** 3 4 2 10 ba** 1 4  2 10 1 2 + 2 10 2 10 bad* 1 4 + 2 9 2 10 bad! 2 8 Figure 2: Markov chain for motivating example Figure 2 represents the simplified transition matrix pij as a state diagram|,Non-data,22
|6 For example, if the current input is the word “bill”, the Markov Chain is in the state b*** The like- lihood to transition to the state ba** is 2 10 as explained earlier In other words, on average it takes 210 = 1024 exe- cutions of MI on the word “bill” to exercise Path 3 and reach state ba** Given the word “bill”, the likelihood to transi- tion to the same state b*** is 0|,Non-data,22
75 because MI may choose the first letter and ’b’ as substitute or the second letter and any letter except ’a’ as substitute with a total probability of 025 and it may choose the third or fourth letter with a total probability of 05 The probability to transition to state **** is 1/4  2 10 because MI may choose the first of four letters and substitute it with any letter except ’b’,Non-data,22
| Notice that there is a very high probability density in state **** Most 4-character words do not start with ’b’ such that the initial distribution is heavily biased towards that state The random walker can transition to the next state only with probability 2 10, stays in b*** with probability 3/4 and comes back to the state **** with the approximate probability 1/4 Many inputs will be generated until the walker reaches the state bad!|,Non-data,22
| 6For simplicity, we ignore some low probability transitions, eg, from state **** to state bad! ⌅ ⇧ 10363|,Non-data,22
|3 Challenges of Coverage-based Fuzzers A coverage-based greybox fuzzer is an ensemble of random walkers in the Markov chain There is one walker for each seed t 2 T  The objective is to discover an interesting path s 2 S that is not exercised by any t 2 T while generating a minimal number of inputs Conceptually, all walkers can move simultaneously|,Non-data,22
| Technically, resources are limited and we need to choose which walker can move and how often In a sequential setting, the fuzzer chooses the next input to fuzz t 2 T according to chooseNext and generates as many in- puts as determined by p = assignEnergy(t) in Algorithm 1 Usually, p < M where M 2 N gives an upper bound on the number of generated inputs In AFL, M ⇡ 160k|,Non-data,22
| More Energy Than Needed AFL implements a schedule that assigns energy that is constant in the number of times the corresponding seed has been chosen from the queue Let Xij be the random variable that describes the minimum energy that should be assigned to state i 2 S+ so that the fuzzer discovers the new state j 2 S where pij > 0 Then, E[Xij] = 1 pij Now, AFL’s constant schedule might assign significantly more or significantly less energy than is actually required|,Non-data,22
| Example Let AFL’s power schedule assign an energy of p(i) = 216 = 64k to a state i every time ti is chosen Since most 4-character words do not start with ’b’, the first input t0 likely exercises Path 0 After 216 inputs have been gener- ated by fuzzing t0, several inputs are expected to begin with the letter ’b’|,Non-data,22
| One input that exercises Path 1 is retained as seed t1 After another 216 inputs have been generated by fuzzing t1, at least one input is expected to exercise Path 2 and is retained as t2 Figure 3 shows how the procedure con- tinues After a total of 256k inputs were generated from the four seeds that were retained for each path, the crashing in- put is found|,Non-data,22
| A more e cient fuzzer would need to generate no more than E[X01]+E[X12]+E[X23]+E[X34] = 4·210 = 4k inputs to expose the same vulnerability #Total Tests State Explored States 1 216 + 1 2 · 216 + 1 3 · 216 + 1 4 · 216 + 1 **** b*** ba** bad* bad! **** ****, b*** ****, b***, ba** ****, b***, ba**, bad* ****, b***, ba**, bad*, bad! Figure 3: The crash is found after 218 = 256k inputs were generated by fuzzing when p = 216 is constant Excessive Energy for High-Density Regions AFL’s power schedule also assigns constantly high energy: Fuzzing a seed input often takes about a minute on our machine|,Non-data,22
| This addresses the problem of rapid mixing Initial seeds are of- ten provided such that they exercise interesting paths in a low-density region in the stationary distribution of the Markov chain Assigning high energy to the inital seeds and the seeds in the immediate neighborhood allows to discover many more neighbors in the same low-density region How- ever, as the retained inputs exercise paths in high-density regions – and there is a natural tendency – too much energy is assigned to these states|,Non-data,22
| By definition, the higher the den- sity of the stationary distribution of the Markov chain for the given state i, the higher the proportion of inputs gener- ated by fuzzing ti that will exercise high-frequency paths State ba** **** b*** ba** **** b*** bad* ba** **** b*** bad* 1 2 3 4 5 6 7 8 9 10 11 **** 1 · 27 5 · 27 6 · 27 7 · 27 11 · 27 12 · 27 13 · 27 14 · 27 18 · 27 19 · 27 20 · 27 b*** 1 · 27 1 · 27 4 · 27 5 · 27 5 · 27 8 · 27 9 · 27 10 · 27 10 · 27 13 · 27 14 · 27 ba** 2 · 27 2 · 27 2 · 27 4 · 27 4 · 27 4 · 27 5 · 27 7 · 27 7 · 27 7 · 27 8 · 27 bad* 0 0 0 1 1 1 1 · 27 1 · 27 1 · 27 1 · 27 2 · 27 bad! 0 0 0 0 0 0 0 0 0 0 1 Figure 4: Total #fuzz exercising the corresponding path when fuzzing the given state Too much energy assigned to state **** and not enough to state bad* once it is discovered Lines indicate new cycles|,Non-data,22
 Example Let the initial seed input be the word ball and let AFL’s power schedule assign an energy of p(i) = 29 = 512 to a state i every time ti is chosen This allows us to discuss the case where the next state is not found in a single fuzzing iteration and several cycles through the circular queue might be required Recall that AFL chooses the seeds in the order they are added,Non-data,22
| Figure 4 elaborates the example After fuzzing the initial seed input for 29 times, two new seeds are discovered About one quarter of the fuzz (ie|,Non-data,22
|, 27 inputs) exercises paths **** and b***, respectively (see Fig 2 and Fig 4, Row 1) Fuzzing the first discovered seed (Row 2), all fuzz exercises the same path|,Non-data,22
| Fuzzing the second discovered seed (Row 3), a quarter of the fuzz exercises path **** and three quarters exercises path b*** Since no new seeds are discovered, a new cycle begins with the initial seed (Row 4) This procedure continues until the vulnerability is exposed (Row 11) In each row we see that most fuzz exercises path ****|,Non-data,22
| Evidently, the fuzzer spends way too much time exercising this high-frequency path The same time would be better spent fuzzing the seed exercising the low-frequency path bad* In summary, two challenges of existing coverage-based greybox fuzzers are: Their power schedules 1 may assign more energy than is required in expectation to discover a new and interesting path and 2|,Non-data,22
| may assign too much energy to states in high-density regions of the chain’s stationary distribution and not enough energy to states in low-density regions 4 BOOSTING GREYBOX FUZZING A more e cient coverage-based greybox fuzzer discovers an undiscovered state in a low-density region while assigning the least amount of total energy More specifically, 1|,Non-data,22
 Search Strategy The fuzzer chooses i 2 S+ such that 9j 2 S where ⇡j is low and E[Xij] is minimal 2 Power Schedule,Non-data,22
| The fuzzer assigns the energy p(i) = E[Xij] to the chosen state i in order to limit the fuzzing time to the minimum that is required to be expected to discover a path in a low-density region In this paper, we propose monotonous power schedules that first assign low energy which monotonously increases every time the corresponding seed is chosen from the queue This allows to rapidly approach E[Xij] Moreover, our power schedules assign energy that is inversely proportional to the density of the stationary distribution of the Markov chain|,Non-data,22
| 1037Intuitively, as soon as a new path is discovered, we want to swiftly explore its general neighborhood expending only low energy This allows us to get a first estimate of whether i lives in a high-density region Every time i is chosen there- after, it is assigned more energy Intuitively, after the neigh- borhood is explored and it is established that i lives in a low- density region, the fuzzer can invest significantly more en- ergy trying to find paths in the low-density neighborhood of i|,Non-data,22
| We also propose and evaluate search strategies that are aimed at the fuzzer expending most energy for paths in low- density regions For instance, to establish whether a state is in a low-density region, we prioritize such t 2 T that have been chosen from the circular queue least often and such t that exercise paths that have least often been exercised by other generated test inputs 41 Power Schedules A power schedule regulates the energy p(i) of a state|,Non-data,22
| More specifically, a power schedule decides how many in- puts are generated by fuzzing the seed ti 2 T which exer- cises path i when ti is selected next In general, p(i) is a function of a) the number of times s(i) that ti has previ- ously been choosen from the queue T and b) the number of generated inputs f (i) that exercise i In fact, f (i) serves as approximation of the distribution’s density We discuss and evaluate several power schedules|,Non-data,22
| The exploitation-based constant schedule (EXPLOIT) is implemented by most greybox fuzzers After some burn- in, the assigned energy is fairly constant every time s(i) that ti is being chosen from the circular queue The energy p(i) for state i is computed as p(i) = ↵(i) eg|,Non-data,22
|, for AFL (1) where ↵(i) is the CGF’s present implem of assignEnergy in Algorithm 1 and remains constant as s(i) orf (i) varies For instance, AFL computes ↵(i) depending on the execution time, block transition coverage, and creation time of ti The example in Figure 3 is derived using a constant schedule|,Non-data,22
 The exploration-based constant schedule (EXPLORE) is a schedule that assigns constant but also fairly low energy The energy p(i) for state i is computed as p(i) = ↵(i)   (2) where ↵(i)/ maintaints the fuzzer’s original judgement ↵(i) of the quality of ti and where > 1 is a constant Cut-O↵ Exponential (COE) is an exponential schedule that prevents high-frequency paths to be fuzzed until they become low-frequency paths The COE increases the fuzzing time of ti exponentially each time s(i) that ti is chosen from the circular queue,Non-data,22
| The energy p(i) is computed as p(i) =(0 min⇣ ↵(i)  · 2s(i), M⌘ if f (i) > μ otherwise (3) where ↵(i) maintaints the fuzzer’s original judgement and > 1 is a constant that puts the fuzzer in exploration mode for ti that have only recently been discovered (ie, s(i) is low), and where μ is the mean number of fuzz exercising a discovered path μ = Pi2S+ f (i) ||S+|| where S+ is the set of discovered paths|,Non-data,22
| Intuitively, high- frequency paths where f (i) > μ that receive a lot of fuzz even from fuzzing other seeds are considered low-priority and not fuzzed at all until they are below the mean again The constant M provides an upper bound on the number of inputs that are generated per fuzzing iteration #Tests State Explored States 1 210 2 · 210 3 · 210 4 · 210 **** b*** ba** bad* bad! **** ****, b*** ****, b***, ba** ****, b***, ba**, bad* ****, b***, ba**, bad*, bad! Figure 5: The crash is found after 212 = 4k inputs were generated by fuzzing with a power schedule Example|,Non-data,22
| Figure 5 depicts the states that a greybox fuzzer explores with the COE power schedule with ↵(i)/ = 1 The first test input is chosen at random from the program’s input space Since most 4-character words do not start with ’b’, the first input t0 likely exercises path 0 which corresponds to state **** The first time that t0 is fuzzed, s(0) = 0 and f (0) = μ = 1 so that ↵(0) = 20|,Non-data,22
| Next time, s(0) = 1 and f (0) = μ = 2 so that ↵(0) = 21 When s(0) = 9 and ↵(0) = 29, 210 test inputs will be generated so that one generated test input t1 is expected to start with the letter ’b’ and the state b*** is discovered (see Fig 2) Now, the newly discovered state is assigned low energy ↵(1) = 20|,Non-data,22
| However, f (0) > μ so that soley t1 will be fuzzed in a similar fashion as t0 until s(1) = 9, ↵(1) = 29 and 210 test inputs have been generated by fuzzing t1 Again, one test input is expected to start with “ba” and the state ba** is discovered Table 5 shows how the procedure continues After 4k test inputs were generated from the four inputs that were retained for each path, the crashing input is found|,Non-data,22
| The random generation of the same string would require five orders of magnitude more inputs on average (4·106k random inputs) while the constant schedule in Figure 3 would require one order of magnitude more test inputs on average (256k) The exponential schedule (FAST) is an extension of COE Instead of not fuzzing ti at all if f (i) > μ, the power sched- ule induces to fuzz ti inversely proportional to the amount of fuzz f (i) that exercises path i The energy p(i) that this schedule assigns to state i is computed as p(i) = min✓ ↵(i)  · 2s(i) f (i) , M◆ (4) Intuitively, f (i) in the denominator allows to exploit ti that have not received a high number of fuzz in the past and is thus more likely to be in a low-density region|,Non-data,22
 The expo- nential increase with s(i) allows more and more energy for paths were we are more and more confident that they live in a low-density region The linear schedule (LINEAR) increases the energy of a state i in a linear manner wrt,Non-data,22
| the number of times s(i) that ti has been chosen from T , yet is also inversely proportional to the amount of fuzz f (i) that exercises path i p(i) = min✓ ↵(i)  · s(i) f (i) , M◆ (5) 1038The quadratic schedule (QUAD) increases the energy of a statei in a quadratic manner wrt|,Non-data,22
| the number of times s(i) that ti has been chosen from T , yet is also proportional to the amount of fuzz f (i) that exercises path i The energy p(i) for state i is computed as p(i) = min✓ ↵(i)  · s(i)2 f (i) , M◆ (6) 42 Search Strategies While a power schedule regulates the time spent fuzzing a seed, a search strategy decide which seed is chosen next The decision is purely based on the number the number of times a seed has been fuzzed before and the amount of fuzz exer- cising the same path as the seed|,Non-data,22
| An e cient coverage-based greybox fuzzer prioritizes inputs that have not been fuzzed very often and inputs that exercise low-frequency paths Prioritize small s(i)s(i)s(i) This strategy chooses ti 2 T such that the number of times s(i) that ti has been fuzzed is mini- mal However, the fuzzer may still decide to skip the choosen test input, for instance if it is not a designated favourite|,Non-data,22
| In that case, the search strategy is applied again until the fuzzer does not skip the input E↵ectively, the queue is reordered using the search strategy Intuitively, the fuzzer can estab- lish early whether or not path i is a low-frequency path and whether it should invest more energy into fuzzing ti Prioritize small f (i)f (i)f (i)|,Non-data,22
| This strategy chooses ti 2 T such that the number f (i) of generated inputs that exercise path i is minimal The fuzzer may skip the chosen test input, for instance if it is not a designated favourite, until finally an input is chosen according to the search strategy and accepted for fuzzing Intuitively, fuzzing an input that exercises a low-frequency path might generate more inputs exercising low-frequency paths 4|,Non-data,22
3 Implementation of AFLFast AFL is a coverage-based greybox fuzzer that collects infor- mation on the basic block transitions that are exercised by an input AFL’s binary instrumentation is discussed in Sec- tion 21,Non-data,22
| In our experiments, we extended version 194b AFL implements certain strategies to select “interesting” in- puts from the fuzz to add to the queue We did not change this functionality|,Non-data,22
 AFL addresses path explosion by “buck- eting” – the grouping of paths according to the number of times all executed basic block transitions are exercised We did not change this functionality either All changes were made to assignEnergy and chooseNext in Algorithm 1 Changes for Power Schedule,Non-data,22
| We changed the computation of the amount of fuzz p(i) that is generated for an input ti Firstly, AFL computes p(i) depending on execution time, transition coverage, and creation time of ti Essentially, if it executes more quickly, covers more, and is generated later, then the number of fuzz is greater We maintain this eval- uation in the various power schedules discussed above|,Non-data,22
| Sec- ondly, AFL executes the deterministic stage the first time ti is fuzzed Since our power schedules assign significantly less energy for the first stage, our extension executes the deter- ministic stage later when the assigned energy is equal to the energy spent by deterministic fuzzing Lastly, AFL might initially compute a low value for p(i) and then dynamically increase p(i) in the same run if “interesting” inputs are gen- erated Since our implementation controls p(i) via a power schedule, we disabled this dynamic increase for AFLFast|,Non-data,22
| Changes for Search Strategy We changed the order in which AFL chooses the inputs from the queue and how AFL designates “favourite” inputs that are e↵ectively exclusively chosen from the queue Firstly, for all executed basic block transitions b, AFL chooses as favourite the fastest and small- est inputs executing b AFLFast first chooses the input ex- ercising b with the smallest number of time s(i) that it has been chosen from the queue, and if there are several, then the input that exercises a path exercised by the least amount of fuzz f (i), and if there are still several, then the fastest and smallest input|,Non-data,22
| Secondly, AFL chooses the next favourite in- put which follows the current input in the queue AFLFast chooses the next favourite input with the smallest number of time s(i) that it has been chosen from the queue and if there are several, it chooses that which exercises a path exercised by the least amount of fuzz f (i) 5 EVALUATION 5|,Non-data,22
|1 Vulnerabilities We chose GNU binutils as subject because it is non-trivial and widely used for the analysis of program binaries It con- sists of several tools including nm, objdump, strings, size, and c++filt We zoom into some results by discussing the results for nm in more detail7 Binutils is a di cult subject because the fuzzer needs to generate some approximation of a program binary in order to exercise interesting behav- iors of the programs|,Non-data,22
| We found a large number of serious vulnerabilities and several bugs (listed in Table 1) Type Exploitable Bu↵er Overflow Invalid Write due to a Use-After-Free Invalid Write due to a Use-After-Free Invalid Write due to Integer Overflow Table 1: CVE-IDs and Exploitation Type Vulnerability CVE-2016-2226 CVE-2016-4487 CVE-2016-4488 CVE-2016-4489 CVE-2016-4490 Write Access Violation CVE-2016-4491 Various Stack Corruptions CVE-2016-4492 Write Access Violation CVE-2016-4493 Write Access Violation CVE-2016-6131 Bug 1 Bug 2 Bug 3 Stack Corruption Bu↵er Overflow (Invalid Read) Bu↵er Overflow (Invalid Read) Bu↵er Overflow (Invalid Read) All vulnerabilities were previously unreported and rated as medium security risk We informed the maintainers, sub- mitted patches, and informed the security community via the ossecurity mailing list8 Mitre assigned nine (9) CVEs|,Non-data,22
| At the time of writing, all but one patches have been ac- cepted while one is still under review These vulnerabilities a↵ect most available binary analysis tools including valgrind, gdb, binutils, gcov and other libbfd-based tools An at- tacker might modify a program binary such that it executes malicious code upon analysis, eg|,Non-data,22
|, an analysis to identify whether the binary is malicious in the first place or during the attempt of reverse-engineering the binary Measure of #paths AFL maintains a unique path inden- tifier cksum for each input in the queue that is computed as a hash over the shared memory region that has a bit set for each basic block transition that is exercised by t We imple- mented a map {(cksum(i), f (i)) || ti 2 T} that keeps track of the number of generated (and potentially discarded) inputs for each exercised path|,Non-data,22
 7Manual analysis and patching of 12k plus unique crashes took much time and hence was done for one program 8http://wwwopenwall,Non-data,22
|com/lists/oss-security/2016/05/05/3 1039Measure of #crashes AFL defines unique crash as follows If two crashing inputs exercise a path in the same “bucket”, then both inputs e↵ectively expose the same unique crash Experimental Infrastructure|,Non-data,22
| We ran our experiments on a 64-bit machine with 40 cores (26 GHz Intel R Xeon R E5- 2600), 64GB of main memory, and Ubuntu 1404 as host OS We ran each experiment at least eight times for six or 24 hours|,Non-data,22
| We ran 40 experiments simultaneously, that is, one experiment was run on one core For each exper- iment, only one seed input is provided — the empty file Time is measured using unix time stamps We tested nm -C, objdump -d, readelf -a, and the others without options|,Non-data,22
| 52 General Results s e h s a r C e u q n U   i  f o  r e b m u N c++filt readelf 1000 10 1000 10 0 2 4 6 0 nm size objdump strings 2 4 Time (in hours) 6 0 2 4 6 Figure 6: #Crashes over time (on a log-scale) for AFLFast (solid line) vs AFL (dashed line) Crashes over time After 6h, AFLFast found one and two orders of magnitude more unique crashes than AFL in c++filt and nm, respectively|,Non-data,22
|9 AFLFast found 30 unique crashes in objdump where AFL found no crash at all None of the fuzzers found a crashing input for the remaining three studied tools in any of eight runs of six hours For each tool, the number of crashes found over time is shown in Figure 6 In what follows, we investigate the unique crashes generated for nm with a 24 hour budget in more details|,Non-data,22
| Vulnerabilities in nm On average, AFLFast exposes the CVEs seven (7) times faster than AFL and exposes three (3) CVEs that are not exposed by AFL in any of eight runs in 24 hours AFLFast exposes all vulnerabilities in 2h17m, on av- erage while AFL would require more than 12h30m The first three rows of Figure 7 show the results for the vulnerabilities in the nm tool in more details|,Non-data,22
