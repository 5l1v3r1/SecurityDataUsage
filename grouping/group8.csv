 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| 3 Generality DrK does not depend on software settings The attack works well over the latest version of all three commod- ity OSes (Windows, Linux, and OS X), and even works on in virtualized environments (Linux guest under Xen HVM)|,Non-data,15
| The root cause of the timing channel in the DrK attack bounds to the hardware specifications; therefore, if the processor sup- ports TSX, then the system is vulnerable to the attack This also indicates that the attack would be very difficult to defeat using software-level countermeasures Attack strategy The DrK attack consists of two stages|,Non-data,15
| First, we scan all possible slots of kernel pages mentioned in Table 2 to find the base and the end address of both kernel and drivers (modules) In this step, the base address (ASLR slide) is found The second step is to obtain more accurate mapping information at a page-level granularity We try to measure the permission of each page starting from the base address to the end address|,Non-data,15
| Then, we compare the result with the ground truth mapping information extracted from page table entries to evaluate the accuracy of the DrK attack In the following, we describe in detail the experiment configura- tion, settings, and interesting issues and tricks specific to each OS and virtualized environment 2All tested operating systems are the latest version as of May 2016 4|,Non-data,15
|21 Finding the Base and End Address We used the following OS-specific information to get the current The base address of the kernel mapping range of the running OS (see Table 2) Linux In Linux, kernel and modules addresses are mapped in different regions|,Non-data,15
| is in the 0xffffffff80000000–0xffffffffc0000000 address range, and there are only 64 slots where the kernel can start (aligned with 16 MB mask) For the module addresses, the base address can start in the range of 0xffffffffc0000000–0xffffffffc0400000, and 1,024 slots are available for base addresses for the modules (aligned with 4 KB mask) To find the base address of each region, we sequentially scan those slots from start to end After successfully determining the base address of the region, we find the end address of each region as follows|,Non-data,15
| For the kernel, since it is always mapped as a whole chunk in Linux, we set the end address as the first unmapped page that can be found starting from the kernel base address For the modules, while each module is mapped as a chunk, there is a region of unmapped pages between the modules Thus, finding unmapped pages in the region can only tell the number of modules loaded in the area To identify the end of module mapping area from this information, we use the number of modules that is currently loaded in the OS|,Non-data,15
| This is available through a user level program lsmod, which shows the list of currently loaded modules If the number of detected unmapped region matches the total number of modules, we set the end address at that point Windows Unlike Linux, Windows does not have separated ar- eas for kernel and driver mappings|,Non-data,15
| Specifically, kernel pages and driver pages can both lie in the same address range of 0xfffff80000000000–0xfffff80400000000 To distinguish be- tween kernel pages and drivers, we use the following facts: 1) all kernel pages in Windows are mapped with executable permission, 2) the kernel uses a page size of 2 MB, and its total size is at most 6 pages (12 MB in size for the tested version of Windows 10), and 3) the kernel can either come in front of drivers or come after Knowing this, we scan the whole available address space from one end to the other, to find the first and the last mapped pages in the area If first and the last pages are found, we look for a consecutive 12 MB area mapped with executable permissions at either end|,Non-data,15
| This area contains kernel pages After the kernel page range is determined, we know the remaining space that is mapped to be the module area OS X For OS X, we only launched the attack to find the base address (i|,Non-data,15
|e, ASLR slide) of the kernel image Since the kernel can be mapped in the range of 0xffffff8000000000– 0xffffff8020000000 over 256 slots, we scan them to find the first mapped address On all tested operating systems, finding the kernel base and end address can be done very quickly|,Non-data,15
| All scans were completed within several milliseconds (5 ms, 31 ms, and 797 ms in Linux, OS X and Windows, respectively) 422 Accuracy: Detecting Page Mappings After discovering the base and the end address of kernel mappings, we performed accuracy testing of the DrK attack|,Non-data,15
| Basically, we probed all mapped areas with DrK, then compared the result from the attack to the ground truth mappings extracted from the page tables Table 4 shows the result of our accuracy testing Linux For Linux, we ran the attack on three different CPUs (i7- 6700K, i5-6300HQ, and E3-1271 v3), and on the kernel version 4|,Non-data,15
|40 running Ubuntu 1604 LTS DrK measured 6,147 pages in total (3,075 for kernel and 3,072 pages for the modules) and it was 385OS Linux Windows Linux Xen Amazon EC2 Linux Windows OS X CPU Type # Pages Skylake (i7-6700K) Skylake (i5-6300HQ) Skylake (i5-6300HQ) Haswell (E3-1271 v3) Skylake (i5-6300HQ) Skylake (i5-6300HQ) Skylake (i5-6300HQ) Skylake (i5-6300HQ) Skylake (i5-6300HQ) Haswell (E7-8880 v3) Skylake (i7-6700K) Skylake (i5-6300HQ) Skylake (i7-6700K) Kernel/Modules Kernel/Modules Kernel/Modules Kernel/Modules Kernel/Driver Kernel/Driver Kernel/Driver Kernel/Modules Kernel/Modules Kernel/Modules Kernel Base Addr Kernel Base Addr Kernel Base Addr 6,147 6,147 6,147 6,147 34,258 34,258 34,258 5,633 5,633 6,147 64 8,192 256 Accuracy M/U M/U Kernel Module X/NX/U Kernel Module 100|,Non-data,15
00% 10000% 10000% 10000% 100,Non-data,15
00% 10000% 10000% 10000% 100,Non-data,15
00% 10000% 10000% 10000% 100,Non-data,15
00% 10000% 10000% 10000% 90,Non-data,15
45% 10000% 10000% 10000% 100,Non-data,15
00% 9860% 9928% 10000% 100,Non-data,15
00% 10000% 10000% 9998% 100,Non-data,15
00% 10000% 10000% 10000% 100,Non-data,15
00% 10000% 10000% 10000% - 100,Non-data,15
|00% - 10000% 10000% - See (a) See (a) See (a) 9998% - - - - - - X/NX/U Max M Max X # Iter Time (s) Clock 235 183 183 192 183 183 183 580 (b) 580 (b) 181 235 183 235 210 163 163 177 163 163 163 530 (b) 530 (b) 165 - - - 100 20 100 100 100 500 1,000 100 500 100 100 100 100 0|,Non-data,15
16 009 021 019 4,Non-data,15
96 225 459 065 2,Non-data,15
61 027 5ms 797ms 31ms 39 GHz 30 GHz 3,Non-data,15
0 GHz 39 GHz 28 GHz 28 GHz 2,Non-data,15
8 GHz 23 GHz 23 GHz 27 GHz 3,Non-data,15
|9 GHz 30 GHz 39 GHz Table 4: Summary of the evaluation results of the DrK attack To calculate the accuracy, we ran the full attack 10 times, then calculated the geometric mean to show the consistency of the result over multiple runs|,Non-data,15
| To break KASLR in Linux, it took around 02 seconds with 100% accuracy in detecting the mapping status of each page For Windows, while the attack on determining mapped / unmapped address resulted 100% accuracy over 100 probing iterations, the attack on the executable permission did not Running more iterations gives better accuracy: 98|,Non-data,15
|60% and 9928% on 500, and 1,000 iterations respectively The DrK attack also works well in a virtualized environment We ran Linux over a Xen hypervisor and in cloud environment on an X1 instance of Amazon EC2, and both resulted 100% of accuracy|,Non-data,15
| For the last three rows, we only ran the DrK attack to find the base address of the kernel It only took 5 ms for Linux, 31 ms for OS X, and 797 ms for Windows to find the ASLR slide (a) In Windows, all pages of the kernel (HAL and ntkrnlmpexe) are mapped with executable permissions|,Non-data,15
| Therefore, we did not run X/NX detection for the pages (b) See §43 and §44 for the effect of frequency scaling on the timings|,Non-data,15
| able to identify their mappings with 100% accuracy In total, the attack took around 02 seconds (from retrieving the base address to determining all page permissions) Windows|,Non-data,15
| For Windows, we ran the DrK attack on Skylake i5- 6300HQ processor running Windows 10 version 10010586 Both kernel and drivers consisted of 34,258 pages (probing 8,192 of 2 MB pages for the base and end addresses, and 26,066 pages for measuring 4 KB pages for the module addresses) to be scanned|,Non-data,15
| The total attack, including scanning slots for the base address and measuring each page, completed in under five seconds with 100 iterations of probing, which yields 100% (mapping) and 9045% (executable) accuracy in detecting module mappings Running more iterations on Windows gives better results in find- ing executable pages When running 1,000 iterations on each page, it yields 99|,Non-data,15
|28% accuracy in detecting executable pages, while taking long (459 s) for probing 42|,Non-data,15
|3 Detecting Module Addresses - NAME PERM END_ADDR BASE_ADDR 1 // 2 0xffffffffc035b000-0xffffffffc0360000 U 3 0xffffffffc0360000-0xffffffffc0364000 X libahci 4 0xffffffffc0364000-0xffffffffc0368000 NX libahci 5 0xffffffffc0368000-0xffffffffc036c000 U 6 0xffffffffc036c000-0xffffffffc036e000 X i2c_hid 7 0xffffffffc036e000-0xffffffffc0371000 NX i2c_hid 8 0xffffffffc0371000-0xffffffffc0376000 U 9 0xffffffffc0376000-0xffffffffc039a000 X drm 10 0xffffffffc039a000-0xffffffffc03cc000 NX drm 11 0xffffffffc03cc000-0xffffffffc03cd000 U SIZE 4000 4000 2000 3000 24000 32000 Figure 7: List of module mappings in Linux kernel 440 Note that the mapping is always done in the following sequence: X, NX, U, and a chunk of unmapped pages separates the mappings of consecutive modules|,Non-data,15
| The sizes of X and NX pages are diverse by the modules The DrK attack uses the size information of executable and non- executable pages of the module as a signature Figure 7 shows the list of module mappings in Linux In Linux, module mapping always start with a code area (|,Non-data,15
|text), which has executable permission Subsequently, areas such as bss, rodata with NX permission are mapped|,Non-data,15
| Note that the size of any single module is likely different from that of the others We set the size of X/NX areas as the signature (eg, X:0x2000 and NX:0x3000 for i2c_hid module)|,Non-data,15
| Among a total of 80 modules loaded in Ubuntu 1604 LTS, we can determine the exact location of 29 modules that have a unique size signature However, the method cannot detect modules with the same size For example, for the worst case, there were 27 modules with minimal size that have one page (0x1000) of X area and three pages (0x3000) of NX area|,Non-data,15
| Despite such a limitation, this module detection can still be useful in attacks because the attacker can reduce the uncertainty of the address (from targeting 80 modules to only targeting 27 modules in the worst case) For Windows, we can uniquely detect 97 drivers among a total of 141 drivers using size-based driver signatures Since the kernel drivers of Windows have discardable mappings after initialization, we cannot directly use the same signature for detecting Linux kernel modules Instead, we use two sizes that are unchanging during the lifetime of the module to build the signature: 1) the total size of the driver memory region (from start of the driver, but before the start address of the next mapped driver), and 2) the size of first contiguous executable region|,Non-data,15
| Via experimentation, we observed 97 unique size signatures for detecting the driver addresses A prior work [27] tried a similar method for detecting kernel drivers on Windows However, since the work could not distinguish X pages from NX pages, their detection result was far smaller (21) than ours (97) Detection of X/NX gives much better precision for determining the location of the drivers since it provides unique size signatures for the drivers|,Non-data,15
| Fine-grained module detection The DrK attack allows for a very accurate picture of the kernel address space layout This can be further exploited to identify the exact location of a specific module (driver) For example, from the mapping information, we can infer the addresses of modules such as raid, drm, and libahci in Linux, and locating the drivers such as NTFS, pci, and msrpc in Windows|,Non-data,15
| 43 DrK in Virtualized Environment To test the feasibility of the DrK attack in virtual and cloud environments, we carried out the attack on Linux running under Xen hypervisor 44, as well as an X1 instance of Amazon EC2 [2] to check if the attack can be launched in such an environment 386Iterations # incorrect Accuracy (%) 2 239 92|,Non-data,15
22 5 70 9772 20 18 9941 50 8 9974 100 0 100,Non-data,15
|0 Table 5: Achieved accuracy over the number of iterations for the modules pages (3,072 pages in total) of Linux Kernel 440 on Haswell (Xeon E3-1271 v3) processor Probing the address with more iterations gives better accuracy|,Non-data,15
| For measuring with only 2 iterations (minimum iterations to measure TLB cache hit), 239 mapped pages were detected as unmapped pages, which renders 9222% of accuracy With more iterations, such as 20, 50, and 100, the number of incorrectly measured pages decreases as 18, 8, and 0, respectively With 100 iterations, the DrK attack achieves perfect accuracy on breaking KASLR|,Non-data,15
 Results The DrK attack can detect 9999%–100% of kernel mappings in a virtualized environment The accuracy is slightly lower than the bare-metal result,Non-data,15
| We believe that the difference in accuracy is caused by factors that can affect TSX execution, such as virtual interrupts generated by the hypervisor (eg, VMEXIT) Interestingly, we observed that a Skylake laptop processor (Core i5-6300HQ) with Xen resulted in timings that were very different from other environments (Table 4)|,Non-data,15
| We believe that this was due to speed throttling, ie, Intel Speed Step and Turbo Boost, because its clock rate was lower than the same processor in a bare-metal environment (23 GHz versus 3|,Non-data,15
0 GHz) We cover more issues with clock speed in §44 4,Non-data,15
|4 Controlling the Noise Since DrK is a cache-based timing channel attack, it is not free from the noise of the channel On determining page mapping status and executable status, we used the minimum cycle observed when probing the pages as the threshold However, occasionally, we ob- served measurement errors, possibly due to hardware characteristics (eg|,Non-data,15
|, cache coherence traffic and cache conflict) We minimized such measurement errors by probing a certain address multiple times Table 5 shows how the accuracy changes by the number of iterations With 2 iterations, 239 mapped pages were detected as unmapped, among 3,072 pages in the scanned area (92|,Non-data,15
|22% of accuracy) However, as the number of iterations increased to 5, 20, and 50, the number of mis-detected pages was drastically reduced, 70, 18, and 8, respectively Finally, probing with 100 iteration, the accuracy reached 100% Note that the number of iterations to achieve the perfect accu- racy depends on the environment, such as processor generation or software settings for generating interrupts that is asynchronously handled in TSX|,Non-data,15
| For example, unlike Haswell that needed 100 it- erations to get the 100% accuracy on Linux, Skylake only required 20 iterations to achieve perfect accuracy (see the second row on Table 4) For the virtualized environment, the measured accuracy is slightly lower than running bare-metal with the same number (100) of iterations (100% vs 9998%) However, still, we can manage the noise by increasing the number of iterations: e|,Non-data,15
|g, 500 iterations achieved 100% accuracy Dynamic frequency scaling (ie|,Non-data,15
|, Intel Speed Step or Intel Turbo Boost) also affects the timings Since we use the number of clock cycles (using rdtscp) to measure timing, a change in the clock frequency would affect the timing measurements [30, §1714] We solved this problem by keeping the processor busy|,Non-data,15
| We em- pirically observed that running two dummy loops consuming 100% CPU time was enough to maximize the processor clock rate, and achieve perfect accuracy This also implies that the DrK attack works well with processors with high workload; ie, when the pro- cessor runs jobs other than the attacks|,Non-data,15
| READ M JUMP NX U 64 91 590 1,000,247 31 1,157 1,190 X 84 2,000,086 425 267 6 6 1,092 1,027 U Trace point 3,021,847 3,020,043 3,018,191 3,018,857 3,025,769 dTLB-loads 109 dTLB-load-misses 272 iTLB-loads 12 1,000,175 iTLB-load-misses 1,391 L1-icache-load-misses L1-dcache-loads 3,021,885 3,020,081 3,018,229 3,018,895 3,025,807 L1-dcache-load-misses 1,000,856 1,000,787 1,002,456 1,000,603 1,002,539 Table 6: The number of TLB and cache loads and misses when DrK probes single kernel memory page 1,000,000 times, measured by hardware perfor- mance counters Probing methods are reading mapped (M) and unmapped (U) pages, and jumping into executable (X), non-executable (NX), and un- mapped (U) pages Tracepoints are data TLB loads/misses, instruction TLB loads/misses, L1 instruction cache misses, and L1 data cache load/misses Reading of U page generated data TLB misses|,Non-data,15
| In addition, while jumping into X pages does not generate hit/miss counts on an instruction TLB (iTLB), jumping into NX page incurs hit on iTLB, but jumping into U page generated an iTLB miss The remaining tracepoints were similar to each other 45 Comparison with the Prior Attack We summarize the evaluation result of the DrK attack by compar- ing it with the prior attack presented by Hund et al|,Non-data,15
 [27] Speed and accuracy The DrK attack took about 05 seconds in Linux and about 5 seconds in Windows to achieve 100% accuracy of detecting the full mapping information of kernel and driver space,Non-data,15
| In contrast, the prior attack requires 17 seconds to obtain 96% accuracy Noise of the channel Compare to the prior attack, DrK is strong against measurement noise As shown in Figure 6, the timing dif- ference between mapped and unmapped pages was over 10% in DrK|,Non-data,15
| In contrast, in the prior attack, the timing difference between mapped and unmapped pages was only around 1% (30–50 cycles from 5,000 cycle), which can easily fluctuate Executable page detection Unlike the prior attack, DrK can distinguish executable pages from non-executable pages Our new finding is to demonstrate an accurate way of distinguishing exe- cutable pages from the mapped pages, which allows an attacker to effectively break KASLR, especially when detecting the exact location of kernel drivers|,Non-data,15
| Module detection As mentioned in §423, DrK detected a larger number of drivers (97) than the prior attack (5–21)|,Non-data,15
| This is because DrK has better accuracy than the prior attack and DrK is able to use not only size signatures but also executable mapping status 5 IN-DEPTH ANALYSIS OF DrK In this section we figure out what causes DrK observe timing differences Since the internal characteristics of Intel processors are barely documented, we first take a look into detailed measure- ments on hardware events during the DrK attack using the hardware performance counter (HPC) (§5|,Non-data,15
|1) Then, we analyzed the measure- ment results to figure out what causes the time difference between mapped and unmapped pages (§52), and between executable and non-executable pages (§53), in accordance with a simplified Intel CPU architecture diagram (Figure 8)|,Non-data,15
| 51 Measuring Hardware Events We probed a memory page 1,000,000 times while measuring hardware events using the HPC We tested the following five of memory probings: 1 read a mapped kernel page 2|,Non-data,15
 read an unmapped kernel page 3 jump into an executable kernel page 4 jump into a non-executable kernel page 5 jump into an unmapped kernel page,Non-data,15
| 38753 Executable versus Non-executable Pages We conjecture that decoded icache is the hardware components that creates the side channel by handling executable and non- executable kernel pages differently, as shown in timing differences In the DrK attack, timing of probing executable (X) pages was mea- sured as faster than that of non-executable (NX) and unmapped (U) pages While it seems caching in iTLB would generate such timing difference, nonetheless, it is not true|,Non-data,15
| Table 6 supports the hypothesis as follows iTLB is not the origin Unlike the result on mapped/unmapped pages, jumping into an X page did not generate any additional iTLB-loads (590 in iTLB-loads on 1 M accesses) This means that iTLB hit did not even happen on probing|,Non-data,15
| Moreover, although iTLB actually hits on probing NX pages (only 12 misses on 1 M accesses), the timing of NX pages is not as fast as X Further, although probing on U pages generates many iTLB misses, the timing of NX pages and U was the same (see Table 3) This proves that iTLB is not the origin of the timing channel Decoded icache for faster timing on X|,Non-data,15
| Table 6 also implies that, unlike executing on NX and U pages, probing X pages does not need to translate the virtual address to the physical address to fetch instructions From this observation, we came up with a hypothesis that decoded icache is the origin of the timing channel; decoded icache is the place in which fetched and decoded micro-ops are cached (Figure 8) And it is virtually-indexed, and virtually-tagged (VIVT) cache, which does not require address translation on its access according to a patent document [49] published by Intel Cor- poration On probing an executable memory page, once the instructions in the address are decoded and cached, the processor no longer needs to translate the address|,Non-data,15
| Instead, it directly fetches the instructions from the decoded icache, however, the actual execution fails due to the access violation Since the probing does not go through iTLB nor page table walk, the exception is generated relatively faster than probing other page mappings Page table walk is required for both NX and U We conjecture that page faults for both NX and U pages are generated after the pro- cessor finished the page table walk, since their timings are the same (Table 3)|,Non-data,15
| And, we hypothesize missing of coherency mechanism in TLB in Intel processor makes those two access must go through the page table walk On probing non-executable (NX) pages, the processor will cache the corresponding page table entry into iTLB, and the entry is marked as non-executable However, the processor cannot deter- mine the page fault by just inspecting the NX bit on the page table entry from iTLB since TLB is not a coherent cache in Intel architec- ture [24] That is, there could be a case that other cores have updated the permission on the page table as executable, but the current core has a mismatched page table entry in its TLB|,Non-data,15
| In such a case, on (trying) execution on the page, the processor is required to resolve the latest page table entry from the page table to check if there has been any update Therefore, on the subsequent probing, despite iTLB hits, but the entry set with the NX bit; then, the processor walks through the page table, and get the results that latest entry: the entry is set with the NX bit Finally, the processor can generates a page fault exception U pages take the same path as the mapped versus unmapped case|,Non-data,15
| After the iTLB miss, the processor walks through the page table, figures out the address is not mapped, and generates a page fault In summary, while executable pages (X) do not walk through the page table on the subsequent probing (fast), both mapped (M) and Figure 8: Simplified Intel Skylake architecture including pipeline and cache hierarchy We omitted L2, last level, and any other page table caches for simplicity Each M, U, X, and NX indicates the locations where page faults are checked according to our measurements|,Non-data,15
| Note that decoded icache, which caches decoded micro-ops, is inside L1 icache [30, 49] and it is a virtually-indexed and virtually tagged (VIVT) cache, which does not requires an iTLB access for address translation On probing, we set tracepoints to measure: 1 dTLB-loads: the total number of attempts to load data trans- lation lookaside buffer (dTLB), including cache hit on dTLB 2|,Non-data,15
| dTLB-load-misses: the number of failed attempts to load dTLB; cache miss on dTLB 3 iTLB-loads: the total number of attempts to load instruction TLB (iTLB), including cache hit on iTLB 4|,Non-data,15
| iTLB-load-misses: the number of failed attempts to load iTLB; cache miss on iTLB 5 L1-icache-load-misses: the number of failed attempts to load L1 instruction cache (icache), cache miss on icache 6|,Non-data,15
| L1-dcache-loads: the total number of attempts to load L1 data cache (dcache), including dcache hit 7 L1-dcache-load-misses: the number of failed attempts to load L1 dcache; dcache miss Note that we were unable to measure L1-icache-loads because all tested CPUs that support TSX (listed in Table 3) did not support the counter for it|,Non-data,15
| Table 6 summarizes the results measured in the Linux machine with Intel Core i7-6700K (Skylake) 40 GHz CPU 52 Mapped versus Unmapped Pages We conjecture that dTLB makes timings for mapped and un- mapped kernel pages differently, by its different caching behavior on page mappings|,Non-data,15
| As introduced in §3 and §4, a TSX abort handler for a violation of reading mapped kernel memory (M) was called faster than that for a violation of reading unmapped kernel memory (U) We believe that the timing difference is originated by dTLB hit on accessing a mapped memory (fast), and dTLB miss for an unmapped memory (slow, because it requires a page table walk) Table 6 supports this hypothesis: while reading an unmapped (U) page generated a lot of (over two millions) dTLB misses (dTLB-load-misses, marked in red), accessing a mapped (M) page did not The counter shows that the access to a mapped kernel mem- ory caches its page table entry in dTLB|,Non-data,15
| On the subsequent probing, the page table entry can be retrieved by just accessing the dTLB Then, the page privilege is checked without having page table walk, thus it results in faster determination of the page fault exception In contrast, the access to an unmapped kernel memory cannot be cached into dTLB, because it has no corresponding physical address After suffering dTLB-miss, the probing should wait until the proces- sor seek the page table entry then figuring out the page fault|,Non-data,15
| Thus, a read attempt to an unmapped page always requires a page table walk, so it takes longer to raise the page fault exception (and calling TSX abort handler) We note that this explanation corresponded to Hund et al [27]’s finding ExecutionUnitInstructionSchedulerFetchDecodeMemoryUnitDecodedicacheL1 icacheL1 iTLBL2 TLBL1 dcacheL1 dTLBL2cacheMemory(page table)XNXMU388unmapped (U) pages always make processor walks through the page table (slow) to determine the page fault|,Non-data,15
| 63 Live Re-randomization and Fine-grained KASLR 6 POTENTIAL COUNTERMEASURES We discuss potential countermeasures against the DrK attack In summary, we see there are no effective countermeasures that can prevent DrK without hurting usability and performance|,Non-data,15
| 61 Eliminating Timing Channel One of the most fundamental countermeasures against DrK is eliminating any timing differences when probing the kernel ad- dresses at the user-level execution When the Intel CPU handles exceptions for unprivileged accesses, it takes different hardware paths according to whether the accessed memory region is exe- cutable, mapped, or unmapped §5 shows our measurements about the differences in terms of the loads and misses of cache and TLB|,Non-data,15
| Hardware modification One possible way to flatten the timing differences is modifying the hardware For example, we can change the CPU to not cache unprivileged accesses to kernel addresses, which makes every unprivileged memory access take the same hard- ware path Any timing channel attacks, including DrK and Hund et al|,Non-data,15
| [27], cannot observe timing differences and would therefore fail However, since this solution demands hardware modifications, it cannot protect already deployed CPUs from DrK Kernel page table separation Another countermeasure against DrK is separating the kernel page table from a user page table|,Non-data,15
| If no kernel memory is mapped into a user page table, DrK would have no chance to break KASLR However, the kernel address space is mapped into a user page table to minimize the execution overhead of privileged instructions (eg, system call)|,Non-data,15
| Without this, the system would need to flush TLBs whenever a user process invokes a system call, which would significantly reduce the overall system performance [6, 27] For example, Xen uses separated page tables for kernel and user processes when a guest machine is a 64-bit para-virtualized machine (PVM), but this degrades system performance such that the 64-bit PVM is not recommended [46] for use Therefore, It is impractical to adopt this countermeasure due to performance degradation 6|,Non-data,15
|2 Monitoring Hardware Events Modern CPUs provide HPC interfaces to monitor hardware events that occur inside a CPU, such as the numbers of retired instructions, taken branches, and cache loads/misses Although the OS cannot observe any page faults while being attacked by DrK, it can infer whether DrK is being performed by using the hardware event in- formation For example, we identified that during the DrK attack, a CPU generates lots of loads/misses on both TLBs and the L1 i-cache (see Table 6) Further, the HPC provides information about the number of transactional aborts (tx-abort) generated by a CPU|,Non-data,15
| This number would be large when the system is under attack by DrK because each memory probing generates an abort However, monitoring hardware events has limitations to detect DrK in terms of accuracy and performance First, a benign program can show a similar behavior to DrK when it randomly accesses different memory regions or heavily uses TSX Further, DrK can cloak its behavior by decreasing the frequency of memory probing|,Non-data,15
| Thus, the system cannot avoid false detection problems Next, monitoring all processes of the OS is unrealistic due to the overhead of checking HPC: about 20% performance overhead [60] System- wide monitoring could reduce the overhead, but, in that case, it is difficult to determine which process engages in suspicious behavior One possible approach to cope with DrK is to use fine-grained ASLR and live re-randomization [21]|,Non-data,15
| They not only adjust the base addresses of kernel code and modules, but also randomize all kernel code, static data, stack, dynamic data, and modules while re-randomizing them periodically However, as shown in Table 4, DrK took less than 02 seconds in Linux to detect full page mappings with 100% accuracy Moreover, by detecting a single module rather than the whole space, the attack can be even faster (proportional to the scan size)|,Non-data,15
| This implies that the OS needs to re-randomize its address space more than once per second, which is problematic due to performance overhead In case of fine-grained KASLR, adding base offset within a page can defeat DrK since the finest granularity that DrK can detect the mapping is a page However, this would have implementation challenges, eg|,Non-data,15
|, a compatibility issue on misaligned pages 64 Other Countermeasures Lastly, we introduce a few mechanisms that can prevent or miti- gate DrK, but these are less practical Disabling TSX|,Non-data,15
| The strongest countermeasure against DrK, though a naïve one, is disabling TSX Unlike other instructions that can be disabled through model-specific registers (MSRs) or BIOS settings (eg VM extensions), TSX cannot be disabled in such manner|,Non-data,15
| However, as a CPU manufacturer, Intel can disable the feature via a microcode update or product line change In fact, Intel had already disabled TSX in the Haswell CPU due to a hardware bug (Erratum HSD136 in [29]) Nonetheless, this solution is problematic because TSX is already widely used; eg|,Non-data,15
|, glibc uses TSX in its pthread library for synchronization and Java uses TSX for thread scheduling [34, 45] Different caching policy TSX only works with memory regions configured as write-back ([30, §153|,Non-data,15
|82]), which is a default con- figuration due to its efficiency In our experiment, we observed a few (288 pages among 26,066 pages in Windows) memory pages in driver area configured as write-through or uncacheable and DrK misjudged them as unmapped pages Although those pages do not belong to any kernel drivers, (i|,Non-data,15
|e, it does not affect the accuracy evaluation) this implies that if an OS makes the entire kernel mem- ory either write-through or uncachable, it can be secure against DrK However, this configuration is impractical, as it results in huge performance degradation [6] Noisy timer|,Non-data,15
| Finally, a noisy timer or coarse-grained timer is a well- known countermeasure against timing attacks The system can add some noise when returning a timer value or prevent a user program from using a fine-grained timer (eg, rdtsc)|,Non-data,15
| However, the noisy timer is just a work-around such that it cannot completely prevent DrK Also, many benign programs need to use the fine-grained timer, eg, to precisely measure performance|,Non-data,15
| 7 DISCUSSIONS Limitations DrK has some limitations First, DrK always treats uncachable, write-through, and paged-out memory regions as un- mapped|,Non-data,15
| DrK relies on Intel TSX, which only works with memory pages configured as write-back ([30, §15382])|,Non-data,15
| Thus, it cannot probe memory pages configured as uncachable or write-through; its access to such memory pages always aborts DrK also treats swapped-out pages as unmapped because access to such pages gen- erates a page fault which aborts the transaction ([30, §1538|,Non-data,15
|2]) However, we did not observe write-through pages for the code and data areas of the kernel and drivers, in both Linux and Win- 389dows, because write-through pages are slower than write-back pages Due to the performance issues, kernel developers do not use write- through pages in general Further, most of the important kernel pages, such as kernel text, data, and drivers, are frequently used, so they are usually kept in memory (i|,Non-data,15
|e, not paged out) Therefore, these limitations are negligible Breaking “security by memory obscurity”|,Non-data,15
| DrK can also be applied to launch an undetectable, crash-resistant memory map- ping probing [19] Some system protection mechanisms, such as CPI [35], ASLR-Guard [39], and Kenali [54], assume a secret mem- ory location that the attacker cannot know to store sensitive in- formation for integrity protection However, using DrK, such an assumption could be broken if such a secret address is not selected carefully, because the DrK attack can fully search for the address space without any crash We plan to figure out how we can use DrK to break such protection mechanisms|,Non-data,15
| 8 RELATED WORK In this section, we provide a comprehensive landscape of past research related to the DrK attack ASLR: Attacks and defenses Since the most modern OSes adapt W⊕X and ASLR to prevent code injection and code reuse attacks [12, 48, 51, 52], attackers and defenders continuously find new attacks to break ASLR and develop countermeasures against them|,Non-data,15
| Researchers find that many ASLR implementations are in- secure because they do not fully randomize address spaces (eg, shared libraries without ASLR and fixed memory allocation) and do not provide enough entropy (eg|,Non-data,15
|, limited mapping range and large alignment size) to avoid performance degradation These make the ASLR implementations vulnerable to prediction and brute-force attacks [9, 12, 18, 51, 52] To prevent such attacks, researchers pro- pose fine-grained ASLR technologies that randomize the location of functions [7, 33], basic blocks [59], and even instructions and registers [26, 47] On the other hand, researchers also discover that even fine-grained ASLR can be broken by information leak vulnerabilities [50, 55], since they let attackers know de-randomized addresses|,Non-data,15
| By using it, Snow et al [53] break the fine-grained ASLR To mitigate such an attack, three kinds of schemes have been proposed: (1) dynamic (re-)randomization [4, 8, 16, 20, 21, 38] to make leaked information useless, (2) execution-only memory [3, 11, 15] and destructive code read [56] to prevent attackers from reading any code gadgets, and (3) pointer integrity [14, 35, 39] to prevent code pointer manipulation researchers recently found that memory de- duplication can be used to break ASLR without information leak vulnerabilities [5, 10]|,Non-data,15
| Timing attacks against KASLR Hund et al [27] present a timing side channel attack against kernel space ASLR, which is the work most relevant to DrK The main advantage of these timing attacks over the previous ASLR attacks is that they neither relies on weak implementations of ASLR nor information leak vulnerabilities|,Non-data,15
| In addition, Hund et al’s attack and DrK focus on similar timing differences caused by how a processor handles a page fault for mapped com- pared to unmapped kernel memory pages However, unlike DrK, Hund et al’s attack should call the OS page fault handler whenever probing each kernel memory page, which suffers from high noise due to a long execution path inside the OS|,Non-data,15
| Furthermore, this lets the OS know which user process frequently accesses kernel memory pages, so that the OS can easily detect the attack In contrast, DrK uses a TSX abort handler to probe a kernel memory page, whose execution path is shorter than that of OS page fault handler, making it less error-prone and even able to recognize the small difference between accessing executable and non-executable pages Also, it is difficult for the OS to detect DrK because it cannot directly observe the behavior of DrK (§4) Recently, Gruss et al|,Non-data,15
| [22] exploit the prefetch instruction on the processor, which loads a specific address into a certain cache level, to probe mapping information without causing exceptions However, since the prefetch instruction targets data, this attack cannot identify whether an address is executable or non-executable, unlike DrK Crash-resistant memory probing One of the advantages of DrK is that it does not generate a crash when probing the kernel’s address space|,Non-data,15
| Recently, Gawlik et al [19] have shown a similar web attack for crash-resistant memory probing They found that memory access violations by some JavaScript methods do not crash modern web browsers having fault-tolerant functionality, which allows for memory probing without a browser crash However, OSes can identify whether such an attack is performed because it cannot suppress the exception, unlike DrK|,Non-data,15
| Also, as the authors mention, this attack can be mitigated by limiting the number of faults that can be caused, checking the exception information, using guard pages, and using memory safety solutions However, none of these approaches can mitigate DrK TSX timing channel We found two blog articles [1, 64] that depicted kernel timing attacks using TSX while we conducted this research|,Non-data,15
| Note that although this paper and the two blog articles are based on similar observations, this work makes the following impor- tant contributions, unlike the blog articles which only conjecture that such an attack is possible First, we did comprehensive evaluations We demonstrated and analyzed DrK with three different Intel CPU generations (§41) in all major OSes (§4|,Non-data,15
|2 and §423) Moreover, we give instructions on controlling the noise of timing channel to get the best precision (§4|,Non-data,15
|4) Second, we showed what causes this tim- ing channel through experiments We studied the architecture of the modern Intel CPU in depth and discovered which execution paths lead to such a timing channel (§5) We monitored the behavior of the Intel CPU in detail using the HPC and checked its architectural details to figure out the root cause|,Non-data,15
| Lastly, we discovered that the TSX timing channel can be used to determine whether a memory page is executable or non-executable (§3 and §4) Note that neither the two blog articles nor Hund et al [27]’s work discovered this timing channel 9|,Non-data,15
| CONCLUSION To protect the kernel memory from attacks in the wild, commod- ity OSes have adopted KASLR, which is proven to be a practical defense mechanism against many memory corruption attacks In this paper, we introduced DrK, a timing side channel attack that almost perfectly de-randomizes KASLR using the Intel CPU’s new instruction set, TSX Our evaluation shows DrK is much better than the prior side channel attack in terms of precision, platform independence, covertness, and speed We further analyzed which architectural characteristics exposed such timing differences and proposed some countermeasures to eliminate it|,Non-data,15
| Acknowledgments We thank the anonymous reviewers, for their helpful feedback, as well as GTISC lab members for their proofreading efforts This research was supported by the NSF award DGE-1500084, CNS- 1563848, CRI-1629851 ONR under grant N000141512162, DARPA TC program under contract No DARPA FA8650-15-C-7556, and DARPA XD3 program under contract No DARPA HR0011-16-C- 0059, and ETRI MSIP/IITP[B0101-15-0644]|,Non-data,15
| 390Responsible vulnerability disclosure Following the guidance of responsible vulnerability disclosure, We confidentially reported the vulnerability to through US-CERT (VU#954695) and Microsoft Security Response Center (MSRC, Case 32737, TRK:0001003139), and shared this manuscript with affected vendors to resolve the newly discovered security threat After the public disclosure, we will release the source code of the DrK attack available to the public |,Non-data,15
|ABSTRACT Remote attestation is a crucial security service particularly relevant to increasingly popular IoT (and other embedded) devices It al- lows a trusted party (verifier) to learn the state of a remote, and potentially malware-infected, device (prover) Most existing ap- proaches are static in nature and only check whether benign soft- ware is initially loaded on the prover However, they are vulnerable to runtime attacks that hijack the application’s control or data flow, e|,Non-data,17
|g, via return-oriented programming or data-oriented exploits As a concrete step towards more comprehensive runtime remote attestation, we present the design and implementation of Control- FLow ATtestation (C-FLAT) that enables remote attestation of an application’s control-flow path, without requiring the source code We describe a full prototype implementation of C-FLAT on Rasp- berry Pi using its ARM TrustZone hardware security extensions|,Non-data,17
| We evaluate C-FLAT’s performance using a real-world embedded (cyber-physical) application, and demonstrate its efficacy against control-flow hijacking attacks Keywords remote attestation; control-flow attacks; embedded system security INTRODUCTION 1 Embedded systems are becoming increasingly ubiquitous, perme- ating many aspects of daily life They are deployed in automotive, medical, industrial, household and office settings, smart cities and factories, as well as in critical infrastructures|,Non-data,17
| Unfortunately, this increased popularity also leads to numerous security issues [44] Securing embedded devices is challenging, particularly because they are special-purpose and resource-constrained [23] Remote attestation is a means of verifying integrity of software running on a remote device Typically, it is realized as a challenge- ∗Author names are listed in alphabetical order|,Non-data,17
| Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita- tion on the first page Copyrights for components of this work owned by others than ACM must be honored Abstracting with credit is permitted To copy otherwise, or re- publish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee|,Non-data,17
| Request permissions from permissions@acmorg CCS ’16, October 24–28, 2016, Vienna, Austria c(cid:13) 2016 ACM|,Non-data,17
 ISBN 978-1-4503-4139-4/16/10   $15,Non-data,17
00 DOI: http://dxdoiorg/101145/2976749,Non-data,17
|2978358 response protocol allowing a trusted verifier to obtain an authentic, and timely report about the software state of a (potentially untrusted and infected) remote device – a prover Based on that report, a verifier checks whether prover’s current state is trustworthy, ie, whether only known and benign software is loaded on the prover|,Non-data,17
| The standard trust assumption needed for authenticity of the at- testation report requires the existence of some trusted component – called a trust anchor – on the prover Moreover, most attestation schemes assume malicious software (ie, remote malware infes- tations) as their adversarial model|,Non-data,17
| Prominent examples of trust anchors are secure components such as a Trusted Platform Module (TPM) Although available on many laptops and desktops, TPMs are too complex and expensive for deployment on low-end em- bedded devices Ideally, trust anchors for small embedded devices should be light-weight, ie|,Non-data,17
|, require minimal hardware features and assumptions, in light of recent proposals such as SMART [18], SANCUS [32], and Intel’s TrustLite [24] The next generation of ARM Microcontrollers (MCUs) [46] will feature TrustZone-M, a lightweight trust anchor Most current remote attestation approaches are static in nature In such schemes, the prover’s report is typically authenticated by means of a cryptographic signature or a MAC computed over the verifier’s challenge and a measurement (typically, a hash) of the binary code to be attested|,Non-data,17
| However, static attestation, though effi- cient, only ensures integrity of binaries and not of their execution In particular, it does not capture software attacks that hijack the program’s control flow [42] These attacks tamper with the state information on the application’s stack or heap to arbitrarily divert execution flow State-of-the-art memory corruption attacks take advantage of code-reuse techniques, such as return-oriented pro- gramming, that dynamically generate malicious programs based on code snippets (gadgets) of benign code without injecting any ma- licious instructions [34]|,Non-data,17
| As a result, the measurements (hashes) computed over the binaries remain unchanged and the attestation protocol succeeds, even though the prover is no longer trustwor- thy These sophisticated exploitation techniques have been shown effective on many processor architectures, such as Intel x86 [39], SPARC [9], ARM [25], and Atmel AVR [19] The problem arises because static attestation methods do not cap- ture a program’s runtime behavior (ie|,Non-data,17
|, timely trustworthiness) of the underlying code In particular, recent large-scale studies have shown [14, 11] that embedded software suffers from a variety of vulnerabilities, including memory errors (such as buffer overflows), that allow runtime exploits To be truly effective, an attestation technique should report the prover’s dynamic state (ie|,Non-data,17
|, its current 743executions details) to the verifier As we elaborate in Section 9, there have been some proposals to enhance and extend static bi- nary attestation [35, 20] However, they either require involvement of an external trusted third party, or only attest higher level of poli- cies at the Java bytecode layer by instrumenting the Java virtual machine Hence, they do not capture control-flow related attacks at the binary level of embedded systems software|,Non-data,17
| Mitigation of runtime exploitation techniques has been a subject of intensive research Prominent defenses against control-flow hi- jacking include: control-flow integrity (CFI) [1], fine-grained code randomization [13, 27], and code-pointer integrity (CPI) [26] How- ever, naïvely integrating these approaches into remote attestation protocols would provide limited state information to the verifier In particular, these techniques only report whether a control-flow attack occurred, and provide no information about the actually ex- ecuted control-flow path|,Non-data,17
| Therefore, the verifier can not determine which (of the many possible) paths the prover executed This lim- itation allows an attacker to undermine such defenses by means of so-called data-oriented exploits [12] These attacks corrupt data variables to execute a valid, yet unauthorized, control-flow path A prominent example of this attack is the corruption of an authentica- tion variable, allowing the attacker to execute a privileged control- flow path|,Non-data,17
| Recently, Hu et al [21] demonstrated that such attacks allow Turing-complete malicious computation Goals and Contributions This paper proposes Control-FLow ATtestation (C-FLAT), a technique for precise attestation of the execution path of an application running on an embedded device|,Non-data,17
| C-FLAT complements static attestation by measuring the program’s execution path at binary level, capturing its runtime behavior As a new approach, C-FLAT represents an important and substantial advance towards tackling the open problem of runtime attestation C-FLAT allows the prover to efficiently compute an aggregated authenticator of the program’s control flow, ie|,Non-data,17
|, of the exact se- quence of executed instructions, including branches and function returns This authenticator represents a fingerprint of the control- flow path It allows the verifier to trace the exact execution path in order to determine whether application’s control flow has been compromised Combined with static attestation, C-FLAT can pre- cisely attest embedded software execution so as to allow detection of runtime attacks|,Non-data,17
| In designing C-FLAT, we focus on embedded systems As the initial proof-of-concept, we attest single-thread programs executed by small IoT MCUs, since C-FLAT is not meant for arbitrary com- plex applications We discuss the path towards control-flow attes- tation of MCUs in Section 8 The main contributions of this paper are: • A novel and practical scheme for attestation of the applica- tion’s execution path|,Non-data,17
| In contrast to more traditional static attestation, C-FLAT captures application’s runtime behav- ior (Section 4) • Addressing several challenges unique to control-flow path attestation, such as handling loops and call-return matching (Section 42) • A proof-of-concept implementation that features (i) a static analysis tool to determine valid control flows of an applica- tion, (ii) a static binary instrumentation tool to extend ARM binaries with C-FLAT functionality, and (iii) a background service implemented as a trusted application, using ARM TrustZone extensions, which monitors runtime control flow and generates the attestation response (Section 5)|,Non-data,17
| • A systematic evaluation of C-FLAT in the context of Open Syringe Pump, a real embedded control application for a widely- used class of cyber-physical systems (Section 6) We also demonstrate C-FLAT’s resilience against various runtime at- tacks (Section 7) We chose to initially instantiate C-FLAT using ARM TrustZone since ARM-based platforms (particularly Raspberry Pi) are widely available and popular for building embedded applications, eg|,Non-data,17
|, the syringe pump described in Section 61 Although our implemen- tation uses TrustZone-A hardware security extensions available in current general-purpose ARM processors, its more lightweight suc- cessor TrustZone-M will be available on ARMv8 MCUs [46] which are expected to come on the market soon This will allow C-FLAT to be easily realizable on commercial MCUs (see Section 8)|,Non-data,17
| Code Availability and Technical Report To enable reproducibil- ity of our results, and to encourage further research in this area, the source code for C-FLAT, our use-case cyber-physical programs, and the proof-of-concept exploits are available at https://googl/ pTiVdU We also provide an extended version of this paper as a technical report [2]|,Non-data,17
| 2 PROBLEM SETTING Runtime attacks exploit program vulnerabilities to cause malicious and unauthorized program actions The most prominent example is a buffer overflow, allowing the attacker to corrupt memory cells adjacent to a buffer The main target of these attacks is manipula- tion of control-flow information stored on the program’s stack and heap|,Non-data,17
| Figure 1: Abstract view of runtime attacks Figure 1 shows a generic runtime attack example of a program that calls either a privileged or non-privileged subroutine based on the authentication variable auth1 Line numbers in the pseudo- code map to CFG nodes The example program suffers from a control-flow vulnerability at node N3 allowing the attacker to over- write code pointers that store control-flow information (Typically, these vulnerabilities allow the attacker to read from, and write to, the application’s memory|,Non-data,17
|) Upon encountering the corrupted code pointer, the program’s control flow is deviated to either (i) previ- ously injected code (node NX) [3] or (ii) existing code (node N2) such as system functions [41] or unintended code sequences [39] The latter is commonly referred to as code-reuse attack, one type of which – called return-oriented programming – allows the attacker 1In general, any program can be abstracted through its correspond- ing control-flow graph (CFG), where nodes represent code blocks and edges control-flow transitions if(auth==true) then: call privileged()else: call unprivileged()terminate|,Non-data,17
privileged {,Non-data,17
instructions}unprivileged {,Non-data,17
instructions,Non-data,17
|}123456N1N2N3N4N5N6unprivileged pathprivileged pathcontrol-flow attack pathcontrol-flow vulnerabilitynon-control data vulnerabilityNX(i)(ii)(iii)attacker-injected codeX744to generate arbitrary malicious program actions based on chaining short sequences of benign code Since code-reuse attacks do not require injection of malicious code, they undermine the widely- deployed security model of data execution prevention (DEP) [31] which aims at preventing code injection attacks by either marking memory as writable or executable Code-reuse attacks have emerged as the state-of-the-art exploita- tion technique on various processor architectures|,Non-data,17
| Both control- flow integrity (CFI) [1] and code-pointer integrity (CPI) [26] aim at mitigating these attacks While CFI enforces the program always following a legitimate path, CPI ensures integrity of code pointers However, these schemes do not cover so-called non-control-data attacks [12] These attacks corrupt data variables which are used to drive the control flow of the program|,Non-data,17
| In the example of Figure 1, node N1 transitions the control flow to either N2 or N3, based on auth Thus, if the program suffers from a non-control-data vulnera- bility, the attacker can change auth from false to true, so that execu- tion continues in the privileged path although the user has not been authenticated to execute that path, ie, attack path (iii) in Figure 2|,Non-data,17
| For the sake of completeness, attacks discussed thus far lead to unintended, yet valid, program flows However, it is also possi- ble to mount pure data-oriented programming (DOP) attacks which only corrupt memory load and store operations, without inducing any unintended program flows [21] Consider a program that reads from a buffer via a data pointer and sends retrieved data over net- work A pure DOP attack would only manipulate the data pointer, e|,Non-data,17
|g, to reference a private key Hence, the original program con- trol flow would lead to leakage of the private key without incurring any suspicious control flows Since we focus on control-flow at- testation, such pure data-flow attacks are beyond the scope of this paper|,Non-data,17
| As shown in Figure 1, we focus on control-flow related at- tacks launched either by manipulating control-flow information, or non-control-data, such as data variables, ie, the attacks (i)-(iii) 3|,Non-data,17
| SYSTEM MODEL Figure 2 shows our system model: the verifier Ver wants to attest runtime control flows of an application module on a remote embed- ded system – the prover Prv The application module is typically an entire program or a subset thereof, such as a specific function Both Ver and Prv are assumed to have access to the binaries of the underlying application ment database ()|,Non-data,17
| This needs to be done only once per application module Since Prv is assumed to be a low-end anemic embedded device with very limited memory, it cannot generate and store the entire CFG However, this can be easily done by Ver which has no such resource limitations NOTE: We realize that efficient computation of a generic program’s CFG and exploration of all possible execution paths is an open problem|,Non-data,17
| However, in this paper, we focus on static embedded ap- plication software which is typically much simpler than programs for general-purpose computers, eg, the syringe pump program we analyze for our proof-of-concept consists of only 13k instructions In , Ver asks Prv to execute the application by transmitting a challenge that includes the name of the application module2 and a nonce to ensure freshness|,Non-data,17
| Next, Prv initiates execution of the ap- plication module (), while a dedicated and trusted Measurement Engine computes a cumulative authenticator Auth of the control- flow path () At the end, Prv generates the attestation report r = SigK (Auth, c), computed as a digital signature over the chal- lenge c and Auth using a key K known only to the Measurement Engine Finally, Prv sends r to Ver () for validation () Since Prv attests the application code (with static attestation) and its control flow (with C-FLAT), Ver can detect runtime at- tacks, as discussed in Section 2|,Non-data,17
| Any deviation from the program’s legitimate control flow results in an unrecognized measurement Further, non-control data attacks output an unexpected, though valid, measurement allowing Ver to detect attacks within the applica- tion’s valid CFG Static attestation (not shown in Figure 2), assures Ver that Prv is running the intended application 3|,Non-data,17
|2 Requirements and Adversarial Model As expected of an attestation scheme, we require that the attestation report (r) must be a fresh and authentic representation of the appli- cation’s runtime control flows The scheme itself must therefore be resilient against replay and masquerading attacks adversary, denoted by Adv We make the following assumptions about the behavior of the Adv can introduce arbitrary malware into the prover|,Non-data,17
| However, we rule out physical attacks, which is a standard assumption in all single-prover attestation protocols We focus on attacks that hijack the execution path of the code to be attested (see Section 2) Such attacks are based on providing malicious inputs to Prv’s public interfaces Furthermore, we assume the following Prv features: • Data execution prevention (DEP) to prevent an attacker from injecting and executing malicious code into running processes|,Non-data,17
| All modern platforms – including embedded systems – pro- vide hardware to support enforcement of this principle • A trust anchor that: (1) provides an isolated measurement en- gine, which cannot be disabled or modified by non-physical means (ie, it allows measurements for both the static and control-flow path attestation), and (2) generates a fresh, au- thenticated attestation report|,Non-data,17
| In Section 8, we discuss sev- eral concrete instantiations of this trust anchor These assumptions are in line with all previous work on remote attestation3 However, we consider a stronger Adv, capable of control-flow hijacking attacks Figure 2: Overview of C-FLAT 3|,Non-data,17
|1 Overview C-FLAT requires Ver to perform offline pre-processing: (1) gen- erate the control-flow graph (CFG) of the application module via static analysis (), and (2) measure each possible control-flow path using a measurement function H, and store the result in a measure- 4 C-FLAT DESIGN In order to perform control-flow attestation, Ver asks for a mea- surement of Prv’s execution path This measurement should allow Ver to efficiently determine and verify Prv’s control-flow path 2In practice, the verifier could transmit the actual application code|,Non-data,17
| 3Assuming a trust anchor is typical for remote attestation protocols Generate Control-Flow Graph: G=CFG(A(*))Verifier VerProver PrvChallenge cApplication Module AResponse rMeasure CFG Paths: H(G)Measurement DBApplication Module AExecute: Exec(A(input))Measure executed CFG Path: Auth=H(Exec(A(input)))Generate Authenticated Attestation Report: r=SigK(Auth,c)123456Verification of r7745It is clearly infeasible to record and transmit every executed in- struction, since that would: (1) result in a very long attestation response which Prv would have to store, and (2) require Ver to walk through every single instruction The same applies to another intuitive approach that would record and transmit source and tar- get addresses of every executed branch, since such instructions fre- quently occur during program execution To keep the attestation response short and allow fast verification, we propose a cumulative hash-based control-flow attestation scheme that builds a hash chain of executed control-flow transitions|,Non-data,17
| 41 C-FLAT: High-Level Description The main idea is to extend static (hash-based) attestation of bi- nary files to dynamic (runtime) control-flow paths Figure 3 illus- trates this idea based on a simple control-flow graph (CFG) already shown in Section 2 Each CFG node contains a set of assembler instructions, and each edge represents a node transition by means of a branch instruction|,Non-data,17
| Depending on the desired granularity, the nodes can be (1) entire functions, (2) basic blocks (BBLs) ending in an indirect branch, or (3) BBLs ending in any branch instruction, eg, direct or indirect jump, call and return In this paper, we con- sider the last case allowing Ver to precisely validate the executed control-flow path of an application on Prv’s device|,Non-data,17
| number of indirect and conditional branches Indirect branches may target from 1 to n nodes, and conditional branches target 2 nodes in the CFG Loops and recursive calls also lead to a high number of valid measurements, depending on the number of loop iterations, or recursive calls In Section 4|,Non-data,17
|2 we address this chal- lenge using an approach for efficient loop and recursion handling, allowing us to limit the number of possible (legal) measurements 42 Challenges There are several challenges in instantiating C-FLAT First, naïvely applying it to arbitrary code containing loops can lead to a combi- natorial explosion of legal Auth values, since each execution in- volving a distinct number of loop iterations would yield a different Auth value|,Non-data,17
| Furthermore, a static CFG does not capture call-return matching, eg, a subroutine might return to various call locations This would necessitate allowing too many possible Auth values that could be exploited by Adv [16]|,Non-data,17
| Loops Figure 4 depicts a CFG and its corresponding pseudo-code for a classic while loop, which contains an if-else statement Note that conditional statements (lines 2 and 3) introduce nodes (N2, N3) with multiple outgoing edges Hence, based on a condition check, they follow one of these edges|,Non-data,17
| The main challenge is that the cumulative hash computed at N2 is different at each loop it- eration, since it subsumes the cumulative hash produced after the previous iteration For an application that contains multiple (and even nested) loops, the number of legal Auth values grows expo- nentially, making control-flow attestation cumbersome Figure 3: C-FLAT control-flow attestation C-FLAT depends on every executed branch instruction It em- ploys a measurement function H which takes as input: (1) node ID of the source node Ni, and (2) previous measurement: Hi = H(Hprev, Ni)|,Non-data,17
| At the beginning, when no previous measurement is available, we start with Hprev = 0 As a result, there is a cumu- lative measurement for each possible program path, eg, the priv- ileged path outputs H5, while the unprivileged path leads to H6 in Figure 3|,Non-data,17
| Any unexpected measurement indicates to Ver that an illegal path has been executed Furthermore, based on the re- ported measurement, Ver can easily determine whether the privi- leged path has been executed Due to its speed and simplicity, we chose the cryptographic hash function BLAKE-24 as H for cumulative hashing that yields Auth Hash-based measurements are already deployed in static attestation and allow mapping of an input to a unique5 fixed-size result|,Non-data,17
| To generate the final attestation report r, Prv can use a public key signature or a MAC over Ver’s challenge c and Auth (Without loss of generality, we use signatures in the rest of the paper) In ei- ther case, the secret (private) key is assumed to be protected within the trust anchor Obviously, the number of valid measurements depends on the complexity and size of the application module, particularly, the 4https://blake2|,Non-data,17
|net 5With overwhelming probability Figure 4: Loop Handling in C-FLAT Our approach to tackling this problem is based on handling a loop as a sub-program We measure each loop execution separately and merge its cumulative value with that of the previous execution, at loop exit Consider the example in Figure 4: first, we identify the loop starting node by means of static analysis – N2|,Non-data,17
| Second, we initiate a new computation when the loop is entered, ie, H2a = H(0, N2) To avoid losing the previous value, we store H1|,Non-data,17
| Our example also has an if-else statement within the loop It di- verts control flow at N3 to either N4 or N5, depending on cond_2 Consequently, each loop iteration can either output H6a (solid line) or H6b (dashed line) Upon loop exit, it is also desirable to attest the number of times a loop is executed|,Non-data,17
| To do so, we track each N1N2N3N4N5N6H1=H(0,N1)H1=H(0,N1)H3=H(H1,N3)H2=H(H1,N2)H5=H(H2,N5)H6=H(H3,N6)Auth=H4= H(H6,N4) OR H(H5,N4)unprivileged pathprivileged pathN1N2N3N4H1=H(0,N1)H2a=H(0,N2)H3=H(H2a,N3)N5N6H3=H(H2a,N3)H5=H(H3,N5)H4=H(H3,N4)N7H6a=H(H4,N6)H2b=H(H1,N2)Auth= H7, <H1,{<H6a ,#H6a>,<H6b,#H6b>}>H6b=H(H5,N6)BBL_Awhile(cond_1) {if(cond_2)then: BBL_Belse: BBL_CBBL_D } BBL_E1234567H7=H(H2b,N7)746loop measurement separately, by storing the number of times a dis- tinct measurement was encountered at N2, and including this result #H6a, #H6b in Auth where #Hi reflects the number of loop it- erations for each possible path This ensures that every loop iter- ation is attested However, the size of Auth is now expanded by the number of different paths inside the loop In Section 6|,Non-data,17
|2, we demonstrate some actual Auth sizes for several sample runs of the syringe pump application Upon loop exit, we simply take the recorded measurement of the execution right before the loop was entered (H1) for the computa- tion of H2b The measurement for H2b does not capture whether the loop has executed However, observed loop path measurements are reported in Auth|,Non-data,17
| We denote these with < Hi, #Hi > to re- port the loop path measurement and the number of times this mea- surement has been observed Since a program might enter the loop at different execution stages, we need to separate loop counters for each stage Otherwise, Ver will not be able to determine the time when the loop has been entered For this, we maintain a reference that indicates the program stage at which loop measurements were taken|,Non-data,17
| This is achieved by simply taking the previous measurement right before the loop is entered, eg, H1 in Figure 4 This general approach also supports nested loops and recursive function calls, since each starting node initiates a separate mea- surement chain and the result at loop exit (or recursion return) is reported as separate measurements in Auth|,Non-data,17
| We also perform call- return matching on Prv in order to distinguish multiple instances of a particular loop from each other This includes recursive calls to subroutines that contain loops Such loops occur in the CFG only once but at runtime multiple loop instances might exist con- currently In such cases, each distinct instance is represented sep- arately in Auth|,Non-data,17
| For further details we refer the reader to the ac- companying technical report [2] Break Statements Another related challenge arises when break statements occur inside loops or switch-case statements Once en- countered during program execution, they immediately terminate the innermost loop|,Non-data,17
| Figure 5 shows a code example and its associ- ated CFG for such a case Compared to the previous loop example in Figure 4, node N5 now executes a break instruction, where the path leading to the break is indicated by a dotted line We need to treat break statements inside loops as special loop exit nodes with a slightly modified measurement function, for the following reason Typically, loop exits only occur at the conditional check at node N2|,Non-data,17
| However, break in N5 will not return back to the conditional statement, but immediately to N7 Hence, we slightly extend the original measurement function to capture the fact that the measurement right before the loop was H1 and the loop has been terminated over the break statement To do so, the measure- ment at N5 indicates that the loop has been entered at N2 with the previous hash value H1 (H2b) and terminated via N5 The same principle is applied to goto statements that terminate a loop, e|,Non-data,17
|g, a goto from a nested loop that also terminates an outer loop Call-Return Matching Function calls and returns pose another challenge, especially, when a subroutine can be invoked from mul- tiple calling locations|,Non-data,17
| Figure 6 depicts a sample scenario where two function calls (N2, N3) call subroutine N4 In the static CFG, the return instruction at N4 can either target N5 or N6 However, if the previous flow is not considered, Adv can execute a malicious path, eg|,Non-data,17
|, N2 (cid:55)→ N4 (cid:55)→ N6 As recent work demonstrates, such malicious flows allow for a variety of control-flow attacks [16] To cope with this issue, we index call and return edges during static analysis In the CFG of Figure 6, the call from N2 (cid:55)→ N4 is indexed with C1 and the corresponding return edge N4 (cid:55)→ N5 – with the same index marked as R1|,Non-data,17
| Hence, the only Auth values Ver considers legal are H4a and H4b Figure 6: Call-return matching IMPLEMENTATION 5 This section presents our prototype instantiation of C-FLAT and discusses its key implementation aspects 5|,Non-data,17
|1 Architecture of Proof-of-Concept To demonstrate the feasibility of C-FLAT, we prototyped it on a popular embedded platform As discussed in Section 32, remote attestation requires a trust anchor on Prv Because lightweight hardware trust anchors for small embedded devices, such as Intel’s TrustLite or ARM’s TrustZone-M, are not currently commercially available we opted for a more powerful ARM application processor that features TrustZone-A [4] security extensions for our prototype|,Non-data,17
| Specifically, we chose Raspberry Pi 2 as the underlying embedded device platform In our experimental setup, Raspberry Pi 2 is set up to execute a bare metal, monolithic, single-purpose program in the “Normal World” [4] of the ARM core, without a separate OS In Section 8, we explain why the same approach is also applicable in systems where applications run on top of an embedded OS The prototype has two main components: i) a program analyzer to compute legal measurements of the target program, and ii) a Runtime Tracer and an isolated, trusted Measurement Engine to trace and measure the runtime control-flow path|,Non-data,17
| The former can Figure 5: Handling Break Statements in C-FLAT N1N2N3N4H1=H(0,N1)H2a=H(0,N2)H3=H(H2a,N3)N5N6H3=H(H2a,N3)H5=H(H2b,N5)H4=H(H3,N4)N7H6=H(H4,N6)H2b=H(H1,N2)Auth= H7, <H1,{<H6 ,#H6>, <H3 ,#H3>}>BBL_Awhile(cond_1) {if(cond_2)then: BBL_Belse: breakBBL_C } BBL_D1234567H7=H(H2b,N7) OR H(H5,N7)N1N2N4N5H1=H(0,N1)H4a=H(H2,N4)N6H4b=H(H3,N4)Auth=H4aOR H4bN3H1=H(0,N1)H2=H(H1,N2)H3=H(H1,N3)CALL:RET:C1C2R1R2747be realized either as: (1) a static binary analyzer that generates the program’s CFG by identifying basic blocks and their connection through branch instructions, or (2) a dynamic analyzer that pro- duces valid measurements for a set of inputs by tracing execution of the target program We opted for a dynamic analyzer We also developed a binary rewriting tool for ARM binaries used to instru- ment the target program in order to allow the Runtime Tracer to in- tercept all branches during execution Figure 7 shows the C-FLAT prototype architecture|,Non-data,17
 Black boxes depict C-FLAT system com- ponents Below we describe the operation of the prototype Figure 7: Proof-of-concept architecture Instrumentation Phase Initially the program binary is analyzed and instrumented using our instrumentation tool,Non-data,17
| During the anal- ysis, information about direct branches and loops is collected from the binary, and stored in the branch table and loop table data struc- tures included as part of the Runtime Tracer in the software image loaded onto Raspberry Pi 2 At runtime, these data structures are made available in read-only memory to the Runtime Tracer and Measurement Engine During instrumentation, each control-flow instruction in the tar- get program is modified to pass control to Trampolines belonging to the Runtime Tracer Further details about the instrumentation tool can be found in Section 5|,Non-data,17
|2 We note that the analysis and trans- formations done to the target program could also be performed at program load time, either by a trusted bootloader, or a program loader in configurations where an embedded operating system is present on the device Runtime Operation The C-FLAT Library () serves as a media- tor between the attested program on Prv and the Measurement En- gine|,Non-data,17
| It provides an API that allows software on Prv to initiate the attestation procedure, and obtain an attestation response from the Measurement Engine Specifically, cfa_init initializes a new control-flow trace for attestation, and cfa_quote generates the attestation response from initialized trace Once Prv receives the challenge c from Ver, it initiates a runtime trace by executing the cfa_init function () and proceeds to execute the target pro- gram The attestation procedure on Prv may be initialized from within the target program in cases where an attestation of only a particular operation is desired|,Non-data,17
| The target program can, based on eg, input from the verifier, decide at runtime which portions of program operation are to be attested As a result of the instrumentation of the target program binary, all control-flow instructions are intercepted by the Runtime Tracer Trampolines ()|,Non-data,17
| The Runtime Tracer determines the source and destination address of the observed branch, and the type of control- flow instruction that caused it (see Section 52) It then triggers the Measurement Engine () The Measurement Engine performs the incremental measurement of the runtime control-flow path as described in Section 4, i|,Non-data,17
|e, computes the cumulative Auth (using the BLAKE2 hash function) The Measurement Engine then trans- fers control back to the Runtime Tracer, which in turn resumes the execution of the target program at the destination address of the observed branch () Once the program procedure that is to be at- tested completes, Prv executes the cfa_quote function () with the challenge c provided by Ver|,Non-data,17
| This triggers the Measurement Engine to finalize Auth and generate the attestation response Trust Assumptions are as follows: • Assumption 1: The Normal World software stack, including the attested target program and Runtime Tracer components are covered by the static attestation from Prv to Ver • Assumption 2: The Measurement Engine is trusted and can- not be disabled or modified Static attestation of the Normal World software stack ensures that Adv cannot modify this without being detected by Ver|,Non-data,17
| This is im- portant because it allows Ver to detect if Adv tampers with Nor- mal World software to manipulate the inputs to the Hash Engine computing cumulative hashes Isolation of the Measurement En- gine from the Normal World is important since, in the event of a compromised control flow (even without modifying Normal World software), Adv might attempt to influence hash computation prior to its delivery to Ver It is also possible that an adversary may attempt to mount a run- time attack against the Runtime Tracer and through this tamper the input to the Measurement Engine However, the Measurement En- gine can prior to relinquishing control back to the Trampoline that triggered the measurement validate that the actual destination of the recorded branch matches the input to the algorithm|,Non-data,17
| We implemented the Measurement Engine as a monolithic trusted kernel executing in the ARM TrustZone “Secure World” [4], thus isolating it from the untrusted target program, and the Runtime Tracer, to prevent Adv from tampering with measurements Node IDs Recall that C-FLAT requires unique node IDs for CFG nodes There are several options for doing this: (1): Identify en- try and exit addresses of basic blocks|,Non-data,17
| These addresses are unique and already present, without extra instrumentation However, they change for each run of the program, if memory layout random- ization (ASLR) [27] is used (2): Using labels, instrument the pro- gram to embed a unique ID at the beginning of each basic block, similar to label-based CFI schemes [1] (3): Maintain a dedicated table that maps memory addresses of basic blocks to node IDs|,Non-data,17
| We selected (1), since many embedded systems do not yet sup- port ASLR due to lack of an MMU However, if ASLR is used, we can either report the base address in the attestation result, or adopt alternative approaches 52 ARM Instrumentation Another consideration for our implementation is the instrumenta- tion of ARM binaries|,Non-data,17
| 32-bit ARM processors feature 16 general- purpose registers All these registers, including the program counter (pc) can be accessed directly In addition to a 32-bit RISC instruc- tion set, ARM processors also support a 16-bit Thumb instruction set Thumb instructions act as compact shorthands for a subset of the 32-bit ARM instructions, allowing for improved code density|,Non-data,17
 Modern ARM processors extend the Thumb instruction set with 32- bit instructions (distinct from those in the 32-bit ARM instruction set) that may be intermixed with 16-bit Thumb instruction The resulting variable-length instruction set is referred to as Thumb-2 Programs conforming to the ARM Architecture Procedure Call Standard (AAPCS) [5] perform subroutine calls either through a Branch with Link (bl) or Branch with Link and eXchange (blx) These instructions load the address of the subroutine to the pc and the return address to the link register (lr),Non-data,17
| The non-linking vari- ants, Branch b and Branch and eXchange, are used to direct the Secure WorldMeasurement EngineAttestationHardwareTrusted KernelHash EngineTrampolinesTarget ProgramC-FLAT LibraryBootloader13cfa_initcfa_quote5ins_Ains_Bins_Cbranch Cins_Dins_F2674Runtime TracerNormal World748control flow within subroutines as they update the pc, but leave lr untouched The ARM architecture provides no dedicated re- turn instruction Instead, any instruction that is able to write to the program counter may function as an effective return instruction In order to faithfully reproduce the control flow of the program being attested, our instrumentation approach needs to be able to in- tercept all instructions sequences that affect the control flow of the monitored program|,Non-data,17
| On our evaluation platform programs execute solely in the 32-bit ARM state, allowing us to instrument the pro- gram binary such that all control-flow instructions are replaced by instructions that transfer control to a fixed piece of code belonging to the Runtime Tracer Binary rewriting In the instrumentation phase, the original branch targets for direct branch instructions are collected from the target program binary to be stored at runtime in the read-only branch table data structure that resides in target program memory Each target address is indexed in the branch table by the location of the orig- inal branch instruction|,Non-data,17
| These locations, the locations of indirect branches, as well as other control-flow instructions are overwrit- ten with dispatch instructions that redirect program control flow to a short piece of assembler code, the trampoline We use the bl instruction as the dispatch instruction The value of lr after the dispatch is used to identify the call site of the trampoline Our tool utilizes the Capstone disassembly engine6 to identify control-flow instructions for rewriting|,Non-data,17
| Trampolines Each different type of control-flow instruction re- quires a separate trampoline, but unlike previous work [15], our approach does not leverage a separate trampoline for each instru- mented branch The trampoline manages the return address regis- ter as well as the register holding the destination address in indirect branches If the original instruction was a non-linking branch, the trampoline must retain the original link register value from the prior bl originally present in the executable, and restore the program link register upon returning to program code|,Non-data,17
| In order to avoid overwriting values stored in lr, the target pro- gram must not use lr as a general purpose register This can be enforced at compile time using appropriate compiler options During program execution, the trampoline will collect the return address from lr and determine the original branch target For di- rect branches, the trampoline will look up the original destination address from the branch table|,Non-data,17
| For indirect branches, the trampo- line will consult the corresponding register holding the destination address, and for instructions utilized as function returns, the tram- poline will either read the destination address from the stored lr value, or read the return address from the program stack It will then invoke the Measurement Engine through a Secure World tran- sition, passing as parameters the source and destination address After trampoline execution resumes, control is transferred back to the target program, to the original branch destination Conditional branches|,Non-data,17
| All conditional branch instructions in the ARM instruction set have a linking bl variant that updates lr During instrumentation, we use the bl variant to redirect execu- tion to the corresponding trampoline, but do not change the condi- tion under which the branch is executed Conditional branches that are not taken must at runtime be inferred from the branch informa- tion collected during the instrumentation phase, or by introspecting the program code In C-FLAT, we make the branch table avail- able to the Measurement Engine, and infer non-taken conditional branches based on the start of the previous basic block known to the Measurement Engine, and the source address of the branch that caused us to enter the Secure World|,Non-data,17
| 6 EVALUATION We evaluated our design and prototype implementation by apply- ing C-FLAT to a real embedded application This section describes our case study application, explains the attestation results, and dis- cusses runtime performance The practical attacks and mitigations we demonstrated using this case study are presented in Section 7|,Non-data,17
| 61 Case Study of a Cyber-Physical System A syringe pump is an electromechanical system designed to dis- pense (or withdraw) precise quantities of fluid It is used in a vari- ety of medical applications, especially those requiring small quan- tities of medication to be administered relatively frequently Many research fields, including chemical and biomedical research, also use syringe pumps|,Non-data,17
| Commercial syringe pumps are usually expen- sive, especially if they have been certified, but there has recently been significant interest in producing low-cost open-source alter- natives [45] Functionality A syringe pump typically consists of a fluid-filled syringe, a controllable linear actuator (eg|,Non-data,17
|, using a stepper motor), and a control system The control system’s task is relatively sim- ple and would typically be implemented on an MCU – it translates the desired input value (eg, millilitres of fluid) into the control output for the actuator (e|,Non-data,17
|g, setting a digital IO line high for a cal- culated duration) However, given its intended usage, this system must provide a very high degree of assurance that it is operating correctly In both commercial and open-source designs, the control system may be a weak point since it runs embedded software and accepts external input (potentially from remote sources)|,Non-data,17
| Unde- tectable runtime attacks affecting either the control flow or critical data variables could have serious consequences This is therefore a prime use case for C-FLAT Open Syringe Pump For this case study, we used Open Syringe Pump, an open-source, open-hardware syringe pump design|,Non-data,17
|7 It is controlled by an Arduino MCU running an embedded applica- tion written in Arduino Script Since C-FLAT is not yet available for this type of MCU, we ported the application to a Raspberry Pi, which provides the required ARM TrustZone extensions Other open-source syringe pump designs already use the Raspberry Pi as a controller (eg|,Non-data,17
|, [45]), but run the control software as an appli- cation on top of a Linux OS To retain the embedded nature of the controller, we chose to port Open Syringe Pump as a bare-metal im- plementation, which removes potential vulnerabilities introduced by an OS Our port required only minimal changes to the source code (less than 25% of the overall application) in order to adapt it from Arduino Script to C Neither the functionality nor the control- flow graph (CFG) of the application was changed|,Non-data,17
| In terms of func- tionality, this application reads user input via the serial connection, and then performs one of the following types of actions: • set-quantity: a numeric input changes a state variable • move-syringe: a trigger input causes the syringe pump representing the quantity of fluid to be used; to dispense or withdraw the set quantity of fluid; These types of actions naturally have different control flows, but even for the same action, the exact control flow depends on the state variable (ie, the user-defined quantity of fluid) Overall, the compiled application has a total of 13,000 instructions, and its static CFG contains 332 unique edges, of which 20 are loops|,Non-data,17
 62 Attestation Results We evaluated the functionality of our prototype implementation by instrumenting the syringe pump controller application and attesting 6http://wwwcapstone-engineorg/ 7https://hackaday,Non-data,17
|io/project/1838-open-syringe-pump 749the critical section of this application Specifically, we attested the sequence of actions that take place immediately after an external input is provided This ensures that any action which exercises the critical functionality (eg|,Non-data,17
|, causes the syringe to move) is covered by the attestation, whilst eliminating irrelevant time periods when the state of the system does not change We supplied a range of different inputs and recorded the resulting Auth values For the set-quantity path, the maximum length of Auth was for any input value was 1527 bytes This path contains 16 loop invocations, and 18 unique loop paths|,Non-data,17
| Similarly, for the move-syringe path, the maximum Auth length was 1179 bytes (12 loop invocations and 14 unique paths) As expected, whenever the same control-flow path was taken (eg, set-quantity or move-syringe), the same final hash value was obtained|,Non-data,17
| These hash values therefore enable the ver- ifier to determine the precise control-flow path that was actually executed In this application, these hash values remained the same irrespective of the quantity of fluid dispensed/withdrawn by the sy- ringe The reason for this is that the state variable is only used to determine how many times a critical loop should be executed The value of the state variable is therefore captured entirely in the addi- tional loop information provided with the attestation|,Non-data,17
| Although the purpose of this loop handling behavior is to overcome the exponen- tial increase in complexity caused by loops, in this application (and others like it) this also greatly simplifies the attestation output 63 Performance Impact We measured the time taken to perform C-FLAT attestation in the syringe pump case study in order to determine (a) which factors affect the attestation overhead, and (b) whether this overhead is tol- erable in real applications All timing measurements were obtained using the hardware’s built-in performance counters|,Non-data,17
| It is important to emphasize that, in a real-world deployment, this type of attes- tation would not be used on every execution of the program The verifier can choose when and how frequently to attest the prover Attestation overhead We measured the time required to perform a complete attestation of the system, whilst varying the applica- tion’s state variable through a representative range of values (i|,Non-data,17
