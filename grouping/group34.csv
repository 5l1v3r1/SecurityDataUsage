 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| 221 Testing Once the devices Di have been produced by the (mali- cious) manufacturer, they are tested by a PPT tester T The goal of T is to verify whether each Di implements its corresponding functionality given by the circuit specification Γi|,Non-data,82
| We consider black-box testing That is, T can specify the inputs of Di and communicate with Di over the specified interface To this end, the tester will typically take the role of the master M, ie|,Non-data,82
|, the tester can run the manufactured devices Di on chosen inputs and verify whether the results correspond to the results produced by the honest function- ality Γi Notice that these tests typically also include the verification of the communication with M We will write b ← TD1(),|,Non-data,82
|,D(cid:96)()(1k, Γ), where T can interact with the de- vices Di via the communication commands and at the end of the test outputs a bit b indicating whether the test has passed or failed|,Non-data,82
| We call the tester T t-bounded, if each of the Di is run for at most t times 222 Trojan protection schemes A trojan protection scheme Π := (TR, T) consists of the circuit transformation TR and the testing algorithm T|,Non-data,82
| We 3Concretely, in our construction the devices Di supposedly run a passively secure 3-party protocol At some point in the proof we want to replace the physical devices Di by some abstract description of a circuit ̃Γi (which is not necessarily the same as Γi) that emulates the malicious behavior of Di At this point in the proof we need Assumption 1 145Game ROBΠ(A, pub, Γ, (cid:126)m): ((M,{Γi}i), (cid:126)m(cid:48)) ← (TR1(1k, (cid:96), Γ), TR2(1k, (cid:96), (cid:126)m)) {Di}i ← A(1k, (M,{Γi}i)) Set the initial state of the devices Init({Di}i, (cid:126)m(cid:48)) If TD1(|,Non-data,82
|),,D(cid:96)(|,Non-data,82
|)(1k, (M,{Γi}i)) = false then return 0 (cid:126)x1 ← A(1k) For i = 1 to n repeat: (cid:126)zi ← (M ⇔ D1,    , D(cid:96))[ (cid:126)m(cid:48)]((cid:126)xi) (cid:126)yi ← Γ[ (cid:126)m]((cid:126)xi) If (cid:126)yi (cid:54)= (cid:126)zi then return 1 (cid:126)xi+1 ← A(1k, (cid:126)zi) Return 0|,Non-data,82
| Figure 1: The robustness game ROBΠ model security of the trojan protection scheme Π against a malicious manufacturer by a robustness game denoted by ROBΠ, given in Figure 1 In the game, we first run the trans- formation to obtain the specification of the protected circuit ((M,{Γi}i), (cid:126)m) Next, the specification is given to the ma- licious manufacturer A who outputs a set of devices {Di}i|,Non-data,82
| The devices are tested by T, and if the testing succeeds then A may interact with (cid:126)zi ← (M ⇔ D1,    , D(cid:96))[ (cid:126)m]((cid:126)xi) by spec- ifying an input (cid:126)xi and receiving the output (cid:126)zi|,Non-data,82
| We say that A wins the game iff after the testing has succeeded, he man- ages to produce an output (cid:126)zi that differs from the output (cid:126)yi of a correct computation on input (cid:126)xi, ie, (cid:126)yi ← Γ[ (cid:126)m]((cid:126)xi) Note that for our constructions, we will require that the number of tests t done by T is larger than the number of executions n|,Non-data,82
| We state the security properties of a trojan protection scheme as: Definition 1 Let (cid:96), n, t, and k be some natural parame- ters A trojan protection scheme Π = (TR, T) is (t, n, )- trojan robust if the following two conditions hold: 1 The tester T is t-bounded, 2|,Non-data,82
| For any manufacturer A, any circuit Γ and any initial state (cid:126)m we have: Pr[ROBΠ(A, (cid:96), n, t, k, Γ, (cid:126)m) = 1] ≤ , where the probability is taken over the internal coin tosses of A and the coin tosses of the game ROBΠ To simplify the notation in the sequel we will use a symbol pub as a shorthand for the tuple consisting of “public param- eters” in ROB, ie we will set pub := ((cid:96), n, t, k), and write ROBΠ(A, pub, Γ, (cid:126)m)|,Non-data,82
| 3 IMPOSSIBILITY RESULTS We now discuss some inherent limitations of the testing techniques presented in the previous section First, we argue that in most of the realistic applications the maximal num- ber t of testing rounds should be much larger than the num- ber n of times that the device will be used For this purpose, consider a single device D and suppose that the malicious manufacturer designed it in such a way that it behaves as its specification requires, except with probability  (whose value we will determine later)|,Non-data,82
| More precisely let Badi de- note the event that in the ith round of its life (during testing or the real execution) D behaves wrongly (for example: it starts to produce wrong results, or it terminates) Assume that the Badi’s are independent, and Pr(Badi) =  The probability that this malicious actions are not de- tected during testing is equal to Pr(¬Bad1 ∧ ··· ∧ ¬Badt0 ), where t0 ≤ t is the number of rounds of test This, clearly, is at at least equal to (1 − )t|,Non-data,82
| Similarly the probability that a Bad event happened during one of the n rounds of execution is equal to 1 − (1 − )n Hence the probability p that D passed the tests and failed during the execution is at least equal to (1 − )t · (1 − (1 − )n) Now suppose that the adversary sets  := 1 − (t/(n + t))1/n Then p is at least (t/(n + t))t/n · n/(n + t) = (1 + n/t)−t/n · n/(n + t), which is at least equal to n/(e · (n + t)), where e is the base of the natural logarithm (this is because (1 + n/t)−t/n ≥ e−1)|,Non-data,82
| This in particular means that if t is small then with very good probability (at least n/(e · (n + t))) the adversary’s device behaves correctly during the testing, and incorrectly during the real-life execution This shows that in reality we will usually need to have t (cid:29) n if we want to get high as- surance that the device will not fail during the execution Also, since this probability is inversely proportional to the number t of tests, thus, intuitively, to obtain error proba- bility smaller than O(n−c) (for some c) we need to have at least c devices D in the system This last statement is of course informal, since in order to formalize it, we would need to restrict the power of the master circuit (in principle every computation can be done in a perfectly secure way if it is performed by the trusted master)|,Non-data,82
| For this purpose, we next state some simple ob- servations regarding the necessary complexity of the master circuit First, note that the above observations imply that, in order to get any security beyond the “n/(e · (n + t))” bar- rier, none of the Di gadgets can be “directly connected to the output”, ie, the master circuit M cannot just forward the outputs from Di as its own output (without performing any computation on this value)|,Non-data,82
| This is because the adver- sary can make such “unprocessed” output to be wrong with probability n/(e · (n + t)) It justifies why we always need some kind of “output processing” (which, in our case, will be handled by a majority gate) A similar fact can be shown about the input processing, ie|,Non-data,82
|, we can prove that in most of the cases no M can pass its input directly to one of the Di gadgets Observe, that the above fact certainly cannot hold for all functionalities Γ For illustration, suppose that Γ ignores its input (eg|,Non-data,82
|, it is a pseudorandom generator whose output depends only in the initial state and does not depend on the inputs) Then it can be implemented by (M ⇔ D1,   |,Non-data,82
| , D(cid:96)) such that M sends its inputs directly to the some “dummy” Di’s that do not perform any actions To be more formal, let us say that a circuit Γ is simple if it contains no gates (ie it has only wires)|,Non-data,82
| We say that a circuit Γ can be simplified if for every initial state (cid:126)m there exists a sequence {Γi}i=1 of simple circuits which, for every sequence {(cid:126)xi}i of inputs Γ with initial state (cid:126)m and rounds inputs {(cid:126)xi}i, produces the same output as {Γi}i=1 on inputs {(cid:126)xi}i (where in round i we apply Γi to (cid:126)xi) Intuitively, a circuit, cannot be simplified if it performs some non-trivial operations on its input We now show that every such a circuit Γ cannot be simu- lated by a circuit Γ(cid:48) = (M ⇔ D1,  |,Non-data,82
|  , D(cid:96)), where M is simple (and in particular, every circuit with simple M can be bro- ken with probability close to 1 for n that does not depend on t) We consider circuits Γ that do not have any randomness gates, but our argument can be generalized also to the case of circuits with random gates 146Lemma 1|,Non-data,82
| Consider a trojan protection scheme Π = (TR, T) Suppose it produces as output only circuits (M,{Γi}i) such that M is simple Let Γ be a circuit that cannot be simplified, and suppose (cid:96)(k) is the number of sub-circuits Γi that Π produces on input (Γ, 1k) Then the scheme Π is not (t, n, )-trojan robust for any t, k, n = ((cid:96)(k) + 1) · k, and  < 1 − ((cid:96)(k) · t + 1) · ||F||−k|,Non-data,82
| The proof of the lemma appears in the extended version of this paper [15] Summarizing, the above statements high- light that the complexity of both the testing phase and the master circuits in the following constructions (measured in number of tests and gates) is essentially necessary 4 TROJAN RESILIENT CIRCUITS To simplify our analyses, we first consider the case when Γ is deterministic and does not update its initial state|,Non-data,82
 This means that once the state has been initialized to (cid:126)m it is never changed by the computation of Γ AES implementations are an example of such circuits In Section 45 we then discuss how to extend our results to circuits that update their state (e,Non-data,82
|g, stream cipher) and are probabilistic 41 Our basic construction i , Γ2 i , Γ1 The compiler TR takes as input a description of a (bi- nary/arithmetic) circuit Γ and outputs λ sub-circuits Γi := i ) for i ∈ [λ] and the master circuit M|,Non-data,82
| Each sub- (Γ0 circuit consist of three mini-circuits so that (cid:96) = 3λ While the λ sub-circuits operate independently from each other (ie, there is no communication between them), the mini- circuits of each sub-circuit are connected through M|,Non-data,82
| The processing of an input (cid:126)x ∈ Fα with an initial secret input (cid:126)m resulting in an output (cid:126)y ∈ Fβ proceeds in three phases: (i) the input pre-processing phase, (ii) the compu- tation phase and (iii) the output post-processing phase The bulk of the computation is carried out in phase (ii), while phase (i) and (iii) are carried out by the master M Since the implementation of M has to be trustworthy, we will minimize the work of M In particular, we require that the number of gates (but not the number of wires) used by M is inde- pendent of the number of gates used by Γ; instead, it will depend only on Γ’s input size α and output size β|,Non-data,82
| The over- all structure of the specification of the transformed circuit Γ(cid:48) is given in Figure 2 In the pre-processing phase on input (cid:126)x the master circuit M produces λ additive 2-out-of-2 secret sharings of (cid:126)x More formally, it proceeds as follows: 1 Repeat the following for i ∈ [λ]: (a) Sample (cid:126)ri ← Fα using α rand gates|,Non-data,82
| (b) Compute (cid:126)si = (cid:126)x − (cid:126)ri 2 Output {((cid:126)ri, (cid:126)si)}i Note that such a pre-processing does not imply that the master cricuit needs to generate trusted randomness|,Non-data,82
| As discussed in Section 61, we can use an efficient construction of trojan-secure PRG for this purpose i , Γ2 In the computation phase, each triplet of sub-circuits Γi := (Γ0 i , Γ1 i ) implements computation of the circuit Γ using a passively secure 3-party protocol While in principle any construction of a passively secure 3-party protocol will work, we chose to present a particular protocol which is well-suited Figure 2: Transformed circuit (global view)|,Non-data,82
| for our application and allows efficient hardware implemen- tations4 In our construction the λ sub-circuits Γi carry out exactly the same computation, where Γi uses the public in- put tuple ((cid:126)ri, (cid:126)si) Since the computation of each sub-circuit is identical, to ease notation, in the following we omit to explicitly mention the index i The triplet (Γ0, Γ1, Γ2) eval- uates the circuit Γ gate-by-gate|,Non-data,82
| That is, each gate in Γ is processed by the sub-circuit (Γ0, Γ1, Γ2) running a secure 3-party protocol emulating the operation of the gate in Γ In the computation phase, the role of the master M is re- stricted to forward commands between mini-circuits In par- ticular, to initiate the computation of (Γ0, Γ1, Γ2) the master M sends the following command to Γi: 1 (in, (cid:126)r) to Γ1 and (in, (cid:126)s) to Γ2, respectively|,Non-data,82
| 2 (in, ∅) to Γ0 Notice that this means that Γ0 is inde- pendent of the inputs of the computation On receiving the in command, the mini-circuits (Γ0, Γ1, Γ2) will then run one of the protocols shown in Figure 3 depend- ing on the type of gates in Γ|,Non-data,82
| The basic invariant is that (Γ0, Γ1, Γ2) guarantee that for a gate g in Γ that outputs c, we have that at the end of the protocol Γ1 produces c1 while Γ2 computes c2 such that (c1, c2) represents a ran- dom sharing of c In other words: each value on a wire in Γ is shared between Γ1 and Γ2 The mini-circuit Γ0 is in- volved only for computing the field multiplication by provid- ing correlated randomness To generate randomness, Γ0 will use an implementation of a secure pseudorandom generator prg : Fs → Fκ|,Non-data,82
|5 To this, end it holds an initial state (cid:126)w ∈ Fs in its internal memory gates and computes ( (cid:126)w, (cid:126)y) = prg( (cid:126)w) 4In principle, for our application a passively secure 2-party protocol (eg, [14], Chapter I, Section 4) would suffice|,Non-data,82
| How- ever, the security would need to rely on computational as- sumptions for the OT protocols, which would result in a less efficient scheme In the following, the OT protocol is therefore performed by a third party, which samples an “OT- tuple”, ie, correlated randomness that is later used by the two other parties to perform secure computation|,Non-data,82
| 5Notice that common implementations of PRGs do not out- 1471 Transformation for field addition, ie, (cid:126)a(cid:98)⊕(cid:126)b = (cid:126)c: Γ1 holds the shares (a1, b1) that either were received from M via an in 2|,Non-data,82
| Transformation for multiplication, ie, (cid:126)a(cid:98)(cid:12)(cid:126)b = (cid:126)c: This involves the mini-circuits (Γ0, Γ1, Γ2) and the driver circuit command, or resulted as an output from a previous gate Similarly, Γ2 holds (a2, b2)|,Non-data,82
| Given these inputs Γ1 computes c1 = a1 ⊕ b1 and Γ2 computes c2 = a2 ⊕ b2 Evaluating the gates g of Γ by (Γ0, Γ1, Γ2) to forward commands between the circuits Γi To keep the description simple, we will not explicitly describe the computation carried of by M as it only forwards commands Initially, Γ1 holds (a1, b1) and Γ2 has (a2, b2)|,Non-data,82
| They proceed as follows: (a) Run jointly (u, v) ← MultShares(a1, b2) and (u(cid:48), v(cid:48)) ← MultShares(b1, a2) (see description below) (b) Mini-circuit Γ1: Compute c1 = a1 (cid:12) b1 ⊕ u ⊕ u(cid:48) and output c1 (c) Mini-circuit Γ2: Compute c2 = a2 (cid:12) b2 ⊕ v ⊕ v(cid:48) and output c2 Sub-circuit (u, v) ← MultShares(x, y) Initially, Γ1 holds x and Γ2 holds y|,Non-data,82
| At the end Γ1 holds u and Γ2 has v such that v = x (cid:12) y ⊕ u and u ∈ F defined below 1 Mini-circuit Γ0[ (cid:126)w]: Γ0 has memory cells to store the internal state of the PRG (cid:126)w Notice that Γ0 uses the contents of its memory cells (cid:126)w and computes ( (cid:126)w, (u1, u2, u3, u4)) = prg( (cid:126)w), where the output (cid:126)w represents the secret output|,Non-data,82
| It then computes u = u3 ⊕ u4 (cid:9) u1 (cid:12) u2 and sends ((send, 1), (u, u2, u3)) and ((send, 2), (u1, u4)) to M 2 Mini-circuit Γ2: on receiving ((send, 2), (u1, u4)) from M, compute z = y ⊕ u1 and send ((send, 1), z) to M 3|,Non-data,82
| Mini-circuit Γ1: on receiving ((send, 1), (u, u2, u3, z)) from M, compute e = (z (cid:12) x) ⊕ u3 and f = x ⊕ u2 Send 4 Mini-circuit Γ2: on receiving ((send, 2), (e, f )) from M, compute v = u4 ⊕ e (cid:9) f (cid:12) u1 ((send, 2), (e, f )) to M|,Non-data,82
| Figure 3: The computation of the gates by the sub-circuits (Γ0, Γ1, Γ2) All operations are field operations in the underlying field F The MultShares circuit is used as sub-circuit in the field multiplication operation, where the latter is also shown in Figure 6 explaining the communication in further detail Here, (cid:126)w is the internal state of the PRG and (cid:126)y is the out- put|,Non-data,82
| For our concrete construction, we require κ := s + 4 Notice that for security it does not matter how prg is imple- mented Hence we misuse notation and let prg denote the circuit computing the PRG Finally notice that to simplify the description all operations described in Figure 3 have fan- out 1|,Non-data,82
| An extension to larger fan-out is trivially possible by just fanning out this single output Finally, in the output post-processing phase, we have that for each i ∈ [λ] the sub-circuit Γ1 i sends (out, (cid:126)di) to M Here, ((cid:126)ci, (cid:126)di) are λ independent sharings of the output (cid:126)y of Γ On receiving the out commands M proceeds as follows: i sends (out, (cid:126)ci) and Γ2 1|,Non-data,82
| For each i ∈ [λ] compute (cid:126)yi = (cid:126)ci + (cid:126)di 2 Output MAJ((cid:126)y1,  |,Non-data,82
|  , (cid:126)yλ), where MAJ returns the most common value that occurs as an input; if two or more inputs are most common, then it outputs the first one of them Notice that MAJ can easily be implemented using only standard arithmetic gates i , Γ2 the original circuit Γ)|,Non-data,82
| Of course, the memory cells may be updated by the circuits (Γ1 i ) during the runs of the circuit In the following description, we will often neglect mentioning the initial state explicitly as essentially it can be treated in the security analysis as part of the public inputs (this makes the adversary only stronger) 42 Correctness Correctness of our construction follows by observing that the output of a transformed operation satisfies the invariant that it is a sharing of the corresponding value on the wire in Γ|,Non-data,82
| The only non-trivial operation is the transformation (cid:98)(cid:12) of the field multiplication, which requires interaction between the mini-circuits Hence, it results in connecting wires be- tween the different Γj We show that the transformation for the multiplication gate achieves correctness Lemma 2|,Non-data,82
| For any (cid:126)a,(cid:126)b ∈ F2 we have c1 ⊕ c2 = (a1 ⊕ a2) (cid:12) (b1 ⊕ b2), where (c1, c2) = (cid:126)a(cid:98)(cid:12)(cid:126)b is the output of the transformed multiplication operation We additionally need to describe how to handle the initial secret state (cid:126)m The initialization function Init produces for each sub-circuit i ∈ [λ], a secret sharing of (cid:126)m as (cid:126)oi ← Fs and (cid:126)pi = (cid:126)m − (cid:126)oi, and stores (cid:126)oi in the internal memory cells of Γ1 i , respectively Notice that this implies that in total we require 2λs mem- ory cells in the transformed specification (compared to s in i and (cid:126)pi in the internal memory cells of Γ2 put random field elements, however, it is easy to do such a mapping in practice and we believe that the most common application of our techniques are binary circuits anyway, in which case we may just use AES in counter mode|,Non-data,82
| The proof of this lemma appears in the extended version of this paper [15] To complete the correctness analysis, observe that each of the sub-circuits Γi produces a shar- ing of an output (cid:126)yi When M receives the out command it will re-combine the two shares to recover (cid:126)yi and compute MAJ((cid:126)y1,  |,Non-data,82
|  , (cid:126)yλ) Due to the correctness of the computation phase all of them will be identical, and MAJ((cid:126)y1,  |,Non-data,82
|  , (cid:126)yλ) out- puts the correct result (cid:126)y ← Γ((cid:126)x) It is straightforward to extend the correctness analysis to circuits that have secret inputs/outputs We can just view the secret inputs/outputs as an additional public input/output of the circuit|,Non-data,82
| 14843 Testing circuits Besides the circuit transformation that outputs a pro- tected specification that supposedly is implemented by the malicious manufacturer, the trojan protection scheme also defines a tester T The description of T is public, and uses a probabilistic approach to defeat the malicious manufac- turer A Consider the (potential) malicious implementation {Di}i ← A(1k, (M,{Γi}i)) output by A|,Non-data,82
| Following Fig- ure 2, our construction consists of λ sub-devices, each of them made of three mini-devices (D0 i , D1 i ) which suppos- edly implement the mini-circuits Γj i  As the sub-devices Di operate independently, we can test them independently i , D2 i , D2 i , D1 Let Di = (D0 i ) be one of the sub-devices Denote the joint view of the mini-devices Dj i by View(Di((cid:126)r, (cid:126)s)) when run as part of Di on public inputs ((cid:126)r, (cid:126)s) after the initial- ization with (cid:126)m|,Non-data,82
| Notice that in this view we have all tuples of the form (cmd, val) exchanged between the mini-devices Di j and the master circuit M As the outputs of Di are also sent as a command, the view also contains the output shares ((cid:126)ci, (cid:126)di) Similarly, we denote by View(Γi((cid:126)r, (cid:126)s)) the view of the mini-circuits Γj At a high-level, T repeats the following process for each i ∈ [λ] First, it chooses a random value ti ← [t], where ti denotes the number of test runs|,Non-data,82
| In each of the ti runs the public/secret inputs are chosen uniformly at random and we execute once Di produced by A and once the specification Γi (in both cases using the same inputs) If the views differ in one of the runs we return false and the tester T aborts The formal description of the tester T is given in Figure 4 i when run on public inputs ((cid:126)r, (cid:126)s)|,Non-data,82
| The tester TD1(),|,Non-data,82
|,Dλ()(1k, λ) Set the initial state Init({Di}i,(cid:126)0) For i ∈ [λ] repeat the following: Sample ti ← [t] and repeat for ti times: Sample random sharing of public input (cid:126)r, (cid:126)s ← Fα If View(Di((cid:126)r, (cid:126)s)) (cid:54)= View(Γi((cid:126)r, (cid:126)s)) return false Return true Figure 4: The tester T for verifying whether the devices follow the specification given by Γ(cid:48) 4|,Non-data,82
|4 Main theorem and security proof The basic idea for the security of our construction is as follows Recall that in the testing phase each of the sub- devices Di was tested for a random number of times ti ∈ [t] Consider a mental experiment where instead of running the sub-devices for ti times, we execute them for ti+n times, ie|,Non-data,82
|, we view the real runs of Di also as test runs Informally, the malicious manufacturer A wins in the mental experiment if the sub-devices Di succeed in the test runs, but he makes a large fraction of Di fail in the following n real runs We show that the probability that A wins in the mental experiment decreases exponentially with the number of sub-devices What remains to show is that for the devices Di the real environment, where A can choose the inputs, looks (com- putationally) indistinguishable from the test runs|,Non-data,82
| In par- ticular, we need to avoid that the adversary can choose the inputs (cid:126)xi in order to signal to the devices that they are now used outside of the test environment6 The basic idea to 6Consider the input trigger attack where the adversary Γ(1k, q,{(cid:126)xi}i∈[q], (cid:126)m): The experiment Realj Initialize circuit Γ by Init(Γ, (cid:126)m) Output(cid:0)View(Γj(Share((cid:126)x1))),   |,Non-data,82
| , View(Γj(Share((cid:126)xq)))(cid:1) Output(cid:0)View(Γj(Share((cid:126)z1))),    , View(Γj(Share((cid:126)zq)))(cid:1) The experiment Randomj Initialize circuit Γ by Init(Γ,(cid:126)0) Sample (cid:126)z1, |,Non-data,82
|   , (cid:126)zq ← Fα uniformly at random Γ(1k, q): Figure 5: Views produced by a continuous real and test execution of the specification Γj by the mini- circuits of our construction prevent such signaling is to let the mini-devices Dj i run a passively secure 3-party computation protocol on shares of the input|,Non-data,82
| This guarantees that none of the mini-devices ac- tually knows the inputs on which it computes, and can start to behave differently from the test environment The rest of this section is structured as follows In Section 44|,Non-data,82
1 we prove that the specification of our construction satisfies the property that real runs and test runs are indistinguishable In Section 442 we use this fact to prove robustness,Non-data,82
| 441 The transformed specification Before we move to the device-level, we prove a property about the transformed specification Γi := (Γ0 i ) Re- call that each Γi is independent from the other sub-circuits and specifies exactly the same functionality|,Non-data,82
| Hence, we con- centrate in the following on a single sub-circuit and omit to explicitly mention the parameter i Let Γ denote one of the sub-circuits and Γj are the corresponding mini-circuits i , Γ1 i , Γ2 In Figure 5 we define two distributions: The distribution Γ(1k, q,{(cid:126)xi}i∈[q], (cid:126)m) considers the view of Γj on public Realj inputs (cid:126)xi and with secret initial input (cid:126)m On the other hand Randomj Γ(1k, q) describes the view of Γj in q runs of Γ with random inputs|,Non-data,82
| The next lemma states that both distributions are computationally close Lemma 3 Let q ∈ N denote the number of executions For any j ∈ [3], any set of public inputs {(cid:126)xi}i∈[q], and any initial secret input (cid:126)m ∈ Fk, we have: Realj Γ(1k, q,{(cid:126)xi}i∈[q], (cid:126)m) ≈c Randomj Γ(1k, q)|,Non-data,82
 The proof appears in the extended version of this paper [15] 442 Trojan robustness of our construction The theorem below shows the robustness of our construc- tion,Non-data,82
| In particular, it states that trojan robustness increases exponential with the number of devices Theorem 1 Let t, n, (cid:96), k ∈ N>0 with n < t and k be- ing the computational security parameter Π = (TR, T) is (t, n, )-trojan robust for  :=(cid:0) n (cid:1)λ/2 + negl(k)|,Non-data,82
| t We provide the proof in the extended version of this paper [15] Here we briefly discuss the parameters given by the theorem statement The factor negl(k) can be ignored since it comes from the security of the PRG The dominating fac- tor for realistic values of t, n, (cid:96) := 3λ is the value (cid:0) n (cid:1)λ/2|,Non-data,82
| Let us give an example for the level of robustness we can t chooses a 128-bit random value at production time on which the device is starting to deviate when received as input 149achieve Suppose we have λ = 10 sub-circuits, which re- sults into 30 mini-devices that need to be produced by the manufacturer Suppose we test each of the sub-devices for max t = 109 runs (which is realistic for simple hardware de- vices), and want to use them for n = 105 executions later|,Non-data,82
 The theorem guarantees that except with probability 10−20 the resulting computation is correct 45 Stateful and randomized circuits So far we only discussed how to handle original circuits Γ that are stateless (ie,Non-data,82
|, write their internal state only once) and are deterministic (ie, have no rand gates) We now briefly discuss how to extend our results to probabilistic and stateful circuits|,Non-data,82
| To handle the rand gates we do a simple transformation before using our compiler TR Namely, we replace each rand gate by the output of a deterministic PRG Clearly, this reduces probabilistic computation to the deter- ministic case we already discussed in the previous sections However, if the original circuit Γ was stateless, then after replacing the rand gates in Γ by the PRG, the new circuit Γ(cid:48) may become stateful|,Non-data,82
| Hence, to complete our construction we need to discuss how to handle stateful primitives (eg, like a PRG or a stream cipher) The problem with the stateful primitives is that in the testing phase we test the different sub-devices a different number of times, which makes the devices end up (after the testing) in different states|,Non-data,82
| When then after the test- ing phase in the real-execution we execute all sub-devices jointly (driven by the master) and take the majority of their outputs, then the majority will fail to provide the correct result (since all the sub-devices are in a different state) A first idea to deal with this issue is to reset the state of the sub-devices after the testing However, such reseting can be noticed by the malicious sub-devices7 To overcome this problem, we augment Γ with a special circuit that carries out input-triggered re-initialization|,Non-data,82
| For instance, consider a Boolean circuit Γ that originally takes inputs from {0, 1}α We add an additional bit to the input which signals re-initialization, ie, the inputs of the aug- mented Γ are now from {0, 1}α+1, where if the first bit is 1, then the following α bits are used to reset the state|,Non-data,82
| Other- wise, if the first bit is 0, then the it is a normal execution of Γ without updating the initial state Such augmented cir- cuitry can easily be implemented using our simple operations from above For instance, using the simple example above, we compute for re-initialization: (cid:126)m = (1 − b) (cid:12) (cid:126)m ⊕ b (cid:12) (cid:126)x, where b is the first bit of the input, (cid:126)m is the initial state and (cid:126)x are remaining α bits of the input Clearly, if b = 0 the state is not touched, while if b = 1 we rewrite the state with the input|,Non-data,82
| In order to achieve security, we then compile Γ added with the augmented circuitry described above using our compiler TR Notice that this means not that we also share the triggering bit b as otherwise the sub-devices can notice that they are re-initialized Of course, the above approach has one drawback It gives the adversary in the real-execution the possibility to over- write the state with a fresh adversarial chosen state|,Non-data,82
| If (cid:126)m is a key then this is an undesirable feature However, this can be easily fixed by telling the master M to set the first bit permanently to 0 after re-initialization 7For instance, the devices may just monitor their internal state in some extra memory and hence can notice if the state was changed outside of their normal execution pattern Figure 6: MultShares with threee mini-circuits|,Non-data,82
| 5 DISCUSSIONS In this section, we discuss the relevance of our circuit model, the implementation cost of our transformed circuits and testing phase, and the concrete attacks covered by our threat model Due to place constraints, we focus on general observations and arguments in favor of the practicality of our proposals and leave the concrete investigation of meaningful case studies as a scope for further research 5|,Non-data,82
|1 Instantiation of the circuit model In practice, the circuit specification of Section 21 can be simply instantiated with existing Hardware Description Lan- guages (HDLs) such as VHDL or Verilog, and its communi- cation commands with standard communication interfaces In fact, the only fundamental requirement for this circuit specification is that it allows describing and testing the func- tional correctness of the devices implementing them Besides, since for our previous construction, we essentially convert the original circuit Γ into a couple of passively secure 3-party implementations of this circuit, we use an abstract representation based on addition and multiplication gates, which allow us to describe a generic compiler|,Non-data,82
| Yet, this is not a strict requirement and any specialized compiler that would lead to a more efficient 3-party implementation of a given circuit Γ (as long as it can be specified in a hardware description language) is in fact eligible 52 Cost of the transformed circuits Concretely, our circuit transformation essentially requires to design λ sub-circuits, each of them corresponding to a 3-party implementation of the functionality to protect For linear functionalities (in the binary/arithmetic field we con- sider) this implies overheads that are linear in the total num- ber of devices (cid:96)|,Non-data,82
| So as usual in multiparty computation, the most significant overheads come from the non-linear opera- tions In order to estimate these overheads, an implemen- tation of the MultShares circuit of Figure 3 is sketched in Figure 6, where we can see that such an operation can be carried out in 6 “abstract cycles” (denoted from C0 to C6 on the figure) with a PRG and 10 arithmetic operations Therefore, in terms of timing/latency the best that we can hope is a cycle count that is proportional to the logic depth of the functionality to protect, which would happen if we compute all the multiplications in parallel Considering that all the communications have to commute through the master circuit, and that each send, in,out command can be performed in c cycles, the latency of each multiplicative level will be multiplied by a maximum factor 6c (since not all the abstract cycles require communications)|,Non-data,82
| 150Figure 7: Implementation with 3D circuits In terms of circuit size, each sub-circuit will require a (con- stant) multiplicative overhead (≈ ×10) due to the arithmetic operations of MultShares, and a (constant) additive overhead due to the PRG The impact of the latter naturally depends on the implementation size of this PRG compared to the one of the functionality to protect Taking the (expensive) case where we compute several multiplications in parallel, we could for example require to generate 128 pseudoran- dom bits per cycle with an AES-based PRG, which remains achievable, e|,Non-data,82
|g, in low-cost FPGA devices Quite naturally, there may be additional overheads due to representation issues For example, standard block ciphers are generally implemented thanks to table lookups, which are not included in our circuit model|,Non-data,82
| In this respect, we first note that such overheads can be mitigated by taking advantage of cryptographic primitives designed for masking, multiparty computation or fully homomorphic encryption (which aim to minimize the multiplicative complexity and depth of the circuits) [18, 4] Besides, even for a standard cipher such as the AES, the broad literature on masking suggests that 3-party implementations similar to ours are achievable in mainstream embedded devices (see, eg [25, 17] for software and hardware evaluations)|,Non-data,82
| Eventually, we show in the next section that much more efficient specialized solutions can be obtained for certain im- portant cryptographic functionalities 53 Testing of the transformed circuits As clear from the previous section, the security of our trojan-resilient circuits depends on the possibility to test sub- and mini-circuits, including all their communications In general, this can be implemented by connecting various circuits to a master via standard communication interfaces|,Non-data,82
| However, we note that more compact solutions also exist, by taking advantage of the 3D technologies of which the use- fulness for trojan-resilient circuits was already put forward in [20] As illustrated in Figure 7, we can then easily embed the sub-circuits as the different tiers of a 3D hardware Besides, note that (as suggested in the right part of Fig- ure 2), one can speed up the communication between the mini-circuits by allowing them to communicate directly, given that the tester can monitor these communications with “wires” that would be used only during the testing phase, and of which the monitoring would not be noticed by the mini- circuits, ie|,Non-data,82
|, under a “no hidden communications” assump- tion This could be achieved by equiping the tester with specialized hardware capacities (eg, an oscilloscope)|,Non-data,82
| 54 Attacks & limitations We conclude this section by listing the attacks covered by our threat model and its limitations Compared to [30], we prevent any digital input-triggered hardware trojan (eg|,Non-data,82
|, single-shot cheat codes and sequence cheat codes) In this respect, we additionally cover the risk of “infection attacks”, where one activated sub-circuit starts to communicate with others sub-circuits, which is achieved by limiting the communication between them Next, we prevent internally-triggered trojans (eg|,Non-data,82
|, time bombs) in a more general manner than [30] Namely, this previous work was limited to preventing volatile time bombs with power resets We also prevent non-volatile ones (eg|,Non-data,82
|, a counter that would store the number of executions of the circuit independent of its powering) thanks to our testing phase We believe this is an important improvement for emerging technologies such as FRAM-based devices [16] We also cover all the attacks considered in [20] and, as pre- viously mentioned, are able to efficiently bound the success rate of these attack to exponentially small probabilities By contrast, as mentioned in Section 2|,Non-data,82
|2, we cannot pre- vent physical trojan attacks since our testing phase is look- ing for functional incorrectness Yet, we note that exploit- ing physical side-channels such as the power consumption or electromagnetic radiation of a chip usually requires physical proximity (which may be excluded by other means) As for side-channels that are exploitable remotely, such as timing attacks [11], they could be prevented by functional testing (eg|,Non-data,82
|, in order to ensure constant-time executions) In gen- eral, the extension of our tools towards physical hardware trojans is an important scope for further research Eventually, we mention one more type of attack which, to the best of our knowledge, has not been mentioned in the literature so far and is not covered by our tools, namely “battery attacks” In this case, the infected chip would go on performing harmful operations (e|,Non-data,82
|g, the increaing of a counter) independent of whether the chip is performing any computation Interestingly, existing (eg|,Non-data,82
|, lithium) battery and energy harvesting technologies are currently based on quite different design techniques than digital ASICs [12, 27] So it may be a reasonable hardware assumption to ask such trojans to be detected by chip inspection (via microscopy or other means), which we leave as another interesting chal- lenge for hardware research 6 EFFICIENT FUNCTIONALITIES In this section, we briefly discuss how to use testing am- plification to get better efficiency for certain cryptographic primitives|,Non-data,82
| We achieve the better efficiency by (a) focusing on specific functionalities and (b) by only showing a weaker security property In particular, in contrast to trojan robust- ness from Definition 1, which aims at correctness, we will focus on a security property that is tailored to the particu- lar functionality we want to protect Notice that typically the constructions presented in this section do not achieve correctness and do not protect against the denial-of-service attacks mentioned in the introduction That is, a hardware trojan can always disable the functionality completely|,Non-data,82
| 61 Trojan secure PRGs We first describe how to construct a PRG that is trojan se- cure, where “trojan security” is a weaker security guarantee than trojan robustness from Definition 1 Nevertheless, we 151argue that for certain cryptographic primitives and certain applications trojan security is a sufficiently strong security property In contrast to trojan robustness which requires essentially that the malicious devices output correct results (i|,Non-data,82
|e, the same result as the honest specification), trojan se- curity of a PRG only guarantees that the malicious imple- mentation of the PRG still outputs pseudorandomness Constructing a trojan secure PRG is very simple Just let the malicious manufacturer produce (cid:96) device D1, |,Non-data,82
|   , D(cid:96), where each Di supposedly implements a cryptographically strong PRG with binary output {0, 1}β8 Each of the Di’s is initialized with a random and independent initial secret seed Ki|,Non-data,82
| The master M then runs the devices Di and just XORs the outputs of Di on each invocation Observe that since all keys Ki were sampled uniformly and independently and we XOR the outputs of Di, we get that the output of the composed device is pseudorandom as long as one device Di outputs pseudorandomness De-randomization of our circuit compiler Let us now argue about the security of the above con- struction|,Non-data,82
| Testing the above implementation is easy: we just use the same random testing approach as for our circuit compiler That is, each of the sub-devices Di is tested inde- pendently for ti times Next, we can use a similar analysis as in Theorem 1 to show that if the Di’s pass the testing phase, then with probability 1 − (n/t)(cid:96) at least one device outputs the correct result for all n real executions By the above observation, this suffices to show that with probability at least 1 − (n/t)(cid:96) the device outputs pseudorandomness|,Non-data,82
|9 In our circuit compiler, the master M is randomized since it needs to secret-share the inputs of the device (which requires ran- domness) We can use the above construction of the trojan secure PRG to de-randomize M To this end we let the mali- cious manufacturer produce (cid:96) additional devices, where each computes a PRG Whenever M needs uniform randomness, we replace it by the output of the above construction of a trojan secure PRG|,Non-data,82
| Notice that this further simplifies the as- sumptions that we put on M, since now the master M does not need to run a trusted component for random number generation In this approach the complexity of M is reduced to a small number of additions and multiplications 62 Other cryptographic primitives We conclude our paper with a short discussion on other cryptographic primitives that can benefit from the technique of testing amplification (i|,Non-data,82
|e, having many independent de- vices that are tested independently and the combined using a master) For efficiency, we concentrate on the “trojan secu- rity” (see Sect 6|,Non-data,82
|1 above) and because of the space reasons, we only discuss how to construct an efficient trojan secure Message Authentication Code (MAC) Recall that a message authentication code is a symmet- ric cryptographic primitive that can be used to guarantee the authenticity of messages One way to protect a MAC against trojan attacks is to use our generic compiler from Section 4 We now describe a more efficient way achieving trojan security for MACs|,Non-data,82
| Let us start by describing the 8It also may be a elements in a field, but we only consider the most simple case here 9Observe that we obtain better parameters than for the strong property of trojan robustness since we only require that one sub-device behaves honestly This allows us to save a factor of 1/2 in the exponent security property we are aiming at|,Non-data,82
| Let D be a device that supposedly implements a secure MAC with key K, ie, it outputs tags with respect to the key K Informally, trojan security guarantees that valid tags can only be produced by running the device D|,Non-data,82
| Notice that this in particular implies that an adversary interacting with the supposedly malicious D in the n real executions does not learn anything about the internal secret key K More concretely, to specify the trojan security of a MAC, we consider the following two phases (of course, prior to these two phases we execute a testing phase of the sub-devices): 1 In the learning phase, A interacts with the potentially malicious implementation D That is, A can ask for MACs of messages of his choice and sees the output of the MAC|,Non-data,82
| Notice that this can be done for at most n times (similar as in the robustness definition) 2 In the challenge phase the adversary has to provide a forgery for the key K and a fresh message X is given back to the master M who computes Y = (cid:76) In order to construct an efficient trojan secure MAC, we proceed as follows|,Non-data,82
| Let F : {0, 1}k × {0, 1}α → {0, 1}β be a secure pseudorandom function (for instance, instanti- ated with an AES) We let the malicious manufacturer pro- duce (cid:96) sub-devices D1,   |,Non-data,82
| , D(cid:96) where each supposedly imple- ments the PRF F  The sub-devices Di are then combined by the master M in the following way On an input message X ∈ {0, 1}α the master produces an (cid:96)-out-of-(cid:96) secret sharing (X1,  |,Non-data,82
|  , X(cid:96)) of X Each share Xi is given to the sub-device Di as input, which computes Yi = F (Ki, Xi) The value Yi i Yi and outputs the tag ((X1, |,Non-data,82
|   X(cid:96)), Y ) Notice that we can de-randomize the master M by using our PRG construction from Section 6|,Non-data,82
|1 Verification of the tag produced by the above construction is simple Essentially, since (X1,  |,Non-data,82
|  X(cid:96)) are part of the tag the verifier can use (K1,   |,Non-data,82
| , K(cid:96)) to ver- ify the correctness of the MAC The above construction has the shortcoming that it increases the length of the tag by (cid:96) times the message length We leave it as an interesting open question to improve the tag length The basic intuition why the above construction is trojan secure is as follows|,Non-data,82
| First, observe that the sub-devices Di operate independently from each other (they all use inde- pendent keys and no communication is needed between the Di’s for computing F ) Second, they are run on shares of the inputs X, so the adversary cannot initiate malicious behav- ior by signaling it through the inputs The random testing guarantees that with probability 1 − (n/t)(cid:96) at least one de- vice Di outputs the correct result for all n real executions Since we are XORing the outputs of all sub-devices Di, we are guaranteed that as long as at least one device Di op- erates honestly, it “blinds” the outputs of all other devices, and hence hides the output of potential malicious devices (that try to reveal their internal keys)|,Non-data,82
| In general it can be observed that, informally speaking, in order to construct efficient trojan robust cryptographic primitives using our technique of testing amplification, we need algorithms that are both input homomorphic and key homomorphic (essentially this is what the use of the MPC enables) We leave it as an interesting question for future work to find such cryptographic schemes Acknowledgments Stefan Dziembowski is supported by the Foundation for Polish Science|,Non-data,82
 Sebastian Faust is funded by the Emmy Noether Program FA 1320/1-1 of the German 152Research Foundation (DFG) Fran ̧cois-Xavier Standaert Stan- daert is a research associate of the Belgian Fund for Scientific Research (FNRS-FRS,Non-data,82
|) [17] V Grosso, F Standaert, and S|,Non-data,82
 Faust “Masking vs multiparty computation: how large is the gap for AES?” In: J Cryptographic Engineering 1 (2014),Non-data,82
| [18] V Grosso, G Leurent, F Standaert, and K|,Non-data,82
 Varici “LS-Designs: Bitslice Encryption for Efficient Masked Software Implementations” In: FSE 2014,Non-data,82
| [19] S K Haider, C Jin, M|,Non-data,82
| Ahmad, D M Shila, O Khan, and M|,Non-data,82
| van Dijk Advancing the State-of-the-Art in Hardware Trojans Detection Cryptology ePrint Archive, Report 2014/943 2014|,Non-data,82
| [20] F Imeson, A Emtenan, S Garg, and M|,Non-data,82
 V Tripunitara “Securing Computer Hardware Using 3D Integrated Circuit (IC) Technology and Split Manufacturing for Obfuscation” In: USENIX Security Symposium,Non-data,82
| 2013 [21] Y Ishai, A Sahai, and D|,Non-data,82
 Wagner “Private Circuits: Securing Hardware against Probing Attacks” In: CRYPTO 2003,Non-data,82
| [22] Y Ishai, M Prabhakaran, A Sahai, and D|,Non-data,82
 Wagner “Private Circuits II: Keeping Secrets in Tamperable Circuits” In: EUROCRYPT 2006,Non-data,82
| [23] P C Kocher “Timing Attacks on Implementations of Diffie-Hellman, RSA, DSS, and Other Systems”|,Non-data,82
 In: CRYPTO 1996 [24] P C,Non-data,82
| Kocher, J Jaffe, and B Jun “Differential Power Analysis”|,Non-data,82
| In: CRYPTO 1999 [25] A Moradi, A|,Non-data,82
| Poschmann, S Ling, C Paar, and H Wang|,Non-data,82
 “Pushing the Limits: A Very Compact and a Threshold Implementation of AES” In: EUROCRYPT 2011 2011 [26] S,Non-data,82
| Narasimhan, D Du, R S Chakraborty, S|,Non-data,82
| Paul, F G Wolff, C A|,Non-data,82
| Papachristou, K Roy, and S Bhunia “Hardware Trojan Detection by Multiple-Parameter Side-Channel Analysis”|,Non-data,82
 In: IEEE Trans Computers 11 (2013) [27] S Priya and D,Non-data,82
 J Inman Energy harvesting technologies 2009,Non-data,82
 [28] M Tehranipoor and F Koushanfar “A Survey of Hardware Trojan Taxonomy and Detection”,Non-data,82
| In: IEEE Design & Test of Computers 1 (2010) [29] R S Wahby, M|,Non-data,82
| Howald, S Garg, abhi shelat, and M Walfish Verifiable ASICs|,Non-data,82
| Cryptology ePrint Archive, Report 2015/1243 2015 [30] A Waksman and S|,Non-data,82
 Sethumadhavan “Silencing Hardware Backdoors” In: IEEE S&P 2011,Non-data,82
|ABSTRACT Defenders of enterprise networks have a critical need to quickly identify the root causes of malware and data leak- age Increasingly, USB storage devices are the media of choice for data exfiltration, malware propagation, and even cyber-warfare We observe that a critical aspect of ex- plaining and preventing such attacks is understanding the provenance of data (ie|,Non-data,83
|, the lineage of data from its creation to current state) on USB devices as a means of ensuring their safe usage Unfortunately, provenance tracking is not offered by even sophisticated modern devices This work presents ProvUSB, an architecture for fine-grained provenance collection and tracking on smart USB devices ProvUSB maintains data provenance by recording reads and writes at the block layer and reliably identifying hosts editing those blocks through attestation over the USB chan- nel|,Non-data,83
| Our evaluation finds that ProvUSB imposes a one-time 850 ms overhead during USB enumeration, but approaches nearly-bare-metal runtime performance (90% of through- put) on larger files during normal execution, and less than 01% storage overhead for provenance in real-world work- loads ProvUSB thus provides essential new techniques in the defense of computer systems and USB storage devices 1|,Non-data,83
| INTRODUCTION When securing computer systems and data, a great deal of effort is put into ensuring that the perimeter of an or- ganization is secure For example, firewalls and DMZs are designed to keep malicious outsiders from gaining access to, and exfiltrating, sensitive information However, it is sub- stantially more difficult to ensure that information is secure from a trusted insider within an organization In some cases, the insider may be an active adversary, as with the Manning Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page|,Non-data,83
| Copyrights for components of this work owned by others than the author(s) must be honored Abstracting with credit is permitted To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acm|,Non-data,83
|org CCS’16, October 24 - 28, 2016, Vienna, Austria c(cid:13) 2016 Copyright held by the owner/author(s) Publication rights licensed to ACM ISBN 978-1-4503-4139-4/16/10|,Non-data,83
   $1500 DOI: http://dx,Non-data,83
doiorg/101145/29767492978398 case where classified data was exfiltrated on portable media [37],Non-data,83
| In other cases, the insiders may be unwitting vectors for attack, such as in 2008 when CENTCOM employees inad- vertently loaded malware on to SIPRnet through an insecure USB drive [34] USB devices are ubiquitous within organizations and en- terprises, but because of their potential for propagating mal- ware and becoming a medium for data exfiltration, their use has been curtailed or altogether banned [1, 73, 57] While enterprise-level solutions to USB device security can poten- tially detect malware contained within these devices [49], they require centralized authentication mechanisms in addi- tion to hardware crypto coprocessors [32] Most important, these solutions are incomplete|,Non-data,83
| No signature-based malware scheme is perfect: new and previously-undisclosed zero-day attacks, such as those used by the Stuxnet worm [18] and the Havex trojan [55], render these defenses moot Further- more, there are no mechanisms to determine how malicious software was loaded onto the USB device, nor any means of determining where this data has been disseminated; conse- quently, there is no method for understanding the spread of malware after an attack After storage is compromised, it is non-trivial to determine even with hardware forensics where malware has originated and migrated [9] Finally, there are minimal protections for data integrity within the storage|,Non-data,83
| While filesystem encryption provides confidentiality, data integrity can still be violated by malicious but authorized I/O operations as the result of compromising or bypassing the authentication mechanisms Data provenance represents a powerful technique allowing us to address these shortcomings The provenance of a data object characterizes its lineage from the time it was gener- ated, describing all modifications made that result in the object’s current state With provenance mechanisms incor- porated into storage devices, we would possess the means to carry out forensic analysis and even to thwart attacks based on information collected within the device itself|,Non-data,83
| In this paper, we propose ProvUSB, block-level prove- nance for USB storage devices When plugged into a ma- chine, the ProvUSB device uniquely identifies the host through trusted hardware, then generates provenance records describing each I/O operation that is performed by the host on the device storage partition Extending this mechanism, we present a provenance-based integrity 242protection scheme, providing fine-grained authorization of access attempts based on the Biba [11] and Low Water- Mark Access Control (LOMAC) [19, 20] integrity models We fully implement the ProvUSB device using an embedded USB development board and perform a thorough evaluation covering enumeration overhead, I/O micro benchmarks, realistic workloads, storage overheads, and two forensic investigation case studies|,Non-data,83
| The results show that ProvUSB imposes a once-per-session overhead of less than a second during device enumeration (the USB protocol handshake), but throughput and latency for normal device usage is close to bare metal performance (90% of the original throughput with a 17% latency overhead) when considering a mean file size of 10 MB The overhead of provenance storage is less than 01% in real-world workloads Our contributions can be summarized as follows: • Block-level provenance: ProvUSB leverages Trusted Platform Modules (TPMs) to authenticate host ma- chines and collect provenance automatically for each I/O operation at the block level|,Non-data,83
| To the best of our knowledge, ProvUSB is the first USB storage solution to support provenance natively • Block-level policy control: We extend ProvUSB with a policy mechanism that enforces integrity protec- tions for USB storage at the block layer This unprece- dented granularity allows ProvUSB to remain useful in MLS environments in which devices may pass between machines of different integrity levels • Comprehensive evaluation and analysis: we eval- uate ProvUSB’s TPM attestation, USB enumeration, and I/O overhead, using micro and macro benchmarks, and real-world workloads, demonstrating that over- head is sufficiently low for practical usage|,Non-data,83
| The paper is organized as follows: Section 2 provides back- ground on USB storage, data provenance and TPM attes- tation Section 3 describes how ProvUSB works in general, identifies key challenges of block-level provenance and pol- icy control, and presents our solution Section 4 presents technical details of ProvUSB’s implementation We evaluate ProvUSB in Section 5|,Non-data,83
| Section 6 discusses the trade-offs and limitations, as well as potential mitigations, of ProvUSB Section 7 provides an overview of related work, and Section 8 concludes 2 BACKGROUND USB Storage: The USB (Universal Serial Bus) specifica- tion [16] defines protocols used in communication between a host machine and a device across a serial bus|,Non-data,83
| When a USB device is plugged into a host machine, the host initi- ates an enumeration process that identifies the device and loads drivers on its behalf During this procedure, the device reports hardware information (eg, product ID, vendor ID) and supported configurations, and requests a specific con- figuration and set of device interfaces (e|,Non-data,83
|g, Storage, Human Interface, etc) Based on this information, the host USB controller loads and configures the appropriate drivers for the device to function|,Non-data,83
| To further regulate the standards of USB devices, the USB DWG (Device Working Group) de- fines sub standards, categorizing USB devices into different classes, promoting increased interoperability and reliability Figure 1: An example provenance graph from the perspec- tive of a USB device capture agent As the device lacks insight into the internal state of the connected host, hosts are represented as opaque, monolithic activities among devices in the same class [66] After the normal USB enumeration, the corresponding storage class driver, e|,Non-data,83
|g, usb-storage in the Linux kernel, is loaded as a glue layer between the lower USB transportation layer and the higher block layer The USB mass storage protocol provides support for a subset of SCSI commands, and every device implementing the standard supports these When a USB mass storage device is connected, the host starts scanning the SCSI LUNs (logical unit numbers) on the device, which collects the corresponding filesystem information before the device or partition can be mounted correctly|,Non-data,83
| Data Provenance: Data provenance describes the history of manipulations performed on a data object from its cre- ation up to the present As such, provenance is a powerful means of reasoning about the value of a piece of data Tra- ditionally, provenance capture has been proposed on hosts at the system call layer, which requires changes to system libraries [27] or the operating system [8, 22, 46] Such sys- tems require provenance to be saved in the host machine or relayed to a remote server, placing trust in the software run- ning on the host|,Non-data,83
| Due to the fine granularity of provenance collection, these approaches are also prone to requiring stor- age overheads of gigabytes per day [8, 47] In this work, we conceptualize data provenance from the perspective of a USB storage device in order to overcome the obstacles of storage overhead and trust in the host plat- form A visualization of USB storage provenance is shown in Figure 1, shown here as a directed acyclic graph that is compliant with the W3C PROV data model [17] The prin- cipals we consider are USB storage data objects and host machines, treating the internal state of the host machine as opaque|,Non-data,83
| These entities are represented as vertices in Figure 1, while edges encode relationships between the principals and flow backwards into the history of system execution Here, “Used” corresponds to object reads, and “WasGener- atedBy” to object writes To prevent cycles from forming in the graph, a versioning system is used in which a new ver- sion node is created every time an object is written to In this case, we see that Host B used USB Object A, Version 0 and subsequently generated USB Object A, Version 1|,Non-data,83
| TPM Attestation: A Trusted Platform Module (TPM) is a tamper-resistant cryptographic module embedded in the motherboards of many commodity systems It pro- vides a hardware root of trust for storing cryptographic keys and measurements that represent the current system state These measurements begin by hashing over the system BIOS and then successively storing hashes of all software in the stack, including boot loaders, operating systems and ap- Host DHost EUSB Object AVersion 0Host BHost CHost AUsedUsedUsedWasGeneratedByUsedUsedUsedUSB Object BVersion 0USB Object AVersion 1243plications [33, 36, 51, 56] All measurements are stored in dedicated Platform Configuration Registers (PCRs) that reside inside the TPM|,Non-data,83
| The TPM enables third parties to remotely validate a system’s state using an attestation pro- tocol A host’s TPM enrolls keys with a Privacy Certifica- tion Authority (PCA) or Attestation Certification Authority (ACA), and acquires an Attestation Identity Key (AIK) cre- dential key pair To start TPM attestation, the challenger sends a nonce (to counter replay attacks) to the target TPM The target TPM executes a quote command, which returns a report of the current PCR values signed with the AIK|,Non-data,83
| Upon receiving the quote result, the challenger verifies it using the public AIK and compares the PCR values within the quote against known good values, which can be obtained from a factory installation or PCA A successful attestation implies that the challenger is communicating with the correct host and that the system is in a known good state While TPM attestations are usually performed remotely over a network, in this work we enhance the host operating system to sup- port TPM attestations over the USB channel 3|,Non-data,83
| DESIGN 31 Threat Model & Assumptions This work considers an enterprise environment that wishes to protect itself from USB-based threats For portable stor- age, we assume that such an organization is willing to make exclusive use of advanced USB technologies such as Iron- Keys [32], which is already a common practice in many high- security environments We assume that these devices are distributed within the organization similarly to the way that “loaner” devices are distributed for the purposes of business travel: in order to to check-out a device, an employee reg- isters with a technology office; after a pre-defined length of time (epoch), the employee is required to return the equip- ment to the technology office; upon receiving the piece of equipment, the technology office will perform forensic anal- ysis and then re-image the device|,Non-data,83
| Although firewalls, IDS, and security training seminars for employees may be extensively deployed in such an organi- zation, it is only a matter of time before powerful attackers (eg, APTs [45]) gain a foothold within the network We thus assume that any manner of software compromise is pos- sible on hosts in the network|,Non-data,83
| Therefore, our solution cannot trust any software running on the host machine, including the kernel and the entire USB stack However, we do assume that all hosts contain a TPM, and that because the attacker does not have physical access, hardware or firmware attacks against the TPM are not possible1 USB storage is a known delivery mechanism for malware, eg|,Non-data,83
|, Stuxnet [18] To mitigate the threat of USB-based mal- ware propagation, we present a provenance-based integrity protection scheme that prevents data originating within low integrity sources from flowing to high-integrity targets To facilitate this, we make the assumption that all hosts in the enterprise have been assigned integrity levels by a system administrator This process would be intuitive to adminis- trators, as each host’s integrity level would likely correspond 1While any mechanism that ensures the security of the host and underlying firmware and hardware may be used, we fo- cus discussion here on the TPM due to its wide-spread de- ployment and well-understood integrity semantics [52]|,Non-data,83
| Figure 2: The ProvUSB device contains several components: a TPM manager, Provenance Tracker, and Policy Engine When plugged into the host, the device issues a TPM chal- lenge to the Attestation Daemon over the USB channel, which then responds with the signed quote to the privilege level of its users Examples of Low Integrity (LI) hosts might include unprivileged employee workstations and machines outside of the demilitarized zone, while a High Integrity (HI) level might be assigned to administrator hosts or workstations handling highly sensitive data|,Non-data,83
| Attack Scenarios: Our architecture is designed to provide provenance for two notorious forms of USB attack, malware propagation and data exfiltration Malware Propagation For malware, we specifically focus on tracking infected hosts that inject payloads onto stor- age devices, which are later read by other machines This pattern of behavior is consistent with live malware samples, including ZeuS [64] and Stuxnet [18]|,Non-data,83
| Antivirus software may eventually detect such malware after new signatures are generated and pushed to the client, but offer little foren- sic insight into when and how the malware was initially in- jected This is usually true because most forensics rely on the MAC (Modification, Access, Change) time provided by the filesystem, which only provides the latest timestamps Data Exfiltration In the case of data exfiltration, insider attacks are particularly dangerous|,Non-data,83
| With a USB storage de- vice, an attacker can easily exit the physical premises with large amounts of sensitive data secreted away in their pock- ets Most secure USB storage devices constrain the I/O operations via authenticating the user, either using central- ized authentication servers or local passwords [31], but do not address the problem of malicious users with legitimate access credentials We aim to ensure that exfiltration events can be traced back to the host that acted as a source of the data leak, even if that host has been compromised to wipe traces of the exfiltration Additionally, device pol- icy can be configured such that the storage device erases all of its blocks (while maintaining provenance metadata) if it is plugged into an unrecognized or unauthorized host, substantially limiting the damage from a malicious insider absconding with the device from an enterprise|,Non-data,83
| In both of these scenarios, forensic analysis requires that the attacker’s actions be tracked prior to detection and without requiring trust in software running on the host 32 Security Goals Critically, in both of the above attacker scenarios, the ability to reliably track read and write operations to the USB storage device is sufficient to explain the actions of the ProvUSBHostAttestation DaemonDeviceUSBUSBBlocksProv TrackerPolicy EngineTPM ManagerTPM244attacker|,Non-data,83
| With the above considerations in mind, ProvUSB sets out to provide the following capabilities: G1 Minimal Trusted Computing Base ProvUSB’s TCB must be limited to software running on the de- vice ProvUSB must verify the identity of host ma- chines prior to granting access to the storage partition Additionally, ProvUSB must verify both the identity and the software configuration of privileged machines prior to exposing provenance information|,Non-data,83
 G2 Forensic Validity ProvUSB must provide a com- plete and exhaustive provenance description of the de- vice’s interactions with host machines If provenance loss occurs it must be detectable by the administrator G3 Tamperproof,Non-data,83
 The host machine should not be able to disable ProvUSB’s provenance collection logic G4 Track Malware Propagation Given out-of-band knowledge that host A is known to be infected at time t (eg,Non-data,83
|, Antivirus alert), ProvUSB must 1) identify the hosts that contributed to A’s internal state prior to time t, and 2) identify the hosts that used A’s internal state between time t and the present G5 Explain Data Leaks Given out-of-band knowledge that file f was leaked prior to time t (eg|,Non-data,83
|, f ’s con- tents were published online), ProvUSB must identify the hosts that had knowledge of f prior to time t G6 Integrity Assurance For data in the storage par- tition, ProvUSB must prevent all integrity violations in which data from a lower integrity host flows to a higher integrity host 3|,Non-data,83
|3 Design Overview An overview of the ProvUSB architecture is shown in Fig- ure 2 ProvUSB requires host machines to be equipped with a TPM chip, an Attestation Daemon in user space to commu- nicate with the TPM, and an enhanced USB storage driver in the kernel space to support TPM attestations Several components are introduced on the device side: a TPM Man- ager, Provenance Tracker, and Policy Engine The host ma- chine and the device communicate exclusively over the USB channel|,Non-data,83
| When a ProvUSB device is connected to the host, the host initiates a TPM attestation following normal enu- meration The TPM Manager verifies the attestation on the device side, then permits the host to perform storage operations During normal usage, the Provenance Tracker generates provenance for all I/O events performed on the device An optional Policy Engine can be enabled to autho- rize access attempts|,Non-data,83
| During device usage, all provenance is created and managed within the ProvUSB device While the software stack within ProvUSB is included in the TCB, no software running in the host system is trusted 34 Identifying Host Machines Before we can track device provenance, we need a means of authenticating the hosts to which ProvUSB connects|,Non-data,83
| The identifier should be persistent over the host’s lifetime, mean- ing volatile or spoofable values, such as the MAC address of a NIC, will not work The device must also be able to obtain the identifier over the USB channel While other ap- proaches including host fingerprinting over USB exist [6], Figure 3: In device enumeration with ProvUSB, the host initiates an attestation procedure over the USB channel to allow the device to authenticate the host our approach is to leverage TPMs, found in most current commodity machines|,Non-data,83
| To allow TPM attestation over USB, we make use of a technique introduced in the Kells framework [12] Kells uses TPM attestations to authenticate hosts prior to exposing sensitive storage partitions In the event that attestation fails, Kells only exposes the public partition instead of the private one It accomplishes this functionality through the introduction of a USB-based TPM attestation, as shown in Figure 3|,Non-data,83
| In ProvUSB, the TPM Manager is able to verify the identity of the host using the following procedure: (1) During normal device enumeration, the host USB storage driver recognizes the device as ProvUSB-enabled based on its vendor ID (2) Following enumeration, the host sends out a USB Accept Device Specific Command (ADSC) [72] to the device asking for a 20 byte nonce, which marks the beginning of the TPM attestation (3) The device’s TPM Manager sends a nonce to the host (4) The host USB storage driver sends the nonce to the Attestation Manager, which generates a TPM quote and returns the TPM AIK public key and quote to the storage driver|,Non-data,83
| The host storage driver sends the public key and quote to the device over ADSC (5) On the device, the TPM Manager validates the TPM AIK public key, using it to verify the TPM quote If the verification succeeds, the device permits the SCSI scanning request, allowing the host machine to mount the partition, and the device moves into the provenance track- ing phase If verification fails, the storage partition is not exposed to the host|,Non-data,83
| As described above, depending on how device policy is configured, a failed verification can also re- sult in the device erasing all of its blocks to prevent exfil- tration attempts Furthermore, when ProvUSB devices are deployed in enterprise environments, host machines should also reject non-ProvUSB storage devices to avoid attacks from uncertified devices 35 Block-level Tracking and Protection Provenance Tracking: When designing ProvUSB, we ini- tially considered instrumenting a specific filesystem, as was done in the past for host system provenance [27]|,Non-data,83
| However, this would constrain our approach to a particular filesys- tem format, which was in conflict with the Plug and Play HostDeviceGetDescriptor(Interface)Storageend of normal device enumerationInit TPM Attestation nonceTPM AIK public keyTPM Quote resultVerifyAttestationend USB TPM attestation, begin normal operationSCSI Scanning|,Non-data,83
245level is equal to the lowest integrity class found in the ob- ject’s provenance ancestry (eg,Non-data,83
|, the lowest integrity writer) On access attempts, ProvUSB’s Policy engine applies the enforcement rules pictured in Figure 4 For read operations, ProvUSB grants the request only if the host machine’s in- tegrity level is less than or equal to the data block’s integrity level For write operations, ProvUSB grants all requests|,Non-data,83
| If an LI host writes to an HI block, ProvUSB transitions the block’s level to LI An additional transition (not pictured) is if ProvUSB detects that an entire block has been overwritten by an HI host, the block returns to an HI state Optimization: Provenance Filtering: The automatic capture of provenance is associated with high storage over- heads For example, several provenance-aware operating systems generate more than 1 GB of provenance during ker- nel compilation [8, 47]|,Non-data,83
| While we expect the overall volume of activity to be less for a USB device than an operating system, the storage overhead imposed by provenance collec- tion will nonetheless dictate the frequency with which de- vices need to be collected and re-imaged by the technology office (§31) We introduce the following filtering optimiza- tion to the ProvUSB device provenance daemon to ensure that provenance storage costs are minimized without loss of expressivity, considering the following three scenarios: (1) Consecutive Reads: A host reads the same block mul- tiple times prior to a new write After the initial read, we assume this data already exists on the host|,Non-data,83
| (2) Consecutive Writes: A host writes to the same block multiple times without intervening reads from another host Since this block is already tagged with the host’s integrity level, recording a second write event provides no new infor- mation except the latest timestamp (3) Write, then Read: A host reads from a block that it had previously written Here, the consumed data was already assumed to be on the host, so recording the read event is not necessary|,Non-data,83
| Our versioning algorithm filters the number of provenance events recorded, maintaining an in-memory map structure for the current version of each block in use Each version is a tuple consisting of: < BlockN um, V ersionN um, HwGB, T SwGB, U sedBy > where BlockN um is the block number, V ersionN um is a monotonically increasing integer representing the current version of BlockN um, HwGB is the label of the host that most recently wrote to the block, and T SwGB is the times- tamp when HID first wrote to BlockN um U sedBy is a list of tuples (HU B, T SU B) where T SU B is the time that HU B first read the current version of BlockN um The filtering algorithm works as follows: Read from Host HA to BlockN um: the device dae- mon updates BlockN um’s struct, appending U sedBy iff HwGB (cid:54)= HA and ∀HU B ∈ U sedBy, HU B (cid:54)= HA |,Non-data,83
| Write from Host HA to BlockN um: iff HwGB (cid:54)= HA, the device daemon writes BlockN um’s struct to flash storage, re-initializes the struct, sets HwGB = HA and T SwGB equal to the current timestamp The result is that flushes to storage never occur for consec- utive reads, and only occur on writes when a new host writes to a given block When the ProvUSB device receives an ejec- tion signal, the in-memory structure is flushed to storage, (a) Read Operations (b) Write Operations Figure 4: ProvUSB’s Integrity Model High Integrity (HI) hosts are not permitted to read Low Integrity (LI) data blocks from USB storage|,Non-data,83
| HI data blocks transition to an LI state if written to by an LI host nature of USB devices Even worse, filesystem layer moni- toring could be bypassed using raw I/O [58, 70], leading to incomplete provenance Additionally, we wished to be able to track storage operations at the finest possible granularity|,Non-data,83
| Instead, ProvUSB integrates provenance capture into the lower layers of the storage device; provenance is generated for all I/O operations at the SCSI layer By designing the provenance at the block level, we are able to make ProvUSB filesystem agnostic This means, although ProvUSB requires specialized firmware or software running on the device, it can be adopted without requiring any changes to the filesystem format of the storage partition One consequence of this approach is that, in many cases, block-level provenance will need to be translated into human-readable filesystem semantics before it can be interpreted by an investigator|,Non-data,83
| Auxiliary tools that are compatible with ProvUSB’s provenance store will therefore be necessary to translate block-level activity to file level information Such tools can be built as straightforward extensions of block reverse engineering mechanisms such as filesystem checkers or even built as file-to-block mapping services embedded within existing filesystems In Section 4, we implement a tool that correlates files with their blocks for the FAT filesystem By relegating this translation to a post- processing step, we decouple provenance collection from interpretation and ensure that our design is independent of actual filesystem implementation|,Non-data,83
| Block-level Integrity Protection: While a variety of USB devices appearing on the market [32, 38] and in the literature [12] provide data confidentiality, less attention has been paid to integrity assurance We now discuss an exten- sion to ProvUSB that provides provenance-based enforce- ment of an MLS integrity lattice For clarity, we intro- duce simple lattice featuring Low Integrity (LI) and High Integrity (HI) levels, although our system could accommo- date arbitrarily many integrity levels Although we choose to focus on integrity assurance, the following could also be easily adapted to provide fine-grained confidentiality in an MLS model that provides Bell-LaPadula guarantees [10]|,Non-data,83
| To provide a realistic operating environment for USB stor- age, ProvUSB’s integrity model borrows from both Biba [11] and LOMAC [19, 20] in that it assumes immutable host la- bels and mutable data labels Like Biba, hosts are assigned an integrity level at creation time and subsequently have a null transition state Blocks on the storage device have a stateful transition between integrity levels, like LOMAC At creation time, all blocks are in an HI state|,Non-data,83
| Their current 246In user space, the NetLink TPM Daemon (nltpmd) listens on a netlink socket for a new TPM challenge (ie, a nonce) from the usb-storage driver Once the nonce arrives, it uses the TrouSerS API [69] to talk to the TPM hardware, then sends both the TPM quote and AIK public key back to the usb-storage driver|,Non-data,83
| The driver delivers this response to the ProvUSB device over an ADSC message Immediately after this, the driver requests SCSI scanning the device stor- age in order to mount the partition, which is permitted by ProvUSB only if it successfully authorizes the host Device Modifications: In the kernel space of the USB storage device, we modified the f-mass-storage gadget driver We created a new device entry mapping for ven- dor ID 0xb000 and added it into the USB Mass Storage compliant devices list|,Non-data,83
| To support TPM attestation over USB, we added new EP0 callbacks to process ADSCs from the host machine To manage the TPM AIK public keys and maintain the policy control for each block, we added two linked lists to the gadget driver We backported the RSA verification implementation from Linux Kernel 313 to directly support signature verification in kernel space|,Non-data,83
| We also patched the crypto subsystem to make it callable in the EP0 handlers (IRQ context) Finally, we added a kernel timer to the gadget driver so TPM attestations can gracefully fail in the event of a timeout, which could occur if the host machine was not equipped with a TPM or the TPM attestation response was sent late In the event of a failure, the gadget driver rejects subsequent requests from the host machine In the user space of the USB storage device, a prove- nance daemon (provd) communicates with the kernel gad- get driver using a netlink socket|,Non-data,83
| Provd performs three key tasks: 1) TPM management, 2) policy configuration, and 3) provenance logging TPM management supports adminis- trative tasks such as adding TPM AIK public keys to the gadget driver key store, or removing old ones The pol- icy configuration component allows administrators to assign integrity labels to new machines It also maintains persis- tent storage of the integrity labels of different blocks on the storage partition for when the device is unmounted, which is necessary for bus-powered devices|,Non-data,83
| This information is loaded automatically into the gadget driver when the de- vice is plugged into a host machine again The provenance logging component runs in two configurations, ProvFlush and ProvSave The ProvFlush configuration synchronously flushes each new provenance record to persistent storage as soon as it is created The ProvSave configuration imple- ments the optimization described in Section 3|,Non-data,83
|5 in which provenance is only flushed to persistent storage on write op- erations and initial read operations among consecutive ones To bridge the semantic gap between human-interpretable file metadata and block provenance, we implemented a utility called file2block (f2b) that can identify the blocks corre- sponding to a given file name in the FAT16 filesystem After recovering the blocks associated with a file, the provenance of each block can then be queried individually to discover the file’s provenance 5|,Non-data,83
| SECURITY ANALYSIS Minimal Trusted Computing Base (G1) To verify the identity and software configuration of the host, ProvUSB performs a TPM-based remote attestation over the USB in- terface ProvUSB does not trust any configuration infor- Figure 5: ProvUSB Software Stacks The left figure shows a software stack of a USB storage in the view of a host ma- chine|,Non-data,83
| The right box displays the software stack of ProvUSB devices All layers are mapped between the host machine and the storage device Figure 6: ProvUSB Architecture In the host machine, the nltpmd communicates with the TPM and relays the TPM at- testation results to the usb-storage driver|,Non-data,83
| In the ProvUSB device, f-mass-storage driver verifies the TPM attestation using krsa and monitors each I/O operations at the block level, enforcing the policy control and relaying the prove- nance to provd in the user space saving provenance and block integrity information, which is read back into memory next time the device is plugged in 4 IMPLEMENTATION We implemented ProvUSB on a Gumstix COM (Computer- on-Module) [25] equipped with a USB OTG (On-The- Go [71]) interface, acting as a USB storage device formated in FAT16 filesystem, as shown in Figure 5|,Non-data,83
 The host ma- chine was a TPM-equipped desktop running a modified version of Linux An overview of the architecture is shown in Figure 6 Host Modifications: We modified the Linux usb-storage driver to support TPM attestation over USB ProvUSB de- vices enumerating to the host signal their presence by using vendor ID 0xb000 to distinguish themselves from other USB storage devices,Non-data,83
| After the normal enumeration and before the driver begins scanning the storage device, the host ini- tiates a TPM attestation procedure as outlined in Section 34, beginning with sending an ADSC over the USB control channel (EP0) to activate the TPM attestation procedure on the device side Note that because EP0 is mandatory for all USB devices and ADSC uses EP0, ADSC is natively supported by the USB hardware 247mation reported by the host during USB enumeration, as the host could spoof these messages|,Non-data,83
| The host cannot lie about the operations it performs on the device’s storage partition, as ProvUSB is able to record the ground truth of the hosts interactions with the USB storage Therefore, ProvUSB only trusts software running onboard the device Forensic Validity (G2) ProvUSB provenance informa- tion is aggregated and analyzed by an enterprise’s technol- ogy office periodically upon device check-in|,Non-data,83
| The length of epochs is parametrizable, but we envision that device check- ins will occur on the order of days Failure to return a ProvUSB device could lead to incomplete provenance, but in this instance the technology office is alerted to the possi- bility of nefarious behavior on the part of the employee that checked-out the device From this, we can conclude that G2 is satisfied, as at the end of each epoch the administrator is guaranteed to have either a complete provenance history for the device or an alert to the possibility of misbehavior Tamperproof (G3)|,Non-data,83
| A violation of Goal G3 would occur if an employee is able to manipulate ProvUSB in or- der to insert or remove provenance records between epochs; through use of a modified version of the Yocto Linux ker- nel and USB OTG, the storage of provenance is separated from the storage partition exposed to the host, making it ex- tremely difficult to view or modify provenance records with- out physically opening the device The possibility of such attacks could be further mitigated through implementing ProvUSB on tamper-resistant hardware, in much the same way that IronKey ensures confidentiality guarantees [32] Another possible attack that could lead to lost provenance would be to exploit the race condition between the times when a block operation occurs and when its provenance record is written to persistent storage For example, imme- diately after a write operation the employee could physically unplug the device, causing the device to shut down before ProvUSB can record the operation’s provenance|,Non-data,83
| While our prototype implementation would be vulnerable to this at- tack, this threat could be remedied by extending ProvUSB with a capacitor-backed mechanisms to flush out such meta- data quickly when disconnected from the host power source Track Malware and Explain Data Leaks (G4,G5) Given Goals G2 and G3, it logically follows that G4 and G5 are satisfied This is because previous work has already demonstrated that data provenance can be used to track the propagation of malware [5, 21, 54, 65, 74] and detect data exfiltration [8, 35, 40, 41, 43]|,Non-data,83
| We provide specific examples of how ProvUSB can detect malware propagation in §66 Integrity Assurance (G6) Given Goals G2 and G3, it logically follows that G6 is satisfied|,Non-data,83
| This is because pre- vious work has demonstrated that provenance histories can be used to provide fine-grained access control enforcement [7, 48, 50] We provide specific examples of how ProvUSB can prevent integrity violations in §66 6|,Non-data,83
| EVALUATION We now evaluate the performance of the various compo- nents of ProvUSB The host machine used in our tests is a Dell Optiplex 7010 desktop with a quad-core Intel i5-3470 320 GHz CPU, 8 GB memory, standard USB 20 ports and an STM TPM (version 1|,Non-data,83
|2 and firmware 1312), run- ning Ubuntu LTS 1404 (x86-64) with Linux kernel version 313|,Non-data,83
|11 and TSS API 12 rev 03 The ProvUSB device is a Gumstix Overo COM with an ARMv7 600 MHz CPU, 256 TPM Operation Min PCR Read AIK Read Quote Avg Max Dev 23|,Non-data,83
199 1709 10633 60491 5,Non-data,83
218 48220 323647 344028 347,Non-data,83
858 360209 6100 Med 11978 60,Non-data,83
273 12188 57244 Table 1: TPM operation time (ms) averaged by 1000 runs Avg Max Dev Enumeration Min Kingston2G 338,Non-data,83
