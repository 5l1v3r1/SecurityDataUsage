 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| We mea- sure DeltaSwitch as the switching introduced by the Tro- jan, which is the difference of number of switches between the golden circuit and the Trojan-infected circuit We mea- sure RelativeSwitch as the ratio of DeltaSwitch to the to- tal number of switches (TotalSwitch) in the golden circuit 133Algorithm 1: Multiple Excitation of Rare Switching (MERS) Input: Circuit netlist, rare switching requirement (N ), list of rare nodes (R = {r1, r2, |,Non-data,63
|, rm}), list of random patterns (V = {v1, v2, |,Non-data,63
|, vn}) Output: MERS test patterns (T ) // simulate and sort random vectors 1: for each random vector v in V do 2: Simulate the circuit with the input vector v Count the number of nodes (RV ) in R with their rare values satisfied 4: end 5: Sort vectors in V in descending order of RV 6: for each node ri in R do 7: 8: end Set its rare switching counter (Si) to 0 3: 12: 13: 14: 15: 16: 17: 18: 19: 20: 21: 22: 23: 24: 25: 26: 27: (a) A 4-trigger Trojan (b) An 8-trigger Trojan Figure 2: Trojans with rare nodes as trigger conditions The 4-trigger Trojan will only be activated by the rare combina- tion 1011 and the 8-trigger Trojan will only be activated by the rare combination 10110011 An effective test vector should be capable of creating large DeltaSwitch, and more importantly it should create large RelativeSwitch, as it is directly related to the sensitivity for side channel analysis RelativeSwitch = DeltaSwitch/T otalSwitch (1) The major challenges for generating high-quality test vectors are as follows: (1) we are not sure of the location where the Trojan is inserted in the circuit; (2) the Trojan is stealthy and has very low activity when it is not triggered|,Non-data,63
 These characteristics have made random tests not effective in mag- nifying the side channel signal for Trojan detection Fig 2 shows two example Trojan instances The 4-trigger Trojan will only be activated by the rare combination 1011 and the 8-trigger Trojan will only be activated by the rare combina- tion 10110011,Non-data,63
| If the possibility of each rare node to take its rare value is 01, the probability to have these two Trojans fully triggered is 10−4 and 10−8, respectively Our test generation approach (MERS) is based on creat- ing a set of test vectors for each candidate rare node indi- vidually to have rare switching multiple (at least N ) times Our approach utilizes the principle of N -detect [20] tests to increase the likelihood of partially or fully activating a Tro- jan|,Non-data,63
| MERS can generate a high-quality testset for these rare nodes individually to have rare switching for N times If N is sufficiently large, a Trojan with triggering conditions from these rare nodes is likely to have high switching activity even though it might not be fully activated 41 Multiple Excitation of Rare Switching The basic idea of MERS is that if we can make a rare node switch N times where N is sufficiently large, it significantly // mutate vector to find improved vector pairs 9: Initialize previous vector tp as a vector of all 0’s 10: for each vector vj in V do 11: Simulate the circuit with vector pair (tp, vj) Count the number of rare switches (RS) Set v(cid:48) for each bit in v(cid:48) j = vj j do Mutate the bit and re-simulate the circuit with vector pair (tp, v(cid:48) j) Count the number of rare switches (R(cid:48) S) if R(cid:48) S > RS then Accept the mutation to v(cid:48) j end end Update Si for all nodes in R due to vector v(cid:48) if v(cid:48) j increases Si for at least one rare node then Add the mutated vector v(cid:48) Set tp = v(cid:48) j to T j j end if Si ≥ N for all nodes in R then Break end 28: 29: end 30: return MERS test patterns T improves the chance of switching in a Trojan associated with that rare node|,Non-data,63
| The rare switching in our algorithm spe- cially refers to a rare node switching from its non-rare value to its rare value The reason to choose this criteria is two- fold: (1) it is more difficult to switch from non-rare to rare value than from rare to non-rare value; (2) it defines the switching between the previous vector and the current vec- tor, and it usually helps to create an extra switching between the current vector and the next vector This will increase the probability of switching of a Trojan which has rare nodes as its trigger conditions Our approach is also applicable to se- quential Trojans, which requires the rare condition to occur a certain number of times to be fully triggered|,Non-data,63
| Algorithm 1 shows the steps of MERS to generate high quality tests for creating switching in rare nodes, so as to assist side channel analysis for hardware Trojan detection The algorithm is fed with the golden circuit netlist, the list of random test patterns (V ) and a list of rare nodes (R) (which is obtained by random vector based circuit simulation 134Algorithm 2: Tests Reordering by Hamming Dis- tance (MERS-h) Input: List of Test Patterns (Torig = {t1, t2, |,Non-data,63
|, tn}) produced by Algorithm 1 Output: Improved Test Patterns (Thamm) 1: Initialize Thamm = {} 2: Initialize previous test tp as a vector of all 0’s 3: while Torig is not empty do 4: mindist = int max bestidx = −1 for all remaining tests tj in Torig do if mindist > hamming dist(tp, tj) then mindist = hamming dist(tp, tj) bestidx = j end end Add tbestidx to the end of Thamm Remove tbestidx from Torig Update tp = tbestidx 14: 15: end 16: return Thamm Algorithm 3: Tests Reordering by Simulation (MERS-s) Input: List of Test Patterns (Torig = {t1, t2, , tn}) produced by Algorithm 1 Output: Improved Test Patterns (Tsim) 1: Initialize Tsim = {} 2: Initialize previous test tp as a vector of all 0’s 3: while Torig is not empty do 4: maxp = int min bestidx = −1 for all remaining tests tj in Torig do Simulate the circuit with vector pair (tp, tj) Count the number of RareSwitch and TotalSwitch prof it = C ∗ RareSwitch − T otalSwitch if maxp < prof it then maxp = prof it bestidx = j end end Add tbestidx to the end of Tsim Remove tbestidx from Torig Update tp = tbestidx 17: 18: end 19: return Tsim beforehand)|,Non-data,63
| First, we simulate each random pattern and count the number of rare nodes (RV ) that take their rare values We sort the random patterns in descending order of RV , which means that the vector with ability to activate the most number of rare nodes goes first Next, we initialize the rare switching counter Si for each rare node to 0 In the next step, we mutate vectors from the random pattern set to generate high quality tests|,Non-data,63
| We mutate the current vector one bit at a time and we accept the mutated bit only if the mutated vector can increase the number of nodes to have rare switching In this step, only those rare nodes with RS < N are considered The mutation process repeats until each rare node has achieved at least N rare switches The output of the test generation process is a compact set that improves the switching capability in rare nodes, compared to random patterns|,Non-data,63
| The complexity of the algorithm is O(n∗m), where n is the total number of test vectors mutated during the process, and m is the number of bits in primary inputs The runtime to generate MERS tests can be found in Table 1 The testset generated by MERS is expected to be very effective in increasing the likelihood of rare nodes to switch and thus increasing the activities in Trojans In other words, MERS testset is capable of maximizing the DeltaSwitch (the numerator in Equation 1)|,Non-data,63
| MERS testset is already a very high quality testset in terms of criteria for DeltaSwitch However, MERS testset also creates more switching in other parts of the circuit, when it is making efforts to switch rare nodes This characteristic of increased TotalSwitch would be further illustrated in the Section 5 In order to maximize relative switching, we need to have TotalSwitch in control as well|,Non-data,63
| In the following subsections, we propose two meth- ods to tune the MERS testset, so that it can: (1) still be effective for DeltaSwitch, (2) reduce TotalSwitch and im- prove the effectiveness for RelativeSwitch The first method is a heuristic approach based on hamming distance of test vectors, which can reduce the total switching The second one is simulation based, in which we try to balance the rare switching and the total switching while we explore all the candidate vectors 4|,Non-data,63
|2 Hamming Distance based Reordering If two consecutive input vectors have the same values in most bits, it is very possible that the internal nodes will also have a lot of values in common A simple heuristic to reduce total switching in circuit is to have similar input vec- tors We use the Hamming distance between two vectors to represent the similarity Algorithm 2 shows our approach to reorder the testset by Hamming distance|,Non-data,63
| The algorithm is a greedy approach to explore all candidate vectors and take the best one in terms of Hamming distance We first check the Hamming distances between the previous vector and all the remaining vectors, then we select the vector which has the minimum Hamming distance as the next vector The time complexity of Algorithm 2 is O(n2), where n is the testset size Fortunately, it is of low cost to calculate the Hamming distance between two input vectors|,Non-data,63
| The actual run-time is very short because n (number of test patterns produced by MERS) is small, in the order of tens of thou- sands 5: 6: 7: 8: 9: 10: 11: 12: 13: 5: 6: 7: 8: 9: 10: 11: 12: 13: 14: 15: 16: 43 Simulation based Reordering The reordering problem to improve the relative switching is actually a multi-objective optimization problem: maxi- mize the DeltaSwitch and minimize the T otalSwitch as in Equation 1 We do not know the DeltaSwitch, because the location and type of the Trojan is unknown|,Non-data,63
| However, rare switching between two vectors is a good indicator for DeltaSwitch, which means a large number of rare switching would imply a large DeltaSwitch in Trojan We redefine the optimization goal as to maximize the rare switching and 135minimize the total switching at the same time between vec- tor pairs We formalize the problem as shown in Equation 2 We need to explore the best weights to balance between the two objectives: maximize (w1 ∗ RareSwitch − w2 ∗ T otalSwitch) (2) We propose an approach as shown in Algorithm 3 based on real simulation of the test vectors to maximize the com- bined objective|,Non-data,63
| We introduce a concept of prof it to indi- cate the fitness of a test vector to follow the previous test vector prof it is defined as (C∗RareSwitch−T otalSwitch), where C is the ratio of two weights w1 and w2 It is meant to maximize the rare switching (activity in Trojan circuits) and minimize the total switching of the whole circuit In the experiment section, we will explore different weight ra- tios and check the influence of weight ratios on side channel sensitivity|,Non-data,63
| Algorithm 3 shows our approach to tune the testset by simulation with prof it as a reordering criterion By ex- haustively checking the prof it between the previous vector and all the remaining vectors, we select the vector which has the maximum prof it as the next following vector The time complexity of Algorithm 3 is O(n2), where n is the test length However, it is much slower than Algorithm 2, because it is time-consuming to simulate input vector pairs and calculate prof it|,Non-data,63
| Figure 3: Test generation framework for side-channel anal- ysis based Trojan detection 5 EXPERIMENTS 51 Experimental setup The test generation framework, including the MERS core algorithms and the evaluation framework, is implemented using C|,Non-data,63
| As shown in Fig 3, the test generation framework can simulate circuit netlists, generate MERS testset, further tune the testset, and evaluate the effectiveness of testsets on random Trojans We evaluated our approach on a subset of ISCAS-85 and ISCAS-89 benchmark circuits The se- quential circuits are converted into full scan mode|,Non-data,63
 We also implemented the MERO [5] approach with parameter N of 1000 for comparison We did our experiments on a server with AMD Opteron Processor 6378 (24GHz) The runtime for different benchmarks and different methods is shown in Table 1,Non-data,63
| The table also shows the number of rare nodes in each benchmark We used 01 as the rare threshold to select rare nodes Table 1: Runtime for MERS test generation, reordering us- ing hamming and reordering using simulation, with N=1000, rare threshold = 0|,Non-data,63
1 Benchmark Nodes (rare / total) c2670 c3540 c5315 c6288 c7552 s13207 s15850 s35932 63 / 1010 331 / 1184 255 / 2485 45 / 2448 306 / 3720 592 / 2504 679 / 3004 896 / 6500 Run-time (s) MERS MERS-h reordering MERS-s reordering 1337086 609751 4559597 4154,Non-data,63
62 8140589 1251195 1990344 7295,Non-data,63
74 492523 1816694 3907381 2802,Non-data,63
85 6350219 2906472 3818149 31201,Non-data,63
04 724 943 1104 0,Non-data,63
31 252 36502 72814 39,Non-data,63
|53 52 Evaluation Criteria When applying a testset to a circuit with Trojan, there are four criteria to evaluate the effectiveness of the testset: • AvgDeltaSwitch: the average delta switch when ap- plying the testset on this Trojan-infected circuit • MaxDeltaSwitch: the maximum delta switch when applying the testset • AvgRelativeSwitch: the average relative switch when applying the testset|,Non-data,63
| • MaxRelativeSwitch: the maximum relative switch when applying the testset We choose this criterion as the Side Channel Sensitivity because this directly determines whether a Trojan can be detected through side-channel analysis AvgDeltaSwitch and MaxDeltaSwitch reflect the activity in Trojan, and AvgRelativeSwitch as MaxRelativeSwitch reflect the sensitivity of the side channel signal in detecting the Trojan As for evaluation of testsets, we would expect a high- quality testset to have a good coverage over all possible Tro- jans|,Non-data,63
| In our experiments, we apply the testset to 1000 ran- domly inserted Trojan samples and compute these four val- ues for each Trojan instance We would then take the aver- age of these four metrics, which would reflect the capability of the testset to enable detection of different Trojans through side-channel analysis The average M axRelativeSwitch would be most suitable for Side Channel Sensitivity evaluation, which is to maximize the sensitivity for an arbitrary Trojan in unknown circuit location 5|,Non-data,63
3 Exploration of N Fig 4 shows the distribution of MaxDeltaSwitch over 1000 random 8-trigger Trojan samples for two ISCAS-85 136(a) c2670: Distribution of MaxDeltaSwitch over 1000 random sam- ples of 8-trigger Trojans (a) (b) (b) c3540: Distribution of MaxDeltaSwitch over 1000 random sam- ples of 8-trigger Trojans Figure 4: Impact of N (number of times that a rare node have rare switching) on MaxDeltaSwitch for benchmarks (a) c2670 and (b) c3540,Non-data,63
| benchmarks We choose different N to generate MERS test- sets, to compare with the Random (10K vectors) testset For each testset, the box plot shows (minimum, first quartile, median, third quartile, maximum) values of MaxDeltaSwitch of the 1000 Trojan samples It is clear from these plots that the distribution of MaxDeltaSwitch is constantly improving with increasing N |,Non-data,63
| For c2670, the average MaxDeltaSwitch (as shown by the red lines) can reach 1867 for MERS (N = 1000), while Random testset can achieve only 1215 For c3540, the average MaxDeltaSwitch can reach 11|,Non-data,63
|13 for MERS (N = 1000), while for Random testset it is only 919 The fact that the quality of MERS tests improves with increasing N is not surprising It is similar to N -detect tests for stuck- at faults, where fault coverage is expected to improve with increasing N |,Non-data,63
| The testset size also increases with N  The sizes of testsets for MERS (N = 10, 20, 50, 100, 200, 500, 1000) are (71, 140, 347, 656, 1262, 3142, 6199) for c2670, and (161, 302, 742, 1441, 2858, 7070, 14250) for c3540 In most of our experiments, we choose a value of N = 1000, which is a good balance between testset quality and testset size For fair comparison with Random testset, we will only take the first 10K vectors of MERS testset if it is larger than 10K|,Non-data,63
| Figure 5: MaxDeltaSwitch versus TotalSwitch for different N for benchmarks (a) c2670 and (b) c3540 MERS creates more switching in Trojan, as well as more switching in other parts of the circuit (which results in increased total switch- ing) 54 Effect of Increased Total Switching Fig|,Non-data,63
| 5 shows the average M axDeltaSwitch and the av- erage T otalSwitch of the testsets for 1000 8-trigger Tro- jan samples for different values of N  For both of the two benchmarks, the average T otalSwitch increases with N as well as the average M axDeltaSwitch It is obvious that all the MERS testsets have much larger average T otalSwitch, compared with the Random testset For c2670, the aver- age T otalSwitch for MERS (N = 1000) is 644|,Non-data,63
|9, which is about 125X times of that of the Random testset (5157) For c3540, the average T otalSwitch for MERS (N = 1000) is 808, while Random testset is only 649|,Non-data,63
|2 The insight that we can get from here is that MERS tends to increase the T otalSwitch of the circuit, although it is designed to in- crease switches in rare nodes The following subsection will show that the proposed reordering methods would be effec- tive to reduce T otalSwitch and thus increase side channel sensitivity 5|,Non-data,63
5 Effect of Weight Ratio (C) The effectiveness of the two reordering methods can be ob- served in Fig 6 and Fig 7 As shown in Fig,Non-data,63
| 6, MERS-h can reduce T otalSwitch and thus increase the relative switching 137(a) (b) Figure 6: Side Channel Sensitivity versus T otalSwitch for Random, the original MERS, MERS-h and MERS-s (with different C) for benchmarks (a) c2670 and (b) c3540 Both MERS-h and MERS-s (with a small C) are effective in re- ducing the total switching (ie|,Non-data,63
| the Side Channel Sensitivity), compared with the orig- inal MERS testset For MERS-s with different weight ratio C, side channel sensitivity improves steadily with a small C, and then goes down when C is too large As the weight ra- tio tries to balance DeltaSwitch and T otalSwitch, a large C will outweigh the influence of T otalSwitch, which will make it less different from the original MERS testset In the fol- lowing experiments, we choose the weight ratio as C = 5, as it provides a good balance between the total switching and rare switching|,Non-data,63
| Fig 7 shows detailed distribution of Side Channel Sensi- tivity for 1000 8-trigger Trojan samples with different choices of C The reordering methods are working well to improve Side Channel Sensitivity, which is built on the fact that the original MERS testset is already of high quality in terms of DeltaSwitch, or switching in Trojans 5|,Non-data,63
|6 Increase in Trojan Activity Table 2 shows that MERS (N =1000) is very effective in creating DeltaSwitch caused by arbitrary Trojans due to its statistical nature The average Max Delta Switch increases by 3111% and the average Avg Delta Switch by 18733% on average for different benchmarks, compared with Random (a) c2670: Distribution of Side Channel Sensitivity over 1000 random samples of 8-trigger Trojans|,Non-data,63
| (b) c3540: Distribution of Side Channel Sensitivity over 1000 random samples of 8-trigger Trojans Figure 7: Distribution of Side Channel Sensitivity for Ran- dom, the original MERS, MERS-h and MERS-s (with dif- ferent C) for benchmarks (a) c2670 and (b) c3540 testset This shows the effectiveness of MERS in creating Trojan activity|,Non-data,63
| Table 3 shows that MERS is also helpful in improving RelativeSwitch The average AvgRelativeSwitch increased by 15816%, compared with Random testsets For average MaxRelativeSwitch (Side Channel Sensitivity), MERS has an average improvement of 18|,Non-data,63
|89% However, Side Channel Sensitivity values for benchmark c3540 and c6288 are not as good as those of Random testsets This is due to the fact that MERS testset also increases the total switching, when it is making efforts to cause rare nodes switching This phenomenon is illustrated and explained in Fig|,Non-data,63
| 5 and Fig 6, and this side effect can be improved by the two reordering algorithms as shown in Table 4 and 5 57 Side Channel Sensitivity Improvement To this point, we have explored the parameters: N for MERS and C for MERS-s|,Non-data,63
| We choose N = 1000 and C = 5 in the following experiment to compare our pro- posed schemes with Random testset and MERO Table 4 and 5 show the improvement of proposed approaches on Side Channel Sensitivity for 4-trigger and 8-trigger Trojans Table 4 shows that MERS, MERS-h and MERS-s have 1037%, 138|,Non-data,63
|44% and 15226% improvement over the Ran- 138Table 2: Comparison of MERS (N=1000) with Random (10K) for average MaxDeltaSwitch and average AvgDeltaSwitch, over 1000 random samples of 8-trigger Trojans Benchmark c2670 c3540 c5315 c6288 c7552 s13207 s15850 s35932 average MaxDeltaSwitch Random MERS 1867 11|,Non-data,63
13 1380 726 1200 8,Non-data,63
83 1084 1537 Improve Random MERS 6,Non-data,63
8561 5367% 29058 2116% 45,Non-data,63
16% 39300 48448 963% 2,Non-data,63
7700 4076% 09771 3318% 43,Non-data,63
99% 13609 135% 68060 31,Non-data,63
11% average AvgDeltaSwitch Improve 37983% 11185% 199,Non-data,63
64% 35550% 10536% 5201% 82,Non-data,63
29% 21216% 18733% 14289 1,Non-data,63
3716 13116 10636 13488 0,Non-data,63
6428 07465 21803 1215 9,Non-data,63
19 951 663 853 6,Non-data,63
63 753 1516 Avg Improve,Non-data,63
| – – – – Table 3: Comparison of MERS (N=1000) with Random (10K) for average M axRelativeSwitch (Side Channel Sensitivity) and average AvgRelativeSwitch, over 1000 random samples of 8-trigger Trojans Benchmark c2670 c3540 c5315 c6288 c7552 s13207 s15850 s35932 Random MERS 002469 003108 0|,Non-data,63
01933 002670 000766 000526 0,Non-data,63
00395 000534 000452 000852 0,Non-data,63
00844 000756 000716 000593 0,Non-data,63
00523 000587 Avg Improve – – average MaxRelativeSwitch (Side Channel Sensitivity) average AvgRelativeSwitch Improvement Random MERS 0,Non-data,63
01054 000361 000200 000219 0,Non-data,63
00113 000085 000082 000223 0,Non-data,63
00255 000214 000075 000059 0,Non-data,63
00058 000066 000053 000060 25,Non-data,63
90% -2759% 4572% -2606% 88,Non-data,63
48% 1164% 2070% 1229% 18,Non-data,63
89% – – Improvement 31414% 6912% 16565% 270,Non-data,63
68% 9465% 2822% 5425% 268,Non-data,63
|54% 15816% dom testsets, respectively While the original MERS testsets is 2395% worse than MERO testsets, MERS-h and MERS- s have 52|,Non-data,63
|62% and 6201% improvement over MERO Ta- ble 5 shows the results for 8-trigger Trojans Compared to Random testsets, MERS, MERS-h and MERS-s can have 18|,Non-data,63
|89%, 10753% and 9661% improvement, respectively The original MERS testsets is 12|,Non-data,63
|43% worse than MERO test- sets MERS-h and MERS-s testsets can improve the Side Channel Sensitivity by 4079% and 3850%, respectively|,Non-data,63
| In this section, we explore the impact of different values of N for MERS and observe the effectiveness of MERS to maximize Trojan activity as N increases We confirm the su- periority of MERS testsets over Random testsets in Section 56 on creating switching activity in randomly sampled Tro- jans We observed that the total switching was also likely to increase while MERS made efforts to maximize rare switch- ing in Trojans|,Non-data,63
| The two reordering methods (MERS-h and MERS-s) successfully had the total switching under control while maintaining the rare switching high The comparison with Random and MERO testsets shows the effectiveness of our test generation framework in maximizing Side Channel Sensitivity for Trojan detection obtain the limiting threshold values, beyond which any chip is classified as Trojan-infected MERS can simultaneously maximize the switching in Trojan and minimize the back- ground switching, so as to maximize the relative switching|,Non-data,63
| By calibration or reference to that of a golden chip, MERS helps side channel analysis to reduce the intra-die systematic process variations Moreover, as shown in [23], various mea- surable parameters can be used for multiple-parameter side- channel-based Trojan detection where at least one parame- ter is affected by the Trojan and other parameters are used to calibrate the process noise For example, the dynamic current (IDDT ), the quiescent or leakage current (IDDQ) and the maximum operating frequency (Fmax) may be influenced when there is a Trojan They can serve as side channel refer- ences to calibrate process noise|,Non-data,63
| Authors in [23] have shown Trojan and process variation effects on these three vari- ables (IDDT , IDDQ and Fmax) MERS can increase IDDT , which would greatly improve the accuracy of [23] to isolate a Trojan-infected chip in the multiple-parameter space from process induced variations 59 Scalability to Large Designs 5|,Non-data,63
|8 Process Calibration and Multiple-Parameter Side-Channel Analysis MERS can be combined with existing process calibration approaches [21][22][23] to minimize the false positives/negatives and maximize Trojan coverage Most side-channel analysis based approaches perform process variation calibration by using golden chips at different process corners This helps us For a large design, the supply current of a golden chip for a high-activity vector can be very large compared to the additional current consumed by a small Trojan The vari- ation in the current value due to process noise can also be very large, which would mask the effect of the Trojan on the measured current and create difficulty for accurate Tro- jan detection|,Non-data,63
| Scalability of MERS to larger designs can be enhanced by combining it with region-based test generation 139Table 4: Comparison of average Side Channel Sensitivity between Random (10K), MERO, and MERS testsets, N=1000, C=5 for MERS-s, over 1000 random samples of 4-trigger Trojans Benchmark Comparison Testsets Proposed Schemes Improvement to Random Improvement to MERO c2670 c3540 c5315 c6288 c7552 s13207 s15850 s35932 Avg Improve Random MERO MERS MERS-h MERS-s MERS MERS-h MERS-s MERS MERS-h MERS-s 31|,Non-data,63
01% 001703 2869% 002144 -37,Non-data,63
71% 39797% 41616% -6848% 151,Non-data,63
96% 16116% 6779% 18897% 256,Non-data,63
29% -3097% 1889% 000445 46,Non-data,63
59% 8685% -2088% 8750% 126,Non-data,63
80% -3481% 5447% 000480 58,Non-data,63
42% 3961% 25563% 23238% -33,Non-data,63
46% 6950% 000351 3380% 25,Non-data,63
29% 907% 000568 000447 6,Non-data,63
14% 4186% 3017% 1048% 1,Non-data,63
89% 790% 000354 1037% 138,Non-data,63
44% 15226% -2395% 5262% 62,Non-data,63
01% 002571 004238 001082 0,Non-data,63
00395 000737 000617 000487 0,Non-data,63
00463 002231 001336 000747 0,Non-data,63
00313 000491 000619 000474 0,Non-data,63
00361 003035 010677 001287 0,Non-data,63
00741 001250 000773 000691 0,Non-data,63
00500 003308 011067 001586 0,Non-data,63
00896 001168 000826 000634 0,Non-data,63
00512 031% 4549% -275% 42,Non-data,63
06% 4453% -2212% 9431% -13,Non-data,63
23% 1807% 3624% 5483% 41,Non-data,63
|17% 7827% – – – – – Table 5: Comparison of average Side Channel Sensitivity between Random (10K), MERO, and MERS testsets, N=1000, C=5 for MERS-s, over 1000 random samples of 8-trigger Trojans Benchmark Comparison testsets Proposed Schemes Improvement to Random Improvement to MERO c2670 c3540 c5315 c6288 c7552 s13207 s15850 s35932 Avg Improve|,Non-data,63
 Random MERO MERS MERS-h MERS-s MERS MERS-h MERS-s MERS MERS-h MERS-s 002469 2435% 2590% -27,Non-data,63
59% 34853% 27596% -6505% 116,Non-data,63
47% 8144% 002670 9403% 114,Non-data,63
78% -1238% 1666% 2914% 45,Non-data,63
72% 000526 5749% 9172% -26,Non-data,63
06% 2155% 000534 -420% 57,Non-data,63
31% 2574% 8848% 21778% 154,Non-data,63
00% -670% 000452 2558% 0,Non-data,63
00756 1164% 069% 3263% 13,Non-data,63
28% 2786% -087% 2070% 0,Non-data,63
00593 974% 1229% 858% 0,Non-data,63
00523 -790% 1889% 10753% 96,Non-data,63
61% -1243% 4079% 3850% 0,Non-data,63
03204 005532 000875 000412 0,Non-data,63
00914 000838 000722 000638 0,Non-data,63
03108 001933 000766 000395 0,Non-data,63
00852 000844 000716 000587 0,Non-data,63
03729 011974 001020 000649 0,Non-data,63
01437 001053 000923 000692 0,Non-data,63
03984 010037 001129 000790 0,Non-data,63
01149 001112 000818 000700 39,Non-data,63
24% 5569% 3239% 4705% 37,Non-data,63
94% 3380% 5105% 6140% 16,Non-data,63
|37% 4797% -301% – – – – – approaches, which segment a circuit into nearly-isolated re- gions (ie|,Non-data,63
| with low connectivity between them) In this case, MERS can be applied separately to each region For example, in case of a processor, MERS can be employed separately to its building blocks, such as, integer execution unit, floating point datapaths, control logic, and result bus logic MERS can work with schemes proposed in [23] to iso- late a region and prevent unwanted switching in independent functional modules by taking advantage of the power gating techniques conventionally used by low-power designs, such as clock gating, supply gating, or operand isolation|,Non-data,63
| MERS can also be applied a more flexible region-based side channel analysis approach proposed in [24] They perform a func- tional decomposition to divide a large design into several small blocks or regions, so that they can activate them one region at a time MERS can be used as the test genera- tion algorithm to generate vectors that maximize the ac- tivity within each region The decision to report a chip as Trojan-infected would be based on the deviation of its region current matrix with respect to the golden chip|,Non-data,63
| Future work will include integration of MERS with region-based circuit partitioning techniques to further enhance its effectiveness and its evaluation on larger industry-standard designs 6 CONCLUSIONS a test generation approach will, in general, be effective for any side-channel analysis approaches that rely on activity in Trojan circuits (eg|,Non-data,63
| transient current, dynamic power profile, or electromagnetic emanation based methods) Fur- thermore, MERS is effective for any Trojan forms/sizes, as long as a Trojan is implanted through alterations in a circuit structure - the most dominant mode of Trojan implantation Our simulation results on a set of benchmark circuits show that the proposed approach can improve the side channel sensitivity by more than 9661%, compared with random tests for a large set of arbitrary Trojans|,Non-data,63
| It shows that a judicious statistical test generation such as MERS can serve as an essential component in a side-channel Trojan detection approach Future work will include further improvement in scalability to larger designs and evaluation of MERS with test chip measurements 7 ACKNOWLEDGMENTS This work was partially supported by grants from Na- tional Science Foundation (1441667, 1603475, 1603483), Semi- conductor Research Corporation (2014-TS-2554) and Cisco Systems (F020375)|,Non-data,63
| Any opinions, findings, conclusions or recommendations expressed in this publication are those of the authors and do not necessarily reflect the views of the funding agencies We have presented a framework for statistical test gen- eration, called MERS, which can significantly improve the Trojan detection sensitivity in side-channel analysis based Trojan detection The approach aims at statistically increas- ing switching activity in an unknown Trojan to amplify the Trojan effect in presence of large process variations Such 8|,Non-data,63
|ABSTRACT We give attacks on Feistel-based format-preserving encryp- tion (FPE) schemes that succeed in message recovery (not merely distinguishing scheme outputs from random) when the message space is small For 4-bit messages, the at- tacks fully recover the target message using 221 examples for the FF3 NIST standard and 225 examples for the FF1 NIST standard The examples include only three messages per tweak, which is what makes the attacks non-trivial even though the total number of examples exceeds the size of the domain The attacks are rigorously analyzed in a new defini- tional framework of message-recovery security|,Non-data,64
 The attacks are easily put out of reach by increasing the number of Feistel rounds in the standards INTRODUCTION 1 Format-preserving encryption (FPE) schemes based on Feis- tel were standardized by NIST in [7] and are in widespread use for the encryption of credit card numbers This paper gives new attacks on these schemes that succeed in message recovery in the case that the message space is small,Non-data,64
| FPE An FPE scheme [1, 5] specifies a deterministic en- cryption function FE : FKeys × F|,Non-data,64
|Twk × FDom → FDom that takes a key K, a tweak T and a message X to return a ciphertext Y = FE(K, T, X)|,Non-data,64
 There is a corresponding decryption function FD : FKeys× FTwk× F,Non-data,64
|Dom → FDom such that the maps FE(K, T, ·), FD(K, T, ·) are permuta- tions over F|,Non-data,64
|Dom that are inverses of each other What makes an FPE scheme special —compared to a tweakable blockcipher [8]— is that the domain FDom can be arbitrary, and, most importantly, can be very small Some examples are F|,Non-data,64
|Dom = {0, 1}8 (encrypt a byte so that the ci- phertext is also a byte), FDom = Z4 10 (encrypt a 4 digit PIN so that the ciphertext is also four decimal digits), FDom = Z16 10 (encrypt a 16-digit credit-card number so that the re- sult is also a 16-digit credit-card number) FPE is motivated by legacy constraints which in many systems mandate that Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita- tion on the first page|,Non-data,64
| Copyrights for components of this work owned by others than ACM must be honored Abstracting with credit is permitted To copy otherwise, or re- publish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acm|,Non-data,64
|org CCS’16, October 24-28, 2016, Vienna, Austria c(cid:13) 2016 ACM ISBN 978-1-4503-4139-4/16/10 |,Non-data,64
  $1500 DOI: http://dxdoi,Non-data,64
|org/101145/29767492978390 the ciphertext replace the plaintext, and must thus have the same “format” as the plaintext Schemes and standardization|,Non-data,64
| FPE is harder than it may look Blockciphers like AES can encipher 128-bit messages but it isn’t clear how to encipher messages of length signif- icantly shorter than 128 The main paradigm for FPE has been to use a Feistel network Feistel based FPE schemes were given in [5, 1]|,Non-data,64
| (Tweaking is done by incorporating the tweak as an input to the round functions) The growing use of FPE led to interest in standardization Several submis- sions were made to NIST [4, 6, 3] Based on these, in March 2016, NIST SP 800-38G [7] standardized two Feistel-based FPE schemes, FF1 and FF3|,Non-data,64
| In Fig 3 we specify Feistel-based FPE in a general and parameterized way Prior schemes, including the standards, are special cases, and our attacks apply to all of these Summary|,Non-data,64
| This paper has three main contributions: (1) New message recovery attacks on Feistel-based FPE that are practical for small messages (2) A definitional frame- work for message recovery security that allows us to pre- cisely say what our attacks accomplish and why they are interesting (3) Rigorous analyses establishing lower bounds on the advantages of the attacks in our framework For the purpose of this Introduction, we take, as illustra- tive example, balanced Feistel with FDom = {0, 1}2n We denote by r ≥ 2 the number of Feistel rounds|,Non-data,64
| It is r = 10 for FF1 and r = 8 for FF3 Prior attacks and our new ones are summarized in Fig 1 Our attacks are the first to have all of the following properties: they succeed in (partial or full) recovery of the target message, not just in distinguish- ing outputs of the FPE from random; they have advantage as close to one as possible, rather than very small; and they succeed given a number Q of examples —an example is a tweak, ciphertext pair (T, Y ) possessed by the adversary— that, for the values of r in the standards, makes the attacks feasible for small n|,Non-data,64
 There has been a misconception that attacks using a num- ber Q of examples in excess of the size 22n of the domain are uninteresting This is not necessarily true It depends on the nature of the examples Amongst the elements that make our attacks non-trivial are that they involve only a tiny number qe of examples for any particular tweak and en- cryptions of the target message are provided only under a tiny number of tweaks,Non-data,64
| In this case, FPE ought to provide very good security even for a number Q of examples well in excess of the domain size We are saying that Feistel-based FPE with the standardized number of rounds fails to do so on small message spaces 444Attack Name Attack type Advantage ǫ Number of tweaks, qt Examples per tweak, qe Source Distinguishing Distinguishing Recovery of left half of message LHR RHR FMR Recovery of left half of message Recovery of right half of message Recovery of entire message 2−(r−2)n 1/3 2−(r−2)n 1 − 2/2n 1 − 2/2n 1 − 2/2n 1 2 · 2(r−2)n 1 24(n + 4) · 2(r−3)n 24(n + 4) · 2(r−2)n 24(n + 4) · 2(r−2)n 2 2 2 2 2 3 [9] [11] [1] Here Here Here Figure 1: Attack parameters and effectiveness This is for balanced-Feistel FPE with domain {0, 1}2n (n ≥ 2) and r rounds|,Non-data,64
| We show the type of attack (distinguishing from random, or recovery, of part or all of the message), and the advantage (success probability of the attack) The number of examples used is Q = qt · qe, broken down into the number qt of tweaks involved and the number qe of examples per tweak The running time of all attacks is O(Q) r = 8 (FF3) r = 10 (FF1) 2n 4 8 ǫ 1/2 14/16 Q 221 232 253 ǫ 1/2 14/16 63/64 Q 225 240 267 14 63/64 Figure 2: Attack numbers|,Non-data,64
 We show the advantage and number of examples for the FMR attack for various input lengths 2n and the number of rounds of the standards Prior definitions for message recovery security [1] cannot capture the distinctions we make above The purpose and value of our new definitional framework for message-recovery security is to elucidate when an attack is non-trivial It is so when the adversary advantage under our definition is large,Non-data,64
| Beyond this, our framework allows us to capture fine- grained distinctions between attacks (for example, full versus partial plaintext recovery, known versus unknown example plaintexts, ) allowing theorem statements about attacks that are correspondingly fine-grained and informative|,Non-data,64
| It is common to have theorems, making precise statements and giving rigorous proofs, in support of security Such the- orems give upper bounds on adversary advantage It is less common than it should be to have similarly rigorous the- orems about attacks, giving lower bounds on adversary ad- vantage We give such theorems for our attacks, in the model where the Feistel round functions are random|,Non-data,64
| The analyses establishing this were challenging and also allow us to give rigorous and improved analyses of some prior attacks The second table in Fig 2 shows, for the full message re- cover (FMR) attack on the standardized schemes FF3 and FF1, the advantage ǫ and number of examples Q, for dif- ferent message lengths 2n The attack is feasible for 4-bit messages and 8-bit messages|,Non-data,64
| At 14-bit messages —this cor- responds roughly to four decimal digits, the subset of the digits of the credit-card number that is encrypted in many FPE-based credit-card transactions— the attacks are not practical In all cases, the attacks are significantly faster for FF3 than for FF1 The attacks can be defended against quite simply by in- creasing the number of rounds on small inputs The BRS [4] submission to NIST had, in fact, specified the number of rounds as a function of the input length|,Non-data,64
| The r = 10 rounds adopted by NIST for FF1 was based on BRS’s later adden- dum [3] BPS [6] had proposed r = 8 rounds from the start, and this was adopted for FF3 [7] Reverting to the formula of BRS [4] would put our attacks out of reach for the message spaces they consider Their suggestion, for FF1 on domain {0, 1}m, was to use r = 12 rounds if 31 ≤ m ≤ 128, r = 18 rounds if 20 ≤ m ≤ 31, r = 24 rounds if 14 ≤ m ≤ 19, r = 30 rounds if 10 ≤ m ≤ 13, and r = 36 rounds if 8 ≤ m ≤ 9|,Non-data,64
| BRS [4] do not consider m < 8, although the standard [7] does We now expand on all the above Our starting point is def- initions, meaning attack types and taxonomy, because this is crucial towards determining the effectiveness of attacks Types of attacks|,Non-data,64
| A distinguishing attack aims to violate (tweakable) PRP security [1, 8] The adversary has an or- acle taking T, X and returning Y such that either Y = FE(K, T, X) for the target key K or Y is the result of a tweak-determined random permutation on X In this case the examples (T1, X1, Y1), |,Non-data,64
|   , (TQ, XQ, YQ) are triples where Yi is the result of the oracle on Ti, Xi The advantage is that of determining the type of the oracle|,Non-data,64
| Distinguishing attacks have not been considered a signifi- cant threat in practice because they do not, in general, ap- pear to cause any practical damage in envisaged applications of FPE The concern in practice, rather, is message recovery BRRS [1] give the first definition of message recovery se- curity for FPE The adversary gets input (T ∗, Y ∗) where Y ∗ = F|,Non-data,64
|E(K, T ∗, X ∗), and its goal is to recover the tar- get message X ∗ To aid in this task, it is allowed Q − 1 queries to an encryption oracle The latter, given T, X re- turns Y = FE(K, T, X)|,Non-data,64
| The advantage of the adversary is the probability that it wins (returns X ∗) minus the prob- ability that a simulator, on input T ∗, wins (returns X ∗), given Q − 1 queries to a test oracle The latter, given X, returns true if X = X ∗ and false otherwise The intuition is that since FE(K, ·, ·) is deterministic, the adversary can use its encryption oracle to test candidate plaintexts, so the simulator gets the same ability via its test oracle|,Non-data,64
| Notice that the simulator can always win with probability one when Q ≥ 22n is more than the size of the domain, because it can simply query all possible messages to its test oracle Thus, any adversary making Q− 1 ≥ 22n − 1 queries to its encryption oracle has zero advantage Based in part on this, the conception in this area has been that an attack using 445a number of examples larger than the size of the domain is trivial and not interesting Our framework|,Non-data,64
| We argue that the above conclusion is in- correct Attacks can be interesting, non-trivial and of prac- tical significance even when the number of examples is much more than the size of the domain We give a new defini- tion for message recovery security in which this and other distinctions surface In our framework of Section 4, an algorithm XS called a message sampler produces Q tweak-message pairs (T1, X1), |,Non-data,64
|   , (TQ, XQ), a target message X ∗ and auxiliary informa- tion a Now let Yi = F|,Non-data,64
|E(K, Ti, Xi) for 1 ≤ i ≤ Q, where K is the target key The adversary A gets examples (T1, Y1),   |,Non-data,64
| , (TQ, YQ), as well as a It wins if it outputs the target message X ∗ Its mr-advantage is its winning probability mi- nus what we call the mg-advantage of XS The latter is the maximum, over all simulators S, of the probability that S, given T1, |,Non-data,64
|   , TQ and a, returns X ∗  The auxiliary infor- mation encodes partial information about the messages that the adversary may have|,Non-data,64
| There are no oracles involved Now, there are many choices of XS for which we would expect and want the mr-advantage to be small, even for Q much larger than the domain size The instance we consider here is that, in the list (T1, X1),  |,Non-data,64
|  , (TQ, XQ), the number qe of times any particular tweak T shows up is very small, much smaller than the size 22n of the domain, or the number of i such that Xi = X ∗ is very small So if X ∗ is (say) random, the mr-advantage should be small Our attacks say that, for the standardized schemes, this advantage is not small|,Non-data,64
 The problem with the BRRS definition [1] is that the sim- ulator queries may all be under the target tweak even if the adversary makes few queries under the target tweak Our definition models security more accurately by forcing the simulator to use exactly the same tweaks as the adversary Prior attacks Row 1 of Fig,Non-data,64
| 1 is a distinguishing attack of Patarin [9] that in Q = 2 examples gets a distinguish- ing advantage ǫ ≈ 2−(r−2)n/2 Row 2 is a variant he gives in [11] which achieves a constant distinguishing advantage using Q = 4 · 2(r−2)n examples BRSS [1] extend Patarin’s ideas [9, 10, 11] to give a mes- sage recovery attack under their definition discussed above It recovers the left half of a message with known right half|,Non-data,64
| Thus the target message X ∗ = (L∗, R∗) has a random left half L∗ and an adversary-known right half R∗ Given T ∗ and target ciphertext Y ∗ = (A∗, B∗) = FE(K, T ∗, X ∗), the adversary picks a random left-half L and queries its en- cryption oracle with T ∗, X for X = (L, R∗) to get back Y = FE(K, T ∗, X)|,Non-data,64
| It returns (A⊕A∗⊕L, R∗) The ad- vantage as per the BRRS definition is about 2−(r−2)n These attacks were known at the time of standardization but not considered significant In the case of Patarin’s at- tacks, this is because they are distinguishing attacks that did not appear to cause any practical damage in envisaged applications of FPE|,Non-data,64
| In the case of the BRRS attack, the ad- vantage seems too tiny to matter For example say n = 4 (one byte messages) The a priori probability of guessing the target message is 2−4|,Non-data,64
| The attack recovers the target message with a probability only marginally higher, namely 2−4(1 + 2−28) ≈ 2−4 in the case r = 10 (FF1) The concern in practice is message recovery with high advantage Overview of our attacks Our attacks boost the mes- sage recovery advantage to close to one|,Non-data,64
| This is done by using more examples than BRRS, but, importantly, there are very few examples for any given tweak Our LHR attack, like the one of BRRS [1], recovers the left half of the message when the right half is known Our RHR attack recovers the right half of the message when the left is known, but using different and more novel techniques We then put these to- gether to get the FMR attack recovering the entire target message|,Non-data,64
| The attack parameters are shown in Fig 1, and we now discuss the attacks at a more technical level The LHR and RHR attacks target a sampler XS which, for two plaintexts X and X ′, produces 2qt tweak-message pairs (T1, X ′), (T1, X),  |,Non-data,64
|  , (Tqt , X ′), target message X ∗ = X, and some side information a about X and X ′ In particular, the end goal is recovering X ∗ = X Here, we illustrate the main ideas behind the attacks for the special case of r-round balanced Feistel with F|,Non-data,64
|Dom = {0, 1}2n The LHR attack assumes that X and X ′ share the same right half R and have different left halves L 6= L′ Here, a = (L′, R) The starting point is Patarin’s observation [9, 11] that if Lr and L′ r are left halves of the encryptions of X r ⊕ L′ is more likely and X ′ under some tweak, then Lr ⊕ L′ to be L than any other value|,Non-data,64
| This property was exploited already in the aforementioned distinguishing attacks [9, 11] and in the low-advantage recovery attack from [1] In con- trast, here we show that under many tweaks, this fact can be exploited to recover L with constant probability – namely, if Li,r and L′ i,r are the left halves of the encryptions of X and X ′ under Ti, respectively, the attack analyzes the empirical i,r ⊕ L′, and takes the most distribution of the values Li,r ⊕ L′ frequent value as the guess for L Our analysis shows that qt = O(2(r−3)n) suffices for the guess to be correct with con- stant probability While qt is well above the domain size, the crucial point is that we only obtain two ciphertexts per tweak for the same two plaintexts, and this should not help for non-trivial message recovery|,Non-data,64
| In the RHR attack, the plaintexts X and X ′ are distinct, but do not satisfy any other relation Also, a = (L, R′), and the attack recovers the right half R of X To understand the main ideas behind the attack, assume we are given two encryptions of X and X ′ such that the left halves Lr and L′ r of the ciphertexts are equal, while their right halves Rr 6= R′ r differ Then, we show that R′ ⊕ Rr ⊕ R′ r is more likely to equal R than any other value|,Non-data,64
| Intuitively, the reason for this is the similarity between evaluating Feistel in the forward and backward direction, combined with the ideas from the LHR attack However, making this precise requires more work Also, this by itself is not useful – we have no control on whether Lr = Lr′ occurs or not However, on average, this will be true once every (roughly) 2n tweaks|,Non-data,64
| Indeed, we show that the number of examples required for the RHR attack to succeed is indeed 2n larger than for the LHR attack, ie, qt = O(2(r−2)n) The final FMR attack combines both attacks, and recovers X when given three ciphertexts per tweak of plaintexts X, X ′ and X ∗|,Non-data,64
| In conjunction with ciphertexts of X, those of X ′ will be used to perform the RHR attack first, and this will then allow, together with ciphertexts of X ∗, performing the LHR attack 2 NOTATION If y is a string then ||y|| denotes its length and y[i] denotes If X is a finite set, we let its i-th bit for 1 ≤ i ≤ ||y|| 446x ←$ X denote picking an element of X uniformly at ran- dom and assigning it to x|,Non-data,64
| Algorithms may be randomized unless otherwise indicated Running time is worst case If A is an algorithm, we let y ← A(x1,  |,Non-data,64
|  ; r) denote running A with random coins r on inputs x1,   |,Non-data,64
| and assigning the out- put to y We let y ←$ A(x1,   |,Non-data,64
|) be the result of picking r at random and letting y ← A(x1,    ; r)|,Non-data,64
| We use the code based game playing framework of [2] By Pr[G] we denote the event that the execution of game G results in the game returning true If D is a set then Perm(D) denotes the set of all permutations on D Let exp(x) denote ex, where e is the base of the natural logarithm|,Non-data,64
 3 FPE AND FEISTEL-BASED FPE FPE An FPE scheme F specifies a deterministic encryption algorithm FE : F,Non-data,64
Keys × FTwk × FDom → FDom and a deterministic decryption algorithm F,Non-data,64
D : FKeys × FTwk × FDom → F,Non-data,64
|Dom The sets FKeys, FTwk and F|,Non-data,64
|Dom are, respectively, the key space, the tweak space and the domain For every key K ∈ FKeys and tweak T ∈ T, the maps FE(K, T, ·), F|,Non-data,64
|D(K, T, ·) ∈ Perm(FDom) are permutations over FDom that are inverses of each other Feistel-based FPE|,Non-data,64
| Feistel-based constructions represent the currently most important method to obtain FPE The FF1 and FF2 standards [7] are both Feistel based We now specify Feistel-based FPE in a general, parameterized way Particular choices of the parameters allow us to talk of schemes with ideal round functions or with concrete ones, and to recover the standards|,Non-data,64
| We associate to parameters r, M, N, ⊞, PL an FPE scheme F = Feistel[r, M, N, ⊞, PL] Here r ≥ 2 is an even integer, the number of rounds Integers M, N ≥ 1 define the domain of F as FDom = ZM × ZN |,Non-data,64
| Let ⊞ be an operation for which (ZM , ⊞) and (ZN , ⊞) are Abelian groups We let ⊟ denote the inverse operator of ⊞, meaning that (X ⊞Y ) ⊟Y = X for every X and Y  PL = (T , K, F1,  |,Non-data,64
|  , Fr) is a list It specifies the set T of tweaks, meaning FTwk = T |,Non-data,64
| It specifies a set K of keys, so that FKeys = K Finally it specifies round functions F1,  |,Non-data,64
|  , Fr where Fi : K × T × ZN → ZM if i is odd, and Fi : K×T × ZM → ZN if i is even The encryption and decryption functions of F are shown in Fig 3|,Non-data,64
| The simplest instance is the boolean one, where M = 2m and N = 2n are powers of two We identify ZM , ZN with {0, 1}m and {0, 1}n, respectively, and let ⊞ = ⊕ be bit- wise xor Classical Feistel was, in this way, boolean How- ever FPE schemes sometimes operate on integers, whence the generalization|,Non-data,64
| The scheme is balanced if M = N and unbalanced otherwise We will focus on the case where the round functions are random Proceeding formally, let RF(T , r, M, N ) denote the : set of all tuples of functions (G1,  |,Non-data,64
|  , Gr) such that Gi T × ZN → ZM if i is odd, and Gi : T × ZM → ZN if i is even Let T = {0, 1}∗ and let K = RF(T , r, M, N ) Then for 1 ≤ i ≤ r define Fi, on input K, T, X, to parse the key as (G1, |,Non-data,64
|   , Gr) ← K and simply return Gi(T, X) Now let PL = (T , K, F1, |,Non-data,64
|   , Fr) We write Feistel[r, M, N, ⊞] to denote Feistel[r, M, N, ⊞, PL] for this particular choice of PL|,Non-data,64
| Schemes in the standards [7] correspond, in our frame- work, to particular choices of r, M, N, ⊞, PL In particular they specify the round functions using AES The analysis of our attacks, as with prior ones, is for Feistel[r, M, N, ⊞], meaning round functions are truly random However, the round functions in the standardized schemes are conjectured to be PRFs, and this means that the bounds we show on ad- versary advantage with random round functions translate to the standards with small differences|,Non-data,64
| For X = (L, R) ∈ ZM × ZN , we call L and R the left segment and right segment of X, respectively For simplicity, we assume that 0 is the zero element of the groups (ZM , ⊞) and (ZN , ⊞) 4 MESSAGE RECOVERY FRAMEWORK Here we give a new formalization of message-recovery se- curity, defining the goal our attacks will violate|,Non-data,64
| Samplers and guessing probability A message sampler is an algorithm XS that returns a tuple ((T1, X1),   |,Non-data,64
| , (TQ, XQ), X, a) consisting of Q tweak-message pairs called the example tweak- message pairs, a message X called the target message and a string a called the auxiliary information The number of examples Q is a parameter of XS that is denoted XSQ We require (in our FPE context, for reasons explained below) the following distinctness condition: the Q pairs (T1, X1), |,Non-data,64
|   , (TQ, XQ) are all distinct On the bottom of Fig|,Non-data,64
| 4 is a message guessing (mg) game associated to XS and an adver- sary S Let Advmg XS = max Pr[Gmg S XS (S)]  This represents the best possible probability at guessing the target message X given the tweaks and auxiliary informa- tion There is nothing cryptographic involved here, and the probability depends only on the message sampler|,Non-data,64
| Further parameters and terms of interest for a sampler are as follows The number of tweaks of XS, denoted qt, is the number of distinct values in the list T1,   |,Non-data,64
| , TQ, meaning the size of the set {T1,    , TQ}|,Non-data,64
| The number of examples per tweak, denoted qe, is the maximum, over all T , of the size of the set { i : Ti = T } A tweak T is called a target tweak if there is some i such that (T, X) = (Ti, Xi), meaning that the target message occurs with this tweak, and q∗ denotes the number of target tweaks Note that this number could be zero, one or more than one Message recovery security|,Non-data,64
| Let F be an FPE scheme Let XS be a message sampler such that T1,   |,Non-data,64
| , TQ ∈ FTwk and X1,   |,Non-data,64
| , XQ ∈ FDom for any ((T1, X1),   |,Non-data,64
| , (TQ, XQ), X, a) ∈ [XS] On the top of Fig 4 is a message recovery (mr) game associated to F, XS and an adversary A Let Advmr F,XS(A) = Pr[Gmr F,XS(A)] − Advmg XS |,Non-data,64
| This measures A’s advantage at recovering the target mes- sage given the tweaks, ciphertexts, and auxiliary informa- tion Discussion The definition is a framework parameterized by the message sampler XS An attack or a security claim can be made relative to a particular sampler or, more generally, a class of samplers|,Non-data,64
| Specifying the sampler(s) allows us to precisely and formally capture attack features and draw fine- grained distinctions between attacks In the mr game, X1,   |,Non-data,64
| , XQ represent messages that the user of the target key K encrypts under tweaks T1,    , TQ, respectively, so that the adversary is in possession of the tweaks, and of the ciphertexts Y1, |,Non-data,64
|   , YQ The adversary is 447F|,Non-data,64
|E(K, T, X) (L, R) ← X For i = 1 to r do If (i mod 2 = 1) then L ← L ⊞ Fi(K, T, R) Else R ← R ⊞ Fi(K, T, L) Return (L, R) FD(K, T, Y ) (L, R) ← Y For i = r to 1 do If i mod 2 = 1 then L ← L ⊟ Fi(K, T, R) Else R ← R ⊟ Fi(K, T, L) Return (L, R) ZM L0 ZN R0 K, T F1 L1 L2 L3 L4 K, T F2 R1 R2 K, T F3 K, T F4 R3 R4 Figure 3: On the left is code for the encryption and decryption algorithms of F = Feistel[r, M, N, ⊞, PL], where PL = (T , K, F1,   |,Non-data,64
| , Fr) On the right is an illustration of encryption with r = 4 rounds Game Gmr F,XS(A) K ←$ FKeys ((T1, X1), |,Non-data,64
|   , (TQ, XQ), X, a) ←$ XS For i = 1,  |,Non-data,64
|  , Q do Yi ← FE(K, Ti, Xi) X ∗ ←$ A((T1, Y1),  |,Non-data,64
|  , (TQ, YQ), a) Return (X ∗ = X) XS (S) Game Gmg ((T1, X1),   |,Non-data,64
| , (TQ, XQ), X, a) ←$ XS X ∗ ←$ S(T1,    , TQ, a) Return (X ∗ = X) Figure 4: Games defining message-recovery security of an FPE scheme F, parameterized by a message sampler XS|,Non-data,64
