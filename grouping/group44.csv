 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| ble 1 shows that these constraints are indeed strong enough to effectively prune all invalid data and attest to the accu- racy of any recovered evidence — resulting in VCR produc- ing no false positive or false negative results In total, VCR recovered 245 pieces of photographic evidence in these test cases Table 1 shows that of the 32 total test cases, all 12 cases left behind several preview frames These results range from a high of 11 preview frames in the LG G3’s Google Camera, Facebook, and Instagram cases to only 2 frames in the LG G3’s Chase Bank test case|,Non-data,110
| Interestingly, the average “pre- view frames recovered per app” appears to be phone depen- dent: 717 for the Samsung Galaxy S4 and 9 for the LG G3 (or even 104 if we ignore the outlier: the Chase Bank app) This implies some connection between phone hardware or vendor customizations versus the amount of potential ev- idence|,Non-data,110
| Since both phones have relatively equally power- ful hardware, we reason that the latter is more influential Again, these preview frames are generated by the apps au- tomatically when the user only opens the app’s photographic features Also shown in Table 1 is that video frames are far more prevalent than any other form of photographic evidence This is intuitive given that video frames are often sampled at higher rates than preview frames|,Non-data,110
| Our evaluation shows that on average each app left 129 video frames Again, the LG G3 provides more evidence with an average of 178 video frames per app versus the Samsung at 8 video frames on average|,Non-data,110
| Intuitively, Skype leaves fewer frames than the other apps in our tests (9 frames on the LG G3 and 8 on the Samsung Galaxy S4) likely because of the high through- put design of Skype’s video-call feature Also note that the 152recovered video frames are the result of explicitly recording video with the tested apps, unlike the preview frames which are generated without any explicit user command to record Finally, Table 1 shows that only one photograph per ap- plication is available in the memory images Manual in- vestigation revealed that the Android framework prefers to reuse buffers as quickly as possible, so despite taking sev- eral photos during our testing only a single photograph is left buffered — always accompanied by a number of preview frames|,Non-data,110
| 411 Case Study 1: Camera Apps Camera apps are standard Android apps which only pro- vide a front-end user interface to the camera back-end (the mediaserver and camera HAL) A newly purchased Android device will come with a pre-installed camera app, but the user may install a new camera app and select one to use as the default|,Non-data,110
| To illustrate the generality of VCR, we evalu- ate both pre-installed camera apps from our test phones as well as the third-party Google Camera app The results of the LG G3 Default Camera and Google Camera tests are shown in Rows 5 and 6 of Table 1, and the Samsung Galaxy S4 Default Camera and Google Camera tests are shown in Rows 11 and 12 Table 1 shows that in each of the camera app tests VCR is able to accurately recover and render all photographic ev- idence For the LG G3 Default Camera case, we see that VCR recovered 10 preview frames, 1 photo, and 20 video frames, and similarly for the Google Camera test VCR re- covered 11 preview frames, 1 photo, and 20 video frames|,Non-data,110
| Again we observe fewer recoverable frames in the Samsung cases: 7 preview frames, 1 photo, and 8 video frames for both the Default Camera and Google Camera evaluations The default camera app is important because other apps may rely on it for photographic operations When choosing test cases, we intentionally included the Facebook app as an example of this (shown in Rows 2 and 8 of Table 1) The Facebook app allows users to capture and post videos and photos on-the-fly (i|,Non-data,110
|e, without leaving the Facebook app) To implement this, the Facebook app requests the default camera app to take a photo or video and then return the resulting image Thus when the Facebook app user requests to capture a photo or video, the default camera app opens, manages the image capture, and makes the resulting image available to the Facebook app|,Non-data,110
| The fact that the Facebook app (and others like it) em- ploy the default camera to handle photography, leads to a forensically interesting observation: photographic evidence from such apps will likely use similar formatting and sizing parameters to conform with the default camera pass-through interface In the Facebook app case studies from Table 1, we see that VCR is able to render 11 preview and 20 video frames plus 1 photograph for the LG G3 test and 7 preview and 8 video frames plus 1 photograph for the Samsung S4 case It is important to note that among all of our test cases only the Facebook app is an example of requesting photography through the default camera Although default camera pass- through is common, we intentionally focused the majority of our evaluation on test cases which implement their own photography features|,Non-data,110
| This directly shows VCR’s generality with regards to the evidentiary apps’ implementation 412 Case Study 2: Skype In this case study, we highlight the Skype app because image frames collected by Skype are never present on non- volatile stores — Skype immediately encodes, packages, and transmits the image frames over the internet|,Non-data,110
| Thus the only visual artifacts of a Skype video-call will be the frames left in the device’s memory Such frames provide vital evidence in a digital investigation — as we will show with a scenario based on the Usenix Security 2014 invited talk “Battling Human Trafficking with Big Data” [23] Imagine, for the sake of example, that a human-trafficking suspect is using Skype video calls from a smartphone to show victims to potential clients While the criminal may be careful not to show his or her identity, the video frames of the Skype call clearly link the smartphone user to the victims of the crime|,Non-data,110
| Further, this criminal may try deleting (or obfuscating) Skype’s call history, but even after the criminal has ended the Skype calls and finished trying to hide the evidence, the last snippets of video are still recoverable in the device’s memory Later, when law enforcement agents arrest the suspect, investigators will not find any evidence on the smartphone’s non-volatile storage Applying VCR to the smartphone’s memory will reveal the last video frames of the Skype call showing one or more victims of this crime, and providing vital evidence to investigators which would otherwise be inaccessible For this case study, we set up a simplified crime reen- actment by having one of the authors walk slowly through a Skype video call’s field of view|,Non-data,110
| We then used VCR to recover the remaining video frames frozen in the device’s memory image The LG G3 device was used in this trial, and the results of analyzing the device’s memory image are shown in Row 4 of Table 1 Figure 7 shows some of the recovered video frames and gives a clear example of the importance of VCR-recovered photographic evidence to an investigation The 6 frames shown in Figure 7 are a subset of the 9 video frames in total which VCR recovered|,Non-data,110
| These frames reveal a person walking through the Skype call’s field of view, and we can easily see how this provides substantial evidence to investigators about the human-trafficking victims in our crime scenario above In addition to recovering the video frames shown in Figure 7, VCR also recovered 9 preview frames still buffered in the memory image (as shown in Table 1) Visual inspection of all 18 images recovered for this test case revealed that 4 of the 9 preview frames were identical (to the investigator’s eye) to 4 of the recovered video frames Thus yielding 14 total unique images to be used as evidence|,Non-data,110
| This case study shows the importance of VCR recovered photographic evidence to aiding a digital investigation 42 Analysis Across Android Frameworks Given that many versions of the AOSP are being widely used today [16], VCR must be effective for a majority of devices that investigators may face In this section, we eval- uate VCR’s effectiveness against memory images taken from the three most recent, widely used versions of the AOSP|,Non-data,110
| To perform this evaluation, we set up unmodified Android emulators running AOSP versions 43, 442, and 5|,Non-data,110
|0 As be- fore, we used VCR to analyze memory images after interact- ing with each of the tested applications For this evaluation, we selected three of the apps to use in each of the three 153Figure 7: Sample video frames recovered from the Skype case study This is an example of how multiple recovered frames can capture evidence of time and direction for the suspect shown here|,Non-data,110
 Device App Facebook Android 43 Skype Default Camera Facebook Android 442 Skype Default Camera Facebook Android 5,Non-data,110
|0 Skype Default Camera Evidence Preview Photo Video Preview Video Preview Photo Video Preview Photo Video Preview Video Preview Photo Video Preview Photo Video Preview Video Preview Photo Video Live Instances w/ Image Data Recovered FP FN 32 1 31 32 1 32 1 202 32 1 16 32 1 32 1 24 32 1 19 32 1 32 1 297 3 1 31 3 1 5 1 202 3 1 16 3 1 3 1 24 3 1 19 3 1 3 1 297 3 1 31 3 1 5 1 202 3 1 16 3 1 3 1 24 3 1 19 3 1 3 1 297 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Table 2: Results from recovering photographic evidence from current and future Android versions emulators: Facebook, Skype, and each emulator’s default camera app Table 2 presents the results which VCR rendered from the different emulators’ memory images Column 1 shows the version of Android that the emulator is running|,Non-data,110
| Columns 2 and 3 show the app and types of photographic evidence evaluated respectively Like in Section 41, the number of “live” image frames in each memory image is show in Column 4, and Column 5 shows the subset of these which contained image data Column 6 shows the number of images which VCR recovered and rendered|,Non-data,110
| Finally, Columns 7 and 8 report the false positives and false negatives Table 2 shows that VCR is highly effective at recovering and rendering photographic evidence produced on the most widely used Android versions We observe that the emu- lated camera device used in the Android emulator does not produce frames at a high rate similar to our test smartphone devices This leads to (as shown in Table 2) fewer frames being available in the memory images|,Non-data,110
| On average, the tests in Table 2 produce only 58 frames (with the exception of the outliers: the 43 and 50 emulators’ default cameras)|,Non-data,110
| Additionally, the preview frame buffer is rarely filled above 3 frames This results in VCR recovering only those 3 pre- view frames for all three apps on all three emulators, except for the Android 43 Default Camera test in which VCR re- covered all 5 preview frames Again, VCR is able to recover and render all instances of photographic data in the evalu- ated memory images without any false positive or false neg- ative results — as Table 2 shows, 627 pieces of photographic evidence in total for these test cases|,Non-data,110
| Notably, Table 2 contains two exceptional cases The de- fault cameras for Android 34 and Android 50 report very large numbers of video frames|,Non-data,110
| We performed manual in- spection of the results and found that all output images were valid (ie, from distinct buffers filled individually by the camera HAL) Further investigation revealed that there ex- isted a bottleneck when saving those video frames to the em- ulator’s storage|,Non-data,110
| Admittedly, this is likely an emulator con- figuration error, but the resulting backup of frames further demonstrates the effectiveness of VCR’s recovery and ren- dering — though run-times for these two cases were nearly 30 minutes 43 Recovering Temporal Evidence As shown in Table 1, numerous preview frames and/or video frames can be recovered for a single app — represent- 154ing a time-lapse of what the camera was viewing Here, we analyze how a set of preview or video frames can give investigators temporal evidence of the incident under inves- tigation|,Non-data,110
| To measure the time captured by a set of recovered frames, we reran the two camera app test cases on the two smart- phones Time lapses were measured using the camera apps to record video of a stopwatch for a period of 1 minute, and the phones were rebooted between each test Note that the “stopwatch” used here was actually a stopwatch app on the first author’s smartphone While this measurement may seem “low-tech,” our results in Table 3 show that the time- lapse captured by the recovered sets of frames is long enough to make an empirical measurement very accurate|,Non-data,110
| After recording for 30 seconds, we captured a memory image from the device, and VCR was used to recover all available preview and video frames from the memory im- ages The output image frames were grouped into three sets: Preview frames, Video frames, and a Union set containing all visually unique frames from both the preview and video sets (which would be recoverable for any app which captures video) We then manually measured the difference between the earliest frame and the latest frame in each set Figure 8 shows an example of some recovered stopwatch preview frames|,Non-data,110
 Device App LG Default Camera Google Camera S4 Default Camera Google Camera Evidence Frames Time-Lapse Preview Video Union Preview Video Union Preview Video Union Preview Video Union 13s 06s 14s 0,Non-data,110
9s 04s 09s 05s 0,Non-data,110
3s 05s 04s 03s 0,Non-data,110
|5s 11 20 22 11 20 25 7 8 10 7 8 11 LG G3 Samsung Galaxy S4 Table 3: Time-Lapse Evaluation Figure 8: Recovered preview frames used to mea- sure temporal evidence For this experiment, we recorded another smartphone’s stopwatch app and used VCR to recover the preview and video frames — yielding empirical measurements of the temporal evidence captured in VCR recovered evidence Table 3 presents the time measurements captured within the sets of recovered preview and video frames|,Non-data,110
| Columns 1 and 2 show the tested device and app Column 3 names the type of set being measured: Preview, Video, or the Union set Column 4 shows the number of frames in the set, and the measured time difference is shown in Column 5 From the times in Table 3 we can make several observa- tions: First, the windows of time captured by the recovered frames are large enough to provide substantial evidence to an investigation — we already empirically saw this in the evidence recovered for the “crimes” in Figures 1 and 7|,Non-data,110
| To best analyze the results show in Table 3, consider the first row as meaning: The set of preview frames from the LG G3’s Default Camera captures 13 seconds of time divided over 11 images From this, we see that a majority of the results yield over a half second of time-lapse This may seem like a small amount of time, but consid- ering how quickly many crimes can occur and how powerful this evidence can be (such as an image of a car involved in a shooting or a human-trafficking victim) this provides a significant amount of evidence to investigators|,Non-data,110
| Specifically, the example sequences of images shown in Figures 1 and 7 both represent a time-lapse of less than 1 second Table 3 shows that of the 12 measurements, the LG G3 provides much longer time windows with the average being 092 sec- onds per test The Samsung provides an average of 0|,Non-data,110
42 seconds per test A second observation we make from Table 3 is that pre- view frames capture longer time windows in fewer frames but video frames provide many more images Preview frame sets on the LG G3 average more than double the time window of video frame sets (ie,Non-data,110
|, 04 seconds versus 09 seconds and 06 seconds versus 1|,Non-data,110
|3 seconds) However, the video frame sets in the LG G3 test contain 20 frames compared to only 11 frames in the preview sets The Samsung results show a similar pattern but the differences between sets are much closer (eg|,Non-data,110
|, 8 frames over 03 seconds versus 7 frames over 05 seconds) As a consequence, we can observe that the time delta between images is much shorter between video frames than between preview frames|,Non-data,110
| Finally, Table 3 shows that when video and preview frames are available then (not surprisingly) considering the union of those sets yields the best results In practice, nearly any app which generates video frames will also generate preview frames Table 3 shows that the video frames will mostly be enclosed by the larger time delta captured by the preview frames For example, consider the LG G3’s Google Camera Union test: the investigator can now see 0|,Non-data,110
|9 seconds of time captured in 25 images — leading to roughly a 0036 second time delta between each image Using such analysis, inves- tigators can gain a wealth of evidence from only the frames being recovered by VCR 4|,Non-data,110
|4 Privacy Concerns Figure 9: Recovered check image left behind in a memory image This case study gives an example of the potentially sensitive user information which VCR (or worse, malware) can generically recover from the mediaserver’s memory 155Finally, this section highlights a potential privacy concern which VCR reveals VCR exploits the centralized design of the Android framework to access app-agnostic photographic evidence|,Non-data,110
| It should be noted however that the same proper- ties which make the mediaserver beneficial for digital foren- sics also make it a target for attack There has been extensive prior work on exploiting vulnera- bilities in the Android framework to glean information about a smartphone’s owner [12, 19] Following that line of work, we can envision a malware which aims to steal confidential information and remain as stealthy as possible Unfortu- nately, the mediaserver is a great target for such malware for a few reasons: 1) As we will show, the mediaserver han- dles very sensitive data regarding the device’s owner, 2) As we have shown, it is beneficial to utilize the mediaserver’s centralized design to capture photographic evidence from all apps generically, and 3) The mediaserver runs as a back- ground service in a dedicated process (which makes for a great hiding spot for malware)|,Non-data,110
| To underscore the potential danger of malware gaining access to a device’s intermediate service processes (like the mediaserver), we have included the Chase Bank app in our previous evaluations The Chase Bank app, like many other financial institutions’ apps, includes a check image and up- load feature When the device’s owner has a check to de- posit, they simply take a picture of the check and upload the image to Chase from within the app The image is never saved to non-volatile storage and handled securely once the Chase app has received the image|,Non-data,110
| Unfortunately, the image is buffered in the mediaserver long before it is returned to the Chase app and may remain buffered for long after To highlight this point, Figure 9 shows one of the check images that VCR recovered during our previous evaluations Further, Table 1 shows that VCR was effective at recovering and rendering all forms of photographic evidence from the Chase Bank app test cases (12 images in total) The real danger here is that by employing the same techniques as VCR, malware can also have access to any image taken by any app on the smartphone — in the same way that VCR op- erates independent of which app generated the photograph|,Non-data,110
| Moreover, if malware has access to the image buffers in the mediaserver at the right time, it may even alter the check image before the Chase app receives it In light of this, we hope to emphasize the importance of Android’s intermedi- ate service processes as a security critical component and the need for security mechanisms to prevent malware from tampering with these services 5 RELATED WORK Smartphone memory acquisition tools, such as LiME [3] which captures memory via a kernel module and TrustDump [32] which leverages ARM’s TrustZone, have only recently become widely available|,Non-data,110
| Due to the relatively recent interest in Android memory forensics, few works have focused specifically on the topic Originally, Thing et al [35] investigated recovering Android in-memory message-based communications Sylve et al|,Non-data,110
| [33], followed by Saltaformaggio [27], ported existing Linux mem- ory analysis tools to recover Android kernel data Later, Macht [24] recovered raw Dalvik-JVM control structures Dalvik Inspector [2] built on that to recover Java objects from app memory dumps Most recently, GUITAR [28] re- covered app GUIs from Android memory images|,Non-data,110
 Hilgers et al [17] proposed using memory analysis on cold-booted Android phones Apostolopoulos et al [5] recovered login credentials from memory images of certain apps,Non-data,110
| VCR fol- lows the trend of these works as it provides a new Android memory forensics capability (ie, generically recovering pho- tographic evidence), which these existing efforts can hardly provide Originally, memory forensics works focused on in-memory value-invariants [6,7,15,26,30,34], where data structures are identified via brute-force scanning for constant or expected values|,Non-data,110
| DEC0DE [36] enhances such signatures to recover formatted textual evidence from smartphones VCR and DEC0DE share complimentary goals: both recovering differ- ent categories of smartphone evidence Increasingly, mem- ory forensics tools are employing pointer traversal to locate data structures [8, 11, 25, 37] In particular, SigGraph [21] builds maps of structures in a memory image via brute force scanning|,Non-data,110
| VCR also employs value-invariants and pointer traversal in its signatures, but focuses on both recovering and rendering photographic evidence, which is a step be- yond only locating data structure instances Later, DSCRETE [29] used binary analysis to identify data structure rendering logic within the application which defines that structure However, no rendering logic exists within the mediaserver (which only fetches photographic data from the camera device) VCR is designed based on our knowledge of the photographic evidence buffers, and op- erates independently of any app’s implementation (avoiding DSCRETE’s application-specific binary analysis step)|,Non-data,110
| Other efforts aimed to derive data structure signatures from applications via binary analysis [18, 22, 31] or unsuper- vised learning [13] Such tools are essential when the sub- ject data structures are entirely unknown, but luckily, we can rely on the “gold standard” AOSP definitions to build VCR’s vendor-generic signatures More closely related to VCR, DIMSUM [20] uses probabilistic inference to locate known data structures in un-mapped memory However, DIMSUM requires input data structure definitions to be cor- rect|,Non-data,110
| In contrast, we assume that the AOSP definitions are not correct and employ probabilistic inference to derive sig- natures for vendor customizations 6 CONCLUSION In this paper, we have presented VCR, a memory foren- sics tool which recovers and renders photographic evidence from memory images VCR contributes novel memory foren- sics techniques to recover key data structures in the face of vendor customizations|,Non-data,110
| Our evaluation shows that VCR is highly effective at recovering and rendering photographic evidence regardless of the app which generates it Further, our tests with different versions of the Android framework show VCR to be robust across the most popular Android versions in use today Finally, we make several key observa- tions about the importance of VCR rendered photographic evidence and the temporal evidence which they provide to investigations 7|,Non-data,110
 ACKNOWLEDGMENTS We thank the anonymous reviewers for their insightful comments and suggestions We also thank Dr Golden G Richard III for his valuable input on the legal and technical aspects of memory forensics,Non-data,110
|ABSTRACT If someone has the ability to take control of a botnet, can they just clean up all the infected hosts? Can we deceive users, if our goal is to better understand how they are de- ceived by attackers? Can we demonstrate the need for better methods, by breaking something that people rely on today? To be effective, we must find ways to balance societal needs and ethical issues surrounding our research, lest we drift to the extremes—becoming the very thing we deplore, or ced- ing the Internet to the miscreants because we fear to act In this paper, we advocate for a community dialogue on the ethical issues in computer security and the ethical standards that we intend to enforce as a community 1 INTRODUCTION Modern threats such as Denial of Service Attacks, Worms, Viruses, Phishing, and Botnets underscore the need for secu- rity research in an increasingly networked and computation- ally reliant society|,Non-data,115
| Unfortunately, as our understanding of these phenomena have grown, so has the uncertainty in the computer security research community on the appropriate ways in which to observe and address these problems For example, consider the area of botnet research, which centers around the detection and mitigation of large num- bers of infected hosts, or bots, networked into a single dis- tributed system, or botnet We have recently seen a steady increase in criminal activity using botnets In response, we see an increase in academic research and federal funding to counter this threat|,Non-data,115
| This criminal activity is compounded by the emergence of politically motivated attacks, such as those against elements of the cyber-infrastructure of Estonia Re- sponses to these threats vary, from passive measurement and observation, to calls for the legal right to defend computer systems from attack using aggressive countermeasures Unfortunately, the structured public discussion of an ethi- cal framework to guide decision making about actions taken while researching and countering botnet attacks, and indeed in a broader set of computer security research, has not kept pace Existing structures for determining the ethical behav- ior (e|,Non-data,115
|g, Institutional Review Boards (IRB), Professional Codes of Conduct) fail to provide detailed actionable guid- ance due to the absence of technical expertise in this spe- cific domain and a lack community shared values [1] There is growing frustration expressed by researchers, program committees, and professional organizations about the lim- its of ethical research and who has responsibility to enforce them [1, 4] Our primary goal in this work is to encourage a contin- uing dialogue on the ethics of computer security research|,Non-data,115
| Through this dialogue, we hope to build both an expertise that can be used in various policy enforcement bodies (eg, program committees, IRBs) and will help us arrive at a form of community consensus 2|,Non-data,115
| UNDERSTANDING THE NEED LxLabs, a company based in Bangalore, India, markets a web server virtualization system called HyperVM, which uses an administration interface named Kloxo One com- pany who uses HyperVM and Kloxo is UK-based Vacertcom On Sunday, June 7, 2009, Vacert|,Non-data,115
|com suffered a compro- mise of their web hosting system, resulting in over 100,000 accounts being deleted from the system On Monday, June 8, 2009, LxLabs’ CEO, 32 year old K T Ligesh, was found dead in his apartment of an apparent suicide [6] Just a few days before, on June 6, 2009, an analysis of “several dozen vulnerabilities in kloxo” with complete details on how to exploit these vulnerabilities was posted anonymously to the web site milw0rm The time line in this analysis describes an attempt by the unknown secu- rity researcher to correspond with staff at LxLabs about the vulnerabilities, which includes such problems as file permis- sion bypass, cross-site scripting, symbolic link exploitation, denial of service, and arbitrary command execution at el- evated privilege through unclean user input|,Non-data,115
| The posting claims an initial report was sent two weeks prior and that resources demonstrating the vulnerabilities were made avail- able to assist LxLabs in confirming and fixing the problems After two email exchanges with an unnamed LxLabs em- ployee, no further communication as promised from LxLabs, and no observed attempts by LxLabs to even review the re- sources, the researcher posted the full analysis and exploit details Within days, multiple sites using Kloxo (including Vacertcom) were attacked by unknown parties|,Non-data,115
| It is not known whether there is any relationship between the person(s) who attacked and damaged the web sites and the security researcher who published the vulnerability in- formation, nor the identity of the person who the researcher was in communication with at LxLabs There is no indica- tion that the security researcher attempted to report these problems to any other organizations Finally, there is no in- dication that the researcher considered releasing only partial details in order to warn Kloxo users or the general public and give them a chance to protect themselves prior to re- lease of full details including exploits, as is recommended in various responsible vulnerability disclosure guidelines 3|,Non-data,115
| BUILDING ETHICAL STANDARDS While the previous case study may seem extreme it is representative of a growing set of cases [3], which challenge program committees, institutional review boards, and our broad community to evaluate the risks and benefits of secu- rity research Increasingly we require fine-grained guidance in a form that could be evaluated and acted on Researchers themselves need to be able to include in their publications an indication that they have made the effort to evaluate their work against the ethical concerns Such internal and external evaluations need to be performed in a way that is uniform across all research situations and topics|,Non-data,115
| The approach adopted here is close to that of Johnson and Miller [5] in that we are concerned with building expertise in practical decision making Bynum and Rogerson [2] suggest a multi-staged approach to case study analysis in order to build ethical judgement capabilities These stages include: identifying key ethical principles, detailing the case study, identifying specific ethical issues raised by the case, calling on your own experience and skills for evaluation, then the abilities of others, and finally, applying a systematic analysis technique In the following sections we briefly summarize an application of these approaches|,Non-data,115
| 31 General Ethical Issues ulation, and if so, which population? When considering actions related to research or mitiga- tion of malicious or illegal activity, there are many issues that must be considered These involve issues of (a) propor- tionality, (b) targeting, (c) necessity, (d) desired outcome, (e) potential consequences, and (f) the greater moral good to society that is expected to result (and whether it out- weighs any potential harm to innocent third parties) For example, the kinds of questions that researchers should ask themselves include (but are not limited to): • Are the research results intended to protect a specific pop- • Is there a way to achieve multiple benefits to society si- • Who will benefit more from publication of research find- ings, and in which order: Victims of criminal acts; au- thorities responsible for protecting their citizens; the re- searchers themselves; or the criminals who are perpetrat- ing computer crimes? • Is there any other way to accomplish the desired research • What is the safest way to disseminate research results without risk of improper use by individuals who may not share the researchers’ ethical standards? multaneously when studying criminal behavior? result(s)? 3|,Non-data,115
|2 Analyzing Case Studies Systematically Following Bynum and Rogerson, we have identified a hand- ful of issues that researchers can use to evaluate their re- search However, to build consensus across a wide range of research and situations, it is advantageous to explore formal methodologies for evaluating these questions Such method- ologies allow for comparisons to be made across researchers and projects In the following section we examine some po- tential methodologies|,Non-data,115
| 321 Stakeholder Analysis Stakeholder Analysis identifies the key players in the sit- uation in terms of their interests, involvement, and their relationship (ie|,Non-data,115
|, producer or recipient) of outcomes such as benefit or harm We will adapt the definitions of stakehold- ers from http://wwwtheasaorg/networks/apply/ethics/ analysis/stakeholder|,Non-data,115
|htm for the purposes of this section • Primary stakeholders are, “those ultimately affected, either [positively or negatively]” These will typically be the end-users of computer systems, and consumers of in- formation or information system products or services • Secondary stakeholders are, “intermediaries in deliv- ery” of the benefits and harms|,Non-data,115
| In the computer secu- rity context, these would be service providers, operators, or other parties responsible for integrity, availability, and confidentiality of information and information systems • Key stakeholders are, “those who can significantly in- fluence, or are important to the success [or failure] of the project” We will include the researcher(s), vendor(s), those who design and implement systems, and criminals or attackers 3|,Non-data,115
|22 Roles and Responsibilities Analysis Roles and Responsibilities Analysis takes the identified Stakeholders, and lists both their role or roles in the situa- tion, as well as their responsibilities towards each other and to society as a whole Once stakeholders have been identi- fied, and roles and responsibilities mapped out, one can start to define desired outcomes in terms of maximizing benefits and minimizing harms to stakeholders Alternative actions that fall within the delineated roles and responsibilities can then be weighed against each other in terms of expected out- comes|,Non-data,115
| One of the hardest challenges is in trying to identify potential negative outcomes that may result from alterna- tive actions in order to minimize unintended consequences This is where involvement of trusted external parties, such as peer-review of proposed actions or protocols, can help 4 REVISITING KLOXO / HYPERVM The study of kloxo is interesting and unique in terms of the possible relationship with the suicide of the CEO of the vendor and it brings in many issues of risk/benefit across many parties|,Non-data,115
| In kloxo, we can identify the following stake- holders: • Key Stakeholders The researcher who discovered the vulnerabilities The programmers who were responsible for creating the HyperVM system and Kloxo administra- tive front end The corporate management of the vendor (LxLabs), which includes the CEO The Criminals and Attackers who would exploit vulnerabilities for their own purposes|,Non-data,115
| • Secondary Stakeholders The service providers who pur- • Primary Stakeholders The customers of the service providers who use the virtual servers The consumers who obtain products or services from the customers of the ser- vice providers (eg, the online merchants using virtual storefronts hosted on HyperVM virutal machines|,Non-data,115
|) chased HyperVM / Kloxo The researcher attempted to contact the corporate man- agement of LxLabs, presumably to convince them to make decisions that would direct the programmers to fix the bugs that the researcher identified Implicitly, we assume the researcher chose to contact the vendor privately to allow them to fix the problem in order to protect the primary stakeholders (ie|,Non-data,115
|, virtual machine customers and their end consumers) The action of the researcher as a key stakeholder to make detailed vulnerability and exploit information to the vendor is intended to assist the vendor in correcting the problems and eliminating the vulnerability This creates a benefit to the primary stakeholders by protecting their services and accounts, as well as benefiting the secondary stakeholders by improving their product and protecting their customers It is the vendor’s responsibility as a key stakeholder to use this information to minimize potential harm to the primary stakeholders|,Non-data,115
| While the researcher did not state this ex- plicitly, we can assume that the researcher has taken upon himself/herself the responsibility of assisting in protecting the primary and secondary stakeholders We can infer that the action of reporting was intended to obtain the outcome of protecting the primary stakeholders by minimizing harm to them that would result from a malicious actor finding and exploiting these vulnerabilities before the vendor corrected them The researcher had several optional pathways that could achieve this same goal: • The researcher could have taken a high-level outline of the vulnerabilities and provided them to a reporter, who could have written a news article disclosing (in general terms) that vulnerabilities in the HyperVM / Kloxo sys- tem were discovered and warning the primary stakehold- ers (ie|,Non-data,115
|, customers and end consumers) The primary stakeholders could then take their own actions to ask questions, harden defenses, ensure they had current back- ups, or consider moving their storefronts to other service providers • The researcher could have identified a representative set of HyperVM / Kloxo customers and warn them (again, in general terms) of the vulnerabilities, and/or provided mit- igation details These customers could have been encour- aged to contact LxLabs and put pressure on the vendor to fix the problems|,Non-data,115
| This would also have the same added benefits in terms of minimization of harm as the previ- ous option This would not be as easy as contacting a single reporter, or reporting to a CERT organization, but would still move towards achieving the goal of protecting the customers and end consumers • The researcher could have published a high-level sum- mary of the vulnerabilities, rather than full exploit de- tails This may well result in calls from full-disclosure advocates to provide more details, and possibly criticism of the researcher for over-stating the significance of their findings|,Non-data,115
| Anyone with the same (or greater) skills would be able to repeat the research and thus possess the same ability to exploit these vulnerable systems, however this would take time that the vendor may be able to use to fix the problems before any harm is done to the primary stakeholders The researcher thus has to balance personal benefit from first discovery and/or immediate full disclo- sure, potential harm resulting from criticism for partial disclosure, and potential harm to primary stakeholders from release of exploit information prior to patches being available to fix the bugs The use of anonymity by the researcher for unstated rea- sons leaves open many questions (i) It may indicate that there is no personal gain to the researcher from disclosure|,Non-data,115
| Then again, it also has the potential of avoiding account- ability for any actions that are taken, including unintended consequences that cause harm (ii) Releasing full details only two weeks after first contacting the vendor is another difficult issue Because there was no evidence of the vendor even looking at the vulnerability details, could the researcher have been acting with a punitive motive against the vendor? (iii) The researcher may be a disgrunteled current/former employee with a retributive motive It is unreasonable for the researcher to anticipate the CEO would commit suicide, nor is it provable that the pressure from disclosure and resulting damage from exploitation of the vulnerabilities contributed to the suicide|,Non-data,115
| It is foresee- able, however, that disclosure of full exploit details without warning would likely result in one or more parties using this information to do anything made possible, up to and includ- ing destroying the contents of any servers they could find The exploit details alone do not help the primary stake- holders in protecting themselves, as there is nothing they can do (short of immediately switching to another virtual machine provider, which would take significant effort and time) Since the researcher provided no mitigation details, the information that was released reasonably can be seen to benefit attackers more Thus, if the primary goal of the researcher was to minimize harm to the primary stakehold- ers, the choice to disclose the vulnerabilities two weeks after first attempting to contact the vendor resulted in the exact opposite result (i|,Non-data,115
|e, increased harm and decreased benefit to both primary and secondary stakeholders) 5 CONCLUSION More questions are typically raised about the ethics of computer security research activities than answers are pro- vided|,Non-data,115
| To help understand these issues and define a workable ethical framework, we believe that a more structured series of public discussions are urgently needed For a glimpse at our efforts to help energize this needed dialog, please see our extended technical report [3] 6 |,Non-data,115
|Abstract threats propagate randomly, The Internet today is beset with constant attacks tar- geting users and infrastructure One popular method of detecting these attacks and the infected hosts behind them is to monitor unused network addresses Because many Internet infection attempts can be captured by monitoring the unused spaces be- tween live addresses Sensors that monitor these unused address spaces are called darknets, network telescopes, or blackholes|,Non-data,116
| They capture important information about a diverse range of threats such as Internet worms, denial of services attacks, and botnets In this paper, we describe and analyze the important measurement issues associated with deploying darknets, evaluating the placement and service configuration of darknets, and analyzing the data collected by darknets To support the discussion, we lever- age 4 years of experience operating the Internet Motion Sensor (IMS), a network of distributed darknet sensors monitoring 60 distinct address blocks in 19 organizations over 3 continents I|,Non-data,116
| Introduction Monitoring packets destined to unused Internet ad- dresses has become an increasingly important measure- ment technique for detecting and investigating malicious Internet activity Since there are no legitimate hosts or devices in an unused address block, any observed traf- fic must be the result of misconfiguration, backscatter from spoofed source addresses, or scanning from worms and other network probing Systems that monitor unused address space have been called darknets [8], network telescopes [11], blackhole monitors [17], Sinkholes [9], or background radiation monitors [13], and capture important information about a diverse range Internet threats such as denial of service attacks [12], random scanning worms [3], [10], [15], [16], and botnets [7] In this paper, we describe and analyze the important measurement issues associated with deploying darknets, configuring darknets, and analyzing the data collected by darknet monitors|,Non-data,116
| The goal is to provide a general overview of darknet measurement and give researchers with the information needed to deploy and analyze the data from darknet monitoring systems Our approach does not focus on a particular architecture and is meant to be complementary to existing work [1], [11], [19], [21] We begin by describing how to setup a darknet and how to configure the network to forward traffic destined for unused addresses to a monitoring system Next, we analyze data from different sized darknets to assess the storage and network resources required for darknet measurements|,Non-data,116
| We next discuss how the placement of a darknet within address space and the surrounding network topology influences the visibility of monitoring systems We also describe how visibility is impacted by the response to incoming packets In particular, we show how no response, a SYN-ACK responder, an emulated operating system and application- level response, and a real honeypot host response represent a spectrum of interactivity that can provide additional intelligence on network events and threats Finally, with this understanding of how to deploy and configure darknet monitors, we describe different methods of identifying important events in data collected by darknet monitors|,Non-data,116
| To inform our analysis we use data from the globally deployed Internet Motion Sensor (IMS) distributed darknet monitoring system The IMS consists of 60 darknet blocks at 18 organizations including broadband providers, major service providers, large enterprises, and academic networks in 3 continents It monitors over 17 million addresses which represents more than 125% of all routed IPv4 space|,Non-data,116
| 2 Fig 1 A sample configuration which illustrates the three major darknet deployment models; capturing traffic out-bound to reserved space (lines 6-8), traffic destined to a statically configured, unused subnet (line 4), or capturing all unused space within an allocation (line 5) II|,Non-data,116
| Darknet Deployment The deployment of a darknet monitoring system re- quires an understanding of the topology of the local network Since a darknet monitor observes traffic to unused addresses, the upstream router or dynamic host configu- ration server must be instructed to forward undeliverable packets to the monitor In this section we highlight some of the important challenges associated with configuring the network and then discuss how to provision adequate storage and network resources for a darknet system A|,Non-data,116
| Configuration There are three general techniques for forwarding pack- ets to a darknet monitoring system The simplest approach is to configure the monitoring box to send ARP replies for each unused address to the router This works well when the darknet is well-defined and spans a few addresses or when access to the upstream router is not possible However, it is far less efficient with thousands or millions of monitored addresses|,Non-data,116
 A more scalable approach is to configure the upstream router to statically route an entire address block to the monitor This idea is illustrated in line 4 of the router configuration in Figure 1 This figure depicts a darknet monitoring setup in which the monitor is connected to a switch which is then connected to an upstream router The use of a static route illustrated in the figure is simple but requires that darknet address block be specifically set aside for monitoring,Non-data,116
| A more flexible approach is to route all packets destined to locations that do not have a more specific address configured (and would thus be dropped) to the monitoring system by means of a blackhole (also called a fall-through route) Thus, if an organization is allocated a /8, then it could create a static route to the darknet monitor for the entire /8 Packets to valid addresses will hit more specific prefixes and only packets to unused addresses will fall through to the /8 route This idea is also illustrated in Figure 1 and is similar to adding a route to prevent flooding attacks against persistent loops [20]|,Non-data,116
| The setup thus far has assumed monitoring of unused addresses that are both globally addressable and reachable It is also possible to monitor unused and non-routable addresses [5] For example, RFC 1918 addresses are often used within service providers and enterprises for local systems and unused addresses in these ranges can also be monitored by darknet systems Lines 6-8 of the router configuration in Figure 1 demonstrate how to setup static fall-through routes for the three major RFC 1918 ranges|,Non-data,116
| B Resource Provisioning Understanding the storage and network requirements of a darknet is critical to correctly provision the monitoring system as the amount of incoming traffic can be quite large These requirements are typically dependent on the number of addresses monitored To provide a general overview of the data rates observed at darknets of different sizes, we measured the packets per day per IP for various sized darknet blocks|,Non-data,116
| The results are shown on the left of Figure 2 Note that the darknets that monitored less addresses tended to receive more packets per day per IP than the larger darknets We explore these differences in more detail in the next section On average, we found that a small /24 sensor is likely to see a sustained rate of 9 packets per second, a moderately sized /16 monitor will see roughly 75 packets per second, and a large /8 monitor over 5,000 packets per second|,Non-data,116
 An important caveat that biases these results is that the /24 monitors actively responded to certain incoming connections We found that the traffic was between 11 to 16 times greater on average than nearby passive /24 monitor Details on the response are described in the next section,Non-data,116
| Another consideration is that the average rates can be deceptive because traffic routinely bursts two to three orders of magnitude above the sustained rate For example, one IMS sensor has had a sustained rate of 9 packets per seconds over the last 25 years with a daily low of 6 packets per second and a daily high 31|,Non-data,116
000/8310,Non-data,116
023110,Non-data,116
0/161:2:3:4:5:6:7:8:interface FastEthernet2/0ip address 31001 255,Non-data,116
255255252arp 310,Non-data,116
02 00096b49f013 ARPAip route 31,Non-data,116
110 255255,Non-data,116
2550 3100,Non-data,116
2ip route 31000 255,Non-data,116
000 310,Non-data,116
02ip route 1921680,Non-data,116
0 2552552550 31,Non-data,116
002ip route 17216,Non-data,116
00 17231255,Non-data,116
255 31002ip route 10,Non-data,116
000 2550,Non-data,116
00 3100,Non-data,116
2Simple DarkNet Network ConfigurationDarkNetMonitorInternetCisco ProductsCisco Systems Corporate IconographyMicroWebserverMobileAccessrouterMobileAccess IPphoneMultilayerswitchMulti-FabricServerSwitchMultilayerRemote switchMoH server(Music on Hold)MultiSwitchDeviceNetRangerNetSonarNetworkManagementNetFlowrouterOptical ServicesRouterOptical AmpliiferONS15500OpticalTransportPC RouterCardPIXFirewallProgrammableSwitchProtocolTranslatorPXFRateMUXRelationalDatabaseRepeaterRoute SwitchProcessorRouter withSilicon SwitchRouterSmallhubSoftswitchPGWMGCStandardhostSIP ProxyserverServer withPC RouterServerSwitchService controlSecurityapplianceStorageRouterStoragearraySTPSystemcontrollerTape arrayTDMrouterTranspathuBR910uMG seriesUnity serverUniversalGatewayVIPRouter withFirewallSiPC AdapterCardSiSTPTDMIPVirtualswitch controller(VSC 3000)80211VirtualLayer Switch3100,Non-data,116
131200/16Cisco ProductsCisco Systems Corporate IconographyMicroWebserverMobileAccessrouterMobileAccess IPphoneMultilayerswitchMulti-FabricServerSwitchMultilayerRemote switchMoH server(Music on Hold)MultiSwitchDeviceNetRangerNetSonarNetworkManagementNetFlowrouterOptical ServicesRouterOptical AmpliiferONS15500OpticalTransportPC RouterCardPIXFirewallProgrammableSwitchProtocolTranslatorPXFRateMUXRelationalDatabaseRepeaterRoute SwitchProcessorRouter withSilicon SwitchRouterSmallhubSoftswitchPGWMGCStandardhostSIP ProxyserverServer withPC RouterServerSwitchService controlSecurityapplianceStorageRouterStoragearraySTPSystemcontrollerTape arrayTDMrouterTranspathuBR910uMG seriesUnity serverUniversalGatewayVIPRouter withFirewallSiPC AdapterCardSiSTPTDMIPVirtualswitch controller(VSC 3000)802,Non-data,116
11VirtualLayer SwitchCisco ProductsCisco Systems Corporate IconographyMicroWebserverMobileAccessrouterMobileAccess IPphoneMultilayerswitchMulti-FabricServerSwitchMultilayerRemote switchMoH server(Music on Hold)MultiSwitchDeviceNetRangerNetSonarNetworkManagementNetFlowrouterOptical ServicesRouterOptical AmpliiferONS15500OpticalTransportPC RouterCardPIXFirewallProgrammableSwitchProtocolTranslatorPXFRateMUXRelationalDatabaseRepeaterRoute SwitchProcessorRouter withSilicon SwitchRouterSmallhubSoftswitchPGWMGCStandardhostSIP ProxyserverServer withPC RouterServerSwitchService controlSecurityapplianceStorageRouterStoragearraySTPSystemcontrollerTape arrayTDMrouterTranspathuBR910uMG seriesUnity serverUniversalGatewayVIPRouter withFirewallSiPC AdapterCardSiSTPTDMIPVirtualswitch controller(VSC 3000)80211VirtualLayer SwitchRFC19183111,Non-data,116
0/24Cisco ProductsCisco Systems Corporate IconographyVoicecommserverVoiceATM switchVoicegatewayVoicerouterVoiceswitchWavelengthrouterWirelessBridgeWirelessrouterWirelessLocationApplicanceWLAN controllerWiSMWorkgroupdirectorWorkgroupswitchVPNGatewayVPN concentratorVVVVVWi-Fi Tag3 Fig 2 The provisioning requirements for various blocks On the left the number of packets seen per day per IP for various sized blocks,Non-data,116
| On the right the size on disk for various representations of of darknet Traffic of 290 packets per second The average packet size was approximately 100 bytes The corresponding bandwidth requirements for an average /24 sensor is 7 Kbps, 60 Kbps for a /16 monitor, and 4 Mbps for a /8 monitor The storage format used to log incoming packets also has a large impact on the storage requirements|,Non-data,116
| Com- mon formats for collecting network traces like pcap and NetFlow are well suited for collecting darknet data To better quantify the actual storage requirements based on different darknet sizes, we analyzed the bytes required for different storage formats (in raw and zipped format) at /16 darknet monitor over a 17 hour period The results are shown by hour on the right side of Figure 2 The plot shows that pcap tends to compress very well and so keeping data files in gzip format can reduce storage requirements by more than a factor of two|,Non-data,116
| The figure also shows that while flow-based representation lose important data like a the payload, they do provide excellent data reduction There was nearly 15:1 compression when converting pcap to Netflow v9 These measurements demonstrate that a /16 monitor can record a few months worth of data on commodity hardware with a single disk Furthermore, by compressing or converting data into flow-based formats the storage requirements can be reduced by a factor 2 to 15|,Non-data,116
 III Darknet Visibility Considerations Before deciding exactly what addresses to allocate to a darknet it is important to understand how the placement of a darknet impacts what it observes It has been shown that the malicious and misconfigured activity observed by two different but equally sized darknets is almost never the same [6] These differences tend to depend on two Fig,Non-data,116
| 3 Packet per day per IP at 25 different IMS darknet monitors important factors: the placement of a darknet, and the way in which a darknet responds to incoming packets In this section we provide a brief overview of these two influences and describe how they impact darknet visibility|,Non-data,116
| A Placement Evaluating the placement of a darknet involves under- standing several topological factors One of the biggest influences on visibility appears to be vicinity to live hosts That is, proximity in IP address space to live hosts [6]|,Non-data,116
| Figure 3 shows the average packets per day per IP for 25 of the IMS sensor blocks The values are normalized per IP to make different sized blocks comparable The values range from 10 packets per day to more than 10,000 packets per day per IP Of note, the darknets that observe the most 100100010000100000100000010000000100000000Number of IPs in the DarkNet10100100010000Number of Packets per Day per IP 10 100 1000 10000 100000 0 2 4 6 8 10 12 14 16 18 20 22 24Packets per day per IPSensors4 data like the exploit used in an attack or the details of misconfigured application requests|,Non-data,116
| For example, all valid TCP transactions require a three-way handshake that must be completed before any application-level data is exchanged This means that a passive darknet will not observe application-level data from hosts that attempt to connect via TCP An active response to incoming packets on a darknet can be used to collect additional application-level infor- mation to better understand an exploit attempt and better understand the intentions of an attacker A simple but effective active response technique is to respond to TCP SYN packet with TCP SYN-ACK packets [1]|,Non-data,116
| A single stateless response packet provides at least the first data packet on a TCP session and helps uniquely identify complex threats like the Blaster worm The first data payload may not provide enough infor- mation, so more complex responses can be used to elicit additional information One method of generating these responses is to emulate the behavior of a real host [14], [21] An emulated host can masquerade as a large variety of operating system and application combinations|,Non-data,116
| An emulator provides the flexibility to emulate just enough of an application to acquire the needed information However, one danger is that a malicious attacker could identity an emulated host and avoid a darknet monitor or sent it false information The simple way to reduce the impact of this fingerprinting problem is to use a real host (ie|,Non-data,116
| a honeypot) instead of an emulated host [18] A real host can provide complex information on an attacker and help profile the behavior, however, it can be very resource intensive The cost of running a real host is significant and limits the number of possible monitored addresses from thousands to just a handful One way to regain scalability is to use a pool of quickly recyclable virtual machines [19] so that multiple virtual hosts can be executed on a single physical system|,Non-data,116
| Another method is to filter the connections before they reach the end hosts so that only the newer and more interesting connection are investigated [2] Together, these different response techniques form a spectrum of interactivity that provide additional informa- tion from darknets Figure 4 visually depicts this spectrum along the y-axis labeled depth We define depth as a measure of the accuracy of the responses from a darknet when compared to the responses from a real host|,Non-data,116
 On the x- axis is breadth We define breadth as a measure of scope or number of addresses a darknet monitor can observe This figure demonstrates the tradeoffs between scalability and fidelity and associated resource cost incurred in attempting to achieve additional breadth or depth A final and critical configuration decision when running a darknet with real or emulated hosts is what operating Fig,Non-data,116
 4 Illustration of the tradeoffs between the number of addresses a darknet can mon- itor (breath) and the accuracy of the re- sponses from a darknet as compared to a real host (depth) Additional resource costs are incurred attempting improve breath or depth traffic also tend to be smaller ( /24) and are located in live networks near hosts,Non-data,116
| The concrete reasons behind these traffic differences are still not well understood but it appears to be related to tar- geting behavior [6] In particular, the preference for nearby addresses by malware and misconfigured applications For example, Internet worms like Blaster [3] and Nimda [4] have a strong preference for nearby addresses Another factor appears to be targeting by botnets and other attack- ers [7]|,Non-data,116
| By targeting specific ranges of addresses that are known to contain vulnerable hosts, attackers can increase the number of systems they are able to compromise Another important darknet placement consideration is the location within a network If a darknet monitor is placed behind a firewall or other infrastucture protection or filtering device, it will likely not observe externally sourced threats On the other hand, darknets within the network can also provide important visibility into locally-scoped threats within a network|,Non-data,116
| Ideally, a darknet deployment that in- cludes monitors deployed both inside and outside network perimeters should have the greatest potential visibility B Service configuration The visibility provided by darknets is also heavily dependent on how a darknet responds to incoming packets The simplest action is not to respond at all|,Non-data,116
| A pas- sively configured darknet simply records all the packets it observes and no further action is taken This reveals the address of the host sending the packet and other header information However, it may not reveal critical BreadthDepthLive HostEmulationSYN-ACKPassiveLocal ScopeGlobal ScopeNo ServiceEmulationReal ServicesVM-based Increasing CostIncreasing CostDistributedHoneyfarmNetwork /Mask Type of Organization Hosts Unique A/16 B/16 C#1/17 C#2/19 D#1/19 D#2/19 university university webfarm webfarm webfarm webfarm 5512 1289 11342 2438 1859 1652 TCP HTTP Implment- Config- urations ations 241 352 73 156 256 862 293 93 221 118 137 208 TABLE I Different TCP implementations and HTTP server configurations across different production networks|,Non-data,116
 systems and applications should be run/emulated This is a very important consideration because it can be the difference between quickly identifying a new threat or missing it because the correct service was not running Choosing appropriate services to run is far more complex than it might first appear We conducted a survey of the ser- vices running on the University of Michigan’s engineering campus and found a wide variety of operating system and application combination,Non-data,116
| A table of the different TCP stack and HTTP server implementations is shown in Table III- B In the table, network A/16 contained 5512 scannable hosts and we found 252 unique TCP implementations, 241 unique HTTP configurations, and 1210 combinations of TCP and open and closed port configurations This diversity means that choosing the right services to run is a complex problem for which their is currently no simple solution IV|,Non-data,116
| Analysis of Darknet Data Darknets can produce vast quantities of high- dimensional measurement data Making sense of this data can be a daunting task An entire study was dedicated to understanding the traffic observed in darknets [13] In general, darknet traffic can be classified into four main areas: • Infection attempts by worm, botnet, and exploit tools|,Non-data,116
 • Misconfigured application requests and responses (eg DNS) • Backscatter from spoofed denial of service attacks,Non-data,116
| • Network scanning and probing Generating these classifications can be complex due to scalability constraints from the huge amount of darknet data that must be processed One method of reducing this effort is to filter the data into a smaller set of more manageable events One simple yet powerful method is to cluster the data by source address [13], [2]|,Non-data,116
 A single address may contact many different destination addresses 5 Fig 5 Example of an IMS report based on clustering by source address in the darknet but will tend to perform similar behavior at each address,Non-data,116
| For example, a host infected with the Slam- mer worm [10] may scan tens or hundreds of thousands of destination addresses in a single day This generates a huge amount of total traffic however it can be compressed down to a single event by grouping all that traffic by the single Slammer source address To get a better idea of the real-world savings consider that a certain IMS darknet received 57,178,687 IP packets in a single 24-hour period If we instead cluster that same traffic by source address we find 95,888 unique source IPs|,Non-data,116
| Thus, this simple technique provides three orders-of-magnitude savings in the number of events that must be analyzed We leverage this technique to provide daily IMS reports to operators of potentially infected systems A clipping from a report detail the same 24-hour period described earlier is shown in Figure 5 A|,Non-data,116
| Global and Local Darknet Events The individual events detected in darknets can usually be further divide to two locality classes When an event such a new attack or large increase in probing occurs, it will impact a very small number of addresses (ie, local) or the entire Internet (i|,Non-data,116
|e, global) This classification only applies to the destination of an event so a local event could originate from a different network across the Internet as long it targeted a specific destination network Figure 6 shows examples of global and local events|,Non-data,116
| The left pane of the figure shows a globally-scoped attack against the MySQL service as observed by 23 IMS sensors (each color represent a separate sensor) In the right pane is a targeted RPC-DCOM attack observed in academic network containing an IMS sensor In general, we see this bimodal distribution across many different vectors such as payload and source addresses The implication is that attacks and other events observed in darknets are observed at only one network or are widespread and are observed at many points around the Internet|,Non-data,116
| V Conclusion This paper has described the important measurement issues associated with deploying darknets, configuring darknets, and analyzing the data collected by darknet - 56 -IMS Darknet ReportsAll Sources Total IP Packets:  57178687 Total TCP Packets: 20173121 Total UDP Packets: 34238463 Total ICMP Packets: 2747341 Unique Source IPs: 95888 Statistics on Top 10 TCP Source IPs:  Source IP  TCP Pkt Cnt Top 3 Dest Ports  XX56|,Non-data,116
81  229695    tcp/445:221043 tcp/8080:8652  XX153156 219602    tcp/445:219593 tcp/80:9  X,Non-data,116
X199134 162931    tcp/443:26456 tcp/80:25899 tcp/1315:1113 Statistics on Top 10 UDP Source IPs:  Source IP  UDP Pkt Cnt Top 3 Dest Ports  XX,Non-data,116
2961  1272378   udp/53:1272202 udp/123:176  XX1,Non-data,116
15  319201    udp/137:319201  XX3633  243518    udp/137:238843 udp/123:3251 udp/138:1416 Statistics on Top 10 ICMP Source IPs:  Source IP  ICMP Pkt Cnt Top 3 Dest Ports  X,Non-data,116
X3151  664139    icmp/8:664139  XX,Non-data,116
6326  175178    icmp/8:175178  XX14,Non-data,116
23  152564    icmp/8:152564Report from 24 hours of darknet traffic from enterprise network 6 Fig 6 The left figure is globally-scoped attack against the MySQL service as observed by 23 IMS sensors (each color represent a separate sensor) In the right figure is a targeted RPC-DCOM attack observed in academic network containing an IMS sensor,Non-data,116
| monitors We have attempted to provide researchers with a general overview of darknet measurement and the impor- tant details needed to deploy darknet monitoring systems This analysis has attempted to demonstrate that building and operating a darknet monitor is a simple and productive method of gaining significant additional visibility into network threats and the state of local network and Internet as a whole Acknowledgments This work was supported by the Department of contract number Homeland Security (DHS) under NBCHC040146, and by corporate gifts from Intel Cor- poration and Cisco Corporation|,Non-data,116
| The authors would like to thank all of the IMS participants for their help and sugges- tions We would also like to thank Danny McPherson, Jose Nazario, Dug Song, Robert Stone, and G Robert Malan of Arbor Networks and Manish Karir and Bert Rossi of Merit Network for their assistance and support |,Non-data,116
|Abstract A key way in which banks mitigate the effects of phishing is to re- move fraudulent websites or suspend abusive domain names This ‘take-down’ is often subcontracted to specialist firms Prior work has shown that these take-down companies refuse to share ‘feeds’ of phishing website URLs with each other, and consequently, many phishing websites are not removed because the firm with the take-down contract remains unaware of their existence|,Non-data,118
| The take-down compa- nies are reticent to exchange feeds, fearing that competitors with less compre- hensive lists might ‘free-ride’ off their efforts by not investing resources to find new websites, as well as use the feeds to poach clients In this paper, we propose the Phish Market protocol, which enables companies with less comprehensive feeds to learn about websites impersonating their own clients that are held by other firms The protocol is designed so that the contributing firm is compensated only for those websites affecting its competitor’s clients and only those previ- ously unknown to the receiving firm Crucially, the protocol does not reveal to the contributing firm which URLs are needed by the receiver, as this is viewed as sensitive information by take-down firms|,Non-data,118
| Using complete lists of phishing URLs obtained from two large take-down companies, our elliptic-curve-based imple- mentation added a negligible average 5 second delay to securely share URLs 1 Introduction Phishing is the criminal activity of enticing people into visiting websites that imper- sonate genuine bank1 websites, and to dupe them into revealing passwords and other credentials to carry out fraudulent activities One of the key countermeasures to phish- ing is the prompt removal of the imitation bank websites Removal may be achieved by erasing the web pages from the hosting machine, or by contacting a registrar to suspend a domain name from the DNS so the fraudulent host can no longer be resolved|,Non-data,118
| Although some banks deal with phishing website removal exclusively ‘in-house’, most hire specialist ‘take-down’ companies to carry out the task Take-down companies – typically divisions of brand-protection firms or information security service providers – perform two key services for banks First, they are good at getting phishing websites removed quickly, having developed relationships with ISPs and registrars across the globe and deployed multi-lingual teams at 24x7 operations centers Second, they collect a more timely and comprehensive listing of phishing URLs than banks normally gather|,Non-data,118
| 1 Although a wide range of companies have been subject to phishing attacks, the vast majority are financial institutions; for simplicity, we use the term ‘banks’ for firms being attacked 2 Tal Moran and Tyler Moore Most take-down companies view their URL feeds as a key competitive advantage over banks and other take-down providers However, recent work has shown that the feeds compiled by take-down companies suffer from large gaps in coverage that sig- nificantly prolong the time taken to remove phishing websites Moore and Clayton ex- amined six months of aggregated URL feeds from many sources, including two major take-down companies [13]|,Non-data,118
| They found that up to 40% of the phishing websites im- personating banks hired by take-down companies were known to others but not by the company with the take-down contract Another 29% of websites were discovered by the responsible take-down company only after others had identified the sites By mea- suring the substantially longer lifetimes of these missed websites, Moore and Clayton estimated that at least $330 million per year is being put at risk by the failure to share proprietary feeds of URLs for just the two companies they studied But is sharing the answer, and, if so, then how should an effective sharing mech- anism be designed? Moore and Clayton appealed to the security industry’s sense of responsibility and argued that URL feeds should be shared freely between take-down companies and banks, pointing to the precedent of sharing in the anti-virus industry|,Non-data,118
| However, there are some reasonable objections to a sharing free-for-all First, com- petition between take-down companies may drive investment into better techniques for identifying new phishing websites faster, and mandated sharing might undermine the in- centive to innovate Unsurprisingly, most take-down companies would rather see banks purchase the services of several take-down providers to overcome gaps in coverage In this paper, we describe the Phish Market protocol, which addresses the compet- itive concerns of take-down companies so that widespread sharing can take place|,Non-data,118
| To bolster the incentive to share, our protocol enables sharing of URLs where the net con- tributors are compensated without revealing the sensitive details of what is shared to competitors At a high level, the Phish Market protocol does the following: 1 shares only those URLs that the receiving party wants (ie|,Non-data,118
|, the banks the receiving party works for); 2 does not reveal to the providing party which URLs are given to the receiving party; 3 securely tallies the number of URLs given to the receiving party; 4 does not count URLs the receiving party already has|,Non-data,118
| Timing is critical when it comes to distributing URL feeds — the longer a phishing website remains online, the more customer credentials may be at risk While in theory generic multiparty computation protocols can be used to implement this mechanism, in practice they are very inefficient and would introduce significant delays in processing the many thousands of phishing websites In contrast, our custom protocol is extremely efficient (and still provably secure) To demonstrate the feasibility of our mechanism, we have implemented an elliptic- curve-based version of the protocol in Java|,Non-data,118
| Using the feeds from two take-down com- panies during the first two weeks of April 2009, we tested protocol performance in a real-world scenario We found that our sharing protocol introduces an average delay of 5 seconds to the processing and transmission per phishing URL In exchange for this very short delay, information on new phishing websites is exchanged between take- down companies so that the overall lifetime of phishing websites may be halved [13] while crediting the contributing firm The Phish Market Protocol: Securely Sharing Attack Data Between Competitors 3 2 The Phish Market Protocol We now describe the Phish Market protocol, where companies with more comprehen- sive feeds of phishing URLs are compensated for sharing with those who learn most from sharing|,Non-data,118
| The protocol deals with a number of constraints in order to satisfy the exchanging parties without relying on a trusted third party While we formalize the se- curity properties guaranteed in Section 22, it is helpful to first mention the requirements affecting the protocol’s design In particular, each company is only interested in a sub- set of their competitors’ feeds, namely those URLs that affect their own customers|,Non-data,118
| As an added complexity, take-down companies keep their list of client banks secret from competitors Hence, we need a way to share only those URLs that the other party is in- terested in, without revealing which URLs are being shared Note that our mechanism does not directly compensate contributors; instead, it tallies the total number of useful URLs exchanged in a way that cannot be manipulated by either party An Optimal Ideal-World Protocol|,Non-data,118
| We describe the task our protocol performs by first explaining how it could be done if we used a trusted third party (TTP) — someone who was entirely trusted by both the contributor (or Seller) and the receiver (or Buyer) To share data in this ideal scenario, both the Buyer and the Seller would send the data to the TTP; the Buyer’s data consists of the URLs she already knows and her list of client banks, while the Seller’s data consists of the URLs he is attempting to sell and their classification (ie, which bank each URL is attempting to impersonate)|,Non-data,118
| The TTP could then send the Buyer only those URLs that both impersonate her clients and that she did not already know The TTP would send the Seller the number of URLs sent to the Buyer This number would then be used to compute the compensation owed to the Seller Since the TTP only sends the new “interesting” URLs to the Buyer, she will not learn anything about URLs she was not interested in (and would not have to pay for them)|,Non-data,118
| On the other hand, the TTP sends the Seller only the number of URLs sold, not the URLs themselves Consequently, the Seller will not gain additional information about the Buyer’s client list Our protocol is intended to provide this functionality, maintaining its privacy prop- erties, but without requiring a third party Using powerful results from theoretical cryp- tography, it is known how to convert any task that can be performed with the aid of a TTP to one that does not require third parties|,Non-data,118
| However, these techniques are usually inefficient In our case, even the most efficient implementations of general techniques (such as the Fairplay system [11]) would be orders of magnitude too slow for practical use We give an efficient protocol for executing a single ‘transaction’ of the following form: the Seller first sends a ‘tag’ to the Buyer The tag can be, for example, the name of the bank associated with the URL to be sold|,Non-data,118
| The Buyer uses the tag to decide whether or not she is interested in learning the corresponding URL She also commits in advance to the set of URLs she already knows If the Buyer was interested in the tag and did not already know the corresponding URL, the Seller receives a ‘payment’ Otherwise, the Seller receives a ‘counterfeit payment’ (the Seller should not be able to tell whether or not a payment is counterfeit — otherwise he would be able to tell whether or not the Buyer was interested in the URL, and thus discover the Buyer’s client list)|,Non-data,118
| 4 Tal Moran and Tyler Moore At the end of some previously agreed period (or number of transactions), the Buyer reveals to the Seller how many ‘real’ payments were sent, and proves that this is indeed the case (without revealing which of the payments were real) In practice, we envision each pair of take-down companies executing the basic protocol in both directions: when one of the companies acquires a new URL, it would execute the protocol as the Seller, with the other company playing the Buyer When the second company acquires a new URL, it would execute an instance of the protocol in the other direction, with the first party as Buyer and the second as Seller Note that, even in the using a trusted third party, some attacks are still possible|,Non-data,118
| For example, there is no guarantee that the URLs sold will be useful or correctly tagged A malicious Seller could send random strings instead of URLs, forcing the Buyer to ‘pay’ for garbage URLs (since they would not appear in the Buyer’s database) A malicious Seller can also attack the Buyer’s privacy: if he uses the same tag for all the URLs in a certain period, the Seller can tell whether or not the Buyer is interested in the tag by whether or not a payment was made at the end of the period Since these attacks can be carried out in the ideal world, any protocol implementing this type of exchange is also vulnerable|,Non-data,118
| For the situations in which we anticipate our protocol will be used, however, there are mitigating strategies First, the Buyer can evaluate the URLs she learns and set the price she is willing to pay for each URL based on the quality of URLs she received in the past If she determines that the Seller is providing low-quality URLs, the Buyer can request a lower dollar price per URL or refuse to do business with that Seller in the future This would mitigate the “garbage URL” attack|,Non-data,118
| Defending against the privacy breach attack is harder — the payment will always leak some information about which tags the Buyer is interested in We can help the Buyer detect this type of attack by compromising a little on the Seller’s privacy: if we give the Buyer all the tags the Seller uses (without the corresponding URLs), the Buyer can verify that no set of tags is overly represented Finally, in a two-party protocol, unlike a protocol that uses a trusted third party, each side can decide to abort the protocol prematurely This affects the security of our proto- col if the Buyer decides to abort after learning a URL but before making the payment|,Non-data,118
| However, the same problem exists in many remote transactions (eg, when purchasing physical goods over the phone, the seller can refuse to send the goods after receiving payment) The same legal frameworks can be used to handle a refusal to pay in this case|,Non-data,118
| Below, we describe the protocol as well as the precise security guarantees we make 21 Protocol overview Payment Commitments Before we describe the protocol itself, we must clarify what we mean by ‘real’ and ‘counterfeit’ payments|,Non-data,118
| Our protocol uses cryptographic commit- ments as payment tokens Loosely speaking, a commitment to a value x can be thought of as a public-key encryption of x, for which only the Buyer knows the secret key; the Seller can’t tell what x is from the commitment, but the Buyer can ‘open’ a commit- ment and prove to the Seller that the commitment is to a specific value In our protocol, a ‘real’ payment is a cryptographic commitment to the number 1, while a ‘counterfeit’ payment is a commitment to the number 0 The Phish Market Protocol: Securely Sharing Attack Data Between Competitors 5 The payment commitments used by the protocol have a special property that allows them to be efficiently aggregated, even in encrypted form (they are homomorphic; see App|,Non-data,118
| B for a formal definition) Thus, the Seller can take the ‘payments’ from multiple executions of the basic protocol and compute a commitment to the total payment (the number of URLs actually ‘sold’) The Buyer will eventually open the aggregated commitment At this point, the Seller will learn only the total number number of ‘real’ payments received (and not which individual payments were real)|,Non-data,118
| This value can be used as the basis for a monetary transaction between the two parties Protocol Construction One of the more difficult challenges to solve efficiently is that the Buyer should not have to pay for URLs she already knew, while simultaneously protecting the privacy of the Buyer’s client list The known techniques for general se- cure computation of a function require an expensive public-key operation for each input (or even each bit of the input)|,Non-data,118
| In our case, the input would have to include the set of previously known URLs, which may be very large: A typical take-down company could learn an excess of 10 000 URLs per month, making existing systems impractical To solve this problem, we let the Buyer perform the database search locally, after learning the URL If she discovers the URL in the database, she must then prove to the Seller that the URL existed in the database before the start of the transaction However, this proof cannot use the URL itself, since that would reveal to the Seller that the Buyer was interested in it (thus exposing one of the Buyer’s clients)|,Non-data,118
 The main idea behind the protocol is to split the proof into two: 1 The first proof is a ‘proof of payment’ The payment in this case is a commitment to the value 1; the proof of payment proves that the Buyer can open the commitment she sent to the value 1 2,Non-data,118
| The second proof is a ‘proof of previous knowledge’ This proof convinces the Seller that the Buyer knew the URL before the start of the protocol The essence of the protocol is that we allow the Buyer to ‘fake’ a proof if she knows a corresponding secret key The protocol is set up so that the Buyer initially knows a single secret key: she can fake the first proof or the second proof, but not both|,Non-data,118
| Once the Buyer learns the tag, she must make a choice: she can either learn the corresponding URL, or learn the second secret key (but not both) Thus, if she chooses not to learn the URL, the Buyer can send a counterfeit payment (a commitment to 0), and fake both proofs If she chooses to learn the URL and did not already know it, she is forced to fake the second proof, and therefore cannot fake the first (so she must send a real payment) The proofs we use are Zero-Knowledge (ZK) proofs: the Seller learns nothing from the proof except the validity of its statement|,Non-data,118
 This protects the security of the Buyer (the Seller cannot tell whether or not the Buyer was interested in the URL or whether she previously knew it) Fig 1 shows a graphical overview of the protocol We split the second proof into the boxes labeled ZK Proof #2 and Proof #3 in the figure,Non-data,118
| Before the protocol begins, the Buyer sends the Seller a commitment to her set of previously known URLs (see App B for a more in-depth explanation of set commitments) ZK Proof #2 proves the Buyer holds a commitment for the URL (this part can be faked using a secret key) 6 Tal Moran and Tyler Moore Proof #3 proves the Buyer knew the commitment before the protocol began (this part cannot be faked; however, if the Buyer faked ZK Proof #2 she can choose an arbitrary commitment and prove she knew that)|,Non-data,118
| The reason for the split is that Proof #3 can be performed very efficiently, while Proof #2 requires public-key type operations The numbers on the left and right-hand sides of the figure reference the corresponding lines in the full protocol listing (on the left these are the lines in Prot 1a, and on the right in Protocols 1b and 2) To simplify the presentation, the protocol in Fig|,Non-data,118
| 1 omits two steps present in the full protocol: 1 The Buyer must prove that the payment is valid (either a commitment to 0 or a commitment to 1) Otherwise, if the Buyer fakes the first proof she could send a commitment to a negative number instead of a zero commitment (in which case the aggregate commitment would be opened to a lower value than the actual payment due) 2|,Non-data,118
| The use of a Merkle tree as a set commitment (Proof #3) is not completely secure if the same Merkle tree is used for multiple transactions This is because every execution of the protocol requires the Buyer to reveal a path from some leaf in the tree to the root If the Seller sees the same leaf twice, he will learn that in at least one of the transactions the Buyer was using a “fake” To prevent this attack, the Buyer must make sure the tree also contains “chaff” commitments|,Non-data,118
| When a fake commitment is needed, the Buyer uses one of the chaff commitments The Buyer makes sure to use each chaff commitment at most once (she can add chaff commitments to the tree if they run out) 22 Security Properties Unlike errors in most computer algorithms, protocols with faulty security may perform flawlessly — often by definition a failure in security is one that is undetected|,Non-data,118
| Thus, an important part of the specification for any secure protocol is a formal definition of its security properties and an analysis of the conditions under which they are guaranteed We make separate security guarantees for the Seller and for the Buyer in each trans- action (execution of the basic protocol) Buyer’s Security The Buyer in our protocol has as input a set of tags in which she is interested, T (e|,Non-data,118
|g, the list of banks she has as clients) and a set of previously known URLs, U The security guarantee for the Buyer is that a malicious Seller does not learn anything about T or U, beyond what he can deduce from the payment amount This is important because competitors naturally do not wish to reveal weaknesses (in terms of gaps in URL coverage)|,Non-data,118
| On the other hand, the Seller does not want to reveal URLs to the Buyer that the Buyer is unaware of without compensation Finally, the Buyer does not want to reveal its client list to the Seller More formally: Theorem 1 (Buyer’s Security) For any two sets of inputs (T0, U0) and (T1, U1), such that ||U0|| = ||U1||, the Seller’s view of a protocol execution when the Buyer is given input (T0, U0) is statistically indistinguishable from its view when the Buyer is given input (T1, U1)|,Non-data,118
 The Phish Market Protocol: Securely Sharing Attack Data Between Competitors 7 Fig 1 Simplified Phish Market protocol overview Note that the Seller’s view of the protocol does not include the opening of the ag- gregate payment: the Seller will obviously gain some information about T and U from the payment amount — what the theorem implies is that this is all the Seller learns,Non-data,118
| The intuitions behind the proof of this theorem appear in Appendix A1 Seller’s Security Essentially, the Seller needs to ensure that he is being justly com- pensated for each URL that the Buyer learns from him We define the security of the Seller by formally comparing our protocol to an ‘ideal world’ in which there exists a trusted third party (the ‘ideal Phish Market functionality’) that is completely trusted by both parties|,Non-data,118
| The protocol in the ideal world is much simpler than that in the real world, hence its security guarantees are easier to understand intuitively We prove our proto- col’s security by showing that any attacks by the Buyer on the protocol in the real world (without the trusted third party) can be performed in the ideal world as well Hence, our intuitions for the ideal world must hold for the real world too (this is the ideal/real simulation paradigm) Below, we describe the ideal-world protocol for a single transaction|,Non-data,118
| In both the real and the ideal world, the Buyer’s inputs consist of T, a set of tags in which the Buyer is interested, and U, a set of previously known URLs The Seller’s inputs consist of a tag t and a URL u The output of the protocol, on the Buyer’s side, is the tag t, and optionally the URL u (if the Buyer was interested in it) On the Seller’s side, the output is a payment commitment|,Non-data,118
| We denote Compk∗(x) a commitment to a value x2 The protocol in the ideal world proceeds as follows: 1: The ideal functionality waits for the Buyer to send U and the Seller to send t, u 2 For clarity, we’re ignoring the fact that the commitments are randomized — the commitment function is actually Compk∗(x, r), where r is the commitment’s randomizer) 8 Tal Moran and Tyler Moore 2: The functionality then sends t to the Buyer and waits for the Buyer to respond|,Non-data,118
 3: if The Buyer responds with 0 (she’s interested in t) then 4: 5: 6: 7: 8: The functionality sends u to the Buyer if u (cid:60) U then else // u ∈ U The functionality sends e = Compk∗(1) to the Seller The functionality sends e = Compk∗(0) to the Seller (The functionality will allow a corrupt Buyer to send e = Compk∗(1) in this case as well) The functionality sends e = Compk∗(0) to the Seller,Non-data,118
| 9: else // The Buyer is not interested in t 10: We allow a corrupt party to abort the computation at any point, in which case the other party will receive a special ⊥ symbol from the ideal functionality (this corresponds to a cheating party being detected) This ideal-world protocol is very similar to the optimal ideal-world protocol described in the beginning of this section However, in this protocol the ideal party always sends the tag to the Buyer, and if the Buyer is interested, always sends the URL to the Buyer (rather than only sending those URLs that were both interesting and not previously known) This extra ‘information leakage’ (compared to the optimal protocol) is the result of allowing the Buyer to perform the database lookup on her own|,Non-data,118
| Formally, the Seller’s security is defined as follows: Theorem 2 (Seller’s Security) For any set of inputs to the Buyer and Seller, and for every (probabilistic polynomial-time) adversary A that corrupts the Buyer in the real world, there exists a simulator S who corrupts the Buyer in the ideal world such that the outputs of both parties in the ideal world (the ideal-world Seller and S) are compu- tationally indistinguishable from the outputs of both parties in the real world (the real- world Seller and A), under the assumption that the underlying cryptographic primitives are secure The intuitions behind the proof of this theorem appear in Appendix A2 Side-Channel Attacks|,Non-data,118
| As with every ‘provably secure’ system, the proof of security only holds as long as certain assumptions are met For example, it may be possible to break the security of the protocol if the parties receive information outside the ‘legiti- mate’ channels specified by the protocol (these unanticipated information channels are called side channels) The Phish-Market protocol is potentially vulnerable to a timing side-channel attack: the Seller can measure the time it takes the Buyer to complete a transaction If this time depends on whether or not she was interested in the tag, or on whether or not she already knew the URL, the Seller will gain information about the Buyer’s client list or coverage rate|,Non-data,118
| This particular attack can be foiled with relatively little effort by adding artificial delays to the code to ensure all code paths on the Buyer’s side take the same time3 Of course, as in the case of any secure protocol, the Phish-Market protocol may be vulnerable to other side-channel attacks that we did not anticipate 3 Note that the delays are not random noise — the delay on each code path must be computed so that the total time taken by the Buyer does not depend on her input The Phish Market Protocol: Securely Sharing Attack Data Between Competitors 9 2|,Non-data,118
|3 Formal Protocol Definition We give a full protocol listing (in pseudocode) below We describe separately the pseu- docode for the Sellers’ and Buyers’ sides of the protocol To make the protocol listing easier to read, we divide it into a number of smaller subprotocols (called as subrou- tines from the top-level protocol, Prot 1)|,Non-data,118
 Prot 1a specifies the top-level protocol run by the Seller and Prot 1b that run by the Buyer Prot,Non-data,118
| 2 is called by the Buyer when she is interested in the tag sent by the Seller (the Seller’s side of the protocol looks the same whether or not the Buyer was interested) Prot 3 is used to prove knowledge of a given commitment value; this protocol has three “sides”: Prot 3a is the Seller’s view of the proof (verification), Prot|,Non-data,118
| 3b is the Buyer’s view when performing a “real” proof, and Prot 3c is the Buyer’s view when performing a “fake” proof (using the protocol’s trapdoor key) Throughout the protocol, we denote a Pedersen commitment under public-key pk to a value x and with randomizer r by Compk(x, r) To simplify the description, we assume all the Pedersen commitments are over some group with prime order p (thus, the inputs to the function Compk are both elements of Zp)|,Non-data,118
| We also assume the two parties have previously agreed on a Pedersen public-key pk∗ that is binding to both parties (ie, neither party knows its secret key) See App|,Non-data,118
| B for more details on the cryptographic primitives used in the protocol, including a protocol that can be used to generate Pedersen commitment keys with trapdoors (Prot 5) Protocol 1a Phish Market Protocol: Seller Input: Commitment public-key, pk∗, such that Buyer does not know corresponding secret key Input: A URL, u, with tag, t 1: Perform Commitment Key Generation (e|,Non-data,118
|g, Prot 5a) Denote the resulting commitment keys (pk0, pk1) and the secret k // Learning k will allow Buyer to compute both sk0 and sk1 2: Perform Commitment Key Generation (e|,Non-data,118
|g, Prot 5a) Denote the resulting commitment keys (pk2, pk3) (discard the secret)|,Non-data,118
| 3: Wait to receive Merkle root cU from Buyer // Root of a Merkle hash tree whose leaves are commitments to known URLs 4: Choose r ∈R Zp Send (t, Compk∗ (H(u), r)) to Buyer 5: Perform OT protocol as sender (Buyer as receiver) with input strings s0 = (u, r) and s1 = k 6: Wait to receive commitment e from Buyer|,Non-data,118
 // ‘payment’ commitment Verify that e ∈ C skb 7: Wait to receive bit b from Buyer // Payment proof based on binding of Compkb 8: Verify that e = Compk∗ (1) using Compkb for coin-flipping (Prot 3a),Non-data,118
| // Proves that Buyer can either open e to 1 or knows 9: Wait to receive bit b(cid:48) ∈ {2, 3} from Buyer // Payment validity proof based on binding of Compkb(cid:48) 10: Verify that e = Compk∗ (1) using Compkb(cid:48) for coin-flipping (Prot 3a) 11: Verify that e = Compk∗ (0) using Compk5−b(cid:48) for coin-flipping (Prot|,Non-data,118
| 3a) // Together with previous step proves that Buyer 12: Wait to receive commitment cu from Buyer // Buyer’s ‘previously known commitment’ to u 13: Let ctest ← Compk∗ (H(u),r) Verify that ctest = Compk∗ (0) using Compk1−b for coin-flipping (Prot 3a) // Proves that either Buyer can open cu to H(u) or that Buyer knows sk1−b can open e to either 0 or 1 Verify that cu ∈ C |,Non-data,118
| cu 14: Verify proof that cu is in set committed to by cU (eg verify a Merkle path from cu to cU) 10 Tal Moran and Tyler Moore (cid:110) Protocol 1b Phish Market Protocol: Buyer Input: Commitment public-key, pk∗ Input: Set of commitments to known URLs: U = Input: Set of wanted tags, T 1: Perform Commitment-Generation (Prot|,Non-data,118
| 5b) with input bit b 2: Perform Commitment-Generation (Prot 5b) with input bit b(cid:48) ∈ {2, 3} 3: Generate a ‘chaff’ commitment: cchaff ∈R C|,Non-data,118
| cu1 Denote the resulting commitment keys pk0, pk1 and skb Denote the resulting commitment keys pk2, pk3 and skb(cid:48)  Let U(cid:48) ← U ∪ {cchaff} Send Comset(U(cid:48)) to Seller (e|,Non-data,118
|g the root of a Merkle hash tree with elements of U(cid:48) as the leaves) // Commitment to set of already known URLs = Compk∗ (H(u1), r1),   |,Non-data,118
| , cu||U|| = Compk∗ (H(u||U||), r||U||) (cid:111) 4: Wait to receive (t, cu(cid:48) ) from Seller // Tag and commitment to URL 5: if t ∈ T then // Buyer is interested in tag 6: 7: else // Buyer is not interested in tag 8: Run Subprotocol 2 Perform OT protocol as receiver (Seller as sender) with choice bit 1 Denote result sk0, sk1 Choose re ∈R Zp Send e = Compk∗ (0, re) to Seller // ‘Fake’ payment Send b to Seller // Use Compkb for payment proof ‘Prove’ that e = Compk∗ (1) using Compkb and skb (Prot 3c)|,Non-data,118
 Send b(cid:48) to Seller // Use Compkb(cid:48) for payment validity proof ‘Prove’ that e = Compk∗ (1) using Compkb(cid:48) and skb(cid:48) (Prot 3c) Prove that e = Compk∗ (0) using Compk5−b(cid:48) and re (Prot 3b),Non-data,118
 Choose a ‘chaff’ commitment cu ∈ U Send cu to Seller Let ctest ← cu(cid:48) cu  ‘Prove’ that ctest = Compk∗ (0) using Compk1−b and sk1−b (Prot 3c),Non-data,118
 17: Prove that cu is in set committed to by Comset(U) (eg show a Merkle path from cu to cU) Protocol 2 Phish Market Subprotocol: Buyer is Interested in t 1: Perform OT protocol as receiver (Seller as sender) with choice bit 0,Non-data,118
| 2: if cu(cid:48) = Compk∗ (H(u), r(cid:48)) and ∃i : cui ∈ U and ui = u then // Buyer already knows u 3: Denote result u, r(cid:48) 9: 10: 11: 12: 13: 14: 15: 16: 4: 5: 6: 7: 8: 9: 10: 13: 14: 15: 16: 17: 18: 19: cu = Compk∗ (0, r(cid:48) − r) Choose re ∈R Zp Send e = Compk∗ (0, re) to Seller // ‘Fake’ payment Send b to Seller // Use Compkb for payment proof ‘Prove’ that e = Compk∗ (1) using Compkb and skb (Prot 3c)|,Non-data,118
 Send b(cid:48) to Seller // Use Compkb(cid:48) for payment validity proof ‘Prove’ that e = Compk∗ (1) using Compkb(cid:48) and skb(cid:48) (Prot 3c) Prove that e = Compk∗ (0) using Compk5−b(cid:48) and re (Prot 3b),Non-data,118
| Let cu = Compk∗ (H(u), r) such that cu ∈ U Send cu to Seller Let ctest ← cu(cid:48) Prove that ctest = Compk∗ (0) using Compk1−b and r(cid:48) − r (Prot 3b)|,Non-data,118
| Choose re ∈R Zp Send e = Compk∗ (1, re) to Seller // ‘Real’ payment Send 1 − b to Seller // Use Compk1−b for payment proof Prove that e = Compk∗ (1) using Compk1−b and re (Prot 3b) Send 5 − b(cid:48) to Seller // Use Compk5−b(cid:48) for payment validity proof Prove that e = Compk∗ (1) using Compk5−b(cid:48) and re (Prot|,Non-data,118
 3b) ‘Prove’ that e = Compk∗ (0) using Compkb(cid:48) and skb(cid:48) (Prot 3c) Send cchaff to Seller,Non-data,118
 Let ctest ← cu(cid:48) cchaff ‘Prove’ that ctest = Compk∗ (0) using Compkb and skb (Prot 3c)  11: else // Buyer did not know u or Seller is cheating 12: 3 Performance evaluation 3,Non-data,118
|1 Theoretical efficiency The advantage of this protocol over a generic secure-computation is its efficiency We measure efficiency in terms of both computation and communication overhead In Sec- The Phish Market Protocol: Securely Sharing Attack Data Between Competitors 11 Protocol 3a Proof of Committed Value: Seller Input: Commitment c and claimed value x // Commitment uses public key pk∗ Input: Trapdoor Commitment public key pk // Used for coin flipping 1: Wait to receive cchal from Buyer 2: Wait to receive (b, cb) from Buyer|,Non-data,118
| Verify that cb ∈ C 3: Choose chal1 ∈R Zp Send chal1 to Buyer 4: Wait to receive (chal0, rchal) from Buyer 5: Wait to receive r(cid:48) from Buyer|,Non-data,118
| Verify that cchal = Compk (chal0, rchal) Let chal ← chal0 + chal1 Verify that cchal · cb = Compk∗ (chal · x + b, r(cid:48)) Protocol 3b Proof of Committed Value: Buyer Input: Commitment c = Compk∗ (x, rx), rx and claimed value x // Commitment uses public key pk∗ Input: Trapdoor Commitment public key pk // Used for coin flipping 1: Choose chal0 ∈R Zp and rchal ∈R Zp|,Non-data,118
| 2: Choose b ∈R Zp and rb ∈R Zp Send Compk (chal0, rchal) to Seller Send (b, Compk∗ (b, rb)) to Seller 3: Wait to receive chal1 from Seller 4: Send (chal0, rchal) to Seller 5: Let chal ← chal0 + chal1|,Non-data,118
