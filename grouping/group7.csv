 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| In the next section we introduce a system for “typing” the nodes of such graphs; our main theorem states that AE schemes built from Enc, Dec, and Tag algorithms whose graphs can be correctly typed are secure The main instructions we support are XOR, which com- putes the XOR of two n-bit strings, and TBC, which invokes the tweakable blockcipher or its inverse We also have an instruction DUP that duplicates a value Nodes correspond- ing to input blocks are labeled IN, those corresponding to output blocks are labeled OUT, those corresponding to the initial state are labeled INI, and those corresponding to the final state are labeled FIN|,Non-data,13
| These labels, along with their in-/out-degree, are summarized for convenience next: 86Figure 32: The OCB scheme illustrated for a four- block message M1,   |,Non-data,13
| , M4, where Σ is the checksum M1 ⊕ ··· ⊕ M4 EncEK (T, X, M1, M2) (N, A, v) := T X1, X2 := X // ||Xi|| = n C1 := EK (T, M1) T := (N, A, v + 1) C2 := EK (T, M2) Y := (X1 ⊕ M1 ⊕ M2) (cid:107) X2 return (Y, C1, C2) −1 DecEK ,E K (T, X, C1, C2) (N, A, v) := T X1, X2 := X // ||Xi|| = n M1 := E−1 k (T, C1) T := (N, A, v + 1) M2 := E−1 K (T, C2) Y := (X1 ⊕ M1 ⊕ M2) (cid:107) X2 return (Y, M1, M2) TagEK (T, X) X1, X2 := X; V := EK (T, X1); return V Figure 33: The algorithms (Enc, Dec, Tag) corre- sponding to OCB We have Cost(OCB) = 2|,Non-data,13
| Name In-deg Out-deg Meaning IN INI FIN OUT DUP XOR TBC 0 0 1 1 1 2 1 1 1 0 0 2 1 1 Input block Initial state Final state Output block Duplicate XOR operation Tweakable blockcipher Figure 32 illustrates the OCB scheme [23], Figure 33 shows the corresponding Enc, Dec, and Tag algorithms, and Figure 34 shows the corresponding graphs|,Non-data,13
| (In OCB, only the first n bits of the state are used, so we treat the state as an element of {0, 1}n) Note that Figure 34 is informal and omits information needed to fully specify OCB; see next for formal details of how graphs are specified Formally, we denote a graph G by a tuple (d, r, F, P, L), where d ∈ {2, 4} is the total number of IN and INI nodes (Enc and Dec graphs have d = 4; Tag graphs have d = 2), and r ∈ N is the total number of nodes|,Non-data,13
| Each node in the graph is numbered from 1 to r, and we require that if node i is a parent of node j then i < j (This ensures that G is acyclic) Let Nodes denote the power set of {1,  |,Non-data,13
|  , r}, and let Inst = {IN,   |,Non-data,13
| , TBC} be the set of instructions Then F : {1,   |,Non-data,13
| , r} → Inst gives the instruction of each node and P : {1,    , r} → Nodes gives the set of parents for each node|,Non-data,13
| We require that F (1) = F (2) = INI and F (r) = OUT For Enc and Dec graphs, we additionally require that F (3) = F (4) = IN, F (r − 2) = F (r − 3) = FIN, and F (r − 1) = OUT For Enc and Dec graphs, let S ⊂ {1,  |,Non-data,13
|  , r} be the set of all nodes corresponding to a TBC instruction Function L : S → Z specifies, for each such node i, whether the tweakable blockcipher is computed in the forward direction (if L(i) ≥ 0) or the reverse direction (if L(i) < 0) at that Figure 34: Graph representations for algorithms Enc (left), Dec (middle), and Tag (right) of OCB|,Non-data,13
| −1 K (G, T, Z1,    , Zd) proc EvalEK ,E (d, r, F, P, L) := G for i = d + 1 to r do if F (i) ∈ {DUP, OUT, FIN} then {p} := P (i); Zi := Zp elseif F (i) = XOR then {p1, p2} := P (i); Zi := Zp1 ⊕ Zp2 else // F (i) = TBC (cid:96) := L(i); (N, A, v) := T T ∗ := (N, A, v + ||(cid:96)||); {p} := P (i) if (cid:96) > 0 then Zi := EK (T ∗, Zp) else Zi := E−1 K (T ∗, Zp) return (Z1, |,Non-data,13
|   , Zr) Figure 35: Procedure to compute the value Zi of each node i in a graph G, given input Z1, |,Non-data,13
|   , Zd and tweak T  (Note that L(i) ≥ 0 for Enc graphs|,Non-data,13
|) Moreover, node6 ||L(i)|| determines the tweak at node i; ie, on input tweak (N, A, v), the tweak at node i is (N, A, v + ||L(i)||)|,Non-data,13
| Let G− = (d, r, F, P ) denote the unlabeled graph corre- sponding to a graph G In Section 32, we introduce a type system and show that one can reason about the security of an AE scheme by evaluating the scheme’s unlabeled graphs Fix some graph G, tweakable blockcipher E, and key K|,Non-data,13
| Given a tweak T and n-bit values for all INI/IN nodes in G, we can naturally define an n-bit value Zi associated with each node i in the graph We describe this formally as pro- cedure Eval in Figure 35, which shows how to compute Zi given values Z1,  |,Non-data,13
|  , Zd ∈ {0, 1}n and tweak T  32 A Type System for AE Schemes Let Types = {$,⊥, 0, 1} be a set of “types” we can assign to nodes|,Non-data,13
| Intuitively, ‘$’ indicates a node whose output value is (pseudo)random (when the key K for E is random and secret), whereas ‘⊥’ indicates a node whose output value is arbitrary (ie, potentially controlled by an attacker) Look- ing ahead, types ‘0’ and ‘1’ will be used to compare values on the same node in two different decryption queries using the same nonce and associated data; ‘0’ means the correspond- ing values are the same, and ‘1’ means they are different|,Non-data,13
| In Figure 36, we define a deterministic procedure Map that takes as input an unlabeled graph G−, pre-assigned types type1,   |,Non-data,13
| , typed ∈ Types for all the INI/IN nodes, and a boolean flag rand, and returns a map R that asso- ciates each node i with a pair (typei, ctr i) ∈ Types × N The procedure Map traverses the graph in topological or- 6While it might be conceptually simpler to use two different −1 instructions for EK and E K , instead of just a single TBC instruction with positive/negative labels, our approach is an optimization that prunes the search space when synthesizing schemes (cf Section 4) M3M1M2C1Σ C2C3tagM4C4τEKN,A,1EKN,A,2EKN,A,3EKN,A,4EKN,A,−4INIINOUTOUTINXORDUPDUPTBCTBCXORFININITBCOUTINIINOUTOUTINXORTBCTBCDUPDUPXORFIN87proc Map(G−, type1, |,Non-data,13
|   , typed, rand) (d, r, F, P ) := G−; maxCtr := 0 for i = 1 to d do if typei = $ then R(i) := ($, 1); maxCtr := 1 else R(i) := (typei, 0) if F (i) ∈ {FIN, OUT, DUP} then for i = d + 1 to r do elseif F (i) = TBC then {p} := P (i); R(i) := R(p) {p} := P (i); (x, ctr) := R(p) if x ∈ {1, $} or (rand = true) then maxCtr := maxCtr + 1; R(i) := ($, maxCtr) else // F (i) = XOR else R(i) := (x, ctr) {p1, p2} := P (i); (x, ctr) := R(p1); (y, ctr(cid:48)) := R(p2) // Assume that ctr ≥ ctr(cid:48) if (x, y) ∈ {(0, 0), (0, 1), (1, 0)} then R(i) := (x ⊕ y, ctr) elseif x = $ and ctr > ctr(cid:48) then R(i) := ($, ctr) else R(i) := (⊥, ctr) return R Figure 36: A procedure for generating a mapping R : {1, |,Non-data,13
|   , r} → Types×N for a given unlabeled graph der and assigns types to each node of the graph based on the instruction associated with that node and the types of its parents|,Non-data,13
| These types are used for probabilistic reason- ing about the underlying n-bit values on that node; eg, we show that if a node has type $ then the n-bit value of that node is (pseudo)random The ctr values are used as “times- tamps” for values output by TBC nodes in order to determine independence among values of type $|,Non-data,13
| Finally, the rand flag denotes whether the nonce/associated data are fresh For FIN, OUT, and DUP nodes, Map simply propagates the type of the parent node For TBC nodes, if the nonce or input is fresh then the output is (pseudo)random and independent of any prior random values, and so the node gets type $; otherwise, we propagate the type of the parent node For XOR nodes, we have several cases|,Non-data,13
| If the two input nodes x and y are typed typex and typey, respectively, with (typex, typey) ∈ {(0, 0), (0, 1), (1, 0)}, then we type the XOR node as typex ⊕ typey We briefly explain this reasoning The fact that typex, typey ∈ {0, 1} means there is a prior query using the same nonce and associated data If the two parents have type 0, indicating that the values computed at those nodes are equal in the two queries, then clearly the value computed at the XOR node is also equal in the two queries, and thus that node gets type 0|,Non-data,13
| On the other hand, if one parent is typed 0 and the other is typed 1, then the value computed at the XOR node will be different from the corresponding value in the prior query, and thus the XOR node is assigned type 1 If (typex, typey) = (1, 1) then we cannot say anything definitive and thus Map assigns type ⊥ to the XOR node Finally, suppose input node x has type $ Here we utilize the ctr values|,Non-data,13
| If the ctr value at x is different from the ctr value of y, then the (random) value of x is independent of the value of y, and hence we assign the XOR node type $ In the next two lemmas we show how determining the types for an unlabeled graph can be used to reason about the values that one obtains when evaluating the labeled graph We first show that all values typed $ by Map (when inputs are typed ⊥ and hence may be under arbitrary control of the adversary) are indeed random when computed using Eval and a truly random tweakable permutation Lemma 3|,Non-data,13
|1 Let G = (d, r, F, P, L) and let n ≥ 1 be an integer Set R := Map(G−,⊥,  |,Non-data,13
|  ,⊥, true) Fix arbitrary Z1,  |,Non-data,13
|  , Zd ∈ {0, 1}n and T ∈ T , and consider the following probabilistic experiment: 1 Choose f ←$ Perm(T , n) 2|,Non-data,13
| Run (Z1,    , Zr) := Evalf,f−1 (G, T, Z1, |,Non-data,13
|   , Zd) Then for any j with R(j) = ($, ctr j), the random variable Zj is uniform and independent of {Zi || ctr i < ctr j}|,Non-data,13
| Suppose both claims hold for all i ≺ j Proof First note that for any node i and its parent p, we have ctr i ≥ ctr p Thus, there is a topological ordering s1, |,Non-data,13
|   , sr of the nodes such that the sequence ctr s1 ,  |,Non-data,13
|  , ctr sr is non-decreasing, and si = i for i ≤ d Write i ≺ j if node i precedes node j in this topological order We prove by induction (with respect to ≺) that for all j we have (i) typej ∈ {⊥, $} and (ii) if typej = $ then Zj is uni- form and independent of {Zi || ctr i < ctr j}|,Non-data,13
| Note that these claims are trivially true when j ≤ d, because then typej = ⊥ If F (j) ∈ {FIN, OUT, DUP} then let p ≺ j be the parent of j Since (typej, ctr j) = (typep, ctr p), the claims follow for j If F (j) = TBC then typej = $, proving claim (i)|,Non-data,13
| Since f ←$ Perm(T , n), and Eval never repeats a tweak in query- ing f , we see that random variable Zj is uniform and inde- pendent of {Zi || ctr i < ctr j}, justifying claim (ii) Finally, say F (j) = XOR Let i and t be the parents of j, and assume t ≺ i Then typet, typei ∈ {⊥, $}, and thus so is typej, proving claim (i)|,Non-data,13
| For claim (ii), note that typej = $ only if typei = $ and ctr i > ctr t Since ctr j = ctr i, the claim follows The next lemma proves a similar property for pairs of queries Consider the query (Y1, |,Non-data,13
|   , Yr) := Evalf,f−1 (G, T, Y1,  |,Non-data,13
|  , Yd) followed by query (Z1,   |,Non-data,13
| , Zr) := Evalf,f−1 (G, T, Z1,    , Zd), where each Zi is either chosen equal to Yi (and thus typei = 0), distinct from Yi (and thus typei = 1), or uniformly (and thus typei = $)|,Non-data,13
| We show that for all nodes j of type $ assigned by Map(G−, type1,    , typed, false), the statistical difference between Zj and uniform is small, even conditioned on all the {Yi}|,Non-data,13
| Lemma 32 Let G = (d, r, F, P, L) and let n ≥ 1 be an integer Fix arbitrary Y1, |,Non-data,13
|   , Yr ∈ {0, 1}n and T ∈ T such that the set S = {f ∈ Perm(T , n) || (Y1,  |,Non-data,13
|  , Yr) = Evalf,f−1 (G, T, Y1,   |,Non-data,13
| , Yd)} is non-empty For each i ≤ d, choose Zi and typei in one of the following ways: (i) Zi = Yi and typei = 0, (ii) Zi (cid:54)= Yi and typei = 1, (iii) Zi ←$ {0, 1}n and typei = $ Let R = Map(G−, type1,  |,Non-data,13
|  , typed, false) Consider the following probabilistic experiment: 1 Choose f ←$ S|,Non-data,13
| 2 Run (Z1,   |,Non-data,13
| , Zr) := Evalf,f−1 (G, T, Z1,    , Zd)|,Non-data,13
| Then for any j with R(j) = ($, ctr j), the statistical differ- ence between the random variable Zj and uniform, condi- tioned on {Zi || ctr i < ctr j} and all the {Yi}, is at most 2 · ctr j/2n Proof As in the previous lemma, there is a topological ordering s1,  |,Non-data,13
|  , sr of the nodes such that ctr s1 ,   |,Non-data,13
| , ctr sr is non-decreasing and si = i for i ≤ d Write i ≺ j if i precedes j in this topological order We prove by induction (with 882 are unlabeled graphs of Enc and Tag, respectively // Check that output of Tag is random proc Priv(G− // G− 1 ; (d2, r2, F2, P2) := G− 2 , ⊥, ⊥, true); (type, ctr) := R(r2) 1 , G− 2 ) 1 and G− 01 (d1, r1, F1, P1) := G− 02 R := Map(G− 03 if type (cid:54)= $ then return false 04 R := Map(G− 1 , ⊥, ⊥, ⊥, ⊥, true) 05 (type1, ctr1) := R(r1 − 1); (type2, ctr2) := R(r1) 06 return ((type1 = $) ∧ (type2 = $) ∧ (ctr1 (cid:54)= ctr2)) 2 // Check that output blocks of Enc are random and independent proc Auth(G− 1 and G− // G− 1 , G− 2 ) 2 are unlabeled graphs of Dec and Tag, respectively|,Non-data,13
| 1 ; (d2, r2, F2, P2) := G− 11 (d1, r1, F1, P1) := G− 12 R := Map(G− 2 , ⊥, ⊥, true); (type, ctr) := R(r2) 13 if type (cid:54)= $ then return false 2 // Check that output of Tag is random when the nonce/associated data are fresh // Check that if there are two executions of Dec with the same initial state // but different input blocks, then the first half of the final state is random 14 for (x, y) ∈ {(0, 1), (1, 0), (1, 1)} do 15 R := Map(G− 16 1 , 0, 0, x, y, false); (type, ctr) := R(r1 − 3) if type (cid:54)= $ then return false // Check that if the first half of the initial state input to Dec is random, // then the first half of the final state output by Dec is random 17 for x, y, z ∈ {0, 1} do 18 R := Map(G− 19 1 , $, x, y, z, false); (type, ctr) := R(r1 − 3) if type (cid:54)= $ then return false // Check that if there are two executions of Tag in which the first halves of the // initial states are different, then the resulting tags are random and independent 20 for x ∈ {0, 1} do 21 R := Map(G− 22 23 return true if type (cid:54)= $ then return false 2 , 1, x, false); (type, ctr) := R(r2) Figure 37: Tests to determine if a scheme Π satisfies privacy and authenticity, respectively respect to ≺) that for all j: (i) if typej = 0 then Zj = Yj, (ii) if typej = 1 then Zj (cid:54)= Yj, and (iii) if typej = $ then the statement of the lemma holds These claims all trivially hold when j ≤ d|,Non-data,13
| Suppose that all three of the claims hold for all i ≺ j If F (j) ∈ {FIN, OUT, DUP} then let p ≺ j be the parent of j Since (typej, ctr j) = (typep, ctr p), the claims follow easily If F (j) = XOR, let t, i ≺ j be the parents in this case of j, and assume t ≺ i|,Non-data,13
| Note that typej ∈ {0, 1} only if typei, typet ∈ {0, 1} and at most one of these values is 1, in which case the claims all hold On the other hand, typej = $ only if typei = $ and ctr i > ctr t, in which case the claims also follow Finally, if F (j) = TBC then let i be the parent of j Let (cid:96) = L(j), and let T = (N, A, v)|,Non-data,13
| Then Yj = f (T ∗, Yp) and Zj = f (T ∗, Zp), where T ∗ = (N, A, v + ||(cid:96)||) Consider the following cases: Case 1 typei ∈ {0,⊥} Then (typej, ctr j) = (typei, ctr i) and the claims follow|,Non-data,13
| Case 2 typei = 1 Then typej = $ and ctr j ≥ 1 First, since ctr t ≥ ctr j when t is a descendant of j, we see that no node t with ctr t < ctr j is a descendant of j|,Non-data,13
| Next, since Zi (cid:54)= Yi and we use a different tweak for each TBC node, Zj ←$ {0, 1}n\{Yj} is independent of {Yt || t ≤ r} and {Zt || ctr t < ctr j} which occurs except with probability at most (2ctr i + 1)/2n, then Zj is 2−n-close to uniform (even conditioned on all the {Yt} values and {Zt || ctr t < ctr j}) Hence, overall, Zj is (2ctr i + 2)/2n-close to uniform (conditioned on {Yt || t ≤ r} and {Zt || ctr t < ctr j}) and the statement of the lemma follows since we have ctr j ≥ ctr i + 1 3|,Non-data,13
|3 Verifying Privacy and Authenticity We use Lemmas 31 and 32 to automatically check if a candidate AE scheme is secure in the sense of both privacy and authenticity Specifically, Figure 3|,Non-data,13
|7 shows procedures Priv and Auth to check for privacy and authenticity, respec- tively, of an AE scheme Π Intuitively, for privacy we verify that the tag and all the ciphertext blocks output by the scheme are random and in- dependent (namely, have type $ and distinct counter values) even when the inputs—that is, the message blocks—are con- trolled by the adversary (namely, have type ⊥) We remark that the values of ctr assigned to nodes by the map R output by Map depend on the topological order in which Map tra- verses the input graph; see Figure 38 for an example|,Non-data,13
| Thus, there are schemes which, depending on the order in which the graph is traversed, are accepted or (incorrectly) rejected by Priv (due to the ctr values for the OUT nodes being equal) This shows that the test is sound but not complete7 Case 3 typei = $|,Non-data,13
| Then typej = $ By the induction hypothesis, Zi is (2ctr i/2n)-close to uniform (even condi- tioned on {Yt || t ≤ r} and {Zt || ctr t < ctr i}) If Zi (cid:54)= Yi, 7In the full version [13] we describe a technique for generat- ing attacks given a scheme which fails the tests of Figure 37|,Non-data,13
| Looking ahead, we find only a handful of schemes which we 89Figure 38: Left: A scheme that can be accepted or (incorrectly) rejected by Priv, depending on the topological ordering of the nodes Middle left: The corresponding Enc graph Middle right: The (type, ctr) pairs in each node of the Enc graph if the left TBC node is visited first|,Non-data,13
| The graph is (incorrectly) rejected because the two OUT nodes both have ctr = 2 Right: The (type, ctr) pairs in each node of the Enc graph if the right TBC is visited first This time, the graph is accepted because the two OUT nodes have different ctr values The authenticity check for a scheme (Enc, Dec, Tag) is more complicated|,Non-data,13
| We now argue informally that if a scheme passes the checks of algorithm Auth (cf Figure 37), then the scheme satisfies authenticity To see this, consider a candidate forgery (N, A, C) output by an adversary|,Non-data,13
| First suppose there was no prior query (N, A, (cid:63)) to the encryp- tion oracle Auth verifies that the Tag algorithm outputs a random tag when the tweak for the TBC node in Tag was not used previously; thus, the candidate forgery will be in- valid except with probability 2−τ  (Recall that τ is the tag length) Next, consider the case that there was a prior en- cryption query (N, A, M ), and let C(cid:48) be the corresponding ciphertext|,Non-data,13
| Then C (cid:54)= C(cid:48); otherwise (N, A, C) is not a valid forgery If C and C(cid:48) only differ in their tags, the candidate forgery must be invalid because the tag is uniquely deter- mined by N , A, and the rest of the ciphertext Otherwise, consider the first pair of blocks in which C and C(cid:48) differ Auth verifies that (i) the first half of the final state produced by Dec when run on those blocks is random, (ii) Dec has the property that if the first half of its initial state is random, then the first half of the final state it outputs is random, and (iii) Tag has the property that if the first half of its initial state is random, then the tag it outputs is random8|,Non-data,13
| Taken together, these imply that the tag will be random, and hence the candidate forgery will be invalid except with probability 2−τ  To demonstrate the strength of our approach, consider a modified version of the OTR scheme [21] The original OTR scheme (cf Figure 3|,Non-data,13
|9) is secure, which our automated tests confirm If, however, the scheme is changed so that Σ is computed as the checksum of the odd blocks M1 ⊕ M3 ⊕ ··· , rather than the even blocks, then it becomes insecure And, indeed, the modified scheme does not pass our tests Namely, on input (0, 0, 1, 0) to Map we find that the required FIN node is typed 1 instead of $|,Non-data,13
| Proofs of correctness We now prove that schemes that pass our tests are secure We first show that if Priv re- turns true when given the (unlabeled) graphs corresponding to the Enc and Tag components of some AE scheme, then can neither prove secure nor find concrete attacks for; see Section 4 8Although here we are considering just the first half of the final/initial state, if one switches to the second half then one will get the same set of synthesized schemes: if one changes the topological ordering in the graphs so that the first FIN/INI node becomes the second one, and vice versa, then the scheme remains the same|,Non-data,13
| Figure 39: The OTR scheme, illustrated for a four- block message M1 ··· M4 Here, Σ is the checksum of the even blocks M2 ⊕ M4 that scheme satisfies privacy when instantiated with a secure tweakable blockcipher|,Non-data,13
| − 1 , G − 2 ) = true, where G Theorem 33 Let Π[E] = (K,E,D) be an AE scheme − for which Priv(G 2 are the unlabeled graphs for algorithms Enc and Tag of Π, respec- tively Then for any adversary A, there is an adversary B E (B)|,Non-data,13
| Adversary B has the same with Advpriv running time as A and makes at most (Cost(Π) + 1) · σ/2 queries, where σ is the number of message blocks in the queries of A Π[E](A) ≤ Adv(cid:103)prp − 1 and G Proof Adversary B runs A For each of A’s queries (N, A, M ), adversary B runs the encryption scheme Π[E] on (N, A, M ) with each call to EK replaced by a query to B’s oracle, and returns the ciphertext to A|,Non-data,13
| Finally, B out- puts the same guess as A Let Π[π] be the ideal variant of Π[E], where calls to EK are replaced by corresponding queries to π, with π ←$ Perm(T , n) It suffices to show that Advpriv Π[π](A) = 0 Consider experiments H1–H4 in Figure 3|,Non-data,13
|10 The adver- sary has oracle access to the encryption scheme of Π[π] in ex- periment H1, and oracle access to $(·,·,·) in experiment H4 Experiment H2 is identical to H1, except that we re-sample π ←$ Perm(T , n) each time we use Enc or Tag Since a tweak 2 ⇒ true]|,Non-data,13
| In to π is never repeated, Pr[HA experiment H3, instead of calling Tagπ(T, X) to get the tag, we sample the tag at random Considering lines 02–03 of − Priv (and the fact that Priv(G 2 ) = true) in conjunction with Lemma 31 shows that the string V := Tagπ(T, X) is uniform and so experiments H2 and H3 are identical Fi- nally, experiment H4 is identical to H3, except that instead of calling Encπ(T, X, M2i−1M2i) to get the blocks C2i−1C2i of the ciphertext, we sample them at random|,Non-data,13
| Consider- 1 ⇒ true] = Pr[HA − 1 , G INIINFINOUTINDUPDUPTBCTBCXOROUTXORDUPXOR⊥,0⊥,0⊥,0$,2⊥,0⊥,0⊥,0$,1$,2$,2$,2$,2$,2⊥,0⊥,0⊥,0⊥,0$,2⊥,0⊥,0⊥,0$,2$,1$,1$,1$,2$,1⊥,0M1M2C1C2M3M4C3C4tagτM1M2C1C2M3M4C3C4Σ tagτ90// Experiments H1, H2 // ||Mi|| = n proc Encrypt[π](N, A, M ) M1 · · · M2m := M ; X := 02n; v := 1 for i = 1 to m do T := (N, A, v); π ←$ Perm(T , n) (Y, C2i−1C2i) := Encπ(T, X, M2i−1M2i) v := v + Cost(Π); X := Y π ←$ Perm(T , n); T := (N, A, 1 − v); V := Tagπ(T, X) return C1 · · · C2m (cid:107) V [1, τ ] // Experiments H3, H4 // ||Mi|| = n proc Encrypt[π](N, A, M ) M1 · · · M2m := M ; X := 02n; v := 1 for i = 1 to m do T := (N, A, v); π ←$ Perm(T , n) (Y, C2i−1C2i) := Encπ(T, X, M2i−1M2i) C2i−1C2i ←$ {0, 1}2n v := v + Cost(Π); X := Y T := (N, A, 1 − v); V ←$ {0, 1}n return C1 · · · C2m (cid:107) V [1, τ ] Figure 310: Experiments H1–H4 in the proof of The- orem 33 Experiments H2 and H4 include the corre- sponding boxed statements, but H1 and H3 do not|,Non-data,13
| − ing lines 04–05 of Priv (and the fact that Priv(G 2 ) = true) in conjunction with Lemma 31 shows that the out- put blocks of Encπ(T, X, M2i−1M2i) are uniform and in- dependent (and this is true even conditioned on all prior ciphertext blocks) Hence H3 and H4 are identical, and Advpriv 1 ⇒ true] − Pr[HA 4 ⇒ true] = 0 Π[π](A) = Pr[HA − 1 , G ±(cid:103)prp Next, in Theorem 3|,Non-data,13
|4, we show that if Auth in Figure 37 returns true when given graphs corresponding to the Dec and Tag components of some AE scheme, then that scheme satisfies authenticity when instantiated with a secure tweak- able blockcipher (Examination of the proof shows that if −1 algorithm Dec does not use E K , as in the case of OTR, then (B) in Theorem 34 can be weakened to the term Adv E (B)|,Non-data,13
|) Adv(cid:103)prp Theorem 34 Let Π[E] = (K,E,D) be an AE scheme − such that Auth(G 2 are the un- labeled graphs for algorithms Dec and Tag of Π, respectively Then for any adversary A, there is an adversary B with (B), Advauth where (cid:96) is the number of blocks in the forgery output by A|,Non-data,13
| Adversary B has the same running time as A and makes at most (Cost(Π)+1)·σ/2 queries, where σ is the total number of message blocks in the queries of A Π[E](A) ≤ 2−τ + (cid:96) · (Cost(Π) + 2)/2n + Adv − 2 ) = true, where G ±(cid:103)prp − 1 , G E E − 1 , G Proof Adversary B runs A For each of A’s encryp- tion queries, B runs the encryption scheme of Π[E] but with each call to EK replaced by a query to B’s first oracle, and returns the ciphertext to A|,Non-data,13
| When A outputs a forgery (N, A, C), adversary B runs the decryption scheme of Π[E] −1 on (N, A, C), but with each call to EK /E K replaced by a query to B’s oracles Adversary B returns 1 if A output a valid forgery, and returns 0 otherwise Let Π[π] be the ideal −1 K are replaced by cor- variant of Π[E], where calls to EK /E responding queries to π/π−1, with π ←$ Perm(T , n) It suf- Π[π] (A) ≤ 2−τ + (cid:96)(Cost(Π) + 2)/2n|,Non-data,13
| fices to show that Advauth Consider experiments H1–H3 in Figure 311 In H1, the adversary has oracle access to the encryption and decryption proc Decrypt[π](N, A, C) if ||C|| (cid:54)≡ τ (mod 2n) then return ⊥ C1 · · · C2m (cid:107) tag := C // ||Ci|| = n and ||tag|| = τ X := 02n; v := 1 for i = 1 to m do // Experiments H1, H2 (T, X, C2i−1C2i) T := (N, A, v) (Y, M2i−1M2i) := Decπ,π−1 v := v + Cost(Π); X := Y π ←$ Perm(T , n) T := (N, A, 1 − v); V := Tagπ(T, X) if tag (cid:54)= V [1, τ ] then return ⊥ return M1 · · · M2m proc Decrypt[π](N, A, C) if ||C|| (cid:54)≡ τ (mod 2n) then return ⊥ C1 · · · C2m (cid:107) tag := C // ||Ci|| = n and ||tag|| = τ X := 02n; v := 1 for i = 1 to m do // Experiment H3 T := (N, A, v) (Y, M2i−1M2i) := Decπ,π−1 v := v + Cost(Π); X := Y V ←$ {0, 1}n if tag (cid:54)= V [1, τ ] then return ⊥ return M1 · · · M2m (T, X, C2i−1C2i) Figure 311: Experiments H1–H3 in the proof of The- orem 3|,Non-data,13
|4 Experiment H2 includes the correspond- ing boxed statement, but experiment H1 does not Each experiment also has a procedure Encrypt[π], implementing the encryption algorithm of Π[π], that is not shown for simplicity − 1 , G schemes of Π[π]|,Non-data,13
| Experiment H2 is identical to H1, except that when running the decryption algorithm, we re-sample π ←$ Perm(T , n) before using it in Tag Experiment H3 is identical to H2, except that instead of using Tag to generate the tag, we sample the tag uniformly Let (N, A, C) be the forgery output by A Suppose there is no encryption query (N, A, M(cid:48)) with ||M(cid:48)|| = ||C|| − τ |,Non-data,13
| Since decryption of the forgery query involves calling Tag with a tweak that has never been used before, we have Pr[A forges in H1] = Pr[A forges in H2] Considering lines − 12–13 of Auth (and the fact that Auth(G 2 ) = true) in conjunction with Lemma 31 shows that the string V := Tagπ(T, X) is uniform Thus Pr[A forges in H2] = Pr[A forges in H3]|,Non-data,13
| The probability that A can forge in H3 is at most 2−τ  Hence Advauth Now, suppose that there is an encryption query (N, A, M(cid:48)) such that ||M(cid:48)|| = ||C||−τ  (Note that there can be at most one such query, since the attacker is not allowed to re-use a nonce value in two encryption queries) Let C(cid:48) be the correspond- ing ciphertext output by this encryption query, and let C = C1 ··· C2m (cid:107) tag and C(cid:48) = C(cid:48) j for every j ≤ 2m then tag and tag(cid:48) must be different and thus, since Tag is deterministic, the forgery is invalid|,Non-data,13
| Otherwise, take the least index r ≤ m such that C2r−1C2r (cid:54)= C(cid:48) 2r−1C(cid:48) 2r Consider experiments P1,   |,Non-data,13
| , Pm−r+4 in Figure 312 In P1, the adversary has two oracles: Encrypt and Decrypt The first implements the encryption scheme of Π[π], and the sec- ond implements the decryption scheme of Π[π] but returns false if the decrypted value is ⊥ and returns true otherwise|,Non-data,13
| Let S be the subset of Perm(T , n) such that for any f ∈ S and query (T, X) that Encrypt[π](N, A, M(cid:48)) makes to π, Π[π] (A) ≤ 2−τ in this case 2m (cid:107) tag(cid:48) If Cj = C(cid:48) 1 ··· C(cid:48) 91// Experiments P1, P2 proc Decrypt[π](N, A, C) if ||C|| (cid:54)≡ τ (mod 2n) then return ⊥ C1 · · · C2m (cid:107) tag := C // ||Ci|| = n and ||tag|| = τ X := 02n; v := 1 for i = 1 to m do T := (N, A, v); π ←$ S (Y, M2i−1M2i) := Decπ,π−1 v := v + Cost(Π); X := Y (T, X, C2i−1C2i) T := (N, A, 1 − v); π ←$ S; V := Tagπ(T, X) if tag (cid:54)= V [1, τ ] then return false return true // Experiments P3+j , for 0 ≤ j ≤ m − r + 1 proc Decrypt[π](N, A, C) if ||C|| (cid:54)≡ τ (mod 2n) then return ⊥ C1 · · · C2m (cid:107) tag := C // ||Ci|| = n and ||tag|| = τ X := 02n; v := 1 for i = 1 to m do T := (N, A, v); π ←$ S (Y, M2i−1M2i) := Decπ,π−1 if r ≤ i ≤ r + j then Y ←$ {0, 1}n v := v + Cost(Π); X := Y π ←$ S; V := Tagπ(T, X) if j = m − r + 1 then V ←$ {0, 1}n if tag (cid:54)= V [1, τ ] then return false return true (T, X, C2i−1C2i) Figure 312: Experiments P1, |,Non-data,13
|   , P4+m−r in the proof of Theorem 34|,Non-data,13
| Experiment P2 includes the corre- sponding boxed statement, but P1 does not Each experiment also has a procedure Encrypt[π], im- plementing the encryption algorithm of Π[π], that is not shown for simplicity Here S is the set of f ∈ Perm(T , n) such that for any query (T, X) that Encrypt[π](N, A, M(cid:48)) makes to π, it holds that f (T, X) = π(T, X) we have f (T, X) = π(T, X)|,Non-data,13
| Experiment P2 is identical to P1, except that in procedure Decrypt, each time we call Dec or Tag we resample π ←$ S Since in the forgery query we do not repeat the tweak of any encryption query other than (N, A, M(cid:48)), and π and π−1 are called with distinct tweaks, we have Pr[A forges in P1] = Pr[A forges in P2] In experi- ment P3 we sample Y uniformly instead of computing Y := Decπ,π−1 (T, X, C2r−1C2r) Considering lines 14–16 of Auth − (and the fact that Auth(G 2 ) = true) in conjunction with Lemma 3|,Non-data,13
|2, we have Pr[A forges in P2]− Pr[A forges in P3] ≤ 2Cost(Π)+2 For j = 1,    , m − r, experiment P3+j is identical to P2+j, except that we sample Y uniformly instead of com- puting Y := Decπ,π−1 (T, X, C2r+2j−1C2r+2j)|,Non-data,13
| Considering − lines 17–19 of Auth (and the fact that Auth(G 2 ) = true) in conjunction with Lemma 32, we conclude that Pr[A forges in P2+j] − Pr[A forges in P3+j] ≤ 2Cost(Π)+2 − 1 , G − 1 , G 2n   Experiment Pm−r+4 is identical to Pm−r+3 except that we sample V uniformly when checking the validity of the forgery instead of computing V := Tagπ(T, X)|,Non-data,13
| Let X(cid:48) be the state used by Tag in Encrypt[π](N, A, M(cid:48)) If X[1, n] (cid:54)= X(cid:48)[1, n], which happens with probability at least 1 − 2−n, then applying Lemma 32 to lines 20–22 of procedure Auth, we have Pr[A forges in Pm−r+3]−Pr[A forges in Pm−r+4] ≤ 2n 2 2n  Finally, Pr[A forges in Pm−r+4] ≤ 2−τ |,Non-data,13
| Summing up, 2(m − r + 1)(Cost(Π) + 1) + 3 Advauth Π[π] (A) ≤ 2 ≤ 2 −τ + −τ + 2n (cid:96)(Cost(Π) + 2) 2n  To summarize, Theorems 33 and 34 show that if the graphs induced by a given scheme Π satisfy Priv and Auth as defined in Figure 3|,Non-data,13
|7, then Π is a secure AE scheme 4 IMPLEMENTATION AND RESULTS We have implemented the Priv and Auth algorithms de- scribed in Section 3, and used them to synthesize AE schemes The code is written in OCaml and available at https://github|,Non-data,13
|com/amaloz/ae-generator Our system has two modules: an analysis module that, given graphs cor- responding to an AE scheme, verifies whether the scheme is secure, and a synthesis module that synthesizes AE schemes by enumerating candidate AE schemes and using the anal- ysis module to see if they are secure We describe these components below, where throughout this section, the term graph denotes an unlabeled graph Analyzer|,Non-data,13
| The analysis module takes as input a representa- tion (in a stack-based language) of the Dec and Tag graphs; the stack-based language makes it easy to both convert the inputs into their respective graphs as well as to synthesize schemes We first derive a graph for the Enc algorithm given the graph for the Dec algorithm, as described below Given graphs for the Enc, Dec, and Tag algorithms, we can then run the privacy and authenticity checks described in Fig- ure 37 to check security of the scheme|,Non-data,13
| Our analyzer is able to verify simplified variants of OCB [23], XCBC [12], COPA [3], OTR [21], and CCM [10], among others Deriving the Enc graph We implement an algorithm Reverse that, given a Dec graph, computes a corresponding Enc graph if one exists The basic idea is to swap the IN and OUT nodes of the input graph (recall that IN and OUT nodes in the Dec graph denote ciphertext blocks and plaintext blocks, respectively, whereas IN and OUT nodes in the Enc graph are flipped), and then selectively reverse the edges to ensure that each node has correct ingoing/outgoing degrees|,Non-data,13
| Deriving the Enc graph is thus simple if there is at most one path from an IN node to an OUT node and these paths do not cross, as in the case of OCB However, in other schemes, such as OTR, each IN node may have multiple paths to each OUT node We handle this as described next − 1 |,Non-data,13
| In G1, rename IN nodes as OUT nodes, and OUT nodes as IN nodes; let G2 be the resulting graph Reverse then assigns direction to the edges of G2 such that each node has correct − 2 is output ingoing/outgoing degrees; the resulting graph G (If no assignment is possible, then the output is ⊥) 1 , let G1 be the undirected graph of G − On input G To implement this idea efficiently, we color each node ei- ther “red” or “blue”, where red nodes denote nodes that have already been processed, and blue nodes denote unprocessed nodes|,Non-data,13
| Starting from G2, we initially color IN and INI nodes red and all other nodes blue We repeatedly iterate over the blue nodes until we reach a fixed point, where in each iter- ation we assign direction to some edges and re-color some nodes red If a fixed point is reached before all nodes have been colored red, we return ⊥; otherwise, we return G2, 92which represents the reversed graph If the graph G2 has r nodes then we have at most r iterations with each iteration taking O(r) time|,Non-data,13
| In each iteration, we process each blue node x as follows Let ord(x) = 2 if x is an XOR node, and let ord(x) = 1 otherwise If there are exactly ord(x) red neighbors of x then (1) for each such neighbor y, assign the direction y → x, and (2) color x red Note that in each step we ensure that the current node x has the correct ingoing degree if we color it red|,Non-data,13
| We never assign an ingoing edge to x in any other step Hence when there are no blue nodes, each node in the directed graph has the correct ingoing/outgoing degrees We prove in the full version [13] that Reverse is sound; namely, that if running Reverse on a Dec graph produces an Enc graph, then Dec is a correct decryption algorithm for Enc As a side note, the Reverse algorithm allows us to easily check if a scheme is inverse-free (i|,Non-data,13
|e, the scheme only uses the forward direction of the TBC), which is important when constructing hardware realizations of AE schemes due to the potential savings in chip space, among other benefits [15, 21] After running Reverse, we can check if the parent nodes for all the TBC nodes in the Enc and Dec graph are the same; if so, the scheme is inverse-free Synthesizer|,Non-data,13
| We synthesize schemes as follows Fixing a Tag graph, we enumerate all possible Dec graphs of a given size, pruning out “uninteresting” schemes such as ones with two (or more) TBC nodes chained together, and feed each pair of (Dec, Tag) graphs to our analysis module To generate the Dec graph, we start from a graph containing just the IN and INI nodes, and add nodes and their corresponding edges until the given size bound is reached If the resulting graph is “well-formed” (i|,Non-data,13
|e, there are no “dangling” edges and no loops), we derive the corresponding Enc graph as discussed above and run the analysis module on the result Unfortunately, this approach is prohibitively expensive as described, especially as the size bound increases Thus, we use several optimizations to speed up the process|,Non-data,13
| Firstly, instead of synthesizing graphs with FIN and OUT nodes, we replace these with “terminal” nodes Upon de- riving a well-formed graph, we replace the “terminal” nodes with all possible permutations of FIN and OUT nodes and check security of each Thus we no longer need to explore the search space for each FIN and OUT node; instead, we explore the search space once using a “terminal” node, and later replace the “terminal” node with all possible combi- nations of FIN and OUT nodes Likewise, we can apply this same idea to INI and IN nodes by introducing a “start” node|,Non-data,13
| Secondly, we observe that AE schemes like OCB, COPA, and OTR do not utilize one of the INI nodes in the sense that they simply output the input value directly Thus, we can remove two nodes from the synthesis by only synthesizing schemes containing one INI and FIN node The drawback of this optimization is that it misses schemes such as XCBC and CCM which do in fact use both INI nodes; however, it greatly speeds up synthesis All the results that follow use this optimization|,Non-data,13
| (It would, of course, be possible to synthesize schemes without using this optimization) Results Using the optimizations described above, we ran our synthesizer to find AE schemes with Dec and Enc graphs of sizes between twelve and sixteen (we found no AE schemes with size less than twelve) Note that our synthesizer does # 12 13 14 15 16 13 (0) 142 (0) 582 (2) 2826 (54) 3090 (—) 13 0 171 40 66 290 7 0 48 (4) 18 25 (4) 5 0 5 6 1 98 (8) 17 47 sec 4|,Non-data,13
3 min 242 min 28 hours 3 hours∗ Unique “Optimal” WP SP Time Total 6653 Figure 41: Synthesis results,Non-data,13
| The first column shows the number of instructions in the Dec graph of the given scheme; the second column the number of secure (and unique) schemes, with the number in parentheses denoting the number of schemes in which the security check fails but we cannot auto- matically find a concrete attack; the third column the number of (secure) schemes that are “optimal”, ie, having two TBC nodes per Dec graph; the fourth column the number of “optimal” weakly paralleliz- able schemes, with the number in parentheses de- noting the weakly parallelizable schemes which only use the forward direction of the TBC; the fifth col- umn the number of “optimal” strongly parallelizable schemes; and the final column the total synthesis time, where an asterisk indicates that we halted ex- ecution after the given time not remove duplicate schemes|,Non-data,13
| In addition, there are many “equivalent” schemes in the sense that one is the same as another except with the outputs and/or inputs flipped We thus developed a heuristic to remove duplicate and “equiv- alent” schemes as follows Let F (·,·,·) be the encrypt op- eration of a given scheme, where the first argument is the INI input (recall we consider the simplified variant where we only use one INI node) and the other arguments are the IN inputs Choosing arbitrary but fixed inputs X, M1, and M2, we compute Y (cid:107)C1(cid:107)C2 := F (X, M1, M2) and Y (cid:48)(cid:107)C(cid:48) 2 := F (X, M2, M1)|,Non-data,13
| We maintain a table of existing ciphertexts; if any of Y C1C2, Y C2C1, Y (cid:48)C(cid:48) 1 exists in the table, we discard the scheme as a “duplicate”; otherwise, we add each of these to the table and continue 2, or Y (cid:48)C(cid:48) 1(cid:107)C(cid:48) 1C(cid:48) 2C(cid:48) Figure 41 shows the results The experiments were run on a commodity laptop; because of the long running time for synthesizing schemes of size sixteen, we stopped the synthe- sis after three hours for this size|,Non-data,13
| Due to the large number of discovered schemes, we developed two algorithms to prune the result space The first simply filters out all schemes Π such that Cost(Π) > c for some integer c In Figure 41 we set c = 2, thus pruning out all non-“rate-1” schemes; this removes 95% of the found schemes|,Non-data,13
| Our second algorithm checks whether a scheme is paral- lelizable, an important criterion for AE schemes Note that we can view the encryption of a message M = M1 ··· M2m as a single graph constructed from m Enc graphs G1,   |,Non-data,13
| , Gm, where the FIN nodes of Gi coincide with the INI nodes of Gi+1 We can then assign a “depth” to each node in this graph as follows: (1) The INI nodes in G1 and the IN nodes in {Gi} get a depth of 0; (2) For each node x, let t be the maximum depth of x’s parent(s); if x is a TBC node then depth(x) = t + 1; otherwise depth(x) = t (Intuitively, depth(x) represents the latency, in terms of the number of TBC calls, of computing the value at node x) We can use the same idea to compute a “depth” for decryption|,Non-data,13
 93Scheme Enc (cycles/byte) Dec (cycles/byte) OCB 1 2 3 07122 ± 00072 07253 ± 0,Non-data,13
0055 07116 ± 00025 08139 ± 0,Non-data,13
0121 07650 ± 00025 07485 ± 0,Non-data,13
0047 07643 ± 00023 27566 ± 0,Non-data,13
|0010 Figure 43: Performance results of OCB and the three synthesized schemes in Figure 42 (Scheme 1 denotes the top scheme, Scheme 2 the middle scheme, and Scheme 3 the bottom scheme) We re- port the time for encryption and decryption when processing a 4096-bit message with empty associated data, along with the 95% confidence intervals over 100 runs of each scheme|,Non-data,13
| The experiments were run on a 4-core 290 GHz Intel Core i5-4210H CPU with TurboBoost disabled is strongly parallelizable; for the third scheme, however, de- cryption cannot be parallelized) We implemented all three schemes and compared their performance with that of an optimized implementation of OCB by Krovetz9 using AES- NI; see Figure 4|,Non-data,13
|3 (Note that the results in Figure 43 are preliminary timing numbers; the purpose of these experi- ments is to show that our schemes are competitive with, not necessarily better than, OCB) We find that the encryption procedure for all four schemes is comparable|,Non-data,13
| However, the decryption procedure of the third synthesized scheme is no- ticeably slower than the others This is because decryption for this scheme is not parallelizable; namely, to decrypt ci- phertext block Ci we need plaintext block Mi−1 In addition, among the weakly parallelizable schemes, we found eight schemes which are inverse-free (we found no such schemes for strongly parallelizable schemes) The schemes of size fourteen that we found use one fewer XOR instruction than OTR, the fastest known inverse-free AE scheme we are aware of|,Non-data,13
| We also ran our attack generation algorithm over schemes of size 12–15 and found that the number of schemes where no attack could be found closely matched the number of schemes our analysis found secure, thus pointing to the fact that while our analysis is not sound, it appears to capture most secure schemes; see the full version [13] for details We remark that our tool currently takes a given bound S and enumerates all schemes in which decryption can be im- plemented using at most S instructions In future work one could consider assigning a cost to different instructions (eg|,Non-data,13
|, letting DUP have cost 0, and letting TBC have cost some fixed multiple of XOR) and enumerating all schemes having at most some given cost 5 CONCLUSION In this work, we present a methodology for automatically proving the security of a large class of authenticated en- cryption (AE) schemes Using our approach, we are able to synthesize thousands of schemes, most of which have never been studied in the literature|,Non-data,13
| Among these, we discovered five new schemes which are as “compact” (in terms of the number of instructions per message block), as “efficient” (in terms of the number of blockcipher calls per message block), and as parallelizable as OCB, with competitive performance There are several interesting avenues for future work Fur- ther optimizing the synthesis procedure would allow us to 9See http://webcs|,Non-data,13
|ucdavisedu/~rogaway/ocb/news Figure 42: Three of our synthesized schemes of size twelve, illustrated for a four-block message M1, |,Non-data,13
|   , M4 In the second scheme, Σ is the check- sum of the even blocks, i|,Non-data,13
|e, Σ = M2 ⊕ M4 We now define our notion of parallelizability We call an AE scheme Π weakly parallelizable if for any integer m and any node x in the graph described above we have depth(x) ≤ Cost(Π) for both encryption and decryption|,Non-data,13
| A scheme is strongly parallelizable if depth(x) ≤ 1 Intuitively, weakly parallelizable schemes are ones where the TBC calls can be parallelized across two-block chunks (but not necessarily within the processing of a two-block chunk), and strongly parallelizable schemes are ones where the TBC calls can be parallelized even within a two-block chunk As an example, OTR (cf Figure 3|,Non-data,13
|9) is weakly parallelizable while OCB (cf Figure 32) is strongly parallelizable We can check these conditions efficiently by noting first that we only need to look at the OUT and FIN nodes, since depth is strictly increasing|,Non-data,13
| Now, suppose we run the analy- sis on graph Gi If the depth of the FIN nodes is zero, then it suffices to compute t = max{depth(OUT1), depth(OUT2)} (where OUT1 and OUT2 are the two OUT nodes) and check whether t ≤ Cost(Π) or t ≤ 1 If the FIN nodes have depth greater than zero (say, c), we need to rerun the analysis, this time setting the depths of the INI nodes to c (rather than zero) We can then compute t(cid:48) = max{depth(OUT1), depth(OUT2)}|,Non-data,13
| If t(cid:48) (cid:54)= t then this implies that depth grows with m (and thus the scheme is not paral- lelizable); otherwise we can check whether t(cid:48) ≤ Cost(Π) or t(cid:48) ≤ 1 to determine whether the scheme is parallelizable Looking at the results of Figure 41, we found thirteen secure AE schemes of size twelve, five of which are strongly parallelizable Of these schemes, as far as we know, only OCB exists in the literature|,Non-data,13
| In Figure 42 we show two of these newly synthesized schemes, along with one which is not parallelizable (For all the schemes in the figure, encryption M1M2C1C2M3M4C3C4tagτM1M2C1C2M3M4C3C4tagτΣ M1M2C1C2M3M4C3C4tagτ94generate more schemes Some of these schemes may have ad- ditional properties of interest, such as misuse-resistance [11]; developing techniques for automatically checking schemes for these additional properties would be very useful|,Non-data,13
| Taking a different approach, it would be interesting to see if simi- lar techniques can be applied to more general classes of AE schemes Acknowledgments We thank Samuel Neves for pointing out that on Haswell CPUs, TurboBoost must be disabled to measure the timing accurately We also thank the anonymous reviewers of CCS 2015 for their suggestion of automatic generation of attacks on schemes that fail our tests Work of Jonathan Katz was done for Exelis under contract number N00173-11-C-2045 to NRL|,Non-data,13
| Work of Alex J Mal- ozemoff was conducted with Government support awarded by DoD, Air Force Office of Scientific Research, National Defense Science and Engineering Graduate (NDSEG) Fel- lowship, 32 CFR 168a 6 |,Non-data,13
|ABSTRACT Kernel hardening has been an important topic since many applica- tions and security mechanisms often consider the kernel as part of their Trusted Computing Base (TCB) Among various hardening techniques, Kernel Address Space Layout Randomization (KASLR) is the most effective and widely adopted defense mechanism that can practically mitigate various memory corruption vulnerabilities, such as buffer overflow and use-after-free In principle, KASLR is secure as long as no memory leak vulnerability exists and high entropy is ensured In this paper, we introduce a highly stable timing attack against KASLR, called DrK, that can precisely de-randomize the mem- ory layout of the kernel without violating any such assumptions|,Non-data,15
| DrK exploits a hardware feature called Intel Transactional Synchro- nization Extension (TSX) that is readily available in most modern commodity CPUs One surprising behavior of TSX, which is es- sentially the root cause of this security loophole, is that it aborts a transaction without notifying the underlying kernel even when the transaction fails due to a critical error, such as a page fault or an access violation, which traditionally requires kernel intervention DrK turned this property into a precise timing channel that can determine the mapping status (ie|,Non-data,15
|, mapped versus unmapped) and execution status (ie, executable versus non-executable) of the priv- ileged kernel address space In addition to its surprising accuracy and precision, DrK is universally applicable to all OSes, even in virtualized environments, and generates no visible footprint, making it difficult to detect in practice|,Non-data,15
| We demonstrated that DrK can break the KASLR of all major OSes (ie, Windows, Linux, and OS X) with near-perfect accuracy in under a second Finally, we propose potential countermeasures that can effectively prevent or mitigate the DrK attack|,Non-data,15
| We urge our community to be aware of the potential threat of having Intel TSX, which is present in most recent Intel CPUs—100% in workstation and 60% in high-end Intel CPUs since Skylake—and is even available on Amazon EC2 (X1) Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page Copyrights for components of this work owned by others than the author(s) must be honored Abstracting with credit is permitted|,Non-data,15
| To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acmorg CCS’16, October 24 - 28, 2016, Vienna, Austria c⃝ 2016 Copyright held by the owner/author(s)|,Non-data,15
 Publication rights licensed to ACM ISBN 978-1-4503-4139-4/16/10  ,Non-data,15
 $1500 DOI: http://dxdoiorg/10,Non-data,15
|1145/29767492978321 Figure 1: The adoption status of both user-space and kernel-space ASLR in popular operating systems, ordered by year [62] 1 INTRODUCTION Enhancing the security of operating systems (OSes) has been an active and important research topic since the underlying OS is commonly considered to be the Trusted Computing Base (TCB) for user applications and their security mechanisms|,Non-data,15
| Among various hardening techniques, Kernel Address Space Layout Randomization (KASLR) is the most comprehensive and effective security mecha- nism and raises a practical hurdle for exploiting memory corruption vulnerabilities [31, 32], such as buffer overflow and use-after-free In this regard, today’s major commodity OSes (eg, Windows, Linux and OS X) as well as mobile OSes (e|,Non-data,15
|g, Android and iOS) have implemented and deployed KASLR to protect the core kernel image and device drivers from exploitation (see Figure 1) In principle, KASLR can effectively (ie|,Non-data,15
|, statistically) mitigate exploitation, as long as two assumptions hold: 1) no memory dis- closure vulnerabilities exist and 2) enough randomization entropy is guaranteed Therefore, typical attacks against the kernel require a preceding attack, which focuses either on leaking code or data pointers [17, 40, 42] to directly figure out the memory layout, or on exploiting implementation caveats to indirectly break the imper- fect randomness [44], as a stepping stone for the ultimate control- hijacking attack To the best of our knowledge, exploiting the cache-based timing channel [27] is the first attempt to universally break KASLR without violating these two fundamental assumptions The key idea of the cache-based timing attack is to exploit a timing difference (i|,Non-data,15
|e, cache miss and hit) for accessing mapped (ie, cached) and unmapped (i|,Non-data,15
|e, not-cached) pages to determine page mapping status More precisely, it deliberately fills or evicts certain cache lines to indirectly affect the execution time in the kernel space Such timing differences can be observed by measuring how quickly a system call returns from the kernel space, or how quickly a faulty access to the kernel space gets to the OS page fault handler|,Non-data,15
| Under a typical threat model—local privilege escalation, this attack can break KASLR (ie, leaking the partial bits of a randomized address) in theory, but it barely works in practice for three reasons First, it generates strong signals (e|,Non-data,15
|g, segmentation faults and lots of system calls) that typical system monitoring tools (eg, fail2ban and sysdig) consider to be abnormal behavior, thereby resulting in prompt mitigation|,Non-data,15
 Windows VistaKernel/User spaceOS X 105User-spaceiOS 5User-spaceAndroid 40User-spaceOS X 108Kernel-spaceLinux 3,Non-data,15
14Kernel-spaceYears2005200720142011iOS 6Kernel-space2012Linux 2612User-space380Grade/Generation Server/Workstation High-end Consumer Low-end Consumer Skylake Broadwell Haswell 17/17 (1000%) 23/38 (60,Non-data,15
1%) 4/32 (125%) 19/19 (1000%) 11/22 (500%) 2/16 (12,Non-data,15
|5%) 37/85 (435%) 2/92 (22%) 0/79 (00%) Table 1: Commodity Intel CPUs supporting TSX, varying CPU grades and generations (February 2016)|,Non-data,15
| Server CPUs include Xeon and Pentium D server, high-end consumer CPUs include i5 and i7, and low-end consumer CPUs include i3, m, and others All recent CPUs for server/workstation and more than half of high-end consumer CPUs support TSX [28] Second, it requires a large page (2 MB) to accurately locate the virtual address regions to intentionally generate cache conflicts to the targeted physical pages, which unfortunately requires higher privileges than a normal user in most commodity OSes: hugetlbfs in Linux [57], and SeLockMemoryPrivilege in Windows [13, 63] Lastly, the attack is neither accurate (i|,Non-data,15
|e, reversely mapping a conflicted cache line to its preimage set) nor fast enough (eg, their double page fault attack took 17|,Non-data,15
|3–729 s to probe the entire kernel space of 32-bit Windows 7 in a carefully controlled environment) for practical use In fact, these practical hurdles are the essential founda- tion of currently proposed software-based mitigation schemes [27] In this paper, we introduce a highly stable timing attack against KASLR, called DrK ([dIræk] De-Randomize Kernel address space), which is similar in spirit to the previous universal attack [27], but with higher accuracy and better performance|,Non-data,15
| To break KASLR in an OS-agnostic way, DrK exploits a timing side-channel in a new hardware feature, called Intel Transactional Synchronization Exten- sion (Intel TSX), that is widely deployed in modern Intel CPUs—in our survey, 100% of CPUs for server/workstation and 60% in high- end computers since Skylake have Intel TSX (see Table 1) Our attack has higher precision (eg, executable bits of pages), higher accuracy (e|,Non-data,15
|g, near-prefect de-randomization of memory layout), and is faster (eg, under a second) than the state-of-the-art cache- based attack|,Non-data,15
| More importantly, DrK does not generate distinctive footprints that look abnormal to system monitoring tools, and is uni- versally applicable to all OSes, even under a virtualized environment (eg, Amazon EC2) The key idea of DrK is to exploit an unusual behavior of TSX in handling erroneous situations inside a transaction|,Non-data,15
| When a transac- tion aborts (typically due to read or write conflicts), the CPU directly invokes an abort handler (specified by a user) to resolve it without interrupting the underlying OS However, even when an unrecov- erable error happens inside a transaction (eg, an access violation or a page fault), the CPU similarly aborts the transaction without informing the underlying OS, although these errors traditionally require the intervention of the underlying OS|,Non-data,15
| In DrK, we turned this property into a better timing channel, enabling us to precisely determine the mapping status (ie, mapped versus unmapped) and executable status (ie|,Non-data,15
|, executable versus non-executable) of the privileged address space, by intentionally generating an access violation inside a transaction (eg, accessing or jumping into kernel address regions) In this paper, we make three significant contributions: • A practical attack|,Non-data,15
| We demonstrate that DrK can break the KASLR of popular OSes, including the latest Windows, Linux and OS X, with near-perfect accuracy and high precision with sub-second execution time • Analysis We provide an in-depth analysis of the DrK attack with our hypothesis and experiment designs We show our results in three major OSes to understand the root cause (i|,Non-data,15
|e, CPU internal architecture) of the timing differences • Countermeasures Although we believe it could be hard to have a practical software-based mitigation, we propose several countermeasures that can effectively prevent a DrK attack|,Non-data,15
 The remainder of this paper is organized as follows §2 introduces KASLR and Intel TSX §3 explains how our attack works §4 shows our evaluation results,Non-data,15
| §5 provides an in-depth analysis of DrK to understand the hardware characteristics §6 proposes possible countermeasures §7 discusses the limitations of DrK §8 compares it with other projects, and §9 concludes this paper|,Non-data,15
| 2 BACKGROUND In this section, we provide a technical overview of KASLR and Intel TSX as a basis for understanding the technical details of the DrK attack 21 Kernel ASLR ASLR is a comprehensive and popular defense mechanism that mitigates memory corruption attacks in a probabilistic manner|,Non-data,15
| To exploit a memory corruption vulnerability, such as use-after-free, attackers need to figure out the memory layout of a target process or the system ahead of time ASLR mitigates such attacks by incor- porating a non-deterministic behavior in laying out the program’s or system’s address space More specifically, whenever a program is loaded or a system is booted, the ASLR mechanism randomizes their address spaces, including code and data pages Since ASLR is highly effective in practice, most real exploits first have to bypass ASLR (or KASLR) before attempting to launch a real control-hijacking attack, such as return-oriented programming (ROP)|,Non-data,15
| For example, most web browser exploits demonstrated in the latest Pwn2Own competition [41, 43] include one or more in- formation leak vulnerabilities to bypass KASLR, thereby escaping a user-level sandbox For this reason, all major commodity OSes, including Windows, Linux, and OS X, as well as mobile OSes, in- cluding Android and iOS, have deployed ASLR in user space and recently applied it to kernel space Adoption Figure 1 shows the timeline of the ASLR deployment in popular OSes|,Non-data,15
 Microsoft started supporting KASLR in Win- dows Vista (2007) and Apple started its support with iOS 5 and OS X 108 (2012) Linux has provided KASLR as an option (ie,Non-data,15
|, CONFIG_RANDOMIZE_BASE=y) since kernel version 314 (2014) and, recently, popular distributions (eg, Ubuntu 15|,Non-data,15
04) have enabled KASLR by default Implementation Table 2 summarizes how 64-bit commodity OSes implement KASLR for kernel text and modules in terms of entropy (ie,Non-data,15
|, amount of randomness) and granularity (ie, unit of randomization) The entropy of KASLR is determined by the kernel address range (e|,Non-data,15
|g, 1 GB–16 GB) and the size of alignment, which is usually a multiple of the page size (eg, 4 KB–16 MB) for better performance and memory utilization|,Non-data,15
| For example, Linux’s kernel address range is 1 GB (30 bits) and its alignment size for kernel text is 16 MB (24 bits), so that its KASLR entropy is only 6 bits (ie, 64 slots for the location) In contrast, Windows 10’s kernel address range is 16 GB (34 bits) and its alignment size for kernel text is 2 MB (21 bits), so that its KASLR entropy is 13 bits (i|,Non-data,15
|e, 8,192 slots for the location) Thus, a set of all possible randomized base addresses is {base_address + s × align_size : 0 ≤ s < #slots} 2|,Non-data,15
|2 Intel TSX In this section, we explain the basic concept of Intel TSX to help understand the DrK attack Intel TSX is Intel’s implementation of hardware transactional memory (HTM) [23, 36, 37, 58, 61] HTM 381OS Linux Windows OS X Types Kernel Modules Kernel Modules Kernel Entropy 6 bits 10 bits *13 bits *13 bits 8 bits #Slots 64 1,024 8,192 8,192 256 Address Range 0xffffffff80000000 – 0xffffffffc0000000 0xffffffffc0000000 – 0xffffffffc0400000 0xfffff80000000000 – 0xfffff80400000000 0xfffff80000000000 – 0xfffff80400000000 0xffffff8000000000 – 0xffffff8020000000 Align Base 0x1000000 0x1000 0x200000 0x200000 0x200000 Align Size 16 MB 4 KB 2 MB 2 MB 2 MB Broken by DrK? (10000%) ✓ (100|,Non-data,15
0%) ✓ (1000%) (9998%) (1000%) ✓ ✓ ✓ Table 2: Summary of KASLR implementations in popular OSes,Non-data,15
| According to our experiment, all KASLR implementations we tested generate a random address by adding a random offset to the fixed base address (ie, kernel or module base) either at the booting time or when loading modules The numbers marked in blue color indicate varying, randomized ranges, so called entropy|,Non-data,15
| (*) Johnson and Miller [31] reported that Windows has 17-bit worth of entropy for the kernel and 19-bit for modules, but we have only observed 13-bit of entropy during our experiments // the transaction starts |,Non-data,15
| // this transaction successfully terminated _xend(); 1 // begin a transaction 2 if (_xbegin() == _XBEGIN_STARTED) { 3 4 5 6 7 } else { 8 9 10 } Figure 2: A minimal code snippet that derives TSX: this example executes the code block in the if-statement transactionally, meaning that any error inside the code block makes it roll back // the transaction is aborted abort_handler(); provides lock-less synchronization among threads by ensuring trans- actional execution at the hardware level; ie, it enables concurrent access to shared memory by multiple threads and discards changes if a read-write conflict, write-write conflict, or other error happens during the transaction|,Non-data,15
| Note that this paper’s main concern is not how we effectively use TSX to process transactions, but how we exploit the way it handles an exception, which accidentally exposes a clear, stable timing channel Example code To explain our attack, we first introduce how a transaction can be implemented by using TSX, which we will use as a template for the actual attack Figure 2 shows a minimal source snippet to run a transaction|,Non-data,15
| A transaction region starts with _xbegin() and terminates when _xend() is invoked (ie, commit- ted) Then, all instructions (e|,Non-data,15
|g, if-statement in Figure 2) in the transactional region are guaranteed to be atomically executed How- ever, a transaction might fail (ie|,Non-data,15
|, abort) as well: for example, when two or more concurrent transactions affect each other during the execution—a read-write or a write-write conflict, depending on how they affect each other In such a case, it automatically rolls back the aborted transactions (eg, cleaning up the overwritten memory space) and invokes an abort handler specified by a user (e|,Non-data,15
|g, else- branch in Figure 2) The more interesting situation, in terms of security, is when erroneous situations occur during the execution: for example, segmentation faults, page faults, or even interrupts Suppressing exceptions|,Non-data,15
| According to Intel’s manual ([30, §1537]), a transaction aborts when such a hardware exception occurs during the execution of the transaction However, unlike nor- mal situations where the OS intervenes and handles these exceptions gracefully, TSX instead invokes a user-specified abort handler with- out informing the underlying OS|,Non-data,15
| More precisely, TSX treats these exceptions in a synchronous manner—immediately executing an abort handler while suppressing the exception itself In other words, the exception inside the transaction will not be communicated to the underlying OS This allows us to engage in abnormal behavior (eg|,Non-data,15
|, attempting to access privileged, ie, kernel, memory regions) without worrying about crashing the program In DrK, we break KASLR by turning this surprising behavior into a timing channel that leaks the status (e|,Non-data,15
|g, mapped or unmapped) of all kernel pages 3 THE DrK ATTACK In this section, we provide a high-level description of the DrK attack, which breaks KASLR by exploiting a timing channel in TSX|,Non-data,15
| As explained in §22, when an exception occurs inside a transaction, TSX aborts its execution and, importantly, suppresses the exception (ie, no OS intervention)|,Non-data,15
| The key idea of DrK is to measure the timing difference in handling a transaction abort when attempting to access mapped kernel memory regions compared to unmapped regions Accessing the kernel space from a user process incurs an access violation (ie, a page fault), but TSX suppresses this excep- tion and immediately invokes its abort handler|,Non-data,15
| The mapping status of the targeted kernel address results in a time difference (an order of a few hundred cycles) in invoking the abort handler due to the subtleties in TSX’s micro-architecture (see §5) More importantly, this attack is not observable to the OS, as these exceptions are all suppressed Furthermore, unlike prior attacks that only try to dis- tinguish between mapped and unmapped pages, the DrK attack can even extract the executable and non-executable bit of every kernel page 3|,Non-data,15
|1 Threat Model The DrK attack is built on four realistic assumptions: 1 The attacker has unrestricted access to the local, user-level, and non-root privilege execution environment of the target system 2 The attacker knows a memory corruption vulnerability in the kernel space, but needs to bypass the KASLR deployed in the target system in order to exploit this vulnerability|,Non-data,15
| 3 The attacker does not have any explicit way to figure out the kernel memory layout 4 The attacker can gather the information of the target system: for example, the OS version or CPU information|,Non-data,15
| This threat model is very realistic For example, the platform- as-a-service (PaaS) cloud services such as Heroku [25] provide a local execution environment that satisfies all of the assumptions above Similarly, these assumptions hold true in exploiting the vul- nerabilities in modern web browsers due to their user-level sandbox; real exploits demonstrated in the Pwn2Own competition [41, 43] are performed under the same threat model as the DrK attack Moreover, the operating systems disallow user-level code to ac- cess to their kernel address space information|,Non-data,15
| In Ubuntu, access to /proc/kallsyms, which shows all mappings of kernel space, is prohibited to non-root users In Windows 10, there is a system call NtQuerySystemInformation() which allows a normal user to see the current mapping of the kernel However, in the LOW or UNTRUSTED integrity level that is generally set as the running level of sandboxed applications (eg|,Non-data,15
|, the renderer process of Google Chrome), it is not allowed to access the system call to get the address layout of the 382: mov rax, addr; jmp rax : mov rax, [addr] } errx(1, "Not reachable"); // TSX aborted; end timer, return the timing return rdtsc_end() - beg; // Timer starts uint64_t beg = rdtsc_beg(); // initiate TSX region if (_xbegin() == _XBEGIN_STARTED) { // fn() performs either 1) or 2) // 1) execute // 2) read fn(addr); // commit TSX, which will never take place _xend(); 1 // The given argument addr is an address for a kernel page|,Non-data,15
| 2 uint64_t do_probe_memory(void *addr, mode_fn fn) 3 { 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 } 20 // probe the address for multiple times 21 uint64_t probe_memory(int ntimes, void *addr, mode_fn fn) 22 { 23 24 25 26 27 28 29 30 31 } Figure 3: Code snippet that probes timing for a kernel address access The access on address through fn(addr) always raise an exception (ie, access violation) which makes the transaction abort|,Non-data,15
| In the DrK attack, we measure the minimum timing value from multiple trials of probing for determining page mapping status (eg, 215 cycles for mapped region and 245 cycles for unmapped region) uint64_t clk = do_probe_memory(addr, fn); // Only record the minimum timing observed|,Non-data,15
 if (clk < min) uint64_t min = (uint64_t)-1; // UINT64_MAX while (ntimes --) { } else { min = clk; } return min; kernel We confirmed that DrK works in such restricted integrity levels 32 Overview Figure 3 shows a code snippet that we ran to probe a kernel ad- dress for its mapping status,Non-data,15
| We perform two types of access to a kernel address addr inside a TSX region (if-statement, from _xbegin() to _xend()): (1) try to execute on addr by running mov rax, addr; jmp rax (exec), and (2) try to read a value from addr by running mov rax, [addr] (read) Note that since addr is a kernel address, the access is not performed, instead generating an exception, which makes the transaction abort We measure the timing between the initialization of the TSX region (_xbegin()) and the abort handler (line 15-16) Since the DrK attack relies on the timing difference on the hardware critical path (see §5), we measure the minimum timing for a memory page|,Non-data,15
| Figure 4 shows an example of how timing can determine the mapping status of a kernel page First, we attempted to read a given kernel address It took more than 235 cycles for unmapped pages and less than 220 cycles for mapped pages (see Figure 6a)|,Non-data,15
| Next, we attempted to execute (ie, mov rax, addr; jmp rax) on a given kernel address It took less than 200 cycles for the exe- cutable pages and more than 220 cycles if the page is non-executable (see Figure 6b)|,Non-data,15
| We observed a significant timing difference (±10%) that can be used for a timing channel to precisely identify the mapping and executable permission status for a given kernel address Probing strategy Figure 5 shows how DrK works Basically, it consists of two steps: (1) collect timing information for the memory (probing step) and (2) determine the kernel map using the timing information|,Non-data,15
| In (1) we first analyze the target OSes to determine some invariant of the kernel address space layout This step is essential to avoid Figure 4: An overview of the timing attack in DrK From the timing differences in calling TSX abort handler for read access (U/M) and execution access (X/NX) inside a transaction, the DrK attack can infer the memory layout of the OS, as well as their permission status (ie|,Non-data,15
|, executable or non- executable) The numbers are collected on a system running Ubuntu 1604 LTS (kernel 44|,Non-data,15
|0), on Intel Core i7-6700K (Skylake) 40 GHz processor Figure 5: Our attack consists of two steps: 1 Probing and 2 Analysis 1 Given resource budgets provided by users (e|,Non-data,15
|g, time or iteration) and memory specification of the target OS (eg, maps, types, and page size), we first probe the timing of the TSX aborts in each memory region|,Non-data,15
| 2 Then, with the pre-measured knowledge base on the timing characteristics of each CPU model, we determine the memory layout (eg, mapped regions) and status (eg|,Non-data,15
|, executable regions) searching the entire 64-bit address space For example, we can use the information in Table 2 to largely reduce the random search space In the analysis step (2), we determine the mapping status of the kernel address using the timing information gathered in step (1)|,Non-data,15
| Note that the timing information largely depends on the hardware characteristics (eg, CPU generation and clock frequency, see Ta- ble 3), so we need to know such information for the CPU We can collect such information during an offline analysis and store it in a database|,Non-data,15
| Summary The benefits of DrK, accuracy, covertness, and OS- independence, come from the characteristics of TSX On accessing a kernel address, the occurrence of a page fault inside the TSX region will directly call an abort-handling procedure in the user- space process without notifying the operating system This shortcut not only minimizes measuring noise but also probes any kernel address without the OS being aware of it and does not rely on how an OS interrupt handler is implemented|,Non-data,15
| This is a clear advantage over Hund et al’s attack against KASLR [27], which relies on an OS interrupt handler, leading to high noise, OS-awareness, and OS-dependency 4 ATTACK EVALUATION ous CPU and OSes? (§4|,Non-data,15
1) We attempt to answer the following questions to evaluate DrK: • How different are the TSX timing characteristics across vari- • How effectively can DrK break KASLR of the popular OSes? • How does DrK work in a virtualized environment (§43)? • With what configuration does DrK give high precision (§44)? • How much better is DrK than prior attacks on KASLR (§45)? (§4,Non-data,15
|2, §423) addr[read]★[jmp]★>235 cycles<220 cyclesunmapped(U)<200 cycles>220 cyclesexecutable(X)non-executable(NX)def probe(addr):  beg = rdtsc()  if _xbegin():     [mode]★  else     end = rdtsc()  return end - begmapped(M)❶ Probing memoryaddrResource budget(eg|,Non-data,15
|, time) OS Memory SpecCPU ModelKnowledge Base❷ DeterminingU/X/NXdb MemorymapsinputoutputProbeAnalysis383CPU/Types i7-6700K (40G, Skylake) i5-6300HQ (23G, Skylake) i7-5600U (2|,Non-data,15
|6G, Broadwell) E3-1271v3 (36G, Haswell) READ (mov rax,[addr]) <U X 240 209 188 164 173 149 177 195 NX 209 164 149 177 JMP (mov rax,addr; jmp rax) X< 181 142 134 159 U 226 178 164 189 NX 226 178 164 189 (a) Mapped vs Unmapped Table 3: The minimum observed timings over 1,000 iterations of probing for the known kernel mappings, for each CPU In the DrK attack, we use timing differences to determine the mapping status of the page|,Non-data,15
| We measured the timings using mov and jmp instructions, to observe the minimum timings for unmapped (U), non-executable (NX), and executable (X) pages The value indicates that having access with a mov instruction on unmapped pages takes 18–31 more cycles (marked in red color) than the mapped pages Likewise, the timing for executable pages on accessing with a jmp instruction takes 30–44 fewer cycles (marked in blue color) than non-executable or unmapped pages Note that the values are observed minimums, namely, we cannot observe the timings below the values per each mapping status during the experiment|,Non-data,15
| ecute arbitrary kernel memory pages using a jmp instruction, the timing differences between executable and non-executable pages were 30–44 cycles While the timings depend on the architecture or clock rate of the processor, the common characteristics of the timing is that there is always a timing gap for the page mapping types across different types of processors Furthermore, the minimum timing does not depend on OS settings By running the experiment over multiple environments (different OSes, or under the Xen hypervisor), we discovered that the timing is characteristic of the processor and did not depend on the software settings (see §4|,Non-data,15
|4) The difference between minimum timings for each page mapping type can be exploited to determine the memory mapping status For example, on an Intel Core i7-6700K Skylake processor, probing unmapped pages always took more than 240 cycles In contrast, probing on mapped pages took less than that, with a minimum of 209 cycles|,Non-data,15
| If a page was probed in 230 cycles, then it is a mapped page because for unmapped pages, it is impossible for probing to take less than 240 cycles Thus, we set the threshold to use in determining page mapping status as a value less than the minimum timing of an unmapped page We also took a value less than the minimum timing of non-executable page as the threshold for distinguishing executable and non-executable pages Figure 6 shows how the timing is measured for the actual memory pages, for 100 iterations of probing|,Non-data,15
| On probing mapped and un- mapped pages (Figure 6(a)), we set the horizontal (red) line at 235 cycles (less than the minimum of U), and used it as the threshold for mapped pages The line clearly separates the unmapped pages (the upper half) from the mapped pages (the lower half), and there is a clear gap of about 30 cycles between the halves On probing the executable permission status (Figure 6(b)), we set 210 cycles (less than the minimum of NX) as the threshold for executable pages The red line on the threshold clearly separates the non-executable or unmapped pages (the upper half) from the executable pages (the lower half), and there is a clear gap of about 40 cycles between them|,Non-data,15
| As shown in the graph, the timing channel is highly consistent Using this timing channel, the DrK attack can clearly determine the mapping status of a page and its executable permission by comparing measured timings to the minimum threshold for the types of pages On evaluating DrK for breaking KASLR in the commodity OSes (in §42), we observed that the DrK attack can achieve 100% accuracy in determining page mapping and executable status across multiple runs of the attacks|,Non-data,15
| (b) Executable vs Non-executable Figure 6: Two timing graphs for measuring timings on Linux kernel mod- ules area, running on a Skylake (Core i7-6700K) processor The graph shows that the difference in the minimum timing (see Table 3) is suffi- cient to set the threshold (the red line in each graph) for determining page mappings In the upper graph, the red line placed at 235 cycles clearly distinguishes the mapped from the unmapped pages of the modules|,Non-data,15
| Simi- larly, the red line placed at 210 cycles in the lower graph clearly separates the executable pages from the non-executable ones (including unmapped pages) We probed the timing on accessing each page in the Linux ker- nel module area 100 times, while running kernel version 440|,Non-data,15
| Modules are loaded from 0xffffffffc0347000 to 0xffffffffc0bf9000, and the DrK attack breaks KASLR with perfect (100%) accuracy 41 Characteristics of the Timing Channel The DrK attack uses timing information as an oracle for deter- mining the mapping status of kernel memory pages We rely on the timing difference on accessing each type of kernel page mappings: unmapped, mapped, and executable|,Non-data,15
| A necessary condition that enables such a distinction is that there should be a prominent timing gap to determine different mappings We observed that the timing channel measured with a TSX abort handler has a significant timing gap between the different mappings Table 3 shows the minimum timing that we could observe on ac- cessing each type of page mapping, across 4 types of processors over 1,000 times There are significant timing differences between mapped (fast) versus unmapped (slow) pages, and executable (fast) versus non-executable (slow, including unmapped) pages|,Non-data,15
| When we attempted to access to arbitrary kernel memory pages using a mov instruction, the timing differences between unmapped and mapped pages were 18–31 cycles1 Similarly, when we attempted to ex- 1There was no difference between read and write attempts 38442 Breaking KASLR in Popular OSes To demonstrate the feasibility of the DrK attack in realistic set- tings, we evaluated the attack on commodity 64-bit OSes that use KASLR, namely, Linux kernel 4|,Non-data,15
|40, Windows 10 10010586, and Mac OS X El Capitan 10|,Non-data,15
|114 2 Furthermore, we also mounted the DrK attack on a Linux virtual machine (VM) running on a Xen hypervisor, and a cloud environment (an X1 instance of Amazon EC2), to test DrK against cloud environment settings Table 4 summarizes the result of the DrK attack on various hardware and software configurations|,Non-data,15
| In short, the DrK attack demonstrates around 99%–100% accuracy—not just mapped and unmapped pages, but also executable pages, independent to the OS— for determining kernel address mappings in all major OSes and even in a virtualized environment, in few seconds with near-perfect accuracy To the best of our knowledge, this level of accuracy, speed, and generality in a cache timing side-channel attack has never been demonstrated before 1 Accuracy|,Non-data,15
| The DrK attack is highly accurate It can identify the mapping status of a kernel address at the page-level gran- ularity In comparing the result from the DrK attack with the ground truth page table mappings, we achieved 100% accu- racy in detecting the correct page mapping across the OSes and CPUs The high accuracy of DrK lets the attacker infer more infor- mation about the kernel; for example, the mapping addresses can be used for detecting the exact location of some kernel modules|,Non-data,15
| The DrK attack can accurately identify the location of the driver code in Windows, by correctly determining the base address of 97 specific drivers among a total 141 loaded drivers using the unique signature of X/NX/U mapping size information 2 Speed DrK can scan the entire possible kernel allocation space of 64-bit OSes very quickly|,Non-data,15
| For attacking the start address of the kernel image, ie, getting ASLR slide, DrK is very fast: it only took 5 ms to successfully identify the base address of the Linux Kernel For the full scanning of the Linux kernel and modules pages (more than 6,000 pages), it took less than a second while achieving 100% accuracy|,Non-data,15
