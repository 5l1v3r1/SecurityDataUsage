 6303. DATASETS Our Internet-wide study of key sharing in the HTTPS ecosystem is driven by four datasets: SSL certificates We use SSL certificates from full IPv4 scans as the basis of our measurements,Data,0
| Our SSL scans [30] also contain information on the IP address(es) that advertised each certificate. To obtain in- formation about the entity that controls this IP address, we use full IPv4 reverse DNS scans [29] that are also conducted by Rapid7|,Data,0
| Each AS is assigned an AS Number (ASN): for example, MIT is AS 3 and the Chicago Public Schools are AS 1416 [26]. CAIDA collects and publishes mappings between IP addresses and ASNs via their Route- Views datasets [7]|,Data,0
| For example, AT&T owns 160 unique ASNs. To aggregate these, we use CAIDA’s AS- to-Organization dataset [8] to group together ASes owned by the same organization|,Data,0
| For that, we rely on WHOIS [12], a protocol for querying domain registrars to obtain data on the domain owner. In practice, WHOIS data often contains fields such as the con- tact information for the owner of the domain, the contact for technical issues, where to send abuse complaints, and so on|,Data,0
| Here, we expand upon these prior findings by evaluating whether there is a correlation between centralized management and the quality of the keys chosen. Figure 13 compares several different features of self- managed and outsourced certificates across our entire cor- pus of leaf certificates (3,275,635 self-managed and 1,781,962 outsourced): (a) Key lengths in self-managed certificates are nearly identical to those managed by third-party hosting providers|,Data,0
|1 Combining Packet Capture (PCAP) Files The data set used in this study is a combination of the packet capture files obtained from two main sources. First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour|,Data,1
| First of all, the APTs were collected from Contagio malware database [15] contributed by Mila Parkour. The normal and non-malicious data is obtained from PREDICT internet data set repository [18] under the category of “DARPA Scalable Network Monitoring (SNM) Program Traffic”|,Data,1
| The data collection was performed during April 2016 using ZGrab, an application-layer scanner that operates with ZMap [15]. In the first phase, we performed an Internet-wide scan of all IPv4 addresses on port 500 to determine which hosts were configured 16This defect was corrected quite recently, years after the version of OpenSSL ScreenOS uses was written|,Data,6
|, download from an external source). Running on 71,000 articles collected from 45 leading technical blogs, this new approach demonstrates a remarkable performance: it gener- ated 900K OpenIOC items with a precision of 95% and a coverage over 90%, which is way beyond what the state-of-the-art NLP tech- nique and industry IOC tool can achieve, at a speed of thousands of articles per hour|,Data,7
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
| To structure our efforts, we followed a multi- step process. First, we collected exploits from various online databases and exploit frameworks, including Metasploit (22 exploits)3, Exploit-DB (2)4, Packet Storm (5)5, from the security research company Security Explorations (52)6, and an online repository for Java exploits7|,Data,11
 5. ANALYSIS AND FINDINGS In the following we use the extensive documentation of the 61 minimal exploits to provide insight into how attackers use specific vulnerabilities and features of the Java platform to implement their attacks,Data,11
| We run our event analysis on the top 100 free applications in the Android application store to determine how often this happens. In total, our analysis finds 1060 errors across 88 of the top 100 applications (10|,Data,12
| To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review-level and app-level. We crawled a real-world dataset of 2, 614, 186 users, 12, 783 apps and 13, 129, 783 reviews from Google play, and use it to comprehensively evaluate AUTOREB|,Data,14
| 4.1 Data collection For each team, we collected a variety of observed and self- reported data|,Data,16
| To demonstrate this, we scraped greatfire.org for websites in the top 1000 Alexa websites that are blocked by the GFW|,Data,18
| (cid:15) Identifying New Vulnerabilities. Our tool successfully an- alyzed 1,591 service interfaces of all the 80 system services in Android 5|,Data,19
| To understand the scope and magnitude of this new XARA threat, we developed an ana- lyzer for automatically inspecting Apple apps’ binaries to deter- mine their susceptibility to the XARA threat, that is, whether they perform security checks when using vulnerable resource-sharing mechanisms and IPC channels, a necessary step that has never been made clear by Apple. In our study, we ran the analyzer on 1,612 most popular MAC apps and 200 iOS apps, and found that more than 88|,Data,24
| To assist software developers (or secu- rity analysts) in tracking down a memory corruption vulnerability, CREDAL also performs analysis and highlights the code fragments corresponding to data corruption. To demonstrate the utility of CREDAL, we use it to analyze 80 crashes corresponding to 73 memory corruption vulnerabilities archived in Offensive Security Exploit Database|,Data,25
| These techniques may be applicable in other scenarios. We implemented and evaluated the attacks against the popular Gmail and Bing services, in several environments and ethical experiments, taking careful, IRB-approved mea- sures to avoid exposure of personal information|,Data,26
|, CSPAutoGen can handle all the inline and dynamic scripts. We have implemented a prototype of CSPAutoGen, and our eval- uation shows that CSPAutoGen can correctly render all the Alexa Top 50 websites|,Data,27
| 5. EXPERIMENTAL RESULTS This section reports on our evaluation of the moments ac- countant, and results on two popular image datasets: MNIST and CIFAR-10|,Data,28
| 6.1 Mobility Trace Dataset We use the CRAWDAD dataset roma/taxi [2, 3] for our simu- lations|,Data,31
 6.1 Evaluation We evaluated the performance of Σoφoς using 4 data sets of increasing size and also the English Wikipedia,Data,33
|1 Datasets, Metrics, Competitors & Settings Datasets. We test EpicRec on two real-world datasets: MovieLens1: a movie rating dataset collected by the Grou- pLens Research Project at the University of Minnesota through the website movielens|,Data,36
| 1 http://grouplens.org/datasets/movielens 188Yelp2: a business rating data provided by RecSys Chal- lenge 2013, in which Yelp reviews, businesses and users are collected at Phoenix, AZ metropolitan area|,Data,36
| The number of movie categories is 18. We use the MovieLens- 1M, with 1000,209 ratings from 6,040 users on 3,883 movies|,Data,36
| Our goal is to show that an ad- versary can insert an unbounded number of Sybil identities in the SybilLimit protocol, breaking its security guarantees. For our evaluation, we consider a real-world Facebook inter- action graph from the New Orleans regional network [28]|,Data,38
| We utilize these papers to extract Android malware behaviors and to construct the semantic network. From the electronic proceedings distributed to conference participants, we collect the papers from the IEEE Sympo- sium on Security and Privacy (S&P’08–S&P’15)4, the Com- puter Security Foundations Symposium (CSF’00–CSF’14), and USENIX Security (Sec’11)|,Data,39
 We conduct experiments on two publicly available set-valued datasets. • AOL search log dataset [1],Data,45
 90% of the users have fewer than 84 keywords in their logs. • Kosarak dataset [2],Data,45
 We select one month of data for our study. The data logs we used are col- lected from more than 30 machines with various server mod- els and operating systems,Data,46
| This paper rigorously investigates how users’ security beliefs, knowledge, and demographics corre- late with their sources of security advice, and how all these factors influence security behaviors. Using a carefully pre- tested, U|,Data,48
 We have ported Valgrind to iOS and implemented a prototype of iRiS on top of it. We evaluated iRiS with 2019 applications from the official App Store,Data,54
| from manufacturing equipment, as shown in Figure 1. We capture the relevant sensor data by deliberately or accidentally placing an attack-enabled phone close to, on top of, or inside a piece of manu- facturing equipment while the machinery is fabricating the target object|,Data,55
| Our new metric helps us compare in a fair way previously proposed attack-detection mechanisms. (ii) We compare previous attack-detection proposals across three di↵erent experimental settings: a) a testbed operating real-world systems, b) network data we collected from an operational large-scale Supervisory Control and Data Acqui- sition (SCADA) system that manages more than 100 Pro- grammable Logic Controllers (PLCs), and c) simulations|,Data,57
| Evaluation. We ran Oyente on 19, 366 smart contracts from the first 1, 460, 000 blocks in Ethereum network and found that 8, 833 contracts potentially have the documented bugs|,Data,58
| First, we consolidate the eight origin-exposing vectors into one auto- mated origin-exposing system called Cloudpiercer. Then, we assemble a list of clients from five CBSP companies by studying their DNS configurations and obtaining their adop- tion rate across the Alexa top 1 million websites|,Data,59
| The vast majority of them were exposed through their A record, indicating a brief dis- abling of the protection system. SSL certificate exposure In order to find IP addresses hosting SSL certificates associ- ated with the domains in the evaluation set, we made use of the publicly available data of Rapid7’s Project Sonar [42]|,Data,59
| 4. LARGE-SCALE ANALYSIS To assess the magnitude of the origin-exposure problem, we conduct a large-scale analysis in which we attempt to uncover the origin of CBSP-protected domains|,Data,59
|1 Dataset Description The dataset was first presented and used by Keller et al. in [23], and is publicly available in the gene expression om- nibus (GEO) database under reference GSE61741|,Data,61
| Although the cost of stor- age and processing have diminished, the cost of maintaining reliable infrastructure for transaction logs is still noticeable. Figure 1: A plot of transaction fee versus frequency for 1 million transactions in May 2015|,Data,65
| To estimate the cost of producing the preprocessing data (multiplication triples, random bits etc.), we used figures from the recent MASCOT protocol [31], which uses OT ex- tensions to obtain what are currently the best reported triple generation times with active security|,Data,67
| In this section, we validate whether the smartphone’s acoustic data can be utilized to deduce the movements. To conduct the validation, we implement an application on Nexus 5 (Android OS v6|,Data,68
| As seen in Table 4, we found that about half of the servers in Alexa’s top 10 support a large number of requests without rekeying. For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client|,Data,72
| For a better estimate of the number of vulnerable servers, we tested servers from Alexa’s top 10k that negotiate 3DES with a modern client. We identified 11483 different HTTPS servers11, and found that 226 of them (1|,Data,72
| In this paper, we study the possible techniques to detect and measure this fraud and evaluate the real impact of OTT bypass on a small European country. For this, we performed more than 15,000 test calls during 8 months and conducted a user study with more than 8,000 users|,Data,78
|, the server cannot learn their relative order) after some number of queries are performed over real-world data. Specifically, we ran an experiment where we inserted over 2 million public employee salary figures from [1] and then performed 1000 random range queries|,Data,79
| In this study, we are interested in finding answers to security- and privacy-related questions about libraries, such as “How prevalent are third- party libraries in the top apps and how up-to-date are the library versions?”, “Do app developers update the libs included in their apps and how quickly do they update?”, or “How prevalent are vulnerabilities identified in prior research [28, 9] in libraries and how many apps are affected?” To answer these questions, we first built a comprehensive repository of third-party libraries and applications (see Section 5). Our library set contains 164 libraries of different categories (Ad- vertising, Cloud,|,Data,84
|) and a total of 2,065 versions. We then collected and tracked the version histories for the top 50 apps of each category on Play between Sep 2015 and July 2016, accumulating to 96,995 packages from 3,590 apps|,Data,84
|6.1, we found in our sample set 360 affected packages from 23 distinct apps, when only considering exact library matches|,Data,84
|15 for Android, which contained an account hijacking vulnerability, on 06/11/2014. In the histories of our sample set apps, we discovered, in total, 394 affected packages from 51 distinct apps, when only considering packages with exact matches of the vulner- able lib version|,Data,84
| We used LibScout to detect the affected application packages in our data set. In total 2,667 app versions of 296 distinct apps with a cumu- lative install-base of 3|,Data,84
| We observed that there is a significant variance in ACFG size. To reduce the sampling bias, we first collect a dataset which covers ACFGs of different functions from various architec- tures|,Data,89
| This dataset was used for base- line comparison, and all functions in this dataset has known ground truth for metric validation. We prepared this dataset using BusyBox (v1|,Data,89
| Dataset II – Public dataset. Recent work such as Pewny et al [45] and Eschweiler et al [23] used the same public dataset based upon two publicly-available firmware images for baseline comparison [7, 8]|,Data,89
| Dataset III – Firmware image dataset. This dataset of 33,045 firmware images was collected from the wild|,Data,89
| As a result, we created a freely available vulnerability database for this effort and for the broader research community. To build this database, we mined official software websites to collect lists of vulnerabilities with the corresponding CVE num- bers|,Data,89
| We selected OpenSSL for demonstration, since it is widely used in IoT devices. The resulting vulnerability database includes 154 vulnerable functions|,Data,89
| Roughly speaking, our measurement methods can be divided into two kinds: those that could be fully automated and scaled eas- ily, and those that required some manual interaction. For the latter, we used a set of 302938 major email providers and email genera- tors, while for the former, we used a much larger set of a million popular providers occurring in the Adobe leak and the Alexa top million Web sites (as potential email generators)|,Data,90
1.2 Provider List We created the set of popular email providers based on the top 1 million email address domains occurring in the leaked Adobe user data set of September 2013,Data,90
| Using a combination of mea- surement techniques, we determine whether major providers sup- ports TLS at each point in their email message path, and whether they support SPF and DKIM on incoming and outgoing mail. We found that while more than half of the top 20,000 receiving MTAs supported TLS, and support for TLS is increasing, servers do not check certificates, opening the Internet email system up to man- in-the-middle eavesdropping attacks|,Data,90
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
|26 and are configured with 4G RAM and 2 virtual processors. The VMs for TorA run on a workstation and are connected to a campus wired network, whereas the VMs for TorB and TorC are run on a laptop and connect to a home wired network, Each of these three datasets contains 30,000 traces collected as follows: (1) For each target obfuscator, we used our trace collection framework to visit Alexa Top 5,000 websites to collect 5,000 traces (labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon respectively); (2) In addition, we visited the same set of websites without Tor and obfuscators to collect 5,000 traces and labeled them as nonTor|,Data,91
| 3.1 Datasets We use two major types of datasets: (1) packet-level traffic traces collected at various locations in a campus network, and (2) packet-level traces for Tor Pluggable Transport traffic collected in controlled environments|,Data,91
 Evaluation: local mixing time in social graphs. We use 10 various large-scale real-world social network topolo- gies that mainly come from the Stanford Large Network Dataset Collection [23] and other sources [45] to evaluate the local mixing time for nodes in social graphs,Data,92
| Feature Functions and Weights. To learn all feature functions and weights, we downloaded 1784 non-obfuscated Android applications from F-Droid [3], a popular repository for open-source Android applications|,Data,93
2.2 Experiments with Malware Samples We randomly selected one sample from each of the 49 mal- ware families reported in [40],Data,93
1_r1). Apps in our dataset used for the case study are downloaded from the Google official market (Google Play) in May 2016,Data,95
| • Using SInspector, we perform the first study of Unix domain sockets on Android, including the categoriza- tion of usage, existing security measures being en- forced, and common flaws and security implications. We analyze 14,644 apps and 60 system daemons, find- ing that 45 apps, as well as 9 system daemons, have vulnerabilities, some of which are very serious|,Data,98
| We presented SInspector, a tool for discovering potential security vulnerabilities through the process of identifying socket addresses, detecting authen- tication checks, and performing data flow analysis on na- 90tive code. We analyzed 14,644 Android apps and 60 system daemons, finding that some apps, as well as certain system daemons, suffer from serious vulnerabilities, including root privilege escalation, arbitrary file access, and factory reset- ting|,Data,98
| Our results show that many of our attacks succeed with a 100% chance such that the Sound-Proof cor- relation algorithm will accept the attacked audio samples as valid. Third, we collect general population statistics via an online sur- vey to determine the phone usage habits relevant to our attacks|,Data,100
 We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable (“Jessie”) and 200 popular open-source projects hosted on GitHub,Data,104
| We have applied UniSan to the latest Linux kernel and Android kernel and found that UniSan can successfully prevent 43 known uninitialized data leaks, as well as many new ones. In particular, 19 of the new data leak vulnerabilities in the latest kernels have been confirmed by the Linux community and Google|,Data,107
| This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public|,Data,108
| If two commits were blamed for the same amount of lines, blame both. Our heuristic maps the 718 CVEs of our dataset to 640 VCCs|,Data,109
| However, improving our blame heuristics further is an interesting avenue for future research. Apart from the 640 VCCs, we have a large set of 169,502 unclassified commits|,Data,109
|9 The SVM detected a high amount of excep- tions, a high number of changed code, inline ASM code, and variables containing user input such as __input and user. 6As previously mentioned we use the years 2011–2014 as the test dataset, since we have ground truth data on which to base the discussion|,Data,109
| When given a source file, Flawfinder returns lines with suspected vul- nerabilities. It offers a short explanation of the finding as well as a link to the Common Weakness Enumeration (CVE) database|,Data,109
| The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database|,Data,109
| Our results show that our approach significantly outperforms the vulner- ability finder Flawfinder. We created a large test database containing 66 C and C++ project with 170,860 commits on which to evaluate and compare our approach|,Data,109
 VoiceLive takes advantages of the user’s unique vocal system and high quality stereo recording of smartphones. • We conduct extensive experiments with 12 participants and three different types of phones under various ex- perimental settings,Data,111
| To test if WebCapsule can successfully record and subsequently replay real-world phishing attacks, we proceeded as follows, us- ing Chromium on our desktop machine. We selected a large and diverse set of recently reported phishing web pages from Phish- Tank8|,Data,112
| 2.4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime|,Data,113
|4 Datasets and implementation We use two real geographic datasets Cal, SpitzLoc, one synthetic geographic distribution Globe, and one real time- stamp dataset SpitzTime. The dataset Cal represents the latitude and longitude of about 21,000 intersections in the California road network1 (also used by Mavroforakis et al|,Data,113
294258. The dataset SpitzLoc consists of latitude and longitude coordinates tracking the movement of German Green party politician Malte Spitz over six months,Data,113
| In this section, we aim to explore whether the differences of keystroke wave- forms are large enough to be used for recognizing different keys inputs in the real-world setting. We collected training and testing data from 10 volunteers|,Data,114
 B. Real Attacks MAD uniformly detects attacks more quickly than the PAD; we use the former method to detect the presence of an attack in real Internet traces3,Data,119
 III. DATA SET  changes  The data used was the PREDICT ID USC-Lander!  (- 60  The total  were DNS attack packets,Data,120
|395326000  files IPs. There are total 59,928,920 packet counts out of which there was a total of  DoS_DNS_amplification-20130617 (2013-06-17) (2013-06-17) with anonymized million) 358019 DNS packets|,Data,120
| The maximum number of unique hosts per day we measured was 106,000. To understand these differences, we compared the observations from our network monitor to data collected from DShield (www|,Data,121
| 3.1 From our own transactions We engaged in 344 transactions with a wide variety of services, listed in Table 1, including mining pools, wallet services, bank ex- changes, non-bank exchanges, vendors, gambling sites, and mis- cellaneous services|,Data,122
| Wallets. We kept money with most of the major wallet services (10 in total), and made multiple deposit and withdrawal transac- Bank exchanges|,Data,122
|, in which the exchange rate is not fixed) also function as banks. As such, we tagged these services just as we did the wallets: by depositing into and withdrawing from our accounts (but rarely par- ticipating in any actual currency exchange)|,Data,122
|info/tags, including both addresses provided in users’ signatures for Bitcoin forums, as well as self-submitted tags. We collected all of these tags — over 5,000 in total — keeping in mind that the ones that were not self-submitted (and even the ones that were) could be regarded as less reliable than the ones we collected ourselves|,Data,122
| 3.1 Data analysis overview We use three data sets, summarized in Table 1|,Data,123
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
|1 PlanetLab Deployment We deployed tracebox on PlanetLab, using 72 machines as vantage points (VPs). Each VP had a target list of 5,000 items build with the top 5,000 Alexa web sites|,Data,124
| We also describe our application of the technique to the IPv6 interface-level graph captured by CAIDA’s Archipelago (Ark) infrastructure [14] for March 2013. The graph consists of all the 52,986 IPv6 interfaces numbered within the 2000::/3 unicast prefix captured from all 27 Ark vantage points (VPs) with IPv6 connectivity|,Data,125
| cause the counters of distinct routers to diverge, and (4) confirm aliases with pairwise probing. Given the absence of velocity in ID counters and the large probes required for the technique to work, we probe at a low rate of 20pps from a single VP, producing 26Kbps of traffic|,Data,125
| 3. METHODOLOGY In this section, we describe the design of our experiment and our data collection methodology, as well as the mitigating steps and proactive measurements we conducted to ensure a minimal im- pact of our covering routes|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| of IPs 1622 1219 159 9,409 9 12,418 No. of Unique ASNs 603 530 62 3,654 8 4,857 In order to validate minimal impact on data plane connectivity, we performed the following: We collected a set of public IPv6 addresses by querying the Alexa top 1M domains [2] for AAAA records|,Data,126
| Our IPv6 network telescope results suggest sev- eral important differences (and some similarities) compared to that body of work. To produce a more recent and valid comparison, we analyzed a single week of IPv4 background radiation captured during the course of our ongoing IPv6 packet capture|,Data,126
| 4. DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1|,Data,127
| DATA COLLECTION In this section we describe the datasets used in our analysis, which we summarize in Table 1. Our primary dataset consists of changes made to the |,Data,127
| domains, (2) the removal of existing domains, and (3) changes to existing domains in terms of revisions to their associated name- servers. Our data includes captures of the DNZA files as recorded every five minutes, time periods we refer to as epochs|,Data,127
| Since we lack comprehensive ground truth regarding the ultimate use of domains, to this end we use two proxies: subsequent appearance of a newly registered do- main in: (1) an email spam campaign, or (2) a domain blacklist. For the first of these, we operated a spam trap, i|,Data,127
|com), by restricting our focus to domains recently registered (March–July 2012) we can filter down the do- mains appearing in the spam trap to those very likely used for spam- ming. For the second, we subscribed to three major DNS blacklists, URIBL, SURBL, and Spamhaus DBL|,Data,127
| In this paper, we examine the effectiveness of these inter- ventions in the context of an understudied market niche, counterfeit luxury goods. Using eight months of empirical crawled data, we identify 52 distinct SEO campaigns, document how well they are able to place search results for sixteen luxury brands, how this ca- pability impacts the dynamics of their order volumes and how well existing interventions undermine this business when employed|,Data,128
| For a small number of stores, we were also able to collect user traffic data that directly measures an SEO campaign’s effectiveness in attracting customers to their stores. Specifically, we were able to periodically collect AWStats data for 647 storefronts in 12 cam- paigns|,Data,128
| One issue that undermines coverage is that Google only labels the root of a Web site as “hacked”, and does not label search results that link to sub-pages within the same root domain. In the PSR data set, we found 68,193 “hacked” search results|,Data,128
| We begin by exam- ining the properties of individual darknets and in particular the behavior of source IP addresses. We provide these char- acterizations by looking at data from 14 darknet monitors ranging in size from a /25 monitor to a /17 monitor over a period of 10 days between August 18, 2004 and August 28, 2004|,Data,129
| Figure 10: The number of darknets (of 31) reporting a port in the top 10 ports over a day, week, and month time frame. The analysis is performed for the top 10 destination ports over a day, top 10 destination ports over a week, and top 10 destination ports over a month|,Data,129
| 3.6 Datasets This paper uses DNS datasets from three authorities: one national-level top-level domain, operators of two root servers as shown in Table 1|,Data,130
 JP-DNS operates the .jp country code domain for Japan; we have data from all seven of their anycast sites,Data,130
|) part of the 2014 DITL collection [16] (for B-Root, shortly after 2014 DITL). We also use data for M-Root’s 2015 DITL collection (§ 4|,Data,130
 These root datasets are available to re- searchers through DNS-OARC. For longitudinal analysis we draw on 9 months of data taken at the M-Root server,Data,130
| However, we treat the union of these classes together. We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness|,Data,131
| We use data from 103 surveys taken between April 2006 and February 2015, and performed initial studies based on 2011–2013 data, but focus on the most recent of them, in January and February of 2015 for data quality and time- liness. The dataset consists of all echo requests that were sent as part of the surveys in this period, as well as all echo responses that were received|,Data,131
|, “host unreachable”); we ignore all probes as- sociated with such responses since the latency of ICMP error responses is not relevant. In later sections, we will complement this dataset with results from Zmap [5] and additional experiments includ- ing more frequent probing with Scamper [13] and Scrip- troute [22]|,Data,131
| 3.2 Milking 3 Methodology To collect the information needed to cluster servers into oper- ations, we have built an infrastructure to track individual exploit servers over time, periodically collecting and classi- fying the malware they distribute|,Data,132
 2. We receive feeds of drive-by download URLs (Sect,Data,132
 2. CHARACTERISTICS OF CHECK-INS We use three different datasets that capture human mobility,Data,133
 First we consider two online location-based social networks. We col- lected all the public check-in data between Feb,Data,133
| There are 196,591 nodes, 950,327 edges in Gowalla and 58,228 nodes, 214,078 edges in Brightkite. To ensure that our observations on human movement are not specific to data based on check-ins from location-based social net- works, we also include a dataset of cell phone location trace data|,Data,133
| Backscatter DDoS is a commonly seen behaviour in darknets where the attacker uses simultaneous bots to generate the actual attack packets to reach the targeted (original) victim. In our study, five publicly available network traffic datasets from CAIDA’s archives are employed|,Data,134
| Datasets Employed In this research, five publicly available real-life network traffic traces (datasets) from CAIDA’s archives are employed. Three of them, which were captured by a passive darknet in 2007, 2008 and 2012 [27][26][28], namely UCSD Network Telescope [21], include mostly one-way malicious traffic while the remaining ones collected in 2008 [29] and 2014 [30] via CAIDA’s Internet backbone links include only normal traffic|,Data,134
| 3 Approach This section presents our approach for the evalua- tion of reputation based blacklists. We evaluated the blacklists by deploying them in a large academic net- work of over 7,000 hosts|,Data,135
| This was a preliminary step to preventing inexperienced and non-serious workers from participating in our survey. Our survey is based on the participants’ actual check-ins on Foursquare posted over the last 24 months (that we collected through a specific application we developed), and it requires a significant amount of time to complete (30-45 minutes)|,Data,136
| The third phase of worm activ- ity is the persistence phase which for the Blaster worm has continued through 2004. In this one-week period of measurement, the IMS system observed over 286,000 unique IP addresses displaying the characteristics of Blaster activity|,Data,137
| published a study in 2011 that focused on the dynamics of leaf cer- tificates and the distribution of certificates among IP addresses, and attempted to roughly classify the overall quality of served certifi- cates. The study was based on regular scans of the Alexa Top 1 Mil- lion Domains [1] and through passive monitoring of TLS traffic on the Munich Scientific Research Network [17]|,Data,138
| Our study is founded on what is, to the best of our knowledge, the most comprehensive dataset of the HTTPS ecosystem to date. Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443|,Data,138
| Between June 2012 and August 2013, we completed 110 exhaustive scans of the public IPv4 address space in which we performed TLS handshakes with all hosts publicly serving HTTPS on port 443. Over the course of 14 months, we completed upwards of 400 billion SYN probes and 2|,Data,138
| Content Provider e Service Provider v i t c e p s r e P Content Consumer Addressing Prerequisite IP Functions Routing Naming A1: Address Allocation; A2: Address Advertisement N1: Nameservers; R1: Server Readiness N2: Resolvers N3: Queries A2: Address Advertisement; T1: Topology End-to-End Reachability R1: Server Readiness Operational Characteristics Usage Profile Performance U3: Transition Technologies U1: Traffic Volume; U3: Transition Technologies P1: Network RTT R2: Client Readiness U2: Application Mix; N3: Queries Table 2: Dataset summary showing the time period, scale, and public or new status of the datasets we analyzed. Dataset RIR Address Allocations Routing: Route Views Routing: RIPE Google IPv6 Client Adoption Verisign TLD Zone Files CAIDA Ark Performance Data Arbor Networks ISP Traffic Data Verisign TLD Packets: IPv4 Verisign TLD Packets: IPv6 Alexa Top Host Probing Time Period Metrics Jan 2004 – Jan 2014 A1 Jan 2004 – Jan 2014 A2, T1 Jan 2004 – Jan 2014 A2, T1 Sep 2008 – Dec 2013 R2, U3 Apr 2007 – Jan 2014 N1 P1 Dec 2008 – Dec 2013 U1, U2, U3 Mar 2010 – Dec 2013 Jun 2011 – Dec 2013 N2, N3 N2, N3 Jun 2011 – Dec 2013 Apr 2011 – Dec 2013 R1 Recent Scale ≈18K allocation snapshots (5 daily) 45,271 BGP table snapshots millions of daily global samples daily snapshots of ≈2|,Data,139
com & .net) ≈10 million IPs probed daily ≈33-50% of global Internet traffic; 2013 daily median: 50 terabits/sec (avg,Data,139
| To put the IPv6 allocation data in context, Figure 1 also shows IPv4 prefix allocations over the same period. The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled|,Data,139
| There were less than 30 IPv6 prefixes al- located per month prior to 2007, generally increasing thereafter. In the past several years, we typically find more than 300 prefixes allocated per month, with a high point of 470 prefix allocations in February 2011|,Data,139
| The number of IPv4 prefix allocations grows from roughly 300 per month at the begin- ning of our observation period to a peak of 800–1000 per month at the start of 2011, after which it drops to around 500 per month in the last year, as the number of available addresses at RIRs has dwindled. 1 Overall, we find nearly 69K IPv4 prefix allocations at the beginning of our dataset and just over 136K at the end|,Data,139
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| We deployed this detection mechanism on an Alexa top 10 website, Facebook, which terminates connections through a diverse set of network operators across the world. We analyzed 3, 447, 719 real-world SSL connections and successfully discovered at least 6, 845 (0|,Data,140
| Table 1 shows the datasets we use in our paper. We use two ICMP surveys taken by USC [12]: IT17ws and IT16ws; IT17ws is the main dataset used in this paper, while we use IT16ws for validation in Section 6|,Data,142
2. We collected VUSC s at our enterprise in order to compare our inferences with network operators as discussed in Section 6,Data,142
| # of Data-Oriented Attacks gives the number of attacks generated by FLOWSTITCH, includ- ing privilege escalation attacks and information leakage attacks. FLOWSTITCH generates 19 data-oriented attacks from 8 vulnerable programs|,Data,144
| Third, this method is not specific to C or C++, and can be applied to any programming language. We collected C++ source of thousands of contestants from the annual international competition “Google Code Jam”|,Data,145
| Finally, we analyze various attributes of programmers, types of programming tasks, and types of features that appear to influence the success of attribution. We identified the most important 928 fea- tures out of 120,000; 44% of them are syntactic, 1% are layout-based and the rest of the features are lexical|,Data,145
|3.1ScalingWecollectedalargerdatasetof1,600programmersfromvariousyears|,Data,145
| ) s y a D n i (    e m T i  7  6  5  4  3  2  1  10  20  30  40  50  60  70  80  90 Time Before Accounts Suspension Number of IP Addresses 2 Motivation: Analysis of Malicious Activ- ity on a Webmail Service We want to understand the way in which cybercrimi- nals abuse accounts on online services, to identify weak points that we could leverage for detection. To this end, we observed the email-sending activity on a large web- mail service|,Data,147
| Following accepted frameworks for qualitative research [18, 30, 35], we focus closely on a small number of participants. We interviewed 15 journalists employed in a range of well-respected journalistic institutions in the United States and France, analyzing these interviews using a grounded theory approach [18, 30]|,Data,146
| 3.1 Datasets We examine 13,345 passwords from four sets created under composition policies ranging from the typical to the currently less common to understand the suc- cess of password-guessing approaches against passwords of different characteristics|,Data,149
| Had we used any major password leak, their analysts would have already been familiar with most or all of the passwords contained in the leak, biasing results. The passwords in these sets were collected using Ama- zon’s Mechanical Turk crowdsourcing service|,Data,149
| The decision for or against pinning is always a trade- off between increasing security and keeping mainte- nance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps|,Data,152
| Therefore, we instrument telemetry data from a popular anti-virus software provider. We evaluate the update behaviour of 871,911 unique users from January 2014 to December 2014 and find that only 50% of the users update to a new app version within the first week after release|,Data,152
| Developer View Although pinning is only ap- plicable in relatively few cases, the nominal-actual comparison leaves room for improvement. We there- fore collected feedback from 45 developers of apps for which we would recommend pinning|,Data,152
| Section 4). Altogether we found 20,020,535 calls to network related API calls (cf|,Data,152
| Instability of the routes to the sensor address space can also result in reachability problems, especially given that route flap damping can be triggered during convergence to suppress unstable routes [9]. Using the BGP updates data from RouteViews BGP monitor, we studied the availability of the routes to the sensor blocks in our de- ployment from a large set of ASes|,Data,154
| This section probes these differences using three successively more specific views of traffic to a network of distributed blackhole sensors. The data was recorded over a one month period with SYN responders on TCP port 135, 445, 4444, and 9996 across all sen- sors|,Data,154
|  V. EXPERIMENT RESULTS  In this section, we mainly focus on how our router-to-AS Mapping method and other baseline methods behave on global router-level topology, as discussed above, we use PeeringDB data as ground truth, and apply clustering method on global topology based on CAIDA ITDK project|,Data,155
| It describes the properties that a dataset should have in order to be used for comparison purposes. The dataset used in the paper includes an IRC-based Botnet attack1, but the bot used for the attack was developed by the authors and therefore it may not represent a real botnet behavior|,Data,156
| This dataset may be downloaded with authorization. The Protected Repository for the Defense of Infrastructure Against Cyber Threats (PRE- DICT) indexed three Botnet datasets2 until May 16th, 2013|,Data,156
 None of them are labeled. A custom botnet dataset was created to verify five P2P botnet detection algorithms in Saad et al,Data,156
| Unfortunately, there is only one infected machine for each type of botnet, therefore no synchronization analysis can be done. The Traffic Laboratory at Ericsson Research created a normal dataset that was used in Saad et al|,Data,156
 This is the only normal dataset that is labeled inside the pcap file. A considerable amount of malware traffic in pcap format was published in the Contagio blog9,Data,156
| But since each scenario includes only one infected computer, it should be possible to label them. Another dataset with malware logs and benign logs was collected in NexGinRC (2013)|,Data,156
 Access to this dataset may be granted upon request10. The last dataset analyzed is currently created by the MAWI project described in Cho et al,Data,156
| Methodology and datasets We deployed Paris Traceroute with its Multipath Detection Algorithm (MDA) [29] enabled in 90 PlanetLab nodes. We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]|,Data,158
| We configured each node to trace IP-level routes toward 10 thou- sand destinations selected at random from a list of 102,404 reachable destinations in different /16 prefixes we obtained from the PREDICT project [11]. Our dataset contains more than 900 thousand IP-level (multi)routes and 324,313 IP addresses|,Data,158
1 3.1 Address Allocation and BGP Data We analyzed BGP announcements captured by all collectors (24 collectors peering with 184 peers) of the Routeviews [3] and RIPE RIS [52] projects,Data,159
| For each /24 block, we computed the maximum number of peers that saw it reachable at any time within the full observation period of 92 days. To determine which address blocks are available for assignment, we used a dataset compiled by Geoff Hus- ton [23], which merges the extended delegation files from the 5 RIRs [4, 6, 7, 41, 51] with IANA’s published registries [31–36]|,Data,159
| SWITCH. We collected unsampled NetFlow records from all the border routers of SWITCH, a national aca- demic backbone network serving 46 single-homed uni- versities and research institutes in Switzerland [55]|,Data,159
| R-ISP. We collected per-flow logs from a vantage point monitoring traffic of about 25,000 residential ADSL customers of a major European ISP [21]|,Data,159
 UCSD-NT. We collected full packet traces from the /8 network telescope operated at the University of Cal- ifornia San Diego [1],Data,159
| IXP. Our fourth VP is a large European IXP inter- connecting more than 490 networks, exchanging more than 400 PB monthly [5]|,Data,159
|3 Active Measurements ISI. We used the ISI Internet Census dataset it55w- 20130723 [37], obtained by probing the routed IPv4 address space with ICMP echo requests and retaining only those probes that received an ICMP echo reply from an address that matched the one probed (as rec- ommended [38])|,Data,159
| HTTP. We extracted IP addresses from logs of Project Sonar’s HTTP (TCP port 80) scan of the entire IPv4 address space on October 29, 2013 [24]|,Data,159
| Definitions of graph parameters measuring metric tree-likeness of a graph, as well as notions and notations local to a section, are given in appropriate sections. 3 Datasets Our datasets come from different domains like Internet measurements, biological datasets, web graphs, social and collaboration networks|,Data,160
| The experiments were executed as follows. Traces were col- lected by using ICMP, UDP, and TCP Traceroute to probe the paths to a set of 100 destination websites from a source located on the Pennsylvania State University, University Park campus|,Data,161
| For UDP and TCP Traceroute, traces were collected using the default destination port numbers. We also collected traces using other ports and observed similar results|,Data,161
| Realistic Networks Here we compare the merged topologies produced by iTop, MN, and Isomap for realistic topologies. We use the Au- tonomous System (AS) topologies from both the Rocketfuel [20] and the CAIDA [21] projects, which represent IP-level connections between backbone/gateway routers of several ASes from major Internet Service Providers (ISPs) around the globe|,Data,161
| Although the paris-traceroute output of ITDK is more reliable than that of IPlane’s traceroute, the random selection of endpoints implemented by CAIDA hinders the collection of routes between the same vantage- and endpoints. Therefore we used the data of IPlane’s traceroute measurements|,Data,162
| They can also be used for constructing maps of the Internet at the Autonomous Systems level [, ]. In this work we used the CAIDA router-level Internet map from October th,  []|,Data,163
| 3 Table 1: Dataset Description Name BGP Usage AS Geolocation; Detour Detection Date 2016-01 Sources Info RouteViews, RIPE 38,688 RIBS, 416 peers, RIS 30 countries, 55GB Infrastructure IP List AS Geolocation 2016-01 to 2016-03 CAIDA Ark, iPlane, OpenIPMap, RIPE Atlas Measurements 3M Router IPs Infrastructure IPs to AS Mapping Infrastructure IP geolocation 2015-08 CAIDA ITDK, iPlane 6.6M IP to AS mappings AS to IXP Mapping AS Relationship AS Geolocation 2016-01 to 2016-03 Filtering peered paths from detection 2016-01 Traceroute Detour Validation 2016-05-01 IXP websites, PeeringDB, PCH CAIDA AS Relationship RIPE Atlas MaxMind Prefix Geolocation; Detour Validation 2016-01, 2016-03 MaxMind GeoLite City (free and paid) 368 IXP websites crawled 482,657 distinct relationships Used by Netra, 163 traceroutes Paid version used only for geolocating infrastructure IPs and detour validation longest prefix match on the global routing table and map the IP to the AS announcing the longest matching prefix|,Data,164
| As shown in Figure 3, we install LaBrea on a /29 subnetwork and use PlanetLab [9] to probe from multiple vantage points the entire /24 aggre- gate to which the /29 belongs. We scan the /24 network by attempting to establish TCP connections to each IP address in the subnet and capture the packets for further analysis|,Data,165
| • Active IPs in a Subnet: Intuitively, we might ex- pect high-occupancy subnets to be good indicators of pos- sible tarpits. To this end, we initially investigated using a hitlist of probable tarpits as inferred from the /24 subnets with more than 240 responding web hosts in the scans|,Data,165
| To facilitate large-scale scanning and avoid triggering anomaly detectors, degreaser uses permu- tation scanning [7, 12] to pseudo-randomly iterate through the IP address space when probing. Our real-world Internet scan, which probes at least one address in each /24 network in the Internet, discovers 107 different tarpit subnetworks (cid:20)(cid:24)(cid:25) ranging in size from /16 (with up to 216 fake hosts) to /24 (with up to 28 fake hosts)|,Data,165
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
  III. DATA SET  The data used in this work was the PREDICT ID USC-Lander/ DoS_DNS_amplification-20130617 (2013- 06-17) to (2013-06-17) [26],Data,166
| • Discovering correlations between anomalous traffic types detected with deep inspection techniques and traffic feature entropy variations. • Providing a traffic-type dissection (in-depth and entropy based) of a representative portion of the IBR for three weeks of April, 2012, with a 10-minute time scope|,Data,167
 Following is the summary of information about these data sets:  1. Data set from PREDICT USA [24] which contains traces of a DNS distributed denial of service attack (DDOS),Data,168
  from optical  2. Data set from CAIDA USA [25] which contains internet internet connectivity from 2002 and 2003,Data,168
  3. Data set from our experiment in which a PCAP file is captured from a lab computer which is being used for browsing and software development for the cyber security project,Data,168
| Yet, the complexity of PRNGs coupled with large desired flows puts this application beyond the reach of state-of-the-art QIF tools Some of the entropy loss instances described in this pa- per are “simple” enough to be detectable by some form of (to be developed) static or even dynamic dataflow anal- ysis This is the case where some part of the entropy- carrying state is never read (Sections 66, 6|,Non-data,80
|7) or immedi- ately overwritten with clearly irrelevant values (Section 2) Other instances (Section 69) feature complex flows that re- quire, at the least, (unsound) cryptographic primitive ideal- ization to be detectable without losing practical complete- ness Furthermore, due to their lack of precision and impos- sibility to use sound idealizations, aforementioned analyses can only detect bugs|,Non-data,80
| Entroposcope, on the other hand, can prove their absence within the analyzed scope Nonethe- less, dataflow analyses have the advantage of scalability and warrant further investigation Manual PRNG analysis A number of publications report results of manual anal- ysis of individual cryptographic PRNGs or PRNG classes, among them [12–14, 17, 22, 23, 26] and [3, 7, 9]|,Non-data,80
| The perspec- tive taken in the latter works is based on elaborate attack models, where the attacker, for instance, can control the distribution of the inputs used to seed the PRNG, view, or even corrupt the internal PRNG state Complementary research There exists a wide body of work on randomness in cryp- tography and security Research subjects include secure the- oretical PRNG constructions, cryptographic schemes that either do not require randomness or degrade gracefully in presence of bad randomness, empirical studies of random- ness in practice through cryptographic artifacts collected from public sources, studies and methods of entropy col- lection in embedded devices or virtual machines|,Non-data,80
| Since this research is orthogonal to the immediate goals or techniques of our work, we do not survey it here 9 CONCLUSION We have presented the first static analysis and one of the first technical quality assurance measures for cryptographic PRNG implementations We implemented our analysis in a tool named Entroposcope and demonstrated its prac- ticality by analyzing five real-world PRNGs implementing different designs, including one of the most complex in wide deployment today|,Non-data,80
| In the experiments, Entroposcope uncovered PRNG de- fects effectively and with reasonable effort Five instances of entropy loss showcase the tool’s capabilities, including pre- viously undiscovered anomalies in OpenSSL and Libgcrypt The detection is systematic (ie|,Non-data,80
|, it is not based on exam- ples, patterns, or heuristics) and sound A negative analysis outcome guarantees absence of entropy loss in the analyzed scope 688The analysis we presented is intended to detect a large but specific class of implementation mistakes It is thus not intended to replace expert review, nor, more generally, re- search into good PRNG designs and deployment practices|,Non-data,80
| Yet, it is the first instance where the work of a PRNG se- curity analyst in a particular area can be supported by an effective tool Interesting directions for future research include exten- sions to more powerful attacker models, scenarios with multi- threading, and automatic counterexample-guided synthesis of cryptographic idealizations Acknowledgments This work was in part supported by the German National Science Foundation (DFG) under the priority program 1496 “Reliably Secure Software Systems – RS3” The authors would like to thank the anonymous CCS 2016 reviewers for the helpful suggestions for improving this paper and for pointing out [6] and [24]|,Non-data,80
|ABSTRACT Modern operating systems use hardware support to protect against control-flow hijacking attacks such as code-injection attacks Typically, write access to executable pages is pre- vented and kernel mode execution is restricted to kernel code pages only However, current CPUs provide no protection against code-reuse attacks like ROP ASLR is used to pre- vent these attacks by making all addresses unpredictable for an attacker|,Non-data,81
| Hence, the kernel security relies fundamentally on preventing access to address information We introduce Prefetch Side-Channel Attacks, a new class of generic attacks exploiting major weaknesses in prefetch instructions This allows unprivileged attackers to obtain address information and thus compromise the entire system by defeating SMAP, SMEP, and kernel ASLR Prefetch can fetch inaccessible privileged memory into various caches on Intel x86|,Non-data,81
| It also leaks the translation-level for virtual ad- dresses on both Intel x86 and ARMv8-A We build three at- tacks exploiting these properties Our first attack retrieves an exact image of the full paging hierarchy of a process, defeating both user space and kernel space ASLR Our sec- ond attack resolves virtual to physical addresses to bypass SMAP on 64-bit Linux systems, enabling ret2dir attacks|,Non-data,81
| We demonstrate this from unprivileged user programs on Linux and inside Amazon EC2 virtual machines Finally, we demonstrate how to defeat kernel ASLR on Windows 10, enabling ROP attacks on kernel and driver binary code We propose a new form of strong kernel isolation to protect com- modity systems incuring an overhead of only 006–5|,Non-data,81
09% CCS Concepts •Security and privacy → Side-channel analysis and countermeasures; Systems security; Operating sys- tems security; Keywords ASLR; Kernel Vulnerabilities; Timing Attacks Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page Copyrights for components of this work owned by others than the author(s) must be honored Abstracting with credit is permitted,Non-data,81
| To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acmorg CCS’16, October 24 - 28, 2016, Vienna, Austria c(cid:13) 2016 Copyright held by the owner/author(s)|,Non-data,81
 Publication rights licensed to ACM ISBN 978-1-4503-4139-4/16/10  ,Non-data,81
 $1500 DOI: http://dxdoiorg/10,Non-data,81
|1145/29767492978356 1 INTRODUCTION The exploitation of software bugs imperils the security of modern computer systems fundamentally Especially, buffer overflows can allow an attacker to overwrite data structures that are used in the control flow of the program|,Non-data,81
| These attacks are not limited to user space software but are also possible on operating system kernels [16] Modern computer hardware provides various features to prevent exploitation of software bugs To protect against control-flow hijacking attacks, the operating system configures the hardware such that write access to executable pages is prevented Fur- thermore, the hardware is configured such that in kernel mode, the instruction pointer may not point into the user space, using a mechanism called supervisor mode execu- tion prevention (SMEP)|,Non-data,81
| Data accesses from kernel mode to user space virtual addresses are prevented by operating system and hardware, using a mechanism called supervi- sor mode access prevention (SMAP) To close remaining at- tack vectors, address-space layout randomization (ASLR) is used to make all addresses unpredictable for an attacker and thus make return-oriented-programming (ROP) attacks in- feasible All major operating systems employ kernel ASLR (KASLR) [32, 39, 43] Information on where objects are lo- cated in the kernel address space is generally not available to user programs|,Non-data,81
| Knowledge of virtual address information can be exploited by an attacker to defeat ASLR [17, 46] Knowledge of phys- ical address information can be exploited to bypass SMEP and SMAP [27], as well as in side-channel attacks [11,22,34, 35,42] and Rowhammer attacks [10,29,30,45] Thus, the se- curity of user programs and the kernel itself relies fundamen- tally on preventing access to address information Address information is often leaked directly through system inter- faces such as procfs [27] or indirectly through side chan- nels such as double page faults [17]|,Non-data,81
| However, operating system developers close these information leaks through se- curity patches [30] In this paper, we show that even if the operating system itself does not leak address information, recent Intel and ARM systems leak this information on the microarchitectural level We introduce Prefetch Side-Channel Attacks, a new class of generic attacks that allow an unprivileged local attacker to completely bypass access control on address information This information can be used to compromise the entire phys- ical system by bypassing SMAP and SMEP in ret2dir at- tacks or defeating KASLR and performing ROP attacks in the kernel address space|,Non-data,81
| Our attacks are based on weak- nesses in the hardware design of prefetch instructions In- 368deed, prefetch instructions leak timing information on the exact translation level for every virtual address More severely, they lack a privilege check and thus allow fetching inacces- sible privileged memory into various CPU caches Using these two properties, we build two attack primitives: the translation-level oracle and the address-translation oracle|,Non-data,81
| Building upon these primitives, we then present three dif- ferent attacks Our first attack infers the translation level for every virtual address, effectively defeating ASLR Our sec- ond attack resolves virtual addresses to physical addresses on 64-bit Linux systems and on Amazon EC2 PVM instances in less than one minute per gigabyte of system memory This allows an attacker to perform ret2dir-like attacks|,Non-data,81
| On mod- ern systems, this mapping can only be accessed with root or kernel privileges to prevent attacks that rely on knowl- edge of physical addresses Prefetch Side-Channel Attacks thus render existing approaches to KASLR ineffective Our third attack is a practical KASLR exploit We provide a proof-of-concept on a Windows 10 system that enables return-oriented programming on Windows drivers in mem- ory|,Non-data,81
| We demonstrate our attacks on recent Intel x86 and ARM Cortex-A CPUs, on Windows and Linux operating systems, and on Amazon EC2 virtual machines We present a countermeasure against Prefetch Side-Channel Attacks on commodity systems, that involves reorganizing the user and kernel address space to protect KASLR Our countermeasure requires only a small number of changes to operating system kernels and comes with a performance im- pact of 006–5|,Non-data,81
09% Our key contributions are: 1 We present two generic attack primitives leveraging the prefetch instructions: the translation-level oracle and the address-translation oracle We then use these primitives in three different attacks,Non-data,81
| 2 We present a generic attack to infer the translation level for every virtual address to defeat ASLR 3 We demonstrate generic unprivileged virtual-to-physical address translation attack in the presence of a physical direct map in kernel or hypervisor, on Linux and in a PVM on Amazon EC2|,Non-data,81
| This allows bypassing SMAP and SMEP, enabling ret2dir attacks 4 We present a generic attack to circumvent KASLR, which enables ROP attacks inside the kernel We demon- strate our attack on a Windows 10 system|,Non-data,81
 5 We propose a new form of strong kernel isolation to mitigate Prefetch Side-Channel Attacks and double page fault attacks on kernel memory Outline This paper is structured as follows,Non-data,81
 Section 2 provides background on caches and address spaces Section 3 presents the settings and two novel attack primitives leveraging the prefetch instructions: the translation-level oracle and the address-translation oracle The translation-level oracle is used in Section 4 to perform a translation-level recovery at- tack to defeat ASLR The address-translation oracle is used in Section 5 to perform unprivileged virtual-to-physical ad- dress translation as the basis of ret2dir attacks,Non-data,81
| Both oracles are used in Section 6 to defeat KASLR Section 7 shows how to perform cache side-channel and Rowhammer attacks on inaccessible kernel memory Section 8 presents countermea- sures against our attacks Section 9 discusses related work, and Section 10 concludes this article|,Non-data,81
| 2 BACKGROUND AND RELATED WORK 21 Address translation To isolate processes from each other, CPUs support vir- tual address spaces For this purpose, they typically use a multi-level translation table|,Non-data,81
| Which translation table is used is determined by a value stored in a CPU register This reg- ister value is exchanged upon a context switch Thus, each process has its own address mappings and only access to its own address space The kernel is typically mapped into every address space but protected via hardware-level access control|,Non-data,81
| When a thread performs a system call it switches to an operating system controlled stack and executes a kernel- level system call handler However, it still has the same translation table register value In the case of recent Intel CPUs, this translation table has 4 levels On each level, translation table entries define the properties of this virtual memory region, e|,Non-data,81
|g, whether the memory region is present (ie, mapped to physical memory), or whether it is accessible to user space|,Non-data,81
| The upper-most level is the page map level 4 (PML4) It divides the 48- bit virtual address space into 512 memory regions of each 512 GB (PML4 entries) Each PML4 entry maps to page directory pointer table (PDPT) with 512 entries each con- trolling a 1 GB memory region that is either 1 GB of phys- ical memory directly mapped (a so-called 1 GB page), or to a page directory (PD) The PD again has 512 entries, each controlling a 2 MB region that is either 2 MB of phys- ical memory directly mapped (a so-called 2 MB page), or a page table (PT)|,Non-data,81
| The PT again has 512 entries, each con- trolling a 4 KB page The lowest level that is involved in the address translation is called the translation level The CPU has special caches and so-called translation-lookaside buffers for different translation levels, to speed up address translation and privilege checks A second, older mechanism that is used on x86 CPUs in virtual-to-physical address translation is segmentation|,Non-data,81
| User processes can be isolated from each other and especially from the kernel by using different code and data segments Seg- ments can have a physical address offset and a size limit, as well as access control properties However, these features are widely redundant with the newer translation table mecha- nism Thus, most of these features are not available in 64-bit mode on x86 CPUs|,Non-data,81
| In particular, all general purpose seg- ments are required to have the offset set to physical address 0 and the limit to the maximum value Thus, the CPU can ignore these values at runtime and does not have to perform runtime range checks for memory accesses 22 Virtual address space The virtual address space of every process is divided into user address space and kernel address space|,Non-data,81
| The user ad- dress space is mapped as user-accessible, unlike the kernel space that can only be accessed when the CPU is running in kernel modeThe user address space is divided into memory regions for code, data, heap, shared libraries and stack De- pending on the operating system, the user address space may look entirely different in different processes with respect to the absolute virtual offsets of the regions and also the order of the regions In contrast, the kernel address space looks mostly identical in all processes|,Non-data,81
| To perform context switches, the hardware requires map- ping parts of the kernel in the virtual address space of every 3690 Physical memory max phys a p m dire ct 0 User 247 −247 Kernel −1 Virtual address space Figure 1: Direct mapping of physical memory A physical address is mapped multiple times, once ac- cessible for user space and once in the kernel space|,Non-data,81
| process When a user thread performs a syscall or handles an interrupt, the hardware simply switches into kernel mode and continues operating in the same address space The difference is that the privileged bit of the CPU is set and kernel code is executed instead of the user code Thus, the entire user and kernel address mappings remain generally unchanged while operating in kernel mode|,Non-data,81
| As sandboxed processes also use a regular virtual address space that is pri- marily organized by the kernel, the kernel address space is also mapped in an inaccessible way in sandboxed processes Many operating systems have a physical memory region or the whole physical memory directly mapped somewhere in the kernel space [28, 32] This mapping is illustrated in Fig- ure 1 It is used to organize paging structures and other data in physical memory|,Non-data,81
| The mapping is located at a fixed and known location, even in the presence of KASLR Some hy- pervisors also employ a direct map of physical memory [49] Thus, every user page is mapped at least twice, once in the user address space and once in the kernel direct map When performing operations on either of the two virtual addresses, the CPU translates the corresponding address to the same physical address in both cases|,Non-data,81
| The CPU then performs the operation based on the physical address Physical direct maps have been exploited in ret2dir at- tacks [27] The attacker prepares a code page to be used in the kernel in the user space Exploiting a kernel vulnera- bility, code execution in the kernel is then redirected to the same page in the physical direct map|,Non-data,81
| Hence, the attacker has obtained arbitrary code execution in the kernel 23 Address-space layout randomization Modern CPUs protect against code injection attacks (eg|,Non-data,81
|, NX-bit, W ⊕X policy), code execution in user space memory in privileged mode (eg, SMEP, supervisor mode execution protection), and data accesses in user space memory regions in privileged mode (eg|,Non-data,81
|, SMAP, supervisor mode access pro- tection) However, by chaining return addresses on the stack it is possible to execute small code gadgets that already ex- ist in the executable memory regions, eg, return-to-libc and ROP attacks|,Non-data,81
| In an ROP attack, the attacker injects return addresses into the stack and in some cases modifies the stack pointer to a user-controlled region, in order to chain the ex- ecution of so-called gadgets These gadgets are fragments of code already existing in the binary, typically consisting of a few useful instructions and a return instruction ASLR is a countermeasure against these control flow hi- jacking attacks Every time a process is started, its virtual memory layout is randomized|,Non-data,81
| ASLR can be applied on a coarse-grained level or a fine-grained level In the case Core 0 Core 1 L o o k u p d i r e c t i o n ITLB DTLB PDE cache PDPTE cache PML4E cache ITLB DTLB PDE cache PDPTE cache PML4E cache Page table structures in system memory (DRAM) Figure 2: Paging caches are used to speed-up ad- dress translation table lookups of coarse-grained ASLR, only the base addresses of differ- ent memory regions are randomized, eg|,Non-data,81
|, code, data, heap, libraries, stack This is mostly performed on a page-level granularity An attacker cannot predict addresses of code and data and thus cannot inject modified code or manipu- late data accesses In particular, an attacker cannot predict the address of gadgets to be used in an ROP attack|,Non-data,81
| All modern operating systems implement coarse-grained ASLR Fine-grained ASLR randomizes even the order of functions, variables, and constants in memory on a sub-page-level gran- ularity However, it incurs performance penalties, and can be bypassed [47] and thus is rarely used in practice User space ASLR primarily protects against remote at- tackers that only have restricted access to the system and thus cannot predict addresses for ROP chains|,Non-data,81
| KASLR pri- marily protects against local attackers as they cannot predict addresses in the kernel space for ROP chains In particular, invalid accesses cause a crash of the application under attack or the entire system On Windows, the start offsets of the kernel image, drivers and modules, are randomized 2|,Non-data,81
|4 CPU caches CPU caches hide slow memory access latencies by buffer- ing frequently used data in smaller and faster internal mem- ory Modern CPUs employ set-associative caches, where ad- dresses are mapped to cache sets and each cache set consists of multiple equivalent cache lines (also called ways) The in- dex to determine the cache set for an address can be based on the virtual or physical address The last-level cache is typ- ically physically indexed and shared among all cores|,Non-data,81
| Thus executing code or accessing data on one core has immediate consequences for all other cores Address translation structures are stored in memory and thus will also be cached by the regular data caches [21] In addition to that, address translation table entries are stored in special caches such as the translation-lookaside buffers to allow the CPU to work with them When accessing virtual addresses these buffers are traversed to find the correspond- ing physical address for the requested memory area|,Non-data,81
| The caches of the different table lookups are represented in Fig- ure 2 These caches are typically fully-associative As CPUs are getting faster, they rely on speculative execu- tion to perform tasks before they are needed Data prefetch- ing exploits this idea to speculatively load data into the cache|,Non-data,81
| This can be done in two different ways: hardware prefetching, that is done transparently by the CPU itself, and software prefetching, that can be done by a program- mer Recent Intel CPUs have five instructions for software 370prefetching: prefetcht0, prefetcht1, prefetch2, prefetch- nta, and prefetchw These instructions are treated like hints to tell the processor that a specific memory location is likely to be accessed soon The different instructions al- low hinting future repeated accesses to the same location or write accesses|,Non-data,81
| Similarly, recent ARMv8-A CPUs sup- ply the prefetch instruction PRFM Both on Intel and ARM CPUs, the processor may ignore prefetch hints 25 Cache attacks Cache attacks are side-channel attacks exploiting timing differences introduced by CPU caches|,Non-data,81
| Cache attacks have first been studied theoretically [26,31], but practical attacks on cryptographic algorithms followed since 2002 [3, 38, 48] In the last ten years, fine-grained cache attacks have been proposed, targeting single cache sets In an Evict+Time at- tack [37], the attacker measures the average execution time of a victim process, eg|,Non-data,81
|, running an encryption The at- tacker then measures how the average execution time changes when evicting one specific cache set before the victim starts its computation If the average execution time is higher, then this cache set is probably accessed by the victim A Prime+Probe attack [37,41] consists of two steps|,Non-data,81
| In the Prime step, the attacker occupies one specific cache set Af- ter the victim program has been scheduled, the Probe step is used to determine whether the cache set is still occupied A new generation of Prime+Probe attacks have recently been used to perform attacks across cores and virtual machine borders [22, 34, 35] as well as from within sandboxes [36] Gullasch et al|,Non-data,81
| [13] built a significantly more accurate at- tack that exploits the fact that shared memory, eg, shared libraries, is loaded into the same cache set for different pro- cesses running on the same CPU core Yarom and Falkner [50] presented an improvement over this attack, called Flush+ Reload that targets the last-level cache and thus works across cores|,Non-data,81
| Flush+Reload attacks work on a single cache line granularity These attacks exploit shared inclusive last-level caches An attacker frequently flushes a targeted memory lo- cation using the clflush instruction By measuring the time it takes to reload the data, the attacker determines whether data was loaded into the cache by another process in the meantime|,Non-data,81
| Applications of Flush+Reload are more reliable and powerful in a wide range of attacks [12, 14, 23, 24, 51] Flush+Reload causes a high number of cache misses due to the frequent cache flushes This has recently also been used to perform a memory corruption attack called Rowham- mer [29] In a Rowhammer attack, an attacker causes ran- dom bit flips in inaccessible and higher privileged memory regions|,Non-data,81
| These random bit flips occur in DRAM memory and the Flush+Reload loop is only used to bypass all levels of caches to reach DRAM in a high frequency Proof-of- concept exploits to gain root privileges and to evade a sand- box have been demonstrated [44] For the attack to succeed, an attacker must hammer memory locations that map to dif- ferent rows in the same bank However, the mapping from addresses to rows and banks is based on physical addresses|,Non-data,81
| Thus, Rowhammer attacks are substantially faster and eas- ier if physical address information is available as an attacker can directly target the comparably small set of addresses that map to different rows in the same bank As a counter- measure, operating systems have recently restricted access to physical address information to privileged processes [30] 3 SETTING AND ATTACK PRIMITIVES In this section, we describe the prefetch side channel and two primitives that exploit this side channel|,Non-data,81
| We build a translation-level oracle, that determines whether a page is present and which translation table level is used for the mapping This primitive is the basis for our translation- level recovery attack described in Section 4 to defeat ASLR We build an address-translation oracle that allows verifying whether a specific virtual address maps to a specific physi- cal address We use this to resolve the mapping of arbitrary virtual addresses to physical addresses to mount ret2dir at- tacks, defeating SMAP and SMEP, in Section 5|,Non-data,81
| We use both attack primitives in our the KASLR exploit described in Section 6 31 Attack setting and attack vector Attack setting In our attacks, we consider a local attack scenario where user space and KASLR are in place|,Non-data,81
| The attacker can run arbitrary code on the system under attack, but does not have access to the kernel or any privileged interfaces such as /proc/self/pagemap providing user space address informa- tion This includes settings such as an unprivileged process in a native environment, an unprivileged process in a virtual machine, and a sandboxed process To exploit a potential vulnerability in kernel code, an at- tacker cannot inject code into a writable memory region in the kernel, or directly jump into code located in the user address space as this is prevented by modern CPUs with features like the NX-bit, SMEP, and SMAP Thus, an at- tacker can only reuse existing code in a so-called code reuse attack, e|,Non-data,81
|g, ROP attacks However, building an ROP pay- load requires exact knowledge of the addresses space lay- out Even if the operating system does not leak any address space information and ASLR is employed and effective, we show that the hardware leaks a significant amount of address space information|,Non-data,81
| The information gained allows an attacker to conduct cache side-channel attacks and Rowhammer attacks, as well as to defeat KASLR and bypass SMAP and SMEP in a ret2dir-like attack Attack vector Prefetch Side-Channel Attacks are novel and generic side- channel attacks We exploit the following two properties: Property 1 The execution time of prefetch instructions varies depending on the state of various CPU internal caches|,Non-data,81
 Property 2 Prefetch instructions do not perform any priv- ilege checks The execution time (Property 1) of a prefetch instruc- tion can be directly measured It is independent of privi- lege levels and access permissions We exploit this property in our translation-level oracle,Non-data,81
| Intel states that prefetching “addresses that are not mapped to physical pages” can in- troduce non-deterministic performance penalties [21] ARM states that the prefetch instructions are guaranteed not to cause any effect that is not equivalent to loading the address directly from the same user process [1] In both cases, we found timing differences to be deterministic enough to be ex- ploitable That is, Property 1 can be observed on all our test 371Table 1: Experimental setups|,Non-data,81
| CPU / SoC System type Microarchitecture i5-2530M, i5-2540M Sandy Bridge Laptop Laptop Desktop Laptop Desktop i5-3230M i7-4790 i3-5005U, i5-5200U i7-6700K Xeon E5-2650 Exynos 7420 Ivy Bridge Haswell Broadwell Skylake Sandy Bridge Amazon EC2 VM ARMv8-A Smartphone platforms shown in Table 1, ie, all Intel microarchitectures since Sandy Bridge as well as the ARMv8-A microarchitec- ture Thus, attacks based on Property 1 are applicable to the vast majority of systems used in practice|,Non-data,81
| We demon- strate our translation-level recovery attack on all platforms The timing difference caused by the lack of privilege checks (Property 2) can only be measured indirectly using one of the existing cache attack techniques The combination of the prefetch side channel with different cache attack tech- niques yields different properties Intel states that software prefetches should not be used on addresses that are not “managed or owned” by the user process [19], but in prac- tice does not prevent it, thus letting us do this in our attack|,Non-data,81
| Property 2 can be observed on all Intel test platforms shown in Table 1, ie, all microarchitectures since Sandy Bridge Thus, attacks based on Property 2 are applicable to the vast majority of desktop, server, and cloud systems|,Non-data,81
| Measurements Measuring the execution time of instructions or memory accesses is typically necessary to perform micro-benchmarks On ARM CPUs we experienced no difficulties with out-of- order execution We used clock_gettime() to measure time in nanoseconds, as in previous work [33], and surrounded the target instr|,Non-data,81
| with a memory and instruction barrier con- sisting of DSB SY; ISB Depending on the attack we used a memory access or the PRFM instruction as target instruction On Intel CPUs micro-benchmark measurements are sig- nificantly harder, due to out-of-order execution The in- structions rdtsc and rdtscp both provide a sub-nanosecond timestamp|,Non-data,81
| rdtscp also waits for all memory load opera- tions to be processed before retrieving the timestamp The cpuid instruction can be used to serialize the instruction stream To perform accurate measurements, Intel recom- mends using a sequence of cpuid; rdtsc before executing the code to measure and rdtscp; cpuid afterward [18] In cache side-channel attacks memory fences like mfence can be used to ensure that memory store operations are also serial- ized|,Non-data,81
| However, the prefetch instruction is not serialized by rdtscp or any memory fence, but only by cpuid [20] Due to these serialization issues we crafted instruction sequences to measure exactly a target instruction in different scenarios: 1 In cases of long measurements and measurements of memory access times, the target instruction is unlikely to be reordered before a preceding rdtscp instruction We thus use: mfence cpuid rdtscp target instr|,Non-data,81
| rdtscp cpuid mfence 2 When measuring prefetch instructions repeatedly, cor- rect values for minimum and median latency are im- portant Thus, noise introduced by cpuid is tolerable but reordering the target instruction is not, because it could lead to a lower measurement for the minimum latency|,Non-data,81
| In this case we use: mfence rdtscp cpuid target instr cpuid rdtscp mfence Depending on the attack we used a memory access, or the prefetch instructions prefetchnta and prefetcht2 as target instruction 3|,Non-data,81
|2 Translation-level oracle In the translation-level oracle, we exploit differences in the execution time of prefetch instructions (Property 1) Prefetch instructions resolve virtual addresses to physical addresses to enqueue the prefetching request Intel CPUs follow a defined procedure to find a cache entry or a physi- cal address for a specific virtual address (cf Section 4|,Non-data,81
1032 of Intel Manual Vol 3A [21]): 1,Non-data,81
 Cache lookup (requires TLB lookup) 2 TLB lookup 3 PDE cache lookup 4 PDPTE cache lookup 5,Non-data,81
| PML4E cache lookup The procedure aborts as early as possible omitting all sub- sequent steps Step 1 and 2 can be executed in parallel for the L1 cache and thus the latency of step 2 is hidden in this case However, in case of the L2 or L3 cache, step 2 needs to be executed before to complete the cache lookup in step 1 If no entry is found in any TLB, step 3 needs to be executed to complete step 2 and the same applies for steps 4 and 5|,Non-data,81
| Depending on the specific CPU, some caches may not be present and the corresponding steps are omitted Every step of the lookup procedure introduces a timing dif- ferences that can be measured For ARM CPUs, the same mechanism applies to the corresponding translation tables However, on all CPUs tested, we found at least 4 distinct average execution times for different cases|,Non-data,81
| The translation-level oracle works in two steps First, we calibrate the execution time of a prefetch instruction on the system under attack Second, we measure the execution time of a prefetch instruction on an arbitrary virtual address Based on the execution time, we can now derive on which level a prefetch instruction finished the search for a cache entry or a physical address|,Non-data,81
| Prefetch instructions on Intel CPUs ignore privilege lev- els and access permissions (Property 2) Thus, it is possible to prefetch execute-only pages, as well as inaccessible ker- nel memory When running the procedure over the whole address space, we now also obtain information on all kernel pages Note that even a process with root privileges could not obtain this information without loading a kernel module on modern operating systems|,Non-data,81
| 33 Address-translation oracle The lack of privilege checks (Property 2) is the basis for our second oracle, as well as other privilege checks that are not active in 64-bit mode on x86 CPUs (cf Section 21)|,Non-data,81
| An attacker can execute prefetch on any virtual address includ- ing kernel addresses and non-mapped addresses Thus, we can use prefetch as an oracle to verify whether two virtual addresses p and ̄p map to the same physical address The address-translation oracle works in three steps: 1 Flush address p 2|,Non-data,81
| Prefetch (inaccessible) address ̄p 3 Reload p If the two addresses map to the same physical address, the prefetch of ̄p in step 2 leads to a cache hit in step 3 with a high probability Thus, the access time in step 3 is lower than for a cache miss By repeating this measurement, the 372y c n e t a l |,Non-data,81
| i n M 250 200 150 100 0 e m i t n o i t u c e x E 400 300 200 250 100 50 Page offset in kernel direct map 200 150 Figure 3: Minimum memory access time for an ad- dress p after prefetching different inaccessible ad- dresses, on an i5-3320M Peak shows the single ad- dress ̄p mapping to the same physical address as p confidence level can be increased to the desired value One measurement round takes 100–200 nanoseconds on our test systems|,Non-data,81
| Thus, an attacker can run up to 10 million such measurements per second Figure 3 shows the minimum access time from step 3, over a set of inaccessible addresses ̄p measured on an i5-3320M The peak shows the single address ̄p that maps to the same physical address as p Similarly, we can also perform a microarchitectural tim- ing attack on prefetch instructions directly|,Non-data,81
| Based on the execution time of prefetch instructions (Property 1), we can measure whether a targeted address p is in the cache In this Evict+Prefetch-variant of the address-translation ora- cle, we exploit both properties of prefetch instructions (cf Section 31)|,Non-data,81
| As the target address might be inaccessible, we evict the address instead of flushing it in the first step The prefetching replaces the reload step and checks whether the inaccessible address is already in the cache: 1 Evict address p 2 Execute function or system call 3|,Non-data,81
| Prefetch p If the function or system call in step 2 accesses any address ̄p that maps to the same physical address as address p, we will observe a lower timing in step 3 with a high probability Thus, as in the regular address-translation oracle, we deter- mine whether an address ̄p and an address p map to the same physical address The difference is that in the Evict+ Prefetch-variant the address ̄p is unknown to the attacker Instead, the attacker learns that a targeted address p is used by the function or system call|,Non-data,81
| 4 TRANSLATION-LEVEL RECOVERY ATTACK In this section, we describe how to determine the trans- lation level from an unprivileged user space process based on the translation-level oracle described in Section 32 Pro- cesses with root privileges can normally obtain system infor- mation to derive the translation level, for instance on Linux using the pagemap file in procfs|,Non-data,81
| However, even here the information provided by the operating system is incomplete and to obtain the translation-level information for kernel memory, it is necessary to install a kernel module for this purpose We instead only rely on the timing difference ob- served when running a prefetch attack on an address Figure 4 shows the median prefetch execution time for 5 different cases measured on an i5-2540M compared to the actual mapping level We measured the execution time of prefetchnta and prefetcht2 in 0|,Non-data,81
|5 million tests The low- est median timing can be observed when the address is valid 383 230 P D P T 246 P D 222 P T P a g e 181 ( c a c h e d ) P a g e ( u n c a c h e d ) Mapping level Figure 4: Median prefetch execution time in cycles compared to the actual address mapping level, mea- sured on an i5-2540M Check PML4 offsets 0 0 0 Check PDPT offsets Check PDPT offsets Check PD offsets 511 511 0 1 GB page 511 511 2 MB page Entry present Figure 5: Breadth-first search through the page translation entries that are present The attacker obtains an accurate map of the page translation level for user and kernel address space|,Non-data,81
| and cached, with a median of 181 cycles It is interesting to observe that prefetching a non-cached address when all TLB entries are present has a median execution time of 383 cycles Thus, we can use prefetch instructions to distinguish cache hits and misses for valid addresses In case the tar- geted address is not valid, we observe different execution times depending the mapping level where the address reso- lution ends|,Non-data,81
| If the memory region has a page directory but the page table is not valid, the median execution time is 222 cycles If the memory region does not have a page directory but a PDPT, the median execution time is 246 cycles If the memory region does not have a PDPT, the median ex- ecution time is 230 cycles Note that these timings strongly depend on the measurement techniques in Section 3|,Non-data,81
1 We perform a breadth-first search starting with the PML4 and going down to single pages as illustrated in Figure 5 We start the recovery attack with the top-level PML4 re- cursively going down to the lowest level (cf Section 2,Non-data,81
|1) We eliminate measurement noise by checking multiple ad- dresses in each of the 512 regions on each layer The median execution time of a prefetch instruction sequence is used to decide whether a PDPT is mapped or not On the PDPT level we thus obtain information on 1 GB pages, on the PD level we obtain information on 2 MB pages and on the lowest level (PT) we obtain information on 4 KB pages|,Non-data,81
| On each level we learn whether the address is mapped directly from this level, or a lower level, or whether it is marked as invalid For a single check, we perform 28 tests that in total take less than 4ms on the i5-2540M We check 4 addresses per region and thus require less than 16ms per memory region Thus, for every translation table that is present, our attack has a runtime of approximately 8 seconds|,Non-data,81
| Programs on 373Linux typically use at least 8 translations tables (1 PML4, 2 PDPTs, 2 page directories, 3 page tables) The total run- time to only recover the translation levels for the user space here is approximately 1 minute However, recovering the translation levels for the kernel can take several minutes if 1 GB pages are used by the kernel, or even several hours if 2 MB pages are used for the physical direct map If more addresses are mapped in the user space, the execution time can increase to several minutes or hours, depending on the target process|,Non-data,81
| In either case, our attack successfully recovers the trans- lation level which is normally only accessible for processes with root privileges Obtaining this information effectively defeats ASLR, as the attacker can now accurately deter- mine which addresses are mapped to physical memory by locating libraries or drivers in inaccessible memory regions Finally, our attack defeats recently proposed countermea- sures [7] that employ execute-only mappings, as prefetch instructions ignore access permissions Translation-level recovery from Android apps|,Non-data,81
| Similarly to 64-bit x86, 64-bit ARMv8-A has a 4-level page translation mechanism This is for instance the case on our Samsung Galaxy S6 with an Exynos 7420 system-on-chip with a non-rooted stock Android system On this system, we use the unprivileged PRFM PLDL1KEEP instruction to prefetch memory and the unprivileged DC CIVAC instruction to flush memory from user space The basic translation-level recovery attack on our ARMv8- A CPU is the same as on Intel x86 CPUs|,Non-data,81
 The timing measurement by clock_gettime provides a measurement on a nanosecond scale The timing measurement is signifi- cantly faster than on Intel x86 CPUs as there is no cpuid instruction consuming a significant amount of cycles We performed 28 tests per address from an Android app In total this takes less than 50μs on our ARMv8-A system,Non-data,81
| Thus, the translation-level recovery attack runs on ARM- based devices successfully 5 ADDRESS-TRANSLATION ATTACK In this section, we describe how to mount ret2dir-like at- tacks without knowledge of physical addresses based on our address-translation oracle We also build an efficient attack to resolve virtual addresses to physical addresses|,Non-data,81
| This at- tack exploits the physical direct map in the kernel Many operating systems and hypervisors use such a mapping to read and write on physical memory [28, 32, 49] The phys- ical direct map has been exploited by Kemerlis et al [27] to bypass SMEP in their attack called ret2dir|,Non-data,81
| Similarly, this map can also be used for return stacks in an ROP at- tack if the attacker has knowledge of the physical address of user-accessible memory However, our address-translation attack is not restricted to ret2dir-like attacks, it also pro- vides physical address information that is necessary in many side-channel attacks and fault attacks [11,22,29,30,34,42,45] The attack does not require prior knowledge of the virtual offset of the physical direct map in the kernel This offset is typically fixed, but it can also be determined by using a translation-level recovery attack|,Non-data,81
| We demonstrate our at- tack on a native Ubuntu Linux system, and from within an Amazon EC2 instance The attacker runs the address-translation oracle on one address p and one address ̄p in the virtual memory area of Prefetched Not prefetched s e s a C 108 105 102 100 150 250 300 200 Latency in cycles 350 400 Figure 6: Access latency that has (or has not) been prefetched through a kernel address Measurements performed on Linux on an Intel i5-3320M s d n o c e S 150 100 50 0 Expected time per GB Raw false negatives 60% 40% 20% 0% i 5 - 2 5 4 0 M i 5 - 3 2 3 0 M i 7 - 4 7 9 0 i 5 - 5 2 0 0 U i 7 - 6 7 0 0 K Experimental setup Figure 7: Expected brute-force search time per GB of physical memory, searching for a 2 MB page|,Non-data,81
 Raw false negative rate after a single run of the attack On all platforms the whole system memory can be searched exhaustively within minutes to hours the kernel that is directly mapped to physical memory The timing difference resulting from prefetching ̄p is shown in Figure 6,Non-data,81
| Note that p and ̄p have the same page offset, as the page offset is identical for physical and virtual pages By only checking the possible offsets based on the known page size, the attacker reduces the number of addresses to check to a minimum The search space for 2 MB pages is only 512 possibilities per 1 GB of physical memory and for 4 KB pages only 262 144 possibilities per 1 GB of physical memory The attacker performs a brute-force search for the correct kernel physical direct-map address by trying all possible values for ̄p|,Non-data,81
| Finding an address ̄p means that the attacker has ob- tained an address that maps user space memory in the ker- nel address space, thus providing a bypass for SMAP and SMEP Thus it is possible to mount ret2dir-like attacks us- ing this address However, the correct physical address can be obtained by subtracting the virtual address of the start of the physical direct map On Linux, the physical direct map is located at virtual address 0xffff 8800 0000 0000|,Non-data,81
| Figure 7 shows the average brute-force search time per gi- gabyte of physical memory, when searching for a 2 MB page In this search, we ran our address-translation oracle 214 to 217 times, depending on the architecture Increasing the number of runs of the address-translation oracle decreases the false negative rate but at the same time increases the execution time We did not find any false positives in any of the native attack settings|,Non-data,81
| Depending on the architec- ture, delays were introduced to lower the pressure on the prefetcher The highest accuracy was achieved on the i5- 3230M (Ivy Bridge), the i7-4790 (Haswell), and the i5-5200U (Broadwell) systems where the false negative rate was be- 374tween 7% and 13% The accuracy was significantly lower on the i5-2540M (Sandy Bridge) test system However, the false-negative rate remained at ≥ 25% even with a higher number of address-translation oracle runs|,Non-data,81
| For the expected execution time per gigabyte of physical memory, we com- puted how long the attacks have to be repeated until the physical address is found with a probability of more than 99% The i5-2540M (Sandy Bridge) test system had the highest false negative rate and thus the expected search time is the highest here Similarly, on the Skylake system, the at- tack needs to be executed 3 times to find a physical address with a probability of more than 99% However, as the exe- cution time per round of the attack on the Skylake system was much lower than on the other systems, the expected execution time is close to the other systems|,Non-data,81
| Getting host physical addresses on Amazon EC2 On the Amazon EC2 instance running Linux, we exploit the Xen PVM physical direct map, located at virtual address 0xffff 8300 0000 0000 Apart from this, the basic attack remains the same To perform the attack on an Amazon EC2 instance, we compensated the noise by checking mul- tiple 4 KB offsets per 2 MB page|,Non-data,81
| Our machine was sched- uled on an Intel Xeon E5-2650 (Sandy Bridge) In a dual CPU configuration, it can manage up to 768 GB of physical memory To compensate for this huge amount of poten- tially addressable physical memory, we reduced the number of address-translation oracle runs from 215 to 213 Our at- tack speed is thus reduced from 154 seconds to 46 seconds per gigabyte on average, limiting the total attack time to less than 10 hours|,Non-data,81
| While this is significantly more than in a native environment with a smaller amount of physical memory, it is still practical to use this attack to translate a small number of virtual addresses to physical addresses As we had no direct access to the real address translation information, we verified our results based on the technique from Section 33 Translations are considered correct if mul- tiple consecutive verification loops confirm that the hypervi- sor physical direct-map addresses indeed allow prefetching the targeted user virtual address, and if the mappings of multiple addresses from the same virtual page can be con- firmed as well using the address-translation oracle|,Non-data,81
| We ob- tained an accuracy of the attack in the cloud that is compa- rable to the accuracy of the attack in a native environment The presumably correct physical address is always found, ie, no false negatives|,Non-data,81
| When searching through the maxi- mum 768 GB of address space, we consistently found 1 false positive match (ie, a 2 MB page) that was later eliminated in the verification loop Other operating systems|,Non-data,81
| Many other operating systems, such as BSD or OSX, maintain a physical direct map However, we found no such mapping on Windows Thus, our address-translation oracle can not directly be applied to Windows systems Although 64-bit Android has a physical direct map lo- cated at virtual address 0xffff ffc0 0000 0000 and 32- bit Android at virtual address 0xc000 0000, we were not able to build an address-translation oracle on Android|,Non-data,81
| As the prefetch instructions do not prefetch kernel addresses mapped through the second translation-table base register, the attack is mitigated However, an attack could be pos- sible on systems where user space and kernel space share a translation-table base register, while the kernel would still be inaccessible Similarly, the attack does not work on to- day’s Google NaCl sandbox as it uses a 32-bit address space using 32-bit segmentation The sandboxed process there- fore only partially shares an address space with the non- sandboxed code and thus the attack is mitigated|,Non-data,81
| However, we verified that a Prefetch Side-Channel Attack using cache eviction instead of clflush within the Google NaCl sandbox works on the lowest 4 GB of virtual memory Thus, when Google NaCl introduces support for 64-bit address spaces in the NaCl sandbox, 32-bit segmentation cannot be used anymore and our attack is likely to succeed on all virtual addresses and thus to leak physical addresses to sandboxed processes 6 KERNEL ASLR EXPLOIT In this section, we demonstrate how to defeat KASLR by using prefetch instructions|,Non-data,81
| We demonstrate our attack on Windows 10 and Windows 7 systems Similarly as in the previous attack, we try to locate mapped memory regions in address space regions that are not accessible from user space Again, we exploit the omission of privilege checks by prefetch instructions (Property 2) As described in Section 3, we use prefetch instructions in combination with code execution to identify the load address of drivers in kernel mode in this first stage of the attack|,Non-data,81
| In the second stage of the attack, we determine addresses used by a specific driver By locating the driver, we effectively defeat KASLR Similarly, on Windows 7, kernel and hardware-abstraction layer are located between virtual address 0xffff f800 0000 0000 and 0xffff f87f ffff ffff and system drivers are lo- cated between virtual address 0xffff f880 0000 0000 and 0xffff f88f ffff ffff On Windows 10, the address range is extended to the region from 0xffff 8000 0000 0000 to 0xffff 9fff ffff ffff|,Non-data,81
| Which drivers are present in the driver area depends on the system configuration Further- more, the order in virtual address space directly depends on the order the drivers are loaded, which again depends on the system configuration To exploit a kernel vulnerability and build an ROP chain in the code of a known driver, an attacker has to know the exact address offset of the driver However, the exact address offsets are randomized and can normally not be retrieved from user processes|,Non-data,81
| Our attack exploits that KASLR does not randomize the offset of drivers on a sub-page level Kernel and hardware-abstraction layer are loaded on consecutive 2 MB pages with a random 4 KB start offset on Windows 7 Thus, we cannot attack this memory region directly using a translation-level recovery at- tack However, an Evict+Prefetch attack is possible on any kernel memory region|,Non-data,81
| To build the most efficient attack, we target the driver memory area where we can first perform a translation-level recovery attack and an Evict+Prefetch at- tack afterward Windows 10 uses 4 KB pages instead, adding entropy to the randomized driver location In the first stage of our attack, we locate addresses mapped to physical memory in the driver memory area using our translation-level recovery attack Figure 8 illustrates the timing difference between valid and invalid addresses in the driver region on Windows 7 on an Intel i3-5005U|,Non-data,81
| As drivers are loaded consecutively in the virtual address space, we found it to be sufficient for our attack to search through the address space in 2 MB steps and measure where pages are mapped to physical memory On Windows 7, the average 375s e s a C 100% 75% 50% 25% 0% Valid Invalid 80 100 120 140 Time in cycles Figure 8: Timing difference of a prefetch sequence on valid and invalid addresses in kernel space, from unprivileged user space process Measurements per- formed on Windows 7 on an Intel i3-5005U 120 110 100 90 e m i t n o i t u c e x e |,Non-data,81
| g v A 0 4,000 8,000 12,000 Page offset in kernel driver region Figure 9: Second stage: driver region is searched by measuring average execution times of prefetching addresses in the driver memory area from the first stage Lowest average execution time is measured on an address in the memory of the targeted driver runtime for the first stage of the attack, mapping both the kernel region and the driver region, is 7 ms on an idle sys- tem On Windows 10, the first stage runs in 64 KB steps and takes 101 ms on average|,Non-data,81
| As Windows 10 maps 4 KB pages we scan the address range in 4 KB steps in an intermediate step taking 180 ms on average At a high system load, the attack requires several hundred repetitions to perform the first stage of the attack reliably, having an average runtime below 2 seconds on Windows 7 In the second stage of our attack, we use the Evict+ Prefetch variant of the address-translation oracle Instead of searching for pages that are mapped to physical memory, we now determine whether a target address p is used by a syscall|,Non-data,81
| Therefore, we perform the Evict+Prefetch attack over all potentially used addresses in a random order We run the following three steps: 1 We evict all caches For this purpose, we access a buffer large enough to evict all driver addresses from all TLBs, page translation caches, code and data caches|,Non-data,81
| 2 We perform a syscall to the targeted driver If the tar- get address p is used by the targeted driver, the CPU fetches it into the caches while executing the syscall 3|,Non-data,81
| We measure the timing of a prefetch instruction se- quence This reveals whether the target address p was loaded into the cache by the driver in the second step In order to verify the measurement, we perform a control run where we omit the system call to the targeted driver If the execution time of a prefetch instruction sequence on the target address p is higher without the system call, we learn that p is in fact used by the driver and not loaded into the cache by other driver activity on the system|,Non-data,81
| The attack can be repeated multiple times to increase the accuracy By determining the lowest virtual address in the driver region that is used by the targeted driver, we learn where the driver starts As we know the driver version we can now use the virtual addresses from this kernel driver in return- oriented-programming attacks The average runtime for the second stage of the attack is 490 seconds on Windows 7|,Non-data,81
| Thus, the total average runtime is below 500 seconds on Windows 7 on our i3-5005U On Windows 10 we narrowed down the potential addresses in the first stage more than in Windows 7 Thus, the average runtime of the second stage is also lower on Windows 10, requiring only 12 seconds on average to locate a driver 7|,Non-data,81
| OTHER APPLICATIONS In this section, we discuss how prefetch instructions can be used in other cache attacks First, we implemented mod- ified variant of Flush+Reload called Flush+Prefetch The measurement accuracy of this cache attack is comparable to Prime+Probe while the spatial accuracy is the same as in a Flush+Reload attack We verified the feasibility of this attack by implementing a cross-core covert channel|,Non-data,81
| On a Haswell i7-4790 we achieved a performance of 146 KB/s at an error rate of < 1% This is in the same order of magnitude as the fastest state-of-the-art cache covert channels [11] Second, the Evict+Prefetch variant of the address-trans- lation oracle can be used to perform a Flush+Reload -style attack on privileged kernel addresses Indeed, we demon- strated such an attack in Section 6 to detect whether specific virtual addresses are used by a driver|,Non-data,81
| However, an attacker could also spy on the usage of known virtual addresses in kernel code and drivers This would allow monitoring activ- ity on system and specific hardware interfaces Third, the Evict+Prefetch attack also allows performing Rowhammer attacks on privileged addresses An attacker could directly target kernel page tables or any other kernel data structure|,Non-data,81
| As the execution time is lower than that of Evict+Reload , an attack is likely possible We verified that bit flips can be induced by this attack on a system running at a refresh rate reduced to 25% However, we leave examinations on the prevalence of this problem on default configured systems and the study of practical Rowhammer exploits using Evict+Prefetch open to future work 8|,Non-data,81
| COUNTERMEASURES In this section, we discuss countermeasures against Prefetch Side-Channel Attacks First, we propose a new form of strong kernel isolation, that effectively prevents all Prefetch Side-Channel Attacks on the kernel address space Second, we will discuss countermeasures that have been proposed against other side-channel attacks and hardware modifica- tions to mitigate Prefetch Side-Channel Attacks Stronger kernel isolation|,Non-data,81
| Removing the identity mapping would help against our virtual-to-physical address translation attack and completely prevent ret2dir-like attacks, however, it would not protect against our KASLR or translation-level recovery attacks We propose stronger kernel isolation, a new form of strong kernel isolation, to provide security against a wide range of attacks Strong kernel isolation ensures that no address is mapped in both user space and kernel space This mech- anism has initially been proposed by Kemerlis et al|,Non-data,81
| [27] 376Today’s operating systems: Shared address space User memory Kernel memory context switch Stronger kernel isolation: User address space User memory Not mapped −1 −1 context switch a d d r  s p a c e s w i t c h Interrupt dispatcher Not mapped Kernel memory Kernel address space −1 0 0 0 Figure 10: Currently kernel and user memory are only separated through privilege levels With stronger kernel isolation, the kernel switches from the user space to a dedicated kernel space, directly after a context switch into privileged mode|,Non-data,81
| Thus, only a negligible portion of interrupt dispatcher code is mapped in both address spaces Their approach unmaps pages from the kernel physical di- rect map when they are mapped in user space This only introduces a performance penalty of 018–2|,Non-data,81
|91% However, this is not sufficient to protect against our attacks Instead, stronger kernel isolation does not run syscalls and unrelated kernel threads in the same address space as user threads We propose to switch the address translation tables imme- diately after the context switch into the kernel|,Non-data,81
| Thus, only short and generic interrupt dispatching code would need to be mapped in the same address space used by the user pro- gram The remainder of the kernel and also the direct map- ping of physical memory would thus not be mapped in the address translation tables of the user program This layout is illustrated in Figure 10 Stronger kernel isolation also eliminates the double page fault side channel [17], as no virtual address in the user pro- gram is valid in both user space and kernel space|,Non-data,81
 This countermeasure can be implemented on commodity hard- ware and existing operating systems and it only requires a few modifications in operating system kernels The perfor- mance impact is comparably small as switching the address translation tables has to be done once per context switch into the kernel and once per context switch from the ker- nel back to the user space This is done by replacing the value in the cr3 register on Intel x86 CPUs once per con- text switch We implemented a proof-of-concept to measure the overhead of updating the cr3 as an estimate for the per- formance penalty of stronger kernel isolation,Non-data,81
| Table 2 shows the overhead in different benchmarks We observe that for benchmarks that perform a small number of syscalls, the performance overhead is negligible, eg, 0|,Non-data,81
|06% For other benchmarks the overhead can be higher, eg, up to 5|,Non-data,81
|09% in the case of pgbench State-of-the-art countermeasures While there have been recent advances in detecting cache attacks using performance counters [6, 11, 15, 40] it is less Table 2: Estimation of overhead Benchmark Baseline Stronger kernel isolation Overhead apache pgbench pybench x264 37578|,Non-data,81
83 req/s 14681 trans/s 1552 ms 96,Non-data,81
20 fps 3720516 req/s 13970 trans,Non-data,81
|/s 1553 ms 9614 fps +100% +509% +0, 06% +0|,Non-data,81
|06% clear whether this is also applicable to Prefetch Side-Channel Attacks Prefetch Side-Channel Attacks can indeed cause an increased number of DTLB misses and thus could be de- tected using hardware performance counters We observe approximatively 4 billion DTLB hits/minute while brows- ing in Firefox, and approximatively 47 billion while running our virtual-to-physical attack A more thorough evaluation is needed to assess false positives|,Non-data,81
| While there are numerous events related to prefetching that can be monitored with per- formance counters, to the best of our knowledge, since Ne- halem micro-architecture it is not possible anymore to mon- itor software prefetching but only hardware prefetching [21] Future work has to show whether performance counters can indeed be used for a reliable detection mechanism We also note that while it is possible to disable hardware prefetching, it is not possible to disable software prefetching Hardware modifications|,Non-data,81
| Complete protection against Prefetch Side-Channel At- tacks could also be achieved through microarchitectural mod- ifications We think that prefetch instructions need to be modified in two ways to completely close this attack vector First, if prefetch instructions performed privilege checks just as other memory referencing instructions, prefetching kernel addresses would trigger a segmentation fault and the process would be killed It would also prevent measuring the trans- lation table levels over the whole address space as the pro- cess would be killed after accessing the first invalid address|,Non-data,81
| Second, prefetch instructions leak timing information on the cache state The timing difference on our ARM-based smart- phones was even higher than on our Intel x86 test system Eliminating this timing difference would only introduce a small performance overhead, as prefetch instruction are not used by most software This would prevent cache attacks based on prefetch instructions completely|,Non-data,81
 9 RELATED WORK Hund et al [17] demonstrated three timing side channel attacks to obtain address information The first is a cache attack searching for cache collisions with kernel addresses,Non-data,81
| The second performs double page faults to measure timing differences for valid and invalid memory regions introduced by the TLB The third exploits page fault timing differences due to the TLB and address translation caches The first attack is mitigated on current operating systems by prevent- ing access to physical addresses, and the second and third attacks can be prevented at the operating system level by preventing excessive use of page faults leading to segmenta- tion faults In contrast, our attack exploits the TLB and ad- dress translation caches without triggering any page faults|,Non-data,81
| Furthermore, as our approach leaks the timing more directly through prefetch instructions, it is faster and retrieves infor- mation on a finer granularity, ie, we can obtain the exact virtual-to-physical address translation Our approach is also more generic as it bypasses the operating system|,Non-data,81
| 377Kemerlis et al [27] presented two methods providing a ba- sis of ret2dir attacks First, they use the procfs interface to obtain physical addresses, now mitigated on current operat- ing systems by preventing access to this interface Second, they perform a memory spraying attack where they can use any address in the physical direct map for their ret2dir at- tack|,Non-data,81
| Our attack enables ret2dir-like attacks without knowl- edge of physical addresses and recovery of physical addresses from unprivileged user space applications, enabling ret2dir attacks As a countermeasure, they proposed strong kernel isolation, which we extended in this paper Barresi et al [2] focused on a cross-VM scenario to break ASLR in the cloud with CAIN, while our work mostly fo- cuses on a local attack, that can also be performed on a guest VM|,Non-data,81
| However, CAIN attacks assume a cloud environ- ment that enables memory deduplication, which is already known to be nefarious and is not deployed on eg, Ama- zon EC2 In contrast, our attacks do not require memory deduplication and have been performed on Amazon EC2|,Non-data,81
| Bhattacharya et al [4] showed that hardware prefetching, performed automatically by the CPU, leaks information In contrast to this work, we exploit software prefetching which can be triggered at any time by an attacker, from user space The hardware prefetcher has also been used by Fuchs and Lee [9], as a countermeasure against cache side channels|,Non-data,81
| Concurrent to our work, Jang et al [25] exploited In- tel TSX transaction to defeat KASLR TSX transactions prevent pagefaults by jumping to an alternative code path When accessing or executing on kernel address the timing difference until reaching the alternative code path leaks in- formation on the address translation caches|,Non-data,81
| Evtyushkin et al [8] exploit the branch-target buffer to break KASLR Finally, Chen et al [5] proposed dynamic fine-grained ASLR during runtime to defeat KASLR attacks|,Non-data,81
| 10 CONCLUSION Prefetch Side-Channel Attacks are a new class of generic attacks exploiting fundamental weaknesses in the hardware design of prefetch instructions These new attacks allow un- privileged local attackers to completely bypass access con- trol on address information and thus to compromise an en- tire physical system by defeating SMAP, SMEP, and kernel ASLR Our attacks work in native and virtualized environ- ments alike|,Non-data,81
| We introduced two primitives that build the basis of our attacks First, the translation-level oracle, ex- ploiting that prefetch leaks timing information on address translation Second, the address-translation oracle, exploit- ing that prefetch does not perform any privilege checks and can be used to fetch inaccessible privileged memory into various caches The translation-level oracle allowed us to defeat ASLR and locate libraries and drivers in inaccessi- ble memory regions|,Non-data,81
| Using the address-translation oracle, we were able to resolve virtual to physical addresses on 64- bit Linux systems and from unprivileged user programs in- side an Amazon EC2 virtual machine This is the basis for ret2dir-like attacks that bypass SMEP and SMAP Based on both oracles, we demonstrated how to defeat kernel ASLR on Windows 10, providing the basis for ROP attacks on ker- nel and driver binary code As a countermeasure against this new class of attacks, we proposed stronger kernel isola- tion, such that syscalls and unrelated kernel threads do not run in the same address space as user threads|,Non-data,81
| This coun- termeasure only requires a few modifications in operating system kernels and that the performance penalty is as low as 006–509% Therefore, we recommend that it is deployed in all commodity operating systems|,Non-data,81
 11 ACKNOWLEDGMENTS We would like to thank Klaus Wagner for help with some experiments and our anonymous reviewers for their valuable comments and suggestions Supported by EU Horizon 2020 programme GA No 644052 (HECTOR) and EU FP7 programme GA No,Non-data,81
|ABSTRACT Security against hardware trojans is currently becoming an essential ingredient to ensure trust in information systems A variety of solutions have been introduced to reach this goal, ranging from reactive (ie, detection-based) to pre- ventive (i|,Non-data,82
|e, trying to make the insertion of a trojan more difficult for the adversary) In this paper, we show how test- ing (which is a typical detection tool) can be used to state concrete security guarantees for preventive approaches to trojan-resilience For this purpose, we build on and formal- ize two important previous works which introduced “input scrambling” and “split manufacturing” as countermeasures to hardware trojans|,Non-data,82
| Using these ingredients, we present a generic compiler that can transform any circuit into a trojan-resilient one, for which we can state quantitative se- curity guarantees on the number of correct executions of the circuit thanks to a new tool denoted as “testing amplifica- tion” Compared to previous works, our threat model covers an extended range of hardware trojans while we stick with the goal of minimizing the number of honest elements in our transformed circuits Since transformed circuits essen- tially correspond to redundant multiparty computations of the target functionality, they also allow reasonably efficient implementations, which can be further optimized if special- ized to certain cryptographic primitives and security goals 1|,Non-data,82
| INTRODUCTION While modern cryptography generally assumes adversaries with black box access to their target primitives, the last two decades have witnessed the emergence of increasingly pow- erful physical attacks that circumvent this abstract model Side-channel analysis [23, 24] and fault attacks [10, 9] are typical examples of such concerns, where the adversary can respectively observe physical leakages produced by an imple- mentation, or force it to perform erroneous computations In this respect, hardware trojan attacks can be viewed as the ultimate physical attack, where the adversary can even modify the implementations at design time, in order to hide a backdoor that may be used after deployment This threat Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page|,Non-data,82
| Copyrights for components of this work owned by others than the author(s) must be honored Abstracting with credit is permitted To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee Request permissions from permissions@acm|,Non-data,82
|org CCS’16, October 24 - 28, 2016, Vienna, Austria c(cid:13) 2016 Copyright held by the owner/author(s) Publication rights licensed to ACM ISBN 978-1-4503-4139-4/16/10|,Non-data,82
   $1500 DOI: http://dx,Non-data,82
|doiorg/101145/29767492978419 has recently gained attention, since the increasing complex- ity of electronic systems, and the ongoing trend of outsourc- ing chip fabrication to a few specialized foundries, has made it more and more realistic, with possibly catastrophic conse- quences for security and safety [2, 8]|,Non-data,82
| As documented in [7, 28] the attacks by a malicious manufacturer are also hard to prevent, since they can lead to very diverse attack vectors, with various activation mechanisms and payloads In this context, and looking back at the already broad lit- erature on countermeasures against side-channel and fault attacks, an important lesson learned is that the most ef- fective protections usually rely on a good separation of du- ties between well-chosen (generally physical) assumptions and sound mathematical principles to amplify them Taking one emblematic example, masking improves security against side-channel attacks by relying on the assumption that phys- ical leakages are noisy, and by amplifiying this noise thanks to secret sharing [13] Based on the similar (physical) na- ture of hardware trojans, it is therefore reasonable to expect that solutions to prevent them may follow a similar path|,Non-data,82
| In this respect, and starting at the hardware level, detection thanks to side-channels possibly amplified by some finger- printing has been studied, eg, in [1, 3, 26] Very summa- rized, such approaches are powerful in the sense that they are in principle able to detect any type of trojan, including purely physical ones (e|,Non-data,82
|g, triggered by a temperature change and sending secret messages through an undocumented an- tenna), which makes them an important part of the puzzle But they are also inherently limited by their heuristic na- ture and sometimes strong assumptions For example, they work best in presence of a golden (trusted) chip that may not be easily available, and the effectiveness of the detection decreases when reducing the size of the trojan circuitry|,Non-data,82
| In this paper, we therefore tackle the question whether more formal solutions can help to rule out well-defined classes of hardware trojan attacks, and achieve stronger resistance in practice For this purpose, we build on two important previous works In the first one, Waksman and Sethumad- havan consider digitally triggered trojan attacks [30] A dig- itally triggered trojan is a malicious piece of hardware that delivers its payload when a digital input is given to the de- vice|,Non-data,82
| This can be done, for instance, through so-called “cheat codes” or “time bombs” The first type of attack triggers the malicious behavior of the trojan when a certain input is provided to the device, while “time bombs” activate the trojan, eg, after the device is executed for a certain num- ber of times|,Non-data,82
| The work of Waksman and Sethumadhavan provides ad-hoc countermeasures against these two types of 142attacks In particular, they propose to scramble the inputs to defeat the cheat codes and use power resets to protect against (volatile) time bombs In the second one, Imeson et al introduce the concept of “split manufacturing” for obfus- cation, as a way to make it hard for an adversary to identify the gates of an implementation that he would need to mod- ify to mount his attack [20]|,Non-data,82
| The main contribution of our work is to provide generic countermeasures for significantly broader classes of trojan attacks, and to provide a formal framework in which these countermeasures can be analyzed and concrete security bounds can be derived We describe our technical contribution in more detail below Types of hardware trojans Similar to Waksman and Sethumadhavan, we consider a setting where the produc- tion of a device is outsourced to a potentially malicious hardware manufacturer|,Non-data,82
| The manufacturer produces a set of devices D1,    , D(cid:96) that supposedly implement function- alities Γ1, |,Non-data,82
|   , Γ(cid:96), but may contain trojans and react ma- liciously As in [30] we restrict the type of malicious be- havior to hardware trojans that are digitally triggered, such as cheat codes or time bombs|,Non-data,82
| Besides formally modeling such digitally triggered trojans, we also extend the model of Waksman and Sethumadhavan by not only considering volatile time bombs (ie, where the clock needs to be pow- ered) but also non-volatile ones (which may become hard to detect in highly integrated electronic systems) The trojan protection schemes|,Non-data,82
| To protect against dig- itally triggered hardware trojans we introduce so-called tro- jan protection schemes A trojan protection scheme consists of two components: a circuit transformation TR and a tester T The transformation describes a method to compile an arbitrary functionality described as an arithmetic circuit Γ into a protected specification consisting of a trusted master circuit M and a set of circuits Γ1,  |,Non-data,82
|  , Γ(cid:96) We assume that M has to be implemented in a trusted way and its production is not outsourced to the malicious hardware manufacturer A, while the devices Di are produced by A To obtain a stronger result, we require that M is as simple as possible|,Non-data,82
| For our concrete construction M will consist of a couple of wires and a small number of simple gates – in particular, the size (counted as the number of gates) of M is independent of the size of Γ The implementation of our transformed circuits therefore follows the same “split manufacturing” principles as introduced by Imeson et al [20] The second component of the trojan protection scheme is a tester T|,Non-data,82
 The tester ver- ifies if the devices Di correctly implement the functionality Γi Such tests typically involve whether the input/output behavior of Di corresponds to the input/output behavior of the honest specification Γi Robustness of trojan protection schemes The main security guarantee that our trojan protection scheme shall achieve is called robustness,Non-data,82
| Informally, robustness is mod- eled by a game with two phases First, in the testing phase the tester T checks whether the devices Di implement the corresponding specification Γi If the testing is passed the adversary can in a second phase interact with the device composed of the trusted master M and the devices Di Ro- bustness guarantees that for the same inputs, the outputs produced in the second phase by the device are identical to the outputs produced by the honest specification Γ|,Non-data,82
| Ro- bustness is parameterized by two parameters t and n, where t denotes the number of tests carried out by T and n is the number of executions for which the output produced by the device has to be identical to the honest specification Γ Typically, for our constructions we require t > n A trojan protection scheme for any functionality Γ Our main contribution is the design of a trojan protection scheme that achieves robustness for any functionality Γ|,Non-data,82
| We next give a high-level description of our trojan protection scheme omitting several technical details As a first step, the transformation compiles the specifica- tion Γ into three so-called mini-circuits (Γ0, Γ1, Γ2) These mini-circuits emulate Γ using a passively secure 3-party pro- tocol, where the inputs to (Γ0, Γ1, Γ2) are secret-shared by the trusted master circuit M The first observation in order to achieve robustness is that if the mini-circuits Γi follow exactly the secure 3-party proto- col, then they do not learn anything about the user provided input|,Non-data,82
| Hence, a malicious user is hindered in activating the trojan by choosing a special input Of course, once Γi gets implemented by A nothing stops A to produce devices Di that do not follow the protocol, eg, by transmitting their shares to the other devices|,Non-data,82
| Such a behavior will, however, be detected with good probability during the testing phase The above only prevents activation of the trojan by a ma- licious input, but does not deal yet with an activation via time-bombs For instance, assume that the trojan is acti- vated only after the (t + 1)-th execution If we test devices only for t times, the malicious behavior will not be detected and achieving robustness is infeasible|,Non-data,82
| To circumvent this, we randomize the number of tests t(cid:48), where t(cid:48) is drawn uni- formly from {1,    , t}|,Non-data,82
| Since (i) the total number of exe- cutions after testing is bounded by n and (ii) test and real executions look the same from the device’s point of view (due to the 3-party computation), we can bound the probability that malicious behavior is triggered by time bombs Unfortunately, the above gives only a weak security bound It is, however, easy to amplify security by letting A produce λ independent copies (D0 λ), so that (cid:96) = 3λ, where each such tuple is tested for a random and independent number of times ti In our final construction, the master M then runs each of the tuples on independent input sharings and takes the majority of the results to pro- duce the final output with good robustness|,Non-data,82
| Concretely, we can guarantee correct execution with probability(cid:0) n (cid:1)λ/2 1),   |,Non-data,82
| , (D0 1, D1 1, D2 λ, D1 λ, D2 t Applications of trojan protection schemes The re- quirement that t > n can be viewed as a limitation of our work, but we argue in Section 3 that this condition is in fact necessary for testing-based security against hardware trojans Hence, such schemes are only applicable in settings where there is an a-priori bound on the number of times the device is used Such bounded number of executions natu- rally occurs when a user manually interacts with a device|,Non-data,82
| Since testing can be automatized it is then feasible to carry out millions of test cases, while after deployment many de- vices are used only a few thousand times There are many examples of such settings (eg, opening doors)|,Non-data,82
| Their rele- vance naturally increases with the sensitivity of the data to protect and not too limited cost constraints, such as elec- tronics in planes used for starting and landing (which have natural restrictions on the number of executions) We stress that nothing prevents the master circuit M to count the number of runs, issue a warning when the executions limit is reached, and then to re-perform a testing phase 143Implementation issues Despite our primary focus is on the genericity and formal guarantees of the proposed coun- termeasure against hardware trojans, we also take imple- mentation issues into account in our developments|,Non-data,82
| In this respect, we first limit the use of trusted components to some routing and a couple of gates, as in [20] We argue in Sec- tion 3 why a minimum complexity (ie, the presence of gates in M) is necessary for testing-based security against hard- ware trojans|,Non-data,82
| Next, and as far as performances are con- cerned, the main efficiency bottleneck in our trojan protec- tion scheme is the use of a passively secure 3-party compu- tation protocol We discuss the time and area overheads it implies for a mainstream cryptographic functionality such as a standard block cipher in Section 52 And we conclude the paper by showing that better efficiency can be achieved if we aim for protecting specific cryptographic primitives|,Non-data,82
| In particular, we give constructions for a PRG and a MAC that only increase the complexity by a linear factor (cid:96) (compared to the unprotected scheme), while guaranteeing security ex- cept with probability O(2−(cid:96)) Notice that these schemes also have two additional benefits compared to our generic solution: first, except for an initial secret sharing of the in- puts their execution does not require the sometimes costly generation of pseudorandomness, and second they require almost no interaction between the sub-devices Related works In a separate line of papers, Bayer and Seifert [6] and very recently Wahby et al|,Non-data,82
| and Ateniese et al [29, 5] consider a setting where an untrusted ASIC proves, each time it performs a computation, that the execution is correct These papers build on a large literature on verifiable computation, probabilistically checkable proofs and other, related topics Compared to our work, such approaches and techniques correspond to a different tradeoff between secu- rity and trust|,Non-data,82
| On the one hand, they cover even broader classes of hardware Trojans and achieve security for an arbi- trary number of executions (unlike us who restrict the num- ber of executions a-priori) On the other hand, they require a trusted verifier which is typically more complex than our master circuit that does only routing and and uses a small number of gates1 These works also aim at different goals than ours Namely, whenever a proof of correct execution is not verified in [29, 5], the system stops|,Non-data,82
| By contrast, we can guarantee a number of correct executions and therefore are also resistant against denial-of-service attacks The work of Haider et al [19] also shares similarities with ours, and provides a formal analysis of trojan detection using pre-silicon logic testing tools Eventually, our constructions follow the seminal investi- gations of Ishai et al|,Non-data,82
| who introduced circuit transformation in the field of side-channel and fault attacks [21, 22] Their results on “Private Circuits” (I and II) motivated us to look at generic compilers for trojan-resilient circuits, which is a natural next step in the study of physical adversaries against cryptographic hardware Conceptually, the principles we ex- ploit in our trojan protection schemes are also close to mask- ing against side-channel attacks Namely, masking exploits secret sharing and multiparty computation in order to am- plify the impact of noise in leaking cryptographic implemen- tations|,Non-data,82
| Similarly, we exploit these techniques to amplify the impact of testing against hardware trojans 1Comparing the efficiencies of prover sides is more challeng- ing since application-dependent, and is therefore an inter- esting scope for further research 2 TROJAN PROTECTION SCHEMES 2|,Non-data,82
|1 The model of computation 211 The circuit specification Computation carried out by an algorithm is abstractly defined via a specification We model the specification as a circuit Γ, which is represented by a Directed Acyclic Graph (DAG)|,Non-data,82
| The set of vertices of the graph represents the gates of the circuit, while the edges are the wires connecting the gates The wires in the circuit carry elements from a finite field F, while the gates carry out the operations in the finite field or take special task such as storing values The sim- plest case is when F is the binary field, in which case the wires carry bits, and the gates, for instance, represent the Boolean operations AND (next denoted by (cid:12)) and XOR (next denoted by ⊕) For simplicity, all the gates are as- sumed to have at most fan-in two|,Non-data,82
| On the other hand, gates may have arbitrary fan-out, where we assume that all out- put wires carry the same value We will also consider the arithmetic circuits, where F is a larger field, and the gates represent the corresponding arithmetic operations In addition to the standard Boolean/arithmetic gates, we allow the specification Γ to contain two additional gates: the randomness gates rand and (volatile and non-volatile) mem- ory gates The randomness gate has no incoming wires but can have an arbitrary number of outgoing wires, which carry a random element from F|,Non-data,82
| One may think of rand as a gate producing true randomness Next, the non-volatile memory gates (next called registers), are used to store the results of the computation’s different (clock) cycles and only maintain their state when the chip is powered Registers have a single incoming wire and an arbitrary number of outgoing wires They can be placed everywhere in the circuit, but we require that each cycle of Γ contains at least one register|,Non-data,82
| Eventu- ally, non-volatile memory gates (next called memory gates for short) play a similar role as volatile ones, but maintain their state even if the chip is not powered To complete the description of the circuit, we also need to explain how it processes inputs/outputs The circuit takes inputs (cid:126)x ∈ Fα and the outputs (cid:126)y ∈ Fβ as a result of the computation are delivered to the user One may view them as wires carrying the inputs and outputs, respectively, that are connected to the “outside world” of the circuit|,Non-data,82
| For a circuit that takes as input (cid:126)x and produces output (cid:126)y we write (cid:126)x ← Γ((cid:126)y) and call it a run of Γ or a round, which usually takes several clock cycles to be executed Beside the public inputs/outputs, the circuit also may keep a (secret) state between runs of Γ The secret state of Γ is initially set through the Init operation and kept in non-volatile memory gates We write Init(Γ, (cid:126)m) when the initial state of Γ is set to (cid:126)m|,Non-data,82
| Notice that the state of Γ may change via the public inputs (cid:126)x, in which case we say Γ is stateful Otherwise, if the state is only written once via the Init procedure, we say that Γ is stateless For a com- putation on input (cid:126)x and an initial state (cid:126)m ∈ Fs, we write (cid:126)x ← Γ[ (cid:126)m]((cid:126)y) If Γ has been run for many rounds then (cid:126)m may already have been changed|,Non-data,82
| 212 Circuit compilers The goal of the circuit compiler (or transformer) TR = (TR1, TR2) is to compile a specification described as a cir- cuit Γ into a protected specification Γ(cid:48) We write for the 144compilation process: Γ(cid:48) ← TR1(1k, (cid:96), Γ), where k is the computational security parameter (e|,Non-data,82
|g, used for the PRG in our following generic construction) and (cid:126)m(cid:48) ← TR2(1k, (cid:96), (cid:126)m) for compiling the initial state In the following, we will of- ten abuse notation and omit to explicitly denote the com- piled state by (cid:126)m(cid:48) since in our construction it will be just a longer (secret-shared) vector Also, we will sometimes omit to mention explicitly the parameter (cid:96), when it is clear from the context|,Non-data,82
| The specification of Γ(cid:48) consists of two parts First, a set of sub-circuits Γ1,   |,Non-data,82
| , Γ(cid:96) and second, a so-called master circuit M2 The role of the master circuit M is to manage the communication between the sub-circuits Γi and the user of these circuits While these sub-circuits can be constructed using the above described gates, for ease of no- tation we choose to describe them with an additional feature for communication That is, we allow the sub-circuits Γi to communicate with M and vice versa|,Non-data,82
| To this end, we intro- duce commands having the form (cmd, val), where cmd is a label denoting the command that shall be executed and val is an accompanied element in F (or a vector thereof) We will consider the following types of commands: 1 The command ((send, j), (cid:126)x) is sent by Γi to M to spec- ify that Γi wants to send message (cid:126)x to the circuit j 2|,Non-data,82
| The command (in, (cid:126)x) is sent by M to Γi to specify that Γi receives message (cid:126)x as input 3 The command (out, (cid:126)y) is sent by Γi to M to specify that Γi’s output is ready and worth (cid:126)y The evaluation of the sub-circuits Γ1, |,Non-data,82
|   , Γ(cid:96) with master M on input (cid:126)x with initial state (cid:126)m producing output (cid:126)y will next be written as (cid:126)y ← (M ⇔ Γ1,  |,Non-data,82
|  , Γ(cid:96))[ (cid:126)m]((cid:126)x), where (cid:126)m is the initial compiled state One may think of (M ⇔ Γ1,  |,Non-data,82
|  , Γ(cid:96)) as a circuit composed of the sub-circuits Γi and M, where the composition is specified by the communication commands between Γi and M In the following we will often need to describe the view of a circuit Γi The view of Γi includes all command/value pairs denoted by (cmd, val) that Γi receives/sends from/to M|,Non-data,82
| The view of Γi is denoted by View(Γi[ (cid:126)m]((cid:126)x)) and contains tuples of the form (cmd, val) Notice that the view also includes the inputs/outputs given by M to Γi The simplest property that we require from the transfor- mation is correctness That is, for all (cid:126)m, (cid:126)xi it holds that outputs produced by Γ on initial state (cid:126)m with input (cid:126)xi are identical to the outputs produced by Γ(cid:48) on initial state (cid:126)m(cid:48) with input (cid:126)xi|,Non-data,82
| Notice that if Γ was a randomized circuit (ie, it uses rand gates), then we require that the output distributions are computationally indistinguishable The second property that we require is robustness against malicious manufacturers, which we introduce in the next sec- tion|,Non-data,82
| To look ahead, we will typically let the manufacturer produce devices Di that take the role of Γi, while the master M is required to be implemented honestly Of course, due to this assumption, the latter has to be as simple as possi- ble (in our case typically M will only require wiring devices together and a few very basic operations) 22 Security against malicious manufacturers Consider a circuit specification Γ with initial state (cid:126)m and let (Γ(cid:48), (cid:126)m(cid:48)) ← (TR1(1k, (cid:96), Γ), TR2(1k, (cid:96), (cid:126)m)), where Γ(cid:48) = (M, (Γ1, |,Non-data,82
|   , Γ(cid:96))) We are interested in a setting where a 2Notice that Γ1, |,Non-data,82
|   , Γ(cid:96) and M are described using the circuit model from above and therefore may include memory cells potential malicious manufacturer A gets as input the speci- fications (Γ1, |,Non-data,82
|   , Γ(cid:96)) and produces a set of devices D1,  |,Non-data,82
|  D(cid:96), where Di supposedly implements some functionality Γi A device Di takes some input (cid:126)x and produces an output (cid:126)y In order to compute (cid:126)y from the input (cid:126)x the device Di may com- municate with the master circuit M, which is implemented honestly|,Non-data,82
| To this end, it can send and receive commands of the form (cmd, val) to/from M While the devices Di can in principle implement any functionality (since they are built by the malicious hardware manufacturer), we require that an implementation of Di can be simulated using our circuit model above, as formalized by the following assumption Assumption 1 Let Di be the devices output by A|,Non-data,82
| We require that there exists (possibly probabilistic) circuit specifi- cations(cid:101)Γi such that for all public inputs (cid:126)x ∈ Fα and any ini- tial state (cid:126)m ∈ Fs, we have View(Di[ (cid:126)m]((cid:126)x)) ≡ View((cid:101)Γi[ (cid:126)m]((cid:126)x)) Informally, the assumption says that as long as a trojan attack can be modeled by a (possibly probabilistic) circuit, then the attack is within our security model Note that this allows for fairly general trojan attacks For instance, we will not make any assumption of the computational complexity of the trojan other than it was produced by a PPT adversary A|,Non-data,82
| This, eg, means that it can be more complex than the computation carried out by the honest specification Γi We note also that some restriction on the power of the trojan attack is necessary|,Non-data,82
| For instance, if the trojan embeds an antenna into the device that sends secret data via a side- channel to the attacker, then security is hard to achieve Looking ahead, at a technical level Assumption 1 is also crucial for the security proof and shows up in Theorem 13 We discuss the plausibility of Assumption 1 and the attacks that are (not) incorporated in our model in Section 54|,Non-data,82
