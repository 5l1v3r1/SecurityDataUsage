Routing State Distance:

A Path-based Metric for Network Analysis

Gonca Gürsun, Natali Ruchansky, Evimaria Terzi, and Mark Crovella

Department of Computer Science

Boston University

ABSTRACT

Characterizing the set of routes used between domains is
an important and diﬃcult problem. The size and complex-
ity of the millions of BGP paths in use at any time can
hide important phenomena and hinder attempts to under-
stand the path selection behavior of ASes.
In this paper
we introduce a new approach to analysis of the interdomain
routing system designed to shed light on collective routing
policies. Our approach starts by deﬁning a new metric for
‘distance’ between preﬁxes, which we call routing state dis-
tance (RSD). We show that RSD has a number of properties
that make it attractive for use in visualizing and analyzing
the state of the BGP system. Further, since RSD is a met-
ric, it lends itself naturally to use in clustering preﬁxes or
ASes. In fact, the properties of RSD allow us to deﬁne a
natural clustering criterion, and we show that this criterion
admits to a simple clustering algorithm with provable ap-
proximation guarantees. We then show that by clustering
ASes using RSD, one can uncover macroscopic behavior in
BGP that was previously hidden. For example, we show
how to identify groups of ASes having similar routing poli-
cies with respect to certain destinations, which apparently
reﬂects shared sensitivity to economic or performance con-
siderations. These routing patterns represent a considerable
generalization and extension of the notion of BGP atoms to
the case where routing policies are only locally and approx-
imately similar across a set of preﬁxes.

Categories and Subject Descriptors

C.2.3 [Network Operations]: Network monitoring; C.2.5
[Local and Wide-Area Networks]: Internet — BGP

Keywords

BGP, Interdomain Routing

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’12, November 14–16, 2012, Boston, Massachusetts, USA.
Copyright 2012 ACM 978-1-4503-1705-4/12/11 ...$15.00.

1.

INTRODUCTION

One of the principal challenges in working with measure-
ments of Internet topology is to extract insight from mas-
sive, complex datasets. Many projects have collected ex-
tensive measurements of Internet topology at the router or
autonomous-system (AS) level, but comparatively few tools
have been developed to discover important patterns or struc-
tures in the resulting data. The lack of such tools makes it
diﬃcult to visualize the Internet topology, understand the
routing behavior of ASes, and detect signiﬁcant changes in
Internet routing.

In this paper, we deﬁne a new metric for analyzing routing
at the interdomain level, and we describe various kinds of
useful data analysis that the metric enables. The metric is
called routing state distance (RSD); it measures ‘closeness’
between two preﬁxes in terms of similarity of routing to the
preﬁxes.

The key idea behind RSD can be stated simply: the rout-
ing state distance between two preﬁxes is conceptually just
the number of ASes that disagree about the next hop to the
two preﬁxes. (Later we will make this notion precise and
deal with the practical issues that arise in applying it to
real BGP measurements.) The basic idea is illustrated in
Figure 1. Figures 1(a), (b), and (c) each show the next hops
from a set of ASes to diﬀerent destinations. The routing
state distance between the destinations in (a) and (b) is 3,
because there are three ASes that choose diﬀerent next hops
between (a) and (b). Likewise, the routing state distance
between the destinations in (b) and (c) is 5.

The key properties of RSD can be understood by contrast-
ing it with typical measures of distance between ASes. The
most common starting point is the AS graph – a graph in
which nodes are ASes – and distance is traditionally thought
of as some number of hops between ASes. In contrast, RSD
is not deﬁned in terms of a graph; rather, it is deﬁned in
terms of a set of paths. This has a number of advantages.
First of all, it is well-known that measurements of the AS
graph are highly incomplete (a recent review of this prob-
lem is [17]). By deﬁning RSD in terms of AS paths rather
than the AS graph, the problem of missing edges in the AS
graph does not arise. This is a crucial advantage, given the
large fraction of missing edges in AS graph measurements.
Second, as we will show later, the set of paths to a preﬁx is a
much richer characterization of the preﬁx’s location than is
its position in the AS graph. As a result, RSD can provide
much more nuanced information about the relative location
of two (or more) preﬁxes than can be provided by simply
noting their position in a graph.

239(a)

(b)

(c)

Figure 1: Example illustrating RSD. In each ﬁgure the ﬁlled node is the destination.

Having deﬁned RSD, we next explore its utility. We show
that it has a number of desirable properties. First, it is
a metric (it obeys the triangle inequality), which makes it
easy to reason about. Second, we show that it deﬁnes ﬁne-
grained neighborhoods — the number of preﬁxes that are
within distance d of a given preﬁx declines smoothly with
decreasing d. Third, we show that RSD generally exhibits
low eﬀective dimension, which means that 2-D visualiza-
tions can capture most of the information present in a set
of RSD measurements. And fourth, we show that RSD has
a natural clustering criterion, and that criterion has an as-
sociated clustering algorithm with provable approximation
guarantees.

Most importantly, these four properties together allow us
to develop an analytic toolkit that we use to uncover sur-
prising patterns and behaviors that have not previously been
documented in the interdomain routing system. Using the
RSD toolkit we demonstrate the existence of collective rout-
ing behavior that we call local atoms. Roughly, a local atom
is a set of preﬁxes that are routed similarly, but only in some
region of the Internet. We show the existence of local atoms
spanning a wide range of sizes, from macroscopic (Internet-
wide) to microscopic. Although detecting these sorts of pat-
terns in data is hard in general, we show that RSD and its
associated clustering tools are natural and eﬀective ways to
uncover local atoms in BGP data.

Finally, we note that RSD, as a measure of distance be-
tween ASes, was ﬁrst introduced by G¨ursun et al. [10]. How-
ever, that paper used RSD for a speciﬁc purpose (as an input
to a particular inference algorithm), and did not focus on
the exploration of the theoretical and practical properties of
RSD as a distance measure. In this paper, we ﬁll this gap by
studying the geometric properties of RSD and by deﬁning
notions of clustering appropriately tailored to this measure.
Finally, we provide a thorough experimental study, which
demonstrates the utility of RSD and the clusters identiﬁed
by our clustering framework. Although our present study
is motivated by the concept of RSD deﬁned in [10], none of
the results we present here were anticipated or discussed in
that previous paper.

2. ROUTING STATE DISTANCE

In this section we deﬁne RSD starting from a general def-
inition for arbitrary graphs. We then discuss how to cus-
tomize RSD to address the practical issues that arise when
applying it to BGP measurements.

2.1 Deﬁnition

To deﬁne RSD, we will assume a universe X of nodes,
with |X| = n.1 To ﬁx a set of paths, we require that for
each source-destination pair (x1, x2) there is a unique node
x3, which is the next hop on the path from x1 to x2. We
denote this by x3 = N(x1, x2). Note by following the nodes
on N(·, x2) recursively, one will eventually reach x2. We also
assume that the next hop of every node x is the node itself;
i.e., N(x, x) =x . Thus, N encodes a set of paths that leads
from each node to every other node, without any branches
or loops.

We generally treat the function N as an n×n matrix. That
is, we interpret N(x!, x) as a matrix element that stores the
next hop from node x! to node x. We also use N(x, :) (resp.
N(:, x)) to denote the x-th row (resp. column) of N. We call
N the nexthop matrix that encodes the paths over the set
X.

Using the nexthop matrix, we can deﬁne the Routing State

Distance (RSD) between two nodesx 1 and x2 as follows:

RSD(x1, x2) = |{xi | N(xi, x1) "= N(xi, x2)}| .

(1)

That is, RSD(x1, x2) is the number of positions where the
columns N(:, x1) and N(:, x2) diﬀer. Hence, by deﬁnition,
RSD is an integer that takes values in {0, . . . , n}. Referring
back to Figure 1, each of the subﬁgures (a), (b), and (c)
corresponds to a single column N(:, x) for diﬀerent values
of x. Intuitively, N(:, x) tells us what the ‘direction’ is to x
from each node in X. Two nodes that appear to most other
nodes to be in the same direction are considered close under
RSD.

We now show that RSD satisﬁes the triangle inequality.

Proposition 1. For

any nodes x1, x2,

and x3,

RSD(x1, x2) ≤ RSD(x1, x3) + RSD(x2, x3).

Proof. Assume the opposite, i.e., that RSD(x1, x2) >
RSD(x1, x3) +RSD (x2, x3). Then there must be a node x
for which N(x, x1) "= N(x, x2), but for which N(x, x1) =
N(x, x3) and N(x, x2) =N( x, x3), which is a contradic-
tion.

Oftentimes, we use rsd to refer to the normalized value
of RSD. That is, for every x1, x2 we deﬁne the normalized
RSD as follows:

rsd(x1, x2) =

RSD(x1, x2).

(2)

1
n

1Note that the deﬁnition given here is essentially equivalent
to that in [10], but has been recast in somewhat diﬀerent
terms for simplicity of discussion.

240By deﬁnition, rsd(x1, x2) ∈ [0, 1] and – given that it is a
rescaling of RSD – it also satisﬁes the triangle inequality.
Intuitively, the the rsd value between two nodes x1 and
x2 encodes the fraction of positions in which the columns
N(:, x1) and N(:, x2) diﬀer with each other.

2.2 Applying RSD to BGP Analysis

Having deﬁned RSD, we next seek to apply it to a dataset
of publicly available BGP paths so as to compute the RSD
between preﬁx pairs in the dataset. However, computing
RSD from BGP data raises some implementation consider-
ations.

The ﬁrst issue concerns the distinction between ASes
(which choose next hops, but are not themselves destina-
tions) and preﬁxes (which are destinations, but do not make
next-hop choices). In fact, our framework can adapt to this
situation easily. We slightly redeﬁne the matrix N: while
the columns of N correspond to preﬁxes, the rows of N cor-
respond to ASes. Thus, to analyze BGP, N(a, p) needs to
be deﬁned as the next hop from AS a on the path to preﬁx
p.

The next issue concerns the fact that publicly available
BGP data consists (essentially) of paths from a set of mon-
itor ASes to a large collection of preﬁxes. For any given
AS-preﬁx pair (a, p), these paths may not contain informa-
tion about N(a, p). We address this by approximating RSD.
We make the following observation: some ASes have a much
larger impact on RSD than others. For example, a stub AS
a has a highly uniform row N(a, :). If the stub AS a has
a small set of providers, then for many preﬁxes p1, p2, ...,
N(a, p1) =N( a, p2) =... . In the limit of a stub AS that
makes use of only a single provider, the row N(a, :) will be
constant. Note that a constant row in N has no eﬀect on
the RSD value of any preﬁx pairs. Since the majority of
ASes are stub ASes, most ASes contribute little information
to RSD.

Thus, we observe that we can approximate RSD using just
a subset of all ASes. In particular we should use the ASes
with many neighbors since these ASes have many next hop
choices and therefore can contribute the most information
to RSD. We call these ASes the basis set. We select the
basis set by identifying those ASes with the largest number
of neighbors in our data.2 Luckily, such ASes tend to appear
on many paths in the publicly available data; hence we can
often ﬁnd N(a, p) when a is in the basis set.

To address the case when N(a, p) is not available (for AS
a in the basis set), we performed extensive studies of the ef-
fect of missing nexthop information on RSD. We found that
proportional approximation yields results that work well in
practice. This approximation allows the matrix N to include
‘don’t know’ elements. We then approximate RSD by the
fraction of known positions in which N(:, p1) and N(:, p2)
diﬀer, times the number of ASes in the basis set. This en-
sures that the approximation to RSD always ranges between
zero and the size of the basis set.

One consequence of using proportional approximation to
RSD is that it can introduce minor violations of the triangle
inequality. However we ﬁnd that in practice, such violations
are quite small and do not impair our ability to reason about
RSD or use it as if it were a metric.

The last issue is that for some AS-preﬁx pairs there is
2Two nodes are neighbors if they appear consecutively on
any path.

1

0.8

0.6

0.4

0.2

F
D
C

0
0

50

100

RSD

150

200

250

Figure 2: Distribution of D for 1000 preﬁx pairs.

more than one next hop. This happens when an AS uses
detailed routing policies (such as hot-potato routing) that
are not strictly per-neighbor. That is, traﬃc destined for
the same preﬁx may take diﬀerent next hops depending on
where it enters the network. We address this problem the
same way as in [14], i.e., by introducing the notion of ‘quasi-
routers.’ Using the algorithm in [14] we divide each AS in
the basis set into a minimal set of quasi-routers such that
for each (quasi-router, preﬁx) pair there is a unique next
hop AS. Thus, the rows of N correspond either to ASes or
quasi-routers of ASes.

Having addressed these issues, we can compute our version
of RSD specialized for BGP, which we store in the n × n
matrix D. Clearly, the values of the cells of D depend on
the number of rows in N, i.e., the total number of ASes (or
quasi-routers of ASes). For the rest of the discussion we will
assume that we have m such ASes and therefore N is of size

the normalized rsd for BGP.

m × n and D(x, x!) ∈ {0, . . . , m}. We also use eD to denote
3. DATASETS

To evaluate our methods, we use a collection of BGP ta-
bles collected on midnight UTC on December 6, 2011 from
the Routeviews [18] and RIPE [16] repositories.

The full dataset is collected from 359 unique monitors; it
consists of over 48 million AS paths, and contains 454,804
unique destination preﬁxes. However, the dataset does not
contain paths from every monitors to every preﬁx. Rather,
there is a subset of preﬁxes that appear in most tables, i.e.,
to which most monitors have paths. We chose a subset of
135,369 preﬁxes on this basis; these preﬁxes are typically
present in most BGP tables in our dataset.

Next, we need to select a subset of monitors to serve as the
basis set, as described in Section 2.2. We select the basis set
by identifying 77 ASes with the largest number of neighbors
in our data. Finally, we expand the basis set with quasi-
routers to handle the cases where there is not a unique next
hop to certain preﬁxes. This expands the size of the basis
set from 77 to 243. Hence, our ﬁnal N matrix is of size 243
× 135,369.

From N we can compute D, our RSD metric based on
BGP paths applied to preﬁxes. To illustrate the distribution

241l

l

s
e
u
a
v
 
r
a
u
g
n
s

i

12 x 104

10

8

6

4

2

0
0

10

20

30

40

50

Figure 3: Singular values of D.

of D values, Figure 2 shows the CDF of D for a randomly
chosen set of 1000 preﬁx pairs. The ﬁgure shows three im-
portant aspects of RSD applied to preﬁxes. First, it takes on
values in the range 0 to 243, because there are 243 ASes and
quasi-routers in the basis set. Second, it varies smoothly –
there are no sudden jumps or steps in the distance function.
This is in contrast to a metric like hop distance, in which
going from hop distance 1 to hop distance 2 encompasses
a huge increase in the number of preﬁx pairs. Finally, the
gradual slope on the left of the ﬁgure shows that RSD can
make ﬁne distinctions between preﬁx pairs. The number
of preﬁxes in a neighborhood grows very slowly for small to
moderate values of RSD, which means that RSD can be used
to identify ﬁne-grained groups of preﬁxes. This capability
will be important when we use RSD for clustering later in
the paper.

4. VISUALIZATION WITH RSD

In this section, we motivate the use of RSD for visualiza-
tion and we demonstrate that visualization using RSD can
yield useful insights in the analysis of interdomain routing.

4.1 Why 2-D Visualization is Meaningful

As described in Section 2, the information provided by
RSD can be organized into a distance matrix D in which
D(i, j) = RSD(i, j). We seek a way to eﬀectively visualize
the information contained in D.

To do so, we start by observing that in practice, we ﬁnd
that D has low eﬀective rank. That is, although D is a n×n
matrix it can be well approximated by a matrix of rank r
with r % n. A simple way to assess this is through a scree
plot, which is a plot of the singular values of D in decreasing
order. The sum of the ﬁrst k squared singular values is equal
to the fraction of total variance in D that can be captured
in a rank-k approximation. Thus, the scree plot of D gives
a direct assessment of the eﬀective rank of D.

We start by choosing 3000 preﬁxes at random from the
set of all 135,369 preﬁxes in our dataset. We then form the
3000 × 3000 matrix D consisting of the RSD values for all
preﬁx pairs. The scree plot of D is shown in Figure 3.

The Figure shows that D has very low eﬀective rank –
almost all of the the variation in D is captured in ﬁve di-

150

100

50

0

−50

D
S
R

−100

−100

−50

0

50

RSD

100

150

Figure 4: Visualization of RSD for 3000 randomly chosen
preﬁxes. Axes are marked in units of RSD to give a sense of
scale to the plots.

mensions, and even a rank-2 approximation to D captures
more than half of D’s total variance. (Results for other ran-
dom samples look very similar).

The fact that D has low eﬀective rank is important for
a number of reasons. First, it suggests that (as we will
demonstrate) RSD captures speciﬁc phenomena – were the
matrix D purely random, it would have high eﬀective rank.
Second, from a visualization standpoint, it indicates that a
large fraction of the total information captured by RSD can
be represented in a 2-D or 3-D visualization.

Thus, Figure 3 suggests that even a 2-D visualization of D
should give a reasonably accurate picture of its information
content. The usual way to construct such a visualization is
by using multidimensional scaling (MDS) [19]. Given a set of
items I and a set of item-item distances {dij}, i, j ∈ I, MDS
assigns each item a location xi, i ∈ I in some r-dimensional
Euclidean space. The goal is that distances between items
in Euclidean space should closely approximate the given set
of input distances {dij}. That is, MDS seeks to minimize:

min

x1,...,x|I|

X

i<j

(||xi − xj|| − dij)2 .

When r = 2, the result can be plotted; in such a plot, dis-
tances (i.e., RSD values) are approximately preserved.

4.2 The Emergence of Clusters

We use MDS to visualize the randomly chosen set of 3000
preﬁxes. The results are shown in Figure 4; distances be-
tween points in this ﬁgure approximate RSD. The ﬁgure
shows remarkable high-level structure: there are two large
clusters, with the smaller cluster comprising about 23% of all
preﬁxes. We ﬁnd this same clustering quite consistently for
any random sampling of preﬁxes; it seems to be an Internet-
wide phenomenon.

The fact that Internet preﬁxes cluster into two distinct
groups under the RSD metric is surprising. In fact, under-
standing the reason behind the presence of the two clusters
in Figure 4 is important and motivates our subsequent anal-
yses. Hence, we will now explore the cause of these two
clusters in depth.

First, we consider exactly what causes clustering under

242150

100

50

0

−50

D
S
R

Denmark

Brazil

Switzerland

Brazil
Canada

India
Sweden

Russia

Korea
Korea
Japan
Hong Kong
China

Australia

Thailand

US

−100

−100

−50

0

50

RSD

100

150

Figure 5: A cluster within the nexthop matrix N.

Figure 6: Locations of a random subset of preﬁxes.

RSD. Consider a cluster of preﬁxes C. This cluster corre-
sponds to a set of columns of N, i.e., N(:, C). Because the
preﬁxes in C are close to each other in RSD, the columns
of N(:, C) are similar to each other, at least in certain posi-
tions. This must be the case, by the deﬁnition of RSD.

This situation is shown in Figure 5. The ﬁgure shows the
nexthop matrix N, where cluster C is shown in gray. The
fact that the columns are similar in certain positions S is
signiﬁed by the horizontal bars. Note that for the columns
to be similar, rows in S must be constant (or at least nearly
constant).3 The region where the rows are constant is the
submatrix N(S, C).
(We have assumed that the columns
and rows of N have been reordered to bring out this struc-
ture.)

The key fact is that, in order for the preﬁxes in C to
cluster together, there will typically be a subset of rows S
with the following property: for any row within the subma-
trix N(S, C), the next hop AS in each cell must be (nearly)
always the same AS. That is, the entries of N(S, C) are ex-
pected to be highly coherent.

Thus, we can identify a cluster with a coherent submatrix
N(S, C). To understand what such coherent submatrices
signify, we consider how they arise in the course of BGP
routing. Expressed in terms of BGP, N(S, C) captures a set
of source ASes (S) that all make similar routing decisions
with respect to a set of destination ASes (C, i.e., the clus-
ter). In Section 6, we use diﬀerent measures to quantify and
evaluate the coherence of the submatrix N(S, C).

We refer to the pair (S, C) as a local atom. A local atom
is a generalization of the notion of BGP atoms [6]. Whereas
a BGP atom is a set of preﬁxes that are routed the same
way by all routers in the Internet, a local atom is a set
of preﬁxes that are routed similarly in some region of the
Internet (i.e., by the ASes in S). To be interesting, a local
atom (S, C) should have a signiﬁcant number of ASes in S
and also preﬁxes in C.

To illustrate the concept of a local atom, we return to the

3Strictly speaking, it is possible to construct a cluster with-
out a common set of similar rows; but such an arrangement
is highly unlikely in practice as it requires a very speciﬁc
structure. In all the cluster examples we study, we ﬁnd that
the preﬁxes cluster together because of a common set of
similar rows.

example in Figure 4. The smaller cluster turns out to be
the result of a local atom. We demonstrate this as follows.
Sampling the preﬁxes in the smaller cluster, we ﬁnd that
they belong primarily to networks in the Far East, with a
small portion belonging to networks in the US. For example,
out of a random sample of 100 preﬁxes we ﬁnd that 64%
are Far East and Paciﬁc Rim networks (including Korea,
Japan, Taiwan, Thailand, Singapore, China, Hong Kong,
Australia, and New Zealand) and 30% are from North Amer-
ica. However, there are also many Far Eastern (29%) and
North American (20%) preﬁxes in the larger cluster (along
with 33% European, which are almost completely absent in
the smaller cluster).4 Figure 6 shows examples of where
a random selection of these preﬁxes occurs within the two
clusters.

Given that Far Eastern and US preﬁxes occur in both
clusters, why then should this speciﬁc set of Far Eastern
and US preﬁxes group together in the smaller cluster?

The answer has to do with the next-hop decisions made
by the source set S. There are 35 ASes in the S set; they are
predominantly in Europe (52%) and North America (40%).
These ASes prefer one particular provider for transit to the
Far East and US. This provider is Hurricane Electric, ASN
6939 (‘HE’). The overwhelming presence of AS 6939 as a
next-hop results in the observed coherence of N(S, C). On
the other hand, the set of ASes in S does not commonly
agree on next hops to destinations in Europe. Therefore,
these preﬁxes do not occur in the local atom. Instead, those
preﬁxes appear in the larger cluster in Figure 4.

Figure 7 is a visualization of a portion of the nexthop ma-
trix N. In this plot, colors represent the ﬁve most popular
next-hop ASes across both clusters. The preﬁxes (columns)
consist of 50 samples chosen at random from each of the two
clusters. The ﬁrst 35 rows correspond to the ASes in set S
and the remaining rows are other ASes shown for compar-

4The assignment of a preﬁx to a geographic region was done
by noting the AS that announced the preﬁx, and then com-
bining information from the various routing registries along
with inspection of network maps and peering relationships
where available.
In particular, for preﬁxes that were an-
nounced by internationally distributed ASes, care was taken
to identify the region the preﬁx originated from.

243s
e
c
r
u
o
S

10
20
30
40
50
60
70
80
90
100

20

40
60
Destinations

80

100

Figure 7: Coherence of the N(S, C) submatrix for the
smaller cluster. The ﬁve most frequently-occurring ASes
are shown in color: 6939 (Hurricane Electric, blue), 10026
(Pacnet, green), 3257 (TiNet, red), 3356 (Level3, turquoise),
and 3549 (Global Crossing, magenta).

ison. The local atom (S, C) can be seen as the submatrix
N(S, C) in the upper left part of the plot.

The ﬁgure shows the remarkable coherence of the N(S, C)
submatrix. The similarity of the columns on the left side of
the plot is the reason that those preﬁxes cluster together in
Figure 4. It also shows that, while sources in S clearly dis-
tinguish between preﬁxes in the two clusters, other sources
do not.

In fact, the preﬁxes that occur in the smaller cluster have
the following property: if any path from a monitor to a pre-
ﬁx in our dataset passes through Hurricane Electric, then
that preﬁx is in the smaller cluster. This remarkable fact
is illustrated in Figure 8. The ﬁgure shows which preﬁxes
can be reached from one or more monitors through three of
the most commonly occurring ASes in our data: (a) Level
3, (b) Hurricane Electric, and (c) Sprint. The ﬁgure shows
that what determines which preﬁxes go into the smaller clus-
ter is whether the preﬁx can be reached through Hurricane
Electric.

An example of routing to one such preﬁx is shown in Fig-
ure 9 (generated using BGPlay [4]). The preﬁx is one of
those that falls into the smaller cluster. The ﬁgure shows
how Hurricane Electric (ASN 6939) plays a special role with
respect to this preﬁx for a large set of ASes. The presence
of the smaller cluster is a result of routing patterns similar
to Figure 9 for all the preﬁxes in the cluster.

To uncover the reasons behind this eﬀect, we consulted
with a number of the network operators whose BGP conﬁg-
urations contributed to the clustering (that is, operators of
networks in the source set S). As a result, we can explain
the reason for this unusual routing behavior with respect to
Hurricane Electric: HE is a large ISP, but it has an open
peering policy. That is, any ISP that has a presence in an
exchange point in common with HE will be allowed to peer
with HE at that exchange point [12]. HE is present in dozens
of exchange points, mainly in the US and Europe (but with
some in the Far East).

Note that most operators will prefer peer routes over
provider routes in general. This implies that an ISP that

peers with HE will typically use HE as the next-hop to reach
any network that is a customer of HE (and not one of its own
customers). Hence, we can identify S as largely consisting
of networks that peer with HE, and D as the set of networks
that are customers (or customers of customers, etc.) of HE.
Thus, the presence of two clusters among Internet pre-
ﬁxes is due to a large-scale phenomenon:
for many ASes,
Hurricane Electric is the preferred next hop for any preﬁxes
for which it provides transit. Thus this local atom is a case
of similar decision making by independent entities (ASes)
when driven by common external factors; in this case, it
seems that the particular, open peering policy used by HE
is responsible for the observed similarity of routing behavior.
Hence, we conclude that clustering in RSD space has the
potential to uncover local atoms, and local atoms are evi-
dence of (generally unexpected) synchronization of routing
decisions among certain ASes with respect to certain des-
tinations. We then naturally ask the question: besides the
macroscopic cluster shown in Figure 4, are there other local
atoms, corresponding to other clusters, in our data? Pre-
sumably these clusters are at smaller scale and thus will
be much harder to ﬁnd. This motivates us to consider the
problem of clustering in RSD space more analytically, and
to look for eﬃcient and eﬀective methods of clustering for
RSD.

5. CLUSTERING WITH RSD

Finding a natural clustering for preﬁxes using the RSD
metric is challenging. Common clustering methods either
operate over a continuous metric space (e.g., k-means) or
others (e.g., k-median) require deﬁning the notion of a ‘rep-
resentative’ object for each cluster (i.e., the object that min-
imizes the sum of the distances to all other points in the
cluster). Unfortunately, our data are not continuous; each
data point is a column of the nexthop matrix and therefore
its elements are categorical. Secondly, the notion of a rep-
resentative in the RSD metric space is not clear. Further,
most clustering algorithms require the number of clusters
as input. Here we show that the RSD metric has a natural
clustering formulation that does not have these drawbacks.
Throughout this section, we will use the generic deﬁnition
of RSD (or rsd) on a set of preﬁxes – which we refer to as
nodes.
In practice, we make the adaptations discussed in

Section 2.2 and use D (resp. eD) instead of RSD (resp. rsd).
5.1 The RS-Clustering problem

Given a set X of n preﬁxes, our goal is to produce a parti-
tion P of X; every preﬁx x ∈ X belongs only to one cluster
of P, denoted by P(x). (Note that we will often overload no-
tation and use partition names like P as labeling functions
that map preﬁxes to clusters.)

Intuitively, a good partition satisﬁes the property that
the routing state distance between two preﬁxes x and x!
in the same cluster (P(x) =P (x!)) should be minimized,
while the routing state distance between preﬁxes x and x! in
diﬀerent clusters (P(x) "= P(x!)) should be maximized. This
intuition can be captured in the following formal deﬁnition
of the RS-Clustering problem.

Problem 1

(RS-Clustering). Given a set of nodes
X = {x1, . . . , xn} and the m × n nexthop matrix N, ﬁnd

244150

100

50

0

−50

D
S
R

150

100

50

0

−50

D
S
R

150

100

50

0

−50

D
S
R

−100

−100

−50

0

RSD
(a)

50

100

150

−100

−100

−50

0

50

RSD

(b)

100

150

−100

−100

−50

100

150

0

50

RSD

(c)

Figure 8: Preﬁxes that can be reached from one or more monitor ASes through (a) Level3, (b) Hurricane Electric, or (c)
Sprint.

ϳϬϭϴ

ϯϮϱϳ

ϳϬϭ

ϯϵϳϱϲ

ϭϮϵϵ

ϮϯϯϬϬ

ϮϮϵϮϱ

ϱϬϱϲ

Ϯϵϭϰ

ϭϲϲϴ ϯϯϱϲ

ϭϮϯϵ

ϯϱϰϵ

ϯϱϲϭ

ϭϭϲϴϲ

ϱϰϭϯ

ϲϱϯϵ

ϭϯϬϯϬ

ϴϱϮ

ϲϵϯϵ

Ϯϵϯ

Ϯϴϲ

ϴϰϵϮ

Ϯϰϵϳ

ϴϬϬϭ

ϲϳϲϮ

ϯϭϯϬ

ϰϲϯϳ

ϴϭϮ

ϯϭϱϬϬ

ϭϭϭϲϰ

ϭϮϮϭ

Ϯϱϭϲ

ϳϲϲϬ

ϮϭϱϮ

Figure 9: BGPlay snapshot of preﬁx 64.72.205.0/24 (origin
AS: 23300) which occurs in the smaller cluster.

a partition P of the nodes in X such that

P-Cost(P) =

X

D(x, x!) + X

x,x!:

P(x)=P(x!)

x,x!:

P(x)"=P(x!)

`m − D(x, x!)´ .

is minimized.

Observe that the deﬁnition of the RS-Clustering prob-
lem does not require the number of clusters to be part
of the input. That is, RS-Clustering is parameter-free.
This happens because the objective function of the cluster-
ing problem (i.e., the P-Cost function) is not guaranteed
to decrease as the number of clusters increases. This is
in contrast with the objective functions of many classical
clustering problems (e.g., k-means, k-median etc). Hence,
there exists an optimal number of clusters that minimizes
the P-Cost function. A solution to RS-Clustering pro-
vides both the clusters of the preﬁxes as well as the optimal
number of clusters as part of its output.

Despite the fact that the RS-Clustering problem is pa-
rameter free, its optimal solution cannot be computed in
polynomial time. This is shown in the following proposi-
tion.

D
S
R

120
100
80
60
40
20
0
−20
−40
−60
−100

−50

0

50

RSD

100

150

Figure 10: Pivot clustering of RSD with τ = 120.

Proposition 2. The RS-Clustering problem is NP-

hard.

The proof of the above proposition is by a reduction from
the Clustering Aggregation problem [2, 7, 8].

5.2 The Pivot algorithm

Based on the similarity between the RS-Clustering
problem with the Correlation Clustering [3] and the
Clustering Aggregation [2, 8] problems, we propose
solving the problem using the Pivot algorithm, which was
ﬁrst proposed for solving the Clustering Aggregation
problem.

The pseudocode of Pivot is shown in Algorithm 1. The
algorithm takes as input the set of preﬁxes, their RSD values,
and the value of a threshold parameter τ ∈ [0, m]. The
algorithm works as follows: starting from a random preﬁx
x, it ﬁnds all preﬁxes that are within distance τ from x. All
these preﬁxes are assigned in the same cluster – centered at
preﬁx x. We call x the pivot of cluster Cx. The preﬁxes
that are assigned in the cluster are removed from the set
of preﬁxes X and the Pivot algorithm is reapplied to the
remaining subset of preﬁxes that have not been assigned to
any cluster.

Observe that Pivot requires the precomputation of all
pairwise RSD distances. Given that these distances are
known, the running time of Pivot is O(n2).

245l

e
u
a
v
 
e
v
i
t
c
e
b
o

j

1.5 x 108

1.4

1.3

1.2

1.1

1

0.9
0

14000

12000

10000

8000

6000

4000

2000

s
r
e
t
s
u
C
#

 

l

50

100

τ

150

200

250

(a)

0
0

50

100

200

250

150

τ
(b)

Figure 11: (a) Value of P-Cost and (b) number of clusters as clustering threshold τ varies.

Algorithm 1 The Pivot algorithm .

A set of preﬁxes X = {x1, . . . , xn} and a threshold τ ∈
[0, m].
A partition P of the preﬁxes
1: pick a random preﬁx x ∈ X
2: create a cluster Cx = {x! | D(x, x!) ≤ τ }
3: X = X \ Cx
4: Pivot(X, τ )

The quality of the solution output by Pivot can be mea-
sured using the P-Cost function. An interesting observa-
tion is that a small rewriting of the P-Cost function reveals
that it is identical with the optimization function used for
the Correlation Clustering problem [2, 3]. Hence, using
the results of Ailon et al. [2] we can state the following:

Proposition 3. For τ = m/2,

the Pivot algorithm
is is an expected 3-approximation algorithm for the RS-
Clustering problem.

Observe that Pivot is a randomized algorithm since at
every recursive call it picks a random preﬁx to play the role
of a pivot.

6. APPLICATIONS

In this section, we illustrate how the solutions of RS-
Clustering obtained using Pivot, automatically extract
local atoms of N.

We start by applying Pivot using the threshold τ = m/2
as suggested by Proposition 3. This translates into τ = 120
in our data.

Five large clusters identiﬁed by Pivot are shown in Fig-
ure 10. The sharpest separation is shown by the cluster in
the lower left. Upon inspection, we ﬁnd that the lower left
cluster is in fact the Hurricane Electric cluster which was
described in detail in Section 4. Note that whereas pre-
viously the Hurricane Electric cluster was identiﬁed manu-
ally, in this case it is extracted automatically through the
use of Pivot. This provides good validation of the RS-
Clustering problem deﬁnition and our proposed solution
obtained via Pivot.

D
S
R

100

80

60

40

20

0

−20

−40

−60
 
−100

 

C1
C2
C3
C4
C5

−50

0

50

RSD

100

150

Figure 12: Pivot clustering of RSD with τ = 50.

While Figure 10 shows that the Hurricane Electric cluster
is clearly separated from the other preﬁxes, the other clus-
ters are not so well separated. In fact, although Pivot with
τ = m/2 has a provable approximation bound, it is entirely
possible that the algorithm may ﬁnd a better solution with
a diﬀerent value of the threshold. We can assess the quality
of a clustering simply by computing the value of the objec-
tive function P-Cost. Figure 11(a) shows how the objective
function varies by decreasing the threshold below τ = 120.
It shows that at a threshold τ of about 50, the quality of
the clustering levels oﬀ, and below 25 or so it starts to climb
again. Furthermore, Figure 11(b) shows the number of clus-
ters found at each threshold, and shows that below a τ value
of 50 the number of clusters becomes very large. In fact, be-
low τ = 50, many clusters are just singletons which are not
interesting as local atoms. Hence we next apply Pivot using
a threshold value of 50.

Five of the largest clusters found with a threshold of 50
are shown in Figure 12. (Note that these clusters are not
the same as those shown in Figure 10; the two ﬁgures show
outputs of diﬀerent clustering runs.) Compared to those in
Figure 10, these clusters show much sharper separation, and
we ﬁnd that each of these corresponds to a local atom. To

246Table 1: Statistics for the clusters in Figure 12.

C1

Size of cluster (C)
Size of source set (S)
Destinations

Dominant Next Hops
Next Hop Density
Coherence

150
16
Ukraine 83%
Czech Rep. 10%
9002
0.26
0.70

21011
0.23
0.82

3549
0.11
0.74

C2

170
9
Romania 33%
Poland 33%
3549
5588
0.16
0.33
0.88
0.67

1299
0.11
0.58

C3

126
7
India 93%
US 2%
9498
0.30
0.69

3257
0.10
0.43

174
0.06
0.39

C4

C5

484
8
Russia 73%
Czech Rep. 10%
12389
0.31
0.67

3257
0.07
0.28

1273
0.06
0.29

375
15
US 74%
Australia 16%
6939
0.54
0.80

174
0.06
0.25

16735
0.03
0.90

50

s
e
c
r
u
o
S

100

150

200

50

s
e
c
r
u
o
S

100

150

200

50

s
e
c
r
u
o
S

100

150

200

200

400

600

800
Destinations

1000

1200

C1

200

400

600

800
Destinations
C2

1000

1200

200

400

1000

1200

600

800
Destinations
C3

50

s
e
c
r
u
o
S

100

150

200

50

s
e
c
r
u
o
S

100

150

200

200

400

600

800
Destinations

1000

1200

C4

200

400

600

800
Destinations

1000

1200

C5

Figure 13: Visualization of the portion of N corresponding to the union of all ﬁve clusters. In each plot, we color the three
most dominant next hops used in one cluster.

247explore the nature of these local atoms, we start by charac-
terizing them in Table 1.

The ﬁrst two rows of the table give the size of the local
atom. This is captured by the number of preﬁxes in the
cluster (the size of C) and by the number of sources that
show common routing behavior to those preﬁxes (the size of
S). In each cluster, we ﬁnd a signiﬁcant number of ASes that
show similar routing behavior to a large number of preﬁxes.
Next, we dive into the characteristics of each local atom.
The next two rows characterize the geographic location of
the preﬁxes (destinations). In each case, we have only listed
the top-2 countries associated with the preﬁxes in the clus-
ter, and we give the percent of preﬁxes that we ﬁnd in each
cluster from those countries. These rows show that in most
cases, as much as 90% of the preﬁxes in a cluster are as-
sociated with only one or two countries. This shows that
geography clearly inﬂuences the formation of local atoms.

The next three rows of Table 1 illustrate the nature of the
‘common routing behavior’ that the sources S exhibit with
respect to the destinations C. The row labeled Dominant
Next Hops lists the ASNs of the three most common next-
hop ASes (in order of decreasing frequency) used by sources
in S for destinations in C. The row Next Hop Density shows
the fraction of entries in the cluster (across all 243 sources)
that correspond to each of the three common next hops.
And the row Coherence shows the fraction of entries only in
the submatrix N(S, C) that correspond to each of the three
common next hops. That is, the Coherence aims to quantify
the cohesiveness of the nexthops appearing in the submatrix
N(S, C).

This is further illustrated graphically in Figure 13.

The last two rows of Table 1 illustrate how common rout-
ing behavior is concentrated in the submatrix N(S, C). The
much larger density of the dominant next hops used by
sources in S as compared to among all sources shows that
the sources in S are indeed making similar nexthop choices.
In
this ﬁgure, each plot is a view of the nexthop matrix N.
The same portion of N is shown in each plot, namely, the
columns that correspond to preﬁxes forming the union of
clusters C1 through C5. The diﬀerence between each plot
is the choice of which next hop ASes are highlighted.
In
each plot, the three dominant next-hop ASes as given in
Table 1 are colored in blue, green, and red, respectively.
The ﬁgure shows how sharply the routing behavior of each
local atom is deﬁned. The common routing decisions made
within each local atom appear as clearly isolated regions
within the overall N matrix. This conﬁrms our intuition of
a local atom as equivalent to a coherent submatrix of N.

7. OVERLAPPING CLUSTERING

The local atoms we have found so far have non-overlapping
preﬁx sets. Consider the case of two coherent submatrices
of N as shown in Figure 14. It is quite possible for BGP
routing to result in this situation, but such local atoms can
not be distinguished by the approach we have taken so far.
The Pivot algorithm outputs a partition of the preﬁxes.
That is, every preﬁx x (column of N) is only assigned to
one cluster. However, as demonstrated by Figure 14, some
columns should belong to both clusters, thus the expressive-
ness of partition-based clustering is limited. In this section,
we propose a clustering that allows us to create clusters that
can express such scenarios. Such clustering allows for over-
lapping clusters — the same node can be assigned to more








Figure 14: Overlapping clusters in N.

than one cluster, and hence can capture the relationship
shown in Figure 14.

Algorithm 2 The Local algorithm .

A set of preﬁxes X = {x1, . . . , xn}, the matrix of their

normalized rsd distances eD and integer p.

A labeling L that assigns at most p labels (clusters) for
every x ∈ X.

Lt(x) =Initialize(p)

1: t = 0
2: for every x ∈ X do
3:
4: end for
5: while true do
6:
7:
8:
9:
10:
11:
12:
13:
14:
end if
15: end while

return Lt

t = t + 1
Lt = Lt−1
for every x ∈ X do

eLt(x) =NNLS(eD, Lt)
Lt(x) =Boolean( ˆLt(x), p)

end for
if |L-Cost(Lt) − L-Cost(Lt−1)| <  then

7.1 The Overlapping-Clustering

problem

In this section, we deﬁne the Overlapping-Clustering
problem. The output of this problem is a labeling L, which
assigns every node x to a set of clusters L(x). That is, every
label corresponds to a cluster.

Since every node is assigned to a set (rather than to a
single) cluster, we can compare a cluster-assignment for two
nodes – e.g., x and x! – by comparing the corresponding
labels. We do this by considering the Jaccard distace of the
label sets L(x) and L(x!), which is deﬁned as follows:

J `x, x! | L´ = 1 −

|L(x) ∩ L(x!)|
|L(x) ∪ L(x!)|

.

That is, the Jaccard distance captures the extent to which
two label sets overlap, as a fraction of the total number of
labels in both sets.

To capture the kind of relationship shown in Figure 14,

248































































































(a)

(b)

Figure 15: Cluster pairs (a) C4/C9 and (b) C3/C7. For each pair, the points in common are in green, while the points exclusive
to each cluster are in red or blue. Cluster outlines are also overlaid for ease of interpretation.

the deﬁnition of the Overlapping-Clustering problem fo-
cuses on identifying a labeling of each preﬁx such that the
Jaccard distance between the labels assigned to two preﬁxes
approximates the rsd distance between the corresponding
preﬁxes, to the maximum extent possible. Note that since
the Jaccard distance is a real number in the interval [0, 1]
we seek to approximate the normalized version of RSD.

Our deﬁnition of Overlapping-Clustering builds on
the recent work of Bonchi et al. [5]; its formal deﬁnition
follows.

Problem 2

a
set of nodes X, their m × n nexthop matrix N and an
integer p, identify a labeling of nodes L such that

(Overlapping-Clustering). Given

L-Cost (L) =

X

x,x!∈X×X

˛˛˛J `x, x! | L´ − eD(x, x!)˛˛˛

is minimized and for every x ∈ X it is guaranteed that
|L(x)| ≤ p.

The deﬁnition of Problem 2 does not require the number
of clusters in the output to be provided as part of the input.
Rather, the problem requires as input the maximum number
of clusters p in which a node can participate. Note that the
L-Cost function does not necessarily decrease as p increases.
Thus, in theory there is an optimal value of p, which can
be found by trying all possible values (i.e., {1, . . . , n}) and
report the clustering with the smallest L-Cost value.
In
our experiments, we chose p = 10, because for p >10 we
observed no signiﬁcant decreases in the objective function.

7.2 The Local algorithm

Bonchi et al. [5] showed that not only is Problem 2 NP-
hard to solve, but it is also NP-hard to approximate. There-
fore, we are content with eﬃcient heuristics to minimize the
L-Cost objective function. In this section, we give a brief
description of such a heuristic, which we call Local; this
heuristic is an instantiation of the generic algorithm pro-
posed in [5]. Although space does not permit a detailed

description of our algorithm here, the code is available at:
CodeURL.

The pseudocode of the Local algorithm is shown in Al-
gorithm 2. On a high level it uses a local-search heuristic,
which starts with a random assignment of preﬁxes to clus-
ters and iteratively improves it to reduce the value of the
L-Cost function. More speciﬁcally, at the ﬁrst step (Ini-
tialize routine), every preﬁx is assigned a random set of at
most p labels. Subsequently, the labels of each preﬁx x are
appropriately changed so that the cost of the objective func-
tion improves. This is done by the NNLS and the Boolean
routines. First, NNLS ﬁnds a real-valued assignment of labels
to a node by solving a non-negative least squares problem.
The output of this step is weighted association of the preﬁx

with every cluster– denoted by eL in Algorithm 2. Then, the

routine Boolean transforms the real-valued assignment into
one-zero assigment. Thus, the output of this step is a set of
labels (i.e., clusters) that are associated with preﬁx x. The
details of these steps are described by Bonchi et al. [5]. The
two steps are repeated, till a local minimum – with respect
to the objective function L-Cost – is reached.

7.3 Overlapping Clustering Results

To demonstrate overlapping clustering using RSD we ap-
ply Local to our data with p = 10. This allows any preﬁx
to be a member of as many as 10 clusters. To understand
the results, it is easiest to look at pairs of clusters. All pairs
of clusters have some overlapping subset, so pairs of clusters
illustrate the general power of overlapping clustering for our
data.

From our 10 clusters, we focus on two pairs which we
denote C4/C9 and C3/C7. We show the two pairs visualized
using MDS in Figure 15.

The ﬁgure shows that, as intended, clusters overlap. In
each case, a large number of preﬁxes are in both clusters.
What is perhaps less expected is that points that are close
to each other in RSD space as visualized in 2-D are not
necessarily contained in the same cluster. For example, note
the regions on the right side of each plot in which points
belonging to distinct clusters are shown to be near in RSD.

249C4

C4∩C9

C9

C3

C3∩C7

C7

s
e
c
r
u
o
S

2
4
6
8
10
12
14
16
18

1000

s
e
c
r
u
o
S

2
4
6
8
10
12
14
16
18
20

5000

6000

500

1000 1500 2000 2500 3000 3500

Destinations

2000

3000

4000
Destinations

(a)

(b)

Figure 16: Submatrices of N, with diﬀerent nexthop ASes in diﬀerent colors.

In fact, this eﬀect is exactly what we had hoped overlap-
ping clustering would capture. The reason for this eﬀect is
that point-pairs can be close to each other in RSD space for
diﬀerent reasons. Consider again Figure 14. There are two
diﬀerent sets of sources (S1 and S2) that have similar rout-
ing behavior and create coherent submatrices in N. Each
set of sources causes preﬁxes to cluster together, but inde-
pendently so; the preﬁxes in C1 are near each other in RSD
space because of the similar routing decision of the ASes in
S1, while preﬁxes in C2 are near each other in RSD space
because of the similar routing decision of the ASes in S2.

As a result, in contrast to the non-overlapping case, we
do not ﬁnd that clusters typically map to geographic sets
or regions. Furthermore, clusters are not compact in RSD
space as can be seen in Figure 15.

The overlapping clustering constructed by the Local algo-
rithm allows us to discover the diﬀerent sets of source ASes
that have similar routing behavior. This is shown in Fig-
ure 16. The ﬁgure shows submatrices of N in which each
next hop values has been given a color. These submatrices
correspond to the cluster pairs C4/C9 and C3/C7. In each
ﬁgure, we have ordered the columns so that the preﬁxes con-
tained in each cluster are in the center, and the preﬁxes that
are only in one cluster are on the sides. This allows us to
visualize the sets of ASes that give rise to each cluster.

For example, in Figure 16(a), we can see that the AS in
row 4 has the same next hop for all preﬁxes cluster C4, but
not for the preﬁxes that are only in C9. Likewise, the AS in
row 8 has the same next hop for preﬁxes in C9, but not for
those only in C4. In the case of C3/C7, the cluster-deﬁning
rows are rows 5 and 10.

We conclude that these results give evidence that over-
lapping clustering (using an algorithm such as Local) can
ﬁnd clusters in which diﬀerent sets of ASes each have cohe-
sive routing behavior over overlapping sets of preﬁxes. This
holds the promise of extracting a richer set of local atoms
from BGP data.

8. DISCUSSION

Our sense is that RSD, owing to its simple deﬁnition, is a
general tool that can be used in a variety of settings. These
include further in-depth analysis of BGP, as well as its ap-
plication to entirely diﬀerent domains.

A promising direction for further application of RSD is
to incorprate temporal analysis. Consider a set of nexthop
matrices indexed in time, i.e., Nt, Nt+1, .... In this setting,
one can ask about the RSD of the same preﬁx at diﬀerent
points in time. For preﬁx x, this is simply the number of po-
sitions where Nt(:, x) and Nt+1(:, x) diﬀer. Such a measure
could have value over short timescales for detecting sudden,
signiﬁcant routing changes (such as a preﬁx hijacking) or
over long timescales for characterizing the evolving routing
structure of the Internet. Further, comparison of average
RSD change across all or a selected set of preﬁxes from time
t to time t + 1 could give a sense of overall rate of change
and stability in the interdomain routing system.

Another direction for further analysis of BGP follows from
the observation that the RSD matrix D has low eﬀective
rank. Previous work on traﬃc matrices has shown that this
property naturally leads to an eﬀective method for anomaly
detection [13]. Our initial investigations indicate that this
method can very eﬀectively identify preﬁxes that have un-
usual connectivity patterns in BGP (such as CDNs).

Another consequence of the low eﬀective rank property of
D is that D may be amenable to matrix completion. That
is, it may be possible to accurately estimate the RSD be-
tween two pairs of preﬁxes if enough measurements of RSD
between other pairs is available. This could be useful in
situations where only partial path information is available.
Going beyond the analysis of BGP, RSD can be applied in
any situation in which paths between nodes are an available
data source. For example, it could be applied to collections
of traceroute measurements, information dissemination in
social media, or infection propagation in social and commu-
nication networks.

2509. RELATED WORK

It’s been widely reported that publicly available BGP ta-
bles provide an incomplete view of the AS graph [17].
In
this regard, it is important to develop tools that can ana-
lyze the network using only the BGP path data instead of
the AS graph. The way we deﬁne RSD based on paths elim-
inates the problem of missing edges in the AS graph so that
ambiguities due to missing links do not arise.

In addition, our paper touches on the problem of visualiza-
tion of preﬁxes (or ASes) based on BGP data. The authors
in [11] visualize the set of core ASes using placement based
on AS degree and geographic location. Small scale visual-
izations of selected BGP paths are available through BGPlay
[4] and bgpviz [15]. However, to our knowledge, no macro-
scopic visualization method relies directly on BGP paths as
we do, despite the fact that paths are the fundamental unit
of measurement in BGP. In addition, relatively little work
has been done on clustering of preﬁxes or ASes; the work
that has been done relies on the inferred AS graph rather
than BGP paths [9].

Finally, a number of studies explore aggregation of pre-
ﬁxes. In [6], the authors show that there are many cases in
which a collection of preﬁxes is routed the same way. Such
collections, so called policy atoms, consist of preﬁxes that
share the same BGP paths. In [1], the authors study meth-
ods for calculating policy atoms and their characteristics in
detail. The main goal of these works is using policy atoms
to reduce the sizes of BGP tables. Our work diﬀers from
these works in the sense that we do not require that the pre-
ﬁxes in the same local atom routed the same way. Instead
we cluster the preﬁxes that are routed similarly in some re-
gions of the Internet. In fact, we generalize and extend the
notion of atoms so that it can be used to analyze the routing
behaviors at diﬀerent granularities.

10. CONCLUSIONS

In this paper we have developed a new set of tools for ex-
tracting insight from BGP measurements. We deﬁned a new
metric for measuring distance between preﬁxes, called RSD.
This metric captures the notion of ‘closeness’ of two pre-
ﬁxes with respect to the global routing state of the Internet.
As such, it is a natural tool for visualizing the relationship
between preﬁxes. But going beyond visualization, we show
that RSD can uncover surprising patterns in routing data.
In particular, we show that RSD exposes situations in which
large numbers of ASes make similar routing decisions with
respect to speciﬁc sets of preﬁxes. We call this situation a
local atom, generalizing the notion of a BGP atom. We show
that local atoms exist at the macroscopic scale (one involves
23% of all preﬁxes in the Internet) as well as at much smaller
scales. To expose local atoms, we develop and demonstrate
the power of two new clustering methods speciﬁcally tai-
lored for use with RSD. We conclude that the combination
of (1) computing RSD, (2) visualizing RSD using MDS, and
(3) clustering RSD using Pivot and Local together consti-
tute a powerful toolbox for discovering patterns in massive
datasets of BGP paths.

Code for the Pivot and Local algorithms, as well as code
for computing RSD, is available at http://csr.bu.edu/rsd.
That site also provides a list of RSD values for the preﬁx
pairs used in this study.

11. ACKNOWLEDGEMENTS

This work was supported by NSF grants CNS-1017529,
CNS-0905565, CNS-1018266, CNS- 1012910, CNS-1117039,
by a GAANN Fellowship, and by grants from Microsoft, Ya-
hoo!, and Google. The authors thank the IMC referees and
shepherd for their help in improving the paper. The authors
also appreciate helpful discussions with various network op-
erators.

12. REFERENCES

[1] Y. Afek, O. Ben-Shalom, and A. Bremler-Barr. On the
structure and application of bgp policy atoms. In ACM
SIGCOMM Workshop on Internet measurment, 2002.
[2] N. Ailon, M. Charikar, and A. Newman. Aggregating
inconsistent information: Ranking and clustering. J.
ACM, 55(5), 2008.

[3] N. Bansal, A. Blum, and S. Chawla. Correlation

clustering. Machine Learning, 56:89–113, 2004.

[4] Bgplay. http://bgplay.routeviews.org.
[5] F. Bonchi, A. Gionis, and A. Ukkonen. Overlapping
correlation clustering. In ICDM, pages 51–60, 2011.

[6] A. Broido and k. claﬀy. Analysis of RouteViews BGP

data: policy atoms. In NRDM, 2001.

[7] V. Filkov and S. Skiena. Integrating microarray data

by consensus clustering. Intern. J. on Artiﬁcial
Intelligence Tools, 13:863–880, 2004.

[8] A. Gionis, H. Mannila, and P. Tsaparas. Clustering

aggregation. TKDD, 1(1), 2007.

[9] C. Gkantsidis, M. Mihail, and E. W. Zegura. Spectral

analysis of internet topologies. In INFOCOM, 2003.

[10] G. G¨ursun, N. Ruchansky, E. Terzi, and M. Crovella.
Inferring visibility: Who’s (not) talking to whom? In
SIGCOMM, 2012.

[11] B. Huﬀaker and k. claﬀy. CAIDA’s IPv4 and IPv6 AS

Core AS-level Internet Graph. http://www.caida.
org/research/topology/as_core_network/, 2010.

[12] Hurricane Electric. Hurricane electric peering policy.

http://he.net/peering.html.

[13] A. Lakhina, M. Crovella, and C. Diot. Diagnosing

network-wide traﬃc anomalies. In SIGCOMM, 2004.

[14] W. M¨uhlbauer, S. Uhlig, B. Fu, M. Meulle, and

O. Maennel. In search for an appropriate granularity
to model routing policies. In SIGCOMM, 2007.

[15] RIPE. bgpviz. http://www.ris.ripe.net/bgpviz.
[16] Ripe’s routing information service raw data project.

http://www.ripe.net/data-tools/stats/ris/
ris-raw-data.

[17] M. Roughan, W. Willinger, O. Maennel, D. Perouli,
and R. Bush. 10 lessons from 10 years of measuring
and modeling the internet’s autonomous systems.
IEEE Journal on Selected Areas in Communications,
2011.

[18] University of oregon route views project.

http://www.routeviews.org.

[19] W. S. Torgerson. Multidimensional scaling: I. theory

and method. Psychometrika, 17:401–419, 1952.

251