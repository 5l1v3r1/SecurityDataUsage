Using Extreme Learning Machine for Intrusion Detection in

a Big Data Environment

Junlong Xiang

University of Helsinki

Magnus Westerlund

Arcada University of Applied

Sciences

Dušan Sovilj

Göran Pulkkis

Arcada University of Applied

Arcada University of Applied

Sciences

Sciences

ABSTRACT
Extending state-of-the-art machine learning algorithms to
highly scalable (big data) analysis environments is crucial
for the handling of authentic datasets in Intrusion Detec-
tion Systems (IDS). Traditional supervised learning meth-
ods are considered to be too slow for use in these environ-
ments. Therefore, we propose the use of Extreme Learning
Machine (ELM) for detecting network intrusion attempts.
We show they hold great promise for the ﬁeld by employing
a MapReduce based variant evaluated on the open source
tool Hadoop.

Categories and Subject Descriptors
D.1.3 [Programming Techniques]: Concurrent Program-
ming—Distributed programming; I.5.1 [Pattern Recogni-
tion]: Models—Neural nets

Keywords
Extreme Learning Machine; MapReduce; big data; intrusion
detection; classiﬁcation

1.

INTRODUCTION

Intrusion detection in computer networks has been a hot
research topic since the late 90’s. The creation of a de-facto
standardized dataset, KDDcup99 [1], has arguably been in-
strumental in the development of the ﬁeld. The dataset
has allowed researchers to compare and combine results in
order to continually improve detection accuracy of intru-
sion threats. Despite the critique towards the KDDcup99
dataset, in terms of not representing all known modern types
of attacks and for being a collection of laboratory simu-
lated data, it is still considered by most intrusion manage-
ment researchers to be a relevant benchmark dataset for the
ﬁeld [2]. Until now state-of-the-art research often considers

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
AISec’14, November 7, 2014, Scottsdale, Arizona, USA.
Copyright 2014 ACM 978-1-4503-2953-1/14/11 ...$15.00.
http://dx.doi.org/10.1145/2666652.2666664.

the dataset to be too large and complex for handling the
complete set, and therefore usually uses only a sub-set.

In this paper, we propose a machine learning method which
scales horizontally without losing detection accuracy. We
employ a recent advance in a machine learning algorithm
called Extreme Learning Machine (ELM) [3] for the MapRe-
duce programming model. We make use of this machine
learning algorithm for classifying intrusion attempts. ELM
has earlier been shown to outperform Support Vector Ma-
chine (SVM) in terms of accuracy, training speed and user
friendliness (automation) [4].
In our research, we use a
MapReduce implementation of ELM that scales horizontally
in an almost linear fashion. We strive to improve detec-
tion eﬃciency by increasing the training data used during
the learning process. Our solution is computationally heavy.
However, due to horizontal scaling through the MapReduce
programming model, we show that machine learning based
intrusion detection using ELM can extend its applicability
to signiﬁcantly larger datasets than datasets currently used
in most papers. This is possible without increasing training
time drastically, due to the near linear scaling ability of the
proposed ELM algorithm.

The remainder of this paper is structured as follows. Sec-
tion 2 presents a literature review of the ﬁeld, including a
brief background. Section 3 introduces the machine learning
paradigm ELM and describes both a local implementation
and a MapReduce implementation. Section 4 contains ex-
perimentation results, while Section 5 includes concluding
remarks.

2. RELATED RESEARCH

The Cloud Security Alliance (CSA) [5] started in 2012 a
Big Data Working Group consisting of representatives from
industry and academia. This working group has issued a
report focusing on the role of big data in network and in-
formation security [6]. The report presents big data ana-
lytics examples for security and highlights the importance
of developing methods for security experimentation with big
data analytics [7]. The MapReduce programming model,
which is often utilized in big data analytics, decomposes data
into smaller pieces, which are then processed on the network
hosts in which they reside, instead of moving the data pieces
to other network nodes for processing [8]. As such, key con-
tributions of MapReduce are scalability and fault-tolerance.
A technology which extends the MapReduce programming

73model is the open source tool Hadoop [9]. We chose Hadoop
because it has become a stable and common tool for han-
dling big data. Hadoop’s processing capabilities are built on
top of the Hadoop Distributed File System (HDFS), which is
a general purpose ﬁle system. Inherently it means, that for
Hadoop to be competitive when comparing processing speed,
the dataset used should be very large and the compute clus-
ter should contain enough processing nodes. HDFS is de-
signed for handling ﬁle sizes up to Terabytes and hundreds
of processing nodes. Therefore the KDDcup99 dataset does
not fulﬁll the big data criteria of volume [10]. Still, using
authentic network intrusion data from longer time periods
requires big data type solutions and therefore motivates our
study on how machine learning methods can be utilized with
the MapReduce programming model for detecting network
traﬃc anomalies.

The current intrusion detection research can be divided
into two core domains; information reduction and network
anomaly detection methods [11]. Information reduction in-
cludes techniques such as data compression and feature se-
lection. Network anomaly detection methods mostly focus
on learning methods for alert decision support in anomaly
based intrusion detection. See [12] for a survey of traditional
detection methods used in intrusion detection research.

Supervised learning methods based on Support Vector Ma-
chine (SVM) and on Artiﬁcial Neural Networks (ANN) have
traditionally been used for intrusion detection research with
good results [13]. Modern neural network based learning
methods for intrusion detection based on ELM are used in [4,
14]. The ELM method is still fairly novel in the Intrusion
Detection System (IDS) ﬁeld in the sense that it is still not
mentioned in recent surveys of the methods employed [12,
2]. Cheng et al. [4] argued that while SVM delivers with
ELM comparable results in terms of quality for binary intru-
sion detection, its inability to handle large training datasets
due to the computational complexity (quadratic order of the
sample size) makes it diﬃcult to use for authentic settings.
Due to the dataset variety and the requirement of performing
multi-class intrusion detection for 22 diﬀerent attack types
in the KDDcup99 dataset, the use of SVM for big data prob-
lems is diﬃcult and ineﬃcient.

Dealing with massive training datasets in machine learn-
ing is often cumbersome. The MapReduce framework pro-
vides two primitive functions, map and reduce, for data pro-
cessing. The basic data structures used in MapReduce for
dealing with data are <key, value> pairs. A map task typ-
ically processes input data to an intermediate result, that
acts as input to a reduce task. The shuﬄing of data be-
tween processing nodes after each task is handled by the
underlying system. The system executes each map and re-
duce task independently in a fully parallelized fashion. He
et al. [15] designed the proper <key, value> pairs for the
ELM algorithm to process large-scale datasets. Earlier im-
plementations performed a multiplication of matrix H and
its transpose matrix HT. The size of the matrix H is N × L,
where N is the dataset size and L is the number of hidden
nodes. Therefore loading HHT into a computer memory is
not feasible for large dataset sizes N as a N × N matrix is
required. Instead the calculation is split into several levels
of MapReduce tasks as is described in Section 3.4.

Input layer

Hidden layer

Output layer

Input neuron1

Input neuron2

Input neuron3

Output neuron1

Output neuron2

Figure 1: Single hidden Layer Feed-forward Neural
network (SLFN).

3. EXTREME LEARNING MACHINE

Extending state-of-the-art machine learning algorithms to
highly scalable analysis environments is crucial for the han-
dling of authentic datasets. The traditional Feed-Forward
Neural Network (FFNN) [16], that utilizes gradient descent
based methods for the training phase, is considered to be
very slow due to parameter tuning by multiple rounds of it-
eration. However, a learning algorithm known as Extreme
Learning Machine (ELM) [17, 18, 3] has been proposed to
handle this problem and is aimed for solving regression, bi-
nary classiﬁcation, and multi-class classiﬁcation problems.
ELM is a supervised machine learning algorithm for Single
hidden Layer Feed-forward Neural networks (SLFNs) mean-
ing that a SLFN contains only one hidden layer as can be
seen in Figure 1. A SLFN consists of three layers:
input
layer, hidden layer and output layer.

The highlight of the ELM algorithm is that it requires no
parameter tuning of the hidden layer, rather the parameters
of the hidden layer are generated randomly. It ﬁrst generates
the input weights and biases randomly, then determines the
output weights analytically based on the random parame-
ters. The input weights are the weights between input layer
and hidden layer, the biases are the thresholds for hidden
neurons and the output weights are the weights between the
hidden layer and output layer. So the key part for training
phase of ELM is to calculate the output weights. As ELM
does not need to iteratively tune the parameters, it has an
extremely fast training speed, and because the input weights
and biases are randomly generated, it is less sensitive to user-
speciﬁed parameters and thus has a better performance [19].
In the following sections, we explain the ELM algorithm
and show the diﬀerence between a local implementation of
ELM and a recently proposed MapReduce variant.

3.1 Deﬁnition of ELM

We use the following notation to describe the ELM algo-

rithm:

• N : number of training samples.
• Nt: number of testing samples.
• L: number of hidden neurons.
• n: number of input neurons.
• m: number of output neurons.
• (xj, tj), j = 1, 2, . . . , N : arbitrary distinct (input, out-
put) samples xj = (xj1, xj2, . . . , xjn)T ∈ Rn, expected

74output vectors tj = (tj1, tj2, . . . , tjm)T ∈ Rm. All the
vectors can be combined together to form a matrix T

T =




2

1

tT
tT
...
tT
N


N ×m

=

t11
t21
...
tN 1




t12
t22
...
tN 2

· · ·
· · ·
. . .
· · ·

t1m
t2m
...
tNm




.

(1)

• oj, j = 1, 2, . . . , N : output of the network for the sam-

ple xj.

• W = [wij]L×n: input weights between input layer and
hidden layer, the corresponding ith row vector of W is
wi = [wi1, wi2, . . . , win]T which can be written as

W =




2

1

wT
wT
...
wT
L


L×n

=




w11 w12
w21 w22
...
...
wL1 wL2

· · · w1n
· · · w2n
...
. . .
· · · wLn




.

(2)

• β = [βij]L×m: output weights between hidden layer
and output layer, where the ith row vector of β is βi =
[βi1, βi2, . . . , βim]T which can be written in matrix form
as

β =




2

1

βT
βT
...
βT
L


L×n

=




β11
β12
β21
β22
...
...
βL1 βL2

· · · β1m
· · · β2m
...
. . .
· · · βLm




.

(3)

• b = [b1, b2, . . . , bL]T: vector of biases where bi repre-

sents the threshold of the ith hidden neuron.

The standard mathematical model of SLFNs is

L

∑i=1

g(wi · xj + bi)βi = oj ,

j = 1, 2, . . . , N ,

(4)

where wi · xj represents the inner product between wi and
xj. The function g represents the activation function of the
hidden neurons. There are many candidates for the acti-
vation function like sigmoid [15], sine [18], Gaussian [20]
and linear [20].
In this paper, the choice for the activa-
tion function is the sigmoid function, which can be written
as g(z) = 1/(1 + exp(−z)).

If N = L, the model given by Eq. (4) can approximate N
arbitrary distinct samples with zero error [18], which means
that

H = H(W, b) = [hij]N ×L

= 


g(w1 · x1 + b1)

...

g(w1 · xN + b1)

· · ·
. . .
· · ·

g(wL · x1 + bL)

...

g(wL · xN + bL)




(8)

while T and β are given by Eqs. (1) and (3) respectively.
The matrix H is called the hidden layer output matrix of
a neural network. The ith column of H corresponds to the
ith hidden neuron output. When N = L then Eq. (7) has
a unique solution that can approximate the training sam-
ples with zero error. However, in most scenarios L << N .
We can therefore not guarantee to choose W,b and ﬁnd β
satisfying that they are the least squares solution according
to

( ˆW, ˆb, ˆβ) = arg min

∥H(W, b)β − T∥

(9)

W,b,β

To solve this problem, it is common to use gradient de-
scent based learning method. For FFNNs, the common al-
gorithm is Back-Propagation (BP) method [16]. However,
this method has the following problems:

a) Time-consumption: the gradient descent based method
is time-consuming in most applications because of it-
erative parameter tuning.

b) Over-training: the BP algorithm may be over-trained
and also needs validation for search of optimal param-
eter values.

c) Parameter sensitivity: the method is sensitive to user-
speciﬁed parameters such as the learning rate. Too
small or too large learning rate will both make the
result improper [18].

The traditional learning algorithms for FFNNs require ad-
justments of input weight and hidden neurons biases. How-
ever, if we ﬁx the input weights and hidden layer biases, then
Eq. (9) is equal to

ˆβ = arg min

∥Hβ − T∥ .

β

(10)

(HTH)−1

The solution to Eq. (10) is then ˆβ = H†T, where H† =
HT is the Moore-Penrose generalized inverse of
the hidden layer output matrix H. In order to provide a more
stable solution to the minimization problem in Eq. (10), a
regularization term 1/C is added to the diagonal of HTH.
The output weights β are then calculated as

N

∑i=1

∥oj − tj∥ = 0 .

(5)

ˆβ = ( I

C

+ HTH)−1

HTT

(11)

In other words, it means that we can ﬁnd the matrix β

where I is the identity matrix.

from matrices W and b such that

L

∑i=1

g(wi · xj + bi)βi = tj ,

j = 1, 2, . . . , N .

(6)

We can also simply write Eq. (6) in a compact way as

where

Hβ = T

(7)

3.2 Training Algorithm for ELM

Given the number of hidden neurons N , the parameter C,
and the training dataset {(xj, tj) | xj ∈ Rn, tj ∈ Rm}, j =
1, 2, . . . , N , the training algorithm of ELM has the following
steps:

1) Randomly generate input weights W and biases b.
2) Calculate the hidden layer output matrix H (Eq. (8)).
3) Calculate the output weights β (Eq. (11)).
The values randomly drawn in the ﬁrst step can be sam-
pled from any continuous probability distribution over any

75Training phase

Testing phase

Input training dataset, number 

of hidden neurons and C

Input testing dataset and
number of hidden neurons

Extract the feature and label 

matrix from training data

Extract the feature and label 

matrix from testing data

Generate random input

weights and biases

Calculate hidden layer output H

Calculate output weights

Calculate hidden layer 
output H based on the 

generated random 

input weights and biases

Calculate and output the 
target scores and obtain 

testing accuracy

Figure 2: Logic workﬂow of a local ELM.

interval [18]. In the following section we compare a local im-
plementation of ELM with a recently proposed MapReduce
variant.

3.3 Local Implementation for

Intrusion Detection

The workﬂow of a local ELM version is shown in Fig-
ure 2. For the training phase, three arguments are required:
a training dataset, the number of hidden neurons and the
parameter C. Then we extract the feature matrix from the
training dataset and generate random input weights W and
random biases b. Next we calculate the hidden layer out-
put matrix H based on the feature matrix, the input weight
matrix, the biases, and the activation function. Finally, we
calculate output weights β which involves calculating the
Moore-Penrose inverse of the hidden layer output matrix.
For the testing phase, we ﬁrst give a testing dataset, then
we extract the feature matrix and expected labels from test-
ing dataset, next we get the hidden layer output matrix, and
ﬁnally we calculate the target scores in order to get the ac-
tual labels and compare actual labels with expected labels
to compute the overall accuracy.

3.4 Distributed Implementation for

Intrusion Detection

Machine learning with Hadoop usually consists of the fol-

lowing steps:

1) Store data in Hadoop.
2) Run data preprocessing in order to vectorize input data

(applying ﬁlters and/or feature extraction methods).

3) Start training jobs, learning at least one model per
input vector (only applied during the training phase).
4) Execute models - a model classiﬁes an input vector as a
threat or not as a threat (the decision is not necessarily
a binary decision).

As described before, the training phase of ELM includes
three steps: ﬁrst generate random input weights and biases,
then calculate the hidden layer output matrix H, and ﬁnally
calculate the output weights β. The distributed implemen-
tation is called MR ELM in this paper. The main idea for
implementing MR ELM is to divide the sample dataset into
multiple map tasks and process these tasks in parallel in
order to get the intermediate data, then combine and pro-

Block1

Block2

.
.
.

Map task1

Map task2

.
.
.

Reduce task1

.
.
.

Reduce task

Blockm-1

Map taskm-1

Reduce taskn-1

Blockm

Map taskm

Reduce taskn

Figure 3: The workﬂow of MR ELM.

cess the intermediate data in reduce tasks. The workﬂow of
MR ELM is given in Figure 3.

The whole MR ELM includes both training and testing

phases and can be summarized as follows:

1) Randomly generate input weights and biases.
2) Do the training job and produce the output weights.
3) Do the testing job and output the predictions and ac-

curacy.

The whole MR ELM consists of two kinds of jobs – the
training job and the testing job. Detailed implementation is
given in Algorithms 1–6 in the Appendix.

3.4.1 Training Phase

The training phase consists of three steps. The ﬁrst step
is to generate random input weights W and random biases
b. The second step is to calculate the hidden layer output
matrix H based on the training dataset, and the last step
is to calculate the output weights based on the hidden layer
output matrix H. In the ﬁrst step, we know that the input
weight matrix W has L × n dimensionality, where L is a rel-
atively small number of hidden neurons and n is the input
vector length (the number of input neurons). As n is also rel-
atively small, the ﬁrst step needs no distributed computing.
Input weights and the vector b of random biases are therefore
easily and eﬃciently generated. For the step of calculating
hidden layer output matrix H as given by Eq. (8), L is not
very large but N is much larger than L. However, we can use
a distributed way to handle this problem. Hadoop stores the
training dataset in a HDFS by physically dividing it into sev-
eral blocks, and stores each block in a diﬀerent node. When
MR ELM program is going to input the training dataset,
it will therefore ﬁrst logically divide it into several splits
and copy each split to a node for computing. Each node will
therefore process only a relatively small training dataset and
implement parallel computing to speed up calculations. The
number of splits is subject to the blockSize, goalSize and
minSize and can be conﬁgured in Hadoop conﬁguration pro-
ﬁles as splitSize = max(minSize, min(goalSize, blockSize)).
The last step involves calculating the output weights β.

The main tasks for this step is to calculate HTH and
HTT. The dimension of H is N × L, but since HTH is
L × L, we can put this calculation in one node. From Eq. (7)
and based on the thought in [15] we know that the matrix
HTH is the summation of each vector rk multiplied with ck,
where vector rk is the kth row of H and ck is the kth column
of HT. Therefore, we can process this step in a parallel way
by assigning each multiplication operation of vector rk and
vector ck to a diﬀerent node during the map tasks, and sum
products in reduce tasks.
In order to enhance processing
speed, we use a two level reduce process. In the ﬁrst level,
reduce tasks sum partial multiplication results yielded from

76Table 1: Attack types and categories in KDDcup99.

Category Type
PROBE
DOS
U2R
R2L

ipsweep, nmap, satan, portsweep
back, land, neptune, pod, smurf, teardrop
perl, buﬀer overﬂow, loadmodule, rootkit
ftp write, guess passwd, imap, multihop, phf,
spy, warezclient, warezmaster

map tasks. In the second level, reduce tasks sum the result
of ﬁrst level reduce tasks.

3.4.2 Testing Phase

The testing phase consists of three steps. The ﬁrst step is
to calculate the hidden layer output matrix H based on the
testing dataset. The second step is to calculate the target
score matrix (output neurons). The third step is to calcu-
late the accuracy for this testing operation. For the ﬁrst
step, as in the operation of the second training phase step,
the hidden layer output matrix H is calculated in a parallel
way by dividing the whole testing dataset into several splits
and processing each split is done in a separate cluster node.
During the second step of calculating the target scores, the
formula is Hβ = T. The dimension of H is Nt × L, where
Nt is the number of testing sample instances, and of β is
L × m. The dimension of Hβ is therefore Nt × m. As Nt
is much larger than L and m, we can divide Nt, assign a
node to calculate each row in H, and multiply β in diﬀer-
ent nodes in the map tasks. Actually, each row of H can
be seen as the hidden neuron output vector for each sam-
ple instance. Thus, we actually distribute the calculation
of the hidden neuron output vector of sample instances to
multiple nodes for parallel execution. During the third step
we have got the target scores for each instance and transfer
them with the corresponding expected label to reduce tasks.
In reduce tasks, we calculate the actual labels based on the
target scores and calculate the accuracy by comparing actual
labels with expected labels of each sample instance. For this
step we also use a two level reduce process. In the ﬁrst level,
each reduce task calculates the accuracy of a partial testing
dataset. In the second reduce level the overall accuracy is
calculated.

4. EXPERIMENTS

For the experimentation we used the KDDcup99 dataset,
which was generated more than a decade ago and is still
being used as the usual benchmark in intrusion detection
experiments.

4.1 KDDcup99 Dataset Description

The KDDcup99 dataset was created in the 1998 DAPRA
intrusion detection program [1]. This program simulated
a U.S. Air Force LAN network environment, and collected
9 weeks’ network connection instances as TCP/IP dumps.
Each connection sample instance contains 41 features and
one label. Label values are normal and abnormal. The ab-
normal value is in the training dataset further divided into 4
main attack groups and 22 speciﬁc attack types falling into
the 4 main attack groups. The evaluation dataset contains
39 speciﬁc attack types in 4 main attack groups. The 22
speciﬁc attacks types in the training dataset are shown in
Table 1.

Table 2: Data preprocessing: mapping of symbolic-
valued features to numeric-valued features. IDS(k)
indicates the number of labels for classiﬁcation task.

Feature
protocol
type
service

ﬂag

IDS(2)
IDS(5)

IDS(23)

Numeric-valued transformation
1=tcp; 2=udp; 3=icmp

imap4=9;

smtp=15;

systat=16;

ecr i=2;

eco i=3;

ftp data=5;

ftp=6;

ﬁn-
domain-u=1;
http=7;
ger=4;
hostnames=8;
login=10;
mtp=11; netstat=12; other=13; pri-
vate=14;
tel-
net=17; time=18; uucp=19; others=20
1=OTH; 2=REJ; 3=RSTO; 4=RSTOS0;
5=RSTR; 6=S0; 7=S1; 8=S2; 9=S3;
10=SF; 11=SH;
1=normal; −1=attack;
1=normal; 2=PROBE; 3=DOS; 4=U2R;
5=R2L;
1=normal;
4=ip-
sweep; 5=nmap; 6=satan; 7=portsweep;
8=land;
10=pod;
13=buﬀer -
11=teardrop;
overﬂow; 14=loadmodule; 15=rootkit;
17=guess passwd;
16=ftp write;
18=imap;
20=phf;
21=spy; 22=wareclient 23=waremaster;

9=neptune;
12=perl;

19=multihop;

2=smurf;

3=back;

The training dataset needs to be preprocessed before use
as some features of the raw training dataset are symbolic-
valued features which cannot be directly used. The map-
ping of symbolic-valued features to numeric-valued features
is shown in Table 2.

4.2 Experimental Layout

For experimentation with the local implementation, the
program was executed in a computer with 32 GB RAM and
2 CPUs both having 4×2.53 GHz cores. For experimenta-
tion with the distributed implementation, the program was
executed in a cluster of Linux computer nodes, where each
node had 32 GB RAM and 2 CPUs, both with 4×2.53 GHz
cores. Each node had therefore a total of 8 cores. We set
the maximum number of map tasks to 7, which means that
the maximum number of map tasks which can be executed
in parallel on each node is 7. The MapReduce framework is
deployed with Hadoop-1.2.1 and java-1.7.0 51.

We conducted two kinds of intrusion detection experi-
ments, binary intrusion detection and multi-class intrusion
detection, in order to evaluate MR ELM against local ELM.
For each experiment, we compared two aspects of MR ELM
with local ELM. The ﬁrst aspect focuses on performance
evaluation of MR ELM against local ELM. We compared
the performance of the local ELM and MR ELM by the cri-
terion of accuracy. We tested the local ELM on one stan-
dalone machine and MR ELM on a cluster of 10 nodes. Both
were trained with datasets of diﬀerent size and then tested
with the same testing dataset. We generated 4 diﬀerent ran-
dom training datasets of sizes 100k, 200k, 300k, and 490k
as sub-datasets from the 10% KDDcup99 training dataset.
The 490k case indicates the complete 10% dataset. As a
testing dataset, we used the KDDcup99 (corrected) evalu-
ation dataset by excluding those attack instances which do
not belong to the set of 22 speciﬁc attack types in the train-
ing dataset. In each experiment we recorded the following
information: False Positives (FP) – the number of normal in-

77stances detected as attack instances; False Negatives (FN) –
the number of attack instances detected as normal instances;
True Positive (TP) – the number of correctly detected attack
instances; and True Negative (TN) – the number of correctly
detected normal instances.

For each diﬀerent training dataset size and the same test-
ing dataset we repeated training and testing 4 times in order
to obtain averages of FP, FN TP and TN. Based on these
results, the performance of MR ELM against local ELM was
measured by Overall Accuracy, which means the percentage
of correctly detected sample instances:

Overall Accuracy =

TP + TN

FP + FN + TP + TN

× 100 .

(12)

We also calculated Detection rate (DR) and False Alarm
rate (FAR) according in our binary intrusion detection ex-
periments. Detection rate is the percentage of detected at-
tacks:

Detection rate =

TP

FP + FN

× 100 .

(13)

False Alarm rate indicates the percentage of False Posi-

tives among all normal sample instances:

False Alarm rate =

FP

FP + TN

× 100 .

(14)

The second aspect focuses on the eﬃciency and scalabil-
ity of MR ELM in comparison with local ELM. In order to
evaluate the eﬃciency of MR ELM, we adopted the value of
speedup as the criterion:

speedup =

computing time on 1 node
computing time on m nodes

.

(15)

The eﬃciency of MR ELM represents the speedup for MR -
ELM compared to the local ELM. A speedup improvement
is obtained for an additional processing node as long as
W/n+S(n) < W/(n−1)+S(n−1), where n > 2 is the num-
ber of processing nodes, W represents the workload to be
processed, and S(n) represents the average processing over-
head in a node caused mainly by communication between
nodes. It is reasonable to assume, that S(n) is a continuously
growing function and that S(n + 1) − S(n) ≥ S(n) − S(n − 1)
for each n > 2. The optimal number of processing nodes,
Nn, can then be determined from S(Nn + 1) − S(Nn) =
W/(Nn(Nn + 1)). If S(n) is linear, S(n) = nD for a con-

stant D, then Nn = √(1 + 4W/D) − 1)/2.

In a real distributed computing environment, the dataset
is partitioned into blocks which are stored and executed in
diﬀerent cluster nodes. In our experiments, we tested diﬀer-
ent dataset sizes ranging from 1000k to 3000k with a step
of 1000k. These datasets were extracted from the complete
KDDcup99 training dataset and executed on cluster nodes
ranging from 15 to 30 nodes with a step of 5 nodes. We used
sizeup to evaluate the scalability of MR ELM:

sizeup =

computing time for processing m data
computing time for processing 1 data

.

(16)

sizeup represents the ability of MR ELM to deal with in-
creasing datasets in a limited CPU time. For fairness, in
our experiments we chose 50 and 200 as numbers of hid-
den neurons and C = 1024 = 210. The number of neurons

Table 3: Overall Accuracy for binary intrusion de-
tection with 50 hidden neurons. DR - detection rate;
FAR - false alarm rate.
local ELM

N

100k
200k
300k
490k

acc.
94.75
93.31
97.08
97.58

DR
94.68
92.21
96.67
97.39

FAR
1.53
1.49
1.39
1.72

MR ELM (10 nodes)
FAR
acc.
1.79
94.65
94.57
1.42
1.39
96.60
97.70
1.62

DR
93.87
93.34
96.07
97.57

Table 4: Overall Accuracy for binary intrusion de-
tection with 200 hidden neurons. DR - detection
rate; FAR - false alarm rate.

N

100k
200k
300k
490k

local ELM

acc.
96.22
94.33
97.12
97.88

DR
95.68
92.97
96.67
97.67

FAR
1.44
1.46
1.18
1.31

MR ELM (10 nodes)
FAR
acc.
97.63
0.89
1.45
95.20
1.41
96.35
97.68
1.66

DR
97.12
94.01
95.77
97.27

can be set to a high value without the risk of overﬁtting in
cases with a large number of samples [4, 17]. Since the C
parameter mainly acts as a regularization term to ill-deﬁned
linear problems, it is set to a high value as there are plenty
of samples to make the matrix HTH full rank. The optimal
number of reducers is
(between 0.95 and 1.75) ×

(number of nodes × mapred.tasktracker.tasks.maximum) .

When this factor is 0.95, then all reducers can launch and
start transferring map outputs immediately after the map
tasks have ﬁnished. When this factor is 1.75, then the fast
nodes can execute the ﬁrst round of reducers and thereafter
launch the second round in order to achieve a better load
balance.

4.3 Binary Intrusion Detection

4.3.1 Performance Analysis of MR_ELM

Overall Accuracy for diﬀerent training dataset sizes and
the same testing dataset is shown in Tables 3 and 4 for binary
intrusion detection. For this binary intrusion detection ex-
periment, we preprocessed the training and testing datasets
by giving label value 1 for each normal sample instance and
label value −1 for each attack instance. Overall Accuracy
for both MR ELM and local ELM is about 93% or better
depending on the training set size. A slight, nearly general,
Overall Accuracy improvement is achieved by increasing the
number of hidden neurons from 50 to 200. MR ELM has a
little bit higher detection rate than local ELM in almost all
training dataset experiments. For a larger training dataset
size Detection rate increases a little bit. False Alarm rate is
very low, between 0.89% and 1,72%, in all training dataset
experiments.

4.3.2 Efﬁciency and scalability analysis of MR_ELM
Table 5 shows the execution time of MR ELM for dataset
sizes in binary intrusion detection with 50 hidden neurons.
We tested three datasets with sizes 1000k, 2000k and 3000k.
For each dataset the program was executed 4 times both on a
single machine and on 15, 20, 25 cluster nodes. The average

78Table 5: Execution times (in seconds) of MR ELM
in binary intrusion detection setting with 50 hidden
neurons.

number of

nodes
single

15
20
25
30

1000k
6659s
278s
258s
223s
246s

dataset size N
2000k
11837s Out of memory

3000k

441s
400s
332s
382s

643s
558s
462s
470s

1 million dataset
2 million dataset
3 million dataset

p
u
d
e
e
p
S

0

.

2

8

.

1

6

.

1

4

.

1

2

.

1

0

.

1

●

●

●

●

●
●

25

30

number of nodes

●

●
●

20

●
●
●

15

Figure 4: speedup of MR ELM for binary intrusion
detection with 50 hidden neurons.

execution times were calculated. We can see that MR ELM
can signiﬁcantly decrease the execution time compared to
local ELM. For the 3000k dataset we can see that local ELM
cannot execute. MR ELM can run some big data that local
ELM cannot run. We can also see that the execution time
of MR ELM decreases as the number of nodes increases up
to 25 nodes. When the number of nodes is increased from
25 to 30, then the running time increases a bit because of
increased communication between nodes. A drawback of the
MapReduce framework is the overhead required by the disk
read/write operations of map/reduce tasks. This overhead
can severely prolong the execution time, if the response time
of the hard disks strongly depends on the workload on the
processing nodes.

speedup performance of MR ELM for binary classiﬁcation
with 50 hidden neurons is shown in Figure 4. The perfect
speedup is linear which is diﬃcult to achieve in a real envi-
ronment because of increased communication between nodes.
However, it can be seen in Figure 4 that a higher speedup is
achieved for a larger dataset size.

Figure 5 shows sizeup of MR ELM for binary intrusion
detection with 50 hidden neurons. Like speedup, the ideal
sizeup should be linear, but this is hard to achieve in a real
environment because of increasing communication between
nodes. However, for all dataset sizes and program execution
on clusters with diﬀerent number of nodes sizeup is approx-
imately linear.

0
3

.

5
2

.

0

.

2

5
1

.

p
u
e
z
S

i

0

.

1

●
●
●
●

15 nodes
20 nodes
25 nodes
30 nodes

●

●

●

●

●
●
●

●

1.0

1.5

2.0

2.5

3.0

size of dataset(1 million instances)

Figure 5: sizeup of MR ELM for binary intrusion
detection with 50 hidden neurons.

Table 6: Overall Accuracy for multi-class intrusion
detection with 50 hidden neurons. LE - Local ELM.

Training

5 classes

23 classes

data size N

100k
200k
300k
490k

LE MR ELM LE MR ELM
91.77
92.94
95.93
97.39

92.86
93.26
95.16
96.84

91.37
93.18
96.53
97.44

92.78
93.91
97.28
97.41

Table 7: Overall Accuracy for multi-class intrusion
detection with 200 hidden neurons. LE - Local ELM.

Training

5 classes

23 classes

data size N

100k
200k
300k
490k

LE MR ELM LE MR ELM
91.40
92.29
94.97
97.72

93.82
94.85
97.66
97.72

90.84
93.53
96.37
97.47

93.79
95.01
97.27
97.44

4.4 Multiclass Intrusion Detection

4.4.1 Performance analysis of MR_ELM

Tables 6 and 7 demonstrate Overall Accuracy for diﬀerent
training dataset sizes and the same testing dataset for multi-
class intrusion detection. The training and testing dataset
have been preprocessed by assigning the 5 class label values
for 1 normal group and 4 main attack groups as well as 23
class labels for 1 normal group and 22 speciﬁc attack types.
Both for the 5 class and the 23 class dataset experiment
MR ELM and local ELM have a very similar and relatively
good Overall Accuracy above 90%. For an increased train-
ing dataset size Overall Accuracy increases. For the largest
training dataset size, Overall Accuracy is slightly improved
by increasing the number of hidden neurons from 50 to 200.

4.4.2 Efﬁciency and scalability analysis of MR_ELM
Table 8 shows the execution time of MR ELM for 3 dif-
ferent dataset sizes in multi-class intrusion detection with
50 hidden neurons. We tested these 3 dataset sizes on a
single machine and on 4 clusters with a diﬀerent number of

79Table 8: Execution times (in seconds) of MR ELM
for multi-class intrusion detection with 50 hidden
neurons.

number of

nodes
single

15
20
25
30

1000k
7336s
294s
256s
230s
252s

dataset size N
2000k
13498s Out of memory

3000k

485s
431s
367s
382s

659s
571s
488s
494s

1 million dataset
2 million dataset
3 million dataset

p
u
d
e
e
p
S

0

.

2

8

.

1

6

.

1

4

.

1

2

.

1

0

.

1

●

●

●

●

●

●

●
●
●

20

●
●
●

15

25

30

number of nodes

Figure 6: speedup of MR ELM for multi-class intru-
sion detection with 50 hidden neurons.

nodes 4 times in order to obtain average execution times. We
can see that MR ELM signiﬁcantly decreases the execution
time in comparison with local ELM. Increased communica-
tion between nodes slightly increases the execution time of
MR ELM, when the number of nodes is increased from 25
to 30.

Figures 6 and 7 show the measured speedup and sizeup for
multi-class intrusion detection with 50 hidden neurons. The
speedup is approximately linear except for the tails. From
15 to 25 nodes all three lines increase linearly as more nodes
improve parallel computing ability. Increasing the number
of nodes from 25 to 30 decreases speedup because of the in-
creased overhead in nodes mainly caused by communication
between nodes. In Figures 6 and 7 can be seen, that a higher
speedup and sizeup can be achieved by MR ELM for a larger
dataset.

5. CONCLUSIONS

Extreme Learning Machine is a promising straightforward
algorithm which can achieve a relatively high Overall Accu-
racy and can signiﬁcantly decrease the time of the training
phase. However, massive data or big data is a big challenge
for the practical use of ELM. In this paper, we proposed a
massively parallel algorithm for ELM, MR ELM, to solve
big data problems. By experiments, we demonstrated that
our MapReduce variant of ELM can eﬃciently process the
complete KDDcup99 dataset that a local ELM cannot. It
clearly outperforms local ELM without losing any Overall
Accuracy, Detection rate, and False Alarm rate. These ex-

15 nodes
20 nodes
25 nodes
30 nodes

●
●

●

●

●
●

●

●

0
3

.

5
2

.

0

.

2

5
1

.

p
u
e
z
S

i

0

.

1

●
●
●
●

1.0

1.5

2.0

2.5

3.0

size of dataset(1 million instances)

Figure 7: sizeup of MR ELM for multi-class intru-
sion detection with 50 hidden neurons.

periments also show that MR ELM tends to have a good
speedup and sizeup performance. However, there is still
room for improvement. For future research, a distributed
approach for solving a linear system would allow for larger
network architectures to be used. Also, the complete algo-
rithm can be tested on other intrusion detection datasets
to measure how well MR ELM scales within modern com-
puter environments. By employing more complete datasets,
issues with sampling that might lead to omitting important
features in data can be avoided [21].

6. REFERENCES
[1] “KDDcup dataset,” 1999. Available: http://kdd.ics.

uci.edu/databases/kddcup99/kddcup99.html.

[2] S. Wu and W. Banzhaf, “The use of computational

intelligence in intrusion detection systems: A review,”
Applied Soft Computing, vol. 10, no. 1, pp. 1–35, 2010.

[3] Z. Q.-Y. Huang, G.-B. and C.-K. Siew, “Universal

approximation using incremental constructive
feedforward networks with random hidden nodes,”
IEEE Transactions on Neural Networks, vol. 17, no. 4,
pp. 879–892, 2006.

[4] C. Cheng, W. P. Tay, and G.-B. Huang, “Extreme

learning machines for intrusion detection,” in
Proceedings of the International Joint Conference on
Neural Networks (IJCNN’12), pp. 1–8, IEEE, June
10-12, 2012.

[5] “CSA Cloud Security Alliance.” Available:

https://cloudsecurityalliance.org/.

[6] Big Data Working Group, “Big data analytics for

security intelligence,” 2013. CSA Cloud Security
Alliance, Retrieved January 3, 2014, from
https://downloads.cloudsecurityalliance.org/
initiatives/bdwg/Big_Data_Analytics_for_
Security_Intelligence.pdf.

[7] T. Dumitras and D. Shou, “Toward a standard
benchmark for computer security research: The
worldwide intelligence network environment (wine),” in
Proceedings of the First Workshop on Building
Analysis Datasets and Gathering Experience Returns
for Security, pp. 89–96, ACM, 2011.

80[8] J. Dean and S. Ghemawat, “Mapreduce: Simpliﬁed

data processing on large clusters,” Communications of
the ACM, vol. 51, pp. 107–113, Jan. 2008.

[9] The Apache Software Foundation, “Welcome to

Apache Hadoop!,” 2013.

[10] D. Borthakur, “The hadoop distributed ﬁle system:

architecture and design,” 2007. Retrieved July 17,
2014, from http://hadoop.apache.org/common/docs/
r0.18.0/hdfs_design.pdf.

[11] T. Chen, X. Zhang, S. Jin, and O. Kim, “Eﬃcient

classiﬁcation using parallel and scalable compressed
model and its application on intrusion detection,”
Expert Systems with Applications, vol. 41, no. 13,
pp. 5972–5983, 2014.

[12] M. Bhuyan, D. Bhattacharyya, and J. Kalita,

“Network anomaly detection: Methods, systems and
tools,” Communications Surveys & Tutorials, IEEE,
vol. 16, no. 1, pp. 303–336, 2014.

[13] S. Mukkamala, G. Janoski, and A. Sung, “Intrusion
detection using neural networks and support vector
machines,” in Proceedings of the International Joint
Conference on Neural Networks (IJCNN’02),
pp. 1702–1707, May 12-17 2002.

[14] G. Creech and J. Hu, “A semantic approach to

host-based intrusion detection systems using
contiguous and discontiguous system call patterns,”
IEEE Transaction on Computers, vol. 63, no. 4,
pp. 807–819, 2014.

[15] Q. He, T. Shang, F. Zhuang, and Z. Shi, “Parallel
extreme learning machine for regression based on
mapreduce,” Neurocomputing, vol. 102, pp. 52–58, Feb.
2013.

[16] S. Haykin, Neural Networks and Learning Machines.

Pearson Prentice Hall, USA, 3rd ed., 2009.

[17] G.-B. Huang, H. Zhou, X. Ding, and R. Zhang,

“Extreme learning machine for regression and
multiclass classiﬁcation,” IEEE Transactions on
Systems, Man, and Cybernetics, Part B, vol. 42, no. 2,
pp. 513–529, 2012.

[18] G.-B. Huang, Q.-Y. Zhu, and C.-K. Siew, “Extreme

learning machine: Theory and applications,”
Neurocomputing, vol. 70, no. 1-3, pp. 489–501, 2006.

[19] J. Xin, Z. Wang, C. Chen, L. Ding, G. Wang, and

Y. Zhao, “Elm: distributed extreme learning machine
with mapreduce,” World Wide Web, pp. 1–16, 2013.

[20] Y. Miche, A. Sorjamaa, P. Bas, O. Simula, C. Jutten,

and A. Lendasse, “OP-ELM: Optimally-pruned
extreme learning machine,” IEEE Transactions on
Neural Networks, vol. 21, pp. 158–162, January 2010.

[21] R. Rouhi, F. Keynia, and M. Amiri, “Improving the

intrusion detection systems’ performance by
correlation as a sample selection method,” Journal of
Computer Sciences and Applications, vol. 1, no. 3,
pp. 33–38, 2013.

Appendix
List of important variables:

InW
bias
nHidNeur

randomly generated input weights
randomly generated biases
number of hidden neurons

nInNeur
C
nOutNeur
actFcn
nReducer

number of input neurons
C parameter
number of output neurons
activation function
assigned number of reduce tasks

Algorithm 1: Calculate HTH and HTT for each sample
Input: key – oﬀset for one line input; value – training sample
Output: key – string of ”THHandTHT” + Trainkeyindex % nRe-

ducer; value is HTH and HTT for one sample

sample = parse the input training sample
get the expected label from array sample
initialize labelArray for storing expected target score
Trainkeyindex = 0
for i = 1 to nOutNeur do

labelArray[i] = -1

end for
initialize Harray for matrix H for one sample
for i =1 to nHidNeur do

if expected label == i then

labelArray[i] = 1

end if

temp += InW[i][j] * sample[j]

temp = 0
for j = 1 to nInNeur do

end for
for i = 1 to nOutNeur do

1: function SubOutMapper(key, value)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
34:
35:
36:
37:
38:
39:
40:
41: end function

end for
outValue = ””
outKey = ”THHandTHT”
for i = 1 to nHidNeur do

end for
temp += bias[i]
temp = actFcn(temp)
Harray[i] = temp

ret = Harray[i] * Harray[j]
THH += ret
THH += ”,”

r = Harray[i] * labelArray[j]
THT += r
THT += ”,”

end for
for j = 1 to nOutNeur do

end for
outValue = outValue + THH + THT
outKey += Trainkeyindex%nReducer
Context.write(outKey, outValue)

for j = 1 to nHidNeur do

◃ calculate matrix H for one sample

◃ THH stores HTH

◃ THT stores HTT

end for

Algorithm 2: Calculate HTH and HTT for each subdataset
Input: key – string of ”THHandTHT” + Trainkeyindex % nRe-

ducer; values – HTH and HTT for samples of subdataset

initialize array THHMatrix[nHidNeur][nHidNeur] for HTH
initialize THTMatrix[nHidNeur][nOutNeur] for HTT
for each oneVal in values do

Output: key – HTH and HTT ; value – empty string
1: function SubOutWReducer(key, values)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:

parse oneVal into an array named arr
for i = 1 to nHidNeur do

end for
for j = 1 to nOutNeur do

THTMatrix[i][j] += arr[nHidNeur*nHidNeur +

THHMatrix[i][j] += arr[i*nHidNeur + j]

for j = 1 to nHidNeur do

◃ get matrix HTH

i*nOutNeur + j]

end for

end for

end for
outKey = ””
for i = 1 to nHidNeur do

12:
13:
14:
15:
16:

◃ get matrix HTT

81for j = 1 to nHidNeur do

outKey += THHMatrix[i][j]
outKey += ”,”

end for

17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30: end function

end for

end for
for i = 1 to nHidNeur do

for j = 1 to nOutNeur do

outKey += THTMatrix[i][j]
outKey += ”,”

end for
outValue = ””
Context.write(outKey, outValue))

Algorithm 3: Calculate the output weights β
Input: key – string of ”outW”; values – HTH and HTT for each

subdataset

initialize array THHMatrix[nHidNeur][nHidNeur] for HTH
initialize THTMatrix[nHidNeur][nOutNeur] for HTT
for each oneVal in values do

Output: key – output weights β; value – empty string
1: function OutWReducer(key, values)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:

parse oneVal into an array named arr
for i = 1 to nHidNeur do

end for
for j = 1 to nOutNeur do

THTMatrix[i][j] += arr[nHidNeur*nHidNeur +

THHMatrix[i][j] += arr[i*nHidNeur + j]

◃ get matrix HTH for all samples

for j = 1 to nHidNeur do

i*nOutNeur + j]

end for

◃ get matrix HTT for all samples

end for
generate identity matrix named mtr Iden
outW = mtr Iden / C
outW = outW + THH
outW = inverse(outW)
outW = outW * THT
outKey = ””
outValue = ””
for i = 1 to nHidNeur do

◃ compute inverse

end for

12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30: end function

for j = 1 to nOutNeur do

outKey += outW[i][j]
outKey += ” ”

end for
outKey += ”\r\n”

end for
Context.write(outKey, outValue)

Algorithm 4: Calculate the target scores(output neurons) of
actual label for each testing sample
Input: key – oﬀset for one line input; value – one testing sample
Output: key – string ”oneTargetScore” + Testkeyindex % nRe-
ducer; value – target scores plus expected label for one testing
sample

sample = parse input testing sample
get the expected label from array sample
initialize onesampleH[nHidNeur] for H for a testing sample
Testkeyindex = 0
outValue = ””
outKey = ”oneTargetScore”
for i = 1 to nHidNeur do

1: function SubAccMapper(key, value)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:

end for
temp += bias[i]
temp = actFcn(temp)
onesampleH[i] = temp

temp = ””
for j = 1 to nHidNeur do

◃ calculate H for one testing sample

temp += InW[i][j] + sample[j]

end for

17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28: end function

for i = 1 to nOutNeur do

temp = 0
for j = 1 to nHidNeur do

temp += onesampleH[j] * outW[j][i]

end for
outValue += temp
outValue += ” ”
outValue += expected label
outKey += Testkeyindex%nReducer

end for
Context.write(outKey, outValue)

Algorithm 5: Calculate the matchnum (the number of matched
samples) and sum (the number of samples) for sub testing dataset
Input: key – string ”oneTargetScore” + Testkeyindex % nRe-
ducer; values – target scores plus expected label for all testing
samples

Output: key – matchnum and sum for sub testing dataset; value

– empty string

◃ store the number of sample
◃ store the actual label
◃ store the number of matched samples

sum++
maxIndex = 0
Parse the oneVal in a array named actualScore
Get the expected label from array actualScore
maxScore = actualScore[0]
for i = 1 to nOutNeur do

if actualScore[i] > maxScore then

outKey = ””
outValue = ””
sum = 0
label = 0
matchnum = 0
for each oneVal in values do

1: function SubAccReducer(key, values)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26: end function

end for
outKey = matchum + ”:” + sum
Context.write(outKey, outValue)

end for
label = maxIndex
if expected label == label then

maxScore = actualScore[i]
maxIndex = i

matchnum++

end if

end if

Algorithm 6: Calculate the accuracy for the whole test dataset
Input: key – string of ”Accuracy”; values – matchnum and sum

testing subdataset

outKey = ””
outValue = ””
g sum = 0
◃ store the number of test samples
g matchnum = 0 ◃ store the number of matched samples
for each oneVal in values do

Output: key – accuracy for testing dataset; value – empty string
1: function AccReducer(key, values)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14: end function

end for
accuracy = g matchnum / g sum * 100
outKey += accuracy
Context.write(outKey, outValue)

parse oneVal and get the input matchnum and sum
g matchnum += matchnum
g sum += sum

82