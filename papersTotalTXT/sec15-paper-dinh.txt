M2R: Enabling Stronger Privacy in MapReduce 

Computation

Tien Tuan Anh Dinh, Prateek Saxena, Ee-Chien Chang, Beng Chin Ooi,  

and Chunwang Zhang, National University of Singapore

https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/dinh

This paper is included in the Proceedings of the 24th USENIX Security SymposiumAugust 12–14, 2015 • Washington, D.C.ISBN 978-1-931971-232Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXM2R: Enabling Stronger Privacy in MapReduce Computation

Tien Tuan Anh Dinh, Prateek Saxena, Ee-Chien Chang, Beng Chin Ooi, Chunwang Zhang

School of Computing, National University of Singapore

ug93tad@gmail.com, prateeks@comp.nus.edu.sg, changec@comp.nus.edu.sg

ooibc@comp.nus.edu.sg, zhangchunwang@gmail.com

Abstract

New big-data analysis platforms can enable distributed
computation on encrypted data by utilizing trusted com-
puting primitives available in commodity server hard-
ware. We study techniques for ensuring privacy-
preserving computation in the popular MapReduce
framework.
In this paper, we ﬁrst show that protect-
ing only individual units of distributed computation (e.g.
map and reduce units), as proposed in recent works,
leaves several important channels of information leak-
age exposed to the adversary. Next, we analyze a variety
of design choices in achieving a stronger notion of pri-
vate execution that is the analogue of using a distributed
oblivious-RAM (ORAM) across the platform. We de-
velop a simple solution which avoids using the expen-
sive ORAM construction, and incurs only an additive
logarithmic factor of overhead to the latency. We im-
plement our solution in a system called M2R, which en-
hances an existing Hadoop implementation, and evaluate
it on seven standard MapReduce benchmarks. We show
that it is easy to port most existing applications to M2R
by changing fewer than 43 lines of code. M2R adds fewer
than 500 lines of code to the TCB, which is less than
0.16% of the Hadoop codebase. M2R offers a factor of
1.3× to 44.6× lower overhead than extensions of previ-
ous solutions with equivalent privacy. M2R adds a total of
17% to 130% overhead over the insecure baseline solu-
tion that ignores the leakage channels M2R addresses.

1

Introduction

The threat of data theft in public and private clouds from
insiders (e.g. curious administrators) is a serious con-
cern. Encrypting data on the cloud storage is one stan-
dard technique which allows users to protect their sen-
sitive data from such insider threats. However, once
the data is encrypted, enabling computation on it poses
a signiﬁcant challenge. To enable privacy-preserving
computation, a range of security primitives have sur-
faced recently, including trusted computing support for
hardware-isolated computation [2, 5, 38, 40] as well as
purely cryptographic techniques [20,21,47]. These prim-

itives show promising ways for running computation se-
curely on a single device running an untrusted software
stack. For instance, trusted computing primitives can iso-
late units of computation on an untrusted cloud server. In
this approach, the hardware provides a conﬁdential and
integrity-protected execution environment to which en-
cryption keys can be made available for decrypting the
data before computing on it. Previous works have suc-
cessfully demonstrated how to securely execute a unit of
user-deﬁned computation on an untrusted cloud node, us-
ing support from hardware primitives available in com-
modity CPUs [8, 14, 38, 39, 49] .

In this paper, we study the problem of enabling
privacy-preserving distributed computation on an un-
trusted cloud. A sensitive distributed computation task
comprises many units of computation which are sched-
uled to run on a multi-node cluster (or cloud). The input
and output data between units of computation are sent
over channels controlled by the cloud provisioning sys-
tem, which may be compromised. We assume that each
computation node in the cluster is equipped with a CPU
that supports trusted computing primitives (for example,
TPMs or Intel SGX). Our goal is to enable a privacy-
preserving execution of a distributed computation task.
Consequently, we focus on designing privacy in the pop-
ular MapReduce framework [17]. However, our tech-
niques can be applied to other distributed dataﬂow frame-
works such as Spark [62], Dryad [26], and epiC [27].
Problem. A MapReduce computation consists of two
types of units of computation, namely map and re-
duce, each of which takes key-value tuples as input.
The MapReduce provisioning platform, for example
Hadoop [1], is responsible for scheduling the map/reduce
operations for the execution in a cluster and for provid-
ing a data channel between them [31]. We aim to achieve
a strong level of security in the distributed execution of a
MapReduce task (or job) — that is, the adversary learns
nothing beyond the execution time and the number of
input and output of each computation unit. If we view
each unit of computation as one atomic operation of a
larger distributed program, the execution can be thought
of as running a set of operations on data values passed

USENIX Association  

24th USENIX Security Symposium  447

1

via a data channel (or a global “RAM”) under the ad-
versary’s control. That is, our deﬁnition of privacy is
analogous to the strong level of privacy offered by the
well-known oblivious RAM protocol in the monolithic
processor case [22].

We assume that the MapReduce provisioning platform
is compromised, say running malware on all nodes in
the cluster. Our starting point in developing a defense
is a baseline system which runs each unit of computation
(map/reduce instance) in a hardware-isolated process, as
proposed in recent systems [49, 59]. Inputs and outputs
of each computation unit are encrypted, thus the adver-
sary observes only encrypted data. While this baseline
offers a good starting point, merely encrypting data in-
transit between units of computation is not sufﬁcient (see
Section 3). For instance, the adversary can observe the
pattern of data reads/writes between units. As another
example, the adversary can learn the synchronization be-
tween map and reduce units due to the scheduling struc-
ture of the provisioning platform. Further, the adversary
has the ability to duplicate computation, or tamper with
the routing of encrypted data to observe variations in the
execution of the program.
Challenges. There are several challenges in building
a practical system that achieves our model of privacy.
First, to execute map or reduce operations on a single
computation node, one could run all computation units
— including the entire MapReduce platform — in an ex-
ecution environment that is protected by use of existing
trusted computing primitives. However, such a solution
would entail little trust given the large TCB, besides be-
ing unwieldy to implement. For instance, a standard im-
plementation of the Hadoop stack is over 190K lines of
code. The scope of exploit from vulnerabilities in such a
TCB is large. Therefore, the ﬁrst challenge is to enable
practical privacy by minimizing the increase in platform
TCB and without requiring any algorithmic changes to
the original application.

The second challenge is in balancing the needs of pri-
vacy and performance. Addressing the leakage channels
discussed above using generic methods easily yields a
solution with poor practical efﬁciency. For instance, hid-
ing data read/write patterns between speciﬁc map and
reduce operations could be achieved by a generic obliv-
ious RAM (ORAM) solution [22, 55]. However, such
a solution would introduce a slowdown proportional to
polylog in the size of the intermediate data exchange,
which could degrade performance by over 100× when
gigabytes of data are processed.
Our Approach. We make two observations that en-
able us to achieve our model of privacy in a MapRe-
duce implementation. First, on a single node, most of the
MapReduce codebase can stay outside of the TCB (i.e.

code performing I/O and scheduling related tasks). Thus,
we design four new components that integrate readily to
the existing MapReduce infrastructure. These compo-
nents which amount to fewer than 500 lines of code are
the only pieces of trusted logic that need to be in the
TCB, and are run in a protected environment on each
computation node. Second, MapReduce computation
(and computation in distributed dataﬂow frameworks in
general) has a speciﬁc structure of data exchange and ex-
ecution between map and reduce operations; that is, the
map writes the data completely before it is consumed by
the reduce. Exploiting this structure, we design a com-
ponent called secure shufﬂer which achieves the desired
security but is much less expensive than a generic ORAM
solution, adding only a O(logN) additive term to the la-
tency, where N is the size of the data.
Results. We have implemented a system called M2R
based on Hadoop [1]. We ported 7 applications from a
popular big-data benchmarks [25] and evaluated them on
a cluster. The results conﬁrm three ﬁndings. First, port-
ing MapReduce jobs to M2R requires small development
effort: changing less than 45 lines of code. Second, our
solution offers a factor of 1.3× to 44.6× (median 11.2×)
reduction in overhead compared to the existing solu-
tions with equivalent privacy, and a total of 17%− 130%
of overhead over the baseline solution which protects
against none of the attacks we focus on in this paper. Our
overhead is moderately high, but M2R has high compati-
bility and is usable with high-sensitivity big data analysis
tasks (e.g. in medical, social or ﬁnancial data analytics).
Third, the design is scalable and adds a TCB of less than
0.16% of the original Hadoop codebase.
Contributions. In summary, our work makes three key
contributions:

• Privacy-preserving distributed computation. We
deﬁne a new pragmatic level of privacy which can
be achieved in the MapReduce framework requiring
no algorithmic restructuring of applications.

• Attacks. We show that merely encrypting data in en-
claved execution (with hardware primitives) is inse-
cure, leading to signiﬁcant privacy loss.

• Practical Design. We design a simple, non-
intrusive architectural change to MapReduce. We
in a real Hadoop implementation
implement
and benchmark its performance cost for privacy-
sensitive applications.

it

2 The Problem

Our goal is to enable privacy-preserving computation for
distributed dataﬂow frameworks. Our current design and

448  24th USENIX Security Symposium 

USENIX Association

2

USENIX Association  

24th USENIX Security Symposium  449

mapmappershufflermapmapshufflermapreducereducereduce...............reducermapperreducerreducershuffle phaseFigure1:TheMapReducecomputationmodel.implementationarespeciﬁctoMapReduceframework,thecomputationstructureofwhichisneverthelesssimi-lartootherdistributeddataﬂowengines[26,27,62],dif-feringmainlyinsupportedoperations.BackgroundonMapReduce.TheMapReducelan-guageenforcesastrictstructure:thecomputationtaskissplitintomapandreduceoperations.Eachinstanceofamaporreduce,calledacomputationunit(orunit),takesalistofkey-valuetuples1.AMapReducetaskcon-sistsofsequentialphasesofmapandreduceoperations.Oncethemapstepisﬁnished,theintermediatetuplesaregroupedbytheirkey-components.Thisprocessofgroupingisknownasshufﬂing.Alltuplesbelongingtoonegroupareprocessedbyareduceinstancewhichex-pectstoreceivetuplessortedbytheirkey-component.Outputsofthereducestepcanbeusedasinputsforthemapstepinthenextphase,creatingachainedMapRe-ducetask.Figure1showsthedataﬂowfromthemaptothereduceoperationsviatheshufﬂingstep.Intheactualimplementation,theprovisioningofallmapunitsononeclusternodeislocallyhandledbyamapperprocess,andsimilarly,byareducerprocessforreduceunits.2.1ThreatModelTheadversaryisamaliciousinsiderinthecloud,aimingtosubverttheconﬁdentialityoftheclient’scomputationrunningontheMapReduceplatform.Weassumethattheadversaryhascompleteaccesstothenetworkandstorageback-endoftheinfrastructureandcantamperwiththepersistentstorageornetworktrafﬁc.Foreachcompu-tationnodeinthecluster,weassumethattheadversarycancorrupttheentiresoftwarestack,saybyinstallingmalware.Weconsideranadversarythatperpetratesbothpas-siveandactiveattacks.Apassiveorhonest-but-curiousattackerpassivelyobservesthecomputationsession,be-1Toavoidconfusionofthetuplekeywithcryptographickey,werefertotheﬁrstcomponentinthetupleaskey-component.havinghonestlyinrelayingdatabetweencomputationunits,butaimstoinfersensitiveinformationfromtheobserveddata.Thisisapragmaticmodelwhichincludesadversariesthatobservedatabackedupperiodicallyondiskforarchival,orhaveaccesstoperformancemoni-toringinterfaces.Anactiveormaliciousattacker(e.g.aninstalledmalware)candeviatearbitrarilyfromtheex-pectedbehaviorandtamperwithanydataunderitscon-trol.Ourworkconsidersbothsuchattacks.ThereareatleasttwodirectattacksthatanadversarycanmountonaMapReducecomputationsession.First,theadversarycanobservedatapassingbetweencompu-tationunits.Ifthedataisleftunencrypted,thisleadstoadirectbreachinconﬁdentiality.Second,theadversarycansubvertthecomputationofeachmap/reduceinstancebytamperingwithitsexecution.Toaddressthesebasicthreats,westartwithabaselinesystemdescribedbelow.BaselineSystem.Weconsiderthebaselinesysteminwhicheachcomputationunitishardware-isolatedandexecutedprivately.Weassumethatthebaselinesys-temguaranteesthattheprogramcanonlybeinvokedonitsentireinputdataset,orelseitabortsinitsﬁrstmapphase.Datablocksenteringandexitingacomputationunitareencryptedwithauthenticatedencryption,andallside-channelsfromeachcomputationunitareassumedtobemasked[51].Intermediatedataisdecryptedonlyinahardware-attestedcomputationunit,whichhaslimitedmemorytosecurelyprocessuptoTinputstuples.Sys-temsachievingthisbaselinehavebeenpreviouslypro-posed,basedondifferingunderlyinghardwaremecha-nisms.VC3isarecentsystembuiltonIntelSGX[49].Notethatinthisbaselinesystem,theMapReducepro-visioningplatformisresponsibleforinvokingvarioustrustedunitsofcomputationinhardware-isolatedpro-cesses,passingencrypteddatabetweenthem.InSec-tion3,weexplainwhythisbaselinesystemleakssig-niﬁcantinformation,andsubsequentlydeﬁneastrongerprivacyobjective.2.2ProblemDeﬁnitionIdeally,thedistributedexecutionoftheMapReducepro-gramshouldleaknothingtotheadversary,excepttheto-talsizeoftheinput,totalsizeoftheoutputandtherun-ningtime.Theaforementionedbaselinesystemfailstoachievetheidealprivacy.Itleakstwotypesofinforma-tion:(a)theinputandoutputsize,andprocessingtimeofindividualcomputationunit,and(b)dataﬂowamongthecomputationunits.Westressthattheleakageof(b)issigniﬁcantinmanyapplicationssinceitrevealsrelationshipsamongthein-put.Forinstance,inthewell-knownexampleofcomput-ingPagerankscoresforanencryptedgraph[44],ﬂowsfromacomputationunittoanothercorrespondtoedges3in the input graph. Hence, leaking the dataﬂow essen-
tially reveals the whole graph edge-structure!

Techniques for hiding or reducing the leakage in (a)
by padding the input/output size and introducing timing
delays are known [35, 41]. Such measures can often re-
quire algorithmic redesign of the application [9] or use of
specialized programming languages or hardware [33,34],
and can lead to large overheads for applications where
the worst case running time is signiﬁcantly larger than
the average case. We leave incorporating these orthogo-
nal defenses out-of-scope.

Instead, in this work, we advocate focusing on elimi-
nating leakage on (b), while providing a formulation that
clearly captures the information that might be revealed.
We formulate the admissible leakage as Ψ which cap-
tures the information (a) mentioned above, namely the
input/output size and running time of each trusted com-
putation unit invoked in the system. We formalize this
intuition by deﬁning the execution as a protocol between
trusted components and the adversary, and deﬁne our pri-
vacy goal as achieving privacy modulo-Ψ.

Execution Protocol. Consider an honest execution of a
program on input I = (cid:31)x1,x2, . . . ,x n(cid:30). For a given map-
reduce phase, let there be n map computation units. Let
us label the map computation units such that the unit with
label i takes xi as input. Recall that the tuples generated
by the map computation units are to be shufﬂed, and
divided into groups according to the key-components.
Let K to be the set of unique key-components and let
π : [n+1,n+m] → K be a randomly chosen permutation,
where m = |K|. Next, m reduce computation units are to
be invoked. We label them starting from n + 1, such that
the computation unit i takes tuples with key-component
π(i) as input.

Let Ii,Oi,Ti be the respective input size (measured by
number of tuples), output size, and processing time of the
computation unit i, and call Ψi = (cid:31)Ii,Oi,Ti(cid:30) the IO-proﬁle
of computation unit i. The proﬁle Ψ of the entire execu-
tion on input I is the sequence of Ψi for all computation
units i ∈ [1, . . . ,n + m] in the execution protocol. If an
adversary (cid:31)A can initiate the above protocol and observe
Ψ, we say that the adversary has access to Ψ.
Now, let us consider the execution of the program on
the same input I = (cid:31)x1,x2, . . . ,x n(cid:30) under a MapReduce
provisioning protocol by an adversary A . A semi-honest
adversary A can obtain information on the value of the
input, output and processing time of every trusted in-
stance, including information on trusted instances other
than the map and reduce computation units. If the adver-
sary is malicious, it can further tamper with the inputs
and invocations of the instances. In the protocol, the ad-

versary controls 6 parameters:

(C1)
(C2)
(C3)
(C4)
(C5)
(C6)

the start time of each computation instance,
the end time of each instance,
the encrypted tuples passed to its inputs,
the number of computation instances,
order of computation units executed,
the total number of map-reduce phases executed.

Since the adversary A can obtain “more” information
and tamper the execution, a question to ask is, can the
adversary A gain more knowledge compared to an ad-

versary (cid:31)A who only has access to Ψ? Using the standard

notions of indistinguishability2 and adversaries [28], we
deﬁne a secure protocol as follows:

Deﬁnition 1 (Privacy modulo-Ψ ). A provisioning pro-
tocol for a program is modulo-Ψ private if, for any ad-
versary A executing the MapReduce protocol, there is a

adversary (cid:31)A with access only to Ψ, such that the output
of A and (cid:31)A are indistinguishable.

The deﬁnition states that the output of the adversaries
can be directly seen as deduction made on the informa-
tion available. The fact that all adversaries have output
indistinguishable from the one which knows Ψ suggests
that no additional information can be gained by any A
beyond that implied by knowledge of Ψ.
Remarks. First, our deﬁnition follows the scenario pro-
posed by Canneti [11], which facilitates universal com-
position. Hence, if a protocol is private module-Ψ for
one map-reduce phase, then an entire sequence of phases
executed is private module-Ψ. Note that our proposed
M2R consists of a sequence of map, shufﬂe, and reduce
phases where each phase starts only after the previous
phase has completed, and the chain of MapReduce jobs
are carried out sequentially. Thus, universal composition
can be applied. Second, we point out that if the developer
restructures the original computation to make the IO-
proﬁle the same for all inputs, then Ψ leaks nothing about
the input. Therefore, the developer can consider using or-
thogonal techniques to mask timing latencies [41], hid-
ing trace paths and IO patterns [34] to achieve ideal pri-
vacy, if the performance considerations permit so.

2.3 Assumptions
In this work, we make speciﬁc assumptions about the
baseline system we build upon. First, we assume that the
underlying hardware sufﬁciently protects each computa-
tion unit from malware and snooping attacks. The range
of threats that are protected against varies based on the
underlying trusted computing hardware. For instance,

2non-negligible advantage in a distinguishing game

450  24th USENIX Security Symposium 

USENIX Association

4

traditional TPMs protect against software-only attacks
but not against physical access to RAM via attacks such
as cold-boot [24]. More recent trusted computing prim-
itives, such as Intel SGX [40], encrypt physical mem-
ory and therefore offer stronger protection against adver-
saries with direct physical access. Therefore, we do not
focus on the speciﬁcs of how to protect each computa-
tion unit, as it is likely to change with varying hardware
platform used in deployment.
In fact, our design can
be implemented in any virtualization-assisted isolation
that protects user-level processes on a malicious guest
OS [12, 52, 57], before Intel SGX becomes available on
the market.

Second, an important assumption we make is that of
information leakage via side-channels (e.g. cache laten-
cies, power) from a computation unit is minimal. Indeed,
it is a valid concern and an area of active research. Both
software and hardware-based solutions are emerging, but
they are orthogonal to our techniques [18, 29].

Finally, to enable arbitrary computation on encrypted
data, decryption keys need to be made made available
to each hardware-isolated computation unit. This pro-
visioning of client’s keys to the cloud requires a set of
trusted administrator interfaces and privileged software.
We assume that such trusted key provisioning exists, as
is shown in recent work [49, 65].

3 Attacks

In this section, we explain why a baseline system that
merely encrypts the output of each computation unit
leaks signiﬁcantly more than a system that achieves pri-
vacy modulo-Ψ. We explain various subtle attack chan-
nels that our solution eliminates, with an example.
Running Example. Let us consider the canonical ex-
ample of the Wordcount job in MapReduce, wherein the
goal is to count the number of occurrences of each word
in a set of input ﬁles. The map operation takes one ﬁle
as input, and for each word w in the ﬁle, outputs the tu-
ple (cid:31)w,1(cid:30). All outputs are encrypted with standard au-
thenticated encryption. Each reduce operation takes as
input all the tuples with the same tuple-key, i.e. the same
word, and aggregates the values. Hence the output of
reduce operations is an encrypted list of tuples (cid:31)w,wc(cid:30),
where wc is the frequency of word w for all input ﬁles.
For simplicity, we assume that the input is a set of ﬁles
F = {F1, . . . ,Fn}, each ﬁle has the same number of words
and is small enough to be processed by a map operation3.
What does Privacy modulo-Ψ Achieve? Here all the
map computation units output same size tuples, and af-
ter grouping, each reduce unit receives tuples grouped

3Files can be processed in ﬁxed size blocks, so this assumption is

without any loss of generality

by words. The size of map outputs and group sizes con-
stitute Ψ, and a private modulo-Ψ execution therefore
leaks some statistical information about the collection of
ﬁles in aggregate, namely the frequency distribution of
words in F. However, it leaks nothing about the con-
tents of words in the individual ﬁles — for instance, the
frequency of words in any given ﬁle, and the common
words between any pair of ﬁles are not leaked. As we
show next, the baseline system permits a lot of inference
attacks as it fails to achieve privacy modulo-Ψ. In fact,
eliminating the remaining leakage in this example may
not be easy, as it may assume apriori knowledge about
the probability distribution of words in F (e.g. using dif-
ferential privacy [48]).
Passive Attacks. Consider a semi-honest adversary that
executes the provisioning protocol, but aims to infer ad-
ditional information. The adversary controls 6 parame-
ters C1-C6 (Section 2.2 ) in the execution protocol. The
number of units (C4) and map-reduce phases executed
(C6) are dependent (and implied) by Ψ in an honest exe-
cution, and do not leak any additional information about
the input. However, parameters C1,C2,C3 and C5 may
directly leak additional information, as explained below.

• Dataﬂow Patterns (Channel C3). Assume that the
encrypted tuples are of the same size, and hence do
not individually leak anything about the underlying
plain text. However, since the adversary constitutes
the data communication channel, it can correlate the
tuples written out by a map unit and read by a spe-
ciﬁc reduce unit.
In the Wordcount example, the
ith map unit processes words in the ﬁle Fi, and then
the intermediate tuples are sorted before being fed
to reduce units. By observing which map outputs
are grouped together to the same reduce unit, the
adversary can learn that the word wi in ﬁle Fi is the
same as a word w j in ﬁle Fj. This is true if they
are received by the same reduce unit as one group.
Thus, data access patterns leak signiﬁcant informa-
tion about overlapping words in ﬁles.

• Order of Execution (Channel C5). A determinis-
tic order of execution of nodes in any step can re-
veal information about the underlying tuples be-
yond what is implied by Ψ. For instance, if the
provisioning protocol always sorts tuple-keys and
assigns them to reduce units in sorted order, then
the adversary learns signiﬁcant information. In the
WordCount example, if the ﬁrst reduce unit always
corresponds to words appearing ﬁrst in the sorted
order, this would leak information about speciﬁc
words processed by the reduce unit. This is not di-
rectly implied by Ψ.

• Time-of-Access (Channel C1,C2) Even if data ac-
cess patterns are eliminated, time-of-access is an-

USENIX Association  

24th USENIX Security Symposium  451

5

452  24th USENIX Security Symposium 

USENIX Association

otherchannelofleakage.Forinstance,anoptimiz-ingschedulermaystarttomovetuplestothere-duceunitsevenbeforethemapstepiscompleted(pipelining)togainefﬁciency.Insuchcases,thead-versarycancorrelatewhichblockswrittenbymapunitsarereadbywhichreduceunits.Ifoutputsofallbuttheithmapunitaredelayed,andthejthre-duceunitcompletes,thentheadversarycandeducethatthereisnodataﬂowfromtheithmapunittojthreduceunit.Ingeneral,ifcomputationunitsinasubsequentstepdonotsynchronizetoobtainout-putsfromallunitsinthepreviousstep,thetimeofstartandcompletionleaksinformation.ActiveAttacks.Whileweallowtheadversarytoabortthecomputationsessionatanytime,weaimtopreventtheadversaryfromusingactiveattackstogainadvantageinbreakingconﬁdentiality.Weremindreadersthatinourbaselinesystem,theadversarycanonlyinvokethepro-gramwithitscompleteinputset,withouttamperingwithanyoriginalinputs.Theoutputtuple-setofeachcompu-tationunitisencryptedwithanauthenticatedencryptionscheme,sotheadversarycannottamperwithindividualtuples.Despitethesepreliminarydefenses,severalchan-nelsforactiveattacksexist:•TupleTampering.Theadversarymayattempttodu-plicateoreliminateanentireoutputtuple-setpro-ducedbyacomputationunit,eventhoughitcannotforgeindividualtuples.Asanattackillustration,supposetheadversarywantstolearnhowmanywordsareuniquetoaninputﬁleFi.Todothis,theadversarycansimplydroptheoutputoftheithmapunit.Ifthenumberoftuplesintheﬁnaloutputre-ducesbyk,thetupleseliminatedcorrespondtokuniquewordsinFi.•MisroutingTuples.Theadversarycanreorderin-termediatetuplesorroutedatablocksintendedforonereduceunittoanother.Theseattackssubvertourconﬁdentialitygoals.Forinstance,theadver-sarycanbypasstheshufﬂeraltogetherandroutetheoutputofithmapunittoareduceunit.TheoutputofthisreduceunitleaksthenumberofuniquewordsinFi.Similarinferenceattackscanbeachievedbyduplicatingoutputsoftuplesinthereduceunitandobservingtheresult.4DesignOurgoalistodesignaMapReduceprovisioningproto-colwhichisprivatemodulo-ΨandaddsasmallamountoftheTCBtotheexistingMapReduceplatform.Weex-plainthedesignchoicesavailableandourobservationsthatleadtoanefﬁcientandcleansecuritydesign.MapTmapperMapTReducergroupingx1x2x3x...xn-1xnMapTMapTMapTMapTReduceTSecure Shufflero1o2o3o...on-1onIn+1In+2In+...In+mOn+1On+2On+...On+mJOBIMixTMixTMixTMixTMixTMixTReduceTReduceTReduceTReduceTReduceTGroupTGroupTGroupTGroupTGroupTGroupTFigure2:ThedataﬂowinM2R.Filledcomponentsaretrusted.Input,intermediateandoutputtuplesareencrypted.Theorig-inalmapandreduceoperationsarereplacedwithmapTandreduceT.NewcomponentsarethemixernodeswhichusemixT,andanothertrustedcomponentcalledgroupT.4.1ArchitectureOverviewThecomputationproceedsinphases,eachconsistingofamapstep,ashufﬂestep,andareducestep.Figure2depictsthe4newtrustedcomponentsourdesignintro-ducesintothedataﬂowpipelineofMapReduce.ThesefournewTCBcomponentsaremapT,reduceT,mixTandgroupT.Twoofthesecorrespondtotheexecutionofmapandreduceunit.Theyensurethatoutputtuplesfromthemapandreduceunitsareencryptedandeachtupleisofthesamesize.Theother2componentsim-plementthecriticalroleofsecureshufﬂing.Weexplainournon-intrusivemechanismforsecureshufﬂinginSec-tion4.2.Further,allintegritycheckstodefeatactiveat-tacksaredesignedtobedistributedrequiringminimalglobalsynchronization.TheshufﬂerintheMapReduceplatformisresponsibleforgroupingtuples,andinvokingreduceunitsondisjointrangesoftuple-keys.Oneachclusternode,thereducerchecksthegroupedorderandtheexpectedrangeoftuplesreceivedusingthetrustedgroupTcomponent.Theoutputsofthereduceunitsarethenfedbackintothenextroundofmap-reducephase.MinimizingTCB.Inourdesign,amajorpartoftheMapReduce’ssoftwarestackdealswithjobschedulingandI/Ooperations,henceitcanbeleftoutsideoftheTCB.Ourdesignmakesnochangetothegroupingandschedulingalgorithms,andtheyareoutsideourTCBasshownintheFigure2.Therefore,thedesignisconcep-tuallysimpleandrequiresnointrusivechangestobeim-plementedoverexistingMapReduceimplementations.Developersneedtomodifytheiroriginalapplicationstopreparethemforexecutioninahardware-protectedpro-6USENIX Association  

24th USENIX Security Symposium  453

cessinourbaselinesystem,asproposedinprevioussys-tems[38,39,49].BeyondthismodiﬁcationmadebythebaselinesystemtotheoriginalMapReduce,M2Rrequiresafewadditionallinesofcodetoinvokethenewprivacy-enhancingTCBcomponents.Thatis,MapReduceappli-cationsneedmodiﬁcationsonlytoinvokecomponentsinourTCB.Next,weexplainhowourarchitectureachievesprivacyandintegrityinaMapReduceexecution,alongwiththedesignofthesefourTCBcomponents.4.2Privacy-PreservingExecutionForanygivenexecution,wewishtoensurethateachcomputationstepinaphaseisprivatemodulo-Ψ.Ifthemapstep,theshufﬂestep,andthereducesteparein-dividuallyprivatemodulo-Ψ,bythepropertyofserialcomposibility,theentirephaseandasequenceofphasescanbeshowntobeprivate.Wediscussthedesignofthesestepsinthissection,assumingahonest-but-curiousadversarylimitedtopassiveattacks.Thecaseofmali-ciousadversariesisdiscussedinSection4.3.4.2.1SecureShufﬂingAsdiscussedintheprevioussection,thekeychallengeisperformingsecureshufﬂing.Considerthenaiveap-proachinwhichwesimplymovetheentireshufﬂerintotheplatformTCBofeachclusternode.Toseewhythisisinsecure,considerthegroupingstepoftheshufﬂer,oftenimplementedasadistributedsortorhash-basedgroup-ingalgorithm.Thegroupingalgorithmcanonlyprocessalimitednumberoftupleslocallyateachmapper,soac-cesstointermediatetuplesmustgotothenetworkduringthegroupingprocess.Here,networkdataaccesspatternsfromtheshufﬂerleakinformation.Forexample,iftheshufﬂerwereimplementedusingastandardmergesortimplementation,themergestepleakstherelativeposi-tionofthepointersinsortedsub-arraysasitfetchespartsofeachsub-arrayfromnetworkincrementally4.OnegenericsolutiontohidedataaccesspatternsistoemployanORAMprotocolwhencommunicatingwiththeuntrustedstoragebackend.Thegroupingstepwillthenaccessdataobliviously,therebyhidingallcorre-lationsbetweengroupedtuples.Thissolutionachievesstrongprivacy,butwithanoverheadofO(logkN)foreachaccesswhenthetotalnumberoftuplesisN[55].AdvancedtechniquescanbeemployedtoreducetheoverheadtoO(logN),i.e.k=1[43].Nevertheless,us-ingasortingalgorithmforgrouping,thetotaloverheadbecomesO(Nlogk+1N),whichtranslatestoafactorof30−100×slowdownwhenprocessinggigabytesofshuf-ﬂeddata.4Thiscanreveal,forinstance,whethertheﬁrstsub-arrayisstrictlylesserthantheﬁrstelementinthesecondsortedsub-array.mappermappermappermixTmixTmixTmixTmixTmixTmixTmixTreducerreducerreducermixermixermixermixerFigure3:Highleveloverviewofthemap-mix-reduceexecutionusinga2-roundmixnetwork.Amoreadvancedsolutionistoperformoblivioussort-ingusingsortingnetworks,forexample,odd-evenorbitonicsortingnetwork[23].Suchanapproachhidesdataaccesspatterns,butadmitsaO(log2N)latency(ad-ditiveonly).However,sortingnetworksareoftende-signedforaﬁxednumberofsmallinputsandhardtoadapttotensofgigabytesofdistributeddata.Wemakeasimpleobservationwhichyieldsanon-intrusivesolution.OurmainobservationisthatinMapReduceandotherdataﬂowframeworks,these-quenceofdataaccesspatternsisﬁxed:itconsistsofcyclesoftuplewritesfollowedbyreads.Thereduceunitsstartreadingandprocessingtheirinputsonlyaf-terthemapunitshaveﬁnished.Inoursolution,were-writeintermediateencryptedtupleswithre-randomizedtuplekeyssuchthatthereisnolinkabilitybetweenthere-randomizedtuplesandtheoriginalencryptedmapoutputtuples.Weobservethatthisstepcanberealizedbyse-curemixnetworks[30].Theprivacyofthecomputa-tionreducesdirectlytotheproblemofsecuremixing.ThetotallatencyaddedbyoursolutionisanadditivetermofO(logN)intheworstcase.SinceMapReduceshufﬂestepisbasedonsortingwhichalreadyadmitsO(NlogN)overhead,ourdesignretainstheasymptoticruntimecomplexityoftheoriginalframework.Ourdesignachievesprivacyusingacascadedmixnet-work(orcascaded-mix)tosecurelyshufﬂetuples[30].Theprocedureconsistsofacascadingofκintermedi-atesteps,asshowninFigure3.Ithasκidenticalsteps(calledmixingsteps)eachemployinganumberoftrustedcomputationunitscalledmixTunits,theexecutionofwhichcanbedistributedovermultiplenodescalledmix-ers.EachmixTtakesaﬁxedamountofTtuplesthatitcanprocessinmemory,andpassesexactlythesamenumberofencryptedtuplestoallmixTunitsinthesub-7sequent step. Therefore, in each step of the cascade, the
mixer utilizes N/T mixT units for mixing N tuples. At
κ = log N
T , the network ensures the strongest possible un-
linkability, that is, the output distribution is statistically
indistinguishable from a random distribution [30].

Each mixT unit decrypts the tuples it receives from
the previous step, randomly permutes them using a
linear-time algorithm and re-encrypts the permuted tu-
ples with fresh randomly chosen symmetric key. These
keys are known only to mixT units, and can be derived
using a secure key-derivation function from a common
secret. The processing time of mixT are padded to a
constant. Note that the re-encryption time has low vari-
ance over different inputs, therefore such padding incurs
low overhead.

Let Ω represents the number of input and output tu-
ples of cascaded-mix with κ steps. Intuitively, when κ is
sufﬁciently large, an semi-honest adversary who has ob-
served the execution does not gain more knowledge than
Ω. The following lemma states that indeed this is the
case. We present the proof in Appendix A.

Lemma 1. Cascaded-mix is private module-Ω under
semi-honest adversary, given that the underlying encryp-
tion scheme is semantically secure.

4.2.2 Secure Grouping

After the mixing step, the shufﬂer can group the random-
ized tuple keys using its original (unmodiﬁed) grouping
algorithm, which is not in the TCB. The output of the
cascaded-mix is thus fed into the existing grouping al-
gorithm of MapReduce, which combines all tuples with
the same tuple-key and forward them to reducers. Read-
ers will notice that if the outputs of the last step of the
cascaded-mix are probabilistically encrypted, this group-
ing step would need to be done in a trusted component.
In our design, we add a last (κ +1)-th step in the cascade
to accommodate the requirement for subsequent group-
ing. The last step in the cascade uses a deterministic
symmetric encryption Fs, with a secret key s, to encrypt
the key-component of the ﬁnal output tuples. Speciﬁ-
cally, the (cid:31)a,b(cid:30) is encrypted to a ciphertext of the form
(cid:31)Fs(a),E(a,b)(cid:30), where E(·) is a probabilistic encryption
scheme. This ensures that the two shufﬂed tuples with
the same tuple-keys have the same ciphertext for the key-
component of the tuple, and hence the subsequent group-
ing algorithm can group them without decrypting the tu-
ples. The secret key s is randomized in each invocation of
the cascaded-mix, thereby randomizing the ciphertexts
across two map-reduce phases or jobs.

What the adversary gains by observing the last step
of mixing is the tuples groups which are permuted using
Fs(·). Thus, if Fs(·) is a pseudorandom function family,
the adversary can only learn about the size of each group,

which is already implied by Ψ. Putting it all together
with the Lemma 1, we have:

Theorem 1. The protocol M2R is modulo-Ψ private (un-
der semi-honest adversary), assuming that the underly-
ing private-key encryption is semantically secure, and
Fs(·) is a pseudorandom function family.

4.3 Execution Integrity
So far, we have considered the privacy of the protocol
against honest-but-curious adversaries. However, a mali-
cious adversary can deviate arbitrarily from the protocol
by mounting active attacks using the 6 parameters un-
der its control. In this section, we explain the techniques
necessary to prevent active attacks.

The program execution in M2R can be viewed as a
directed acyclic graph (DAG), where vertices denote
trusted computation units and edges denote the ﬂow of
encrypted data blocks. M2R has 4 kinds of trusted com-
putation units or vertices in the DAG: mapT, mixT,
groupT, and reduceT. At a high-level, our integrity-
checking mechanism works by ensuring that nodes at the
jth level (by topologically sorted order) check the con-
sistency of the execution at level j−1. If they detect that
the adversary deviates or tampers with the execution or
outputs from level j− 1, then they abort the execution.
The MapReduce provisioning system is responsible
for invoking trusted computation units, and is free to de-
cide the total number of units spawned at each level j.
We do not restrict the MapReduce scheduling algorithm
to decide which tuples are processed by which reduce
unit, and their allocation to nodes in the cluster. How-
ever, we ensure that all tuples output at level i−1 are pro-
cessed at level i, and there is no duplicate. Note that this
requirement ensures that a computation in step i starts
only after outputs of previous step are passed to it, im-
plicitly synchronizes the start of the computation units at
step i. Under this constraint, it can be shown that chan-
nels C1-C2 (start-end time of each computation node)
can only allow the adversary to delay an entire step, or
distinguish the outputs of units within one step, which is
already implied by Ψ. We omit a detailed proof in this
paper. Using these facts, we can show that the malicious
adversary has no additional advantage compared to an
honest-but-curious adversary, stated formally below.

Theorem 2. The protocol M2R is private modulo-Ψ un-
der malicious adversary, assuming that the underlying
authenticated-encryption is semantically secure (conﬁ-
dentiality) and secure under chosen message attack (in-
tegrity), and Fs(·) is a pseudorandom function family.
Proof Sketch: Given a malicious adversary A that ex-
ecutes the M2R protocol, we can construct an adversary

454  24th USENIX Security Symposium 

USENIX Association

8

(cid:31)A that simulates A , but only has access to Ψ in the
following way. To simulate A , the adversary (cid:31)A needs

to ﬁll in information not present in Ψ. For the output
of a trusted unit, the simulation simply ﬁlls in random
tuples, where the number of tuples is derived from
Ψ. The timing information can likewise be ﬁlled-in.
Whenever A deviates from the protocol and feeds a
different
the simulation
expects the instance will halt and ﬁlls in the information
accordingly. Note that the input to A and the input

to a trusted instance,

input

DAG of program execution, although the encrypted
tuples are different. Suppose there is a distinguisher

constructed for the simulator (cid:31)A could have the same
that distinguishes A and (cid:31)A , let us consider the two
cases: either the two DAG’s are the same or different.
If there is a non-negligible probability that they are the
same, then we can construct a distinguisher to contradict
the security of the encryption, or Fs(·).
If there is a
non-negligible probability that they are different, we can
forge a valid authentication tag. Hence, the outputs of
A and (cid:31)A are indistinguishable.

Integrity Checks. Nearly all our integrity checks can
be distributed across the cluster, with checking of invari-
ants done locally at each trusted computation. There-
fore, our integrity checking mechanism can largely bun-
dle the integrity metadata with the original data. No
global synchronization is necessary, except for the case
of the groupT units as they consume data output by an
untrusted grouping step. The groupT checks ensure
that the ordering of the grouped tuples received by the
designated reduceT is preserved. In addition, groupT
units synchronize to ensure that each reducer processes
a distinct range of tuple-keys, and that all the tuple-keys
are processed by at least one of the reduce units.

4.3.1 Mechanisms

In the DAG corresponding to a program execution, the
MapReduce provisioning system assigns unique instance
ids. Let the vertex i at the level j has the designated
id (i, j), and the total number of units at level j be |Vj|.
When a computation instance is spawned, its designed
instance id (i, j) and the total number of units |Vj| are
passed as auxiliary input parameters by the provision-
ing system. Each vertex with id (i, j) is an operation
of type mapT, groupT, mixT or reduceT, denoted
by the function OpType(i, j). The basic mechanism
for integrity-checking consists of each vertex emitting a
tagged-block as output which can be checked by trusted
components in the next stage. Speciﬁcally, the tagged
block is 6-tuple B = (cid:29)O, LvlCnt, SrcID, DstID, DstLvl,

9

DstType (cid:28), where:
O
LvlCnt
SrcID
DstID
DstLvl
DstType

is the encrypted output tuple-set,
is the number of units at source level,
is the instance id of the source vertex,
is instance id of destination vertex or NULL
is the level of the destination vertex,
is the destination operation type.

In our design, each vertex with id (i, j) fetches the
tagged-blocks from all vertices at the previous level, de-
noted by the multiset B, and performs the following con-
sistency checks on B:
1. The LvlCnt for all b ∈ B are the same (say (cid:29)(B)).
2. The SrcID for all b ∈ B are distinct.
3. For set S = {SrcID(b) |b ∈ B}, |S| = (cid:29)(B).
4. For all b ∈ B, DstLvl(b) = j.
5. For all b ∈ B, DstID(b) = (i, j) or NULL.
6. For all b ∈ B, DstType(b) = OpType(i, j).
Conditions 1,2 and 3 ensure that tagged-blocks from
all units in the previous level are read and that they are
distinct. Thus, the adversary has not dropped or dupli-
cated any output tuple. Condition 4 ensures that the
computation nodes are ordered sequentially, that is, the
adversary cannot misroute data bypassing certain levels.
Condition 6 further checks that execution progresses in
the expected order — for instance, the map step is fol-
lowed by a mix, subsequently followed by a group step,
and so on. We explain how each vertex decides the
right or expected order independently later in this sec-
tion. Condition 5 states that if the source vertex wishes
to ﬁx the recipient id of a tagged-block, it can veriﬁably
enforce it by setting it to non-NULL value.

Each tagged-block is encrypted with standard authen-
ticated encryption, protecting the integrity of all meta-
data in it. We explain next how each trusted computation
vertex encodes the tagged-block.
Map-to-Mix DataFlow. Each mixT reads the output
metadata of all mapT. Thus, each mixT knows the to-
tal number of tuples N generated in the entire map step,
by summing up the counts of encrypted tuples received.
From this, each mixT independently determines the to-
tal number of mixers in the system as N/T . Note that
T is the pre-conﬁgured number of tuples that each mixT
can process securely without invoking disk accesses, typ-
ically a 100M of tuples. Therefore, this step is com-
pletely decentralized and requires no co-ordination be-
tween mixT units. A mapT unit invoked with id (i, j)
simply emit tagged-blocks, with the following structure:
(cid:29)·,|Vj|, (i, j), NULL, j + 1, mixT(cid:28).
Mix-to-Mix DataFlow. Each mixT re-encrypts and per-
mutes a ﬁxed number (T ) of tuples. In a κ-step cascaded
mix network, at any step s (s < κ − 1) the mixT out-
puts T /m tuples to each one of the m mixT units in the

USENIX Association  

24th USENIX Security Symposium  455

step s + 1. To ensure this, each mixT adds metadata to
its tagged-block output so that it reaches only the speci-
ﬁed mixT unit for the next stage. To do so, we use the
DstType ﬁeld, which is set to type mixTs+1 by the mixer
at step s. Thus, each mixT node knows the total num-
ber of tuples being shufﬂed N (encoded in OpType), its
step number in the cascaded mix, and the public value T .
From this each mixT can determine the correct number
of cascade steps to perform, and can abort the execution
if the adversary tries to avoid any step of the mixing.
Mix-to-Group DataFlow.
In our design, the last mix
step (i, j) writes the original tuple as (cid:31)Fs(k), (k,v,tctr)(cid:30),
where the second part of this tuple is protected with
authenticated-encryption. The value tctr is called a
tuple-counter, which makes each tuple globally distinct
in the job. Speciﬁcally, it encodes the value (i, j,ctr)
where ctr is a counter unique to the instance (i, j). The
assumption here is that all such output tuples will be
grouped by the ﬁrst component, and each group will be
forwarded to reducers with no duplicates. To ensure that
the outputs received are correctly ordered and untam-
pered, the last mixT nodes send a special tagged-block
to groupT nodes. This tagged-block contains the count
of tuples corresponding to Fs(k) generated by mixT unit
with id (i, j). With this information each groupT node
can locally check that:

• For each received group corresponding to g = Fs(k),
the count of distinct tuples (k,·,i, j,ctr) it receives
tallies with that speciﬁed in the tagged-block re-
ceived from mixT node (i, j), for all blocks in B.

Finally, groupT units need to synchronize to check if
there is any overlap between tuple-key ranges. This
requires an additional exchange of tokens between
groupT units containing the range of group keys and
tuple-counters that each unit processes.
Group-to-Reduce Dataﬂow. There is a one-to-one
mapping between groupT units and reduceT units,
where the former checks the correctness of the tuple
group before forwarding to the designated reduceT.
This communication is analogous to that between mixT
units, so we omit a detailed description for brevity.

5

Implementation

Baseline Setup. The design of M2R can be imple-
mented differently depending on the underlying archi-
tectural primitives available. For instance, we could im-
plement our solution using Intel SGX, using the mech-
anisms of VC3 to achieve our baseline. However, Intel
SGX is not yet available in shipping CPUs, therefore
we use a trusted-hypervisor approach to implement the

baseline system, which minimizes the performance over-
heads from the baseline system. We use Intel TXT to
securely boot a trusted Xen-4.4.3 hypervisor kernel, en-
suring its static boot integrity5. The inputs ands output of
map and reduce units are encrypted with AES-GCM us-
ing 256-bit keys. The original Hadoop jobs are executed
as user-level processes in ring-3, attested at launch by the
hypervisor, making an assumption that they are protected
during subsequent execution. The MapReduce jobs are
modiﬁed to call into our TCB components implemented
as x86 code, which can be compiled with SFI constraints
for additional safety. The hypervisor loads, veriﬁes and
executes the TCB components within its address space
in ring-0. The rest of Hadoop stack runs in ring 3 and
invokes the units by making hypercalls. Note that the
TCB components can be isolated as user-level processes
in the future, but this is only meaningful if the processes
are protected by stronger solutions such as Intel SGX or
other systems [12, 14, 52].
M2R TCB. Our main contributions are beyond the base-
line system. We add four new components to the TCB
of the baseline system. We have modiﬁed a stan-
dard Hadoop implementation to invoke the mixT and
groupT units before and after the grouping step. These
two components add a total 90 LoC to the platform TCB.
No changes are necessary to the original grouping algo-
rithm. Each mapT and reduceT implement the trusted
map and reduce operation — same as in the baseline sys-
tem. They are compiled together with a static utility code
which is responsible for (a) padding each tuple to a ﬁxed
size, (b) encrypting tuples with authenticated encryption,
(c) adding and verifying the metadata for tagged-blocks,
and (d) recording the instance id for each unit. Most of
these changes are fairly straightforward to implement. To
execute an application, the client encrypts and uploads
all the data to M2R nodes. The user then submits M2R
applications and ﬁnally decrypts the results.

6 Evaluation
This section describes M2R performance in a small clus-
ter under real workloads. We ported 7 data intensive jobs
from the standard benchmark to M2R, making less than
25% changes in number of lines of code (LoC) to the
original Hadoop jobs. The applications add fewer than
500 LoC into the TCB, or less than 0.16% of the entire
Hadoop software stack. M2R adds 17− 130% overhead
in running time to the baseline system. We also compare
M2R with another system offering the same level of pri-
vacy, in which encrypted tuples are sent back to a trusted
client. We show that M2R is up to 44.6× faster compared
5Other hypervisor solutions such as TrustVisor [39], Over-

shadow [14], Nova [56], SecVisor [50] could equivalently be used

456  24th USENIX Security Symposium 

USENIX Association

10

Job
Wordcount
Index
Grep
Aggregate
Join
Pagerank
KMeans

changed

LoC
Hadoop job)
10 (15%)
28 (24%)
13 (13%)
16 (18%)
30 (22%)
42 (20%)
113 (7%)

(vs.

TCB increase (vs. Hadoop
codebase)
370 (0.14%)
370 (0.14%)
355 (0.13%)
395 (0.15%)
478 (0.16%)
429 (0.15%)
400 (0.12%)

Input size (vs. plaintext size)
2.1G (1.06×)
2.5G (1.15×)
2.1G (1.06×)
2G (1.19×)
2G (1.19×)
2.5G (4×)
1G (1.09×)

Shufﬂed bytes
4.2G
8G
75M
289M
450M
2.6G
11K

# App hyper-
calls
3277173
3277173
3277174
18121377
11010647
1750000
12000064

# Platform hy-
percall
35
59
10
12
14
21
8

Table 1: Summary of the porting effort and TCB increase for various M2R applications, and the application runtime cost factors. Number of app
hypercalls consists of both mapT and reduceT invocations. Number of platform hypercalls include groupT and mixT invocations.

Job
Wordcount
Index
Grep
Aggregate
Join
Pagerank
KMeans

Baseline (vs. no en-
cryption)
570 (221)
666 (423)
70 (48)
125 (80)
422 (211)
521 (334)
123 (71)

M2R (% increase vs.
baseline)
1156
1549
106
205
510
755
145

(100%)
(130%)
(50%)
(64%)
(20%)
(44%)
(17%)

Download-and-compute
(× M2R)
1859
2061
1686
9140
5716
1209
6071

(1.6×)
(1.3×)
(15.9×)
(44.6×)
(11.2×)
(1.6×)
(41.9×)

Table 2: Overall running time (s) of M2R applications in compari-
son with other systems: (1) the baseline system protecting computation
only in single nodes, (2) the download-and-compute system which does
not use trusted primitives but instead sends the encrypted tuples back to
trusted servers when homomorphic encrypted computation is not pos-
sible [59].

to this solution.

6.1 Setup & Benchmarks
We select a standard benchmark for evaluating Hadoop
under large workloads called HiBench suite [25]. The
7 benchmark applications, listed in Table 1, cover a
wide range of data-intensive tasks: compute intensive
(KMeans, Grep, Pagerank), shufﬂe intensive (Word-
count, Index), database queries (Join, Aggregate), and
iterative (KMeans, Pagerank). The size of the encrypted
input data is between 1 GB and 2.5 GB in these case stud-
ies. Different applications have different amount of shuf-
ﬂed data, ranging from small sizes (75MB in Grep, 11K
in KMeans) to large sizes (4.2GB in Wordcount, 8GB in
Index).

Our implementation uses the Xen-4.3.3 64-bit hyper-
visor compiled with trusted boot option. The rest of M2R
stack runs on Ubuntu 13.04 64-bit version. We con-
duct our experiments in a cluster of commodity servers
equipped with 1 quad-core Intel CPU 1.8GHz, 1TB hard
drive, 8GB RAM and 1GB Ethernet cards. We vary our
setup to have between 1 to 4 compute nodes (running
mappers and reducers) and between 1 to 4 mixer nodes
for implementing a 2-step cascaded mix network. The
results presented below are from running with 4 com-
pute nodes and 4 mixers each reserving a 100MB buffer
for mixing, averaged over 10 executions.

6.2 Results: Performance

Overheads & Cost Breakdown. We observe a lin-
ear scale-up with the number of nodes in the cluster,

which conﬁrms the scalability of M2R.
In our bench-
marks (Table 2), we observe a total overhead of between
17% − 130% over the baseline system that simply en-
crypts inputs and outputs of map/reduce units, and uti-
lizes none of our privacy-enhancing techniques. It can
also be seen that in all applications except for Grep and
KMeans, running time is proportional to the size of data
transferred during shufﬂing (shufﬂed bytes column in Ta-
ble 1). To understand the cost factors contributing to the
overhead, we measure the time taken by the secure shuf-
ﬂer, by the mapT and reduceT units, and by the rest of
the Hadoop system which comprises the time spent on
I/O, scheduling and other book-keeping tasks. This rel-
ative cost breakdown is detailed in Figure 4. From the
result, we observe that the cost of the secure shufﬂer is
signiﬁcant. Therefore, reducing the overheads of shuf-
ﬂing, by avoiding the generic ORAM solution, is well-
incentivized and is critical to reducing the overall over-
heads. The two main benchmarks which have high over-
heads of over 100%, namely Wordcount and Index, incur
this cost primarily due to the cost of privacy-preserving
shufﬂing a large amount of data. In benchmarks where
the shufﬂed data is small (Grep, KMeans), the use of
mapT/reduceT adds relatively larger overheads than
that from the secure shufﬂer. The second observation is
that the total cost of the both shufﬂer and other trusted
components is comparable to that of Hadoop, which pro-
vides evidence that M2R preserves the asymptotic com-
plexity of Hadoop.

Comparison to Previous Solutions. Apart from the
baseline system, a second point of comparison are pre-
viously proposed systems that send encrypted tuples
to the user for private computation. Systems such as
Monomi [59] and AutoCrypt [58] employ homomorphic
encryption for computing on encrypted data on the single
servers. For operations that cannot be done on the server
using partially homomorphic encryption, such Monomi-
like systems forward the data to a trusted set of servers
(or to the client’s private cloud) for decryption. We re-
fer to this approach as download-and-compute approach.
We estimate the performance of a Monomi-like system
extended to distributed computation tasks, for achiev-
ing privacy equivalent to ours. To compare, we assume
that the system uses Paillier, ElGamal and randomized

USENIX Association  

24th USENIX Security Symposium  457

11

Figure 4: Normalized break-down time for M2R applications. The run-
ning time consists of the time taken by mapT and reduceT, plus the
time by the secure shufﬂer. The rest comes from the Hadoop runtime.

search schemes for homomorphic computation, but not
OPE or deterministic schemes (since that leaks more than
M2R and our baseline system do). We run operations
that would fall outside such the expressiveness of the
allowed homomorphic operations, including shufﬂing,
as a separate network request to the trusted client. We
batch network requests into one per MapReduce step.
We assume that the network round trip latency to the
client is only 1ms — an optimistic approximation since
the average round trip delay in the same data center is
10 − 100ms [4, 61]. We ﬁnd that this download-and-
compute approach is slower compared to ours by a fac-
tor of 1.3× to 44.6× (Table 2), with the median bench-
mark running slower by 11.2×. The overheads are low
for case-studies where most of the computation can be
handled by homomorphic operations, but most of the
benchmarks require conversions between homomorphic
schemes (thereby requiring decryption) [58, 59] or com-
putation on plaintext values.
Platform-Speciﬁc Costs. Readers may wonder if the
evaluation results are signiﬁcantly affected by the choice
of our implementation platform. We ﬁnd that the dom-
inant costs we report here are largely complementary to
the costs incurred by the speciﬁcs of the underlying plat-
form. We conduct a micro-benchmark to evaluate the
cost of context-switches and the total time spent in the
trusted components to explain this aspect. In our plat-
form, the cost of each hypercall (switch to trusted logic)
is small (13µs), and the execution of each trusted com-
ponent is largely proportional to the size of its input data
as shown in Figure 5. The time taken by the trusted
computation grows near linearly with the input data-size,
showing that the constant overheads of context-switches
and other platform’s speciﬁcs do not contribute to the
reported results signiﬁcantly. This implies that simple
optimizations such as batching multiple trusted code in-
vocations would not yield any signiﬁcant improvements,
since the overheads are indeed proportional to the total
size of data and not the number of invocations. The total
number of invocations (via hypercalls) for app-speciﬁc
trusted logic (mapT, reduceT) is proportional to the to-
tal number input tuples, which amounts for less than half

Figure 5: Cost of executing mapT instance of the Wordcount and
Aggregate job, and the cost for executing mixT. Input sizes (number
of ciphertexts per input) varies from 2 to 106.

a second overhead even for millions of input tuples. The
number of invocations to the other components (mixT
and groupT) is much smaller (8−59) and the each invo-
cation operates on large inputs of a few gigabytes; there-
fore the dominant cost is not that of context-switches, but
that of the cost of multi-step shufﬂing operation itself and
the I/O overheads.

6.3 Results: Security & Porting Effort

Porting effort. We ﬁnd that the effort to adapt all bench-
marks to M2R is modest at best. For each benchmark, we
report the number of Java LoC we changed in order to
invoke the trusted components in M2R, measured using
the sloccount tool 6. Table 1 shows that all applica-
tions except for KMeans need to change fewer than 43
LoC. Most changes are from data marshaling before and
after invoking the mapT and reduceT units. KMeans
is more complex as it is a part of the Mahout distribution
and depends on many other utility classes. Despite this,
the change is only 113 LoC, or merely 7% of the original
KMeans implementation.
TCB increase. We deﬁne our TCB increase as the to-
tal size of the four trusted components. This represents
the additional code running on top of a base TCB, which
in our case is Xen. Note that our design can eliminate
the base TCB altogether in the future by using SGX en-
claves, and only retain the main trusted components we
propose in M2R. The TCB increase comprises the per-
application trusted code and platform trusted code. The
former consists of the code for loading and executing
mapT, reduceT units (213 LoC) as well as the code
for implementing their logic. Each map/reduce codebase
itself is small, fewer than 200 LoC, and runs as trusted
components in the baseline system itself. The platform
trusted code includes that of mixT and groupT, which
amounts to 90 LoC altogether. The entire Hadoop soft-
ware stack is over 190K LoC and M2R avoids moving all
of it into the TCB. Table 1 shows that all jobs have TCB
increases of fewer than 500 LoC, merely 0.16% of the
Hadoop codebase.
Security. M2R achieves stronger privacy than previous

6http://www.dwheeler.com/sloccount

458  24th USENIX Security Symposium 

USENIX Association

12

Job
Wordcount
Index
Grep
Aggregate
Join
Pagerank
KMeans

Baseline (additional leakage)

M2R
# unique words + count word-ﬁle relationship
# unique words + count word-ﬁle relationship
nothing
# groups + group size
# groups + group size
node in-degree
nothing

nothing
record-group relationship
record-group relationship
whole input graph
nothing

Table 3: Remaining leakage of M2R applications, compared with that
in the baseline system.

platforms that propose to use encrypted computation for
big-data analysis. Our deﬁnition allows the adversary to
observe an admissible amount of information, captured
by Ψ, in the computation but hides everything else. It is
possible to quantitatively analyze the increased privacy
in information-theoretic terms, by assuming the proba-
bility distribution of input data [37, 53]. However, here
we present a qualitative description in Table 3 highlight-
ing how much privacy is gained by the techniques in-
troduced in M2R over the baseline system. For instance,
consider the two case studies that incur most perfor-
mance overhead (Wordcount, Index). In these examples,
merely encrypting the map/reduce tuples leaks informa-
tion about which ﬁle contains which words. This may
allow adversaries to learn the speciﬁc keywords in each
In M2R, this leakage is reduced to
ﬁle in the dataset.
learning only the total number of unique words in the
complete database and the counts of each, hiding in-
formation about individual ﬁles. Similarly, M2R hides
which records are in which group for database opera-
tions (Aggregate and Join). For Pagerank, the baseline
system leaks the complete input graph edge structure,
giving away which pair of nodes has an edge, whereas
M2R reduces this leakage to only the in-degree of graph
vertices. In the two remaining case studies, M2R provides
no additional beneﬁt over the baseline.

7 Related Work

Privacy-preserving data processing. One of M2R’s goal
is to offer large-scale data processing in a privacy pre-
serving manner on untrusted clouds. Most systems with
this capability are in the database domain, i.e.
sup-
porting SQL queries processing. CryptDB [47] takes a
purely cryptographic approach, showing the practicality
of using partially homomorphic encryption schemes [3,
15, 45, 46, 54]. CryptDB can only work on a small set
of SQL queries and therefore is unable to support ar-
bitrary computation. Monomi [59] supports more com-
plex queries, by adopting the download-and-compute ap-
proach for complex queries. As shown in our evaluation,
such an approach incurs an order of magnitude larger
overheads.

There exist alternatives supporting outsourcing of

query processing to a third party via server-side trusted
hardware, e.g. IBM 4764/5 cryptographic co-processors.
TrustedDB [7] demonstrated that a secure outsourced
database solution can be built and run at a fraction of
the monetary cost of any cryptography-enabled private
data processing. However, the system requires expensive
hardware and a large TCB which includes the entire SQL
server stack. Cipherbase improves upon TrustedDB by
considering encrypting data with partially homomorphic
schemes, and by introducing a trusted entity for query
optimization [6]. M2R differs to these systems in two
fundamental aspects. First, it supports general compu-
tation on any type of data, as opposed to being restricted
to SQL and structured database semantics. Second, and
more importantly, M2R provides conﬁdentiality in a dis-
tributed execution environment which introduces more
threats than in a single-machine environment.

VC3 is a recent system offering privacy-preserving
general-purpose data processing [49].
It considers
MapReduce and utilizes Intel SGX to maintain a small
TCB. This system is complementary to M2R, as it fo-
cuses on techniques for isolated computation, key man-
agement, etc. which we do not consider. The privacy
model in our system is stronger than that of VC3 which
does not consider trafﬁc analysis attacks.

GraphSC offers a similar security guarantee to that
of M2R for specialized graph-processing tasks [42].
It
provides a graph-based programming model similar to
GraphLab’s [36], as opposed to the dataﬂow model ex-
posed by M2R. GraphSC does not employ trusted prim-
itives, but it assumes two non-colluding parties. There
are two main techniques for ensuring data-oblivious and
secure computation in GraphSC: sorting and garbled cir-
cuits. However, these techniques result in large perfor-
mance overheads: a small Pagerank job in GraphSC is
200,000×−500,000× slower than in GraphLab without
security. M2R achieves an overhead of 2×−5× increase
in running time because it leverages trusted primitives for
computation on encrypted data. A direct comparison of
oblivious sorting used therein instead of our secure shuf-
ﬂer is a promising future work.
Techniques for isolated computation. The current im-
plementation of M2R uses a trusted hypervisor based on
Xen for isolated computation. Overshadow [14] and
CloudVisor [63] are techniques with large TCB, whereas
Flicker [38] and TrustVisor [39] reduce the TCB at the
cost of performance. Recently, Minibox [32] enhances a
TrustVisor-like hypervisor with two-way protection pro-
viding security for both the OS and the applications (or
PALs). Advanced hardware-based techniques include In-
tel SGX [40] and Bastion [12] provide a hardware pro-
tected secure mode in which applications can be exe-
cuted at hardware speed. All these techniques are com-
plementary to ours.

USENIX Association  

24th USENIX Security Symposium  459

13

Mix networks. The concept of mix network is ﬁrst de-
scribed in the design of untraceable electronic mail [13].
Since then, a body of research has concentrated on build-
ing, analyzing and attacking anonymous communication
systems [16, 19]. Canetti presents the ﬁrst deﬁnition of
security that is preserved under composition [11], from
which others have shown that the mix network is secure
under Canetti’s framework [10, 60]. Security properties
of cascaded mix networks were studied in [30]. We use
these theoretical results in our design.

8 Conclusion & Future Work

In this paper, we deﬁned a model of privacy-preserving
distributed execution of MapReduce jobs. We analyzed
various attacks channels that break data conﬁdentiality
on a baseline system which employs both encryption
and trusted computing primitives. Our new design re-
alizes the deﬁned level of security, with a signiﬁcant step
towards lower performance overhead while requiring a
small TCB. Our experiments with M2R showed that the
system requires little effort to port legacy MapReduce
applications, and is scalable.

Systems such as M2R show evidence that specialized
designs to hide data access patterns are practical alterna-
tives to generic constructions such as ORAM. The ques-
tion of how much special-purpose constructions beneﬁt
important practical systems, as compared to generic con-
structions, is an area of future work. A somewhat more
immediate future work is to integrate our design to other
distributed dataﬂow systems. Although having the simi-
lar structure of computation, those systems are based on
different sets of computation primitives and different ex-
ecution models, which presents both opportunities and
challenges for reducing the performance overheads of
our design. Another avenue for future work is to real-
ize our model of privacy-preserving distributed computa-
tion in the emerging in-memory big-data platforms [64],
where only very small overheads from security mecha-
nisms can be tolerated.

9 Acknowledgements

The ﬁrst author was funded by the National Research
Foundation, Prime Minister’s Ofﬁce, Singapore, under
its Competitive Research Programme (CRP Award No.
NRF-CRP8-2011-08). A special thanks to Shruti Tople
and Loi Luu for their help in preparing the manuscript.
We thank the anonymous reviewers for their insightful
comments that helped us improve the discussions in this
work.

References

[1] Apache hadoop. http://hadoop.apache.org.
[2] Trusted

computing

group.

www.

trustedcomputinggroup.org.

[3] R. Agrawal, J. Kiernan, R. Srikant, and Y. Xu. Order pre-
serving encryption for numeric data. In SIGMOD, pages
563–574, 2004.

[4] M. Alizadeh, A. Greenberg, D. A. Maltz, J. Padhye, P. Pa-
tel, B. Prabhakar, S. Sengupta, and M. Sridharan. Data
center tcp (dctcp). In SIGCOMM, 2010.

[5] T. Alves and D. Felton. Trustzone: integrated hardware

and software security. AMD white paper, 2004.

[6] A. Arasu, S. Blanas, K. Eguro, M. Joglekar, R. Kaushik,
D. Kossmann, R. Ramamurthy, P. Upadhyaya, and
R. Venkatesan. Secure database-as-a-service with ci-
pherbase. In SIGMOD, pages 1033–1036, 2013.

[7] S. Bajaj and R. Sion. TrustedDB: a trusted hardware
based database with privacy and data conﬁdentiality. In
SIGMOD, pages 205–216, 2011.

[8] A. Baumann, M. Peinado, and G. Hunt. Shielding ap-
plications from an untrusted cloud with haven. In OSDI,
2014.

[9] M. Blanton, A. Steele, and M. Alisagari. Data-oblivious
graph algorithms for secure computation and outsourcing.
In ASIACCS, pages 207–218. ACM, 2013.

[10] J. Camenisch and A. Mityagin. Mix-network with
In Privacy Enhancing Technologies,

stronger security.
2006.

[11] R. Canetti. Universally composable security: A new
In IEEE Sympo-

paradigm for cryptographic protocols.
sium on Foundations of Computer Science, 2001.

[12] D. Champagne and R. B. Lee. Scalable architectural sup-

port for trusted software. In HPCA, 2010.

[13] D. L. Chaum. Untraceable electronic mail, return ad-
dresses, and digital pseudonyms. Communications of the
ACM, 1981.

[14] X. Chen, T. Garﬁnkel, E. Lewis, P. Subrahmanyam,
C. Waldspurger, D. Boneh, J. Dwoskin, and D. Ports.
Overshadow:
a virtualization-based approach to
retroﬁtting protection in commodity operating systems.
In ASPLOS, pages 2–13, 2008.

[15] R. Curtmola, J. A. Garay, S. Kamara, and R. Ostrovsky.
improved deﬁnitions

Searchable symmetric encryption:
and efﬁcient constructions. In ACM CCS(cid:31)06, 2006.

[16] G. Danezis and C. Diaz. A survey of anonymous com-
munication channels. Technical report, Technical Report
MSR-TR-2008-35, Microsoft Research, 2008.

[17] J. Dean and S. Ghemawat. Mapreduce: simpliﬁed data

processing on large clusters. In OSDI, 2014.

[18] J. Demme, R. Martin, A. Waksman, and S. Sethumadha-
van. Side-channel vulnerability factor: a metric for mea-
suring information leakage. In ISCA, 2012.

460  24th USENIX Security Symposium 

USENIX Association

14

[19] R.

Dingledine.

Anonymity

bibliography.

http://freehaven.net/anonbib/.

[20] C. Gentry. Fully homomorphic encryption using ideal lat-
tices. In ACM Symposium on Theory of Computing, May-
June 2009.

[21] C. Gentry and S. Halevi. A working implementation of
fully homomorphic encryption. In EUROCRYPT, 2010.
[22] O. Goldreich and R. Ostrovsky. Software protection and
simulation on oblivious rams. Journal of the ACM, 1996.
Privacy-
preserving access of outsourced data via oblivious ram
simulation. In ICALP, 2011.

[23] M. T. Goodrich and M. Mitzenmacher.

[24] J. A. Halderman, S. D. Schoen, N. Heninger, W. Clark-
son, W. Paul, J. A. Calandrino, A. J. Feldman, J. Appel-
baum, and E. W. Felten. Lest we remember: cold-boot
attacks on encryption keys. Communications of the ACM,
52(5):91–98, 2009.

[25] S. Huang, J. Huang, Y. Liu, L. Yi, and J. Dai. Hibench:
a representative and comprehensive hadoop benchmark
suite. In ICDE workshops, 2010.

[26] M. Isard, M. Budiu, Y. Y. andAndrew Birrell, and D. Fet-
terly. Dryad: Distributed data-parallel programs from se-
quential building blocks. In Eurosys, 2007.

[37] L. Luu, S. Shinde, P. Saxena, and B. Demsky. A model
counter for constraints over unbounded strings. In PLDI,
page 57, 2014.

[38] J. M. McCun, B. Parno, A. Perrig, M. K. Reiter, and
H. Isozaki. Flicker: An execution infrastructure for tcb
minimization. In EuroSys, 2008.

[39] J. McCune, Y. Li, N. Qu, Z. Zhou, A. Datta, V. Gligor,
and A. Perrig. Trustvisor: Efﬁcient tcb reduction and at-
testation. In IEEE Symposium on Security and Privacy,
pages 143–158, 2010.

[40] F. McKeen, I. Alexandrovich, A. Berenzon, C. V. Rozas,
H. Shaﬁ, V. Shanbhogue, and U. R. Savagaonkar. Inno-
vative instructions and software model for isolated execu-
tion. In HASP, 2013.

[41] D. Molnar, M. Piotrowski, D. Schultz, and D. Wagner.
The program counter security model: Automatic detec-
tion and removal of control-ﬂow side channel attacks. In
Information Security and Cryptology-ICISC 2005, pages
156–168. Springer, 2006.

[42] K. Nayak, X. S. Wang, S. Ioannidis, U. Weinsberg,
N. Taft, and E. Shi. GraphSC: parallel secure compu-
tation made easy.
In IEEE Symposium on Security and
Privacy, 2015.

[27] D. Jiang, G. Chen, B. C. Ooi, K.-L. Tan, and S. Wu. epic:
an extensible and scalable system for processing big data.
In VLDB, 2014.

[43] O. Ohrimenko. Data-oblivious algorithms for privacy-
preserving access to cloud storage. PhD thesis, Brown
University, 2014.

[28] J. Katz and Y. Lindell. Introduction to modern cryptogra-

phy. CRC Press, 2014.

[29] T. Kim, M. Peinado, and G. Mainar-Ruiz. Stealthmem:
system-level protection against cache-based side channel
attacks in the cloud. In USENIX Security, 2012.

[30] M. Klonowski and M. Kutyłowski. Provable anonymity
for networks of mixes. In Information Hiding, pages 26–
38. Springer, 2005.

[31] F. Li, B. C. Ooi, M. T. Ozsu, and S. Wu. Distributed data
management using mapreduce. ACM Computing Survey,
46(6), 2014.

[32] Y. Li, J. McCune, J. Newsome, A. Perrig, B. Baker, and
W. Drewry. Minbox: a two-way sandbox for x86 native
code. In USENIX ATC, 2014.

[33] C. Liu, M. Hicks, A. Harris, M. Tiwari, M. Maas, and
E. Shi. Ghostrider: A hardware-software system for
memory trace oblivious computation, 2015.

[34] C. Liu, M. Hicks, and E. Shi. Memory trace oblivious
In IEEE CSF, pages 51–65. IEEE,

program execution.
2013.

[35] C. Liu, Y. Huang, E. Shi, J. Katz, and M. Hicks. Automat-
ing efﬁcient ram-model secure computation. In Security
and Privacy (SP), 2014 IEEE Symposium on, pages 623–
638. IEEE, 2014.

[36] Y. Low, J. Gonzalez, A. Kyrola, D. Bickson, C. Guestrin,
and J. M. Hellerstein. Distributed graphlab: A framework
for machine learning and data mining in the cloud.
In
VLDB, 2012.

[44] L. Page, S. Brin, R. Motwani, and T. Winograd. The
pagerank citation ranking: bringing order to the web.
Technical report, Stanford InfoLab, 1999.

[45] P. Paillier. Public-key cryptosystems based on composite
degree residuosity classes. In EUROCRYPT, May 1999.
[46] R. A. Popa, F. H. Li, and N. Zeldovich. An ideal-security
protocol for order-preserving encoding. In IEEE Sympo-
sium on Security and Privacy, pages 463–477, 2013.

[47] R. A. Popa, C. M. S. Redﬁeld, N. Zeldovich, and H. Bal-
akrishnan. Cryptdb: Protecting conﬁdentiality with en-
crypted query processing. In SOSP, 2011.

[48] I. Roy, S. T. V. Setty, A. Kilzer, V. Shmatikov, and
E. Witchel. Airavat: Security and privacy for mapreduce.
In NSDI, 2010.

[49] F. Schuster, M. Costa, C. Fournet, C. Gkantsidis,
M. Peinado, G. Mainar-Ruiz, and M. Russinovich. Vc3:
Trustworthy data analytics in the cloud. Technical report,
Microsoft Research, 2014.

[50] A. Seshadri, M. Luk, N. Qu, and A. Perrig. Secvisor: a
tiny hypervisor to provide lifetime kernel code integrity
for commodity oses. In SOSP, pages 335–50, 2007.

[51] S. Shinde, Z. L. Chua, V. Narayanan, and P. Saxena. Pre-
venting your faults from telling your secrets: Defenses
against pigeonhole attacks. CoRR, abs/1506.04832, 2015.
[52] S. Shinde, S. Tople, D. Kathayat, and P. Saxena. Podarch:
Protecting legacy applications with a purely hardware tcb.
Technical report, National University of Singapore, 2015.

USENIX Association  

24th USENIX Security Symposium  461

15

[53] V. Shmatikov and M.-H. Wang. Measuring relationship
anonymity in mix networks. In ACM workshop on Pri-
vacy in electronic society, pages 59–62. ACM, 2006.

[54] D. X. Song, D. Wagner, and A. Perrig. Practical tech-
niques for searches on encrypted data. In IEEE Sympo-
sium on Security and Privacy, May 2000.

[55] E. Stefanov, M. van Dijk, E. Shi, C. Fletcher, L. Ren,
X. Yu, and S. Devadas. Path oram: an extremely simple
oblivious ram protocol. In CCS, 2013.

[56] U. Steinberg and B. Kauer. Nova: a microhypervisor-
based secure virtualization architecture. In Eurosys, 2010.
[57] J. Szefer and R. B. Lee. Architectural support for

hypervisor-secure virtualization. In ASPLOS, 2012.

[58] S. Tople, S. Shinde, Z. Chen, and P. Saxena. AU-
TOCRYPT: enabling homomorphic computation on
servers to protect sensitive web content.
In ACM CCS,
pages 1297–1310, 2013.

[59] S. Tu, M. F. Kaashoek, S. Madden, and N. Zeldovich.
In

Processing analytical queries over encrypted data.
VLDB, 2013.

[60] D. Wikstr¨om. A universally composable mix-net. In The-

ory of Cryptography. 2004.

[61] C. Wilson, H. Ballani, T. Karagiannis, and A. Rowtron.
Better never than late: meeting deadlines in datacenter
networks. In SIGCOMM, 2011.

[62] M. Zaharia, M. Chowdhury, T. Das, A. Dave, J. Ma,
M. McCauley, M. J. Franklin, S. Shenker, and I. Stoica.
Resilient distributed dataset: A fault-tolerant abstraction
for in-memory cluster computing. In NSDI, 2012.

[63] F. Zhang, J. Chen, H. Chen, and B. Zang. Cloudvisor:
retroﬁtting protection of virtual machines in multi-tenant
cloud with nested virtualization.
In SOSP, pages 203–
216, 2011.

[64] H. Zhang, G. Chen, B. C. Ooi, K.-L. Tan, and M. Zhang.
In-memory big data management and processing: a sur-
vey. TKDE, 27(7):1920–1948, 2015.

[65] Z. Zhou, J. Han, Y.-H. Lin, A. Perrig, and V. Gligor. Kiss:
”key it simple and secure” corporate key management. In
TRUST, 2013.

Appendix A Security Analysis

Proof (Lemma 1):

Consider the “ideal mixer” that takes as input a se-
quence (cid:31)x1, . . . ,x N(cid:30) where each xi ∈ [1,N], picks a per-
mutation p : [1,N] → [1,N] randomly and then output the
sequence (cid:31)xp(1),xp(2), . . . ,x p(N)(cid:30). Klonowski et al. [30]
investigated the effectiveness of the cascaded network of
mixing, and showed that O(log N
T ) steps are sufﬁce to

bring the distribution of the mixed sequence statistically
close to the output of the ideal mixer, where T is the
number of items an instance can process in memory. Our
proof relies on the above-mentioned result.

Let us assume that κ, the number of steps carried out
by cascaded-mix, is sufﬁciently large such that the distri-
bution of the mixed sequence is statistically close to the
ideal mixer.

Consider an adversary S that executes the cascaded-
mix. Let us construct an adversary A who simulates S
but only has access to Ω. To ﬁll in the tuple values not
present in Ω, the simulation simply ﬁlls in random tuples.
Note that the number of tuples can be derived from Ω.

Now, suppose that on input x1, . . . ,x N, the output of
A and S can be distinguished by D. We want to
show that this contradicts the semantic security of the
underlying encryption scheme, by constructing a distin-

feed the simulation with the intermediate data generated
by mixT. Let yi, j be the i-th intermediate ciphertext in

random with polynomial-time sampling (i.e. the distin-
guisher sends the challenger multiple messages, and re-
ceive more than one sample).

guisher (cid:31)D who can distinguish multiple ciphertexts from
Let z = (cid:31)z1,z2, . . . ,z N(cid:30) be the output of the mixer on
input x1, . . . ,x N. The distinguisher (cid:31)D asks the challenger
for a sequence of ciphertexts of z. Let ci, j’s be the ci-
phertexts returned by the challenger, where ci, j is the i-th
ciphertexts of z j. To emulate S , likewise, (cid:31)D needs to
round j the distinguisher (cid:31)D generated for the emulation.
1. (cid:31)D simulates the cascaded-mix by randomly pick-
ing a permutation for every mixT. Let p j : [1,N] →
[1,N] be the overall permutation for round j. Let
ˆp j be the permutation that moves the i-th ciphertext
in the input, to its location after j rounds. That is,
ˆp j(i) = p j( ˆp j−1(i)), and ˆp0(i) =i.

The yi, j’s are generated as follow:

2. Set yi, j = c ˆp j(i), j for each i, j.

Let v be the output of D’s simulation. Note that if
xi, j’s are random ciphertexts, then the distribution of v is
the same as the output distribution of A . On the other
hand, if xi, j’s are ciphertexts of z, then the input to the
emulation is statistically close to the input of S , and
thus distribution of v is statistically close to the output
distribution of S.

can distinguish the ciphertexts of z from random. (cid:31)

Since D can distinguish output of S from A ’s, (cid:31)D

462  24th USENIX Security Symposium 

USENIX Association

16

