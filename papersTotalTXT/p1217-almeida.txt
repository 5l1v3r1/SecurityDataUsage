Certiﬁed Computer-Aided Cryptography: Efﬁcient Provably

Secure Machine Code from High-Level Implementations

José Bacelar Almeida
HasLab – INESC TEC and

Universidade do Minho

Braga, Portugal
Gilles Barthe

IMDEA Software Institute

Madrid, Spain

ABSTRACT
We present a computer-aided framework for proving con-
crete security bounds for cryptographic machine code imple-
mentations. The front-end of the framework is an interac-
tive veriﬁcation tool that extends the EasyCrypt framework
to reason about relational properties of C-like programs ex-
tended with idealised probabilistic operations in the style
of code-based security proofs. The framework also incor-
porates an extension of the CompCert certiﬁed compiler to
support trusted libraries providing complex arithmetic cal-
culations or instantiating idealized components such as sam-
pling operations. This certiﬁed compiler allows us to carry
to executable code the security guarantees established at the
high-level, and is also instrumented to detect when compi-
lation may interfere with side-channel countermeasures de-
ployed in source code.

We demonstrate the applicability of the framework by ap-
plying it to the RSA-OAEP encryption scheme, as standard-
ized in PKCS#1 v2.1. The outcome is a rigorous analysis
of the advantage of an adversary to break the security of as-
sembly implementations of the algorithms speciﬁed by the
standard. The example also provides two contributions of
independent interest: it bridges the gap between computer-
assisted security proofs and real-world cryptographic imple-
mentations as described by standards such as PKCS,and
demonstrates the use of the CompCert certiﬁed compiler in
the context of cryptographic software development.

Categories and Subject Descriptors
D.2.4 [Software Engineering]: Software/Program veriﬁ-
cation—formal methods; E.3 [Data]: Data Encryption—
public key cryptosystems, standards, PKCS#1

Keywords
formal proof; PKCS#1; side-channels; certiﬁed compilation
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516652.

Manuel Barbosa

HasLab – INESC TEC and

Universidade do Minho

Braga, Portugal

François Dupressoir
IMDEA Software Institute

Madrid, Spain

1.

INTRODUCTION

The security of computer and communication infrastruc-
tures critically relies on software implementations of cryp-
tographic standards. Practitioners implementing such stan-
dards face signiﬁcant challenges. First, they must resolve
all cases of underspeciﬁcation and address operational con-
siderations that are often ignored by standards. Then, they
must ensure that the generated code is, not only correct and
eﬃcient, but also respects a programming discipline that
minimizes the possibility of side-channel attacks. Such dis-
ciplines, or countermeasures, may be enforced directly over
assembly code, or they may be speciﬁed and validated over
source code in a language such as C [11]; in this latter case
the developer will either trust the compiler to preserve the
countermeasures in generated code, or further validation is
performed. Unfortunately, there is limited tool support to
help practitioners address these issues (see § 6), which makes
the development process error-prone. As a consequence of
subtle errors, software implementations may provide little
or no security [15].

Another problematic technological gap for practitioners
lies between the security claimed by cryptographic standards
and the concrete security bounds derived using provable se-
curity [22]. Indeed, provable security typically relies on an
idealized model of computation and elides security-relevant
aspects of runtime environments (e.g. memory manage-
ment) and implementation details (e.g. error management).
Although this abstraction gap was identiﬁed very early in
the development of provable security, principled approaches
narrowing this gap are only starting to emerge. Prominent
examples include real-world provable cryptography [17, 30],
which analyzes realistic descriptions of cryptographic algo-
rithms. However, realism comes at a signiﬁcant cost: se-
curity analyses in these extended models are vastly more
complex, and therefore more error-prone and more diﬃcult
to check. Moreover, the additional realism achieved by real-
world cryptography does not primarily address the afore-
mentioned issues faced by implementers.

In short, there are two signiﬁcant gaps, with cumulative
eﬀects on the real-world security of cryptographic software
implementations. This paper addresses the challenge of nar-
rowing these gaps.

Technical overview. To achieve this goal, we build on two
recent and independent developments: computer-aided cryp-

1217tography, which provides tool support for provable security,
and veriﬁed compilation, which delivers machine-checkable
evidence of semantic preservation between source and target
programs.

To address the gap between cryptographic proofs and stan-
dards, we extend the EasyCrypt framework [10] to reason
about C-like programs extended with idealised probabilis-
tic operations in an enhanced security model in which the
adversary is given access to execution traces meant to cap-
ture side-channel leakage. The approach is general, but
we focus on the well-known Program Counter Model [28].
The advantage of this approach is twofold. Firstly, one can
make explicit in the security proof various aspects of crypto-
graphic scheme speciﬁcations that address side-channel at-
tacks. For example, we are able to check that a speciﬁ-
cation of a decryption algorithm does not reveal informa-
tion about the secret key by returning a failure value at an
early point in its execution. Secondly, this computational
model serves as a reference for the deployment of counter-
measures against side-channel attacks throughout the com-
pilation process. For example, even though modular ex-
ponentiation is treated as a native operation in our high-
level computational model, we can make it explicit in its
formalization that, in order to ensure security in the Pro-
gram Counter Model, the trace produced by its execution
must be independent of its input values.

To address the second issue, of relating cryptographic
standards and their low-level implementations, we leverage
the annotation mechanism and semantic correctness proof of
the CompCert compiler [25] to prove that security of the C
implementation implies security of the assembly implemen-
tation and, particularly, that countermeasures against side-
channel attacks are correctly deployed in the generated as-
sembly code. In addition, we extend CompCert with the no-
tion of a trusted library providing multi-precision arithmetic
functionality and instantiations of idealised operations. This
allows practitioners to develop and compile their implemen-
tations according to common practices, by providing a clean
interface that speciﬁes the guarantees required from an ex-
ternal library in order to obtain assembly code that is correct
and secure.

The EasyCrypt libraries, formal proofs and the correspond-
ing C code are publicly available. Details can be found in
the full version of this paper.1

Contributions. We introduce a software development frame-
work that allows practitioners to obtain rigorous mathemati-
cal guarantees for low-level (PowerPC, ARM and x86) imple-
mentations of cryptographic software. More precisely, our
framework enables practitioners to:

1. formally verify that a C implementation of a crypto-
graphic algorithm is secure in a security model that
captures both theoretical security and side-channel leak-
age.

2. automatically generate an optimised assembly imple-
mentation that is proven to retain the security prop-
erties of the C implementation, namely by correctly
deploying side-channel countermeasures suitable for a
rigorously deﬁned leakage model.

We illustrate the eﬀectiveness of our framework by proving
security and generating a secure assembly implementation
1Available at http://eprint.iacr.org/2013/316.

of the RSA-OAEP encryption scheme, as standardized in
PKCS#1 v2.1. The main challenges in the security proof
were the following:

• Formalizing and verifying a security proof taking into
account the exact padding scheme adopted in the stan-
dard.
• Carrying out this proof in a computational model that
incorporates Program Counter Model traces, taking
into account the implementations of all the algorithms
speciﬁed in the standard, including encoding and de-
coding routines, as well as the recommended and man-
dated side-channel countermeasures.

The process of generating an assembly implementation of
RSA-OAEP that inherits the security guarantees established
at the C level with EasyCrypt is a fully automatic process us-
ing our extended version of CompCert. We thus believe that
our extensions are of independent interest to cryptographic
software developers deploying side-channel countermeasures
at the C level. Intuitively, they permit validating that as-
sembly code leaks no more information than the source code
via its control ﬂow. This is a non-functional property that
is not known to be oﬀered by CompCert in general (nor,
to the best of our knowledge, by any other C compiler),
and our extension provides this guarantee in the style of
translation validation [25]. For example, we have used this
feature to check the assembly code generated by compil-
ing various components in the NaCl cryptographic library,
which includes relevant side-channel countermeasures at C-
level [11].

2. SYNTAX AND SECURITY OF PKE IM-

PLEMENTATIONS

Although the techniques we discuss in this paper are gen-
erally applicable to implementations of arbitrary crypto-
graphic primitives, we will deal only with public-key encryp-
tion (PKE) schemes.

We will be concentrating on real-world implementations
of this primitive. This means that, throughout the paper,
a PKE scheme will provide descriptions of the encryption
and decryption algorithms as implementations in either C
or assembly code. Our notion of a PKE implementation
does not include the key generation algorithm, which will
be seen as an abstract algorithm that produces key pairs,
and that is modelled as a family of (eﬃciently samplable)
distributions Gλ, indexed by the security parameter. We
adopt this simpliﬁcation for ease of presentation and note
that, from a theoretical point of view, this is without loss of
generality. From a practical point of view, this is also not a
major limitation, as in many applications key generation is
performed in a trusted environment, using implementations
developed independently of the encryption and decryption
algorithms. Nevertheless, we also emphasise that all our
techniques and results can be easily extended to cover the
implementation of the key generation algorithm.

Deﬁnition 1. (PKE syntax) A public-key encryption scheme

implementation Π is a tuple (lang, Enc, Dec, (cid:96)(·)) where:

• lang ∈ {C, asm} indicates the implementation language.
• For each value of λ, EncRand,RO
(m, pk) implements a de-
terministic polynomial-time encryption algorithm. On

λ

1218input a message m and a public key pk, this algorithm
outputs a return code rc and a ciphertext c, possibly
after making a series of calls to external functions (or-
acles) Rand and RO.

• For each value of λ, DecRO

λ (c, sk) implements a deter-
ministic polynomial-time decryption algorithm. On in-
put a ciphertext c and a secret key sk, this algorithm
outputs a return code rc and a message m, possibly af-
ter making series of calls to external function (oracle)
RO.
• (cid:96)pk(·) and (cid:96)sk(·) are polynomials denoting the length of
the octet strings representing public keys and secret
keys, respectively.
• (cid:96)m(·) and (cid:96)c(·) are polynomials denoting the (maxi-
mum) length of the octet strings representing messages
and ciphertexts output by the decryption and encryp-
tion algorithms, respectively.2

Here, Rand((cid:96)) returns a random octet string of length (cid:96),
and RO(i, (cid:96)i, (cid:96)o) gives access to a family of random functions
indexed by ((cid:96)i, (cid:96)o), where each function takes an octet string
i of length (cid:96)i and returns an octet string of length (cid:96)o. The
return codes rc are chosen from a ﬁnite set, and they indicate
the success (T) of the operation or its justiﬁed failure (F(·)).

We treat implementations as families of algorithms in-
dexed by the security parameter, which should be inter-
preted for practical purposes as admitting that the secu-
rity parameter must be known at compile-time. We deviate
slightly from the standard approach of adopting bit-strings
as the representation of inputs and outputs to cryptographic
algorithms, and adopt octet strings instead. This is without
loss of generality. We also restrict our attention to PKEs
for which the (maximum) lengths of the inhabitants of the
message, randomness and ciphertext spaces are ﬁxed in the
description of the scheme (as polynomials in λ) for each
value of the security parameter. This is not without loss of
generality, but is a necessary constraint when dealing with
implementations operating in computational platforms with
limited memory, and a natural one to make when consider-
ing cryptographic standards such as RSA-OAEP.

Correctness. The correctness of a PKE scheme implemen-
tation requires that the decryption operation inverts the en-
cryption procedure. We present this deﬁnition using a code-
based approach, and again emphasise that a scheme Π may
be given as a C implementation or as an assembly imple-
mentation. The notion of correctness is the same in either
case.

Deﬁnition 2. (PKE correctness) Let game CorrΠ,A be as
shown in Figure 1. The correctness of a PKE scheme Π
relative to G requires that, for all adversaries A and for all
λ, we have that

Pr[ CorrΠ,G,A(1λ) ⇒ T ] = 1 .

We note that security games are presented here at a level
of abstraction that omits certain details of the implementa-
tions, e.g., how parameter passing is handled. Such details
are made explicit in the formalization of the model, as de-
scribed in the next section.
2We do not restrict the size of the message and ciphertext
inputs to these algorithms, and require implementations to
check the validity of their lengths.

Game CorrΠ,G,A(1λ):
(pk, sk) ←$ Gλ
m ←$ A(pk, sk)
If |m| > (cid:96)m(λ) Return T
(rc, c) ←$ EncRand,RO
(rc(cid:48), m(cid:48)) ← DecRO
Return rc = T ∧ rc(cid:48) = T ∧ m(cid:48) = m

λ
λ (c, sk)

(m, pk)

Figure 1: Game deﬁning the correctness of a PKE.

Security. For security, we consider the standard notion of
indistinguishability under adaptive chosen-ciphertext attacks
(IND-CCA), adapted to ﬁt in our syntactic conventions and
with an extension to capture side channel leakage.

Deﬁnition 3. (IND-CCA security of PKE implementations)
Let game IND-CCAΠ,G,A be as deﬁned in Figure 2. The
IND-CCA security of a PKE scheme Π relative to G requires
that, for all adversaries A, the following advantage deﬁnition
is negligible:

Advind-cca

Π,G,A(λ) := 2 · Pr [IND-CCAΠ,G,A(λ) ⇒ T] − 1 .

Game IND-CCAΠ,G,A(1λ):
b ←$ {0, 1}
(pk, sk) ←$ Gλ
(m0, m1, st) ←$ ADecrypt,RO
(rc, c∗) ←$ EncRand,RO
b(cid:48) ←$ ADecrypt,RO
Return (|m0| = |m1| ∧ b(cid:48) = b)

(c∗, t, st)

λ

2

1

(pk)

(mb, pk) ; t

oracle Decrypt(c):
(rc, m) ← DecRO
Return (rc, m, t)

λ (c, sk) ; t

Figure 2: Game deﬁning the IND-CCA security of a
PKE scheme. An adversary A is legitimate if A2
does not call Decrypt on c∗.

The ; t notation in Figure 2 denotes information that
is leaked to the adversary by the execution environment,
in addition to the outputs explicitly produced by the PKE
algorithms.3 We recover the standard deﬁnition of security
for PKEs when this leakage is the empty string  for all
algorithms.

Leakage models. We will model leakage as a trace of con-
stant identiﬁers that reveal some information about the con-
trol ﬂow of the executed algorithm. This approach allows us
to capture some leakage models that are relevant for practi-
cal applications, and can be extended to deal with arbitrary
types of leakage by deﬁning diﬀerent types of observable
events in the semantics of the implementation languages,
and controlling if and how this information is revealed to
the adversary.

For concreteness, we will focus on two leakage models for
C and assembly implementations. The leakage model that
we adopt at the C level is chosen for its simplicity, and can
be seen as an adaptation of the Program Counter Model [28]

3Consistently with our discussion above, we consider that
only Enc and Dec are executed in environments that are
observable by the adversary.

1219(PC) to C programs. The leakage model that we adopt at
the assembly level is the standard PC model.
Informally,
these models are deﬁned as follows:

• C leakage. We associate to each branching point in
the C program two observable events with identiﬁers
Event True and Event False. One such event is added
to the (initially empty) trace whenever a branch is
taken, consistently with the Boolean value of the eval-
uated branching condition.
• Assembly leakage. Each instruction in the assembly
program is associated with a unique constant identiﬁer,
which is added to the (initially empty) trace whenever
this instruction is executed.

Referring to Figure 2, we will consider adversaries attack-
ing C implementations and assembly implementations, and
receiving the leakage deﬁned above as extra information.
Later in the paper we will see formalizations of both types
of leakage.

RSA-OAEP as described in PKCS#1. We now illustrate
the level of abstraction at which cryptographic algorithms
are described in standards. This will both justify our ap-
proach of taking C as a high-level language for implement-
ing cryptographic algorithms, and also to facilitate the un-
derstanding of its EasyCrypt formalization in the next sec-
tion. Figure 3 shows the PKCS#1 v2.1 standard’s descrip-
tion of the encoding function that takes a variable-length
message m, pads it to a ﬁxed-length data blob DB , and pro-
duces the ﬁnal encoded message EM . Functions OS2IPPKCS,
I2OSPPKCS and RSAEPPKCS are speciﬁed in the standard;
random and MGF instantiate the Rand, and RO oracles, re-
spectively.

The scheme, as standardized,

is parameterized by two
lengths (which can be seen as the security parameter): k
is the length of the canonical octet string representation of
the RSA modulus; and hLen is the length of the output of
the hash function used to concretely implement the MGF,
and to compute label hashes.
Given these parameters, some derived static lengths can
be introduced: dbLen = k − hLen − 1 is the length of the
padded message, or data blob; and maxMLen = dbLen −
hLen − 1 is the maximum length of message that can be
encrypted.

A C-like language. In this paper we consider only C pro-
grams that follow a strong programming discipline and re-
spect a strict notion of safety. The programming discipline
forbids expressions with side-eﬀects, pointer arithmetic, and
only allows the programmer to refer to arrays using the ad-
dress of their ﬁrst element (and carrying an explicit oﬀset
value where necessary). Our notion of safety excludes the
standard out-of-bound memory accesses and arithmetic er-
ror conditions, but also behaviours that would fall in the
underspeciﬁed parts of the C standard. For simplicity, our
notion of safety also imposes that C implementations termi-
nate for all possible input values.

We allow static allocation of new arrays, and follow stan-
dard practice to pass output parameters by reference to let C
functions return multiple values, or arrays. In addition, we
consider that the language is equipped with a non-primitive
type for arbitrary precision unsigned integers that are, simi-

fun OAEP EncodePKCS(m : octet[]):

PS = 0x00(k−|m|−2∗hLen−2);
DB = dLHash(cid:107)PS(cid:107)0x01(cid:107)m;
seed = random(hLen);
dbMask = MGF(seed, dbLen);
maskedDB = DB ⊕ dbMask ;
seedMask = MGF(maskedDB , hLen);
maskedSeed = seed ⊕ seedMask ;
EM = 0x00(cid:107)maskedSeed(cid:107)maskedDB ;
return EM ;

fun OAEP EncryptPKCS(m : octet[], pk : pkey):

if (maxMLen < mL)
else {

rc = RC MessageTooLong;

rc = OAEP EncodePKCS(m);
p = OS2IPPKCS(EM );
(rc, c) = RSAEPPKCS(pk , p);
(rc, res) = I2OSPPKCS(c, k );
rc = RC Success; }

return (rc, res);

Figure 3: Speciﬁcation for PKCS#1 encryption

larly to arrays, passed by reference. We equip this type with
the usual operations, including modular arithmetic.

We use the const type modiﬁer to prevent functions from
overwriting parameters passed by reference (arrays, big in-
tegers and pointers to primitive types) that are used purely
for input. Purely for simplicity, we forbid the use of short-
circuiting boolean operators, which introduce potentially un-
wanted conditional jumps, and prefer the corresponding bit-
wise operators.

In addition, as discussed above, we impose that the pro-
grammer correctly annotates the program with trace ex-
tension statements Leak(Event True) and Leak(Event False).
Correct annotation means that the next statement in each
execution path after a conditional branch is an annotation
exposing the corresponding value of the branching condition
(see the code in Figure 4). Semantically, these statements
append the corresponding event at the end of a global trace
that is initially empty and can only be manipulated using
the annotation mechanism.

3. SECURE C-LIKE CODE IN EasyCrypt

We formalize security proofs using EasyCrypt [9], an SMT-
based interactive prover geared towards formally proving se-
curity properties of cryptographic schemes. Cryptographic
algorithms, oracles and games are described in a probabilis-
tic imperative language pWhile. Reduction proofs can then
be performed by establishing probabilistic relational proper-
ties on pairs of pWhile functions and, from them, deducing
concrete probability bounds.

Importantly, pWhile’s grammar of expressions can be ex-
tended with user-deﬁned types and functional (pure and to-
tal) operators. The language is equipped with some built-in
types, including booleans, integers, tuples and ﬁxed-length
bitstrings. However, the latter type is insuﬃcient to write,
for example, algorithms whose input are bitstrings whose
length is chosen by the adversary. As we deﬁne grammar
extensions to model variable-length octet strings (in fact,
polymorphic arrays) below, we write them in a style that

1220narrows the gap between pWhile and the subset of trace-
annotated C with big integers described above.

A C mode for EasyCrypt. We extend EasyCrypt with several
libraries to lower the level of abstraction of speciﬁcations to
one similar to our C-like language. The ﬁrst of these libraries
implements variable-sized arrays. It provides a polymorphic
type α[] and select (· [·]) and update (· [·] = ·) operators, de-
ﬁned only when used within the array’s bounds. We let the
user declare statically-sized array variables (var · : ·[·];). For
speciﬁcation purposes, we also deﬁne a length operator (|·|)
and write valid(a, o, l ) whenever o and l are non-negative
integers and a is an array such that o + l ≤ |a|.
(This
guarantees that any access to a with an index i such that
o ≤ i < o + l is within the array bounds, and allows us to
express memory-safety conditions.)

We also introduce a type bigint to distinguish variables
meant to model machine integers from those meant to be im-
plemented as arbitrary precision integers. The bigint type is
equipped with operators for all operations needed, including
comparisons, shifts and modular operations.

Our third library extension deals with parameter-passing:
in order for our adversaries to have at least as much power
over inputs and outputs as standard IND-CCA adversaries in
the context of a C program, we model, in EasyCrypt, param-
eter passing by-reference, where a reference to an array or
variable is passed as argument, and used to return multiple
values by side-eﬀect. When a function takes a parameter of
an array or bigint type, we always assume that it may in fact
overwrite that parameter’s contents, unless otherwise speci-
ﬁed using the const type modiﬁer. (We syntactically ensure
that all such parameters that are not used for output are
marked as const.) Conversely, when a parameter of primi-
tive type is meant to be used as an out-parameter, it should
be marked as such using the out type modiﬁer. Type α out
is equipped with a dereference operator (∗·), and an update
statement (∗· = ·;).

Finally, we deﬁne in EasyCrypt some constants and oper-
ators that capture the abstract C leakage described in Sec-
tion 2. Abstract traces can be the empty trace Zero, the true
and false branch events Event True and Event False, or any
combinations of these using an associative extension opera-
tor · ++ · for which Zero is a left and right neutral element.
In functions, oracles and games, we write Leak(e) to denote
the fact that the observable trace is extended to the right
(using ++) with e.

In addition to these basic events, we also consider abstract
leakage from some of the external functions and big integer
primitives. This allows us to make formal and precise, using
axioms, the usual assumptions on their leakage. We use
the ; t notation introduced in Section 2 to denote that a
particular function call extends the execution trace to the
right with a trace t that may depend on all of the call’s
arguments. (For algorithms, this trace extension is concrete,
whereas it is kept abstract for chosen big integer primitives
and for the external functions.)

Application to PKCS#1 v2.1. We discuss our implemen-
tation of the PKCS standard based on the encryption algo-
rithm. Details of the other algorithms and subroutines can
be found in the full version.

Figure 4 shows our implementation of the encryption al-
gorithm. Auxiliary algorithms, as well as external functions,

are written so that they return their results by passing a ref-
erence to some output parameters, but otherwise provide the
same functionality. The encoding algorithm is optimized to
save space by reusing its internal buﬀers seed and DB once
their contents become obsolete. Apart from the verbosity of
using while loops to implement array operations, this imple-
mentation does not diﬀer much from the encoding function
described in the PKCS#1 standard (see Figure 3).

Between lines (3) and (8), the data blob is built, by copy-
ing the default label hash, writing the zero padding and the
separator, and ﬁnally copying the message m into it. On line
(9), the seed is sampled uniformly at random. On line (10),
the MGF oracle is called and its result (seedMask ) written
directly into the output buﬀer, and used, in the while loop
at (12) to mask the data blob in place. On line (13), the
MGF oracle is queried with the masked data blob and its
result written and used as before to mask the seed. Finally,
on line (16), the ﬁrst byte of the output buﬀer is set to 0.

fun OAEP Encode(res : octet[], m : octet const[], mLen : int):

1: var seed : octet[hLen];
2: var DB : octet[dbLen];
3:
4: while (i < hLen) { Leak(Event True);

i = 0;

DB [i] = dLHash [i] ;
i = i + 1; } Leak(Event False);

5: while (i < dbLen − mLen − 1) { Leak(Event True);

DB [i] = 0x00;
i = i + 1; } Leak(Event False);

6: DB [i] = 0x01;
7:
8: while (i < dbLen) { Leak(Event True);

i = i + 1;

DB [i] = m [i − dbLen + mLen] ;
i = i + 1; } Leak(Event False);

9: sample octets(seed, 0, hLen);
10: MGF1(res, 1 + hLen, dbLen, seed, 0, hLen);
11: i = 0;
12: while (i < dbLen) { Leak(Event True);

res[1 + hLen + i] = res [1 + hLen + i] ⊕ DB [i] ;
i = i + 1; } Leak(Event False);

13: MGF1(res, 1, hLen, res, 1 + hLen, dbLen);
14: i = 0;
15: while (i < hLen) { Leak(Event True);

res[1 + i] = res [1 + i] ⊕ seed [i] ;
i = i + 1; } Leak(Event False);

16: res[0] = 0x00;
17: return RC Success;

fun OAEP Encrypt(res : octet[],

m : octet const[], mLen : int, pk : pkey):

if (maxMLen < mLen) { Leak(Event True);

1: var p, c : bigint;
2: var EM : octet[k ];
3:
4: else { Leak(Event False);

rc = RC MessageTooLong; }

rc = OAEP Encode(EM , m, mLen);
rc = OS2IP(p, EM , k );
rc = RSAEP(c, pk , p);
rc = I2OSP(res, c, k );
rc = RC Success; }

return rc;

Figure 4: Implementation of PKCS#1 encryption

Although it is a rather simple reﬁnement of the speciﬁ-
cation shown in Figure 3, this implementation allows us to
concretely reason about the leakage traces produced when

1221executing the encryption algorithm. From a formal point of
view, the ﬁrst steps in our security and correctness proofs
very much reduce the security of the low-level model to the
security of the high-level scheme (augmented with concrete
side-channel leakage).

However, even the high-level description displayed in Fig-
ure 3 is far removed from the description for which Fujisaki
et al. obtained their well-known security proof [21]. We dis-
play it for comparison in Figure 5. There are three major
diﬀerences between the two speciﬁcations:

• the standard uses only one random oracle, whereas
Fujisaki et al. use two; for the lengths used in the
standard, these are stricly equivalent, since F and G
have disjoint domains.
• to remedy the fact that RSA is not a random per-
mutation over the entire encoded message space, the
standard ensures that it is always called on plaintexts
whose ﬁrst byte is zero; this has an incidence on the
security and the proof.
• ﬁnally, the standard permits the encryption of variable
(but bounded) length messages, using some additional
padding to ﬁxed length; this does not aﬀect theoreti-
cal security, but has led to well-known padding oracle
attacks [27, 33] when implemented carelessly.

Despite these diﬀerences, the security proof is relatively easy
to adapt and follows the same general schema. We perform
it in a reﬁnement of the adversary model presented in Sec-
tion 2, which gives the adversary more control over output
parameters. Oracle wrappers ensure that adversaries respect
memory-safety side conditions when calling the algorithms
and environment functions.

fun OAEP Encryptproof (m : octet[], pk : pkey):

r = random(hLen);
s = (m(cid:107)0x00hLen ) ⊕ G(r );
t = r ⊕ H(s);
return RSA(pk , s(cid:107)t);

Figure 5: Fujisaki et al.’s OAEP encryption

Security theorem. Following Fujisaki et al., we reduce our
PKCS#1 implementation’s leakage-aware IND-CCA security
to a variant of the set partial-domain one-way assumption
(s-PDOW) on RSA. This variant takes into account the fact
that the ﬁrst byte of the random input is set to 0, and also
lets the adversary observe the leakage produced when eval-
uating the one-way permutation and its inverse. More pre-
cisely, Figure 6 shows the assumption in game form, parame-
terized by a one-way permutation f, a leakage function leakf ,
and an adversary B. The leakage function leakf takes a se-
cret key sk, and outputs a secret key sk(cid:96) such that, for any
challenge c, the computations of f−1
(c) produce
the same execution trace. This key is used in the proof to
simulate the trace produced by computing the decryption
algorithm.

sk (c) and f−1

sk(cid:96)

Given a one-way permutation f and a leakage function
leakf for it, we deﬁne, the s-PDOW advantage of an adver-
sary B against f relative to G as
Advs-pdow

f,leakf ,G,B(λ) := 2 · Pr [s-PDOWf,leakf ,G,B(λ) ⇒ T] − 1 .

Game s-PDOWf,leakf ,G,B(1λ)

(pk, sk) ←$ G
s ←$ {0, 1}hLen
t ←$ {0, 1}dbLen
c ← fpk(0x00(cid:107)s(cid:107)t) ; τ
sk(cid:96) ← leakf (sk)
−1
sk (·)(c, τ, sk(cid:96))
T ←$ Bf
return t ∈ T

Figure 6: Leakage-aware s-PDOW assumption

The validity of assuming that this advantage is negligi-
ble depends greatly on the leakage function leakf and the
trace produced when evaluating the permutation f. In par-
ticular, when the leakage function is constant (that is, when
the trace produced when evaluating the inverse permutation
does not depend on the secret key), and evaluating the per-
mutation does not leak information about the plaintext, our
s-PDOW game only diﬀers from the one used by Fujisaki et
al. [21] by the ﬁxed ﬁrst byte of the challenge plaintext. This
only introduces an additional factor 256 in the bound.

We can now state our security theorem for PKCS#1 v2.1

as we implement it.

Theorem 1

(Security of PKCS#1 v2.1). Let Π be
our implementation of the standard. For all key generation
algorithm G, and IND-CCA adversary A making at most qD
queries to the decryption oracle and qG queries to the random
oracle with (cid:96)i = hLen and (cid:96)o = dbLen, we build a s-PDOW
adversary B against RSA such that:

Advind-cca

Π,G,A(λ) ≤ Advs-pdow

RSA,leakRSA,G,B(λ) +

2qDqG + qG − qD

28hLen

The proof is formalized in EasyCrypt, and relies on several
assumptions on the leakage produced by the library and en-
vironment functions. The assumption on modular exponen-
tiation is formalized using the leakRSA function. All other
arithmetic functions are implicitly assumed to produce con-
stant leakage traces. The random oracle and random sam-
pling operations are assumed to produce leakage traces that
depend only on their length parameters.

4. SECURITY-AWARE COMPILATION

Our goal is to take a C implementation such as that de-
scribed in the previous section and compile it to an assem-
bly implementation that retains the security properties that
were established (or are simply assumed to hold) for the
source code. A natural question that arises is then: what
properties must the C compiler guarantee to ensure that the
assembly implementation is secure based on the assumption
that the C implementation is secure?

The classical notion of correctness for any compiler is
known as semantic preservation. Intuitively, this property
guarantees that, for any given source program S, the com-
piler will produce a compiled program T that operates con-
sistently with the semantics of S. Consistency is deﬁned
based on the observable behaviour of a program, which can
be a simple relation on input states and output states, or it
can be a more complex notion including observable events
occurring during program evaluation. A bit more formally,
let us denote the evaluation of a program P over inputs
(cid:126)p, resulting in outputs (cid:126)o and observable behaviour B as

1222P ((cid:126)p) ⇓ ((cid:126)o, B). Then, semantic preservation could be written
as

∀B, (cid:126)p, (cid:126)o, T ((cid:126)p) ⇓ ((cid:126)o, B) =⇒ S((cid:126)p) ⇓ ((cid:126)o, B)

This means essentially that any observable behaviour of the
target program is observable in the source program. Fur-
thermore, if the source language is deterministic (i.e., it has
no intrinsic non-determinism when it interacts with a deter-
ministic environment) then this also gives an implication in
the reverse direction [25].

Here we introduce a notion of security-aware semantic
preservation that reﬁnes the previous high-level notion. We
also prove that, when enforced by a C compiler, this new
notion is suﬃcient to guarantee that, not only the function-
ality of the source program is preserved, but also its security.
We call C compilers that are proven to enforce this type of
semantic preservation security-aware.
In the next section
we will show how we have extended CompCert to enable the
security-aware compilation of C implementations.

Observable behaviour of an implementation. The ob-
servable behaviours that we will consider for security-aware
compilation will include, not only the leakage that is pro-
vided to the adversary, but also all the interactions of the
implementation with the environment via Rand and RO.
Formally, we see behaviours B as sequences of observable
events ν, B ::=  | ν.B , where we consider events of the
following types:

ν ::= const(id)

| Rand(v, (cid:96))

| RO(v, i, (cid:96)i, (cid:96)o) .

Intuitively, const(id) will correspond to a leakage event. In
the case of C implementations, the identiﬁer id will be either
T or F, signalling the evaluation of a branching condition
similarly to what was described in the previous section. In
the case of assembly implementations, the identiﬁer id will
contain the unique identiﬁer (PC address) of the instruction
being executed, according to the program counter model.
Rand events signal a call to an external random sampling
function, including the length and output of the random
octet string that was obtained from the environment. Simi-
larly, RO events reveal the full details of an interaction with
an external function representing the idealised MGF func-
tion.

We will refer to the projection of a behaviour that retains
only the const events as const(B). Similarly, we will refer
to the projection that excludes the const events as coins(B).
We can now present our notion of security-aware semantic
preservation.

Deﬁnition 4. (Security-aware semantic preservation) Take
PKE implementation Π = (C, Enc, Dec, (cid:96)(·)) in C. We say
that assembly implementation π = (asm, Enc(cid:48), Dec(cid:48), (cid:96)(·)) se-
curely preserves the semantics of Π if there exists an eﬃcient
deterministic simulator S such that the following two con-
ditions hold
∀λ, BΠ, Bπ, m, pk, c, rc.

coins(BΠ) = coins(Bπ) ∧ Enc(cid:48)Rand,RO
(m, pk) ⇓ (rc, c, BΠ) ∧

EncRand,RO
const(Bπ) = S(Enc, Enc(cid:48), const(BΠ)) .

λ

(m, pk) ⇓ (rc, c, Bπ) ⇒

λ

∀λ, BΠ, Bπ, c, sk, m, rc.

coins(BΠ) = coins(Bπ) ∧ Dec(cid:48)RO

λ (c, sk) ⇓ (rc, m, Bπ) ⇒

λ (c, sk) ⇓ (rc, m, BΠ) ∧

DecRO
const(Bπ) = S(Dec, Dec(cid:48), const(BΠ)) .

The intuition is the following. Consider behaviours BΠ and
Bπ where the randomness taken by the C implementation
from the environment matches that taken by the assembly
implementation. Then, for all possible parameter inputs,
the assembly implementation must produce an output that
is consistent with that of the C implementation. Further-
more, it must be possible to simulate the PC trace of the
assembly implementation, given only the leakage of the C
implementation.

The next theorem establishes that security-aware seman-
tic preservation implies that PKE correctness is preserved in
compilation. The proof is a direct reduction and is presented
in the full version.

Theorem 2. Let Π = (C, Enc, Dec, (cid:96)(·)) be a correct PKE
implementation. If π = (asm, Enc(cid:48), Dec(cid:48), (cid:96)(·)) is a PKE im-
plementation that securely preserves the semantics of Π, then
π is also correct.

The next theorem shows that security-aware semantic preser-

vation guarantees that security is preserved by compilation,
i.e., that the assembly implementation will be secure against
adversaries that get program counter leakage, assuming that
the C implementation is secure in the leakage model de-
scribed in the previous section.

Theorem 3. Let Π = (C, Enc, Dec, (cid:96)(·)) be an IND-CCA
secure PKE implementation. If π = (asm, Enc(cid:48), Dec(cid:48), (cid:96)(·)) is
a PKE implementation that securely preserves the semantics
of Π, then π is also IND-CCA secure.

The proof is presented in the full version, and it hinges on
the following observation on security-aware semantic preser-
vation. Conceptually, what we are doing in Deﬁnition 4
when we quantify over behaviours BΠ and Bπ is to quantify
over all random coins taken by the implementations, and to
ensure that the same coins are provided to both Π and π.
This can also be seen as quantifying over a set of determin-
istic environments, each of them providing a possible value
of the random coins. Interestingly, in this case, and given
that our source implementation language is a deterministic
subset of C, we get that security-aware semantic preserva-
tion also gives an implication in the reverse direction [25].
In other words, in addition to the implication shown in Def-
inition 4, we also get the following: for each deterministic
environment and for each input (cid:126)p, the source program has
a single observable behaviour which maps to the single ob-
servable behaviour in the compiled assembly code (which is
also deterministic). In a nutshell, this means that one can
directly reduce the security of the assembly implementation
to the security of the C implementation, provided that leak-
age can be simulated.

5. MAKING CompCert SECURITY-AWARE
In this section we show how we extended the CompCert
certiﬁed compiler [25] and used it to perform this type of
security aware compilation.

Background on CompCert. CompCert is a formally veriﬁed
optimizing C compiler [25].
It produces target code with
strong correctness guarantees and reasonable eﬃciency when

1223compared to general purpose compilers. CompCert supports
the C language (with almost complete coverage of the ISO
C 90 / ANSI C standard) and produces assembly code for
the PowerPC, ARM, and IA32 (x86 32-bits) architectures.
CompCert is mostly implemented in Coq, and its develop-
ment is subdivided into 19 compiler phases, each of which
builds a semantic preservation proof between semantically
deﬁned intermediate languages.

Formally, CompCert’s correctness theorem establishes the
strong notion of semantic preservation that was introduced
in the beginning of Section 4, referred in CompCert termi-
nology as a backward simulation. This guarantees that, if a
source program P C is successfully compiled into P asm, then
the observable behaviour of this last program is an admis-
sible behaviour of the original program. The proof of this
result is based on a formalization of the semantics of both
the compiler’s source and target languages (C and assem-
bly), as well as of all the compiler passes. Behaviours are
captured by a possibly inﬁnite sequence of events that model
interactions of the program with the outside world, such as
accesses to volatile variables, calls to system libraries, or
user deﬁned events (so called annotations).

The need for CompCert extensions. There are various as-
pects in which we needed to enhance both the functional-
ity of CompCert and the formal correctness guarantees that
it provides in order to guarantee security-aware semantic
preservation. In the remainder of this section we will begin
by identifying precisely what CompCert does and does not
provide in this direction, and then explain in detail how we
have implemented the necessary extensions.

CompCert’s semantic preservation result establishes guar-
antees very close to Deﬁnition 4: conditioning on similar in-
teractions with the environment, the observable behaviour
for the compiled assembly program matches the observable
behaviour of the source C program. However, the following
caveats need to be addressed before applying the results of
Section 4:

• Expressiveness of CompCert behaviours. The no-
tion of observable behaviour of a C program and an
assembly program in CompCert is conceptually more
general than the one we adopted in the previous sec-
tion.
It considers, for example, the possibility that
programs go wrong or do not terminate. However, it is
more restrictive in the sense that, on one hand it con-
siders only programs with a well-deﬁned entry point
(the main function) and does not include support for
the Rand and RO events that we require (as these imply
exposing or updating the values of memory regions).
• Absence of a leakage model. CompCert behaviours
do not have an associated intrinsic notion of side-channel
leakage (neither at the C nor at the assembly levels).
Although it is possible to emulate such leakage using
annotations directly placed over the source code, there
is no way to guarantee that the target code would have
an observable behaviour that follows the instrumented
semantics conventions of the PC model that we have
described in the previous sections. This means that
there is no straightforward way to capture the simu-
lation of PC traces that we require for security-aware
compilation.

• Complex data types. The common practice in the
implementation of cryptographic software is to split
the development in two parts:
i. a trusted number
theory library that extends the high-level language of
choice with the complex data types required for public-
key cryptography; and ii.
code that implements a
speciﬁc scheme by relying on the functionality of the
trusted library. As described in Section 3, we also
adopt this approach at the EasyCrypt level, by writing
C code that relies on operators that carry out multi-
precision integer calculations. A set of axioms de-
scribes important properties for these operators, sim-
ilarly to what happens to other C native data types
such as octet strings. Conceptually, we see this as an
extension to C that adds support for an additional data
type, which means that the semantics of C as formal-
ized in CompCert need to be extended for our purposes.

In the remainder of this section we will explain how we have
extended CompCert to eliminate the previous caveats.

Adding support for additional external operations. A
diﬃculty that arises when we try to base our results on Com-
pCert’s semantic preservation guarantee is how to handle the
environment that was setup in the EasyCrypt formalization.
This includes primitives for sampling values, the choice of
appropriate hash functions to instantiate the oracles, and
other support functionality. This is an important issue, since
we do not want to impose an a-priori commitment on these
choices — this would, not only weaken (specialize) the guar-
antees oﬀered by the implementation, but also it would not
match what is the common practice in the implementation of
cryptographic software. The semantics formalized in Com-
pCert support calls to system libraries, but these calls are
assumed to leave the memory state unaltered. This makes
them inappropriate to model the environment we require.
Consequently, our ﬁrst extension to CompCert is a mecha-
nism for declaring external functions that may impact the
memory.

Our solution is an extension of the treatment adopted by
CompCert for system-calls. A call to a system library trig-
gers an observable event that registers the name of the called
function, its arguments, and an additional value that repre-
sents the result (provided by the execution environment).
In order to address functions that change the memory state,
we have introduced a new event whose arguments are byte-
arrays containing data read-from/written-to speciﬁed mem-
ory regions. For that, we have implemented a simple mech-
anism to specify the memory footprint of an external func-
tion. We allow the arguments of each function to be either
a primitive C type or a pointer to a memory region that is
either read or written. The size of regions is declared by an
expression that is allowed to refer to other (int) arguments.
As an example, consider the declaration of the sample octets
and random oracle functions that instantiate the Rand and
RO oracles in our PKCS implementation:

#pragma libspec sample_octets: OutPtr #1,Int->Void
extern void sample_octets(unsigned char *,size_t);
#pragma libspec random_oracle: OutPtr #1, Int,

InPtr #3,Int->Void

extern void random_oracle(unsigned char *, size_t,

unsigned char *, size_t);

In the ﬁrst line, the pragma directive informs CompCert that
the ﬁrst argument is a pointer to a memory region written

1224by the function. The size of the region is given by the integer
passed as second argument. This mechanism is implemented
in a general way that allows specifying arbitrary functions
that feed output memory regions to the environment and ﬁll
input memory regions with data collected from the environ-
ment. More precisely, the semantics of a function declared
using this mechanism is deﬁned to:

1. read the memory regions and other input arguments;
2. ask the environment for a byte-array with size equal

to the sum of the output sizes;

3. split the obtained array in the required pieces, and

write them in the corresponding memory regions;

4. produce an event with arguments as described above.

By extending the correctness result of CompCert to cover
these external functions, it follows that the observable be-
haviour of a source program will be preserved in the assem-
bly code, for any instantiation of these functions. However,
in the context of security-aware compilation, one must re-
call that these functions are actually idealised constructions
that are used in the security proofs. It is critical to the se-
curity of the ﬁnal implementation that the instantiation of
these functions complies as much as possible with the as-
sumptions that are made explicit in the EasyCrypt proof. In
other words, these functions must be trustworthy in order
to obtain assembly-level security, and this is why we named
this mechanism TrustedLib.

In the particular case of the RSA-OAEP implementation
the above discussion implies that, in line with standard cryp-
tographic practice, it is up to the end-user to instantiate
sample octets with a function that provides good quality ran-
domness, and to follow the recommentations in the PKCS
standard for the instantiation of the mask generation func-
tion that we model as a random oracle. Furthermore, the as-
sumptions regarding the leakage of these external functions
that are axiomatized in EasyCrypt should also be satisﬁed
by the instantiation.

Correctness of the cryptographic API. There is a mis-
match between what it means for a compiled program to be
correct under the CompCert formalization and our notion of
correctness. In CompCert, the meaning of a C program is
the behaviour of executing a speciﬁc entry-point: the main
function. Our notion of correctness imposes instead the cor-
rectness (in terms of input/output behaviour) of all the func-
tions acting as entry points of the functionality formalized in
EasyCrypt: we call this the correctness of the cryptographic
API. To bridge the gap between these two notions, we have
anchored our correctness result on a C entry-point with the
following shape:

Function main( )
id ← read( )
(cid:126)p ← read( )
o ← id((cid:126)p)
write(o)

This generic entry point reads the identiﬁer of the func-
tion to evaluate (in the case of a PKE implementation this
means either Enc or Dec). It then uses external functions
read and write to obtain input values for the function from
the environment, and to externalise the corresponding out-

puts.4 This pattern registers every possible input/output
behaviour of each function as an admissible behaviour of
the program. Hence, the correctness result of CompCert en-
sures preservation of this behaviour along the compilation
process.

The main function is added to the cryptographic imple-
mentation to ensure that the translation to assembly is ex-
plicitly captured by the correctness theorem of CompCert.
This function can be discarded from the assembly code, since
the implementation is itself intended to be used as a library
by some higher level application.

Adding support for a big-number library. The imple-
mentation of public-key cryptography code often requires
the use of big-number libraries to carry out complex alge-
braic computations such as modular exponentiation. For
example, a typical implementation of RSA-OAEP will dele-
gate the big-number computations to a (often pre-compiled)
library such as GMP.5 From the developers’ point of view,
this can be seen as extending C with a new data type and
native operations that provide support for big integers.

One possible approach to handle such external libraries
would be to use the TrustedLib mechanism to equip our
framework with external functions, which would leave it
to the environment to provide the big-integer operators.6
However, this would not match the setting we have cap-
tured in the EasyCrypt formalization, in which we consider
a well-deﬁned intended semantics for these operations. Fur-
thermore, the correctness and security of the C implemen-
tation depend crucially on the correct implementation of
these functions (otherwise, the axioms assumed in the Easy-
Crypt theory might not be validated). For this reason, we
have opted to include the necessary big-integer operations
as new built-in operations in CompCert, with a fully deﬁned
semantics, which we see as a contract on the library that
we will use for linking with our program. Once again we
must trust the library that instantiates these operations to
correctly implement those contracts, which would ideally be
addressed through formal veriﬁcation. Unfortunately, the
complexity of state-of-art libraries such as GMP make such
an enterprise an enormous eﬀort (although results obtained
on smaller libraries [31] and in speciﬁc algorithms [12] pro-
vide conﬁdence on feasibility in a near future).

Technically, the formalization of the semantics of the big-
number builtin operations is a reﬁnement of that presented
for the TrustedLib functions, in which the transformations
on the state are fully speciﬁed, and where the events sig-
nalling communication with the environment are ommit-
ted. The transformations on the state are described in three
steps: i. reading the big-integer word representations of all
the inputs and converting them into (Coq) integers; ii. per-
forming the operations over the integers; and iii. converting
back into the memory representation and storing the results.
A consequence of our approach is that we needed to com-
mit to a concrete representation of big-integers. We use a
230 radix representation, stored as an array of 32-bit ma-

4In the case of our example, the inputs and outputs are
simply octet strings of various lengths, which means that
the read and write functions can be also implemented using
the external function mechanism described above.
5http://gmplib.org
6In fact, we have used that mechanism to specify all the
GMP low-level integer API.

1225chine integers. This means that we use 30-bits in each ma-
chine word for storage, where the remaining two bits should
always be kept at zero at the function boundaries (func-
tions may internally and temporarily cause these bits to be
non-zero). Our formalization is ﬂexible enough to enable
straightforward adaptation to other representations. The
formalization of the big-number library as built-in opera-
tions in CompCert has the additional advantage of automat-
ically extending the CompCert interpreter to support these
operations, which may be useful for debugging.

Our framework includes an instantiation of the big-number
library that was developed for illustrative purposes, adapted
from the Long Integer Package (LIP) library by A. Lenstra.7
One of our concerns was to ensure that all the big-integer
operations comply with the leakage requirements imposed
by the EasyCrypt proof: the leakage should be constant and
independent of the concrete inputs passed to the functions.
To this end, we have incorporated a standard countermea-
sure against side-channel attacks, and simpliﬁed the library
to consider only unsigned integers and use static memory al-
location. All the routines have been modiﬁed so that there
is no data-dependent branching and memory indexing as ex-
plained, for example, in [11]. This means that all functions
in the library execute in constant time and access the same
memory addresses, regardless of the input data.
Integers
are stored in statically declared arrays of pre-deﬁned size,
which means that the maximum range of the integers that
will be manipulated by the program must be known in ad-
vance, and must be provided at the time of compilation. For
our example, we have aimed at 4096-bit RSA keys, repre-
sented using 137 words. We note that ﬁxing the maximum
length of integers is consistent with our assumption that the
security parameter is known at compile time, and the formal
semantics that we have added in CompCert captures exactly
the behaviour of our library. Although the functionality of
our library is not formally veriﬁed, we have used a Frama-C
plug-in [8] to check that the side-channel countermeasures
are correctly deployed.

Dealing with side-channel leakage. The last extension
to CompCert concerns the need to satisfy the part of Deﬁni-
tion 4 imposing that traces generated by the assembly code
in the PC model can be simulated from the leakage model
we adopted for C programs.

The annotation mechanism of CompCert allows us to ex-
tend standard C code with dummy statements that, when
evaluated, give rise to events that externalize arbitrary con-
stant identiﬁers making them visible in the observable be-
haviour of the program. This means that a direct transla-
tion of the EasyCrypt code into CompCert taking advantage
of these annotations gives rise to a C program whose observ-
able behaviour includes (among the other events that may
be signalled) a trace of all the conditional jumps taken by the
program. Furthermore, CompCert guarantees that the same
exact traces will be observable in the assembly program.

It is obvious that, by inspecting the sequence of events
that reports which conditional jumps were taken, one can
reconstruct the entire control ﬂow of the C program. How-
ever, the same cannot be said for the control ﬂow of the
assembly program: indeed, CompCert is only guaranteed to
preserve the observable behaviour of the C program, and

7http://www.win.tue.nl/~klenstra/

many possible assembly programs can achieve this. In par-
ticular, there may be assembly programs which are insecure
in the PC model (i.e. that leak sensitive information via the
control ﬂow) and still have an observable behaviour that
matches that of the original C program.
In other words,
it may not be possible to fully determine the sequence of
program counter values taken by an assembly implementa-
tion solely from the observable conditional jumps taken by
the C program. However, in order to achieve security-aware
compilation, this is precisely what we require.

Instead of proving that each of the compiler passes does
not introduce spurious branching, we have implemented a
simple static analysis on the generated assembly program
that establishes the desired property. Our analysis is for-
malized in Coq as a translation validation that checks, for
every conditional branch instruction in the assembly code,
that i. all execution paths arising from that instruction go
through an annotation; and ii. that these annotations give
rise to events that externalize (pairwise) distinct constant
identiﬁers. This is suﬃcient to ensure that the observable
behaviour of the program fully reﬂects the choice of the ex-
ecution path, and we have formalized and proved in Coq
the following theorem that establishes the soundness of the
translation validation.

(PC trace simulatability). Let S be an
assembly program that passes the translation validation de-
scribed above. Let also s1 and s2 be memory states s.t.
s1 ≡PC s2; and, let B1 and B2 be behaviours s.t. B1 ∼ann B2,
(cid:104)S; s1(cid:105) ⇓ B1, and (cid:104)S; s2(cid:105) ⇓ B2. Then, for any states s(cid:48)
1, s(cid:48)
and traces t1, t2 we have that
t2−→ s

2 =⇒ s
(cid:48)

1 ∧ s2
(cid:48)

1 ≡PC s
(cid:48)

(cid:48)
2 .

2

Theorem 4

t1−→ s

s1

Here, states s1, s2 are PC-equivalent (s1 ≡PC s2) when
they agree on the value stored in the PC register and have
the same call stack, and behaviours B1, B2 are annotation-
equivalent (B1 ∼ann B2) when they exhibit the same (possi-
bly inﬁnite) sequence of annotation events. The above theo-
rem shows that the sequence of PC values in the evaluation of
an assembly program that passes the translation validation
is fully determined by the sequence of constant identiﬁers
revealed via annotations in the observable behaviour. More
precisely, the theorem expresses this result in the style of
a non-interference result:
if a program is validated by the
test, then any two instances of it that exhibit the same an-
notations on their behaviour, are guaranteed to proceed in
lockstep, i.e., the next PC value can always be determined
from the observable trace.

The above theorem treats the execution of external calls
and other compiler builtins as atomic steps. The sound-
ness of the validation depends on the assumption that these
external functions have precisely the same property (a com-
piler warning collects the identiﬁers of all these functions to
remind the user of this fact). From the perspective of the
end-user, the test is triggered by a new command-line op-
tion -max-annot. When the validation fails, no executable is
produced and an error is emitted pointing to the branch of
the (bad) assembly program that fails the check.

The following corollary relates the theorem above to the

notion of semantic preservation in Deﬁnition 4.

Corollary 5

(Informal). Consider a PKE implemen-
tation that, when it is compiled with CompCert, gives rise to

1226an assembly program that passes the translation validation
check. Then, the compilation performed by CompCert en-
forces Deﬁnition 4.

The proof of this corollary follows directly from the fact
that the correctness theorem for CompCert guarantees that
Deﬁnition 4 is satisﬁed, provided that simulator S can be
constructed. The theorem above guarantees the correctness
of the trivial simulator that looks ahead to the potential
executions of the assembly program, until it ﬁnds the anno-
tation that reveals the correct execution paths.

Using CompCert for security-aware compilation. To sum-
marize the above discussions, we have extended CompCert
with a number of features and adapted the correctness re-
sult of the compiler to accommodate these extensions. This
means that CompCert will preserve the observable behaviours
of source C programs that rely on an arbitrary TrustedLib.
We have also shown that the translation validation step
that we have added to the compiler guarantees that sim-
ulation of PC traces is possible for accepted assembly pro-
grams. Putting these two results together, we conclude that
our version of CompCert provides security-aware compilation
by guaranteeing semantic preservation according to Deﬁni-
tion 4. This means that, by the Theorems proved in Sec-
tion 4, compiling a cryptographic implementation from C
code to assembly, one obtains the following guarantees:

1. Assuming that the C implementation is secure in a
side-channel aware security model such as the one de-
scribed in Section 2;

2. Compiling the C implementation with the generic main
entry point using CompCert and activating the trans-
lation validation stage;

3. Assuming that the TrustedLib functions are instanti-
ated with a secure and correct library that satisﬁes the
requirements speciﬁed in the security proof;

4. Then, if compilation does not fail, the assembly im-
plementation is correct and secure against real-world
adversaries that attack the scheme in the PC model.

i.

Experimental results. We have performed an evaluation
of the performance of the assembly code produced by Com-
pCert when used for security-aware compilation. Our goals
were three-fold:
to evaluate whether or not the trans-
lation validation check might reject the assembly produced
by CompCert (in which case the compiler might not be pre-
serving the side-channel countermeasures); ii. to evaluate
whether the annotation of C source-code with the leakage
tags might damage the performance of the code produced
by CompCert; and iii. to compare the eﬃciency of the se-
cure code produced by CompCert when compared to GCC.
We have conducted our evaluation in a standard PC with
an IA32 architecture. In addition to the PKCS implementa-
tion described here, we have also evaluated the entire NaCl
library core [11].

Our ﬁndings were the following. We have not encountered
any example where the assembly code generated from prop-
erly annotated and secure C code was rejected due to trans-
formations performed by CompCert. On the other hand,
there were several cases where the transformation valida-
tion stage led us to identify points in the C code where

Figure 7: Benchmarking results

there might be potential leakage problems (mostly asso-
ciated with the compilation of composed Boolean expres-
sions). Furthermore, when comparing the performance of
validated assembly code with that produced by CompCert
from non-annotated C code, there were no signiﬁcant devia-
tions in performance. These ﬁndings indicate that CompCert
behaves well in the preservation of the class of side-channel
countermeasures that we considered in this paper, when they
are deployed at the C level.

Regarding the overall performance of generated code, Fig-
ure 7 shows some selected benchmarking results, normalized
with respect to the performance of non-optimized GCC out-
put. For PKCS we show two cases. The values labeled
PKCS correspond to the natural comparison between Com-
pCert and GCC where both the trusted library and the PKCS
code are compiled using either GCC or CompCert. The val-
ues labeled PKCS (nolib) correspond to the case the trusted
library is pre-compiled and linked with the result of compil-
ing the PKCS code with either GCC or CompCert.

Our ﬁndings for the ﬁrst three cases are consistent with
the known reports on CompCert benchmarking when com-
paring CompCert with unoptimized GCC code: the former
outperforms the latter by roughly a factor of 2. When com-
paring with GCC at optimization level 1, we have found that
CompCert is at least 30% slower. These results are slightly
worse than previously reported values [26], which put this
value at roughly 15%. We attribute this discrepancy to the
domain-speciﬁc nature of our code, namely to side-channel
countermeasures and intensive use of arithmetic and bit-wise
operations.

In the PKCS (no lib) case, CompCert performs as well as
GCC at optimization level 1, which shows that most of the
speedups of GCC are being achieved in the optimization of
the trusted library.

6. CONCLUDING REMARKS

We have developed library extensions to EasyCrypt that
enable the development of cryptographic security proofs di-
rectly on a large subset of the C language, in an extended
security model where the adversary is given access to ex-
ecution traces modelling PC security. We have extended
the CompCert certiﬁed compiler with a mechanism for rea-
soning about programs relying on trusted libraries, as well
as a translation validation stage based on CompCert’s anno-
tation mechanism. We have shown that these mechanisms
along with a trusted library providing arithmetic operations
and instantiations of idealised operations are enough to pre-
serve correctness and PC security guarantees from a source
C program down to its compiled assembly executable. We
have also shown the independent value of the new CompCert

1227extensions for compiling third-party C programs whilst pre-
serving their claimed PC security properties.

Related work. Our work lies at the intersection of computer-
aided cryptography and certiﬁed compilation; we refer our
readers to [13] and [25] for recent accounts of these ﬁelds,
and focus this related work section on the veriﬁcation of
cryptographic implementations, and the formal treatment
of side-channels.

Machine-checked correctness proofs of implementations of
crypotographic primitives have been well-studied, using tech-
niques ranging from equivalence checking [32], to verifying
compilation [29], to deductive program veriﬁcation [5] and
interactive theorem proving [1]. However, these techniques
are focused on functional correctness and do not attempt
to formally carry provable security guarantees to the imple-
mentations.

Some proposals have been made towards obtaining com-
putational security guarantees of implementations of cryp-
tographic primitives and protocols. These are based on de-
ductive veriﬁcation [18], code generation [16], model extrac-
tion [4], reﬁnement type systems [20], or static information-
ﬂow analysis [24]. However, these techniques focus on source
program veriﬁcation and do not explicitly address executable
code, nor side-channel attacks.

In addition to being a core area of research in practi-
cal cryptography, side-channel attacks and countermeasures
have been studied extensively in related areas, namely in the
setting of programming languages [2, 3, 23, 34] and of the-
oretical cryptography [19, 6]. These works provide a more
general account of side-channel attacks, either by consider-
ing a more precise computational model, e.g. with caches,
or by providing a more abstract treatment of side-channels.
However, they typically reason in a single setting—source
code, assembly code, or an abstract model of computation.
In contrast, we precisely relate the leakage properties of
primitives to the security of algorithms and their executable
implementations.

Our work is also related to ongoing eﬀorts to formal-
ize programming languages and compilers.
In particular,
the idea of harnessing a general-purpose veriﬁcation tool
with the CompCert compiler appears in the Veriﬁed Software
Toolchain [7], and extensions of CompCert with arithmetic
libraries are considered in [14].

Directions for further work. We intend to leverage the de-
velopments of this paper to build a veriﬁed software toolchain
for cryptographic implementations.

A ﬁrst step towards this goal is to provide automated
support for the C mode of EasyCrypt; we are conﬁdent that
the additional complexity introduced by low-level consider-
ations can be managed automatically to a large extent. Au-
tomation is also instrumental for the feasibility of security
proofs in alternative leakage models. For example, we would
like to investigate stronger leakage models in which the ad-
versary could observe the list or set of memory addresses
accessed during the execution of an algorithm, as well as
weaker leakage models in which the adversary could observe
the number of operations performed during the execution of
an algorithm. Dealing with these alternative models would
also require extending EasyCrypt with further libraries and
to extend the new translation validation stage in CompCert

to guarantee the preservation of countermeasures adequate
for these leakage models.

The security notions we have formalized are at least as
strong as the standard notion of IND-CCA security, and
thus inherit the composability properties of this standard
notion. A natural (and ongoing) extension of our results
is to look at previous work on the composition of crypto-
graphic protocols (e.g., Universal Composability) and lever-
age them to produce veriﬁed implementations of higher-level
protocols. The major challenges here reside on the style of
cryptographic proofs that need to be formalized, which rely
on a simulation paradigm. Also interesting for future work
is the interaction of side-channel leakage at the IND-CCA
level with the security of higher-level protocols.

Finally, we did not tackle the correctness properties of the
big-integer trusted library that we use to extend C. We leave
it as an interesting challenge for future work to evaluate the
impact of side-channel countermeasures on the feasibility of
formally verifying the correctness of such a multi-precision
arithmetic library.
Acknowledgements
This work is supported by ONR Grant N000141210914, by
Amarout II (FP7 Marie Curie Actions-COFUND 291803),
by National Funds through the FCT - Funda¸c˜ao para a
Ciˆencia e a Tecnologia (Portuguese Foundation for Science
and Technology) within project ENIAC/2224/2009 and by
ENIAC Joint Undertaking under grant agreement number
120224. Part of this work was carried out while the second
author was visiting ´Ecole Normale Sup´erieure supported by
FCT grant SFRH/BSAB/1246/2012.

We are grateful to Benjamin Gr´egroire, Santiago Zanella-
B´eguelin and David Pointcheval for early discussions on the
OAEP proof and its EasyCrypt formalization.

7. REFERENCES

[1] Reynald Aﬀeldt, David Nowak, and Kiyoshi Yamada.
Certifying assembly with formal security proofs: The
case of BBS. Sci. Comput. Program.,
77(10-11):1058–1074, 2012.

[2] Johan Agat. Transforming out timing leaks. In

Proceedings of POPL’00, pages 40–53, 2000.

[3] Johan Agat and David Sands. On conﬁdentiality and

algorithms. In IEEE Symposium on Security and
Privacy, pages 64–77. IEEE Computer Society, 2001.

[4] Mihhail Aizatulin, Andrew D. Gordon, and Jan

J¨urjens. Computational veriﬁcation of C protocol
implementations by symbolic execution. In ACM
Conference on Computer and Communications
Security, pages 712–723. ACM, 2012.

[5] Jos´e Bacelar Almeida, Manuel Barbosa, Jorge Sousa
Pinto, and B´arbara Vieira. Deductive veriﬁcation of
cryptographic software. Innovations in Systems and
Software Engineering, 6(3):203–218, 2010.

[6] Jo¨el Alwen, Yevgeniy Dodis, and Daniel Wichs.

Survey: Leakage resilience and the bounded retrieval
model. In Kaoru Kurosawa, editor, ICITS, volume
5973 of Lecture Notes in Computer Science, pages
1–18. Springer, 2009.

[7] Andrew W. Appel. Veriﬁed software toolchain -

(invited talk). In ESOP’11, volume 6602 of Lecture

1228Notes in Computer Science, pages 1–17. Springer,
2011.

In ACM Conference on Computer and
Communications Security, pages 341–350. ACM, 2011.

[8] Manuel Barbosa, editor. Deliverable 5.4: Certiﬁed

[21] Eiichiro Fujisaki, Tatsuaki Okamoto, David

shared library core. Computer Aided Cryptography
Engineering (CACE FP7 EU Project), 2011.
http://www.cace-project.eu.

[9] Gilles Barthe, Benjamin Gr´egoire, Sylvain Heraud,

and Santiago Zanella-B´eguelin. Computer-aided
security proofs for the working cryptographer. In
Advances in Cryptology – CRYPTO 2011, volume
6841 of Lecture Notes in Computer Science, pages
71–90, Heidelberg, 2011. Springer.

[10] Gilles Barthe, Benjamin Gr´egoire, Yassine Lakhnech,

and Santiago Zanella-B´eguelin. Beyond provable
security. Veriﬁable IND-CCA security of OAEP. In
Topics in Cryptology – CT-RSA 2011, volume 6558 of
Lecture Notes in Computer Science, pages 180–196,
Heidelberg, 2011. Springer.

[11] Daniel J. Bernstein, Tanja Lange, and Peter Schwabe.
The security impact of a new cryptographic library. In
Alejandro Hevia and Gregory Neven, editors, Progress
in Cryptology - LATINCRYPT 2012, volume 7533 of
Lecture Notes in Computer Science, pages 159–176.
Springer Berlin Heidelberg, 2012.

[12] Yves Bertot, Nicolas Magaud, and Paul Zimmermann.

A proof of GMP square root. Journal of Automated
Reasoning, 29(3-4):225–252, 2002.

[13] Bruno Blanchet. Security protocol veriﬁcation:

Symbolic and computational models. In Pierpaolo
Degano and Joshua D. Guttman, editors, Principles of
Security and Trust - First International Conference,
POST 2012, volume 7215 of Lecture Notes in
Computer Science, pages 3–29. Springer, 2012.

[14] Sylvie Boldo, Jacques-Henri Jourdan, Xavier Leroy,

and Guillaume Melquiond. A formally-veriﬁed C
compiler supporting ﬂoating-point arithmetic. In Arith
- 21st IEEE Symposium on Computer Arithmetic,
pages 107–115. IEEE, 2013.

[15] Billy Bob Brumley, Manuel Barbosa, Dan Page, and

Frederik Vercauteren. Practical realisation and
elimination of an ECC-related software bug attack. In
Orr Dunkelman, editor, CT-RSA, volume 7178 of
Lecture Notes in Computer Science, pages 171–186.
Springer, 2012.

[16] David Cad´e and Bruno Blanchet. Proved generation of
implementations from computationally secure protocol
speciﬁcations. In POST, volume 7796 of Lecture Notes
in Computer Science, pages 63–82. Springer, 2013.

[17] Jean Paul Degabriele, Kenneth Paterson, and Gaven
Watson. Provable security in the real world. Security
Privacy, IEEE, 9(3):33–41, may-june 2011.

[18] Fran¸cois Dupressoir. Proving Cryptographic C

Programs Secure with General-Purpose Veriﬁcation
Tools. PhD thesis, Open University, 2013.

[19] Stefan Dziembowski and Krzysztof Pietrzak.

Leakage-resilient cryptography. In 49th Annual IEEE
Symposium on Foundations of Computer Science,
FOCS 2008, pages 293–302, Washington, 2008. IEEE
Computer Society.

[20] C´edric Fournet, Markulf Kohlweiss, and Pierre-Yves

Strub. Modular code-based cryptographic veriﬁcation.

Pointcheval, and Jacques Stern. RSA-OAEP is secure
under the RSA assumption. In Advances in Cryptology
– CRYPTO 2001, volume 2139 of Lecture Notes in
Computer Science, pages 260–274. Springer, 2001.

[22] Shaﬁ Goldwasser and Silvio Micali. Probabilistic
encryption. J. Comput. Syst. Sci., 28(2):270–299,
1984.

[23] Boris K¨opf, Laurent Mauborgne, and Mart´ın Ochoa.

Automatic quantiﬁcation of cache side-channels. In
Proc. 24th International Conference on Computer
Aided Veriﬁcation (CAV ’12), pages 564–580.
Springer, 2012.

[24] Ralf K¨usters, Tomasz Truderung, and Juergen Graf. A

framework for the cryptographic veriﬁcation of
Java-like programs. In CSF, pages 198–212. IEEE,
2012.

[25] Xavier Leroy. Formal certiﬁcation of a compiler

back-end, or: programming a compiler with a proof
assistant. In 33rd ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages,
POPL 2006, pages 42–54, New York, 2006. ACM.

[26] Xavier Leroy, editor. The CompCert C veriﬁed

compiler: Documentation and user’s manual. INRIA
Paris-Rocquencourt, 2013.

[27] James Manger. A chosen ciphertext attack on RSA
optimal asymmetric encryption padding (OAEP) as
standardized in PKCS#1 v2.0. In Advances in
Cryptology – CRYPTO 2001, volume 2139 of Lecture
Notes in Computer Science, pages 230–238,
Heidelberg, 2001. Springer.

[28] David Molnar, Matt Piotrowski, David Schultz, and
David Wagner. The program counter security model:
Automatic detection and removal of control-ﬂow side
channel attacks. In ICISC, volume 3935 of Lecture
Notes in Computer Science, pages 156–168. Springer,
2005.

[29] Lee Pike, Mark Shields, and John Matthews. A

verifying core for a cryptographic language compiler.
In ACL2, pages 1–10. ACM, 2006.

[30] Phillip Rogaway. Practice-oriented provable security

and the social construction of cryptography.
Unpublished essay, 2009.

[31] Sabine (formerly Fischer) Schmaltz. Formal

veriﬁcation of a big integer library including division.
Master’s thesis, Saarland University, 2007.

[32] Eric Whitman Smith and David L. Dill. Automatic

formal veriﬁcation of block cipher implementations. In
FMCAD, pages 1–7. IEEE, 2008.

[33] Falko Strenzke. Manger’s attack revisited. In Miguel

Soriano, Sihan Qing, and Javier L´opez, editors,
Information and Communications Security, volume
6476 of Lecture Notes in Computer Science, pages
31–45. Springer Berlin Heidelberg, 2010.

[34] Danfeng Zhang, Aslan Askarov, and Andrew C.

Myers. Language-based control and mitigation of
timing channels. In ACM SIGPLAN Conference on
Programming Language Design and Implementation
(PLDI ’12), pages 99–110. ACM, 2012.

1229