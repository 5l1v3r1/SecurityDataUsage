When Kids’ Toys Breach Mobile Phone Security

Abdul Serwadda and Vir V. Phoha

Louisiana Tech University
Ruston, LA 71272,USA

{ase007,phoha}@latech.edu

ABSTRACT
Touch-based veriﬁcation—the use of touch gestures (e.g.,
swiping, zooming, etc.) to authenticate users of touch screen
devices— has recently been widely evaluated for its poten-
tial to serve as a second layer of defense to the PIN lock
mechanism. In all performance evaluations of touch-based
authentication systems however, researchers have assumed
na¨ıve (zero-eﬀort) forgeries in which the attacker makes no
eﬀort to mimic a given gesture pattern.

In this paper we demonstrate that a simple “Lego” robot
driven by input gleaned from general population swiping s-
tatistics can generate forgeries that achieve alarmingly high
penetration rates against touch-based authentication sys-
tems. Using the best classiﬁcation algorithms in touch-based
authentication, we rigorously explore the eﬀect of the attack,
ﬁnding that it increases the Equal Error Rates of the classi-
ﬁers by between 339% and 1004% depending on parameters
such as the failure-to-enroll threshold and the type of touch
stroke generated by the robot. The paper calls into question
the zero-eﬀort impostor testing approach used to benchmark
the performance of touch-based authentication systems.

Categories and Subject Descriptors
K.6.5 [Management of Computing and Information
Systems]: Security and Protection—authentication

General Terms
Security

Keywords
Biometrics, Touch Gestures, Authentication, Attack, Robot

1.

INTRODUCTION

Recently, there has been considerable research on the ap-
plication of touch gestures for continuous authentication on
mobile phones (e.g., see [17][16][27]). The underlying philos-
ophy behind this type of authentication is that if a mobile

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright 2013 ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516659.

device could learn the owner’s touch pattern during routine
operations (such as swiping, zooming and clicking/tapping),
an adversary who gets access to the phone can be thwart-
ed based on the mismatch between touch patterns. While
several studies (e.g., see [17][27][16]) have shown evidence
that indicates that this type of authentication holds a lot
of promise, the performance evaluation methodology used
in all these studies revolves around a zero-eﬀort [9] threat
model in which the adversary is assumed to be unable to
pull oﬀ a sophisticated forgery.

The zero-eﬀort threat model, although well understood
not to be representative of the state-of-the-art threats [9],
is for several reasons fronted by researchers as being able to
suﬃciently capture the threat that a touch-based authenti-
cation system would face in practice. For instance, in one of
the recent papers on touch biometrics, Frank et al. [17] make
the following arguments to rule out the need for stringent
penetration testing of their system:

.... we can hardly imagine someone learning the
touch behavior of 30 features, such as pressure,
distribution of acceleration, etc., just by looking
over the shoulder [17].

...A more successful but more involved attack would
be to place a malware application on the user’s
device. This malware could learn and report the
touch pattern if the details of how to compute the
features are known to the attacker... However,
we argue that a user with malware on the device
has already lost the race against the attacker [17].

These arguments—echoed in many other papers—are sound

without doubt. Notably though, the notion that these two
attacks (malware and a form of shoulder surﬁng) represent
the full spectrum of threats that the system could face is for
several reasons debatable. In particular, by assuming these
two as the only threats, researchers in this area appear to
disregard the following two attributes of a touch biometric-
s system: 1) Users’ behavioral biometrics patterns exhibit
a great deal of intra-user variability and overlap across a
large population, implying that for certain types of users (see
[30][23] for examples of biometric user categories), statistics
extracted from a large population database could be used to
create forgeries that signiﬁcantly increase error rates (e.g.,
see [8][26]). Given access to population statistics, an adver-
sary could learn a great deal of information about a given
user’s pattern without having to physically observe the vic-
tim’s pattern or depend on a malware application to learn
the pattern, 2) The three gestures on which touch-based

599continuous authentication systems are built (i.e., clicking or
tapping, swiping to move screen content vertically, and swip-
ing to move screen content horizontally — see [17][16]) can
very easily be implemented using elementary robotic devices
available in many homes and grocery stores (see [5]). Given
a touch gesture pattern that is to be executed on the phone,
a simple robotic/mechanical device (as opposed to malware)
would be a cheaper and much less sophisticated option for
an adversary who seeks to retrieve a valuable resource from
a stolen smart phone.

The two attributes cited above motivate the attack de-
signed in this paper. We implement a robotic attack that
achieves alarmingly high success rates against continuous
touch-based authentication systems. Driven by input gleaned
from general population (swiping) statistics, the attack uses
a standard Lego Mindstorms NXT robotic kit [3] to con-
trol a “ﬁnger” that is designed to replicate the human ﬁnger
properties sensed by the state-of-the-art touch based authen-
tication systems. Using a large touch biometrics dataset, we
demonstrate the lethality of the attack against the best ver-
iﬁcation algorithms in touch-based authentication.

The following attributes convince us that the attack could
easily get embraced by adversaries if continuous touch-based
authentication got widely deployed:
No specialized expertise (or experience) required:
The algorithmic and mechanical design of the attack revolves
around some of the most basic Lego robotic skills taught in
middle school in the USA (e.g., see [20]) and many oth-
er parts of the world. While the attack could be designed
based on exquisite programming of both the robot’s sensors
and the motors, the paper seeks to emphasize the simplicity
of the attack—we implement a design that only requires the
motors to be programmed.
Analog domain and sample-level attributes: The at-
tack is launched in the analog domain, and thus cannot be
easily stopped by conventional software solutions like would
be the case for a malware attack. Additionally, the attack is
sample-level meaning that the attacker needn’t know about
the internal implementation details of the veriﬁcation al-
gorithms or features used by the system. As long as the
robot performs the swiping operation, the underlying clas-
siﬁcation system will extract the required features from the
touch strokes.
No extra-ordinary access privileges required: The at-
tack does not require template access; it is driven by general
information on how the “common user” is likely to swipe on
the phone. This kind of information can easily be retrieved
from publicly accessible data sets (e.g., see [4]), and to some
extent from research ﬁndings such as ours (e.g., see Section
4.2).

The main contribution of this paper is the demonstration
that robotic devices pose a major threat to touch-based au-
thentication. Because this threat has never been consid-
ered by researchers in this ﬁeld, the paper has the potential
to spark oﬀ a complete repackaging of touch-based authen-
tication systems. The design of these systems (e.g., fea-
tures, template-building approach, etc.), and the methodol-
ogy used to test their resistance to impostors are examples of
aspects of touch-based authentication that could see change
as a result of our ﬁndings.

The rest of this paper is organized as follows: We discuss
related work in Section 2, our data collection and prepro-

cessing in Section 3 and the attack design in Section 4. We
present the attack results in Section 5 and our conclusions
in Section 6.

2. RELATED WORK

To put this paper into context with previous work, we ex-
amine two streams of past research: works which explored
algorithmic (or non zero-eﬀort) attacks against behavioral
biometric systems, and works which studied the use of touch
gestures for authentication. The latter category of research
has two branches, namely, continuous authentication and
“entry point” authentication. In continuous authentication
(e.g., see [17][16][27]), users’ touch gestures are monitored
throughout a phone usage session. In “entry point” authen-
tication on the other hand, users are authenticated based on
how they execute a certain (possibly secret) gesture (e.g., see
[24][25] [13]) at the entry point to an application or to the
phone itself (i.e., login). Our attack is targeted against con-
tinuous authentication, so we delve deeper into past research
which explored this type of authentication.

Using a dataset of 41 users, Frank et al.

[17] obtained
Equal Error Rates (EERs) of between 0 and 4% when a
k-Nearest Neighbors (k-NN) classiﬁer and a Support-Vector
Machine (SVM) were used to continuously authenticate user-
s based on their touch gestures. The study was based on
30 features extracted while users swiped/scrolled (to move
screen content vertically or horizontally) as they read tex-
t and browsed images.
In [27], a digital sensor glove was
shown to enhance the performance of a touch gesture-based
continuous authentication system. Using a Decision Tree,
Random Forest and Bayes Net classiﬁer, the authors showed
that the glove reduced the error rates seen during authen-
tication. For instance, for the Bayes Net classiﬁer, a False
Accept Rate (FAR) of 11.96% and a False Reject Rate (FR-
R) of 8.53% respectively reduced to 2.14% and 1.63% when
the glove was used. Similar improvements were noted for
the other two classiﬁers.

More recently, Li et al. [16] evaluated the performance of a
live implementation of a touch-based authentication system
on a mobile phone. Leveraging a “hack into the lower layer
of an Android system [16]”, the system monitored touch ges-
tures across all applications installed on the phone. Based
on a group of 75 users who were allowed to freely interac-
t with the phones for days, the SVM-based authentication
system was shown to attain classiﬁcation accuracies as high
as 95%.

All three papers cited above employ a zero-eﬀort testing
approach in which the system’s resistance to attack is gauged
based on simplistic attacks in which samples from a subset
of the population are used to attack samples drawn from a
given user. It is on this front that this paper advances the
state-of-the-art, calling for more rigorous biometric testing
methodologies that are at par with the sophisticated adver-
sarial technologies being seen today. The works by Ballard
et al. [9], Tey et al. [21] and Serwadda et al. [26] resonate
with our research, demonstrating new breeds of impostor at-
tacks against two biometric modalities that are very closely
related to touch based authentication.

Ballard et al. showcase two attacks against handwriting
biometrics: one launched by trained forgers, the other based
on a generative algorithm. Tey et al. and Serwadda et al. on
the other hand demonstrate two attacks against password-
based keystroke authentication, with the former being based

600on trained forgers, and the latter being based on a generative
algorithm which uses general population statistics as input.
In all three papers, the attacks are shown to signiﬁcantly
degrade system performance relative to the standard zero-
eﬀort attacks.

Although this emerging breed of impostor attacks shares
the same motivation as our work, our attack has several op-
erational and technical attributes that put it apart from the
other attacks. Notably, the very low level of expertise re-
quired to implement the attack, the low cost of equipment
required and the fact that it is a hardware-based attack ma-
jorly distinguish it from the above cited attacks (attributes
described in Section 1 portray these diﬀerences in more de-
tail).

3. DATA AND FEATURES USED FOR OUR

INVESTIGATIONS

3.1 Data Collection Process

We conducted two data collection experiments using t-
wo Android applications that captured the way in which
users touched the mobile phone screen. The gestures that
users typically perform on a touch screen include zooming
(in and out), clicking (tapping), swiping to switch between
screens (i.e., horizontal swiping) and swiping to move a page
up and down (i.e, vertical swiping). The tap gesture does
not hold enough information to strongly separate between
a large group of users [17], while the zoom gesture does
not occur frequently enough to guarantee that a continu-
ous authentication application will always have enough data
to make classiﬁcation decisions [17]. For these reasons, a
number of works on continuous touch-based authentication
hinge around the two swipe gestures (e.g., see [17])1. We
will focus on these two gestures in this paper.

For each of a set of points on a touch stroke registered on
the screen during swiping, the applications recorded the: 1)
x and y coordinates, 2) time at which the ﬁnger touched the
point in question, 3) area occluded between the ﬁnger and
the screen, 4) the pressure exerted on the screen and 5) the
orientation of the phone (i.e., landscape or portrait). The
two Android applications basically simulated how users read
text and view images on the touch screen. Based on a short
paragraph of text or an image, users had to answer several
questions by selecting one of two to four alternative answers
that we provided per question. On reading a question, each
user would scroll/swipe back to the image or block of text
containing clues to the solution, before scrolling/swiping to-
wards the answers section where the user would select one
of the choices provided.

Both applications were based on the same idea, although
each application was based on a diﬀerent set of question-
s/images. In the ﬁrst phase of experiments (which we also
refer to as Session I), users interacted with one application.
They then returned on another day at their convenience to
interact with the second application (i.e., during Session II).
All participants used the same brand of phone—the Google
Nexus S running Android version 4.0—so as to avoid bias in
our ﬁndings that might be caused by diﬀerences in the way

1Li et al.
[16] used the tap gesture in conjunction with
the two swipe gestures. However they found that it had
very poor discriminability in comparison to the two swipe
gestures.

in which diﬀerent phones extract information from touch
gestures.
3.2 Feature Extraction and Preprocessing

Before extracting features from the data, we performed
an outlier ﬁltering step to eliminate very short strokes s-
ince these likely originated from click events (or taps), as
opposed to swiping (scrolling). Frank et al. [17] performed
a similar step on users’ strokes before proceeding with the
classiﬁcation process. Having removed outliers, we extracted
28 features from each stroke. There is currently no univer-
sal feature-set that researchers use to represent a distinct
stroke. For example, Frank et al.
[17] deﬁned 30 features
and discarded 3 of them after feature analysis, Li et al. [16]
deﬁned 13 features (or 14 features if the x and y coordinates
of a point are considered as distinct features) and discarded
4 of them after feature analysis while Feng et al. [27] used 53
features. For this work we used 28 features that we believe
best summarize the statistical attributes of a touch stroke.
A description of how we computed these features follows:

Using the pressure and area readings at diﬀerent points
along a stroke, we respectively built a pressure vector, P ,
and an area vector, A, to represent the pressure and area
associated with the stroke. We computed the velocity be-
tween every pair of consecutive points along a stroke, and
used these values to generate the velocity vector, V . Finally,
for every pair of points in V , we computed the acceleration,
′
and generated an acceleration vector, A

.

′
For each of the four vectors A, P , V and A

, we computed
ﬁve measures to summarize a user’s mean behavior, variabil-
ity in behavior and extreme behavior along a stroke. These
were: 1) lower quartile, 2) second quartile, 3) third quartile,
4) mean, and, 5) standard deviation. This gave a total of 20
(=4(cid:2) 5) features per stroke. The last 8 features making up
a vector representing a stroke were: the x and y coordinates
of the starting points, the x and y coordinates of the end
points, the distance between the end and starting points of
a stroke, the time taken to complete the stroke, the tangen-
t of the angle between the line joining the end-points of a
stroke and the horizontal, and the sum of distances between
every pair of adjacent points on a stroke.

4. ATTACK DESIGN

4.1 General Assumptions

The attacks launched in this paper assume an adversary
who gets physical access to a phone for which touch-based
continuous authentication is the only active layer of defence.
In practice, this scenario may arise for an attacker who : 1)
breaks the PIN lock mechanism (e.g., using methods such as
those in [6][22]), or, 2) ﬁnds a phone in which the PIN lock
has been disabled temporarily (e.g., a user who sets a very
long timeout for the PIN lock), or, 3) ﬁnds a phone in which
the PIN lock has been completely disabled by the owner [17].
To be able to determine the amount of extra security that
touch-based continuous authentication adds to the standard
PIN lock in the worst case, we believe that these assump-
tions must necessarily be made. See [7], for an investigation
in which a similar assumption (i.e., that the adversary has
access to the victim’s password) was made in order to enable
rigorous evaluation of the security of Randomized Biometric
Templates (RBTs).

601(a) Spatial distribution of
swiping
during
vertical swiping.

activity

(b) Spatial distribution of
swiping activity during hor-
izontal swiping.

Figure 1: Color map showing the spatial distribu-
tion of touch strokes on the phone screen. A high
intensity of blue corresponds to regions which saw
very few strokes, while a high intensity of red im-
plies a region which saw intense swiping activity.
The phone was being used in portrait mode when
the strokes were generated. Note that the coordi-
nate system used on the ﬁgures is diﬀerent from that
used by the Android system.

In the attack itself, the attacker will seek to view pri-
vate information on the phone (e.g., emails, pictures, etc.,)
without triggering the anomaly detection mechanism. The
attack thus basically proceeds by scrolling/swiping through
documents on the phone.
In practice we believe that the
attacker could even assist the robot during certain opera-
tions (e.g., occasionally clicking at a challenging location),
since the anomaly detector will most likely not be sensitive
enough to detect a few anomalous clicks. Next we discuss
the underlying statistical observations that drive the attack,
and the details of the mechanical and algorithmic design of
the robot.
4.2 How do People Swipe on the Phone?

To design the attacks, we ﬁrst examine the way in which
people swipe in general. How random is swiping behavior
across a population? Are there certain distinct traits that
manifest frequently across a large number of users? This
section provides answers to these and related questions. Due
to space limitations, we only present results on the pressure
exerted on the screen, the area between the ﬁnger and the
screen and the region of the phone at which most swiping is
done. Other measures such as the time taken to complete a
stroke, the velocity of the ﬁnger and the length of a stroke,
to mention but a few, are left out here but will be used to
guide the attack design.

4.2.1 Location of Swiping Activity
Figure 1 shows the density of touch strokes captured at
diﬀerent positions of the phone screen during the ﬁrst phase
of experiments. The dark blue color corresponds to regions
which saw very little or no swiping/scrolling activity while a
high intensity of red corresponds to regions which saw a lot
of swiping. Observe (Figure 1(a)) that the vast majority of

(a) Distribution of the mean pres-
sure and mean area across touch
strokes.

(b) Distribution of the standard de-
viation of the mean pressure and
mean area across touch strokes.

Figure 2: CDFs expressing the mean and variability
of area and pressure seen across the population.

vertical strokes generated by our user population originated
from points having X values in the neighborhood of 300 u-
nits, and terminated at a position with an X value of close
to 400 units (and vice versa). Notably, this region of high
activity comprises less than 50% of the screen display. The
heart of the red region (which tends towards black) occupies
an even much smaller portion of the screen. Similar traits
(see Figure 1(b)) were seen with horizontal swiping.

Based on evidence provided through this plot, an adver-
sary with access to general population statistics could poten-
tially signiﬁcantly narrow down the scope of features such
as: 1) the x coordinate of the start point of a stroke, 2) the y
coordinate of the start point of a stroke, 3) the x coordinate
of the end point of a stroke, 3) the y coordinate of the end
point of a stroke, 4) the duration of a stroke, 5) the summa-
tion of distances between consecutive points of a stroke, and
6) the direction of the end-to end line, among other features.
These features represent a good proportion of the features
used to characterize users’ touch gestures in past research
(e.g., see [17][16]), and will also be used in this study.

Regarding the cause of the clustering tendency, our con-
jecture is that the high density of strokes on the right side
of the screen (i.e., taking the case of vertical swiping for
instance) was likely because the majority of users are right
handed, tending to hold the phone in the right hand and
swiping with the thumb, or holding the phone in the left
hand and swiping using one of the ﬁngers on the right hand.
In any of these two scenarios, a user is very likely to swipe
in the manner reﬂected in the ﬁgure. We do not rule out the
possibility that certain applications could depict variations

XY0  1002003004000  100200300400500600700800XY0  1002003004000  10020030040050060070080000.20.40.60.8100.20.40.60.81MeanCDF  AreaPressure00.10.20.300.20.40.60.81Standard DeviationCDF  AreaPressure602Figure 3: Mechanical design of the robot. The three motors (Motor A, Motor B and Motor C) are respectively
responsible for moving the robot ﬁnger left and right (Mvmt A), up and down (Mvmt B) and back and forth
(Mvmt C). Motor B contributes to the pressure exerted on the screen. Depending on the input parameters
to the motors (see Algorithm 1), the superposition of the three primitive motor movements is able to produce
touch strokes with diﬀerent properties.

from the pattern shown in the ﬁgure. In this case we argue
that a committed attacker who has interest in breaking into
such applications can make research on the swiping traits
associated with these applications.
4.2.2 Finger Area and Pressure on the Screen
Figure 2(a) shows the distribution of the mean area touched
by the ﬁnger and the mean pressure exerted on the screen
across a subset of our full user population. To plot the ﬁg-
ures, we computed each user’s mean area (and mean pres-
sure) and plotted the results on the CDF. Observe that over
80% of the population had a mean area of between 0.1 and
0.25 and that about 50% of the population had mean pres-
sure values of between 0.4 and 0.6. These user proportions
already suggest that a large number of users could be clus-
tered around a narrow band of values (for both pressure and
area). To get a more concrete insight into the possible clus-
tering of users’ proﬁles, we studied the variability seen by
users for each of these two variables.

Particularly, we computed the standard deviation of the
mean area and mean pressure exhibited by each of the user-
s represented in Figure 2(a), and then plotted these values
on a CDF (Figure 2(b)). Taking the case of pressure for
instance, the ﬁgure shows that about 40% of the users had
a standard deviation of over 0.15. Assuming users’ mean
pressure values follow a Gaussian distribution, a user with a
standard deviation of 0.15 could see her/his biometric pat-
tern fall on a band having a width of up to 0.6 units (i.e., 2
standard deviations on either side of the mean). Given such
a wide span, an input selected from the earlier mentioned
clustered regions (Figure 2(a)) could have a good chance of
falling within such a user’s feature range.

Similar observations made for the other features (e.g., ve-
locity, length of strokes, start point of stroke, etc.) further
prompted us to hypothesize that generic information from

the population could possibly enable us to implement a suc-
cessful attack on a subset of the users.
4.3 Mechanical Design
4.3.1 Design of the Robot
Figure 3 depicts the robot design. The main components
of the robot are: 2 NXT Intelligent bricks, 3 motors, 1 rack
gear, 1 pinion gear, 4 wheels and the robotic arm stroking
the screen. Throughout the rest of the paper we will refer
to this robotic arm as the robot ﬁnger (or the ﬁnger). The
two Intelligent bricks, one of which serving as the CPU of
the system, are joined to form the chassis on which other
components are built. Motor C, which propels the wheels,
is responsible for moving the ﬁnger back and forth. Motor
A on the other hand drives the pinion and rack gear system
to move the ﬁnger left and right. Motor B moves the ﬁnger
up and down, and thus helps control the pressure exerted
by the ﬁnger on the screen. Depending on the way in which
the three motors are conﬁgured (see Algorithm 1), the robot
can create strokes having diﬀerent properties (e.g., velocity,
direction, pressure, etc.).
4.3.2 Fabrication of the Finger
We had three main design considerations regarding the
object to be used to touch the screen. These were: 1) the
object had to be able to register touch events on the capaci-
tative screen, 2) it had to easily match the ﬁnger surface area
as needed, 3) it had to be soft to avoid damaging the screen,
and 4) it had to be made from cheap, domestically accessi-
ble materials. The fourth point rules out technologies such
as prosthetics [10] that despite guaranteeing artiﬁcial ﬁngers
that could match many of the properties of a human ﬁnger,
would make the attack implementation expensive, and likely
defeat our aim of demonstrating how easily the attack can

Motor AMotor CPinion GearRack GearRobot FingerMotor BMvmnt  BMvmnt  CMvmnt  A603ALGORITHM 1: Swiping Mechanism

Input: numOfSwipes//Number of Swipes;
Input: SLRight//Step length right;
Input: speedRight//Speed right;
Input: SLFwd//Step length forward;
Input: SLBkwd//Step length backward;
Input: speedFwd//Speed forward;
Input: speedBkwd//Speed backward;
Input: speedUpDown//Finger up-down speed;
Input: numOfSteps
//Number of steps needed to complete the swipe;
GenerateSwipingSteps()
for i 1 to numOfSwipes do

rfs=GRandom((cid:22)1,(cid:27)1); //Gaussian noise in speed
FingerDown(speedUpDown);
for j 1 to (p) //Steps upward-right
do

FingerForward(speedFwd,SLFwd);
FingerRight(speedRight+rfs,SLRight);

for k 1 to (NumOfSteps-p)//Steps downward-right
do

FingerBackward(speedBkwd,SLBkwd);
FingerRight(speedRight+rfs,SLRight);

FingerUp();
FingerBack();
Wait(swipeInterval);//Inter-swipe interval

be launched based on materials that are cheaply available
oﬀ the shelf.

To address all four points we fabricated the ﬁnger surface
from play-doh [28], a malleable compound that children use
to model diﬀerent kinds of play-objects. Although play-doh
on its own was able to register touch points on the screen,
we housed it inside a touch screen glove (see [2]) in order
to have close control of the ﬁnger area touching the screen.
In all experiments we set our ﬁnger area to be approximate-
ly 0.15 units, which was the mean value we observed across
our user population. The area setting itself was manual—we
iteratively molded the play-doh and tested it on the phone
(during preliminary experiments) until the area value sta-
bilized at around 0.15 units. When the motors pushed the
play-doh against the touch screen during scrolling, the play-
doh, owing to its softness, would see some amount of de-
formation. These small variations in play-doh touch surface
area did not aﬀect our attack that much, since human ﬁngers
also see variations in area along the path of a stroke.

Perhaps one interesting observation worth noting here is
that when we connected a battery (AA type) to the play-doh
during the attack, the area registered on the phone screen
increased. A possible reason for this is that the eﬀective
area of contact between the screen and the phone is not on-
ly dependent on the physical area of contact between the
two, but, it also depends on the extent of electrical contac-
t between them. We leveraged this property to introduce
changes in the ﬁnger area during the experiments.
4.4 Algorithmic Design of Robot Movements

4.4.1 Overview
We formulated an algorithm that can generate a wide va-
riety of touch strokes depending on the parameters passed

Figure 4: Demonstrating the steps taken by the
robot during execution of a swipe gesture. The
path seen by the Android system is just a collection
of points (e.g., the black dots in the ﬁgure) sam-
pled from the physical path traversed on the phone
screen.

to it. The attack launched in this paper was just one special
case of the algorithm (i.e., a speciﬁc set of inputs). We ﬁrst
describe the generic algorithm, and then narrow down to the
speciﬁc case which we used for our attacks. Before delving
into the details of the algorithm, we note that we used the
Bricx Command Center IDE (BricxCC) [1] for the algorith-
m implementation. Unlike the standard Lego Mindstorms
NXT IDE (see [3]) which uses a drag and drop graphical in-
terface, BricxCC supports NXC, a high level programming
language whose syntax is similar to that of the C language.
With the NXC language, we were able to easily ﬁne-tune
our code without going through the tedious process of re-
aligning and modifying the graphical components (as would
be the case with the Mindstorms NXT IDE).

4.4.2 General Algorithm
We describe the mechanism of the attack (Algorithm 1)
based on the touch stroke represented in Figure 4. We gen-
eralize an arbitrary touch stroke as comprising of either or
both of an upward trajectory (e.g., XY ) and a downward
trajectory (e.g., Y Z). To traverse the upward path between
X and Y , the robot ﬁrst moves the ﬁnger downwards on-
to the phone at speed speciﬁed by the parameter speedUp-
Down (see method FingerDown), before embarking on a se-
ries of very short vertical and horizontal steps having the
sawtooth-like structure represented along A’B’. The short
vertical step (i.e., Y1) is executed using the method Fin-
gerForward (see (Algorithm 1)) while the short horizontal
step (i.e., X1) that immediately proceeds the vertical step
is executed using the method FingerRight. The algorithm
repeats (loops) this process until the peak position (i.e., Y )
is reached (i.e., after, say, p iterations).

On the downward trajectory (Y Z) the algorithm uses the
same approach used for the upward trajectory, except that
the vertical steps are now downwards (see the method Fin-
gerBackward), while the horizontal steps continue towards
the right (i.e., using the method FingerRight). On reach-
ing the point Z, the robot lifts the ﬁnger oﬀ the phone (see
FingerUp), moves it back towards X (see FingerBack), and
then swipes again after a random interval.

Each of the methods executing the short steps takes two
parameters, one of which is a speed input (e.g., speedFwd),
the other a distance input (e.g., SLFwd). These param-
eters enable us to control the speed and distance covered
in each step. During each swipe (we interchangeably refer

604Parameters / Values Horizontal Vertical
Swiping
4
4
0
2
53
20
0
20
0
300
2
2

numOfSteps
SLRight
SLFwd
SLBkwd
speedRight
speedBkwd
speedFwd
speedUpDown
p
numOfSwipes
(cid:22)1
(cid:27)1

Swiping
4
4
2
0
49
0
20
20
4
300
2
2

Table 1: Parameter settings used for the attack on
the portrait strokes. According to the speciﬁcation-
s of the LEGO system, the speed parameters (i.e.,
speedRight, speedBkwd, speedFwd) are in terms of
the power of the robot motor, while the distance pa-
rameters (SLRight, SLFwd, SLBkwd) are expressed
in terms of the angle of rotation.

to a full path, such as one from X to Z as a swipe or a
stroke), we compute the random noise term, rfs, and use
it to perturb the speed inputs to the FingerRight method.
This perturbation, in addition to the noise arising from the
mechanical dynamics of the robot, enabled us to simulate
the randomness that humans exhibit during the execution
of a stroke. We only add the noise factors to the inputs of
the FingerRight method and not to those of the FingerFor-
ward or FingerBackward methods because the long distance
along the horizontal direction (e.g., along the straight line
from X to Z) gives more room for error than the very short
span towards the direction perpendicular to the straight line
XZ.

A critical diﬀerence between the arbitrary stroke shown in
Figure 4 and the typical touch stroke produced by humans is
that the strokes generated by humans deviate very slightly
from a straight line. For this reason, to generate a stroke
similar to XY (see Figure 4), our settings were such that the
steps along the normal to the straight line XZ were shorter
than those in the direction along XZ. This resulted into
strokes that were much less crooked than the stroke shown
in Figure 4. Given that the actual stroke registered by the
Android system is just a combination of points sampled2
from the physical stroke (e.g., see solid dots on zig-zag line
in Figure 4), evidence of crookedness was further erased from
our strokes, with the vast majority of strokes registered by
the system depicting a smooth shape.

Table 1 summarizes the algorithm settings that we used
for the attack for both the vertical and horizontal swipes
in portrait mode. To generate a horizontal stroke, we po-
sitioned the phone such that the ﬁnger started around the
point with coordinates (363, 541) and moved towards the
point having the coordinates (145, 588). For the vertical
strokes, the phone was positioned such that the start coor-
dinates were approximately (320,613) and the direction of

2On our Google Nexus phones, we found that the system
recorded touch points at an interval of 15 ms on average.

the ﬁnger being towards the point (352,400). As mentioned
earlier, the randomization factor (and the randomness e-
merging out of the mechanical interactions between robot
components) ensured that the diﬀerent variables saw slight
changes between strokes. We set the speedUpDown param-
eter (speed at which ﬁnger meets phone screen) to 20 units
so as to get pressure outputs of between 0.4 and 0.6.

Depending on factors such as the area of the ﬁnger and
the initial position of the ﬁnger relative to the phone, one
may have to set a diﬀerent value for the speedUpDown pa-
rameter in order to get pressure outputs in this range. Like
in the case of the ﬁnger area (see Section 4.3.2.), we not
only iteratively set the pressure during initial experiments,
but also depended on a connected battery to increase the
pressure to the required range. To ease the task of setting
the various attack parameters, we enabled pointer locations
(under developer options) so as to view the strokes and their
associated raw feature outputs on the screen during the ﬁne-
tuning phase. All attack parameters were set based on an
initial set of experiments in which we compared the robotic
output with the mean behavior seen across a subset of the
users who were not subjected to the attack.

5. ATTACK PERFORMANCE EVALUATION
5.1 Veriﬁcation Algorithms

We demonstrate the impact of the attack using a Support
Vector Machine (SVM) [11] and the k-Nearest Neighbors
(k-NN) classiﬁer [12]. We select these two veriﬁcation algo-
rithms because they have recently been shown in [16] and
[17] to perform very well for continuous touch-based authen-
tication. We brieﬂy describe the mechanisms of operation
of the two algorithms below:

Support Vector Machine

5.1.1
An SVM is a binary classiﬁer which uses a hyperplane
to separate two data classes in such a way that the margin
between the two classes is maximized. The margin is the
distance between the hyperplane and the boundary obser-
vations which are also referred to as support vectors. For
classes that are not linearly separable in a given feature s-
pace, it is sometimes necessary to map the original data
points to a higher dimensional space with the aid of a kernel
function. We used the Gaussian radial-basis function as our
kernel, like was done in [17].

k-Nearest Neighbors

5.1.2
During training, this classiﬁer does not have to extract
any model from the data—it only stores the feature vectors
from the diﬀerent classes (in our case two classes). Given
a new observation that is to be assigned a class label, the
k-NN classiﬁer assigns it to the class A if the majority of
the k closest training vectors to the new observation belong
to the class A. Diﬀerent researchers use diﬀerent measures
to represent the distance between the training vectors and
a test observation. Similarly to Frank et al. [17], we use the
Euclidean distance metric.

For both the k-NN and SVM, we used WEKA [29] via
its Java API to implement the classiﬁcation system. We
used k=9 for the k-NN classiﬁer since this value gave us the
best performance. For all other parameters across the two
classiﬁers, we used the WEKA defaults.

6055.2 Training and Testing Methodology

5.2.1 Training and Zero-effort Testing
Training was done based on data collected during Session
I while zero-eﬀort testing was done based on data collected
during Session II. For each user, we distinguished between
portrait and landscape strokes, and further distinguished
between horizontal and vertical strokes for each of the two
phone orientations. This way, each user had four reference
templates. The reason for separating between these four
types of strokes was because certain features change depend-
ing on the type of stroke and the way in which the phone
is held when the stroke is executed. For example, for the
typical user, a horizontal stroke executed in portrait mode
will very likely have diﬀerent start and end-points (among
other features) from a horizontal stroke executed in land-
scape mode. Owing to the mismatch between features, a
classiﬁcation mechanism that does not distinguish between
these two types of strokes will likely perform unreliably.

In practice we believe that a touch-based authentication
application should use all four types of reference templates
since users can switch between stroke types depending on
the type and organization of content they read on the phone.
Regardless of whether a user is biased towards a certain type
of stroke, the system should be able to accurately perform
classiﬁcation during those times when the user executes the
other kinds of strokes.

For each of the four categories of strokes, we only per-
formed our analysis for those users who executed at least 80
strokes during Session I. For the portrait strokes we had 106
and 118 users who met this 80 strokes requirement for the
horizontal and vertical strokes respectively. For the land-
scape strokes, we had 41 and 50 users who met the require-
ment for the horizontal and vertical strokes respectively. For
training, we used 80 strokes executed by the user in ques-
tion (i.e., genuine or positive class) and 5 strokes from each
of the other users (i.e., the impostor or negative class) for
each of the four categories of strokes.

To establish a baseline against which to measure the im-
pact of the robotic attack, we carried out zero-eﬀort testing
for each user. In these tests, to launch an impostor attack a-
gainst a given user’s template, we used 10 strokes from each
of the other users. To carry out a genuine attack against
a given user’s template, we used all the strokes captured
from that particular user during Session II. Because a user
will every now and then execute a stroke which is very dis-
tinct from the rest of her strokes, we used a block of strokes,
rather than a single stroke to make authentication decisions.
Each legitimate or impostor authentication attempt was
based on a single vector derived from 10 consecutive fea-
ture vectors (or strokes). The single authentication vector
was computed such that its elements were the component-
wise means of the 10 vectors contained in a sliding window.
From the results obtained from these tests, we generated
four Detection Error Tradeoﬀ (DET) curves [18] for each us-
er, one for each kind of swiping. From each of these curves,
we determined the Equal Error Rate (EER), a performance
measure that is widely used to evaluate the performance of
biometrics systems (e.g., see [15][17][9]).

on samples generated by the robot. We will refer to the
impostor attack in this case as the robotic impostor attack
or robotic attack. We used 600 strokes generated by the
robot to carry out this attack against each user. Like we did
in the zero-eﬀort tests (Section 5.2.1), we again generated
four DET curves for each user, and calculated the EER from
each of the curves.
5.3 Robotic Attack Results

In this section we present the attack results.

In order
to make a thorough performance evaluation while avoid-
ing duplication, we focus on the portrait strokes since the
landscape strokes did not provide any major new insights.
We present some performance highlights of the landscape
strokes in Appendix 2.

5.3.1 Rationale Behind Failure to Enroll Policy
For behavioral biometric modalities, there are certain user-
s whose biometric footprint is so inconsistent that even a
zero-eﬀort attack can attain very high penetration rates. To
demonstrate the success of an algorithmic attack against
such users is not as meaningful as, for instance, demonstrat-
ing it against the most consistent users on the system. For
this reason, we employed a “failure to enroll” policy, in which
we only enrolled users whose EERs were less than a certain
EER threshold ((cid:11)) for both classiﬁers. Our attack perfor-
mance evaluation was done at values of (cid:11) ranging from 0.2 to
0.08. We chose an upper bound of (cid:11)=0.2 because we believe
that a user with an EER higher than that would probably
not use the technology anyway. For the lower bound we
decided to use (cid:11)=0.08 because the number of users able to
enroll on the system became too small for values of (cid:11) less
than that.

5.3.2 Mean Impact of the Attack
For diﬀerent values of (cid:11), we computed the mean EER
and standard deviation of the EERs across the population
before and after the robotic impostor attack. Figures 5 and
6 respectively summarize these results for the horizontal and
vertical touch strokes. The bottom (horizontal) axis shows
the diﬀerent EER thresholds ((cid:11)), while the top (horizontal)
axis shows the number of users who were able to enroll onto
the system at each value of (cid:11).

Before the robotic attack was launched we obtained EERs
of between 0.13 and 0.035 (see plots on the left side of Fig-
ures 5 and 6)3. These EERs are higher than the EERs
reported in [17], but comparable to those reported in [27]
during the sub-set of experiments in which the users did not
wear a digital sensor glove. With our baseline EERs (i.e.,
before attack) being comparable to the EERs reported in
the literature, we proceeded to evaluate the impact of the
robotic attack.

Observe (Figures 5(b), 5(d), 6(b), 6(d)) that for both the
vertical and horizontal strokes, the attack drastically in-
creased both the mean EERs and the standard deviation
of the EERs. The high mean EERs indicate that users be-
gin to see very high False Reject Rates (FRRs), while im-
postors see equally high False Acceptance Rates (FARs).
Also, the high variance in EERs implies that system perfor-

5.2.2 Robotic Testing
The robotic testing process was the same as that described
in Section 5.2.1, except that the impostor attack was based

3While our vertical scale for the left side plots makes it hard
to view the EERs precisely, we decided to use it (this scale)
because it eases comparison with the plots to the right (i.e..
the post-attack plots)

606(a) Mean and standard de-
viation of EERs obtained
for the SVM veriﬁer before
the robotic attack.

(b) Mean and standard de-
viation of EERs obtained
for the SVM veriﬁer after
the robotic attack.

(a) Mean and standard de-
viation of EERs obtained
for the SVM veriﬁer before
the robotic attack.

(b) Mean and standard de-
viation of EERs obtained
for the SVM veriﬁer after
the robotic attack.

(c) Mean and standard de-
viation of EERs obtained
for the k-NN veriﬁer before
the robotic attack.

(d) Mean and standard de-
viation of EERs obtained
for the k-NN veriﬁer after
the robotic attack.

(c) Mean and standard de-
viation of EERs obtained
for the k-NN veriﬁer before
the robotic attack.

(d) Mean and standard de-
viation of EERs obtained
for the k-NN veriﬁer after
the robotic attack.

Figure 5:
Impact of the robotic attack on the
horizontal strokes generated in portrait mode. The
error bars indicate one standard deviation from the
mean EER. The bottom axis shows the failure to enroll
thresholds, (cid:11), while the top axis shows the number
of users who are able to enroll for each value of (cid:11).

Figure 6: Impact of the robotic attack on the vertical
strokes generated in portrait mode. The error bars
indicate one standard deviation from the mean EER.
The bottom axis shows the failure to enroll thresholds,
(cid:11), while the top axis shows the number of users who
are able to enroll for each value of (cid:11).

mance becomes very unreliable/unpredictable as a result of
the attack. It is noteworthy that the heightened EERs and
standard deviations persist for both veriﬁcation algorithms
even when the system is used only by the best performing
users (i.e., (cid:11)=0.08). This implies that a defence mechanism
centered around barring the poor users from enrolling onto
the system would not thwart the attack.

Table 2 gives a more precise view of the impact of the
attack on the mean EERs. The table shows the percent-
age change in mean system EER seen by each veriﬁcation
algorithm as a result of the attack. Regardless of the veriﬁ-
cation algorithm or failure to enroll threshold, the percent-
age change in mean EER is beyond 200% in all cases, and
over 900% in the most extreme case. These results conﬁr-
m why the robotic attack would signiﬁcantly degrade the
performance of a touch-based authentication system.
5.3.3 Impact of the Attack on each User
To better explain the dynamics of the mean EER and EER
variability seen in Figures 5 and 6, we studied the impact of
the attack on each user. For this analysis we only present
results for (cid:11)=0.2 and (cid:11)=0.08 since the other values of (cid:11)
did not give us any new insights. Figure 7 summarizes these
results for both veriﬁcation algorithms. The plot reveals two
salient features:

1. There was a proportion of between 20% to 40% of the
population whose EER changes were negative (Figures
7(a), 7(c) and 7(d)). For these kinds of users, the

robotic attack actually performed worse (i.e., caused
lower EERs) than the zero-eﬀort attack. Since our
attack was designed based on data gleaned from the
population, this trend suggests that about 20-40% of
the users had a touch gesture biometric footprint that
was very distinct from that of the majority of the users.

2. There was a proportion of users who had EER changes
that were extremely high (close to 1). These types
of users likely had their touch biometric patterns very
similar to the mean behavior exhibited across the pop-
ulation.

These two features to some extent explain the high vari-
ance seen in Figures 5(b), 5(d), 6(b) and 6(d), since a combi-
nation of users seeing decrements in EER and others seeing
very drastic increments in EER must have resulted into a
population having very high variability in EER overall.

Despite the results presented up to this point already
showing evidence for a highly successful attack, rigorous
performance evaluation calls for statistical signiﬁcance test-
ing to rule out the impact of random eﬀects. We used the
Wilcoxon signed-rank test [14] to determine whether the ef-
fect of the attack was statistically signiﬁcant. For instance,
for the enrollment threshold (cid:11), let Vknn1 denote the vector
of EERs obtained across the population for the k-NN veri-
ﬁer (i.e., for horizontal strokes in portrait mode) before the
robotic attack, and Vknn2 denote the corresponding vector
obtained after the robotic attack. The two vectors are such

0.20.180.160.140.120.10.08−0.100.10.20.30.40.50.60.70.80.9EER Threshold: αMean EER# of Users736963585039350.20.180.160.140.120.10.08−0.100.10.20.30.40.50.60.70.80.9EER Threshold: αMean EER# of Users736963585039350.20.180.160.140.120.10.08−0.100.10.20.30.40.50.60.70.80.9EER Threshold: αMean EER# of Users736963585039350.20.180.160.140.120.10.08−0.100.10.20.30.40.50.60.70.80.9EER Threshold: αMean EER# of Users736963585039350.20.180.160.140.120.10.0800.10.20.30.40.50.60.70.80.91EER Threshold: αMean EER# of Users514741352522150.20.180.160.140.120.10.0800.10.20.30.40.50.60.70.80.91EER Threshold: αMean EER# of Users514741352522150.20.180.160.140.120.10.0800.10.20.30.40.50.60.70.80.91EER Threshold: αMean EER# of Users514741352522150.20.180.160.140.120.10.0800.10.20.30.40.50.60.70.80.91EER Threshold: αMean EER# of Users51474135252215607(cid:11)

0.2
0.18
0.16
0.14
0.12
0.1
0.08

SVM

k-NN

Horizontal Vertical Horizontal Vertical

392%
428%
486%
520%
546%
636%
675%

686%
721%
726%
722%
848%
861%
921%

430%
460%
465%
511%
567%
668%
714%

339%
339%
373%
398%
416%
430%
411%

Table 2: Percentage increment in mean EER due to
the robotic impostor attack on the portrait strokes.
For each stroke type and enrollment threshold (cid:11), the
increment in mean EER is expressed as a percentage
of the mean EER obtained during the zero-eﬀort
attack.

that if the EER located in position j for the vector Vknn1
belongs to the user j, then the EER located in position j for
the vector Vknn2 also belongs to user j. We run the Wilcox-
on signed-rank test on the diﬀerences vector Vknn1 -Vknn2 to
determine whether the attack signiﬁcantly aﬀected the k-
NN veriﬁer’s classiﬁcation performance. For both veriﬁers
and all stroke types and enrollment thresholds, we under-
took a similar process. As was done in [26][15], we zeroed
on this test after ﬁnding that the diﬀerences vectors in all
the scenarios evaluated were far from Gaussian (based on ob-
servations of Q-Q plots and results of Kolmogorov Smirnov
(K-S) normality tests [19]).

Formally, the null hypothesis was that the diﬀerence in
EER before and after the robotic attack was insigniﬁcan-
t. The alternative hypothesis was that the EERs under
the robotic attack were higher. For all veriﬁers, enrollment
thresholds and stroke types, we rejected the null hypothe-
sis at the 5% signiﬁcance level (see highlight of P values in
Table 4—Appendix 3). Based on these results, we conclud-
ed that the attack signiﬁcantly degraded the performance of
the two classiﬁcation algorithms.

6. CONCLUSIONS

In this paper we have evaluated the impact of a robotic
attack against touch-based authentication. Using the best
veriﬁcation algorithms in the domain, we have shown the
attack to signiﬁcantly degrade classiﬁcation performance.
There are several aspects of our attack that might need fur-
ther research. First, like most past studies in this area (e.g.,
see [17], [27]), our data collection was based on a group of
users who used a small number of specialized application-
s (two applications in our case). In practice, people use a
wide range of applications, some of which are designed for
tasks which could prompt “touch signatures” (e.g., with re-
gard to regions of the phone that people touch) that are very
distinct from those seen with the common applications. It
would be interesting to determine how the attack scales to
a large number of applications.

Another area worthy of investigation is whether a touch
stroke could be decomposed into a set of features that are
more resilient to this kind of attack than our features. Be-
cause touch-based authentication does not yet have a stan-
dard set of features universally used by all researchers, we
deﬁned a set of 28 features that captured the key statistical

(a) SVM performance with
the horizontal strokes.

(b) SVM performance with
the vertical strokes.

(c) k-NN performance with
the horizontal strokes.

(d) k-NN performance with
the vertical strokes.

Figure 7: Impact of the attack on each user’s por-
trait strokes. For each user, we subtracted the EER
seen under the zero-eﬀort attack from that seen un-
der the robotic attack and then plotted the CDFs of
these changes in EER for each of the two extreme
failure-to-enroll thresholds.

attributes exhibited along a stroke. The underlying philos-
ophy behind our feature deﬁnitions is not so diﬀerent from
that of the features used in past work (e.g., see [17][16]),
however, this does not guarantee that all feature-sets will
succumb to the attack in exactly the same way. It is thus
interesting to determine how much less or how much more
the other features are aﬀected by the attack.

The above factors notwithstanding, our attack highlight-
s a previously unknown threat to touch-based authentica-
tion. Given the low cost of the robots and the simplicity
of the attack, we believe that the attack would realistically
be launched by adversaries if touch-based authentication got
widely deployed in its current form. For sophisticated ad-
versaries who may use more advanced robots (or advanced
designs of the same robot) in conjunction with information
gleaned about the intended victim, the eﬀect of the attack
could even get much worse. Our ﬁndings do not only call for
more stringent performance evaluation of touch-based au-
thentication systems, but should also motivate research into
technologies which could defend against the larger family of
robotic attacks, one instance of which has been demonstrat-
ed in this paper.

7. ACKNOWLEDGEMENTS

We are immeasurably indebted to Diksha Shukla, Rajesh
Kumar and Zibo Wang for their help during the design, im-
plementation and performance evaluation of the robotic at-
tack. We also thank Krystal Corbett and David Irakiza for
pointing us to play-doh as ﬁnger material. This work was
supported in part by the Louisiana Board of Regents under
P-KSFI Grant LEQSF(2007-12)- ENHPKSFI-PRS-03.

−0.2500.250.50.75100.20.40.60.81EER ChangeCDFEmpirical CDF  α = 0.2α = 0.08−0.2500.250.50.75100.20.40.60.81EER ChangeCDFEmpirical CDF  α = 0.2α = 0.08−0.2500.250.50.75100.20.40.60.81EER ChangeCDFEmpirical CDF  α = 0.2α = 0.08−0.2500.250.50.75100.20.40.60.81EER ChangeCDFEmpirical CDF  α = 0.2α = 0.086088. REFERENCES
[1] Bricx command center 3.3.

http://bricxcc.sourceforge.net/. Last accessed in
April, 2013.

[2] A gloves. original touch screen gloves.

http://www.amazon.com/Agloves-Original-
Touchscreen-Gloves-Texting/dp/B005GXMM5W. Last
accessed in April, 2013.

[3] Lego mindstorms.

http://mindstorms.lego.com/en-us/default.aspx.
Last accessed in April, 2013.

[4] Touchalytics.

http://www.mariofrank.net/touchalytics/. Last
accessed in April, 2013.

[5] Walmart. http://www.walmart.com/ip/LEGO-

Mindstorms-NXT-2.0/11081183. Last accessed in
April, 2013.

[6] A. J. Aviv, K. Gibson, E. Mossop, M. Blaze, and

J. M. Smith. Smudge attacks on smartphone touch
screens. In Proceedings of the 4th USENIX conference
on Oﬀensive technologies, WOOT’10, pages 1–7,
Berkeley, CA, USA, 2010. USENIX Association.

[7] L. Ballard, S. Kamara, F. Monrose, and M. K. Reiter.

Towards practical biometric key generation with
randomized biometric templates. In Proceedings of the
15th ACM conference on Computer and
communications security, CCS ’08, pages 235–244,
New York, NY, USA, 2008. ACM.

[8] L. Ballard, D. Lopresti, and F. Monrose. Evaluating
the security of handwriting biometrics. In The 10 th
International Workshop on the Foundations of
Handwriting Recognition, pages 461–466, 2006.

[9] L. Ballard, D. Lopresti, and F. Monrose. Forgery

quality and its implications for behavioral biometric
security. Transactions on Systems Man and
Cybernetics Part B, 37(5):1107–1118, Oct. 2007.

[10] J.-J. Cabibihan. Patient-speciﬁc prosthetic ﬁngers by

remote collaboration - a case study. CoRR,
abs/1105.1028, 2011.

[11] C. Cortes and V. Vapnik. Support-vector networks.

Machine Learning, 20(3):273–297, Sept. 1995.

[12] T. Cover and P. Hart. Nearest neighbor pattern

classiﬁcation. IEEE Transactions on Information
Theory, 13(1):21–27, Sept. 2006.

[13] A. De Luca, A. Hang, F. Brudy, C. Lindner, and

H. Hussmann. Touch me once and i know it’s you!:
implicit authentication based on touch screen patterns.
In Proceedings of the 2012 ACM annual conference on
Human Factors in Computing Systems, CHI ’12, pages
987–996, New York, NY, USA, 2012. ACM.

[14] R. D. Gibbons. Nonparametric Statistical Inference.

M. Dekker, 2nd edition, 1985.

[15] K. S. Killourhy and R. A. Maxion. Comparing

anomaly-detection algorithms for keystroke dynamics.
In DSN, pages 125–134, 2009.

[16] L. Li, X. Zhao, and G. Xue. Unobservable

reauthentication for smart phones. In Proceedings of
the 20th Network and Distributed System Security
Symposium, NDSS’13. Internet Society, 2013.

[17] F. Mario, B. Ralf, M. Eugene, M. Ivan, and S. Dawn.

Touchalytics: On the applicability of touchscreen
input as a behavioral biometric for continuous

authentication. IEEE Transactions on Information
Forensics and Security, 8(1):136–148, 2013.
[18] A. F. Martin, G. R. Doddington, T. Kamm,

M. Ordowski, and M. A. Przybocki. The det curve in
assessment of detection task performance. In Fifth
European Conference on Speech Communication and
Technology, EUROSPEECH ’97. ISCA, 1997.

[19] F. J. Massey. The Kolmogorov-Smirnov test for

goodness of ﬁt. Journal of the American Statistical
Association, 46(253):68–78, 1951.

[20] E. Mauch. Using technological innovation to improve
the problem-solving skills of middle school students:
Educators’ experiences with the lego mindstorms
robotic invention system. Clearing House,
74(4):211–214, April 2001.

[21] T. C. Meng, P. Gupta, and D. Gao. I can be you:

Questioning the use of keystroke dynamics as a
biometric. In NDSS,2013, Feb 2013.

[22] E. Owusu, J. Han, S. Das, A. Perrig, and J. Zhang.

Accessory: password inference using accelerometers on
smartphones. In Proceedings of the Twelfth Workshop
on Mobile Computing Systems and Applications,
HotMobile ’12, pages 9:1–9:6, New York, NY, USA,
2012. ACM.

[23] A. Ross, A. Rattani, and M. Tistarelli. Exploiting the

“doddington zoo” eﬀect in biometric fusion. In
Proceedings of the 3rd IEEE international conference
on Biometrics: Theory, applications and systems,
BTAS’09, pages 264–270, Piscataway, NJ, USA, 2009.
IEEE Press.

[24] N. Sae-Bae, K. Ahmed, K. Isbister, and N. Memon.

Biometric-rich gestures: a novel approach to
authentication on multi-touch devices. In Proceedings
of the 2012 ACM annual conference on Human
Factors in Computing Systems, CHI ’12, pages
977–986, New York, NY, USA, 2012. ACM.

[25] N. Sae-Bae, N. Memon, and K. Isbister. Investigating
multi-touch gestures as a novel biometric modality. In
Biometrics: Theory, Applications and Systems
(BTAS), 2012 IEEE Fifth International Conference
on, pages 156–161, 2012.

[26] A. Serwadda and V. V. Phoha. Examining a large
keystroke biometrics dataset for statistical-attack
openings. ACM Transactions on Information and
System Security, 16(2):(in press), 2013.

[27] F. Tao, L. Ziyi, C. Bogdan, B. Daining, and

S. Weidong. Continuous mobile authentication using
touchscreen gestures. In Proceedings of the 12th IEEE
Conference on Technologies for Homeland Security,
HST’12, 2012.

[28] T. Walsh. Timeless Toys: Classic Toys and the

Playmakers Who Created Them. McMeel Publishing,
2005.

[29] I. H. Witten and E. Frank. Data Mining: Practical

Machine Learning Tools and Techniques. Morgan
Kaufmann, San Francisco, 2nd edition, 2005.

[30] N. Yager and T. Dunstone. The biometric menagerie.
IEEE Transactions on Pattern Analysis and Machine
Intelligence, 32(2):220–30, 2010.

609Appendix 1: Some Robot Design Considerations
Pinion and Rack Gear: For the pinion and rack gear to
remain engaged throughout the attack, the ﬁnger and its
attached mechanism must be able to exert enough weight
on the gears. This weight however must not be too much,
but rather should be adequate to enable smooth movement
of the gears.
Play-doh Fingers: In the state in which it is purchased
from the grocery store, play-doh is too soft to make a ﬁrm
ﬁnger. We exposed the play-doh to fresh air for a few days
to enable it to harden a bit. Care must however be taken to
ensure that it does not become too hard.

Appendix 2: Performance Highlights of the Robot-
ic Attack on the Landscape Strokes

(cid:11)

0.2
0.18
0.16
0.14
0.12
0.1
0.08

SVM

k-NN

Horizontal Vertical Horizontal Vertical

592%
592%
616%
696%
703%
929%
1004%

494%
489%
523%
540%
550%
546%
546%

366%
366%
399%
395%
431%
440%
495%

395%
372%
382%
404%
421%
408%
408%

Table 3: Percentage increment in mean EER due
to the robotic impostor attack on the landscape
strokes. For each stroke type and enrollment thresh-
old (cid:11), the increment in mean EER is expressed as
a percentage of the mean EER obtained during the
zero-eﬀort attack.

Appendix 3: Statistical Signiﬁcance Tests on the
Performance of the Attack

(a) Mean and standard de-
viation of EERs obtained
for the SVM veriﬁer before
the robotic attack.

(b) Mean and standard de-
viation of EERs obtained
for the SVM veriﬁer after
the robotic attack.

(cid:11)

0.2
0.18
0.16
0.14
0.12
0.1
0.08

SVM

kNN

Horizontal Vertical Horizontal Vertical
1.81E-07
1.40E-05
7.50E-06
6.90E-07
6.69E-07
7.27E-06
1.21E-06
6.46E-06
5.10E-05
1.20E-04
1.48E-04
9.90E-05
2.71E-03
7.57E-05

8.14E-08
1.99E-07
4.53E-07
4.16E-06
1.67E-05
4.02E-05
5.30E-04

1.04E-07
2.57E-08
8.48E-08
7.38E-08
9.03E-07
1.60E-05
1.56E-05

Table 4: P values returned by the Wilcoxon signed-
rank test on the impact of the robotic attack on
the performance of the k-NN and SVM veriﬁcation
algorithms for the portrait strokes.

(c) Mean and standard de-
viation of EERs obtained
for the k-NN veriﬁer before
the robotic attack.

(d) Mean and standard de-
viation of EERs obtained
for the k-NN veriﬁer after
the robotic attack.

Figure 8: Impact of the robotic attack on the clas-
siﬁcation of the horizontal strokes generated in land-
scape mode. The error bars indicate one standard
deviation from the mean EER. The bottom axis
shows the failure to enroll thresholds, (cid:11), while the top
axis shows the number of users who are able to en-
roll for each value of (cid:11).

0.20.180.160.140.120.10.08−0.100.10.20.30.40.50.60.70.80.91.0EER Threshold: αMean EER# of Users292928252418140.20.180.160.140.120.10.08−0.100.10.20.30.40.50.60.70.80.91EER Threshold: αMean EER# of Users292928241814250.20.180.160.140.120.10.08−0.100.10.20.30.40.50.60.70.80.91EER Threshold: αMean EER# of Users292928252418140.20.180.160.140.120.10.08−0.100.10.20.30.40.50.60.70.80.91EER Threshold: αMean EER# of Users29292824181425610