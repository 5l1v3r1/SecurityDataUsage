Heavy Hitter Estimation over Set-Valued Data with Local

Differential Privacy

Zhan Qin1,3∗

zhanqin@buffalo.edu

Issa Khalil1

ikhalil@qf.org.qa

Yin Yang2

yyang@qf.org.qa

Xiaokui Xiao4

xkxiao@ntu.edu.sg

Ting Yu1

tyu@qf.org.qa

Kui Ren3

kuiren@buffalo.edu

1Qatar Computing Research Institute, Hamad Bin Khalifa University, Qatar
2College of Science and Engineering, Hamad Bin Khalifa University, Qatar

3Department of Computer Science Engineering, State University of New York at Buffalo, USA
4School of Computer Science and Engineering, Nanyang Technological University, Singapore

ABSTRACT
In local diﬀerential privacy (LDP), each user perturbs her
data locally before sending the noisy data to a data collector.
The latter then analyzes the data to obtain useful statistics.
Unlike the setting of centralized diﬀerential privacy, in LDP
the data collector never gains access to the exact values of
sensitive data, which protects not only the privacy of data
contributors but also the collector itself against the risk of
potential data leakage. Existing LDP solutions in the liter-
ature are mostly limited to the case that each user possesses
a tuple of numeric or categorical values, and the data collec-
tor computes basic statistics such as counts or mean values.
To the best of our knowledge, no existing work tackles more
complex data mining tasks such as heavy hitter discovery
over set-valued data.

In this paper, we present a systematic study of heavy hit-
ter mining under LDP. We ﬁrst review existing solutions,
extend them to the heavy hitter estimation, and explain why
their eﬀectiveness is limited. We then propose LDPMiner,
a two-phase mechanism for obtaining accurate heavy hitters
with LDP. The main idea is to ﬁrst gather a candidate set
of heavy hitters using a portion of the privacy budget, and
focus the remaining budget on reﬁning the candidate set in a
second phase, which is much more eﬃcient budget-wise than
obtaining the heavy hitters directly from the whole dataset.
We provide both in-depth theoretical analysis and extensive
experiments to compare LDPMiner against adaptations of
previous solutions. The results show that LDPMiner signif-
icantly improves over existing methods. More importantly,

∗

This work was conducted while the ﬁrst author was doing

internship at Qatar Computing Research Institute.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’16, October 24-28, 2016, Vienna, Austria
c(cid:2) 2016 ACM. ISBN 978-1-4503-4139-4/16/10. . . $15.00
DOI: http://dx.doi.org/10.1145/2976749.2978409

LDPMiner successfully identiﬁes the majority true heavy
hitters in practical settings.

Keywords
Local Diﬀerential Privacy; Heavy Hitter

1.

INTRODUCTION

Nowadays, with the advance of big data analytics, orga-
nizations have become increasingly interested in collecting
and analyzing user data. For example, web browsers and
mobile apps often collect system logs and usage patterns as
a means to guide the development of future versions; crowd-
sourcing platforms, such as Mechanical Turk1, also provide
a convenient way to collect information from contributors.
However, the collection of user data could incur signiﬁcant
privacy risks, as demonstrated in several past incidences,
e.g., [15, 32], where accidental leakage of sensitive data led to
public outrage, reputation damage, and legal actions against
the data collector.

Local diﬀerential privacy (LDP) is the state-of-the-art ap-
proach to addressing the privacy concerns in data collection,
which has been implemented in the Google Chrome browser
[12]. Its main idea is to ensure that the data collector (i)
never collects or possesses the exact values of any personal
data, and yet (ii) would still be able to derive general statis-
tics about the users. In particular, in LDP, each user locally
perturbs her data under diﬀerential privacy [10], which is a
strong and rigorous notion of privacy that provides plausi-
ble deniability; then, the user sends the perturbed data to
the collector. As such, LDP protects both the users (against
privacy risks) and the data collector itself (against damages
caused by potential privacy breaches).

However, since LDP is a relatively new concept, existing
solutions are mostly limited to obtaining statistics over a
single numeric or categorical attribute, such as select-count
[12], marginals [13] and histograms [3]. Similarly, multi-
dimensional data analysis under LDP is also limited to sim-
ple numeric or categorical attributes, or the most basic types
of aggregates, e.g., mean of each attribute [8]. As a conse-
quence, existing solutions for LDP are inadequate for more

1https://www.mturk.com

192complex types of data mining tasks. In particular, consider
the problem of identifying heavy hitters over set-valued data,
where (i) each user has a set of up to l items (e.g., web pages
browsed, movies watched, locations visited, books purchased
from an online store), and (ii) we aim to identify the top-k
most frequent items among all users. Heavy hitter discov-
ery is a well studied problem in data mining with numerous
important applications, such as marketing analysis, cyber-
attack detection and trend monitoring. As we show in Sec-
tion 3, if we extend existing solutions to the heavy hitter
problem, they would incur both prohibitively high commu-
nications overhead and low utility of result. One main rea-
son for their ineﬃciency and ineﬀectiveness is that each user
reports to the data collector much information that is not rel-
evant to the ﬁnal result, i.e., items not in the ﬁnal top-k list.
This incurs large communication costs, as well as a waste
of the privacy budget, which is a key concept in diﬀerential
privacy whose usage is negatively correlated with the utility
of results.

To address the deﬁciency of the existing solutions, we pro-
pose LDPMiner, a novel algorithm for mining heavy hitters
under local diﬀerential privacy. The main idea of LDPMiner
is to employ a two-phase framework: the ﬁrst phase iden-
tiﬁes a candidate set for the top-k frequent items, and the
second phase focuses the remaining privacy budget on reﬁn-
ing the candidates, rather than spread it over all items in
the universe. Both phases are non-trivial because (i) they
operate on set-valued data, (ii) they involve only constant
communication cost, and (iii) they achieve an error rate that
is both empirically small and asymptotically optimal. In ad-
dition, there is synergy between the two phases: a user that
reports the same items in both phases can do so with a re-
duced amount of perturbations, while still satisfying diﬀer-
ential privacy. In-depth theoretical analysis and extensive
experiments using real data conﬁrm the eﬀectiveness, eﬃ-
ciency, and practical value of LDPMiner.

The remainder of this paper is organized as follows. Sec-
tion 2 provides the background on LDP and the existing
LDP solutions for heavy hitter estimation. Section 3 formu-
lates the problem and describes naive solutions. Section 4
presents the general framework of LDPMiner and elaborates
on the algorithms used in the two phases of LDPMiner. Sec-
tion 5 presents a thorough experimental evaluation. Section
6 surveys related work. Section 7 concludes the paper with
directions for future work.

2. BACKGROUND

2.1 Local Differential Privacy

Local diﬀerential privacy (LDP) [22, 14] is a data collec-
tion framework based on -diﬀerential privacy [10]. Under
this framework, each data contributor (e.g., a user of a web-
site) locally perturbs her own data using a randomized mech-
anism that satisﬁes -diﬀerential privacy, before sending the
noisy version of her data to a data collector. Speciﬁcally, a
randomized mechanism M satisﬁes -diﬀerential privacy, if
and only if for any two neighbor databases D and D(cid:3)
(ex-
plained shortly) that diﬀer in exactly one record, and any
possible output s of M, we have the following inequality:

P r[M(D) = s]
P r[M(D(cid:3)) = s]

≤ e

(1)

Intuitively, given an output s of mechanism M, an ad-
versary cannot infer with high conﬁdence (controlled by )
whether the input database is D or its neighbor D(cid:3)
, which
provides plausible deniability for individuals involved in the
sensitive database. Here,  is a system parameter called the
privacy budget that controls the strength of privacy protec-
tion. A smaller  signiﬁes stronger privacy protection, since
the adversary has lower conﬁdence when it tries to distin-
guish between D and D(cid:3)

.

The concept of diﬀerential privacy was originally proposed
for the setting where a trusted data curator, who possesses
a database containing the exact data records from multiple
individuals, publishes perturbed statistics derived from the
database using a randomized mechanism. Hence, the deﬁni-
tion of diﬀerential privacy involves the notion of “neighbor
databases”. In contrast, in LDP, there is no trusted data cu-
rator; instead, each individual perturbs her own data record
under -diﬀerential privacy. In this situation, D and D(cid:3)
are
two singleton databases, each containing exactly one record.
Since two neighbor databases diﬀer by exactly one record,
essentially D and D(cid:3)
represent two arbitrary records. In the
problem studied in this paper (described in Section 3), ev-
ery record is a set of items, and each of D and D(cid:3)
represents
such an item set.

An important property of diﬀerential privacy is sequential

composability, which is elaborated by McSherry in [26]:

Theorem 2.1. Given t random mechanisms Mi (1 ≤ i ≤
t), each of which satisﬁes i-diﬀerential privacy. Then, the
sequence of Mi(D) satisﬁes
-diﬀerential privacy.

(cid:2)(cid:3)t

(cid:4)

i

i=1

As pointed out in [26], sequential composition applies even
when the t mechanisms are not independent, i.e., subsequent
mechanisms can incorporate the outcomes of the preceding
mechanisms. In other words, these mechanisms can be arbi-
trary functions of the input database and preceding outputs.
Since record perturbation mechanisms in LDP satisfy diﬀer-
ential privacy, they can also be sequentially composed. Ac-
cordingly, given a privacy budget , each user can partition 
into multiple portions and use each portion to release certain
randomized information under diﬀerential privacy. This is
the foundation of the proposed two-phase framework, elab-
orated in Section 4.
2.2 Existing LDP Solutions

An LDP solution includes both (i) a user-side data per-
turbation mechanism and (ii) an algorithm executed by the
data collector for computing statistical information from the
noisy data received from the users. The former one’s main
requirement is to satisfy diﬀerential privacy. Theoretically,
every diﬀerentially private mechanism can be potentially ap-
plied to the LDP setting to be run at each user. In reality,
however, most mechanisms for enforcing diﬀerential privacy
are designed to run at a central data curator who has access
to the exact records of all users, with the goal of publish-
ing perturbed statistics based on these records.
In LDP,
neither assumptions holds, since the privacy protection al-
gorithm is run by individual users who do not have access to
other user’s data, and that the information to be released is
the perturbed data, not analysis results. Consequently, al-
though the fundamental mechanisms for diﬀerential privacy
such as the Laplace mechanism [10] and the geometric mech-
anism [16] can be applied to LDP, more sophisticated ones,
e.g., for the frequent itemset mining [25], cannot be applied

193to LDP as they require global knowledge of all users’ data.
Further, perturbing the data at the user side is only part
of the solution; traditional diﬀerentially private mechanisms
do not address the other important problem in LDP, i.e.,
computing statistics at the data collector based on individ-
uals’ noisy data. Hence, conventional solutions for enforcing
diﬀerential privacy are largely inadequate for the LDP set-
ting.
In the following, we overview LDP solutions, which
have attracted signiﬁcant attention fairly recently.

Randomized Response.
It has been pointed out (e.g.,
in [12]) that a classic randomized response (RR) technique
commonly used in statistics can be adapted to LDP. Specif-
ically, RR asks each user a sensitive question whose answer
can be either yes or no, e.g., “Are you HIV positive?” The
goals are (i) that each user answers the question with plausi-
ble deniability, and (ii) that the data collector can compute
an unbiased estimate of the percentage of users whose an-
swer is “yes” (resp. “no”). To do so, each user ﬂips a coin
before answering the question. If the coin turns head, the
user provides her true answer (let’s say it is “yes”); other-
wise, she reports the opposite of her true answer (i.e., “no”).
To adapt RR to satisfy LDP, we make the coin biased, with
a probability p (resp. 1 − p) to turn head (resp. tail). It
has been proven (e.g., in [12]) that RR satisﬁes -diﬀerential
privacy with the following value of p:

p =

e

1 +e 

(2)

Next we clarify how the data collector in RR estimates
the percentage of users with an “yes” answer.
If the data
collector simply outputs the percentage of “yes” among the
noisy answers (denoted by c), the results would be biased,
due to the random perturbations performed at the users. To
correct this, the data collector reports the following adjusted
estimate:

c(cid:3)

= c × c, where c =

1

1 − 2p

(3)

RR is limited to the case where each user answers a binary
question. Nevertheless, it is a fundamental building block
for more sophisticated LDP solutions, explained below.

RAPPOR. RAPPOR [12, 13] extends RR to more com-
plex data types at the user as well as more sophisticated
statistics at the data collector. The most relevant problem
addressed by RAPPOR is frequency estimation over cate-
gorical data. Speciﬁcally, let n be the total number of users;
each user ui (1 ≤ i ≤ n) possesses exactly one item vi in a
domain containing d possible items, and the data collector
aims to estimate the frequency of each of the d items. In
RAPPOR, user ui represents vi using a length-d bit vector,
whose bits are all zero except for the vi-th bit, which is one.
Then, for each of the d bits, user ui applies RR indepen-
dently with a biased coin with probability p, whose value is
clariﬁed below. The data collector, upon receiving a length-
d bit vector from each of the n users, computes an unbiased
frequency estimate for each of the d items by applying RR
independently.

To determine the value of p (i.e., the probability that a
user reports the true value for each of the d bits), RAPPOR
utilizes an important concept in diﬀerential privacy called
sensitivity. Speciﬁcally, given an arbitrary function f , the

sensitivity Δf of f is deﬁned as

Δf = maxD,D(cid:2)(cid:3)f (D) − f (D(cid:3)

)(cid:3)1

(4)

where D and D(cid:3)
are two arbitrary neighbor databases, and
(cid:3) · (cid:3)1 represents L1 norm of a vector. In RAPPOR, D and
D(cid:3)
are two arbitrary records, i.e., any two diﬀerent items,
and f (D) (resp. f (D(cid:3)
)) is the true value of the length-d bit
vector corresponding to the item of D (resp. D(cid:3)
). Since
such a bit vector contains a single bit of one, the maximum
diﬀerence between f (D) and f (D(cid:3)
) are two bits. Hence, the
sensitivity of f is 2. Accordingly, [12] proves that RAPPOR
ensures diﬀerential privacy with the following value of p:

p =

e 

2

1 +e 

2

(5)

Comparing Equations (2) and (5), the latter calibrates
the noise according to the sensitivity of RAPPOR, i.e., 2.
We use the same methodology to extend RAPPOR to our
problem in Section 3. A main drawback of RAPPOR is
its high communication overhead, i.e., each user needs to
transmit d bits to the data collector, which can be expensive
when the number of possible itemsd is large. For instance, in
an application where each user reports its homepage to the
data collector, the number of items d is the total number
web pages in the entire Internet, leading to prohibitively
high communication costs. Further, the original proposal of
RAPPOR is limited to a single categorical attribute, and it
cannot be directly applied to our problem with set-valued
data.

Succinct histogram. Succinct histogram (SH) [3] addresses
the heavy communication problem incurred by previous so-
lutions such as RAPPOR. Speciﬁcally, SH targets the same
setting described above, i.e., each user possesses exactly one
item out of d possible items, and the data collector estimates
the frequency of each item. In particular, in SH the data
collector only reports items with relatively high frequency
values (above a given threshold); for all other items, SH
simply considers their frequency as zero. [3] proves that SH
achieves asymptotically optimal accuracy. Interestingly, no
previous work has compared SH with RAPPOR in terms of
result accuracy; we provide both theoretical and experimen-
tal comparisons between SH and RAPPOR in this paper.

SH is based on two key ideas. First, instead of reporting
d bits as is done in RAPPOR, in SH each user only reports
one randomly chosen bit. Although not explicitly stated in
[3], this idea only works when d < n, where n is the number
of users, and we show how this is done later in the paper.
Since each user reports only one bit, RR directly applies
with parameter p computed using Equation (2), which is
higher than that in RAPPOR (Equation (5)). Meanwhile,
the communication cost of SH between each user and the
data collector is O(1) rather than O(d) as in RAPPOR.

Second, in order for the ﬁrst idea to work when d > n,
SH applies random projection [5] on the data to reduce its
dimensionality from d to m = O(n) in a preprocessing step.
Speciﬁcally, SH generates a d × m matrix Φ which each ele-
ment is chosen independently and uniformly at random from
m . Note that elements in Φ
two possible values:
are essentially binary values. Then, each user multiplies its
length-d bit vector with Φ, obtaining a length-m vector. Af-
ter that, she applies the ﬁrst idea, i.e., choosing one random
bit and then releasing it using RR.

m and − 1√
1√

194(cid:1847)(cid:1871)(cid:1857)(cid:1870)(cid:3036) with  (cid:1864)(cid:3036)(cid:3)(cid:3408)(cid:3)(cid:1864)
(cid:1847)(cid:1871)(cid:1857)(cid:1870)(cid:3036) with  (cid:1864)(cid:3036)(cid:3)(cid:3407)(cid:3)(cid:1864)

17 

21 

Item set length (cid:1864)
(cid:1709) 

55 

… 

… 

22 

31 

… 

19 

67 

. 

301 

232  (cid:1635) 

1034  69 

. 

(cid:1635) 

Figure 1: Itemset padding and truncation

Speciﬁcally,

in [3], the authors prove that general his-
togram and heavy hitter estimation have the same asymp-
totic lower bound in terms of estimation error, and SH achieves
a matching upper bound. However, [3] focuses on a diﬀerent
problem setting: each user has at most one item, and the
heavy hitter set is deﬁned with a given frequency threshold.
Hence, the theoretical results in [3] do not apply to our prob-
lem. Extending SH to our problem eﬀectively is non-trivial,
which we elaborate in Section 4.2.

3. PROBLEM DESCRIPTION AND NAIVE

SOLUTIONS

Problem description. This paper focuses on heavy hit-
ter discovery and frequency estimation over set-valued data.
Speciﬁcally, each user ui possesses a set vi of items. For
simplicity, we assume that each user has a ﬁxed number l
of items, i.e., ∀i, vi = l, where l is a system parameter. If
a user has less than l items, she pads her item set vi with
dummy items, which are ignored by the data collector, i.e.,
the latter does not compute frequency of the dummy item
and does not consider it in the heavy hitter set. Conversely,
if a user possesses more than l items, she randomly draws l
samples without replacement from her item set, forming a
new set with exactly l items. If items are already in random
order in her original item set, the user can simply truncate
the set to l items, as shown in Figure 1. Because such trun-
cation loses information and introduces bias to the results,
in general l should be set to a reasonable large value so that
most users (i.e., except for a few outliers) have no more than
l items in the original data.

Let n be the total number of users, d be the total number
of diﬀerent items, and fj be the frequency of the j-th item
(denoted as vj), i.e., the portion of users possessing item vj
(1 ≤ j ≤ d). Formally, we have:

|{ui|vj ∈ vi, 1 ≤ i ≤ n}|

n

fj =

The data collector aims to ﬁnd the top-k items with the
highest frequency fj, along with the frequency estimate for
each such item. We assume that k (cid:6) d, i.e., the result only
contains the top few heavy hitters. Meanwhile, for many
applications, k is also signiﬁcantly smaller than l, the maxi-
mum number of items that each user has. The main goal is
to obtain high accuracy of the results while satisfying LDP.
Here result accuracy has two aspects. First, the relative
ranking of the top-k items should be close to their actual
ranking. Second, the error of the estimated frequencies for
the reported heavy hitters should be minimized. We elabo-
rate on the error metrics in Section 5.

Naive solutions. Next we describe two naive solutions ob-
tained by adapting RAPPOR and SH described in Section

2.2 to our problem, respectively. We ﬁrst focus on RAP-
POR. Recall that RAPPOR requires each user to send a
perturbed bit to the data collector, where the perturbation
is based on RR (also described in Section 2.2) using a biased
coin with probability p. The key, therefore, is to determine
the value of p in our problem. To do so, we analyze the sen-
sitivity of releasing a length-d bit vector at each user. Since
each user possesses exactly l items, there are exactly l ones
in the true bit vector; all other bits are zero. Therefore, two
such bit vectors can diﬀer by at most 2l bits, meaning that
the sensitivity is 2l. According to RAPPOR [12], we have:

p =

e 

2l

1 +e 

2l

(6)

Similar to the case with categorical values, RAPPOR in-
curs a transmission cost of O(d) for each user, which can
be rather expensive for large domains. Furthermore, when l
is relatively large, RAPPOR incurs rather high sensitivity,
and, thus, heavy perturbation of the released bit vectors,
leading to low accuracy.

Next we describe the adaptation of SH to our problem.
Unlike RAPPOR, SH is limited to the case where each user
possesses exactly one item.
In order to handle set-valued
data, we apply SH l times using sequential composition (re-
fer to Section 2.1). Speciﬁcally, every user divides its privacy
budget  into l equal portions of 
l each. Then, the user in-
vokes SH l times, one for each of the l items she possesses,
using privacy budget 
l . According to sequential compo-
sition, doing so for all l items satisﬁes -local diﬀerential
privacy.

The data collector receives l independent data releases
from each user. It then proceeds to generate l succinct his-
tograms which correspond to l invocations of SH. After that,
it aggregates these succinct histograms into one histogram.
j (1 ≤ j ≤ d, 1 ≤ k ≤ l) be the fre-
In particular, let f k
quency estimate for item vj from the k-th invocation of SH.
f k
The data collector returns
j as the ﬁnal frequency
estimate for item vj.

(cid:3)l

k=1

The above extension of SH incurs communication over-
head O(l) for each user, i.e., for applying SH l times with
O(1) transmissions each. Since l (cid:6) d in most applications,
this method is less expensive in terms of communications
compared to the adaptation of RAPPOR. Nevertheless, it
can still be costly for large values of l, i.e., a user can possess
a large number of items. Regarding result accuracy, when
l is large, each portion of the privacy budget 
is rather
l
small, leading to heavy perturbation and low accuracy sim-
ilarly as in RAPPOR. Worse, aggregating multiple succinct
histograms at the data collector also accumulates error. For
this reason, the accuracy performance of this method is of-
ten lower than that of RAPPOR, as we show in the analysis
in Section 4.2. Overall, neither naive approach is eﬃcient
(in terms of communications) or eﬀective (in terms of result
utility). Next we present the proposed solution LDPMiner,
which addresses these problems.

4. LDPMINER

This section presents the proposed solution LDPMiner,
which achieves both low communication overhead and high
result accuracy. The main ideas include a novel two-phase
framework, novel LDP mechanisms that are used as build-
ing blocks in these two phases, and further optimizations

195Phase 1

Users 

Randomized Data 

Collector 

Potential Heavy Hitters 

Phase 2

Randomized Data 

Top-k Heavy 

Hitters 

Figure 2: Two-Phase Framework in LDPMiner

In the following, Section 4.1
for each of the two phases.
overviews the general framework of LDPMiner. Section 4.2
presents the building blocks. Sections 4.3 and 4.4 further
optimize the two phases, respectively.
4.1 Two-Phase Framework

Recall from Section 3 that naive solutions incur high com-
munication overhead and noisy results mainly due to the fact
that each user possesses l items. In particular, naive RAP-
POR has a sensitivity proportional to l, and naive SH divides
the privacy budget into l shares; the amount of transmissions
in naive SH is also O(l). Observe that if we can reduce l,
then we can eﬀectively reduce the noise of both naive solu-
tions as well as the transmission cost of naive SH. The main
idea of the two-phase framework is to ﬁrst ﬁlter the items
and select kmax = O(k) candidate heavy hitters in the ﬁrst
phase, and then focuses on reﬁning the frequency estimates
of these candidates in the second phase. Note that k is usu-
ally considerably smaller than l, as explained in Section 3.
Figure 2 illustrates the proposed framework in LDPMiner.
Speciﬁcally, LDPMiner splits the privacy budget  at each
user into two parts 1 and 2, and allocates them to Phase I
and Phase II respectively. The whole process satisﬁes -LDP
according to the sequential composition property described
in Section 2.1. Phase I addresses exactly the same problem
as the original one, i.e., each user possesses a set of l items
and reports them under 1-diﬀerential privacy, and the data
collector computes the top kmax items with the highest fre-
quency, and outputs these items as the candidate set. After
the ﬁrst phase ﬁnishes, the data collector broadcasts the set
of candidate items to all users.

The task in Phase II also resembles the original prob-
lem, with the key diﬀerence that the universe of items be-
comes the kmax candidates, instead of the full set of d items.
In other words, the ﬁnal result consists of top-k heavy hit-
ters that are chosen exclusively among the candidates; any
item outside the kmax candidates are essentially considered
a dummy item in Phase II, and LDPMiner does not compute
the frequency of such an item. Another important distinc-
tion from Phase II and the original problem is that in the
former, each user has already transmitted data in Phase I,
and there can be overlap in the information released between
the two phases. As we show later in Section 4.4, LDPMiner
exploits such overlap between the two phases to further im-
prove accuracy.

Note that the two-phase framework in LDPMiner is ﬂex-
if we set 1 = , 2 = 0 and kmax = k, then the
ible:
second phase does not occur, and LDPMiner reduces to a
single-phase approach. In our experiments, we compare the
proposed two-phase LDPMiner with this single-phase alter-

native and demonstrate the beneﬁts of the two-phase frame-
work.
It remains to clarify the LDP mechanisms used in
Phase I and Phase II. These mechanisms are built upon a
few basic blocks, described in the next subsection.
4.2 Building Blocks

In both phases, each user needs to report her items to the
data collector, in order for the latter to derive frequency es-
timates and compute the set of candidates in Phase I and
ﬁnal heavy hitter sets in Phase II. We observe that the naive
solutions described in Section 3 are ineﬀective and ineﬃ-
cient, because each user tries to report all items she pos-
sesses, which leads to high sensitivity in naive RAPPOR,
as well as tiny privacy budget share for each item and high
communication overhead in naive SH. One key idea in the
LDPMiner building blocks, inspired by another technique
[27] for multi-dimensional data analysis under LDP, is that
each user does not report all items; instead, she chooses a
random item and reports it. Such random sampling leads to
biased item frequency estimates as each user now reports one
instead of l items. To compensate for this, the data collector
multiplies the estimated frequencies by l. As we show soon
in our analysis, this leads to an unbiased estimate of true
item frequencies. We call this approach sampling random-
izer. Algorithm 1 shows the pseudo code for the proposed
sampling randomizer method which implements the above
idea.

Algorithm 1: Sampling randomizer algorithm
Input : Privacy parameter , item setv i for each user

ui, number of heavy hitters k;

Output: Top-k heavy hitters HH k;

1 for user i → n do

2

Pick j from range [1, l] uniformly at random ; Apply
a single-item randomizer to obtain zi = R(vi[j], );
Submit zi to the data collector;
3
4 end
5 Data collector: Estimator HH k = E(
6 Return HH k;

i,j zil, );

(cid:3)

Note that Algorithm 1 is a general framework for comput-
ing heavy hitters over set-valued data under LDP; in particu-
lar, the randomizer at each user (line 2) and the heavy hitter
computation at the data collector (line 5) are left as black
boxes. These black boxes can be fulﬁlled with RAPPOR,
SH, or any method for heavy hitter estimation in the single-
item setting. We call the sampling randomizer algorithm
with RAPPOR (resp. SH) sampling RAPPOR (sampling
SH) respectively. Next we compare the result accuracy of
the naive solutions and the sampling-randomizer-based so-
lutions through theoretical analysis.

Utility Analysis. Because the accuracy of top-k set is
not easy to quantify, we analyze result utility in terms of
the mean squared error of the item frequency estimates.
Intuitively, for methods without special considerations for
the heavy hitters such as the naive solutions (Section 3)
and sampling randomizer (Algorithm 1), more accurate fre-
quency estimates are expected to lead to more accurate
heavy hitter estimation. A direct evaluation on the accu-
racy of the heavy hitter set is provided by the experiments
in Section 5.

196Analysis of naive RAPPOR. According to Section 3, the
biased coin used in naive RAPPOR has probability
e/2l+1
to turn heads. Using this probability into the similar deduc-
tion of original RAPPOR’s utility analysis, we obtain

1

Proposition 1. For the private frequency estimation un-
der naive RAPPOR and its estimator given above, for all ,
l, andn :

(cid:5)

(cid:6)

(cid:3) ˜f − f(cid:3)2

2

E

=

e/2l

n(e/2l − 1)2

Analysis of naive SH. Under naive SH, for the simplicity
and analysis, we assume that every item gets assigned to
an interference-free channel. Hence, in each one of these
channels, we run a frequency oracle and use the resulting
frequency oracle to estimate the frequencies of all the items
on the above list, which is an ideal scenario for SH. Based
on the randomization procedures described in [3], we have
the following result:

Proposition 2. For the private frequency estimation un-

(cid:8)

(cid:7)

der naive SH, for all , l, andn :
E(cid:3) ˜f − f(cid:3)2

/l − 1
c2

f n

2 =

(cid:2)

(cid:4)

1
n2

+ 4 (l − f )2 n2

e/l

m(e/l + 1)2

where m = log(d+1) log(2/β)
conﬁdence parameter in SH.

log(d)+log(2/β) (/l)2n, c/l = e/l

+1
e/l−1

, and β is a

Sampling RAPPOR and sampling SH. Unlike the naive
approaches, in sampling-randomizer-based methods the ran-
domizer enjoys full privacy budget , as well as the same sen-
sitivity as in the single-item setting. We have the following
result:

Proposition 3. For the private frequency estimation un-
der sampling RAPPOR and its estimator given, for all , l,
and n:

E(cid:3) ˜f − f(cid:3)2

2 =

l2e/2 + f (e/2 − 1)2(l − 1)

n(e/2 − 1)2

Proposition 4. For the private frequency estimation un-

(cid:9)

der sampling SH, for all , l, andn :
E(cid:3) ˜f − f(cid:3)2

 − 1
c2

+ 4

2 =

(cid:2)

(cid:4)

l2
n2

f n
l

(cid:7)

(cid:8)

1 − f
l

2

n2

e

m(e + 1)2

(cid:10)

where m = log(d+1) log(2/β)

log(d)+log(2/β) ()2n, andc  = e

+1
e−1 ,

Figure 3 plots the frequency estimation error obtained
through the above analyses as a function of the privacy
budget . Note that the vertical axis (i.e., the error) is
in logarithmic scale. According the results, the sampling-
randomizer-based methods have clear and consistent per-
formance advantages over their naive counterparts. In par-
ticular, sampling RAPPOR obtains the lowest error in its
reported frequency estimates.

In terms of communication costs, both versions of RAP-
POR require each user to transmit a length-d bit vector to
the data collector, leading to a communication cost of O(d).
Naive SH incurs O(l) transmissions as explained in Section
3. Sampling SH, on the other hand, achieves constant com-
munication cost since it invokes SH exactly once. There-
fore, sampling RAPPOR and sampling SH provide diﬀerent

)
r
o
r
r

 

E
d
e

t

a
m

i
t
s
E
(
g
o
L

8

6

4

2

0

-2

-4
0

n=200,000, l=100, d = 10000

(cid:49)(cid:68)(cid:76)(cid:89)(cid:72) RAPPOR(cid:3)
(cid:54)(cid:68)(cid:80)(cid:83)(cid:79)(cid:76)(cid:81)(cid:74) RAPPOR(cid:3)
(cid:49)(cid:68)(cid:76)(cid:89)(cid:72)(cid:3)(cid:54)(cid:43)
(cid:54)(cid:68)(cid:80)(cid:83)(cid:79)(cid:76)(cid:81)(cid:74) (cid:54)(cid:43)

1

2

3

4

5

Epsilon

6

7

8

9

10

Figure 3: Error in the frequency estimates of basic solutions

tradeoﬀs between result accuracy and communication costs.
Hence, we use both sampling-randomizer-based methods as
basic building blocks in LDPMiner.
4.3 Design of Phase I

Phase I of LDPMiner can be implemented using either
sampling RAPPOR or sampling SH, described in Section
4.2. We choose sampling SH since its communication cost is
O(1); sampling RAPPOR, on the other hand, incurs O(d)
transmissions which is prohibitively expensive for large do-
mains.

Algorithm 2 shows the complete sampling SH algorithm.
Note that the SH component is similar to the SH algo-
rithm presented in [3], and here we present the full algo-
rithm for completeness. In particular, in step 4, the random
projection matrix Φ is generated by utilizing the Johnson-
Lindenstrauss (JL) lemma [20], which states that any set
of d points in a high dimensional space can be obliviously
embedded into a pace of dimensionO (log(d)) such that this
embedding preserves pairwise distances with probability at
least 1 − β, where β is the conﬁdence parameter. For this
instance, m = log(d+1) log(2β)2
1n
√
. Note that an element in
m or −1/
x = Φbv is either 1/
m. And the utilization of
JL transform requires for the columns of Φ to be min(n, d)-
wise independent.

log(ed/β)

√

After that, the data collector aggregates each submitted
individual reports zt in its corresponding position t together:

n(cid:11)

i=1

zi

¯z =

1
n

(cid:13) − γ, where γ is an approximation parameter. We

(cid:12)
and constructs a frequency oracle F O = (Φ, ¯z). An item
v ∈ V whose frequency can be estimated through ˆf (v) =
Φxi, ¯zl
refer the reader to [3] for further details, including certain
parameter setting of frequency estimator.

Analysis. The following theorem establishes the correct-
ness of sampling SH.

Theorem 4.1. The construction of the frequency oracle

F O described above is 1-LDP.

197Algorithm 2: Sampling SH
Input : Privacy parameter 1, l-dimensional vector vi.
Output: Report pair (zj, j).

1 Uniformly pick an element v from vi;
2 Uniformly pick a position t from 1 to m;
3 if v (cid:9)=⊥ then
x = Φbv;
(cid:14)
Randomize the t-th bit xt as follows:

4

5

zt =

c1 mxt with probability e1
e1 +1
−c1 mxt with probability
1

e1 +1

where c1 = e1 +1
e1−1 ;
Uniformly pick zt ∈ {−c1

6 else
7
8 end
9 Return the pair (zt, t);

√

√

m};

m, c1

Proof. Let v1 and v2 be two arbitrary sets of items
such that |v1| = |v2| = l. Let A denote Algorithm 2,
and (zt, t) be any possible output of A. Note that zt ∈
m} and t ∈ {1, 2, . . . , m}. We will prove the
{−c1
theorem by showing that

m, c1

√

√

Pr[A(v1) = (zt, t)]
Pr[A(v2) = (zt, t)]

≤ e1 .

Let Pr[t(cid:3) | vi] denote the probability that Algorithm 2
in Line 2, when vi is the input. We have Pr[t(cid:3) |
t | t(cid:3) ∧ vi] denote
in Line 2
) eventually. We have

picks t = t(cid:3)
vi] = 1/m for any t(cid:3)
the probability that, after Algorithm 2 picks t = t(cid:3)
given vi as the input, it outputs (z(cid:3)

. In addition, let Pr[z(cid:3)

t, t(cid:3)

1

e1 + 1

≤ Pr[z(cid:3)

t | t(cid:3) ∧ vi] ≤

e1

e1 + 1

.

Therefore,

Pr[A(v1) = (zt, t)]
Pr[A(v2) = (zt, t)]

Pr[zt | t ∧ v1] · Pr[t | v1]
Pr[zt | t ∧ v2] · Pr[t | v2]
Pr[zt | t ∧ v1]
≤ e1 .
Pr[zt | t ∧ v2]

=

=

Thus, the theorem is proved.

To quantify the proposed solution’s utility, we use a stan-
dard notion of approximation for frequent item mining. We
use γ as an additive error to frequency f and fk as the fre-
quency of the k-th most frequent item in the dataset. Given
β > 0, with probability at least 1 − β, the algorithm is
(γ, β, η)-approximate, if (1) Soundness: no item in the out-
put has true frequency less than fk − γ, (2) Completeness:
all items with true frequency greater than fk + γ is in the
output, and (3) Accuracy: The noisy frequency estimated
diﬀers at most η from the true frequency.

The following theorem establishes the soundness and com-

pleteness of sampling SH, and analyzes its accuracy.

Theorem 4.2. For all β > 0, with probability at least
1 − β, all items estimated by sampling SH mechanism in
Phase I have their true frequencies > ˆfk − γ, and all items
with true frequency > ˆfk − γ are in the list, where γ =
2(e1 +1)
e1−1

(cid:15)

log(d/β)l

·

n

.

4.4 Design of Phase II

For Phase II, we can simply use sampling SH as in Phase
I. Meanwhile, since the universe of items becomes the kmax
candidates as explained in Section 4.1, sampling RAPPOR
also becomes a viable solution, whose communication cost
is now O(kmax) (cid:6) d. We refer to LDMiner with sampling
SH (resp. RAPPOR) in the second phase as LDPMiner-SH
(resp. LDP-RAPPOR).

One complication in Phase II is that the trimming of users’
answer still needs to be handled carefully. For example, the
change of item set length after trimming also contains pri-
vate information. Since user excludes non-candidate items
from their answers, the change of item set length indicates
the number of frequent items in a user’s answer. This in-
formation will give the adversary additional advantage on
certain items’ probability distribution, violating LDP. LDP-
Miner uses a relatively conservative solution for this prob-
lem: after trimming, each user needs to pad her item set to l
items with dummy items. For sampling RAPPOR, an empty
item is a length-kmax binary vector ﬁlled with zeroes. After
trimming, the user performs sampling RAPPOR or SH with
privacy parameter 2.

Optimization. There is one optimization in Phase II that
improves the accuracy of LDPMiner-SH, in which both phases
apply the sampling SH algorithm. Recall from Section 4.2
that in sampling SH, each user ui randomly chooses one item
v ∈ vi to report. The optimization applies when both phases
select the same item. This happens when (i) ui chooses item
v in Phase I; then (ii) the aggregator identiﬁes v as a top-
kmax heavy hitter; ﬁnally (iii) in Phase II , v remains in vi,
and ui again chooses v to report in its second invocation
of sampling SH. Observe that in (i) and (iii), ui reports to
the aggregator two diﬀerent perturbed versions of the same
item, i.e., v ∈ vi, under 1-LDP and 2-LDP, respectively.
In the LDPMiner algorithm descried so far, only the sec-
ond perturbed version (reported in Phase II) is used at the
aggregator, and the ﬁrst one (reported in Phase I) is simply
discarded. Consequently, the privacy budget 1 spent on v
in Phase I is wasted. To avoid this waste, we apply a spe-
cial perturbation technique in [29] in Phase II. In particular,
this technique takes as input both the exact item v and its
perturbed version reported in Phase I (using privacy budget
1), and outputs another perturbed version using privacy
budget  = 1 + 2. According to [29], the noise added in
the two phases are correlated, such that the two perturbed
releases as a whole still satisﬁes -diﬀerential privacy, thus
eliminating any waste of privacy budget, and improving the
accuracy of the second perturbed version of v. In addition,
LDPMiner applies consistent hashing [21] in the random se-
lection of items in the two phases, so that each user is more
likely to report on the same item in both phases.

Finally, the data collector integrates the users’ reports
from both phases into one frequency estimation to utilize
the overlap in the information released between two phases.
Note that to get an unbiased frequency estimation, the col-
lector needs to adjust the frequency estimation generated
from the Phase II following its estimation equations and
then multiply l− 1. After that, the ﬁnal estimation is gener-
ated by aggregating frequency estimations from two phases
together, i.e., ˆf = ( ˆf1 + (l − 1) ˆf2)/l. Then the top-k heavy
hitters in this ﬁnal estimation is the output of the whole two
phase framework.

198Analysis. The following theorem establish the correctness
of Phase II.

Theorem 4.3. The frequency estimation preocedure de-

scribed in Section 4.4 is 2-LDP.
Proof. The frequency estimation procedure described in
Section 4.4 can be regarded as an algorithm B whose input
includes (i) a set vi of l items, (ii) a privacy parameter 2,
(iii) a set Vc of kmax candidate items. The algorithm ﬁrst
trims vi by replacing any item not in Vc with a dummy item
⊥. Let v
(cid:3)
i denote the version of vi thus obtained. After that,
(cid:3)
the algorithm applies either sampling RAPPOR or SH on v
using Vc ∪ {⊥} as the item alphabet, and then submits the
i
output to the collector. We use C to denote the method
i. Note that C satisﬁes 2-LDP.
(cid:3)
applied on v
Let v1 and v2 be any two item sets with l items before
trimming, and o be any output of C submitted to the collec-
tor. We will prove the theorem by showing that

Pr[B(v1, 2,Vc) = o]
Pr[B(v2, 2,Vc) = o]

≤ e2 .

Since the trimming procedure given Vc is deterministic,

Pr[B(vi, 2,Vc) = o] = Pr[C(v

i, 2,Vc) = o].
(cid:3)

Meanwhile, since C satisﬁes 2-LDP, we have

Pr[B(v1, 2,Vc) = o]
Pr[B(v2, 2,Vc) = o]

1, 2,Vc) = o]
Pr[C(v
(cid:3)
Pr[C(v
, 2,Vc) = o]
(cid:3)
2
Therefore, the theorem is proved.

=

≤ e2 .

Theorem 4.4. The LDPMiner algorithm satisﬁes -LDP.
Proof. According to the proofs of Theorems 4.1 and 4.3,
Phase I and Phase II of LDPMiner apply to the same input
data. Speciﬁcally, for user ui, her input to Phase I is clearly
vi, i.e., her set of items. Meanwhile, vi is also ui’s input
to Phase II; note that the trimming and padding operations
on vi are a part of Phase II, which as a whole satisﬁes 2-
LDP according to Theorem 4.3. Since Phase I and Phase
II satisfy 1-LDP and 2-LDP, respectively, by sequential
composition (Theorem 2.1), applying these two mechanisms
in a sequence on the same data satisﬁes -diﬀerential privacy,
where  = 1 + 2. Thus, the theorem is proved.

Next we show the theoretical guarantees that with high
probability, the reported frequencies of the heavy hitters are
close to their true frequencies. First, we provide the error
bound of the reported heavy hitter’s frequency.

Theorem 4.5. For all β > 0, with probability at least
1 − β, the noisy frequency estimated by sampling RAPPOR
mechanism in Phase II diﬀers at most η from the true fre-
quency, where η = l2

f n log( 1

2β ).

Theorem 4.6. For all β > 0, with probability at least 1−
β, all items output by the two-phase have their true frequen-
cies > fk − γ, all items with true frequency > fk − γ are in
the list, and all noisy frequencies diﬀer by at most η from the
corresponding true frequencies, where γ = 4(e
log(d/β)
and η = l2−l

+1)
e−1

2β ) + 2(e1 +1)
e1−1

f ne2 ln( 1

(cid:15)

(cid:15)

ln(d/β)

).

nl

,

nl

Complexity analysis. In LDPMiner, the total communi-
cation cost between each user and the server isO (log(d)+k),

where d is the total number of items in the domain, and k is
the number of heavy hitters. Meanwhile, for each user, the
total computation cost for generating a randomized report
is O(k + l). The additional computation/communication
overhead of the proposed two-phase mechanism is constant
compared with a single-phase mechanism.

5. EXPERIMENTAL EVALUATION
5.1 Setup

We design experiments to study the eﬀectiveness of LDP-
Miner in terms of the accuracy of estimated heavy hitters.
In particular, we want to understand (1) how much LDP-
Miner improves over simple extension of existing LDP mech-
anisms; and (2) how key parameters would aﬀect the accu-
racy of LDPMiner’s estimation of heavy hitters. Towards
this goal, we run experiments over both synthetic and real
datasets: the synthetic datasets allow us to observe the im-
pact of data distributions on LDPMiner in a systematic way,
while the real datasets would show the utility of LDPMiner
in a more practical setting. Note that for a simple expression
in ﬁgures, LDPMiner-RAPPOR and LDPMiner-SH are ab-
breviated as LM-RP and LM-SH respectively. And sampling
RAPPOR and SH are abbreviated as RP and SH, since each
of them outperforms other naive extensions of RAPPOR and
SH respectively.
5.1.1 Datasets
Synthetic datasets. We generate two synthetic datasets
following the normal distribution and the Laplace distribu-
tion respectively. Intuitively, the more “skewed” the heavy
hitters are (i.e., the frequencies of heavy hitters are much
higher than non-heavy hitters), the stronger the signal is,
and thus the more easily for an LDP mechanism to iden-
tify heavy hitters and estimate their frequencies. Given the
same mean and standard deviation, the Laplace distribution
is more skewed than the normal distribution, which enables
us to clearly understand the impact of data distribution on
an LDP mechanism. In our experiments, the total number
of items d is set to 1000. Both distributions are with a mean
of 500 and a standard deviation of 100. Given l, the size of
an item set, for each user we randomly pick l diﬀerent items
following the target distribution. Clearly for both datasets
their heavy hitters are around item 500.
Real Datasets. We conduct experiments on two publicly
available set-valued datasets.

• AOL search log dataset [1]. This dataset contains
the keyword search histories of a subset of AOL users.
The real user names are replaced with a random user
ID. We treat each keyword as an item. The dataset
contains the search log of 647, 377 users and 2, 290, 685
diﬀerent keywords after removing stop words and per-
forming word stemming. 90% of the users have fewer
than 84 keywords in their logs.

• Kosarak dataset [2]. This dataset contains the click-
stream data of a Hungarian online news website. Each
user is associated with a set of clicked URLs. There
are 990, 002 users and 41, 270 diﬀerent URLs. 90% of
users have less than 66 URLs.

1995.1.2 Experiment Parameters
The eﬀectiveness of LDPMiner could be aﬀected by sev-

eral parameters.

n, the number of users. As a signiﬁcant amount of noise
is added to each individual user’s data in local diﬀerential
privacy, a large population would be needed to eﬀectively
remove the noise and reveal the true heavy hitters.

, the privacy budget. Though the tradeoﬀ between  and
utility is clear, due to the nature of local diﬀerential pri-
vacy, we expect that a much larger privacy budget is needed
(compared with the traditional centralized setting) in order
to have reasonable estimations of heavy hitters.

k, the number of top heavy hitters. We expect that LDP-
Miner to perform well when k is relatively small. The reason
is that in the second phase of LDPMiner the privacy budget
has to be split to estimate the frequency of each candidate
heavy hitters. Thus, a larger k would lead to less accuracy
in frequency estimation.

In our experiments, we will vary the above parameters to
study their impacts on LDPMiner. In all the experiments
below, unless explicitly stated, we use the following default
l: the 90-percentile
values for other relevant parameters:
β: 0.01 (for the ﬁrst
of the item set sizes of all users;
phase of LDPMiner). For LDPMiner, by default, the privacy
budget is split equally between the two phases.
5.1.3 Utility Metrics
Recall that the result of heavy hitter estimation is an or-
dered list of items along with their frequencies. Therefore,
its quality should be measured in two aspects: (1) how accu-
rately the estimation captures the actual set of heavy hitters
as well as their ordering; and (2) how accurately the estima-
tion captures the actual frequency of heavy hitters. In our
experiments, we use the following two metrics to cover each
aspect:
Relative Error (RE) [25]. It measures the error of esti-
mated frequencies with respect to the actual frequencies of
heavy hitters. Speciﬁcally, let V = {v1, . . . , vk} be the set
of true top-k heavy hitters.

RE = M edianvi∈V

|festimated(vi) − factual(vi)|

factual(vi)

Discounted Cumulative Gain (DCG). DCG measures
the ordering quality of top heavy hitters estimated by the
data collector [6]. The relevance, or gain, of an item vi in
the ranked list is measured using a graded relevance score
reli deﬁned as:

relvi = log2(|d − |rankactual(vi) − rankestimated(vi)||)

Intuitively, the closer vi’s estimated rank is to its true rank,
the larger is the gain. Given the true top k heavy hitters
v1, . . . , vk, the DCG of an estimated rank list is computed
as:

DCGk = relv1 +

k(cid:11)

i=2

relvi
log2(i)

The discount factor log2(i) is to give more weight to the
gain of higher ranked items. Essentially, we care more about
the correct ranking of important heavy hitters (those with
high ranks). Finally, we normalize the DCG of an estimated
ranking list by comparing it with the Ideal DCG (IDCG),
which is the DCG when the estimated ranking list is exactly

the same as the actual one (i.e., no estimation error):

N DCGk =

DCGk
IDCGk

It is easy to see that N DCGk is between 0 and 1 for allk ,
which allows us to compare the quality of estimated top-k
heavy hitters across diﬀerent k.
Competitors. For each experiment, we compare LDP-
Miner with the baseline approaches that extends RAPPOR
and SH directly. As we show in ﬁgure 3, among the several
extension schemes considered, sampling RAPPOR and SH
oﬀer the smallest variations, which we will use as baseline
approaches. For LDPMiner, we consider both LDPMiner-
SH and LDPMiner-RAPPOR (where SH and RAPPOR are
used respectively in the second phase).
5.2 Experiments with Synthetic Datasets

We ﬁrst study the impact of the number of users on the
eﬀectiveness of LDPMiner. Figure 4a shows a representative
result of LDPMiner-RAPPOR over the synthetic dataset
generated based on the normal distribution. We have 10,000
users, each with 50 items. As the mean of the normal dis-
tribution is 500, items 486 to 515 are the true top-30 heavy
hitters. The green bars show these items along with their ac-
tual frequency, and the blue candlestick bars show their fre-
quencies estimated by LDPMiner-RAPPOR with  = ln(3).
As a special notation, if an actual heavy hitter is missed by
LDPMiner (not included in the estimated top heavy hitters),
we set its candlestick bar to 0 (e.g., items 489 and 491), even
though its estimated frequency is not 0. We can see that,
when n = 10000, LDPMinor fails to capture many heavy hit-
ters, and the reported frequencies are often far away from the
real ones. The results of SH and RAPPOR are even worse
than LDPMiner, which we do not show here due to space
limit. Figure 4a shows the intrinsic challenge of local diﬀer-
ential privacy for set-valued data. If an application cannot
engage a signiﬁcant population of users to contribute, the
estimation of heavy hitters is inevitably of poor accuracy.

When the population size is increased, we see signiﬁcant
improvement of LDPMiner. Figure 4b shows a representa-
tive result of LDPMiner when we have 500,000 users instead.
It is clear that the estimation becomes very accurate, not
only that it only misses one heavy hitter but also the fre-
quency estimation of each heavy hitter is very close to the
real one. Meanwhile, ﬁgure 4c shows a representative re-
sult produced by sampling RAPPOR. Though it improves as
well, it is clearly much inferior to that of LDPMiner, which
shows the beneﬁt of the proposed two-phase approach.

The skewness aﬀects the frequency diﬀerence between heavy

hitters and other items; hence, higher skewness makes it
easier to ﬁnd the correct results. LDPMiner’s eﬀectiveness
would also be aﬀected by the skewness of heavy hitters. Fig-
ure 5a shows a representative result of LDPMiner over the
synthetic dataset generated from the Laplace distribution
with 500,000 users. Compared with Figure 4c, the skewness
of heavy hitters helps further improve estimation accuracy
of LDPMiner: no actual heavy hitters are missed, and the
frequency estimation error for each heavy hitter is further
reduced. In contrast, Figure 5b shows a representative result
of sampling RAPPOR over the same dataset. It does not
show clear improvement over that in ﬁgure 4c. The reason is
that because of the skewness, the ﬁrst phase of LDPMiner is
able to accurately capture the true top heavy hitters, which

200(cid:2)(cid:1)(cid:7)(cid:12)

(cid:2)(cid:1)(cid:6)(cid:8)(cid:12)

(cid:2)(cid:1)(cid:6)(cid:12)

(cid:11)(cid:2)(cid:1)(cid:5)(cid:8)(cid:12)
(cid:2)(cid:4)
(cid:3)(cid:4)
(cid:1)(cid:4) (cid:2)(cid:1)(cid:5)(cid:12)
(cid:10)(cid:12)
(cid:9)(cid:12) (cid:2)(cid:1)(cid:3)(cid:8)(cid:12)

(cid:2)(cid:1)(cid:3)(cid:12)

(cid:2)(cid:1)(cid:2)(cid:8)(cid:12)
(cid:4)(cid:5) (cid:1)(cid:3)(cid:2)

(cid:10)(cid:18)(cid:19)(cid:16)(cid:11)(cid:15)(cid:23)(cid:9)(cid:14)(cid:20)(cid:21)(cid:19)(cid:14)(cid:12)(cid:22)(cid:21)(cid:14)(cid:18)(cid:17)(cid:7)(cid:23) (cid:17)(cid:8)(cid:6)(cid:3)(cid:1)(cid:3)(cid:3)(cid:3)(cid:1)(cid:23)

(cid:16)(cid:8)(cid:6)(cid:3)(cid:3)(cid:1)(cid:23)(cid:20)(cid:21)(cid:13)(cid:8)(cid:4)(cid:3)(cid:3)(cid:1)(cid:23)(cid:5)(cid:8)(cid:6)(cid:3)(cid:2)(cid:23)

(cid:49)(cid:82)(cid:85)(cid:80)(cid:68)(cid:79) Distribution: n=(cid:24)(cid:19)0(cid:15)000,

m=500, std=100, l=50.

0.3

0.25

0.2

0.15

0.1

0.05

y
c
n
e
u
q
e
r
F

(cid:8)(cid:2)(cid:2)(cid:12)

(cid:1)(cid:6)(cid:3)(cid:4)(cid:8)(cid:1)(cid:5)(cid:2)(cid:3)(cid:7)(cid:8)

(cid:8)(cid:4)(cid:8)(cid:12)

0

(cid:23)(cid:27)(cid:25)

50(cid:19)

Item Index

(cid:24)(cid:20)(cid:24)

(cid:2)(cid:1)(cid:5)(cid:7)

(cid:2)(cid:1)(cid:4)(cid:6)(cid:7)(cid:3)(cid:6)
(cid:1)(cid:2) (cid:2)(cid:1)(cid:4)(cid:7)(cid:4)(cid:6)
(cid:7) (cid:2)(cid:1)(cid:3)(cid:6)(cid:7)(cid:5)(cid:6)

(cid:1)(cid:2)

(cid:2)(cid:1)(cid:3)(cid:7)(cid:1)

(cid:2)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)
(cid:4)(cid:5) (cid:1)(cid:3)(cid:2)

(cid:10)(cid:19)(cid:20)(cid:17)(cid:12)(cid:16)(cid:24) (cid:9)(cid:15)(cid:21)(cid:22)(cid:20)(cid:15)(cid:13)(cid:23)(cid:22)(cid:15)(cid:19)(cid:18)(cid:7)(cid:24)(cid:18)(cid:8)(cid:11)(cid:3)(cid:3)(cid:1)(cid:3)(cid:3)(cid:3)(cid:1)(cid:24)

(cid:17)(cid:8)(cid:6)(cid:3)(cid:3)(cid:1)(cid:24)(cid:21)(cid:22)(cid:14)(cid:8)(cid:4)(cid:3)(cid:3)(cid:1)(cid:24)(cid:5)(cid:8)(cid:6)(cid:3)(cid:24)(cid:2)(cid:2)(cid:24)

(cid:2)(cid:1)
(cid:2)(cid:8)(cid:4)(cid:8)
(cid:1)(cid:2) (cid:1)(cid:2)(cid:3)

(cid:2)(cid:3)(cid:1)(cid:4)
(cid:1)(cid:2)

(cid:5)(cid:6)(cid:8)

(cid:1)(cid:2)

(cid:1)(cid:2)(cid:3)
(cid:7)(cid:6)(cid:1)(cid:2) (cid:1)(cid:2) (cid:3)(cid:4)(cid:5)

(cid:3)(cid:4)(cid:8)

(cid:1)

(cid:2)

(cid:1)(cid:2)

(cid:3)(cid:1)(cid:1)(cid:4)

(cid:1)(cid:7)(cid:4)(cid:5)(cid:9)(cid:2)(cid:6)(cid:3)(cid:4)(cid:8)(cid:9)

(cid:3)(cid:2)(cid:3)(cid:4)

(a) LDPMiner-RAPPOR

(b) LDPMiner-RAPPOR

(c) Sampling RAPPOR

Figure 4: Experimental results over synthetic datasets generated from a normal distribution

(cid:10)(cid:11)(cid:21)(cid:17)(cid:11)(cid:13)(cid:15)(cid:26)(cid:9)(cid:16)(cid:23)(cid:24)(cid:22)(cid:16)(cid:12)(cid:25)(cid:24)(cid:16)(cid:20)(cid:19)(cid:7)(cid:26)(cid:19)(cid:8)(cid:6)(cid:3)(cid:3)(cid:1)(cid:3)(cid:3)(cid:3)(cid:1)(cid:26)

(cid:6)(cid:4)(cid:7)(cid:11)(cid:1)(cid:5)(cid:12)(cid:2)(cid:13)(cid:1)(cid:14)(cid:3)(cid:15)(cid:2)(cid:16)(cid:1)(cid:17)(cid:3)(cid:18)(cid:19)

(cid:18)(cid:8)(cid:6)(cid:3)(cid:3)(cid:1)(cid:26)(cid:23)(cid:24)(cid:14)(cid:8)(cid:4)(cid:3)(cid:3)(cid:1)(cid:26)(cid:5)(cid:8)(cid:6)(cid:3)(cid:2)(cid:26)

(cid:2)

(cid:1)

(cid:2)(cid:1)(cid:4)(cid:5)(cid:8)

(cid:7)(cid:8) (cid:2)(cid:1)(cid:4)
(cid:1)(cid:3)
(cid:1)(cid:2)
(cid:2)(cid:3)
(cid:6)(cid:2)(cid:1)(cid:3)(cid:5)(cid:8)
(cid:2)(cid:3)
(cid:1)(cid:2)

(cid:2)(cid:1)(cid:3)(cid:8)

(cid:2)(cid:1)(cid:2)(cid:5)(cid:8)

(cid:1)

y
c
n
e
u
q
e
r
F

(cid:1)

(cid:47)(cid:68)(cid:83)(cid:79)(cid:68)(cid:70)(cid:72) Distribution: n=(cid:24)(cid:19)0(cid:15)000,

m=500, std=100, l=50.

0.3

0.25

0.2

0.15

0.1

0.05

Privacy Budget Allocation

Normal
Laplace

4

3.5

3

2.5

E
R

2

1.5

1

0.5

0

(cid:23)(cid:27)(cid:25)

50(cid:19)

Item Index

(cid:24)(cid:20)(cid:24)

0
0.1

0.2

0.3

0.4

0.6

0.7

0.8

0.9

0.5
(cid:1)

(cid:12)(cid:16) (cid:14)(cid:4)(cid:8)(cid:16)(cid:7)(cid:1)(cid:5)(cid:6)(cid:2)(cid:3)(cid:10)(cid:15)(cid:4)(cid:11)(cid:9)(cid:16)(cid:13)(cid:16)(cid:2)(cid:4)(cid:3)(cid:5)
(cid:5)(cid:3)(cid:5)(cid:8)

(cid:5)(cid:2)(cid:2)(cid:8)

(cid:8)(cid:10)(cid:9)(cid:20)

(cid:1)(cid:7)(cid:4)(cid:5)(cid:9)(cid:2)(cid:6)(cid:3)(cid:4)(cid:8)(cid:9)

(a) LDPMiner-RAPPOR

(b) Sampling RAPPOR

(c) LDPMiner-RAPPOR

Figure 5: (a) and (b) show the experimental results over synthetic datasets following the Laplace distribution. (c) shows the
measured Relative Error of two synthetic datasets (normal and Laplace) with diﬀerent privacy budget allocation strategies

means even less privacy budget is spent on non heavy hitters
in the second phase. For sampling RAPPOR, as the privacy
budget is spread evenly over all items, it cannot take advan-
tage of the skewness of heavy hitters.

In the above experiments, we evenly split the privacy bud-
get between the two phases of LDPMiner. One may wonder
what would be the impact if we split the budget diﬀerently.
Intuitively, we can imagine that when we allocate too little
budget to the ﬁrst phase, according to Theorem 4.2, the can-
didate heavy hitter set would be much larger, which means
that the second phase’s privacy budget would need to be
spread thin over all these candidate items. On the other
hand, if the second phase gets too little budget, though the
candidate set from the ﬁrst phase would be smaller, their fre-
quency estimation would be very noisy, due the limited bud-
get we can spend on each candidate item. Figure 5c shows
the Relative Error of the results of LDPMiner over both the
normal-distribution and the Laplace-distribution synthetic
dataset as described above with n = 500, 000. x-axis is the
percentage of the budget allocated to the ﬁrst phase of LDP-
Miner. It is clear that the relative error is minimized when
we split the budget roughly evenly. We have conducted the
same experiments with other setting and using the NDCG
metrics, obtaining similar observations. Thus, for the rest of
the experiments in this paper, we always allocate the same
amount of budget for each phase of LDPMiner.

5.3 Experiments with Real Datasets
5.3.1 The impact of 
In this experiment, for both datasets, we ﬁx k = 10 and
report the utility measures of diﬀerent LDP mechanisms
when varying . Figure 6 shows the relative errors over
both datasets along with the change of . Not surprisingly,
for all four algorithms, the larger , the lower their relative
errors. Meanwhile, we see that LDPMiner-RAPPOR and
LDPMiner-SH consistently achieve much lower relative er-
rors than sampling RAPPOR and sampling SH. For most ,
the relative errors of single-phase approaches is almost twice
that of LDPMiner.

Another observation is that LDPMiner-RAPPOR consis-
tently outperforms LDPMiner-SH, which shows the utility
gain by tolerating a little more extra communication cost (k
bits vs. 1 bit per each user’s response), when using RAP-
POR instead of SH in the second phase of LDPMiner. We
also observe that sampling RAPPOR is superior to sam-
pling SH. However, this utility gain is associated with pro-
hibitively communication cost. We have similar observations
when the utility of estimated heavy hitters is measured using
NDCG, as shown in Figure 7.
5.3.2 The impact of k
In this experiment, we ﬁx  = 3 and vary the size of re-
ported heavy hitters, i.e., k, to study its impact on the utility

201E
R

0.5
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0

0

(cid:47)(cid:48)-(cid:53)(cid:51)
(cid:47)(cid:48)-(cid:54)(cid:43)
R(cid:51)
(cid:54)(cid:43)
2

1

AOL: k=10

3

4

5

Epsilon

6

7

8

9

10

(cid:40)
(cid:53)

(cid:19)(cid:17)(cid:24)
(cid:19)(cid:17)(cid:23)(cid:24)
(cid:19)(cid:17)(cid:23)
(cid:19)(cid:17)(cid:22)(cid:24)
(cid:19)(cid:17)(cid:22)
(cid:19)(cid:17)(cid:21)(cid:24)
(cid:19)(cid:17)(cid:21)
(cid:19)(cid:17)(cid:20)(cid:24)
(cid:19)(cid:17)(cid:20)
(cid:19)(cid:17)(cid:19)(cid:24)
(cid:19)

(cid:19)

(cid:47)(cid:48)(cid:16)(cid:53)(cid:51)
(cid:47)(cid:48)(cid:16)(cid:54)(cid:43)(cid:3)
(cid:53)(cid:51)
(cid:54)(cid:43)
(cid:21)

(cid:20)

Korasak: k=10

(cid:22)

(cid:23)

(cid:24)

(cid:40)(cid:83)(cid:86)(cid:76)(cid:79)(cid:82)(cid:81)

(cid:25)

(cid:26)

(cid:27)

(cid:28)

(cid:20)(cid:19)

(a) AOL: RE

(b) Kosarak: RE

(cid:21)(cid:17)(cid:21)(cid:24)

(cid:20)(cid:17)(cid:26)(cid:24)

(cid:20)(cid:17)(cid:24)

(cid:20)(cid:17)(cid:21)(cid:24)

(cid:40)
(cid:53)

(cid:20)

(cid:19)(cid:17)(cid:26)(cid:24)

(cid:19)(cid:17)(cid:24)

0.(cid:21)5

0

0

(cid:36)(cid:50)(cid:47)(cid:3)(cid:39)(cid:68)(cid:87)(cid:68)(cid:86)(cid:72)(cid:87): (cid:40)(cid:83)(cid:86)(cid:76)(cid:79)(cid:82)(cid:81)(cid:32)(cid:22)(cid:3)

(cid:47)(cid:48)-R(cid:51)(cid:3)
(cid:47)(cid:48)-(cid:54)(cid:43)
R(cid:51)
(cid:54)(cid:43)

(cid:20)

(cid:19)(cid:17)(cid:27)

(cid:19)(cid:17)(cid:25)

(cid:19)(cid:17)(cid:23)

(cid:19)(cid:17)(cid:21)

(cid:40)
(cid:53)

(cid:46)(cid:82)(cid:86)(cid:68)(cid:85)(cid:68)(cid:78)(cid:3)(cid:39)(cid:68)(cid:87)(cid:68)(cid:86)(cid:72)(cid:87): (cid:40)(cid:83)(cid:86)(cid:76)(cid:79)(cid:82)(cid:81)(cid:32)(cid:22)(cid:3)
(cid:47)(cid:48)(cid:16)(cid:53)(cid:51)
(cid:47)(cid:48)(cid:16)(cid:54)(cid:43)
(cid:53)(cid:51)
(cid:54)(cid:43)

5

10

15

20
(cid:78)

25

30

35

40

(cid:19)

(cid:19)

(cid:24)

(cid:20)(cid:19)

(cid:21)(cid:19)

(cid:21)(cid:24)

(cid:22)(cid:19)

(cid:20)(cid:24)
(cid:78)

(a) AOL: RE

(b) Kosarak: RE

Figure 6: Varying : Relative Error for Real Datasets

Figure 8: Varying k: Relative Error for Real datasets

G
C
D
(cid:49)

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0

AOL: k=10

(cid:47)(cid:48)-(cid:53)(cid:51)
(cid:47)(cid:48)-(cid:54)(cid:43)
R(cid:51)
(cid:54)(cid:43)

1

2

3

4

5

Epsilon

6

7

8

9

10

G
C
D
(cid:49)

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0

Kosarak: k=10

(cid:47)(cid:48)-(cid:53)(cid:51)(cid:3)
(cid:47)(cid:48)-(cid:54)(cid:43)
R(cid:51)
(cid:54)(cid:43)

1

2

3

4

5

Epsilon

6

7

8

9

10

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0

(cid:42)
(cid:38)
(cid:39)
(cid:49)

(cid:36)(cid:50)(cid:47)(cid:3)(cid:39)(cid:68)(cid:87)(cid:68)(cid:86)(cid:72)(cid:87): (cid:40)(cid:83)(cid:86)(cid:76)(cid:79)(cid:82)(cid:81)(cid:32)(cid:22)

(cid:47)(cid:48)-(cid:53)(cid:51)
(cid:47)(cid:48)-(cid:54)(cid:43)(cid:3)
(cid:53)(cid:51)
(cid:54)(cid:43)

5

10

15

20
(cid:78)

25

30

35

40

(cid:42)
(cid:38)
(cid:39)
(cid:49)

(cid:19)(cid:17)(cid:28)
(cid:19)(cid:17)(cid:27)
(cid:19)(cid:17)(cid:26)
(cid:19)(cid:17)(cid:25)
(cid:19)(cid:17)(cid:24)
(cid:19)(cid:17)(cid:23)
(cid:19)(cid:17)(cid:22)
(cid:19)(cid:17)(cid:21)
(cid:19)(cid:17)(cid:20)
(cid:19)
(cid:19)

(cid:46)(cid:82)(cid:86)(cid:68)(cid:85)(cid:68)(cid:78)(cid:3)(cid:39)(cid:68)(cid:87)(cid:68)(cid:86)(cid:72)(cid:87)(cid:29)(cid:3)(cid:40)(cid:83)(cid:86)(cid:76)(cid:79)(cid:82)(cid:81)(cid:32)(cid:22)(cid:3)

(cid:47)(cid:48)(cid:16)(cid:53)(cid:51)
(cid:47)(cid:48)(cid:16)(cid:54)(cid:43)
(cid:53)(cid:51)
(cid:54)(cid:43)

(cid:24)

(cid:20)(cid:19)

(cid:20)(cid:24)

(cid:21)(cid:19)
(cid:78)

(cid:21)(cid:24)

(cid:22)(cid:19)

(cid:22)(cid:24)

(cid:23)(cid:19)

(a) AOL: NDCG

(b) Kosarak: NDCG

(a) AOL: NDCG

(b) Kosarak: NDCG

Figure 7: Varying : Normalized Discounted Cumulative
Gain for Real datasets

Figure 9: Varying : Normalized Discounted Cumulative
Gain for Real Datasets

of each algorithm. The results are shown in Figures 8 and 9.
As expected, for all approaches their utility measures de-
crease when k increases. We also observe that the advantage
of LDPMiner compared to single-phase approaches is much
more signiﬁcant when k is small. Further, when k keeps in-
creasing (for example when k > 30 for the AOL dataset), the
relative error of LDPMiner becomes even higher than single-
phase based approaches. Intuitively, the proposed two-phase
framework improves the utility by reducing the size of item
sets from l to O(k), the size of candidate heavy hitter set
generated in the ﬁrst phase. When k increases, the size of
candidate sets becomes closer to l, and the utility gain due
to the trimmed candidate set is oﬀset by the utility loss
caused by budget splitting. However, it is interesting to see
that for the AOL dataset when k is larger than 30, though
the relative errors of LDPMiner are higher than sampling
RAPPOR, LDPMiner still achieves better NDCG. This ob-
servation is even clearer for the Kosarak dataset. Recall
that the relative error reﬂects the quality of frequency esti-
mation while NDCG reﬂects the quality of the ranked list
of heavy hitters. The above observation suggests that when
k increases, though the frequency estimation of LDPMiner
deteriorates, it still manages to better preserve the relative
orders among heavy hitters.
6. RELATED WORK

As discussed in Section 2, a series of works study the
problem of frequency estimation following local diﬀerential
privacy [3, 9, 19, 22]. After Warner’s ﬁrst study [28] on
randomized response method, many works have explored a
variety of perturbation mechanisms for achieving theoretical
optimal utility. In [22], the local privacy model is ﬁrst for-
malized. A recent work by Duchi et al. [9] shows an upper
bound under the LDP setting, using information theoretic

converse techniques to provide a minimax-error bound on
convex statistical estimation. Hsu et al. [19] focus on es-
timating heavy hitters based on the general technique of
random projection and concentration of measure. Following
this work, Bassily et al. [3] propose an eﬃcient protocol for
succinct histogram estimation with information-theoretical
optimal error. To handle the practical issues for private dis-
tribution estimation, RAPPOR [12, 13] is proposed to gen-
eralize Warner’s randomizer from binary alphabets to k-ary
alphabets. In [11], private estimation of frequent elements
from stream data is studied in a setting called ”pan-privacy”,
which can be considered as a variant of the LDP model.

Quite a few works focus on publishing histogram and
count queries under the centralized diﬀerential privacy model.
Hay et al. [17] generate diﬀerentially private histograms through
hierarchical partitioning of data. Moreover, wavelet trans-
form is utilized to handle multi-dimensional dataset in [30].
Li et al. [23] propose a query matrix framework that gen-
eralizes the above two works while incurring high computa-
tional complexity. Xu et al. [31] propose a two-phase kd-
tree based spatial decomposition mechanism to publish his-
tograms. Moreover, Li et al. [24] addresse the problem of
releasing histograms for dynamic datasets using sparse vec-
tor technique. He et al. [18] propose a ﬂexible policy where
users can specify sensitive information for releasing cumula-
tive histograms. In addition, there is also a rich literature
on frequent itemset mining. Among them, several works are
relevant to our work. Bhaskar et al. [4] also propose a two-
phase based approach using a truncated frequency thresh-
old to shrink the candidate list of frequent itemsets. This
work also conﬁrms the eﬀectiveness of two-phase approach
in a centralized model.
Inspired by [4], Li et al. propose
to improve the utility by constructing a basis set privately.
In addition, Chen et al. [7] study the publication of set-

202valued dataset under diﬀerential privacy. They present a
tree structured partition mechanism in a top-down fashion.
However, all above mechanisms require global knowledge of
the dataset, which makes them not applicable under local
diﬀerential privacy. We remark that though not all tech-
niques developed for a centralized model is suitable to a
local model, the ideas behind these technique still might be
helpful in designing mechanisms in a LDP model.

7. CONCLUSIONS AND FUTURE WORK
In this paper, we study heavy hitter estimation under lo-
cal diﬀerential privacy over set-valued data. We ﬁrst review
existing LDP techniques and study direct extension of these
techniques to handle set-valued data. Our theoretical and
experimental analysis shows that such extensions would ei-
ther suﬀer from high communication overhead or low result
utility. To address the problem, we propose LDPMiner, a
two-phase framework: a candidate set of heavy hitters is
identiﬁed by data collector in the ﬁrst phase, so that each
participant is able to reﬁne the frequency report of items in
the candidate set in the second phase.Both theoretical analy-
sis and extensive experiments conﬁrm the utility, eﬃciency,
and practicality of LDPMiner. A natural venue built on
LDPMiner is to study frequent itemset mining under local
diﬀerential privacy. The challenge is that direct adoption of
existing frequent itemset mining algorithm would require it-
erative information exchange between users and data collec-
tors, which would result in accumulation of dramatic noise
due to the limited budget for each iteration.

8. ACKNOWLEDGMENTS

Xiaokui Xiao was supported by grant ARC19/14 from

MOE, Singapore.

9. REFERENCES
[1] Aol search log.

http://www.gregsadetsky.com/aol-data/.

[2] Spmf: An open-source data mining library.

http://www.philippe-fournier-viger.com/spmf.

[3] R. Bassily and A. D. Smith. Local, private, eﬃcient

protocols for succinct histograms. In STOC, pages
127–135, 2015.

[4] R. Bhaskar, S. Laxman, A. Smith, and A. Thakurta.

Discovering frequent patterns in sensitive data. In
SIGKDD, pages 503–512, 2010.

[5] A. Blum, K. Ligett, and A. Roth. A learning theory
approach to noninteractive database privacy. JACM,
60(2):12, 2013.

[6] C. Burges et al. Learning to rank using gradient

descent. In ICML, pages 89–96, 2005.

[7] R. Chen et al. Publishing set-valued data via

diﬀerential privacy. PVLDB, 4(11):1087–1098, 2011.

[8] J. C. Duchi, M. I. Jordan, and M. J. Wainwright.
Privacy aware learning. J. ACM, 61(6):38:1–38:57.
[9] J. C. Duchi, M. I. Jordan, and M. J. Wainwright.

Local privacy and statistical minimax rates. In FOCS,
pages 429–438, 2013.

[10] C. Dwork. Diﬀerential privacy: A survey of results. In

Theory and applications of models of computation,
pages 1–19. 2008.

[11] C. Dwork, M. Naor, T. Pitassi, G. N. Rothblum, and

S. Yekhanin. Pan-private streaming algorithms. In
ICS, pages 66–80, 2010.

[12] ´U. Erlingsson et al. Rappor: Randomized aggregatable

privacy-preserving ordinal response. In CCS, pages
1054–1067, 2014.

[13] G. Fanti et al. Building a rappor with the unknown:
Privacy-preserving learning of associations and data
dictionaries. PoPETS, issue 3, 2016, 2016.

[14] A. Gupta, M. Hardt, A. Roth, and J. Ullman.

Privately releasing conjunctions and the statistical
query barrier. SICOMP, 42(4):1494–1520, 2013.

[15] S. Hansell. Aol removes search data on vast group of

web users. New York Times, 8:C4, 2006.

[16] M. Hardt and K. Talwar. On the geometry of

diﬀerential privacy. In STOC, pages 705–714, 2010.
[17] M. Hay et al. Boosting the accuracy of diﬀerentially

private histograms through consistency. PVLDB,
3(1-2):1021–1032, 2010.

[18] X. He, A. Machanavajjhala, and B. Ding. Blowﬁsh

privacy: Tuning privacy-utility trade-oﬀs using
policies. In SIGMOD, pages 1447–1458, 2014.

[19] J. Hsu, S. Khanna, and A. Roth. Distributed private

heavy hitters. In Automata, Languages, and
Programming, pages 461–472. 2012.

[20] W. B. Johnson and J. Lindenstrauss. Extensions of

lipschitz mappings into a hilbert space. Contemporary
mathematics, 26(189-206):1, 1984.

[21] D. Karger et al. Consistent hashing and random trees:

Distributed caching protocols for relieving hot spots
on the world wide web. In STOC, pages 654–663, 1997.

[22] S. P. Kasiviswanathan et al. What can we learn

privately? SICOMP, 40(3):793–826, 2011.

[23] C. Li et al. Optimizing linear counting queries under

diﬀerential privacy. In PODS, pages 123–134, 2010.

[24] H. Li et al. Diﬀerentially private histogram

publication for dynamic datasets: an adaptive
sampling approach. In CIKM, pages 1001–1010, 2015.

[25] N. Li, W. Qardaji, D. Su, and J. Cao. Privbasis:
Frequent itemset mining with diﬀerential privacy.
PVLDB, 5(11):1340–1351, 2012.

[26] F. D. McSherry. Privacy integrated queries: an
extensible platform for privacy-preserving data
analysis. In SIGMOD, pages 19–30, 2009.

[27] T. T. Nguyˆen et al. Collecting and analyzing data

from smart device users with local diﬀerential privacy.
arXiv preprint arXiv:1606.05053, 2016.

[28] S. L. Warner. Randomized response: A survey

technique for eliminating evasive answer bias. Journal
of the ASA, 60(309):63–69, 1965.

[29] X. Xiao, Y. Tao, and M. Chen. Optimal random
perturbation at multiple privacy levels. PVLDB,
2(1):814–825, 2009.

[30] X. Xiao, G. Wang, and J. Gehrke. Diﬀerential privacy
via wavelet transforms. TKDE, 23(8):1200–1214, 2011.

[31] J. Xu et al. Diﬀerentially private histogram

publication. VLDBJ, 22(6):797–822, 2013.

[32] Y. Zhou, D. Wilkinson, R. Schreiber, and R. Pan.

Large-scale parallel collaborative ﬁltering for the
netﬂix prize. In Algorithmic Aspects in Information
and Management, pages 337–348. 2008.

203