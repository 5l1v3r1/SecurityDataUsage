2016 IEEE Symposium on Security and Privacy

(State of) The Art of War:

Offensive Techniques in Binary Analysis

Yan Shoshitaishvili, Ruoyu Wang, Christopher Salls, Nick Stephens, Mario Polino, Andrew Dutcher,

John Grosen, Siji Feng, Christophe Hauser, Christopher Kruegel, Giovanni Vigna
{yans,ﬁsh,salls,stephens,mario,dutcher,jmg,slipper,christophe,chris,vigna}@cs.ucsb.edu

UC Santa Barbara

Abstract—Finding and exploiting vulnerabilities in binary
code is a challenging task. The lack of high-level, semantically
rich information about data structures and control constructs
makes the analysis of program properties harder to scale.
However, the importance of binary analysis is on the rise. In
many situations binary analysis is the only possible way to prove
(or disprove) properties about the code that is actually executed.
In this paper, we present a binary analysis framework that
implements a number of analysis techniques that have been
proposed in the past. We present a systematized implementation
of
to
compose them and develop new approaches. In addition, the
implementation of these techniques in a unifying framework
allows for the direct comparison of
these approaches and
the identiﬁcation of their advantages and disadvantages. The
evaluation included in this paper is performed using a recent
dataset created by DARPA for evaluating the effectiveness of
binary vulnerability analysis techniques.

techniques, which allows other

researchers

Our framework has been open-sourced and is available to

these

the security community.

I. INTRODUCTION

this. First,

Despite the rise of interpreted languages and the World
Wide Web, binary analysis has remained an extremely
topic in computer security. There are several
important
interpreted languages are either
reasons for
interpreted by binary programs or
(JIT)
compiled down to binary code. Second, “core” OS constructs
and performance-critical applications are still written in
languages (usually, C or C++) that compile down to binary
code. Third, the rise of the Internet of Things is powered
by devices that are,
in general, very resource-constrained.
Without cycles to waste on interpretation or Just-In-Time
compilation, the ﬁrmware of these devices tends to be written
in languages (again, usually C) that compile to binary.

Just-In-Time

Unfortunately, many low-level

languages provide few
security guarantees, often leading to vulnerabilities. For
example, buffer overﬂows stubbornly remain as one of the
most-common software ﬂaws despite a concerted effort to
develop technologies to mitigate such vulnerabilities. Worse,
the wider class of “memory corruption vulnerabilities”, the
vast majority of which also stem from the use of unsafe
languages, make up a substantial portion of the most common
vulnerabilities [2]. This problem is not limited to software
on general-purpose computing devices: remotely-exploitable
vulnerabilities have been discovered in devices ranging from
smartlocks, to pacemakers, to automobiles [10].

Another important aspect to consider is that compilers and
tool chains are not bug-free. Properties that were proven by
analyzing the source code of a program may not hold after
the very same program has been compiled [56]. This happens
in practice: recently, a malicious version of Xcode, known
as Xcode Ghost [3], silently infected over 40 popular iOS
applications by inserting malicious code at compile time,
compromising the devices of millions of users. These vulnera-
bilities have serious, real-world consequences, and discovering
them before they can be abused is paramount. To this end, the
security research community has invested a substantial amount
of effort in developing analysis techniques to identify ﬂaws
in binary programs [55]. Such “offensive” (because they ﬁnd
“attacks” against the analyzed application) analysis techniques
vary widely in terms of the approaches used and the vulnera-
bilities targeted, but they suffer from two main problems.

First, many implementations of binary analysis techniques
begin and end their existence as a research prototype. When
this happens, much of the effort behind the contribution
is wasted, and future researchers must often start
from
scratch in terms of implementation of work based upon these
approaches. This startup cost discourages progress: every
week spent re-implementing previous techniques is one less
week devoted to developing novel solutions.

Second, as a consequence of the amount of work required
to reproduce these systems and their frequent unavailability
to the public, replicating their results becomes impractical.
As a result, the applicability of individual binary analysis
techniques relative to other techniques becomes unclear. This,
along with the inherent complexity of modern operating
systems and the difﬁculty to accurately and consistently
model the applications’ interaction with their environment,
makes it extremely difﬁcult to establish a common ground
for comparison. Where comparisons do exist, they tend to
compare systems with different underlying implementation
details and different evaluation datasets.

In an attempt to mitigate the ﬁrst issue, we have created
angr, a binary analysis framework that integrates many of
the state-of-the-art binary analysis techniques in the literature.
We did this with the goal of systematizing the ﬁeld and en-
couraging the development of next-generation binary analysis
techniques by implementing, in an accessible, open, and usable
way, effective techniques from current research efforts so that
they can be easily compared with each other. angr provides

© 2016, Yan Shoshitaishvili. Under license to IEEE.
DOI 10.1109/SP.2016.17

138

building blocks for many types of analyses, using both static
and dynamic techniques, so that proposed research approaches
can be easily implemented and their effectiveness compared
to each other. Additionally, these building blocks enable the
composition of analyses to leverage their different strengths.
Over the last year, a solution has also been introduced
to the second problem, aimed towards comparing analysis
techniques and tools, with research reproducibility in mind.
Speciﬁcally, DARPA organized the Cyber Grand Challenge,
a competition designed to explore the current state of
automated binary analysis, vulnerability excavation, exploit
generation, and software patching. As part of this competition,
DARPA wrote and released a corpus of applications that
are speciﬁcally designed to present realistic challenges to
automated analysis systems and produced the ground truth
(labeled vulnerabilities and exploits) for these challenges. This
dataset of binaries provides a perfect test suite with which
to gauge the relative effectiveness of various analyses that
have been recently proposed in the literature. Additionally,
during the DARPA CGC qualifying event, teams around the
world ﬁelded automated binary analysis systems to attack and
defend these binaries. Their results are public, and provide an
opportunity to compare existing offensive techniques in the
literature against the best that the competitors had to offer1.
Our goal is to gain an understanding of the relative efﬁcacy
of modern offensive techniques by implementing them in our
binary analysis system. In this paper, we detail the implemen-
tation of a next-generation binary analysis engine, angr. We
present several offensive analyses that we developed using
these techniques (speciﬁcally,
replications of approaches
currently described in the literature) to reproduce results
in the ﬁelds of vulnerability discovery, exploit replaying,
automatic exploit generation, compilation of ROP shellcode,
and exploit hardening. We also describe the challenges that
we overcome, and the improvements that we achieved, by
combining these techniques to augment
their capabilities.
By implementing them atop a common analysis engine, we
can explore the differences in effectiveness that stem from
the theoretical differences behind the approaches, rather than
implementation differences of the underlying analysis engines.
This has enabled us to perform a comparative evaluation of
these approaches on the dataset provided by DARPA.

In short, we make the following contributions:
1) We reproduce many existing approaches in offensive
binary analysis,
to
provide an understanding of the relative effectiveness of
current offensive binary analysis techniques.
(and solutions

in a single, coherent framework,

2) We show the difﬁculties

difﬁculties) of
techniques and applying them on a large scale.

to those
combining diverse binary analysis

3) We open source our framework, angr, for the use of
future generations of research into the analysis of binary
code.

1The top-performing 7 teams each won a prize of 750, 000 USD. We
expect that, with this motivation, the teams ﬁelded the best analyses that
were available to them.

II. AUTOMATED BINARY ANALYSIS

Researchers have been striving toward automated binary
analysis techniques for many years. However, despite recent
advances in this ﬁeld, such systems are challenging to develop
and deploy in the real world. This is because, depending
on the technique in question, there are serious limitations
that must be overcome to perform automated analysis on
real-world software. In this section, we will touch on the
challenges of automated analysis and discuss why the DARPA
Cyber Grand Challenge contest can provide a meaningful
way to compare different analysis approaches.

A. Trade-offs

It is not hard to see why binary analysis is challenging:
in a sense, asking “will it crash?” is analogous to asking
“will it stop?”, and any such analysis quickly runs afoul of
the halting problem [32]. Program analyses, and especially
offensive binary analyses,
tend to be guided by carefully
balanced theoretical trade-offs to maintain feasibility. There
are two main areas where such trade-offs must be made:
Replayability. Bugs are not all created equal. Depending
on the trade-offs made by the system, bugs discovered by
a given analysis might not be replayable. This boils down
to the scope that an analysis operates on. Some analyses
execute the whole application, from the beginning, so they
can reason about what exactly needs to be done to trigger
a vulnerability. Other systems analyze individual pieces of
an application: they might ﬁnd a bug in a speciﬁc module,
but cannot reason about how to trigger the execution of that
module, and therefore, cannot automatically replay the crash.
Semantic insight. Some analyses lack the ability to reason
about
the program in semantically meaningful ways. For
example, a dynamic analysis might be able to trace the code
executed by an application but not understand why it was
executed or what parts of the input caused the application
to act in that speciﬁc way. On the other hand, a symbolic
analysis that can determine the speciﬁc bytes of
input
responsible for certain program behaviors would have a
higher semantic understanding.

In order to offer replayability of input or semantic insight,
analysis techniques must make certain trade-offs. For example,
high replayability is associated with low coverage. This is
intuitive: since an analysis technique that produces replayable
input must understand how to reach any code that it wants
to analyze, it will be unable to analyze as much code as an
analysis that does not. On the other hand, without being able
to replay triggering inputs to validate bugs, analyses that do
not prioritize bug replayability suffer from a high level of
false positives (that is, ﬂaw detections that do not represent
actual vulnerabilities). In the absence of a replayable input,
these false positives must be ﬁltered by heuristics which can,
in turn, introduce false negatives.

Likewise,

into the
program being analyzed, an analysis must store and process a

in order to achieve semantic insight

139

large amount of data. A semantically-insightful dynamic anal-
ysis, for example, might store the conditions that must hold in
order for speciﬁc branches of a program to be taken. On the
other hand, a static analysis tunes semantic insight through the
chosen data domain – simpler data domains (i.e., by tracking
ranges instead of actual values) represent less semantic insight.
Analyses that attempt both reproducibility and a high
semantic understanding encounter
issues with scalability.
Retaining semantic information for the entire application, from
the entry point through all of the actions it might take, requires
a processing capacity conceptually identical to the resources
required to execute the program under all possible conditions.
Such analyses do not scale, and, in order to be applicable,
must discard information and sacriﬁce soundness (that is, the
guarantee that all potential vulnerabilities will be discovered).
Aside from these fundamental challenges, there are also
implementation challenges. The biggest one of these is the
environment model. Any analysis with a high semantic under-
standing must model the application’s interaction with its en-
vironment. In modern operating systems, such interactions are
incredibly complex. For example, modern versions of Linux
include over three hundred system calls, and for an analysis
system to be complete, it must model the effects of all of them.
Example. To demonstrate the various challenges of binary
analysis, we provide a concrete example of a program with
multiple vulnerabilities in Listing 1. For clarity and space rea-
sons, this example is simpliﬁed, and it is meant only to expose
the reader to ideas that will be discussed later in the paper.

Observe the three calls to memcpy: the ones on lines 10
and 30 will result in buffer overﬂows, while the one on line 16
will not. However, depending on the amount of information
tracked, a static analysis technique might report all three calls
to memcpy as potential bugs, including the one on line 16,
because it would not have the information to determine that
no buffer overﬂow is possible. Additionally, while the report
from a static analysis would include the locations of these
bugs, it will not provide inputs to trigger them.

A dynamic technique, such as fuzzing, has the beneﬁt of
creating actionable inputs that will trigger any bugs found.
On the other hand, simple fuzzing techniques typically only
ﬁnd shallow bugs and fail to pass through code requiring
precisely crafted input. In Listing 1, dynamic techniques will
have difﬁculty ﬁnding the bug at line 10, because it requires
a speciﬁc input for the condition to be satisﬁed. However,
because the overﬂow on line 30 can be triggered through
random testing, fuzzing techniques should be able to ﬁnd an
input which triggers the bug.

To ﬁnd the bug on line 10, one could introduce an abstract
data model to reason about many possible inputs at once.
One such approach is Dynamic Symbolic Execution (DSE).
However, dynamic symbolic techniques, while powerful,
suffer from the “path explosion problem”, where the number
of paths grows exponentially with each branch and quickly
becomes intractable. A symbolic execution will detect the
bug on line 10 and generate an input for it using a constraint

it should be able to prove that

the
solver. Additionally,
memcpy on line 16 cannot overﬂow. However, the execution
will likely not be able to ﬁnd the bug at line 30, as there are
too many potential paths which do not trigger the bug.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34

int main(void) {

char buf[32];

char *data = read_string();
unsigned int magic = read_number();

// difficult check for fuzzing
if (magic == 0x31337987) {

// buffer overflow
memcpy(buf, data, 100);

}

if (magic < 100 && magic % 15 == 2 &&

magic % 11 == 6) {

// Only solution is 17; safe
memcpy(buf, data, magic);

}

// Symbolic execution will suffer from
// path explosion
int count = 0;
for (int i = 0; i < 100; i++) {

if (data[i] == ’Z’) {

count++;

}

}

if (count >= 8 && count <= 16) {

// buffer overflow
memcpy(buf, data, count*20);

}

return 0;

}

Listing 1: An example where different techniques will report
different bugs.

B. The DARPA Cyber Grand Challenge

In October of 2013, DARPA announced the DARPA Cyber
Grand Challenge [23]. Like DARPA Grand Challenges in
other ﬁelds (such as robotics and autonomous vehicles), the
CGC pits teams from around the world against each other in
a competition in which all participants must be autonomous
programs. A participant’s goal in the Cyber Grand Challenge
is straight-forward: their system must autonomously identify,
exploit, and patch vulnerabilities in the provided software.
Millions of dollars in prize money were announced: the top 7
teams to complete the CGC Qualifying Event (held in June,
2015) received 750, 000 USD, and the top 3 teams in the CGC
Final Event (held in August, 2016) will receive 2, 000, 000
USD, 1, 000, 000 USD, and 750, 000 USD, respectively.

The organizers of the Cyber Grand Challenge have put
into designing a competition for automated
much thought
binary analysis systems. For example,
they addressed the
environment model problem by creating a new OS speciﬁcally
for the CGC: the DECREE OS. DECREE is an extremely
simple operating system with just 7 system calls: transmit,
receive, and waitfd to send, receive, and wait for data
over ﬁle descriptors, random to generate random data,

140

allocate and deallocate for memory management,
and terminate to exit.

Despite the simple environment model,

the binaries
provided by DARPA for the CGC have a wide range of
complexity. They range from 4 kilobytes to 10 megabytes
in size, and implement functionality ranging from simple
echo servers, to web servers, to image processing libraries.
DARPA has open-sourced all of the binaries used in the
competition thus far, complete with proof-of-concept exploits
and write-ups about the vulnerabilities [24].

Because the simple environment model makes it feasible to
accurately implement and evaluate (on a large scale) binary
analysis techniques, we use the DARPA CGC samples as our
dataset for the comparative evaluations in this paper.

C. Comparative Analysis of CGC Binaries

analyses

use

different

binary

Offensive

the application that

underlying
techniques to reason about
is being
processed. For example, they may analyze data over different
domains or utilize different
levels of interaction with the
application being tested. In the next two sections, we survey
the current state of the art, and choose several analyses
for in-depth evaluation in the rest of the paper. We focus
speciﬁcally on analyses whose goals are to identify and
exploit ﬂaws in binary software (for example, memory safety
violation identiﬁcation using symbolic execution), as opposed
to the more general binary analysis techniques on which
those are based (in this case, symbolic execution itself).

III. BACKGROUND: STATIC VULNERABILITY DISCOVERY
Static techniques reason about a program without executing
it. Usually, a program is interpreted over an abstract domain.
Memory locations containing bits of ones and zeroes contain
other abstract entities (at the familiar end, this might simply
be integers, but, as we explain below, these can include more
abstract constructs). Additionally, program constructs such as
the layout of memory, or even the execution path taken, may
be abstracted as well.

Here, we split static analyses into two paradigms: those
that model program properties as graphs (i.e., a control-ﬂow
graph) and those that model the data itself.

Static vulnerability identiﬁcation techniques have two main
drawbacks, relating to the trade-offs discussed in Section II-A.
First, the results are not replayable: detection by static analysis
must be veriﬁed by hand, as information on how to trigger
the detected vulnerability is not recovered. Second,
these
analyses tend to operate on simpler data domains, reducing
their semantic insight. In short, they over-approximate: while
they can often authoritatively reason about the absence of
certain program properties (such as vulnerabilities),
they
suffer from a high rate of false positives when making
statements regarding the presence of vulnerabilities.

A. Recovering Control Flow

The recovery of a control-ﬂow graph (CFG),

in which
the nodes are basic blocks of instructions and the edges are

possible control ﬂow transfers between them, is a pre-requisite
for almost all static techniques for vulnerability discovery.

Control-ﬂow recovery has been widely discussed in the
literature [21], [33], [34], [50], [58], [59]. CFG recovery
is implemented as a recursive algorithm that disassembles
and analyzes a basic block (say, Ba), identiﬁes its possible
exits (i.e., some successor basic block such as Bb and Bc)
and adds them to the CFG (if they have not already been
added), connects Ba to Bb and Bc, and repeats the analysis
recursively for Bb and Bc until no new exits are identiﬁed.
CFG recovery has one fundamental challenge: indirect jumps.
Indirect jumps occur when the binary transfers control ﬂow
to a target represented by a value in a register or a memory
location. Unlike a direct jump, where the target is encoded
into the instruction itself and, thus, is trivially resolvable, the
target of an indirect jump can vary based on a number of
factors. Speciﬁcally, indirect jumps fall into several categories:
Computed. The target of a computed jump is determined by
the application by carrying out a calculation speciﬁed by
the code. This calculation could further rely on values
in other registers or in memory. A common example
of this is a jump table: the application uses values in a
register or memory to determine an index into a jump
table stored in memory, reads the target address from
that index, and jumps there.
Context-sensitive. An indirect

jump might depend on the
context of an application. The common example is
qsort() in the standard C library – this function takes
a callback that it uses to compare passed-in values. As
a result, some of the jump targets of basic blocks inside
qsort() depend on its caller, as the caller provides
the callback function.

Object-sensitive. A special case of context sensitivity is
object sensitivity. In object-oriented languages, object
polymorphism requires the use of virtual functions, often
implemented as virtual tables of function pointers that
are consulted, at runtime,
to determine jump targets.
Jump targets thus depend on the type of object passed
into the function by its callers.

Different

techniques have been designed to deal with
different types of indirect jumps, and we will discuss the
implementation of several of them in Section VII. In the
end, the goal of CFG recovery is to resolve the targets of as
many of these indirect jumps as possible, in order to create
a CFG. A given indirect
jump might resolve to a set of
values (i.e., all of the addresses in a jump table, if there are
conditions under which their use can be triggered), and this
set might change based on both object and context sensitivity.
Depending on how well jump targets are resolved, the CFG
recovery analysis has two properties:
Soundness. A CFG recovery technique is sound if the set
of all potential control ﬂow transfers is represented in
the graph generated. That is, when an indirect jump is
resolved to a subset of the addresses that it can actually
target, the soundness of the graph decreases. If a potential

141

target of a basic block is missed, the block it targets
might never be seen by the CFG recovery algorithm,
and any direct and indirect jumps made by that block
will be missed as well. This has a cumulative effect:
the failure to resolve an indirect jump might severely
reduce the completeness of the graph. Soundness can
be thought of as the true positive rate of indirect jump
target identiﬁcation in the binary.

Completeness. A complete CFG recovery builds a CFG
in which all edges represent actually possible control
ﬂow transfers. If the CFG analysis errs on the side of
completeness, it will likely contain edges that cannot
really exist in practice. Completeness can be thought of
as the inverse of the false positive rate of indirect jump
target identiﬁcation.

A CFG recovery analysis that produces an empty graph
would be considered complete, and an analysis that produces
a graph in which every instruction points to every other
is
instruction is considered sound.
somewhere in between,
to achieve with a
scalable algorithm. Thus, different analyses require a different
compromise between the two.

2 While the ideal

this is difﬁcult

A further difﬁculty of control-ﬂow graphs is accurately
measuring code coverage, which is the measure of how much
code is discovered by a control-ﬂow graph. This is often
complicated by the presence of dead code, code which is
unreachable by any jumps.

B. Vulnerability Detection with Flow Modeling

Some vulnerabilities in a program can be discovered

through the analysis of graphs of program properties.
Graph-based vulnerability discovery. Program property
graphs (e.g., control-ﬂow graphs, data-ﬂow graphs and control-
dependence graphs) can be used to identify vulnerabilities in
software. Initially applied to source code [60], [61], related
techniques have since been extended to binaries [45]. These
techniques rely on building a model of a bug, as represented
by a set of nodes in a control-ﬂow or data-dependency graph,
and identifying occurrences of this model
in applications.
However, such techniques are geared toward searching for
copies of vulnerable code, allowing the techniques to beneﬁt
from the pre-existing knowledge of an already existing
vulnerability. Unlike these techniques, the focus of this paper
is on the discovery of completely new vulnerabilities.

C. Vulnerability Detection with Data Modeling

Static analysis can also reason over abstractions of the data

upon which an application operates.
Value-Set Analysis. One common static analysis approach is
Value-Set Analysis (VSA) [6]. At a high level, VSA attempts
to identify a tight over-approximation of the program state
(i.e., values in memory and registers) at any given point in the

2Xu et. al. deﬁnes soundness and completeness of a CFG in the opposite
way, where an empty graph is sound and a full graph is complete [59]. In
this paper, we stick to the deﬁnition in Section III-A.

program. This can be used to understand the possible targets
of indirect jumps or the possible targets of memory write
operations. While these approximations suffer from a lack of
accuracy, they are sound. That is, they may over-approximate,
but never under-approximate.

By analyzing the approximated access patterns of memory
the locations of variables and buffers
reads and writes,
can be identiﬁed in the binary. Once this is done,
the
recovered variable and buffer locations can be analyzed to
ﬁnd overlapping buffers. Such overlapping buffers can be, for
example, caused by buffer overﬂow vulnerabilities, so each
detection is one potential vulnerability.

IV.

BACKGROUND: DYNAMIC VULNERABILITY DISCOVERY
Dynamic approaches are analyses that examine a program’s
execution,
in an actual or emulated environment, as it
acts given a speciﬁc input. In this section, we will focus
speciﬁcally on dynamic techniques
that are used for
identifying vulnerabilities,
than the general binary
analysis techniques on which they are based.

rather

Dynamic techniques are split

into two main categories:
concrete and symbolic execution. These techniques produce
inputs that are highly replayable, but vary in terms of
semantic insight.

A. Dynamic Concrete Execution

Dynamic concrete execution is the concept of executing
a program in a minimally-instrumented environment. The
program functions as normal, working on the same domain
of data on which it would normally operate (i.e., ones and
zeroes). These analyses typically reason at the level of single
paths (i.e., “what path did the program take when given
this speciﬁc input”). As such, dynamic concrete execution
requires test cases to be provided by the user. This is a
problem, as with a large or unknown dataset (such as ours)
such test cases are not readily available.

1) Fuzzing: The most relevant application of dynamic con-
crete execution to vulnerability discovery is fuzzing. Fuzzing
is a dynamic technique in which malformed input is provided
to an application in an attempt to trigger a crash. Initially, such
input was generated by hardcoded rules and provided to the ap-
plication with little in-depth monitoring of the execution [38].
If the application crashed when given a speciﬁc input, the input
was considered to have triggered a bug. Otherwise, the input
would be further randomly mutated. Unfortunately, fuzzers
suffer
from the test case requirement. Without carefully
crafted test cases to mutate, a fuzzer has trouble exercising
anything but the most superﬁcial functionality of a program.
Coverage-based fuzzing. The requirement
for carefully-
crafted test cases was partially mitigated with the advent
of code-coverage-based fuzzing [39]. Code-coverage-based
fuzzers attempt to produce inputs that maximize the amount
of code executed in the target application based on the insight
that the more code is executed, the higher the chance of
executing vulnerable code. American Fuzzy Lop (AFL) [1], a

142

state-of-the art fuzzer responsible for the discovery of many
recent vulnerabilities, uses a code coverage metric as its sole
guiding principle, and its success at ﬁnding vulnerabilities
has driven an increase of interest in fuzzing in recent years.
Coverage-based fuzzing suffers from a lack of semantic
insight into the target application. This means that, while
it is able to detect that a certain piece of code has not yet
been executed, it cannot understand what parts of the input
to mutate to cause the code to be executed.
Taint-based fuzzing. Another approach to improve fuzzing is
the development of taint-based fuzzers [9], [62]. Such fuzzers
analyze how an application processes input
to understand
what parts of the input to modify in future runs. Some of these
fuzzers combine taint tracking with static techniques, such as
data dependency recovery [30], [42]. Others introduce work
from protocol analysis to improve fuzzing coverage [22].

While a taint-based fuzzer can understand what parts of the
input should be mutated to drive execution down a given path
in the program, it is still unaware of how to mutate this input.
2) Dynamic Symbolic Execution: Symbolic techniques
bridge the gap between static and dynamic analysis and
provide a solution to cope with the limited semantic insight
of fuzzing. Dynamic symbolic execution, a subset of symbolic
execution, is a dynamic technique in the sense that it executes a
program in an emulated environment. However, this execution
occurs in the abstract domain of symbolic variables. As
these systems emulate the application, they track the state of
registers and memory throughout program execution and the
constraints on those variables. Whenever a conditional branch
is reached, execution forks and follows both paths, saving
the branch condition as a constraint on the path in which the
branch was taken and the inverse of the branch condition as a
constraint on the path in which the branch was not taken [49].
Unlike fuzzing, dynamic symbolic execution has an ex-
tremely high semantic insight into the target application: such
techniques can reason about how to trigger speciﬁc desired
program states by using the accumulated path constraints to
retroactively produce a proper input to the application when
one of the paths being executed has triggered a condition in
which the analysis is interested. This makes it an extremely
powerful tool in identifying bugs in software and, as a result,
dynamic symbolic execution is a very active area of research.
Classical dynamic symbolic execution. Dynamic Symbolic
Execution can be used directly to ﬁnd vulnerabilities in
software. Initially applied to the testing of source code [12],
[13], dynamic symbolic execution was extended to binary
code by Mayhem [16] and S2E [19]. These engines analyze an
application by performing path exploration until a vulnerable
state (for example, the instruction pointer is overwritten by
input from the attacker) is identiﬁed.

However, the trade-offs discussed in Section II-A come into
play: all currently proposed symbolic execution techniques
suffer from very limited scalability due to the problem of path
explosion: because new paths can be created at every branch,
the number of paths in a program increases exponentially

its lack of semantic insight

with the number of branch instructions in every path. There
have been attempts to survive path explosion by prioritizing
promising paths [11], [37] and by merging paths where the
situation is appropriate [5], [35], [47]. However, in general,
this challenge to pure dynamic symbolic execution analysis
engines has not yet been surmounted, and (as we show later in
this paper), most bugs discovered by such systems are shallow.
Symbolic-assisted fuzzing. One proposed way to address the
path explosion problem is to ofﬂoad much of the processing
to faster techniques, such as fuzzing. This approach leverages
the strength of fuzzing, i.e., its speed, and attempts to mitigate
the main weakness,
into
the application. Thus, researchers have paired fuzzing with
symbolic execution [14], [15], [17], [28], [29], [54]. Such
symbolically-guided fuzzers modify inputs identiﬁed by the
fuzzing component by processing them in a dynamic symbolic
execution engine. Dynamic symbolic execution uses a more
in-depth understanding of the analyzed program to properly
mutate inputs, providing additional
trigger
previously-unexplored code and allow the fuzzing component
to continue making progress (i.e., in terms of code coverage).
Under-constrained symbolic execution. Another way to
increase the tractability of dynamic symbolic execution is to
execute only parts of an application. This approach, known as
Under-constrained Symbolic Execution [26], [46], is effective
at identifying potential bugs, with two drawbacks. First, it is
not possible to ensure a proper context for the execution of
parts of an application, which leads to many false positives
among the results. Second, similar to static vulnerability
discovery techniques, under-constrained symbolic execution
gives up the replayability of the bugs it detects in exchange
for scalability.

i.e.,

test cases that

V. BACKGROUND: EXPLOITATION

Vulnerability discovery analyses actually discover crashing
inputs. Triaging these crashing inputs – that is, understanding
which crashes represent actual security issues, is outside of
the scope of most such approaches. However, some work
does exist on the reproduction and analysis of the discovered
vulnerabilities. In this section, we go through the process
of reproducing an identiﬁed crash, automatically generating
the exploit to verify the security impact of the crash, and
hardening the exploit to make it resilient in the presence of
modern mitigation techniques.

A. Crash Reproduction

Most vulnerability discovery analyses execute a tested
application in less-than-realistic conditions. For example,
many fuzzers will de-randomize execution. That is, they will
hard-code any sources of randomness, such as the PID of
the executable, the current time, and so on. This is done for
two main reasons. First, in most modern fuzzing approaches,
there is an implicit assumption that the same input, provided
to two instantiations of an application, will produce the same
result both times. Second, the modeling of randomness in

143

other techniques, such as dynamic symbolic execution, is not
a well-explored research area.

Because of de-randomization,

the crashes reported by
vulnerability discovery techniques might not be trivially
replayable outside of the analysis environment. Consider the
case of an application that generates a random token and
requires the token to be provided by the user before entering
an unsafe section of code and crashing. In the de-randomized
analysis environment, the generated token will always have
the same value, and the crashing input
identiﬁed by the
analysis will always take the same path, resulting in a crash.
However, outside of the analysis environment, the token will
always be different, and the previously-crashing input might
instead take a non-crashing path.

Crashing inputs that are not trivially replayable generally

fall into two categories.
Missing data. Vulnerability discovery techniques sometimes
manage to “guess” correct response values without having
ﬁrst received them from the application. The token in our
example is always a constant value in the de-randomized
environment, and an analysis engine such as a fuzzer
might accidentally guess it without ﬁrst retrieving it
from the program. When replaying the resulting crashing
input outside of the analysis environment,
the token
value will not match and the crash will not occur.

Missing relationships. Techniques with low semantic insight,
such as fuzzing, are unable to recover the relationships
between data retrieved from the program and subsequent
data provided to it. In our example, even though the crash-
ing input might cause the application to provide the token
to the user, so it can later be used to cause the crash, the
output of the fuzzer lacks the relationship between the to-
ken value that the application provides to the user and the
token value that the user must provide to the application.
is simply not
replayable outside of the analysis environment, and a new
crashing input might be found. Analyses exist that specialize
in the identiﬁcation of data leaks [42], but we have not yet
implemented such analyses in angr.

In the case of missing data,

the input

In the latter case, the de-randomized crashing input must
be converted into an input speciﬁcation that deﬁnes how to
communicate with an application in terms of the relationship
between data received from the application and data later
provided to it. One approach that does this is Replayer [43],
which computes preconditions on program paths to understand
how to reproduce a program path under real-world conditions.

B. Exploit Generation

With a productive vulnerability excavation engine utilizing
one or more of the methods described above, many crashes
might be produced for a tested application. However, not
all of these crashes will be exploitable. An example of a
non-exploitable input is a NULL-pointer dereference. Because
modern operating systems disallow the mapping of memory
at address 0, these previously-exploitable situations have been
reduced to non-exploitable crashes. Understanding whether a

crash is exploitable helps with the triaging of bugs (that is,
understanding which bugs to investigate and ﬁx ﬁrst).

The obvious way to test if a crash would be exploitable is
to try to exploit it. To this end, several systems have been pro-
posed that attempt to take a crashing input and automatically
convert it into an exploit for the application [4], [31], [51].

C. Exploit Hardening

In recent years, binary hardening techniques, such as
non-executable stack regions and Address Space Layout
Randomization (ASLR), have severely reduced the efﬁcacy of
traditional exploits, such as those generated by ﬁrst-generation
automatic exploitation engines. Thus, even an exploitable
vulnerability might be mitigated by modern protections.

Current automatic exploitation techniques were designed
before
the widespread adoption of modern mitigation
techniques, and modern software protections make the exploits
they produce non-functional. To circumvent this, approaches
have been created to automatically harden the exploits
generated using current
techniques against such defenses.
Such techniques work by translating a traditional, shellcode-
based exploit
into an equivalent exploit utilizing Return-
Oriented Programming [52]. As such, an automatic approach
to constructing Return-Oriented Programs is required, and
several such approaches have been developed [18], [48].

VI. ANALYSIS ENGINE

The analyses that we described in sections III, IV and V
were proposed at various times over the last several years,
implemented with different
technologies, and evaluated
on disparate datasets with varying methodologies. This is
problematic, as it makes it hard to understand the relative
effectiveness of different approaches and their applicability
to different types of applications.

To alleviate this problem, we have developed a ﬂexible,
capable, next-generation binary analysis system, angr, and
used it to implement a selection of the analyses we presented
in the previous sections. This section describes the analysis
system, our design goals for it, and the impact that this design
has had on the analysis of realistic binaries.

A. Design Goals

Our design goals for angr are the following:

is made

Cross-architecture support. With the rise of embedded
devices, often running ARM and MIPS processors,
modern software
for varying hardware
architectures. This is a departure from the previous
decade, where x86 support was enough for most analysis
engines: a modern binary analysis engine must be able
to perform cross-architecture analyses. Furthermore,
32-bit processors are no longer the standard; a modern
analysis engine must support analysis of 64-bit binaries.
cross-
architecture support, a modern analysis system must be
able to analyze software from different operating systems.
This means that concepts speciﬁc to individual operating

Cross-platform support. In

similar

vein

to

a

144

systems must be abstracted, and support for loading
different executable formats must be implemented.

Support for different analysis paradigms. A

useful
analysis engine must provide support for the wide range
of analyses described in earlier sections. This requires
that the engine itself abstract away, and provide different
types of memory models as well as data domains.

Usability. The purpose of angr is to provide a tool for the
security community that will be useful in reproducing,
improving, and creating binary analysis techniques. As
such, we strove to keep angr’s learning curve low and its
usability high. angr is almost completely implemented
in Python, with a concise, simple API that is easily usable
from the IPython interactive shell [44]. While Python
results in constant-time lower performance than other po-
tential language choices, most binary analysis techniques
suffer from algorithmic slowness, and the language-
imposed performance impact is rarely felt. When lan-
guage overhead is important, angr can run in the Python
JIT engine, PyPy for a signiﬁcant speed increase.

Our goal was for angr to allow for the reproduction of a
typical binary analysis technique, on top of our platform, in
about a week. In fact, we were able to reproduce Veritesting [5]
in eight days, guided symbolic execution in a month, AEG [4]
in a weekend, Q [48] in about
three weeks, and under-
constrained symbolic execution [46] in two days. It is hard
to produce an implementation effort estimate for dynamic
symbolic execution and value-set analysis, as we implemented
those while building the system itself over two years.

In order to meet these design goals, we had to carefully
build our analysis engine. We did this by creating a set of
modular building blocks for various analyses, being careful
to maintain strict separation between them to reduce the
number of assumptions that higher-level parts of angr (such
as the state representation) make about the lower-level parts
(such as the data model). This makes it easier for us to mix
and convert between analyses on-the-ﬂy. We hope that it will
also make it easier for other researchers to reuse individual
modules of angr. In the next several sections, we discuss
the technical design of each angr submodule.

B. Submodule: Intermediate Representation

In order to support multiple architectures, we translate
architecture-speciﬁc native binary code into an intermediate
representation (IR) atop which we implement the analyses.
Rather than writing our own “IR lifter”, which is an extremely
time-consuming engineering effort, we leveraged libVEX, the
IR lifter of the Valgrind project. libVEX produces an IR, called
VEX, that is speciﬁcally designed for program analysis. We
used PyVEX, which we originally wrote for Firmalice [53],
to expose the VEX IR to Python. By leveraging VEX, we
can provide analysis support for 32-bit and 64-bit versions of
ARM, MIPS, PPC, and x86 (with the 64-bit version of the
latter being amd64) processors. Improvements are constantly
being made by Valgrind contributors, with, for example, a
port to the SPARC architecture currently underway.

As we will discuss later, there is no fundamental restriction
for angr to always use VEX as its IR. As implemented,
supporting a different intermediate representation would be a
straightforward engineering effort.

C. Submodule: Binary Loading

The task of loading an application binary into the analysis
system is handled by a module called CLE, a recursive
acronym for CLE Loads Everything. CLE abstracts
over different binary formats to handle loading a given binary
and any libraries that
it depends on, resolving dynamic
symbols, performing relocations, and properly initializing
the program state. Through CLE, angr supports binaries
from most POSIX-compliant systems (Linux, FreeBSD, etc.),
Windows, and the DECREE OS created for the DARPA
Cyber Grand Challenge.

CLE provides an extensible interface to a binary loader by
providing a number of base classes representing binary objects
(i.e., an application binary, a POSIX .so, or a Windows
.dll), segments and sections in those objects, and symbols
representing locations inside those sections. CLE uses ﬁle
format parsing libraries (speciﬁcally, elftools for Linux
binaries and pefile for Windows binaries) to parse the
objects themselves, then performs the necessary relocations
to expose the memory image of the loaded application.

D. Submodule: Program State Representation/Modiﬁcation

The SimuVEX module is responsible for representing the
program state (that is, a snapshot of values in registers and
memory, open ﬁles, etc.). The state, named SimState in
SimuVEX terms,
is implemented as a collection of state
plugins, which are controlled by state options speciﬁed by
the user or analysis when the state is created. Currently, the
following state plugins exist:
Registers. SimuVEX tracks the values of registers at any
in the program as a state plugin of the

given point
corresponding program state.

Symbolic memory. To enable symbolic execution, SimuVEX
provides a symbolic memory model as a state plugin.
This implements the indexed memory model proposed
by Mayhem [16].

Abstract memory. The abstract memory state plugin is used
by static analyses to model memory. Unlike symbolic
memory, which implements a continuous indexed mem-
ory model, the abstract memory provides a region-based
memory model which is used by most static analyses.

POSIX. When analyzing binaries

for POSIX-compliant
environments, SimuVEX tracks the system state in this
state plugins. This includes, for example, the ﬁles that
are open in the symbolic state. Each ﬁle is represented
as a memory region and a symbolic position index.

Log. SimuVEX tracks a log of everything that is done to the
state (i.e., memory writes, ﬁle reads, etc.) in this plugin.
debugging
interface, allowing breakpoints to be set on complex
conditions, including taint, exact expression makeup, and

Inspection. SimuVEX provides

powerful

a

145

symbolic conditions. This interface can also be used to
change the behavior of SimuVEX. For example, memory
reads can be instrumented to emulate memory-mapped
I/O devices.

Solver. The Solver is a plugin that exposes an interface to
different data domains, through the data model provider
(Claripy, discussed below). For example, when this
plugin is conﬁgured to be in symbolic mode, it inter-
prets data in registers, memory, and ﬁles symbolically
and tracks path constraints as the application is analyzed.
Architecture. The architecture plugin provides architecture-
speciﬁc information that is useful to the analysis (i.e.,
the name of the stack pointer,
the wordsize of the
architecture, etc). The information in this plugin is
sourced from the archinfo module,
is also
distributed as part of angr.

that

These state plugins provide building blocks that can be

combined in various ways to support different analyses.

Additionally, SimuVEX implements

the base unit of
an analysis: representing the semantic changes made to a
program state by a block of application code (in SimuVEX
terminology, such a block of code is called a SimRun). That
is, SimuVEX provides the capability to process an input state
through a block of VEX-represented code, and to generate an
output state (or a set of output states, in case we encounter a
block from which multiple output states are possible, such as
a conditional jump). Again, this part of SimuVEX is modular:
in addition to VEX translations of basic blocks, SimuVEX
currently allows the user to provide a handcrafted Python
function as a SimRun, providing a powerful way to instrument
blocks with Python code. In fact, this is how we implement
our environment model: system calls are implemented as
Python functions that modify the program state.

E. Submodule: Data Model

The values stored in the registers and memory of a
SimState are represented by abstractions provided by
another module, Claripy.

tracks all operations in which it

Claripy abstracts all values to an internal representation
of an expression that
is
used. That is, the expression x, added to the expression 5,
would become the expression x + 5, maintaining a link to
x and 5 as its arguments. These expressions are represented
as “expression trees” with values being the leaf nodes and
operations being non-leaf nodes.

At any point, an expression can be translated into data
domains provided by Claripy’s backends. Speciﬁcally,
Claripy provides backends that support the concrete domain
(integers and ﬂoating-point numbers), the symbolic domain
(symbolic integers and symbolic ﬂoating point numbers,
as provided by the Z3 SMT solver [25]), and the value-set
abstract domain for Value Set Analysis [6]. Claripy is easily
extensible to other backends. Speciﬁcally, implementing other
SMT solvers would be interesting, as work has shown that dif-
ferent solvers excel at solving different types of constraints [8].

User-facing operations, such as interpreting the constructs
provided by the backends (for example, the symbolic expres-
sion x+1 provided by the Z3 backend) into Python primitives
(such as possible integer solutions for x + 1 as a result of
a constraint solve) are provided by frontends. A frontend
augments a backend with additional functionality of varying
complexity. Claripy currently provides several frontends:
FullFrontend. This frontend exposes symbolic solving to
the user, tracking constraints, using the Z3 backend to
solve them, and caching the results.

CompositeFrontend. As suggested by KLEE and Mayhem,
splitting constraints into independent sets reduces the
load on the solver. The CompositeFrontend provides a
transparent interface to this functionality.

LightFrontend. This frontend does not support constraint
tracking, and simply uses the VSA backend to interpret
expressions in the VSA domain.

ReplacementFrontend. The ReplacementFrontend expands
the LightFrontend to add support for constraints on VSA
values. When a constraint (i.e., x+1 < 10) is introduced,
the ReplacementFrontend analyzes it to identify bounds
on the variables involved (i.e., 0 <= x <= 8). When
the ReplacementFrontend is subsequently consulted for
possible values of the variable x, it will intersect the
variable with the previously-determined range, providing
a more accurate result than VSA would otherwise be
able to produce.

HybridFrontend. The HybridFrontend

the
FullFrontend and the ReplacementFrontend to provide
fast approximation support
symbolic constraint
solving. While Mayhem [16] hinted at such capability, to
our knowledge, angr is the ﬁrst publicly available tool
to provide this capability to the research community.

combines

for

This modular design allows Claripy to combine the
functionalities provided by the various data domains in
powerful ways and to expose it to the rest of angr.

F. Submodule: Full-Program Analysis

The analyst-facing part of angr provides complete
analyses, such as dynamic symbolic execution and control-
ﬂow graph recovery. The “entry point” into these analyses
is the Project, representing a binary with its associated
libraries. From this object, all of the functionality of the other
submodules can be accessed (i.e., creating states, examining
shared objects, retrieving intermediate representation of basic
blocks, hooking binary code with Python functions, etc.).
Additionally, there are two main interfaces for full-program
analysis: Path Groups and Analyses.
Path Groups. A PathGroup is an interface to dynamic
symbolic execution – it tracks paths as they run through
an application, split, or terminate.The creation of this
interface stemmed from frustration with the management
of paths during symbolic execution. Early in angr’s
development, we would implement ad-hoc management
of paths for each analysis that would use symbolic

146

execution. We found ourselves re-implementing the same
functionality:
tracking the hierarchy of paths as they
split and merge, analyzing which paths are interesting
and should be prioritized in the exploration, and
understanding which paths are not promising and should
be terminated. We uniﬁed the common actions taken on
groups of paths, creating the PathGroup interface.

Analyses. angr provides an abstraction for any full program
analysis with the Analysis class. This class manages
the lifecycle of static analyses, such as control-ﬂow
graph recovery, and complex dynamic analyses as those
presented in Section IX.

When angr identiﬁes some truth about a binary (i.e., “the
basic block at address X can jump to the basic block at address
Y ”), it stores it in the knowledge base of the corresponding
Project. This shared knowledge base allows analyses to col-
laboratively discover information about the application.
G. Open-Source Release

We started to work on angr with the goal of developing a
platform on which we could implement new binary analysis
approaches. As we faced the unexpected challenges associated
with the analysis of realistic binaries, we realized that such
an analysis engine would be extremely useful to the security
community. We have open-sourced angr in the hope that it
will provide a basis for the future of binary analysis, and it
will free researchers from the burden of having to re-address
the same challenges over and over. angr is implemented
in just over 65, 000 lines of code, usable directly from the
IPython shell or as a python module, and easily installable
via the standard Python package manager, pip.

The open-source release of angr includes the analysis
engine modules (as described in Sections VI-A through VI-F)
on top of which we implemented the applications discussed
in Section XV. Of the latter, we have open-sourced our
control-ﬂow graph recovery, the static analysis framework, our
dynamic symbolic execution engine, and the under-constrained
symbolic execution implementation. While we plan to release
the other applications in the future, they are currently in a
state that is a mix of being prototype-level code and being
actively applied toward the DARPA Cyber Grand Challenge.
angr has been met with extreme enthusiasm by the
community.
the open-source
release, we gathered almost 500 “stars” (measures of persons
valuing the software) on GitHub across the different modules
that make up the system. In the same time period, angr had
roughly 6,000 total installations via pip and an average of
20 “clones” of the Git repository weekly. angr has already
been used in at least one class project in another institution
to introduce students to binary analysis. Additionally, we are
aware of several other institutions using it as a basis to build
research prototypes and a number of corporations evaluating
it for usability in commercial binary analysis systems.

In the ﬁrst 3 months after

VII. IMPLEMENTATION: CFG RECOVERY

We will describe the process that angr uses to generate
a CFG, including speciﬁc techniques that were developed to

improve the completeness and soundness of the ﬁnal result.

Given a speciﬁc program, angr performs an iterative CFG
recovery, starting from the entry point of the program, with
some necessary optimizations. angr leverages a combination
of forced execution, backwards slicing, and symbolic execution
to recover, where possible, all jump targets of each indirect
jump. Moreover, it generates and stores a large quantity of
data about the target application, which can be used later in
other analyses such as data-dependence tracking.

This algorithm has three main drawbacks: it is slow, it does
not automatically handle “dead code”, and it may miss code
that is only reachable through unrecovered indirect jumps.
To address this issue, we created a secondary algorithm that
uses a quick disassembly of the binary (without executing
any basic block), followed by heuristics to identify functions,
intra-function control ﬂow, and direct inter-function control
ﬂow transitions. The secondary algorithm, however, is much
less accurate – it lacks information about reachability between
functions, is not context sensitive, and is unable to recover
complex indirect jumps.

In the reminder of this section, we discuss our advanced
recovery algorithm, which we dub CFGAccurate. We then
discuss our fast algorithm, CFGFast, in Section VII-F.

A. Assumptions

angr’s CFGAccurate makes several assumptions about

binaries to optimize the run time of the algorithm.

1) All code in the program can be distributed into different

functions.

2) All

functions are either called by an explicit call
instruction (or its equivalents), or are preceded by a tail
jump (an optimization, often used to reduce stack space
for recursive functions, in which a call at the very end
of a function is changed to a jump so that the newly
called function simply reuses the return address of its
caller) in the control ﬂow.

stack cleanup behavior of

each function is
predictable, regardless of where it is called from. This
lets CFGAccurate safely skip functions that
it has
already analyzed while analyzing a caller function and
keep the stack balanced.

3) The

These assumptions place constraints on the types of
binaries that angr is designed to analyze. Assumptions 1, 2,
and 3 require that the binary being analyzed is not obfuscated
and behaves in a “normal” way. We can remove those
assumptions when analyzing obfuscated or abnormal binaries,
but this would lead to a higher run time of the CFG recovery.
Our CFG recovery code is built upon techniques proposed
by related literature [21], [34], [50], [58], [59]. However,
these techniques make assumptions that are overly strict or
are unrealistic for real-world binaries. Speciﬁcally, we do not
assume any of the following, unlike the work that our CFG
recovery is based on:

1) All functions return to the next instruction after their

call-site [59].

147

5) No two functions overlap (in other words, they cannot
[34].) CFGAccurate handles

share basic blocks
functions that share code.
information,

6) Additional

such as

symbol

tables or

2) The jump target of an indirect branch is always deter-
mined by a control ﬂow path, not by a program state
or context [59]. For example, some existing literature as-
sumes that indirect jumps are all computed, as opposed to
being passed in as a function pointer from prior contexts.
jumps must
match a set of common idioms [21], [58]. Unlike existing
work, we make no assumptions on the type of operations
that can be applied to pointers.

3) Expressions for jump targets of indirect

4) The stack pointer is the same before entering a function

as it is after returning from it.

relocation information, is available [50].

The actual algorithm to recover a control-ﬂow graph from

a binary is described in the next few sections.

B. Iterative CFG Generation

Unfortunately, no single technique meets CFGAccurate’s
goal of
recovering a complete and sound CFG. Thus,
CFGAccurate constructs a CFG by interleaving a series of
techniques to achieve speed and completeness. Speciﬁcally,
four
lightweight
backward slicing, symbolic execution, and value set analysis.
The CFG to be iteratively recovered by these techniques, C,
is initialized with the basic block at the entry point of the
application.

techniques are used:

forced execution,

Throughout CFG recovery, CFGAccurate maintains
a list of indirect jumps, Lj, whose jump targets have not
been resolved. When the analysis identiﬁes such a jump, it
is added to Lj. After each iterative technique terminates,
CFGAccurate triggers the next one in the list. This next
technique may resolve jumps in Lj, may add new unresolved
jumps to Lj, and may add basic blocks and edges to the CFG
C. CFGAccurate terminates when a run of all techniques
results in no change to Lj or C, as that means that no further
indirect jumps can be resolved with any available analysis.

C. Forced Execution

angr’s CFGAccurate leverages the concept of Dynamic
Forced Execution for the ﬁrst stage of CFG recovery [59].
Forced Execution ensures that both directions of a conditional
branch will be executed at every branch point.

it

initializes its work-list with all

CFGAccurate maintains a work-list of basic blocks,
Bw, and a list of analyzed blocks, Ba. When the analysis
starts,
the basic blocks
in Ba. Whenever CFGAccurate
that are in C but not
analyzes a basic block from this work-list, the basic block
and any direct jumps from the block are added to C. Indirect
jumps, however, cannot be handled this way. Under forced
execution, the targets of indirect jumps may differ from those
of an actual run of the program because forced execution
will execute code in an unexpected order. Thus, each indirect
jump is stored in the list Lj for later analysis.

As it cannot resolve any indirect

this analysis
functions as a fast-pass CFG recovery analysis to quickly
seeds the other analyses with detected basic blocks and
unresolved indirect jumps.

jumps,

D. Symbolic Execution

The main issue with dynamic forced execution is the
presence of indirect jumps, as there is no way to make sure that
the target of an indirect jump is correctly resolved. On the one
hand, an indirect jump may be completely unresolvable (i.e.,
the forced execution resulted in a state where the jump target is
read from uninitialized memory), which leaves a broken con-
trol ﬂow transition in the recovered CFG. On the other hand, an
indirect jump may also be partially solvable (i.e. our analysis
only retrieves a portion of all the possible jump targets).
For each jump J ∈ Lj, CFGAccurate traverses the CFG
backwards until it ﬁnd the ﬁrst merge point (that is, multiple
paths converging on the way to the indirect jump) or up
to a threshold number of blocks (empirically, we found a
reasonable threshold to be 8). From there, it performs forward
symbolic execution to the indirect jump and uses a constraint
solver to retrieve possible values for the target of the indirect
jump.

CFGAccurate considers a jump successfully resolved
if the computed set of possible targets is smaller than a
threshold size. We use a value of 256 for this threshold but
we have found that, in practice, in the cases where jumps
are not resolved successfully,
this value is unconstrained
(meaning, the set of possible targets is bounded only by the
number of bits in the address).

If the jump is resolved successfully, J is removed from Lj
and edges and nodes are added to the CFG for each possible
value of the jump target.

E. Backward Slicing

angr’s forced execution and symbolic execution analyses
fail to resolve many of the unresolved jumps due to the lack of
context. Those analyses are carried out in a context-insensitive
manner: if a function takes pointer as an argument, and that
pointer is used as the target of an indirect jump, the analyses
will be unable to resolve it.

To achieve better completeness, our CFG generation
requires a context-sensitive component. We accomplish this
with backward slicing. CFGAccurate computes a backward
slice starting from the unresolved jump. The slice is extended
through the beginning of the previous call context. That is, if
the indirect jump being analyzed is in a function Fa that is
called from both Fb and Fc, the slice will extend backward
from the jump in Fa and contain two start nodes: the basic
block at the start of Fb and the one at the start of Fc.

CFGAccurate then executes this slice using angr’s
symbolic execution engine and uses the constraint engine to
identify possible targets of the symbolic jumps, with the same
threshold of 256 for the size of the solution set for the jump
target. If the jump target is resolved successfully, the jump
is removed from Lj and the edge representing the control

148

ﬂow transition, and the target basic blocks are added to the
recovered CFG.

develop a number of improvements to increase the precision
of our analysis.

F. CFGFast

The goal of the fast CFG generation algorithm is to
generate a graph, with high code coverage, that identiﬁes at
least the location and content of functions in the binary. This
graph lacks much of the control ﬂow, so it is not complete.
However, such a graph can still be useful for both manual
and automated analysis of binaries.

CFGFast carries out the following steps:

Function identiﬁcation. We

use

hard-coded

function
prologue signatures, which can be generated from
techniques like ByteWeight [7],
to identify functions
inside the application.
the application includes
symbols, specifying the locations of functions, they are
also used to seed the graph with function start positions.
Additionally, the basic block representing the entry point
of the program is added to the graph.

If

Recursive disassembly. Recursive disassembly is used to
recover the direct jumps within the identiﬁed functions.
Indirect jump resolution. Lightweight alias analysis, data-
ﬂow tracking, combined with pre-deﬁned strategies are
used to resolve intra-function control ﬂow transfers.
Currently CFGFast includes strategies for jump table
identiﬁcation and indirect call target resolution.

The goal is to quickly recover a CFG with a high coverage,
without a concern for understanding the reachability of
functions from one another.

G. Using the CFG Recovery

angr exposes the CFG recovery algorithms as two
analyses: CFGFast and CFGAccurate. These analyses
output CFG data to angr’s knowledge base, as discussed
in Section VI-F. This data can then be used in the course of
manual analysis or later automated analyses.

VIII. IMPLEMENTATION: VALUE SET ANALYSIS

Once a CFG is generated, more advanced analyses can
be run. One of these is Value-Set Analysis [6]. Value-Set
Analysis (VSA) is a static analysis technique that combines
numeric analysis and pointer analysis for binary programs.
It uses an abstract domain, called the Value-Set Abstract
domain, for approximating possible values that registers or
abstract locations may hold at each program point.

VSA analyzes a program until it reaches a ﬁx-point for all
program points in the function. This ﬁx-point represents a tight
over-approximation of all values that any register or abstract
memory location can have at any point in the function. With
respect to, for example, a memory write to a computed address
A, consulting the values of A in the computed ﬁx-point will
contain a complete list of all possible write targets.

The original VSA design, proposed by Balakrishnan et
al. [6], does not perform well when analyzing real-world
binaries. To make VSA work on such binaries, we had to

Creating a discrete set of strided-intervals. The

the strided interval,

basic
is essentially
data type of VSA,
an approximation of a set of numbers. It is great for
approximating a set of normal concrete values. However,
if those values are used as jump targets in the program,
the over-approximating nature of strided-intervals yields
unsoundness in our recovered CFG by creating control
ﬂow transitions to addresses that should not be jump
targets. To effectively solve this problem, we developed
a new data type called “strided interval set”, which
represents a set of strided intervals that are not unioned
together. A strided interval set will be unioned into a
single strided interval only when it contains more than K
elements, where K is a threshold that can be adjusted. In
our model discussed in Section II-A, this threshold con-
trols a trade-off of semantic insight versus scalability – a
higher value of K allows us to maintain high precision,
but comes at a cost of increased analysis complexity.

Applying an algebraic solver to path predicates. Tracking
branch conditions helps us constrain variables in a state
after taking a conditional exit or during a merging
procedure, which produces a more precise analysis
result. Afﬁne-Relation Analysis has been proposed as
a technique to track these conditions [40]. However, it
is both complicated to implement (generally leading to
support for very few arithmetic operations in constraint
expressions), and is computationally expensive in reality.
Our solution is to implement a lightweight algebraic
solver that works on the strided interval domain, based on
modulo arithmetic which take care of some of the afﬁne
relations. When a new path predicate is seen (i.e., when
following a conditional branch), we attempt to simplify
and solve it to obtain a number range for the variables
involved in the path predicate. Then we perform an inter-
section between the newly generated number range and
the original values for each corresponding variable. This
allows us to continuously reﬁne the result of our value-
set analysis as new branch conditions are encountered,
increasing the precision of the eventual ﬁx-point.

Adopting a signedness-agnostic domain. As

originally
proposed, VSA operates on a signed strided interval
domain, which assumes all values are signed. That
is, for an n-bit strided-interval with l as its lower
bound and h as its upper bound, we always have
l ∈ [−2n−1, 2n−1 − 1] ∧ h ∈ [−2n−1, 2n−1 − 1] ∧ l ≤ h.
in heavily over-approximated
However,
results of unsigned arithmetic calculations. In fact, this
over-approximation is exacerbated by the fact that, since
jump addresses are unsigned, the computation of jump
addresses generally relies on unsigned values (i.e., in
the case of unsigned comparisons). The solution to this
problem is to adopt a signedness-agnostic domain for
our analysis. Wrapped Interval Analysis [41] is such

results

this

149

UC-angr. UCSE is a dynamic symbolic execution technique
where execution is performed on each function separately.
Since the analysis cannot reason about how to get to the
speciﬁc function, detections by UCSE are not replayable.
Because each function is generated without its context (i.e.,
the arguments and global variables with which it is called
in actual executions), the analysis is not accurate and suffers
from false positives.

UCSE tags missing context

in the state as under-
constrained. When such under-constrained data is used as
a pointer, a new under-constrained region is created and
the pointer is directed at the new region. This “on-demand”
memory allocation enables code that manages complex data
structures to be analyzed. When a security violation is identi-
ﬁed (i.e., a write to the saved return address on the stack), the
values involved are checked for their under-constrained status.
Under certain conditions (i.e., if all data involved is under-
constrained), the violation is ﬁltered out as a false positive.

Global memory under-constraining. The

Path limiters. The

that

We made two changes to the technique described in UCSE:
original UC-
KLEE implementation does not treat access to global
memory as under-constrained. However, such memory
is part of the program context
is impossible to
predict with UCSE, since, when analyzing a given
function, global data could have already potentially been
overwritten. Thus, we mark all global data as under-
constrained, allowing us to lower our false positive rate.
original UC-KLEE implementation
to prevent a path
had several built-in limitations
explosion. For example,
the depth
of under-constrained pointer dereferences to avoid a
search through an under-constrained linked list never
terminating. We added an additional limiter: we abort
is
the analysis of a function when we ﬁnd that
responsible for a path explosion. We detect
this by
hard-coding a limit (in our experiments, we used an
empirically-determined limit of 64 paths) and, when
a single function branches over this many paths, we
replace the function with an immediate return, and
rewind the analysis from the call site of that function.
This keeps the analysis tractable by avoiding path
explosions, but makes the analysis even less accurate.

they would limit

it

an interval domain for analyzing LLVM code, which
takes care of signed and unsigned numbers at the same
time. We based our signedness-agnostic strided-interval
domain on this theory, applied to the VSA domain.

We use VSA for memory corruption detection in three
phases. First, we collect all read and write access patterns in
the program during the VSA. On top of those access patterns,
we perform a variable recovery for variables on both the
stack and heap regions. Our implementation is similar to the
variable recovery in TIE [36]. Next, we scan all stack and heap
regions to ﬁnd abnormal buffers, including a) overlapping
buffers, and b) out-of-bound buffers. Then we simply report
all abnormal buffers as potential memory corruptions.
A. Using VSA

The main interface that angr provides into a full-program
VSA analysis is the Value Flow Graph. The VFG is an
enhanced CFG that includes the program state representing
the VSA ﬁx-point at each program location. Depending on
the parameters passed to the VFG analysis, this can include a
single function, a tree of function calls, or the entire program.
The program states contained in the VFG present memory
layout provided by SimuVEX (speciﬁcally,
in an abstract
the SimAbstractMemory memory model), with values in
memory represented by value-sets, as provided by Claripy.
We performed our buffer overlap analysis over the data
contained in these program states by analyzing the range of
values that memory accesses may take.
IX. IMPLEMENTATION: DYNAMIC SYMBOLIC EXECUTION
The dynamic symbolic execution module of our analysis
platform is mainly based on the techniques described in
Mayhem [16]. Our implementation follows the same memory
model and path prioritization techniques. This module
represents one of the core functionalities of angr, other
analyses, such as Veritesting and under-constrained symbolic
execution, use it as a base.

We use Claripy’s interface into Z3 to populate the sym-
bolic memory model (speciﬁcally, SimSymbolicMemory)
provided by SimuVEX. Individual execution paths through a
program are managed by Path objects, provided by angr,
which track the actions taken by paths, the path predicates, and
various other path-speciﬁc information. Groups of these paths
are managed by angr’s PathGroup functionality, which
provides an interface for managing the splitting, merging, and
ﬁltering of paths during dynamic symbolic execution.

angr has built-in support for Veritesting [5], implementing
it as a Veritesting analysis and exposing transparent
support for it with an option passed to PathGroup objects.
This advanced state merging technique helps mitigate the
problem of exponential state explosion by statically (and
selectively) merging paths.

X. IMPLEMENTATION:

UNDER-CONSTRAINED SYMBOLIC EXECUTION

We implemented under-constrained symbolic execution
(UCSE), as proposed in UC-KLEE [46], and dubbed it

False positive ﬁltering. We introduced several additional
false positive ﬁlters into our implementation of UC-
angr. Speciﬁcally, when we detect an exploitable state,
we attempt to ensure that the state is not incorrectly made
exploitable by a lack of constraints on under-constrained
data. First, we perform a constraint solve with an
additional constraint, E, that expresses the fact that the
state is not exploitable (i.e.,
if the security violation
was an overwrite of the return address, we constrain
the state so that the return address could not have been
overwritten). Then, we constrain each under-constrained
value to its possible solution from this unexploitable
state. We call these constraints U. Finally, we remove
the constraint E, keeping the constraints U, and check

150

that the state can still be exploited. If it can, this means
that the function likely has some inherent ﬂaw, and the
ﬂaw does not necessarily depend on missing data from
the context. Note that the ﬂaw could still be a false
positive due to missing constraints, or due to the limited
context on data that is not under-constrained.

UC-angr is implemented as a SimState plugin that
tracks under-constrained data accesses and carries out
the
required relocations. Once this plugin is initialized, under-
constrained symbolic execution can be performed using the
same PathGroup paradigm as dynamic symbolic execution.

XI. IMPLEMENTATION: SYMBOLIC-ASSISTED FUZZING
While we give a summary of our symbolic-assisted fuzzing
implementation here, the full approach, called Driller, is
detailed in a separate paper [54].

Our implementation of symbolic-assisted fuzzing uses the
AFL fuzzer as its foundation and angr as its symbolic tracer.
By monitoring AFL’s performance, we can decide when to
begin symbolically-tracing the inputs that AFL has created.
To make this decision, we act on the rate at which the fuzzer
is discovering new state transitions. If AFL reports that it
has discovered no new state-transitions after performing a
round of mutations of the input, we assume the fuzzer to
be having trouble making progress, and invoke angr on
all paths AFL has deemed as unique (i.e., any path that has
a jump, identiﬁed by a tuple of the source and destination
address, that no other path has), looking for transitions that
AFL was unable to ﬁnd inputs for.

Driller’s symbolic component

is implemented using
angr’s symbolic execution engine, so as to symbolically
trace paths based on the concrete inputs provided by AFL.
This avoids the path explosion problem inherent to symbolic
execution, as each concrete input corresponds to a single
(traced) path, and these inputs are heavily ﬁltered by AFL
to ensure that only promising ones are traced. Each concrete
input corresponds to an individual path in a PathGroup.
At each step of the PathGroup, every branch is checked
so as to ensure that the most recent jump instruction leads
to a path previously unknown to AFL. When such a jump
is found, the SMT solver is queried to create an input that
would drive execution to the new jump. This input is fed back
to AFL, which goes on to mutate it in future fuzzing steps.
This feedback loop allows us to balance expensive symbolic
execution time with cheap fuzzing time, and mitigates
fuzzing’s low semantic insight into program operation.

XII. IMPLEMENTATION: CRASH REPRODUCTION

We implemented the approach proposed by Replayer [43]
to recover missing relationships between input values (i.e.,
values that the attacker sends) and output values (i.e., values
that the attacker leaks from the application).

Our implementation of Replayer is built atop our symbolic
execution engine. We can deﬁne the problem of replaying
a crashing input as the search for an input speciﬁcation is
to bring a program from an initial state s to a crash state

q. Our algorithm takes, as input, the program P , an initial
state sa (i.e., the state at the entry point of the executable),
the crash state qa, and the input ia that brings sa to qa in
the instrumented (de-randomized) environment, but does not
properly replay in an uninstrumented environment. Our imple-
mentation symbolically executes the path from sa to qa, using
the input ia. It records all constraints that are generated while
executing P . Given the constraints, the execution path, the
program P , and the new initial state sb, we can symbolically
execute P with an unconstrained symbolic input, following the
previously recorded execution path until the new crash state qb
is reached. At this point, the input constraints on the input and
output can be analyzed, and relationships between them can be
recovered. This relationship data is used to generate the input
speciﬁcation is, allowing the crashing input to be replayed.

The implementation proposed by Replayer has two main
limitations in its application to crash reproduction. First, as
we discuss in Section V-A, it is possible that a given crash
does not retrieve all of the data that is required to properly
replay the crash. Replayer is unable to handle these cases,
and new crashing inputs must be found.

Second, Replayer uses only the exact path, as executed by
the application in the de-randomized environment while pro-
cessing the crashing input, to generate the input speciﬁcation.
If the execution trace of a binary changes, based on the exact
value of random data, then Replayer cannot compute the cor-
rect input. For example, if the random cookie introduces path
predicates, by causing the execution of a speciﬁc path through
a decoding function, replaying execution with that exact path
will constrain the cookie to a value that might differ from the
initial one. When this happens, the replayed cookie will not be
correct, and the replaying attempt will fail. As we will discuss
later, AEG is facing a similar limitation. This suggests that re-
search in this area could make progress for both of these tasks.

XIII. IMPLEMENTATION: EXPLOIT GENERATION

By implementing algorithms similar to those described in
AXGEN [51], AEG [4] and Mayhem [16], we were able to
evaluate the effectiveness of the current state of the art in
automatic exploit generation. Our implementation allows us
to create exploits for vulnerabilities, allowing the attacker
to take control of the program’s execution by overwriting
a saved instruction pointer (e.g., by overwriting function
pointers, or exploiting buffer overﬂows on the stack).

Vulnerable States. Unlike AEG/Mayhem, but similar
to AXGEN, we generate exploits by performing concolic
execution on crashing program inputs using angr. We drive
concolic execution forward, forcing it
to follow the same
path as a dynamic trace gathered by concretely executing the
crashing input applied to the program. Concolic execution
is stopped at the point where the program crashed, and we
inspect
the symbolic state to determine the cause of the
crash and measure exploitability. By counting the number
of symbolic bits in certain registers, we can triage a crash
into a number of categories such as frame pointer

151

overwrite, instruction pointer overwrite, or
arbitrary write, among others.

Instruction Pointer Overwrite Technique. The simplest
exploitable bug we can encounter is where symbolic bits
appear in the instruction pointer at crash time. When detecting
that symbolic bits are contained in the instruction pointer,
we can constrain our instruction pointer to point to either a
controlled sequence of instructions, such as shellcode, or a
ROP gadget that pivots the stack to a symbolic buffer where we
can execute a ROP chain (generated by our exploit hardening
step). angr itself handles many of the implementation details
discussed in AEG and AXGEN, such as taint tracking and path
condition building, allowing us to limit ourselves to ﬁnding
symbolic memory buffers and applying constraints to register
values to generate an exploit, as proposed by these approaches.
Exploiting CGC Binaries. The Cyber Grand Challenge
hosts the game on a custom OS which includes only 7 system
calls. The lack of system calls which can execute programs
and open ﬁles means exploitation within the Cyber Grand
Challenge is limited to demonstrating register control and the
ability to read and write memory. By DARPA standards, two
type of exploits exist for the CGC:

• A Type 1 exploit demonstrates that the attacker controls
a general purpose register and the instruction pointer
register.

• A Type 2 exploit demonstrates that the attacker can per-
form a controlled read from the process memory space.
Out of the 126 binaries we applied AEG to, we succeeded
in exploiting only a total of 4 binaries. For only two of these
binaries, we were able to generate a “Type 2” exploit. Both of
these “Type 2” exploits were unable to be hardened with ROP
and resorted to jumping to shellcode. Additionally, AEG was
only able to generate 2 hardened, ROP “Type 1” exploits. We
believe these results show that much more work in the ﬁeld of
automated exploit generation is to be done, and that the current
methods are not well-applicable to modern vulnerabilities.

Challenges Faced. Here we demonstrate some of the
challenges that our tool faced while attempting to exploit
Cyber Grand Challenge binaries, using CROMU00019 [24].
We will focus on the exploitation of the second vulnerability
mentioned in this challenge’s README (speciﬁcally, a buffer
overﬂow on the stack that exists during the decoding of an
attacker-supplied string).

The major issue we ran into during exploit generation was
the presence of path predicates that constrained each byte
of the overﬂowing data to being a single value, despite the
values of these bytes being chosen based on symbolic input.
CROMU00019 demonstrates this in its decode function.
Each byte of the payload takes a branch of the switch
statement contained in decode, placing restrictive predicates
on our path representing the vulnerable state. While the arms
of this switch statement are taken based on symbolic data, the
data returned is concrete, and each of these arms represents
a separate path through the program. The traditional AEG
approach assumes the ability to place the proper constraints
on symbolic data to carry out control ﬂow hijacking, but this

behavior requires ﬁnding the single path through the decode
function which places our desired bytes into the output buffer.
The solution to this problem would be to search for a
single path which performs a desirable control ﬂow hijack
out of the many paths which present vulnerable conditions.
However, modern exploit generation capabilities do not have
this capacity, and cases like these prevent many of the stack
buffer overﬂow vulnerabilities presented in the CGC Qualiﬁer
event from being exploited with the current state-of-the-art
automatic exploit generation.

XIV. IMPLEMENTATION: EXPLOIT HARDENING

To harden exploits against modern mitigation techniques,
we implemented a ROP chain compiler based on the ideas
in Q [48]. This means that we can automatically generate
ROP payloads to fulﬁll an end goal, such as writing data
to memory or calling an arbitrary function in a library. This
section focuses on the differences and improvements we
made over Q itself.

Our approach comprises the following steps:

Gadget discovery. We scan all executable code in the
application, at every byte offset, to identify ROP gadgets
and classify them according to their effects. For example,
the instruction sequence: mov [ebx], eax; pop
ebx; ret would be classiﬁed as a memory write and a
register load. To carry out the classiﬁcation, our analysis
leverages the action history provided by angr’s Path
objects and symbolic relations provided by Claripy.

Gadget arrangement. The ROP

chain

compiler

then
determines arrangements of gadgets that can be used to
perform high-level actions. For example, a gadget that
pushes data to the stack can be paired with a gadget that
pops data to create an arrangement that moves data from
one register to another.

Payload generation. After the ROP compiler identiﬁes the
requisite set of gadget arrangements, it combines these
gadgets into a chain to carry out high-level actions
(such as executing attacker-speciﬁed system calls with
speciﬁed arguments). This is done by writing gadget
arrangements into a program state in angr, constraining
their outputs to the provided arguments, and querying
the SMT solver for a solution for their inputs.

Our implementation differs from Q in minor ways. First,
Q made no use of the stack as scratch storage space. It is
not clear why this is: one explanation is that their analysis
platform did not support the modeling of stack operation,
while another is that the approach remains more general if
we assume that the stack is not necessarily pointed to by
the stack pointer (and, thus, in an unknown location). In our
integrated system, we could identify whether the stack pointer
was pointing to the stack, since we had this metadata from the
exploit that we generated with our implementation of AEG.
Another improvement has to do with the gadget classiﬁ-
cation. Q used a value sampling method to identify speciﬁc
classes of gadgets, which led to some number of missed
gadgets chains due to the limited coverage of the sample

152

Technique
Dynamic Symbolic Execution
Veritesting
Under-constrained DSE
Symbolic-Assisted Fuzzing
Static Analyses
Crash Replay
Exploit Generation
Exploit Hardening

Based On
Various [12], [16], [20]
Veritesting [5]
UCSE [46]
Driller [54]
VSA [6]
Replayer [43]
AEG [4]
Q [48]

Described In
IV-A2, IX
IV-A2, IX
IV-A2, X
IV-A1, XI
III-C, VIII
V-A, XII
V-B, XIII
V-C, XIV

TABLE I

ANALYSES IMPLEMENTED AND EVALUATED IN THIS PAPER, THE

LITERATURE ON WHICH THEY ARE BASED, AND THE SECTIONS OF THIS

PAPER IN WHICH THEY ARE DISCUSSED.

data. In our approach, we symbolically analyze every gadget,
using careful caching techniques to keep the analysis fast.

XV. COMPARATIVE EVALUATION

By leveraging angr’s design, we were able to reproduce
the binary analysis techniques that we have discussed, on
the same codebase, enabling a comparative evaluation of
their effectiveness. To the best of our knowledge, this has
not been done before: previous comparisons were carried
out on different implementations, leaving the possibility of
differences in results being introduced by implementation
differences. With the exception of the fuzzer itself (AFL),
our analyses are all implemented on the same analysis engine
and share over 90% of the same code base with each other.
We use a corpus of CGC binaries, released by DARPA
for the CGC Qualiﬁcation Event, to carry out our evaluation.
As discussed in Section II-B, these binaries vary widely in
complexity, but utilize a simple environment model, designed
by DARPA to reduce the implementation effort of analysis
systems.

We evaluate the techniques that we implemented for CFG
recovery, dynamic and static vulnerability discovery, crash
replay, exploitation, and exploit hardening. A summary of
the analyses we implemented and evaluated, along with the
literature on which they are based and the sections in this
paper in which they are described, is produced in Table I.

A. CFG recovery

As the CFG is used as a pre-requisite for other analyses in
angr, it is important to understand how well angr’s CFG
recovery performs. As we discussed in detail in Section VII,
angr has two CFG recovery algorithms: CFGAccurate
relies on a base approach of forced execution and provides
two methods of indirect jump resolution (backwards slicing
and symbolic back-traversal), while CFGFast mainly uses
recursive disassembly and heuristics to quickly identify
functions and inter-function control ﬂow.

To

of

these

the

understand

effectiveness

recovery
techniques, we compared CFGFast and CFGAccurate
against the CFG recovery of a state-of-the-art commercial
tool, IDA Pro 6.9, on CGC binaries. While little details
about how IDA Pro recovers the CFG are available, based on
descriptions in previous work [59] as well as our observations,
we believe that IDA Pro disassembles a binary recursively,
uses symbols and other heuristics to determine locations

CGC Qualifying Position
First
Second
Third
Fourth
Fifth
Sixth
Seventh
Eighth (did not qualify)
Ninth (did not qualify)

Binaries Crashed
77
12
57
9
23
57
44
39
65

NUMBER OF CRASHED BINARIES FOR THE TOP 9 COMPETITORS IN THE

CGC QUALIFICATION EVENT.

TABLE III

of functions throughout a binary, and then utilizes some
lightweight data-ﬂow analyses to further solve the targets of
indirect jumps. This makes it more similar, conceptually, to
CFGFast than to CFGAccurate. As ground truth CFG
information is not available, we evaluate our results in terms of
the relative number of recovered basic blocks and control ﬂow
transfers between the results of IDA’s and our CFG recovery.
We ﬁrst evaluate the completeness of our CFG, comparing
the blocks and edges identiﬁed by CFGFast and the graph
generated by IDA Pro. Table II shows our results. CFGFast
has a slightly better code coverage than IDA Pro, and recovers
more edges. We believe that this is because the lightweight
data-ﬂow analyses and heuristics that are used by CFGFast
are more advanced than those used by IDA. Manual analysis
of recovery results on a few binaries indicates that CFGFast
is more aggressive in terms of code recovery: while IDA Pro
believes certain parts of code are not reachable and refuses
to disassemble it as code, CFGFast identiﬁes such locations
as code. A possible explanation for this is that our approach
might be overly aggressive, and as such, it might mis-identify
such locations. However, we have not identiﬁed such cases
when analyzing CGC binaries.

As some binary analyses require reachability information
from the entry point, we have also included a comparison
against the reachable portion of a CFG generated by IDA Pro
(that is, a CFG comprising those blocks for which a path from
the entry point can be determined) against the CFG recovered
by angr’s CFGAccurate analysis. Table II shows our
results. By improving the forced execution technique with
backward slicing, angr substantially improves its ability to
reconstruct the CFG. However, since CFGAccurate does
not
the resulting CFG’s code
coverage is not as high as IDA Pro’s. To achieve a better
coverage,
the user can provide CFGAccurate with all
recovered functions from CFGFast as starting points.

leverage ad hoc heuristics,

B. Evaluation of Vulnerability Analysis Techniques

In Sections VIII through XI, we describe the implementation
of several vulnerability discovery techniques. Here, we present
the result of a comparative evaluation of these techniques as
applied to the CGC dataset. We ran these evaluations with a
timeout of 24 hours, which is the time period of the DARPA
competition from which we retrieved the evaluation dataset.
We provide a summary of these results in Table IV.
Additionally, to provide a better context for the number of

153

Approach

IDA Pro 6.9
angr - CFGFast

Functions
M A
48
61

52.96
70.08

Function Edges
M
76.5
88

A
99.62
118.74

Blocks
M
829
843

A
3589.93
3609.45

Block Edges
M
1188
1193

A
6487.68
6538.52

Bytes
M
14037
14296

7874
6125
6323
6109.5

A
104779.66
105007.49

21721.85
13963.5
10883.51
14641.85

Time (s)
M
1.14
0.87

A
1.80
5.01

1.14
23.50
27.22
24.78

1.80
36.96
34.10
79.46

IDA Pro 6.9 - reachability
angr - forced execution
angr - symbolic back traversal
angr - backward slicing

37
31
32
30

40.96
33.24
33.76
32.80

74
48
50
47.5

90.76
55.22
56.28
53.89

1043.81
413.85
635.41
653.56

496
349.5
368
344.5
TABLE II

759
612
645
594

1693.01
751.96
1089.78
1178.98

EVALUATION OF CFGFA S T’S AND CFGAC C U R A T E’S RECOVERED CFG VERSUS THE CFG RECOVERED BY IDA PRO. THE MEDIAN NUMBER (M) AND

AVERAGE NUMBER (A) OF EACH VALUE ACROSS ALL BINARIES ARE SHOWN.

Technique
Dynamic Symbolic Execution
Veritesting
Dynamic Symbolic Execution + Veritesting
Fuzzing (AFL)
Symbolic-Assisted Fuzzing
VSA
Under-constrained Symbolic Execution

Replayable

Semantic Insight

Scalability

Yes
Yes
Yes
Yes
Yes
No
No

High
High
High
Low
High

Medium

High

Low

Medium
Medium

High
High
High
High

Crashes
16
11
23
68
77
27
25

False Positives
0
0
0
0
0
130
346

EVALUATION RESULTS ACROSS ALL VULNERABILITY DISCOVERY TECHNIQUES.

TABLE IV

in the qualifying event

crashes identiﬁed by our techniques, we have included the
number of crashes identiﬁed by the competitors at the actual
CGC Qualiﬁcation Event, in Table III. The overall scores
of the teams relied on more than just crash counts, so the
placement
is not correlated with
the position of the competitors. Two of these competitors,
the ﬁrst-place team [27] and the seventh-place team [57],
have written blog posts describing their techniques in the
competition. Both teams used a symbolically-assisted fuzzing
technique, conceptually similar to Driller. Note that, while
our implementation of Driller identiﬁes the same number of
vulnerabilities as the ﬁrst place team, this is a coincidence
(likely driven by the similarity between the techniques).
Dynamic symbolic execution. We chose to evaluate dynamic
symbolic execution both alone and in the presence of the
Veritesting path explosion mitigation technique. We describe
the implementation details of these approaches in Section IX.
As expected, dynamic symbolic execution frequently suc-
cumbed to the path explosion problem. In total, the standard
approach identiﬁed vulnerabilities in 16 of the CGC binaries.
Veritesting, which is designed to partially mitigate the path
explosion problem, identiﬁed only 11, for a combined count
of 23 applications in which vulnerabilities were identiﬁed.

We were initially surprised to ﬁnd that, despite the better
results,
the Veritesting approach found less vulnerabilities
than dynamic symbolic execution alone. Investigating these
four binaries, we identiﬁed an interesting trade-off inherent to
Veritesting. Veritesting uses efﬁcient path merging to combat
path explosion, which is responsible for its ability to explore
deeper paths in the binary before path explosion renders
further progress impossible. However, such path merging
introduces complex expressions (e.g., if the value of register
eax differs between two merged paths,
the value of the
merged path must be a complex expression encoding both

previous values) and overloads the constraint solver. Thus, the
solve times of the constraint solver tend to increase as more
and more of these merges are done. As constraint solving
is an NP-complete problem, the increased complexity leads
to vulnerabilities becoming unreachable within a reasonable
time. The result of this is that Veritesting is able to identify
shallow bugs that dynamic symbolic execution otherwise
experiences a path explosion with, but overwhelms the
constraint solver for longer paths.

Symbolic-assisted fuzzing. Assisted fuzzing has proven to
be extremely effective in the literature. In Section XI, we
discuss an implementation of a symbolic-assisted fuzzing
method, dubbed Driller [54].

This symbolic-assisted fuzzer uses AFL for the fuzzing
component. Each input that AFL produces is traced in the
dynamic symbolic execution engine to identify code sections
that could be reached by careful mutation of the input. This
careful mutation is carried out by the symbolic constraint
solver, and the input
is reintroduced to AFL for further
execution and mutation. Because the individual inputs traced
by the DSE engine do not branch (as all the input is concrete),
there is no path explosion during tracing, and AFL limits the
number of inputs passed to the DSE engine by ﬁltering out
all the inputs that do not increase code coverage.

It should be mentioned that AFL alone is able to identify
vulnerabilities in a signiﬁcant amount of the CGC services. In
fact, of the 77 vulnerabilities that our symbolic-assisted fuzzer
detected, 68 were detected by AFL alone. The remaining 9
were found through the use of symbolic assistance.

fuzzing. The difference between the results of
DSE vs.
the various dynamic symbolic execution approaches are
surprising. One might reasonably expect DSE to identify
roughly as many vulnerabilities as symbolically-assisted

154

However, as this approach analyzes functions without their
context, it suffers from similar problems as static analyses:
the results contain a large number of false positives, and the
results are not replayable (that is, they do not generate crashing
inputs, but instead point out the location of vulnerabilities). In
fact, we identiﬁed 346 false positives in UC-angr’s results,
leaving 25 true positives and resulting in a false positive rate of
93%, which is in line with those reported by UC-KLEE [46].
Static buffer overlap detection. To be able to compare
the different types of vulnerabilities identiﬁed by fuzzing,
symbolic execution, and other static analyses, we implemented
a VSA-based memory corruption detection analysis. We
describe it in detail in Section VIII.

Similarly to UC-angr, our VSA results are not replayable
and suffer from false positives. In total, VSA was able to iden-
tify 27 actual vulnerabilities in CGC binaries while producing
130 false positives, resulting in a false-positive rate of 82.8%.
Non-replayable vs replayable analyses. Another surprising
result is the comparatively low performance of non-replayable
techniques (VSA and under-constrained symbolic execution).
While
replayability
requirement, can achieve more coverage in their analysis, we
found that the context they lacked resulted in an enormous
amount of false positives in this dataset. To keep the false
positive rate reasonable, we had to implement aggressive false
positive ﬁltering (as discussed in Section X), which ﬁltered
out many true positives as well.

freed from the

techniques,

these

The improvement of static analysis techniques on real
binaries appears to be an area in need of research attention,
and we are considering it as a direction for future work.

C. Exploitation Evaluation.

After a crash is identiﬁed by the above approaches, we

attempt to replay and exploit it to understand its severity.
Crash replay. As we discuss in Section V-A, crashing inputs
identiﬁed by vulnerability discovery analyses might not be
trivially replayable due to environmental data (such as the ran-
dom seed) having been de-randomized by the analysis. We an-
alyzed crashes for each CGC binary, using the reference crash-
ing inputs provided by DARPA for binaries where we were un-
able to identify vulnerabilities with our vulnerability identiﬁ-
cation techniques. Of these crashing inputs, 6 were not trivially
replayable. That is, rather than simply replaying the crashing
input provided to us by the vulnerability identiﬁcation engines,
we had to re-analyze the interaction with the binary to recover
challenge-response components present in these binaries.

Interestingly, DARPA imposes a limitation on the authors of
CGC binaries from the CGC Qualifying Event that disallows
control ﬂow from being impacted by random data. This means
that
the limitation of Replayer discussed in Section XII,
the introduction of different path predicates due to different
values of random data, does not apply to its operation on CGC
binaries. Though angr did hang on one of the applications,
manual analysis revealed this to be an implementation issue,

Fig. 1. Length of crashing paths discovered by fuzzing vs. dynamic symbolic
execution.
fuzzing, and more than fuzzing alone. In reality, fuzzing
identiﬁed almost three times as many vulnerabilities. In a
sense, this mirrors the recent trends in the security industry:
symbolic analysis engines are criticized as impractical while
fuzzers receive an increasing amount of attention. However,
this situation seems at odds with the research directions of
recent years, which seem to favor symbolic execution.

Analyzing the crashing inputs that these approaches did
ﬁnd, we identiﬁed an interesting result: the exploits found by
dynamic symbolic execution engines tend to represent short
paths. This result is presented in Figure 1. By spot-checking
several applications where dynamic symbolic execution
(even with Veritesting) failed to ﬁnd vulnerabilities, we have
concluded that this is due to an increase in analysis complexity,
exponentially proportional to the length of the path.

Speciﬁcally, given a path A, there is a chance pa that A
will split at the end of the next conditional jump, and A1 will
follow the path that takes the jump, while A2 will follow the
path that does not. At the next conditional jump, there is a
chance that A1 and A2 will fork as well. Thus, the amount
of resulting paths to analyze increases exponentially, and the
chance that an unreasonable number of paths will have to be
analyzed at any point is exponentially proportional to how
many basic blocks have been executed by the analysis. As a
result, the typical dynamic symbolic execution approach is best
for ﬁnding shallow crashes that do not require the execution
of many basic blocks. Deep crashes, on the other hand, tend
to be hidden and made unreachable by the path explosion.

To further understand the relative effectiveness of the tech-
niques, we calculated the code coverage of the generated test
cases. We found that symbolic execution (including Veritest-
ing) covered an average of 330 blocks per binary (with a me-
dian of 260), while fuzzing covered 689 (with a median of 402)
and symbolic-assisted fuzzing covered 698 (with a median of
406). These results yield another interesting conclusion: if the
paths generated by fuzzing or symbolic-assisted fuzzing were
combined into a graph, it would represent a CFG with more
code coverage than the one recovered by CFGAccurate
(and, by virtue of each edge in the graph being reachable by
deﬁnition, with perfect completeness), implying a need for
further improvement of the accurate CFG recovery algorithm.
Under-constrained symbolic execution. We extended angr
to support under-constrained symbolic execution to better
understand how effective such techniques are on our dataset.
These details are presented in Section X.

UC-angr reported 371 vulnerabilities in the CGC binaries.

155

rather than one with the approach and, as expected, Replayer
was able to recover the input speciﬁcation of the remaining 5.
While 6 binaries are not a large dataset, this result suggests
that current techniques in this area are able to adequately
handle binaries in the absence of control ﬂow variance caused
by random data. Further work is needed to evaluate, and
possibly extend, these techniques on real-world binaries with
more complex control ﬂow.
Automatic exploit generation. After identifying the crash
and running it through Replayer, we are left with an input
speciﬁcation that
reliably crashes the target application.
However, such inputs might still not be exploitable. For
example, crashes caused by null pointer dereferences, of which
there are many in the CGC dataset, are not exploitable on
modern systems. To separate exploitable from non-exploitable
inputs, we attempt to generate an exploit from the crash.

We attempted to automatically generate exploits for all
of the CGC applications, using techniques proposed in the
AEG system [4]. However, we were surprised to ﬁnd that
only 4 crashing exploits could be weaponized into exploits
using these techniques. Looking deeper into the binaries, we
understood why. First,
the goal of the CGC Qualiﬁcation
Event was to ﬁnd crashes for the binaries, not exploits.
As such, many of the vulnerabilities in these binaries are
not actually exploitable (i.e., null-pointer dereferences).
Second, as the CGC binaries model a wide range of realistic
exploitation scenarios, we found that the techniques proposed
by AEG were not applicable to the majority of them.

The current state of the art in this ﬁeld is fairly basic, and
it appears in these results. Further research is required into
this ﬁeld to enable the automatic exploitation of complex
vulnerabilities.
Exploit hardening. Even an exploitable vulnerability might
be mitigated by modern protections. As a result, exploit
hardening is required, and has been investigated by recent
work. We reimplemented the techniques proposed by Q [48]
and attempted to harden the exploits generated by AEG.

The Q implementation was able to harden 2 of the 4
exploits that AEG generated. Our analysis as to why the
remaining two exploits could not be hardened revealed that
the Q approach does not utilize enough information in the
binary. In these two examples, there is not enough attacker-
controlled data on the stack and a stack pivot is required to
use attacker-controlled data in other parts of the program. The
Q approach has no basis for reasoning about such operations
and, as a result, these exploits cannot be hardened.

XVI. CONCLUSIONS

In this paper, we presented angr, a system that implements,
in a uniﬁed framework, a number of techniques for the
automated identiﬁcation and exploitation of vulnerabilities in
binaries. We presented, in a systematized fashion, the different
analyses and the challenges we encountered when including
them in our framework. By implementing these approaches in
a single system, we were able to meaningfully compare their

effectiveness on a dataset that was created for the evaluation
of these techniques. The results of this evaluation can be used
as a basis to highlight research directions, and to improve
existing techniques.

We made angr open-source, so that the community can
build on top of it and focus on addressing open challenges in
the ﬁeld of binary analysis.

Acknowledgements. This work is sponsored by DARPA
under agreement number N66001-13-2-4039 and by the
ONR under agreement number N00014-15-1-2948. The U.S.
Government is authorized to reproduce and distribute reprints
for Governmental purposes notwithstanding any copyright
notation thereon.

REFERENCES

[1] American Fuzzy Lop. http://lcamtuf.coredump.cx/aﬂ/.
[2] OWASP Top 10 Project. http://http://www.owasp.org.
[3] The XcodeGhost malware.

http://www.apple.com/cn/xcodeghost/

#english.

[4] T. Avgerinos, S. K. Cha, B. L. Tze Hao, and D. Brumley. AEG:
Automatic Exploit Generation.
In Proceedings of the 18th Annual
Network and Distributed System Security Symposium (NDSS’11), 2011.
[5] T. Avgerinos, A. Rebert, S. K. Cha, and D. Brumley. Enhancing

Symbolic Execution with Veritesting. pages 1083–1094, 2014.

[6] G. Balakrishnan, T. Reps, D. Melski, and T. Teitelbaum. WYSINWYX:
What You See Is Not What You eXecute. Lecture Notes in Computer
Science (including subseries Lecture Notes in Artiﬁcial Intelligence and
Lecture Notes in Bioinformatics), 4171 LNCS:202–213, 2008.

[7] T. Bao, J. Burket, M. Woo, R. Turner, and D. Brumley. BYTEWEIGHT:
In Proceedings of

Learning to Recognize Functions in Binary Code.
the 23rd USENIX Security Symposium, pages 845–860, 2014.

[8] C. Barrett, L. De Moura, and A. Stump. SMT-COMP: Satisﬁability
In Computer Aided Veriﬁcation, pages

modulo theories competition.
20–23. Springer, 2005.

[9] S. Bekrar, C. Bekrar, R. Groz, and L. Mounier. A Taint Based Approach
for Smart Fuzzing .
In Software Testing, Veriﬁcation and Validation
(ICST), 2012 IEEE Fifth International Conference on, pages 818–825.
IEEE, 2012.

[10] Bloomberg Business. Hospital Gear Could Save Your Life or Hack
Your Identity. http://www.bloomberg.com/features/2015-hospital-hack/.
[11] P. Boonstoppel, C. Cadar, and D. Engler. RWset: Attacking Path
Explosion in Constraint-Based Test Generation.
In Tools and
Algorithms for the Construction and Analysis of Systems, volume 4963
LNCS, pages 351–366. Springer Berlin Heidelberg, 2008.

[12] C. Cadar, D. Dunbar, and D. Engler. KLEE: Unassisted and Automatic
Generation of High-Coverage Tests for Complex Systems Programs.
In Proceedings of the 8th USENIX Symposium on Operating Systems
Design and Implementation (OSDI’08), volume 8, pages 209–224, 2008.
[13] C. Cadar, V. Ganesh, P. M. Pawlowski, D. L. Dill, and D. R. Engler.
EXE: Automatically Generating Inputs of Death.
In Proceedings of
the 13th ACM Conference on Computer and Communications Security,
pages 322–335, 2006.

[14] G. Campana. Fuzzgrind: un outil de fuzzing automatique. In Actes du
7`eme symposium sur la s´ecurit´e des technologies de linformation et
des communications (SSTIC), pages 213–229, 2009.

[15] D. Caselden, A. Bazhanyuk, M. Payer, L. Szekeres, S. McCamant, and
D. Song. Transformation-aware Exploit Generation using a HI-CFG.
Technical report, DTIC Document, 2013.

[16] S. K. Cha, T. Avgerinos, A. Rebert, and D. Brumley. Unleashing
Mayhem on Binary Code. In Proceedings of the IEEE Symposium on
Security and Privacy, pages 380–394, 2012.

[17] S. K. Cha, M. Woo, and D. Brumley. Program-Adaptive Mutational
Fuzzing. In Proceedings of IEEE Symposium on Security and Privacy,
volume 2015-July, pages 725–741, 2015.

[18] P. Chen, X. Xing, B. Mao, L. Xie, X. Shen, and X. Yin. Automatic
construction of jump-oriented programming shellcode (on the x86). In
Proceedings of the 6th ACM Symposium on Information, Computer and
Communications Security, pages 20–29. ACM, 2011.

156

[19] V. Chipounov, V. Georgescu, C. Zamﬁr, and G. Candea. Selective
In Proceedings of the 5th Workshop on Hot

Symbolic Execution.
Topics in System Dependability, 2009.

[20] V. Chipounov, V. Kuznetsov, and G. Candea. S2E: A Platform for
In Proceedings of
In-Vivo Multi-Path Analysis of Software Systems.
the sixteenth International Conference on Architectural Support
for
Programming Languages and Operating Systems, pages 265–278, 2011.
[21] C. Cifuentes and M. Van Emmerik. Recovery of Jump Table Case State-
ments from Binary Code. In Proceedings of the Seventh International
Workshop on Program Comprehension, pages 192–199. IEEE, 1999.

[22] P. M. Comparetti, G. Wondracek, C. Kruegel, and E. Kirda. Prospex:
In Proceedings of the 2009 IEEE

Protocol Speciﬁcation Extraction.
Symposium on Security and Privacy, pages 110–125. IEEE, 2009.

[23] DAPRA.

DARPA Cyber Grand

Challenge.

http:

//www.cybergrandchallenge.com/.

[24] DARPA.

CyberGrandChallenge

samples

git

repository.

https://github.com/CyberGrandChallenge/samples.

[25] L. De Moura and N. Bjørner. Z3: An Efﬁcient SMT Solver.

In
Proceedings of the Theory and Practice of Software, 14th International
Conference on Tools and Algorithms for the Construction and Analysis
of Systems, TACAS’08/ETAPS’08, pages 337–340, Berlin, Heidelberg,
2008. Springer-Verlag.

[26] D. Engler and D. Dunbar. Under-constrained Execution: Making
Automatic Code Destruction Easy and Scalable. In Proceedings of the
2007 international symposium on Software testing and analysis, pages
1–4, 2007.

[27] ForAllSecure.

Unleashing

the Mayhem CRS.

http:

//blog.forallsecure.com/2016/02/09/unleashing-mayhem/.

[28] P. Godefroid, N. Klarlund, and K. Sen. DART: Directed Automated
Random Testing.
the 2005 ACM SIGPLAN
Conference on Programming Language Design and Implementation,
volume 40, pages 213–223, 2005.

In Proceedings of

[29] P. Godefroid, M. Y. Levin, and D. Molnar. SAGE: Whitebox Fuzzing

for Security Testing. ACM Queue, 10(1):20, 2012.

[30] I. Haller, A. Slowinska, M. Neugschwandtner, and H. Bos. Dowser: a
guided fuzzer to ﬁnd buffer overﬂow vulnerabilities. In Proceedings of
the 22nd USENIX Security Symposium, pages 49–64, 2013.

[31] S.-K. Huang, M.-H. Huang, P.-Y. Huang, C.-W. Lai, H.-L. Lu, and
W.-M. Leong.
CRAX: Software Crash Analysis for Automatic
Exploit Generation by Modeling Attacks as Symbolic Continuations. In
Software Security and Reliability (SERE), 2012 IEEE Sixth International
Conference on, pages 78–87. IEEE, 2012.

[32] Indeﬁnite Studies.

The Halting Problem for Reverse Engineers.
http://indeﬁnitestudies.org/2010/12/19/the-halting-problem-for-reverse-
engineers/.

[33] J. Kinder and H. Veith. Jakstab: A Static Analysis Platform for Binaries.
In Proceedings of the 20th international conference on Computer Aided
Veriﬁcation, pages 423–427, Berlin, 2008. Springer-Verlag.

[34] C. Kruegel, W. Robertson, F. Valeur, and G. Vigna. Static Disassembly
of Obfuscated Binaries. In Proceedings of the 13th USENIX Security
Symposium, volume 13, pages 18–18, 2004.

[35] V. Kuznetsov, J. Kinder, S. Bucur, and G. Candea. Efﬁcient State
Merging in Symbolic Execution.
the 2012
ACM SIGPLAN Conference on Programming Language Design and
Implementation (PLDI’12), page 193, 2012.

In Proceedings of

[36] J. Lee, T. Avgerinos, and D. Brumley.

TIE: Principled Reverse
Engineering of Types in Binary Programs. In Proceedings of the 18th
Network and Distributed System Security Symposium (NDSS’11), 2011.
[37] Y. Li, Z. Su, L. Wang, and X. Li. Steering Symbolic Execution to
Less Traveled Paths.
the 2013 ACM SIGPLAN
international conference on Object Oriented Programming Systems
Languages & Applications, pages 19–32, 2013.

In Proceedings of

[38] B. P. Miller, L. Fredriksen, and B. So. An empirical study of the reliabil-
ity of UNIX utilities. Communications of the ACM, 33(12):32–44, 1990.
https:

Fuzzing With Code Coverage By Example.

[39] C. Miller.

//fuzzinginfo.ﬁles.wordpress.com/2012/05/cmiller toorcon2007.pdf.

[40] M. M¨uller-Olm and H. Seidl. Precise Interprocedural Analysis Through
Linear Algebra.
In Proceedings of the 31st ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages, volume 39,
pages 330–341, 2004.

[41] J. A. Navas, P. Schachte, H. Søndergaard, and P.

J. Stuckey.
Signedness-Agnostic Program Analysis: Precise Integer Bounds for
Low-Level Code.
In Lecture Notes in Computer Science (including

subseries Lecture Notes in Artiﬁcial Intelligence and Lecture Notes in
Bioinformatics), volume 7705 LNCS, pages 115–130, 2012.

[42] M. Neugschwandtner, P. Milani Comparetti, I. Haller, and H. Bos. The
BORG: Nanoprobing Binaries for Buffer Overreads.
In Proceedings
of the 5th ACM Conference on Data and Application Security and
Privacy, pages 87–97. ACM, 2015.

[43] J. Newsome, D. Brumley, J. Franklin, and D. Song. Replayer: Automatic
Protocol Replay by Binary Analysis. In Proceedings of the ACM Confer-
ence on Computer and Communications Security, pages 311–321, 2006.
[44] F. P´erez and B. E. Granger. IPython: A System for Interactive Scientiﬁc
Computing. Computing in Science and Engineering, 9(3):21–29, May
2007. http://ipython.org.

[45] J. Pewny, B. Garmany, R. Gawlik, C. Rossow, and T. Holz. Cross-
architecture bug search in binary executables.
In Proceedings of the
2015 IEEE Symposium on Security and Privacy, volume 2015-July,
pages 709–724, 2015.

[46] D. a. Ramos and D. Engler. Under-Constrained Symbolic Execution:
the 24th

Correctness Checking for Real Code.
USENIX Security Symposium, pages 49–64, 2015.

In Proceedings of

[47] P. Saxena, P. Poosankam, S. McCamant, and D. Song. Loop-Extended
Symbolic Execution on Binary Programs. In Proceedings of the 18th
International Symposium on Software Testing and Analysis, page 225,
2009.

[48] E. Schwartz, T. Avgerinos, and D. Brumley. Q: Exploit hardening
made easy. In Proceedings of the 20th USENIX Security Symposium,
volume 8, page 25, 2011.

[49] E. J. Schwartz, T. Avgerinos, and D. Brumley. All You Ever Wanted to
Know About Dynamic Taint Analysis and Forward Symbolic Execution
(but Might Have Been Afraid to Ask).
In Proceedings of the 2010
IEEE Symposium on Security and Privacy, SP ’10, pages 317–331,
Washington, DC, USA, 2010. IEEE Computer Society.

[50] B. Schwarz, S. Debray, and G. Andrews. Disassembly of Executable
In Proceedings of Ninth working conference on

Code Revisited.
Reverse engineering, 2002, pages 45–54. IEEE, 2002.

[51] D. K. Sean Heelan. Automatic Generation of Control Flow Hijacking
Exploits for Software Vulnerabilities. PhD thesis, University of Oxford
computing laboratory, 9 2009.

[52] H. Shacham. The Geometry of Innocent Flesh on the Bone: Return-
into-libc without Function Calls (on the x86).
In Proceedings of the
14th ACM Conference on Computer and Communications Security,
volume 22, pages 552–561, 2007.

[53] Y. Shoshitaishvili, R. Wang, C. Hauser, C. Kruegel, and G. Vigna.
of Authentication Bypass
Firmalice
- Automatic Detection
Vulnerabilities in Binary Firmware.
In Proceedings of Network
and Distributed System Security Symposium, number February, pages
8–11. Internet Society, 2015.

[54] N. Stephens, J. Grosen, C. Salls, A. Dutcher, R. Wang, J. Corbetta,
Y. Shoshitaishvili, C. Kruegel, and G. Vigna. Driller: Augmenting
Fuzzing Through Selective Symbolic Execution. In Proceedings of the
Network and Distributed System Security Symposium, 2016.

[55] L. Szekeres, M. Payer, T. Wei, and D. Song. SoK: Eternal War in
In Proceedings of the IEEE Symposium on Security and

Memory.
Privacy, pages 48–62, 2013.

[56] K. Thompson. Reﬂections on Trusting Trust. Communications of the

ACM, 27(8):761–763, Aug. 1984.

[57] Trail of Bits Blog. How We Fared in the Cyber Grand Challenge.

http://blog.trailofbits.com/2015/07/15/how-we-fared-in-the-cyber-
grand-challenge/.

[58] J. Troger and C. Cifuentes. Analysis of Virtual Method Invocation for
In Proceedings of Ninth Working Conference on

Binary Translation.
Reverse Engineering, 2002, pages 65–74. IEEE, 2002.

[59] L. Xu, F. Sun, and Z. Su. Constructing Precise Control Flow Graphs

from Binaries. University of California, Davis, Tech. Rep, 2009.

[60] F. Yamaguchi, N. Golde, D. Arp, and K. Rieck. Modeling and discov-
ering vulnerabilities with code property graphs. In Proceedings of the
2014 IEEE Symposium on Security and Privacy, pages 590–604, 2014.
[61] F. Yamaguchi, A. Maier, H. Gascon, and K. Rieck. Automatic Inference
of Search Patterns for Taint-style Vulnerabilities.
In Proceedings of
the 2015 IEEE Symposium on Security and Privacy, volume 2015-July,
pages 797–812, 2015.

[62] M. Zalwski.

Bunny

the Fuzzer Documentation.

http:

//code.google.com/p/bunny-the-fuzzer/wiki/BunnyDoc.

157

