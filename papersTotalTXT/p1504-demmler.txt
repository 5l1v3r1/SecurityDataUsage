Automated Synthesis of Optimized Circuits

for Secure Computation

Daniel Demmler

TU Darmstadt, Germany
daniel.demmler@ec-

spride.de

Ghada Dessouky

TU Darmstadt, Germany

ghada.dessouky@cased.de

Farinaz Koushanfar
Rice University, USA
farinaz@rice.edu

Ahmad-Reza Sadeghi
TU Darmstadt, Germany

ahmad.sadeghi@cased.de

Thomas Schneider
TU Darmstadt, Germany
thomas.schneider@ec-

spride.de

Shaza Zeitouni

TU Darmstadt, Germany

shaza.zeitouni@cased.de

ABSTRACT
In the recent years, secure computation has been the subject
of intensive research, emerging from theory to practice. In
order to make secure computation usable by non-experts,
Fairplay (USENIX Security 2004) initiated a line of research
in compilers that allow to automatically generate circuits
from high-level descriptions of the functionality that is to
be computed securely. Most recently, TinyGarble (IEEE
S&P 2015) demonstrated that it is natural to use existing
hardware synthesis tools for this task.

In this work, we present how to use industrial-grade hard-
ware synthesis tools to generate circuits that are not only
optimized for size, but also for depth. These are required
for secure computation protocols with non-constant round
complexity. We compare a large variety of circuits gener-
ated by our toolchain with hand-optimized circuits and show
reduction of depth by up to 14%.

The main advantages of our approach are developing cus-
tomized libraries of depth-optimized circuit constructions
which we map to high-level functions and operators, and
using existing libraries available in the industrial-grade logic
synthesis tools which are heavily tested. In particular, we
show how to easily obtain circuits for IEEE 754 compliant
ﬂoating-point operations. We extend the open-source ABY
framework (NDSS 2015) to securely evaluate circuits gener-
ated with our toolchain and show between 0.5 to 21.4 times
faster ﬂoating-point operations than previous protocols of
Aliasgari et al. (NDSS 2013), even though our protocols
work for two parties instead of three or more. As application
we consider privacy-preserving proximity testing on Earth.

Keywords
secure computation; automation; optimization, logic design;
hardware description

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, CO, USA.
c(cid:13) 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813678.

1.

INTRODUCTION

Secure computation allows multiple parties to evaluate a
function on their private inputs without revealing any infor-
mation except for the result of the computation. The ﬁrst pro-
tocols given were Yao’s garbled circuits protocol [Yao86] and
the protocol of Goldreich-Micali-Wigderson (GMW) [GMW87].
Both protocols securely evaluate a Boolean circuit that rep-
resents the desired functionality. Since then, a large body of
literature has been investigating the design and implementa-
tion of practical circuit-based secure computation in diﬀerent
adversarial settings. While designing eﬃcient and correct
circuits for smaller building blocks for simple applications
can be performed manually by experts, this task becomes
highly complex and time consuming for large applications
such as ﬂoating-point arithmetic and signal processing, and
is thus error-prone. Faulty circuits could potentially break
the security of the underlying applications, e.g., by leaking
additional information about a party’s private inputs. Hence,
an automated way of generating correct large-scale circuits
which can be used by regular developers is highly desirable.
A large number of compilers for secure computation such
as [MNPS04, BNP08, HKS+10, HEKM11, Mal11, MLB12,
KSS12, HFKV12, SZ13, KSMB13, ZSB13] implemented cir-
cuit building blocks manually. Although tested to some
extent, showing the correctness of these compilers and their
generated circuits is still an open problem.

Recently, TinyGarble [SHS+15] took a completely diﬀerent
approach by using already established powerful hardware
logic synthesis tools and customizing them to be adapted
to automatically generate Boolean circuits for functions to
be evaluated by Yao’s garbled circuits protocol. The ad-
vantage of this approach lies in the fact that these tools
are being used by industry for designing digital circuits,
and hence are tested thoroughly, which is justiﬁed by the
high production costs of Application-Speciﬁc Integrated Cir-
cuits (ASICs). However, these tools are designed primarily
to synthesize circuits on hardware target platforms such as
ASICs or conﬁgurable platforms such as Field Programmable
Gate Arrays (FPGAs) or Programmable Array Logic (PAL).
Using hardware logic synthesis tools for special purposes
such as generating circuits for secure computation, requires
customizations and workarounds. Exploiting these tools
promises accelerated and automated circuit generation, signif-
icant speedup, and ease in designing and generating circuits

1504for much more complicated functions, while also maintaining
the size (and depth) eﬃciency of hand-optimized smaller
circuit building blocks. In particular, TinyGarble exploited
the sequential logic to synthesize highly compact circuits.
However, TinyGarble considered only few functionalities: ad-
dition, Hamming weight, comparison, multiplication, matrix
multiplication, AES, SHA-3, and a MIPS CPU.

In this work we continue along the lines of using logic
synthesis tools for secure computation and automatically
synthesize an extensive set of basic and complex operations,
including IEEE 754 compliant ﬂoating-point arithmetic. In
contrast to TinyGarble, which generated size-optimized cir-
cuits for Yao’s garbled circuits protocol, we focus on synthesiz-
ing depth-optimized circuits for the GMW protocol [GMW87].
Although the round complexity of the GMW protocol de-
pends on the circuit depth, it has some advantages compared
with Yao’s constant-round protocol: 1) it allows to pre-
compute all symmetric cryptographic operations in a setup
phase and thus oﬀers a very eﬃcient online phase, 2) its
setup phase is independent of the function being computed,
3) it balances the workload equally between all parties, 4)
GMW allows for better parallel evaluation of the same circuit
(SIMD operations) [SZ13, DSZ15], 5) it can be extended to
multiple parties, and 6) the TinyOT protocol [NNOB12]
which provides security against stronger active adversaries,
has an online phase which is very similar to that of GMW,
and its round complexity also depends on the circuit depth.
We combine industrial-grade logic synthesis tools with the
recent open-source ABY framework [DSZ15] which imple-
ments state-of-the-art optimizations of the two-party pro-
tocols by GMW and Yao. On the one hand, our approach
allows to use existing and tested libraries for complex func-
tions such as IEEE 754 compliant ﬂoating-point operations
that are already available in these tools without the need to
re-implement them manually. On the other hand, this allows
to use high-level input languages such as Verilog where we
map high-level operations to our optimized implementations
of basic functions.

After summarizing related work in §1.2 and preliminaries

1.1 Outline and Our Contributions
in §2, we present our following contributions:
Architecture and Logic Synthesis (§3). We provide a
fully-automated end-to-end toolchain allowing the developer
to describe the function to be computed securely in a high-
level Hardware Description Language (HDL), such as Verilog,
followed by the generation of the required customized cir-
cuit and its secure evaluation using either GMW [GMW87]
or Yao’s protocol [Yao86]. Our toolchain uses hardware
synthesis tools, both open-source and commercial, to gener-
ate depth- and size-optimized circuits customized for both
protocols respectively. For this, we manipulate and engi-
neer state-of-the-art hardware synthesis tools with synthesis
constraints and customized libraries to generate circuits opti-
mized for either protocol according to the developer’s choice.

Optimized Circuit Building Blocks (§4). We develop
a library of depth-optimized and size-minimized circuits, in-
cluding arithmetic operations (e.g., addition, subtraction,
multiplication, division), comparison, counter, and multi-
plexer, which can be used to construct more complex func-
tionalities such as various distances, e.g., Manhattan, Eu-

clidean, or Hamming distance. Some of the implemented
building blocks show improvements in depth compared with
hand-optimized circuits of [SZ13] by up to 14%, while oth-
ers show at least equivalent results. Assembling sub-blocks
from our customized library can be used to construct more
complicated functionalities, which would otherwise be im-
possible to build and optimize by hand. We exploit the
capabilities of our synthesis tools to bind high-level operators
(e.g., the ‘+’ operator) and functions to optimized circuits
in our library to allow the developer to describe circuits in
Verilog using high-level operators. We also utilize built-in
Intellectual Property (IP) libraries in commercial hardware
synthesis tools to generate Boolean circuits for more complex
functionalities such as ﬂoating-point arithmetic which have
been veriﬁed and tested extensively.
Benchmarks and Evaluation (§5). We use the ABY
framework [DSZ15] to securely evaluate the Boolean cir-
cuits generated by our hardware synthesis toolchain. More-
over, we extend the list of available operations in ABY by
multiple ﬂoating-point operations. In contrast to previous
works that built dedicated and complex protocols for secure
ﬂoating-point operations, we use highly tested industrial-
grade ﬂoating point libraries. We compare the performance
of our constructions with related work. For ﬂoating-point
operations we achieve between 0.5 to 21.4 times faster run-
time than [ABZS13] and 0.1 to 3 267 times faster runtime
than [KW14]. We emphasize that we achieve these improve-
ments even in a stronger setting, where all but one party
can be corrupted and hence our protocols also work in a
two-party setting, whereas the protocols of [ABZS13, KW14]
require a majority of the participants to be honest and hence
need n ≥ 3 parties. We also present timings for integer
division that outperform related work of [ABZS13] (3-party)
by a factor of 0.6 to 3.7 and related work of [KSS13] (2-party)
by a factor of 32.4 to 274. Additionally, we present bench-
marks for matrix multiplication, but here we are slower than
previous approaches of [BNTW12, ZSB13, DSZ15].
Application: Private Proximity Testing (§6). A real
world application of ﬂoating-point calculations on private in-
puts is privacy-preserving proximity testing on Earth [ˇSG14].
We implement the formulas described in [ˇSG14] with our
ﬂoating-point building blocks and achieve faster runtime
as well as higher precision compared to their protocols.
This demonstrates that our automatically generated building
blocks can outperform hand-built solutions.
1.2 Related Work

We classify related work into diﬀerent categories next.

TinyGarble. Most related to our work is the recently pro-
posed TinyGarble framework [SHS+15] which was the ﬁrst
work to consider using hardware-synthesis tools to automati-
cally generate circuits for secure computation. The authors
used sequential circuits that allow to describe a circuit as
a loop over a smaller sub-circuit (e.g., an (cid:96)-bit ripple-carry
adder can be represented as iterating (cid:96) times over a single
bit adder). Thereby, they are capable of generating highly
compact circuit descriptions. Although this approach allows
to represent the circuits in a highly memory-eﬃcient way, the
total number of gates that are evaluated securely and hence
the communication and total number of crypto operations
remains unchanged. As the main goal of TinyGarble was to
assess the memory eﬃciency, the paper gives benchmarks

1505only for evaluating a single circuit, the ripple-carry adder,
with Yao’s garbled circuits protocol.
As described before in §1, the GMW protocol has sev-
eral advantages over Yao’s garbled circuits protocol (pre-
computation, load balancing, multiple parties, etc.), but
requires circuits with low depth. Unfortunately, sequential
circuits cannot directly be applied to the GMW protocol,
since the sequential circuit structure can signiﬁcantly in-
crease the depth of the circuit and thus the communication
rounds required by GMW. Our work is the ﬁrst to consider
automated hardware synthesis of low-depth combinational
circuits optimized for use in the GMW protocol, as well as
size-optimized circuits for Yao’s protocol. Our work also al-
lows developers to write high-level Verilog code which can be
automatically mapped to our optimized circuits by binding
our circuit descriptions to arithmetic operators.

Secure Computation Compilers from Domain Spe-
ciﬁc Languages. Fairplay [MNPS04, BNP08] and the com-
patible PAL compiler [MLB12] compile a functionality in a
domain speciﬁc input language, called Secure Function Def-
inition Language (SFDL), into a Boolean circuit described
in the Secure Hardware Deﬁnition Language (SHDL) which
is evaluated with Yao’s garbled circuits protocol. Our in-
termediate circuit description is very similar to Fairplay’s
SHDL; in fact we could easily process SHDL input. Simi-
larly, TASTY [HKS+10] proposed a domain speciﬁc input
language called TASTYL that allows to combine protocols
that mix Yao’s garbled circuits with additively homomor-
phic encryption. The compiler presented in [KSS12] also
provides a domain speciﬁc input language and showed scal-
ability to circuits consisting of billions of gates that were
evaluated with a variant of Yao’s protocol with security
against malicious adversaries. Recently, ObliVM [LWN+15]
introduced a domain speciﬁc language that is compiled into
a Yao-based secure computation protocol with support for
Oblivious RAM (ORAM).

Instead of using a domain speciﬁc input language, we use
existing Hardware Description Languages (HDLs) such as
Verilog or VHDL that are already known by many develop-
ers. Thereby, we can use existing code and allow a large
community of developers to specify functionalities without
the necessity of learning a new language.

Secure Computation Compilers from ANSI C. The
following secure computation tools use a subset of the ANSI C
programming language as input. CBMC-GC [HFKV12] ini-
tiated this line of development and used a SAT solver to
generate size-optimized Boolean circuits from a subset of
ANSI C. PCF [KSMB13] compiles into a compact interme-
diate representation that also supports loops, similar to the
sequential circuits of TinyGarble described above. Both
CBMC-GC and PCF target Yao’s garbled circuits protocol
and hence only optimize for size. PICCO [ZSB13] is a source-
to-source compiler that allows parallel evaluation and uses
secure computation protocols based on linear secret sharing
with at least three parties.

Although ANSI C is widely known as well, it has the
drawback that some operations are either not supported (e.g.,
pointer arithmetic) or incur signiﬁcant costs when compiled
into a circuit (e.g., array access depending on private values).
Thereby, existing C code sometimes needs to be rewritten or
results in ineﬃcient protocols. Although we do not eliminate
these restrictions in our work, these issues do not occur when

taking existing functionalities described in HDLs that do
not support pointers and often avoid accesses to arrays with
private indices, as these result in costly multiplexers.

Secure Computation Libraries.
In this class of tools,
the developer composes the circuits to be evaluated securely
from circuit libraries that are instantiated at runtime. This
approach has been proposed in FastGC [HEKM11] and VM-
Crypt [Mal11] both of which are based on Yao’s garbled
circuits. In fact, all implementations of the GMW proto-
col [CHK+12, SZ13, DSZ15] are secure computation libraries.
In our work we extend the ABY framework [DSZ15] to
process pre-compiled sub-circuits that can then be composed
dynamically at runtime.

2. PRELIMINARIES
In this section we provide preliminaries and background re-
lated to the GMW protocol (§2.1), hardware synthesis (§2.2),
and the IEEE 754 ﬂoating-point standard (§2.3).
2.1 The GMW protocol

In the GMW protocol [GMW87], two or more parties com-
pute a function that is encoded as Boolean circuit. The
parties’ private inputs and all intermediate gate values are
perfectly hidden by an XOR-based secret sharing scheme.
GMW allows to evaluate XOR gates locally, without interac-
tion, using only one-time pad operations and thus essentially
for free. AND gates, however, require interaction in the
form of Oblivious Transfers (OTs) or Beaver’s multiplication
triples [Bea91] that can be pre-computed in a setup phase,
which is independent from the parties’ private inputs and
the function being computed. This pre-computation can be
achieved eﬃciently by using OT extension [IKNP03, ALSZ13]
as shown in [CHK+12, SZ13]. After evaluating all circuit
gates in the online phase, the output can be reconstructed
by computing the XOR of the resulting output shares.

In order to achieve high performance, the total number of
AND gates in the circuit (the circuit size S) and the number
of AND gates from any input to any output wire (the circuit
depth D) should be low. In this work we use the variant
of the GMW protocol with two parties and security against
passive/semi-honest adversaries.
2.2 Hardware Synthesis

Hand-optimizing Boolean circuits for secure computation
is a tedious, error-prone and time-consuming task. Using
hardware synthesis tools for synthesizing and optimizing
these circuits, and even more complex circuits that cannot be
easily hand-optimized, seems to be a promising and natural
approach. As shown in TinyGarble [SHS+15], using hardware
synthesis tools allows to reduce the time and eﬀort invested
by further automating the process of generating optimized
Boolean netlists in terms of circuit size and/or depth.

Overview. Hardware or logic synthesis is the process of
translating an abstract form of circuit description into its
functionally equivalent gate-level logic implementation using
a suite of diﬀerent optimizations and mapping algorithms
that have been a theme of research over years. A logic
synthesis tool is a software which takes as input a function
description (functional, behavioral or structural description,
state machine, or truth table) and transforms and maps this
description into an output suitable for the target hardware
platform and manufacturing technology.

1506Tools. Common target hardware platforms for synthesized
logic include Field Programmable Gate Arrays (FPGAs),
Programmable Array Logics (PALs), and Application Spe-
ciﬁc Integrated Circuits (ASICs). ASIC synthesis tools, as
opposed to FPGA synthesis tools, are used in this work due
to the increased ﬂexibility and options allowed in their syn-
thesis tools, and because FPGA synthesis tools map circuits
into Look-up Tables (LUTs) and ﬂip-ﬂop (FF) gates in ac-
cordance with FPGA architectures, and not Boolean gates,
which makes them unsuitable for this work. We used two
main ASIC synthesis tools interchangeably: Synopsys Design
Compiler (DC) [Syn10] which is one of the most popular
commercial logic synthesis tools, and the open-source aca-
demic Yosys-ABC toolchain [Wol, Ber]. In the following, we
focus on brieﬂy describing the synthesis ﬂow of Synopsys DC.

Synthesis Flow. A Hardware Description Language (HDL)
description of the desired circuit is provided to Synopsys DC.
Operations in this description get mapped to the most ap-
propriate circuit components selected by Synopsys DC from
two types of libraries: the generic technology (GTECH)
library of basic logic gates and ﬂip-ﬂops called cells, and syn-
thetic libraries consisting of optimized circuit descriptions for
more complex operations. Designware [Syn15] is a built-in
synthetic library provided by Synopsys, consisting of tested
IP constructions of standard and complex cells frequently
used, such as arithmetic or signal processing operations. This
ﬁrst mapping step is independent of the actual circuit man-
ufacturing technology and results in a generic structural
representation of the circuit. This gets mapped next to low-
level gates selected from a target technology library to obtain
a technology-speciﬁc representation: a list of Boolean and
technology-speciﬁc gates (e.g., multiplexers), called netlist.
Synopsys DC performs all of the above mapping and syn-
thesis processes under synthesis and optimization constraints,
which are directives and options provided by the developer
to optimize the delay, area and other performance metrics of
a synthesized circuit.

Input to these hardware synthesis tools can be a pure
combinational circuit, which maps only to Boolean gates, or
a sequential circuit that requires a clock signal and FF gates
which are memory elements to store the current state of the
circuit. The output of a sequential circuit is a function of
both the circuit inputs and the current state. In this work,
we constrain circuit description to combinational circuits.

High-Level Synthesis. Logic synthesis tools accept the
input function description most commonly in a HDL for-
mat (Verilog or VHDL), whereas more recent logic synthesis
tools support high-level synthesis (HLS). This allows them
to accept higher-level circuit descriptions in C/C++ or sim-
ilar high-level programming alternatives. The HLS tools
then transform the functional high-level input code into
an equivalent hardware circuit description, which in turn
can be synthesized by classic logic synthesis. Although this
higher abstraction is more developer-friendly and usable,
performance of resulting circuits is often inferior to HDL
descriptions, unless heavy design constraints are provided to
guide the mapping and optimization process.

2.3 The IEEE 754 Floating-Point Standard

Floating-point (FP) numbers allow to represent approxi-
mations of real numbers with a trade-oﬀ between precision

and range. The IEEE 754 ﬂoating-point standard [FP008]
deﬁnes arithmetic formats for ﬁnite numbers including signed
zeros and subnormal numbers, inﬁnities, and special “Not
a Number” values (NaN) and rounding rules to be satisﬁed
when rounding numbers during ﬂoating-point operations,
e.g., rounding to nearest even. Additionally, the standard
deﬁnes exception handling such as division by zero, overﬂow,
underﬂow, inﬁnity, invalid and inexact.

The IEEE 754 Standard 32-bit single precision ﬂoating-
point format consists of 23 bits for signiﬁcand, 1 bit for sign
and 8 bits for exponent distributed from MSB to LSB as
follows: sign [31], exponent [30:23], and signiﬁcand [22:0].
The 64-bit double precision format consists of 52 bits for
signiﬁcand, one bit for sign, and 11 bits for exponent.

3. OUR TOOLCHAIN

We describe our toolchain here by presenting our architec-

ture followed by a detailed description of each component.
3.1 Architecture

An overview of our architecture is shown in Fig. 1. We
provided the hardware synthesis tools with optimization
and synthesis constraints along with a set of customized
technology and synthesis libraries (cf. §3.2), to map the
input circuit description in Verilog (or any other HDL) into
a functionally-equivalent Boolean circuit netlist in Verilog.
The output netlist, in the meantime, is constrained to consist
of AND, XOR, INV and MUX gates.

Functionality in HDL

Libraries

Constraints

Hardware Synthesis

Synthetic

Synopsys
Design-

ware

Customized
Technology

Circuit
Building
Blocks

InputB

Netlist

Scheduler

Parsed &

Scheduled Netlist

ABY Framework

Secure

Computation

Protocol

Outputs

InputA

Figure 1: Architecture Overview

The Verilog netlist is then parsed and scheduled, and
provided as input to the ABY framework [DSZ15], which we
extended to process this netlist and generate the Boolean
circuit described in it. The evaluation of the GMW protocol
in ABY minimizes the number of communication rounds, i.e.,
all AND gates on the same layer are evaluated in parallel.
In the following we describe in further detail the main com-
ponents of our toolchain architecture: logic synthesis (§3.2),
scheduling (§3.3), and extending the ABY framework (§3.4).

15073.2 Hardware and Logic Synthesis

The GMW protocol and Yao’s protocol require that the
function to be computed is represented as a Boolean circuit.
As described in detail in §1.2, previous work, such as the
Fairplay framework [MNPS04, BNP08], used domain-speciﬁc
high-level languages that allow a developer to describe the
function to be computed, which in turn gets compiled into a
Boolean circuit. Other compilers allow compilation of circuit
descriptions written in C into size-optimized Boolean circuits,
e.g., [HFKV12], whereas further tools allow a developer to
build up the circuit by instantiating its building blocks from
within custom libraries composed of these building blocks,
e.g., [HEKM11, Mal11]. All these works rely on custom-made
compilers and/or languages which have to compile from a
high-level description of the functionality and map it to a
Boolean circuit. This may be considered as “reinventing the
wheel” since Boolean mapping and optimization is the core
of hardware synthesis tools, and has been researched for long.
It has been argued, however, that such “hardware compilers”
target primarily hardware platforms and therefore involve
technology constraints and metrics which are not directly
related to the purpose of generating Boolean circuits for
secure computation. Writing circuits in HDL, such as Verilog
or VHDL, is not entirely high-level, and involves hardware
description paradigms which may not be similar to high-level
programming paradigms. Furthermore, they rely on the use
of sequential logic rather than pure combinational logic.

Exploiting Logic Synthesis. However, the TinyGarble
framework [SHS+15] exploited these very same points, and
employed hardware synthesis tools in generating compact
sequential Boolean circuits for secure evaluation by Yao’s gar-
bled circuits protocol [Yao86]. The work in our paper extends
this further by using the hardware synthesis tools to generate
combinational circuits of more complex functionalities for
evaluation by both Yao and the GMW protocol [GMW87],
while excluding all design and technology optimization met-
rics. The synthesis and generation of the Boolean netlist by
the synthesis tools (cf. §2.2) can be optimized according to
the synthesis constraints and optimization options provided.
Hardware synthesis tools conventionally target circuit synthe-
sis on hardware platforms, but can be adapted and exploited
for secure computation purposes to generate Boolean netlists
which are AND-minimized (depth-optimized primarily for
GMW or size-optimized for Yao’s garbled circuits).

3.2.1 Customizing Synthesis
In the following, we focus on how we customized the syn-
thesis ﬂow of Synopsys DC to generate our Boolean netlists.

Synthesis Flow. The synthesis and optimization con-
straints that can be provided to Synopsys DC allow us to
manipulate it to serve our purposes in this work, and generate
depth-optimized circuit netlists for evaluation with GMW.
Moreover, we developed a synthetic library of optimized
basic cells and depth/size-optimized circuit building blocks
that can be assembled by developers to build more complex
circuits, and a customized technology library to constrain
circuit mapping to XOR and AND gates only. The diﬀerent
libraries and our engineered customizations to achieve this
are described next.

Synthetic Libraries. The ﬁrst step of the synthesis ﬂow is
to convert arithmetic and conditional operations (if-else,
switch-case) to their functionally-equivalent logical repre-

sentations. By default, they are mapped to cells (either
simple gates or more complex circuits such as adders and
comparators) extracted from the GTECH library and the
built-in Synopsys DC DesignWare library [Syn15] (cf. §2.2).
A single cell can have diﬀerent implementations from which
the synthesis tool selects, depending on the provided con-
straints. For example, the sum of two (cid:96)-bit numbers can be
replaced with 1 out of 10 diﬀerent adder implementations
available in both libraries, depending on the optimization
constraints provided (optimizing for area or delay).

Our Optimized Circuit Building Blocks Library. Be-
sides the standard built-in libraries, we developed our own
DesignWare circuits in a customized synthetic library. It
consists of depth-optimized circuit descriptions (arithmetic,
comparators, 2-to-1 multiplexer, etc.) customized for GMW,
as well as size-optimized counterparts for Yao’s garbled cir-
cuits. Synopsys DC can then be instructed to prefer auto-
mated mapping to our customized circuit descriptions (cf. §4)
rather than built-in circuits (cf. §3.2.3 for developer usage).
Technology Library. The intermediate generic representa-
tion of the circuit obtained in the step before is then mapped
into low-level gates extracted from a technology library. A
technology library is a library that speciﬁes the gates and
cells that can be manufactured by the semiconductor ven-
dor onto the target platform. The library consists of the
functional description (such as the Boolean function they
represent) of each cell, as well as their performance and tech-
nology attributes such as timing parameters (intrinsic rise
and fall times, capacitance values, etc.) and area parameters.
Technology libraries targeting ASICs contain a range of
cells ranging from simple 2-input gates to more complex gates
such as multiplexers and ﬂip-ﬂops. A single cell can also
have diﬀerent implementations which have varying technology
attributes. Ultimately, the goal of the synthesis tool is to
map the generic circuit description into a generated netlist
of cells from this target technology such that user-provided
constraints and optimization goals are satisﬁed.

Our Customized Technology Library. In order to meet
our requirements of the Boolean circuit netlists required in
this work, we constrain Boolean mapping to non-free AND
and free XOR gates. However, Synopsys DC requires that
synthesis runs with at least OR, AND and inverter (INV) gates
deﬁned in the technology library. We developed a customized
technology library which has no manufacturing or technology
rules deﬁned, similar to the approach in TinyGarble, and we
manipulated the cost functions of the gates by setting the
area and delay parameters of XOR gates to 0, and set them
to very high non-zero values for OR gates to ensure their
exclusion in mapping. Their very high area and delay costs
force Synopsys DC to re-map all instances of OR gates to
AND and INV gates according to their equivalent Boolean rep-
resentation (A∨B=¬(¬A∧¬B)), and to optimize the Boolean
mapping in order to meet the speciﬁed area/delay constraints.
We set the area and delay costs of an inverter (INV) gate
to zero, as they can be replaced with XOR gates with one
input buﬀered to constant one. For AND gates, the area
and delay costs are set to reasonably high values, but not
too high so that they are not excluded from synthesis. We
set MUX gates to area cost equivalent to that of a single
AND gate (since the 2-to-1 multiplexer construction in [KS08]
is composed of a single AND gate and 2 XOR gates). And
we set its delay cost equivalent to 0.25 times more than that

1508of an AND gate to ensure preferred but also non-redundant
mapping to MUX gates whenever feasible. We concluded
that these settings give the most desirable mapping results
after experimenting with Synopsys DC mapping behavior in
diﬀerent scenarios.

Synthesis Constraints. We provide constraints that make
delay optimization of the circuit a primary objective followed
by area optimization as a secondary objective when generat-
ing depth-optimized circuits for GMW. We set the preference
attribute to XOR gates, and disable circuit ﬂattening to avoid
remapping of XOR gates to other gates. Synthesis tools are
not primarily designed to minimize Boolean logic by maxi-
mizing XOR gates and reducing the multiplicative complexity
of circuits within multi-level logic minimization. This is be-
cause XOR gates are only considered as “free” gates in secure
computation applications, whereas in the domain of tradi-
tional hardware CMOS design, NAND gates are the universal
logic gates from which all other gates can be constructed.
Hence, the tools need to be heavily manipulated to achieve
our objectives. These constraints and technology library
settings also have to be customized diﬀerently when we want
to generate circuits optimized for other secure computation
protocols, such as Yao’s garbled circuits.

Construction of More Complex Circuits. The cus-
tomized circuit descriptions we developed can be used to
build higher-level and more complex applications. We as-
sembled complex constructions such as Private Set Inter-
section (PSI) primitives (bitwise-AND, pairwise comparison,
and Sort-Compare-Shuﬄe networks as described in [HEK12])
using our customized building blocks, and they have demon-
strated equivalent AND gate count and depth as their hand-
optimized counterparts in [HEK12]. In general, all sorts
of more complex functionalities and primitives can be con-
structed by assembling these circuit building blocks along
with built-in Designware IP implementations. Consequently,
these more complex circuits can then be appended to our li-
brary to be re-used in building further more complex circuits,
and so on, in a modular and hierarchical way.

HDLs also allow a developer to describe circuits recur-
sively which can be synthesized, which is often the most
eﬃcient paradigm for describing depth-optimized circuit con-
structions such as the depth-optimized “greater than” opera-
tion [GSV07], the Waksman permutation network [Wak68],
or the Boyar-Peralta counter [BP06].

3.2.2 High-level Function and Operator Mapping
An alternative to describing the circuits for HLS in high-
level C/C++ is to allow developers to input their circuit
descriptions in high-level Verilog, by calling operators and
functions, which we map to “instantiate” circuit modules
such as depth-optimized adders or comparators from our
customized synthetic library. This allows high-level circuit
descriptions without incurring the drawbacks of using HLS
tools, such as inferior hardware implementation (cf. §2.2).
Mapping operators. We prepared a library description
which links our customized circuits into the Synopsys DC.
This provides a description of each circuit module, its diﬀer-
ent implementations, and the operator bound to each module.
These operators can be newly created, or already built-in,
such as (‘+’, ‘-’, ‘*’, etc.), but bound to our customized
circuits. For instance, when synthesizing the statement
Z = X + Y, Synopsys DC is automated to map the ‘+’ to

our customized Ladner-Fischer adder, rather than a built-in
adder implementation.

Mapping Functions. We mapped functions to instantiate
circuit modules by creating a global Verilog package ﬁle
which declares these functions and which circuit modules
they instantiate when being called. This package ﬁle is then
included in the high-level Verilog description code which calls
on these functions.

Explicit Instantiation. Other more complex circuits can
only be explicitly called from our customized building blocks
library, as well as from the Designware IP library which
oﬀers a wide range of IP implementations, all of which have
veriﬁed and guaranteed correctness, such as the ﬂoating-
point operations we present and benchmark in §5.3. A list
of available Designware IP implementations can be found
in [Syn15].

High-level Circuit Description Example. In Fig. 2, we
show how the depth-optimized constructions of the Manhat-
tan, Euclidean and Hamming distances [SZ13] are described
using high-level Verilog. The Manhattan distance between
two points is the distance in a 2-dimensional space between
these two points based only on horizontal and vertical paths.
The Euclidean distance between two points computes the
length of the line segment connecting them. Hamming dis-
tance between two strings computes the number of positions
at which the strings are diﬀerent.

In the Euclidean distance description, in lines 19 and 20
the ‘-’ operator is mapped automatically to our Ladner-
Fischer subtractor. The function sqr called in lines 23 and 24,
is automatically mapped to instantiate our Ladner-Fischer
squarer. We declared and bound this function correctly in
the package ﬁle ‘func_global.v’ which is included in line 6.
case statements (as are if...else statements) in lines 26-
34 are also mapped to our depth-optimized multiplexer. In
line 38, a carry-save network is explicitly instantiated from
our library described in §4.2, since some circuit blocks are
not mapped to functions and operators and have to be ex-
plicitly instantiated due to their structure and design. In
the Manhattan distance description, the absolute diﬀerences
are computed by calling the ‘abs_diff’ function in line 12
which is also mapped to instantiate the corresponding circuit.
The same high-level abstraction can be seen in the Hamming
distance description. Once these distance circuits are con-
structed, they can be appended to our blocks library to be
easily re-used in more complex functionalities.

3.2.3 Developer Usage
By default, Synopsys DC maps operations to Designware
circuit descriptions. For operations that have multiple circuit
descriptions which are optimized for diﬀerent parameters,
e.g., area or delay, Synopsys DC selects the most appropri-
ate circuit description which best satisﬁes the constraints
provided by the developer in the synthesis script. Alterna-
tively, the developer can explicitly select a speciﬁc circuit
description to map an operation to. For example, the built-in
Designware adder circuit is available in diﬀerent implemen-
tations: ripple-carry, carry-look-ahead and other area- and
delay-optimized implementations. Synopsys DC selects the
most suitable implementation to map ‘+’ to, depending on
the developer-provided constraints. Furthermore, the devel-
oper can also specify in the synthesis script that a certain

1509Figure 2: High-level description of the Hamming, Euclidean and Manhattan distances.

implementation is preferred, or the implementation can be
explicitly called in the Verilog code.

In order for developers to use our synthetic libraries in-
stead of Designware to map to our customized circuits, they
have to decide for which metric to optimize: depth or size.
Accordingly, developers add the libraries’ paths and a single
command in the synthesis script to direct Synopsys DC to
optimize for either depth (for GMW) or size (for Yao), and to
prefer mapping to which set of circuit descriptions. If devel-
opers want to instantiate a speciﬁc circuit description from
our customized libraries, they can call it by the name of the
circuit module and deﬁning its input/output and parameters.
Optimization constraints are generally speciﬁed by the de-
veloper once for the entire top-level circuit description in the
synthesis script, while some sub-circuits require speciﬁc opti-
mization constraints. We already speciﬁed the optimization
constraints for our customized circuit building blocks.

3.2.4 Challenges of Logic Synthesis for Secure Com-

putation

Conventionally synthesis tools are best at synthesizing
sequential hardware circuits with a clock input and ﬂip-ﬂops.
This also means that the actual circuit netlists synthesized
are much more compact than combinational Boolean cir-
cuits. However, for the purpose of this work, the netlists
required are combinational to be evaluated with a secure
computation protocol in the ABY framework. This implies
synthesis of circuits which reach up to 10 million gates and
beyond, which is time- and resource-consuming for hardware
synthesis tools. In the hardware synthesis world, this can be

managed by generating sub-blocks in a hierarchical fashion,
and appending them into one top-level circuit.

However, in this work, one coherent Boolean netlist is
required for a single functionality, hence all sub-blocks of
a hierarchy must be un-grouped during synthesis, which is
resource consuming. We use workarounds to ease the memory
and resource requirements. However, this may come at the
expense of inter-block optimization across block boundaries,
but this can also be customized for individual synthesis
scenarios by enabling the boundary optimization option when
desired.
3.3 Scheduling

The output netlist generated from the hardware synthesis
tools has to be parsed in an intermediate step before being
provided to the ABY framework. A parser and scheduler
topologically sorts and schedules the netlist gates [KA99],
since the Verilog netlist output from some synthesis tools is
not topologically sorted, i.e., a wire can be listed as input
to one gate before assigning output to it from another. The
scheduler generates a Boolean netlist in a format which is
similar to Fairplay’s SHDL [MNPS04]. All gates and wires
are renamed to integer wire IDs for easier processing by the
ABY framework, and complex statements are rewritten as
one or several available gates. These steps ensure that the
ﬁnal netlist contains only AND, XOR, INV and MUX gates.
3.4 Extending the ABY Framework

The open-source ABY framework [DSZ15] is an extensive
tool that enables a developer to manually implement secure
two-party computation protocols by oﬀering several low-level

26-35: conditional statements mapped to multiplexers23,24: “sqr“operator is bound to LF-squarer in synthetic library description38: “ csn“ instantiated from synthetic library explicitly12: “reducing_xor“mapped to equivalent module in “func_global.v “ 14: “ boyar_counter“ instantiated from synthetic library explicitly12: “ +“mapped to LF-adder and “abs_diff“ function mapped to instantiate “abs_diff“ module in “func_global.v “ package file19,20: “ -“mapped to LF-subtractor1510as well as intermediate circuit building blocks that can be
freely combined. We extended the ABY framework with
an interface where externally constructed blocks made of
low-level gates can be input in a simple text format, similar
to SHDL [MNPS04] and the circuit format from [ST], that
we can parse as well, with some modiﬁcations.

This interface is used to input the parsed and scheduled
netlists from our hardware synthesis. ABY creates a Boolean
circuit with low depth from that input netlist, i.e. it schedules
AND gates on the earliest possible layer and automatically
processes all AND gates in one layer in parallel. A developer
has two options: 1) our hardware synthesized netlist can
be used as a full protocol instance from private inputs to
output or 2) the netlist’s functionality can be used as a
building block and combined with other synthesized or hand-
built sub-circuits within ABY in order to create the whole
secure computation protocol. The output of ABY is a fully
functional secure computation protocol that is split into setup
phase and online phase, that can be evaluated on two parties’
private inputs.

4. BULIDING BLOCKS LIBRARY

We implemented the following blocks in Verilog as pure
combinational circuits and synthesized their Boolean netlists
using both Synopsys DC and Yosys-ABC interchangeably to
show that the framework is independent of the used synthesis
tool. All implemented circuits have conﬁgurable parameters
such that they can handle the desired bit-width (cid:96) of the
inputs and/or number of inputs n. We summarize and
compare our synthesis results with their hand-optimized
counterparts in [HKS+10, HEK12, SZ13]. The two main
comparison metrics are size S which is the circuit size in terms
of non-free AND gates, and depth D which is the number of
AND gates along the critical path of the circuit. XOR gates
are considered to be free, as the GMW protocol and Yao’s
protocol with free XORs [KS08] allow to securely evaluate
XOR gates locally without any communication. Next we
show the results for functionalities that have improved depth
or size compared with their hand-optimized counterparts
in §4.1, and then in §4.2 we describe further functionalities
and blocks that we have implemented in our library which
show equivalent results as their hand-optimized counterparts.
Finally, in §4.3, we describe the ﬂoating-point operations and
integer division that we benchmark in §5.
4.1 Improved Functionalities

In this section, we present the implemented functionali-
ties that achieved better results in terms of size or depth
compared with [HKS+10, SZ13]. Results are given in Tab. 1.

Ladner-Fischer LF Adder/Subtractor. The LF adder/
subtractor has a logarithmic depth [LF80, SZ13]. Our results
show improvement for both depth (up to 10%) and size (up
to 14%) in the subtraction circuit, while maintaining the
same size and depth for addition of power-of-two numbers.
Both circuits can also handle numbers that are not powers-
of-two and achieve better size (up to 20%) as the hardware
synthesis tool automatically removes gates whose outputs
are neither used later as inputs to other gates nor assigned
directly to the output of the circuit.

Karatsuba Multiplier KMUL. We implemented a re-
cursive Karatsuba multiplier [KO62] using a ripple-carry
multiplier for inputs with bit-width (cid:96) < 20, while for (cid:96) ≥ 20

inputs are processed recursively. We compare our results with
numbers given in [HKS+10], which generated size-optimized
Boolean circuits for garbled circuits, but did not consider
circuit depth. Here we achieve up to 3% improvement in size.

Manhattan Distance DSTM. Manhattan distance is im-
plemented as a depth-optimized circuit using Ladner-Fischer
addition ADDLF and subtraction SUBLF or using ripple-
carry addition ADDRC and subtraction SUBRC for a size-
optimized circuit [CHK+12, SZ13]. Our results demonstrate
improvements in terms of size (up to 16%) and depth (up to
13.6%).
4.2 Further Functionalities

We list further functionalities that we implemented next.
Their circuit sizes and depths are equivalent to the hand-
optimized circuits in [HEK12, SZ13]: ripple-carry adder and
subtractor [BPP00, KSS09], n × (cid:96)-bit carry-save and ripple-
carry network adders [Sav97, SZ13], multipliers and squar-
ers [Sav97, KSS09, SZ13], depth-optimized multiplexer [KS08],
comparators (equal and greater than) [SZ13], full-adder [SZ13]
and Boyar-Peralta counters [BP06, SZ13], and the Sort-
Compare-Shuﬄe circuit for private set intersection (PSI)
[HEK12] and its building blocks (bitonic sorter, duplicate-
ﬁnding circuit, and Waksman permutation network [Wak68]).

Matrix Multiplication. We implemented a size-optimized
matrix multiplication circuit that computes one entry in the
resulting matrix by computing dot products. This circuit is
evaluated such that it computes the entries of the resulting
matrix in parallel. Thereby, we can exploit the capability of
the ABY framework to evaluate circuits in parallel, which
reduces the memory footprint of the implementation. The
circuit uses the Karatsuba multiplier and a ripple-carry net-
work adder. It is conﬁgurable, i.e., we can set the bit-width (cid:96)
and the number of elements per row or column n. The
depths and sizes of these circuits are given in Tab. 3 and
their performance is evaluated in §5.2.
4.3 Floating-Point Operations and Integer Di-

vision

We generated ﬂoating-point operations using the Design-
Ware library [Syn15], which is a set of building block IPs used
to implement, among other operations, ﬂoating-point com-
putational circuits for high-end ASICs. The library oﬀers a
suite of arithmetic and trigonometric operations, format con-
versions (integer to ﬂoating-point and vice versa) and compar-
ison functions. The provided functionalities are parametrized
allowing the developer to select the precision based on either
IEEE single or double precision or set a custom-precision
format. We can also enable the ieee_compliance parameter
when we need to guarantee IEEE compatible ﬂoating-point
numbers (”Not a Number” NaN and denormalized numbers).
Some functionalities provide an arch parameter which can
be set for either depth-optimized or size-optimized circuits.
Some of the ﬂoating-point functions provide a 3-bit op-
tional input round, to determine how the signiﬁcand should
be rounded, e.g. 000 rounds to the nearest even signiﬁcand
which is the IEEE default. They also have an 8-bit optional
output ﬂag status, in which bits indicate diﬀerent exceptions
of the performed operation allowing error detection. We can
choose to truncate or use these status bits as desired.

We generated circuits for ﬂoating-point addition, subtrac-
tion, squaring, multiplication, division, square root, sine,

1511cosine, comparison, exponentiation to base e, exponentiation
to base 2, natural logarithm (ln), and logarithm to base 2
for single precision, double precision and a custom 42-bit
precision format for comparison with [ABZS13]. The 42-bit
format consists of 32 bits for signiﬁcand, one bit for sign
and 9 bits for exponent distributed from MSB to LSB as
follows: sign [41], exponent [40:32] and signiﬁcand [31:0].
We extended the ABY framework with these ﬂoating-point
operations and benchmarked them. We give runtimes, depths
and sizes for various ﬂoating-point operations in §5.3.
We also generated circuits for integer division for diﬀerent
bit-widths (cid:96) ∈ {8, 16, 32, 64} using the built-in DesignWare
library [Syn15]. Another possibility for generating division
circuits is to use the division operator ‘/’ which will be
implicitly mapped to the built-in division module in that
library. As we optimize for depth our circuits have size
O((cid:96)2 log (cid:96)) ≈ 24 576 gates for (cid:96) = 64 but low depth 512. In
contrast, optimizing for size would yield better size O((cid:96)2) ≈
3(cid:96)2 = 12 288 gates (for ADD/SUB, CMP, and MUX), but
worse depth O((cid:96)2) = 4 096. We give circuit sizes and depths
for integer division in Tab. 2 and benchmarks in §5.1.

5. BENCHMARKS AND EVALUATION

We extended the ABY framework [DSZ15] to read in
the parsed and scheduled netlist generated by our hard-
ware synthesis tool and evaluate it with ABY’s optimized
implementations of the GMW protocol and Yao’s garbled
circuits (cf. §3.4). In contrast to TinyGarble [SHS+15], which
mainly focused on a memory-eﬃcient representation of the
circuits and gave only a single example for the time to se-
curely evaluate the circuit, we measure the total execution
times for several operations and applications: integer divi-
sion (§5.1), matrix multiplication (§5.2) and an extensive set
of ﬂoating-point operations (§5.3). For Yao’s protocol we
use today’s most eﬃcient garbling schemes implemented in
the ABY framework [DSZ15]: free XOR [KS08], ﬁxed-key
AES garbling with the AES-NI instruction set [BHKR13] and
half-gates [ZRE15]. For better comparability of the runtimes
we use depth-optimized circuits for both, GMW and Yao.

Compilation and synthesis times for the largest circuits
(FPEXP2, FPDIV) using Synopsys DC are under 1 hour on
a standard PC, but this is only a one-time expense, after
which the generated netlist can be re-used without incurring
compilation costs again.

We provide runtimes for the setup phase, which can be
pre-computed independently of the private inputs of the
participants and the online phase, which takes place after the
setup-phase is done and the inputs to the circuit are supplied
by both parties. All runtimes are median values of 10 protocol
runs. We measured runtimes on two desktop computers with
an Intel Core i7 CPU (3.5 GHz) and 16 GB RAM connected
via Gigabit-LAN. In all our experiments we set the symmetric
security parameter to 128 bits.
5.1 Benchmarks for Integer Division
A complex operation that is not trivially implementable
by hand is integer division, as described in §4.3. In Tab. 2
we list the runtime, split in pre-computation phase and
online phase and list the circuit parameters for multiple input
sizes. We compare our runtime with the runtime prediction
of 32-bit integer long division of [KSS13] which we speed
up by a factor of 32 and even more for Single Instruction
Multiple Data (SIMD) evaluation. We also compare with the

runtime of 3-party 64-bit integer division of [ABZS13], which
outperforms our single evaluation with GMW by a factor
of 1.8. However, for parallel SIMD evaluation we improve
upon their runtime by up to factor 3.7. When comparing to
the 3-party 32-bit integer division of [BNTW12], we achieve
a speedup of 6.5 for single execution, while we require more
than 5 times the runtime for 10 000 parallel executions.

5.2 Benchmarks for Matrix Multiplication

Matrix multiplication of integer values is an important use
case in many applications. Here we exploit ABY’s ability to
evaluate circuits in parallel in a SIMD fashion and instantiate
dot product computation blocks, each of which calculates
a single entry in the result matrix. In Tab. 3 we give the
runtimes for dot product computations of 16 values of 16 bit
each or 32 values of 32 bit each, as described in §4.2. We
compare with the 3-party secret-sharing based implementa-
tions of [BNTW12, ZSB13] as well as the 2-party arithmetic-
sharing implementation of the ABY framework [DSZ15]. For
this comparison we use the values reported in the respective
papers and interpolate them to our parameters.

The secret-sharing or artihmetic-sharing based solutions
outperform our Boolean Circuits by several orders of magni-
tude due to their much faster methods for multiplication.

5.3 Benchmarks for Floating-Point Operations
There is a multitude of use cases for ﬂoating-point opera-
tions in academia and industry, ranging from signal process-
ing to data mining, but due to the complexity of the format
it has only recently been considered as application for secure
computation [FK11]. Until today there are only few actual
implementations of ﬂoating-point arithmetic in secure com-
putation, all of which use custom-built protocols [ABZS13,
KW14]. Instead, we use multiple standard ﬂoating-point
building blocks oﬀered by Synopsys DC and synthesize them
automatically (cf. §4.3). Tab. 4 depicts the runtime in ms
per single ﬂoating-point operation, when run once or multiple
times in parallel using a SIMD approach. We compare our
results for Yao and GMW with hand-optimized ﬂoating-point
protocols of [ABZS13], who used a 3-party secret sharing
approach with security against semi-honest adversaries and
desktop computers connected on a Gigabit-LAN for their
measurements. The largest runtime improvements can be
achieved when evaluating our generated circuits in parallel.
We improve the runtime by up to a factor of 21 for parallel
evaluation and show similar or somewhat improved runtimes
for the lower parallelism levels reported. We can improve
upon many results of [KW14] which is in the 3-party set-
ting, except for highly parallel multiplication. We show that
our automatically generated circuits are able to outperform
hand-crafted circuits in many cases, especially for high de-
grees of parallelism. We give an application for ﬂoating-point
arithmetic in §6.

5.4 Benchmark Evaluation

In general, when comparing the implementations of Yao
and GMW in the ABY framework, we show that Yao out-
performs GMW in most cases but scales much worse, up
to a point where the largest circuits cannot be evaluated
in parallel, due to the high memory consumption of Yao’s
protocol. GMW remains beneﬁcial for highly parallel proto-
col evaluation, as the more critical online time scales almost

1512Table 1: Synthesis results of improved functionalities compared to hand-optimized circuits for inputs of
bit-width (cid:96): Ladner-Fischer ADDLF /SUBLF , Karatsuba multiplication KMUL, Manhattan Distance DSTM.

Circuit

Size S
Hand-optimized Ours

Improvement Hand-optimized Ours

Improvement

Depth-Optimized

Depth D

ADDLF ((cid:96) = 20)
ADDLF ((cid:96) = 30)
ADDLF ((cid:96) = 40)
SUBLF ((cid:96) = 16)
SUBLF ((cid:96) = 32)
SUBLF ((cid:96) = 64)
DSTM ((cid:96) = 16)
DSTM ((cid:96) = 32)
DSTM ((cid:96) = 64)

KMUL ((cid:96) = 32)
KMUL ((cid:96) = 64)
KMUL ((cid:96) = 128)
DSTM ((cid:96) = 16)
DSTM ((cid:96) = 32)
DSTM ((cid:96) = 64)

151
226
361
113
273
641
353
825
1 889

121
214
301
97
241
577
296
741
1 778

1 729
5 683
17 972
65
129
257

1 697
5 520
17 430
65
129
257

20%
5%
16.6%
14%
11%
10%
16%
10%
5.8%

Size-Optimized

1.8%
2.9%
3%
0%
0%
0%

11
11
13
10
12
14
22
26
30
−
−
−
34
66
130

11
11
13
9
11
13
19
23
27

63
127
255
32
64
128

0%
0%
0%
10%
8%
7%
13.6%
11.5%
10%
−
−
−
5.8%
3%
1.5%

Table 2: Runtimes (setup + online phase) in ms per single integer division.
‘–’ indicates that no numbers
were given. Protocols marked with ∗ are in the 3-party setting; all other protocols are in the 2-party setting.
Entries marked with × could not be run on our machines.

Integer Division

8-bit GMW
8-bit Yao
16-bit GMW
16-bit Yao
32-bit [KSS13]
32-bit [BNTW12]∗
32-bit GMW
32-bit Yao
64-bit [ABZS13]∗
64-bit GMW
64-bit Yao

Parallel Batch Size

1

100

10 000

AND Gates
Size

Depth

0.3 + 42.4
1.1 + 0.7
7.8 + 47.7
2.0 + 1.1
2 000
400
3.5 + 58.2
5.2 + 2.1
60
16.9 + 90.3
27.5 + 5.6

0.2 + 0.52
0.2 + 0.04
0.8 + 0.79
0.7 + 0.14
–
4
3.5 + 3.66
3.3 + 0.63
41
12.0 + 7.50
13.1 + 2.49

0.2 + 0.004
367
0.2 + 0.035
367
0.6 + 0.01
1 542
0.7 + 0.14
1 542
–
–
0.5
–
2.7 + 0.04
7 079
×
7 079
40
–
10.8 + 0.15
28 364
× 28 364

32
32
93
93
–
–
207
207
–
512
512

Table 3: Runtimes (setup + online phase) in ms per single dot product computation, as described in §4.2.
Protocols marked with ∗ are in the 3-party setting; all other protocols are in the 2-party setting. Entries
marked with × could not be run on our machines. Data from referenced works are interpolated from values
given in the respective paper.

Dot Product
size-optimized RC 16×16-bit GMW
size-optimized RC 16×16-bit Yao
32×32-bit Multiplication [BNTW12]∗
32×32-bit Multiplication [ZSB13]∗
32×32-bit Arithmetic Multiplication [DSZ15]
size-optimized RC 32×32-bit GMW
size-optimized RC 32×32-bit Yao

Parallel Batch Size

1

100

10 000

AND Gates
Size

Depth

3.1 + 45.9
7.4 + 3.0
25.9
0.289
5.44 + 0.196
55.7 + 68.6
76.7 + 18.5

3.9 + 0.62
4.3 + 1.01
0.261
0.185
5.44 + 0.061
21.0 + 1.12
28.5 + 6.74

3.2 + 0.04
×
0.058
0.184
5.44 + 0.060
21.5 + 0.30

8 427
8 427
–
–
–
56 314
× 56 314

36
36
–
–
–
69
69

1513Table 4: Runtimes (setup + online phase) in ms per single ﬂoating-point operation for multiple precisions.
‘–’ indicates that no numbers were given. Protocols marked with ∗ are in the 3-party setting; ours are in the
2-party setting. Entries marked with × could not be run on our machines.

FP Operation

1

10

100

1 000

10 000

Parallel Batch Size

AND Gates
Size

Depth

FPCMP

FPADD

FPMULT

FPSQRT

FPDIV

FPEXP2

FPLOG2

32-bit GMW
32-bit Yao
42-bit [ABZS13]∗
42-bit GMW
42-bit Yao
64-bit GMW
64-bit Yao
32-bit [KW14]∗
32-bit GMW
32-bit Yao
42-bit [ABZS13]∗
42-bit GMW
42-bit Yao
64-bit [KW14]∗
64-bit GMW
64-bit Yao
32-bit [KW14]∗
32-bit GMW
32-bit Yao
42-bit [ABZS13]∗
42-bit GMW
42-bit Yao
64-bit [KW14]∗
64-bit GMW
64-bit Yao
32-bit [KW14]∗
32-bit GMW
32-bit Yao
42-bit GMW
42-bit Yao
64-bit [KW14]∗
64-bit GMW
64-bit Yao
32-bit [KW14]∗
32-bit GMW
32-bit Yao
42-bit [ABZS13]∗
42-bit GMW
42-bit Yao
64-bit [KW14]∗
64-bit GMW
64-bit Yao
32-bit GMW
32-bit Yao
42-bit [ABZS13]∗
42-bit GMW
42-bit Yao
64-bit GMW
64-bit Yao
32-bit GMW
32-bit Yao
42-bit [ABZS13]∗
42-bit GMW
42-bit Yao
64-bit GMW
64-bit Yao

0.4 + 39.6
1.1 + 0.7
–
0.4 + 39.6
1.0 + 0.7
0.4 + 40.6
1.1 + 0.7
1 370
3.0 + 46.1
2.0 + 1.1
–
5.3 + 46.3
2.6 + 1.3
1 471
2.1 + 46.9
3.6 + 1.6
434.8
1.8 + 42.9
8.1 + 1.1
–
2.0 + 47.3
4.1 + 1.7
476.2
15.5 + 170.1
13.3 + 2.7
11 111
1.3 + 57.7
2.6 + 0.8
2.6 + 66.4
3.9 + 1.2
12 500
10.5 + 87.4
9.4 + 2.6
6 250
2.3 + 64.3
4.2 + 1.9
–
9.9 + 79.8
7.0 + 2.7
6 667
16.6 + 123.4
15.2 + 5.0
5.5 + 144.2
6.5 + 1.8
–
14.5 + 179.1
15.8 + 4.4
16.7 + 455.1
14.3 + 4.2
4.1 + 67.0
7.0 + 2.1
–
16.0 + 67.4
15.9 + 4.1
19.7 + 95.8
13.3 + 3.9

0.1 + 4.1
0.3 + 0.1
5.4
0.2 + 4.3
0.3 + 0.1
0.3 + 4.3
0.3 + 0.1
137.0
1.1 + 5.3
1.0 + 0.2
19.0
1.5 + 5.8
1.3 + 0.3
147.1
2.2 + 6.3
2.2 + 0.5
43.5
1.6 + 5.6
1.6 + 0.3
4.2
2.4 + 6.3
2.5 + 0.5
47.6
5.6 + 8.7
5.4 + 1.1
1 177
1.2 + 6.6
1.5 + 0.3
2.2 + 8.8
2.4 + 0.5
1 316
6.4 + 14.9
6.2 + 1.3
625.0
3.1 + 9.3
2.7 + 0.6
15.0
5.4 + 13.0
4.9 + 1.0
666.7
12.5 + 25.4
11.1 + 2.4
5.2 + 14.7
4.7 + 0.9
88.0
12.6 + 23.7
11.9 + 2.4
12.2 + 88.9
10.6 + 2.2
5.7 + 8.0
5.1 + 1.0
159.0
12.5 + 20.5
11.1 + 2.3
11.0 + 32.1
9.7 + 2.0

0.1 + 0.45
0.5 + 0.03
3.2
0.2 + 0.44
0.2 + 0.04
0.2 + 0.49
0.2 + 0.06
14.5
1.0 + 0.66
0.9 + 0.17
11.0
1.3 + 1.07
1.2 + 0.24
16.7
2.3 + 0.73
2.0 + 0.40
4.4
1.4 + 0.67
1.4 + 0.27
3.4
2.6 + 0.82
2.2 + 0.43
5.1
5.0 + 0.95
5.2 + 1.00
142.9
1.2 + 1.22
1.2 + 0.23
2.4 + 1.69
2.3 + 0.43
217.4
5.1 + 6.23
6.3 + 1.14
71.4
2.6 + 1.78
2.5 + 0.49
12.0
4.6 + 2.48
4.7 + 0.90
83.3
8.4 + 4.92
10.6 + 2.06
4.7 + 0.85
4.5 + 0.84
80.0
10.2 + 1.14
11.3 + 2.13
9.2 + 17.33
1 0.0 + 1.91
5.0 + 1.48
4.9 + 0.91
103.0
9.8 + 2.80
10.7 + 2.01
8.5 + 6.34
9.2 + 1.76

0.1 + 0.06
0.1 + 0.03
2.3
0.2 + 0.05
0.2 + 0.04
0.2 + 0.05
0.2 + 0.06
1.9
0.7 + 0.06
0.9 + 0.17
9.3
1.0 + 0.07
1.2 + 0.23
4.8
1.6 + 0.03
2.0 + 0.40
0.6
1.1 + 0.05
1.4 + 0.27
3.2
1.9 + 0.08
2.2 + 0.43
0.9
4.1 + 0.08
5.1 + 0.99
41.7
0.9 + 0.12
1.2 + 0.22
1.6 + 0.15
2.2 + 0.42
103.1
4.3 + 0.23
5.9 + 1.12
16.9
2.0 + 0.16
2.5 + 0.49
12.0
3.7 + 0.23
4.6 + 0.89
43.5
8.6 + 0.38
10.6 + 2.09
3.7 + 0.09
4.5 + 0.83
75.0
9.4 + 0.17
11.2 + 2.14
8.1 + 0.51
9.9 + 1.89
4.1 + 0.10
4.9 + 0.90
97.0
8.5 + 0.19
10.6 + 1.99
7.6 + 0.45
9.2 + 1.75

0.1 + 0.003
218
0.1 + 0.033
218
2.2
–
0.1 + 0.003
290
0.2 + 0.043
290
0.2 + 0.004
427
0.2 + 0.065
427
1.6
–
0.7 + 0.01
1 820
0.9 + 0.18
1 820
9.1
–
0.9 + 0.02
2 490
1.2 + 0.24
2 490
4.1
–
1.6 + 0.03
4 303
2.0 + 0.40
4 303
0.2
–
1.1 + 0.02
3 016
1.4 + 0.29
3 016
3.1
–
1.8 + 0.03
4 757
2.2 + 0.43
4 757
0.3
–
4.2 + 0.05
11 068
× 11 068
–
2 455
2 455
4 810
4 810
–
12 706
× 12 706
–
5 395
5 395
–
9 937
9 937
–
22 741
× 22 741
9 740
3.8 + 0.05
×
9 740
–
75.0
9.3 + 0.12
24 357
× 24 357
21 431
× 21 431
10 568
× 10 568
–
23 041
× 23 041
19 789
× 19 789

12.7
2.0 + 0.03
2.5 + 0.49
12.0
3.7 + 0.05
×
19.2
8.7 + 0.12

31.3
0.8 + 0.01
1.2 + 0.23
1.6 + 0.03
2.2 + 0.44
96.2
4.3 + 0.06

8.2 + 0.12

4.0 + 0.05

96.0
8.9 + 0.11

7.6 + 0.10

12
12
–
13
13
15
15
–
59
59
–
69
69
–
72
72
–
47
47
–
72
72
–
111
111
–
197
197
300
300
–
557
557
–
296
296
–
462
462
–
994
994
100
100
–
156
156
1214
1214
157
157
–
266
266
649
649

1514compute distances on a sphere and is very accurate regardless
of the position of A and B.

The coordinates are expressed as spherical coordinates
with latitude (lat) and longitude (lon): CA = (latA, lonA)
and CB = (latB, lonB).
DHS(CA, CB) <  ⇔
α2·β2−2αγ·βδ +γ2·δ2 +ζθ2·ηλ2−2ζθµ·ηλν +ζµ2·ην2 < a,
with a as deﬁned above and

α = cos(latA/2)
γ = sin(latA/2)
ζ = cos(latA)
θ = sin(lonA/2)
µ = cos(lonA/2)

β = sin(latB/2)
δ = cos(latB/2)
η = cos(latB)
λ = cos(lonB/2)
ν = sin(lonB/2).

Underlined terms are inputs of party A while all other
terms are inputs of party B. Computing this formula requires
6 FPMULT, 5 FPADD, and 1 FPCMP operations.

Performance. We implemented the three proximity test-
ing algorithms from [ˇSG14] using our ﬂoating-point building
blocks. In Tab. 5 we compare the runtime of the original
implementation of [ˇSG14] that uses homomorphic encryp-
tion (HE) and Yao’s Garbled Circuits (GC) with our imple-
mentation based on GMW and Yao for single and parallel
evaluation. We are able to achieve better runtimes for single
executions of the protocol (by factor 6.2 for HS and more
than factor 14 for UTM and ECEF), and more than two
orders of magnitude speedup for highly parallel execution.
Thereby, we show that our approach allows to substantially
improve upon the runtime of hand-crafted protocols while at
the same time it beneﬁts from the heavily tested and veri-
ﬁed circuit building blocks from industrial-grade hardware
synthesis libraries.
Acknowledgments
We thank the anonymous reviewers of ACM CCS 2015 for
their helpful comments. This work was supported by the
European Union’s 7th Framework Program (FP7/2007-2013)
under grant agreement n. 609611 (PRACTICE), by the
DFG as part of project E3 within the CRC 1119 CROSSING,
by the German Federal Ministry of Education and Research
(BMBF) within the European Center for Security and Privacy
by Design (EC SPRIDE), by the Hessian LOEWE excellence
initiative within the Center for Advanced Security Research
Darmstadt (CASED), and in part by the ONR grant number
R17460 and NSF grant R3F530 to Rice University.

linearly with the level of parallelism. The setup times of Yao
and GMW are similar for all parameters.

Our improved performance stems from both, the optimized
circuits generated by the state-of-the-art hardware synthesis
tools which we manipulate to optimize the circuits for either
depth or size, and from the eﬃcient implementation of GMW
and Yao’s garbled circuits with most recent optimizations
in ABY. Since both protocols are based on Boolean circuits,
we improve the performance of operations that require many
bit operations. Operations that involve many integer multi-
plications are better suited for solutions based on arithmetic-
or secret-sharing.

6. APPLICATION: PRIVACY-PRESERVING

PROXIMITY TESTING ON EARTH

As application for secure computation on ﬂoating-point op-
erations, we consider privacy-preserving proximity testing on
Earth [ˇSG14]. Here, the goal is to compute if two coordinates
CA and CB input by party A and B respectively are within
a given distance : D(CA, CB) < . This is a useful but
rather privacy-critical use case that has many applications,
such as ﬁnding nearby friends, points of interest or targeted
advertising, and is widely used with the recent spread of
end-user GPS receivers and geo location via IP addresses.
The authors of [ˇSG14] present and compare three diﬀerent
distance metrics: UTM, ECEF, and HS described below. In
their paper, the authors design secure protocols based on
additively homomorphic encryption (HE) or Yao’s garbled
circuits (GC) that require to quantize all values to integers,
which means a loss of precision.
Instead, our framework
allows to compute the distance formulas directly on ﬂoating-
point numbers with multiple precision options available and
thus can oﬀer a higher precision.

Universal Transverse Mercator (UTM). This distance
metric maps Earth over a set of planes and provides accurate
results if A and B are located relatively close to each other,
within the same UTM zone.

points: CA = (xA, yA) and CB = (xB, yB).

In this metric coordinates are expressed as 2-dimensional
DUTM(CA, CB) <  ⇔ (xA − xB)2 + (yA − yB)2 < 2,
where underlined variables are inputs of party A and the
other terms are inputs of party B. For computing this
formula we need 2 FPSQR, 3 FPADD, and 1 FPCMP operations.

Earth-Centered, Earth-Fixed (ECEF). This distance
metric uses the Earth-Centered, Earth-Fixed (ECEF, also
known as Earth Centered Rotational, or ECR) coordinate
system which provides very accurate results when the parties
are far apart.

The coordinates are expressed as 3-dimensional points
where (0, 0, 0) is the center of the Earth: CA = (xA, yA, zA)
and CB = (xB, yB, zB).
DECEF(CA, CB) <  ⇔
(xA − xB)2 + (yA − yB)2 + (zA − zB)2 < 4R2a,

(tan 

with a =

2R )2
2R )2 . Underlined variables are inputs of
1 + (tan 
party A and the other terms are inputs of party B. Com-
puting this formula takes 3 FPSQR, 5 FPADD, and 1 FPCMP
operations.

Haversine (HS). This distance metric is based on the haver-
sine (HS) formula which is a trigonometric formula used to

1515Table 5: Runtimes (setup + online phase) in ms per single proximity test for multiple precisions. ‘–’ indicates
that no numbers were given. All protocols are in the 2-party setting. Entries marked with × could not be
run on our machines.

Distance Metric

Parallel Batch Size

1

100

10 000

AND Gates
Size

Depth

UTM

ECEF

HS

HE [ˇSG14]
GC [ˇSG14]
32-bit GMW
32-bit Yao
64-bit GMW
64-bit Yao
HE [ˇSG14]
GC [ˇSG14]
32-bit GMW
32-bit Yao
64-bit GMW
64-bit Yao
HE [ˇSG14]
GC [ˇSG14]
32-bit GMW
32-bit Yao
64-bit GMW
64-bit Yao

700 . . . 1 100
401.0 + 102.0
4.4 + 59.8
18.0 + 2.4
19.9 + 67.2
18.1 + 5.7
1 000 . . . 1 300
404.0 + 105.0
5.7 + 60.1
12.8 + 3.3
13.9 + 78.1
27.4 + 8.8
1 700
409.0 + 124.0
13.6 + 67.5
17.9 + 5.6
49.5 + 283.6
67.8 + 18.0

–
–
4.0 + 1.49
4.2 + 0.87
10.6 + 2.65
12.5 + 2.54
–
–
5.8 + 1.56
6.6 + 1.32
15.8 + 2.91
19.9 + 3.88
–
–
11.6 + 2.11
12.8 + 2.48
33.3 + 3.40
41.4 + 8.03

–
–
–
–
3.3 + 0.05
8 815
×
8 815
10.2 + 0.14
26 588
× 26 588
–
–
–
–
5.3 + 0.07
14 042
× 14 042
41 850
× 41 850
–
–
–
–
10.5 + 0.14
27 525
× 27 525
88 530
× 88 530

16.0 + 0.20

33.4 + 0.41

–
–
146
146
195
195
–
–
205
205
267
267
–
–
224
224
342
342

7. REFERENCES
[ABZS13] M. Aliasgari, M. Blanton, Y. Zhang, A. Steele.
Secure computation on ﬂoating point numbers.
In NDSS’13. The Internet Society, 2013.

[ALSZ13] G. Asharov, Y. Lindell, T. Schneider,

[Bea91]

[Ber]

M. Zohner. More eﬃcient oblivious transfer and
extensions for faster secure computation. In
ACM CCS’13, p. 535–548. ACM, 2013.
D. Beaver. Eﬃcient multiparty protocols using
circuit randomization. In CRYPTO’91, volume
576 of LNCS, p. 420–432. Springer, 1991.
Berkeley Logic Synthesis. ABC: a system for
sequential synthesis and veriﬁcation, release
70930.
http://www.eecs.berkeley.edu/~alanmi/abc/.

[BHKR13] M. Bellare, V. Hoang, S. Keelveedhi,

[BNP08]

P. Rogaway. Eﬃcient garbling from a ﬁxed-key
blockcipher. In IEEE S&P’13, p. 478–492.
IEEE, 2013.
A. Ben-David, N. Nisan, B. Pinkas. FairplayMP:
a system for secure multi-party computation. In
ACM CCS’08, p. 257–266. ACM, 2008.

[BNTW12] D. Bogdanov, M. Niitsoo, T. Toft, J. Willemson.

High-performance secure multi-party
computation for data mining applications.
International Journal of Information Security,
11(6):403–418, 2012.
J. Boyar, R. Peralta. Concrete multiplicative
complexity of symmetric functions. In
Mathematical Foundations of Computer Science
(MFCS’06), volume 4162 of LNCS, p. 179–189.
Springer, 2006.
J. Boyar, R. Peralta, D. Pochuev. On the
multiplicative complexity of boolean functions

[BP06]

[BPP00]

over the basis (∧,⊕, 1). Theoretical Computer
Science, 235(1):43–57, 2000.

[DSZ15]

[CHK+12] S.-G. Choi, K.-W. Hwang, J. Katz, T. Malkin,
D. Rubenstein. Secure multi-party computation
of Boolean circuits with applications to privacy
in on-line marketplaces. In CT-RSA’12, volume
7178 of LNCS, p. 416–432. Springer, 2012.
D. Demmler, T. Schneider, M. Zohner. ABY – a
framework for eﬃcient mixed-protocol secure
two-party computation. In NDSS’15. The
Internet Society, 2015. Code:
https://github.com/encryptogroup/ABY.
M. Franz, S. Katzenbeisser. Processing
encrypted ﬂoating point signals. In ACM
Multimedia and Security (MM&Sec’11), p.
103–108. ACM, 2011.
IEEE standard for ﬂoating-point arithmetic.
IEEE Std 754-2008, p. 1–70, Aug 2008.

[FK11]

[FP008]

[GMW87] O. Goldreich, S. Micali, A. Wigderson. How to
play any mental game. In STOC’87, p. 218–229.
ACM, 1987.
J. Garay, B. Schoenmakers, J. Villegas.
Practical and secure solutions for integer
comparison. In PKC’07, volume 4450 of LNCS,
p. 330–342. Springer, 2007.

[GSV07]

[HEK12] Y. Huang, D. Evans, J. Katz. Private set

intersection: Are garbled circuits better than
custom protocols? In NDSS’12. The Internet
Society, 2012.

[HEKM11] Y. Huang, D. Evans, J. Katz, L. Malka. Faster

secure two-party computation using garbled
circuits. In USENIX Security’11, p. 539–554.
USENIX, 2011.

1516[HFKV12] A. Holzer, M. Franz, S. Katzenbeisser, H. Veith.

Secure two-party computations in ANSI C. In
ACM CCS’12, p. 772–783. ACM, 2012.

[HKS+10] W. Henecka, S. K¨ogl, A.-R. Sadeghi,

T. Schneider, I. Wehrenberg. TASTY: Tool for
Automating Secure Two-partY computations.
In ACM CCS’10, p. 451–462. ACM, 2010.
[IKNP03] Y. Ishai, J. Kilian, K. Nissim, E. Petrank.
Extending oblivious transfers eﬃciently. In
CRYPTO’03, volume 2729 of LNCS, p. 145–161.
Springer, 2003.
Y.-K. Kwok, I. Ahmad. Static scheduling
algorithms for allocating directed task graphs to
multiprocessors. ACM Computing Surveys
(CSUR), 31(4):406–471, 1999.
A. A. Karatsuba, Y. Ofman. Multiplication of
many-digital numbers by automatic computers.
SSSR Academy of Sciences, 145:293–294, 1962.
V. Kolesnikov, T. Schneider. Improved garbled
circuit: Free XOR gates and applications. In
ICALP’08, volume 5126 of LNCS, p. 486–498.
Springer, 2008.

[KO62]

[KA99]

[KS08]

[KSMB13] B. Kreuter, A. Shelat, B. Mood, K. R. B. Butler.

[KSS09]

[KSS12]

[KSS13]

[KW14]

[LF80]

PCF: A portable circuit format for scalable
two-party secure computation. In USENIX
Security’13, p. 321–336. USENIX, 2013.
V. Kolesnikov, A.-R. Sadeghi, T. Schneider.
Improved garbled circuit building blocks and
applications to auctions and computing minima.
In CANS’09, volume 5888 of LNCS, p. 1–20.
Springer, 2009.
B. Kreuter, A. Shelat, C.-H. Shen. Billion-gate
secure computation with malicious adversaries.
In USENIX Security’12, p. 285–300. USENIX,
2012.
F. Kerschbaum, T. Schneider, A. Schr¨opfer.
Automatic protocol selection in secure
two-party computations. In ACNS’15, volume
8479 of LNCS, p. 1–18. Springer, 2013.
L. Kamm, J. Willemson. Secure ﬂoating point
arithmetic and private satellite collision
analysis. International Journal of Information
Security, p. 1–18, 2014.
R. E. Ladner, M. J. Fischer. Parallel preﬁx
computation. Journal of the ACM,
27(4):831–838, 1980.

[LWN+15] C. Liu, X. S. Wang, K. Nayak, Y. Huang,

E. Shi. ObliVM: A programming framework for
secure computation. In IEEE S&P’15, p.
359–376. IEEE, 2015.
L. Malka. VMCrypt - modular software
architecture for scalable secure computation. In
ACM CCS’11, p. 715–724. ACM, 2011.
B. Mood, L. Letaw, K. R. B. Butler.
Memory-eﬃcient garbled circuit generation for

[Mal11]

[MLB12]

mobile devices. In FC’12, volume 7397 of LNCS,
p. 254–268. Springer, 2012.

[MNPS04] D. Malkhi, N. Nisan, B. Pinkas, Y. Sella.

Fairplay – a secure two-party computation
system. In USENIX Security’04, p. 287–302.
USENIX, 2004.

[NNOB12] J. B. Nielsen, P. S. Nordholt, C. Orlandi, S. S.

[Sav97]

[ˇSG14]

Burra. A new approach to practical
active-secure two-party computation. In
CRYPTO’12, volume 7417 of LNCS, p. 681–700.
Springer, 2012.
J. E. Savage. Models of Computation: Exploring
the Power of Computing. Addison-Wesley Pub,
Boston, MA, USA, 1st edition, 1997.
J. ˇSedˇenka, P. Gasti. Privacy-preserving
distance computation and proximity testing on
earth, done right. In ACM ASIACCS’14, p.
99–110. ACM, 2014.

[SHS+15] E. M. Songhori, S. U. Hussain, A.-R. Sadeghi,

[ST]

[Syn10]

[Syn15]

[SZ13]

[Wak68]

[Wol]

[Yao86]

[ZRE15]

[ZSB13]

T. Schneider, F. Koushanfar. TinyGarble:
Highly compressed and scalable sequential
garbled circuits. In IEEE S&P’15, p. 411–428.
IEEE, 2015.
N. Smart, S. Tillich. Circuits of basic functions
suitable for MPC and FHE.
http://www.cs.bris.ac.uk/Research/
CryptographySecurity/MPC/.
Synopsys Inc. Design compiler, 2010. http:
//www.synopsys.com/Tools/Implementation/
RTLSynthesis/DesignCompiler.
Synopsys Inc. DesignWare library - datapath
and building block IP. https:
//www.synopsys.com/dw/buildingblock.php,
2015.
T. Schneider, M. Zohner. GMW vs. Yao?
Eﬃcient secure two-party computation with low
depth circuits. In FC’13, volume 7859 of LNCS,
p. 275–292. Springer, 2013.
A. Waksman. A permutation network. Journal
of the ACM, 15(1):159–163, 1968.
C. Wolf. Yosys open synthesis suite.
http://www.clifford.at/yosys/.
A. C.-C. Yao. How to generate and exchange
secrets. In FOCS’86, p. 162–167. IEEE, 1986.
S. Zahur, M. Rosulek, D. Evans. Two halves
make a whole: Reducing data transfer in
garbled circuits using half gates. In
EUROCRYPT’15, volume 9057 of LNCS, p.
220–250. Springer, 2015.
Y. Zhang, A. Steele, M. Blanton. PICCO: a
general-purpose compiler for private distributed
computation. In ACM CCS’13, p. 813–826.
ACM, 2013.

1517