The Ring of Gyges: Investigating the Future of Criminal

Smart Contracts

Ari Juels

IC3†

Cornell Tech, Jacobs Institute

juels@cornell.edu

Ahmed Kosba

University of Maryland
akosba@cs.umd.edu

Elaine Shi

Cornell University

IC3†

rs2358@cornell.edu

†Initiative for CryptoCurrencies and Contracts

ABSTRACT
Thanks to their anonymity (pseudonymity) and elimina-
tion of trusted intermediaries, cryptocurrencies such as Bit-
coin have created or stimulated growth in many businesses
and communities. Unfortunately, some of these are crim-
inal, e.g., money laundering, illicit marketplaces, and ran-
somware.

Next-generation cryptocurrencies such as Ethereum will
include rich scripting languages in support of smart con-
tracts, programs that autonomously intermediate transac-
tions. In this paper, we explore the risk of smart contracts
fueling new criminal ecosystems. Speciﬁcally, we show how
what we call criminal smart contracts (CSCs) can facilitate
leakage of conﬁdential information, theft of cryptographic
keys, and various real-world crimes (murder, arson, terror-
ism).

We show that CSCs for leakage of secrets (`a la Wikileaks)
are eﬃciently realizable in existing scripting languages such
as that in Ethereum. We show that CSCs for theft of crypto-
graphic keys can be achieved using primitives, such as Suc-
cinct Non-interactive ARguments of Knowledge (SNARKs),
that are already expressible in these languages and for which
eﬃcient supporting language extensions are anticipated. We
show similarly that authenticated data feeds, an emerging
feature of smart contract systems, can facilitate CSCs for
real-world crimes (e.g., property crimes).

Our results highlight the urgency of creating policy and
technical safeguards against CSCs in order to realize the
promise of smart contracts for beneﬁcial goals.

Keywords
Criminal Smart Contracts; Ethereum

The Ring of Gyges is a mythical magical artifact men-
tioned by the philosopher Plato in Book 2 of his Republic.
It granted its owner the power to become invisible at will.
—Wikipedia, “Ring of Gyges”

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’16, October 24-28, 2016, Vienna, Austria
© 2016 ACM. ISBN 978-1-4503-4139-4/16/10. . . $15.00
DOI: http://dx.doi.org/10.1145/2976749.2978362

“[On wearing the ring,] no man would keep his hands oﬀ
what was not his own when he could safely take what he liked
out of the market, or go into houses and lie with anyone at
his pleasure, or kill or release from prison whom he would...
” —Plato, The Republic, Book 2 (2.360b) (trans. Benjamin
Jowett)

1.

INTRODUCTION

Cryptocurrencies such as Bitcoin remove the need for trusted

third parties from basic monetary transactions and oﬀer
anonymous (more accurately, pseudonymous) transactions
between individuals. While attractive for many applica-
tions, these features have a dark side. Bitcoin has stimu-
lated the growth of ransomware [6], money laundering [38],
and illicit commerce, as exempliﬁed by the notorious Silk
Road [31].

New cryptocurrencies such as Ethereum (as well as sys-
tems such as Counterparty [45] and SmartContract [1]) of-
fer even richer functionality than Bitcoin. They support
smart contracts, a generic term denoting programs written
in Turing-complete cryptocurrency scripting languages. In
a fully distributed system such as Ethereum, smart con-
tracts enable general fair exchange (atomic swaps) without
a trusted third party, and thus can eﬀectively guarantee pay-
ment for successfully delivered data or services. Given the
ﬂexibility of such smart contract systems, it is to be expected
that they will stimulate not just new beneﬁcial services, but
new forms of crime.

We refer to smart contracts that facilitate crimes in dis-
tributed smart contract systems as criminal smart contracts
(CSCs). An example of a CSC is a smart contract for
(private-)key theft. Such a CSC might pay a reward for
(conﬁdential) delivery of a target key sk, such as a certiﬁ-
cate authority’s private digital signature key.

We explore the following key questions in this paper. Could
CSCs enable a wider range of signiﬁcant new crimes than
earlier cryptocurrencies (Bitcoin)? How practical will such
new crimes be? And What key advantages do CSCs pro-
vide to criminals compared with conventional online sys-
tems? Exploring these questions is essential to identifying
threats and devising countermeasures.
1.1 CSC challenges

Would-be criminals face two basic challenges in the con-
struction of CSCs. First,
it is not immediately obvious
whether a CSC is at all feasible for a given crime, such
as key theft. This is because it is challenging to ensure

283that a CSC achieves a key property in this paper that we
call commission-fair, meaning informally that its execution
guarantees both commission of a crime and commensurate
payment for the perpetrator of the crime or neither. (We
formally deﬁne commission-fairness for individual CSCs in
the paper.) Fair exchange is necessary to ensure commission-
fairness, but not suﬃcient: We show how CSC constructions
implementing fair exchange still allow a party to a CSC to
cheat. Correct construction of CSCs can thus be delicate.

Second, even if a CSC can in principle be constructed,
given the limited opcodes in existing smart contract sys-
tems (such as Ethereum), it is not immediately clear that
the CSC can be made practical. By this we mean that the
CSC can be executed without unduly burdensome compu-
tational eﬀort, which in some smart contract systems (e.g.,
Ethereum) would also mean unacceptably high execution
fees levied against the CSC.

The following example illustrates these challenges.

Example 1a

(Key compromise contract). Contractor

C posts a request for theft and delivery of the signing key
skV of a victim certiﬁcate authority (CA) CertoMart. C of-
fers a reward $reward to a perpetrator P for (conﬁdentially)
delivering the CertoMart private key skV to C.

To ensure fair exchange of the key and reward in Bitcoin,
C and P would need to use a trusted third party or communi-
cate directly, raising the risks of being cheated or discovered
by law enforcement. They could vet one another using a
reputation system, but such systems are often inﬁltrated by
law enforcement authorities [55]. In contrast, a decentral-
ized smart contract can achieve self-enforcing fair exchange.
For key theft, this is possible using the CSC Key-Theft in
the following example:

Example 1b

(Key compromise CSC). C generates a
private / public key pair (skC, pkC) and initializes Key-Theft
with public keys pkC and pkV (the CertoMart public key).
Key-Theft awaits input from a claimed perpetrator P of a
pair (ct, π), where π is a zero-knowledge proof that ct =
encpkC [skV ] is well-formed. Key-Theft then veriﬁes π and
upon success sends a reward of $reward to P. The contractor
C can then download and decrypt ct to obtain the compro-
mised key skV .

Key-Theft implements a fair exchange between C and P,
paying a reward to P if and only if P delivers a valid key
(as proven by π), eliminating the need for a trusted third
party. But it is not commission-fair, as it does not ensure
that skvict actually has value. The CertoMart can neutralize
the contract by preemptively revoking its own certiﬁcate and
then itself claiming C’s reward $reward!

As noted, a major thrust of this paper is showing how,
for CSCs such as Key-Theft, criminals will be able to bypass
such problems and still construct commission-fair CSCs. (For
key compromise, it is necessary to enable contract cancella-
tion should a key be revoked.) Additionally, we show that
these CSCs can be eﬃciently realized using existing cryp-
tocurrency tools or features currently envisioned for cryp-
tocurrencies (e.g., zk-SNARKS [22]).
1.2 This paper

We show that it is or will be possible in smart contract
systems to construct commission-fair CSCs for three types
of crime:

1. Leakage / sale of secret documents;
2. Theft of private keys; and
3. “Calling-card” crimes, a broad class of physical-world

crimes (murder, arson, etc.)

The fact that CSCs are possible in principle is not surpris-
ing. Previously, however, it was not clear how practical or
extensively applicable CSCs might be. As our constructions
for commission-fair CSCs show, constructing CSCs is not
as straightforward as it might seem, but new cryptographic
techniques and new approaches to smart contract design can
render them feasible and even practical. Furthermore, crim-
inals will undoubtedly devise CSCs beyond what this paper
and the community in general are able to anticipate.

Our work therefore shows how imperative it is for the
community to consider the construction of defenses against
CSCs. Criminal activity committed under the guise of anonymity
has posed a major impediment to adoption for Bitcoin. Yet
there has been little discussion of criminal contracts in public
forums on cryptocurrency [16] and the launch of Ethereum
took place in July 2015.
It is only by recognizing CSCs
early in their lifecycle that the community can develop timely
countermeasures to them, and see the promise of distributed
smart contract systems fully realized.

In summary, our contributions are:

While our focus is on preventing evil, happily the tech-
niques we propose can also be used to create beneﬁcial con-
tracts. We explore both techniques for structuring CSCs
and the use of cutting-edge cryptographic tools, e.g., Suc-
cinct Non-interactive ARguments of Knowledge (SNARKs),
in CSCs. Like the design of beneﬁcial smart contracts, CSC
construction requires a careful combination of cryptography
with commission-fair design [34].
• Criminal smart contracts: We initiate the study of CSCs
as enabled by Turing-complete scripting languages in next-
generation cryptocurrencies. We explore CSCs for three
diﬀerent types of crimes:
leakage of secrets in Section 4
(e.g., pre-release Hollywood ﬁlms), key compromise / theft
(of, e.g., a CA signing key) in Section 5, and “calling-card”
crimes, such as assassination, that use data sources called
“authenticated data feeds” (described below) in Section 6.
We explore the challenges involved in crafting such crimi-
nal contracts and demonstrate (anticipate) new techniques
to resist neutralization and achieve commission-fairness.
We emphasize that because commission-fairness means in-
formally that contracting parties obtain their “expected”
utility, an application-speciﬁc metric, commission-fairness
must be deﬁned in a way speciﬁc to a given CSC. We thus
formally specify commission-fairness for each of our CSC
constructions in the online full version [42].
• Proof of concept: To demonstrate that even sophisticated
CSC are realistic, we report (in their respective sections)
on implementation of the CSCs we explore. Our CSC for
leakage of secrets is eﬃciently realizable today in existing
smart contract languages (e.g., that of Ethereum). Those
for key theft and “calling-card” crimes rely respectively for
eﬃciency and realizability on features currently envisioned
by the cryptocurrency community.
• Countermeasures: We brieﬂy discuss in Section 7 how
our work in this paper can help prevent a proliferation
of CSCs. Brieﬂy, to be most eﬀective, CSCs must be ad-
vertised, making them detectible given community vigi-
lance. Miners have an economic incentive not to include

284CSC transactions in blocks, as CSCs degrade the market
value of a cryptocurrency. Consequently, awareness and
robust detection strategies may oﬀer an eﬀective general
defense. A key contribution of our work is to show the
need for such countermeasures and stimulate exploration
of their implementation in smart contract systems such as
Ethereum.
We also brieﬂy discuss in the online full version [42] how
maturing technologies, such as hardware roots of trust (e.g.,
Intel SGX [40]) and program obfuscation can enrich the
space of possible CSCs—as they can, of course, beneﬁcial
smart contracts.

2. BACKGROUND AND RELATED WORK
Emerging decentralized cryptocurrencies [52, 59] rely on
a novel blockchain technology where miners reach consensus
not only about data, but also about computation. Loosely
speaking, the Bitcoin blockchain (i.e., miners) veriﬁes trans-
actions and stores a global ledger, which may be modeled as
a piece of public memory whose integrity relies on correct
execution of the underlying distributed consensus protocol.
Bitcoin supports a limited range of programmable logic to
be executed by the blockchain. Its scripting language is re-
strictive, however, and diﬃcult to use, as demonstrated by
previous eﬀorts at building smart contract-like applications
atop Bitcoin [23, 17, 7, 53, 46].

When the computation performed by the blockchain (i.e.,
miners) is generalized to arbitrary Turing-complete logic,
we obtain a more powerful, general-purpose smart contract
system. The ﬁrst embodiment of such a decentralized smart
contract system is the recently launched Ethereum [59]. In-
formally, a smart contract in such a system may be thought
of as an autonomously executing piece of code whose inputs
and outputs can include money. (We give more formalism
below.) Hobbyists and companies are already building atop
or forking oﬀ Ethereum to develop various smart contract
applications such as security and derivatives trading [45],
prediction markets [5], supply chain provenance [11], and
crowd fund raising [2, 47].

Figure 1 shows the high-level architecture of a smart con-
tract system instantiated over a decentralized cryptocur-
rency such as Bitcoin or Ethereum. When the underlying
consensus protocol employed the cryptocurrency is secure,
a majority of the miners (as measured by computational
resources) are assumed to correctly execute the contract’s
programmable logic.

Gas. Realistic instantiations of decentralized smart con-
tract systems rely on gas to protect miners against denial-of-
service attacks (e.g., running an unbounded contract). Gas
is a form of transaction fee that is, roughly speaking, pro-
portional to the runtime of a contract.

In this paper, although we do not explicitly express gas
in our smart contract notation, we attempt to factor pro-
gram logic away from the contract as an optimization when
possible, to keep gas and thus transactional fees low. For
example, some of the contracts we propose involve program
logic executed on the user side, with no loss in security.
2.1 Smart contracts: the good and bad

Decentralized smart contracts have many beneﬁcial uses,
including the realization of a rich variety of new ﬁnancial
instruments. As Bitcoin does for transactions, in a decen-

Figure 1: Schematic of a decentralized cryptocur-
rency system with smart contracts, as illustrated by
Delmolino et al. [34]. A smart contract’s state is stored on
the public blockchain. A smart contract program is exe-
cuted by a network of miners who reach consensus on the
outcome of the execution, and update the contract’s state on
the blockchain accordingly. Users can send money or data
to a contract; or receive money or data from a contract.

tralized smart contract system, the consensus system en-
forces autonomous execution of contracts; no one entity or
small set of entities can interfere with the execution of a
contract. As contracts are self-enforcing, they eliminate the
need for trusted intermediaries or reputation systems to re-
duce transactional risk. Decentralized smart contracts oﬀer
these advantages over traditional cryptocurrencies such as
Bitcoin:
• Fair exchange between mutually distrustful parties with
rich contract rules expressible in a programmable logic.
This feature prevents parties from cheating by aborting
an exchange protocol, yet removes the need for physical
rendezvous and (potentially cheating) third-party inter-
mediaries.
• Minimized interaction between parties, reducing opportu-
• Enriched transactions with external state by allowing as
input authenticated data feeds (attestations) provided by
brokers on physical and other events outside the smart-
contract system, e.g., stock tickers, weather reports, etc.
These are in their infancy in Ethereum, but their avail-
ability is growing and use of trusted hardware promises to
stimulate their deployment [61].

nities for unwanted monitoring and tracking.

Unfortunately, for all of their beneﬁt, these properties
have a dark side, potentially facilitating crime because:
• Fair exchange enables transactions between mutually dis-
trustful criminal parties, eliminating the need for today’s
fragile reputation systems and/or potentially cheating or
law-enforcement-inﬁltrated third-party intermediaries [55,
39].
• Minimized interaction renders illegal activities harder for
law enforcement to monitor. In some cases, as for the key-
theft and calling-card CSCs we present, a criminal can
set up a contract and walk away, allowing it to execute
autonomously with no further interaction.
• Enriched transactions with external state broaden the scope

ContractsMined BlockMinersBlock # iBlock # i+ 1Block # i+ 2TimeBlockchain……CodeStorageDataUsersMoney285of possible CSCs to, e.g., physical crimes (terrorism, ar-
son, murder, etc.).
As decentralized smart contract systems typically inherit
the anonymity (pseudonymity) of Bitcoin, they oﬀer similar
secrecy for criminal activities. Broadly speaking, therefore,
there is a risk that the capabilities enabled by decentral-
ized smart contract systems will enable new underground
ecosystems and communities.
2.2 Digital cash and crime

Bitcoin and smart contracts do not represent the earliest
emergence of cryptocurrency. Anonymous e-cash was intro-
duced in 1982 in a seminal paper by David Chaum [29]. Nac-
cache and von Solms noted that anonymous currency would
render “perfect crimes” such as kidnapping untraceable by
law enforcement [57]. This observation prompted the design
of fair blind signatures or “escrow” for e-cash [26, 58], which
enables a trusted third party to link identities and payments.
Such linkage is possible in classical e-cash schemes where a
user identiﬁes herself upon withdraw of anonymous cash,
but not pseudonymous cryptocurrencies such as Bitcoin.

Ransomware has appeared in the wild since 1989 [18]. A
major cryptovirological [60] “improvement” to ransomware
has been use of Bitcoin [44], thanks to which CryptoLocker
ransomware has purportedly netted hundreds of millions of
dollars in ransom [25]. Assassination markets using anony-
mous digital cash were ﬁrst proposed in a 1995-6 essay en-
titled “Assassination Politics” [19].

There has been extensive study of Bitcoin-enabled crime,
such as money laundering [51], Bitcoin theft [49], and ille-
gal marketplaces such as the Silk Road [31]. Meiklejohn et
al. [49] note that Bitcoin is pseudonymous and that mixes,
mechanisms designed to confer anonymity on Bitcoins, do
not operate on large volumes of currency and in general
today it is hard for criminals to cash out anonymously in
volume.

On the other hand, Ron and Shamir provide evidence
that the FBI failed to locate most of the Bitcoin holdings
of Dread Pirate Roberts (Ross Ulbricht), the operator of
the Silk Road, even after seizing his laptop [56]. M¨oser,
B¨ohome, and Breuker [51] ﬁnd that they cannot success-
fully deanonymize transactions in two of three mixes under
study, suggesting that the “Know-Your-Customer” princi-
ple, regulators’ main tool in combatting money laundering,
may prove diﬃcult to enforce in cryptocurrencies. Increas-
ingly practical proposals to use NIZK proofs for anonymity
in cryptocurrencies [20, 33, 50], and at least one currently
in the early stages of commercial deployment [13], promise
to make stronger anonymity available to criminals.

3. NOTATION AND THREAT MODEL

We adopt the formal blockchain model of Kosba et al. [43].
As background, we give a high-level description of that model
in this section. We use the model to specify cryptographic
protocols in our paper; these protocols encompass criminal
smart contracts and corresponding user-side protocols.

Protocols in the smart contract model. Our model
treats a contract as a special party that is entrusted to en-
force correctness but not privacy, as noted above. (In real-
ity, of course, a contract is enforced by the network.) All
messages sent to the contract and its internal state are pub-
licly visible. A contract interacts with users and other con-

tracts by exchanging messages (also referred to as transac-
tions). Money, expressed in the form of account balances,
is recorded in the global ledger (on the blockchain). Con-
tracts can access and update the ledger to implement money
transfers between users, who are represented by pseudony-
mous public keys.
3.1 Threat Model

We adopt the following threat model in this paper.

• Blockchain: Trusted for correctness but not privacy. We
assume that the blockchain always correctly stores data
and performs computations and is always available. The
blockchain exposes all of its internal states to the public,
however, and retains no private data.
• Arbitrarily malicious contractual parties. We assume that
contractual parties are mutually distrustful, and they act
solely to maximize their own beneﬁt. Not only can they
deviate arbitrarily from the prescribed protocol, they can
also abort from the protocol prematurely.
• Network inﬂuence of the adversary. We assume that mes-
sages between the blockchain and players are delivered
within a bounded delay, i.e., not permanently dropped.
(A player can always resend a transaction dropped by a
malicious miner.)
In our model, an adversary immedi-
ately receives and can arbitrarily reorder messages, how-
ever. In real-life decentralized cryptocurrencies, the win-
ning miner sets the order of message processing. An adver-
sary may collude with certain miners or inﬂuence message-
propagation among nodes. As we show in Section 5, for
key-theft contracts, message-reordering enables a rushing
attack that a commission-fair CSC must prevent.
The formal model we adopt (reviewed later in this section
and described in full by Kosba et al. [43]) captures all of the
above aspects of our threat model.
3.2 Security deﬁnitions

For a CSC to be commission-fair requires two things:

• Correct deﬁnition of commission-fairness. There is no
universal formal deﬁnition of commission fairness: It is
application-speciﬁc, as it depends on the goals of the crim-
inal (and perpetrator). Thus, for each CSC, we specify in
the online full version [42] a corresponding deﬁnition of
commission-fairness by means of a UC-style ideal func-
tionality that achieves it. Just specifying a correct ideal
functionality is itself often challenging! We illustrate the
challenge in Section 5 and the online full version [42] with
a naive-key functionality that represents seemingly correct
but in fact ﬂawed key-theft contract.
• Correct protocol implementation. To prove that a CSC is
commission-fair, we must show that its (real-world) pro-
tocol emulates the corresponding ideal functionality. We
prove this for our described CSCs in the standard Univer-
sally Composable (UC) simulation paradigm [28] adopted
in the cryptography literature, against arbitrarily mali-
cious contractual counterparties as well as possible net-
work adversaries. Our protocols are also secure against
aborting adversaries, e.g., attempts to abort without pay-
ing the other party. Fairness in the presence of aborts
is well known in general to be impossible in standard
models of distributed computation [32]. Several recent
works show that a blockchain that is correct, available,
and aware of the progression of time can enforce ﬁnan-
cial fairness against aborting parties [23, 43, 17]. Speciﬁ-

286cally, when a contract lapses, the blockchain can cause the
aborting party to lose a deposit to the honest parties.

3.3 Notational Conventions

We now explain some notational conventions for writing
contracts. The online full version [42] gives a warm-up
example.
• Currency and ledger. We use ledger[P] to denote party
P’s balance in the global ledger. For clarity, variables that
begin with a $ sign denote money, but otherwise behave
like ordinary variables.
Unlike in Ethereum’s Serpent language, in our formal no-
tation, when a contract receives some $amount from a
party P, this is only message transfer, and no currency
transfer has taken place at this point. Money transfers
only take eﬀect when the contract performs operations on
the ledger, denoted ledger.
• Pseudonymity. Parties can use pseudonyms to obtain
better anonymity.
In particular, a party can generate
arbitrarily many public keys. In our notational system,
when we refer to a party P, P denotes the party’s pseudonym.
The formal blockchain model [43] we adopt provides a
contract wrapper that manages the pseudonym genera-
tion and the message signing necessary for establishing
an authenticated channel to the contract. These details
are abstracted away from the main contract program.
• Timer. Time progresses in rounds. At the beginning
of each round, the contract’s Timer function will be in-
voked. The variable T encodes the current time.
• Entry points and variable scope. A contract can have
various entry points, each of which is invoked when re-
ceiving a corresponding message type. Thus entry points
behave like function calls invoked upon receipt of mes-
sages.
All variables are assumed to be globally scoped, with the
following exception: When an entry point says “Upon
receiving a message from some party P,” this allows the
registration of a new party P. In general, contracts are
open to any party who interacts with them. When a
message is received from P (without the keyword “some”),
party P denotes a ﬁxed party – and a well-formed contract
has already deﬁned P.
This notational system [43] is not only designed for con-
venience, but is also endowed with precise, formal mean-
ings compatible with the Universal Composability frame-
work [28]. We refer the reader to [43] for formal modeling
details. While our proofs in the online full version [42] rely
on this supporting formalism, the main body can be under-
stood without it.

4. CSCS FOR LEAKAGE OF SECRETS

As a ﬁrst example of the power of smart contracts, we
show how an existing type of criminal contract deployed over
Bitcoin can be made more robust and functionally enhanced
as a smart contract and can be practically implemented in
Ethereum.

Among the illicit practices stimulated by Bitcoin is payment-

incentivized leakage, i.e., public disclosure, of secrets. The
recently created web site Darkleaks [3] (a kind of subsidized
Wikileaks) serves as a decentralized market for crowdfunded
public leakage of a wide variety of secrets, including, “Hol-
lywood movies, trade secrets, government secrets, propri-

etary source code, industrial designs like medicine or de-
fence, [etc.].”
Intuitively, we deﬁne commission-fairness in this setting
to mean that a contractor C receives payment iﬀ it leaks
a secret in its entirety within a speciﬁed time limit. (See
the online full version [42] for a formal deﬁnition.) As we
show, Darkleaks highlights the inability of Bitcoin to sup-
port commission-fairness. We show how a CSC can in fact
achieve commission-fairness with high probability.

4.1 Darkleaks

In the Darkleaks system, a contractor C who wishes to
sell a piece of content M partitions it into a sequence of
n segments {mi}n
i=1. At a time (block height) Topen pre-
speciﬁed by C, a randomly selected subset Ω ⊂ [n] of k
segments is publicly disclosed as a sample to entice donors /
purchasers—those who will contribute to the purchase of M
for public leakage. When C determines that donors have col-
lectively paid a suﬃcient price, C decrypts the remaining seg-
ments for public release. The parameter triple (n, k, Topen)
is set by C (where n = 100 and k = 20 are recommended
defaults).

To ensure a fair exchange of M for payment without direct
interaction between parties, Darkleaks implements a (clever)
protocol on top of the Bitcoin scripting language. The main
idea is that for a given segment mi of M that is not revealed
as a sample in Ω, donors make payment to a Bitcoin account
ai with public key pki. The segment mi is encrypted under
a key κ = H(pki) (where H = SHA-256). To spend its re-
ward from account ai, C is forced by the Bitcoin transaction
protocol to disclose pki; thus the act of spending the reward
automatically enables the community to decrypt mi.

We give further details in the online full version [42].

Shortcomings and vulnerabilities. The Darkleaks pro-
tocol has three major shortcomings / vulnerabilities that ap-
pear to stem from fundamental functional limitations of Bit-
coin’s scripting language when constructing contracts with-
out direct communication between parties. The ﬁrst two
undermine commission-fairness, while the third limits func-
tionality.1
1. Delayed release: C can refrain from spending purchasers’
/ donors’ payments and releasing unopened segments of M
until after M loses value. E.g., C could withhold segments
of a ﬁlm until after its release in theaters, of an industrial
design until after it is produced, etc.
2. Selective withholding: C can choose to forego payment
for selected segments and not disclose them. For example,
C could leak and collect payment for all of a leaked ﬁlm but
the last few minutes (which, with high probability, will not
appear in the sample Ω), signiﬁcantly diminishing the value
of leaked segments.

3. Public leakage only: Darkleaks can only serve to leak
secrets publicly.
It does not enable fair exchange for pri-
vate leakage, i.e., for payment in exchange for a secret M
encrypted under the public key of a purchaser P.

1That these limitations are fundamental is evidenced by
calls for new, time-dependent opcodes. One example is
CHECKLOCKTIMEVERIFY; apart from its many legiti-
mate applications, proponents note that it can facilitate se-
cret leakage as in Darkleaks [35].

287Additionally, Darkleaks has a basic protocol ﬂaw:

4. Reward theft: In the Darkleaks protocol, the Bitcoin pri-
vate key ski corresponding to pki is derived from mi; specif-
ically ski = SHA-256(mi). Thus, the source of M (e.g.,
the victimized owner of a leaked ﬁlm) can derive ski and
steal rewards received by C. (Also, when C claims a reward,
a malicious node that receives the transaction can decrypt
mi, compute ski = SHA-256(mi), and potentially steal the
reward by ﬂooding the network with a competing transac-
tion [36].)

This last problem is easily remedied by generating the
i=1 of segment encryption keys pseudorandomly or

set {κi}n
randomly, which we do in our CSC designs.

Remark:
In any protocol in which goods are represented
by a random sample, not just Darkleaks, C can insert a
small number of valueless or duplicate segments into M .
With non-negligible probability, these will not result in an
invalid-looking sample Ω, so Ω necessarily provides only a
weak guarantee of the global validity of M . The larger k
and n, the smaller the risk of such attack. Formal analysis
of human-veriﬁed proofs of this kind and/or ways of au-
tomating them is an interesting problem beyond the scope
of this paper, but important in assessing end-to-end security
in a CSC of this kind.
4.2 A generic public-leakage CSC

We now present a smart contract that realizes public leak-
age of secrets using blackbox cryptographic primitives. (We
later present eﬃcient realizations.) This contract overcomes
limitation 1. of the Darkleaks protocol (delayed release) by
enforcing disclosure of M at a pre-speciﬁed time Tend—or
else immediately refunding buyers’ money. It addresses lim-
itation 2. (selective withholding) by ensuring that M is re-
vealed in an all-or-nothing manner. (We later explain how
to achieve private leakage and overcome limitation 3.)
Again, we consider settings where C aims to sell M for
public release after revealing sample segments M∗.

Informal protocol description. Informally, the protocol
involves the following steps:
• Create contract. A seller C initializes a smart contract with
the encryption of a randomly generated master secret key
msk. The master secret key is used to generate (sym-
metric) encryption keys for the segments {mi}n
i=1. C pro-
vides a cryptographic commitment c0 := Enc(pk, msk, r0)
of msk to the contract. (To meet the narrow technical re-
quirements of our security proofs, the commitment is an
encryption with randomness r0 under a public key pk cre-
ated during a trusted setup step.) The master secret key
msk can be used to decrypt all leaked segments of M .
• Upload encrypted data. For each i ∈ [n], C generates en-
:= PRF(msk, i), and encrypts the i-th
cryption key κi
segment as cti = encκi [mi]. C sends all encrypted seg-
ments {cti}i∈[n] to the contract (or, for eﬃciency, provides
hashes of copies stored with a storage provider, e.g., a
peer-to-peer network). Interested purchasers / donors can
download the segments of M , but cannot decrypt them
yet.
• Challenge. The contract generates a random challenge
set Ω ⊂ [n], in practice today in Ethereum based on the
hash of a recent block. Another future possibility is some
well known randomness source, e.g., the NIST randomness

beacon [9], perhaps relayed through an authenticated data
feed.
• Response. C reveals the set {κi}i∈Ω to the contract, and
gives ZK proofs that the revealed secret keys {κi}i∈Ω are
generated correctly from the msk encrypted as c0.
• Collect donations. During a donation period, potential
purchasers / donors can use the revealed secret keys {κi}i∈Ω
to decrypt the corresponding segments. If they like the de-
crypted segments, they can donate money to the contract
as contribution for the leakage.
If enough money has been collected, C decom-
mits msk for the contract (sends the randomness for the
ciphertext along with msk).
If the contract veriﬁes the
decommitment successfully, all donated money is paid to
C. The contract thus enforces a fair exchange of msk for
money. (If the contract expires at time Tend without re-
lease of msk, all donations are refunded.)

• Accept.

The contract. Our proposed CSC PublicLeaks for imple-
menting this public leakage protocol is given in Figure 2.
The corresponding user side is as explained informally above
(and inferable from the contract).

Contract PublicLeaks

Init: Set state := init, and donations := {}. Let crs :=
KeyGennizk(1λ), pk := KeyGenenc(1λ) denote hard-
coded public parameters generated through a trusted
setup.
leaker C:

Create: Upon receiving (“create”, c0, {cti}n

i=1, Tend) from some

Set state := created.
Select a random subset Ω ⊂ [n] of size k, and send
(“challenge”, Ω) to C.

Conﬁrm: Upon receiving (“conﬁrm”, {(κi, πi)}i∈Ω) from C:

Assert state = created.
Assert that ∀i ∈ S: πi is a valid NIZK proof (under
crs) for the following statement:

∃(msk, r0), s.t. (c0 = Enc(pk, msk, r0))

∧ (κi = PRF(msk, i))

Set state := confirmed.

Donate: Upon receiving (“donate”, $amt) from some purchaser

P:

Assert state = confirmed.
Assert ledger[P] ≥ $amt.
Set ledger[P] := ledger[P] − $amt.
donations := donations ∪ {($amt, P)}.
Accept: Upon receiving (“accept”, msk, r0) from C:

Assert state = confirmed
Assert c0 = Enc(pk, msk, r0)
ledger[C] := ledger[C] + sum(donations)
Send (“leak”, msk) to all parties.
Set state := aborted.

Timer: If state = confirmed and T > Tend: ∀($amt, P) ∈
donations: let ledger[P] := ledger[P]+$amt. Set state :=
aborted.

Figure 2: A contract PublicLeaks that leaks a secret M to
the public in exchange for donations.

4.3 Commission-fairness: Formal deﬁnition and

proof

In the online full version [42], we give a formal deﬁnition
of commission-fairness for public leakage (explained infor-
mally above) as an ideal functionality. We also prove that
PublicLeaks realizes this functionality assuming all revealed
segments are valid—a property enforced with high (but not

288overwhelming) probability by random sampling of M in Pub-
licLeaks.
4.4 Optimizations and Ethereum implemen-

tation

The formally speciﬁed contract PublicLeaks uses generic
cryptographic primitives in a black-box manner. We now
give a practical, optimized version, relying on the random
oracle model (ROM), that eliminates trusted setup, and also
achieves better eﬃciency and easy integration with Ethereum [59].
A practical optimization. During contract creation, C
chooses random κi

$←{0, 1}λ for i ∈ [n], and computes

c0 := {H(κ1, 1), . . . , H(κn, n)}.

The master secret key is simply msk := {κ1, . . . , κn}, i.e.,
the set of hash pre-images. As in PublicLeaks, each segment
mi will still be encrypted as cti := encκ[mi]. (For technical
reasons—to achieve simulatability in the security proof—
here encκ[mi] = mi ⊕ [H(κi, 1,“enc”)|| H(κi, 2,“enc”) . . . ,
|| H(κi, z,“enc”)] for suitably large z.)
C submits c0 to the smart contract. When challenged
with the set Ω, C reveals {κi}i∈Ω to the contract, which
then veriﬁes its correctness by hashing and comparing with
c0. To accept donations, C reveals the entire msk.

This optimized scheme is asymptotically less eﬃcient than
our generic, black-box construction PublicLeaks—as the mas-
ter secret key scales linearly in the number of segments n.
But for typical, realistic document set sizes in practice (e.g.,
n = 100, as recommended for Darkleaks), it is more eﬃcient.

Ethereum-based implementation. To demonstrate the
feasibility of implementing leakage contracts using currently
available technology, we implemented a version of the con-
tract PublicLeaks atop Ethereum [59], using the Serpent con-
tract language [10]. We specify the full implementation in
detail in the online full version [42].

The version we implemented relies on the practical opti-
mizations described above. As a technical matter, Ethereum
does not appear at present to support timer-activated func-
tions, so we implemented Timer in such a way that pur-
chasers / donors make explicit withdrawals, rather than re-
ceiving automatic refunds.

This public leakage Ethereum contract is highly eﬃcient,
as it does not require expensive cryptographic operations.
It mainly relies on hashing (SHA3-256) for random number
generation and for verifying hash commitments. The total
number of storage entries (needed for encryption keys) and
hashing operations is O(n), where, again, Darkleaks recom-
mends n = 100. (A hash function call in practice takes a
few micro-seconds, e.g., 3.92 µsecs measured on a core i7
processor.)
4.5 Extension: private leakage
As noted above, shortcoming 3. of Darkleaks is its inability
to support private leakage, in which C sells a secret exclu-
sively to a purchaser P. In the online full version [42], we
show how PublicLeaks can be modiﬁed for this purpose. The
basic idea is for C not to reveal msk directly, but to provide a
ciphertext ct = encpkP [msk] on msk to the contract for a pur-
chaser P, along with a proof that ct is correctly formed. We
describe a black-box variant whose security can be proven
in essentially the same way as PublicLeaks. We also describe

Contract KeyTheft-Naive

Init: Set state := init. Let crs := KeyGennizk(1λ) denote
a hard-coded NIZK common reference string generated
during a trusted setup process.
contractor C := (pkC, . . .):

Create: Upon receiving (“create”, $reward, pkV , Tend) from some

Assert state = init.
Assert ledger[C] ≥ $reward.
ledger[C] := ledger[C] − $reward.
Set state := created.

Claim: Upon receiving (“claim”, ct, π) from some purported per-

petrator P:

Assert state = created.
Assert that π is a valid NIZK proof (under crs) for the
following statement:

∃r, skV s.t. ct = Enc(pkC, (skV , P), r)

and match(pkV , skV ) = true

Timer: If state = created and current time T > Tend:

ledger[P] := ledger[P] + $reward.
Set state := claimed.
ledger[C] := ledger[C] + $reward
state := aborted

Figure 3: A na¨ıve, ﬂawed key theft contract (lacking
commission-fairness)

a practical variant that combines a veriﬁable random func-
tion (VRF) of Chaum and Pedersen [30] (for generation of
{κi}n
i=1) with a veriﬁable encryption (VE) scheme of Ca-
mensich and Shoup [27] (to prove correctness of ct). This
variant can be deployed today using beta support for big
number arithmetic in Ethereum.

5. A KEY-COMPROMISE CSC
Example 1b in the paper introduction described a CSC
that rewards a perpetrator P for delivering to C the stolen
key skV of a victim V—in this case a certiﬁcate authority
(CA) with public key pkV . Recall that C generates a private
/ public key encryption pair (skC, pkC). The contract accepts
as a claim by P a pair (ct, π). It sends reward $reward to
P if π is a valid proof that ct = encpkC [skV ] and skV is the
private key corresponding to pkV .
Intuitively, a key-theft contract is commission-fair if it re-
wards a perpetrator P for delivery of a private key that: (1)
P was responsible for stealing and (2) Is valid for a substan-
tial period of time. (See the online full version [42] for a
formal deﬁnition.)

This form of contract can be used to solicit theft of any
type of private key, e.g., the signing key of a CA, the private
key for a SSL/TLS certiﬁcate, a PGP private key, etc. (Sim-
ilar contracts could solicit abuse, but not full compromise of
a private key, e.g., forged certiﬁcates.)

Figure 3 shows the contract of Example 1b in our notation
for smart contracts. We let crs here denote a common refer-
ence string for a NIZK scheme and match(pkV , skV ) denote
an algorithm that veriﬁes whether skV is the corresponding
private key for some public key pkV in a target public-key
cryptosystem.

As noted above, this CSC is not commission-fair. Thus
we refer to it as KeyTheft-Naive.We use KeyTheft-Naive as a
helpful starting point for motivating and understanding the
construction of a commission-fair contract proposed later,
called KeyTheft.

2895.1 Flaws in KeyTheft-Naive

The contract KeyTheft-Naive fails to achieve commission-

fairness due to two shortcomings.
Revoke-and-claim attack. The CA V can revoke the key
skV and then itself submit the key for payment. The CA
then not only negates the value of the contract but actually
proﬁts from it! This revoke-and-claim attack demonstrates
that KeyTheft-Naive is not commission-fair in the sense of
ensuring the delivery of a usable private key skV .

Rushing attack. Another attack is a rushing attack. As
noted in Section 3, an adversary can arbitrarily reorder
messages—a reﬂection of possible attacks against the net-
work layer in a cryptocurrency. (See also the formal blockchain
model [43].) Thus, given a valid claim from perpetrator P,
a corrupt C can decrypt and learn skV , construct another
valid-looking claim of its own, and make its own claim ar-
rive before the valid one.

5.2 Fixing ﬂaws in KeyTheft-Naive

We now show how to modify KeyTheft-Naive to prevent

the above two attacks and achieve commission-fairness.

Thwarting revoke-and-claim attacks. In a revoke-and-
claim attack against KeyTheft-Naive, V preemptively revokes
its public key pkV and replaces it with a fresh one pk(cid:48)
V . As
noted above, the victim can then play the role of perpetrator
P, submit skV to the contract and claim the reward. The
result is that C pays $reward to V and obtains a stale key.
We address this problem by adding to the contract a fea-
ture called reward truncation, whereby the contract accepts
evidence of revocation Πrevoke.

This evidence Πrevoke can be an Online Certiﬁcate Status
Protocol (OCSP) response indicating that pkV is no longer
valid, a new certiﬁcate for V that was unknown at the time
of contract creation (and thus not stored in Contract), or
a certiﬁcate revocation list (CRL) containing the certiﬁcate
with pkV .
C could submit Πrevoke, but to minimize interaction by C,
KeyTheft could provide a reward $smallreward to a third-
party submitter. The reward could be small, as Πrevoke
would be easy for ordinary users to obtain.

The contract then provides a reward based on the inter-
val of time over which the key skV remains valid. Let Tclaim
denote the time at which the key skV is provided and Tend
be an expiration time for the contract (which must not ex-
ceed the expiration of the certiﬁcate containing the targeted
key). Let Trevoke be the time at which Πrevoke is presented
(Trevoke = ∞ if no revocation happens prior to Tend). Then
the contract assigns to P a reward of f (reward, t), where
t = min(Tend, Trevoke) − Tclaim.

We do not explore choices of f here. We note, however,
that given that a CA key skV can be used to forge certiﬁcates
for rapid use in, e.g., malware or falsiﬁed software updates,
much of its value can be realized in a short interval of time
which we denote by δ. (A slant toward up-front realization
of the value of exploits is common in general [24].) A suitable
choice of reward function should be front-loaded and rapidly
decaying. A natural, simple choice with this property is

(cid:26) 0

f ($reward, t) =

$reward(1 − ae−b(t−δ))

: t < δ
: t ≥ δ

for a < 1/2 and some positive real value b. Note that a
majority of the reward is paid provided that t ≥ δ.
Thwarting rushing attacks. To thwart rushing attacks,
we separate the claim into two phases. In the ﬁrst phase, P
expresses an intent to claim by submitting a commitment of
the real claim message. P then waits for the next round to
open the commitment and reveal the claim message. (Due
to technical subtleties in the proof, the commitment must
be adaptively secure; in the proof, the simulator must be
able to simulate a commitment without knowing the string
s being committed to, and later, be able to claim the com-
mitment to any string s.)
In real-life decentralized cryp-
tocurrencies, P can potentially wait multiple block intervals
before opening the commitment, to have higher conﬁdence
that the blockchain will not fork.
In our formalism, one
round can correspond to one or more block intervals.

Figure 4 gives a key theft contract KeyTheft that thwarts

revoke-and-claim and the rushing attacks.

5.3 Target and state exposure
An undesirable property of KeyTheft-Naive is that its tar-
get / victim and state are publicly visible. V can thus learn
whether it is the target of KeyTheft-Naive. V also observes
successful claims—i.e., whether skV has been stolen—and
can thus take informed defensive action. For example, as
key revocation is expensive and time-consuming, V might
wait until a successful claim occurs and only then perform
a revoke-and-claim attack.

To limit target and state exposure, wenote two possible
enhancements to KeyTheft. The ﬁrst is a multi-target con-
tract, in which key theft is requested for any one of a set of
multiple victims. The second is what we call cover claims,
false claims that conceal any true claim. Our implementa-
tion of KeyTheft, as speciﬁed in Figure 4, is a multi-target
contract, as this technique provides both partial target and
partial state concealment.

Multi-target contract. A multi-target contract solicits
the private key of any of m potential victims V1,V2, . . . ,Vm.
There are many settings in which the private keys of diﬀerent
victims are of similar value. For example, a multi-target
contract KeyTheft could oﬀer a reward for the private key
skV of any CA able to issue SSL/TLS certiﬁcates trusted
by, e.g., Internet Explorer (of which there are more than
650 [37]).

A challenge here is that the contract state is public, thus
the contract must be able to verify the proof for a valid
claim (private key) skVi without knowing which key was fur-
nished, i.e., without learning i. Our implementation shows
that constructing such proofs as zk-SNARKs is practical.
(The contractor C itself can easily learn i by decrypting skVi ,
generating pkVi
, and identifying the corresponding victim.)
Cover claims. As the state of a contract is publicly vis-
ible, a victim V learns whether or not a successful claim
has been submitted to KeyTheft-Naive. This is particularly
problematic in the case of single-target contracts.

Rather than sending the NIZK proof π with ct, it is pos-
sible instead to delay submission of π (and payment of the
reward) until Tend. (That is, Claim takes as input (“claim”,
ct).) This approach conceals the validity of ct. Note that
even without π, C can still make use of ct.

A contract that supports such concealment can also sup-

290Contract KeyTheft

Init: Set state := init. Let crs := KeyGennizk(1λ) denote a
hard-coded NIZK common reference string generated
during a trusted setup process.

Create: Same as in Contract KeyTheft-Naive (Figure 3), except
that an additional parameter ∆T is additionally sub-
mitted by C.
petrator P:

Intent: Upon receiving (“intent”, cm) from some purported per-

Assert state = created
Assert that P has not sent “intent” earlier
Store cm, P

Claim: Upon receiving (“claim”, ct, π, r) from P:

Assert state = created
Assert P submitted (“intent”, cm) earlier such that
cm = comm(ct||π, r).

Continue in the same manner as in contract KeyTheft-
Naive, except that the ledger update ledger[P]
:=
ledger[P] + $reward does not take place immediately.

Revoke: On receive (“revoke”, Πrevoke) from some R:

Assert Πrevoke is valid, and state (cid:54)= aborted.
ledger[R] := ledger[R] + $smallreward.
If state = claimed:

Let t := (time elapsed since successful Claim).
Let P := (successful claimer).
rewardP := f ($reward, t).
ledger[P] := ledger[P] + rewardP .

Else, rewardP := 0
ledger[C] := ledger[C] + $reward

−$smallreward − rewardP

Set state := aborted.

Timer: If state = claimed and at least ∆T time elapsed since

Claim:

ledger[P] := ledger[P] + $reward;
Set state := aborted.
ledger[C] := ledger[C] + $reward.
Set state := aborted.

Else if current time T > Tend and state (cid:54)= aborted:

// P should not submit claims after Tend − ∆T .

Figure 4: Key compromise CSC that thwarts the revoke-
and-claim attack and the rushing attack.

port an idea that we refer to as cover claims. A cover claim is
an invalid claim of the form (“claim”, ct), i.e., one in which
ct is not a valid encryption of skV . Cover claims may be
submitted by C to conceal the true state of the contract. So
that C need not interact with the contract after creation,
the contract could parcel out small rewards at time Tend to
third parties that submit cover claims. We do not implement
cover claims in our version of KeyTheft nor include them in
Figure 4.
5.4 Commision-fairness: Formal deﬁnition and

proof

We deﬁne commission-fairness for key theft in terms of an
ideal functionality in the online full version [42] and also
provide a formal proof of security there for KeyTheft.
5.5 Implementation

We rely on zk-SNARKs for eﬃcient realization of the
protocols above. zk-SNARKs are zero-knowledge proofs of
knowledge that are succinct and very eﬃcient to verify. zk-
SNARKs have weaker security than what is needed in UC-
style simulation proofs. We therefore use a generic transfor-
mation described in the Hawk work [43] to lift security such
that the zero-knowledge proof ensures simulation-extractable
soundness.
(In brief, a one-time key generation phase is

1-Target
Key Gen.[C]

Eval. Key
Ver. Key
Prove[P]

Proof

#threads RSA-2048 ECDSA P256

1
4

1
4

124.88 sec
33.53 sec
215.93 MB

6.09 KB
41.02 sec
15.7 sec

711 B

242.30 sec
73.38 sec
448.24 MB

5.15 KB
83.63 sec
32.19 sec

711 B

Veriﬁcation [Contract]

0.0089 sec

0.0087 sec

500-Target
Key Gen.[C]

Eval. Key
Ver. Key
Prove[P]

Proof

#threads RSA-2048 ECDSA P256

1
4

1
4

161.56 sec
43.35 sec
279.41 MB

4.99 KB
54.15 sec
23.54 sec

711 B

263.07 sec
78.31 sec
490.85 MB

4.99 KB
84.69 sec
33.49 sec

711 B

Veriﬁcation [Contract]

0.0087 sec

0.0087 sec

Table 1: Performance of the key-compromise zk-SNARK circuit
for Claim in the case of a 1-target and 500-target contracts. [.]
refers to the entity performing the computational work.

needed to generate two keys: a public evaluation key, and a
public veriﬁcation key. To prove a certain NP statement, an
untrusted prover uses the evaluation key to compute a suc-
cinct proof; any veriﬁer can use the public veriﬁcation key
to verify the proof. The veriﬁer in our case is the contract.)
In our implementation, we assume the key generation is ex-
ecuted conﬁdentially by a trusted party; otherwise a prover
can produce a valid proof for a false statement. To mini-
mize trust in the key generation phase, secure multi-party
computation techniques can be used as in [21].

zk-SNARK circuits for Claim. To estimate the proof
computation and veriﬁcation costs required for Claim, we
implemented the above protocol for theft of RSA-2048 and
ECDSA P256 keys, which are widely used in SSL/TLS cer-
tiﬁcates currently. The circuit has two main sub-circuits:
a key-check circuit, and an encryption circuit. 2 The en-
cryption circuit was realized using RSAES-OAEP [41] with
a 2048-bit key. Relying on compilers for high-level imple-
mentation of these algorithms may produce expensive cir-
cuits for the zk-SNARK proof computation.
Instead, we
built customized circuit generators that produce more eﬃ-
cient circuits. We then used the state-of-the-art zk-SNARK
library [22] to obtain the evaluation results. Table 1 shows
the results of the evaluation of the circuits for both single-
target and multi-target contracts. The experiments were
conducted on an Amazon EC2 r3.2xlarge instance with 61GB
of memory and 2.5 GHz processors.

The results yield two interesting observations:

i) Once
a perpetrator obtains the secret key of a TLS public key,
computing the zk-SNARK proof would require less than two
minutes, costing less than 1 USD [4] for either single or
multi-target contracts; ii) The overhead introduced by using
a multi-target contract with 500 keys on the prover’s side is
only 13 seconds in the worst case.
In the same time, the
veriﬁcation overhead by the contract is still the same as in
the single-target case. This is achieved by the use of an
eﬃcient Merkle tree circuit that proves the membership of

2The circuit also has other commitment and encryption sub-
circuits needed for simulation extractability – see the online
full version [42].

291the compromised public key in the target key set, while using
the same components of the single-target circuit as is.

Validation of revoked certiﬁcates. The reward function
in the contract above relies on certiﬁcate revocation time,
and therefore the contract needs modules that can process
certiﬁcate revocation proofs, such as CRLs and OCSP re-
sponses, and verify the CA digital signatures on them. As an
example, we measured the running time of openssl verify
-crl_check command, testing the revoked certiﬁcate at [12]
and the CRL last updated at [8] on Feb 15th, 2016, that
had a size of 143KB. On average, the veriﬁcation executed
in about 0.016 seconds on a 2.3 GHz i7 processor. The sig-
nature algorithm was SHA-256 with RSA encryption, with
a 2048-bit key. Since OCSP responses can be smaller than
CRLs, the veriﬁcation time could be even less for OCSP.

The case of multi-target contracts. Verifying the re-
vocation proof for single-target contracts is straightforward:
The contract can determine whether a revocation proof cor-
responds to the targeted key.
In multi-target contracts,
though, the contract does not know which target key corre-
sponds to the proof of key theft P submitted. Thus, a proof
is needed that the revocation corresponds to the stolen key,
and it must be submitted by C.
We built a zk-SNARK circuit through which C can prove
the connection between the ciphertext submitted by the per-
petrator and the compromised target key. For eﬃciency, we
eliminated the need for the key-check sub-circuit in Revoke
by forcing P to append the secret index of the compromised
public key to the secret key before applying encryption in
Claim. The evaluation in Table 2 illustrates the eﬃciency
of the veriﬁcation done by the contract receiving the proof,
and the practicality for C of constructing the proof. In con-
trast to the case for Claim, the one-time key generation for
this circuit must be done independently from C, so that C
cannot cheat the contract. We note that the Revoke circuit
we built is invariant to the cryptosystem of the target keys.

#threads RSA-2048 ECDSA P256

Key Gen.

Eval. Key
Ver. Key

Prove[C]

Proof

1
4

1
4

124.64 sec
33.52 sec
215.41 MB

5.51 KB
41.08 sec
15.94 sec

711 B

124.35 sec
33.38 sec
214.81 MB

4.88 KB
40.96 sec
15.59 sec

711 B

Veriﬁcation [Contract]

0.0087 sec

0.0086 sec

Table 2: Performance of the key-compromise zk-SNARK circuit
for Revoke needed in the case of multi-target contract. [.] refers
to the entity performing the computational work.

6. CALLING-CARD CRIMES

As noted above, decentralized smart contract systems (e.g.,
Ethereum) have supporting services that provide authenti-
cated data feeds, digitally signed attestations to news, facts
about the physical world, etc. While still in its infancy, this
powerful capability is fundamental to many applications of
smart contracts and will expand the range of CSCs very
broadly to encompass events in the physical world, as in the
following example:
(Assassination CSC). Contractor C posts
a contract Assassinate for the assassination of Senator X.
The contract rewards the perpetrator P of this crime.

Example 2

The contract Assassinate takes as input from a perpetra-
tor P a commitment vcc specifying in advance the details
(day, time, and place) of the assassination. To claim the
reward, P decommits vcc after the assassination. To verify
P’s claim, Assassinate searches an authenticated data feed
on current events to conﬁrm the assassination of Senator X
with details matching vcc.

This example also illustrates the use of what we refer to
as a calling card, denoted cc. A calling card is an unpre-
dictable feature of a to-be-executed crime (e.g., in Exam-
ple 2, a day, time, and place). Calling cards, alongside au-
thenticated data feeds, can support a general framework for
a wide variety of CSCs.
A generic construction for a CSC based on a calling card is
as follows. P provides a commitment vcc to a calling card cc
to a contract in advance. After the commission of the crime,
P proves that cc corresponds to vcc (e.g., decommits vcc).
The contract refers to some trustworthy and authenticated
data feed to verify that: (1) The crime was committed and
(2) The calling card cc matches the crime. If both conditions
are met, the contract pays a reward to P.
Intuitively, we deﬁne commission fairness to mean that
P receives a reward iﬀ it was responsible for carrying out
a commissioned crime. (A formal deﬁnition is given in the
online full version [42].)
In more detail, let CC be a set of possible calling cards
and cc ∈ CC denote a calling card. As noted above, it is
anticipated that an ecosystem of authenticated data feeds
will arise around smart contract systems such as Ethereum.
We model a data feed as a sequence of pairs from a source
S, where (s(t), σ(t)) is the emission for time t. The value
s(t) ∈ {0, 1}∗ here is a piece of data released at time t,
while σ(t) is a corresponding digital signature; S has an
associated private / public key pair (skS , pkS ) used to sign
/ verify signatures.
Note that once created, a calling-card contract requires no
further interaction from C, making it hard for law enforce-
ment to trace C using subsequent network traﬃc.
6.1 Example: website defacement contract
As an example, we specify a simple CSC SiteDeface for
website defacement. The contractor C speciﬁes a website url
to be hacked and a statement stmt to be displayed. (For
example, stmt = ”Anonymous. We are Legion. We do not
Forgive...” and url = whitehouse.gov.)

We assume a data feed that authenticates website con-
tent, i.e., s(t) = (w, url, t), where w is a representation of
the webpage content and t is a timestamp, denoted for sim-
plicity in contract time. (For eﬃciency, w might be a hash
of and pointer to the page content.) Such a feed might take
the form of, e.g., a digitally signed version of an archive
of hacked websites (e.g., zone-h.com). The function SigVer
denotes the signature veriﬁcation operation.
As example parameterization, we might let CC = {0, 1}256,
i.e., cc is a 256-bit string. A perpetrator P simply se-
lects a calling card cc $← {0, 1}256 and commitment vcc :=
commit(cc,P; ρ), where commit denotes a commitment scheme,
and ρ ∈ {0, 1}256 a random string. (In practice, HMAC-
SHA256 is a suitable choice for easy implementation in Ethereum,
given its support for SHA-256.) P decommits by revealing
all arguments to commit.

The CSC SiteDeface is shown in Figure 5. The example
we use is simpliﬁed for clarity. We assume in this example

292that the published webpage will only contain the calling card
and the statement, but it is possible to support arbitrarily
rich content in the published webpage.

Contract SiteDeface

Init: On receiving ($reward, pkS , url, stmt) from some C:

Store ($reward, pkS , url, stmt)
Set i := 0, Tstart := T

Commit: Upon receiving commitment vcc from some P:
Store vcci := vcc and Pi := P ; i := i + 1.

P:

Claim: Upon receiving as input a tuple (cc, ρ, σ, w, t) from some
Find smallest i such that vcci = commit(cc, P; ρ),
abort if not found.
Assert w = cc || stmt
Assert t ≥ Tstart
Assert SigVer(pkS , (w, url, t), σ) = true
Send $reward to Pi and abort.

Figure 5: CSC for website defacement

Remarks. SiteDeface could be implemented alternatively
by having P generate cc as a digital signature. Our imple-
mentation, however, also accommodates short, low-entropy
calling cards cc, which is important for general calling-card
CSCs. See the online full version [42].

Implementation. Given an authenticated data feed, im-
plementing SiteDeface would be straightforward and eﬃ-
cient. The main overhead lies in the Claim module, where
the contract computes a couple of hashes and validates the
feed signature on retrieved website data. As noted in Section
4, a hash function call can be computed in very short time
(4µsec), while checking the signature would be more costly.
For example, if the retrieved content is 100KB, the contract
needs only about 10msec to verify an RSA-2048 signature.
6.2 Commission-fairness: Formal deﬁnition

We give a formal deﬁnition of commission-fairness for a

general calling-card CSC in the online full version [42].

We do not provide a security proof, as this would require
modeling of physical-world systems, which is outside the
scope of this paper.
6.3 Other calling-card crimes / data feed cor-

ruption

Using a CSC much like SiteDeface, a contractor C can
solicit many other crimes, e.g., assassination, assault, sab-
otage, hijacking, kidnapping, denial-of-service attacks, and
terrorist attacks. A perpetrator P must be able to designate
a calling card that is reliably reported by an authenticated
data feed.

A natural countermeasure to a calling-card-based CSC,
however, is for an adversary, i.e., party trying to neutral-
ize the CSC, to corrupt an authenticated data feed or data
source such that it furnishes invalid data. In cases involve
highly dangerous CSCs, such approaches might be work-
able. For example, if there is a well-funded CSC calling for
the assassination of a public oﬃcial, a data feed provider or
news source might be persuaded to issue a false report of
the target’s death.
Conversely, if C is concerned about suppression of infor-
mation in one source, it can of course create a CSC that
references multiple sources, e.g., multiple news feeds. The

CSC might treat a event as authentic only if it is reported
by a certain fraction, e.g., a majority, of these sources. Such
diversiﬁcation of sources would render corruption far more
challenging (and is a good idea to provide resilience to data
corruption for benign contracts too).

We discuss a number of the general issues surrounding the
construction of calling-card CSCs in the online full version
[42].

7. COUNTERMEASURES

The main aim of our work is to emphasize the importance
of developing countermeasures against CSCs for emerging
smart contract systems such as Ethereum. We brieﬂy dis-
cuss this challenge here.

Ideas such as blacklisting “tainted” coins / transactions—
those with known criminal use—have been brought forward
for cryptocurrencies such as Bitcoin. A proactive alterna-
tive noted in Section 2 is an identity-escrow idea in early
(centralized) e-cash systems sometimes referred as “trustee-
based tracing” [26, 58]. Trustee-tracing schemes permitted a
trusted party (“trustee”) or a quorum of such parties to trace
monetary transactions that would otherwise remain anony-
mous. In decentralized cryptocurrencies, however, users do
not register identities with authorities—and many would ob-
ject to doing so. It would be possible for users to register
voluntarily and to choose only to accept only currency they
deem suitably registered. The idea of tainting coins, though,
has been poorly received by the cryptocurrency community
because it undermines the basic cash-like property of fungi-
bility [14, 48], and trustee-based tracing would have a similar
drawback. It is also unclear what entities should be granted
the authority to perform blacklisting or register users.

We observe, however, that it is economically advantageous
for most users of a cryptocurrency to monitor and/or re-
strain criminal activity, which can degrade acceptance and
therefore market value. This observation has stimulated the
creation, for instance, of the Blockchain Alliance [15], whose
mission is to combat criminal activity on blockchains. Simi-
larly, core developers of cryptocurrencies such as Ethereum
have indicated the desirability of ﬁltering blockchain con-
tent, by analogy with censorship of hate speech [54].

Identifying Bitcoin transactions as criminal is challeng-
ing, as transactions themselves carry no information about
payment context.
In contrast, CSCs, if identiﬁed as such
(e.g., an assassination contract), are self-incriminating ob-
jects. Reversing CSC binaries could be challenging, but
we note that for CSCs to be eﬀective—as in our examples
above—their deployers must advertise, drawing attention to
the nature of their contracts.
(For example, a contractor
looking to have an assassination performed must ﬁnd an
assassin.) Our hypothesis, therefore, is that a suﬃciently
vigilant cryptocurrency community can detect the presence
of many CSCs and will be incentivized to ﬁlter or purge as-
sociated transactions. One simple potential mechanism is
for miners to omit transactions from blocks when they are
ﬂagged by reputable communities as CSCs.

A more aggressive approach is possible as well, a notion
that we call trustee-neutralizable smart contracts. A smart
contract system might be designed such that an author-
ity, quorum of authorities, or suitable set of general sys-
tem participants is empowered to remove a contract from
the blockchain. Such an approach would have a big ad-
vantage over traditional trustee-based protections, in that

293it would not require users to register identities. Whether
the idea would be palatable to cryptocurrency communities
and whether a broadly acceptable set of authorities could
be identiﬁed are, of course, open questions, as are the right
supporting technical mechanisms.

In general, our work here is therefore important in sensi-
tizing the cryptocurrency community to the threat of CSCs,
enabling structures for monitoring and appropriate counter-
measures to be set in place. We believe it is important to
create awareness in the early stages of development of de-
centralized smart contract ecosystems such as Ethereum.

8. CONCLUSION

We have demonstrated that a range of commission-fair
criminal smart contracts (CSCs) are practical in decentral-
ized currencies with smart contracts. We presented three—
leakage of secrets, key theft, and calling-card crimes—and
showed that they are eﬃciently implementable with existing
cryptographic techniques, given suitable support in smart
contract systems such as Ethereum. The contract Publi-
cLeaks and its private variant can today be eﬃciently imple-
mented in Serpent, an Ethereum scripting language. KeyTheft
would require only modest, already envisioned opcode sup-
port for zk-SNARKs for eﬃcient deployment. Calling-card
CSCs will be possible given a suﬃciently rich data-feed ecosys-
tem. Many more CSCs are no doubt possible.

We emphasize that smart contracts in distributed cryp-
tocurrencies have numerous promising, legitimate applica-
tions and that banning smart contracts would be neither
sensible nor, in all likelihood, possible. The urgent open
question raised by our work is thus how to create safeguards
against the most dangerous abuses of such smart contracts
while supporting their many beneﬁcial applications.

Acknowledgements
This work is funded in part by NSF grants CNS-1314857,
CNS-1330599, CNS-1453634, CNS-1514261, CNS-1514163,
CNS-1518765, a Packard Fellowship, a Sloan Fellowship,
Google Faculty Research Awards, and a VMWare Research
Award. We gratefully acknowledge Rafael Pass, abhi she-
lat, Jonathan Katz, and Andrew Miller for helpful technical
discussions regarding the cryptographic constructions and
formalism. We especially thank Rafael Pass for pointing
out the rushing attack.

9. REFERENCES
[1] http://www.smartcontract.com.
[2] http://koinify.com.
[3] https://github.com/darkwallet/darkleaks.
[4] Amazon EC2 pricing.

http://aws.amazon.com/ec2/pricing/.

[5] Augur. http://www.augur.net/.
[6] Bitcoin ransomware now spreading via spam campaigns.

http://www.coindesk.com/
bitcoin-ransomware-now-spreading-via-spam-campaigns/.

[7] bitoinj. https://bitcoinj.github.io/.
[8] CRL issued bby Symantec Class 3 EV SSL CA - G3.

http://ss.symcb.com/sr.crl.

[9] NIST randomness beacon. https://beacon.nist.gov/home.
[10] Serpent. https://github.com/ethereum/wiki/wiki/Serpent.
[11] Skuchain. http://www.skuchain.com/.
[12] Verisign revoked certiﬁcate test page.

https://test-sspev.verisign.com:

2443/test-SPPEV-revoked-verisign.html. Accessed:
2015-05-15.

[13] Zcash. Referenced Aug. 2016 at z.cash.
[14] Mt. Gox thinks it’s the Fed. freezes acc based on “tainted”

coins. (unlocked now).
https://bitcointalk.org/index.php?topic=73385.0, 2012.
[15] Blockchain Alliance. www.blockchainalliance.org, 2016.
[16] Ethereum and evil. Forum post at Reddit; url:

http://tinyurl.com/k8awj2j, Accessed May 2015.

[17] M. Andrychowicz, S. Dziembowski, D. Malinowski, and

L. Mazurek. Secure Multiparty Computations on Bitcoin.
In S & P, 2013.

[18] J. Bates. Trojan horse: AIDS information introductory

diskette version 2.0,. In E. Wilding and F. Skulason,
editors, Virus Bulletin, pages 3–6. 1990.

[19] J. Bell. Assassination politics.

http://www.outpost-of-freedom.com/jimbellap.htm, 1995-6.

[20] E. Ben-Sasson, A. Chiesa, C. Garman, M. Green, I. Miers,

E. Tromer, and M. Virza. Zerocash: Decentralized
anonymous payments from Bitcoin. In S & P. IEEE, 2014.

[21] E. Ben-Sasson, A. Chiesa, M. Green, E. Tromer, and

M. Virza. Secure sampling of public parameters for succinct
zero knowledge proofs. In S & P, 2015.

[22] E. Ben-Sasson, A. Chiesa, E. Tromer, and M. Virza.

Succinct non-interactive zero knowledge for a von Neumann
architecture. In USENIX Security, 2014.

[23] I. Bentov and R. Kumaresan. How to Use Bitcoin to Design

Fair Protocols. In CRYPTO, 2014.

[24] L. Bilge and T. Dumitras. Before we knew it: an empirical
study of zero-day attacks in the real world. In CCS, 2012.

[25] V. Blue. Cryptolocker’s crimewave: A trail of millions in

laundered Bitcoin. ZDNet, 22 December 2013.

[26] E. F. Brickell, P. Gemmell, and D. W. Kravitz.

Trustee-based tracing extensions to anonymous cash and
the making of anonymous change. In SODA, volume 95,
pages 457–466, 1995.

[27] J. Camenisch and V. Shoup. Practical veriﬁable encryption

and decryption of discrete logarithms. In CRYPTO ’03.
2003.

[28] R. Canetti. Universally composable security: A new

paradigm for cryptographic protocols. In FOCS, 2001.

[29] D. Chaum. Blind signatures for untraceable payments. In

CRYPTO, pages 199–203, 1983.

[30] D. Chaum and T. P. Pedersen. Wallet databases with

observers. In CRYPTO’92, pages 89–105, 1993.

[31] N. Christin. Traveling the Silk Road: A measurement
analysis of a large anonymous online marketplace. In
WWW, 2013.

[32] R. Cleve. Limits on the security of coin ﬂips when half the

processors are faulty. In STOC, 1986.

[33] G. Danezis, C. Fournet, M. Kohlweiss, and B. Parno.

Pinocchio Coin: building Zerocoin from a succinct
pairing-based proof system. In PETShop, 2013.

[34] K. Delmolino, M. Arnett, A. Kosba, A. Miller, and E. Shi.

Step by step towards creating a safe smart contract:
Lessons and insights from a cryptocurrency lab.
https://eprint.iacr.org/2015/460.

[35] P. T. et al. Darkwallet on twitter: “DARK LEAKS coming

soon. http://t.co/k4ubs16scr”. Reddit:
http://bit.ly/1A9UShY.

[36] I. Eyal and E. G. Sirer. Majority is not enough: Bitcoin

mining is vulnerable. In FC, 2014.

[37] E. F. Foundation. EFF SSL observatory. URL:
https://www.eﬀ.org/observatory, August 2010.

[38] A. Greenberg. ’Dark Wallet’ is about to make Bitcoin

money laundering easier than ever.
http://www.wired.com/2014/04/dark-wallet/.

[39] A. Greenberg. Alleged silk road boss Ross Ulbricht now

accused of six murders-for-hire, denied bail. Forbes, 21
November 2013.

294[40] Intel. Intel software guard extensions programming

[50] I. Miers, C. Garman, M. Green, and A. D. Rubin. Zerocoin:

reference. Whitepaper ref. 329298-002US, October 2014.

[41] J. Jonsson and B. Kaliski. Public-Key Cryptography

Standards (PKCS) #1: RSA Cryptography Speciﬁcations
Version 2.1, 2003. RFC 3447.

[42] A. Juels, A. Kosba, and E. Shi. The ring of gyges:

Investigating the future of criminal smart contracts.
Cryptology ePrint Archive, Report 2016/358, 2016.
http://eprint.iacr.org/2016/358.

Anonymous Distributed E-Cash from Bitcoin. In S & P,
2013.

[51] M. Moser, R. Bohme, and D. Breuker. An inquiry into

money laundering tools in the bitcoin ecosystem. In eCRS,
2013.

[52] S. Nakamoto. Bitcoin: A Peer-to-Peer Electronic Cash

System. http://bitcoin.org/bitcoin.pdf, 2009.

[53] R. Pass and a. shelat. Micropayments for peer-to-peer

[43] A. Kosba, A. Miller, E. Shi, Z. Wen, and C. Papamanthou.

currencies. Manuscript.

Hawk: The blockchain model of cryptography and
privacy-preserving smart contracts. In S & P. IEEE, 2016.

[44] V. Kotov and M. Rajpal. Understanding

crypto-ransomware. Bromium whitepaper, 2014.

[45] A. Krellenstein, R. Dermody, and O. Slama. Counterparty

announcement.
https://bitcointalk.org/index.php?topic=395761.0, January
2014.

[46] R. Kumaresan and I. Bentov. How to Use Bitcoin to

Incentivize Correct Computations. In CCS, 2014.

[47] D. Mark, V. Zamﬁr, and E. G. Sirer. A call for a temporary
moratorium on “The DAO” (v0.3.2). Referenced Aug. 2016
at http://bit.ly/2aWDhyY, 30 May 2016.

[48] J. Matonis. Why Bitcoin fungibility is essential. CoinDesk,

1 Dec. 2013.

[49] S. Meiklejohn, M. Pomarole, G. Jordan, K. Levchenko,

D. McCoy, G. M. Voelker, and S. Savage. A ﬁstful of
bitcoins: characterizing payments among men with no
names. In IMC, 2013.

[54] M. Peck. Ethereum developer explores the dark side of

Bitcoin-inspired technology. IEEE Spectrum, 19 May 2016.

[55] K. Poulsen. Cybercrime supersite ‘DarkMarket’ was FBI

sting, documents conﬁrm. Wired, 13 Oct. 2008.

[56] D. Ron and A. Shamir. How did Dread Pirate Roberts

acquire and protect his bitcoin wealth? In FC. 2014.

[57] S. V. Solms and D. Naccache. On blind signatures and

perfect crimes. Computers Security, 11(6):581–583, 1992.
[58] M. Stadler, J.-M. Piveteau, and J. Camenisch. Fair blind

signatures. In Eurocrypt, pages 209–219, 1995.

[59] G. Wood. Ethereum: A secure decentralized transaction

ledger. http://gavwood.com/paper.pdf, 2014.

[60] A. Young and M. Yung. Cryptovirology: Extortion-based

security threats and countermeasures. In S & P, 1996.

[61] F. Zhang, E. Cecchetti, K. Croman, A. Juels, and E. Shi.

Town Crier: An authenticated data feed for smart
contracts. In ACM CCS, 2016. (To appear.).

295