Delegatable Pseudorandom Functions and Applications

Aggelos Kiayias

Dept. of Informatics & Telecommunications

National and Kapodistrian U. of Athens, Greece

aggelos@di.uoa.gr
Nikos Triandopoulos

RSA Laboratories

Cambridge MA, USA

nikolaos.triandopoulos@rsa.com

Stavros Papadopoulos

Dept. of Computer Science & Engineering

HKUST, Hong Kong

stavrosp@cse.ust.hk
Thomas Zacharias

Dept. of Informatics & Telecommunications

National and Kapodistrian U. of Athens, Greece

thzacharias@di.uoa.gr

ABSTRACT
We put forth the problem of delegating the evaluation of a
pseudorandom function (PRF) to an untrusted proxy and
introduce a novel cryptographic primitive called delegatable
pseudorandom functions, or DPRFs for short: A DPRF en-
ables a proxy to evaluate a pseudorandom function on a
strict subset of its domain using a trapdoor derived from
the DPRF secret key. The trapdoor is constructed with re-
spect to a certain policy predicate that determines the subset
of input values on which the proxy is allowed to compute.
The main challenge in constructing DPRFs is to achieve
bandwidth eﬃciency (which mandates that the trapdoor is
smaller than the precomputed sequence of the PRF values
conforming to the predicate), while maintaining the pseu-
dorandomness of unknown values against an attacker that
adaptively controls the proxy. A DPRF may be optionally
equipped with an additional property we call policy privacy,
where any two delegation predicates remain indistinguish-
able in the view of a DPRF-querying proxy: achieving this
raises new design challenges as policy privacy and bandwidth
eﬃciency are seemingly conﬂicting goals.

For the important class of policy predicates described as
(1-dimensional) ranges, we devise two DPRF constructions
and rigorously prove their security. Built upon the well-
known tree-based GGM PRF family [17], our constructions
are generic and feature only logarithmic delegation size in
the number of values conforming to the policy predicate.
At only a constant-factor eﬃciency reduction, we show that
our second construction is also policy private. Finally, we
describe that their new security and eﬃciency properties
render our DPRF schemes particularly useful in numerous
security applications, including RFID, symmetric searchable
encryption, and broadcast encryption.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright 2013 ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516668.

669

Categories and Subject Descriptors
C.2.4 [Communication Networks]: Distributed Systems—
client/server, distributed applications; E.3 [Data Encryp-
tion]; G.3 [Probability and Statistics]: random number
generation; K.6.5 [Management of Computing and In-
formation Systems]: Security and Protection—authenti-
cation

General Terms
Algorithms, Security, Theory

Keywords
delegation of computation; pseudorandom functions; RFIDs;
searchable encryption; broadcast encryption; authentication

1.

INTRODUCTION

Due to its practical importance, the problem of securely
delegating computational tasks to untrusted third parties
comprises a particularly active research area. Generally
speaking, secure delegation involves the design of protocols
that allow the controlled authorization for an—otherwise
untrusted—party to compute a given function while achiev-
ing some target security property (e.g., the veriﬁability of
results or privacy of inputs/outputs) and also preserving
the eﬃciency of the protocols so that the delegation itself
remains meaningful. Beyond protocols for the delegation
of general functionalities (e.g., [18, 33]) a variety of speciﬁc
cryptographic primitives have been considered in this con-
text (see related work in Section 2).

Surprisingly enough, pseudorandom functions (PRFs), a
fundamental primitive for emulating perfect randomness via
keyed functions, thus, ﬁnding numerous applications in in-
formation security, have not been explicitly studied in the
context of delegation of computations (of PRF values). We,
hereby, initiate a study on this matter.

A new PRF concept. We introduce delegatable pseu-
dorandom functions, or DPRFs for short, a novel crypto-
graphic primitive which enables the delegation of the evalu-
ation of a PRF to an untrusted proxy according to a given
predicate that deﬁnes the inputs on which the proxy will
evaluate the PRF.
Speciﬁcally, let F be a PRF family, and P a set of pred-
icates, called the delegation policy, deﬁned over the domain
of F. A DPRF is a triplet (F, T, C) constructed with respect

to P, which provides the elementary functionality shown in
Figure 1: For any secret key k and a predicate P ∈ P,
the delegator computes a trapdoor τ via algorithm T , and
τ is transmitted to the proxy. The latter then runs al-
gorithm C on τ to derive exactly the set of PRF values
BP = {fk(x)|P (x)}, where fk ∈ F, i.e., the PRF value
on every input x satisfying predicate P , overall correctly
enabling the evaluation of PRF fk subject to predicate P
without explicit knowledge of secret key k, or even the input
values AP = {x|P (x)}.

Figure 1: The DPRF functionality.

What motivates the above scheme is bandwidth eﬃciency:
As long as the trapdoor τ is sublinear in the size |BP| of
delegated PRF values, the delegation is meaningful as the
delegator conserves resources (otherwise, the proxy could be
provided directly with all the PRF values in BP ).

At the same time, the DPRF must retain the security
properties of the underlying PRF, namely, (i) pseudoran-
domness for any value x conforming to the delegation pred-
icate P , i.e., P (x), and (ii) unpredictability for any noncon-
forming value x such that ¬P (x). In addition, a DPRF can
optionally satisfy a policy-privacy property which prevents
the proxy from inferring information about P or the dele-
gated (input) set AP from the trapdoor τ .

Our deﬁnitional framework. We introduce a formal def-
initional framework for the new primitive of DPRFs, care-
fully capturing all the above technical requirements. We ﬁrst
rigorously deﬁne the correctness and security requirements
that any DPRF should meet. Correctness captures the abil-
ity of the proxy to successfully evaluate the PRF on exactly
those inputs (set AP ) speciﬁed by predicate P . Security cap-
tures the requirement that the delegation capabilities of the
PRF do not compromise its core pseudorandomness prop-
erty. But this condition goes beyond the standard security
deﬁnition of PRFs, since the pseudorandomness attacker, in
addition to the PRF oracle, may now adaptively query also
a trapdoor oracle for delegation on predicates of its choice.
Equally important is also the policy-privacy property that
a DPRF may optionally satisfy, intuitively capturing the in-
ability of a malicious proxy to learn any (non-trivial) prop-
erty about the delegated set AP (that is not implied by
BP ). Our security notion postulates that for any two pred-
icates P, P (cid:48) the corresponding trapdoors are indistinguish-
able, provided that |AP| = |AP (cid:48)| and the adversary issues
no delegation queries that trivially separate BP and BP (cid:48) .
GGM-based realization for range predicates. We de-
vise two bandwidth-eﬃcient and provably secure DPRF con-
structions for the case where the delegation policy contains
predicates described by 1-dimensional ranges. Range-based
policies is an interesting use case, as many applications main-
tain an ordering over the PRF inputs, and delegation rights
are deﬁned with respect to ranges of such inputs.

670

Our ﬁrst DPRF scheme is called best range cover, or BRC
for short, and relies on the well-known GGM PRF fam-
ily [17]. This family deﬁnes a PRF based on the hierarchical
application of any length-doubling pseudorandom generator
(PRG) according to the structure induced by a tree, where
input values are uniquely mapped to root-to-leaf paths. By
exploiting the above characteristics, our BRC scheme fea-
tures logarithmic delegation size in the number |AP| of val-
ues conforming to the policy predicate, by having the trap-
door τ comprise a subset IP of internal (or partial ) PRF
values that optimally cover the target range BP of PRF val-
ues. We provide a formal security proof for the above scheme
which, interestingly, does not trivially follow from the GGM
security proof. The reason is that the adversary can now
employ delegation queries to learn any internal PRF value
in the tree, and not simply leaf PRF values as in the original
security game in [17]. We note that, although similar “range-
covering” GGM-based constructions appear in the literature,
e.g., in [30], no formal security analysis has been given.

However, our BRC scheme does not satisfy policy privacy,
as the structure of the PRF values in IP leaks information
about predicate P . This motivates our second construction,
called uniform range cover, or URC for short. This scheme
augments BRC in a way that renders all trapdoors corre-
sponding to ranges of the same size indistinguishable. This
is achieved by carefully having τ comprising a subset I(cid:48)
P of
PRF values that cover the target range BP of PRF values
less optimally: I(cid:48)
P contains PRF values that are descendants
of those values in IP at a tree height that depends solely on
|BP| (which by deﬁnition leaks to the adversary). More in-
terestingly, by adopting the above change, URC retains both
the asymptotic logarithmic bandwidth complexity of BRC
and its DPRF security, but it crucially achieves a policy-
privacy notion appropriately relaxed to our setting of range
predicates. Inherently, as we argue, no eﬃcient tree-based
DPRF scheme can satisfy policy privacy, so we have to resort
to a suﬃcient relaxation which we call union policy privacy.

Main applications. Finally, our DPRF schemes, equipped
with bandwidth eﬃciency, security and policy privacy (URC
only), lend themselves to new schemes that provide scalable
solutions to a wide range of information security and applied
cryptography settings that involve the controlled authoriza-
tion of PRF-based computations. Generally, DPRFs are
particularly useful in applications that rely on the evaluation
of (secret) key-based cryptographic primitives on speciﬁc in-
puts (according to an underlying policy): Using a DPRF
scheme then allows a cost-eﬃcient, yet secure and private,
key management for an untrusted proxy who is otherwise
capable in executing a particular computational task.

We outline several such applications in which DPRFs are
useful, including authentication and access control in RFIDs,
eﬃcient batch querying in searchable encryption, as well as
broadcast encryption. Due to the underlying GGM build-
ing component, our DPRFs are extremely lightweight, as
their practical implementation entails a few repeated appli-
cations of any eﬃcient candidate instantiation of a PRG that
is length doubling.

Summary of contributions. Our main contributions are:
• We initiate the study of policy-based delegation of the
task of evaluating a pseudorandom function (PRF) on
speciﬁc input values, and introduce the concept of del-
egatable PRFs (DPRFs).

Delegatork,PτCTBP={fk(x)|P(x)}Proxy• We develop a general and rigorous deﬁnitional frame-
work for the new DPRF primitive, capturing proper-
ties such as bandwidth eﬃciency, correctness, security
and policy privacy, and also oﬀering a relaxed union
policy privacy that is arguably necessary for tree-wise
DPRF constructions.

• We present a framework for building DPRF schemes
for the important case where the delegation policy is
governed by range predicates over inputs; our frame-
work augments the generic GGM construction frame-
work of [17] to provide two concrete DPRF schemes,
namely BRC and URC.

• We prove the security of our constructions in a modu-
lar way, thus also yielding the ﬁrst security analysis of
similar GGM-based key-delegation schemes, and the
union-policy privacy of URC.

• We describe several key applications of DPRFs in the
context of eﬃcient key-delegation protocols for authen-
tication, access control and encryption purposes.

Paper organization. Section 2 reviews related work. Sec-
tion 3 formulates the DPRF primitive, Section 4 presents
our two DPRF constructions for the case of range poli-
cies. Section 5 elaborates on the applicability of DPRFs.
Finally, Section 6 concludes our paper with directions for
future work. Selected proofs appear in the Appendix.

2. RELATED WORK
Secure delegation of computations. The notion of dele-
gation of cryptographic operations is already mature: Start-
ing from early work on proxy signatures [28] and proxy cryp-
tography [5], basic primitives such as signatures (e.g., [6, 28])
and encryption (e.g.,[2, 19, 22]) have been studied in the
context of an untrusted proxy who is authorized to operate
on signatures or ciphertexts. Recently, there has also been
an increased interest in veriﬁability and privacy of general
outsourced computations (e.g., [1, 9, 10, 18, 33]) or speciﬁc
crypto-related operations (e.g., [4, 15, 20]). To the best of
our knowledge, however, no prior work explicitly and for-
mally examines the delegation of PRFs.1
PRF extensions. Closer to our new DPRF primitive are
the known extensions of PRFs, namely the veriﬁable PRFs
(VPRFs) (e.g., [12, 27, 29]) and the oblivious PRFs (OPRFs)
(e.g., [16, 23]). A VPRF provides a PRF value along with
a non-interactive proof, which enables anyone to verify the
correctness of the PRF value. Although such proofs can be
useful in third-party settings, they are not related to the
delegation of the PRF evaluation without the secret key.
Similarly, an OPRF is a two-party protocol that securely im-
plements functionality (k, x) → (⊥, fk(x))—that is, a party
evaluates a PRF value without knowledge of the secret key.
Yet, although the party that provides the key can be viewed
to preserve resources, this setting does not match ours be-
cause there is no (i) input privacy (it is the second party who
provides the input x), and (ii) bandwidth eﬃciency when
applied over many values. Other related work includes al-
gebraic PRFs, employed in [4] to achieve optimal private
veriﬁcation of outsourced computation.
1Delegating PRF evaluation in a similar vein as we consider
here, was considered in [7, 8] after our work was submitted
for publication.

GGM framework. This refers to the seminal work by Gol-
dreich et al. [17], which shows how to generically construct
a PRF given black-box access to a length-doubling PRG.
The approach is based on a tree structure, over which hi-
erarchical invocations of the PRG produce the PRF values
at the leaves. Our constructions extend this framework in
non-trivial ways: First, we support delegation of PRF evalu-
ations; second, our security is proved in a much stronger ad-
versarial setting where the adversary gets to adaptively learn
also internal PRF values. The GGM framework, along with
its tree-based key-derivation structure, have been widely
used in the literature; also for special/limited delegation pur-
poses in the context of access control [30], broadcast encryp-
tion [31] and forward security [21]. Yet, to the best of our
knowledge, no such known key-derivation method has been
analyzed fully in a security model like ours, which allows
for adaptive PRF/delegation queries and addresses policy-
privacy issues.

3. DEFINITIONS
A pseudorandom function (PRF) family F is a family of
functions {fk : A → B | k ∈ K} so that K is eﬃciently
samplable and all F,K, A, B are indexed by a security pa-
rameter λ. The security property of a PRF is as follows:
For any probabilistic polynomial-time (PPT) algorithm A
running in time polynomial in λ it holds that

| Pr[Afk(·) = 1] − Pr[AR(·) = 1]| = negl(λ) ,

where negl denotes a negligible function and the probability
above is taken over the coins of A and the random variables
k and R which are uniformly distributed over the domains
K and (A → B) respectively.
Delegatable PRFs. The notion of delegation for a PRF
family F as above is deﬁned with respect to a delegation
policy P, i.e., P is a set of predicates deﬁned over A, also
indexed by λ, where each predicate P has an eﬃcient en-
coding. The set of elements in A that satisfy P is denoted
as AP = {x ∈ A | P (x)}.
Deﬁnition 1 (Delegatable PRF) A triple (F, T, C) is a
delegatable PRF, or DPRF scheme, for family F = {fk :
A → B | k ∈ K} with respect to policy P of predicates
over A, provided it satisﬁes two properties, correctness and
security, that are deﬁned individually below.

Correctness. We deﬁne T to be a PPT algorithm such
that, given a description of P ∈ P and a key k ∈ K, it out-
puts a “trapdoor” τ . The latter is intended to be used along
with the deterministic PPT algorithm C for the PRF com-
putation over every element of A that satisﬁes the predicate
P . For ﬁxed P, k, algorithm C can be viewed as a function

C : StP,k −→ B × StP,k ,

where StP,k is a set of states, and for any s ∈ StP,k the
output C(s) is a pair that consists of a PRF value and a
(new) state. We denote C(s) = (cid:104)CL(s), CR(s)(cid:105) and deﬁne
recursively the set of reachable states from a subset S of
StP,k as

R(S) (cid:44) S ∪ R(CR(S)) .

The elements of the DPRF that are produced given an ini-
tial state s will be deﬁned using the complete set of reachable

671

states given s. For a singleton S = {s}, we will write R(s)
instead of R({s}), and we will denote by R(s) the closure
of s under R, i.e., the ﬁxpoint of the recursive equation for
R that also contains s.

Deﬁnition 2 (Correctness) The DPRF scheme (F, T, C)
is correct for a policy P if for every P ∈ P:

1. {τ | τ ← T (P, k)} ∪ {⊥} ⊆ StP,k, for any k ∈ K

(initialization).

2. CR(⊥) = ⊥ (termination condition).
3. There is a polynomial q such that for every k ∈ K and

τ ← T (P, k):
(i) ⊥ ∈ R(τ ) (termination guarantee).
(ii) |R(τ )| ≤ q(λ) (feasibility).
(iii) {fk(x) | P (x)} = BP = {CL(s) | s ∈ R(τ )}

(completeness).

According to the above conditions, all possible trapdoors
corresponding to a certain policy predicate P are valid initial
inputs for C. Moreover, starting from an arbitrary trapdoor
for P as initial input, the proxy can execute a number of
steps of algorithm C, during which it successively computes
the DPRF image of every argument x that satisﬁes P , and
eventually terminate when it reaches the ﬁnal state ⊥, where
no further useful information can be derived.

We note that condition 3.(ii) implies the restriction that
the size of every policy predicate is polynomial. This stems
from the fact that we consider the setting where the proxy
wishes to eventually compute all the delegated PRF val-
ues.
If this is not necessary (or desirable) for the DPRF
application, the condition can be relaxed to any size of AP
(including super-polynomial sizes).
In this case, the com-
pleteness condition (item 3.(iii) above) would be infeasible
to meet, since the proxy cannot hope to be able to compute
all the delegated PRF values. There are a number of ways
to capture this by suitably modifying the way C works; for
instance: (i) C may sample the uniform distribution over
BP , (ii) C may be given the value x as input, and return
fk(x) if x ∈ AP and ⊥ otherwise, (iii) C may be given the
lexicographic rank of an element x within AP and return
fk(x) or ⊥ otherwise.
Security. We consider the case where the proxy is mali-
cious, and accordingly model DPRF security as an oracle
indistinguishability game GA
SEC carried out between an at-
tacker A and a challenger C indexed by parameter λ. The
game proceeds as shown in Figure 2. Note that due to the
delegation capabilities of DPRFs, the security game GA
SEC
is more elaborate than the security game of a plain PRF:
Indeed, in addition to issuing standard PRF queries, the
pseudorandomness attacker may now adaptively query also
a trapdoor oracle for delegation on predicates of its choice.

Deﬁnition 3 (Security) A DPRF scheme (F, T, C) is se-
cure for a policy P if for any PPT A, it holds that

Pr[GA

SEC(1λ) = 1] ≤ 1
2

+ negl(λ) .

DPRF Security Game GA

SEC(1λ)

1. The challenger C randomly selects k from K.
2. The adversary A is allowed to interact with C and ask
two types of queries:
(a) PRF queries for a value x ∈ A; to those queries C
responds with fk(x) and adds the value x to a set Lque.
(b) Delegation queries for a policy predicate P ∈ P; to
those queries C responds with τ ← T (P, k) and adds P
to a set Lpol.

3. The adversary A submits a challenge query x∗ to which
the challenger C responds as follows: It ﬂips a coin b
and if b = 1 it responds with y∗ = fk(x∗), otherwise, it
responds with a random value y∗ from B.

4. The adversary A continues as in step 2.
5. The adversary A terminates by returning a single bit ˜b.
Subsequently the game returns a bit which is 1 if and
only if the following holds true:

(b = ˜b) ∧ (x∗ (cid:54)∈ Lque) ∧ ∀P ∈ Lpol : ¬P (x∗) .

Figure 2: The DPRF security game.

We make the following observations about the deﬁnition.
First, it is easy to see that a delegatable PRF is indeed
a PRF. Speciﬁcally, any PRF attacker A against fk can
be turned into an attacker A(cid:48) that wins the DPRF game
GA
SEC(1λ). We provide only a simple sketch of this which fol-
lows by a standard “walking” argument (the reader familiar
with such arguments may skip to the next paragraph). Fix
some PPT A and let α be its non-negligible distinguishing
advantage. There will be some polynomial q so that, for any
λ, q(λ) is an upper bound on the number of queries submit-
ted to A’s oracle by A. Given such q and for ﬁxed λ, we de-
ﬁne the hybrid oracle (fk/R)j for any j ∈ {0, . . . , q(λ)} that
operates as follows: (fk/R)j responds as fk(·) in the ﬁrst j
queries and as R(·) in the last q(λ)− j queries. Taking such
sequence of oracles into account, by triangular inequality, it
follows that there exists some value j ∈ {0, . . . , q(λ)− 1} for
which the distinguishing probability will be at least α/q(λ)
for A to distinguish between two successive hybrid oracles
(fk/R)j and (fk/R)j+1 when R is a random function. This
follows from the fact that A distinguishes the “extreme” hy-
brids R(·) and fk(·) with probability α. We now construct
A(cid:48) as follows out of A: A(cid:48) plays the DPRF game and queries
the DPRF function for the ﬁrst j queries of A. Then it sub-
mits the (j + 1)-th query of A as the challenge. Finally, it
completes the simulation of A by answering any remaining
queries of A with random values drawn from B (w.l.o.g. the
queries to the oracle are all distinct), and outputs what A
does. It is easy to see that the distinguishing advantage of
A(cid:48) is α/2q(λ), i.e., non-negligible in λ.
Second, we observe that there is a trivial construction of
a delegatable PRF from any PRF: Consider an ordering ≤
over A, e.g., the lexicographical order. For ﬁxed P, k set
T (P, k) = (cid:104)fk(x1), . . . , fk(x|AP |)(cid:105) = τ , where xi is the i-th
element of AP according to ≤. Given τ , the set of states can
be StP,k = {τ, (2, τ ), . . . , (|AP|, τ ),⊥}, and the reconstruc-
tion function C can be simply deﬁned to be a table-lookup
in τ . It is straightforward to show that (F, T, C) is a DPRF
as long as the underlying family F is a PRF, since any del-
egation query can be interpreted as a series of polynomially
many PRF queries.

672

The existence of a trivial DPRF construction with re-
spect to arbitrary policies from any given PRF motivates
our primitive: Interesting DPRF constructions will be those
that are bandwidth eﬃcient, i.e., they provide trapdoors with
size that is sublinear in the number of elements that satisfy
the corresponding policy predicate.
Policy privacy. We next introduce an additional privacy
property that a DPRF scheme may optionally satisfy. This
property goes beyond the standard (D)PRF security and is
relevant in the context of PRF delegation for protecting the
associated policy predicates over which the delegation is de-
ﬁned. We accordingly model this new privacy condition as a
predicate indistinguishability game GA
PP carried out between
an attacker A and a challenger C indexed by a security pa-
rameter λ. The game proceeds as shown in Figure 3.

DPRF Policy Privacy Game GA

PP(1λ)

1. The challenger C randomly selects k from K.
2. The adversary A is allowed to interact with C and ask
delegation queries on policy predicates P ∈ P; to those
queries C responds with τ ← T (P, k) and adds P to a
set Lpol.

3. The adversary A submits two policy predicates P0, P1
to C. The challenger ﬂips a bit b and computes τ∗ ←
T (Pb, k). It returns τ∗ to the adversary.
4. The adversary A continues as in step 2.
5. The adversary A terminates by returning a single bit ˜b.
Subsequently the game returns a bit that is 1 if and only
if the following holds true:

(b = ˜b) ∧ (|AP0| = |AP1|) ∧ (AP0 (cid:54)= AP1 )∧

AP ) ∩ AP0

AP ) ∩ AP1

∧∀S ⊆ Lpol :˛˛(

\

P∈S

˛˛ =˛˛(

\

P∈S

˛˛ .

Figure 3: The DPRF policy privacy game.

Deﬁnition 4 (Policy privacy) A DPRF scheme (F, T, C)
is policy private for a policy P if for any PPT A, it holds
that

Pr[GA

PP(1λ) = 1] ≤ 1
2

+ negl(λ) .

The above deﬁnition suggests that the trapdoor that cor-
responds to a certain policy predicate hides the predicate
itself (i) at least among all (distinct) policy predicates that
enable evaluations of the PRF on the same number of ele-
ments in its domain, and (ii) when the adversary does not
make queries whose responses leak unequal parts of the PRF
image of the two challenge predicates. Observe that all the
(cid:54)= |AP1|, then
restrictions stated are necessary:
the adversary can distinguish P0 from P1 by counting the
number |{CL(s) | s ∈ R(τ∗)}| of new PRF values it com-
putes starting from state τ∗ and ending in ⊥. In addition,
if the number of elements that satisfy simultaneously any
set S of delegation queries and P0 is diﬀerent than the num-
ber of elements that satisfy S and P1, then the adversary
can distinguish the two predicates by counting the size of

{CL(s) | s ∈ R(τ∗)} ∩ (T

If |AP0|

P∈S BP ).

We note that while the above formulation can capture a
wide set of attacks against privacy, it can be strengthened

further by allowing multiple challenge pairs of policy predi-
cates. In this case, the policy-privacy game allows a multiple
number of adversarial actions submitting pairs of policies
(as in step 3 of the game) to be interleaved with delegation
queries. The challenger always responds based on the same
coin ﬂip b. Interestingly, this multiple-challenge policy pri-
vacy formulation can be shown to be strictly stronger than
the one corresponding to Deﬁnition 4.

On eﬃciently achieving policy privacy. We next argue
that even though desirable, the above formulations of pri-
vacy conﬂict with our eﬃciency considerations (sublinear-
size trapdoors) for a wide class of schemes. This will mo-
tivate relaxing the policy-privacy property as we will see in
the end of the section; the reader unwilling to go over the
details of the lower bound type of argument we sketch below
may skip directly to the policy-privacy relaxation in the end
of the section.
Assume that the policy predicates are ranges [a, b] that lie
in an interval [0, 2n − 1], where n is a positive integer. Then,
no eﬃcient and policy-private DPRF scheme exists, if the
trapdoor-generation algorithm T is deterministic, and the
delegated-computation algorithm C is tree-wise. This means
that for each range, the trapdoor consists of a data structure
of initial keys and meta-data that enable (by deﬁnition in
a deterministic way) the calculation of the ﬁnal set of PRF
values through a tree-like derivation process, where the ﬁnal
underlying tree structure of this process depends only on the
meta-data (and not on any of the initial keys). Indeed, if
policy privacy is satisﬁed, then for every 0 < j ≤ b − a, the
delegated computation of the PRF values in the intersection
[a + j, b] must be indistinguishable for [a, b] and [a + j, b + j].
Otherwise, an adversary can make queries for all the PRF
values in [a + j, b] and, since it knows the way that each
unique trapdoor of [a, b] and [a + j, b + j] computes the PRF
values of the range [a + j, b], can thus distinguish the two
range predicates by making the corresponding equality tests.
By induction, this implies that for any j ∈ {0, . . . , b − a}, in
the trapdoor of [a, b] there exist distinct keys d0, . . . , dj that
allow the computation of fk(a), . . . , fk(a + j), respectively.
Thus, the size of the trapdoor of the range [a, b] consists of
at least r = b − a + 1 = #[a, b] keys which means that the
DPRF cannot be eﬃcient (i.e., enabling the delegation of
the range with a trapdoor size less than the set of values
being delegated).

The above argument suggests that, if policy privacy is
to be attained, then we need trapdoors at least as long as
the values we delegate. Note that the trivial construction
for ranges mentioned above, i.e., when the trapdoor of [a, b]
is the sequence (cid:104)fk(a), fk(a + 1), . . . , fk(b)(cid:105), does not sat-
isfy policy privacy. For instance, when delegating [1, 3] and
[3, 5] the attacker can easily distinguish them by obtaining
the value fk(3) (it belongs in the intersection hence the at-
tacker is allowed to have it) and checking its location within
the trapdoor vector. To achieve policy privacy for the trivial
construction one needs to additionally permute the PRF val-
ues in the trapdoor in some fashion: It can be easily shown
that a lexicographic ordering of these values suﬃces.

In our upcoming constructions, we obtain eﬃcient DPRFs
that use tree-wise derivations where the PRF values com-
puted are at the leaves of a full binary tree, and the policy
predicates are ranges of the form [a, b], covered by one or
more proper subtrees. In this case, even allowing a proba-
bilistic trapdoor generator does not suﬃce to provide policy

673

privacy for a very eﬃcient scheme. To see this, let [a, b]
be a range of size r and τ be a trapdoor for [a, b] of size
g(r) = O(logc r), i.e., g(r) is polylogarithmic in r, hence
also in λ. By the Pigeonhole principle, there exists a delega-
tion key y in τ that computes all the values corresponding
to a set T ⊆ [a, b] of size at least r/g(r), that is, a subtree T
of depth at least d ≥ log(r) − log(g(r)) = ω(1). The latter
implies that there exists a value x ∈ [a, b] with an all-one
suﬃx of length d that is computed by this key y. (Here, a
tree node contributes a 0 or 1 to root-to-leaves path labelings
if it is a left or right child respectively). Since there are no
more than g(r) such possible values x ∈ [a, b], an adversary
has signiﬁcant probability greater than 1/g(r) of guessing x.
Then it can make a query x, receive fk(x) and submit as the
challenge the two policies P0 = [a, b] and P1 = [x, b+(x−a)].
After it receives the challenge trapdoor τ∗, it can locate all
keys that correspond to subtrees of size ≥ d and check if
there is a minimum leaf value (an all-zero path) in some of
these subtrees that equals to fk(x). Then, the adversary can
distinguish eﬀectively P0, P1 since x cannot be covered by
any subtree of size d in a trapdoor for [x, b+(x−a)] (it must
be covered by a leaf while d > 1). This argument can be ex-
tended to more general tree-like delegation schemes and for
the case g(r) = o(r), but we omit further details as it already
demonstrates that eﬃcient tree-like constructions require a
somewhat more relaxed deﬁnition of policy privacy—which
we introduce next.

secret random seed (of bit length λ). The GGM pseudoran-
dom function family [17] is deﬁned as F = {fk : {0, 1}n →
{0, 1}λ}k∈{0,1}λ , such that

fk(xn−1 ··· x0) = Gx0 (··· (Gxn−1 (k))) ,

where n is polynomial in λ and xn−1 ··· x0 is the input bit-
string of size n.

The GGM construction deﬁnes a binary tree over the PRF
domain. We illustrate this using Figure 4, which depicts a
binary tree with 5 levels. The leaves are labeled with a
decimal number from 0 to 15, sorted in ascending order.
Every edge is labeled with 0 (resp. 1) if it connects a left
(resp. right) child. We label every internal node with the
binary string determined by the labels of the edges along
the path from the root to this node. Suppose that the
PRF domain is {0, 1}4. Then, the PRF value of 0010 is
fk(0010) = G0(G1(G0(G0(k)))). Observe that the compo-
sition of G is performed according to the edge labels in the
path from the root to leaf 2 = (0010)2, selecting the ﬁrst
(second) half of the output of G when the label of the vis-
ited edge is 0 (resp. 1) and using this half as the seed for
the next application of G. Based on the above, the n-long
binary representation of the leaf labels constitute the PRF
domain, and every leaf is associated with the PRF value of
its label—these values constitute the PRF range.

Union policy privacy. We ﬁnally introduce the notion
of union policy privacy, where the adversary is restricted
from making queries in the union of the challenge policy
predicates (but is allowed to query at arbitrary locations
outside the targeted policy set). This privacy condition is
a strict relaxation of the one corresponding to Deﬁnition 4,
and we model it by a game GA
UPP(1λ) that proceeds identi-
cally as GA
PP(1λ), but terminates with 1 provided that the
following (weaker set of) conditions are all met: (i) b = ˜b,
(ii) |AP0| = |AP1|, (iii) AP0 (cid:54)= AP1 and (iv) ∀P ∈ Lpol :
AP ∩ (AP0 ∪ AP1 ) = ∅. To see the connection with Deﬁni-
tion 4 observe that the latter condition is equivalent to

AP ) ∩ AP0

AP ) ∩ AP1

∀S ⊆ Lpol :˛˛(

\

P∈S

˛˛ =˛˛(

\

P∈S

˛˛ = 0 .

Note that for policies P consisting of disjoint predicates, the
games GA

UPP(1λ) are equivalent.

PP(1λ) and GA

4. CONSTRUCTIONS

In this section we present DPRF schemes for range policy
predicates. In Section 4.1 we describe a ﬁrst construction,
called best range cover (BRC), which satisﬁes the correct-
ness and security properties of DPRFs, achieving trapdoors
of logarithmic size in the range size. However, BRC lacks
the policy-privacy property. In Section 4.2 we build upon
BRC to obtain a DPRF scheme, called uniform range cover
(URC), that is additionally (union) policy private, while re-
taining the trapdoor size complexity of BRC. In Section 4.3
we include the security proofs of the two schemes. In Section
4.4 we prove the union policy-privacy property of URC.
4.1 The BRC Construction

Let G : {0, 1}λ → {0, 1}2λ be a pseudorandom gener-
ator and G0(k), G1(k) be the ﬁrst and second half of the
string G(k), where the speciﬁcation of G is public and k is a

674

Figure 4: A GGM tree example.

Note that we can also associate every internal node of
the GGM tree with a partial PRF value, by performing
the composition of G as determined by the path from the
root to that node. For example, node 00 in Figure 4 is
associated with partial PRF G0(G0(k)). Henceforth, for
simplicity, we denote by fk(xn−1 ··· xj) the partial PRF
Gxj (··· (Gxn−1 (k))). Observe that if a party has the partial
PRF fk(xn−1 ··· xj), then it can compute the PRF values of
all 2j inputs that have preﬁx xn−1 ··· xj, simply by following
a DFS traversal in the subtree rooted at (the node labelled
by) xn−1 ··· xj and composing with seed fk(xn−1 ··· xj). In
our running example, using the partial PRF value at node
00, we can derive the PRF values of the inputs in (deci-
mal) range [0, 3] as fk(0000) = G0(G0(fk(00))), fk(0001) =
G1(G0(fk(00))), fk(0010) = G0(G1(fk(00))), and fk(0011)
= G1(G1(fk(00))).

For any range [a, b] of leaf labels, there is a (non-unique)
set of subtrees in the GGM tree that cover exactly the cor-
responding leaves. For instance, [2, 7] is covered by the sub-
trees rooted at nodes 001 and 01 (colored in grey). Ac-
cording to our discussion above, a party having the partial
PRF values of these subtree roots and the subtree depths,
it can derive all the PRF values of the leaves with labels in

1234567891011121314150(0010)2000100fk(00)=G0(G0(k))fk(0010)=G0(G1(G0(G0(k))))001101[2,7](0111)211[a, b]. In our example, having (fk(001), 1) and (fk(01), 2), it
can derive the PRF values of the leaves with labels in [2, 7].
Our ﬁrst construction is based on the above observations.
In particular, given a range policy predicate [a, b] ∈ P with
size r = b − a + 1 = |AP|,2 it ﬁnds the minimum number
of subtrees that cover [a, b]. As such, we call this scheme as
best range cover (BRC). A formal description follows.
The BRC DPRF construction is a triplet (F, T, C), where
F is the GGM PRF family described above with tree depth n.
The delegation policy is P = {[a, b] | 0 ≤ a ≤ b ≤ a + λγ <
2n}, where γ is a constant integer. Note that when a = b
the trapdoor sent to the proxy is (essentially) simply the
PRF value fk(a). In the rest of the section, we focus on the
non-trivial case where the range is not a singleton. When
a < b, the trapdoor generation algorithm T of BRC, hence-
forth denoted by TBRC, is given below.

if (∀i ≤ t : ai = 0) then

if (∀i ≤ t : bi = 1) then

else

Append (fk(an−1 · · · ai+11), i) to τ

return (fk(an−1 · · · at+1), t + 1)
Append (fk(an−1 · · · at), t) to τ

The Trapdoor Generation Algorithm TBRC
Input: a, b : 0 ≤ a < b ≤ a + λγ ≤ 2n − 1 and k ∈ {0, 1}λ
Output: Trapdoor τ for computing {fk(x)|x ∈ [a, b]}
1. τ ← (cid:104)(cid:105)
2. t ← max{i | ai (cid:54)= bi}
3.
4.
5.
6.
7.
8. else
9.
10.
11.
12.
13.
14. if (∀i ≤ t : bi = 1) then
15.
16. else
17.
18.
19.
20.
21.
22. return τ

Append (fk(an−1 · · · aµ), µ) to τ
Append (fk(bν−1 · · · bt), t) to τ
ν ← min{i | i < t ∧ bi = 0}
for i = t − 1 to ν + 1
if bi = 1 then

µ ← min{i | i < t ∧ ai = 1}
for i = t − 1 to µ + 1
if ai = 0 then

Append (fk(bn−1 · · · bi+10), i) to τ

Append (fk(bn−1 · · · bν ), ν) to τ

This algorithm takes as input a secret key k and a range
predicate [a, b] ∈ P. It outputs a delegation trapdoor τ that
enables the computation of fk(x) for every x whose decimal
representation is in [a, b] (i.e., the PRF values of the leaves in
the GGM tree with labels in [a, b]). Initially, TBRC ﬁnds the
ﬁrst bit in which a and b diﬀer (Line 2), which determines
the common path from the root to leaves a and b. Suppose
that this common path ends at node u. If [a, b] is the set
of labels that belong to the subtree with root u, then TBRC
outputs a single pair consisting of the partial PRF value that
corresponds to u along with the depth of the subtree (Lines
3-5). Otherwise, TBRC traverses the left and right subtree of
u separately (Lines 7-13 and 14-21, respectively). We will
describe only the left traversal (the right one is performed
symmetrically). TBRC considers the path pv→a starting from
the left child of u, denoted by v, to a. It checks whether a is
the leftmost leaf of v’s subtree. In this case the PRF value
of v is included in τ along with the depth of v’s subtree,
and the traversal terminates (Lines 3,7). Otherwise, if pv→a
proceeds to the left child of v, it includes in the trapdoor the
PRF value of the right child of v together with the depth of
2In the sequel, we use symbols r and |AP| interchangeably.

675

the subtree rooted at that child. In any case, it continues
the traversal in the same fashion with the next node of pv→a
(Lines 8-13).
In the example of Figure 4, for input [2, 7], algorithm TBRC
outputs trapdoor τ = (cid:104)(fk(001), 1), (fk(01), 2)(cid:105). By con-
struction, it is easy to see that TBRC covers the input range
with maximal subtrees, thus using a minimum number of
them.

We next describe the reconstruction algorithm C of BRC.
For ﬁxed P = [a, b] of size r and key k, we deﬁne the
set of states as StP,k = {τ, (1, τ ), . . . , (r − 1, τ ),⊥}, where
τ = (cid:104)(y1, d1), . . . , (ym, dm)(cid:105) is the trapdoor produced by
algorithm TBRC. Note that, every yi, i = 1, . . . , m corre-
sponds to a partial PRF value associated with the root of
a GGM subtree. Therefore, there is a natural ordering of
PRF values for a given τ , starting from the leftmost leaf
of the subtree of y1 to the rightmost leaf of the subtree
of ym. This order is not necessarily the same as the order
of the leaves in the GGM tree.3 Starting from the PRF
value of the leftmost leaf of the y1 subtree, C computes in
every next step the PRF value of the next leaf in the order-
ing discussed above. Speciﬁcally, C starts with state τ and
computes C(τ ) = (cid:104)G0(··· (G0(y1))), (1, τ )(cid:105), where the G0
composition is performed d1 times. Then, generally, given
the pair (yt, dt) in τ , where t is such that Pt−1
state (i, τ ), C locates the unique subtree that covers the
Pt
(i + 1)-th leaf x in the ordering of τ . In particular, it ﬁnds
ρ=1 2dρ ≤ i <
sentation of i −Pt−1
ρ=1 2dρ . Then, the suﬃx xdt−1 ··· x0 is the binary repre-
ρ=1 2dρ ∈ [0, 2dt − 1]. Given this suﬃx,
C can compute fk(x) = Gx0 (··· (Gxdt−1 (yt))) and output
C((i, τ )) = (cid:104)Gx0 (··· (Gxdt−1 (yt))), (i + 1, τ )(cid:105). For the case
where dt = 0, C simply returns fk(x) = yt. Finally, for in-
put state (r − 1, τ ), C outputs (cid:104)G1(··· (G1(ym))),⊥(cid:105), where
the G1 composition is performed dm times.
(cid:104)(fk(01), 2), (fk(001), 1), (fk(10), 2), (fk(110), 1), (fk(1110), 0)(cid:105).
Algorithm C computes the PRF values for leaves 4, 5, 6, 7,
2, 3, 8, 9, 10, 11, 12, 13, 14 in this order, i.e.,
C(τ ) = (cid:104)G0(G0(fk(01))), (1, τ )(cid:105) = (cid:104)fk(0100), (1, τ )(cid:105) →
C((1, τ )) = (cid:104)G1(G0(fk(01))), (2, τ )(cid:105) = (cid:104)fk(0101), (2, τ )(cid:105) →
...
C((12, τ )) = (cid:104)fk(1110),⊥(cid:105) .

In the example of Figure 4, the trapdoor for range [2, 14] is

As described above, during the execution of C some par-
tial PRF values in the GGM tree are computed multiple
times; e.g., partial PRF value fk(011) is computed twice to
derive fk(0110) and fk(0111). However, this can be easily
avoided by employing a cache of size O(r): Every PRF value
is computed once, stored in the cache, and retrieved in a next
step if necessary. In this manner, the computational cost of
C can become O(r), since we compute one PRF value for
every node in the subtrees covering the range (of size r).

The correctness of BRC is stated in the following theorem.

Theorem 1 The BRC DPRF construction (F, T, C) w.r.t.
policy P = {[a, b] | 0 ≤ a ≤ b ≤ a + λγ ≤ 2n − 1}, where
n is the depth of the underlying GGM tree, γ is a constant
integer, and λγ is the maximum range size, is correct.

3This by-design feature of algorithm C comes at no eﬃciency
cost in BRC, but it is crucial for policy privacy in URC.

Proof. We show that all conditions of Deﬁnition 2 hold.
Condition 1 can be easily seen to hold by the deﬁnition of the
set of states StP,k. Moreover, since R(τ ) = StP,k, conditions
2, 3.(i) and 3.(ii) are directly satisﬁed by the construction of
algorithm C, and because the size of range r (which deter-
mines the number of values conforming to the range policy
predicate) is upper bounded by λγ which is a polynomial.

Therefore, it remains to show that condition 3.(iii) holds.
Note that, by construction, algorithm C computes exactly
the PRF values of the leaves covered by the subtrees cor-
responding to the partial PRF values included in τ by al-
gorithm TBRC. Hence, it suﬃces to show that the labels of
these leaves comprise exactly the set of values in [a, b].
Let t = max{i | ai (cid:54)= bi} and V1, V2 be the sets of argu-
ments of the PRF values that are computed in Lines 3-13
and 14-21 of TBRC, respectively. If V2 = ∅, then the input
range is exactly covered by a single subtree (checks in lines
3 and 4 are true) and V1 = [a, b]. Otherwise, it holds that

V1 = {x ∈ [0, 2n − 1] | xn−1 ··· xt = an−1 ··· at∧

∧ (∃i < t : [xi = 1 ∧ ai = 0] ∨ x = a)}

= {x ∈ [0, 2n − 1] | a ≤ x ≤ an−1 ··· at1··· 1}
= [a, an−1 ··· at1··· 1] .

Similarly, we get that V2 = [bn−1 ··· bt0··· 0, b]. Observe
that, by the deﬁnition of t, at = 0 and bt = 1. Thus, it holds
that an−1 ··· at1··· 1 + 1 = bn−1 ··· bt0··· 0. This means
that [a, b] = V1 ∪ V2, which concludes our proof.

We next discuss the trapdoor size complexity in BRC.
Let V1, V2 be deﬁned as in the proof of Theorem 1. Then,
|V1| + |V2| = r. We will analyze |V1| (the analysis for V2 is
similar). Observe that, in every step in Lines 3-13, the al-
gorithm covers more than (cid:98)|V1|/2(cid:99) values of V1 with a max-
imal subtree of the sub-range deﬁned by V1.
Iteratively,
this means that the algorithm needs no more than log(r)
maximal subtrees to cover the entire sub-range of V1. Con-
sequently, the total number of elements in τ is O(log(r)).

We have explained the correctness of BRC and its eﬃ-
cient trapdoor size. We will also prove its security in Sec-
tion 4.3. Nevertheless, BRC does not satisfy policy privacy,
even for non-intersecting policy predicates. We illustrate
this with an example using the tree of Figure 4. Consider
the ranges [2, 7] and [9, 14], both with size 6, which gen-
erate trapdoors (cid:104)((fk(001), 1), (fk(01), 2)(cid:105) and (cid:104)(fk(101), 1),
(fk(1001), 0), (fk(110), 1), (fk(1110), 0)(cid:105), respectively; these
are trivially distinguishable due to their diﬀerent sizes. This
motivates our second DPRF construction presented next.
4.2 The URC Construction

Consider again the ranges [2, 7] and [9, 14] in the tree of
Figure 4, for which BRC produces two distinguishable trap-
doors, namely trapdoor (cid:104)(fk(001), 1), (fk(01), 2)(cid:105) and trap-
door (cid:104)(fk(101), 1), (fk(1001), 0), (fk(110), 1), (fk(1110), 0)(cid:105).
Now, instead of computing the trapdoor of [2, 7] as above,
assume that we generate an alternative trapdoor equal to
(cid:104)(fk(010), 1), (fk(0010), 0), (fk(011), 1), (fk(0011), 0)(cid:105). Ob-
serve that this trapdoor appears to be indistinguishable to
that of [9, 14]:
Indeed, the two trapdoors have the same
number of elements, the ﬁrst parts of their elements are all
partial PRFs, whereas their second parts (i.e., the depths)
are pairwise equal. This suggests that, we could achieve
policy privacy, if we could devise a trapdoor algorithm T
such that, for any range predicate of a ﬁxed size r it always

generates a trapdoor with a ﬁxed number of elements and a
ﬁxed sequence of depths. More simply stated, the algorithm
should produce uniform trapdoors for ranges of the same
size. The challenge is to design such an algorithm retain-
ing the logarithmic trapdoor size of BRC. Next, we present
our second DPRF construction, called uniform range cover
(URC), which enjoys the eﬃciency of BRC and the union
policy-privacy property.

URC builds upon BRC. In particular, it starts by produc-
ing a trapdoor as in BRC, and then modiﬁes it to generate
a uniform trapdoor for the given range r. Before embarking
on its detailed description, we must investigate some inter-
esting properties of the trapdoors of BRC, and provide some
important deﬁnitions. Recall that a trapdoor in BRC is a
sequence of elements, where the ﬁrst part is a (full or partial)
PRF value, and the second is a depth value.

Deﬁnition 5 For an integer r > 1, a pair of non-negative
integral sequences D = ((k1, . . . , kc), (l1, . . . , ld)) is called a
decomposition of r, if the following hold:

(i) Pc

i=1 2ki +Pd

j=1 2lj = r, and
(ii) k1 > ··· > kc and l1 > ··· > ld.

A decomposition of r D = ((k1, . . . , kc), (l1, . . . , ld)) is a
worst-case decomposition (w.c.d.) of r if it is of maximum
size, i.e., for every decomposition of r D(cid:48) = ((k(cid:48)
1, . . . , k(cid:48)
c(cid:48) ),
d(cid:48) )), we have that c(cid:48) + d(cid:48) ≤ c + d. We deﬁne MD (cid:44)
(l(cid:48)
1, . . . , l(cid:48)
max{k1, l1} as the maximum integer that appears in D.

By the description of algorithm TBRC in BRC for ﬁxed
range size r, the depths in the trapdoor can be separated
into two sequences that form a decomposition of r, unless the
input range is exactly covered by a single subtree. Each se-
quence corresponds to a set of full binary subtrees of decreas-
ing size that cover leaves in the range predicate. The usage
of the worst case decomposition will become clear soon.

The next lemma shows that the maximum integer that
appears in any decomposition of r (hence, the maximum
depth of a subtree in a cover of a range of size r), can only
take on one of two consecutive values that depend only on r.

Lemma 1 Let D = ((k1, . . . , kc), (l1, . . . , ld)) be a decompo-
sition of r. Deﬁne B(r) (cid:44) (cid:100)log(r + 2)(cid:101) − 2. Then MD ∈
{B(r), B(r) + 1}. In addition, if MD = B(r) + 1 then the
second largest value is less than MD.

Proof. By the two properties of D, we have that

≤ 2MD +2 − 2 ⇔ 2MD +2 ≥ r + 2 ⇒ MD ≥ B(r) .

Since 2B(r)+2 ≥ 2log(r+2) > r ≥ 2k1 + 2l1 , we have that the
maximum value MD ∈ {k1, l1} is less than B(r) + 2 and
k1, l1 cannot be both equal to B(r) + 1.

By Lemma 1, the trapdoor that is generated by BRC for a
range P = [a, b] of size |AP| = r, even if this trapdoor corre-
sponds to a w.c.d. of r, consists of at most |{0, . . . , B(r)}| +
|{0, . . . , B(r) + 1}| = 2B(r) + 3 pairs. Hence, the trap-
door size is O(log(r)), which complies with the bound we

676

cX

i=1

dX

j=1

r =

2ki +

2lj ≤ 2k1+1 + 2l1+1 − 2 ≤

described in Section 4.1. Moreover, since |AP| ≤ λγ, every
trapdoor has no more than 2(cid:100)log(λγ + 2)(cid:101) − 1 pairs.

Observe that two trapdoors with depths that form the
same decomposition appear indistinguishable. Moreover, we
have proven that a trapdoor following a w.c.d. retains the
logarithmic size in r. Therefore, our goal for the trapdoor
algorithm T in URC, hereafter referred to as TURC, is to
construct a converter that takes as input a BRC trapdoor,
and produces an alternative trapdoor that complies with a
ﬁxed worst-case decomposition. Before proceeding to the
details of TURC, we must prove the following vital theorem.

Theorem 2 Let D = ((k1, . . . , kc), (l1, . . . , ld)) be a decom-
position of r. Then all the elements in {0, . . . , MD} appear
in D iﬀ D is a w.c.d. of r.

For the converse, let D(cid:48) = ((k(cid:48)

Proof. Assume that the implication does not hold and
let x be the maximum integer in {0, . . . , MD} that does not
appear in D. Since x < MD, x+1 is in {0, . . . , MD}. Assume
w.l.o.g. that lj = x+1. If x > k1, then the decomposition of
r, ((x, k1, . . . , kc), (l1, . . . , lj−1, x, lj+1, . . . , ld)), is of greater
size than that of D. Similarly, if i = min{i | x < ki}, then
the decomposition of r, ((k1, . . . , ki, x, ki+1, . . . , kc), (l1, . . . ,
lj−1, x, lj+1, . . . , ld)), is of greater size than that of D. Both
cases contradict the hypothesis, hence, x must appear in D.
d(cid:48) )) be
a w.c.d. of r. Then, the integers 0, . . . , MD(cid:48) appear in D(cid:48).
By Lemma 1, all integers 0, . . . , B(r) appear in D and D(cid:48).
By removing the integers 0, . . . , B(r) from D and D(cid:48), the
remaining integers are y1 ≥ . . . ≥ ys and z1 ≥ . . . ≥ zt,
respectively. Since an integer cannot appear more than twice
in a decomposition of r and, by Lemma 1, the maximum
possible value B(r) + 1 cannot appear more than once, we
have that y1, . . . , ys and z1, . . . , zt are sequences of distinct
j=1 2zj . Assume that there
exists a minimum index ρ ≤ s such that yρ (cid:54)= zρ and that
w.l.o.g. yρ > zρ. Then we have the contradiction

1, . . . , k(cid:48)

1, . . . , l(cid:48)

c(cid:48) ), (l(cid:48)

i=1 2yi =Pt
X

2yi + 2yρ >

integers such thatPs
2yi ≥X
≥X

sX

i<ρ

i=1

2yi + 2zρ+1 − 1 ≥

tX

i<ρ

2zi =

X

i≥ρ

sX

2zi +

2zj =

2yi .

i<ρ

j=1

i=1

Thus, {y1, . . . , ys} and {z1, . . . , zt} are equal, and therefore
D is a w.c.d. of r.

A consequence of Theorem 2 and Lemma 1 is that, for
every integer r > 1, a w.c.d. of r is a proper re-arrangement
of the integers that appear in the w.c.d. of r where the
ﬁrst sequence is (B(r), . . . , 0) and the second sequence is the
remaining integers in the decomposition in decreasing order.
We term this unique w.c.d. as the uniform decomposition
of r. The main idea in URC is to always generate a trapdoor
that complies with the uniform decomposition of r.

We are ready to describe algorithm TURC in URC, whose
pseudocode is provided below. The process starts with in-
voking the TBRC algorithm of BRC to get an initial trap-
door τ (Line 1). If the input range is covered by a single
subtree, then τ is reformed into two pairs that correspond
to the child subtrees, so that the dephs in τ always form
a decomposition (Lines 2-3). Let D be the decomposition
implied by τ (Line 4). The loop in Lines 5-7 utilizes The-
orem 2 and works as follows. It ﬁnds the highest depth x

677

i , x), (y1

that does not exist in D, and “splits” the partial PRF value
yi in the rightmost pair in τ with depth x+1, producing two
new partial PRF values with depth x, i.e., y0
i = G0(yi) and
y1
i = G1(yi) (Line 6). Note that these values correspond to
the two children of the subtree of yi. Thus, if we substitute
element (yi, x + 1) by (y0
i , x) in τ , then the trapdoor
can still produce the same leaf PRF values as before. How-
ever, at all times we wish the sequence of depths in τ to form
a decomposition. Hence, after removing (yi, x + 1), we ap-
propriately insert (y0
i , x)
in the right pair sequence of τ (Line 7). Upon termination
of the loop, all the values in {0, . . . , MD} appear in D and,
thus, we have reached a w.c.d. according to Theorem 2. The
process terminates, after properly re-arranging the elements
of τ , such that they comply with the unique uniform decom-
position of r (Lines 8-9). This is done deterministically, by
simply ﬁlling the missing depths from {0, . . . , B(r)} in the
left sequence with the unique appropriate pair that exists
(by Theorem 2) in the right sequence.

i , x) in the left pair sequence and (y1

The Trapdoor Generation Algorithm TURC
Input: a, b : 0 ≤ a < b ≤ a + λγ ≤ 2n − 1 and k ∈ {0, 1}λ
Output: Trapdoor τ for computing {fk(x)|x ∈ [a, b]}

τ ← (cid:104)(G0(y), d − 1), (G1(y), d − 1)(cid:105)

1. Invoke TBRC(a, b, k) and receive the output τ
2. if τ consists only of pair (y, d) then
3.
4. Let τ = (cid:104)(y1, d1), . . . , (yn, dm)(cid:105) and
D = ((d1, . . . , dc), (dc+1, . . . , dm))
be the corresponding decomposition of r = b − a + 1

5. while there is a maximum integer x in {0, . . . , MD} that

does not appear in D:

6.

7.

Find the rightmost pair (yi, x + 1) and compute values
i = G0(yi), y1
y0
Remove (yi, x + 1) from τ , insert the pairs
(y0
order, and update D accordingly

i , x) in τ respecting the strictly decreasing

i , x) and (y1

i = G1(yi)

8. if the leftmost sequence of D is not (B(r), . . . , 0) then
9.

Fill leftmost sequence with values from rightmost
sequence until it complies with the uniform
decomposition of r

10. return τ

In our running example, for the range [2, 7], the TURC al-
gorithm in URC converts the original token retrieved by the
trapdoor algorithm of BRC, τ = (cid:104)(fk(001), 1), (fk(01), 2)(cid:105),
as follows (we underline a newly inserted element to the left
sequence, and depict as bold a newly inserted element to the
right sequence):

(cid:104)(fk(001), 1), (fk(01), 2)(cid:105)

(cid:104)(fk(0010), 0), (fk(01), 2), (fk(0011), 0)(cid:105)

↓
↓

(cid:104)(fk(010), 1), (fk(0010), 0), (fk(011), 1), (fk(0011), 0)(cid:105) .
The C algorithm of URC is identical to that of BRC, be-
cause the trapdoor in URC has exactly the format expected
by this algorithm, i.e., pairs of PRF values corresponding to
GGM subtrees along with their depths. Moreover, during
the evolution of the initial BRC trapdoor into one of uni-
form decomposition in the T algorithm of URC, a partial
PRF value y is substituted by two new PRF values that can
generate the same leaf PRF values as y. As such, the cor-
rectness of the BRC scheme is inherited in URC. Finally,
due to Lemma 1, the size of a w.c.d. (and, hence, also a
uniform decomposition) of r is O(log(r)), which means that
the trapdoor size in URC is also O(log(r)).

4.3 Security

In this section we prove the security of BRC and URC.
Both proofs rely on the security of the pseudorandom gen-
erator of the underlying GGM construction. Note that the
security proof does not follow straightforwardly from the
GGM proof because contrary to the case of GGM where the
adversary obtains only leaf PRFs, the adversary in a DPRF
can obtain also partial PRF values in the GGM tree (via
delegation queries). Note that the tree structure of a trap-
door (which is independent of k) for a range predicate P of
size r is deterministic and public in both BRC and URC.
Thus, when querying the oracle in the security game, the
adversary can map the partial or full PRF values appearing
in τ for a selected P to subtrees in the GGM tree. Based on
this observation, we prove ﬁrst the security of BRC against
adversaries that query only subtrees, or equivalently preﬁxes
for strings in {0, 1}n, where n is the depth of the GGM tree.
We call this type of security subtree security. We conclude
our proofs by showing that the subtree security of BRC im-
plies the security of both schemes.

In order to prove the subtree security property of BRC,
we insure and exploit the subtree security for two special
cases. First, we consider the case that the adversary is non-
adaptive, i.e., it poses all its queries in advance.

Lemma 2 The BRC scheme with depth n and range size at
most λγ is subtree secure against PPT adversaries that make
all their queries, even the challenge query, non-adaptively.
Proof. Let A be a non-adaptive preﬁx-only PPT adver-
sary against a BRC scheme with depth n and maximum
range size λγ. Without loss of generality we assume that
A always advances to step 3 (submits a challenge to the
challenger).
We deﬁne recursively two sequences of PPT algorithms
A = An, . . . ,A1 and Sn, . . . ,S1 as follows.
For i = n − 1, . . . , 1, Ai on input 1λ, initially invokes
Ai+1 receiving all of its non-adaptive queries, and chooses a
random value k(cid:48) in {0, 1}λ. If a query xi ··· xt has the same
most signiﬁcant bit (MSB) as the challenge query, Ai makes
the query xi−1 ··· xt, and responds with the received value y.
Otherwise, it responds with the value Gxt (··· (Gxi−1 (k(cid:48)))).
It returns Ai+1’s output.
For i = n, . . . , 1, on input (z0, z1) ∈ {0, 1}2λ, Si invokes
Ai and receives all of its queries. For every query xi−1 ··· xt,
it responds with Gxt (··· (Gxi−2 (zxi−1 ))) (or zx0 for i = 1).
On the challenge phase, it ﬂips a coin b and acts as the
challenger in a DPRF security game with Ai. It returns 1
iﬀ Ai returns b.
Let qi and pi be the probabilities that Si outputs 1 when
it receives its input from the uniform distribution U2λ in
{0, 1}2λ and the pseudorandom distribution G(Uλ), respec-
tively. By the deﬁnition of Si, pn = Pr[GA
SEC(1λ) = 1] while
q1 ≤ 1/2, since it corresponds to a totally random game.
We next observe that An−1, . . . ,A1 behave like attackers
against the subtree security of BRC schemes with respective
depths n− 1, . . . , 1. The behavior of Ai as an attacker is the
same as Ai+1’s, when the latter interacts with a modiﬁed
challenger that replaces the two possible partial PRF values
for the MSB of a preﬁx, with two random values. Thus,
following the previous notation, we have that pi = qi+1.
Since G(Uλ) and U2λ are indistinguishable, it holds that

|pi − qi| ≤ i(λ), where i(·) is a negligible function. Finally:

|pn − q1| = | nX

(pi − qi)| ≤ nX

|pi − qi| ≤ nX

i(λ) ,

i=1

i=1

i=1

SEC(1λ) = 1] = pn ≤ q1 + n · (λ) ≤ 1/2 + n · (λ),

hence Pr[GA
where (λ) = max

{i(λ)}.

i

We use the above lemma to prove the security of a special
category of BRC schemes, where the maximum range size is
at least half of A = [0, 2n − 1], which represents the biggest
interval where range predicates are deﬁned. This will serve
as a stepping stone for designing our ﬁnal security proof.

Lemma 3 The BRC scheme with depth n and maximum
range size λγ is subtree secure if 2n−1 ≤ λγ < 2n.

n−1 ··· x∗

n−1 ··· x∗

i ⊕ 1), . . . , (x∗

Proof. Let A be a preﬁx-only adversary. We construct a
non-adaptive preﬁx-only adversary B for the subtree security
game that on input 1λ chooses randomly a challenge x∗ in
[0, 2n−1] and makes the n queries that cover all the possible
values except from x∗. Namely, B makes queries (x∗
n−1 ⊕
0 ⊕ 1) and submits
1), . . . , (x∗
challenge x∗. It receives responses yn−1, . . . , y0 respectively,
along with y∗ which is the response to x∗. Then, it invokes
A and plays the security game with A, as a challenger that
can respond appropriately for every value that is not x∗ or a
range that does not contain x∗. If A sets x∗ as a challenge,
then B responds with y∗, and returns A’s guess. Otherwise,
A has either made a query which is a preﬁx of x∗, or it has
submitted a challenge diﬀerent than x∗, so B terminates the
game it plays with A and returns a random bit, as its guess
to its challenge.
Let E be the event that B guesses A’s challenge, i.e. A’s
challenge is x∗. By the description of B we have that
SEC(1λ) = 1 ∧ ¬E] = 1/2 · (1 − 1/2n) and
SEC(1λ) = 1 ∧ E] = 1/2n · Pr[GA
SEC(1λ) = 1] .

Pr[GB
Pr[GB

Since B is non-adaptive, by Lemma 2 we get that for some
SEC(1λ) = 1] ≤ 1/2 + (λ). By
negligible function (·), Pr[GB
adding the above equations we have that

1/2n · (Pr[GA

SEC(1λ) = 1] − 1/2) + 1/2 ≤ 1/2 + (λ) ,
SEC(1λ) = 1] ≤ 1/2 + 2n · (λ) ≤ 1/2 + 2λγ · (λ).

so, Pr[GA

We apply Lemma 3 to prove the subtree security of BRC.

Lemma 4 The BRC scheme with depth n and maximum
range size λγ is subtree secure.

Proof. See Appendix.

Finally, we prove that the subtree security of BRC implies

the security of BRC and URC.

Theorem 3 The BRC and URC schemes with depth n and
maximum range size λγ are secure.

Proof. Let A be a PPT adversary that wins the DPRF
security game of either BRC or URC with non-negligible
advantage α(·). As noted in the beginning of this section,
any query A makes, can be represented as a sequence of
O(log(λγ)) subtrees, or equivalently of O(log(λγ)) preﬁxes.
Thus, we can construct a preﬁx-only adversary A(cid:48) that in-
vokes A and when it receives a query sequence (cid:104)x1
n−1 ··· x1
t1 ,

678

n−1 ··· xm

tm(cid:105) from A, it makes all preﬁx queries sepa-
. . . , xm
rately, receives y1, . . . , ym and answers by (cid:104)y1, . . . , ym(cid:105). A(cid:48)
also transfers A’s challenge and outputs its guess. There-
fore, it wins the DPRF security game with advantage α(·),
which contradicts Lemma 4.
4.4 Policy Privacy

This section analyzes the policy privacy of URC. Accord-
ing to the lower bound argument we gave in Section 3, URC
cannot be expected to satisfy the general policy-privacy prop-
erty, because it is eﬃcient. We illustrate this explicitly with
a toy example. For challenge ranges [2, 5] and [4, 7], the
trapdoors will contain PRF values corresponding to subtrees
covering the ranges as [2, 3],{4},{5} and [4, 5],{6},{7}, re-
spectively. Therefore, the adversary can issue query for leaf
4 and receive a PRF value y. Having (cid:104)(y1, 1), (y2, 0), (y3, 0)(cid:105)
as challenge trapdoor, it can check whether y2 = y, which
happens only when [2, 5] was chosen by the challenger.

Nevertheless, in the theorem below we prove that URC
achieves union policy privacy. The above attack is circum-
vented as in the union policy-privacy game, the adversary
cannot obtain a PRF value for a leaf in the intersection of
the challenge ranges, i.e., for 4 and 5.

Theorem 4 The URC scheme with depth n and maximum
range size λγ is a DPRF with union policy privacy.

Proof. See Appendix.

5. APPLICATIONS

In this section we discuss interesting applications of the
general DPRF primitive and our specialized constructions
for range-based policies. We stress, though, that their ap-
plicability is not limited to these scenarios; we are conﬁdent
that they can capture a much wider set of applications.
Authentication and access control in RFID. Radio
Frequency Identiﬁcation (RFID) is a popular technology that
is expected to become ubiquitous in the near future. An
RFID tag is a small chip with an antenna. It typically stores
a unique ID along with other data, which can be transmit-
ted to a reading device lying within a certain range from the
tag. Suppose that a trusted center (TC) possesses a set of
RFID tags (attached to books, clothes, etc.), and distributes
RFID readers to speciﬁed locations (e.g., libraries, restau-
rants, etc.). Whenever a person or object carrying a tag lies
in proximity with a reader, it transmits its data (e.g., the
title of a book, the brand of a jacket, etc.). The TC can
then retrieve these data from the RFID readers, and mine
useful information (e.g., hotlist books and clothes, etc.).

Despite its merits, RFID technology is challenged by secu-
rity and privacy issues. For example, due to the availability
and low cost of the RFID tags, one can easily create tags
with arbitrary information. As such, an adversary may im-
personate other tags, and provide falsiﬁed data to legitimate
readers. On the other hand, a reader can receive data from
any tag in its vicinity. Therefore, sensitive information may
be leaked to a reader controlled by an adversary. For exam-
ple, the adversary may learn the ID and the title of a book
stored in a tag, match it with public library records, and
discover the identity and reading habits of an individual.

Motivated by the above, authentication and access control
in RFID-based systems has been studied in the literature.
A notable paradigm was introduced in [30], which can be

directly beneﬁted by DPRFs. At a high level, every tag is
associated with a key, and the TC delegates to a reader a set
of these keys (i.e., the reader is authorized to authenticate
and access data from only a subset of the tags). The goal
is for the TC to reduce certain costs, e.g., the size of the
delegation information required to derive the tag keys while
maintaining a high number of distinct keys in order to ensure
that attacks can be compartmentalized.
Observe that a DPRF (F, T, C) is directly applicable to
the above setting. F is deﬁned on the domain of the tag IDs,
and its range is the tag keys. Given a delegation predicate on
the tag IDs, the TC generates a trapdoor via algorithm T ,
and sends it to the reader. The latter runs C on the trapdoor
to retrieve the tag keys. In fact, for the special case where
the access policy is a range of IDs, the delegation protocol
suggested in [30] is identical to the non-private BRC scheme
(we should stress though that [30] lacks rigorous deﬁnitions
and proofs). Range-based policies are meaningful, since tag
IDs may be sequenced according to some common theme
(e.g., books on the same topic are assigned consecutive tag
IDs). In this case, a range policy concisely describes a set
of tags (e.g., books about a certain religion) and, hence, the
system can enjoy the logarithmic delegation size of BRC.
However, as explained in Section 4, BRC leaks the position
of the IDs in the tree, which may further leak information
about the tags. Although [30] addresses tag privacy, it pro-
vides no privacy formulation, and overlooks the above struc-
tural leakage. This can be mitigated by directly applying
our policy-private URC construction for delegating tag keys
to the readers. To sum up, DPRFs ﬁnd excellent applica-
tion in authentication and access control in RFIDs, enabling
bandwidth-eﬃcient tag key delegation from the TC to the
reader. Moreover, policy-private DPRFs provide stronger
protection for the tag IDs against the readers.

Batch queries in searchable symmetric encryption.
Searchable symmetric encryption (SSE) (e.g., [11, 24]) en-
ables processing queries directly on ciphertexts generated
with symmetric encryption. Although SSE corresponds to a
general paradigm, various works primarily support the spe-
cial case of keyword queries. Here, we focus on the deﬁni-
tions and schemes of [11] that provide an acceptable level
of provable security. The general framework underlying [11]
is as follows. In an oﬄine stage, a client encrypts his data
with his secret key k, and uploads the ciphertexts c to an
untrusted server. He also creates and sends a secure index I
on the data for eﬃcient keyword search, which is essentially
an encrypted lookup table or inverted index. Given a key-
word w, the client generates a query token τw using k, and
forwards it to the server. It is important to stress that this
“trapdoor” is merely comprised of one or more PRF values
computed on w with k, which were used as keys to encrypt
I. For simplicity and w.l.o.g., we assume that τw is a single
PRF value. The server uses τw on I and retrieves the IDs
of the ciphertexts associated with w. The results c1, . . . , cm
are retrieved and transmitted back to the client, who even-
tually decrypts them with his key. The security goal is to
protect both the data and the keyword from the server.

Suppose that the client wishes to search for a batch of
N keywords w1, . . . , wN . For instance, the client may ask
for documents that contain multiple keywords of his choice
(instead of just a single one). As another example, assume
that the client’s data are employee records, and each record
contains a salary attribute that takes as values intervals of

679

the form [iK, (i + 1)K] (i.e., instead of exact salaries). These
intervals can serve as keywords in SSE search. Suppose that
the client wishes to retrieve records with salaries in a range
of intervals, e.g., [1K, 10K]. Observe that this cannot be pro-
cessed with a single keyword query (no record is associated
with [1K, 10K]). To overcome this while utilizing the SSE
functionality, the client can ask 9 distinct queries with key-
words “[1K, 2K]”, “[2K, 3K]”, . . ., “[9K, 10K]”, which cover
the query range [1K, 10K]. Such scenarios are handled with
“traditional” SSE as shown in Figure 5(a). Given a predi-
cate P that describes the keywords w1, . . . , wN in the batch
query, the client generates N trapdoors τw1 , . . . , τwN using
the standard SSE trapdoor algorithm. These trapdoors are
sent to the server, which then searches I with every τwi fol-
lowing the SSE protocol. Obviously, for large N , the client’s
computational and communication cost is greatly impacted.

(a) “Traditional” SSE.

(b) SSE augmented with DPRFs.

Figure 5: Batch keyword query processing in SSE.

We can augment the discussed SSE framework with DPRF
functionality, in order to support batch queries with sublin-
ear (in N ) processing and communication cost at the client,
while providing provable security along the lines of [11]. Fig-
ure 5(b) illustrates our enhanced SSE architecture. Recall
that τwi is practically a PRF value, computed on wi with
key k. Therefore, instead of computing a PRF value for ev-
ery wi itself, the client delegates the computation of these
PRF values to the server by employing a DPRF scheme
(F, T, C), where F is deﬁned over the domain of the key-
words. Given predicate P and k, the client runs T and
generates trapdoor τ , which is sent to the server. The latter
executes C on τ to produce τw1 , . . . , τwN . Execution then
proceeds in the same manner as in “traditional” SSE. Ob-
serve that, for the special case of ranges, if URC is used as
the DPRF, the computational and communication cost at
the client decreases from O(N ) to O(log(N )). This trans-
formation would work “out of the box” in combination to
any SSE scheme that uses a PRF for creating tokens.

The above framework can be proven secure against adap-
tive adversaries along the lines of [11]. The most important
alteration in the security game and proof is the formulation
of the information leakage of the C algorithm of the DPRF.
In particular, the level of keyword privacy that is provided
by the construction is dictated by the level of policy privacy
that is attained by the underlying DPRF. Speciﬁcally, given

a DPRF with multi-instance policy privacy, it is easy to
show that the same level of keyword privacy as in [11] can be
achieved. Weaker notions of policy privacy (such as single-
instance or union) result in correspondingly weaker notions
of keyword privacy. For instance, recall that union policy
privacy ensures indistinguishability of delegation queries not
intersecting with previously asked queries. Thus, combin-
ing PRF-based SSE with our URC construction will provide
this level of keyword privacy. Given the lower bound argu-
ments for tree-wise constructions we sketched in Section 3,
the privacy loss incurred by this tree-based design is the un-
avoidable cost for the exponential eﬃciency improvement in
client-to-server communication. Eﬃcient constructions at-
taining higher level of policy privacy might be feasible, but
they will have to follow a non tree-base design paradigm.

Broadcast encryption. In a broadcast encryption scheme
(e.g., [14, 31, 32]) a sender wishes to transmit data to a set
of receivers so that at each transmission the set of receivers
excluded from the recipient set can be chosen on the ﬂy
by the sender.
In particular, this means that the sender
has to be able to make an initial key assignment to the
recipients, and then suitably use the key material so that
only the speciﬁc set of users of its choosing can receive the
message.
In such schemes, it was early on observed that
there is a natural tradeoﬀ between receiver memory storage
and ciphertext length (e.g., see lower bounds in [26]). The
intuition behind this is that if the receivers have more keys,
this gives to the sender more ﬂexibility in the way it can
encrypt a message to be transmitted.

In the above sense one can think of the key assignment
step of a broadcast encryption scheme as a PRF deﬁned
over the set Φ which contains all distinct subsets that the
broadcast encryption scheme assigns a distinct key. Given
this conﬁguration, the user u will have to obtain all the keys
corresponding to subsets S ∈ Φ for which it holds that u ∈ S
(we denote those subsets by Su ⊆ Φ). In DPRF language
this would correspond to a delegation policy for a PRF: users
will need to store the trapdoor that enables the evaluation
of any value in the delegated key set Su.

Seen in this way, any DPRF is a key assignment mecha-
nism for a broadcast encryption scheme that saves space on
receiver storage. For example, our constructions for range-
based policies give rise to the following broadcast encryption
scheme: Receivers [n] = {1, . . . , n} are placed in sequence;
each receiver u ∈ [n] is initialized with the trapdoor for a
range [u − t, u + t] for some predetermined parameter t ∈ Z.
In this broadcast encryption scheme the sender can very ef-
ﬁciently enable any range of receivers that is positioned at
distance at most t from a ﬁxed location v ∈ [n]. This is
done with a single ciphertext (encrypted with the key of lo-
cation v). Any receiver of suﬃcient proximity t to location
v can derive the corresponding decryption key from its trap-
door. Furthermore, given the eﬃciency of our construction,
storage on receivers is only logarithmic on t. While the se-
mantics of this scheme are more restricted than a full-ﬂedged
broadcast encryption scheme (which enables the sender to
exclude any subset of users on demand), it succinctly illus-
trates the relation between broadcast encryption and DPRF;
further investigation in the relation between the two primi-
tives from a construction point of view will be motivated by
our notion. Speciﬁcally, an eﬃcient DPRF with domain Φ
over a policy set P = {Su | u ∈ [n]} will provide an eﬃcient
key assignment for a broadcast encryption scheme operating

680

Clientk,Pτw1,...,τwNc1,...,cmServerTrapdoorSearchI,cClientk,Pc1,...,cmServerSearchI,cCTτw1,...,τwNDPRFτover Φ. Interestingly, the reverse is also true and a (suit-
ably structured) broadcast encryption scheme will provide a
DPRF with domain Φ and the policy set {Su | u ∈ [n]}.

Regarding policy privacy, it is interesting to point out
that this security property is yet unstudied in the domain of
broadcast encryption. A diﬀerent privacy notion has been
considered in [3, 13, 25] that deals with the structure of ci-
phertexts in such schemes. Our policy privacy on the other
hand deals with the privacy of memory contents from the
receiver’s point of view. Maintaining the indistinguishabil-
ity of the storage contents is a useful security measure in
broadcast encryption schemes, and our DPRF primitive will
motivate the study of this security property in the context of
broadcast encryption—note that none of the tree-like key-
delegation methods used in broadcast encryption schemes
prior to our work satisﬁes policy privacy.

6. CONCLUSION

We have introduced the concept of delegatable pseudoran-
dom functions (DPRFs), a new cryptographic primitive that
allows for policy-based computation at an untrusted proxy
of PRF values, without knowledge of a secret or even the
input values. We provided formal deﬁnitions of the core
properties of DPRFs for (1) correctness, the ability of the
proxy to compute PRF values only for inputs that satisfy
a given predicate, (2) security, the standard pseudorandom-
ness guarantee, but against a stronger adversary that also
issues delegation queries, and (3) policy privacy, which pre-
vents leakage of the secret preimages of the computed PRF
values. Moreover, we presented two DPRF constructions
for PRF delegation controlled by range-based policies, along
with a comprehensive analysis in terms of their security and
privacy guarantees and some inherent trade-oﬀs with eﬃ-
ciency. Our proposed DPRF schemes are generic, yet practi-
cal, based on the well-understood and widely-adopted GGM
design framework for PRFs and, as we showed, they ﬁnd di-
rect application in many key-delegation or key-derivation
settings providing interesting new results.

Further exploration of DPRFs holds promise for many
directions of interest. Open problems include: Designing
DPRFs for other classes of predicates, establishing upper
and lower bounds on the connection between eﬃciency and
policy privacy, and studying applications in other settings.

Acknowledgments
We thank all anonymous reviewers for providing detailed
comments and suggestions. The ﬁrst and fourth authors
were supported by projects CODAMODA of the European
Research Council, Marie Curie RECUP, and respectively
FINER of GSRT.

7. REFERENCES
[1] M. J. Atallah and K. B. Frikken. Securely outsourcing

linear algebra computations. In Proc. of the 5th
Symposium on Information, Computer and Comm.
Security (ASIACCS), pages 48–59. ACM, 2010.

[2] G. Ateniese, K. Fu, M. Green, and S. Hohenberger.

Improved proxy re-encryption schemes with
applications to secure distributed storage. ACM
Trans. Inf. Syst. Secur., 9(1):1–30, Feb. 2006.

[3] A. Barth, D. Boneh, and B. Waters. Privacy in

encrypted content distribution using private broadcast

encryption. In Proc. of the 10th Int. Conf. on
Financial Cryptography and Data Security, pages
52–64. Springer, 2006.

[4] S. Benabbas, R. Gennaro, and Y. Vahlis. Veriﬁable

delegation of computation over large datasets. In Proc.
of the 31st Annual Conf. on Advances in Cryptology
(CRYPTO), pages 111–131. Springer, 2011.

[5] M. Blaze, G. Bleumer, and M. Strauss. Divertible

protocols and atomic proxy cryptography. In Proc. of
the 17th Int. Conf. on the Theory and Application of
Cryptographic Techniques (EUROCRYPT), pages
127–144. Springer, 1998.

[6] A. Boldyreva, A. Palacio, and B. Warinschi. Secure

proxy signature schemes for delegation of signing
rights. Journal of Cryptology, 25:57–115, 2012.

[7] D. Boneh and B. Waters. Constrained pseudorandom
functions and their applications. In Proc. of the 19th
Int. Conf. on the Theory and Application of
Cryptology and Information Security (ASIACRYPT),
2013. To appear; full version in Cryptology ePrint
Archive, 2013:352.

[8] E. Boyle, S. Goldwasser, and I. Ivan. Functional

signatures and pseudorandom functions. IACR
Cryptology ePrint Archive, 2013:401, 2013.

[9] R. Canetti, B. Riva, and G. N. Rothblum. Practical
delegation of computation using multiple servers. In
Proc. of the 18th Conf. on Computer and Comm.
Security (CCS), pages 445–454. ACM, 2011.

[10] K.-M. Chung, Y. T. Kalai, and S. P. Vadhan.

Improved delegation of computation using fully
homomorphic encryption. In Proc. of the 30th Annual
Conf. on Advances in Cryptology (CRYPTO), pages
483–501. Springer, 2010.

[11] R. Curtmola, J. Garay, S. Kamara, and R. Ostrovsky.

Searchable symmetric encryption: Improved
deﬁnitions and eﬃcient constructions. In Proc. of the
13th Conf. on Computer and Comm. Security (CCS),
pages 79–88. ACM, 2006.

[12] Y. Dodis and A. Yampolskiy. A veriﬁable random

function with short proofs and keys. In Proc. of the
8th Int. Workshop on Public Key Cryptography
(PKC), pages 416–431. Springer, 2005.

[13] N. Fazio and I. M. Perera. Outsider-anonymous

broadcast encryption with sublinear ciphertexts. In
Proc. of the 15th Int. Conf. on Public Key
Cryptography (PKC), pages 225–242. Springer, 2012.
[14] A. Fiat and M. Naor. Broadcast encryption. In Proc.
of the 13st Annual Conf. on Advances in Cryptology
(CRYPTO), pages 480–491. Springer, 1993.
[15] D. Fiore and R. Gennaro. Publicly veriﬁable

delegation of large polynomials and matrix
computations, with applications. In Proc. of the 19th
Conf. on Computer and Comm. Security (CCS), pages
501–512. ACM, 2012.

[16] M. J. Freedman, Y. Ishai, B. Pinkas, and O. Reingold.

Keyword search and oblivious pseudorandom
functions. In Proc. of the 2nd Theory of Cryptography
Conference (TCC), pages 303–324. Springer, 2005.
[17] O. Goldreich, S. Goldwasser, and S. Micali. How to

construct random functions. J. ACM, 33(4):792–807,
1986.

681

[18] S. Goldwasser, Y. T. Kalai, and G. N. Rothblum.

[33] B. Parno, M. Raykova, and V. Vaikuntanathan. How

Delegating computation: interactive proofs for
muggles. In Proc. of the 40th Annual Symposium on
Theory of Computing (STOC), pages 113–122. ACM,
2008.

[19] M. Green and G. Ateniese. Identity-based proxy

re-encryption. In Proc. of the 5th Int. Conf. on
Applied Cryptography and Network Security (ACNS),
pages 288–306. Springer, 2007.

[20] S. Hohenberger and A. Lysyanskaya. How to securely
outsource cryptographic computations. In Proc. of the
2nd Theory of Cryptography Conference (TCC), pages
264–282. Springer, 2005.

[21] G. Itkis. Handbook of Information Security, chapter

Forward Security: Adaptive Cryptography—Time
Evolution. John Wiley and Sons, 2006.

[22] A.-A. Ivan and Y. Dodis. Proxy cryptography

revisited. In Proc. of the 10th Network and Distributed
System Security Symposium (NDSS). The Internet
Society, 2003.

[23] S. Jarecki and X. Liu. Eﬃcient oblivious

pseudorandom function with applications to adaptive
ot and secure computation of set intersection. In Proc.
of the 6th Theory of Cryptography Conference (TCC),
pages 577–594. Springer-Verlag, 2009.

[24] S. Kamara, C. Papamanthou, and T. Roeder.

Dynamic searchable symmetric encryption. In Proc. of
the 19th Conf. on Computer and Comm. Security
(CCS), pages 965–976. ACM, 2012.

[25] B. Libert, K. G. Paterson, and E. A. Quaglia.

Anonymous broadcast encryption: Adaptive security
and eﬃcient constructions in the standard model. In
Proc. of the 15th Int. Conf. on Public Key
Cryptography (PKC), pages 206–224. Springer, 2012.
[26] M. Luby and J. Staddon. Combinatorial bounds for
broadcast encryption. In Proc. of the 17th Int. Conf.
on the Theory and Application of Cryptographic
Techniques (EUROCRYPT), pages 512–526. Springer,
1998.

[27] A. Lysyanskaya. Unique signatures and veriﬁable

random functions from the DH-DDH separation. In
Proc. of the 22nd Annual Conf. on Advances in
Cryptology (CRYPTO), pages 597–612. Springer, 2002.

[28] M. Mambo, K. Usuda, and E. Okamoto. Proxy

signatures for delegating signing operation. In Proc. of
the 3rd Conf. on Computer and Comm. Security
(CCS), pages 48–57. ACM, 1996.

[29] S. Micali, M. O. Rabin, and S. P. Vadhan. Veriﬁable

random functions. In Proc. of the 40th Annual
Symposium on Foundations of Computer Science
(FOCS), pages 120–130. IEEE, 1999.

[30] D. Molnar, A. Soppera, and D. Wagner. A scalable,
delegatable pseudonym protocol enabling ownership
transfer of RFID tags. In Proc. of the 12th Int.
Workshop on Selected Areas in Cryptography (SAC),
pages 276–290. Springer, 2006.

[31] D. Naor, M. Naor, and J. Lotspiech. Revocation and
tracing schemes for stateless receivers. In Proc. of the
21st Annual Conf. on Advances in Cryptology
(CRYPTO), pages 41–62. Springer, 2001.

[32] M. Naor and B. Pinkas. Eﬃcient trace and revoke

schemes. Int. J. Inf. Sec., 9(6):411–424, 2010.

to delegate and verify in public: veriﬁable
computation from attribute-based encryption. In Proc.
of the 9th Theory of Cryptography Conference (TCC),
pages 422–439. Springer, 2012.

| Pr[GA

SEC(1λ) = 1] − Pr[BR(·)(1λ) = 1]| ≤ (λ) .

APPENDIX
Proof of Lemma 4
By Lemma 3, it suﬃces to focus on the case that λγ < 2n−1.
This is deﬁnitely the interesting case, since 2n is normally
superpolynomial in λ. Let A be a preﬁx-only adversary
against BRC that makes at most q(λ) queries (including the
challenge) and d be the minimum integer that λγ < 2d.
We construct a PPT PRF distinguisher B that makes oracle
queries of ﬁxed size n(cid:48) = n − d ≥ 1. On input 1λ, B ﬂips a
coin b, invokes A and initializes a security game, itself being
the challenger. By the bound on the size of the ranges, all
queries of A have length greater than n(cid:48). Thus, for every
query xn−1 ··· xt, we have that t < d and B responds by
making a query xn−1 ··· xd, which is of length n(cid:48), receiving a
value y and answering to A as Gxt (··· (Gxd−1 (y))). When A
submits a challenge, B acts as a normal challenger according
to the coin ﬂip b utilizing its oracle to determine the value
up to level d as above. Finally, B returns 1 iﬀ A returns b.
Clearly, when B’s oracle is a PRF fk of length n(cid:48), B returns
1 iﬀ A wins, i.e Pr[GA
SEC(1λ) = 1] = Pr[Bfk(·)(1λ) = 1]. Since
fk is a PRF, we have that for some negligible function (·),
(1)
Consequently, we can construct a preﬁx-only adversary ˜A
against a BRC with depth d and maximum range size λγ as
follows: ˜A invokes A and chooses a random index j ∈ [q(λ)]
and q(λ) − 1 random values k1, . . . , kj−1, kj+1, . . . , kq(λ) ∈
{0, 1}λ. Index j reﬂects ˜A’s attempt to guess which of all of
possible diﬀerent preﬁxes of length n(cid:48) that will appear in A’s
queries will be the one that a prospective challenge query will
have. Then ˜A keeps count of the diﬀerent preﬁxes of length
n(cid:48) that gradually appear and reacts to a query xn−1 ··· xt
according to the following checks:
(i) xn−1 ··· xd is the i-th preﬁx and i (cid:54)= j: In this case, ˜A
responds with Gxt (··· (Gxd−1 (ki))).
(ii) xn−1 ··· xd is the j-th preﬁx: If all of the queries made
by A that have the j-th preﬁx, along with xn−1 ··· xt,
cover the whole subtree with root preﬁx xn−1 ··· xd,
Tj, then ˜A terminates the game with A and chooses a
leaf zd−1 ··· z0 of Tj that has not been covered by A’s
previous queries. It submits zd−1 ··· z0 as its challenge
and returns a random bit. Otherwise, ˜A makes query
xd−1 ··· xt and responds with the received value y.
(iii) t = 0 and xn−1 ··· x0 is A’s challenge: If xn−1 ··· xd is
not the j-th preﬁx, then ˜A terminates the game with
A, chooses a leaf zd−1 ··· z0 of Tj not yet covered by
A’s queries, submits zd−1 ··· z0 as its challenge and re-
turns a random bit. Otherwise, it submits challenge
xd−1 ··· x0, receives value y∗ and responds with y∗.

If ˜A does not terminate the security game with A, then
it returns A’s guess. By the choice of d, 2d−1 ≤ λγ < 2d,
hence Lemma 3 implies that ˜A has negligible distinguishing
advantage. Thus for some negligible function δ(·),

Pr[G ˜A

SEC(1λ) = 1] ≤ 1/2 + δ(λ) .

(2)

682

By the description of ˜A, the interaction between A and
B in the case that B’s oracle is random is fully simulated
by ˜A when the latter’s guess for the preﬁx of A’s challenge
is correct. Formally, let E be the event that ˜A guesses A’s
challenge. Then it holds that

Pr[BR(·)(1λ) = 1] = Pr[G ˜A

SEC(1λ) = 1|E] .
By the description of ˜A and (3), we have that

(3)

Pr[G ˜A
Pr[G ˜A

SEC(1λ) = 1 ∧ ¬E] = 1/2 · (1 − 1/q(λ)) and
SEC(1λ) = 1 ∧ E] = 1/q(λ) · Pr[BR(·)(1λ) = 1] ,

where we used that Pr[E] = 1/q(λ). Therefore,
Pr[G ˜A
so by applying (2) we get

SEC(1λ) = 1] = 1/2 + 1/q(λ)· (Pr[BR(·)(1λ) = 1]− 1/2) ,

Pr[BR(·)(1λ) = 1] ≤ 1/2 + q(λ) · δ(λ) .

(4)

Finally, by (1) and (4) we conclude that

Pr[GA

SEC(1λ) = 1] ≤ 1/2 + q(λ) · δ(λ) + (λ) =

= 1/2 + negl(λ) .

0 (1λ), . . . ,GA

Proof of Theorem 4
Let A be a PPT adversary that wins the union policy privacy
game with non-negligible distinguishing advantage α(·). Let
P0, P1 be the two challenge ranges and b the chosen random
bit, hence A receives the challenge trapdoor τb for Pb. De-
note each element of a decomposition D as (x, L) or (x, R),
if it is integer x and belongs to the leftmost or rightmost se-
quence of D respectively. Deﬁne the ordering <D over the el-
ements of D as follows: (x, L) <D (y, R) or (x, R) <D (y, L),
if x < y and (x, L) <D (x, R). We deﬁne a sequence of hy-
brid games GA
N (1λ), where N is the maximum
size of a trapdoor output by TURC. As shown in section
4.2, N = 2(cid:100)log(λγ + 2)(cid:101) − 1. The game Gi is executed
as the original game GA
UPP(1λ) during the pre-challenge and
the post-challenge phase. Assume the pairs of the challenge
trapdoor τb are arranged according to the ordering deter-
mined by the decomposition formed by the depths. The
only modiﬁcation in GA
i (1λ) is that in the ﬁrst i pairs of τb,
the partial PRF values are the same as τb’s, while all the
other elements are replaced by random values in {0, 1}λ. In
GA
0 (1λ), the challenge trapdoor consists of a number of pairs
of random values attached to certain integers, independently
of the choice of b. Therefore, Pr[GA
0 (1λ) = 1] = 1/2. Since
GA
N (1λ) is the union policy privacy game, it holds that

Pr[GA

N (1λ) = 1] − Pr[GA

0 (1λ) = 1] ≥ α(λ) .

Let Er be the event that the size of the challenge ranges
|AP0|, |AP1| that A submits is r. Then for some challenge
bit b ∈ {0, 1} and r ∈ [λγ]:
Pr[GA
which implies that there exists an i ∈ [λγ] such that

0 (1λ) = 1∧b∧Er] ≥ α(λ)/2λγ,

N (1λ) = 1∧b∧Er]−Pr[GA

Pr[GA

i (1λ) = 1 ∧ b ∧ Er]−
− Pr[GA

i−1(1λ) = 1 ∧ b ∧ Er] ≥ α(λ)/2N λγ .

(5)

We will show that for these ﬁxed b, r, i, we can construct an
adversary Ai for the security game of a BRC construction

683

SEC(1λ).

that has non-negligible winning advantage. The main idea is
that Ai invokes A and simulates either Gi or Gi−1 on selected
challenge Pb of size r depending on the value of the challenge
bit bi for the security game GAi
On input 1λ, Ai computes the uniform decomposition of
r, Ur, and arranges its elements according to <Ur . Let ui be
the integer that appears in the i-th element of Ur (trivially,
when r = 1 then ui = u1 = 0). The BRC that Ai attacks has
depth n−ui. Speciﬁcally, Ai invokes A and answers all of its
pre-challenge queries as follows: for each query xn−1 ··· xt,
if t ≥ ui, it just transfers the query, receives value y, and
responds with y. Otherwise, it makes query xn−1 ··· xui , re-
ceives value y, and responds with Gxt (··· (Gxui−1 (y))). In
the challenge phase, if |APb| (cid:54)= r, then Ai terminates the
game with A, chooses a valid random challenge, and returns
a random bit. Otherwise, it makes i−1 queries and computes
the <Ur -ﬁrst i−1 partial delegation keys y1, . . . , yi−1 of τb as
n−1 ··· x∗
in the pre-challenge phase, and sets the string x∗
ui
that corresponds to the i-th partial key as its challenge, re-
ceiving y∗. Note that since A is restricted from making
queries within AP0 ∪ AP1 , it makes no queries with preﬁx
n−1 ··· x∗
ui , thus Ai’s challenge is valid. It arranges the val-
x∗
ues y1, . . . , yi−1, y∗ according to the order that τb imposes
and “ﬁlls” the |Ur| − i remaining positions of an array like
trapdoor τb with |Ur| − i pairs consisting of random values
from {0, 1}λ along with the corresponding depths. It returns
τb to A and answers to A’s post-challenge queries as in the
pre-challenge phase. If A returns b, then Ai returns 1, or
else it returns a random bit.

SEC(1λ) = 1] = Pr[GAi

The probability that Ai wins the security game is
SEC(1λ) = 1 ∧ ¬Er]+
SEC(1λ) = 1 ∧ Er ∧ bi = 1]+
SEC(1λ) = 1 ∧ Er ∧ bi = 0] .

+ Pr[GAi
+ Pr[GAi
It holds that Pr[GAi
SEC(1λ) = 1 ∧ ¬Er] = 1/2 · (1 − Pr[Er]).
For the other two terms in the right part of (6), we observe
that when bi = 1, Ai simulates Gi when b and Er occur,
whereas when bi = 0, Ai simulates Gi−1 when b and Er
occur. Therefore, by the description of Ai we have that
Pr[GAi

SEC(1λ) = 1 ∧ Er ∧ bi = 1] =

Pr[GAi

(6)

= 1 · Pr[GA

i (1λ) = 1 ∧ b ∧ Er]+

+ 1/2 · Pr[GA

i (1λ) (cid:54)= 1 ∧ b ∧ Er] =

= 1/2 · Pr[b ∧ Er] + 1/2 · Pr[GA

i (1λ) = 1 ∧ b ∧ Er] ,

and
Pr[GAi

SEC(1λ) = 1 ∧ Er ∧ bi = 0] =

= 0 · Pr[GA

i−1(1λ) = 1 ∧ b ∧ Er]+

+ 1/2 · Pr[GA

i−1(1λ) (cid:54)= 1 ∧ b ∧ Er] =

= 1/2 · Pr[b ∧ Er] − 1/2 · Pr[GA

i−1(1λ) = 1 ∧ b ∧ Er].
By the independency of b and Er, we have that Pr[b∧ Er] =
1/2 · Pr[Er]. Thus, we evaluate Pr[GAi
SEC(1λ) = 1] according
to (6) as
Pr[GAi

i (1λ) = 1 ∧ b ∧ Er]−

SEC(1λ) = 1] = 1/2 + 1/2 · (Pr[GA
− Pr[GA

i−1(1λ) = 1 ∧ b ∧ Er]) .

Therefore by (5), Pr[GAi
which contradicts Theorem 3.

SEC(1λ) = 1] ≥ 1/2 + α(λ)/4N λγ,

