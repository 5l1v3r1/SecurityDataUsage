Intention and Origination: An Inside Look at Large-Scale Bot Queries

Junjie Zhang∗

Wright State University
junjie.zhang@wright.edu

Yinglian Xie

Microsoft Research
yxie@microsoft.com

Fang Yu

Microsoft Research

fangyu@microsoft.com

David Soukal

Microsoft Corporation
dsoukal@microsoft.com

Wenke Lee

Georgia Institute of Technology

wenke@cc.gatech.edu

Abstract

Modern attackers increasingly exploit search engines as
a vehicle to identify vulnerabilities and to gather informa-
tion for launching new attacks. In this paper, we perform a
large-scale quantitative analysis on bot queries received by
the Bing search engine over month-long periods. Our anal-
ysis is based on an automated system, called SBotScope,
that we develop to dissect large-scale bot queries. Specif-
ically we answer questions of “what are the bot queries
searching for?” and “who are submitting these queries?”.
Our study shows that 33% of bot queries are searching for
vulnerabilities, followed by 11% harvesting user account
information. In one of our 16-day datasets, we uncover 8.2
million hosts from botnets and 13,364 hosts from data cen-
ters submitting bot queries. To the best of our knowledge,
our work is the ﬁrst large-scale effort toward systematically
understanding bot query intentions and the scales of the ma-
licious attacks associated with them.

1 Introduction

As an indispensable service, search engines play an im-
portant role in our daily life. Unfortunately, a signiﬁcant
portion of the queries to search engines are bot queries that
are generated by automated scripts and this volume contin-
ues to grow (at least 4.16% of search engine users are bots
according to [17]). While previous work has focused on ac-
curately detecting bot queries [14, 17], little attention has
been devoted to understanding the nature of these queries.
A natural question is “what are these bot queries searching
for and who are submitting these queries?”.

Motivated by recent observations that many bot queries
are associated with malicious activities such as searching

∗Work performed while at Microsoft Research Silicon Valley and the

Georgia Institute of Technology.

for vulnerabilities [20] or performing Search Engine Op-
timization (SEO) attacks [19], we perform a quantitative
analysis of bot queries at a large scale. We believe that
such analysis is important for understanding both the na-
tures of bot queries and the scales of the related attacks. It
can beneﬁt many security applications. For example, pre-
cisely identifying vulnerability-searching queries provides
valuable information on the newest security leaks and helps
discover zero-day exploits [20, 22]. In addition, detecting
hosts that constantly search trendy keywords or pharma-
ceutical topics provides opportunities to uncover blackhat
SEO attacks that attempt to boost the ranks of malicious
web sites [23]. Finally, detecting distributed, coordinated
bot queries can help reveal the existence of botnets [11],
their memberships, and their activity patterns.

As a means to this end, we describe a completely auto-
mated system called SBotScope for analyzing bot queries at
a large scale. Different from previous work that focuses on
speciﬁc types of malicious queries that are extracted based
on domain knowledge or using seeds [20], our goal is to
automatically dissect all bot queries in the following two
aspects:

• Query intentions: Instead of investigating every single
raw query, we look for an approach that can abstract
topics that represent the underlying query intentions.

• Query origination: We are interested in analyzing
hosts that submit bot queries, particularly those that
have engaged in coordinated large-scale efforts. Many
of these hosts are associated with botnet activities.

Despite extensive research on mining normal queries,
analyzing bot queries has a number of unique obstacles.
First, attackers adopt various strategies to obfuscate queries
and to increase search coverage. For example, they often
mix truly intended queries with random ones in a session, or
combine stufﬁng words with the real relevant keywords to

diversify them. In addition, different from real user queries,
bot queries usually do not result in any clicks as their pri-
mary purpose is to scrape information. Thus, we cannot
leverage techniques that rely on clicks for understanding
query intentions [8, 9, 6]. Finally, we are faced with a huge
amount of data complexity, as the bot query volume is enor-
mous and the query contents are highly diversiﬁed and con-
stantly evolving.

To analyze bot query intentions, we develop a compact
representation to summarize raw queries as a set of query
patterns. This new representation forms the technical basis
of our analysis. It allows us to hierarchically construct a set
of topic trees that summarize query intentions syntactically
and semantically. This approach captures the invariants of
obfuscated queries, and further reduces the data complexity
by orders of magnitude.

To understand the types of hosts submitting bot queries,
we develop techniques to perform large-scale clustering of
IP addresses and to identify distributed, coordinated query
activities. We leverage topic trees to represent hosts as fea-
ture vectors and explore their temporal and spatial behav-
iors. Since existing work has mostly focused on detecting
spamming botnets, we take a different angle to detect and
analyze a large number of botnets that submit queries.

Putting things together, we make the following contribu-

tions in the paper:

1. Our work is the ﬁrst large-scale effort towards auto-
matically mining bot queries to understand query in-
tentions and origins. We show that this direction of
research can beneﬁt security applications in multiple
ways.

2. We develop a system called SBotScope to perform au-
tomated analysis and measurements. SBotScope can
efﬁciently process billions of bot queries to categorize
query topics and cluster hosts.

3. Applying SBotScope to two large query logs that were
collected across different periods from the Bing search
engine, we perform systematic analysis and present a
set of unique ﬁndings.

Our study shows that a signiﬁcant portion of bot queries
can be attributed to a small number of malicious purposes
despite a diverse set of query intentions among overall bot
queries.
In particular, 33% of bot queries are searching
for vulnerabilities, followed by 11% attempting to harvest
email addresses. The information collected by attackers via
these queries can be used for zero-day exploits and spam-
ming attacks. The remaining intentions range from con-
tent downloading, fashion items, news, tourism and geo-
locations, to pornographic websites, and more.

We also demonstrate how we can leverage the analysis
results of SBotScope to perform in-depth analysis of ac-

tivities from both botnets and data centers. From our two
datasets, we have identiﬁed 8,154,180 and 7,278,295 botnet
IPs, and 13,364 and 19,559 data center IPs. Leveraging data
center hosts to perform dedicated, malicious activities [1]
is an emerging attack trend. Our analysis of coordinated
search behaviors from data centers enables a unique per-
spective to quantitatively study this phenomenon at a large
scale.

Finally, we show that our study can also help detect and
mitigate malicious activities proactively. Using the gener-
ated query patterns, we detect tens of millions of additional
bot queries that currently slip through the radar. These
queries are likely submitted by stealthier hosts that mimic
legitimate user behaviors.

The rest of the paper is organized as follows. Section 2
reviews related work. Section 3 presents the system design,
followed with experiment results in Section 4. Section 5
presents two example applications of SBotScope. Section 6
discusses attacker counter strategies and future work. We
conclude in Section 7.

2 Related Work

There have been extensive studies on search queries for
improving both search result rankings and user experience.
To date, most research efforts in this ﬁeld have focused on
analyzing real user generated search queries (e.g., [16, 29,
21, 8, 9, 6, 27, 18]) so that we can better understand normal
user intentions and improve query auto-suggestions.

While studying real user queries is important, we can-
not ignore bot queries. Doing so may result in inaccurate
statistics and polluted analysis results. Further, as the vol-
ume of bot queries continues to rise, they may deplete the
resources of search engines, resulting in signiﬁcant perfor-
mance degradation for normal users. In this regard, previ-
ous work has proposed a few systems to more accurately
detect bot queries [14, 15, 17]. For example, Buehrer et al.
leveraged a supervised learning method [14, 15] and Kang
et al. [17] adopted a semi-supervised learning method for
detection.

Comparatively, little attention has been devoted to sys-
tematically understanding bot queries and studying their
broad implications to security. Various recent evidences
suggest that bot queries are often submitted from infected
hosts from botnets [13]. They may also be submitted by
attackers to collect information for a variety of malicious
uses, such as targeted exploits, spamming, search engine
optimization, and click frauds [26, 25, 7]. For example,
a recent study shows that attackers submit queries to look
for known vulnerabilities posted in underground web fo-
rums [20]. A separate study ﬁnds that attackers query trendy
keywords in order to scrape contents from highly-ranked

web sites and use them for promoting the rankings of mali-
cious web sites [19].

With a massive number of sophisticated, actively evolv-
ing bot queries, a system that automatically summarizes and
dissects bot queries can bring in a lot of value to security.
Unfortunately, such a system is still in absence. As a result,
the extent to which attackers have been exploiting search
engine results remains largely unclear. Our work focuses
on this new research problem, where we develop a system
and perform strong quantitative analysis of bot queries to
understand their intentions and the scales of malicious at-
tacks associated with them on the Internet.

Compared with existing techniques on analyzing normal
query intentions, our system differs in many important as-
pects. First, unlike [8, 16, 21], our system does not use
click-through data since the majority of bot queries do not
result in any clicks. Second, in contrast to [29, 27], our sys-
tem does not depend on the availability of labeled data. Fi-
nally, different from [6, 9], our system does not need exter-
nal sources of information, such as query-to-topic mapping
functions based on Wikipedia.

Indeed, bot queries exhibit disparate characteristics com-
pared to normal user queries, which make the approaches
for analyzing normal queries not applicable to our study.
First, both the labeled data and the query-to-topic mappings
are relatively easier to obtain for normal queries than for bot
queries. Compared with bot queries, the set of topic cate-
gories for normal queries are more stable, so they can often
be derived manually. In addition, normal query intentions
are more directly tied to the set of keywords in queries, as
the purpose of normal users is to hit the relevant contents
as fast as possible. In contrast, bot queries are more dy-
namic and their contents largely depend on the current se-
curity vulnerabilities and attack trends. The keywords in bot
queries are more obscure in order to evade detection. They
are also designed to increase the search result coverage with
stufﬁng words. Such vast difference characteristics between
normal and bot queries suggest that we cannot directly ap-
ply techniques for mining normal query intentions to ana-
lyze bot queries, but instead need to develop a customized
system for our purpose.

3 The SBotScope System

Our goal is to analyze bot query intentions and origina-
tion by analyzing search logs automatically. Given the sheer
volume of query records, manual investigation is infeasible.
We need to develop a system to support such large-scale
analysis on a regular basis.

Our system, SBotScope is designed to perform off-line
analysis of search logs. It relies on existing bot query de-
tection systems to generate bot query feeds for analysis. We
assume that a large number of bot queries have been labeled

Field
IP

T ime
Query

U A

F orm

Description
IP address
Time stamp
Query content
Hash value of the User-Agent string
Hash value of the query API

Ref errer Hash value of the Referrer string

Click
isBot

Whether any search result is clicked
Whether it is detected as a bot query

Table 1. Fields in a search query record

Month

Data
D1 May,2011
Oct,2011
D2

# of days

16
16

# of IPs

12,687,346
12,207,937

# of Bot Queries
3,057,549,724
3,198,810,465

Table 2. Datasets

by existing detection systems with a reasonable accuracy.
Our system serves as a monitoring tool to discover query
intentions, identify groups of bots performing coordinated
search behaviors, and categorize queries accordingly. The
output of SBotScope can be used in multiple ways. The
categories and the statistics of query intentions can serve as
input to security analysts for discovering new attack trends.
The set of botnet and data center IP addresses can be used
to block future attacks and to monitor attack scales. Finally,
the output of SBotScope can also help detect additional bot
queries that evade the existing detection systems.

In this section, we present the design of SBotScope in de-
tail. We ﬁrst describe our datasets, the challenges involved,
and the system architecture. We then present the detailed
data-processing ﬂow.

3.1 Datasets

We obtain sampled data collected from the Bing search
engine during two different periods. Table 1 shows the
ﬁelds recorded for each query. Among these ﬁelds, the ﬁrst
seven ﬁelds are directly extracted from a query upon its ar-
rival at the search engine. The last ﬁeld “isBot” indicates
whether this query is classiﬁed as a bot query by the current
detection system, which mainly leverages an extensive set
of features derived from query behaviors, e.g., the number
of queries in a search session and the number of web pages
visited from the user.

Table 2 shows the statistics of the datasets. Each dataset
spans across roughly a two-week window, where we ob-
serve more than 3 billion detected bot queries, submitted
from over 12 million unique IP addresses around the globe.
The published privacy policies for this search engine ad-
dress the storage, use, sharing, and retention of data col-
lected in the course of the operation of these services. Our
use of data is in compliance with these policies.

Pattern Generation

Topic Analysis

Normal 
Search 
Queries

Query Pattern 

Generation

Pattern Tree 
Construction

Topic Clustering

Bot Search 

Queries

Host 

Representation

Feature Vector 

Generation

Host Clustering 
and Classiﬁcation

Host Analysis

Figure 1. System Overview

3.2 Challenges and System Overview

The ﬁrst challenging question of our analysis is how to
represent query intentions. One popular approach, taken
by normal query intention analysis [8, 9, 6], is to leverage
the clicked search results. For example, given two different
queries, if users always click the same set of result URLs,
it is a strong indication that these two queries share simi-
lar intentions. However, such an approach is not applicable
in our case because the vast majority of bot queries do not
result in any clicks.

The exact raw query is another natural way to describe
the underlying intention. This approach is also difﬁcult as
attackers often obfuscate queries or mix irrelevant queries
with truly intended ones. Table 3 shows an example of a
bot-query session 1.
In this case, attackers not only add
stufﬁng words, e.g., “unled” and “cheap mini”, to increase
their query diversity, but also add popular queries such as
“facebook.com” and “bing.com” to make their query ses-
sion look more legitimate. The real intentions of these
queries are looking for vulnerable web sites powered by cer-
tain versions of software.

Intuitively, to capture intentions, we would like to derive
the invariant portions of the queries with truly relevant key-
words and randomly inserted stufﬁng words. Toward this
goal, we derive a set of query patterns in terms of invariant
keywords to represent raw queries in a more compact for-
mat (see Section 3.3). The use of patterns also dramatically
reduces the complexity of our analysis. Furthermore, we
aggregate query patterns into a small set of topic trees that
summarize query intentions both syntactically and semanti-
cally. This step allows human users or security analysts to
conveniently examine the composition of queries.

The second question is how to represent hosts and iden-
tify their correlated activities, especially when the volume
of query records is huge. As Table 2 shows, each of our
datasets contains billions of queries and the total volume

1We use the term “session” to loosely refer to a set of consecutive

queries issued from one IP address within a short duration.

unled “powered vbulletin version 3.8.6”
cheap mini “powered vbulletin version 3.8.4”
discussion “powered vbulletin version 3.8.7”
facebook.com
forum “powered vbulletin remove”
bing.com
email “powered vbulletin music”

Table 3. An example bot-query session

of data is on the order of terabytes. Therefore, our system
needs to effectively reduce data complexity and ﬁlter noise
to study query origins.

To address this challenge, we construct feature vectors
that represent hosts in a low dimensional subspace. It fur-
ther aggregates hosts that share similar query patterns into
clusters for analysis. Speciﬁcally, we implement a paral-
lel version of the single-linkage hierarchical clustering al-
gorithm [24] that enables us to perform host clustering in
a fully distributed fashion. SBotScope then classiﬁes host
clusters based on their temporal and spatial behaviors. This
approach allows us to perform in-depth analysis of queries
submitted from botnets and data centers separately.

To summarize, Figure 1 shows the architecture overview
of the analysis performed by SBotScope. We describe the
details next.

3.3 Pattern Generation

We would like query patterns to capture only the invari-
ant portions of queries and remove irrelevant stufﬁng words.
In doing so, it is important to avoid extracting popular com-
binations of stopwords (e.g., “of”, “the”) as well as com-
mon, popular queries such as “facebook.com”.

To capture the above intuition, we deﬁne a query pattern
as a speciﬁc word-combination (or query) that occurs fre-
quently among bot queries. By “speciﬁc”, we require the
pattern to contain useful information, so that to avoid se-
lecting over-general patterns, such as those of stopwords.

 
f

 

o
n
o

i
t
c
a
r
f
 

e
v
i
t

l

a
u
m
u
c
 
e
h
T

s
n
o

i
t

i

a
n
b
m
o
c
 
d
r
o
w

1

0.8

0.6

0.4

0.2

 

0
0

 

1−Word Comb
2−Word Comb
3−Word Comb
4−Word Comb

5

10

Entropy

15

20

25

Figure 2. The distribution of entropy for fre-
quent word-combinations with certain length

By frequent, we require a pattern to be the common, in-
variant portion of a large number of queries. Finally, we
consider word-combinations instead of query sub-strings or
regular expressions to prevent attackers from manipulating
word orders or query formats to defeat our analysis.

3.3.1 Selecting Frequent Patterns

The “frequent” notion can be naturally quantiﬁed using
the pattern frequency. Without loss of generality, we con-
sider both frequent word combinations and frequent exact
queries. Since we ﬁnd that majority (95%) of the bot queries
contain at most four words, we consider all possible word
combinations up to length 4 for each query. Then for every
length (i.e., 1, 2, 3, and 4), we select the top 0.1% com-
binations that occurred across the most number of unique
queries. After this process, there are still some frequent ex-
act queries that are not covered by popular word combina-
tions. For such cases, we also select frequent exact queries
(i.e., top 0.1%) as potential patterns.

3.3.2 Selecting Speciﬁc Patterns

Once we identify frequent patterns, we proceed to select
speciﬁc ones using the following two metrics:

• Information gain G(wi) quantiﬁes the amount of in-

formation contained in a pattern wi:

G(wi) = E(Q) − E(Q|W = wi)

where E(Q) is the entropy for all bot queries, and
E(Q|W = wi) is the conditional entropy of bot
queries matching pattern wi. Since E(Q) is a con-
stant for the same set of queries Q, G(wi) can simply
be evaluated by E(Q|W = wi). The smaller the con-
ditional entropy, the larger the information gain is, and
hence the corresponding pattern is more speciﬁc. In

the exact query case, the pattern is the entire query it-
self, so the information gain is the maximum value of
E(Q).

• Historic

among

normal

popularity

queries
cnormal(wi):
it refers to the number of unique
IP addresses that submitted normal queries matching
pattern wi. The intuition is that a very speciﬁc bot
query is less likely to be a popular query among
a large number of normal users. A higher value
of cnormal(wi), means the pattern is not distin-
guishing; we ﬁnd that many of them are used for
obfuscating sessions or testing connectivity (e.g.,
“facebook.com”).

Figure 2 presents the conditional entropy E(Q|W = wi)
distribution for frequent patterns of different lengths (we ex-
clude exact query patterns). As shown in the ﬁgure, patterns
with more words tend to have smaller conditional entropy,
since they are naturally more speciﬁc (i.e., containing more
words). Based on these two metrics, SBotScope selects spe-
ciﬁc patterns if wi satisﬁes either of the following condi-
tions:

• E(Q|W = wi) falls in the bottom 90% of entropy for

all popular word combinations with the same length.

• cnormal(wi) is smaller than a certain threshold 1, 000.

We use these two conditions to eliminate over general
patterns or patterns that are popular among normal user
queries.

Note that given a set of patterns, a query may match mul-
tiple of them and contribute to all their frequencies. For
each query, to avoid generating multiple redundant patterns,
we select only the most speciﬁc pattern to represent it (i.e.,
we favor the pattern that has the smallest conditional en-
tropy). After the above pattern generation process, we can
dramatically reduce the data complexity by several orders
of magnitude, from 109 queries to 105 patterns.

3.4 Topic Analysis

The topic analysis step is where we further analyze
query patterns to identify semantically meaningful topics.
Patterns represent the prominent syntactic features of raw
queries, but different patterns may still correspond to the
same or similar intentions. For example, “auto” and “car”
are very different words, but they all correspond to similar
topics and our goal is to uncover the hidden semantic corre-
lations among them.

One potential approach to recognize semantically similar
patterns is to use dictionaries. However, as bot queries are
written in various languages, it is challenging to parse each

"powered"

Data
D1
D2

# of IP-Segments

14,856,347
14,350,435

"powered, smf"

"vbulletin,  powered"

Table 4. The number of “hosts” in two differ-
ent data sets.

"powered, smf,

"powered, smf,

version"

proﬁle"

"vbulletin, 
powered,
version"

"vbulletin, 
powered,
music"

"vbulletin, 
powered,
forum"

Figure 3. An example pattern tree

query and understand it semantically. In our work, we adopt
a simple yet effective process that includes two steps. The
ﬁrst step aggregates patterns hierarchically to construct a
set of pattern trees. The goal is to further reduce the pattern
complexity syntactically. The second step performs clus-
tering on the pattern trees to identify semantically coherent
topics.

3.4.1 Pattern Tree Generation

This step aggregates patterns based on shared common
words. We take a bottom-up approach and treat each in-
put pattern as an individual node. The tree construction
starts with merging the longest patterns with length K if
they share K − 1 common words. The merged pattern is
represented as a new parent node of the corresponding leaf
pattern nodes. This process repeats until all the top-level
tree nodes represent 1-word patterns and thus cannot be fur-
ther aggregated. Figure 3 shows an example pattern tree
constructed using this process. All the patterns on this tree
share the common word “powered”, and they may all be is-
sued to discover certain vulnerabilities. In particular, lower
level siblings are more strongly correlated, as they share
more common words than nodes in higher levels. In our
experience, this step can further reduce hundreds of thou-
sands of patterns to roughly two or three thousand pattern
trees.

3.4.2 Topic Clustering

This step groups pattern trees to identify their semantic cor-
relations. We use the probability of word co-occurrence to
model such correlations. For example, the word “auto” and
“car” may both co-occur with keywords such as “Toyota”
or “dealership”, which can link the two concepts together
into one group.

Speciﬁcally, we focus on only the top-level nodes. Given
two top-level pattern tree nodes with word w1 and w2, we
use a similarity score s(w1, w2) to measure their correla-
tion. We ﬁrst identify the two sets of queries Q1 and Q2

that contain word w1 and w2, respectively. We then com-
pute the similarity score in terms of the Jaccard distance
between Q1 and Q2:

s(w1, w2) =

|Q1 ∩ Q2|
|Q1 ∪ Q2|

With the similarity scores, we essentially obtain a graph
of pattern trees, with each tree becoming a super node in the
graph. The similarity scores serve as edge weights. Given
the graph is reasonably small (with a few thousands of
nodes), we perform spectral clustering [12], the best graph-
cut algorithm, to identify tightly connected subgraphs. Each
subgraph intuitively corresponds to a query topic.

The number of topics can be a pre-conﬁgured parameter
to control the granularity of topics (i.e., coarse-grained cat-
egorizations vs. detailed classiﬁcation). In our current sys-
tem, we pick the number of topics to be 50, which allows
security analysts or search engine operators to manually in-
spect the results.

3.5 Host Analysis

The host analysis step answers the question of “who sub-
mitted bot queries?”. We are interested in identifying and
separating data center hosts from botnet hosts, which we
ﬁnd are the two dominant cases. The infrastructures of
these two categories of hosts are drastically different, so
their query behaviors and contents may also differ radically.
Such a study could yield in-depth understanding to attacker
strategies and attack scales. In our analysis, we group hosts
with similar query behaviors via clustering.

3.5.1 Host Representation

With DHCP, a host’s IP address may dynamically change.
To mitigate this problem, we use an IP-segment to repre-
sent a host that has been active during a period. We ﬁnd
operating on the coarse-grained time period on the order of
days generates stable results. For example, if we observe an
IP address that submitted bot queries on day1, day2, day3,
and day5, then we use two IP-segments to represent the two
“hosts” that issued these queries: IP-segment1 ={IP: day1,
day2, day3} and IP-segment2 = {IP: day5}. We apply this
method to the two data sets to obtain hosts. The number
of hosts are similar across two data sets as presented in Ta-
ble 4. Furthermore, the number of such deﬁned “hosts” is

"powered"

"vbulletin, 
   powered"

host: H1

"powered"

20

1

"vbulletin, 
   powered"

19

1

1

1 1

...

1

host: H2

"powered"

20

"vbulletin, 
   powered"

20

"vbulletin, 
powered,
version"

"vbulletin, 
powered,
music"

"vbulletin, 
powered,
forum"

10 10

0

0

"vbulletin, 
powered,
version"

"vbulletin, 
powered,
music"

Figure 4. An example of generating feature
vectors

close to the number of unique IP addresses in Table 2, which
implies that the vast majority of the IP addresses are either
active on one day or active on consecutive days.

3.5.2 Feature Vector Generation

With the deﬁnition of “hosts”, we construct a feature vector
to represent each host. One straightforward solution is to
deﬁne the feature vectors in the original query space, where
each unique raw query is one dimension. Given that the
sheer volume of unique bot queries is huge, this option will
be prohibitively expensive in practice.

Instead, we leverage the derived pattern trees, which is
much more compact than raw queries. For each host H rep-
resented by an IP-segment, we match all of its bot queries
against the patterns on the trees starting from the root nodes,
using the following steps:

1. SBotScope ﬁrst produces a set of subtrees T (H) where
all the patterns on the subtrees match the queries from
host H.

2. For each node n on T (H), SBotScope additionally
records the number of queries from H matching n as
c(n).

3. SBotScope then prunes T (H). For an edge a → b on
T (H), if c(a) >> c(b) (we consider c(a) >> c(b) if
log10(c(a)) >= log10(c(b)) + 1), then a is a represen-
tative pattern for H while b is not. So we remove the
subtree rooted at b.

Finally, we pick the set of leaf nodes on the pruned sub-
trees to serve as features for describing H. The total num-
ber of dimensions in the feature vector space is the num-
ber of unique pattern nodes selected across all hosts. Fig-
ure 4 presents an example. In this example, H1 generates

20 queries and has matching count c(“powered”) = 20 and
c(“vbulletin, powered”) = 19. The remaining nodes match
only one query from H1. Therefore, we pick “vbulletin,
powered” as a feature to describe H1. For another host H2,
we pick “vbulletin, powered, version” and “vbulletin, pow-
ered, music” as two features to represent H2.

This step is critical as it signiﬁcantly reduces the feature
vector dimensions from billions of raw queries to only tens
of thousands of features (e.g., 27,507 for D1 and 37,843
for D2). More importantly, the feature vectors describe not
only the distinguishing local query contents of each host,
but also the global correlations among different query pat-
terns.

3.5.3 Host Clustering

With a feature vector to represent a host, we can group hosts
into clusters and classify their types based on the aggregated
behaviors of each group. This approach has two advantages
than directly analyzing individual hosts. First, it allows us
to identify correlated or coordinated query behaviors that
cannot be observed in isolation. Second, it is robust to in-
dividual host outliers as we rely on group behaviors rather
than host behaviors to perform classiﬁcation. Thus, we are
able to differentiate hosts even though some of their activi-
ties are atypical and are difﬁcult to classify otherwise.

To perform host clustering, we apply the single-linkage
hierarchical clustering algorithm [24] using the Jaccard dis-
tance of feature vectors:

dist(H1, H2) = 1 −

|F1 ∩ F2|
|F1 ∪ F2|

where F1 and F2 represent the set of features for H1
and H2 respectively. If the Jaccard distance of two hosts
is smaller than a pre-deﬁned threshold (e.g., 0.3), we ag-
gregate two hosts into one cluster. We choose the single-
linkage hierarchical clustering algorithm instead of the pop-
ular K-Means algorithm [10] because it does not need to
predetermine the number of clusters beforehand. In addi-
tion, it enables parallel implementation in a fully distributed
fashion on a computer cluster. In the current implementa-
tion, we keep a cluster if it includes at least 10 hosts.

3.5.4 Cluster Classiﬁcation

To answer the question of what types of hosts are from these
clusters, we classify the group behaviors. Two distinguish-
ing categories of hosts are botnets and data center hosts. A
botnet is a collection of compromised machines performing
malicious activities.
Identifying botnets helps categorize
queries with malicious intentions. The behaviors of botnet
hosts are usually bursty in time [30]. Their IP addresses are
widely distributed across a large number of networks. In
contrast, data center hosts are long-lived, well-maintained

machines for dedicated tasks. Their IP addresses usually
belong to a small number of administrative domains.

We explore both the temporal and spatial characteristics
of hosts to classify a cluster. The temporal behaviors de-
scribe the persistence of the automated search behaviors,
while the spatial behaviors describe the distribution of host
IP addresses across the Internet. To quantify the spatial be-
haviors of a cluster, we use the ratio of the number of unique
/24 preﬁxes over the number of unique IP addresses in a
cluster, deﬁned as r. Speciﬁcally, r = num of /24 pref ixes
.
num of IP s
We use the following two criteria in our classiﬁcation:

1. If the majority (90%) of hosts in a cluster are active
for only a short period (≤ 3 days) and the host IP ad-
dresses are widely distributed (r ≥ 0.7), we classify
this cluster as a likely botnet cluster.

2. If the majority (90%) of hosts in a cluster are long-
lasting (≥ 10 days) and the IP addresses are from a
small number of different networks (r ≤ 0.3), we clas-
sify the cluster as likely a data-center cluster.

This step cannot classify all host clusters, but it does
identify groups with well-known, distinguishing behavior
patterns. Only a small percentage of clusters (around 4%)
cannot be classiﬁed using our approach.

4 Measurement Results

We apply SBotScope to the two datasets described in Ta-
ble 2 (see Section 3). We present our experiment results in
this section.

4.1 Query Intention Analysis

Query Patterns

Datasets

(word-combinations)

D1
D2

361,568
370,338

Query Patterns
(exact queries)

364,405
593,349

Table 5. The number of patterns derived from
each dataset.

The Pattern Generation process is our technical basis for
deriving query intentions. Table 5 shows that this step re-
duces the data from over 3 × 109 raw queries to fewer than
106 query patterns. These patterns can be further aggre-
gated into 1,823 and 3,499 pattern trees for dataset D1 and
D2, respectively.

After further grouping pattern trees into semantically
correlated topics, we examine the compositions of query
intentions in detail. Table 6 presents the top 6 most pop-
ular topics as well as the top 5 query patterns that match the

Query Patterns
powered by photo album

powered by update

powered by icalendar

Vulnerability
PHP Album 0.3.2.3
Remote Command Execution
PHP-Update 2.7
Remote Code Execution
PHP iCalendar 2.24
File Upload

Table 7. Example vulnerabilities derived from
query patterns

Data
D1
D2

# of clusters

% of queries

% of clusters validated

39,037
47,217

90.30%
82.18%

82.96%
85.89%

Table 8. Clustering Results

most number of queries under each topic. Previous work
has suggested the use of bot queries for searching for vul-
nerabilities. Indeed, we ﬁnd vulnerability-searching queries
are the dominant category, corresponding to almost 1/3 of
all bot queries. The second most popular topic (around 11%
of bot queries) is about searching for email addresses or user
accounts, which include critical information for attackers to
perform spamming or account hijacking attacks more effec-
tively. The next four popular categories are used for con-
tent downloads, fashion items (e.g., handbags, cloths, and
watches), car sales, and news.

Investigating further into the vulnerability searching
queries, we ﬁnd that this topic includes 170 pattern trees and
7,295 query patterns. Figure 5 shows three example pattern
trees under this topic. A majority of query patterns in this
category contain keywords that are known to be related to
vulnerabilities such as “php”, “yabb”, “powered”, “topic”,
“forum”, “thread”, “board”, and “vbulletin” [20]. In partic-
ular, both “powered” and “php” are popular words with a
large number of subtrees under each of them. These exam-
ples demonstrate the effectiveness of SBotScope in identi-
fying semantically correlated patterns even when they are
not strongly connected syntactically (i.e., they do not share
common words). These vulnerability-searching queries
provide information to prevent future attacks. For exam-
ple, Table 7 shows three known vulnerabilities [2] that one
can derive from our query patterns, and we leave it as future
work to further explore this direction.

4.2 Query Origin Analysis

We now examine the query origin distributions and clas-
siﬁcation. After performing the host clustering analysis de-
scribed in Section 3.5, we obtain in total 39,037 and 47,217
clusters for dataset D1 and D2, respectively. As indicated
in Table 8, these clusters contain 90% and 82% of all bot
queries, suggesting that a vast majority of bot queries are
generated from coordinated hosts.

Topic

% of Queries

Vulnerability Discovery

32.8%

Email Harvest

11%

Content Download

3.6%

Fashion Items

1.4%

Car Sale

1.3%

News

0.7%

Top 5 Patterns
list members mode php
mode php register
es php page
aspx html php
powered by
yahoo.cn email
163.com email
21cn.com email
sina.cn email
163.net email
download free ﬂash
free games online
coupons online
games play
movie trailer
replica handbags
designer handbags
Black Footwear Leather
clothing store
buy digital watches
accord honda used
dealer used ford
dealer used mercedes
dealerships used hyundai
dealerships used vw
fox live news
10 channel news
dallas morning news
2011 latest news
celebrity gossip

Query Samples
debate members mode list php
ucp php mode register
user php page es
X-Powered-By aspx html php
powered by php register
beijing bank email yahoo.cn
beijing food email 163.com
International email 21cn.com
forum email sina.cn
bbs email 163.net
free ﬂash download 2010
free games online adult
coupons online imax california
play games sony psp
movie trailer spring 2011
CA replica handbags cheap
designer online handbags
Nike Black Footwear Leather mini
lady clothing deal store
buy 2010 digital watches
accord honda used GA
dealer used ford USA NY
number dealer used mercedes 98052
dealerships zipcode used hyundai
dealerships used vw online
fox live news 2011
10 channel news 2010 local
dallas morning news april 2011
2011 latest news archive 2010
celebrity gossip photos jpg

Table 6. Top six popular topics and their top ﬁve patterns

We further classify the group temporal and spatial be-
haviors to separate botnet clusters and data center clusters.
We combine all the clusters from dataset D1 and D2, and
plot each cluster as a point in a two-dimensional space in
Figure 6.

The X-axis represents the ratio of the number of /24 net-
work preﬁxes over the number of unique IP addresses in
a cluster, i.e., r in Section 3.5.4. A small ratio means the
majority of hosts in a cluster come from a small number
of network ranges, so the cluster is more likely to consist
of hosts from common administrations. In contrast, a large
ratio in the X-axis suggests that the cluster is more widely
dispersed in the Internet, with each network range having
only a few hosts.

The Y-axis represents the average active periods of a host
(in terms of days) in a cluster. Long-lived clusters are more
likely data center hosts, while transient clusters are more
likely associated with botnet activities.

From the ﬁgure, we observe that the majority of the clus-
ters are transient and have widely distributed IP addresses,
indicating the existence of a large number of botnets. The
density of the points in the ﬁgure drops signiﬁcantly as the
ratio r decreases and the average number of active days in-
creases. We ﬁnd that the number of data center clusters is
relatively small. Applying the heuristics in Section 3.5.4,
we identify in total 37,268 and 44,252 botnet clusters, and
137 and 150 data center clusters from D1 and D2, respec-
tively. Accordingly, we obtain 8,154,180 and 7,278,295 IPs
in botnet clusters, and 13,364 and 19,559 IPs in data center

Figure 6. “avg active days per IP ” v.s.
“ #of /24 pref ixes

” in one cluster

#of IP s

clusters from D1 and D2. Only a small percentage of clus-
ters, 4.2% in D1 and 6% in D2, remain unclassiﬁed, and we
leave them for future studies.

The existence of botnet activities is perhaps not sur-
prising [13], but the prevalence and scale of using botnets
for submitting bot queries are more than we had expected.
These query-submitting botnets represent an important cat-
egory of botnets that are not well studied yet. Their query
contents and behavior patterns will be valuable to analyze
the trends and scales of malicious activities.

Topic: Vulnerability Discovery (170 Pattern Trees)

"php"

74 sub-trees

"powered"

"cgi"

332 sub-trees

13 sub-trees

"mode, php"

20 sub-trees

"index, php"

13 sub-trees

"powered, smf"

324 sub-trees

"vbulletin, 
powered"

175 sub-trees

"list, member,

"ucp, register,

"board, 

"ﬁd, 

mode, php"

mode, php"

index, php"

index, php"

Figure 5. Three example pattern trees for searching vulnerabilities.

The number of data center clusters is also non-trivial.
Apart from legitimate activities from data centers, the ex-
istence of malicious activities from data centers may indi-
cate a new trend, where attackers have started exploiting
cloud-computing or other well-maintained infrastructures
for launching attacks.

4.3 Cluster Validation

The quality of the identiﬁed clusters and their classiﬁ-
cation could be a concern due to the unsupervised nature
of our clustering process. Ideally, we would like to obtain
the ground-truth information regarding botnet memberships
and data center usages. Nevertheless, it is extremely hard,
if not impossible, to build such ground-truth in practice.

In the lack of ground-truth, we adopt the following three
methods to sanity check our results. First, we evaluate the
quality of clustering using the extra ﬁelds presented in Ta-
ble 1. Intuitively, if a host group was correctly identiﬁed,
they may exhibit similar behaviors in choosing ﬁelds such
as U A, F orm, Ref errer, as they all use the same script.
Second, we perform Whois [5] lookups to examine the
names and the types of the ASes that correspond to different
types of clusters. The purpose is to validate whether botnet
hosts indeed mostly correspond to consumer networks, and
whether data center hosts indeed belong to well known data
center networks or hosting services. Third, we compare our
botnet host lists with those derived from the Conﬁcker IP
address lists in [28] by their courtesy.

4.3.1 Cluster Behavior Similarity Analysis

For each cluster, we examine whether the majority of its
“hosts” have identical ﬁeld values. For each host H, we ﬁrst
pick its dominant values for U A, F orm, and Ref errer.
We then consider these metrics for both the queries match-
ing patterns as well as the queries not matching any patterns.

 
s
r
e
t
s
u
C

l

 
f
o
 
e
g
a
t
n
e
c
r
e
P

d
e
t
a
d

i
l

a
V

0.5

0.4

0.3

0.2

0.1

0

1

2

3

Number of Metrics Verified

4

5

6

Figure 7. Percentage of clusters sharing iden-
tical metrics.

In total, we have six metrics. We then compute the percent-
age of a cluster sharing identical values for these metrics.
For each metric, we also consider the case where each host
randomly chooses a different ﬁeld value (e.g., by adopting
randomization strategies to evade detection). In this case,
we set the value of the corresponding ﬁeld to “random” if
its values exhibit complete randomness.

Figure 7 shows the distribution in terms of the number
of metrics on which a cluster shows strong consistency (i.e.,
90% of hosts in this cluster share an identical value). Over-
all, 82.96% clusters from D1 and 85.89% clusters from D2
share at least one identical metric. A large percentage of
clusters have all six values identical across hosts. These are
strong indications of coordinated behaviors.

4.3.2 Host Network Type Analysis

As botnet and data center clusters usually come from dif-
ferent network regions, we reverse lookup the autonomous
system number (i.e., AS number) for each IP address. In ad-
dition, we perform Whois [5] lookups on the AS numbers,
and examine the names and the types of networks.

Table 9 lists the top ﬁve most popular AS names for both
types of clusters. We observe that botnet clusters include
mainly hosts from residential broadband ISPs and consumer

ASN
4134
8151
3269
27699
4837

ASN
15003
36351
25973
21788
13647

botnet type

Country
CN
MX
IT
BR
CN

AS Name
CHINANETBACKBONE
Uninet S.A. de C.V.
ASN-IBSNAZ
TELECOMUNICACOES
CHINA169-BACKBONE

data center type
AS Name
NOBISTECH
SOFTLAYER
GTT
NOC
TRANQUIL-HOSTING

Country
US
US
US
US
US

Table 9. Top 5 ASes for both types of clusters

IP/Preﬁx

IP

/24 Preﬁx

% in the Conﬁcker Botnet
11.29%
72.75%

Table 10. Percentages of botnet IPs/preﬁxs in
the top 5 ASes that appear in the Conﬁcker
botnet

access networks, while data center clusters mainly consist
of hosts from cloud computing or hosting service infrastruc-
tures. For example, NOBISTECH [3] and SOFTLAYER [4]
are two large service providers that provide hosting services
and data center services.

4.3.3 Comparison with Known Botnet Hosts

We also compare our botnet IP address list with the set of
known Conﬂicker bots derived using methods from [28] by
their courtesy. We ﬁnd that all the top ﬁve popular ASes
in our botnet clusters are the exact same set of popular
ASes for Conﬁcker bots. We also compare the IP addresses
from the top 5 ASes (see Table 9) in our botnet clusters to
the known Conﬁcker IP address set. Table 10 shows that
11.29% of the botnet IPs identiﬁed by SBotScope overlap
with the set of known Conﬁcker IPs, and 72.75% of the bot-
net IPs fall into the set of known /24 Conﬁcker IP preﬁxes.
This result suggests that the subset of botnet hosts that over-
lap with Conﬂicker bots are indeed correctly identiﬁed and
classiﬁed.

4.4 Comparing Botnet and Data Center Query

Activities

The categorization of query contents and host types al-
lows us to perform comprehensive analysis and compar-
isons on the query intentions and the network infrastruc-
tures from botnets and data centers.
In this section, we
quantitatively study the different behaviors and intentions
from these two types of hosts.

Botnet clusters
php
download
powered
email
pdf
email
php
topic
download
blog

Data center clusters
black
light
gold
video
bank
certiﬁed
ﬂights
car
shirt
adult

D1

D2

Table 11. Popular keywords in the patterns

4.4.1 Comparison on Search Behaviors

We ﬁnd that the search contents and behaviors of the two
types of clusters are drastically different. Table 11 sum-
marizes the most popular words in the query patterns from
different types of clusters. We ﬁnd that botnet clusters
mainly focus on discovering vulnerabilities (e.g., using
word “php”, “powered”, “pdf”), searching for email ad-
dresses and user account information (e.g., “email”), and
looking for free content downloads (e.g., “download”). In
contrast, data center clusters focus more on looking for
commercially relevant information using keywords related
to apparel and entertainment.

# of clusters
# of IP-segments
# of IPs
avg # of IPs/cluster
# of queries
avg # of queries/IP
avg # of patterns/cluster

botnet type
37,268
8,355,098
8,154,180
219
2,278,143,556
279
148

data center type
137
13,853
13,364
98
101,638,148
7,605
4,208

Table 12. Host activity summary for dataset
D1

# of clusters
# of IP-segments
# of IPs
avg # of IPs/cluster
# of queries
avg # of queries/IP
avg # of patterns/cluster

botnet type
44,252
7,423,261
7,278,295
164
1,444,931,738
198
166

data center type
150
20,099
19,559
130
198,903,861
10,169
3,121

Table 13. Host activity summary for dataset
D2

Besides different query contents, we also observe distin-
guishing activity patterns. Table 12 and 13 summarize the
statistics of the host activities from dataset D1 and D2. We
ﬁnd that the results are consistent over time. Overall, botnet
clusters include more IP addresses and submit an order of
magnitude of more queries in total than data center clusters.
In contrast, data center hosts are usually long-lived; each

host submits more queries on average, with a larger number
of query patterns per cluster.

4.4.2 Comparisons on Network Infrastructures

We then analyze the network infrastructures used by the
two different types of clusters. The number of botnet clus-
ters clearly dominates among the results. SBotScope identi-
ﬁes 37,268 botnet clusters and only 137 data center clusters
from dataset D1. Similarly, it identiﬁes 44,252 botnet clus-
ters and 150 data center clusters from dataset D2.

IP addresses in May, 2011 overlap with the botnet IP ad-
dresses in October, 2011.

To summarize, our ﬁndings indicate that botnet is a pop-
ular means for attackers to gather vulnerabilities and other
information from search engines. The majority of the bot
queries come from botnets on a global scale. Bot queries
from data centers are of mixed categories. We observe both
queries that are triggered by real users as well as malicious
queries. The appearance of data center hosts performing
malicious activities is a relatively new trend and deserves
futher study.

1

0.8

0.6

0.4

0.2

n
o
i
t
c
a
r
f
 
e
v
i
t
a
l
u
m
u
c

s
r
e
t
s
u
l
c
 
f
o

 

e
h
T

0
 
0

Botnets
Data Centers

0.2

0.1
0.9
Maximum percentage of IP addresses from one AS

0.5

0.3

0.4

0.6

0.7

0.8

 

1

Figure 8. Distribution of the maximum per-
centage of IP addresses from one AS for each
cluster

We ﬁnd that hosts in a data center cluster are more likely
to be from the same organization, perhaps due to the lower
costs and efforts in comparison to the case of renting hosts
from many organizations. We reverse look up the AS num-
ber for each IP address in data centers clusters. We ran-
domly pick 1000 botnet clusters (since the number of botnet
clusters is signiﬁcantly more than the number of data center
clusters) and look up the AS numbers for all of their hosts.
For each cluster, we identify the AS with the most num-
ber of hosts and compute the percentage. Figure 8 presents
the corresponding distribution. More than 90% data center
clusters have a large fraction of hosts (≥ 75%) hosts coming
from the same AS. In contrast, less than 5% botnet clusters
have a dominant AS with over 50% of their hosts.

Botnet IPs
Data center IPs

D1 D1 ∩ D2
489,251
4,544

8,154,180
13,364

% of persistent IPs
6%
34%

Table 14. Host overlap across time

In addition, we also compare the set of classiﬁed IP ad-
dresses across the two datasets collected from different pe-
riods. We ﬁnd that data center hosts are much more stable
over time. As presented in Table 14, for data center IP ad-
dresses that appeared in May, 2011 (D1), 34% of them were
still active and also belong to the data center clusters in Oc-
tober, 2011 (D2). As a comparison, only 6% of the botnet

5 Case Studies and Applications

In this section, we perform in-depth analysis on the in-
tentions and the origins of botnets and data center clusters
using three case studies. From these case studies, we show
how one can derive different attack phases, identify the pre-
cise botnet memberships, and uncover the exact vulnerabil-
ities targeted by attackers.

One application of SBotScope is to leverage the derived
query patterns for detecting bot queries that slipped through
the radar. To our knowledge, all existing bot-query detec-
tion systems rely on host (or user) behaviors or IP address
information for detection. None of them have explored the
use of query contents, which can be more robust to attacker
counter strategies, as it is fundamentally difﬁcult to modify
query keywords without affecting search results.

5.1 Case Study I: A Botnet Cluster

One detected botnet cluster is distinguished by the query
pattern “WordPress forum plugin Fredrik”. Table 15 shows
the statistics for this cluster. It includes 1,807 IP addresses
distributed across 1,752 /24 network preﬁxes, submitting in
total 127,557 queries with 62,115 unique ones. The vast
majority of hosts are active for only 1 day.

# of IPs
# of /24 preﬁxes
# of queries
# of unique queries

1,807
1,752
127,557
62,115

Table 15. Statistics of a botnet cluster

Tokens for vulnerabilities
WordPress forum plugin by Fredrik Fahlstad
fbconnec action=myhome
plugins/wpforum
forum.php
Powered by Joomla!. valid XHTML and CSS

# of queries
48,010
10,699
1,160
1,150
1,012

Table 16. Most popular vulnerability tokens in
the queries.

We examine this cluster and ﬁnd that a large fraction of
its queries are related with vulnerability searching. Each
query contains a quoted sub-string token for discovering
different types of vulnerabilities. There are in total 443
unique sub-string tokens. Table 16 lists the top popular
tokens that were searched most frequently. In addition to
the quoted sub-string tokens, each query also contains addi-
tional words, either specifying the query scopes, or aiming
to increase the search coverage.

14000

12000

10000

8000

6000

4000

2000

s
P

I
/
s
e
i
r
e
u
q

 
f

o

 
r
e
b
m
u
n
e
h
T

 

 

0
0

20

40

60

 

Queries
IPs

160

180

200

80

Time elapsed in hour

100

120

140

Figure 9. Number of queries/IPs in each hour

This botnet cluster shows strong bursty patterns in its
temporal behavior. Figure 9 plots the number of queries and
the number of IP addresses observed overtime. We see two
clear bursty periods, one for 6 hours, and the other for 21
hours. A closer look at these two bursts (Table 17 and 18)
reveals a multi-phase strategy adopted by attackers.

Burst1

Burst2

Duration (in hours)
# of IPs
# of queries
Duration (in hours)
# of IPs
# of queries

6
149
41,276
21
1,682
53,821

Table 17. Detailed statistics of the two phases

“index.php/thread-” shooter
“yabb/yabb.pl?board¯’’ siver
“index.php/thread-” site:com
“register.php?do=” socal
“memberlist.php?page=” somerset
“active topics.asp?at=” sorrowing
act “WordPress forum plugin by Fredrik Fahlstad” site:.edu
inch “WordPress forum plugin by Fredrik Fahlstad” site:.cn
plus “WordPress forum plugin by Fredrik Fahlstad” site:.net
change “WordPress forum plugin by Fredrik Fahlstad” site:.com

Burst1

Burst2

Table 18. Example queries submitted in the
two phases

In the ﬁrst burst, a relatively small number (149) of hosts
are involved, but they are very aggressive in generating
queries (submitted 41,276 queries in merely 6 hours). The
average number of queries per IP address is 277, and the
average interval between two consecutive queries is only

4.6 seconds. Most of the bot queries are in the format of a
quoted vulnerability token, followed with a random string
or word for increasing the query diversity. There are a large
number of different vulnerability tokens queried in this pe-
riod. The ﬁrst row in Table 18 lists some examples.

The second burst involves more bots in this cluster, with
1,682 out of 1,807 hosts active. There are 49 bots in the ﬁrst
phase also active in the second phase. These bots are more
persistent (e.g., active for 21 hours compared to 6 hours in
the ﬁrst phase), and their search behaviors are much more
stealthy. Each bot generated fewer queries (31 queries on
average) and the average interval between two consecutive
queries is 21 seconds, signiﬁcantly higher than the 4.6 sec-
onds before. The second row in Table 18 shows the example
queries submitted in this stage. These queries all target at a
speciﬁc type of vulnerability with different site scopes.

Considering the different but correlated query strategies
used in these two bursts, we suspect that queries in the ﬁrst
burst were mainly used to explore the diversity of the vul-
nerable web sites, while those in the second burst focused
more on ﬁnding information about a speciﬁc vulnerability,
which could be the most popular one or the easiest one for
exploitation. This example provides us with detailed under-
standing into the sophisticated query strategies by attack-
ers. Our system can effectively aggregate such activities
and provide important information for attack detection and
defense.

5.2 Case Study II: A Data Center Cluster

# of IPs
# of /24 preﬁxes
# of queries
# of unique queries
# of names

446
29
873,064
495,211
354,709

Table 19. A case study of data center cluster

One of the interesting data center clusters that we iden-
tify share the query pattern “-Genealogy, -Generation”. Ta-
ble 19 presents the cluster statistics. It has 446 distinct IP
addresses coming from 29 /24 IP preﬁxes. In addition, all
the IP addresses have been actively generating bot queries
throughout the data collection period. Despite the fact that
the 29 /24 IP preﬁxes look quite different, reverse DNS
lookups show that all of the IP addresses actually belong
to the same organization “SOFTLAYER”, which appears to
be an hosting service.

This cluster generates in total 873,064 queries with
495,211 unique ones, looking for information using people
names, possibly for background investigation. Each bot ﬁrst
initiates a query with only a name (e.g., “alice foo”), imme-
diately followed by another query with the same name plus
additional constraints (e.g., “alice foo” +(“alice is” OR

“alice was”) -Genealogy -Generation language:en). We
see 354,709 unique names being queried.

s
P

I
/
s
e
i
r
e
u
q

 
f

o
 
r
e
b
m
u
n

 

e
h
T

104

103

102
0

 

50

 

IPs
Queries

200

250

Figure 11. Query pattern lifetimes (from D1)

100

150

Time elapsed in hour

Figure 10. Number of queries/IPs in each hour

Figure 10 shows strong diurnal patterns in the number of
queries and the number of IP addresses submitting queries
from this cluster over time, suggesting that these queries
may be triggered by the events related to real users. For ex-
ample, there could exist a front end receiving user requests,
which triggers the back end to submit queries automatically.
Each /24 IP preﬁx in this cluster has around 15 IP addresses,
and the number of queries per host is well balanced, around
1000 queries per host.

This example shows different query contents and behav-
ior patterns from the botnet cluster we study in Section 5.1.
Without our tool, we would not be able to group the hosts
or analyze their different intentions at a large scale.

5.3 Case Study III: Two Data Center Clusters

Used For Malicious Purposes

Cluster1 in D1

# of IPs
# of /24 preﬁxes
# of Queries

41
1
244054

Cluster2 in D2

# of IPs
# of /24 preﬁxes
# of Queries

18
1
113994

Table 20. Case studies for two data center
clusters

Although it is not surprising to observe botnets submit-
ting queries with malicious intentions, the appearance of
data center hosts submitting malicious queries is a rela-
tively new trend. Using SBotScope we also ﬁnd data cen-
ter clusters submitting vulnerability-searching queries. Ta-
ble 20 shows two example data center clusters (Cluster1
and Cluster2) from D1 and D2, both associated with the

query pattern “powered by”, Cluster1 has 41 IP addresses
and Cluster2 has 18 IP addresses, all from the same /24 IP
preﬁx in AS21788 (“NOC”). All the IP addresses have been
actively generating bot queries throughout the data collec-
tion period, with the query volume well balanced across
hosts. Speciﬁcally, each host in these two clusters gener-
ated around 6000 queries, exhibiting strongly coordinated
behaviors. Compared to botnets, data center IP addresses
are often shared among multiple services, so they cannot be
easily blacklisted.

5.4 Application:

Queries

Detecting Additional Bot

Since query patterns are more tightly related to the true
intentions of bot queries, it is natural to consider using pat-
terns for detecting bot queries that are missed by the exist-
ing detection approaches. However, two challenges exist for
leveraging query patterns for detection. The ﬁrst is whether
query patterns are long-lasting enough so that we can apply
the bot query patterns derived from historical data to newly
observed ones. The second is whether bot query patterns
are distinguishing enough to differentiate bot queries from
those submitted by normal users.

To address the ﬁrst challenge, we study the persistence
of bot queries by checking the query patterns derived from
D1 against daily historical search logs in the past three
months. Figure 11 shows that query pattern lifetime has
a bimodal distribution. While many query patterns are rel-
atively short-lived, there still exist a large number of query
patterns that are persistent over time across almost the en-
tire three months. Even for the short-lived query patterns,
their lifetime is on the order of a few days, which still pro-
vide enough room for detection. In particular, we ﬁnd many
vulnerability-ﬁnding query patterns fall into the long-lived
category 2. This is encouraging as normal users usually do
not search for speciﬁc web server vulnerabilities.

2We ﬁnd a lot of query patterns for searching email account information

fall into the short-lived pattern category

Newly detected bot queries
12,436,658

# of IPs
3,873,909

# of new IPs
3,361,532

Table 21. Newly detected bot queries in the
same period of dataset D2.

To address the second challenge, we eliminate query pat-
terns that may introduce false positives. To be conservative,
we use the following two rules for detection:

• Bot-query patterns should not match popular normal
queries. Given that there could exist undetected bot
queries, we match each pattern against historical nor-
mal user queries (e.g., three months ago). If a pattern
matches normal user queries from a large number of
hosts (≥ 1000 IP addresses), we do not select this pat-
tern.

• A bot usually generates more than one query each
time. To be conservative, we select only hosts who
have at least m (we currently set m = 100, which is re-
ally conservative) bot queries (either already detected
or newly matched) and mark their newly matched
queries as additionally detected ones.

Applying these two rules on the normal query log col-
lected in the same period as D2, we additionally detected
12,436,658 bot queries that slip through the existing de-
tection system. Table 21 shows that the newly detected
bot queries have widely spread IP addresses, out of which,
86.8% (3,361,532) are addresses not observed in the already
detected bot-query set.

To validate the newly detected bot queries, we take a
similar approach by looking at the behavior similarity of
these queries in their “Form”, “Referrer” and “UA” ﬁelds.
To be comprehensive, we compare the similarity of these
ﬁelds among newly detected queries sharing the same pat-
terns, as well as comparing them against the clusters we al-
ready derived. Additionally we also compute the temporal
correlations of their activities (i.e., activity burstiness). Us-
ing the combinations of these approaches, we can validate
94.13% as suspicious and likely undetected bot queries.

The purpose of this experiment is not to have a bullet-
proof new detection system, but to illustrate the value of
exploring query patterns for detection. The hosts that sub-
mitted the newly detected bot queries were stealthier in their
search behaviors, but their queries revealed their true inten-
tions.

6 Discussion

Attackers may wish to evade any analysis that may lead
to detection or defense. Since SBotScope directly focuses

on query contents and the invariant patterns in terms of key-
word combinations, typical behavior-based strategies such
as randomizing U A, Ref erer ﬁelds or mimicking legiti-
mate query intervals will not impact our analysis.

Attackers may also wish to modify queries, increase or
decrease the number of queries per host. However, doing so
may lead to undesirable side effects. In particular, modify-
ing queries may not retrieve the same quality search results.
Increasing the number of queries per host (e.g., by adding
obfuscated or randomly picked queries) may lead to detec-
tion as the hosts submit queries more aggressively. Reduc-
ing the number of queries will decrease the query through-
puts, making it less cost-effective for attackers.

The ability to automatically dissect

large-scale bot
queries is only a ﬁrst step toward leveraging the value of bot
queries for security. As bot queries provide rich information
about the interests and focus of attackers, we should analyze
them further to extract stronger signals. The SBotScope
system provides the necessary basis for further study. For
example, we could analyze vulnerability-searching queries
in more detail to reveal the vulnerable software and version
numbers, the set of vulnerable web sites, and even zero-
day exploits. Finally, the information about the botnet sizes
and activity patterns can enable better detection and defense
mechanisms.

7 Conclusion

In this paper, we have presented SBotScope, an auto-
mated system to analyze large-scale bot queries from two
important aspects: query intentions and query origination.
SBotScope performs syntactical and semantical analysis of
bot queries to identify query intentions. It further clusters
hosts and classiﬁes them into botnet clusters and data cen-
ter clusters. Our large-scale study, based on month-long
bot queries collected from the Bing search engine, has re-
vealed a number of unique ﬁndings. First we ﬁnd that a
signiﬁcant portion of bot queries are associated with ma-
licious activities, where 33% of bot queries are used for
vulnerability discovery and 11% are used for harvesting
email addresses. Second, SBotScope identiﬁes 81,520 bot-
nets involved in submitting bot queries on a global scale.
Third, SBotScope identiﬁes 287 data center clusters, some
of which are also performing malicious searches. The ap-
pearance of using data center hosts for malicious activities
seems a newly emerged trend. Finally, we demonstrate the
value of SBotScope using a few case studies and a concrete
application. We believe that SBotScope is a useful tool for
improving security in multiple aspects.

8 Acknowledgements

We thank Zijian Zheng and his team for providing us
with the Bing search logs. We thank Qifa Ke and Yunchao
Gong for their help on the spectral clustering algorithm. We
are grateful to Seungwon Shin and Guofei Gu for their help
in validating IP addresses using the Conﬁcker data set. The
development of the SBotScope system and the related anal-
ysis were conducted while Junjie was at Microsoft Research
Silicon Valley. The analysis on the comparison with the
Conﬁcker botnets was partially supported by the National
Science Foundation under grant no. 0831300, and the Of-
ﬁce of Naval Research under grants no. N000140710907
and no. N000140911042.

References

[1] Amazon.Com Server Said To Have Been Used In Sony
Attack. http://www.bloomberg.com/news/2011-05-13/sony-
network-said-to-have-been-invaded-by-hackers-using-
amazon-com-server.html.

[2] Exploit DB.

http://www.exploit-db.com/

google-dorks.

[3] NOBISTECH. http://www.nobistech.net/.

[4] SOFTLAYER. http://www.softlayer.com/.

[5] Whois. http://en.wikipedia.org/wiki/Whois.

[6] L. M. Aiello, D. Donato, U. Ozertem, and F. Menczer.
In Proc.

Behavior-driven clustering of queries into topics.
ACM CIKM, 2011.

[7] B. Miller, P. Pearce, C. Grier, C. Kreibich, and V. Paxson.
What’s clicking what? Techniques and innovations of to-
day’s Clickbots. In Proc. DIMVA, 2011.

[8] D. Beeferman and A. Berger. Agglomerative clustering of a

search engine query log. In Proc. ACM SIGKDD, 2000.

[9] D. Donato, F. Bonchi, T. Chi, and Y. Maarek. Do you want to
take notes?: Identifying research missions in Yahoo! search
pad. In Proc. WWW, 2010.

[10] D. MacKay.

Information Theory, Inference and Learning

Algorithms. Cambridge University Press, 2003.

[11] E. Cooke, F. Jahanian, and D. McPherson. The zombie
roundup: Understanding, detecting, and disrupting botnets.
In Proc. SRUTI, 2005.

[12] F. R. Bach and M. I. Jordan. Learning spectral clustering,
with application to speech separation. Journal of Machine
Learning Research, 7:1963–2001, 2006.

[13] F. Yu, Y. Xie, and Q. Ke. Sbotminer: Large scale search bot

detection. In Proc. ACM WSDM, 2010.

[14] G. Buehrer, J. W. Stokes, and K. Chellapilla. A large scale
study of automated of automated web search trafﬁc. In Proc.
AIRWEB, 2008.

[15] G. Buehrer, J. W. Stokes, and K. Chellapilla. Classiﬁcation
In Chapter in Weaving Services

of automated web trafﬁc.
and People on the World Wide Web, 2009.

[16] H. Cao, D.H. Hu, D. Shen, D. Jiang, J.-T. Sun, E. Chen, and
Q. Yang. Context-aware query classiﬁcation. In Proc. ACM
SIGIR, 2009.

[17] H. Kang, K. Wang, D. Soukal, F. Behr, and Z. Zheng. Large-
scale bot detection for search engines. In Proc. WWW, 2010.
[18] X. He and P. Jhala. Regularized query classiﬁcation using
search click information. Pattern Recognition, 41(7):2283–
2288–145, 2008.

[19] J. P. John, F. Yu, Y. Xie, A. Krishnamurthy, and M.
Abadi. deSEO: Combating search-result poisoning. In Proc.
USENIX Security, 2011.

[20] J. P. John, F. Yu, Y. Xie, M. Abadi, and A. Krishnamurthy.
Searching the searchers with searchaudit. In Proc. USENIX
Security, 2010.

[21] J. Wen, J. Nie, and H. Zhang. Query clustering using user
logs. ACM Transactions on Information Systems, 20(1):59–
81, 2002.

[22] J.P. John, F. Yu, Y. Xie, A. Krishnamurthy, and M. Abadi.
In Proc.

Heat-seeking honeypots: Design and experience.
WWW, 2011.

[23] L. Lu, R. Perdisci, and W. Lee. Surf: Detecting and measur-

ing search poisoning. In Proc. ACM CCS, 2011.

[24] M. Halkidi, Y. Batistakis, and M. Vazirgiannis. On clustering
validation techniques. J. Intell. Inf. Syst., 17(2-3):107–145,
2001.

[25] N. Daswani and M. Stoppelman. The anatomy of Click-

bot.A. In Proc. USENIX HotBots, 2007.

[26] N. Provos, J. McClain, and K. Wang. Search worms. In Proc.

ACM WORM, 2006.

[27] S. M. Beitzel, E. C. Jensen, D. D. Lewis, A. Chowdhury,
and O. Frieder. Automatic classiﬁcation of web queries us-
ing very large unlabeled query logs. ACM Transactions on
Information Systems, 2, 2007.

[28] S. Shin, G. Gu, N. Reddy, and C. Lee. A large-scale empir-
ical study of Conﬁcker. IEEE Transactions on Information
Forensics and Security, 2012.

[29] S.M. Beitzel, E.C. Jensen, Q. Frieder, D.D. Lewis, A.
Improving automatic query
In Proc. IEEE

Chowdhury, and A. Kolcz.
classiﬁcation via semi-supervised learning.
ICDM, 2005.

[30] Y. Xie, F. Yu, K. Achan, R. Panigrahy, G. Hulten, and I.
Osipkov. Spamming botnet: Signatures and characteristics.
In Proc. ACM SIGCOMM, 2008.

