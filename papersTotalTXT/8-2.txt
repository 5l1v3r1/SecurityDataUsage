Parallel and Dynamic Searchable

Symmetric Encryption

Seny Kamara1 and Charalampos Papamanthou2

1 Microsoft Research, senyk@microsoft.com

2 UC Berkeley, cpap@cs.berkeley.edu

Abstract. Searchable symmetric encryption (SSE) enables a client to outsource a
collection of encrypted documents in the cloud and retain the ability to perform
keyword searches without revealing information about the contents of the docu-
ments and queries. Although efﬁcient SSE constructions are known, previous so-
lutions are highly sequential. This is mainly due to the fact that, currently, the only
method for achieving sub-linear time search is the inverted index approach (Curt-
mola, Garay, Kamara and Ostrovsky, CCS ’06) which requires the search algo-
rithm to access a sequence of memory locations, each of which is unpredictable
and stored at the previous location in the sequence. Motivated by advances in
multi-core architectures, we present a new method for constructing sub-linear SSE
schemes. Our approach is highly parallelizable and dynamic. With roughly a loga-
rithmic number of cores in place, searches for a keyword w in our scheme execute
in o(r) parallel time, where r is the number of documents containing keyword w
(with more cores, this bound can go down to O(log n), i.e., independent of the re-
sult size r). Such time complexity outperforms the optimal Θ(r) sequential search
time—a similar bound holds for the updates. Our scheme also achieves the follow-
ing important properties: (a) it enjoys a strong notion of security, namely security
against adaptive chosen-keyword attacks; (b) compared to existing sub-linear dy-
namic SSE schemes (e.g., Kamara, Papamanthou, Roeder, CCS ’12), updates in our
scheme do not leak any information, apart from information that can be inferred
from previous search tokens; (c) it can be implemented efﬁciently in external mem-
ory (with logarithmic I/O overhead). Our technique is simple and uses a red-black
tree data structure; its security is proven in the random oracle model.

1 Introduction
Cloud storage promises high data availability, easy access to data, and reduced infras-
tructure costs by storing data with remote third-party providers. But availability is often
not enough, as clients need privacy guarantees for many kinds of sensitive data that is
outsourced to untrusted providers. For example, privacy is clearly important for medical
data, enterprise data and secret government documents.

The standard approach to achieving privacy in storage systems is to encrypt data
using symmetric encryption. Storage systems based on this approach provide end-to-end
privacy in the sense that data is protected as soon as it leaves the client’s possession.
While such a solution provides strong security guarantees, it induces a high cost in terms
of functionality and is therefore inadequate for storage systems that handle data at large
scales. This is because after the data leaves the client’s machine in encrypted form, the
server cannot perform any meaningful computation on it.

To address this, one can either use general-purpose solutions (e.g., fully-homomorphic
encryption [7] or oblivious RAMs [9]) or special-purpose solutions (e.g., searchable en-
cryption). Although general-purpose solutions have advantages, including generality and
stronger security properties, they are mostly of theoretical interest (e.g., recent work [19]
has shown that ORAM can be relatively practical). On the other hand, special-purpose
solutions like searchable encryption are practical and aim to provide a reasonable trade-
off between efﬁciency, functionality and security.

Using a symmetric searchable encryption (SSE) scheme, a client can store a collec-
tion of encrypted documents remotely while retaining the ability to perform keyword
searches without revealing any information about the contents of either the documents
or the queries. There are two high-level approaches to designing reasonably efﬁcient and
secure SSE schemes. The ﬁrst approach, proposed by Goh [8] and used in [3], associates
to each document an encrypted data structure that can be tested for the occurrence of
a given keyword. This approach naturally results in schemes with search time that is
linear in n, where n the number of documents in the collection. The second approach,
introduced by Curtmola et al. [6], associates an encrypted inverted index to the entire
document collection. This approach yields very efﬁcient schemes since search time is
O(r), where r is the number of ﬁles that contain the keyword. Note that, O(r) is not only
sub-linear, it is optimal. Due to its efﬁciency, the inverted index approach has been used
in many subsequent works, including [4,11,13,20].

While the inverted index approach yields the most efﬁcient SSE schemes to date,
it has at least two important limitations. The ﬁrst is that it is not well-suited to handle
dynamic collections (i.e., document collections that must be updated). Although Kamara
et al. [11] recently showed how to construct an encrypted inverted index that handles
dynamic data, their construction is very complex and difﬁcult to implement. In addition,
the update operations reveal a non-trivial amount of information. The second limitation
of the inverted index approach is that it is inherently sequential, requiring Ω(r) time even
in a parallel model of computation. This is mainly because the encrypted indexes used by
these constructions store data at random disk locations (for security and space efﬁciency),
and because the associated search algorithms are adaptive in the sense that they ﬁnd the
next memory location to access at the currently accessed memory location. In addition,
we note that even in the sequential setting, where the O(r) time bound for search is
optimal, these constructions can still introduce signiﬁcant latency when searching for a
very frequent keyword whose output list contains thousands of documents.

Our contributions. We introduce a new approach for designing SSE schemes that
yields constructions with sub-linear search time but that has none of the limitations of
the inverted index approach. In particular, our approach is simple, highly parallel and can
easily handle updates. More precisely, for n documents indexed over m keywords and
with p cores (processors) available, our construction has the following properties:
1. Searches for a keyword w run in O((r/p) log n) parallel time, where r is the number
of documents containing keyword w. Note that for p = ω(log n), our parallel search
time is o(r), i.e., less than the optimal sequential search time.3

3 Taking p = ω(log n) is very reasonable, given that even 64-core CPUs are now available, e.g.,
see the TILE64 processor at http://en.wikipedia.org/wiki/TILE64.

Table 1. Comparison of several SSE schemes, in terms of worst case parallel search time per
keyword w. With n we denote the size of the documents collection, with r the number of documents
containing keyword w, with m the size of the keywords space and with p the number of cores.

dynamism security search time index size

scheme
Song et al. [18]
Goh [8]
Chang and Mitzenmacher [3]
Curtmola et al. [6] (SSE-1)
Curtmola et al. [6] (SSE-2)
van Liesdonk et al. [20]
Chase and Kamara [4]
Kurosawa and Ohtaki [13]
Kamara et al. [11]
THIS WORK

static

CPA
dynamic CKA1
CKA1
CKA1
CKA2
dynamic CKA2
CKA2

static
static
static

static
static

UC

dynamic CKA2
dynamic CKA2 O( r

O(m + n)

N/A
O(n)
O(mn)

O( n
p )
O( n
p )
O( n
p )
O(r)
O(r)
O(n)
O(r)
O(n)
O(r)
O(m + n)
p log n) O(mn)

O(mn)
O(mn)
O(mn)
O(mn)

2. Updates for a document f containing q unique keywords run in O((m/p) log n)
parallel time. Again, in that case, for p = ω((m/q) log n), our parallel update time
is o(q), i.e., less than the optimal sequential update time.

3. Finally, unlike the updates supported in the works of van Liesdonk et al. [20] and
Kamara et al. [11], the updates of our scheme do not leak information about the
keywords contained in a newly added or deleted document f, apart from information
that is leaked through search tokens that have been issued in the past (updates in our
scheme however require one round of interaction, as in [20]). For example, if we start
adding documents into our encrypted index before we perform any search (which is
common in practical applications like streaming), no information is leaked due to
these update operations.

We ﬁnally note that our scheme enjoys a strong notion of security in this context, namely
security against adaptive chosen-keyword attacks (CKA2), as deﬁned by Curtmola et
al. [6] and can also be implemented efﬁciently in external memory (with logarithmic I/O
overhead).
Our approach. Our approach is based on a new tree-based multi-map data structure
we refer to as a keyword red-black (KRB) tree. As we show in Section 3, KRB trees
can index a document collection in such a way that keyword search can be performed in
O(r log n) sequential time and O( r
p log n) parallel time. In addition, a KRB tree supports
efﬁcient updates because all the information it contains about a given ﬁle f can be found
and updated in O(log n) time. To construct our SSE scheme, we show how to encrypt
KRB trees based on simple and efﬁcient primitives like pseudorandom functions and
permutations and a random oracle. The resulting scheme is CKA2-secure and preserves
the same (asymptotic) efﬁciency as an unencrypted KRB tree.
Related work. The problem of searching on symmetrically encrypted data can be
solved in its full generality using the work of Goldreich and Ostrovsky [9] on oblivi-
ous RAM (ORAM). In addition to handling any type of search query, this approach also
provides the strongest levels of security, namely the server does not learn any informa-
tion about the data or the queries—not even information inferred by the client’s access

pattern. This approach requires interaction and has a high overhead for the server and the
client, especially for more involved functionalities like search. Lorch et al. [14] explored
the notion of parallel ORAM and proposed a parallel ORAM scheme based on a binary
√
tree approach. Finally, while a recently introduced ORAM scheme [19] has been shown
to be relatively practical, it still requires O(

n) storage at the client.

Song et al. [18] were the ﬁrst to explicitly consider the problem of searchable encryp-
tion and presented a non-interactive solution that with search time that is linear in the
length of the data collection. Goh [8] introduced formal security deﬁnitions for SSE and
proposed a construction based on Bloom ﬁlters [1] that requires O(n) search time and
results in false positives. Chang and Mitzenmacher [3] proposed an alternative security
deﬁnition and construction also with O(n) search time but without false positives. While
both the schemes of Goh and of Chang and Mitzenmacher can be naively parallelized,
this would require a linear (in n) number of cores.

Curtmola et al [6]. gave the ﬁrst constructions (SSE-1 and SSE-2) to achieve sub-
linear (and in fact optimal) search time. Like previous work [8,3], SSE-1 was shown
secure against chosen-keyword attacks (CKA1). In that work, it was noted, however, that
CKA1-security does not sufﬁce for practical use. To address this, the stronger notion of
security against adaptive chosen-keyword attacks (CKA2) was proposed and a CKA2-
secure SSE scheme (SSE-2) was proposed. A similar CKA2-secure scheme was also
described by Chase and Kamara [4] but its space complexity is high. Finally, recent
work by Kurosawa et al. [13] shows how to construct a (veriﬁable) SSE scheme that is
universally composable (UC). While UC-security is a stronger notion of security than
CKA2-security, their construction requires linear search time.

None of the above schemes are “explicitly dynamic”, i.e., to handle dynamic data one
must use general dynamization techniques that are relatively inefﬁcient (except for the
scheme of Goh [8] which unfortunately has linear search time). The ﬁrst explicitly dy-
namic scheme was presented by Liesdonk et al. [20], but unfortunately that construction
supports a limited number of updates and can has linear search time in the worst case.
Recently, Kamara et al. [11] constructed an SSE scheme that is CKA2-secure, achieves
optimal search time (with small constants) and is explicitly dynamic, Unfortunately, this
construction leaks the tokens of the keywords contained in an updated document. Our
construction avoids such leakage and, in addition, is considerably simpler. A complete
comparison of all the schemes can be found in Table 1.

All the above solutions are either inherently sequential or admit naive parallelization.
For example, in the schemes based on the inverted index approach of Curtmola et al
[4,6,11,13,20], in order to retrieve the documents d1, d2, . . . , dr containing keyword w,
the algorithm uses the pointer to d1 along with a special token t(w) to decrypt the pointer
to d2, then it uses the pointer to d2 and the token t(w) to decrypt the pointer to d3 until
the ﬁnal pointer to dr can be decrypted. Similarly, to delete a document that contains
keywords w1, w2, . . . , wq, the algorithm deletes the entry corresponding to wi only after
it deletes the entry corresponding to wi−1. Both these procedures are sequential in nature.
Although this work focuses on the case of single-keyword equality queries, we note
that more complex queries have also been considered. This includes conjunctive queries
in the symmetric key setting [10]; it also includes conjunctive queries [16,2], comparison
and subset queries [2], and range queries [17] in the public-key setting.

2 Preliminaries
Our construction makes use of several basic cryptographic primitives. A private-key en-
cryption scheme consists of three algorithms E = (Gen, Enc, Dec) such that Gen(1k; r)
is a probabilistic polynomial-time (PPT) algorithm that takes a security parameter k and
randomness r and returns a secret key K; Enc(K, m) is PPT algorithm that takes a key
K and a message m and returns a ciphertext c; Dec(K, c) is a deterministic algorithm
that takes a key K and a ciphertext c and returns m if K was the key under which c was
produced. Informally, a private-key encryption scheme is CPA-secure if the ciphertexts it
outputs do not leak any partial information about the plaintext even to an adversary that
can adaptively query an encryption oracle.

In addition to encryption schemes, we also make use of pseudorandom functions
(PRF), which are polynomial-time computable functions that cannot be distinguished
from random functions by any PPT adversary and random oracles, to which we assume
all parties have black-box access. We refer the reader to [12] for formal deﬁnitions of
CPA-security, PRFs and random oracles.
Keyword hash tables.
In our construction we use static hash tables [5] to store some
speciﬁc information for each one of the m keywords. The entries of the hash table λ
are tuples (key, value), where the key key is from a domain of exponential size, i.e., from
{0, 1}k and value is an encryption of a boolean value. However, the maximum number of
entries in our hash table will be polynomial in k and equal to m, the number of keywords.
If, for a table λ, the key ﬁeld is from {0, 1}k, and there are at most m entries in λ, then
we say λ is a (k, m) hash table. For each x ∈ {0, 1}k, we denote with λ[x] the value
associated with key x, if key x exists.
Searchable symmetric encryption. SSE allows a client to encrypt data so that it can
later generate search tokens which the server can use to search over the encrypted data
and return the appropriate encrypted ﬁles.

The encryption algorithm in an SSE scheme takes as input an index δ, a sequence of
n ﬁles f = (fi1 , . . . , fin ) that have unique identiﬁers i = (i1, . . . , in),4 and a universe of
keywords w = (w1, . . . , wm). The index δ efﬁciently maps a keyword w ∈ w to a set
of identiﬁers iw ⊆ i that correspond to a set of ﬁles fw ⊆ f. The encryption algorithm
outputs an encrypted index γ and a sequence of n ciphertexts c = (ci1 , . . . , cin ), cor-
responding to the identiﬁers i = (i1, . . . , in). We assume all the ciphertexts include the
identiﬁers of their plaintext ﬁles. All known constructions (except for [18]) can encrypt
the ﬁles f using any CPA-secure encryption scheme. The encrypted index γ and the ci-
phertexts c do not reveal any information about f other than the number of ﬁles n and
their length,5 so they can be stored safely at an untrusted cloud provider.
To search for a keyword w, the client generates a search token τs and given τs, γ and
c, the provider can ﬁnd the subset of ciphertexts cw ⊆ c that contain w. Notice that the
provider learns some limited information about the client’s query. In particular, it knows
that whatever keyword the client is searching for is contained in whichever ﬁles resulted

4 The identiﬁers are chosen uniformly at random and do not reveal any information about the
plaintexts they are representing, e.g., they can be the i-nodes of the underlying ﬁle system. In
order not to overload the notation, ﬁle fi has identiﬁer i.
5 Note that this information leakage can be mitigated by padding if desired.

in the ciphertexts cw. A more serious limitation of known SSE constructions (including
ours) is that the tokens they generate are deterministic, in the sense that the same token
will always be generated for the same keyword. This means that searches leak statistical
information about the user’s search pattern. Currently, it is not known how to design
efﬁcient SSE schemes with probabilistic trapdoors.

Our scheme supports parallel keyword search as well as parallel addition and dele-
tion of ﬁles. For updates, we use 1.5 rounds of interaction (i.e., three messages between
client and server). For example, to add a ﬁle f, the client generates—with the help of
the server—an addition token τa. Given such token and γ, the server can update the in-
dex γ. The same pattern occurs for deletion. To account for this interaction, we slightly
change the deﬁnition of CKA2-security for dynamic SSE which was recently presented
by Kamara et al. [11].

k and outputs a secret key K.

secret key K and a keyword w and outputs a search token τs.

Deﬁnition 1 (Dynamic SSE). A dynamic SSE scheme is a tuple (Gen, Enc, SrchToken,
Search, UpdHelper, UpdToken, Update, Dec) of eight polynomial-time algorithms such
that:
1. K ← Gen(1k): is a probabilistic algorithm that takes as input a security parameter
2. (γ, c) ← Enc(K, δ, f ): is a probabilistic algorithm that takes as input a secret key K,
an index δ and a sequence of ﬁles f. It outputs an encrypted index γ and a sequence
of ciphertexts c.
3. τs ← SrchToken(K, w): is a (possibly probabilistic) algorithm that takes as input a
4. iw ← Search(γ, c, τs): is a deterministic algorithm that takes as input an encrypted
index γ, a sequence of ciphertexts c and a search token τs. It outputs a sequence of
identiﬁers iw ⊆ i.
5. infoi,u ← UpdHelper(i, u, γ, c): is a deterministic algorithm that takes as input a
ﬁle identiﬁer i, the update type u ∈ {add, delete}, an encrypted index γ and se-
quence of ciphertexts c. It outputs helper information infoi,u for the speciﬁc update.
6. τu ← UpdToken(K, fi, infoi,u): is a (possibly probabilistic) algorithm that takes
as input a secret key K, a ﬁle fi and the respective helper information infoi,u as
output by algorithm UpdHelper. It outputs an update token τu for the update type
u ∈ {add, delete}.
7. (γ(cid:48), c(cid:48)) ← Update(γ, c, τu): is a deterministic algorithm that takes as input an en-
crypted index γ, a sequence of ciphertexts c and an update token τu. It outputs a new
encrypted index γ(cid:48) and new sequence of ciphertexts c(cid:48).
8. f ← Dec(K, c): is a deterministic algorithm that takes as input a secret key K and

a ciphertext c and outputs a ﬁle f.

We can now easily deﬁne correctness of the above dynamic SSE scheme deﬁnition.
Deﬁnition 2 (Correctness). Let D be a dynamic SSE scheme consisting of the tuple of
eight algorithms as given in Deﬁnition 1. We say that D is correct if for all k ∈ N,
for all K output by Gen(1k), for all tuples (δ, f ), for all tuples (γ, c) output by one
execution of Enc(K, δ, f ) and successive executions of Update(γ, c, τu), where τu is the
update token output by UpdToken(K, fi, UpdHelper(i, u, γ, c)) for all ﬁles fi and all

u ∈ {add, delete}, for all keywords w, for all tokens τs output by SrchToken(K, w), for
all iw output by Search(γ, c, τs), the plaintexts fw = {Dec(K, ci) : i ∈ iw} are all the
plaintexts in f containing keyword w.

Security. Intuitively, the security guarantee we require from a dynamic SSE scheme is
that (1) given an encrypted index γ and a sequence of ciphertexts c, no adversary can
learn any partial information about the ﬁles f; and that (2) given, in addition, a sequence
of search tokens τ = (τ1, . . . , τt) for an adaptively generated sequence of keywords
q = (q1, . . . , qt) (which can be for the search, add or delete operations), no adversary
can learn any partial information about either f or q. This exact intuition can be difﬁcult
to achieve and most known efﬁcient and non-interactive SSE schemes [3,6,8,11,13,20]
reveal the access and search patterns.6 We therefore need to weaken the deﬁnition ap-
propriately by allowing some limited information about the messages and the queries to
be revealed to the adversary. To capture this, we follow the approach of [4] and [6] and
parameterize our deﬁnition with a set of leakage functions that capture precisely what
is being leaked by the ciphertext and the tokens. Speciﬁcally, the leakage functions we
consider in this work are deﬁned as follows:
1. L1(δ, f ): given the index δ and the set of ﬁles f (along with the respective identiﬁers),
this function outputs the number of keywords m, the number of ﬁles n, the identiﬁers
i of the ﬁle and the size of each ﬁle;
2. L2(δ, f , w, t): this function takes as input the index δ, the set of ﬁles f and a keyword
w for a search operation that took place at time t. It outputs two different types of
information, namely the search pattern P(δ, q, t) and the access pattern ∆(δ, f , w, t),
both of which are described in the following deﬁnitions.

Deﬁnition 3 (Search pattern). Given a search query for keyword w at time t, the search
pattern P(δ, q, t) is deﬁned as the binary vector of length t with a 1 at location i if the
search at time i ≤ t was for w; and 0 otherwise. Namely the search pattern reveals
whether the same search was performed in the past or not.

Deﬁnition 4 (Access pattern). Given a search query for keyword w at time t, the access
pattern ∆(δ, f , w, t) is deﬁned as the identiﬁers in the set fw at time t.

Discussion on leakage.
In our scheme (described in Section 3), if one searches for w
at time t, the output of the leakage function L2(δ, f , w, t) consists of ∆(δ, f , w, t), which
includes the identiﬁers iw of the ﬁles fw that contain keyword w at time t. As we add ﬁles
to the collection, ∆(δ, f , w, t) is expanded with the identiﬁers of the new ﬁles that contain
w. This is a limitation of our construction since search tokens are valid even for future
documents added to the collection and effectively allow the server to use old tokens to
search over newly-added documents. It is an open problem to construct efﬁcient dynamic
SSE schemes that do not have this limitation.7

6 One exception is the construction described in [4] which leaks only the access and the intersec-
tion patterns.
7 The scheme of Chang and Mitzenmacher [3] does not have this limitation but requires linear
time search.

We note that with our construction, if one adds documents to the index before per-
forming any search operations (which is common in practical applications like stream-
ing), no information is leaked due to the updates. From a security point of view, this is the
main difference between our scheme and the recently proposed construction of Kamara
et al. [11], which always leaks information on an update. In this sense, our construction
satisﬁes a slightly stronger notion of security since since the leakage of our updates is
conditional on previous operations and does not occur unconditionally. This is also why,
unlike [11], we do not use an explicit leakage algorithm for updates.

Finally, as observed in [6], another issue with respect to SSE security is whether the
scheme is secure against adaptive chosen-keyword attacks (CKA2) or only against non-
adaptive chosen keyword attacks (CKA1). The former guarantees security even when
the client’s queries are based on the encrypted index and the results of previous queries.
The latter only guarantees security if the client’s queries are independent of the index and
of previous results. Our scheme achieves the stronger notion of security, namely CKA2-
security. In our deﬁnition of security below, we adapt the notion of CKA2-security from
[11] to the setting of dynamic SSE with interactive updates. We model the interaction
required by our scheme with an algorithm UpdHelper.
Deﬁnition 5 (CKA2-security). Let D be a dynamic SSE scheme consisting of the tuple
of eight algorithms as given in Deﬁnition 1. Consider the following probabilistic exper-
iments, where A is a stateful adversary, S is a stateful simulator and L1 and L2 are
stateful leakage algorithms:
RealA(k): the challenger runs Gen(1k) to generate a key K. A outputs a tuple (δ, f )
and receives (γ, c) ← Enc(K, δ, f ) from the challenger. The adversary makes a
polynomial number of adaptive queries by picking q ∈ {w, fi}. If q = w is a
search query then the adversary receives from the challenger a search token τs ←
SrchToken(K, w). If q = fi is an update of type u, then the adversary also sends
the helper information infoi,u ← UpdHelper(i, u, γ, c) to the challenger and then
receives from the challenger the update token τu ← UpdToken(K, fi, infoi,u). Fi-
nally, A returns a bit b that is output by the experiment.
IdealA,S (k): A outputs a tuple (δ, f ). Given L1(δ, f ), S generates and sends a pair
(γ, c) to A. The adversary makes a polynomial number of adaptive queries by pick-
ing q ∈ {w, fi}. If q = w is a search query then the simulator is given L2(δ, f , w, t).
If q = fi is an update of type u, the simulator is given the updated output of
L2(δ, f , w, t) for all keywords w that have appeared before in the adaptive queries.8
The adversary also sends infoi,u ← UpdHelper(i, u, γ, c) to the simulator. The sim-
ulator returns an appropriate token τ. Finally, A returns a bit b that is output by the
experiment.
We say that D is (L1,L2)-secure against adaptive dynamic chosen-keyword attacks if for
all PPT adversaries A, there exists a PPT simulator S such that

|Pr [ RealA(k) = 1 ] − Pr [ IdealA,S (k) = 1 ]| ≤ neg(k).

8 This will be used to simulate searches for previous tokens, the output of which (of those
searches) has changed due to the update. This is the only leakage that our updates cause.

3 Our Dynamic SSE Construction
In this section we describe our parallel and dynamic construction. Let f = (fi1, . . . , fin )
be a sequence of documents with corresponding identiﬁers i = (i1, . . . , in) over a set of
keywords w = (w1, . . . , wm). We view each individual fi document as a bit-string of
polynomial length, i.e., fi = {0, 1}poly(k). Recall that an index δ maps a keyword w ∈ w
to a set of documents identiﬁers iw.

We assume that the universe of keywords is ﬁxed but that the number of documents
can grow. In particular, we assume that the total number of keywords m is much smaller
than the number of ﬁles n. We now introduce a standard (i.e., unencrypted) data structure
keyword search which we refer to as a keyword red-black tree. KRB trees will be the basis
of our dynamic SSE scheme.
The KRB tree. The KRB tree is a dynamic data structure that—similarly to an inverted
index—can be used to efﬁciently answer multi-map queries. A KRB tree δ is constructed
from a set of documents f = (fi1, . . . fin ) (which include the identiﬁers i = (i1, . . . , in))
and a universe of keywords w. The data structure is constructed using the following
procedure, which we denote as buildIndex(f ):
1. Assume a total order on the documents f = (fi1, . . . , fin ), imposed by the ordering
of the identiﬁers i = (i1, . . . , in). Build a red-black tree T on top of i1, . . . , in. At
the leaves, store pointers to the appropriate documents. We assume the documents
are stored separately, e.g., on disk. Note that this is a slight modiﬁcation of a red
black tree since the tree is constructed on top of the identiﬁers but the leaves store
pointers to the ﬁles.

2. At each internal node u of the tree, store an m-bit vector datau. The i-th bit of
datau accounts for keyword wi, for i = 1, . . . , m. Speciﬁcally, if datau[i] = 1,
then there is at least one path from u to some leaf that stores some identiﬁer j, such
that fj contains wi;

3. We guarantee the above property of vectors datau, by computing datau as fol-
lows: for every leaf l storing identiﬁer j, set datal[i] = 1 if and only if document
fj contains keyword wi. Now let u be an internal node of the tree T with left child v
and right child z. The vector datau of the internal node u is computed recursively
as follows:

datau = datav + dataz ,

(1)

where + denotes the bitwise boolean OR operation.

To search for a keyword w in a KRB tree T one proceeds as follows. Assuming that w
has position i in the m-bit vectors stored at the internal nodes, check the bit at position i
of node v and examine v’s children if the bit is 1. When this traversal is over, return all
the leaves that were reached.

The intuitive reason the KRB tree is so useful for our purposes is that it allows both
keyword-based operations (by following paths from the root to the leaves) and ﬁle-based
operations (by following paths from the leaves to the root). As we will see later, this
property is useful for handling updates efﬁciently. We now have the following:
Lemma 1 (KRB tree data structure). Let f = (fi1 , . . . , fin ) be a set of n documents
containing keywords from a dictionary of m keywords w = (w1, . . . , wm). Then there
exists a dynamic data structure for keyword search such that: (a) the space complexity

of the data structure is O(mn); (b) constructing the data structure takes time O(mn);
(c) the search time for a keyword w is O(r log n), where r is the number of documents
containing w; (d) the time to insert and delete a document f is O(q log n), where q is the
number of unique keywords contained in document f; (e) search and updates take par-
p log n) time, respectively, with p processors in the concurrent-
allel O( r
read-exclusive-write (CREW) model of parallel computation.

p log n) and O( q

Proof. Since the underlying red-black tree has space complexity O(n) and we have to
store at each node a bit-vector of m bits, it follows that the space complexity of the KRB
tree is O(mn). Now due to the property of Relation 1, given the document collection f
one can start building the data structure following a postorder traversal. Since a postorder
traversal visits O(n) nodes and the time spent at each node is O(m) (to compute the OR
of two m-bit vectors), the time required for constructing the data structure is O(mn).

Recall that sequential search for a keyword w (corresponding to position i of the m-
bit vectors) proceeds as follows: while the bit at position i of node v is 1, examine v’s
children. Therefore the search procedure will traverse as many paths as the documents
containing keyword w, namely r paths. Since the maximum height of the red-black tree
is maintained to be O(log n) [5], the search time is O(r log n).
The parallel search is executed as follows. Let 0, 1, . . . , p − 1 be the processors that
are available. Processor 0 queries the root r of the tree for a speciﬁc keyword. If the
search is to be continued in both the subtrees Tu and Tv of the processor’s children u and
v, processor 0 continues with one subtree (say Tu) and assigns the other subtree Tv to
be explored by another processor. The same algorithm is recursively applied for nodes u
and v. However, if at some point during the search no more processors are available (i.e.,
all p processors are working—this test can be achieved with concurrent read of the same
data structure by all processors, that is why we require CREW model), the current pro-
cessor simply selects one of its two possible children to continue, marks the other child
c as “unexplored” and pushes c into a local stack of unexplored nodes so that it can be
explored later. All p processors terminate their execution in O(log n) time, outputting p
documents containing the queried keyword. In the second round, each processor i starts
over by popping (and removing) a node c from the processor’s local stack and by resum-
ing the search from that node c. Again, during that round, each processor pushes nodes
it cannot explore into its local stack. At the end of the second round, at least another p
documents are retrieved in O(log n) time. Eventually, after r/p rounds of logarithmic
time, all documents are retrieved (and all the local stacks are guaranteed to be empty).
Therefore, search executes in parallel O( r

p log n) time.

The sequential update time follows from the complexity of the update of the red-
black tree [5]. Since it involves bit operations between q independent vector positions, it
can be implemented in O( q

p log n) parallel time. This completes the proof. (cid:3)

We now show the following corollary, establishing the number of processors required for
improving the optimal sequential performance:

Corollary 1 (Number of processors). With ω(log n) processors available, parallel searches
take o(r) time and parallel updates take o(q) time in a KRB tree.

KRB-based dynamic SSE. We now describe in detail our KRB-based parallel and
dynamic SSE construction. Let f = (fi1, . . . , fin ) be the set of documents and w =
(w1, . . . , wm) be the set of keywords. We use the following cryptographic primitives:
1. A pseudo-random function G : {0, 1}k × {w1, . . . , wm} → {0, 1}k;
2. Another pseudo-random function P : {0, 1}k × {w1, . . . , wm} → {0, 1}k;
3. A random oracle H : {0, 1}k × {0, 1} → {0, 1}.

Fig. 1. The construction of a dynamic symmetric searchable encryption (DSSE) scheme using the
KRB tree data structure, for a collection of n = 8 documents indexed over m = 5 keywords. Note
that for each node v we store two vectors. The encryption of the actual bit of position i at node v
is stored to either hash table λ0v or hash table λ1v, depending on the output of the random oracle.
The red arrows indicate the search for keyword 5, returning documents f3, f6, f7. Note that the
two searches displayed can be parallelized.

We now describe the algorithms (Gen, Enc, SrchToken, Search, UpdHelper, UpdToken,
Update, Dec) of the DSSE scheme from Deﬁnition 1 in detail:
Algorithm K ← Gen(1k): Generate three random k-bit strings K1, K2 and r. Instan-
tiate one private-key CPA-secure encryption scheme for encrypting documents by calling
K3 ← E.Gen(1k; r). Set K := (K1, K2, K3);
Algorithm (γ, c) ← Enc(K, δ, f ): Let δ ← buildIndex(f ) be a KRB tree and proceed
as follows:
1. Instantiate a second private-key CPA-secure encryption scheme R. Derive a secret
key SKi per keyword wi by calling SKi = R.Gen(1k; GK2 (wi)), for i = 1, . . . , m.
2. For 1 ≤ j ≤ n, let cij ← E.Enc(K3, fij ), outputting a vector of ciphertexts c;
3. Store c on disk (note that the identiﬁers i remain the same) and then delete f. For ev-
ery node v of the KRB tree T , that has identiﬁer id(v), do the following: (a) Instan-
tiate two (k, m) keyword hash tables λ0v and λ1v—see Section 2 for the deﬁnition
of a (k, m) keyword hash table. Store λ0v and λ1v at v; (b) For every i = 1, . . . , m,
set λbv[PK1(wi)] ← R.Enc(SKi, datav[i]), where b = H(PK1 (wi), id(v)) is a bit
computed as the output of a random oracle and datav is the vector at node v in
T ; (c) Store a random string at λ|1−b|v[PK1 (wi)] (namely at each node v, the bit b

              f1f2r21r11              f3f4r22              f5f6r23r12              f7f8r24r100010110110111100111101101000000100000101010110110001111011                            011010001111011dictates which hash table (either λ1v or λ0v) contains the actual entry for keyword
wi); (d) Delete vector datav.

4. Output γ := T and c := (ci1 , . . . , cin ).
Algorithm τs ← SrchToken(K, wi): Call R.Gen(1k; GK2(wi)) to output the secret key
SKi and output the search token τs := (PK1 (wi), SKi);
Algorithm iw ← Search(γ, c, τs): Parse τs as (τ1, τ2). Call search(r), where r is the
root of the KRB tree T . Let v and z be the left and right child of a node u respectively.
Algorithm search(u) is recursively deﬁned as follows:
1. Output a bit b = H(τ1, id(u)) and compute a = R.Dec(τ2, λbu[τ1]);
2. If a = 0, return;
3. If u is a leaf, set cw := cw ∪ cu, where cu is the ciphertext corresponding to ﬁle

identiﬁer u (and also stored at node u). Else call search(v) and search(z).

|cw|
p log n) time, where p is the number of processors).

Output cw (note here that, by Lemma 1, this algorithm can be parallelized to execute in
O(
Algorithm infoi,u ← UpdHelper(i, u, γ, c): The update u in this algorithm refers to
the document fi and is either an insertion of document fi or a deletion of document
fi (with identiﬁer i). To compute the information infoi,u, the algorithm performs the
structural update9 on the KRB tree T . Note that in order to perform the structural update,
no access to the actual content of the documents is required, since such an update is
only based on the identiﬁer i. The information infoi,u consists of the portion T (u) of the
KRB tree T that is accessed during the update. In other words T (u) sufﬁces to perform
the update, in absence of the rest of the tree T − T (u). Moreover, the size of T (u) is
O(m log n) in the worst case, given that a red-black tree update takes O(log n) time in
the worst case (see Lemma 1) and therefore it can “touch” as many bits (multiplied by
the size m of the encrypted vectors that are stored at the tree nodes). To give an example,
in Figure 1, info3,u, where u is “deletion of ﬁle f3”, contains the nodes r22, r11 and r
(along with the encrypted vectors stored at them).
Algorithm τu ← UpdToken(K, fi, infoi,u):
If the update u is an insertion of docu-
ment fi, compute ﬁrst an encryption ci ← E.Enc(K3, fi) of the added document. Now
let infoi,u contain the speciﬁc portion T (u) of the KRB tree, as returned by UpdHelper.
Perform the structural update on T (u) and let T (cid:48)(u) be the new subtree after the up-
date. Every node v of T (cid:48)(u) that has new/modiﬁed ancestors (compared to its structure
in T (u)) must also change its encrypted local information, since this is always com-
puted as a function of its ancestors (in a sense, its encrypted local information is going
to be recomputed and rerandomized). Also it changes its identiﬁer from id(v) to id(v(cid:48)).
Speciﬁcally, for every such node v ∈ T (cid:48)(u) we do the following:
1. Instantiate two new (k, m) keyword hash tables with random entries λ0v and λ1v.

Store λ0v and λ1v at v;

9 The structural update involves the necessary rotations that are performed during an update of
a red-black tree, so that its height can be maintained to be logarithmic. The details of such
operations are described in the book by Cormen, Leiserson, Rivest and Stein (CLRS) [5].

2. Update the new hash tables by setting λbv[PK1(wi)] ← R.Enc(SKi, datav[i]) (i =
1, . . . , m), where b = H(PK1(wi), id(v(cid:48))) is a bit computed as the output of the
random oracle and datav is the updated vector due to the update;

3. Output τu := (T (cid:48)(u), ci).
Algorithm (γ(cid:48), c(cid:48)) ← Update(γ, c, τu): On input τu, just copy the new information
T (cid:48)(u) to the already structurally updated KRB tree T (note that T was structurally up-
dated by the UpdHelper algorithm) and output the new encrypted index γ(cid:48) and the new
set of ciphertexts c(cid:48).
Algorithm fi ← Dec(K, ci): Output the plaintext fi := E.Dec(K3, ci).
Correctness, security and main result.
correct (Lemma 2) and secure (Lemma 3). Then we give the ﬁnal result (Theorem 1).
Lemma 2 (Correctness). The dynamic searchable symmetric encryption scheme pre-
sented above is correct according to Deﬁnition 2.

In this section we prove that our scheme is

Proof. Note that the Update algorithm modiﬁes the encrypted KRB tree in a way that
Relation 1 is satisﬁed, since the correct value of the bit at each node v is stored as in-
dicated by the random oracle. Since the Search algorithm will query the same random
oracle, it follows that when searching for a keyword w, it will follow the tree paths that
lead to the correct set of documents.
Lemma 3 (Security). The dynamic searchable symmetric encryption scheme presented
above is (L1,L2)-secure in the random oracle model and according to Deﬁnition 5
(CKA-2 security), where L1 leaks the number of the keywords, the number of the docu-
ments, the identiﬁers of the documents and the size of each document; and L2 leaks the
search pattern and the access pattern, as deﬁned in Deﬁnitions 3 and 4.

The proof of Lemma 3 can be found in the Appendix. We now state our ﬁnal theorem.
Theorem 1 (Parallel and dynamic SSE scheme). There exists a dynamic searchable
symmetric encryption scheme for a collection of n documents indexed over a set of m
keywords such that: (a) it is correct according to Deﬁnition 2 and secure according to
Deﬁnition 3 and in the random oracle model; (b) searches for keywords w can be per-
formed in sequential O(r log n) time or parallel O( r
p log n) time in the CREW model
of parallel computation, where r is the number of documents containing w and p is the
number of processors available; (c) additions or deletions of a document fi can be per-
formed in sequential O(m log n) time or parallel O( m
p log n) time, with one interaction,
and have O(m log n) communication complexity; (d) the encrypted data structure γ has
size O(mn) and the local space needed is O(1).

Proof. Correctness follows from Lemma 2, security follows from Lemma 3 and most
complexities (including the parallel ones) follow from Lemma 1. Note that the update
complexity is not O(q log n), as in Lemma 1—it is O(m log n), since we do not want
to reveal which keywords are contained in the ﬁle of the update. Also, our scheme has
interactive updates due to the algorithm UpdHelper in the deﬁnition. (cid:3)
In the following corollary we give the minimum number of processors required so that
the parallel operations of our scheme outperform the optimal sequential complexity.

Corollary 2 (Number of processors). With ω(log n) processors available in the above
q log n) processors avail-
scheme, parallel searches take o(r) time. Similarly, with ω( m
able, parallel updates take o(q) time.

which is O(n) as long as m ≤ √

√

4 Extensions and Optimizations
Improving the space complexity. We note here that the space complexity of our en-
crypted KRB tree is O(mn), where m is the number of the keywords and n is the number
of documents. Since m (cid:28) n in practical scenarios, the space complexity can be kept low
√
in practice. However, one way to reduce the size of the data structure is to use a tree of
depth 2 with internal nodes of degree O(
n). Similarly to KRB trees, one can store m-bit
vectors at the internal nodes of such a tree and perform search, add and delete operations
√
in the same manner. Encryption of these trees can also be handled with the same algo-
n),
rithm that encrypts KRB trees. The space complexity of this structure is O(n + m
n. Note however that this construction increases the
n), where r is the

search time and communication complexity (for updates) to O(r
number of the documents that contain w.
Supporting I/O-efﬁcient search.
In the case of very large indexes that cannot ﬁt into
main memory10, our approach can be implemented in an I/O-efﬁcient way by using a B-
tree instead of a red-black tree. With such a structure, search always requires logB n I/Os.
Note that after the disk page has been loaded into main memory, the encrypted search in
main memory can be parallelized. In order now to store the B siblings of a B-tree node
in a single disk page of x bits, one has to choose B such that 2Bm ≤ x. This is because
at each node of the B-tree we need to store two encrypted m-bit vectors, where m is the
size of the universe of keywords.
Veriﬁability of encrypted searches. Our model assumes an adversary that is curious
but honest. However, we note that our scheme can be potentially extended to support ver-
iﬁability of results in a scenario where the adversary is malicious. This could be achieved
by turning our KRB tree into a hash-based KRB tree (e.g., using Merkle hash trees [15])
and maintaining hashes at the internal nodes of the KRB tree. For verifying the result the
client could access a logarithmic number of hashes and verify the search computation
step-by-step, in logarithmic time (for that, the client also needs to store and update the
root hash of the tree). In this way, a client could be assured that no encrypted documents
have been omitted from the results, unless the adversary is able to break the collision
resistance of the hash function. We defer a more formal description of such a scheme and
a proof of security to future work.

Acknowledgments
The second author was supported by Intel through the ISTC for Secure Computing. Part
of this work was performed while the second author was interning at Microsoft Research.
The authors would like to thank Elaine Shi, Dawn Song, Emil Stefanov and Tom Roeder
for useful discussions.

10 E.g., Amazon Common Crawl Corpus, http://aws.amazon.com/datasets/41740.

References
1. B. Bloom. Space/time trade-offs in hash coding with allowable errors. Communications of the

ACM, 13(7):422–426, 1970.

2. D. Boneh and B. Waters. Conjunctive, subset, and range queries on encrypted data. In Theory

of Cryptography Conference (TCC), pages 535–554, 2007.

3. Y. Chang and M. Mitzenmacher. Privacy preserving keyword searches on remote encrypted

data. In Applied Cryptography and Network Security (ACNS), pages 442–455, 2005.

4. M. Chase and S. Kamara. Structured encryption and controlled disclosure. In Theory and

Application of Cryptology and Information Security (ASIACRYPT), pages 577–594, 2010.

5. T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein. Introduction to Algorithms. The

MIT Press, 3rd edition, 2009.

6. R. Curtmola, J. Garay, S. Kamara, and R. Ostrovsky. Searchable symmetric encryption: Im-
In Computer and Communications Security

proved deﬁnitions and efﬁcient constructions.
(CCS), pages 79–88, 2006.

7. C. Gentry. Fully homomorphic encryption using ideal lattices. In Symposium on Theory of

Computing (STOC), pages 169–178, 2009.

8. E.-J. Goh. Secure indexes. IACR Cryptology ePrint Archive, 2003:216, 2003.
9. O. Goldreich and R. Ostrovsky. Software protection and simulation on oblivious RAMs. Jour-

nal of the ACM, 43(3):431–473, 1996.

10. P. Golle, J. Staddon, and B. Waters. Secure conjunctive keyword search over encrypted data.

In Applied Cryptography and Network Security (ACNS), pages 31–45, 2004.

11. S. Kamara, C. Papamanthou, and T. Roeder. Dynamic searchable symmetric encryption. In

Computer and Communications Security (CCS), pages 965-976, 2012.

12. J. Katz and Y. Lindell. Introduction to Modern Cryptography. Chapman & Hall/CRC, 2008.
13. K. Kurosawa and Y. Ohtaki. UC-secure searchable symmetric encryption. In Financial Cryp-

tography (FC), pages 285–298, 2012.

14. J. R. Lorch, J. W. Mickens, B. Parno, M. Raykova, and J. Schiffman. Toward practical private
access to data centers via parallel ORAM. IACR Cryptology ePrint Archive, 2012:133, 2012.
15. R. C. Merkle. A digital signature based on a conventional encryption function. In International

Cryptology Conference (CRYPTO), pages 369–378, 1987.

16. D. Park, K. Kim, and P. Lee. Public key encryption with conjunctive ﬁeld keyword search. In

Workshop on Information Security Applications (WISA), pages 73–86, 2004.

17. E. Shi, J. Bethencourt, T. Chan, D. Song, and A. Perrig. Multi-dimensional range query over

encrypted data. In IEEE Symposium on Security and Privacy (SSP), pages 350–364, 2007.

18. D. Song, D. Wagner, and A. Perrig. Practical techniques for searching on encrypted data. In

IEEE Symposium on Security and Privacy (SSP), pages 44–55, 2000.

19. E. Stefanov, E. Shi, and D. Song. Towards practical oblivious ram. In Network and Distributed

System Security Symposium (NDSS), 2012.

20. P. van Liesdonk, S. Sedghi, J. Doumen, P. H. Hartel, and W. Jonker. Computationally efﬁcient
searchable symmetric encryption. In Secure Data Management (SDM), pages 87–100, 2010.

Appendix
Proof sketch of Lemma 3. We describe a simulator S that interacts with an adversary
A in an execution of an IdealA,S (k) experiment as described in Deﬁnition 5. Given
the leakage L1(δ, f ), it constructs (γ, c) as follows. It simulates the encrypted ﬁles c =
(ci1 , . . . , cin ) using the simulator SE, which is guaranteed to exist by the CPA-security
of E, together with the value n and the size of each ﬁle (both of which are included in
the leakage function). To simulate γ, it constructs a red black tree T using the identiﬁers

i = (i1, . . . , in) included in the leakage function. It then picks m random addresses
addri ∈ {0, 1}k and generates m keys (SK1, . . . , SKm) for R to be used for encrypting
the entries of the bit-vectors at the internal nodes of T . Note that m is also included in
the leakage function.

Now, for every node v of the tree T the simulator sets up two (k, m) keyword hash
tables Λ0v and Λ1v as follows: for every i = 1, . . . , m, the simulator stores (a) either
an encryption of a “0” at Λ0v[addri] and an encryption of a “1” at Λ1v[addri] or, (b)
an encryption of “1” at Λ0v[addri] and an encryption of a “0” at Λ1v[addri]. This is
decided, for every node, by ﬂipping a coin. To encrypt bit biti ∈ {0, 1} at position addri,
the simulator uses R, outputting the ciphertext R.Enc(SKi, biti) for all i = 1, . . . , m.
The simulator also stores this information locally: For each node v of T it stores a vector
statev such that statev[i] = j ∈ {0, 1} if and only if the encryption of “1” was
stored at vector Λjv, for all i = 1, . . . , m.11 Finally, the simulator outputs the encrypted
KRB tree γ to the adversary. γ consists of the red black tree T and the vectors Λ0v and
Λ1v for every node v of T . We continue by distinguishing two cases, one for adaptive
queries and one for adaptive updates. Before that we recall that given a search query for
keyword w that takes place at time t, the leakage L2(δ, f , w, t) consists of the search
pattern P(δ, q, t) and the access pattern ∆(δ, f , w, t) (from Deﬁnitions 3 and 4):
1. Adaptive queries: Suppose the simulator receives a new query q for a keyword wi.
Using L2(δ, f , wi, t) the simulator knows whether this query has appeared before
(due to the search pattern P(δ, q, t)), and if so, it outputs the same token τs. Else, the
simulator picks an address addri that has not been used before. The simulated token
is τs = (addri, SKi). After the adversary receives the token τs = (addri, SKi) =
(τ1, τ2) he is able to execute the search by using the algorithm Search(γ, c, τs), in a
way that Search is accessing exactly the same locations contained in the access pat-
tern ∆(δ, f , wi, t), therefore always returning the correct answer. We show, that this
can be achieved by appropriate use of the random oracle. Namely, the output b of the
random oracle at Step 1 of the Search(γ, c, τs) algorithm (with reference to node v)
is programmed by the simulator in the following manner: if v is contained in the path
to an identiﬁer contained in the access pattern ∆(δ, f , wi, t), then b is the bit such that
R.Dec(τ2, Λbv[τ1]) = 1. Otherwise, b is the bit such that R.Dec(τ2, Λbv[τ1]) = 0.
Note that the appropriate bit can be determined by the simulator, since it is storing
the state vector statev, for every node v of the tree T .

2. Adaptive updates: Suppose the simulator receives a new query q = u = fi for in-
serting/deleting document fi with identiﬁer i. If u is an insertion, the simulator uses
SE to simulate ci (note that while fi is not available to the simulator, its identiﬁer
is revealed through the updated leakage L1(δ, f )). Now let infoi,u be the helper in-
formation that is returned during the protocol by UpdHelper. We recall that infoi,u
consists of a certain subtree T (u) of T , namely the portion of the red-black tree T
that is accessed during the update. The simulator can now compute T (cid:48)(u) (since he
knows the identiﬁer of the new document) which is the new subtree after the update.
For every node v(cid:48) that changes its structure in the subtree T (cid:48)(u) (e.g., it obtains a

11 Note that the simulator could also retrieve that information without storing it, by using the initial

randomness he used to compute it.

new child), and has a new identiﬁer id(v(cid:48)), the simulator does the following (similar
actions taken in the setup phase of the simulation):
(a) it instantiates two (k, m) keyword hash tables with random entries Λ0v(cid:48) and Λ1v(cid:48)

and stores λ0v(cid:48) and λ1v(cid:48) at v;

(b) For every i = 1, . . . , m, the simulator reinitializes the keyword hash tables Λ0v(cid:48)
and Λ1v(cid:48) by storing (a) either an encryption of a “0” at Λ0v(cid:48)[addri] and an en-
cryption of an “1” at Λ1v(cid:48)[addri] or, (b) an encryption of “1” at Λ0v(cid:48)[addri]
and an encryption of a “0” at Λ1v(cid:48)[addri]. This is decided by ﬂipping a coin.
Again, to encrypt bit bi ∈ {0, 1} at position addri, the simulator executes
R.Enc(SKi, bi). Also the simulator updates its state statev(cid:48) accordingly.

(c) Output τu := (T (cid:48)(u), ci).

After the update, if the adversary searches for keywords for which it has old tokens, the
simulator can again control the search by programming the random oracle appropriately
since it gets the updated leakage ∆(δ, f , wi, t) for each previous keyword for which a
token was issued at time t.
It remains to show that for all PPT adversaries A, the outputs of a RealA(k) and of
an IdealA,S (k) experiment are negligibly close. This holds for the following reasons.
The keys used in the tokens and the ones used to encrypt the hash table elements are
indistinguishable from real keys since they are constructed with PRFs which are indistin-
guishable from random functions. Therefore, the CPA-security of E and R guarantee that
the adversary cannot distinguish between the real and simulated encryptions of the ﬁles
and bit vectors, respectively. Finally, the answers returned by simulator to the adversary’s
random oracle queries are consistent and are appropriately distributed. (cid:3)

