ZØ: An Optimizing Distributing  

Zero-Knowledge Compiler

Matthew Fredrikson, University of Wisconsin—Madison;  

Benjamin Livshits, Microsoft Research

https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/fredrikson

This paper is included in the Proceedings of the 23rd USENIX Security Symposium.August 20–22, 2014 • San Diego, CAISBN 978-1-931971-15-7Open access to the Proceedings of  the 23rd USENIX Security Symposium is sponsored by USENIXZØ: An Optimizing Distributing Zero-Knowledge Compiler

Matthew Fredrikson

University of Wisconsin

Benjamin Livshits
Microsoft Research

Abstract
Traditionally, conﬁdentiality and integrity have been two
desirable design goals that are have been diﬃcult to com-
bine. Zero-Knowledge Proofs of Knowledge (ZKPK) of-
fer a rigorous set of cryptographic mechanisms to bal-
ance these concerns. However, published uses of ZKPK
have been diﬃcult for regular developers to integrate into
their code and, on top of that, have not been demon-
strated to scale as required by most realistic applications.
This paper presents ZØ (pronounced “zee-not”), a
compiler that consumes applications written in C#
into code that automatically produces scalable zero-
knowledge proofs of knowledge, while automatically
splitting applications into distributed multi-tier code. ZØ
builds detailed cost models and uses two existing zero-
knowledge back-ends with varying performance charac-
teristics to select the most eﬃcient translation. Our case
studies have been directly inspired by existing sophisti-
cated widely-deployed commercial products that require
both privacy and integrity. The performance delivered
by ZØ is as much as 40× faster across six complex ap-
plications. We ﬁnd that when applications are scaled to
real-world settings, existing zero-knowledge compilers
often produce code that fails to run or even compile in
a reasonable amount of time. In these cases, ZØ is the
only solution we know about that is able to provide an
application that works at scale.
1
As popular applications rely on personal, privacy-
sensitive information about users, factors such as legal
regulations, industry self-regulation, and a growing body
of privacy-conscious users all pressure developers to re-
spond to demands for privacy. Storing user’s data in
the cloud creates downsides for the application provider,
both immediately and down the road. While policy mea-
sures such as DoNotTrack and anonymous advertising
identiﬁers become increasingly popular, a recent trend
explored in several research projects has been to move
functionality to the client [13, 17, 37, 40]. Because ex-
ecution happens on the client, such as a mobile device
or even in the browser, this alone provides a degree of
privacy in the computation: only relevant data, if any, is
disclosed (to a server). However, in many cases, moving

Introduction

functionality to the client conﬂicts with a need for com-
putational integrity: a malicious client can simply forge
the results of a computation.

Traditionally, conﬁdentiality and integrity have been
two desirable design goals that are have been diﬃcult to
combine. Zero-Knowledge Proofs of Knowledge (ZKPK)
oﬀer a rigorous set of cryptographic mechanisms to bal-
ance these concerns, and recent theoretical developments
suggest that they might translate well into practice. In
the last several years, zero-knowledge approaches have
received a fair bit of attention [23]. The premise of
zero-knowledge computation is its promise of both pri-
vacy and integrity through the mechanism cryptographic
proofs. However, published uses of ZKPK [4, 5, 7, 8,
19, 36] have been diﬃcult for regular developers to in-
tegrate into their code and, on top of that, have not been
demonstrated to scale, as required by most realistic ap-
plications.
Zero-knowledge example: pay as you drive insur-
ance: A frequently mentioned application and a good
example of where zero-knowledge techniques excel is
the practice of mileage metering to bill for car insur-
ance: pay as you drive auto insurance is an emerging
scheme that involves paying a rate proportional to the
number of miles driven, either linearly, or using several
billing brackets [4, 38, 41]. Of course, given that the
insurance company knows much about the customer, in-
cluding their address, if daily mileage data is provided,
much can be inferred about user’s daily activities, where
they shop, etc. [15, 29, 30]. The user in this scheme
performs a calculation on their own data, but of course
the insurance company wants to prevent cheating. Zero-
knowledge proofs provide a way to ensure both privacy
and integrity, which involves performing the billing com-
putation on the user’s hardware (on the client), perhaps,
monthly, and providing the insurance company with 1)
the ﬁnal bill and 2) a proof of correctness of the account-
ing calculation, which can be veriﬁed by the insurance
company (on the server) [4, 18, 35, 39].
What we did: In this paper, we present ZØ, a com-
piler that consumes applications written in a subset of C#
into code that produces scalable zero-knowledge proofs
of knowledge, while automatically splitting applications
into distributed code, to be executed on two (or more)

USENIX Association  

23rd USENIX Security Symposium  909

execution tiers. We are building on very recent develop-
ments in zero-knowledge cryptographic techniques [16,
31], exposing to the developer the ability to take advan-
tage of these advances. ZØ builds detailed cost models
of the code regions that require ZKPK, and uses exist-
ing zero-knowledge back-ends with varying performance
characteristics to select the most eﬃcient translation, by
formulating and solving constrained numeric optimiza-
tion problems. Our cost modeling takes advantage of the
strengths of both back-ends, while avoiding their weak-
nesses, both for local and global (distributed) optimiza-
tion. Using a set of realistic applications that perform
tasks such as distributed data mining and crowd-sourced
data aggregation, we demonstrate ZØ’s ability to produce
privacy-preserving code which runs signiﬁcantly faster
than previously possible.
High-level goals: ZØ aims to provide an attractive com-
bination of high-level goals of privacy, integrity, expres-
siveness, and performance. While the ﬁrst two goals
are achieved through the use of zero-knowledge, to sup-
port ease of programming and expressiveness, ZØ ac-
cepts (a subset of) C#, a widely-used general purpose
language as input that can run in many settings. Of
course, we are not tied to C# and could support an-
other high-level language such as JavaScript, Java, or
C++. Our use of a general-purpose language allows de-
velopers to include hundreds or thousands of lines of C#
or other .NET code, allowing the construction of full-
featured GUI-based distributed applications that support
zero-knowledge instead of small examples written in a
domain-speciﬁc language.

To enable distributed programming wherever .NET
code can run, ZØ supports automatic tier-splitting, in-
spired by distributing compilers such as GWT [20] and
Volta [24]. We primarily target client-server computa-
tions (two tiers), although other options such as P2P are
also supported by ZØ. Code produced by ZØ can be run
on desktops, in the cloud, on mobile devices (Windows
Phone) and on the web (Silverlight).
Applications: Much of the inspiration for ZØ came
from our desire to be able to use ZKPK techniques to
build applications directly analogous to some widely-
deployed commercial products, as opposed to toy bench-
marks.
In our studies detailed in Section 7, we show
how they can be (re-)built in a privacy- and integrity-
preserving way. For example, our FitBit study was in-
spired by wireless activity tracking devices manufactured
by FitBit (fitbit.com) and Earndit (earndit.com).
The Slice study was inspired by purchase tracking soft-
ware from Slice, Inc. (slice.com). The study Waze app
was inspired by Waze, a popular crowd-sourced, real-
time traﬃc app for mobile platforms (waze.com).
Contributions: We make these contributions:

• This paper proposes ZØ, a distributing compiler that
allows developers to create highly performant, large
distributed applications, while preserving both privacy
and integrity. ZØ uses precisely calibrated cost mod-
els to choose which underlying zero-knowledge back-
end to employ. Based on the cost model, ZØ statically
determines the appropriate splitting perimeter for the
application to achieve best performance and rewrites
it to be run on multiple tiers.

• Developer: ZØ is designed to be easily accessi-
to this end, we expose
ble to a regular developer;
zero-knowledge functionality via LINQ,
language-
integrated-queries built into .NET. We demonstrate the
expressiveness of the ZØ approach by developing six
case studies directly inspired by commercial appli-
cations which we hope will become benchmarks for
zero-knowledge tools, ranging from personal ﬁtness
tracking (Fitbit) to crowd-sourced traﬃc-based rout-
ing (Waze), to personalized shopping scenarios.

• Cost modeling: We develop cost models for the indi-
vidual back-ends, allowing us to perform global cross-
tier optimizations. Our cost-ﬁtting models provide
an excellent match with the observed performance,
with R2 scores between .98 and .99.

• Speedup: We evaluate ZØ on six complex real-life
large-scale applications of zero knowledge, focusing
on latency and throughput of zero-knowledge tasks.
Our global optimizer is fast, completing in under 3
seconds on all programs. ZØ produces code that
achieves as much as 40× speedups compared to state-
of-the art zero-knowledge systems. We also ﬁnd that
ZØ is able to eﬀectively optimize across tiers in a
distributed application: while the code it generates
may be slower on one tier (we observed one case that
was 2× slower for the server), the savings at other tiers
are always greater (e.g., 4× faster on the client).
• Scale: At scale, existing zero-knowledge compilers
often produce code that fails to run in a reasonable
amount of time, or exhaust system resources during
compilation. In these cases, ZØ is the only solution
that is able to provide a working application.

Paper Organization: The rest of the paper is organized
as follows. Section 2 provides motivating examples and
some background on zero-knowledge. Section 3 gives
an overview of the ZØ approach. Section 5 describes
the ZØ compiler implementation. Section 4 talks about
cost models and both local and global optimizations ZØ
performs. Section 5 describes ZØ implementation. Sec-
tion 6 discusses how ZØ translates C# into ZK proof-
generating code. Section 7 presents six case studies.
Section 8 describes our experimental evaluation. Re-
lated work is discussed in Section 10 and Section 11
concludes the paper. The PDF version of this paper has

910  23rd USENIX Security Symposium 

USENIX Association

public void DoWork ( string [] args )
{

var discount =

GetDiscounts ( shophist , items ,

automata , transducer );

ApplyDiscount ( discount );

public void Initialize ( string [] args )
{...}

ZeroKnowledgeBegin ();
// Check that the history is in ascending order
var historyAscendingCheck = history . Aggregate (

[ Location ( Client )]
IEnumerable < Pair > GetDiscounts (
[ MaxSize ( Purchases )] IEnumerable <int > history ,
[ MaxSize ( Items )] IEnumerable <int > items ,
[ MaxSize ( Edges )] IEnumerable < Triple > automata ,
[ MaxSize ( States )] IEnumerable < Pair > transducer )

// Local variable declarations
[ Location ( Client )] IEnumerable <int > shophist ;
[ Location ( Client )] IEnumerable <int > items ;
IEnumerable < Triple > automaton ;
IEnumerable < Pair > transducer ;

1 public class LoyaltyCard : DistributedRuntime
2 {
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59 }

[ Location ( External )] void ApplyDiscount (...)
{...}

0,
( last , curel ) => check ( last <= curel ));

// Total the current state discount
state . fld (2) + transducer . First (

edge => edge . fld (1) == state . fld (1)));

var discount = history . Aggregate (

new Pair ( purch_state , 0) ,
( state , purch ) =>

// Get the " discount state "
var purch_state = history . Aggregate (

// Get the next automata state
automata . First (

trans => ( trans . fld (1) == state . fld (1))

&& ( trans . fld (2) == purch )).
fld (3) ,

0,
( state , purch ) =>

automaton . First (

trans => ( trans . fld (1) == state ) &&

( trans . fld (2) == purch )).

fld (3));

}

{

}

new Pair (

ZeroKnowledgeEnd ();

return new IEnumerable < Pair >( discount );

Figure 1: Example application: a personalized retail loyalty card.

with additional diagrams to supplement

an
the main text.
2 Background
To explain the goals of ZØ concretely, we will demon-
strate its functionality on a smartphone application with
conﬂicting privacy and integrity needs.
2.1 Example: Retail Loyalty Card
Figure 1 shows the ZØ code for a personalized retail loy-
alty card mobile app, with functionality similar to Safe-

❶ 

discount claim + ZKPK

transcations

❷ signed purchase transaction

100

Figure 2: Personalized loyalty card application.

way’s “Just for U” application or Walgreens’ iOS appli-
cation. Each time the customer reaches the check-out
line, this application interacts with the retail terminal in
a bi-directional exchange of information. The exchange
takes place using the phone’s built-in NFC sensor.

First, the application sends a discount claim to the re-
tail terminal, pertaining to the items the customer is about
to purchase. This discount is computed based on the
customer’s previous purchases, using personalization to
provide enhanced value and incentive for the customer.
Zero-knowledge proofs are supplied to ensure the pri-
vacy of the customer’s shopping history, without sacri-
ﬁcing the trustworthiness of their discount claim.

Second, the terminal sends a list of purchases to the
client, corresponding to the current check-out transac-
tion. This list, along with the customer’s other previous
purchases, will be stored in a client-side database used to
compute a discount the next time the user shops with this
retailer.
Application Code: Figure 1 contains C# code for com-
puting the core functionality of this application: using
the customer’s purchase history to produce a discount,
and sending that discount to the retail terminal.
It is
important to notice that this is standard C#, capable of
seamless incorporation into larger bodies of C# code. In
fact, ZØ extends the standard C# compiler, and only ap-
plies specialized reasoning to classes that inherit from
ZØ’s DistributedRuntime class. All of the UI and ex-
ternal library code can remain in the application, without
aﬀecting the performance and functionality of ZØ. This
allows ZØ to scale to large applications with arbitrary
legacy dependencies, provided that the sections requiring
zero-knowledge reasoning are localized and moderate in
size. Several important points bear mentioning.

First, of the four functions,

two of them, which
we call worker functions, contain location annotations:
GetDiscounts is constrained to execute on the client
the user’s smartphone), and ApplyDiscount to
(e.g.,
External (e.g., the retail terminal). ZØ generates sep-
arate object code for each of these locations, and inserts
code to handle the network transfer and data marshalling
for any dependencies between these two functions. In or-
der to streamline the code generated by ZØ, the worker
functions must always return void or IEnumerable ob-

USENIX Association  

23rd USENIX Security Symposium  911

jects, which ZØ’s underlying runtime is optimized to
quickly marshall and transfer.

Second, the target functionality is computed from the
main function DoWork, which is called after Initialize.
Initialize gives the application an opportunity to pre-
pare the class’s local state by reading sensors, buﬀering
data, etc., and can contain arbitrary C# code. DoWork
is more constrained: it can contain a sequence of calls
to worker functions, with no intermediate local compu-
tations, branching statements, or loop statements. This
allows ZØ to eﬃciently compute the dependencies be-
tween diﬀerent tiers. In this case, ZØ determines that the
return value of GetDiscounts (computed on the smart-
phone) is always used by ApplyDiscount (computed on
the retail terminal), and inserts code to package and send,
or receive and unpack, the necessary data as well as any
accompanying zero-knowledge proofs.

Third,

the main code is located in GetDiscounts,
which takes a list of the user’s previous purchases
(history), the user’s current check-out items (items),
and a ﬁnite-state transducer (automata and transducer),
and produces a discount dollar value for transfer to the
retail terminal. The transducer is produced by the re-
tailer, and is designed to associate past purchases to items
that the customer may be interested in buying in the fu-
ture; the details of designing the transducer are beyond
the scope of this work. GetDiscounts begins by check-
ing that the purchases are given in ascending order, by
their ID numbers; this is a simple optimization that al-
lows the retailer to minimize the size of the transducer.
This check is performed using LINQ’s Aggregate oper-
ator, and ZØ’s check function, which behaves like an
assertion.
It then proceeds to traverse the transducer’s
ﬁnite-state machine using the customer’s shopping his-
tory, eﬀectively loading the history into the transducer’s
memory in preparation for emitting discount values.

Finally, the customer’s current items are processed by
traversing the ﬁnite-state machine, starting in the ﬁnal
state of the previous traversal, and summing the output
of the transducer relation. The ﬁnal sum is returned to
DoWork as a discount claim.
Zero-knowledge: The entirety of GetDiscounts is
computed in zero-knowledge, as indicated by the
ZeroKnoweldgeBegin() and ZeroKnowledgeEnd() annota-
tions. Notice that each statement of this method con-
sists of a LINQ query, giving the computation an overall
functional form, without using language features such as
references, loops, or conditionals. This is necessary to
accommodate faithful translation into code that produces
zero-knowledge proofs using the zero-knowledge back-
ends discussed in Section 2.2. However, the programmer
is still able to express computations in this fragment of
standard C#, without dealing with the overhead of inter-
language binding between the engines and the main pro-

gram, and without needing to learn the diﬀerent input
languages understood by each engine.

Finally, a few subtle details of this code bear mention-
ing. Two of the class variable declarations, shophist
and items, have location annotations that tell ZØ that
they should not leave the customer’s smartphone with-
out ﬁrst being processed by zero-knowledge code. This
gives the programmer an extra degree of assurance of
the code’s privacy properties, letting her treat the zero-
knowledge code regions like declassiﬁers with additional
integrity guarantees. Finally, notice that the parameters
to GetDiscounts contain MaxSize attribute annotations.
These optional size annotations allow the ZØ compiler
to do precise cost modeling, as explained in Section 4.
2.2 Zero-Knowledge Back-ends
ZØ relies on two zero-knowledge back-ends, Pinoc-
chio [31] and ZQL [16], to produce code that balances
privacy and integrity. Each of these back-ends takes an
expression, in the form of executable code in a high-level
source language, and produces object code that computes
the expression over dynamically-provided inputs while
building zero-knowledge proofs for the expression on the
given input. These engines have very diﬀerent character-
istics that aﬀect performance and usability in diﬀerent
ways, which we outline here.
Pinocchio: Pinocchio utilizes a novel underlying com-
putation model, Quadratic Arithmetic Polynomials, to
evaluate an expression and produce zero-knowledge
proofs [31]. For some computations, it yields perfor-
mance gains several orders of magnitude beyond pre-
vious systems that gave similar functionality, producing
proofs of a constant size regardless of the size or struc-
ture of the target expression.

The expression language supported by Pinocchio is a
strict subset of C, and the object created for evaluation is
an arithmetic circuit [31]. The fact that the target circuit
must be ﬁnite, and cannot encode side-eﬀects, imposes
necessary conditions on the parts of C that are available.
Loops and conditionals are “unrolled” during compila-
tion, so all loops must have static bounds. Likewise,
pointers and array indices must be compile-time con-
stants, or simple loop variables (as these are unrolled),
thus simplifying cost modeling. For this paper we used a
publicly released version of Pinoccio 0.4 obtained from
the public distribution1.
ZQL: ZQL utilizes several fairly recent advances in the
theory of zero-knowledge proofs to produce eﬃcient ver-
iﬁed private code that operates over functional lists [16].
The underlying cryptographic machinery used by ZQL
is more traditional than that of Pinocchio, relying heav-
ily on homomorphic commitment schemes to provide its

1https://vc.codeplex.com/downloads/get/714129

912  23rd USENIX Security Symposium 

USENIX Association

-
o
r
e
Z

l

e
g
d
e
w
o
n
k

60*expOp + 1800*expOp + 
2*hashOp + 30*hashOp + 
900*hashOp + 30*hashOp + 
30*mltEOp + 900*mltEOp + 
2*sigSignOp

900*eqOp + expOp + 60*expOp + 
6300*expOp + extendOp + 
60*extendOp + 4500*extendOp + 
60*extendOp + 30*mltEOp + 
60*mltOp + 60*subOp + 
2700*invEOp + 3600*mltEOp +
5400*mltOp + 900*sIntNumOp + 
3600*subOp + 6*sIntNumOp

30*expOp + 450*expOp + 
2*hashOp + 15*hashOp + 
225*hashOp + 15*hashOp + 
15*mltEOp + 225*mltEOp + 
2*sigSignOp

eqOp + 3*expOp + 90*expOp + 
9900*expOp + extendOp + 
30*extendOp + 2700*extendOp
+ 2*hashOp + 30*hashOp + 
900*hashOp + 30*hashOp + 
60*mltEOp + 3600*invEOp + 
6300*mltEOp + 900*mltOp + 
1800*sIntNumOp + 900*subOp + 
mltEOp + 3*mltOp + 
6*sIntNumOp + 2*sigVerifyOp + 
3*subOp

225*eqOp + expOp + 30*expOp + 
1575*expOp + extendOp + 
30*extendOp + 1125*extendOp + 
30*extendOp + 15*mltEOp + 
30*mltOp + 30*subOp + 
675*invEOp + 900*mltEOp + 
1350*mltOp + 225*sIntNumOp + 
900*subOp + 6*sIntNumOp

eqOp + 3*expOp + 45*expOp + 
2475*expOp + extendOp + 
15*extendOp + 675*extendOp + 
2*hashOp + 15*hashOp + 
225*hashOp + 15*hashOp + 
30*mltEOp + 900*invEOp + 
1575*mltEOp + 225*mltOp + 
450*sIntNumOp + 225*subOp + 
mltEOp + 3*mltOp + 
6*sIntNumOp + 2*sigVerifyOp + 
3*subOp

60*expOp + 1800*expOp + 
2*hashOp + 30*hashOp + 
900*hashOp + 30*hashOp + 
30*mltEOp + 900*mltEOp + 
2*sigSignOp

900*eqOp + expOp + 60*expOp + 
6300*expOp + extendOp + 
60*extendOp + 4500*extendOp + 
60*extendOp + 30*mltEOp + 
60*mltOp + 60*subOp + 
2700*invEOp + 3600*mltEOp +
5400*mltOp + 900*sIntNumOp + 
3600*subOp + 6*sIntNumOp

(fold
(fun (acc,i) ! ((let (_1, _2) 
= acc in _2),
(let (_1, _2) = acc in _1)
+ (let (_1, _2) = acc in 
_2)))
(1, 1) inputNums)

eqOp + 3*expOp + 90*expOp + 
9900*expOp + extendOp + 
30*extendOp + 2700*extendOp
+ 2*hashOp + 30*hashOp + 
900*hashOp + 30*hashOp + 
60*mltEOp + 3600*invEOp + 
6300*mltEOp + 900*mltOp + 
1800*sIntNumOp + 900*subOp + 
mltEOp + 3*mltOp + 
6*sIntNumOp + 2*sigVerifyOp + 
3*subOp

n
o
i
t
a
c
i
f
i
c
e
p
s
 
r
e
T

i

d
e
t
a
l
s
n
a
r
t
 
e
d
o
c
 
e
g
d
e
w
o
n
k
-
o
r
e
Z

l

Tier 1

(fold
(fun (acc,i) ! ((let (_1, _2) 
= acc in _2),
(let (_1, _2) = acc in _1)
+ (let (_1, _2) = acc in 
_2)))
(1, 1) inputNums)

Tier 2

Tier 1

1) Input is supplied as C# code, containing a 

mix of ZK blocks and regular blocks.

2) Cost modes for ZQL and Pinoccio are used 

to decide ZK runtime costs.

3) Appropriate ZK translations are generated 

in .NET IL.

4) Final .NET DLLs are produced for each tier

Figure 3: ZØ architecture. ZQL and Pinoccio are used as sample back-ends for illustrative purposes.

guarantees. The expression language supported by ZQL
is a simple functional language without side eﬀects, and
limited operator support.
In a nutshell, ZQL supports
map and fold operations, as well as ﬁnd operations over
tuples of integers. Boolean expressions can only be used
inside of ﬁnd operations, and are currently limited to con-
junctions of equality tests; all forms of inequality are not
explicitly supported, although the authors plan to sup-
port these operations in future versions. In terms of arith-
metic, addition, subtraction, and multiplication are sup-
ported. Finally, multiple operations can be sequenced us-
ing classic functional let bindings. Although these con-
structs might seem modest at ﬁrst blush, the ability to
perform table lookups using ﬁnd allows for the evaluation
of logic gates, and the list-based map and fold operations
place no upper-bound on the size of the program’s input,
as in the case of Pinocchio. We obtained a version of
ZQL from its authors.

3 Overview
Figure 3 shows the architecture of the ZØ compiler. The
developer provides as input a set of C# source ﬁles,
which may include arbitrary regions of legacy and li-
brary code as well as functionality targeted towards zero-
knowledge proof generation. ZØ then enters a cost mod-
eling stage, analyzing the zero-knowledge regions, build-
ing performance models that characterize the cost of pro-
viding zero-knowledge proof generation and veriﬁcation
code for each available zero-knowledge back-end. These
models take the form of polynomials over the size of the
input data to the zero-knowledge region in the original
C# application. ZØ then compares the models to deter-
mine which engine the application should use for each
C# statement in the region, and translates the C# code
(depicted in the zero-knowledge translation stage of Fig-
ure 3) into expressions understood by the appropriate
zero-knowledge engine. In the ﬁnal output stage (Fig-

Redeem	  workout	  

Apply	  discount	  

Process	  a	  GPS	  Reading	  

Z0	  
Pinocchio	  
ZQL	  
350	  

450	  

0	  

50	  

400	  
Figure 4: Comparison of times for several applications.

100	  

150	  

300	  

200	  

250	  

ure 3), ZØ decides how to split the application across
tiers to maximize performance, given privacy annota-
tions as well as relative costs for transmitting data and
computing at each tier.

This translation yields a separate module which is
callable from the original application, either as an
arithmetic circuit (Pinocchio) or standard .NET byte-
code (ZQL). Finally, ZØ partitions the original C# code,
along with the zero-knowledge modules compiled in the
previous step, into multiple applications to run at each
service tier. During partitioning, ZØ inserts code to per-
form communication, synchronization, data marshaling,
and zero-knowledge proof transfer in parallel to the orig-
inal application code. The resulting modules are standard
.NET bytecode that can be run on the proper tiers without
the need for additional specialized software.
Optimization & cost models: Even apparently straight-
forward applications like the personalized loyalty card
app discussed in Section 2.1 contain subtle character-
istics that might make zero-knowledge proof genera-
tion expensive.
It is often the case that one zero-
knowledge engine oﬀers signiﬁcantly better performance
for a particular statement, and selecting the appropri-
ate engine for each computation in the zero-knowledge
region means the diﬀerence between a scalable, low-
latency implementation and one that requires hours or
days to execute.

USENIX Association  

23rd USENIX Security Symposium  913

For the loyalty card application in Figure 1, it turns
out that the inequality comparisons are better handled by
Pinocchio, whereas the table lookups needed to execute
the transducer are very inexpensive when performed by
ZQL. A comparison of the times to perform the opera-
tion on the y-axis for several applications from Section 7
is shown in Figure 4. We can see dramatic diﬀerences
in performance between the back-ends, with the ZØ ap-
proach out-performing either of the two back-ends. ZØ
addresses these performance diﬀerences by building de-
tailed performance models for each statement in the zero-
knowledge region.
Distributed conﬁguration: To support a variety of dis-
tributed scenarios, ZØ allows the developer to place
code on several diﬀerent tiers, which are speciﬁed us-
ing the following tier labels: Client (end-user’s primary
device), External (provider’s servers), ClientShare (peer-to-
peer nodes), and ClientResource (additional hosts owned by
end-user). Tiers impose data conﬁdentiality and integrity
constraints, as ZØ makes assumptions about the trust re-
lationships between tiers.

The ﬁgure in this paragraph shows these relationships;

Note that by design, these annotations are lightweight:
they are only needed on (the few) variables that must be
kept conﬁdential. Most can be declared without any an-
notations at all.

When ZØ compiles the application and runs a global
optimization described in Section 4.2 to place each
worker method on a speciﬁc tier, privacy annotations are
used in part to determine on which tiers a method may
reside. These constraints are hard, meaning that a pri-
vacy annotation that requires a less performant compila-
tion conﬁguration will always be respected; if the pri-
vacy constraints conﬂict with each other, then compi-
lation will not terminate early. Privacy annotations are
propagated transitively using a local dataﬂow analysis,
so that dependent variables have matching annotations.
Threat model: Because of
its reliance on zero-

E

C CS CR

C
CS
CR
E

white cells indicate trust, and
gray the opposite. At compile
time, the user can modify the con-
ﬁguration by specifying weights
on each tier label indicating the
relative cost of computation at that tier, as well as the cost
of communication between tiers. ZØ uses these weights
during optimization to determine the best placement of
code and data amongst the tiers, and are only necessary
to ﬁne-tune the performance of certain applications; they
can be ignored and left at the default value of 1 by de-
fault. Data privacy constraints are given by the program-
mer by marking certain variables as private to a particu-
lar tier using the attribute [Private(TL)], where TL speciﬁes
the tier to which the data is considered private (e.g., Client,
External, . . . ).

knowledge back-ends, ZØ makes all of the assumptions
needed for security by ZQL [16] and Pinocchio [31]. The
result of ZØ compilation will be executed on one or more
tiers. Privacy is violated when the trust relationships
given in the previous section are violated. We assume
that tiers cannot learn information by means other than
direct communication, i.e. Server cannot obtain the list of
purchases through side channels, for instance, unless it is
directly shared by Client. Our applications that use secret
sharing (Waze and Slice in Section 7) also assume that
P2P clients do not collude.
4 Cost Models & Optimizations
This section discusses ZØ’s cost modeling approach to
optimizing zero-knowledge computations. As outlined
in Section 3, in many cases one zero-knowledge engine
will outperform the other on a particular computation by
a signiﬁcant factor, giving ZØ a key opportunity to opti-
mize the code it produces. ZØ optimizes zero-knowledge
regions by building detailed performance models that
characterize the cost of building and verifying zero-
knowledge proofs in each engine. We are able to accom-
plish this with reasonable accuracy because the execution
depth of zero-knowledge regions is statically-bounded (a
necessary condition imposed by the underlying engines),
and the evaluation of zero-knowledge code universally
relies on a few primitive operations. This allows ZØ to
build static cost models as polynomials over the number
of primitive operations each region must execute.

Section 4.1 discusses local optimizations within a
given zero-knowledge region to decide which back-end
to use. Section 4.2 proposes a split for the entire applica-
tion designed for maximal performance.
4.1 Local Optimization
In order to build cost models for ZQL code, we execute
the F# “object code” generated by ZQL’s compiler sym-
bolically. Symbolic data is represented by polynomials
that characterize the size of the corresponding concrete
data, or structured sets of polynomials in the case of
structured data types. The symbolic operation for each
ZQL operation accumulates terms on a polynomial that
characterize the cost of that operation in terms of the size
of its input data, and returns a new polynomial that char-
acterizes the cost of producing of the result. Because
the execution depth of iteration commands is always a
polynomial function of the size of the inputs, and ZQL
programs do not contain branching, accumulating a cost
polynomial by symbolic execution necessarily accounts
for all of the operations contained in a ZQL program.

Recall that Pinocchio compiles C code into a circuit,
which is evaluated by a specialized runtime to produce
and verify zero-knowledge proofs. The Pinocchio run-
time executes roughly the same code to evaluate every

914  23rd USENIX Security Symposium 

USENIX Association

FitBit
Waze
Loyalty
Slice
Average

Setup
0.01
0.11
0.03
0.06
0.05

Pinocchio

ZQL
Prover Verif. Keygen Prover Verif.
0.00
1.81
0.00
0.29
0.00
0.35
0.41
0.00
0.00
0.72

0.39
0.04
0.31
0.05
0.20

0.20
0.02
0.20
0.03
0.11

0.10
0.25
0.11
0.32
0.20

Figure 5: Absolute regression error (in seconds).

circuit, varying only on the number of times each opera-
tion is executed to handle every element of each input list
and every operation in the circuit. We build a set of static
polynomials that characterize the execution time of the
runtime in terms of the size of the input circuit, i.e., the
number of I/O wires and multiplication gates it contains.
For example, the cost of the veriﬁcation stage is given by
the polynomial:

ExpMulB × NInputs + 12 × Pair + VerifyConst

In this polynomial, ExpMulB corresponds to the amount
of time taken to complete a multi-Exponentiation on the
Pinocchio’s base elliptic curve, NInputs to the number
of input wires in the circuit, Pair to the ﬁeld pairing
cost [31], and VerifyConst to a ﬁxed setup cost for the
veriﬁcation stage. Similar polynomials are derived for
the other stages of Pinocchio’s runtime.

We use least-squares regression to derive coeﬃcients
for all models except those for Pinocchio’s compute-
stage model, which contains a non-linear term cor-
responding to the O(n · log2n) runtime of polyno-
mial interpolation. To cope with the non-linearity in
Pinocchio’s compute-stage model, we use the Gauss-
Newton method [33] with at most 1,000 iterations and
a randomly-chosen starting point.
Cost-ﬁtting results: To derive the necessary coeﬃcients
for our models, we built a regression training applica-
tion in ZØ consisting of several basic operations likely
to appear in zero-knowledge applications. The training
application takes as input a list of integers, and computes
an aggregate sum, scalar product, second-degree polyno-
mial, boolean mapping, and table lookup on the list. We
compiled this application to use both all-ZQL and all-
Pinocchio zero knowledge computations, and ran it ten
times for each zero-knowledge engine using a ﬁxed list
size (n = 100). We performed regression to learn coeﬃ-
cients corresponding to the execution time of each primi-
tive operation appearing in the cost model. We then com-
piled a representative subset of the applications described
in Section 7 to use either all-ZQL or all-Pinocchio zero-
knowledge computations, executed each zero-knowledge
region ten times, and recorded the deviation between
execution time predicted by the regression-trained cost
models and the mean execution time observed over all
experiments for a given application. Figure 5 presents

the prediction error of the trained cost models in terms
of the total zero-knowledge execution time in seconds.
Note that the models derived for Pinocchio are gener-
ally more accurate in terms of relative error than those
for ZQL, but the error in both cases is quite small: the
greatest Pinocchio error is 0.39 seconds (on FitBit’s key
generation routine), while the greatest ZQL error is 1.81
seconds (on FitBit’s prover routine). The coeﬃcient
of determination (R2) for each performance model is at
least 0.98, indicating a precise ﬁt of the models to the
execution time.
Summary: To summarize, ZØ is able to build perfor-
mance models of zero-knowledge regions that predict ac-
tual execution time within tenths of a second in most
cases, which provides ample accuracy to make a cor-
rect decision when selecting zero-knowledge engines at
compile-time.
4.2 Global Optimization
ZØ builds cost polynomials to characterize the expense
of each zero-knowledge operation in the target appli-
cation. However, selecting the least expensive engine
for each operation is oftentimes not as straightforward
as evaluating each polynomial at a target input size and
choosing the engine corresponding to the lesser value —
it may be the case that a less expensive operation on the
prover’s side requires a more expensive operation on the
veriﬁer’s side, and depending on the application compu-
tation may be more expensive for the veriﬁer. Alterna-
tively, there may be several ways to partition an applica-
tion between tiers while preserving the privacy of vari-
ables at each tier, with each partition yielding a diﬀerent
trade-oﬀ between computation and communication cost.
To address these concerns, ZØ performs global optimiza-
tion on the application to balance the cost of computation
and communication among diﬀerentiated tiers.
Performance
optimization:
implemented
gorithm
as
We use CCI2 to traverse the AST
of the target code, and our cost
modeler to generate the objective
function.

We
al-
compiler.

of
our
part

optimization

global
of

Constr. Time

global

the

ZØ

179
38
263
230

1.50
FitBit
0.01
Loyalty
2.65
Waze
2.14
Sice
Figure 6: Global opti-
mization performance,
showing solver time in
seconds for the bench-
marks in Section 7.

To perform the constrained
optimization needed to ﬁnd an
optimal solution, we used the
Nelder-Mead method [33] with at
most 100 iterations. We looked
for integer solutions over the full
space of tier splittings.

The results are presented in Figure 6. Each applica-
tion resulted in between 30 and 300 constraints, and the
constraint solver found an optimal solution in under three
seconds for all applications. Because Nelder-Mead is an

USENIX Association  

23rd USENIX Security Symposium  915

GetGPS

Preprocess

ComputeDistance

ComputeBalances

UpdateDB

P

Z

P

P

GenQuery

Preprocess

MakeShares

Aggregate Shares

Gen Forest

P

P

P

Z

P

P

P

t
n
e

i
l

C

r
e
v
r
e
S

t
n
e

i
l

C

r
e
v
r
e
S

Figure 7: Splits produced by global ZØ optimizations, for FitBit and
Slice. For each phase of the computation, grey cells indicate computa-
tion location (or tier) chosen by the optimizer, with P and Z denoting
ZQL and Pinocchio back-ends, respectively.

approximate numerical optimization algorithm, it is pos-
sible that it would return a local minimum.

Implementation

However, we checked the solution returned for each
application, and veriﬁed that it corresponded to the true
global minimum. Figure 7 shows examples of ZØ-
computed global splits for two representative applica-
tions.
5
In order to make privacy analysis, zero-knowledge trans-
lation, and aggressive optimization feasible for the pro-
grammer, ZØ supports a subset of C# that includes cer-
tain LINQ (language integrated queries [34]) functional-
ity and support for external code. To ensure that the ex-
ternal code does not interfere with the privacy, integrity,
and optimization goals of ZØ, the contexts in which it is
allowed are limited in some cases. The syntax accepted
by ZØ is summarized in Figure 8.

The main program is structured into three parts: an
initialization routine (InitBlock, contained in a method
Initialize), the main body (MainBlock, contained in a
method DoWork), and the worker methods (MethodDef).
The initialization routine may consist of a sequence of
arbitrary C# assignment statements, including calls to
methods in external libraries not written in ZØ’s input
language. The main block consists of a sequence of
method calls, assignment statements, and sleep state-
ments. Each method call in the main body must be to
a worker method deﬁned in the ZØ application.
Zero-knowledge regions: The body of each worker
method can contain calls to external methods, standard
C# arithmetic and Boolean operations, and a subset of
the standard LINQ data processing operations. Regions
comprised of LINQ operations can be converted into
zero-knowledge proof-generating object code using ei-
ther available zero-knowledge engine (ZQL or Pinoc-

::= InitBlock MainBlock MethodDef∗TypeDef∗
::= CSMethodSig VarDecl∗
::= CSMethodSig WorkerStmt+
::= CSMethodSig (ExternCall | LinqStmt)+
::= class Id { CSFieldDef + }
::= PrivacyAnnot CSType Id(. . .){ . . . }

Main program deﬁnition
Program
InitBlock
MainBlock
MethodDef
TypeDef
CSMethodSig
Statements
WorkerStmt
SleepStmt
CallStmt
ExternCall
LinqStmt
VarDecl
Expressions
Lambda
LambdaExpr

::= SleepStmt | CallStmt | ZKAnnot
::= WorkerSleep(Integer, Integer, Integer)
::= (Id =)? MethodCall
::= return External.Id“(”Id∗“)”
::= (Id =)? LinqExpr
::= (PrivacyAnnot | SizeAnnot)? Id(= CSExpr)?
::= “(”Id∗“)” ⇒ LambdaExpr
::= MethodCall | ArithOrBoolExpr
::= LambdaLinqExpr | ZipLinqExpr
LinqExpr
LambdaLinqExpr ::= Id.LambdaLinqId(Lambda)
::= Select | Aggregate | First
LambdaLinqId
::= Id.Zip(Id, NewAnonObj)
ZipLinqExpr
::= Id “(”LambdaExpr∗“)”
MethodCall
::= NewAnonObj | NewStaticObj
NewObj
::= new {(Id = LambdaExpr)+}
NewAnonObj
::= new MethodCall
NewStaticObj
::= Id.fld(cid:26)Type(cid:25)(Int)
FieldExpr
Annotations
ZKAnnotat

| FieldExpr | NewObj

::= ZeroKnowledgeBegin()
| ZeroKnowledgeEnd()

::= [Private(TL)]
::= [MaximumInputSize(Int+)]

PrivacyAnnot
SizeAnnot

Figure 8: BNF syntax for the subset of C# supported by ZØ. Entities
preﬁxed with CS correspond to the corresponding C# syntax entity.

chio). The supported LINQ operations include Select, Ag-
gregate, First, and Zip. Select provides the ability to project
the data in one list into a new list, while performing
arithmetic and Boolean operations on each item in the
original source list. Aggregate provides the ability to com-
pute iterated functions over a list, maintaining an order-
sensitive state through the iteration, which is eventu-
ally returned as the result of the operation. First pro-
vides the ability to perform searches over lists, using a
programmer-deﬁned predicate to determine which ele-
ment of the list to match. Finally, Zip provides the abil-
ity to combine multiple lists, applying arithmetic and
Boolean operations to each pair of items from the origi-
nal source lists.

Zero-knowledge regions are speciﬁed by the program-
mer using a pair of methods ZeroKnowledgeBegin and Ze-
roKnowledgeEnd. Because zero-knowledge computations
provide both integrity and privacy,
these annotations
serve a dual purpose. First, the programmer is denot-
ing that the variables which are live [1] at the end of a
zero-knowledge region are trusted across all tiers:
the
values have accompanying proofs that any tier can exam-
ine to verify that the computations in the zero-knowledge

916  23rd USENIX Security Symposium 

USENIX Association

region are performed correctly. Second, these regions
serve to declassify private values that are used as in-
puts to a zero-knowledge region;
this is in line with
the approach taken by ZQL [16]. Because the inputs to
zero-knowledge regions are kept private, except in cases
where the computations are in some way invertible, the
output values that depend on these inputs are considered
public to all tiers.

Formal reasoning about composing proofs obtained
from diﬀerent zero-knowledge back-ends remains an av-
enue for future work. Because this work involves ex-
perimentation with very recent cryptographic tools, we
are not aware of a readily-available composition theorem
that would support reasoning about Pinocchio and ZQL.
Code splitting: ZØ partitions the given target appli-
cation into code that runs on multiple tiers, inserting
marshalling and synchronization code [20, 24] as nec-
essary to ensure that the compiled functionality matches
that speciﬁed in the original input program. The rewrite
process is implemented as a bytecode-to-bytecode trans-
formation within the CCI 2 rewriting framework for
.NET [27]. We assume that the target tier for each
method is provided as input to the compiler by the op-
timizer, as described in Section 4.2.

Code partitioning between tiers takes place at method
granularity, and data partitioning is determined by the
chosen code partition; data is transmitted between tiers
on-demand, with all of the data represented by a variable
used by a particular method being transmitted at once
as it becomes available. Only worker methods can be
split between diﬀerent tiers, so all external code refer-
enced by the application is present on each tier. This al-
lows the compiler to avoid a potentially expensive deep-
dependency analysis of the referenced external code,
while keeping the dependency analysis of the target ap-
plication localized to DoWork.
Runtime support: The architectural principle that
guides ZØ’s tier-splitting algorithm can be summarized
as follows: whenever possible, delegate the data com-
munication and synchronization operations necessary to
support functionality to a runtime API. Each application
compiled by ZØ is linked to a runtime library that pro-
vides an API for communicating data and synchroniza-
tion between separate tiers. When the compiler performs
tier splitting, rather than inlining complex code to per-
form the tasks, simple calls to this API are inserted to
perform the “heavy lifting” of tier crossings at runtime.
6 Translating LINQ to Zero-Knowledge
Our compiler translates speciﬁed statements containing
LinqExpr components in the worker methods into code that
generates zero-knowledge proofs of knowledge. To ac-
complish this, ZØ relies on two zero-knowledge back-
ends: ZQL [16] and Pinocchio [31]. Each back-end is

itself a compiler, accepting as input an expression of a
computation, and producing executable code to produce
a zero-knowledge proof of the computation for a given
set of inputs. As such, each back-end supports its own
expression language with signiﬁcantly diﬀerent charac-
teristics. The challenge addressed in this section is the
translation of the common subset of LINQ supported by
ZØ into the expression languages of these back-ends.

Figure 1 in the

gives an overview of
our back-end compilation process for ZQL and Pinoc-
chio. The details diﬀer widely for each back-end, con-
verging only on the ﬁrst and last steps which corre-
spond to lifting low-level intermediate language code
into a higher representation and inserting I/O marshal-
ing instructions before and after the compiled object
code. This divergence of functionality is necessary given
the diﬀerences between the two expression languages:
ZQL’s expression language is essentially a small subset
of pure standard ML, whereas Pinocchio’s is a subset of
C with restrictions on data types and loop bounds. Be-
cause the subset of LINQ functions supported by ZØ cor-
responds to a small core of functional expressions, trans-
lating from ZØ to Pinocchio is much more involved than
to ZQL.
6.1 Pinocchio
The structure of C code is substantially diﬀerent from
the types of LINQ queries allowed by ZØ, and Pinoc-
chio’s additional restrictions make translation more com-
plicated yet. First, all list sizes used in the Pinocchio ex-
pression must be statically-declared, and any operation
over a list requires a static value to bound the correspond-
ing loop statement. The LINQ commands in ZØ do not
have these restrictions, so we must ﬁnd a way to derive
the needed information. Second, many expression forms
in ZØ’s LINQ commands have no corresponding expres-
sion form in C: they must be converted into statements
whose side-eﬀects are available as sub-expressions to en-
closing expressions.

To perform translation to Pinocchio, ZØ follows a
three-step process. First, static values for the size of each
identiﬁer that refers to a list value are derived using a
constraint solver. The basis for this computation is a set
of annotations provided by the developer, which indicate
upper bounds on the sizes of certain input lists.
List Size Resolution: As previously discussed, Pinoc-
chio requires static sizes for all lists and list operations,
so our translation procedure requires a mapping from
identiﬁers (for those that refer to list objects) to size con-
stants. To produce such a mapping, we use a constraint
resolution procedure over a set of bounding constraints
generated by traversing the source expression. The rules
for generating the constraints are given in Figure 9. Each
rule is of the form Γ, Syntactic Element ⇒ Γ(cid:30), where Γ

USENIX Association  

23rd USENIX Security Symposium  917

con(expr) =
{id.elt}
{id1, id2}

{id}
{id}
{id.n}

con(id) = {id}

when expr is id.First(. . .)
when expr is id1.Zip(id2, . . .)
when expr is id.Aggregate(. . .)
when expr is id.Select(. . .)
when expr is id.Fld(n)

C-FieldDef2

C-Method

C-Basic

Command ∈ {Select, First}

Γ, id1.Command(id2 → ··· ) ⇒ Γ ∪ {id1.elt = id2}

C-FieldDef1

ϕ ≤ id = x ∧ id.elt = 1

Γ, [MaximumInputSize(x)] IEnumerable(cid:27)T(cid:26) id ⇒ Γ ∪ {ϕ}

ϕ =

id ≤ x ∧ id.elt ≤ n1 ∧ id.elt.elt
≤ n2 ∧ ··· ∧ id.(elt)k ≤ nk ∧ id.eltk+1 = 1

Γ, [MaximumInputSize(x,{n1, . . . , nk})] IEnumerable(cid:27)T(cid:26) id ⇒ Γ ∪ {ϕ}
Γ, Type id(id f

id(id1, . . . , idn) is a call site

f

1 , . . . , id f

1 ≥ id1, . . . , id

n ≥ idn}

f

n) { . . . } ⇒ Γ ∪ {id
Vi = con(expri)

C-New

C-Aggregate

Γ, new id(expr1, . . . , exprn) ⇒ Γ ∪(cid:31)1≤i≤n{(cid:30)v∈Vi id.i = v}
Γ, id1.Aggregate((id2, id3) → ··· ) ⇒ Γ ∪ {id1.elt = id3}

C-Zip

Γ, id1.Zip(id2, (id3, id4) → ··· ) ⇒ Γ ∪ {id1.elt = id3 ∧ id2.elt = id4}

Figure 9: List size constraint generation rules. Γ is a set of constraints.

C-Assign

V = con(expr)

Γ, id = expr ⇒ Γ ∪ {(cid:30)v∈V id = v}

and Γ(cid:19) are sets of constraints. The constraints for each
LINQ command are straightforward. The outcome of Se-
lect, Aggregate, and Zip operations has the same size as the
input variable(s). The outcome of a First statement has the
size of the elements contained in the input list.

The rules are invoked by a procedure that traverses
each node of the program’s AST, and performs syntac-
tic matching on the entity represented by each node and
the Syntactic Element of each rule. As the traversal pro-
ceeds, a list of constraints is maintained, and updated
when rules match AST nodes. When the AST traver-
sal completes, the set of constraints generated is passed
to Z3 for resolution.
If the constraints are satisﬁable,
Z3 will produce a model that associates constraint vari-
ables to integers that satisfy the original constraints. This
model contains all of the information needed to derive
the needed mapping between identiﬁers and list sizes.
Type Generation and Function Isolation: Pinocchio
requires static sizes on all arrays and loop bounds. To
accomplish this, ZØ creates a new struct type for each
list with a distinct base type and size in the original pro-
gram. Each new type has two ﬁelds: a static array and a
constant deﬁning the size.

Once types for each identiﬁer are established, each
sub-expression in the source statement is converted to a
function body. To see the need for this step, consider
the statement x.Select(el → el.Select(. . .)). C has no ex-
pression form for the functionality needed by the Select
command, so both expressions must be converted into
loop statements. Rather than placing the loop statements
in the same method body and carefully managing side
eﬀects and sequencing with other sub-expressions, we
isolate the emitted code for the inner Select in a separate
function, and emit a call to the new function in its place
in the context of the outer Select expression.

The statements generated for each LINQ command are
straightforward translations of their deﬁned behavior into
basic C; in general, the input loop is iterated over, and the

lambda passed to the command is invoked over each ele-
ment. Field lookups, new object construction, and func-
tion calls are rewritten to their C equivalents.
6.2 ZQL
Recall that we only attempt to convert LinqStmt statements
into zero-knowledge, so there are four primary func-
tions to convert, in addition to a few additional expres-
sion forms. By no coincidence, the four primary LINQ
functions correspond closely to the operations supported
by ZQL. Figure 2 in the
gives a set of
rewrite rules that can be used to translate a LinqExpr to
ZQL’s expression language. Select, Aggregate, Zip, and First
calls are translated to map, fold, map2, and ﬁnd expressions.
Lambda deﬁnitions and functions calls are translated
compositionally, by ﬁrst translating sub-expressions and
then building a new construct in the target language. Ob-
ject creation using new is translated into tuple construc-
tion. Recall that user-deﬁned types in a ZØ program
must expose a single constructor that assigns all ﬁelds
of the type; ﬁeld names are translated into a tuple order
using the constructor signature. Similarly, ﬁeld accesses
using ﬂd are translated into a let binding that returns the
appropriate tuple component; the translation consults the
target identiﬁer’s type constructor to deduce the number
of ﬁelds in the type.
7 Motivating Case Studies
This section presents six case studies in ZØ, that are
the focus of our experiments in Section 8. Similarly
to [16], we assume that the sensor readings devices can
are trusted and untampered with, and come signed by
their producer, but the machine or mobile phone (Client
tier) that performs the distance computation is not.
1) Walk for Charity with FitBit: Several programs ex-
ist for paying users for the amount of physical exercise
they perform, either directly in the form of rewards, or in-
directly by making charitable donations on their behalf,

918  23rd USENIX Security Symposium 

USENIX Association

such as earndit.com. This works by requiring users
to log their exercise habits using a FitBit or other sensor
device to measure the distance the user walks, runs, or
bikes, and send the logs to a centralized server.
Privacy: The user may not want to reveal their detailed
physical activities or exercise route to a relatively un-
trusted third party.
Integrity: The service is spending money on the basis of
distance derived from sensor logs. If the distance com-
putation can be subverted, the possibility for fraud arises,
analogously to pay as you drive insurance [4, 38, 41].
Solution: Keep all sensor readings local to the user’s
machine (laptop or mobile device), perform the distance
computation locally, on the client, send the result of
the distance computation to the centralized third-party
server. Use ZKPK to ensure that the distance compu-
tation is performed correctly. This approach is similar to
what has been advocated for smart metering [35].
2) Supervised Studies in Social Sciences: Many scien-
tiﬁc studies, especially in medical and social sciences,
require subjects to wear sensors and undergo protocols
that provide information about their physiological and
psychological state. A study that seeks to understand the
eﬀect of common workplace events on worker’s stress
levels might require a participant to wear a galvanic skin
response sensor and a camera to detect face-to-face in-
teractions.
Privacy: Participants may have concerns about the use of
their physiological measurements or, most prominently,
the processing of images taken from their cameras.
Integrity: These studies typically involve payment given
to subjects. Subjects concerned about their privacy, or
those who simply do not want to wear intrusive sensor
devices, have an incentive to fake their data.
Solution: Have all sensors associated with the study re-
port readings to the subject’s machine (desktop or mobile
phone). This machine performs aggregate computations
relevant to the actual study on the readings, reporting re-
sults and discarding the raw sensor readings. ZKPK is
used to ensure that the readings are processed correctly.
3) Personalized Loyalty Cards: Many of today’s large
retailers such as Target, BestBuy, etc. use customer loy-
alty cards to encourage repeat visits. Typically, the cus-
tomer must enroll in a loyalty program, and receive a
card that can be applied to receive discounts in future
visits. Recently, certain retailers (e.g., Safeway) have be-
gun personalizing this process by using the customer’s
past purchase history (available because of the associ-
ation between checkout and loyalty card) to create dis-
counts available only to one particular customer. De-
pending on the retailer, these discounts can be sent to
the customer’s mobile phone, or applied automatically at
checkout.

Privacy: Many people are not comfortable with a retailer
tracking their purchases. This is most readily illustrated
by a recent scandal with Target discovering that a teenage
girl was pregnant before her parents did [14].
Integrity: Retailers oﬀer discounts on the basis of past
purchase history.
If a customer could fake a purchase
history, they might be able to obtain a discount for an
item of their choosing. Moreover, having a reproducible
strategy for “generating” discounts might create a seri-
ous problem for the retailer, similar to those experienced
by some retailers that were overly generous in oﬀering
Groupons [32].
Solution: The solution is discussed in Section 2.1.
4) Crowd-sourced Traﬃc Statistics: Several mobile
applications such as Waze (waze.com) and Google Maps
provide traﬃc congestion information to end-users based
on the combined GPS readings of the users.
Privacy: Users do not want to share their location with
the app’s servers, or the general public (in the case of a
distributed protocol).
Integrity: The app needs reliable GPS readings from
users to provide its core functionality.
If users wish
to “game” the system by providing fake GPS readings
while receiving the end-product, the integrity of traﬃc
data is compromised for everyone.
Solution: Let the users keep their GPS readings local,
and take part in a distributed protocol to compute local
density information for transmission to the app’s central
server. Clients represent their location on a map using a
vector, represented as a set of secret shares, which can
be added to the other clients’ vector shares to derive the
overall traﬃc density map. When each client sends their
summed shares to the server, it can reconstruct the den-
sity map by combining the shares, as detailed in the ap-
pendix.
5) CNIDS: Collaborative intrusion detection (CNIDS)
has long been a goal of security practitioners [25].
In
the CNIDS scenario, multiple (distrustful) organizations
share the results of their network intrusion detection sen-
sors, to provide their peers with advanced warning about
possible threats. A practical approach involves sharing
IP blacklists: when an IP generates a valid NIDS alert on
one organization’s network, the IP is recorded and sent
to the other participating organizations.
Privacy: NIDS operate on highly sensitive data — raw
network traces. Organizations participating in CNIDS
do not want to share their traces with other organizations,
and in many cases, may be prohibited from doing so by
law or organizational policy.
Integrity: Given the privacy concern and the beneﬁts of
participating, some organizations may want to freeload
by suppressing their own NIDS alerts. Additionally, if

USENIX Association  

23rd USENIX Security Symposium  919

an adversary manages to compromise a participating net-
work, it may choose to suppress or even generate false
alerts, which may result in a denial of service for the tar-
geted IP address.
Solution: Provide a ZKPK for the NIDS signature-
matching process, to prove that a claimed intrusion is
correct according to the signature. Note that this ap-
proach assumes that raw network data coming into the
NIDS has not been tampered with, but that the machine
performing the signature matching may not be trusted.
6) Slice: Organizing Shopping: Slice (slice.com) is a
service that takes as input a user’s past purchase history
from their email mailbox, and provides various services
using that data. One such service is product recommen-
dation — given everybody’s past purchase history, slice
can build classiﬁers that predict a likely “next” purchase.
Privacy: Handing one’s entire purchase history to a
proﬁt-driven third party has obvious privacy implica-
tions. So does the troubling need to share one’s email
credentials with Slice at the moment.
Integrity: A user, particularly one concerned about pri-
vacy, might provide fake data to Slice in order to obtain
the useful classiﬁer, which would pollute Slice’s data for
everyone and jeapordize Slice’s ability to proﬁt from the
classiﬁer.
Solution: Keep the user’s purchase history local, and
have the users take part in a distributed protocol in order
to produce the classiﬁer for Slice. Use ZKPK to ensure
that no user is able to subvert the distributed classiﬁer
computation.
8 Experimental Evaluation
a Win-
All
dows Server 2012 R2 machine with two 3.0 GHz 64-bit
cores with 8 GB of RAM. All reported timing measure-
ments correspond only to the zero-knowledge portion
of the application’s execution time, as this is the only
portion that our compiler attempts to optimize.

experiments were

performed

on

The execution time of the ZK code is generally much
higher that of the rest of the application, so focusing on
these parts gives an accurate picture of the overall exe-
cution time. Each zero-knowledge proof generation and
veriﬁcation task was terminated after ten minutes. Our
implementation uses 1,024-bit RSA keys for ZQL com-
putations. Integers in Pinocchio circuits were conﬁgured
to have 32-bits for comparison operations, and operate
over a 245-bit ﬁeld.

Figure 11 summarizes the key performance results
from our experiments. We found that the ZØ-generated
code gave signiﬁcant performance beneﬁts both in terms
of computation time and proof size: up to 40× runtime
speedup, with most proofs below 1 MB (the largest be-
ing ≈ 1.9 MB). Furthermore, we saw that global opti-

Scaling

Latency

Proof size

Global
tradeoﬀs

ZØ scales to all application conﬁgurations. Others may
time out or fail to compile in fewer than 20 minutes on
some parameter settings: 100-byte traces (NIDS), >100
peers (Slice), large automata (Loyalty).
ZØ improves up to 40×, ≈ 5–13× on average
ZØ almost always less than 1 MB, at most 1.5 MB. ZQL
proofs can be tens or hundreds of MBs.
ZØ may be slower at one tier (2× slower for Waze server),
but savings at other tiers is always much greater (4×
faster for Waze clients)
Figure 11: Performance summary.

mization is necessary to arrive at an ideal performance
proﬁle: some applications perform noticeably worse at
one tier, but in each case the speedup at another tier was
always greater. For example, the code ZØ generated for
the Waze server ran ≈ 2× slower than Pinocchio’s on av-
erage, but latency on the client tier was reduced ≈ 4×.
Figure 12 shows the latency speedups across all appli-
cations. The average speedup delivered by ZØ is 3.3×
compared to Pinocchio and 7.4× compared to ZQL.
Results: Space limitations do not allow us to present our
measurements exhaustively. Instead, Figure 10 shows a
sample of the runtime characteristics for our target ap-
plications. Rather than giving raw execution times, the
results are broken into three categories: throughput, la-
tency, and proof size. These metrics were selected to
more clearly depict the impact of zero-knowledge tech-
niques on each application.
Throughput: Figure 10(a)–(c) shows the results of three
experiments involving throughput. Figure 10(a) shows
the server’s throughput for the Waze application, which
corresponds to the number location updates per minute
the server can handle as the number of users (n) in-
creases. Notice that Pinocchio outpaces both the hybrid
and ZQL compilations by about 2× on average. This is
a result of the global optimization engine: veriﬁcation in
Pinocchio is very fast, whereas the time to construct a
proof can be quite slow: in this case, the proof construc-
tion phase was up to 7× slower than the hybrid solution.
This is critical, as proof construction takes place on the
client where resources are especially constrained for the
application. The discrepancy in resources is correctly
used by ZØ to optimize for a lighter client workload at
the expense of greater server overhead.

Figure 10(b) shows the number of random forest con-
struction queries per minute the Slice server is able to
handle, as the number of participating peers increases.
As with Waze the Pinocchio solution dominates the ZØ
solution at all data points because of the greater ex-
pensive of constructing proofs on the client, where the
Pinocchio solution is up to 4× slower than ZØ.
Figure 10(c) shows the number of intrusion alerts per
minute the collaborative NIDS server can handle as the
number of bytes in the intrusion trace increases. Notice

920  23rd USENIX Security Symposium 

USENIX Association

(a) Waze (server)

(b) Slice (server)

(c) NIDS (server)

t
u
p
h
g
u
o
r
h
T

)
1
(

i

e
t
u
n
m
/
s
e
t
a
d
p
U
#

400

300

200

100

0

y
c
n
e
t
a
L

)
2
(

e
z
i

S
f
o
o
r
P
)
3
(

600

400

200

)
s
(

y
c
n
e
t
a
L

·107

)
b
(

e
z
i
S

f
o
o
r
P

3

2

1

0

Hybrid

Pinocchio

ZQL

100

200

300

400

500

600

700

800

900

1,000

# Peers

(d) Loyalty (client)

Hybrid

Pinocchio

ZQL

50

100

150

250

300
200
# Purchases

350

400

450

500

(g) Loyalty

Hybrid

Pinocchio

ZQL

50

100

150

250

200
300
# Purchases

350

400

450

500

i

e
t
u
n
m
/
s
e
i
r
e
u
Q

600

400

200

0

400

200

)
s
(

y
c
n
e
t
a
L

)
b
(

e
z
i
S

f
o
o
r
P

8

6

4

2

0

Hybrid

Pinocchio

ZQL

100

200

300

400

500

600

700

800

900

1,000

# Peers

(e) NIDS (client)

Hybrid

Pinocchio

ZQL

i

e
t
u
n
m
/
s
t
r
e
l
A

600

400

200

0

)
s
(

y
c
n
e
t
a
L

10

8

6

4

2

Hybrid

Pinocchio

ZQL

100

200

300

400

500

600

700

800

900

1,000

Trace Length (bytes)

(f) Waze (client)

Hybrid

Pinocchio

ZQL

100

200

300

400

500

600

700

800

900

1,000

100

200

300

Trace Length (bytes)

(h) Waze

·106

Hybrid

Pinocchio

ZQL

100

200

300

400

500

600

700

800

900

1,000

400

500

600
# Regions

700

800

900

1,000

(i) NIDS

·106

Hybrid

Pinocchio

ZQL

100

200

300

400

500

600

700

800

900

1,000

)
b
(

e
z
i
S

f
o
o
r
P

6

4

2

0

# Peers

Trace Length (bytes)

Figure 10: (1) Throughput, (2) latency, and (3) proof size for a characteristic sample of application functionality.

that Pinocchio outperforms at a few small data points,
but fails to scale to any larger points. This is not be-
cause the server-side component is unable to scale, but
rather the client timed out at these settings. For the re-
maining points, the ZØ solution outperforms the others
by about 4×, and is the only solution that is able to scale
to even the modest intrusion trace length of 1 KB.

Latency: Figure 10(d)–(f) shows the results of three ex-
periments involving latency. Latency is always measured
in seconds, and has a uniform upper bound of 600 sec-
onds, which corresponds to our experimental timeout.

ZQL

Pinocchio
Mean Max Mean Max
4.7
6.4
40.3
1.0
21.8
4.1
4.0
4.7
2.7
5.3
2.5
12.9

4.5
39.7
10.1
4.3
2.7
8.1

6.6
1.0
4.2
7.1
7.3
4.1

Figure 10(d) shows
the latency of the client
side of the Loyalty appli-
cation as the number of
purchases used to per-
sonalize discounts (n)
increases.
The ZØ
solution far outpaces
both alternatives at all
data points (4–22× im-
provement).
These
experiments were per-
formed for an automaton with about 75 edges. We found
that when we scaled the automaton to more realistic sizes
(a few thousand edges), the ZØ solution was the only one
capable of completing any number of purchases before
timing out, and the Pinocchio compiler timed out after 20

FitBit
Study
Loyalty
Waze
CNIDS
Slice
Mean
Figure 12: Latency speedup fac-
tors for each application; averages
use geometric mean for propor-
tional speedup.

3.3

7.4

minutes. For longer purchase histories, the ZØ solution
completes in just over 1.5 minutes, which is ample time
if the application is location-aware and begins proving a
set of discounts when the user enters the store.

Figure 10(e) shows the NIDS client’s latency to demon-
strate that a single intrusion is present in a trace. Pinoc-
chio times out at all points beyond 300 bytes, whereas
ZØ is about 2.7× faster than ZQL. Otherwise, we see that
as long as intrusions are spaced more than two-and-a-half
minutes (159 seconds) apart, the NIDS client has enough
time to build proofs for each intrusion trace.

Figure 10(f) shows the latency of the Waze client to
send traﬃc statistics for a single location query as the
size of the map (n) increases. First notice that the ZØ
solution is essentially constant, not varying by more
than 1.5 seconds between any two data points. The other
solutions require as much as 4–7× as long to process a
query on the client, which will limit the quality (i.e., re-
cency) of the statistics the server is able to gather over
time. Second, notice that at about n = 700, ZQL be-
comes more performant than Pinocchio. This is because
as the map increases, the size of the lookup table needed
to encode the regions increases. Pinocchio is not able
to perform lookups as quickly as ZQL, so the portion
of the computation needed for lookups becomes more
signiﬁcant at higher values of n. ZQL performs worse
at lower values because most of the computation corre-
sponds to the multiplications needed to compute secret

USENIX Association  

23rd USENIX Security Symposium  921

shares, which it does not complete as quickly as Pinoc-
chio.
Proof Size: Figure 10(g)–(i) shows the results of exper-
iments involving the size of the zero-knowledge proof in
various applications. We always measure in bytes, and
do not display a curve for the Pinocchio solutions, as it is
constant across input size and is usually too small to dis-
tinguish on the same scale as the ZQL and ZØ solutions.
Figure 10(g) shows the proof size for the Loyalty applica-
tion as the number of past purchases (n) varies. While
the Pinocchio solution of course dominates the others by
this metric (864 bytes), as we know from previous ex-
periments (Figure 10(d)) it does not scale in terms of La-
tency. The ZØ proof size remains nearly constant, always
under 500 KB, whereas the ZQL solution requires at least
three megabytes (to perform the inequality checks at the
beginning), and ﬁnishes at about 100 megabytes. Note
that we obtained the point at n = 300 despite the time-
out, by letting the prover run for longer in this single
instance. Because the Loyalty application needs to com-
municate this proof wirelessly to a POS terminal, size is
crucial, and the ZØ solution oﬀers the best overall char-
acteristics in terms of size and latency.

Figure 10(h) shows the proof size for the Waze appli-
cation as the number of peers varies. Again, Pinocchio
dominates (2 KB), but the tradeoﬀ in latency for this
proof size is quite high (Figure 10(f)). The ZØ proof
size remains constant at around 5 KB because the only
processing done by ZQL is table lookups, which have
a constant proof size. The ZQL solution requires 20
megabytes for 2,500 clients, and 8 megabytes for 1,000
clients, making it untenable given that the clients need to
transmit proofs frequently over cellular networks.

Figure 10(i) shows the proof size for the NIDS appli-
cation as the intrusion trace length increases. The Pinoc-
chio proof is about 1 KB, but again the tradeoﬀ in latency
makes this characteristic mostly irrelevant. The sizes for
the ZØ and ZQL solutions are both linear, with the ZØ
solution oﬀering a savings of about 4× at all data points.
This is a signiﬁcant savings, considering that false pos-
itives may be frequent, so the client may need to send
proofs to the server almost continuously.
9 Limitations and Future Work
Proof of security: The main piece of outstanding work
for ZØ is a formal argument of security. Because ZØ
composes non-interactive zero-knowledge proofs from
distinct back-ends, the security guarantees given by the
original back-ends do not necessarily readily translate to
the ﬁnal optimized code produced by the compiler. In fu-
ture work, we hope to characterize a uniﬁed threat model
that encompasses those of both back-ends, as well as
a composition theorem that demonstrates the safety of
ZØ’s modular compilation philosophy.

Optimization robustness: One concern is that a devel-
oper may unwittingly write code in a zero-knowledge
block that ZØ compiles into very ineﬃcient code. In gen-
eral, ZØ’s cost models should allow it to select the best
back-end most of the time. In certain close cases, where
the performance diﬀerence between back-ends is slight,
discrepancies between ZØ’s model coeﬃcients and the
characteristics of the target architecture may lead it to
select the less-eﬃcient back-end. However, as the diﬀer-
ence between back-ends is small to begin with in such
cases, the absolute performance penalty will likely be
small as well.

As non-interactive zero-knowledge is still signiﬁ-
cantly more expensive than “normal” computation even
in the best cases, the programmer must be careful not to
place unnecessary statements inside of a zero-knowledge
block. Additionally, if the programmer places inaccu-
rate size annotations on data structures, i.e., annotations
that are signiﬁcantly larger than the average workloads
encountered in practice, then the cost models used by
ZØ during optimization might not characterize the ac-
tual performance requirements of the application; this
can lead to sub-optimal performance.
Hardware integrity: Many of the applications dis-
cussed in this paper gather data from trusted hardware
devices. The zero-knowledge facilities in ZØ ensure that
the results of computations performed on such data can
also be trusted, i.e., they were derived by the code orig-
inally intended by the application developer. However,
zero-knowledge proofs might not provide all of the guar-
antees needed to realize an intended high-level security
goal in some cases.

For example, nothing prevents a malicious user from
“fooling” the FitBit application by physically manipulat-
ing the hardware to register more steps than were actually
taken.
In these cases, ZØ increases security by ensur-
ing that attacks on the application code will not succeed,
so that more-expensive hardware-layer attacks are nec-
essary. Whether this makes an attack on a given applica-
tion suﬃciently diﬃcult, or economically infeasible, is a
point to be carefully considered as part of an end-to-end
security strategy.
10 Related Work
Tier-Splitting and Language Methods: A number of
compilers exist that enable automated tier-splitting in
some form. In the context of web programming, Google
Web Toolkit (GWT) [20], Volta [24], Links [11], and
Hilda [43] are among the pioneering eﬀorts. ZØ is clos-
est to Volta and GWT, allowing developers to supply a
single piece of code that is compiled into separate mod-
ules for the client and server. Unlike those projects, ZØ
uses cost models of execution time and data size to de-
rive an optimization problem whose solution represents

922  23rd USENIX Security Symposium 

USENIX Association

zero-knowledge computation. There are a number of
larger projects that incorporate zero-knowledge proofs
in order to manage integrity without sacriﬁcing pri-
vacy. Applications include privacy-preserving smart me-
tering [35], random forest and hidden Markov model
classiﬁcation [12], and privacy-preserving automotive
toll charges [4].
11 Conclusions
This paper paves the way for using zero-knowledge tech-
niques for day-to-day programming. We have described
the design and implementation of ZØ, a distributing zero-
knowledge compiler which produces distributed applica-
tions that rely on ZKPK to provide simultaneous guaran-
tees for privacy and integrity. We build on recent devel-
opments in zero-knowledge cryptographic techniques,
exposing to the developer the ability to take advantage of
these advances without requiring domain-speciﬁc knowl-
edge or learning a new specialized language. Most of
the heavy lifting is done by the compiler, including cost
modeling to decide which zero-knowledge back-end to
use and how to split the application for optimal perfor-
mance, together with the actual code splitting.

Our cost-ﬁtting models provide an excellent match
with the observed performance, with R2 scores at least
and .98. Our global application optimizer is fast, com-
pleting in under 3 seconds on all programs. Our man-
ual and experimental examination of program splits and
back-end choices proposed by ZØ conﬁrms that they are
indeed optimal. Using six applications based on real-life
commercial products, we show how ZØ makes it viable
to use zero-knowledge technology. We observe perfor-
mance improvements of over 40×. Perhaps most impor-
tantly, ZØ allowed many of the applications to scale to
large data sizes with thousands of users while remain-
ing practical in terms of computation time and data size.
This means that applications which were not feasible us-
ing state-of-the-art zero-knowledge tools are now practi-
cal in realistic settings.
Acknowledgments
We thank the anonymous reviewers for their helpful
comments. We thank the ZQL and Pinocchio developers
for graciously providing code and support for our eﬀort.

an ideal division of functionality between tiers.

Others

have

security

accomplish

TS P I IL O

(cid:31) (cid:31)
(cid:31) (cid:31) (cid:31)
(cid:31)
(cid:31)
(cid:31) (cid:31)
(cid:31) (cid:31) (cid:31)
(cid:31) (cid:31)

References
[11, 20, 24, 43] (cid:31)
[10]
[3]
[40]
[2, 3, 16, 26, 31]
[16]
(cid:31)
[31]
(cid:31) (cid:31) (cid:31) (cid:31) (cid:31)
ZØ
Figure 13: Comparison of dis-
tributed and secure compiler eﬀorts.
TS = Automatic tier-splitting; P
= Privacy enforcement; I = In-
IL = Inte-
tegrity enforcement;
gration with widely-used languages
and runtimes; O = Optimizing code
generation.

used
splitting to pro-
tier
and
vide
guarantees.
privacy
SWIFT [10] builds on
the JIF [28] language,
incorporating security
types for conﬁdential-
ity and tier-splitting
for web applications.
To
this,
information ﬂow con-
straints are embodied
in an integer program-
ming problem whose
solution
corresponds
to a valid (e.g., secure)
placement of code onto tiers that minimizes the number
of messages that must be transferred. Unlike ZØ,
SWIFT does not explicitly account for data size and
transfer time when looking for a split that is likely to
maximize performance.

Backes et al. [3] presented a compiler for distributed
authorization policies written in Evidential DKAL [6],
an authorization logic that supports signature-based
proofs. The use of zero-knowledge proofs allows princi-
pals to prove access rights based on sensitive data with-
out directly revealing its content. ZØ diﬀers in its ap-
plicability: ZØ allows developers to use C# as part of
a larger .NET application, whereas this work translates
authorization logic formulas into cryptographic code.

Others have addressed the problem of untrusted client-
side computation in various contexts [21, 22, 40, 42]. A
similar notion of integrity was presented in Ripley [40],
which prevents client-side cheating in web applications
by eﬃciently replicating client-side computations on the
server. Unlike ZØ, Ripley’s mechanism does not pre-
serve privacy.

Zero-Knowledge Proofs: Zero-Knowledge proofs of
knowledge [5] have been extensively studied. Schemes
have been developed for various types of relations and
computations [7, 8, 19, 36]. Several projects have sought
to provide zero-knowledge compilers [2, 3, 16, 26, 31]
that take a proof goal and produce executable zero-
knowledge code. The ﬁrst set of zero-knowledge com-
pilers [2, 3, 26] required speciﬁcations of cryptographic
protocols [9], and so are diﬃcult for non-cryptographers
to use. The second generation [16, 31] are geared to-
wards generating ZK code for general computations ex-
pressed in restricted high-level languages. Our work
makes extensive use of these compilers to optimize

USENIX Association  

23rd USENIX Security Symposium  923

References

[1] A. V. Aho, M. Lam, R. Sethi, and J. D. Ullman. Compilers:

Principles, Techniques, and Tools. Addison-Wesley, 2007.

[2] J. B. Almeida, E. Bangerter, M. Barbosa, S. Krenn, A.-R.
Sadeghi, and T. Schneider. A certifying compiler for zero-
knowledge proofs of knowledge based on σ-protocols. In Pro-
ceedings of the European Conference on Research in Computer
Security, 2010.

[3] M. Backes, M. Maﬀei, and K. Pecina. Automated synthesis of
privacy-preserving distributed applications. In Proceedings of the
Network and Distributed System Security Symposium, 2012.

[4] J. Balasch, A. Rial, C. Troncoso, B. Preneel, I. Verbauwhede, and
C. Geuens. Pretp: privacy-preserving electronic toll pricing. In
Proceedings of the Usenix Security Conference, 2010.

[5] M. Bellare and O. Goldreich. On deﬁning proofs of knowledge.
In Proceedings of the International Cryptology Conference on
Advances in Cryptology, 1993.

[6] A. Blass, Y. Gurevich, M. Moskal, and I. Neeman. Evidential
authorization*. In S. Nanz, editor, The Future of Software Engi-
neering. 2011.

[7] S. Brands. Rapid demonstration of linear relations connected by
boolean operators. In Proceedings of the International Confer-
ence on Theory and Application of Cryptographic Techniques,
1997.

[8] J. Camenisch, R. Chaabouni, and A. Shelat. Eﬃcient protocols
for set membership and range proofs. In Proceedings of the Inter-
national Conference on the Theory and Application of Cryptology
and Information Security: Advances in Cryptology, 2008.

[9] J. Camenisch and M. Stadler. Eﬃcient group signature schemes
for large groups. In Proceedings of the International Cryptology
Conference on Advances in Cryptology, 1997.

[10] S. Chong, J. Liu, A. C. Myers, X. Qi, K. Vikram, L. Zheng, and
X. Zheng. Secure Web applications via automatic partitioning.
SIGOPS Operating Systems Review, 41(6), 2007.

[11] E. Cooper, S. Lindley, P. Wadler, and J. Yallop. Links: Web
programming without tiers. In Formal Methods for Components
and Objects. 2007.

[12] G. Danezis, M. Kohlweiss, B. Livshits, and A. Rial. Private
client-side proﬁling with random forests and hidden Markov
models. In Proceedings of the International Conference on Pri-
vacy Enhancing Technologies, 2012.

[13] D. Davidson, M. Fredrikson, and B. Livshits. MoRePriv: Mobile
OS Support for Application Personalization and Privacy (Tech
Report). Technical Report MSR-TR-2012-50, Microsoft Re-
search, May 2012.

[14] C. Duhigg. How companies learn your secrets. http://nyti.

ms/SZryP4, Feb. 2012.

[15] T. Fechner and C. Kray. Attacking location privacy: exploring
human strategies. In Proceedings of the Conference on Ubiqui-
tous Computing, 2012.

[16] C. Fournet, M. Kohlweiss, and G. Danezis. ZQL: A compiler for
privacy-preserving data processing. In Usenix Security Sympo-
sium, 2013.

[17] M. Fredrikson and B. Livshits. RePriv: Re-envisioning in-
browser privacy. In IEEE Symposium on Security and Privacy,
May 2011.

[18] F. D. Garcia, E. R. Verheul, and B. Jacobs. Cell-based roadpric-
ing. In Proceedings of the European Conference on Public Key
Infrastructures, Services, and Applications, 2012.

[19] R. Gennaro, C. Gentry, B. Parno, and M. Raykova. Quadratic
span programs and succinct NIZKs without PCPs. In Proceedings
of the IACR Eurocrypt Conference, 2013.

[20] Google Web Toolkit.

http://code.google.com/

webtoolkit.

[21] G. Hoglund and G. McGraw. Exploiting Online Games: Cheating

Massively Distributed Systems. Addison-Wesley, 2007.

[22] S. Jha, S. Katzenbeisser, and H. Veith. Enforcing semantic in-

tegrity on untrusted clients in networked virtual environments. In
Proceedings of the IEEE Symposium on Security and Privacy,
2007.

[23] F. Kerschbaum. Privacy-preserving computation (position paper).

http://www.fkerschbaum.org/apf12.pdf, 2012.

[24] D. Manolescu, B. Beckman, and B. Livshits. Volta: Devel-
oping distributed applications by recompiling. IEEE Softtware,
25(5):53–59, 2008.

[25] M. Marchetti, M. Messori, and M. Colajanni. Peer-to-peer ar-
chitecture for collaborative intrusion and malware detection on a
large scale. In Proceedings of the International Conference on
Information Security, 2009.

[26] S. Meiklejohn, C. C. Erway, A. Küpçü, T. Hinkle, and A. Lysyan-
skaya. ZKPDL: a language-based system for eﬃcient zero-
knowledge proofs and electronic cash.
In Proceedings of the
Usenix Conference on Security, 2010.

[27] Microsoft Research. Common compiler infrastructure. http:

//ccimetadata.codeplex.com, 2012.

[28] A. C. Myers and B. Liskov. A decentralized model for infor-
mation ﬂow control. In Proceedings of the ACM Symposium on
Operating Systems Principles, 1997.

[29] A. Narayanan and V. Shmatikov. Robust de-anonymization of
large sparse datasets. In Proceedings of the IEEE Symposium on
Security and Privacy, 2008.

[30] A. Narayanan and V. Shmatikov. De-anonymizing social net-
works. In Proceedings of the IEEE Symposium on Security and
Privacy, 2009.

[31] B. Parno, C. Gentry, J. Howell, and M. Raykova. Pinocchio:
In Proceedings of the

Nearly practical veriﬁable computation.
IEEE Symposium on Security and Privacy, 2013.
Is groupon a raw deal

[32] C. Pontoriero.

for publish-
ers?
http://risnews.edgl.com/retail-trends/Is-
Groupon-a-Raw-Deal-for-Retailers-73442, June 2011.
[33] W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery.
Numerical Recipes, 3rd edition: The Art of Scientiﬁc Computing.
Cambridge University Press, 2007.

[34] J. Rattz and A. Freeman. Pro LINQ: Language Integrated Query

in C# 2010. Apress, 2010.

[35] A. Rial and G. Danezis. Privacy-preserving smart metering. In
Proceedings of the Workshop on Privacy in the Electronic Soci-
ety, 2011.

[36] C.-P. Schnorr. Eﬃcient signature generation by smart cards. Jour-

nal of Cryptology, 4:161–174, 1991.

[37] V. Toubiana, A. Narayanan, D. Boneh, H. Nissenbaum, and
S. Barocas. Adnostic: Privacy preserving targeted advertising.
In Proceedings of the Network and Distributed System Security
Symposium, Feb. 2010.

[38] C. Troncoso, G. Danezis, E. Kosta, and B. Preneel. PriPAYD:
privacy friendly pay-as-you-drive insurance. In P. Ning and T. Yu,
editors, Proceedings of the 2007 ACM Workshop on Privacy in
the Electronic Society, 2007.

[39] C. Troncoso, G. Danezis, E. Kosta, and B. Preneel. PriPAYD:
In Proceedings of

privacy friendly pay-as-you-drive insurance.
the ACM Workshop on Privacy in Electronic Society, 2007.

[40] K. Vikram, A. Prateek, and B. Livshits. Ripley: Automatically
securing distributed Web applications through replicated execu-
tion. In Conference on Computer and Communications Security,
2009.

[41] Wikipedia. Usage-based insurance. http://en.wikipedia.

org/wiki/Usage-based_insurance, 2013.

[42] J. Yan. Security design in online games. In Proceedings of the

Annual Computer Security Applications Conference, 1993.

[43] F. Yang, J. Shanmugasundaram, M. Riedewald, and J. Gehrke.
Hilda: A high-level language for data-driven Web applications.
In Proceedings of the International Conference on Data Engi-
neering, 2006.

924  23rd USENIX Security Symposium 

USENIX Association

