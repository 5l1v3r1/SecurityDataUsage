SABOT: Speciﬁcation-based Payload Generation for

Programmable Logic Controllers∗

Stephen McLaughlin Patrick McDaniel

Systems and Internet Infrastructure Security

Laboratory

Pennsylvania State University

{smclaugh,mcdaniel}@cse.psu.edu

ABSTRACT
Programmable Logic Controllers (PLCs) drive the behavior of in-
dustrial control systems according to uploaded programs. It is now
known that PLCs are vulnerable to the uploading of malicious code
that can have severe physical consequences. What is not under-
stood is whether an adversary with no knowledge of the PLC’s
interface to the control system can execute a damaging, targeted,
or stealthy attack against a control system using the PLC. In this
paper, we present SABOT, a tool that automatically maps the con-
trol instructions in a PLC to an adversary-provided speciﬁcation of
the target control system’s behavior. This mapping recovers sufﬁ-
cient semantics of the PLC’s internal layout to instantiate arbitrary
malicious controller code. This lowers the prerequisite knowledge
needed to tailor an attack to a control system. SABOT uses an in-
cremental model checking algorithm to map a few plant devices at
a time, until a mapping is found for all adversary-speciﬁed devices.
At this point, a malicious payload can be compiled and uploaded
to the PLC. Our evaluation shows that SABOT correctly compiles
payloads for all tested control systems when the adversary cor-
rectly speciﬁes full system behavior, and for 4 out of 5 systems in
most cases where there where unspeciﬁed features. Furthermore,
SABOT completed all analyses in under 2 minutes.
Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection—Invasive soft-
ware; J.7 [Computers in Other Systems]: Process control
General Terms
Security
Keywords
Programmable Logic Controller, Attack, Critical Infrastructure
∗This material is based upon work partially supported by the Na-
tional Science Foundation under Grants CCF 0937944 and CNS
0643907, and by a grant from the Security and Software Engineer-
ing Research Center (S2ERC).

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’12, October 16–18, 2012, Raleigh, North Carolina, USA.
Copyright 2012 ACM 978-1-4503-1651-4/12/10 ...$15.00.

1.

INTRODUCTION

Process control systems are vulnerable to software-based exploits
with physical consequences [16, 33, 27, 35, 37, 3]. The increased
network connectivity and standardization of Supervisory Control
and Data Acquisition (SCADA) have raised concerns of attacks on
control system-managed infrastructure [5, 20, 6, 44]. Control sys-
tems use Programmable Logic Controllers (PLCs) to drive physical
machinery according to software control logic. For ease of modiﬁ-
cation, control logic is uploaded to the PLC from the local network,
the Internet, or serial port [41, 11]. For example, hundreds of Inter-
net accessible PLCs and SCADA devices can be found through the
Shodan search engine [1, 12]. An adversary with PLC access can
upload malicious control logic, called the payload, thereby gaining
full control of the devices under the PLC. Nevertheless, an addi-
tional challenge still remains: Even with knowledge of the target
control system’s behavior, an adversary cannot construct a payload
for speciﬁc devices without knowing how the PLC interfaces with
those devices. However, there is often no direct way of determining
which PLC memory locations regulate which devices.

This paper presents SABOT (Speciﬁcation-based Attacks against
Boolean Operations and Timers)1, a proof-of-concept tool for gen-
erating PLC payloads based on an adversary-provided speciﬁca-
tion of device behavior in the target control system. SABOT’s main
purpose is to recover semantics of PLC memory locations that are
mapped to physical devices. Speciﬁcally, SABOT determines which
PLC memory locations map to the devices in a behavioral speciﬁ-
cation of the target plant. This enables an adversary with a goal to
attack speciﬁc devices to automatically instantiate that attack for a
speciﬁc PLC in the victim control system. Unlike previous attacks,
such as Stuxnet [16], a precompiled payload is not necessary.

An attack using SABOT proceeds as follows:

1. The adversary encodes his understanding of the plant’s be-
havior into a speciﬁcation. The speciﬁcation contains a dec-
laration of plant devices and a list of temporal logic proper-
ties deﬁning their behavior.

2. SABOT downloads the existing control logic bytecode from

the victim PLC, and decompiles it into a logical model. SABOT
then uses model checking to ﬁnd a mapping between the
speciﬁed devices and variables within the control logic.

3. SABOT uses the mapping to instantiate a generic malicious
payload into one that can be run on the victim PLC. The
generic payload can contain arbitrary manipulation of the
speciﬁed devices, which SABOT substitutes with PLC ad-
dresses.

1Sabots were wooden shoes thrown into the gears of machinery by
Luddites in the Industrial Revolution.

439Figure 1: An example plant and process speciﬁcation for a chemical mixing control process.

SABOT is not for adversaries that do not understand the behavior of
the victim plant. In such cases, an adversary can erase the PLC’s
memory, upload random instructions, or attempt to bypass safety
properties of the control logic [29]. None of these attacks, however,
are guaranteed to be effective or stealthy. Instead, SABOT is most
useful to adversaries with accurate knowledge of the target plant
and process, but that are unaware of a critical piece of information:
how to manipulate speciﬁc plant devices from the PLC. This infor-
mation is not obvious to the adversary because it is unknown which
PLC variables are mapped to plant devices.

There are several implications stemming from the existence of a

tool like SABOT:
1. Reduced adversary requirements. In most cases, the only way
to know which PLC memory addresses map to which devices is to
physically inspect the labels on wires connecting the PLC to de-
vices. Only the most powerful adversaries e.g., insiders or nation
states, will have this information [38]. Furthermore, SABOT en-
ables attacks by adversaries that are unfamiliar with PLC instruc-
tion set architectures and communication protocols. Because the
variable mapping is done on an intermediate representation, code
from arbitrary PLCs can be decompiled for analysis by SABOT. We
give an example implementation of one such decompiler in Sec-
tion 3.2.
2. Improved target identiﬁcation. In the Stuxnet attack, PLC ver-
sion strings and device metadata were used to verify that the correct
target had been identiﬁed [16]. If this metadata was not found in
the PLC, then it was silently ignored by the virus. Using SABOT, a
target is identiﬁed by whether or not its control logic behaves in the
way speciﬁed by the adversary. Thus, the adversary need not know
any version strings or vendor metadata a priori. This may also re-
duce false positives in cases where an unintended PLC contains the
expected version strings and metadata. We evaluate SABOT’s abil-
ity to correctly identify a target control logic out of a number of
candidates in Section 4.4.
3. Room for error. Using a precompiled payload, an adversary’s
understanding of the plant’s behavior must be exactly correct or
the payload will likely fail. Using a dynamically generated pay-
load, there is some room for error. For example in Section 4.5 we
describe a method for writing behavioral speciﬁcations that will
correctly map to a control logic regardless of whether or not it im-
plements an emergency stop button, a common feature in many
control systems. While this is a ﬁrst step towards making a truly
adaptable attack mechanism, our results show that it works well
when an adversary correctly speciﬁes the behavior of a majority of

plant devices, as shown in Section 4.1.
It is also, to the best of
our knowledge, the ﬁrst analysis of its kind directed at PLC-based
control systems.

Our evaluations of SABOT show that it performs accurately and
efﬁciently against control logics of equal or greater complexity than
the target of the Stuxnet attack [16]. We begin our discussion of
SABOT in the next section by providing a brief overview of se-
quential control systems and detail an illustrative example.

2. CONTROL SYSTEMS

Control systems are used to monitor and control physical pro-
cesses. These systems can drive processes as simple as motion ac-
tivated light switches or as complex as wastewater treatment. Re-
gardless of their purpose and complexity, control systems are gen-
erally structured the same.

The physical apparatus in which the control system resides is
called the plant. Within the plant, control systems can be decom-
posed into three distinct elements: control inputs, control outputs,
and control logic. Control inputs are used to communicate the state
of the plant. For example, temperature, motion, or light sensors
are used to detect and communicate physical states. Other inputs
are human driven, such as switches, dials, and buttons. The control
system sends output signals to external devices to effect changes in
the physical world. For example, such signals may turn on indi-
cator lights, open and close valves, or drive bi-directional motors.
The control logic is the PLC software that computes new outputs
based on sensor inputs. The PLC repeatedly executes the control
logic in a scan cycle consisting of: i. read new inputs, ii. execute
control logic, and iii. write outputs to devices.

An example control system for a simpliﬁed chemical mixer is
shown in Figure 1. The plant (Figure 1(a)) is a single mixer with
valves to dispense two ingredients, A and B, a mixing element,
and a valve for draining the tank. The valves are controlled by
the output variables y1 and y2 respectively, the mixer by y3, and
the drain by y4. A device is ON when its corresponding output
variable is set to (cid:62) (true) and OFF when it is ⊥ (false). Three level
sensors are used to detect when the tank is at three levels–low, half
full, and full (corresponding to inputs x1, x2, and x3, respectively).
A level switch xi = (cid:62) if the contents of the tank are at or above its
level. A start signal is sent to the PLC via x4.

The mixer follows a simple process in which ingredient A is
added until the tank is half full, ingredient B is mixed with A until
the tank is full, and the result is drained. The speciﬁcation, shown
in Figure 1(b), details the control system implementation:

y1(a)Plantx1x2x3y2y3y4...PLCx1x2x3y1y2y3y4=X{}=Y{}ABProductX∪Y=VMx4x4(c)Control Logic (High Level)FillA:y1←(x4∨y1)∧¬x2AddB:y2←x2∧¬y4Mix:y3←(x2∨y3)∧x1Drain:y4←(x3∨y4)∧x1(b)x1:LowLevelSwitchx2:MidLevelSwitchx3:HighLevelSwitchx4:StartButtony1:IngredientAValvey2:IngredientBValvey3:Mixery4:DrainValveFill AMix BDrainStartProcess4401. Initially, all inputs and outputs are off until the Start button

is pressed (x4 = (cid:62)).

2. At this point the process enters state Fill A (y1 = (cid:62)), and the
tank is ﬁlled with ingredient A until the tank is ﬁlled midway
(x2 = (cid:62)), at which point the valve for A is closed (y1 = ⊥).
3. Next, the system transitions to the state Mix B, in which in-
gredient B is added (valve B is opened) until x3 = (cid:62). The
mixer y3 is also started in this state.
4. At this point, the system closes the value for B and enters the
Drain state (y4 = (cid:62)) until the tank is empty (detected by the
“low” sensor x1 = ⊥). At this point, the mixer is stopped.
The mixing process is an example of a common class of control sys-
tems, called sequential control systems. Sequential control systems
drive a physical plant through a process consisting of a sequence
of discrete steps. Sequential control is used in industrial manu-
facturing (automotive assembly, QA testing), building automation
(elevators, lighting), chemical processing (process control), energy
delivery (power management), and transportation automation (rail-
way switching, trafﬁc lights), among others.

Not shown in the example, a timer is a special control system
primitive that introduces a preset time delay between when an input
becomes true, and when a subsequent output becomes true. A timer
only sets the speciﬁed output to (cid:62) when the input has been set to
(cid:62) for the duration of its preset delay value. Timers can be used to
replace other sensors. For example, the level sensors above could
be replaced with timers, presuming the ﬂow and drain rates of the
apparatus were known and ﬁxed.
2.1 PLC Logic and ISA

The control logic for a sequential process is codiﬁed into a set of
Boolean circuits that are evaluated in order with dependencies. The
circuits are then compiled into the PLC’s native instruction set.

The control logic implementation of the chemical mixing pro-
cess is shown in Figure 1(c). The PLC executes each of the four
statements starting with Fill A and ending with Drain once each
scan cycle. At the plant start up state, y1 = ⊥. After the button x4
is pressed, y1 = (cid:62) until x2 = (cid:62). Notice that the clause (x4∨y1) is
necessary as x4 is a button that may only be depressed temporarily,
thus once y1 is activated, it should remain so until the terminating
condition x2 = (cid:62). Here, the value of y1 on the right hand side of
the statement is the value for y1 from the previous scan cycle.
The control output for valve B (y2) is activated immediately
when y1 = ⊥ on the condition x2 = (cid:62). y2 then remains ON
until the draining process begins with y4. The mixer (y3) is on as
long as the level in the tank has reached midway, and has not sub-
sequently been emptied. Finally, the drain (y4) is activated when
the tank is full, and remains ON until the tank is empty.

A logic program must be compiled to a PLC’s native instruction
set architecture (ISA) before being uploaded to the PLC. While
ISAs vary between PLC vendors, many are equivalent to the IEC
61131-3 standard for the Instruction List (IL) programming lan-
guage [21]. We implement an IL decompiler in Section 3.2.
2.2 Attacking PLCs

Control systems have shown to be vulnerable to attacks through
sensors [27], human machine interfaces [2], and PLCs [16, 4]. In
this work we focus on the last of these due to the complete control
offered to an adversary by PLCs, and the vulnerability of PLCs rel-
ative to the other two. For example, hundreds of Internet address-
able PLCs can be found on the Shodan computer search engine [1,
12], and new web-enabled, PLCs are being released into the mar-
ket place with the aims of making remote management more con-

Figure 2: SABOT: Steps to generate a malicious payload.

venient [41, 11]. An even more common arrangement is to have
the control system network connected to a corporate network for
economic reasons [44, 34]. Given this requirement, it is indeed the
case that all but the most critical PLCs will be at least reachable
from public networks.

In this work, we consider an adversary that has sufﬁcient knowl-
edge about the behavior of the target control system to design a tar-
geted and perhaps stealthy payload for that control system. While
this may sound like a strong requirement, it is important to note
that there are several methods through which one can obtain such
information. Many control systems, including railway switching,
and electrical substations exhibit some or all of their machinery
and behavior in plain view. Furthermore, details about plant struc-
ture can be gleaned from vulnerable human machine interfaces [2],
and scanning of industrial network protocols [29]. Vendors also re-
lease device data sheets and sample control logic, precisely deﬁn-
ing device behavior, for example [22]. Of course such information
is available to low ranking insiders [24]. Finally, we mention that
while it is unlikely that unskilled or “script kiddie” adversaries will
mount attacks targeted at speciﬁc devices, there is existing work
describing such naive attacks and their limitations [29].

3. SABOT

SABOT instantiates malicious payloads for targeted control sys-
tems. Depicted in Figure 2, the SABOT initially extracts a logi-
cal model of the process from the PLC code (see Section 3.2, De-
compilation). Next, the model and process speciﬁcation are used
to create a mapping of physical devices to input and output vari-
ables (called the variable-to-device mapping), or VTDM, (see Sec-
tion 3.3, VTDM Recovery). Last, a generic attack is projected onto
to the existing model and VTDM to create a malicious payload
called the PLC Malcode (see Section 3.4, Payload Construction).
This malcode is delivered to the victim interface.
3.1 Problem Formulation

Consider a scenario in which an adversary may wish to cause
ingredient A to be omitted from the chemical mixing process de-
scribed above. A PLC payload for this might look like:

Valve A ← ⊥
Valve B ← (Start Button ∨ Valve B) ∧ ¬Drain Valve

Intuitively, this control system never dispenses A, but rather ﬁlls
the tank with B. Unfortunately, the adversary does not know how
to specify to the PLC which device is meant by “Valve A” or “Start
Button.” This is because PLCs do not necessarily label their I/O
devices with semantically meaningful names like “Drain Valve.”2
2Some PLCs such as the Rockwell Controllogix line allow pro-
grammers to give names to I/O ports, but these names are still of
no use autonomous malware.

PLC CodeProcess SpeciﬁcationVTDM RecoveryVTDMGeneric MalcodePayloadPayload ConstructionPLCMalcodeDecompilationModel441Desc.

Bytecode Accumulator α

Stack

And x1
Nested Or
And x2
And y1
Pop stack
Store α to y2 = y2

A x1
O(
A x2
A y1
)

x1 ∨ (x2 ∧ y1)
C ← C ∪ {y2 ← x1 ∨ (x2 ∧ y1)}
VM ← VM ∪ {x1, x2, y1, y2}

(cid:62)

(cid:62)
x1
(cid:62)
x2

x2 ∧ y1

x1 : ∨
x1 : ∨
x1 : ∨

-
-

-
-

Table 1: Example accumulation of a constraint.

Instead, PLCs use memory addresses, e.g., x1, y2, to read values
from and write values to sensors and physical devices. We refer
to this set of address names as VM. The adversary, who does not
know the semantics of the names in VM, prefers to use the set of
semantically meaningful names Vφ = { Start Button, Valve B, . . .}.
This raises the problem, How can an adversary project attack
payloads using names in Vφ onto a system that uses the unknown
memory references VM? One of SABOT’s main tasks is to ﬁnd a
mapping from the names in Vφ to those in VM. Here, SABOT re-
quires one additional piece of information from the adversary: a
speciﬁcation of the target behavior.

If the adversary is to write a payload such as the one above for
the mixing plant, then it is assumed that he knows some facts about
the plant. For example, the adversary can make statements like:
“The plant contains two ingredient valves, and one drain valve,”
and “When the start button is pressed, the valve for ingredient A
opens.” The adversary encodes such statements into a behavioral
speciﬁcation of the target plant. When SABOT is then given a spec-
iﬁcation and control logic from a plant PLC, it will try to locate the
device addresses that behave the same under the rules of the logic
as the semantically meaningful names in the adversary’s speciﬁca-
tion.

Like the payload, the sensors and devices speciﬁed in the spec-
iﬁcation are deﬁned using semantically meaningful names from
Vφ. Given a control logic implementation, SABOT will construct
a model M from the control logic (Var(M) = VM), and perform
a model checking analysis to ﬁnd the Variable To Device Mapping
(VTDM) µ : Vφ → VM. SABOT assumes it has the correct
mapping µ when all properties in the speciﬁcation hold under the
control logic after their names have been mapped according to µ.
For example, the above property, “When the start button is pressed,
the valve for ingredient A opens,” will be checked as, “Under the
rules of the control logic, When x4 is pressed, then y1 opens,” un-
der the mapping µ = {Start Button (cid:55)→ x4, Valve A (cid:55)→ y1}.
The speciﬁcation is written as one or more temporal logic for-
mulas φ (Var(φ) ⊆ Vφ) with some additional hints for SABOT.
For a given mapping µ, the adversary supplied payload or spec-
iﬁcation under µ, denoted µ/payload or µ/φ, is identical to the
original, except with any names from Vφ replaced by names from
VM. Thus, to check whether a given mapping µ maps Vφ to the
devices is correct, SABOT checks:

M |= µ/φ

Read, “The temporal logic formula φ with literal names mapped
by µ holds over the labeled transition system M.” If these checks
are satisﬁed under a given µ, then SABOT instantiates the payload
over Vφ into a payload over VM.

3.2 Decompilation

To obtain a process model M, SABOT must ﬁrst bridge the gap
between the bytecode-level control logic, and the model itself. This

Constraint

input x

output or local y

c = y ← α

timer t

c = t ← α

NuSMV Model M

VAR x : boolean;
ASSIGN
init(x) := ⊥;
next(x) := {(cid:62), ⊥};
VAR y : boolean;
ASSIGN
init(y) := ⊥;
next(y) := α;
VAR t : boolean, tp : boolean;
ASSIGN
init(t) := ⊥;
next(t) := α ∧ (tp ∨ t) ? (cid:62) : ⊥;
init(tp) := ⊥;
next(tp) := α;

Table 2: Constructing M from constraints C.

means decompiling a list of assembly mnemonics that execute on
an accumulator-based architecture into a labeled transition system
deﬁned over state variables. SABOT performs this decompilation
in two steps. (1) The disassembled control logic bytecode is con-
verted to an intermediate set of constraints C on local, output, and
timer variables from the PLC. (2) The constraints in C are then
translated to M using the modeling language of the NuSMV model
checker [9].

For step 1, the constraints are obtained via symbolic execution of
the bytecode. This requires a preprocessing to remove nonstandard
instructions not handled by our symbolic execution. The resulting
code conforms to the IEC 61131-3 standard for PLC instruction
lists [21]. The control ﬂow graph (CFG) of the resulting code is
constructed and a symbolic execution is done over the CFG accord-
ing to a topological ordering. Several register values are tracked,
most importantly the logic accumulator α. An example symbolic
accumulation of control logic is shown in Table 1.
Step 2 translates the set of constraints resulting from step 1 into a
control logic model M that can be evaluated by the NuSMV model
checker. NuSMV takes deﬁnitions of labeled transitions systems
with states consisting of state variables. SABOT uses the VAR · :
boolean expression to declare a state variable for each name in
VM. Each Boolean variable is ﬁrst initialized using the init( · )
expression, and updated at each state transition using the next( · )
expression. A Boolean variable may be initialized or updated to a
constant value of (cid:62) or ⊥, another expression, or a nondeterministic
assignment {(cid:62),⊥}, where both transitions are considered when
checking a property. For a complete speciﬁcation of the NuSMV
input language, see [7].

As shown in Table 2, there are three translation rules. In the case
of input variables, a new Boolean variable is declared, initialized to
⊥, and updated nondeterministically. The nondeterministic update
is necessary because all possible combinations of sensor readings
must be factored into the model. Output and local variables are
initialized to ⊥ and updated according to the expression α.
Timer variables require an extra bit of state. Recall that a PLC
timer t = (cid:62) only when its input expression α = (cid:62) continuously
for at least t’s preset time duration. Furthermore, any input variable
in the model may change state while the timer is expiring. Thus, for
each timer, α must hold for two state transitions. The ﬁrst transi-
tion simulates the starting of the timer’s countdown, and the second
simulates the expiration, allowing the timer to output (cid:62).

The decompilation process includes several other steps such as
preprocessing bytecode to rewrite vendor speciﬁc instructions. Full
details can be found in our technical report [30].

4423.3 VTDM Recovery

SABOT attempts to ﬁnd a Variable To Device Mapping (VTDM)
µ from names in the adversary’s speciﬁcation to names in the con-
trol logic model M. If the correct mapping is found, then the se-
mantics are known for each name in VM mapped to by µ.

A speciﬁcation is an ordered list of properties. A property with

name id has the following syntax:

id : <input [input-list]> <output [output-list]>

<INIT [init-input-list]> <UNIQUE> φ

As an example, we can now restate our earlier speciﬁcation for the
plant start button, “When the start button is pressed, the valve for
ingredient A opens,” as the following property sbutton:

∗
sbutton : input start

∗
output vA INIT start

∗ ⇒ AX vA

start

The only mandatory part of a property is the Computational Tree
Logic (CTL) formul φ [19]. (Interpretations of CTL formulae are
given in quotes for the unfamiliar reader.) The CTL formula is
deﬁned over names given after the input and output keywords,
where {input-list} ∪ {output-list} ⊆ Vφ. SABOT will
check φ under the control logic model M in three steps:

1. Choose µ :{input-list}∪{output-list}→ VM.
2. Apply µ to φ by substituting all names in φ with their map-
pings in µ. This is denoted by µ/φ, read “The property φ
under the mapping µ.”

3. Check M |= µ/φ.

These three steps are applied over all possible mappings for a given
speciﬁcation. There are two optional parts to each speciﬁcation, the
list of inputs that will be initially ON INIT, and the conﬂict reso-
lution hint UNIQUE. Any names in init-input-list will be ini-
tialized to (cid:62) by the model checker. The keyword UNIQUE declares
that the names in input-list and output-list will not appear
in any conﬂict mappings.

A conﬂict mapping is a satisfactory mapping of multiple distinct
sets of variables in Vφ into a property. Conﬂict mappings repre-
sent ambiguity in the speciﬁcation, and must be resolved by adding
additional properties to the speciﬁcation. In practice, one or two
additional properties are required to resolved such conﬂicts. The
addition of properties only modiﬁes the constant factor of the map-
ping algorithm’s running time. A full discussion of conﬂict map-
pings with examples can be found in Section 3.3.2.
3.3.1 Mapping Speciﬁcations to Models
SABOT searches for a mapping µ : Vφ → VM such that M |=
µ/φ for every speciﬁcation φ in the speciﬁcation. This is done
incrementally, ﬁnding a satisfying mapping for each speciﬁcation
before moving to the next. If no satisfying mapping is found for
a given speciﬁcation, the previous speciﬁcation’s mapping is dis-
carded, and it is searched again for another satisfying mapping. If
no more satisfying mappings are found for the ﬁrst speciﬁcation
in the speciﬁcation, the algorithm terminates without identifying a
mapping. If a satisfying mapping is found for all speciﬁcations, the
algorithm accepts this as the correct mapping µSAT Algorithm 1
shows the basic mapping procedure (except for the UNIQUE fea-
ture).
We use the NuSMV model checker [9] for deciding M |= µ/φ.
The running time of IncMapping is dependent on the number of
false positive mappings for each speciﬁcation in the speciﬁcation
bounded below by Ω(|specif ication|) and above by O(|VM||Vφ|
).

Algorithm 1: IncMapping
: µ, spec, VM, M
Input
Output: The satisfying mapping µSAT or none

1 if spec = ∅ then
µSAT ← µ
2
return (cid:62)
3
4 φ ←Pop(spec)
5 foreach µ0 :Var(φ) → VM do
6
7

if M |= µ0/φ then

if IncMapping(µ ∪ µ0, spec, VM− µ0(Var(φ)), M)
then

return (cid:62)

8
9 return ⊥

3.3.2 Resolving Conﬂicts
Consider the problem of writing a speciﬁcation for the chemical
mixer process shown in Figure 1. First, one must deﬁne the names
in Vφ. Denoting input variable names with an ‘∗’, let l
∗
∗
2, and l
3
be the names of the low, mid, and high level switches respectively,
∗ be the start button. Additionally, let vA and vB be
and let start
the valves for ingredients A and B, mixer be the mixer, and vd
be the drainage valve. As in the ﬁgure, VM = {x1, x2, x3, x4} ∪
{y1, y2, y3, y4}.

∗
1, l

Recall the speciﬁcation sbutton from above. While sbutton is
an accurate speciﬁcation of plant behavior, it is also ambiguous.
To see this, we ﬁrst consider the case of the correct (true positive)
mapping µT P = {start
∗ (cid:55)→ x4, vA (cid:55)→ y1}. When the map-
ping is applied to the CTL speciﬁcation, we get: µT P /sbutton =
INIT x4 x4 ⇒ AX y1. µT P is the correct mapping because, (1)
µT P /sbutton holds under the control logic (Figure 1(c)), and (2)
x4, and y1 are the names of the control input and output for the
devices that the adversary intended.
∗ (cid:55)→
x2, vA (cid:55)→ y2}. Judging by the same criteria as above, we can see
that (1) µF P /sbutton holds under the control logic, but criterion
(2) fails because x2 and y2 (the mid level switch and the B in-
gredient valve respectively) are not the names of control variables
intended by the adversary. This raises the question: how can the
adversary remove this ambiguity from the speciﬁcation without a
priori knowledge of the semantics of x1, x2, y1, and y2?

Consider an example false positive mapping: µF P = {start

While the adversary does not know the semantics of names in
VM, he does know the semantics of names in Vφ. Thus, the adver-
sary need not know that x2 is a name for a mid level switch and
not a start button, only that there is some control variable name that
corresponds to a mid level switch. But the adversary already has
∗
an abstraction for this, the name l
2. The same goes for y2 and its
abstraction, the name vB. Thus, the adversary can reliably remove
this ambiguity by checking which names in Vφ are in conﬂict with
names in the property sbutton. For example, consider a speciﬁca-
tion that has the same structure as sbutton but with different names
(Read, “Switch 2 activates valve B”):

cf lict : input l

∗
2 output vB INIT l

∗
2

2 ⇒ AX vB
∗

l

Because the correct mapping for cf lict differs from the correct
∗, and
mapping for sbutton, we have that l
vB conﬂicts with vA. If the adversary can remove this conﬂict, then
the false positive mapping µF P will also be removed, and the am-
biguity is resolved. The conﬂict can be removed by the addition of

∗
2 conﬂicts with start

443the following speciﬁcation (Read, “Valve A can be on with the start
button released”).

∗
sbindep : input start
∗ ∧ vA)
EF(¬start

output vA

To see that the pair sbutton, sbindep removes the conﬂict, we
can substitute the conﬂict into sbindp, giving: EF(¬l
2 ∧ vB),
∗
which does not hold under the control logic. Thus, if the con-
ﬂicting mapping is initially made when checking sbutton, this
mapping will fail when checking sbindep, which will cause the
SABOT checker to go back to sbutton, and search for another
mapping, in this case, the correct one. Of course, this approach
is not guaranteed to make a completely unambiguous speciﬁcation
(as will be seen in Section 4), but it does remove all ambiguities
with respect to devices the adversary is aware of.

In larger examples, we keep track of conﬂicts and resolutions us-
ing conﬂict tables. An example set of conﬂict tables for a speciﬁca-
tion of a chemical process is shown in Figure 3. Each speciﬁcation
has a (potentially empty) conﬂict table listing all unmapped names
in Vφ that satisfy the speciﬁcation. Given a nonempty conﬂict table
for a speciﬁcation spec, one can make spec unambiguous by writ-
ing at most one additional speciﬁcation over the names in spec for
each entry in its conﬂict table. This guarantees a ﬁnite speciﬁca-
tion size bounded in O(|Vφ|2) speciﬁcations. Signiﬁcantly fewer
are usually necessary in practice.

The speciﬁcation keyword UNIQUE is used to declare that no
name appearing in the speciﬁcation will appear in a conﬂicting
mapping. This is useful because there are some cases where the
same name appears in many conﬂict table entries. (See speciﬁca-
tion sbutton in Figure 3). It is never required to use UNIQUE to
remove conﬂicts, but it can be useful in reducing the search space.
3.4 Payload Construction

In the payload construction step, SABOT instantiates a generic
malicious payload for the target PLC. Given a VTDM µ for a vic-
tim PLC and speciﬁcation, SABOT uses µ to map the names in the
adversary’s generic payload into those in the control logic. There-
after, the instantiated payload is recompiled into bytecode and up-
loaded to the PLC.

SABOT payloads are control logic programs deﬁned over names
in Vφ. Once the VTDM µ is found, the payload is instantiated
under µ, producing a payload over names in VM. Using this ap-
proach, an adversary can assume the same semantics for names in
the payload that are assumed for names in the speciﬁcation. As an
example, the following payload manipulates the chemical mixing
process into omitting ingredient A from the mixture.

Generic Payload

vA ← ⊥
vB ← (start∗ ∨ vB) ∧ ¬l∗
2 ∨ mixer) ∧ l∗
3 ∨ vd) ∧ l∗

mixer ← (l∗
vd ← (l∗

3

1

1

Instantiated Payload
y1 ← ⊥
y2 ← (x4 ∨ y2) ∧ ¬x3
y3 ← (x2 ∨ y3) ∧ x1
y4 ← (x3 ∨ y4) ∧ x1

Annunciator
Emergency
Sequential
Baseline
Parallel

System

Container Filling
Motor Control
Trafﬁc Signaling
pH Neutralization
Railway Switching

Table 3: Control system variants (omitted shaded).

such side effects can be concealed by malicious code execution on
the PLC programming machine [16].

4. EVALUATION

We evaluate SABOT using four metrics:
• Accuracy is the ability of SABOT to correctly map a speciﬁ-
cation onto a control system, even when unexpected features
are present. We evaluate the number of devices that are cor-
rectly mapped in each test case in Section 4.1.

• Adaptability is the ability to recognize different variants of
a control system. A canonical speciﬁcation is tested against
two unique implementations of a trafﬁc light control logic,
and results evaluated in Section 4.2.

• Performance is the ability to efﬁciently recover the VTDM
for a given speciﬁcation. We evaluate not only the total run-
ning time, but the number of false positives encountered by
the incremental mapping process in Section 4.3.

• Scalability is the ability to perform accurately and efﬁciently
as additional control system functionality is added to the PLC.
We augment SABOT with a basic dependency graph analysis,
and evaluate both accuracy and performance for PLCs run-
ning multiple independent subsystems Section 4.4.

Note that this is the ﬁrst set of experiments on SABOT, and addi-
tional future studies providing further validation and enlightenment
are appropriate. However, the results of this initial study indicate
that SABOT works well on a variety of control logics, and that there
remain numerous avenues for engineering and ﬁne tuning results.
We evaluate the use of two such improvements to reﬁne our initial
results in section 4.5.

All experiments are conducted using the ﬁve variants of ﬁve rep-
resentative process control systems taken from real-world applica-
tions described in Table 3. Each process description is used to im-
plement a speciﬁcation and a control logic. All speciﬁcations were
created independently of the implementations. Note that control
variables are denoted using emphasis and input variable are anno-
tated with ‘∗’ (e.g., invar

∗, outvar) below.

While seemingly simple, most of the following systems have a
larger variety of devices and more complex state machines than the
target of the Stuxnet attack, many uniform variable speed drives [16].
The ﬁve applications are:

Assuming that the correct mapping, i.e. µT P is found by SABOT,
then this payload will execute as expected when uploaded to the
mixer PLC. Our results in Section 4.1 show that the correct map-
ping can be recovered the majority of the time, even when the plant
has unexpected devices and functionality. If the adversary is un-
aware of a device in the plant, then even a correct VTDM may
cause side effects when used to instantiate an attack. The cause of

Container Filling. Consider the ﬁlling of product containers on an
assembly line, e.g., cereal boxes [13]. In the basic process, a belt
belt carries an empty container (belt = (cid:62)) until it is under the ﬁll-
∗, e.g., a light barrier detects
bin as indicated by a condition cond
when container is in position. Thereafter, a ﬁll valve f ill is opened
for a period of time to ﬁll, and the belt is activated to move the
next container into place. It may also occur that the ﬁll bin itself

444Figure 3: An unambiguous speciﬁcation with conﬂict tables for the pH neutralization system.

∗) and reverse (rev

∗ and a secondary
is depleted, as indicated by a level sensor low
source bin with valve source will be used to replenished the ﬁll
bin.
Motor Control. Stepper motors divide a full rotation into a set
of discrete angular positions. This has many applications in pre-
cision equipment like lathes, conveyors, and applications requiring
bidirectional operation. A stepper motor controller allows for start-
ing the motor in the forward direction f on and reversing the motor
ron, such that ¬f on∨¬ron always holds. Buttons are used for se-
∗) operation, and stopping
lecting forward (f or
∗. The controller will also enforce a minimum spin
the motor stop
down time before the motor is allowed to change direction.
Trafﬁc Signaling.3 Consider further a typical 4-way trafﬁc light
with red1, yellow1, and green1 in the North/South direction, and
red2, yellow2, and green2 in the East/West direction. Ignoring
inputs from pedestrians or road sensors, the trafﬁc light follows the
cycle: (red1, red2), (red1, green2), (red1, yellow2), (red1, red2),
(green1, red2), (yellow1, red2).
pH Neutralization. A pH neutralization system mixes a substance
of unknown acidity with a neutralizer until the desired pH level
is achieved, e.g., in wastewater treatment. An example process
adapted from [15] operates as follows:

3Trafﬁc signal attacks can cause signiﬁcant congestion [18].

∗

∗

∗

= (cid:62). If ts

∗
2, valve v1 is opened to ﬁll the tank
When the tank level is below ls
∗
with the acidic substance up to level ls
2. At this point valve v2 is
opened to dispense the neutralizer until the correct acidity level is
= (cid:62) and the correct temper-
indicated by the acidity sensor as
ature of the product has been reached as indicated by temperature
= ⊥, the heater is activated. If the desired
sensor ts
∗
3, v2 is closed and
pH level is not achieved before the tank ﬁlls to ls
∗
2. Once the correct pH
v4 is opened to drain the tank back to level ls
∗
level and temperature are achieved, and there is at least ls
2 liquid in
the tank, it is drained to the next stage by v3. The temperature and
acidity lights tl and al are activated when the desired temperature
and acidity have been reached respectively, and the tank is at least
∗
at level ls
2.
Railway Switching. Lastly, consider a process that safely coordi-
nates track switches and signal lights on a real railway segment [17]:

The segment consists of the two tracks (tr1 and tr2), two switches
(s1 and s2) and four signal lights a–d. A switch is said to be in the
normal state if it does not allow a train to switch tracks and in the
reverse state if it does allow a train to switch tracks. If a signal is
ON, it indicates that the train may proceed and if it is OFF, the train
must stop. The direction of each signal is indicated by an arrow.

∗–d

∗
2 and a

∗, where s

The signalman can control the state of the lights and switches
1 = (cid:62) puts switch s1
∗
∗
1, s
using the inputs s
∗ turns signal a ON. To ensure safe operation,
into reverse, and a
the control logic maintains several invariants over the signal and
switching commands from the signalman. (1) Two signals on the
same track, e.g., a and b, can never be ON simultaneously. (2) If a
switch is in reverse, then at most one signal is allowed to be ON.
(3.a) If switch s1 is in reverse, then signals a and c must be OFF.
(3.b) If switch s2 is in reverse, then signals b and d must be OFF.
(4) If both switches are set to reverse, then all signals must be OFF.

sbutton:INITstart∗UNIQUEstart∗⇒AXv11.ls∗2v22.ls∗2mixer3.ls∗2heater4.ls∗3v45.ls∗3heater6.ts∗tl7.as∗allatchedreﬁnessbutton:EF(start∗∧AX(¬start∗∧v1∗))Emptyheateron:UNIQUEAG(ts∗⇒AX¬heater)1.ls∗2v12.ls∗3v22.as∗v2mixeron:AG(¬ls∗1⇒AX¬mixer)1.ls∗1v32.ls∗2v43.ls∗2tl4.ls∗2asmixerindepreﬁnesmixeron:EF(¬ts∗∧¬mixer∧AX(¬ts∗∧mixer))Emptylevelindepreﬁnesmixeron:EF(ls∗1∧v1∧AX(ls∗1∧v1))Emptylevel2:AG(¬mixer∧ls∗1∧ls∗2⇒AXmixer)Emptyvalve2:INITls∗1,ls∗2ls∗1∧ls∗2⇒AXv2Emptyvalve4:AG(ls∗1∧ls∗2∧ls∗3⇒AXv4)Emptyvalve3:AG(¬as∗∨¬ts∗∧¬v3⇒AX¬v3)Emptytlight:AG(¬ts∗⇒AX¬tl)EmptypHlight:AG(¬as∗⇒AX¬al)EmptyNeutralizer:1.sbutton2.latched3.heateron4.mixeron5.mixerindep6.levelindep7.level28.valve29.valve410.valve311.tlight12.pHlightNeutralizerFrom SourceTo SourceTo Next Stepmixerls∗1ls∗2ls∗3v1v2v3v4heaterts∗as∗tlalstart∗tr1tr2abcds1s2←←→→a∗b∗c∗d∗s∗1s∗2...445Filling
Button
Control Logic Container
Start
Belt

Baseline
Emergency
Annunciator
Sequential
Parallel

Button
Forward
Button
Reverse
Control
Synchronized
Synchronized
Synchronized
Signal
Light
Light
Light
Light
Button
Light
Light
Forward
Reverse
Trafﬁc
Yellow
Yellow
Motor
Motor
Motor
Green
Green
Stop
Red
Red

1

2

1

2

1

2

Valve
Fill

n n n n n n

1

2

Synchronized
Switch

C

D

Signal

Signal

Switch

Neutralization
Valve
Valve
Valve
Valve
Button
Neutralizer
Source
Product
Heater
Source
Start

To

Mixer

Switching
Switch
Switch
Switch
Sensor
Synchronized
Sensor
Level
Level
Level
Railway
Acidity
Signal
Signal
Temp
High
Low
Mid

A

B

n n n n n n n n n n n n

p
p p p
p p p p

p p

p
p p

Control Logic pH
Baseline
Emergency
Annunciator
Sequential
Parallel

Table 4: Per-device accuracy results. Empty cell: Correct mapping, ‘p’: false positive mapping, ‘n’:false negative (no mapping),
Shaded cell: experiment omitted (see description).

Each of the applications is implemented in a Baseline control
system. Each baseline system is then modiﬁed with four variants
to introduce plant features not anticipated by the baseline speciﬁ-
cations:
Emergency. This case adds an emergency shutdown button named
∗ to each plant. If the emergency shutdown button is pushed,
estop
all devices will be immediately turned OFF. One can see how this
can cause false negative mappings. For example, a property of the
∗ ⇒ AX output) will no longer hold, because of
form AG(input
∗ holds, but output is forced to ⊥.
the case where input
The motor controller’s stop button acts as a shutdown, so there was
no need to add one.

∗ ∧ estop

Annunciator. Annunciator panels are visual or sometimes audible
displays present within the plant itself. We place a single annunci-
ator light on each input and output in the plant. This light is turned
ON by the control logic if the corresponding input or output is ON,
and OFF otherwise. We evaluate the plants with annunciator pan-
els as they nearly double the number of control variables that are
expected by the adversary. The trafﬁc signal and railway switching
processes were not evaluated with annunciator panels, as annunci-
ator functionality is already present in both systems.
Sequential. This case considers a plant with two distinct instances
of the process, where the second instance is dependent on the ﬁrst.
For the motor controller, this simply means that the second motor
mimics the forward and reverse behavior of the second. The same
is true for the trafﬁc lights, where the state of the second mimics
the ﬁrst. For sequential container ﬁlling, containers are partially by
the ﬁrst system, then by the second. The railway switching exam-
ple is modiﬁed to include three tracks, and allow a train to switch
from the ﬁrst track, to a middle second track, and then to the third
track. The safety properties are extended to prevent any conﬂicting
routes between the three tracks. Finally, the chemical neutraliza-
tion process is serialized to two tanks, such that the ﬁrst process
fully drains to the second before the second starts.

Parallel. This case models two independent instances of the pro-
cess executing in parallel on the same PLC. This is expected to
occur in production environments where it is more cost effective to
add more input and output wires to the same PLC than to maintain
distinct PLCs for each parallel instance of the process. A special
criterion is added for the parallel case called Synchronized, which
is true if all mappings where true positives in the same instance of
the process. I.e., there is no mixing of mappings between the two
independent processes.
4.1 Accuracy

Recall that accuracy is a measure of the correctness of the iden-
tiﬁed mappings between internal devices and the process speciﬁca-
tions, i.e., the accuracy of the VTDM. Here we measure correctly
mapped devices, incorrect mappings (false positives), and failures
to identify any mapping at all (false negatives). The results for ac-
curacy experiments are shown in Table 4. To summarize, in three
out of ﬁve test systems the baseline speciﬁcation is sufﬁcient to
produce a complete, correct mapping for the control system, and
four out of ﬁve systems had no false positives.

As expected, the emergency shutdown case caused false nega-
tives in two out of the three control systems. This was due to the
∗ ⇒ output) to
failure of speciﬁcations of the form AG(input
always hold under any mapping when there is always a state in
∗ makes the property not hold. The false negatives
which estop
occur for all devices in both cases, because later speciﬁcations con-
tained names that failed to map in earlier speciﬁcations, making
them uncheckable.

The pH neutralization system experienced the most false pos-
itives due to its multiple parallel behaviors.
In the annunciator
panel, the behavior of the valve for the neutralizer (v2) could not
be distinguished from the annunciator light for the mid level switch
2 = (cid:62) implies that both the valve and annunciator
∗
∗
2 because ls
ls
light are ON. More broadly, the sequential system false positives
were caused by devices in the ﬁrst instance that were mistaken for
a device in the second instance. For example, the heater in the

446System

Container Filling
Motor Control
Trafﬁc Signal
pH Neutralization
Railway Switching

Baseline
0.59/16
0.23/7
5.59/125
2.42/70
0.92/25

-/-

6.35/130
3.67/101
1.05/27

Emergency Annunciator
0.68/21

1.03/28
0.26/7
-/-

4.55/100

-/-

Sequential
1.00/27
0.45/14
51.76/1040
14.16/228
4.00/97

Parallel
1.57/29
0.86/19

103.60/1385
11.51/179
19.95/97

Table 5: Running time (s) / number of calls to the model checker for each system and case.

ﬁrst instance of the pH neutralization system was confused with the
heater in the second. The false positives in the parallel case were
caused by devices in the ﬁrst instance that were mistaken for non-
equivalent devices in the second. For example, the ﬁnished product
valve (v3) in the ﬁrst instance of the pH neutralization system was
confused with the mixer in the second instance. We improve upon
these results in Section 4.5.
4.2 Adaptability

Adaptability is the ability to recognize a control system by its
behavior, independent of its implementation. Because SABOT only
considers control logic behavior and not its structure, any imple-
mentation conforming to the process description will be handled
equivalently. To conﬁrm this is the case, and as an experimental
control, a team member not involved in prior analysis was tasked
with implementing an alternative trafﬁc signal control program that
exhibited the behavior from the description. The team member took
an alternative strategy of allowing the light timers to drive the rest
of the process, resulting in a signiﬁcantly different implementation.
The same experiments run above were rerun on this new implemen-
tation, and the results were identical.
4.3 Performance

To gauge runtime costs, we measured the running time and num-
ber of calls to the NuSMV model checker of each experiment con-
ducted in Section 4.1. Note that SABOT’s running time for a given
model and speciﬁcation is hard to calculate for a given set of in-
puts because it is highly dependent on the number of incremental
mappings attempted.

Shown in Table 5, in over 75% of tests, the mapping is found in
less than 10 seconds, and in 90% of tests, the mapping is found in
less than 30 seconds. Two tests however deserve particular atten-
tion. The test with a running time of 1m43.6s for parallel trafﬁc
signaling made the most calls to the model checker of any test. It
also represented the greatest increase in calls to the model checker
over its own baseline. This can be attributed to the fact that the traf-
ﬁc signal was the only speciﬁcation containing speciﬁcations that
mapped three names at once.

Also note the comparative running times and number of checker
calls for the sequential and parallel railway switching tests. Both
required the same number of calls to the checker, but the parallel
case has nearly a ﬁvefold increase in running time. The extended
running time for each call to the checker was the result of the dif-
ference in state space between the two. In the sequential case, there
were two systems with one set of inputs, and the second system
dependent on the ﬁrst. In the parallel case, the independent input
sets greatly inﬂated the model’s state space. We discuss a check
that could reduce state space explosion in the following section.
4.4 Scalability

Thus far, we have assumed that the control logic only contained
the speciﬁed functionality. In this section, we evaluate SABOT’s
accuracy and performance given a PLC that has functionality for
additional independent subsystems in place. In practice, a large fa-

Speciﬁed
Container Filling
Motor Control
Trafﬁc Signal
pH Neutralization
Railway Switching

Run time (s) Calls
96
138
485
174
2057

3.28
4.70
18.28
6.49
75.70

FP
0
1
0
0
0

Table 6: Run time (s), checker calls, and false positives for
checks against the monolithic control logic.

cility such as a nuclear power plant or waste water treatment facil-
ity will be broken down into subsystems, each of which will have a
dedicated PLC. These PLCs are in turn coordinated by higher levels
of supervisory control. However, this does not guarantee that ad-
ditional unspeciﬁed functionality will not be run on the same PLC.
Thus, we wish to evaluate SABOT under such a scenario.

In this section, we augment SABOT with a simple dependency
analysis that separates the control logic into separate models for
each independent subsystem. The subsystem models are constructed
as follows. First, the variable dependency graph for the control
logic is constructed. Second, an undirected edge is added between
any two output variables with a common dependency. Third, a
new graph is constructed using just the output variables and newly
added undirected edges. A single subsystem model is constructed
for each strongly connected component in this graph. The speciﬁ-
cation is then tested against each model independently.

To simulate independent subsystems running in the same PLC,
we combined all ﬁve test systems into a single monolithic control
logic. We then ran SABOT with the dependency analysis against
the monolithic logic with each of the ﬁve speciﬁcations. Ideally, in
each run, SABOT would match the speciﬁcation only to the correct
corresponding subsystem. There are two types of errors that can
occur here. First, a speciﬁcation could be mapped to an incorrect
subsystem. Second, an incorrect dependency analysis may occur,
e.g., if variables in multiple subsystems share a dependency. While
this was not an issue in our experiments, we defer a more sophisti-
cated dependency analysis algorithm to future work.

The performance and accuracy results are shown in Table 6.
Only a single false positive mapping occurred from the speciﬁca-
tion for motor control onto the implementation of railway switch-
ing. Unlike the performance results in Section 4.3, here, the railway
switching has the highest running time. This is due to the large
number of incremental false positive mappings that occur when
testing the railway switching speciﬁcation against pH neutraliza-
tion, which led to many false positive variable mappings being re-
jected by the incremental mapping algorithm. Nevertheless, in all
cases, the run times are still within the limits found in Section 4.3.
4.5 Accuracy Improvements

In this section, we consider using two reﬁnements to improve
the accuracy results found in Section 4.1. First, we include the
dependency analysis introduced in the previous section in hopes of
improving the results for the parallel variation in pH neutralization.
Second, we introduce a method to safeguard a speciﬁcation against
the presence of emergency stop systems, a common feature.

447Neutralization
Valve
Valve
Valve
Valve
Button
Neutralizer
Source
Product
Heater
Source
Start

To

Mixer

Control Logic pH
Baseline
Emergency
Annunciator
Sequential
Parallel

Switch
Switch
Switch
Sensor
Synchronized
Synchronized
Signal
Sensor
Light
Light
Light
Light
Level
Level
Level
Light
Light
Acidity
Trafﬁc
Yellow
Yellow
Green
Green
Temp
High
Low
Mid
Red
Red

1

2

1

2

1

2

p
p p p

p

Table 7: Accuracy improvements on results from Table 4.

We safeguard a speciﬁcation against an emergency stop button
by slightly weakening each property of the form AG(ψ ⇒ φ) to al-
low it to fail on cases where ψ∧estop holds. For example, in the pH
neutralizer, the property AG(¬mixer ∧ ls
2 ⇒ AX mixer)
1 ∧ ls
∗
∗
was changed to AF(¬mixer ∧ ls
2 ⇒ AX mixer), and a
1 ∧ ls
∗
∗
fairness constraint FAIRNESS mixer was added to force the model
checker to ignore the path on which estop was inﬁnitely ON. For
properties of other forms, such as AG(¬ψ ⇒ φ), no such weak-
ening is necessary because it still holds when either ψ ∧ estop or
ψ ∧ ¬estop.

The results with both dependency analysis and safeguards are
shown in Table 7. The safeguard was applied to all properties in
the pH neutralization and trafﬁc signal systems, and all ﬁve test
cases were rerun. The addition of the safeguards did not negatively
affect accuracy in the baseline case, and the number of test cases
for which all devices are mapped regardless of plant features is in-
creased to 4 out of 5. Thus, if an adversary has reason to suspect
that an emergency stop system may be in place, the use of safe-
guards can be an effective workaround.

5. COUNTERMEASURES

We now explore several avenues to countermeasures to SABOT-
like mechanisms in control systems: improved perimeter security,
novel PLC security architectures, and control logic obfuscation.
Improved perimeter security. Perhaps the most straightforward
way to safeguard against malicious PLC payloads is to improve
perimeter defenses around PLCs. Unfortunately, the most effective
solution, disconnecting the PLC from any networked computer, is
neither common practice, nor in many cases economically feasible.
Due to economic constraints and for ease of maintenance, PLCs are
often connected to the corporate networks [44] or the Internet [41,
11]. However numerous standards exists for defense in depth secu-
rity in control systems across industries [14] such as in the power
sector [42, 32]. Compliance with standards, however, can lead to a
checklist approach to security that can ultimately give a false sense
of security impact [43, 34]. A ﬁnal defense-in-depth technique is
the use of SCADA honeynets [36] outside of the protected perime-
ter to detect adversaries before they access production SCADA de-
vices.
Novel PLC security architectures. PLCs as they exist today sup-
port virtually no security precautions short of basic passwords. There
are several basic architectural changes that can mitigate any PLC
payload mechanism. Mohan et al. [31] proposed the use of a safety
PLC to monitor plant behavior and detect deviations from deter-
ministic behavior. Similarly, a model based anomaly detection sys-
tem for SCADA networks was proposed in [8]. Lemay et al. [25]

used attestation protocols to verify the integrity the code running on
a smart electricity meter, including ﬁrmware updates. Attestations
have also been used to prevent peripheral ﬁrmware from attacking
a host computer [26]. A similar method could be applied to con-
trol systems in which PLCs must attest their entire stack, including
ﬁrmware and control logic, to a trusted third party before being al-
lowed to send control signals to devices. Thus, any maliciously
uploaded control logic would be discovered. Of course, any such
solution faces a long path to deployment in real world systems.

Control logic obfuscation. If the above two measures fail, obfus-
cation of the PLC’s control logic can offer a ﬁnal line of defense in
preventing SABOT’s analysis. This has the added advantage that no
modiﬁcation of the control system is required beyond obfuscating
the control logic itself. Much of the existing work on program ob-
fuscation is has attempted either to evade malware signature match-
ing [39] or to prevent code injection into address spaces [40]. Here,
the objectives are different; the goal in this case is to prevent either
decompilation or VTDM recovery by SABOT. Attempts at pre-
venting decompilation will likely fail, as control engineers expect
to be able to read code from a PLC and decompile it. (Most PLC
development environments can decompile control logic.) A more
promising route is to add noise in the form of unused variables that
are not mapped to any devices. This would, however, be a funda-
mental departure from current control engineering practices.

6. RELATED WORK

There are many tools preceding SABOT aimed at exploiting soft-
ware vulnerabilities in control systems. Automated exploit frame-
works like Metasploit [28] have been extended to attacks against
SCADA and control systems [23]. While such exploitation of con-
trol systems is however not new [5], the rate of release of new
SCADA and PLC exploits has been accelerating [35, 10]. Such
tools can be seen as fulﬁlling the ﬁrst step of control system pen-
etration, the subsequent step being automatic payload generation
against the victim PLC.

McLaughlin ﬁrst described the requirements for extending auto-
mated exploit frameworks to perform attacks against PLCs in [29].
The focus is, however, how to execute untargeted attacks against
an PLC system based on techniques such as the violation of safety
interlocks found in the control logic. The topic of executing a tar-
geted attack is only brieﬂy touched on, as it is mentioned that a
means will be necessary for an adversary to specify the payload
goal. However, no means is given for actually specifying the goal,
or for achieving it. SABOT is, to the best of our knowledge, the ﬁrst
evaluation of these techniques.

4487. CONCLUSION

In this paper, we have presented SABOT as a means to lower
the bar of sophistication needed to construct payloads for vulner-
able PLCs. If an adversary is familiar enough with their target to
specify a precise attack deﬁnition, then SABOT can map a supplied
behavioral speciﬁcation onto the code from the victim PLC, allow-
ing a malicious payload to be instantiated. We have demonstrated
that even when unexpected features or independent subsystems are
implemented in a PLC, SABOT can still ﬁnd a sufﬁcient mapping to
instantiate a payload for the system within a reasonable time frame.
PLC code obfuscation may prove an effective defense against such
attacks, though it is in conﬂict with current practices.

8. REFERENCES
[1] Shodan. http://www.shodanhq.net.
[2] ADVANTECH/BROADWIN WEBACCESS RPC

VULNERABILITY. ICS-CERT Advisory 11-094-02, April 2011.

[3] AMIN, S., LITRICO, X., SASTRY, S. S., AND BAYEN, A. M.

Stealthy Deception Attacks on Water SCADA Systems. In
Proceedings of the 13th ACM international conference on Hybrid
systems: computation and control (2010).

[4] BERESFORD, D. Exploiting Siemens Simatic S7 PLCs. In Black Hat

USA (2011).

[5] BYRES, E., AND LOWE, J. The Myths and Facts behind Cyber

Security Risks for Industrial Control Systems. In ISA Process
Control Conference (2003).

[6] CÁRDENAS, A. A., AMIN, S., AND SASTRY, S. Research

Challenges for the Security of Control Systems. In Proceedings of
the 3rd conference on Hot topics in security (2008).

[7] CAVADA, R., CIMATTI, A., JOCHIM, C. A., KEIGHREN, G.,

OLIVETTI, E., PISTORE, M., ROVERI, M., AND TCHALTSEV, A.
NuSMV 2.5 User Manual, 2010.

[8] CHEUNG, S., DUTERTRE, B., FONG, M., LINDQVIST, U.,

SKINNER, K., AND VALDES, A. Using Model-based Intrusion
Detection for SCADA Networks. In Proceedings of the SCADA
Security Scientiﬁc Symposium (2007).

[9] CIMATTI, A., CLARKE, E., GIUNCHIGLIA, F., AND ROVERI, M.

NuSMV: A New Symbolic Model Veriﬁer. In Computer Aided
Veriﬁcation. Springer Berlin / Heidelberg, 1999.

[10] CONSTANTIN, L. Researchers Expose Flaws in Popular Industrial
Control Systems. http://www.pcworld.com, January 2012.

[11] CONTROL TECHNOLOGY CORP. Blue Fusion: Model 5200

Controller. http:
//www.ctc-control.com/products/5200/5200.asp.
[12] ÉIREANN P. LEVERTT. Quantitatively Assessing and Visualising
Industrial System Attack Surfaces. Master’s thesis, University of
Cambridge, 2011.

[13] ERICKSON, K. T., AND HEDRICK, J. L. Plantwide Process Control.

Wiley Inter-Science, 1999.

[14] EVANS, R. P. Control Systems Cyber Security Standards Support

Activities, January 2009.

[15] FALCIONE, A., AND KROGH, B. Design Recovery for Relay Ladder

Logic. In First IEEE Conference on Control Applications (1992).
[16] FALLIERE, N., MURCHU, L. O., AND CHIEN, E. W32.Stuxnet

Dossier. http://www.symantec.com, 2010.

[17] FERREIRA, N. G., AND SILVA, P. S. M. Automatic Veriﬁcation of
Safety Rules for a Subway Control Software. In Proceedings of the
Brazilian Symposium on Formal Methods (SBMF) (2004).

[18] GRAD, S. Engineers who hacked into L.A. trafﬁc signal computer,

jamming streets, sentenced.
http://latimesblogs.latimes.com.

[19] HUTH, M., AND RYAN, M. Logic in Computer Science. Cambridge

University Press, 2004.

[20] IGURE, V. M., LAUGHTER, S. A., AND WILLIAMS, R. D. Security

Issues in SCADA Networks. Computers and Security (2006).

[21] INTERNATIONAL ELECTROTECHNICAL COMMISSION.

International Standard IEC 61131 Part 3: Programming Languages.

[22] KEYENCE AMERICA. Position control using a stepper motor.

http://www.keyence.com/downloads/plc_dwn.php.
[23] LANGILL, J. White Phosphorus Exploit Pack Ver 1.11 Released for

Immunity Canvas. http://scadahacker.blogspot.com,
2011.

[24] LEALL, N. Lessons from an Insider Attack on SCADA Systems.

http://blogs.cisco.com/security/lessons_from_
an_insider_attack_on_scada_systems, August 2009.
[25] LEMAY, M., AND GUNTER, C. A. Cumulative attestation kernels

for embedded systems. In Proceedings of the 14th European
Symposium on Research in Computer Security (ESORICS) (2009).

[26] LI, Y., MCCUNE, J. M., AND PERRIG, A. Viper: verifying the

integrity of peripherals’ ﬁrmware. In Proceedings of the 18th ACM
conference on Computer and communications security.

[27] LIU, Y., NING, P., AND REITER, M. K. False Data Injection

Attacks against State Estimation in Electric Power Grids. In
Proceedings of the 16th ACM Conference on Computer and
Communications Security (November 2009).

[28] MAYOR, D., MOOKHEY, K. K., CERVINI, J., AND ROSLAN, F.
Metasploit Tookit: for Penetration Testing, Exploit Devevlopment,
and Vulnerability Research. Syngress, 2007.

[29] MCLAUGHLIN, S. On Dynamic Malware Payloads Aimed at

Programmable Logic Controllers. In 6th USENIX Workshop on Hot
Topics in Security (2011).

[30] MCLAUGHLIN, S., AND MCDANIEL, P. SABOT:

Speciﬁcation-based Payload Generation for Programmable Logic
Controllers. Tech. Rep. NAS-TR-0162-2012, The Pennsylvania State
University, 2012.

[31] MOHAN, S., BAK, S., BETTI, E., YUN, H., SHA, L., AND

CACCAMO, M. S3A: Secure System Simplex Architecture for
Enhanced Security of Cyber-Physical Systems.
http://arxiv.org, 2012.

[32] NATIONAL ENERGY REGULATORY COMISSION. NERC CIP 002 1

- Critical Cyber Asset Identiﬁcation, 2006.

[33] NICOL, D. M. Hacking the Lights Out. Scientiﬁc American 305, 1

(July 2011), 70–75.

[34] PIÈTRE-CAMBACÉDÈS, L., TRISCHLER, M., AND ERICSSON,

G. N. Cybersecurity Myths on Power Control Systems: 21
Misconceptions and False Beliefs. IEEE Transactions on Power
Delivery (2011).

[35] POLLET, J. Electricity for free? the dirty underbelly of scada and
smart meters. In Proceedings of Black Hat USA 2010 (July 2010).

[36] POTHAMSETTY, V., AND FRANZ, M. The SCADA Honeynet
Project. http://scadahoneynet.sourceforge.net.

[37] ROBERTS, P. F. Zotob, PnP Worms Slam 13 DaimlerChrysler Plants.

http://www.eweek.com, August 2008.

[38] SANGER, D. E. Obama Order Sped Up Wave of Cyberattacks

Against Iran. New York Times (June 2012).

[39] SZOR, P. The Art of Computer Virus Research and Defense. Addison

Wesley, 2005.

[40] THE PAX TEAM. Address Space Layout Randomization of PaX.

pax.grsecurity.net.

[41] TRIANGLE RESEARCH INTERNATIONAL. Connecting Super PLCs

to the Internet.
http://www.tri-plc.com/internetconnect.htm.

[42] U.S. DEPARTMENT OF ENERGY OFFICE OF ELECTRICITY

DELIVERY AND ENERGY RELIABILITY. A Summary of Control
System Security Standards Activities in the Energy Sector, October
2005.

[43] WEISS, J. Are the NERC CIPS making the grid less reliable. Control

Global (2009).

[44] YARDLEY, T. SCADA: Issues, Vulnerabilities, and Future

Directions. ;login 34, 6 (December 2008), 14–20.

449