Gatling: Automatic Attack Discovery in Large-Scale Distributed Systems

Hyojeong Lee, Jeff Seibert, Charles Killian and Cristina Nita-Rotaru

Department of Computer Science

Purdue University

{hyojlee, jcseiber, ckillian, crisn}@purdue.edu

Abstract

In this paper, we propose Gatling, a framework that au-
tomatically ﬁnds performance attacks caused by insider at-
tackers in large-scale message-passing distributed systems.
In performance attacks, malicious nodes deviate from the
protocol when sending or creating messages, with the goal
of degrading system performance. We identify a represen-
tative set of basic malicious message delivery and lying ac-
tions and design a greedy search algorithm that ﬁnds effec-
tive attacks consisting of a subset of these actions. While
lying malicious actions are protocol dependent, requiring
the format and meaning of messages, Gatling captures them
without needing to modify the target system, by using a type-
aware compiler. We have implemented and used Gatling on
six systems, a virtual coordinate system, a distributed hash
table lookup service and application, two multicast systems
and one ﬁle sharing application, and found a total of 41
attacks, ranging from a few minutes to a few hours to ﬁnd
each attack.

1 Introduction

Building robust, high-performance,

large scale dis-
tributed systems is a challenging task given the complex-
ity of designing,
testing, and debugging such systems.
Programming environments [27, 33, 35, 36, 38], execution
logging and replay tools [20, 39],
test case generation
tools [13], and a variety of testbeds [4, 7, 44], emula-
tions [1, 2, 52], and simulation platforms [3, 5, 6] were cre-
ated to ease code development and testing.

Given the difﬁculty of ﬁnding bugs manually, several
techniques have been applied to ﬁnd them automatically.
Model checking using static analysis [25, 34] has been used
to verify that the design of a system is correct. Given the
model of the system, this approach proves that some invari-
ants hold for every reachable state in the system. Model
checking has limited applicability for complex designs due
to the intractable number of states that must be checked.

Checking the design is not a guarantee that the actual code
is free from bugs because models do not capture all the in-
tricacies of real implementations and additional bugs can be
introduced during implementation.

Finding bugs in distributed systems implementation has
been done with the use of symbolic execution, fault injec-
tion, and model checking. Symbolic execution [13] has
been used to generate test cases that are capable of cover-
ing many control ﬂow branches. This technique also suffers
from a state-space explosion when applied to more com-
plex implementations. Fault injection [24] has been used
to discover unknown bugs by testing fault handling code
that would not normally be tested. Fault injection is often
limited in scope because it is difﬁcult to apply to an imple-
mentation in a systematic manner. Finally, model checking
using a systematic state-space exploration [25,26,41,56,57]
has been used on system implementations to ﬁnd bugs
that violate speciﬁed invariants. To mitigate the effect of
state-space explosion, the state exploration uses an itera-
tive search, bounding some aspect of the execution. These
heuristics do not prove bug absence, but rather help pinpoint
where bugs do exist.

More recently, debugging techniques have been applied
to automatically ﬁnd attacks. Many works have been fo-
cused on ﬁnding or preventing vulnerabilities that either
cause the victim to crash or allow the attacker to gain es-
calated privileges [16, 22, 37, 43, 54]. Dynamic taint anal-
ysis [37, 43, 54] has been used to protect implementations
from well-deﬁned attacks, such as buffer overﬂow attacks.
Taint analysis is limited in that it is a detection mechanism,
not a search mechanism. Fault injection with an iterative
parameter space search [11] has also been used to ﬁnd vul-
nerabilities in distributed systems. However, this approach
requires a costly parameter optimization limiting the size of
the system it can be used to analyze.

are designed to meet
Most distributed systems
application-prescribed metrics
that ensure availability
and high-performance. However, attacks can signiﬁcantly
degrade performance, limiting the practical utility of these
systems in adversarial environments.
In particular, com-

promised participants can manipulate protocol semantics
through attacks that target the messages exchanged with
honest nodes. To date, ﬁnding attacks against performance
has been primarily a manual task due to both the difﬁculty
of expressing performance as an invariant in the system and
the state-space explosion that occurs as attackers are more
realistically modeled. The only works we are aware of
that focused on automatically ﬁnding performance attacks
are the works in [50] which considers lying in headers of
packets in two-party protocols, and [32] which assumes the
user supplies a suspect line of code, indicating that it should
not be executed many times. The method in [50] explores
all states and does not scale for a distributed system. The
method used in [32] has better scalability by combining
static with runtime testing, but focuses only on attacks that
exploit control ﬂow and where attackers know the state of
the benign nodes.

In this work we focus on how to automatically detect
performance attacks on implementations of large-scale mes-
sage passing distributed systems. We consider insider at-
tacks that have a global impact on system performance and
which are conducted through message manipulation. We
focus on these attacks given they have received limited at-
tention, they can cause signiﬁcant disruption on the system,
and they are applicable to many distributed systems. Our
goal is to provide a list of effective attacks to the user in
a timely manner, requiring the user to provide only one or
several metrics measuring system progress. Our contribu-
tions are:

• We propose Gatling, a framework that combines a
model checker and simulator environment with a fault
injector to ﬁnd performance attacks in event-based
message passing distributed systems. We identify ba-
sic malicious message delivery and message lying ac-
tions that insider attackers can use to create attacks.
We design an attack discovery algorithm that uses a
greedy search approach based on an impact score that
measures attack effectiveness. Gatling works for a
large class of distributed systems and does not require
the user to write a malicious implementation. While
Gatling does not ﬁx attacks nor prove their absence, it
provides the user with protocol-level semantic mean-
ing about the discovered attacks.

• We provide a concrete implementation of Gatling for
the Mace [27] toolkit. Mace provides a compiler and
runtime environment for building high performance,
modular distributed systems. Our changes include:
(1) adding an interposition layer between Mace ser-
vices and the networking services to implement ma-
licious message delivery actions, (2) modifying the
Mace compiler to include a message serialization code
injector to implement message lying actions, and (3)

modifying the simulator to implement our attack dis-
covery algorithm. The user provides an implementa-
tion of the distributed system in Mace and speciﬁes an
impact score in a simulation driver that allows the sys-
tem to run in the simulator.

• We demonstrate with a case study how to use Gatling
to ﬁnd attacks on a real system implementation, the
BulletPrime peer-to-peer ﬁle distribution system. Our
goal is not to criticize BulletPrime’s design, but to ex-
plore its behavior in an adversarial environment. While
some of the attacks found on BulletPrime were ex-
pected, such as delaying or dropping data messages,
others were more surprising.
Speciﬁcally, Bullet-
Prime’s reliance on services that provide improved
download times led to a number of vulnerabilities.

• We further validate Gatling by applying it to ﬁve addi-
tional systems having different application goals and
designs:
the Vivaldi [19] virtual coordinate system,
the Chord lookup service and distributed hash table
(DHT) [51], and two multicast systems: ESM [17] and
Scribe [49]. Gatling found a total of 41 performance
attacks across the systems tested, 17 attacks based on
message lying actions and 24 attacks based on mes-
sage delivery actions. Finding each attack took a few
minutes to a few hours.

Roadmap. Sections 2 and 3 describe the design and
implementation of Gatling. Section 4 provides an exam-
ple of how to use Gatling to ﬁnd attacks in a well-known
distributed ﬁle sharing system, BulletPrime [28]. Section 5
presents results on using our tool on ﬁve representative dis-
tributed systems: Vivaldi [19], Chord, DHT [51], ESM [17],
and Scribe [49]. Section 6 presents related work and Sec-
tion 7 concludes our paper.

2 Gatling Design

The design goal of Gatling is to automatically ﬁnd in-
sider attacks in distributed systems. We focus on attacks
against system performance where compromised partici-
pants running malicious implementations try to degrade the
overall performance of the system through their actions.
Such attacks require that the system has a performance met-
ric, that when evaluated gives an indication of the progress
it has in completing its goals. For example, for an overlay
multicast system throughput is an indication of the perfor-
mance of the system. Speciﬁcally, we deﬁne:

Performance attack A set of actions that deviate from the
protocol, taken by a group of malicious nodes, that re-
sults in performance that is worse than in benign sce-
narios by some ∆.

Next, we describe the system model we consider, iden-
tify malicious actions which represent building blocks for
an attack, and describe our algorithm that searches and dis-
covers attacks consisting of multiple malicious actions.

2.1 Design Overview

Model checking event-driven state machines. Many
distributed systems [27, 29–31, 36, 40, 46–48, 55] are de-
signed following event-based state machines that commu-
nicate through messages. Also several other systems use
RPCs [35, 51], continuations [33], or data ﬂow [38], which
are compatible with this approach. Thus, we focus on
distributed systems implementations that are conceptually
message passing event-driven state machines, and we will
refer to this as the message-event model.

A well-known approach to ﬁnd bugs in distributed sys-
tems is to use model checking which allows a user to ex-
plore the set of all possible behaviors. This approach, when
applied to systems implementations, results in a systematic
state-space exploration through carefully controlled execu-
tion to determine all reachable system states. The state of
a distributed system is conceptually the combination of the
state maintained at each node, in conjunction with the state
of the network connecting distributed nodes.

The message-event model provides opportunities for re-
ducing the state space. First, it avoids the complexity of
simulating networking and routing layers by abstracting the
network to be a basic service which either provides FIFO
reliable message passing (such as TCP), or best-effort mes-
sage passing (such as UDP). As a result, the network state is
given by the set of messages in-ﬂight, and the corresponding
service guarantees for each message. Second, it limits the
complexity model of concurrency by maintaining the event
queue, and systematically executing each possible event se-
quence. Events may be network events (e.g. delivery of a
message), scheduled events (e.g. expiration of a timer), or
application events (e.g. user request for an action).

Several prior model checker designs [21, 26, 41, 42] have
explored the capabilities of event-driven state machines to
ﬁnd bugs in systems implementations. Each of these de-
signs provide mechanisms to explore complex interactions
between nodes which would normally be infeasible for a
user to exhaustively explore. However, due to the expo-
nential state space explosion as the search depth increases,
these systems settle for heuristically exploring the state
space and locating correctness bugs only in an execution
with benign participants.

Our approach. Finding performance problems is very
challenging in an exhaustive approach because often these
bugs are the result of speciﬁc timings, for which ﬁnding
would require searching on the space of possible timings
of events, a far less practical approach. On the other hand,

simulating performance of a system is straightforward - as
the simulator keeps an ordered list of outstanding events, in-
cluding the time at which they are scheduled to occur. Each
time an event executes, the clock of that node advances, al-
lowing the system to conduct a time-based event driven sim-
ulation. However, it does not systematically explore all the
possible executions.

Our design, Gatling, overcomes these limitations by us-
ing a hybrid approach. Speciﬁcally, Gatling uses a time-
based simulation model to provide support for detecting
performance attacks, and integrates a search algorithm into
the time-based simulation model to ﬁnd in a practical way
such attacks. The resulting architecture is illustrated in
Fig. 1. Gatling constructs a set of nodes, with a fraction
of them ﬂagged as being malicious. Gatling maintains an
event queue sorted by event start time, and simulates the
event queue normally. However, when an event is exe-
cuting on a node selected to be malicious, Gatling uses a
model-checking exploration approach to test the set of dif-
ferent possibilities for what new events are scheduled by
the malicious node; in particular, the set of messages sent
by the malicious node. Note, Gatling does not require the
developer to provide a malicious implementation. Instead,
Gatling requires type-awareness of the messaging protocol,
and applies the basic actions described in the next section
to the outputs of a non-malicious node implementation. To
measure the impact of the malicious action, Gatling exe-
cutes an impact score function, considering only the nodes
not ﬂagged as malicious.

2.2 Malicious Actions

An insider attacker can globally inﬂuence the perfor-
mance of the system by misleading other honest participants
through exchanged messages. We classify all malicious ac-
tions on messages into two categories, message delivery ac-
tions and message lying actions. Message delivery actions
refer to how a message is sent, while message lying actions
refer to what a message contains. The list we present is not
an exhaustive list and can be easily extended by adding ad-
ditional delivery or lying strategies. Below we describe the
speciﬁc malicious actions we consider.

Message delivery actions. Performing message deliv-
ery actions does not require knowledge of the messaging
protocol, because the actions are being applied to where
and when the message is delivered, rather than modifying
the message contents. We deﬁne the following types of ma-
licious message delivery actions.

• Dropping: A malicious node drops a message instead

of sending it to its intended destination.

• Delaying: A malicious node does not immediately

send a message and injects a delay.

 
e
u
e
u
Q

 
t
n
e
v
E

Simulator 

n1 

n

2 

n3 

n4 

Messages generated and 
result of impact score 

Simulator invokes 
event handlers 

Figure 1. Gatling simulator model

• Diverting: A malicious node does not send the mes-
sage to its destination as intended by the protocol, and
instead enqueues the message for delivery to a node
other than the original destination. The destination is
randomly chosen from the set of nodes in the system.

• Duplicating: A malicious node sends a message twice
instead of sending only one copy, applying delay to
the second copy. We consider two versions of message
duplication. One is to send the duplicated message to
the original destination again, and the other is to divert
the duplicated message to another random destination
in the system.

Message lying actions. We deﬁne message lying ac-
tions as actions where malicious participants modify the
content of the message they are sending to another partici-
pant. An effective lying action involves intelligently modi-
fying ﬁelds of messages to contain contents likely to cause
different behaviors, which is more sophisticated than ran-
dom bit-ﬂipping. Gatling makes data-type-speciﬁc changes
to message contents by being dependent on the messaging
protocol. As the number of possible values that the mes-
sage ﬁeld could contain may be extremely large, we deﬁne
a few general strategies for ﬁeld types that stress the system
in different ways based on general experience on the kind
of error cases or hand-crafted attacks observed in practice
previously. We provide the following strategies for numeric
types.

type. Spanning values are important because protocols
sometimes use only a subset of legal values, apply san-
ity checks to inputs, or fail to apply sanity checks when
necessary to avoid e.g. overﬂow/underﬂow. Spanning
values can be chosen assisted by static analysis or de-
veloper insight; we ﬁnd that a range of values orders of
magnitude apart are sufﬁcient to ﬁnd attacks in many
systems.

• Random: A malicious node can select a random value

from the range of the type.

In addition to the above choices, boolean values have an
additional option: toggling the value between true and false.
The list can be easily extended, for example using a “com-
plement” strategy for integral values (a generalization of the
boolean ﬂipping).

Node identiﬁers, such as an IPv4 address or a hash key,
are integral aspects of distributed systems. Thus, we treat
them as a native type and allow lying on them as well. Ma-
licious nodes can lie about node identiﬁers, where lying val-
ues are selected randomly from the identiﬁers of all nodes,
malicious nodes, or benign nodes.

We also have special handling for non-numeric types.
For simplicity, collections (e.g.
list, set, map, etc.) are
treated as applying one of the above strategies to all of the
elements within the collection. Users can further extend
Gatling as needed to provide lying strategies for additional
types, as we have done for node identiﬁers.

• Min or Max: A malicious node can change the value

to be the minimum or maximum value for the type.

2.3 Discovering Attacks

• Zero: For signed types, a malicious node can addition-

ally change the value of the ﬁeld to be the number 0.

• Scaling: A malicious node could increase or decrease

the numeric value by a percentage.

• Spanning: A malicious node can select speciﬁc val-
ues from a set which spans the range of the data

A naive approach to discovering attacks is executing all
possible sequences of actions (malicious and benign) in the
system and then ﬁnding the sequences that cause perfor-
mance to degrade below the benign case scenario. However,
this approach becomes intractable because of the size of the
search space considering the number of possible sequences
of actions. Speciﬁcally, at every time step, any benign event

could execute based on timings, but additionally, any mali-
cious node could generate any message deﬁned by the sys-
tem, performing any combination of malicious actions on
it and send it to any node. Considering all possible attack
values for a message containing a single 32-bit integer en-
tails an exploration branching at the impractical rate of at
least 232. Benign state-space exploration is shielded from
this problem by the fact that while the message ﬁeld could
theoretically contain any of the 232 values, at any point in
time only a small subset of those values would be sent by a
non-malicious node.

Attack properties. As a ﬁrst step toward practical au-
tomated search of attacks, we focus on a class of perfor-
mance attacks that have several properties that reduce the
state space exploration needed to discover them:

1) Single-behavior: We deﬁne a single-behavior attack
as a list which describes, for each type of message, what
malicious or benign action all malicious nodes will take
whenever sending a message of that type. Intuitively, this
attack deﬁnition is based on the principle that in some cases,
past success is an indication of future success. Thus, ev-
ery time a malicious node must decide how to behave when
sending a message, it can choose the same action that suc-
ceeded before, and expect success again. This allows us to
reduce the search space of malicious actions substantially,
because once we have discovered a successful malicious ac-
tion for a message type, we no longer explore other possi-
bilities for the same type of message sent by any malicious
node.

2) Easily reproducible: We assume attacks that are not
largely dependent on the speciﬁc state of the distributed
system and thus can be easily reproduced. Intuitively, the
attacks we discover are those to which the system is gener-
ally vulnerable, rather than having only a small vulnerabil-
ity window. Easily reproducible attacks allow us to safely
ignore the particular sequence of benign actions that occur
alongside the malicious actions and focus our search solely
on malicious actions.

3) Near-immediate measurable effects: We consider at-
tacks that do not have a large time-lag between when they
occur and when the performance of the system is actually
affected. Intuitively, focusing on near-immediate effective
attacks will be ideal for ﬁnding direct attacks on system per-
formance, but it will not allow Gatling to discover stealth
attacks, where the goal is to obtain control without affect-
ing the performance of the system under attack. The near-
immediate impact on the system performance of the attacks
creates the opportunity to ﬁnd attacks by only executing a
smaller sequence of actions for a relatively short window of
time. We decide if a malicious action is a possible attack
by using an impact score Is function that is based on a per-
formance metric of the system and is provided by the user.
We require two properties of the impact score. One, that

it can be evaluated at any time during the execution. Two,
that when comparing scores, a larger score implies that the
performance is worse.

4) Most effective minimal combination: While Gatling
will discover single-behavior attacks that contain basic be-
haviors for many message types, some behaviors will have
only a nominal impact on the performance of the system,
and other behaviors may be quite effective as stand-alone at-
tacks. To allow the developer to discern these cases, Gatling
automatically determines the relative contribution of each
attack action to the overall performance degradation, allow-
ing the developer to further reduce the attack to their mini-
mal portions that have the most signiﬁcant impact.

Gatling builds up an attack by ﬁnding several instances
where applying a malicious action on a message results in
an increase in the impact score, then building up the maxi-
mally effective single-behavior attack across message types.
Once it has found the maximally effective single-behavior
attack, it determines the contribution of each malicious ac-
tion of the attack, and then can be repeated to ﬁnd additional
attacks.

Greedy action selection procedure. To ﬁnd an instance
where a single malicious action results in an increase in the
impact score, we use the procedure depicted in Fig. 2. The
main idea is to execute the program normally until a ma-
licious node attempts to send a message. At this point we
branch the execution and run on each branch the malicious
version of the sending of the message (try all malicious ac-
tions described in Section 2.2) and then continue running
the branch for a window of time tw. By measuring the im-
pact score at the end of each window of execution, we can
determine whether any of the malicious actions degraded
the performance relative to the baseline without a malicious
action. Since we measure the impact of only a single mali-
cious action instance, we consider any increase in the im-
pact score to suggest that the particular malicious action
could be a part of a successful attack. We greedily select
the strongest such malicious action and update a tally for
that message type and malicious action.

Building up the single-behavior attack. The greedy ac-
tion selection procedure ﬁnds the most effective malicious
action for a single instance of sending a message. We report
a malicious action as part of an attack once it has been se-
lected in na different instances for the same message type.
The na threshold allows us to avoid cases in which the im-
pact was a random variation, and provides a balance be-
tween attacks which are more frequently successful but with
a lower impact, and attacks which are less frequently suc-
cessful but with a higher impact.

If we only wished to ﬁnd attacks incorporating a single
message type at a time, we could at this point simply iterate
through the set of message types, and perform the greedy
procedure each time that message type is sent. While suc-

(1) Previous 

execution path 

(2) A malicious node sends a 

message of type m1 

(3) B = m(Ø), 

execute protocol for 

tw seconds 

(4) Find the benign 

baseline 

S = evaluate(Is, B) 

… 

(5) For every malicious 

action ai  

Bi = m(ai ), execute 

protocol for tw seconds,  

(6) Si = evaluate (Is, Bi) 
and update the tally for 

malicious action ai 

Malicious action a

 is 
3

chosen n

a times for 

message type m

2 

Malicious action a

 is 
2

chosen n

a times for 

message type m

1 

Figure 2. Greedy action selection procedure for
one instance of sending message type m1

Figure 3. Greedy procedure applied for several
instances of message types m1 and m2

cessful in ﬁnding single-behavior, single-message attacks,
this approach would not ﬁnd dependent attacks, where the
success of an attack is conditional on a prior malicious ac-
tion choice. Consider for example the case of a malicious
node which lies to increase the number of children it has in
a tree overlay. If the malicious node does not also perform
an action on application data, then this kind of attack would
not be discovered using single-message attacks.

To discover dependent attacks, Gatling simultaneously
searches across all message types, allowing it to ﬁnd com-
bination attacks, where individual malicious actions work
together to build stronger overall attacks. By applying
the greedy action selection procedure to the instances as
they are encountered, rather than iterating through message
types, our algorithm can locate amplifying stealth attacks
without prior knowledge of the order in which malicious
actions must occur. Speciﬁcally, the system is simulated
normally until a malicious node attempts to send a message
of a type for which an attack has not been identiﬁed. The
greedy selection procedure is used to determine the best ac-
tion to take for this instance, and a tally is kept of the times
each malicious action was chosen. The number of times
no malicious action is selected in a row is also tallied, as a
means to halt the search. We show in Fig. 3 the greedy pro-
cedure being applied to several instances for two different
types of messages.

Once the search halts, the contribution of each of the ac-
tions is computed, and if the attack impact is greater than
some ∆, the user is notiﬁed, and the algorithm repeats but
does not search on previously used malicious actions. Com-
puting the action contribution involves running the system
again for an extended period both with and without the de-
termined attack. This allows Gatling to verify that the at-
tack satisﬁes the requirement that its impact is greater than
∆. Gatling then determines the relative contribution of each
component by running additional tests, subtracting out the
least effective contributor until it is no longer an attack.
This computation and sorting procedure is important for

variables:

vector Attack : Learned behaviors for most effective

attack for each message type

map AttackAndContribution : Attack listing relative

contribution of actions

matrix AttackTally : Count, for each message type, the

times the attack is determined most effective

IneﬀectiveTally : The number of times no malicious

action is chosen consecutively
while IneﬀectiveTally < HaltingThreshold do

Continue simulating system until malicious node sends
a message m;
msgType ← typeof (m);
MostEﬀectiveAction ← Attack [msgType ];
if MostEﬀectiveAction = ø then

Find behavior
MostEﬀectiveAction ∈ {ø, A(msgType)}
according to selection procedure (Fig. 2)
if MostEﬀectiveAction 6= ø then

AttackTally [msgType][MostEﬀectiveAction ]++;

IneﬀectiveTally ← 0;
if
AttackTally [msgType][MostEﬀectiveAction ] =
na then

Attack [msgType] ←
MostEﬀectiveAction ;

end

IneﬀectiveTally ++;

else

end

end
execute behavior m(MostEﬀectiveAction );

end
AttackAndContribution , δ =
computeActionContribution(Attack );
if δ > ∆ then

output AttackAndContribution ;
Repeat, ignoring prior Attack actions

end

Algorithm 1: Attack discovery algorithm

three reasons. First, as a greedy approach, it is possible that
Gatling ﬁnds a local maximum, but that the order in which
malicious actions were selected diminished the overall im-
pact (e.g. an attack may later be found which by itself is
more potent than when combined with the earlier attack).
Second, some malicious actions may depend on other ma-
licious actions for success, this search will order them ac-
cordingly. Third, some malicious actions may have only a
minor impact, or a strong enough impact to be used in iso-
lation, this post processing can provide this information. In
fact, we often ﬁnd multiple attacks from a single run of the
Gatling search algorithm. We present our algorithm in de-
tails in Algorithm 1.

Impact score and parameter selection. The user must
specify an impact score. As stated, the impact score must
be able to be executed at any time, rather than only at the
completion of an execution, and must let greater values in-
dicate a greater impact. Consider, for example, an impact
score for a ﬁle download system. Using total download time
as an impact score would satisfy the requirement that big-
ger numbers indicate more impact (slower download times),
but fails the requirement that it can be evaluated at any time
(it can only be evaluated once the ﬁle is downloaded). The
current average goodput of the ﬁle download satisﬁes the
requirement that it can be evaluated at any time, but in the
case of goodput, bigger numbers actually mean less impact.
An alternative might include an inversion of the goodput, or
instead it could simply be a measure of how much of the ﬁle
is left to download.

Gatling requires the setup of two parameters, tw and na.
Larger values of tw increase the search time while smaller
values may not capture the effects of the malicious action
on performance. In the case of na, its setup should take into
account the normal variability of performance in the system
that is evaluated.

3 Implementation

We created a concrete implementation of Gatling for
the Mace [27] toolkit. Mace is publicly available and was
designed for building large-scale, high-performance dis-
tributed systems implementations based on C++. It consists
of a source-to-source compiler, a set of runtime libraries,
as well as a model checker and time-based simulator. The
release also includes several distributed systems implemen-
tations. The Mace compiler enforces the message-event
model and generates implementations of message serial-
ization, both useful for Gatling. Speciﬁcally, the message
event-model allows us to inﬂuence message delivery, while
message serialization allows us to implement message ly-
ing without modifying the target system code, but just by
deﬁning speciﬁc lying actions for different types.

To implement Gatling we made the following changes to

Mace. We added an interposition layer between Mace ser-
vices and the networking services, we modiﬁed the Mace
compiler to include a message serialization code injector,
we added supporting serialization code in the Mace runtime
library, and we modiﬁed the simulator to implement our at-
tack discovery algorithm. The user provides an implemen-
tation of the distributed system in Mace and speciﬁes an
impact score in a simulation driver that allows the system to
run in the simulator. The Mace compiler will generate the
message serialization injected code in the user code.

This modular design allows code reuse and allows
Gatling to focus attacks on modules independently. The
interposition layer implements malicious message delivery
actions. When a node requests sending a message, before
providing the message to the network messaging services,
Gatling consults the attack discovery algorithm to decide
whether to take any message delivery action. Message drop-
ping, delaying, diverting, and duplicating are provided by
either not making the call to the messaging services, queue-
ing the message for sending 0.5 to 2 seconds later, calling
into the messaging services multiple times, or passing a dif-
ferent destination to the messaging services. To support di-
verting messages, the simulator provides lists of malicious
and benign node identiﬁers.

The injected serialization code component implements
malicious message lying actions. The injected code simi-
larly consults the attack discovery algorithm to determine
if a lying action should be taken. As we are searching for
single-behavior attacks, the simulator directs only a single
ﬁeld in a message to be lied about during one branch of the
greedy selection procedure. If any lying does occur, when
serializing the appropriate ﬁeld of the message a simula-
tor chosen value is used instead of the one provided. The
user-written code is not modiﬁed, nor are any user-visible
variables. Simulator-provided lists are similarly used to lie
about node identiﬁers.

Fig. 4 shows the Mace+Gatling architectural design
when testing a layered DHT application. The parts noted
with G represent the Gatling additions and modiﬁcations.
The user provides each DHT component layer in the Mace
language (shown at left): a simulation driver (SimDriver),
containing the impact score function;
the storage layer
(DHT); a recursive overlay routing layer (ROR); and the
Chord lookup service layer. The Mace compiler then trans-
lates each layer into C++ code, injecting message lying ac-
tions into each layer tailored to the messages that layer de-
ﬁnes. Standard C++ tools then compile and link the gen-
erated code with the Gatling interposition layer, Mace run-
time library, simulated TCP and UDP messaging services,
and the Mace simulator application. SimDriver allows the
application to run in the simulator; to deploy the DHT ap-
plication, the C++ code need only be re-linked with the real
TCP and UDP messaging services, and a C++ user applica-

SimDriver 

I 

DHT 

ROR 

Chord 

Mace 
Source-
to-Source 
Compiler 

G 

SimDriver 

DHT 

I 

G 

ROR 

G 

Chord 

G 

G 

SimTCP 

SimUDP 

 
e
m

i
t
n
u
R
 
e
c
a

M

 

y
r
a
r
b
i
L

 
 
 
 
 
 
 
 

G 

 
r
o
t
a
l
u
m
i
S

 
 

G 

I 

G 

G 

G 

G 
G 

Mace Toolkit 

User Supplied Code 

User Supplied Impact Score 

Gatling Interposition Layer 

Gatling Serialization Code Injector 

Gatling Injected Serialization Code 

Gatling Attack Discovery Algorithm 

Gatling Serialization Library Modification 

Figure 4. Gatling implementation for one node: DHT example

tion in lieu of SimDriver.

4 Case Study: BulletPrime

In this section we demonstrate how to use Gatling to ﬁnd
attacks on a real system implementation. For our case study
we apply Gatling to an implementation of the BulletPrime
peer-to-peer ﬁle distribution protocol [28, 31] that we re-
ceived from the authors of the system. We selected Bul-
letPrime as a case study because it uses a more complex
design involving several services. While we illustrate how
a developer might use Gatling to ﬁnd attacks arising from
a malicious or simply misconﬁgured node, our intention is
not to criticize BulletPrime’s design. Instead we explore its
behavior in an adversarial environment that many practical
uses might require.

BulletPrime is a ﬁle distribution system similar to Bit-
Torrent [18]. However, where BitTorrent focuses on lo-
cal optimizations that greedily beneﬁt each node individu-
ally, BulletPrime uses a more collaborative set of algorithms
that are geared towards global optimization. For example,
while both BitTorrent and BulletPrime implement mesh-
based strategies for peering, and use rarity as a mechanism
for increasing block diversity, BulletPrime learns about new
peers by using a gossip protocol that guarantees each node
receives a uniformly random distribution of peers and their
current download status. BulletPrime also searches inde-
pendently for peers that can provide maximal download or
upload bandwidth, as opposed to BitTorrent’s symmetric
block exchange algorithm.

The BulletPrime component design is illustrated in
Fig. 5. The BulletPrime service manages the state of the
ﬁle download, implements sending Diff messages to con-
nected peers with information of newly available blocks of
the ﬁle; and tracks the performance of the peers. It utilizes
the Distributor service to manage the queued Data messages
to each peer, keeping the network buffers full without send-
ing excess data. BulletPrime uses the Mesh service to learn
of new peers and maintain active connection to upload and
download peers. The Mesh service sends Join and JoinRe-

ply messages, and uses the RanSub [30] service to discover
potential peers. RanSub, meanwhile, uses an overlay tree
to perform a specialized type of aggregation, proceeding in
periodic phases that Collect candidate sets of information to
the root, and then Distribute uniformly randomized candi-
date sets to all peers.

To run Gatling on BulletPrime, we ﬁrst had to prepare
it to run in the simulator and implement an impact score.
We wrote an 85 line simulated application driver that pro-
vides the basic functionality of having the source node dis-
tribute data to others and having the client nodes download
and participate in the ﬁle-sharing protocol. We chose for
the impact score a performance metric which captures the
progress of node downloads; namely the number of blocks
of the ﬁle downloaded. To satisfy the requirement that a
higher score indicates more attack impact, we instead use
the total number of blocks remaining before completion.
We had to modify BulletPrime slightly, adding the 8-line
impact score function, because it did not expose enough
information to the simulated driver to compute the score.
We simulated BulletPrime with 100 nodes disseminating a
50MB ﬁle. We use a small 5 sec tw as nodes download
blocks quickly, starting nearly at the beginning of the simu-
lation. Due to some variable system performance, we set na
to 5, allowing Gatling to explore a few instances per mes-
sage type. We set ∆ to be zero for all our experiments to
ﬁnd as many attacks as possible.

Assertions and segmentation faults: As we began to use
Gatling on the BulletPrime implementation, we encoun-
tered nodes crashing due to the fact that BulletPrime as-
sumes peers to act correctly. For example, we found nodes
crashing due to assertions and segmentation faults when re-
ceiving a malicious FileInfo message. This message deﬁnes
the ﬁle and block size and is created by the source.
In-
termediate nodes that forward the message can lie about its
contents when passing it along. We found another crash sce-
nario when a malicious node requests a non-existing block,
causing the recipient to crash by assertion attempting to re-
trieve the block. We implemented checks in the code to
prevent crashing and we disabled any attack on FileInfo for

BulletPrime 

Distributor 

Mesh 

RanSub 

OverlayTree 

TCP 

g
n
i
n
i
a
m
e
R
 
s
k
c
o
l
B

 
f
o

 

#

 3500

 3000

 2500

 2000

 1500

 1000

 500

 0

 0

No Attack
Lie Data
Delay Data
Drop Data
Delay Diff
Dup Join

 50

 100

 150

 200

 250

Simulation Time (s)

g
n
i
n
i
a
m
e
R
 
s
k
c
o
l
B

 
f
o

 

#

 3500

 3000

 2500

 2000

 1500

 1000

 500

 0

 0

No Attack
Delay JoinAccept
Divert JoinReject
Dup Collect
Drop Dist
Drop Dist + Dup Collect

 50

 100

 150

 200

 250

Simulation Time (s)

Figure 5. BulletPrime design

Figure 6. Remaining blocks for the attacks found on BulletPrime

g
n
i
n
i
a
m
e
R
 
s
k
c
o
l
B

 
f
o

 

#

 3500

 3000

 2500

 2000

 1500

 1000

 500

 0

No Attack
Lie Data
Delay Data
Drop Data
Delay Diff
Dup Join

No Attack
Delay JoinAccept
Divert JoinReject
Drop Dist
Dup Collect
Drop Dist + Dup Collect

g
n
i
n
i
a
m
e
R
 
s
k
c
o
l
B

 
f
o

 

#

 3500

 3000

 2500

 2000

 1500

 1000

 500

 0

 0

 20

 40

 60

 80

 100  120

 0

 20

 40

 60

 80

 100  120

Time (s)

Time (s)

Figure 7. Remaining blocks for the attacks found on BulletPrime on PlanetLab

further Gatling simulations.

Fig. 6 shows the performance of the system under the
attacks we discover. To give a baseline comparison, we also
show the benign scenario when there is no attack. We have
found attacks against four of the ﬁve services.

Distributor service: We found several attacks on Data
messages. Lying on the id ﬁeld of a Data message degrades
the performance signiﬁcantly. We also found dropping or
delaying Data causes performance degradation.

BulletPrime service: Furthermore, Gatling found a de-
laying attack on the Diff message which causes a perfor-
mance penalty, since peers cannot request the block until
receiving the Diff message.

Mesh service: Gatling also reported an attack vector that
is a combination of 1) duplicate Join message and divert
the second copy to a random destination, 2) delay JoinAc-
cepted message for 0.5s, and 3) divert JoinRejected mes-
sage to a random destination. Gatling computed the most
effective minimal combination found that all actions are ef-
fective even when they are used alone, however the com-
bination of the three was the most effective. We show the
individual attacks in Fig. 6.

RanSub service: Gatling found an attack which was a
combination of dropping Distribute messages that are dis-
seminated from the root toward the leaves over the control
tree and also duplicating Collect messages that are collected
from leaves towards the root. Gatling found that both ac-

tions alone degrade performance and furthermore dropping
Distribute messages causes nodes to never be able to down-
load a number of blocks.

While some of the attacks found on BulletPrime were ex-
pected, such as delaying or dropping data messages, less ob-
vious was the impact of the attacks on the Mesh and RanSub
services. Although BulletPrime gains nice mathematical
properties by using RanSub, it seems that a BulletPrime im-
plementation robust to insider attacks may be better served
by a gossip service re-design. As an extra beneﬁt, Gatling
also identiﬁed several cases where insiders can crash system
nodes due to a lack of input validity checking.

To validate that the attacks are not a result of lack of
ﬁdelity in the simulator we ran real-world experiments with
the discovered attacks on the PlanetLab testbed, with the
same number of nodes and ﬁle size. We conﬁrmed that all
attacks have a similar effect as in the simulator and we show
graphs in Fig. 7.

5 Results

We further validate the Gatling design by applying it to
ﬁve systems with different application goals and designs.
Speciﬁcally, we evaluate the Vivaldi [19] virtual coordinate
system, the Chord lookup service and distributed hash ta-
ble (DHT) [51], and two multicast systems: ESM [17] and
Scribe [49]. Chord, DHT, and Scribe were previously im-

plemented for Mace; we implemented Vivaldi and ESM ac-
cording to published papers. We set the number of mali-
cious nodes to be 20% and we select malicious nodes ran-
domly.

Gatling found performance attacks in each system tested,
taking from a few minutes to a few hours to ﬁnd each attack.
Gatling was run on a 2GHz Intel Xeon CPU with 16GB of
RAM. Gatling processes are CPU bound, so parallelizing
the search could further reduce the search time. We discov-
ered 41 attacks in total, however due to lack of space we
only present in detail a subset of attacks that illustrate the
capabilities of Gatling. In Table 1, we summarize all the
attacks.

5.1 Vivaldi

System description. Vivaldi [19] is a distributed sys-
tem that provides an accurate and efﬁcient service that al-
lows hosts on the Internet to estimate the latency to arbitrary
hosts without actively monitoring all of the nodes in the net-
work. The system maps these latencies to a set of coordi-
nates based on a distance function. Each node measures the
round trip time (RTT) to a set of neighbor nodes, and then
determines the distance between any two nodes. The main
protocol consists of Probe messages sent by a node to mea-
sure their neighbors RTTs and then a Response message
from these neighbors is sent back with their current coordi-
nates and local error value.

Impact score. We use the prediction error [19]
the system predicts the ac-
which describes how well
tual RTT between nodes. Prediction error is deﬁned as
median(|RT T i,j
Est is node i’s
estimated RTT for node j given by the resulting coordinates
and RT T i,j

Act is the most recently measured RTT.

Est − RT T i,j

Act|), where RT T i,j

Experimental setup. We simulated 400 nodes and ran-
domly assign RTT values for each node from the KING
data set [23] which contains pair-wise RTT measurements
of 1740 nodes on the Internet. Malicious nodes start their
attacks from the beginning of the simulation. We set tw to
be 5 sec and na to be 5.

Attacks found using prediction error. We found ﬁve
attacks using the prediction error impact score. In Fig. 8 we
show how each attack affects Vivaldi prediction error over
time. The Overﬂow attack is omitted because the predic-
tion error was NaN (not a number). As a baseline we also
present Vivaldi when there are no attacks, which we ﬁnd
converges to a stable set of coordinates with 17 ms of error.
Overﬂow. We ﬁrst found two variations of an attack
where malicious nodes lie and report DBL MAX for their
coordinate and their local error, respectively. In both cases
the result is that honest nodes compute their coordinates as
NaN. We implemented safeguards to address the overﬂow.
Inﬂation, oscillation, deﬂation. We then found three pre-

viously reported attacks against Vivaldi [58]. First, known
as inﬂation is a lying attack where malicious nodes lie about
their coordinates, providing larger than normal values from
the spanning set without causing overﬂow. Second, known
as deﬂation attack, occurs when where malicious nodes
drop outgoing probes, thereby never updating their own co-
ordinates. The third, known as the oscillation attack, occurs
where attackers set their coordinates to random values. This
is a very effective attack in which nodes cannot converge
and the prediction error remains high, about 250,000 ms.

5.2 Chord

System description. Chord [51] is an overlay routing
protocol that provides an efﬁcient lookup service. Each
node has an identiﬁer that is based on consistent hashing,
and is responsible for a range of keys that make up that
space. Nodes in Chord construct a ring and maintain a set
of pointers to adjacent nodes, called predecessors and suc-
cessors. When a node i wants to join the ring, it will ask
a node already in the ring to identify the correct predeces-
sor and successor for i.
i then contacts these nodes and
tells them to update their information. Later, a stabilization
procedure will update global information to make sure i is
known by others in the ring.

Impact score. We use an impact score which measures
the progress of forming a correct ring. Since Chord cor-
rectness depends on being able to reach every node by fol-
lowing the successor reference around the ring, we use as
the impact score the average number of nodes each node
can reach by following each node’s successor. For a benign
case, the impact score should be equal to the total number
of nodes.

Experimental setup. We simulate Chord with 100
nodes. Malicious actions start immediately as the goal of
Chord is to construct a properly functioning ring and thus
we want to ﬁnd attacks on that construction process. We set
tw to be 2 sec as ring construction takes only 10 sec in the
benign case and set na to 5.

Attacks found using number of reachable nodes. We
found six attacks against the Chord protocol. In Fig. 9 we
show the effects of the attacks and illustrate the resulting
ring for one attack. As a baseline we verify that when there
is no attack all 100 nodes are able to form a ring in less than
10 sec.

Dropping attacks. We found three attacks where ma-
licious nodes drop responses or do not forward replies to
requests for predecessor and successor information. The
attacks prevent a correct ring from forming. We show in
Fig. 9(a) (Drop Find Pred, Drop Get Pred, and Drop Get
Pred Reply) that when malicious nodes drop predecessor
related messages, less than half the nodes are reachable.

Lying attacks. We found three lying attacks that prevent a

System

Metric
Used

BulletPrime

Number of

Blocks Remaining

Vivaldi

Prediction Error

Attack
Name

Lie Data

Delay Data
Drop Data
Delay Diff
Dup Join

Delay JoinAccept
Divert JoinReply

Drop Dist
Dup Collect

Overﬂow
Inﬂation

Oscillation

Delay

Deﬂation

Drop Find Pred
Drop Get Pred

Attack
Description
Lie data message distribution
Delay data message distribution
Drop data message distribution
Delay diff information
Duplicate join message and send copy to another
Delay join accepted
Send join rejected to another node
Drop information distributed
Dup information collected
Lie about coordinates, setting them to maximum value
Lie about coordinates, setting them to large values
Lie about coordinates, setting them to random values
Delay probe reply messages 2s
Do not initiate request (Drop probes)
Drop query to ﬁnd predecessor
Drop query to get predecessor and successor

Number of

Drop Get Pred Reply Drop the answer to ﬁnd predecssor

Lie Find Pred
Lie Predecessor
Lie Successor

Drop Msg
Delay Msg
Dup Msg

Lie Msg Src
Lie Msg Dest

Lie SetKeyRange

Lie Reply Key
Lie Reply Found

Lie Reply Get

Drop Data
Dup Parent
Lie Latency

Lie Bandwidth

Drop Parent
Drop Data
Drop Join
Dup Join
Dup Data

Drop HB

Lie GroupId HB
Lie GroupId Join

Lie about key that is in query while forwarding queries
Lie about predecessor in response while forwarding
Lie about successor candidates in response while for-
warding
Drop recursive route messages
Delay recursive route messages
Delay recursive route messages and divert second mes-
sage
Lie about the source of recursive route messages
Lie about the destination of recursive route messages
Lie about what keys are stored
Lie about the key in get reply messages
Lie about ﬁnding the value in get reply messages
Lie about the request wanting the value in get reply
messages
Drop data messages
Duplicate parent reply messages, drop data
Lie about measured latency, duplicate probe messages,
drop data
Lie about received bandwidth, duplicate probe mes-
sages, drop data
Drop parent reply messages
Drop data messages
Drop join messages
Duplicate join messages
Duplicate data messages, sending second message to
random node
Drop heartbeat message
Lie about the group identiﬁer in a heartbeat message
Lie about the group identiﬁer in a join message

Chord

Reachable Nodes

DHT

Lookup Latency

ESM

Throughput

Latency

Scribe

Throughput

Known
Attack

[58]
[58]
[58]
[58]
[45]
[45]
[14]
[14]
[14]
[14]

[14]

[14]

[14]
[14]

[14]
[14]
[14]

[53]

[53]

[53]

Table 1. Attacks found using Gatling: 41 attacks in total (17 lie, 12 drop, 6 delay, 5 duplicate, 1 divert)

No Attack
Inflation
Oscillation
Delay
Deflation

)
s

m

 

(
 
r
o
r
r
E
n
o
i
t
c
i
d
e
r
P

1014
1012
1010
108
106
104
102
 25
 15
 5

 0

 300

 600

 900  1200  1500  1800

Simulation Time (s)

No Attack
Drop Find Pred
Drop Get Pred
Drop Get Pred Reply
Lie Find Pred
Lie Predecessor
Lie Successor

e
l
b
a
h
c
a
e
R
 
s
e
d
o
N
 
#

 200

 150

 100

 50

 0

 0

 10

 20

 30

 40

 50

 60

Simulation Time (s)

Figure 8. Prediction error for
the attacks found on Vivaldi

(a) No.
found on Chord

of reachable nodes for the attacks

(b) Chord ring under Lie Predeces-
sor attack

Figure 9. Attack impact on Chord

correct ring from forming. The join protocol ﬁrst locates the
predecessor of a given address i by forwarding a FindPred
message through the Chord overlay. If a malicious node
modiﬁes the address i in the message, it effectively redi-
rects the node joining to an incorrect place in the ring, and
can cause inconsistent state in the nodes, which can lead to
a failure to properly join (Lie Find Pred). We found similar
attacks when a malicious node, during stabilization, queried
as to who are its predecessors and successors, lies and gives
incorrect information (Lie Predecessor, Lie Successor). We
show impact scores of these attacks in Fig. 9(a). The ef-
fect of Lie Predecessor on the ring can be seen visually in
Fig. 9(b), where some nodes failed to join, and others are
confused about their relationships to adjacent nodes.

5.3 Distributed Hash Table

System description. A Distributed Hash Table (DHT)
provides a scalable key-value storage service, where nodes
self-organize so that each node is responsible for storage
of a portion of the key-space. DHTs expose at least two
operations to the user, a put operation that stores a value
based on its key in the overlay and a get operation that re-
trieves key-values that are previously stored. The DHT im-
plementation used is a basic one based on the outline in the
Chord paper [51], structured as the example described in
Figure 4. When an application node requests an operation
(get or put), the storage layer routes the operation to the
responsible node using the recursive routing layer. The re-
cursive overlay routing layer forwards any message to the
destination by forwarding it hop-by-hop along the Chord
overlay links. The DHT also responds to changes in the
responsible address space by sending a SetKeyRange mes-
sage to the new owner to notify it of the keys it should now
manage.

a node issuing a get request on a key and when it actually re-
ceives the corresponding value. Formally, the impact score
is the average time spent on lookups that either completed
in the last tw or elapsed time of pending lookups.

Experimental setup. We simulated 100 nodes and each
one randomly generates 100 key-value pairs which it puts
around the DHT, thus we expect that each node stores one
of its values on every node. Each node then tries to retrieve
2 values every second, and tries to retrieve the whole set of
values 10 times. A request is timed-out if no response is re-
ceived before the next retrieval attempt. Most experiments
allow Chord 10 sec to form the overlay before beginning
to put data. It then uses 50 sec to put data, putting only 2
values every second, before beginning to lookup data. The
remaining lookups take 500 sec. We set tw to be 70 sec,
which allows Gatling to ﬁnd attacks during the Chord setup
and DHT put phase; na was set to 5.

Attacks found using lookup latency. We show lookup
latency over time for each attack in Fig. 10. As a baseline
we show DHT with no attack and ﬁnd it converges to 215
ms. We found a total of seven attacks (and several variants)
against DHT and rediscovered some attacks against Chord.

Recursive Overlay Routing Attacks. We ﬁrst run Gatling
on the recursive message routing layer that routes all DHT
messages. We begin malicious actions after 10 sec, after
the Chord ring converges. We found two attacks where de-
laying or dropping messages causes an increase in lookup
latency (Drop Msg, Delay Msg). We also found a third at-
tack where duplicating the message and diverting the sec-
ond copy to a random node causes network ﬂooding and
congestion due to malicious nodes repeatedly replicating
the same messages (Dup Msg). Finally, we found an at-
tack where in forwarding messages, an attacker provides a
false destination key for the message, causing the next hop
of the message to forward it incorrectly (Lie Msg Dest).

Impact score. For an impact score we use lookup la-
tency, which measures the amount of time passed between

Storage Attacks. We found two lying attacks. The ﬁrst
one, Lie Reply Key occurs when a node responds to a DHT

get request and it lies about the key it is responding about.
The second one, Lie Set Key Range occurs during the setup
phase of the DHT, considering a scenario where nodes start
putting data into the DHT at the beginning of the simula-
tion, before the Chord ring can stabilize. We found that at-
tackers can subvert the process of load-balancing and cause
many key-value pairs to go missing. This occurred when
an attacker notiﬁed another node of what key-value pairs it
had. The attacker lied about what keys it was responsible
for, then when another node takes over a part of that key-
range, he will not know the real values that it should store,
thus losing them.

5.4 ESM

System description. ESM [17] is a multicast system that
efﬁciently disseminates video streaming data broadcast by
a single source. ESM accomplishes this by building up a
tree, rooted at the source, where each child node forwards
on the data to its own children. Each node maintains a set
of neighbors periodically reporting their throughput and la-
tency. With this information, a node can change parents to
maintain desired performance.

Impact score. We use two scores [17]: throughput and
latency. Throughput as described in [17], is the amount of
data received over the last 5 sec, so the impact score is the
streaming rate minus the throughput, to satisfy requirements
that larger means more impact. Latency is the amount of
time it takes for data to reach each node after being initially
sent by the source, and the impact score is the average la-
tency of data in the last tw.

Experimental setup. We simulated ESM with 100
nodes and one source streaming data at 1 Mbps. As the
goal of ESM is both to form an efﬁcient tree and to stream
data to all participants, we use two different settings for the
time (i.e., 0 sec and 10 sec) when attackers start their ma-
licious actions. Thus we can ﬁnd attacks both against tree
formation and data delivery. We use a tw of 5 sec and na of
5.

Attacks found using throughput. We found four at-
tacks using throughput as an impact score. Fig. 11(a) shows
the results of how each attack affects ESM where we plot
the throughput over time. For a baseline we also have ESM
in the benign case when there is no attack, delivering aver-
age throughput near 900 kbps.

Drop Data. First we delay malicious actions until 10 sec
into the execution, to allow ESM to build a tree ﬁrst, and test
the steady state. Despite ESM using an adaptation mecha-
nism to switch to parents that give them good performance,
dropping data was an effective attack.

Dup Parent. We then examined attacks that targeted the
tree formation and adaptation process. We increased the
window size tw to 10 sec, and had attackers immediately

start trying malicious actions once the simulation started.
Gatling again added dropping data as an attack action, then
proceeded to amplify that attack with another malicious
action—duplicating messages that tell a node they are ac-
cepted as a child, sending the duplicate message to a random
node. With this ampliﬁcation, the throughput is usually be-
low 200 kbps.

Attraction attacks. In these attacks malicious nodes am-
plify dropping streaming data by lying about their perfor-
mance metrics, making them look better than what they ac-
tually are. This causes benign nodes to continually ask ma-
licious nodes to be their parents. The ﬁrst attraction attack
found is where nodes lie about their latency (Lie Latency),
setting it to zero. This causes nodes to think the attacker
is close to the source. The second attraction attack is when
malicious nodes lie about their bandwidth using scaling (Lie
Bandwidth), increasing it to appear they are receiving much
of the streaming data. To further amplify the attack the at-
tackers also duplicate probe messages, diverting the second
message to random nodes, causing the attackers to be more
well-known in the overlay, thus more likely to be asked to
be a parent. These two attacks are very effective, causing all
nodes to have a very low throughput of less than 100 kbps
when lying about latency and 300 kbps when lying about
bandwidth.

Attacks found using latency. We found one attack us-
ing latency as an impact score function. We compare in
Fig. 11(b) the latency when there is no attack with the at-
tack we found.

Drop Parent. We found an attack where malicious nodes
drop replies to parent request messages. This results in in-
creased latency due to malicious nodes gaining spots high
up in the tree over time by simply following the adaptation
protocol, and then never allowing the tree to grow beyond
them. Furthermore, as benign nodes never get a response,
the protocol dictates that they wait 1 sec to send another par-
ent request to a different node, further slowing down their
attempt to ﬁnd or change parents.

5.5 Scribe

System description. Scribe [49] is an application-level
multicast system that organizes each group into an overlay
tree to efﬁciently disseminate data. To send data, a node
sends the message toward the root, and each node forwards
it to its parent and children. Scribe is built on top of Pas-
try [48], an overlay routing protocol with similar function-
ality to Chord. Scribe trees are built based on reverse-path
forwarding combined with load balancing:
the multicast
tree is the reverse of the routes Join messages take when
routed from tree participants to the Pastry node managing
the group identiﬁer, except that nodes whose out-degree is
too high will push children down in the tree.

No Attack
Drop Msg
Delay Msg
Dup Msg
Lie Msg Dest
Lie Msg Src
Lie SetKeyRange
Lie Reply Key

)
s

m

(
 

y
c
n
e
t
a
L
p
u
k
o
o
L

 

 25000

 20000

 15000

 10000

 5000

 0

)
s
p
b
k
(
 
t
u
p
h
g
u
o
r
h
T

 1400

 1200

 1000

 800

 600

 400

 200

 0

No Attack
Drop Data
Dup Parent
Lie Latency
Lie Bandwidth

)
s

m

(
 

y
c
n
e
t
a
L

 12000

 10000

 8000

 6000

 4000

 2000

 0

No Attack
Drop Parent

 0

 100

 200

 300

 400

 500

 0  100  200  300  400  500  600  700  800

 0  100  200  300  400  500  600  700  800

Simulation Time (s)

Simulation Time (s)

Simulation Time (s)

(a) Throughput impact score

(b) Latency impact score

Figure 10. Lookup latency for
the attacks found on DHT

Figure 11. Throughtput and latency for the attacks found on ESM

No Attack
Drop Data
Drop Join
Dup Join
Dup Data
Lie GroupId HB
Lie GroupId Join

)
s
p
b
k
(
 
t
u
p
h
g
u
o
r
h
T

 1600

 1400

 1200

 1000

 800

 600

 400

 200

 0

 0

 100

 200

 300

 400

 500

 600

Simulation Time (s)

(a) Throughput for the attacks found on Scribe

(b) Scribe tree under Lie GroupId Join attack

Figure 12. Attack impact on Scribe

Impact score. We use throughput, which measures the
average amount of data received over time. As with ESM,
the impact score is the streaming rate minus the average
throughput over the last tw seconds.

Experimental setup. We simulated Scribe with 50
nodes and test it under the scenario where a source node cre-
ates a group, publishes streaming data at a rate of 1 Mbps,
and all other nodes subscribe to that group. We start ma-
licious actions immediately after the experiment starts so
we can attack tree construction, however as we ﬁnd the tree
takes up to 30 sec to form in our test environment, we set
tw to be 35 sec. We also ﬁnd malicious actions have a high
probability of being effective the ﬁrst time tried and thus set
na to be 1.

Attacks found using throughput. We found seven at-
tacks using throughput as an impact score. Fig. 12(a) shows
the effects of the different attacks. As a baseline we run
the system with no attack and ﬁnd that nodes are able to
consistently receive 1 Mbps of data.

Drop Data and Dup Data. First we found two obvious
attacks where nodes do not forward the data or they du-
plicate data messages and send the second message to a
random node. In the latter case, loops can occur, causing
signiﬁcant system load as data is increasingly replicated,
resulting in throughput to decrease below 200 kbps.

Dup Join, Lie GroupID Join, Drop Join. We found
that when malicious nodes duplicate Join messages and di-
vert the second message to a random node this causes the
throughput to drop below 200 kbps. This drop is due to
temporary forwarding loops when a tree node is a child of
multiple parent nodes. This temporary error will be cor-
rected by a heartbeat protocol, but only after a period of
time in which forwarding loops can cause damage. Gatling
found two additional attacks that cause the tree to not be
formed properly.
If malicious nodes lie about the group
identiﬁer in the Join message, then effectively the malicious
nodes are joining a different group, while believing they are
joining the requested group. Malicious nodes still respond
normally to other nodes’ requests to join the correct group.
This lie led the system to a situation that all malicious nodes
fail to join, and some benign nodes build a tree under ma-
licious nodes as seen in Fig. 12(b). Since the tree is split,
only nodes in the tree that have the source node inside can
receive data and nodes in other tree(s) can not receive any
data. Gatling also ﬁnds an attack of dropping Join mes-
sages, causing the same effect, but in the explored simula-
tion, more benign nodes happened to be a part of the tree
with the source, allowing better throughput.

6 Related Work

Automated debugging techniques, such as model check-
ing, have been in use for many years. Most similar to our
work is CrystalBall [56], where Yabandeh et al. utilize state
exploration to predict safety violations and steer the execu-
tion path away from them and into safe states in the de-
ployed system. Nodes predict consequences of their actions
by executing a limited state exploration on a recently taken
snapshot, which they take continuously. Since a violation
is predicted beforehand, it is possible to avoid actions that
will cause the violation. The Mace model checker is uti-
lized for safety properties and state exploration. However,
they do not consider performance metrics and thus can only
ﬁnd bugs or vulnerabilities that cause safety violations but
not performance degradation.

Many previous works have also used debugging tech-
niques for the purpose of automating the process of dis-
covering or preventing attacks. Proving the absence of
particular attacks have also been explored in the context
of limited models and environments [9, 10, 12]. These
debugging techniques include static and dynamic analy-
sis [16, 22, 32, 37, 43, 54], modelchecking [9, 10, 12], and
fault injection [8, 11, 50]. Below we summarize the works
that are focused on discovering attacks and are most similar
to our own.

Finding vulnerabilities in distributed systems has re-
cently been explored by Banabic et al. [11]. They employ
a fault injection technique on PBFT [15] to ﬁnd combina-
tions of MAC corruptions that cause nodes to crash. Our
work is more general, as Gatling does not focus on ﬁnding
all possible inputs that cause a single kind of vulnerability,
but rather searches on basic malicious actions to ﬁnd new
attacks.

Stanojevic et al. [50] develop a fault injection tech-
nique for automatically searching for gullibility in proto-
cols. They experiment on the two-party protocol ECN to
ﬁnd attacks that cause a malicious receiver to speed up and
slow down the sending of data. Their technique uses a brute
force search and considers lying about the ﬁelds in the head-
ers of packets and also drops packets. As they also utilize
Mace they are able to conduct protocol dependent attacks.
Our work differs in that we focus on large-scale distributed
systems, incorporate a fault injector that includes more di-
verse message delivery and lying actions, and use a greedy
approach to avoid brute forcing.

Kothari et al. [32] explore how to automatically ﬁnd
lying attacks that manipulate control ﬂow in implementa-
tions of protocols written in C. Their technique focuses on
searching for a sequence of values that causes a particular
statement in the code to be executed many times, thus po-
tentially causing an attack. Their method ﬁrst utilizes static
analysis of the code to reduce the search space of possi-

ble attack actions and then uses concrete execution to verify
the attack. However, to utilize the technique the user must
know ahead of time what parts of the code, if executed many
times, would cause an attack, which may not always be ob-
vious. Gatling, on the other hand, utilizes an impact score
to direct its search. Furthermore, some distributed systems,
such as Vivaldi, do not have attacks on them that manipulate
control ﬂow, but only attacks that involve lying about state.
Such attacks would go undiscovered by this technique.

7 Conclusion

Securing distributed systems against performance at-
tacks has previously been a manual process of ﬁnding at-
tacks and then patching or redesigning the system. In a ﬁrst
step towards automating this process, we presented Gatling,
a framework for automatically discovering performance at-
tacks in distributed systems. Gatling uses a model-checking
exploration approach on malicious actions to ﬁnd behaviors
that result in degraded performance. We provide a concrete
implementation of Gatling for the Mace toolkit. Once the
system is implemented in Mace the user needs to specify an
impact score in a simulation driver that allows the system to
run in the simulator.

To show the generality and effectiveness of Gatling, we
have applied it to six distributed systems that have a diverse
set of system goals. We were able to discover 41 attacks
in total, and for each system we were able to automatically
discover attacks that either stopped the system from achiev-
ing its goals or slowed down progress signiﬁcantly. While
some of the attacks have been previously found manually
through the cleverness of developers and researchers, we
show that the amount of time Gatling needs to ﬁnd such
attacks is small. Therefore, we conclude that Gatling can
help speed up the process of developing secure distributed
systems.

References

[1] Cyber-DEfense Technology Experimental Research labora-

tory Testbed. http://www.isi.edu/deter/.

[2] Emulab - Network Emulation. http://www.emulab.net/.
[3] Georgia

Simulator.
http://www.ece.gatech.edu/research/labs/MANIACS/GTNet
S/.

Network

Tech

[4] Global

Environment

for

Network

Innovation.

http://www.geni.net.

[5] Network Simulator 3. http://www.nsnam.org/.
peer-to-peer
[6] p2psim:

A simulator

for
http://pdos.csail.mit.edu/p2psim/.

protocols.

[7] Resilient Overlay Networks. http://nms.csail.mit.edu/ron/.
[8] J. Antunes, N. Neves, M. Correia, P. Verissimo, and
R. Neves. Vulnerability Discovery with Attack Injection.
IEEE Transactions on Software Engineering, 36:357–370,
2010.

[9] A. Armando, D. Basin, Y. Boichut, Y. Chevalier, L. Com-
pagna, J. Cuellar, P. H. Drielsma, P. Hem, O. Kouchnarenko,
J. Mantovani, S. Mdersheim, D. von Oheimb, M. Rusinow-
itch, J. Santiago, M. Turuani, L. Vigan, and L. Vigneron.
The AVISPA Tool for the Automated Validation of Inter-
net Security Protocols and Applications. In Proceedings of
Computer Aided Veriﬁcation, 2005.

[10] A. Armando and L. Compagna. SAT-based model-checking
for security protocols analysis. International Journal of In-
formation Security, 7:3–32, January 2008.

[11] R. Banabic, G. Candea, and R. Guerraoui. Automated Vul-
nerability Discovery in Distributed Systems. In Proceedings
of HotDep, 2011.

[12] B. Blanchet. From Secrecy to Authenticity in Security Pro-
tocols. In Proceedings of International Static Analysis Sym-
posium. Springer, 2002.

[13] C. Cadar, D. Dunbar, and D. Engler. KLEE: Unassisted
and automatic generation of high-coverage tests for complex
systems programs. In Proceedings of OSDI, 2008.

[14] M. Castro, P. Drushel, A. Ganesh, A. Rowstron, and D. Wal-
lach. Secure routing for structured peer-to-peer overlay net-
works. In Proceedings of OSDI, 2002.

[15] M. Castro and B. Liskov. Practical Byzantine fault tolerance.

In Proceedings of OSDI, 1999.

[16] C. Y. Cho, D. Babi, P. Poosankam, K. Z. Chen, E. X. Wu,
and D. Song. MACE: Model-inference-assisted concolic ex-
ploration for protocol and vulnerability discovery. In Pro-
ceedings of USENIX Security, 2011.

[17] Y.-H. Chu, A. Ganjam, T. S. E. Ng, S. Rao, K. Sripanid-
kulchai, J. Zhan, and H. Zhang. Early Experience with an
Internet Broadcast System Based on Overlay Multicast. In
Proceedings of USENIX ATC, 2004.

[18] B. Cohen. Incentives build robustness in BitTorrent. In Pro-

ceedings of P2P Economics, 2003.

[19] F. Dabek, R. Cox, F. Kaashoek, and R. Morris. Vivaldi: a
decentralized network coordinate system. In Proceedings of
SIGCOMM, 2004.

[20] D. Geels, G. Altekar, P. Maniatis, T. Roscoe, and I. Stoica.
Friday: global comprehension for distributed replay. In Pro-
ceedings of NSDI, 2007.

[21] P. Godefroid. Model checking for programming languages

using Verisoft. In Proceedings of POPL, 1997.

[22] P. Godefroid, M. Y. Levin, and D. Molnar. Automated

Whitebox Fuzz Testing. In Proceedings of NDSS, 2008.

[23] K. P. Gummadi, S. Saroiu, and S. D. Gribble. King: Esti-
In

mating Latency between Arbitrary Internet End Hosts.
Proceedings of ACM SIGCOMM-IMW, 2002.

[24] H. S. Gunawi, T. Do, P. Joshi, P. Alvaro, J. M. Hellerstein,
A. C. Arpaci-Dusseau, R. H. Arpaci-Dusseau, K. Sen, and
D. Borthakur. FATE and DESTINI: a framework for cloud
recovery testing. In Proceedings of NSDI, 2011.

[25] G. J. Holzmann. The Model Checker SPIN. IEEE Transac-

tions on Software Engineering, 23:279–295, May 1997.

[26] C. Killian, J. W. Anderson, R. Jhala, and A. Vahdat. Life,
Death, and the Critical Transition: Detecting Liveness Bugs
in Systems Code. In Proceedings of NSDI, 2007.

[27] C. E. Killian, J. W. Anderson, R. Braud, R. Jhala, and A. M.
language support for building distributed

Vahdat. Mace:
systems. In Proceedings of PLDI, 2007.

[28] D. Kosti´c, R. Braud, C. Killian, E. Vandekieft, J. W. Ander-
son, A. C. Snoeren, and A. Vahdat. Maintaining high band-
width under dynamic network conditions. In Proceedings of
USENIX ATC, 2005.

[29] D. Kostic, A. Rodriguez, J. Albrecht, , and A. Vahdat. Bul-
let: High Bandwidth Data Dissemination Using an Overlay
Mesh. In Proceedings of SOSP, 2003.

[30] D. Kostic, A. Rodriguez, J. Albrecht, A. Bhirud, and A. Vah-
dat. Using random subsets to build scalable network ser-
vices. In Proceedings of USENIX-USITS, 2003.

[31] D. Kosti´c, A. C. Snoeren, A. Vahdat, R. Braud, C. Killian,
J. W. Anderson, J. Albrecht, A. Rodriguez, and E. Van-
dekieft. High-bandwidth data dissemination for large-scale
distributed systems. ACM Transactions on Computer Sys-
tems, 26(1):1–61, 2008.

[32] N. Kothari, R. Mahajan, T. Millstein, R. Govindan, and
M. Musuvathi. Finding Protocol Manipulation Attacks. In
Proceedings of SIGCOMM, 2011.

[33] M. Krohn, E. Kohler, and M. F. Kaashoek. Events can make

sense. In Proceedings of USENIX ATC, 2007.

[34] L. Lamport.

Specifying Systems: The TLA+ Language
and Tools for Hardware and Software Engineers. Addison-
Wesley Longman Publishing Co., Inc., Boston, MA, USA,
2002.

[35] L. Leonini, E. Rivi`ere, and P. Felber. SPLAY: distributed
systems evaluation made simple (or how to turn ideas into
live systems in a breeze). In Proceedings of NSDI, 2009.

[36] S. Lin, A. Pan, Z. Zhang, R. Guo, and Z. Guo. WiDS: an
Integrated Toolkit for Distributed Systems Deveopment. In
Proceedigs of HotOS, 2005.

[37] Z. Lin, X. Zhang, and D. Xu. Convicting exploitable soft-
ware vulnerabilities: An efﬁcient input provenance based
approach. In Proceedings of DSN, 2008.

[38] B. T. Loo, T. Condie, J. M. Hellerstein, P. Maniatis,
T. Roscoe, and I. Stoica. Implementing Declarative Over-
lays. In Proceedings of SOSP, Brighton, United Kingdom,
October 2005.

[39] X. Lui, W. Lin, A. Pan, and Z. Zhang. WiDS Checker:
In Proceedings

Combating Bugs In Distributed Systems.
of NSDI, Cambridge, Massachusetts, April 2007.

[40] N. Lynch. Distributed Algorithms. Morgan Kaufmann,

1996.

[41] M. Musuvathi, D. Park, A. Chou, D. Engler, and D. Dill.
CMC: A pragmatic approach to model checking real code.
In Proceedings of OSDI, 2002.

[42] M. Musuvathi, S. Qadeer, T. Ball, G. Basler, P. A. Nainar,
and I. Neamtiu. Finding and Reproducing Heisenbugs in
Concurrent Programs. In Proceedings of OSDI, 2008.

[43] J. Newsome and D. Song. Dynamic Taint Analysis for Auto-
matic Detection, Analysis, and Signature Generation of Ex-
ploits on Commodity Software.
In Proceedings of NDSS,
2005.

[44] PlanetLab. http://www.planetlab.org.
[45] S. Ratnasamy, P. Francis, M. Handley, R. Karp, and
S. Shenker. A scalable content-addressable network. In Pro-
ceedings of SIGCOMM. ACM, 2001.

[46] S. Rhea, D. Geels, T. Roscoe, and J. Kubiatowicz. Handling

churn in a DHT. In Proceedings of USENIX ATC, 2004.

[47] A. Rodriguez, D. Kosti´c, Dejan, and A. Vahdat. Scalability
in Adaptive Multi-Metric Overlays. In Proceedings of IEEE
ICDCS, 2004.

[48] A. Rowstron and P. Druschel. Pastry: Scalable, Decentral-
ized Object Location, and Routing for Large-Scale Peer-to-
Peer Systems.
In Proceedings of IFIP/ACM Middleware,
2001.

[49] A. Rowstron, A.-M. Kermarrec, M. Castro, and P. Druschel.
SCRIBE: The design of a large-scale event notiﬁcation in-
frastructure. In Proceedings of NGC, 2001.

[50] M. Stanojevic, R. Mahajan, T. Millstein, and M. Musuvathi.
Can You Fool Me? Towards Automatically Checking Proto-
col Gullibility. In Proceedings of HotNets, 2008.

[51] I. Stoica, R. Morris, D. Karger, M. F. Kaashoek, and H. Bal-
akrishnan. Chord: A Scalable Peer-to-Peer Lookup Service
for Internet Applications.
In Proceedings of SIGCOMM,
2001.

[52] A. Vahdat, K. Yocum, K. Walsh, P. Mahadevan, D. Kosti´c,
J. Chase, and D. Becker. Scalability and accuracy in a large-
scale network emulator. In Proceedings of OSDI, 2002.

[53] A. Walters, D. Zage, and C. Nita-Rotaru. A Framework
for Mitigating Attacks Against Measurement-Based Adap-
tation Mechanisms in Unstructured Multicast Overlay Net-
works. IEEE/ACM Transactions on Networking, 16:1434–
1446, 2008.

[54] W. Wang, Y. Lei, D. Liu, D. Kung, C. Csallner, D. Zhang,
R. Kacker, and R. Kuhn. A Combinatorial Approach to De-
tecting Buffer Overﬂow Vulnerabilities. In Proceedings of
DSN, 2011.

[55] M. Welsh, D. E. Culler, and E. A. Brewer. SEDA: An Ar-
chitecture For Well-conditioned, Scalable Internet Services.
In Proceedings of SOSP, 2001.

[56] M. Yabandeh, N. Knezevic, D. Kostic, and V. Kuncak. Crys-
talBall: Predicting and Preventing Inconsistencies in De-
ployed Distributed Systems. In Proceedings of NSDI, 2009.
[57] J. Yang, T. Chen, M. Wu, Z. Xu, X. Liu, H. Lin, M. Yang,
F. Long, L. Zhang, and L. Zhou. MODIST: transparent
model checking of unmodiﬁed distributed systems. In Pro-
ceedings of NSDI, 2009.

[58] D. J. Zage and C. Nita-Rotaru. On the accuracy of decen-
tralized virtual coordinate systems in adversarial networks.
In Proceedings of CCS, 2007.

