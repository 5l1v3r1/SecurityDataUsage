2013 IEEE Symposium on Security and Privacy

PRIVEXEC: Private Execution as an Operating System Service

Kaan Onarlioglu, Collin Mulliner, William Robertson and Engin Kirda

College of Computer and Information Science

Northeastern University

Boston, MA, USA

{onarliog,crm,wkr,ek}@ccs.neu.edu

normal execution, browsers store a large amount of personal
information that could potentially be damaging were it to be
disclosed, such as the browsing history, bookmarks, cache,
cookie store, or local storage contents. In recognition of the
fact that users might not want to leave traces of particularly
sensitive browsing sessions, browsers now typically offer a
“private browsing mode” that attempts to prevent persistent
modiﬁcations to storage that could provide some indication
of the user’s activities during such a session. In this mode,
sensitive user data that would normally be persisted to disk is
instead only stored temporarily, if at all, and when a private
browsing session ends, this data is discarded.

Abstract—Privacy has become an issue of paramount im-
portance for many users. As a result, encryption tools such as
TrueCrypt, OS-based full-disk encryption such as FileVault,
and privacy modes in all modern browsers have become
popular. However, although such tools are useful, they are not
perfect. For example, prior work has shown that browsers
still leave many traces of user information on disk even if
they are started in private browsing mode. In addition, disk
encryption alone is not sufﬁcient, as key disclosure through
coercion remains possible. Clearly,
it would be useful and
highly desirable to have OS-level support that provides strong
privacy guarantees for any application – not only browsers.

In this paper, we present the design and implementation
of PRIVEXEC, the ﬁrst operating system service for private
execution. PRIVEXEC provides strong, general guarantees of
private execution, allowing any application to execute in a mode
where storage writes, either to the ﬁlesystem or to swap, will not
be recoverable by others during or after execution. PRIVEXEC
does not require explicit application support, recompilation, or
any other preconditions. We have implemented a prototype of
PRIVEXEC by extending the Linux kernel that is performant,
practical, and that secures sensitive data against disclosure.

Keywords-privacy; operating systems;

I. INTRODUCTION

in many cases, users do not necessarily want

Privacy has become an issue of paramount importance for
for many users. The increasing signiﬁcance of computers
in our daily lives, whether to work,
to entertain, or to
communicate, has resulted in the present situation where our
computers store immense amounts of personal information.
Since,
to
share this information with others (e.g., political afﬁliation
with a superior, or records of communication with the
press) a number of approaches exist toward restricting the
disclosure of personal information to the wrong parties. For
the network, privacy-related goals can include data conﬁ-
dentiality through encryption, or disassociation of endpoints
engaged in communication. Network-based approaches can
range from using simple steps such as social networks that
allow for ﬁne-grained control of information disclosure,
to anonymizing virtual private networks, to onion routing
systems like Tor.

On the client, approaches to preserving user privacy often
involve preventing sensitive data from being exposed in
the clear on persistent storage. Web browsers serve as a
canonical example of such an approach. As part of their

1081-6011/13 $26.00 © 2013 IEEE
DOI 10.1109/SP.2013.24

206

Private browsing mode has come to be a widely-used
feature of major browsers. However,
its implementation
as an application-speciﬁc feature has signiﬁcant disadvan-
tages that are important to recognize. First, implementing a
privacy-preserving execution mode is extremely difﬁcult to
get right. For instance, prior work by Aggarwal et al. [12]
has demonstrated that all of the major browsers leave traces
of sensitive user data on disk despite the use of private
browsing mode. Second, if any sensitive data does reach
stable storage, it is difﬁcult for user-level applications to
guarantee that this data will not be recoverable via forensic
analysis. For example, modern journaled ﬁlesystems make
disk-wiping techniques unreliable, and applications must be
careful to prevent sensitive data from being swapped to disk
through judicious use of system calls such as mlock on
Linux.

One way to avoid leaving traces of sensitive user data
in the clear on persistent storage is to use cryptographic
techniques such as full-disk encryption. Here, the idea is to
ensure that all application disk writes are encrypted prior to
storage. Therefore, regardless of the nature of the data that is
saved to disk, users without knowledge of the corresponding
secret key will not be able to recover any information. While
this is a powerful and realizable technique, it nevertheless
has the signiﬁcant disadvantage that users can be coerced,
through legal or other means, into disclosing their keys, at
which point the encryption becomes useless.

These concerns suggest

that a) private execution is a
feature that is best provided by the operating system, where
strong privacy guarantees can be provided to any application
and analyzed for correctness; and, b) standard cryptographic

techniques such as disk encryption do not satisfactorily solve
the problem.

In this paper, we present the design and implementation
of PRIVEXEC, a novel operating system service for private
execution. PRIVEXEC provides strong, general guarantees
of private execution, allowing any application to execute
in a mode where storage writes, either to the ﬁlesystem
or to swap, will not be recoverable by others during or
after execution. PRIVEXEC achieves this by binding an
ephemeral private execution key to groups of processes
that wish to execute privately. This key is used to encrypt
all data stored to ﬁlesystems, as well as process mem-
ory pages written to swap devices, and is never exposed
outside of kernel memory or persisted to storage. Once a
private execution session has ended, the private execution
key is securely wiped from volatile memory. In addition,
inter-process communication (IPC) restrictions enforced by
PRIVEXEC prevent inadvertent leaks of sensitive data to
public processes that might circumvent the system’s private
storage mechanisms.

PRIVEXEC does not require application support; any
unmodiﬁed, legacy binary application can execute privately
using our system. Due to the design of our approach,
users cannot be coerced into disclosing information from a
private execution. We also demonstrate that our prototype
implementation of PRIVEXEC, which we construct using
existing, well-tested technologies as a foundation, incurs
minimal performance overhead. Indeed, for many popular
application scenarios, PRIVEXEC has no discernable impact
on the user experience aside from its signiﬁcant privacy
beneﬁts.

In summary, our contributions are the following.
• We propose PRIVEXEC, a novel operating system ser-
vice for private execution, that provides strong privacy
guarantees to any application without requiring explicit
application support, recompilation, or any other precon-
ditions.

• We describe a prototype implementation of PRIVEXEC
for Linux, which leverages the short-lived nature of
the private execution model
to associate protected,
ephemeral private execution keys with processes that
can be securely wiped after use such that they cannot
be recovered by a user or adversary.

• We evaluate the functionality and performance char-
acteristics of our implementation, and show that it is
performant, practical, and that
it effectively secures
sensitive data against disclosure.

The remainder of the paper is structured as follows.
Section II describes the threat model we assume for this
work. Section III presents the design of PRIVEXEC, while
Section IV discusses our implementation of the system as
a modiﬁcation to the Linux kernel. Section V presents
an evaluation of the functionality and performance of our
PRIVEXEC prototype. Section VI discusses the limitations

207

of PRIVEXEC. Finally, Sections VII and VIII present related
work and brieﬂy conclude.

II. THREAT MODEL

Our primary motivation for designing PRIVEXEC is to
prevent the disclosure of sensitive user information involved
in short-lived private execution sessions. The model for
these private execution sessions is similar to the private
browsing mode implemented in most modern browsers, but
generalized to any user-level application.

We divide the threat model we assume for this work into
two scenarios, one for the duration of a targeted private
execution session, and another for after a session has ended.
For the ﬁrst scenario, we assume that an adversary can
have remote access to the target system as a normal user.
Due to normal process-based isolation, the attacker cannot
inspect physical memory, kernel virtual memory, or process
virtual memory for processes labeled with a different user
ID. Furthermore, we assume that an active network attacker
can drop, reorder, or modify trafﬁc, or could control a remote
endpoint, such as a web site, that the user communicates
with. As with private browsing mode, we rely on common
mechanisms such as SSL/TLS and user awareness to prevent
the disclosure of sensitive information in this case.

The threat model for the second scenario corresponds to
a technically sophisticated adversary with physical access
to a target system after a private execution session has
ended. In this scenario, the adversary has complete access
to the contents of any local storage such as hard disks or
non-volatile ﬂash memory, as well as the system RAM. It
is assumed that the adversary has access to sophisticated
forensics tools that can retrieve insecurely deleted data from
a ﬁlesystem, or process memory pages from swap devices.
Common to both scenarios is the assumption of a “benign-
but-buggy”, or perhaps “benign-but-privacy-unaware”, ap-
plication. In particular, our threat model does not include
applications that maliciously transmit private information
to remote parties, or users that do the same. However, as
we describe in the next section, PRIVEXEC aims to avoid
inadvertent disclosure of private information.

III. PRIVEXEC DESIGN

In this section, we ﬁrst outline the security guarantees that
our system aims to provide, and then elaborate on the privacy
policies that a PRIVEXEC-enabled system must enforce for
the ﬁlesystem, swap space, IPC, and memory isolation. We
defer a discussion of the details of our prototype implemen-
tation to Section IV.

A. Security Properties and Design Goals

PRIVEXEC provides private execution as a generic operat-
ing system service by creating a logical distinction between
public processes and private processes. While public pro-
cesses execute with the usual semantics regarding access

Public Processes

Private Process Group

x

P1

P3

P2

P4

IPC

P6

{PEK }x

Private 
Container

Disk 

reads, writes

Private Process Groupy
P7

Disk 

reads, writes

{PEK }y

IPC

Private 
Container

P5

IPC

P8

{PEK }y

Disk 

reads, writes

Disk 

reads, writes

Disk reads

Public 

Filesystem

Figure 1. Overview of the design of PRIVEXEC. Public processes behave
as normal applications, with read-write access to one or more public
ﬁlesystems and unrestricted IPC in that they can write to all other processes.
Private processes, however, have read-only access to the public ﬁlesystem.
All private process writes are redirected to a dedicated temporary secure
storage container that persists only for the lifetime of the process and
is irrevocably discarded at process exit. Data stored in this container is
encrypted with a protected, process-speciﬁc private execution key (PEK)
that is never revealed. Private process swap is conceptually handled in
a similar fashion. Finally, private processes cannot write data to public
processes or unrelated private processes via IPC channels.

to shared system resources, private processes are subject to
special restrictions to prevent disclosure of sensitive data
resulting from private execution. In the PRIVEXEC model,
private processes might execute within the same logical
privacy context, where resource access restrictions between
processes sharing a context are relaxed. We refer to private
processes related in this way as private process groups.

The concrete security properties that our system provides

are the following.
(S1) Data explicitly written to storage must never be re-
coverable without knowledge of a secret bound to an
application for the duration of its private execution.

(S2) Application memory that is swapped to disk must
never be recoverable without knowledge of the ap-
plication secret.

(S3) Data produced during a private execution must never
be passed to processes outside the private process

group via IPC channels.

(S4) Application secrets must never be persisted, and never

be exposed outside of protected volatile memory.

(S5) Once a private execution has terminated, application

secrets and data must be securely discarded.

Together, (S1), (S2) and (S3) guarantee that data resulting
from a private execution cannot be disclosed without access
to the corresponding secret. (S4) ensures that users cannot
be coerced into divulging their personal information, as they
do not know the requisite secret, and hence, cannot provide
it. (S5) implies that once a private execution has ended, it
is computationally infeasible to recover the data produced
during that execution.

In addition, we set out to satisfy the following design

goals for the system.
(D1) PRIVEXEC must be generic; it must be applicable to
any type of application, running on any ﬁlesystem
and block I/O device. It must not require explicit
cooperation on behalf of applications that wish to
make use of the private execution service, including
source code modiﬁcation, or recompilation against a
new API or library.

(D2) PRIVEXEC must be ﬂexible; users should be able
to apply it selectively to arbitrary applications to
execute them privately as desired. At the same time,
PRIVEXEC must not have any negative impact on
other public processes running on the system.

(D3) After launching a private process, PRIVEXEC must
operate automatically, without requiring any manual
intervention on behalf of the user.

(D4) Finally, the system must introduce minimal perfor-

mance overhead relative to normal execution.

Figure 1 depicts an overview of the design of PRIVEXEC.

B. Filesystem

Public processes have the expected read-write access to
public ﬁlesystems. Private processes, on the other hand, are
short-lived processes that have temporary secure storage
containers. This storage container is allocated only for the
lifetime of a private execution and is accessible only to the
private process group it is associated with.

Each private process group is bound to a private execution
key, or PEK, which is the basis for uniquely identifying a
privacy context. This PEK is randomly generated at private
process creation, protected by the operating system, never
stored in non-volatile memory, and never disclosed to the
user or any other process. The PEK is used to encrypt all
data produced during a private execution before it is written
to persistent storage within the secure container. In this
way, PRIVEXEC ensures that sensitive data resulting from
private process computation cannot be accessed through the
ﬁlesystem by any process that does not share the associated
privacy context. Furthermore, when a private execution

208

terminates, PRIVEXEC securely wipes its PEK, and hence
makes it computationally infeasible to recover the encrypted
contents of the associated storage container.

Although all new ﬁles created by a private process must
clearly be stored in its secure container, applications of-
ten need to access ﬁles that already exist in the normal
ﬁlesystem in order to function correctly. For instance, most
applications load shared libraries and read conﬁguration ﬁles
as part of their normal operation. The OS needs to ensure
that such read requests are directed to the public ﬁlesystem.
An even more complicated situation arises when a private
process attempts to modify existing ﬁles. In that case, we
need to create a separate private copy of the ﬁle in the
process’ secure container, and redirect all subsequent read
and write requests for that ﬁle to the new copy. PRIVEXEC
ensures that private processes can only write to the secure
storage container while they still have a read-only view of
the public ﬁlesystems by enforcing the following copy-on-
write policy.

• For a write operation,

– if the destination ﬁle does not exist in the ﬁlesys-
tem or in the secure container, a new ﬁle is created
in the container;

– if the ﬁle exists in the ﬁlesystem, but not in the
container, a new copy of the ﬁle is created in the
container, and the write is performed on this new
copy;

– if the ﬁle exists in the container,

the process
directly modiﬁes it regardless of whether it exists
in the ﬁlesystem.
• For a read operation:

– if the ﬁle exists in the container, it is read from
there regardless of whether it also exists in the
ﬁlesystem;

– if the ﬁle exists in the ﬁlesystem but not in the

container, the ﬁle is read from the ﬁlesystem;

– if the ﬁle exists neither in the ﬁlesystem nor in the

container, the read operation fails.

C. Swap Space

In addition to protecting data written to ﬁlesystems by a
private process, PRIVEXEC must also preserve the privacy
of virtual memory pages swapped to disk. This is different
from existing approaches to swap encryption, which use a
single key to encrypt the entire swap device, and fail to
meet our security requirements in the same way that full-
disk encryption also does not. Since swap space is shared
between processes with different user principals, PRIVEXEC
encrypts each private process memory page that is swapped
to disk with the PEK of the corresponding process as
in the ﬁlesystem case, and thus imposes a per-application
partitioning of the system swap.

209

D. Inter-Process Communication

The private storage mechanisms described in the previous
sections effectively prevent sensitive data resulting from
private computation from being stored in the clear. However,
applications frequently make use of a number of IPC chan-
nels during their normal operation. Without any restrictions
in place, private processes might use these channels to
inadvertently leak sensitive data to a public process. If that
public process in turn persists that data, it would circumvent
the protections PRIVEXEC attempts to enforce. Therefore,
PRIVEXEC must also enforce restrictions on IPC to prevent
such scenarios from occurring.

Speciﬁcally, PRIVEXEC ensures that a private process
can write data via IPC only to the other members of its
group that share the same privacy context. In other words,
a private process cannot write data to a public process, or
to an unrelated private process.

As usual, public processes can freely exchange data with
other public processes. Note that public processes can also
write data to private processes, since data ﬂow from a public
process to a private process does not violate the security
properties of PRIVEXEC.

E. Memory Isolation

Enforcing strong memory isolation is essential

to the
private execution model, not only for protecting the virtual
address space of a private process, but also for preventing the
disclosure of PEKs. To this end, PRIVEXEC takes measures
to enforce process and kernel isolation boundaries against
unprivileged users for private processes, in particular by
disallowing standard exceptions to system isolation policies
that would otherwise be allowed. This includes disabling fea-
tures such as debugging facilities or disallowing unprivileged
access to devices that expose the kernel virtual memory or
physical memory.

F. Discussion

The design we describe satisﬁes the goals we enumer-
ate in Section III-A. The PEK serves as the application
secret that ensures conﬁdentiality of data produced during
private execution (S1), (S2). The PRIVEXEC-enabled OS is
responsible for protecting the conﬁdentiality of the PEK,
ensures that the user cannot be expected to know the value
of individual PEKs, and prevents private processes from
inadvertently leaking sensitive data via IPC channels to other
processes (S3), (S4). Destroying the PEK after a private
execution has ended ensures that any data produced cannot
feasibly be recovered by anyone, including the user (S5).

IV. PRIVEXEC IMPLEMENTATION

In the following, we describe our prototype implementa-
tion of PRIVEXEC as a set of modiﬁcations to the Linux
kernel and a user-level helper application, and support its
satisfaction of the design goals we list in Section III-A. We

A SUMMARY OF MODIFICATIONS TO THE LINUX KERNEL TO SUPPORT

PRIVATE PROCESS MANAGEMENT.

Table I

File Path
include/linux/sched.h

kernel/fork.c

kernel/exit.c

Changes
Extend task_struct to store PEK
Deﬁne PF_PRIVEXEC
Deﬁne CLONE_PRIVEXEC
Modify do_fork to create private processes
Set up CryptoAPI, generate the PEK
Modify do_exit to clean up private processes
Release CryptoAPI resources, destroy the PEK

center this discussion around ﬁve main technical challenges:
managing private processes, constructing secure storage con-
tainers, implementing private application swap, enforcing
restrictions on IPC channels, and running applications pri-
vately at the user level.
A. Private Process Management

The ﬁrst requirement for implementing PRIVEXEC is to
enable the OS to support a private execution mode for
processes. The OS must be able to launch an application as
a private process upon request from the user, generate the
PEK, store it in an easily accessible context associated with
that process, mark the process and track it during its lifetime,
and, ﬁnally, destroy the PEK when the private process ter-
minates. Additionally, these new capabilities must not break
the established kernel process management functionality. At
the same time, the OS must expose a simple interface for
user-level applications to request private execution without
requiring modiﬁcations to existing application code.

The Linux kernel

represents every process on the
system using a process descriptor, deﬁned as struct
task_struct in include/linux/sched.h. The process
descriptor contains all the information required to execute
the process, including functions such as scheduling, virtual
address space management, and accounting. A new process,
or child, is created by copying an existing process, or parent,
through the fork and clone system calls. clone is a
Linux-speciﬁc system call that offers ﬁne-grained control
over which system resources the parent and child share
through a set of clone ﬂags passed as an argument, and is
typically used for creating threads. fork, on the other hand,
deﬁnes a static set of clone ﬂags to create independent pro-
cesses with the usual POSIX semantics. These two system
calls, in turn, invoke the function do_fork implemented in
kernel/fork.c, which allocates a new process descriptor
for the child, initializes it, and prepares it for scheduling.
When the process is terminated, for example by invoking
the exit system call, the function do_exit, implemented
in kernel/exit.c, deallocates resources associated with
the process.

To implement our system, we ﬁrst extended the process
descriptor by deﬁning a new process ﬂag, PF_PRIVEXEC,

210

is set

in the flags ﬁeld of the process descriptor
that
to indicate that it is a private process. We deﬁned a new
ﬂag, CLONE_PRIVEXEC, that is passed to clone whenever a
private process is to be created. We introduced a ﬁeld to store
the PEK in the process descriptor called privexec_key.
The ﬁnal addition to the process descriptor was a pre-
allocated cryptographic transform struct
is used for
swap encryption. Here, we relied upon the Linux kernel’s
cryptography framework (Crypto API); we defer details of
its use to Section IV-C.

that

To handle private process creation, we modiﬁed do_fork
to check for the presence of CLONE_PRIVEXEC. In that
case, we set the PF_PRIVEXEC ﬂag, and generate a fresh
PEK using a cryptographically-secure PRNG. The PEK is
stored inside the process descriptor, resides in the kernel
virtual address space, and is never disclosed to the user.
For private process termination, we adapted do_exit to
check for the presence of PF_PRIVEXEC in the ﬂags bitset. If
present, the process cryptographic transform is deallocated,
and the PEK is securely wiped prior to freeing the process
descriptor. Since the Linux kernel handles both processes
and threads in the same functions, this approach also allows
for creating and terminating private threads without any
additional implementation effort.

Note that applications might spawn additional children
for creating subprocesses or threads during the course
of execution. This can lead to two critical
issues with
multi-process and multi-threaded applications running under
PRIVEXEC. First, public children of a private process could
cause privacy leaks. Second, public children cannot access
the parent’s secure container, which could potentially break
the application. In order to prevent these problems, our
notion of a private execution should include the full set
of application processes and threads, despite the fact that
the Linux kernel represents them with separate process
descriptors. Therefore, we modiﬁed do_fork to ensure that
all children of a private process inherit the parent’s private
status and privacy context,
including both the PEK and
the secure storage container. Reference counting is used
to ensure that resources are properly disposed of when the
entire private process group exits.

Also, note that our implementation exposes PRIVEXEC to
user applications through a new clone ﬂag that is passed to
clone. As a result, when the private execution ﬂag is not
passed to the system call, the original semantics of fork
and clone are preserved, maintaining full compatibility
with existing applications. Likewise, applications that are
not aware of the newly implemented PRIVEXEC interface
to clone could be made private by simply wrapping their
executables with a program that spawns them using the
private execution ﬂag. We explain how existing applications
run under PRIVEXEC without modiﬁcations in Section IV-E.
A summary of all modiﬁcations to the Linux kernel

described in this section is presented in Table I.

User space

Process 1

Process 2

Process 3

read()

write()

write()

Virtual File System (VFS)

Ext3

Ext4

Reiserfs

VFAT

Kernel space

Page Cache

Request Queues

Driver A

Driver B

Physical devices

Figure 2. An overview of the Linux block I/O layers.

B. Private Disk I/O

PRIVEXEC requires the OS to provide every private
application with a dedicated secure storage container, to
which all application data writes must be directed. Upon
launching a private application, the OS must construct this
container, intercept and redirect I/O operations performed by
the private application, and encrypt writes and decrypt reads
on the ﬂy.

Although the Linux ﬁle I/O API consists of simple system
calls such as read and write, the corresponding kernel
execution path crosses many different layers and subsys-
tems before the actual physical device is accessed. Block
I/O requests initiated by a system call ﬁrst pass through
the virtual ﬁle system (VFS), which provides a unifying
abstraction layer over different underlying ﬁlesystems. After
a particular concrete ﬁlesystem processes the I/O request,
the kernel caches it
in the page cache, and eventually
inserts the request into the target device driver’s request
queue. The driver periodically services queued requests by
initiating asynchronous I/O on the physical device, and then
notiﬁes the OS when the operation is complete. We refer the
reader to Figure 2 for a graphical overview of these kernel
subsystems.

The choice of where to integrate PRIVEXEC into the ﬁle
I/O subsystems requires careful consideration. In particular,
in order to build a generic solution that is independent of
the underlying ﬁlesystem and physical device, we should
avoid modifying the individual ﬁlesystems, or the drivers
for the physical storage devices. One option is to intercept
I/O requests between the page cache and the device’s request
queue. However, this results in sensitive data being stored

211

as plaintext in the page cache, which is accessible to the
rest of the system. Thus, this is not an acceptable solution.
Likewise, encrypting the data as it enters the page cache is
insufﬁcient, since direct I/O operations that bypass the page
cache would not be intercepted by our system. In addition,
a second major implementation question is how to handle
the redirection of I/O requests made by private processes per
our copy-on-write policy.

In order to build a generic system that addresses all of
the above challenges, we leverage stackable ﬁlesystems. A
stackable ﬁlesystem resides between the VFS and any un-
derlying ﬁlesystem as a separate layer. It does not store data
by itself, but instead interposes on I/O requests, allowing
for controlled modiﬁcations to these requests before passing
them to the ﬁlesystem it wraps. Since stackable ﬁlesystems
usually do not need to know the workings of the underly-
ing ﬁlesystem, they are often used as a generic technique
for introducing additional features to existing ﬁlesystems.
PRIVEXEC uses a combination of two stackable ﬁlesystems
to achieve its goals: A version of eCryptfs [5] with our
modiﬁcations to provide the secure storage containers, and
Overlayfs [7] to overlay these secure containers on top of
the root ﬁlesystem. In the following, we explain their use in
PRIVEXEC and our modiﬁcations to eCryptfs in detail.

1) Secure Storage Containers: eCryptfs is a stackable
cryptographic ﬁlesystem distributed with the Linux kernel,
and it provides the basis of PRIVEXEC’s secure storage
containers. eCryptfs provides ﬁlesystem-level encryption,
meaning that each ﬁle is encrypted separately, and all
cryptographic metadata is stored inside the encrypted ﬁles.
While this is likely to be less efﬁcient compared to block-
level encryption (e.g., the approach taken by dm-crypt [4]),
eCryptfs does not require a full device or partition allocated
for it, which allows us to easily create any number of
secure containers on the existing ﬁlesystems as demand
necessitates.

Containers are structured as an upper directory and a
lower directory. All I/O operations are actually performed on
the lower directory, where ﬁles are stored in encrypted form.
The upper directory provides applications with a private
view of the plaintext contents.

The lower directory is provided by eCryptfs, using 256-bit
AES to encrypt not only ﬁle contents but directory entries
as well. However, while its cryptographic capabilities are
powerful, eCryptfs has a number of shortcomings that make
it unsuitable for use in PRIVEXEC on its own. First, once an
encrypted directory is mounted and a decrypted view is made
available at the upper directory, all users and applications
with sufﬁcient permissions can access the decrypted content.
Second, eCryptfs expects to ﬁnd the secret key in the Linux
kernel keyring associated with the user before the ﬁlesystem
can be mounted. This makes it possible for other applications
running under the same user account to access the keyring,
dump the key, and access data belonging to another private

A SUMMARY OF MODIFICATIONS TO THE ECRYPTFS IMPLEMENTATION IN THE LINUX KERNEL.

Table II

File Path
fs/ecryptfs/ecryptfs kernel.h
fs/ecryptfs/main.c

fs/ecryptfs/crypto.c

fs/ecryptfs/inode.c

Changes
Extend ecryptfs_sb_info to store privexec_token
Modify ecryptfs_mount to derive and save privexec_token on mount by a private process
Modify ecryptfs_kill_block_super to destroy privexec_token on unmount
Modify encrypt_scatterlist to check for PRIVEXEC, use PEK for encryption
Modify decrypt_scatterlist to check for PRIVEXEC, use PEK for decryption
Modify ecryptfs_permission to check for correct privexec_token on ﬁle access

application. Therefore, we modiﬁed eCryptfs in order to
address these issues and restrict access to private process
data in line with our system design.

Our ﬁrst set of modiﬁcations aim to uniquely associate
mounted eCryptfs containers with a single privacy con-
text. In Linux, each ﬁlesystem allocates and initializes a
super_block structure, deﬁned in include/linux/fs.h,
when it is mounted. The s_fs_info ﬁeld in super_block
is available for each ﬁlesystem to freely use for their
speciﬁc needs. eCryptfs uses this ﬁeld to store superblock
private data in a structure called ecryptfs_sb_info de-
ﬁned in fs/ecryptfs/ecryptfs_kernel.h. We extended
this structure to include a new ﬁeld, privexec_token.
This ﬁeld serves as a secret token that identiﬁes the pri-
vacy context associated with the mounted eCryptfs con-
tainer. We then modiﬁed ecryptfs_mount implemented
in fs/ecryptfs/main.c, the function called by the VFS
when a eCryptfs container is mounted, to check whether
the mount operation is requested by a private process.
Since this function runs in the process context inside the
kernel, we can bind a container to a privacy context by
simply checking for the presence of the PF_PRIVEXEC ﬂag
we introduced in Section IV-A in the process descriptor.
If the ﬂag is set, we populate privexec_token with a
value derived from the PEK. These extensions allow us
to use privexec_token as a unique identiﬁer in order to
determine whether a process performing eCryptfs operations
is the owner of the container. We also modiﬁed the function
ecryptfs_kill_block_super in fs/ecryptfs/main.c
to destroy the contents of privexec_token when the con-
tainer is unmounted.

implemented

the owner of the container,

the I/O request

cryptographic

functions
decrypt_scatterlist

To enforce access control on containers, we modiﬁed the
two
encrypt_scatterlist
in
and
the
fs/ecryptfs/crypto.c to check the identity of
requesting process using privexec_token. If the process
is not
is
blocked. Otherwise, if the private process is the owner of
the container, we fetch the PEK from the current process
descriptor and use it as the cryptographic key. This ensures
that the PEK never appears in the user’s kernel keyring,
and is never exposed outside of the private process group.

Although these extensions to eCryptfs address the root
cause of the aforementioned privacy issues, one last problem
remains: Once an encrypted ﬁle is accessed by an autho-
rized private process, eCryptfs caches the decrypted content
and directly serves subsequent I/O requests made by other
processes from the cache, bypassing our privacy measures.
Therefore, we perform a ﬁnal token check inside the func-
tion called by the VFS for ﬁle access permission checks,
ecryptfs_permission in fs/ecryptfs/inode.c, to en-
sure that access to the eCryptfs upper directory is denied to
the rest of the system, regardless of the directory’s UNIX
permissions.

As a result, our modiﬁed eCryptfs layer provides a secure
storage container that is only accessible to a single private
process group. Also, note that all of the security checks we
inserted only trigger if eCryptfs is mounted by a private
process in the ﬁrst place. This guarantees that normal
applications can still use eCryptfs as before, without being
restricted by our additional privacy requirements.

A summary of all modiﬁcations to eCryptfs in the Linux

kernel described in this section is presented in Table II.

2) Overlaying Secure Storage Containers: Once a ded-
icated secure container has been constructed for a private
process group, we need to redirect I/O operations to that con-
tainer as appropriate, as previously discussed. We achieve
this through the use of a stackable union ﬁlesystem. Union
ﬁlesystems are used to overlay several different ﬁlesystem
trees – sometimes referred to as branches – in a uniﬁed
hierarchy, and merge their contents as if they were a single
ﬁlesystem together. Although every implementation supports
different unioning capabilities, in theory, a union ﬁlesystem
can be used to overlay any number of branches in a deﬁned
order, with speciﬁc read and write policies for each branch.
Overlayfs is an implementation of this idea, and we
leverage it as part of our prototype. It is not distributed with
the main kernel source tree, but is available as a separate
kernel patchset. While Overlayfs implements only a limited
set of unioning features compared to other alternatives such
as Aufs [1] or Unionfs [10], it is sufﬁcient for PRIVEXEC’s
requirements, making its simplicitly an advantage. In par-
ticular, Overlayfs is restricted to overlaying two branches,
with the lower branch always being read-only.

212

Step I

P

r/w

root

/

r/w
eCryptfs
~/private/

Step II

P

r/w

root

/

r/w

Overlayfs
/tmp/fakeroot/

r/w

eCryptfs
~/private/

ro

root

/

r/w

U

eCryptfs
~/private/

Step III

chroot

/tmp/fakeroot/

P

r/w
Overlayfs
/tmp/fakeroot/

ro

root

/

r/w

U

eCryptfs
~/private/

Figure 3. Setting up the secure storage container and overlaying it on the root ﬁlesystem.

We use Overlayfs to layer secure storage containers on top
of the root ﬁlesystem tree. The root ﬁlesystem is mounted
as a read-only lower branch, while the secure container is
made the read-write upper branch. In this way, through an
Overlayfs mount point, a private process has a complete
view of the root ﬁlesystem, while all write operations are
actually performed on the secure container. Overlayfs also
supports copy-on-write; in other words, when an application
attempts to write to a ﬁle in the lower read-only root
ﬁlesystem, it ﬁrst makes a copy of the ﬁle in the writable
secure container and performs the write on the copy. The
ﬁles in an upper branch take precedence over and shadow
the same ﬁles in the lower branch, which also ensures that
all subsequent read and write operations are redirected to
the new encrypted copies.

The entire process of setting up a secure container for a
private process P and overlaying it on the root ﬁlesystem is
illustrated in Figure 3. Note that the given path names are
only examples; PRIVEXEC actually uses random paths to
support multiple private execution sessions that run simul-
taneously. Before launching a private process, in step one,
PRIVEXEC creates a secure container using our modiﬁed
version of eCryptfs and mounts it on ~/private. In step 2,
Overlayfs is used to overlay the container on the root ﬁlesys-
tem, and this new view is mounted on /tmp/fakeroot.
In the ﬁnal step,
the private process is launched in a
chroot environment, with its root ﬁlesystem the Overlayfs
mount point. In this way, the private process still has a
complete view of the original ﬁlesystem, and full read-write
access; however, all writes are transparently redirected to
the secure container. When the private process terminates,
PRIVEXEC destroys the secure container and PEK, rendering
the encrypted data in ~/private irrecoverable.

Together, the combination of Overlayfs with our modiﬁed
eCryptfs satisﬁes all of our desired security properties and
stated design goals for PRIVEXEC ﬁlesystem I/O.

C. Private Swap Space

Since the Linux kernel handles swap devices separately
from block ﬁlesystem I/O, PRIVEXEC must also interpose
on these operations in order to preserve the privacy of virtual
memory pages swapped to disk. To this end, each page
written to a swap device must be encrypted with the PEK
of the corresponding private process.

Concretely, this is a straightforward modiﬁcation to the
kernel swap routines. The cryptographic primitives we use
for this are provided by the kernel Crypto API framework;
speciﬁcally, AES in CBC-ESSIV mode, with a page-speciﬁc
IV consisting of the page’s process virtual address and a
random nonce.

We implemented per-application swap encryption as a
patch to the pageout function in mm/vmscan.c. First, a
check is performed to determine whether a page to be written
belongs to a private process. If so, the pre-allocated cipher
transform in the process task_struct is initialized with a
page-speciﬁc IV, and the page is encrypted with PEK prior
to scheduling an asynchronous write operation.

For page-in, the situation is more complex. The kernel
swap daemon (kswapd) is responsible for scanning memory
to perform page replacement, and operates in a kernel
thread context. Therefore, once a page has been selected
for replacement, process virtual memory structures must be
traversed to locate a task_struct that owns the swap page.
Once this has been done, however, the inverse of page-out
can be performed. Speciﬁcally, once the asynchronous read
of the page from the swap device has completed, a check
is performed to determine whether the owning process is in
private execution mode. If so, the process cipher transform
is initialized with the page-speciﬁc IV, and the page is
decrypted with PEK prior to resumption of the user process.
A summary of all modiﬁcations to the Linux kernel

described in this section is presented in Table III.

213

A SUMMARY OF MODIFICATIONS TO THE LINUX KERNEL TO ENABLE

ENCRYPTED SWAP PAGES.

Table III

Changes

File Path
mm/vmscan.c Modify pageout to encrypt page writes with PEK
mm/memory.c Modify do_swap_page to decrypt page reads with PEK

D. Private Inter-Process Communication

PRIVEXEC also imposes restrictions on private process
IPC to prevent data leaks from a privacy context. In general,
our approach with respect to private IPC is to modify each
IPC facility available to Linux applications as follows.

Similarly to secure storage containers, we embedded a
privexec_token in the kernel structures corresponding to
IPC resources. We then modiﬁed the kernel IPC functions
to perform a check to compare the tokens of the endpoint
processes at the time of channel establishment, or before
read and write operations, augmenting the usual UNIX per-
mission checks as appropriate. The policy we implemented
ensures that private processes with the same token can freely
exchange data, while private processes with different tokens
are prevented from communicating with a permission denied
error. In addition, private processes are allowed to read from
public processes, but prevented from writing data to them.
Of course, IPC semantics for communication between public
processes remains unchanged.

The speciﬁc Linux IPC facilities that we modiﬁed to
conform to the policy described above include UNIX SysV
shared memory and message queues, POSIX shared memory
and message queues, FIFO queues, and UNIX domain sock-
ets. Due to space restrictions, we elide details of the speciﬁc
changes as they are similar in nature to those described for
the case of secure storage containers.

E. Launching Private Applications

While PRIVEXEC-aware applications can directly spawn
private subprocesses or threads as they require by passing
the CLONE_PRIVEXEC ﬂag to the clone system call, we
implemented a PRIVEXEC wrapper as the primary method
for running existing applications in private mode.

The PRIVEXEC wrapper ﬁrst creates a private copy of
itself by invoking clone with the CLONE_PRIVEXEC ﬂag.
Then, this private process creates an empty secure storage
container and mounts it in a user-speciﬁed location. Recall
that, as explained in Section IV-B1, our modiﬁcations to
eCryptfs ensure that only this speciﬁc private process and
its children can access the container from this point on. The
wrapper then creates the ﬁlesystem overlay as described in
Section IV-B2. Finally, it loads the target application exe-
cutable in a chroot environment, changing the application’s
root ﬁlesystem to our overlay. As explained in Section IV-A,
the application inherits the PEK of the wrapper, and starts

its private execution. When the application terminates, the
PRIVEXEC wrapper cleans up the mounted overlay and
exits.

Note that the ﬁnal destruction of the container is simply
for user convenience. Even if the wrapper or the private
application itself crashes or is killed such that the container
and the overlay remain mounted, the container is accessible
only to the processes that have the corresponding PEK;
that is, the private application that created it. Since that
application and its PEK have been destroyed, the private data
remains inaccessible even if the container remains mounted.

V. EVALUATION

The primary objective of our evaluation is to demonstrate
that PRIVEXEC is practical for real-world applications that
often deal with sensitive information, without detracting
from the user experience. To this end, we ﬁrst tested whether
our system works correctly, without breaking program func-
tionality, by manually running popular applications with
PRIVEXEC. Next, we tested PRIVEXEC’s performance using
standard disk I/O and ﬁlesystem benchmarks. Finally, we
ran performance experiments with well-known desktop and
console applications that are representative of the use cases
PRIVEXEC targets.

A. Running Popular Applications

To demonstrate that our approach is applicable to and
compatible with a wide variety of software, we manually
tested 50 popular applications with PRIVEXEC. We selected
our test set from the top rated applications list reported by
Ubuntu Software Center. Speciﬁcally, we selected the top
50 applications, excluding all non-free or Ubuntu-speciﬁc
software. The tested applications include software in many
different categories such as developer tools (e.g., Eclipse,
Emacs, Geany), graphics (e.g., Blender, Gimp, Inkscape), In-
ternet (e.g., Chromium, FileZilla, Thunderbird), ofﬁce (e.g.,
LibreOfﬁce), sound and video (e.g., Audacity, MPlayer), and
games (e.g., Battle for Wesnoth, Teeworlds). We launched
each application with PRIVEXEC, exercised their core fea-
tures, and checked whether they worked as intended.

This experiment revealed two important limitations of
PRIVEXEC regarding our measures to block IPC channels.
First, private X applications failed to start because they
could not communicate with the public X server through
UNIX domain sockets. This led us to modify our system
to launch these applications in a new, private X session,
which resolved the issue. Alternatively, the IPC protection
for stream type UNIX domain sockets could be disabled as
a tradeoff in order to run private and public applications in
the same X session.

Second, a number of X applications that utilized the MIT
Shared Memory Extension (MIT-SHM) to draw to the X
display failed to render correctly since SysV shared memory
writes to the public X server were blocked. This issue

214

DISK I/O AND FILESYSTEM PERFORMANCE OF PRIVEXEC. ECRYPTFS-ONLY PERFORMANCE IS ALSO SHOWN FOR COMPARISON.

Table IV

Original

Performance

110694.60 KB/s
48724.53 KB/s
111217.67 KB/s
196.27 seeks/s

eCryptfs-only

PRIVEXEC

Performance
97536.83 KB/s
38800.78 KB/s
107134.53 KB/s
147.53 seeks/s

Overhead
13.49 %
25.58 %
3.81 %
33.04 %

Performance
97979.47 KB/s
38790.07 KB/s
106293.73 KB/s
138.37 seeks/s

13906.73 ﬁles/s
217734.60 ﬁles/s
42012.87 ﬁles/s

8312.73 ﬁles/s
126326.23 ﬁles/s
25232.67 ﬁles/s

67.29 %
8181.10 ﬁles/s
72.36 % 117844.75 ﬁles/s
66.50 %
23017.00 ﬁles/s

Overhead

12.98 %
25.61 %
4.63 %
41.84 %

69.99 %
84.76 %
82.53 %

Write
Rewrite
Read
Seek

Create
Stat
Delete

could also be resolved by running a private X session, or
simply by disabling the MIT-SHM extension in the X server
conﬁguration ﬁle.

Once the above problems were dealt with, all 50 ap-
plications worked correctly, without exhibiting any unusual
behavior or noticeable performance issues.

B. Disk I/O and Filesystem Benchmarks

In order to evaluate the disk I/O and ﬁlesystem per-
formance of PRIVEXEC, we used Bonnie++ [3], a well-
known ﬁlesystem benchmark suite for UNIX-like operating
systems.
We ﬁrst conﬁgured Bonnie++ to use 10 × 1 GB ﬁles to
test the throughput of block write, rewrite, read, and random
seek operations. Next, we benchmarked ﬁlesystem metadata
operations such as ﬁle creation and deletion rates, and small-
ﬁle access performance by conﬁguring Bonnie++ to create,
access, and delete 102,400 ﬁles, each containing 512 bytes
of data, in a single directory. We ran Bonnie++ as a normal
process and then using PRIVEXEC for comparison, repeated
all the experiments 10 times, and calculated the average
scores to get the ﬁnal results. We present our ﬁndings in
Table IV.

These results show that PRIVEXEC performs reasonably
well when doing regular reads and writes, incurring an over-
head of 12.98% and 4.63%, respectively. However, private
applications can experience slowdowns ranging from 70%
to 85% when dealing with large numbers of small ﬁles in a
single directory. In fact, unoptimized ﬁlesystem performance
with large amounts of ﬁles is a known deﬁciency of eCryptfs,
which could provide an explanation for this performance
hit.1 When we adjusted our benchmarks to decrease the
number of ﬁles used, or when we conﬁgured Bonnie++ to
distrubute the ﬁles evenly to a number of subdirectories, the
performance gap decreased drastically.

To see the impact of eCryptfs on PRIVEXEC’s perfor-
mance in general, we repeated the measurements by running

1See

an

eCryptfs

similar
performance-related
http://superuser.com/questions/397252/
ecryptfs-and-many-many-small-ﬁles-bad-performance, also linked from
the ofﬁcial eCryptfs web page.

developer’s

response

issue

at

to

a

Bonnie++ on an eCryptfs-only partition. The results, also
shown in Table IV for comparison, indicate that a signiﬁcant
part of PRIVEXEC’s disk I/O and ﬁlesystem overhead is
introduced by the eCryptfs layer. This suggests that a more
optimized encrypting ﬁlesystem, or the use of block-level
encryption via dm-crypt (despite its various disadvantages
such as the requirement to create separate partitions of ﬁxed
size to be utilized by PRIVEXEC) could greatly increase
PRIVEXEC’s disk I/O and ﬁlesystem performance. We report
the worst-case ﬁgures in this paper and leave the evaluation
of these alternative techniques for future work.

While these results clearly indicate that PRIVEXEC might
not be suitable for workloads involving many small ﬁles,
such as running scientiﬁc computation applications or com-
piling large software projects, we must stress that such
workloads do not represent the use cases PRIVEXEC is de-
signed to target. Indeed, in the next section we demonstrate
that these benchmark scores do not translate to decreased
performance when executing real-world applications with
concrete privacy requirements using PRIVEXEC.
C. Real-World Application Performance

In a ﬁnal set of experiments, we measured the overhead
incurred by various common desktop and console appli-
cations when running them with PRIVEXEC. Speciﬁcally,
we identiﬁed 12 applications that are representative of the
privacy-related scenarios and concerns that PRIVEXEC aims
to address, and designed various automated tests to stress
those applications. We ran each application ﬁrst as a normal
process, then with PRIVEXEC, and compared the elapsed
times under each conﬁguration.

Note that designing custom test cases and benchmarks in
this way requires careful consideration of factors that might
inﬂuence our runtime measurements. In particular, a major
challenge we faced was automating the testing of desktop
applications with graphical user interfaces. Although several
GUI automation and testing frameworks exist for Linux,
most of them rely on recording and issuing X server events
without any understanding of the tested application’s state.
As a result, the test developer is often expected to insert
ﬁxed delays between each step of the test in order to give

215

RUNTIME PERFORMANCE OVERHEAD OF PRIVEXEC FOR TWO POPULAR WEB BROWSERS.

Table V

Firefox

Alexa
Wikipedia
CNN
Gmail

Orig. Runtime (s)
98.43
37.80
66.61
58.43

PRIVEXEC Runtime (s)
103.56
39.96
69.15
61.36

Overhead
5.21 %
5.71 %
3.81 %
5.02 %

Orig. Runtime (s)
91.63
39.25
49.21
30.61

Chromium
PRIVEXEC Runtime (s)
94.69
40.12
50.83
30.98

Overhead
3.34 %
2.22 %
3.29 %
1.21 %

the application enough time to respond to the issued events.
For instance, consider a test that involves opening a menu
by clicking on it with the mouse, and then clicking on a
menu item. When performing this task automatically using
a tool that issues X events, the developer must insert a delay
between the two automated click events. After the ﬁrst click
on the menu, the second click must be delayed until the
tested application can open and display the menu on the
screen. This technique works well for simple automation
tasks, but for runtime measurements, long delays can easily
mask the incurred overhead and lead to inaccurate results.
Taking this into consideration, in our tests, we refrained from
using any artiﬁcial delays, or employing tools that operate
in this way.

First, we tested PRIVEXEC with two popular web
browsers, Firefox and Chromium. We designed four test
cases that represent different browsing scenarios.

Alexa

In this test, we directed the browsers to visit the top
50 Alexa domains. While some of these sites were
relatively simple (e.g., www.google.com), others
included advertisement banners, embedded Flash,
multimedia content, JavaScript, and pop-ups (e.g.,
www.bbc.co.uk).

RUNTIME PERFORMANCE OVERHEAD OF PRIVEXEC FOR VARIOUS

DESKTOP AND CONSOLE APPLICATIONS.

Table VI

Audacious
Feh
FFmpeg
grep
ImageMagick
LibreOfﬁce
MPlayer
Pidgin
Thunderbird
Wget

Orig. Runtime (s)
61.27
51.86
105.47
245.37
96.16
99.64
122.98
116.49
75.45
71.48

PRIVEXEC Runtime (s)
62.30
52.52
111.31
253.82
101.41
100.62
129.39
117.87
78.78
71.89

Overhead
1.68 %
1.27 %
5.54 %
3.44 %
5.46 %
0.98 %
5.21 %
1.19 %
4.41 %
0.57 %

runtime over all the runs. We present a summary of the
results in Table V.

Next, we tested 10 popular Linux applications, including
media players, an email client, an instant messenger, and
an ofﬁce suite. These applications and their corresponding
test cases are described below.

Audacious

We conﬁgured Audacious, a desktop audio player,
to iterate through a playlist of 2500 MP3 audio ﬁles
totaling 15 GB, load each ﬁle, and immediately
skip to the next ﬁle without playing them.

Feh is a console-based image viewer. We conﬁg-
ured Feh to load and cycle through 1000 JPEG
images, totaling 1.5 GB.

FFmpeg, a video and audio converter, was conﬁg-
ured together with libmp3lame to convert 25 AAC
formatted audio ﬁles to the MP3 format.

grep is the standard Linux command-line utility for
searching ﬁles for matching regular expressions.
We used grep to search the entire root ﬁlesystem
for the string “linux”, and dumped the matching
lines into a text ﬁle. This process resulted in 16186
matching lines, leading to a 3 MB dump.

ImageMagick is a software suite for creating,
editing and viewing various image formats. Using

ImageMagick

Wikipedia

CNN

Gmail

In this test, we visited 50 Wikipedia articles. As
is typical of Wikipedia, these web pages mostly
included text and images.

Feh

In this test, we navigated within the CNN web
site by clicking on different news categories and
articles. We cycled 5 times through 10 CNN pages
with many embedded images, videos and Flash
content in order to exercise the browser’s cache.

In this test, we navigated to and logged into Gmail,
composed and sent 5 emails, and then logged out
of the web site.

FFmpeg

grep

To execute these tests, we used Selenium WebDriver [8],
a popular browser automation framework. Selenium com-
mands browsers natively through browser-speciﬁc drivers,
and is able to detect when the page elements are fully
loaded without requiring the user to introduce ﬁxed delays.
We repeated each test 10 times, and calculated the average

216

ImageMagick’s convert utility, we converted 150
JPEG images to PNG images.

LibreOfﬁce is a comprehensive ofﬁce software
suite. We used LibreOfﬁce to open 5 large word
documents and 5 spreadsheets, and print them to
PostScript ﬁles.

We conﬁgured MPlayer, a console and desktop
movie player, to iterate through a playlist of 100
Matroska ﬁles totaling 30 GB containing videos
in various formats, load each ﬁle, and immediately
skip to the next one without displaying the content.

LibreOfﬁce

MPlayer

Pidgin

Pidgin is a multi-protocol instant-messaging client.
Using Pidgin, we sent 500 short text messages
between two Gtalk accounts.

Thunderbird is a desktop email client. We com-
posed and sent 5 emails with 1 MB attachments in
our test.

Thunderbird

Wget

Wget is a console-based network downloader. We
used Wget to download 10 small video clips, each
sized 10-25 MB, from the Internet.

To carry out

these tests, we utilized the synchronous
command line interfaces provided by the applications them-
selves, and also used xdotool [11], an X automation tool
that can simulate mouse and keyboard events. We stress that
we only used xdotool for simple tasks such as bootstrapping
some of the GUI applications for testing, and never included
any artiﬁcial delays. Similar to the previous experiments,
we repeated each test 10 times, and we present the average
runtimes in Table VI. Note that in the tests above, we had the
option to supply inputs to the applications from the secure
storage containers or from the public ﬁlesystems. For each
application, we tested both and have reported the worse
case. Also note that PRIVEXEC would normally prevent
us from writing to the secure container from outside the
private process. Therefore, we implemented a backdoor in
PRIVEXEC during the evaluation phase in order to copy the
test data to the secure container.

In our experiments, the overhead of private execution
was under 6% in every test case, and, on average, private
applications took only 3.31% longer to complete their tasks.
These results suggest that PRIVEXEC is efﬁcient, and that
it does not detract from the user experience when used with
popular applications that deal with sensitive data. Finally,
these experiments support our claim in Section V-B that
the Bonnie++ benchmark results do not necessarily indicate
poor performance for common desktop and console applica-
tions. On the contrary, PRIVEXEC can demonstrably provide
a private execution environment for real applications without

a signiﬁcant performance impact. Still, we must stress that if
a user runs PRIVEXEC with a primarily I/O bound workload,
lower performance should be expected as indicated by the
Bonnie++ benchmarks.

Finally, we note that

the authors deployed and used
PRIVEXEC on their computers during the testing phase, and
did not experience any performance issues under normal
workloads.

VI. LIMITATIONS

While our prototype aims to provide a complete imple-
mentation of private execution for Linux, there are some
important limitations to be aware of.

One limitation is that

the current prototype does not
attempt to address system hibernation, which entails that
the contents of physical memory are persisted to disk. As a
result, if a hibernation event occurs while private processes
are executing, sensitive information could be written to disk
as plaintext in violation of system design goals. We note that
this is not a fundamental limitation, as hibernation could be
handled in much the same manner as per-process encrypted
swap. However, we defer the implementation of private
execution across hibernation events to a future release.

By design, PRIVEXEC relies upon memory isolation
to protect both private process memory as well as the
corresponding PEK, which resides in kernel memory. If
malicious code runs as a privileged user, such as root on
UNIX-like systems, then that code could potentially bypass
PRIVEXEC’s protection mechanisms. One example of this
would be for a malicious user to load a kernel module that
directly reads out PEKs, or simply introspects on a private
process to access its memory directly. For this reason, we
explicitly consider privileged malicious users or code as
outside the scope of PRIVEXEC’s threat model.

As previously discussed in Section V, certain X ap-
plications do not interact well with the current prototype
implementation of stream-based UNIX domain socket and
SysV shared memory IPC privacy restrictions. In the former
case, UNIX domain socket restrictions must be relaxed for
X applications, while disabling the MIT-SHM extension
is sufﬁcient
to work around the second case. A related
limitation is the possibility for malicious code to extract
sensitive data by capturing screenshots of private graphical
elements through standard user interface facilities. However,
we again note that these are not fundamental limitations of
the approach, and we plan to address these cases in a future
release of the system.

VII. RELATED WORK

To the best of our knowledge, there exists no work that
aims to provide private execution for any existing binary as
a generic operating system service. However, there is a large
body of work that has studied privacy attacks and defenses,
ﬁlesystem and disk encryption, and sensitive information
leakage in various contexts.

217

A. Privacy Leaks in Web Browsers

Privacy attacks and defenses have been studied exten-
sively speciﬁcally in the context of web browsers. For ex-
ample, Felten and Schneider [21] introduce the ﬁrst privacy
attacks exploiting DNS and browser cache timing. In other
works, Clover et al. [19] demonstrate a technique for stealing
browsing history using CSS visited styles, and Janc and
Olejnik [28] show the real-world impact of this attack. On
the defense side, solutions have been proposed for prevent-
ing snifﬁng attacks and session tracking (e.g., [13], [24],
[26], [37]). However, these works are largely orthogonal
to ours in that they target information leaks on the web,
while PRIVEXEC addresses the problem of privacy leaks
for persistent storage.

Aggarwal et al. [12] and Said et al. [36] analyze the
private browsing modes of various browsers, and reveal
weaknesses that would allow a local attacker to recover
sensitive data saved on the disk. The former study also shows
that poorly designed browser plug-ins and extensions could
undermine well-intended privacy protection measures. These
studies underline the value of PRIVEXEC, as our approach
aims to mitigate the attacks described in these papers. More-
over, PRIVEXEC is designed as a generic solution that is not
only limited to protecting web browsers. In other words,
our approach can be used to run any arbitrary application in
private sessions, including browsers that already have private
browsing modes and that have been shown to be vulnerable.

B. Privacy Leaks in Volatile Memory

Studies have demonstrated that it is possible to recover
sensitive data, such as disk encryption keys, from volatile
memory [22], and many others have proposed solutions
to address this problem. While PRIVEXEC stores PEKs in
memory, we are careful to wipe them after the associated
process has ended. Anti-cold boot measures could also be
deployed to complement PRIVEXEC if so desired by users.
Secure hardware architectures such as XOM [40] and
AEGIS [38] extensively study memory encryption tech-
niques to prevent information leakage, and support tamper-
resistant software and processing. Alternatively, Crypt-
keeper [32] proposes a software-encrypted virtual memory
manager that works on commodity hardware by partitioning
the memory into a small plaintext working set and a large
encrypted area.

Likewise, secure deallocation [18] aims to reduce the
lifetime of sensitive data in the memory by zeroing memory
promptly after deallocation. In a recent study, Lacuna [20]
utilizes a modiﬁed QEMU virtual machine manager, a
patched host operating system, custom drivers, and hardware
support to run applications inside special virtual machines
that provide them with encrypted communication channels to
peripheral devices. Provos [34] proposes encrypting swapped
out memory pages in order to prevent data leaks from
memory to disk.

In contrast, PRIVEXEC is designed as an operating system
service that guarantees storage writes to the ﬁlesystem or to
swap cannot be recovered during or after a private execu-
tion session. As such, encrypted memory is complementary
to PRIVEXEC’s private processes. Furthermore, PRIVEXEC
works on commodity hardware, does not necessitate archi-
tectural changes to existing systems or virtualization, and
incurs only minimal performance and resource overhead.
C. Disk and Filesystem-Based Encryption

Many encrypted ﬁlesystems (e.g., CFS [15], Cryptfs [41],
eCryptfs [5], EncFS [6]), and full-disk encryption technolo-
gies (e.g., dm-crypt [4], BitLocker [2]) have been proposed
to protect
the conﬁdentiality of data stored on disk. In
a recent study, CleanOS [39] extends this idea to a new
Android-based operating system that protects the data on
mobile devices against device loss or theft by encrypting
local ﬂash and storing keys in the cloud. Borders et al. [17]
propose a system that takes a system checkpoint, stores
conﬁdential information in encrypted ﬁle containers called
Storage Capsules, and ﬁnally restores the previous state to
discard all operations that the sensitive data was exposed to.
Although many of these solutions provide conﬁdentiality
while the encrypted drives or partitions are locked, once
they are unlocked, sensitive data may become exposed to
privacy attacks. Moreover, encryption keys can be retrieved
by exploiting insecure key storage, or through malware
infections. Approaches that may be resilient to such attacks
(e.g., Storage Capsules) remain open to key retrieval via
coercion (e.g., through a subpoena issued by a court). In
contrast, PRIVEXEC destroys encryption keys promptly after
a process terminates, guaranteeing that recovery of sensitive
data on the disk is computationally infeasible. Furthermore,
it can be applied selectively to speciﬁc processes on demand,
as opposed to encrypting an entire device or partition.
Finally, PRIVEXEC is a ﬂexible solution that can work with
any ﬁlesystem supported by the kernel.
D. Secure File Deletion

Other more general secure wiping solutions,

The idea of securely deleting ﬁles using ephemeral en-
cryption keys was introduced by Boneh and Lipton [16],
and was later used in various other systems (e.g., [31], [33],
[35]). We borrow this idea, and apply it to a new context.
includ-
ing user space tools such as shred [9] and kernel ap-
proaches [14], [29] provide only on-demand secure removal
of ﬁles. In contrast, PRIVEXEC provides operating system
support for automatically rendering all ﬁles created and
modiﬁed by a private process irrecoverable, and does not
require users to manually identify ﬁles that contain sensitive
data for deletion.
E. Application-Level Isolation

Various mechanisms have been proposed to sandbox
applications and undo the effects of their execution. For

218

example, Alcatraz [30] and Solitude [25] provide secure
execution environments that sandbox applications while
allowing them to observe their hosts using copy-on-write
ﬁlesystems. Other works utilize techniques such as system
transactions, monitoring and logging to roll back the host to
a previous state (e.g., [23], [27]). Unlike PRIVEXEC, these
systems are primarily concerned with executing untrusted
applications and recovery after a compromise; they do not
provide privacy guarantees.

VIII. CONCLUSIONS AND FUTURE WORK

Privacy is of paramount

importance for many users.
Whereas most commodity operating systems did not support
disk encryption a decade ago, today, all major operating
systems provide a standard implementation (e.g., Apple
FileVault, Microsoft BitLocker, and Linux dm-crypt). Fur-
thermore, “private browsing mode” has become a widely-
used feature of popular web browsers, with the aim of
allowing users to surf the Internet privately without leaving
behind sensitive information on disk. Indisputably, there is a
large demand from users for privacy-enabling technologies.
Unfortunately, although existing approaches such as
application-speciﬁc privacy modes are useful in practice,
prior work has shown that such systems still leave behind
much sensitive information on disk that can be retrieved
using forensic analysis techniques [12]. In addition, disk
encryption alone is not sufﬁcient, as key disclosure through
technical means or coercion remains possible.

In this paper, we presented the design and implementation
of PRIVEXEC, the ﬁrst operating system service for private
execution of arbitrary applications. PRIVEXEC does not
require explicit application support, recompilation, or any
other preconditions. It provides strong, general guarantees
of private execution, allowing any application to execute in
a mode where storage writes, either to the ﬁlesystem or to
swap, will not be recoverable during or after execution. We
have implemented a prototype of PRIVEXEC as a modiﬁ-
cation to the Linux kernel that is performant, practical, and
that secures sensitive data against disclosure. We hope that
PRIVEXEC will pave the way for creating similar services
on other operating systems to enable private execution.

As future work, one avenue we plan to investigate is
whether cooperative applications can beneﬁt from a ﬁne-
grained private execution API that would allow for more
control over the degree or types of privacy an application
would like to provide.

ACKNOWLEDGMENT

REFERENCES

[1] Aufs. http://aufs.sourceforge.net/.

[2] BitLocker.

http://windows.microsoft.com/en-US/windows7/

products/features/bitlocker.

[3] Bonnie++. http://www.coker.com.au/bonnie++/.

[4] dm-crypt.
DMCrypt.

http://code.google.com/p/cryptsetup/wiki/

[5] eCryptfs. https://launchpad.net/ecryptfs.

[6] EncFS. www.arg0.net/encfs.

[7] Overlayfs. http://git.kernel.org/?p=linux/kernel/git/mszeredi/

vfs.git.

[8] Selenium – Web Browser Automation. http://seleniumhq.org/.

[9] shred(1) - Linux Man page. http://www.gnu.org/software/

coreutils/.

[10] Unionfs. http://unionfs.ﬁlesystems.org/.

[11] xdotool.

http://www.semicomplete.com/projects/xdotool/

xdotool.xhtml.

[12] G. Aggarwal, E. Bursztein, C. Jackson, and D. Boneh. An
Analysis of Private Browsing Modes in Modern Browsers. In
Proceedings of the USENIX Security Symposium, Berkeley,
CA, USA, 2010. USENIX Association.

[13] A. Alsaid and D. Martin. Detecting Web Bugs with Bugnosis:
Privacy Advocacy through Education. In Proceedings of the
International Conference on Privacy Enhancing Technolo-
gies, Berlin, Germany, 2003. Springer-Verlag.

[14] S. Bauer and N. B. Priyantha. Secure Data Deletion for
Linux File Systems. In Proceedings of the USENIX Security
Symposium, Berkeley, CA, USA, 2001. USENIX Association.

[15] M. Blaze. A Cryptographic File System for UNIX.

In
Proceedings of the ACM Conference on Computer and Com-
munications Security, New York, NY, USA, 1993. ACM.

[16] D. Boneh and R. J. Lipton. A Revocable Backup System. In
Proceedings of the USENIX Security Symposium, Berkeley,
CA, USA, 1996. USENIX Association.

[17] K. Borders, E. V. Weele, B. Lau, and A. Prakash. Protecting
Conﬁdential Data on Personal Computers with Storage Cap-
sules.
In Proceedings of the USENIX Security Symposium,
Berkeley, CA, USA, 2009. USENIX Association.

We would like to thank our shepherd Helen J. Wang
and the anonymous reviewers for their precious time and
helpful comments. This work was partially supported by
ONR grant N000141310102 and Secure Business Austria.
Engin Kirda also thanks Sy and Laurie Sternberg for their
generous support.

[18] J. Chow, B. Pfaff, T. Garﬁnkel, and M. Rosenblum. Shredding
Your Garbage: Reducing Data Lifetime through Secure Deal-
location. In Proceedings of the USENIX Security Symposium,
Berkeley, CA, USA, 2005. USENIX Association.

[19] A. Clover. CSS visited pages disclosure. http://seclists.org/

bugtraq/2002/Feb/271, 2002.

219

[20] A. M. Dunn, M. Z. Lee, S. Jana, S. Kim, M. Silberstein,
Y. Xu, V. Shmatikov, and E. Witchel. Eternal Sunshine of
the Spotless Machine: Protecting Privacy with Ephemeral
Channels.
In Proceedings of the USENIX Conference on
Operating Systems Design and Implementation, Berkeley,
CA, USA, 2012. USENIX Association.

[21] E. W. Felten and M. A. Schneider. Timing Attacks on Web
Privacy. In Proceedings of the ACM Conference on Computer
and Communications Security, New York, NY, USA, 2000.
ACM.

[22] J. A. Halderman, S. D. Schoen, N. Heninger, W. Clarkson,
W. Paul, J. A. Calandrino, A. J. Feldman, J. Appelbaum, and
E. W. Felten. Lest We Remember: Cold Boot Attacks on
Encryption Keys.
In Proceedings of the USENIX Security
Symposium, Berkeley, CA, USA, 2008. USENIX Association.

[23] F. Hsu, H. Chen, T. Ristenpart, J. Li, and Z. Su. Back to
the Future: A Framework for Automatic Malware Removal
and System Repair. In Proceedings of the Annual Computer
Security Applications Conference, 2006.

[24] C. Jackson, A. Bortz, D. Boneh, and J. C. Mitchell. Protecting
Browser State from Web Privacy Attacks. In Proceedings of
the International World Wide Web Conference, New York,
NY, USA, 2006. ACM.

[25] S. Jain, F. Shaﬁque, V. Djeric, and A. Goel. Application-Level
Isolation and Recovery with Solitude. In Proceedings of the
European Conference on Computer Systems, New York, NY,
USA, 2008. ACM.

[26] M. Jakobsson and S. Stamm. Invasive Browser Snifﬁng and
Countermeasures. In Proceedings of the International World
Wide Web Conference, New York, NY, USA, 2006. ACM.

[27] S. Jana, D. E. Porter, and V. Shmatikov. TxBox: Building
Secure, Efﬁcient Sandboxes with System Transactions.
In
Proceedings of the IEEE Symposium on Security and Privacy,
Washington, DC, USA, 2011. IEEE Computer Society.

[28] A. Janc and L. Olejnik. Web Browser History Detection
as a Real-world Privacy Threat.
the
European Conference on Research in Computer Security,
Berlin, Germany, 2010. Springer-Verlag.

In Proceedings of

[29] N. Joukov, H. Papaxenopoulos, and E. Zadok. Secure Dele-
tion Myths, Issues, and Solutions. In Proceedings of the ACM
Workshop on Storage Security and Survivability, New York,
NY, USA, 2006. ACM.

[30] Z. Liang, W. Sun, V. N. Venkatakrishnan, and R. Sekar.
Alcatraz: An Isolated Environment for Experimenting with
Untrusted Software. ACM Transactions on Information and
System Security, 12(3):14:1–14:37, 2009.

[31] R. Perlman.

The Ephemerizer: Making Data Disappear.
Technical report, Sun Microsystems, Inc., Mountain View,
CA, USA, 2005.

[32] P. A. H. Peterson. Cryptkeeper: Improving Security with
Encrypted RAM. In Proceedings of the IEEE International
Conference on Technologies for Homeland Security, Waltham,
MA, USA, 2010.

[33] Z. N. J. Peterson, R. Burns, J. Herring, A. Stubbleﬁeld,
and A. D. Rubin. Secure Deletion for a Versioning File
System.
the USENIX Conference on
File and Storage Technologies, Berkeley, CA, USA, 2005.
USENIX Association.

In Proceedings of

[34] N. Provos. Encrypting Virtual Memory.

In Proceedings of
the USENIX Security Symposium, Berkeley, CA, USA, 2000.
USENIX Association.

[35] J. Reardon, S. Capkun, and D. Basin. Data Node Encrypted
File System: Efﬁcient Secure Deletion for Flash Memory. In
Proceedings of the USENIX Security Symposium, Berkeley,
CA, USA, 2012. USENIX Association.

[36] H. Said, A. N. Mutawa, A. A. Ibtesam, and M. Guimaraes.
Forensic Analysis of Private Browsing Artifacts.
In Pro-
ceedings of the International Conference on Innovations in
Information Technology, Abu Dhabi, United Arab Emirates,
2011.

[37] U. Shankar and C. Karlof. Doppelganger: Better Browser
Privacy Without the Bother.
In Proceedings of the ACM
Conference on Computer and Communications Security, New
York, NY, USA, 2006. ACM.

[38] G. E. Suh, D. Clarke, B. Gassend, M. van Dijk, and
S. Devadas. AEGIS: Architecture for Tamper-Evident and
Tamper-Resistant Processing. In Proceedings of the Annual
International Conference on Supercomputing, New York, NY,
USA, 2003. ACM.

[39] Y. Tang, P. Ames, S. Bhamidipati, A. Bijlani, R. Geambasu,
and N. Sarda. CleanOS: Limiting Mobile Data Exposure with
Idle Eviction.
In Proceedings of the USENIX Conference
on Operating Systems Design and Implementation, Berkeley,
CA, USA, 2012. USENIX Association.

[40] D. L. C. Thekkath, M. Mitchell, P. Lincoln, D. Boneh,
J. Mitchell, and M. Horowitz. Architectural Support for
Copy and Tamper Resistant Software.
In Proceedings of
the International Conference on Architectural Support for
Programming Languages and Operating Systems, New York,
NY, USA, 2000. ACM.

[41] E. Zadok, I. Badulescu, and A. Shender. Cryptfs: A Stackable
Technical report,
Vnode Level Encryption File System.
Computer Science Department, Columbia University, 1998.

220

