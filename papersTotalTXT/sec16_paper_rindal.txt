Faster Malicious 2-Party Secure Computation  

with Online/Offline Dual Execution

Peter Rindal and Mike Rosulek, Oregon State University

 https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/rindal

This paper is included in the Proceedings of the 25th USENIX Security SymposiumAugust 10–12, 2016 • Austin, TXISBN 978-1-931971-32-4Open access to the Proceedings of the 25th USENIX Security Symposium is sponsored by USENIX Faster Malicious 2-party Secure Computation

with Online/Ofﬂine Dual Execution

Peter Rindal∗

Oregon State University

Mike Rosulek∗

Oregon State University

Abstract

We describe a highly optimized protocol for general-
purpose secure two-party computation (2PC) in the pres-
ence of malicious adversaries. Our starting point is a pro-
tocol of Kolesnikov et al. (TCC 2015). We adapt that
protocol to the online/ofﬂine setting, where two parties
repeatedly evaluate the same function (on possibly dif-
ferent inputs each time) and perform as much of the com-
putation as possible in an ofﬂine preprocessing phase be-
fore their inputs are known. Along the way we develop
several signiﬁcant simpliﬁcations and optimizations to
the protocol.

We have implemented a prototype of our protocol and
report on its performance. When two parties on Ama-
zon servers in the same region use our implementation to
securely evaluate the AES circuit 1024 times, the amor-
tized cost per evaluation is 5.1ms ofﬂine + 1.3ms online.
The total ofﬂine+online cost of our protocol is in fact
less than the online cost of any reported protocol with
malicious security. For comparison, our protocol’s clos-
est competitor (Lindell & Riva, CCS 2015) uses 74ms
ofﬂine + 7ms online in an identical setup.

Our protocol can be further tuned to trade performance
for leakage. As an example, the performance in the
above scenario improves to 2.4ms ofﬂine + 1.0ms online
if we allow an adversary to learn a single bit about the
honest party’s input with probability 2−20 (but not vio-
late any other security property, e.g. correctness).
1
Secure two-party computation (2PC) allows mutually
distrusting parties to perform a computation on their
combined inputs, while revealing only the result. 2PC
was conceived in a seminal paper by Yao [34] and
shown to be feasible in principle using a construction
now known as garbled circuits. Later,
the Fairplay

Introduction

∗Supported by NSF award 1149647. The ﬁrst author is also sup-

ported by an ARCS foundation fellowship.

project [24] was the ﬁrst implementation of Yao’s proto-
col, which inspired interest in the practical performance
of 2PC.
1.1 Cut & Choose, Online/Ofﬂine Setting
The leading technique to secure Yao’s protocol against
malicious adversaries is known as cut-and-choose. The
idea is to have the sender generate many garbled circuits.
The receiver will choose a random subset of these to
be checked for correctness.
If all checked circuits are
found to be correct, then the receiver has some conﬁ-
dence about the unopened circuits, which can be evalu-
ated.

The cost of the cut-and-choose technique is therefore
tied to the number of garbled circuits that are generated.
To restrict a malicious adversary to a 2−s chance of vi-
olating security, initial cut-and-choose mechanisms re-
quired approximately 17s circuits [20]. This overhead
was later reduced to 3s circuits [21, 31, 32] and then s
circuits [19].

Suppose two parties wish to perform N secure com-
putations of the same function f (on possibly differ-
ent inputs each time), and are willing to do ofﬂine pre-
processing (which does not depend on the inputs).
In
this online/ofﬂine setting, far fewer garbled circuits are
needed per execution. The idea, due to [14, 22], is to
generate many garbled circuits (enough for all N execu-
tions) and perform a single cut-and-choose on them all.
Then each execution of f will evaluate a random subset
(typically called a bucket) of the unopened circuits. Be-
cause the unopened circuits are randomly assigned to ex-
ecutions, only O(s/logN) circuits are needed per bucket
to achieve security 2−s. Concretely, 4 circuits per bucket
sufﬁce for security 2−40 and N = 1024.
1.2 Dual-execution Paradigm
An alternative to cut-and-choose for malicious-secure
2PC is the dual-execution protocol of Mohassel &
Franklin [25], which requires only two garbled circuits.

USENIX Association  

25th USENIX Security Symposium  297

The idea is that two parties run two instances of Yao’s
protocol, with each party acting as sender in one instance
and receiver in the other. They then perform a reconcilia-
tion step in which their garbled outputs are securely com-
pared for equality. Intuitively, one of the garbled outputs
is guaranteed to be correct, so the reconciliation step al-
lows the honest party to check whether its garbled output
agrees with the correct one held by the adversary.

Unfortunately, the dual execution protocol allows an
adversary to learn an arbitrary bit about the honest party’s
input. Consider an adversary who instead of garbling
the function f , garbles a different function f (cid:31). Then the
output of the reconciliation step (secure equality test)
reveals whether f (x1,x2) = f (cid:31)(x1,x2). However, it can
be shown that the adversary can learn only a single bit,
and, importantly, cannot violate output correctness for
the honest party.
1.3 Reducing Leakage in Dual-execution
Kolesnikov et al. [16] proposed a combination of dual-
execution and cut-and-choose that reduces the probabil-
ity of a leaked bit. The idea is for each party to garble
and send s circuits instead of 1, and perform a cut-and-
choose to check each circuit with probability 1/2. Each
circuit should have the same garbled encoding for its out-
puts, so if both parties are honest, both should receive
just one candidate output.

However, a malicious party could cause the honest
party to obtain several candidate outputs. The approach
taken in [16] is to have the parties use private set inter-
section (PSI) to ﬁnd a common value among their sets
of reconciliation values. This allows the honest party to
identify which of its candidate outputs is the correct one.
In Section 4 we discuss in more detail the security of-
fered by this protocol. Brieﬂy, an adversary cannot vi-
olate output correctness for the honest party, and learns
only a single bit about the honest party’s input with prob-
ability at most 1/2s (which happens only when the hon-
est part doesn’t evaluate any correct garbled circuit).
2 Overview of Our Results
We adapt the dual-execution protocol of [16] to the on-
line/ofﬂine setting. The result is the fastest protocol to
date for 2PC in the presence of malicious adversaries.
At a very high level, both parties exchange many gar-
bled circuits in the ofﬂine phase and perform a cut-and-
choose. In the online phase, each party evaluates a ran-
dom bucket of its counterpart’s circuits. The parties then
use the PSI-based reconciliation to check the outputs.
2.1 Technical Contributions
While the high-level idea is straight-forward, some non-
trivial technical changes are necessary to adapt [16] to
the online/ofﬂine setting while ensuring high perfor-
mance in practice.

In particular, an important part of any malicious-
secure protocol is to ensure that parties use the same
inputs in all garbled circuits. The method suggested in
[16] is incompatible with ofﬂine pre-processing, whereas
the method from [23] does not ensure consistency be-
tween circuits generated by different parties, which is
the case for dual-execution (both parties generate gar-
bled circuits). We develop a new method for input con-
sistency that is tailored speciﬁcally to the dual-execution
paradigm and that incurs less overhead than any existing
technique.

Implementation, Performance

In [16], the parties evaluate garbled circuits and then
use active-secure private set intersection (PSI) to recon-
cile their outputs. We improve the analysis of [16] and
show that it sufﬁces to use PSI that gives a somewhat
weaker level of security. Taking advantage of this, we
describe an extremely lightweight PSI protocol (a vari-
ant of one in [30]) that satisﬁes this weak level of security
while being round-optimal.
2.2
We implemented a C++ prototype of our protocol us-
ing state-of-the-art optimizations, including the garbled-
circuit construction of [35]; the OT-extension protocol
of [15] instantiated with the base OTs of [7]. The pro-
totype is heavily parallelized within both phases. Work
is divided amongst threads that concurrently generate &
evaluate circuits, allowing network throughput to be the
primary bottleneck. The result is an extremely fast 2PC
system. When securely evaluating the AES circuit on co-
located Amazon AWS instances, we achieve the lowest
amortized cost to date of 5.1ms ofﬂine + 1.3ms online
per execution.
2.3 Comparison to GC-based Protocols
There have been several implementations of garbled-
circuit-based 2PC protocols that achieve malicious secu-
rity [1, 12, 18, 23, 29, 31, 32]. Except for [23], none of
these protocols are in the online/ofﬂine settings so their
performance is naturally much lower (100-1000× slower
than online/ofﬂine protocols). Among them, the fastest
reported secure evaluation of AES is that of [12], which
was 0.46s exploiting consumer GPUs. Other protocols
have been described (but not implemented) that com-
bine cut-and-choose with the dual-execution paradigm to
achieve malicious security [13, 26]. The protocol of [13]
leaks more than one bit when the adversary successfully
cheats during cut-and-choose.

Our protocol is most closely related to that of [23],
which also achieves fast, active-secure 2PC in the on-
line/ofﬂine setting. [23] is an implementation of the pro-
tocol of [22], and we refer to the protocol and its imple-
mentation as “LR” in this section. Both the LR protocol
and ours are based on garbled circuits but use fundamen-
tally different approaches to achieveing malicious secu-

298  25th USENIX Security Symposium 

USENIX Association

2

LR [23]
Us (Async PSI)
Us (Sync PSI)

Input Labels Reconciliation
|x|(B + B(cid:30))κc

|x|B(cid:30)κc
B2κsκc
Bκs + B2κc

|x|Bκc

Figure 1: Asymptotic communication costs of the LR protocol
vs. ours (comparing online phases). B is the number of cir-
cuits in a bucket; B(cid:30) ≈ 3B is the number of auxiliary cheating-
recovery circuits in [23]; |x| is length of sender’s inputs; κs is
the statistical security parameter; κc is the computational secu-
rity parameter.

rity. For clarity, we now provide a list of major differ-
ences between the two protocols.

(1) LR uses a more traditional cut-and-choose mecha-
nism where one party acts as sender and the other as re-
ceiver & evaluator. Our protocol on the other hand uses a
dual-execution paradigm in which both parties play sym-
metric roles, so their costs are identical.

Since parties act as both sender and receiver, each
party performs more work than in the traditional cut-
and-choose paradigm. However, the symmetry of dual-
execution means that both parties are performing com-
putational work simultaneously, rather than idle waiting.
The increase in combined work does not signiﬁcantly af-
fect latency or throughput if the communication channel
is full-duplex.

(2) Our protocol can provide more ﬂexible security
guarantees; in particular, it may be used with smaller pa-
rameter choices. In more detail, let κs denote a statistical
security parameter, meaning that the protocol allows the
adversary to completely break security with probability
1/2κs. In the LR protocol, a failure of the cut-and-choose
step can violate all security properties, so the number of
garbled circuits is proportional to κs.

Our protocol has an additional parameter κb, where
the protocol leaks (only) a single bit to the adversary with
probability 1/2κb. In our protocol (as in [16]), the num-
ber of garbled circuits is proportional to κb. When instan-
tiated with κb = κs = 40, our protocol gives an equivalent
guarantee to the LR protocol with κs = 40. From this
baseline, our protocol allows either κs to be increased
(strictly improving the security guarantee without involv-
ing more garbled circuits) or κb to be decreased (trading
performance for a small chance of a single bit leaking).1
(3) Our online phase has superior asymptotic cost,
stemming from the differences in protocol paradigm —
see a summary in Figure 1. LR uses a cheating-recovery
phase, introduced in [19]: after evaluating the main cir-
cuits, the parties evaluate auxiliary circuits that allow the
receiver to learn the sender’s input if the receiver can

1For example, two parties might want to securely evaluate AES a
million times on the same secret-shared key each time, where the key
is not used for anything else. In that case, a 1/220 or 1/230 chance of
leaking a single bit about this key might be permissible.

“prove” that the sender was cheating. Our protocol uses
the PSI-based dual-execution reconciliation phase.

The important difference is that in the LR protocol,
the sender’s input is provided to both the main circuits
and auxiliary circuits. If there are B main garbled cir-
cuits in a bucket, then there are B(cid:30) ≈ 3B auxiliary cir-
cuits, and garbled inputs must be sent for all of them in
the online phase. Each individual garbled input is sent
by decommitting to an ofﬂine commitment, so it con-
tributes to communication as well as a call to a hash func-
tion. Furthermore, the cheating-recovery phase involves
decommitments to garbled outputs for the auxiliary cir-
cuits, which are again proprotional to the sender’s input
length.

In contrast, our protocol uses no auxiliary circuits so
has less garbled inputs to send (and less associated de-
commitments to check). Our reconciliation phase scales
only with B and is independent of the parties’ input size.
The overall effect is that our online phase involves sig-
niﬁcantly less communication and computation, with the
difference growing as the computations involve longer
inputs. With typical parameters B = 4 and κs = 40, our
reconciliation phase is cheaper whenever |x| ≥ 54 bits.
Even for the relatively small AES circuit, our protocol
sends roughly 10× less data in the online phase.
(4) LR’s online phase uses 4 rounds of interaction2 and
delivers output only to one party. If both parties require
output, their protocol must be modiﬁed to include an ad-
ditional round. Our online phase also delivers outputs to
both parties using either 5 or 6 rounds (depending on the
choice of PSI subprotocols). We conjecture that our pro-
tocol can be modiﬁed to use only 4 rounds, but leave that
question to follow-up work.

(5) Our implementation is more efﬁcient than LR. The
ofﬂine phase more effectively exploits parallelism and
LR is implemented using a mix of Java & C++. The
architecture of LR has a serial control ﬂow with com-
putationally heavy tasks performed in parallel using low
level C++ code. In contrast, our protocol implementation
is in C++ and fully parallelized with low level synchro-
nization primitives.
2.4 Comparison to Non-GC Protocols
Another paradigm for malicious security in the on-
line/ofﬂine setting is based not on garbled circuits but
arithmetic circuits and secret sharing. Notable proto-
cols and implementations falling into this paradigm in-
clude [8, 9, 10, 11, 27]. These protocols indeed have

2For our purposes, a round refers to both parties sending a message.
In other words, messages in the same round are allowed to be sent
simultaneously, and our implementation takes advantage of full-duplex
communication to reduce latency. We emphasize that synchronicity is
not required for our security analysis. The protocol is secure against
an adversary who waits to obtain the honest party’s message in round i
before sending its own round i message.

USENIX Association  

25th USENIX Security Symposium  299

3

lightweight online phases, and many instances can be
batched in parallel to achieve throughput comparable to
our protocol. However, all of these protocols have an on-
line phase whose number of rounds depends on the depth
of the circuit being evaluated. As a result, they suffer
from signiﬁcantly higher latency than the constant-round
protocols in the garbled circuit paradigm like ours. The
latest implementations of [9] can securely evaluate AES
with online latency 20ms [33]. Of special note is the im-
plementation of the [11] protocol reported in [10], which
achieves latency of only 6ms to evaluate AES. However,
the implementation is heavily optimized for the special
case of computing AES, and it is not clear how applica-
ble their techniques are for general-purpose MPC. In any
case, no protocol has reported online latency for AES
that is less than our protocol’s total ofﬂine+online cost.
The above protocols based on secret-sharing also have
signiﬁcantly more expensive ofﬂine phases. Not all im-
plementations report the cost of their ofﬂine phases, but
the latest implementations of the [9] protocol require 156
seconds of ofﬂine time for securely computing AES [33];
many orders of magnitude more than ours. We note that
the protocols in the secret-sharing paradigm have an of-
ﬂine phase which does not depend on the function that
will be evalauted, whereas ours does.
3 Preliminaries
Secure computation. We use the standard notion of
universally composable (UC) security [6] for 2-party
computation. Brieﬂy, the protocol is secure if for every
adversary attacking the protocol, there is a straight-line
simulator attacking the ideal functionality that achieves
the same effect. We assume the reader is familiar with
the details.

We deﬁne the ideal functionality Fmulti-sfe that we
achieve in Figure 2. The functionality allows parties to
evaluate the function f , N times. Adversaries have the
power to delay (perhaps indeﬁnitely) the honest party’s
output, which is typical in the setting of malicious secu-
rity. In other words, the functionality does not provide
output fairness.

Furthermore, the functionality occasionally allows the
adversary to learn an arbitrary additional bit about the in-
puts. This leakage happens according to the distribution
L chosen by the adversary at setup time. The probability
of a leaked bit in any particular evaluation of f is guar-
anteed to be at most ε. Further, the leakage is “risky” in
the sense that the honest party detects cheating when the
leaked bit is zero.

Building blocks.
In Figures 10 & 11 we deﬁne obliv-
ious transfer (OT) and commitment functionalities that
are used in the protocol.
In the random oracle model,
where H is the random oracle, a party can commit to v by
choosing random r ← {0,1}κc and sending c = H(r(cid:28)v).

We use and adapt the Garbled Circuit notation and
terminology of [5]; for a formal treatment, consult that
paper.
In Appendix A we deﬁne the syntax and secu-
rity requirements, highlighting the differences we adopt
compared to [5].
4 The Dual Execution Paradigm
We now give a high-level outline of
the (non-
online/ofﬂine) 2PC protocol paradigm of [16], which is
the starting point for our protocol. The protocol makes
use of a two-phase PSI subprotocol. In the ﬁrst phase,
both parties become committed to their PSI inputs; in
the second phase, the PSI output is revealed. This com-
n,(cid:30)
psi functionality in
ponent is modeled in terms of the F
Figure 12.

Assume the parties agree on a function f to be eval-
uated on their inputs. The protocol is symmetric with
respect to Alice and Bob, and for simplicity we describe
only Alice’s behavior.
(1) Alice generates κb garbled circuits computing f , us-
ing a common garbled output encoding for all of
them.

(2) Alice announces a random subset of Bob’s circuits
to open. However, the actual checking of the cir-
cuits is delayed until later in the protocol.

(3) Alice uses OT to receive garbled inputs for the cir-
cuits generated by Bob, as in Yao’s protocol. Alice
sends the garbled circuits she generated, along with
her own garbled input for these circuits.

(4) Alice evaluates the garbled circuits received from
Bob. If Bob is honest, then all of his circuits use
the same garbled output encoding and Alice will re-
ceive the same garbled output from each one. But in
the general case, Alice might obtain several incon-
sistent garbled outputs.

(5) Assume that Alice can decode the garbled outputs
to obtain the logical circuit output. For each candi-
date circuit output y with garbled encoding Y b
y (b for
a garbled output under Bob’s encoding), let Y a
y de-
note the encoding of y under Alice’s garbled output
encoding (which Alice can compute). Interpreting
Y a
y and Y b
y as sets of individual wire labels, let Ry
be the XOR of all items in Y a
y , which we write
as Ry =(cid:31)[Y a
y ] and which we call the reconcil-
iation value for y. Alice sends the set of all {Ry}
values as input to a PSI instance.
(6) With the PSI inputs committed, the parties open and
check the circuits chosen in the cut-and-choose step.
They abort if any circuit is not correctly garbled, or
the circuits do not have consistent garbled output
encodings.

y ∪Y b

y ∪Y b

(7) The parties release the PSI output. Alice aborts if
the PSI output is not a singleton set. Otherwise, if

4

300  25th USENIX Security Symposium 

USENIX Association

Setup stage: On common input (SETUP, f ,N,ε) from both parties, where f is a boolean circuit:
• If neither party is corrupt, set L = 0N. Otherwise, wait for input (CHEAT, L ) where L is a distribution over
{0,1}N ∪{⊥} with the property that for every i, PrL←L [Li = 1] ≤ ε. Sample L ← L using random coins χ
and give (CHEATRESULT, χ) to the adversary. If L = ⊥ then give output (CHEATING!) to the honest party
and stop responding.

• Send output (READY) to both parties. Initialize counter ctr = 1. Proceed to the execution stage.

Execution stage: Upon receiving inputs (INPUT,x1) from P1 and (INPUT,x2) from P2:

p = P(x1,x2) and give (LEAKRESULT, p) to the adversary.

• Compute z = f (x1,x2). If both parties are honest, give (OUTPUT,ctr,z) to both parties.
• If any party is corrupt, give (OUTPUT,ctr,z) to the adversary.
• If Lctr = 1, wait for a command (LEAK,P) from the adversary, where P is a boolean predicate. Compute
• If any party is corrupt, then on input (DELIVER) from the adversary, if p = 0 above, then give output
• If ctr = N then stop responding; otherwise set ctr = ctr + 1 and repeat the execution stage.

(CHEATING!) to the honest party, else give output (OUTPUT,ctr,z) to the honest party.

Figure 2: The (ε-leaking) secure function evaluation functionality Fmulti-sfe.

the output is {R∗} then Alice outputs the value y
such that R∗ = Ry.

4.1 Security Analysis and Other Details
Suppose Alice is corrupt and Bob is honest. We will ar-
gue that Alice learns nothing beyond the function output,
except that with probability 2−κb she learns a single bit
about Bob’s input.

Suppose Alice uses input x1 as input to the OTs, and
Bob has input x2. Since Bob’s circuits are honestly gen-
erated and use the same garbled output encoding, every
circuit evaluated by Alice leads to the same garbled out-
put Y b
y∗ that encodes logical value y∗ = f (x1,x2). Note
that by the authenticity property of the garbled circuits,
this is the only valid garbled output that Alice can pre-
dict.

Since Alice may generate malicious garbled circuits,
honest Bob may obtain several candidate outputs from
these circuits. Bob’s input to the PSI computation will
be a collection of reconciliation values, each of the form

Ry =(cid:31)[Y a

y ∪Y b
y ].

At the time of PSI input, none of Bob’s (honestly) gar-
bled circuits have been opened, so they retain their au-
thenticity property. Then Alice cannot predict any valid
reconciliation value except for this Ry∗. This implies that
the PSI output will be either {Ry∗} or /0. In particular,
Bob will either abort or output the correct output y∗. Fur-
thermore, the output of the PSI computation can be simu-
lated knowing only whether honest Bob has included Ry∗
in his PSI input.

The protocol includes a mechanism to ensure that Al-
ice uses the same x1 input for all of the garbled circuits.
Hence, if Bob evaluates at least one correctly generated
garbled circuit, it will give output y∗ and Bob will surely
include the Ry∗ reconciliation value in his PSI input. In
that case, the PSI output can be simulated as usual.

The probability the Alice manages to make Bob evalu-
ate no correctly generated garbled circuits is 2−κb — she
would have to completely predict Bob’s cut-and-choose
challenge to make all opened circuits correct and all eval-
uated circuits incorrect. But even in this event, the simu-
lator only needs to know whether f (cid:22)(x1,x2) = y∗ for any
of the f (cid:22) computed by Alice’s malicious garbled circuits.
This is only one bit of information about x2 which the
simulator can request from the ideal functionality.
4.2 Outline

for Online/Ofﬂine Dual-

Execution

Our high-level approach is to adapt the [16] protocol to
the online/ofﬂine setting. The idea is that the two par-
ties plan to securely evaluate the same function f , N
times, on possibly different inputs each time. In prepara-
tion they perform an ofﬂine pre-processing phase that de-
pends only on f and N, but not on the inputs. They gener-
ate many garbled circuits and perform a cut-and-choose
on all of them. Then the remaining circuits are assigned
randomly to buckets. Later, once inputs are known in the
online phase, one bucket’s worth of garbled circuits are
consumed for each evaluation of f .

Our protocol will leak a single bit about the honest
party’s input only when a bucket contains no “good”
circuit from the adversary (where “good” is the condi-
tion that is veriﬁed for opened circuits during cut-and-
choose). Following the lead of [23], we focus on choos-
ing the number of circuits so that the probability of such
an event in any particular bucket is 2−κb. We note that
the analysis of parameters in [14, 22] considers an over-
all cheating condition, i.e., that there exists a bucket that
has no “good” circuits, which leads to slightly different
numbers.

Lemma 1 ([23]). If the parties plan to perform N exe-

USENIX Association  

25th USENIX Security Symposium  301

5

cutions, using a bucket of B circuits for each execution

and a total of(cid:31)N ≥ NB garbled circuits generated for the

overall cut-and-choose, then the probability that a spe-
ciﬁc bucket contains no good circuit is at most:

Ofﬂine phase:
(1) Parties perform ofﬂine preprocessing for the OTs
that will be needed, and for the PSI subprotocol,
if appropriate.

max

.

(cid:27) (cid:31)N−t
NB−t(cid:26)
NB(cid:26) · (cid:27) t
B(cid:26)(cid:27)NB
B(cid:26)
(cid:27) (cid:31)N

t∈{B,...,NB}


Suppose the parties will perform N executions, us-
ing buckets of size B in the online phase, and wish for
2−κb probability of leakage. We can use the formula
to determine the smallest compatible (cid:31)N.
In the full
version we show all reasonable parameter settings for
κb ∈ {20,40,80} and N ∈ {8,16,32, . . . ,32768}.
By adapting [16] to the online/ofﬂine setting, we ob-
tain the generic protocol outlined in Figure 3. Even with
pre-processing, an online OT requires two rounds, one
of which can be combined with the direct sending of gar-
bled inputs. The protocol therefore requires three rounds
plus the number of rounds needed for the PSI subproto-
col (at least two).
4.3 Technicalities
We highlight which parts of the [16] protocol break down
in the online/ofﬂine setting and require technical modiﬁ-
cation:

Same garbled output encoding. In [16] each party is re-
quired to generate garbled circuits that have a common
output encoding. Their protocol includes a mechanism
to enforce this property. In our setting, we require each
bucket of circuits to have the same garbled output encod-
ing. But this is problematic because in our setting a gar-
bled circuit is generated before the parties know which
bucket it will be assigned to.

Our solution is to have the garbler provide for each
bucket a translation of the following form. The garbler
chooses a bucket-wide garbled output encoding; e.g., for
the ﬁrst output wire, he chooses wire labels W∗0 ,W∗1 en-
coding false and true, respectively. Then if W j
1 are
the output wire labels already chosen for the jth circuit
in this bucket, the garbler is supposed to provide trans-
lation values W j
v ⊕W∗v for v ∈ {0,1}. After evaluating,
the receiver will use these values to translate the garbled
input to this bucket-wide encoding that is used for PSI
reconciliation.

0 ,W j

Of course, a cheating party can provide invalid transla-
tion values. So we use step 3 of the online phase (Figure
3) to check them. In more detail, a sender must commit
in the ofﬂine phase to the output wire labels of every gar-
bled circuit. These will be checked if the circuit is chosen
in the cut-and-choose. In step 3 of the online phase, these
commitments are opened so that the receiver can check
the consistency of the translation values (i.e., whether

(2) Based on N and κb, the parties determine appro-

sion in Section 4.2. Each party generates and

priate parameters (cid:31)N, B according to the discus-
sends (cid:31)N garbled circuits, and chooses a random
subset of(cid:31)N − NB of their counterpart’s circuits to

be opened. The chosen circuits are opened and
parties abort if circuits are found to be generated
incorrectly.

(3) Each party randomly assigns their counterpart’s
circuits to buckets of size B. Each online execu-
tion will consume one bucket’s worth of circuits.

Online phase:
(1) Parties exchange garbled inputs: For one’s own
garbled circuits in the bucket, a party directly
sends the appropriate garbled inputs;
for the
counterpart’s garbled circuits, a party uses OT as
a receiver to obtain garbled inputs as in Yao’s pro-
tocol.

(2) Parties evaluate the garbled circuits and compute
the corresponding set of reconciliation values.
They commit their sets of reconciliation values as
inputs to a PSI computation.

(3) With the PSI inputs committed, the parties open
some checking information (see text in Section
4.3) and abort if it is found to be invalid.

(4) The parties release the PSI output and abort if the
output is /0. Otherwise, they output the plaintext
value whose reconciliation value is in the PSI out-
put.

Figure 3: High-level outline of the online/ofﬂine, dual-
execution protocol paradigm.

they map to a hash of the common bucket-wide encod-
ing provided during bucketing.). This step reveals all of
the bucket-wide encoding values, making it now easy for
an adversary to compute any reconciliation value. This
is why we employ a 2-phase PSI protocol, so that PSI
inputs are committed before these translation values are
checked.

Adaptive garbling. Standard security deﬁnitions for gar-
bled circuits require the evaluator to choose the input
before the garbled circuit is given. However, the entire
purpose of ofﬂine pre-processing is to generate & send
the garbled circuits before the inputs are known. This
requires the garbling scheme to satisfy an appropriate
adaptive security property, which is common to all works
in the online/ofﬂine setting [14, 22]. See Appendix A for
details.

302  25th USENIX Security Symposium 

USENIX Association

6

Input consistency. To achieve security against active ad-
versaries, GC-based protocols must ensure that parties
provide the same inputs to all circuits that are evaluated.
This is known as the problem of input consistency. The
protocol of [16] uses the input consistency mechanism of
shelat & Shen [32] which is unfortunately not compati-
ble with the online/ofﬂine setting. More details follow in
the next section.
5
In this section we describe a new, extremely lightweight
input-consistency technique that is tailored for the dual-
execution paradigm.
5.1 Consistency Between Alice’s & Bob’s

Input Consistency

Circuits

We start with the “classical” dual-execution scenario,
where Alice and Bob each generate one garbled circuit.
We describe how to force Alice to use the same input in
both of these garbled circuits (of course, the symmetric
steps are performed for Bob). The high-level idea is to
bind her behavior as OT receiver (when obtaining gar-
bled inputs for Bob’s circuits) to the commitments of her
garbled inputs in her own circuits.

It is well-known [2] that oblivious transfers on ran-
dom inputs can be performed ofﬂine, and later “deran-
domized” to OTs of chosen inputs. Suppose two parties
perform a random string OT ofﬂine, where Alice receives
c,mc and Bob receives m0,m1, for random c ∈ {0,1} and
m0,m1 ∈ {0,1}k. Later when the parties wish to per-
form an OT of chosen inputs c∗ and (m∗0,m∗1), Alice can
send d = c ⊕ c∗ and Bob can reply with m∗0 ⊕ md and
m∗1 ⊕ m1⊕d.
In the ofﬂine phase of our protocol, the parties perform
a random OT for each Alice-input wire of each circuit,
where Alice acts as the receiver. These will be later used
for Alice to pick up her garbled input for Bob’s circuit.
Let c denote the string denoting Alice’s random choice
bits for this collection of OTs.

Also in the ofﬂine phase, we will have Alice commit
to all of the possible garbled input labels for the circuits
that she generated. Suppose she commits to them in an
order determined by the bits of c; that is, the wire la-
bel commitments for the ﬁrst input wire are in the order
(false,true) if the ﬁrst bit of c is 0 and (true,false) other-
wise.

In the online phase with input x, Alice sends the OT
“derandomized” message d = x⊕ c. She also sends her
garbled inputs for the circuits she generated by opening
the commitments indexed by d; that is, she opens the
ﬁrst or second wire label of the ith pair, depending on
whether di = 0 or di = 1, respectively. Bob will abort if
Alice does not open the correct commitments.

Alice’s effective OT input is x = d ⊕ c, so she picks

up garbled input corresponding to x. If Alice did indeed
commit to her garbled inputs arranged according to c,
then she opens the commitments whose truth values are
also x = d ⊕ c. More formally,
Ofﬂine: Alice garbles the labels A0,A1 and Bob
garbles B0,B1 for Alice’s input. Alice receives OT
message mc and Bob holds m0,m1. Alice sends
(COMMIT, (sid,i),Ai⊕c) to Fcom for i ∈ {0,1}.
Online: Alice send d = c⊕ x to Bob and (OPEN, (sid,
d)) to Fcom. Bob receives (OPEN, (sid,d),Ax) from
Fcom and sends (B0 ⊕ md,B1 ⊕ m1⊕d) to Alice who
computes Bx = mc ⊕ (Bc⊕d ⊕ mc).
Figure 4: Input consistency on a single bit of Alice’s input for
“classic” dual-execution.

Looking ahead, we will use cut-and-choose to guar-
antee that there is at least one circuit for which Alice’s
garbled input commitments are correct in this way.
5.2 Aggregating Several OTs
In our protocol, both parties evaluate a bucket of several
circuits. Within the bucket, each of Alice’s circuits is
paired with one of Bob’s, as above. However, this im-
plies that Alice uses separate OTs to pick up her garbled
inputs in each of Bob’s circuits. To address this, we ag-
gregating several OTs together to form a single OT.

Suppose Alice & Bob have performed two random
string OTs, with Alice receiving c,c(cid:26),mc,m(cid:26)c(cid:26) and Bob re-
ceiving m0,m1,m(cid:26)0,m(cid:26)1, for random c,c(cid:26) ∈ {0,1}. Sup-
pose further that Alice sends δ = c⊕ c(cid:26) to Bob in an of-
ﬂine phase. To aggregate these two random OTs into
a single chosen-input OT with inputs c∗,m∗0,m∗1, Alice
can send d = c⊕ c∗, and Bob can reply with m∗0 ⊕ (md ⊕
m(cid:26)d⊕δ ) and m∗1 ⊕ (m1⊕d ⊕ m(cid:26)1⊕d⊕δ ).
The idea extends to aggregate any number B of dif-
ferent random OTs into a single one, with Alice sending
B− 1 different δ difference values. In our protocol, we
aggregate in this way the OTs for the same wire across
different circuits. Intuitively, Alice either receives wire
labels for the same value on each of these wires (by re-
porting correct δ values), or else she receives nothing for
this wire on any circuit.
5.3 Combining Everything with Cut-and-

Choose

Now consider a bucket of B circuits. In the ofﬂine phase
Alice acts as receiver in many random OTs, one collec-
tion of them for each of Bob’s circuits. Let c j be her
(string of) choice bits for the OTs associated with the jth
circuit. Alice is then supposed to commit to the garbled
inputs of her jth circuit arranged according to c j. Bob
will check this property for all circuits that are opened
during the cut-and-choose phase by Alice showing the

USENIX Association  

25th USENIX Security Symposium  303

7

corresponding OT messages.3 Hence with probability at
least 1 − 2−κb, at least one circuit in any given bucket
has this property. Alice also reports aggregation values
δ j = c1 ⊕ c j for these OTs.
In the online phase Alice chooses her input x and sends
d1 = c1 ⊕ x as the OT-derandomization message. This is
equivalent to Alice sending d j = δ j ⊕ d1 as the message
to derandomize the jth OTs. To send her garbled input
for the jth circuit, Alice is required to open her commit-
ments indexed by d j.

If Alice lies in any of the aggregation strings, then
she will be missing at least one of the B-out-of-B secret
shares which mask her possible inputs. Intuitively, Al-
ice’s two strategies are either to provide honest aggrega-
tion strings or not obtain any garbled inputs in the po-
sition that she lied. In the latter case, the simulator can
choose an arbitrary input for Alice in that position.

If we then consider the likely case where Bob’s jth
circuit is “good” and Alice provided honest aggregation
strings, then Alice will have decommitted to inputs for
the jth circuit that are consistent with her effective OT in-
put x∗1. From the discussion in Section 4.1, this is enough
to guarantee that the reconciliation phase leaks nothing.
Even if there are no “good” circuits in the bucket
(which happens with probability 1/2κb), it is still the
case that Alice learns no more than if she had received
consistent garbled input x∗1 for all of Bob’s circuits. So
the reconciliation phase can be simulated knowing only
whether Bob evaluates any circuit resulting in f (x∗1,x2).
This is a single bit of information about Bob’s input x2.
6 Selective Failure Attacks
In the garbled circuit paradigm, suppose Alice is acting
as evaluator of some garbled circuits. She uses OT to
pick up the wire labels corresponding to her input. A
corrupt Bob could provide incorrect inputs to these OTs,
so that (for instance) Alice picks up an invalid garbled
input if and only if the ﬁrst bit of her input is 0. By ob-
serving whether the evaluator aborts (or produces other-
wise unexpected behavior), Bob can deduce the ﬁrst bit
of Alice’s input. This kind of attack, where the adversary
causes the honest party to abort/fail with probability de-
pending on its private input is called a selective failure
attack.

A common way to prevent selective failure is to use

what is called a k-probe-resistant input encoding:
Deﬁnition 2 ([20, 32]). Matrix M ∈ {0,1}(cid:29)×n is called k-
probe resistant if for any L ⊆ {1,2, ...,n}, the Hamming
distance of(cid:31)i∈L Mi is at least k, where Mi denotes the
ith row vector of M.

3In fact, since the OT messages are long random strings, Alice can
prove that she had particular choice bits in many OTs by simply report-
ing the XOR of all of the corresponding OT messages.

The idea is for Alice to choose a random encoding ˜x1
of her logical input x1 satisfying M ˜x1 = x1. Then the par-
ties evaluate the function f (cid:23)( ˜x1,x2) = f (M ˜x1,x2). This
additional computation of M ˜x1 involves only XOR op-
erations, so it does not increase the garbled circuit size
when using the Free-XOR optimization [17] (it does in-
crease the number OTs needed).

Alice will now use ˜x1 as her choice bits to the OTs.
The adversary can probe any number of bits of ˜x1, by
inserting invalid inputs to the OT in those positions, and
seeing whether the other party aborts. For each position
probed, the adversary incurs a 1/2 probability of being
caught.4

The property of k-probe-resistance implies that prob-
ing k bits of the physical input ˜x1 leaks no information
about the logical input M ˜x1. However, probing k bits
incurs a 1 − 2−k probability of being caught. Hence,
our protocol requires a matrix that is κs-probe resistant,
where κs is the statistical security parameter. We refer
the reader to [23] for the construction details of k-probe
resistant matrices and their parameters.
6.1 Ofﬂining the k-probe computations
Using k-probe-resistant encodings, the encoded input ˜x1
is signiﬁcantly longer than the logical input x1. While
the computation of M ˜x1 within the garbled circuit can
involve no cryptographic operations (using Free-XOR),
it still involves a quadratic number of XOR operations.

Lindell & Riva [22] suggest a technique that moves
these computations associated with k-probe-resistant en-
codings to the ofﬂine phase. The parties will compute the
related function f (cid:23)( ˆx1,c,x2) = f ( ˆx1 ⊕ Mc,x2). In the of-
ﬂine phase, Alice will use OT to obtain wire labels for a
random string c. She can also begin to partially evaluate
the garbled circuit, computing wire labels for the value
Mc.

In the online phase, Alice announces ˆx1 = x1 ⊕ Mc
where x1 is her logical input. Then Bob directly sends
the garbled inputs corresponding to ˆx1. This introduces
an asymmetry into our input consistency technique. The
most obvious solution to maintain compatibility is to
always evaluate circuits of the form f (cid:23)( ˆx1,c1, ˆx2,c2) =
f ( ˆx1⊕ Mc1, ˆx2⊕ Mc2), so that Alice uses the same phys-
ical input (c1, ˆx1) in both hers and Bob’s circuits. How-
ever, we would prefer to let Alice use logical input x1
rather than its (signiﬁcantly longer) k-probe-encoded in-
put, to reduce the concrete overhead. It turns out that we
can accommodate this by exploiting the Z2-linearity of
the encoding/decoding operation.

Consider a bucket of circuits {1, . . . ,B}. For the jth
4Technically, the sender will commit to all garbled inputs, and then
the OTs will be used to transfer the decommitment values. That way,
the receiver can abort immediately if an incorrect decommitment value
is received.

304  25th USENIX Security Symposium 

USENIX Association

8

circuit, Alice acts as receiver in a set of random OTs,
and receives random choice bits c j. The number of OTs
per circuit is the number of bits in a k-probe-resistant
encoding of Alice’s input.

For Alice’s jth circuit, she must commit to her garbled
inputs in the order given by the string Mc j (rather than
just c j as before). This condition will be checked by Bob
in the event that this circuit is opened during cut-and-
choose. To assemble a bucket, Alice reports aggregation
values δ j = c1⊕c j as before. Imagine Alice derandomiz-
ing these OTs by sending an all-zeroes derandomization
message. This corresponds to her accepting the random
c1 as her choice bits. (Of course, an all-zeroes message
need not be actually sent.) Bob responds and uses the ag-
gregated OTs to send Alice the garbled inputs for c1 for
all of his garbled circuits (indeed, even in the jth circuit
Alice receives garbled inputs corresponding to c1).

In the online phase, Alice decides her logical input x1,
and she sends ˆx1 = Mc1 ⊕ x1. This value derandomizes
the ofﬂine k-probe-resistant encoding. Then in her own
jth circuit, Alice must open the garbled input commit-
ments indexed by the (public) string ˆx1 ⊕ Mδ j.
To see why this solution works, suppose that Alice’s
jth circuit is “good” (i.e., garbled correctly and input
commitments arranged by Mc j). As before, deﬁne her
effective OT input to the jth OTs as c∗ = c j ⊕ δ j (which
should be c1 if Alice did not lie about δ j). Even if Alice
lied about the δ values she surely learns no more than she
would have learned by being truthful about the δ values
and using effective input c∗ in all OTs. Hence, we can
imagine that she uses logical input x∗1 = ˆx1 ⊕ Mc∗ in all
of Bob’s garbled circuit.
Alice is required to open garbled inputs indexed by
ˆx1 ⊕ Mδ j = ˆx1 ⊕ M(c∗ ⊕ c j) =x ∗1 ⊕ Mc j. These are ex-
actly the garbled inputs corresponding to logical input x∗1,
since the commitments were arranged according to Mc j.
We see that Bob evaluates at least one correctly garbled
circuit with Alice using input x∗1, which is all that is re-
quired for weak input consistency.
7 Optimizing PSI Reconciliation
7.1 Weaker security.
Our main insight is that our PSI reconciliation step does
not require a fully (UC) secure PSI protocol. Instead, a
weaker security property sufﬁces. Recall that the ﬁnal
steps of the [16] protocol proceed as follows:
• Alice & Bob commit to their PSI inputs.
• The garbled-output
• The parties either abort or release the PSI output.

translations are opened and

For simplicity, assume for now that only one party re-
ceives the ﬁnal PSI output. We will address two-sided
output later.

checked.

Suppose Alice is corrupt and Bob is honest. Following
from the discussion of security in Section 4, Bob will use
as PSI input a collection of valid reconciliation values.
At the time Alice provides her PSI inputs, the authen-
ticity property of the garling scheme is in effect. This
means that Alice can predict a valid reconciliation value
only for the “correct” output y∗. All other valid recon-
ciliation values that might be part of Bob’s PSI input are
unpredictable.

Below we formalize a weak notion of security for in-

put distributions of this form:
Deﬁnition 3. Let Π be a two-phase protocol for set in-
n,(cid:30)
psi , Figure 12). We say that Π is weakly
tersection (F
malicious-secure if it achieves UC-security with respect
to environments that behave as follows:
(1) The adversary sends a value a∗ ∈{0,1}(cid:30) to the envi-
ronment along with the description of a distribution
D whose support is cardinality-(n − 1) subsets of
{0,1}(cid:30). We further require that D is unpredictable
in the sense that the procedure “A ← D; output a
uniformly chosen element of A” yields the uniform
distribution over {0,1}(cid:30) (the joint distribution of all
elements of A need not be uniform).
(2) The environment (privately) samples A ← D and
gives input A∪{a∗} to the honest party for the ﬁrst
phase of PSI.
(3) After the ﬁrst phase ﬁnishes (i.e., both parties’ in-
puts are committed), the environment gives the coins
used to sample A to the adversary.

(4) The environment then instructs the honest party to

perform the second phase of PSI to obtain output.

In this deﬁnition, the adversary knows only one value
in the honest party’s set, while all other values are essen-
tially uniform. We claim that when (cid:30) is large, the simu-
lator for this class of environments does not need to fully
extract the adversary’s PSI input! Rather, the following
are enough to ensure weakly-malicious security:

• The adversary is indeed committed to some (un-
known to the simulator) effective input during the
commit phase.

fective PSI input contains the special value a∗.

• The simulator can test whether the adversary’s ef-
With overwhelming probability, no effective input ele-
ment other than a∗ can contribute to the PSI output. Any
other values in the adversary’s effective input can simply
be ignored; they do not need to be extracted.

For technical reasons and convenience in the proof, we
have the environment give the adversary the coins used
to sample A, but only after the PSI input phase.
7.2 PSZ protocol paradigm.
We now describe an inexpensive protocol paradigm for
PSI, due to Pinkas et al. [30]. Their protocol is proven

USENIX Association  

25th USENIX Security Symposium  305

9

secure only against passive adversaries. We later discuss
how to achieve weak malicous security.

The basic building block is a protocol for private
equality test (PEQT) based on OT. A beneﬁt of using
OT-based techniques is that the bulk of the effort in gen-
erating OTs can be done in the ofﬂine phase, again lead-
ing to a lightweight online phase for the resulting PSI
protocol.

Suppose a sender has input s and receiver has input
r, with r,s ∈ {0,1}n, where the receiver should learn
whether r = s (and nothing more). The PEQT protocol
requires n string OTs; in the ith one, the receiver uses
choice bit r[i] and the sender chooses random string in-
puts (mi
s[i], and
r[i], which is the

1). The sender ﬁnally sends S =(cid:31)i mi

0,mi

the receiver checks whether S =(cid:31)i mi

XOR of his OT outputs.

The PEQT can be extended to a private set mem-
bership test (PSMT), in which the sender has a set
{s1, . . . ,s t} of strings, and receiver learns whether r ∈
{s1, . . . ,s t}. We simply have the sender randomly
permute the s j values, compute for each one S j =
(cid:31)i F(mi
s j[i], j) and send {S1, . . . ,S t}, where F is a PRF.5
The receiver can check whether (cid:31)i F(mi
r[i], j) matches
S j for any j. Finally, we can achieve a PSI where the
receiver has strings {r1, . . . ,r t} by running independent
PSMTs of the form r j ∈ {s1, . . . ,s t} for each r j (in ran-
dom order).
The overhead of this approach is O(t2), and [30] de-
scribe ways to combine hashing with this basic PSI pro-
tocol to obtain asymptotically superior PSI protocols for
large sets. However, we are dealing with very small val-
ues of t (typically at most 5), so the concrete cost of this
simple protocol is very low.

To make the PSI protocol two-phase, we run the OTs
and commit to the S values in the input-committing
phase. Then the output phase consists simply of the
sender opening the commitments to S.
7.3 Achieving weakly-malicious security

and double-sided output.

We use the [30] protocol but instantiate it with malicious-
secure OTs. This leads to the standard notion of security
against an active receiver since the simulator can extract
the receiver’s input from its choice bits to the OTs.

However, the protocol does not achieve full security
against a malicious sender. In the simple PEQT building
block, the simulator cannot extract a malicious sender’s
input. Doing so would require inspecting S,{mi
b} and
determining a value s such that S =(cid:31)i mi
s[i]. Such an
s may not exist, and even if it did, the problem seems

5Simply XORing the mi

b values would reveal some linear dependen-
cies; applying a PRF renders all of the S j values independently random
except the ones for which r = s j.

closely related to a subset-sum problem.

However, if the simulator knows a candidate s∗, it can
certainly check whether the corrupt sender has sent the
corresponding S value. This is essentially the only prop-
erty required for weakly malicious security.

We note that a corrupt sender could use inconsistent
sets {s1, . . . ,s t} in the parallel PSMT instances. How-
ever, the simulator can still extract whether the candidate
s∗ was used in each of them. If the sender used s∗ in t(cid:27)
of the t subprotocols, then the simulator can send s∗ to
the ideal PSI functionality with probability t(cid:27)/t, which is
a sound simulation for weakly-malicious security.

Regarding double-sided output, it sufﬁces to simply
run two instances of the one-sided-output PSI protocol,
one in each direction, in parallel. Again, this way of
composing PSI protocols is not sound in general, but it is
sound for the special case of weakly-malicious security.
7.4 Trading computation for lower round

complexity.

Even when random OTs are pre-processed ofﬂine, the
PSI protocol as currently described requires two rounds
to commit to the outputs, and one round to release the
output. The two input-committing rounds are (appar-
ently) inherently sequential, stemming from the sequen-
tial nature of OT derandomization.

In terms of round complexity, these two PSI rounds
are a bottleneck within the overall dual-execution pro-
tocol. We now describe a variant of the PSI protocol
in which the two input-committing messages are asyn-
chronous and can be sent simultaneously. The modi-
ﬁed protocol involves (a nontrivial amount of) additional
computation but reduces the number of rounds in the
overall 2PC online phase by one. This tradeoff does not
always reduce the overall latency of the 2PC online phase
— only sometimes, depending on the number of garbled
circuits being evaluated and the network latency. The
speciﬁc break-even points are discussed in Section 9.

0,mi

In our PEQT protocol above, the two parties have pre-
processed random OTs, with choice bits c and random
strings mi
1. To commit to his PSI input, the receiver’s
ﬁrst message is d = c⊕ r, to which the sender responds
with S =(cid:31)i mi
d[i]⊕s[i].
Consider randomizing the terms of this summation as
S =(cid:31)i[mi
d[i]⊕s[i] ⊕ zi] where zi are random subject to
(cid:31)i zi = 0.
Importantly, (1) each term in this sum de-
pends only on a single bit of d; (2) revealing all terms in
the sum reveals no more than S itself. We let the sender
commit to all the potential terms of this sum and reveal
them individually in response to d. In more detail, the
sender commits to the following values (in this order):

((cid:28)) [m1
[m1

s[1] ⊕ z1]
s[1]⊕1 ⊕ z1]

[m2
[m2

s[2] ⊕ z2]
s[2]⊕1 ⊕ z2]

···
···

[mn
[mn

s[n] ⊕ zn]
s[n]⊕1 ⊕ zn]

306  25th USENIX Security Symposium 

USENIX Association

10

dexed by d to see whether their XOR is(cid:31)i mi

Importantly, these commitments can be made before d is
known. In response to the message d from the receiver,
the sender is expected to release the output by opening
the commitments indexed by the bits of d. The sender
will open the commitments {mi
d[i]⊕s[i] ⊕ zi}; the receiver
will compute their XOR S and proceed as before.
The simulator for a corrupt sender simulates a random
message d and then checks whether the sender has used
a candidate input s∗ by extracting the commitments in-
d[i]⊕s∗[i].6
We can further move the commitments to the ofﬂine
phase, since there are two commitments per bit of s per
PEQT. Observe that the commitments in ((cid:31)) are arranged
according to the bits of s, which are not known until the
online phase. Instead, in the ofﬂine phase the sender can
commit to these values arranged according to a random
string π. In the online phase, the sender commits to its
input s by sending s ⊕ π. Then in response to receiver
message d, the sender must open the commitments in-
dexed by the bits of d ⊕ (s⊕ π).
protocol, the sender commits to an array of F(mi
values for each j.
7.5 Final Protocols
For completeness, we provide formal descriptions of
the ﬁnal PSI protocols (synchronous 3-round and asyn-
chronous 2-round) in Figures 13 & 14.

When extending the asynchronous PEQT to a PSMT
b, j)⊕ z j
i

We defer the proof of their security to the full version.

Theorem 4. The protocols Πsync-psi and Πasync-psi de-
scribed in Figures 13 & 14 are weakly-malicious secure
(in the sense of Deﬁnition 3) when (cid:29) ≥ κs, the statistical
security parameter.

8 Protocol Details & Implementation
The full details of our protocol are given in Figure 15
and the c++ implementation may be found at https:
//github.com/osu-crypto/batchDualEx. The pro-
tocol uses three security parameters:
κb is chosen so that the protocol will leak a bit to the
adversary with probability at most 2−κb. This pa-
rameter controls the number of garbled circuits used
per execution.

κs is the statistical security parameter, used to deter-
mine the length of the reconciliation strings used as
PSI input (the PSI protocol scales with the length
of the PSI input values). The adversary can guess
an unknown reconciliation value with probability at
most 2−κs.

6Note: although we intend for the two parties’ messages to be sent
simultaneously, we must be able to simulate in the case that a corrupt
sender waits for incoming message d before sending its commitments.

κc is the computational security parameter, that con-
trols the key sizes for OTs, commitments and gar-
bled circuits.

In our evaluations we consider κc = 128, κs ∈ {40,80}
and κb ∈ {20,40,80}. In the full version we prove the
security of our protocol:

Implementation & Architecture

Theorem 5. Our protocol (Figure 15) securely realizes
the Fmulti-sfe functionality, in the presence of malicious
adversaries.
8.1
In the ofﬂine phase, the work is divided between p paral-
lel sets of 4 threads. Within each set, two threads gener-
ate OTs and two threads garble and receive circuits and
related commitments. Parallelizing OT generation and
circuit generation is key to our ofﬂine performance; we
ﬁnd that these two activities take roughly the same time.
We generate OTs using an optimized implementation
of the Keller et al. [15] protocol for OT extension. Start-
ing from 128 base OTs (computed using the protocol of
[28]), we ﬁrst run an OT extension to obtain 128· p OT
instances. We then distribute these instances to the p dif-
ferent thread-sets, and each thread-set uses its 128 OT
instances as base OTs to perform its own independent
OT extension.

We further modiﬁed the OT extension protocol to pro-
cess and ﬁnalize OT instances in blocks of 128 instances.
This has two advantages: First, OT messages can be
used by other threads in the ofﬂine phase as they are
generated. Second, OT extension involves CPU-bound
matrix transposition computations along with I/O-bound
communication, and this approach interlaces these oper-
ations.

The ofﬂine phase concludes by checking the circuits in
the cut-and-choose, bucketing the circuits, and exchang-
ing garbled inputs for the random k-probe-encoded in-
puts.

The online phase similarly uses threading to exploit
the inherently parallel nature of the protocol. Upon re-
ceiving input, a primary thread sends the other party
their input correction value as the ﬁrst protocol message.
This value is in turn given to B sub-threads (where B
is the bucket size) that transmit the appropriate wire la-
bels. Upon receiving the labels, the B threads (in par-
allel) each evaluate a circuit.Each of the B threads then
executes (in parallel) one of the set-membership PSI sub-
protocols. After the other party has committed to their
PSI inputs, the translation tables of each circuit is opened
and checked in parallel. The threads then obtain the in-
tersection and the corresponding output value.
8.2 Low-level Optimizations
We instantiate the garbled circuits using the state-of-the-
art half-gates construction of [35]. The implementation

USENIX Association  

25th USENIX Security Symposium  307

11

utilizes the hardware accelerated AES-ni instruction set
and uses ﬁxed-key AES as the gate-level cipher, as sug-
gested by [3]. Since circuit garbling and evaluation is the
major computation bottleneck, we have taken great care
to streamline and optimize the execution pipeline.

The protocol requires the bucket’s common output la-
bels to be random. Instead, we can optimize the online
phase choose these labels as the output of a hash at a ran-
dom seed value. The seed can then be sent instead of
sending all of the common output labels. From the seed
the other party regenerates the output labels and proceed
to validate the output commitments.
9 Performance Evaluation
We evaluated the prototype on Amazon AWS instances
c4.8xlarge (64GB RAM and 36 virtual 2.9 GHz
CPUs). We executed our prototype in two network set-
tings: a LAN conﬁguration with both parties in the same
AWS geographic region and 0.2 ms round-trip latency;
and a WAN conﬁguration with parties in different regions
and 75 ms round-trip latency.

We demonstrate the scalability of our implementation

by evaluating a range of circuits:

• The AES circuit takes a 128-bit key from one party
and a 128-bit block from another party and outputs
a 128-bit block to both. The circuit consists of 6800
AND gates and 26,816 XOR gates.

• The SHA256 circuit takes 512 bits from both par-
ties, XORs them together and returns the 256-bit
hash digest of the XOR’ed inputs. The circuit con-
sists of 90,825 AND gates and 145,287 XOR gates.
takes a 16-block
(2048-bit) input from one party and a 128-bit key
from the other party and returns the 128-bit result
of 16-round AES-CBC-MAC. The circuit consists
of 156,800 AND gates and 430,976 XOR gates.7

• The AES-CBC-MAC circuit

In all of our tests, we use system parameters derived
from Lemma 1. N denotes the number of executions, and
B denotes the bucket size (number of garbled circuits per
execution) and we use ∼ B online threads.
9.1 PSI protocol comparison
In Section 7 we describe two PSI protocols that can
be used in our 2PC protocol — a synchronous protocol
that uses three rounds total, and an asynchronous pro-
tocol that uses two rounds total (at higher communica-
tion cost). We now discuss the tradeoffs between these
two PSI protocols. A summary is given in Figure 5. For
small parameters in the LAN setting, the 2-round asyn-
chronous protocol is faster overall, but for larger param-
eters the 3-round synchronous protocol is faster. This is

7The circuit is not optimized; each call to AES recomputes the en-

tire key schedule.

PSI

κs

40

80

B
2
3
4
6
5
7
9

Async

Sync

Time
0.31
0.34
0.42
0.65
0.55
0.83
1.39

Size
2,580
5,790
10,280
32,100
23,100
62,860
103,860

Time
0.35
0.39
0.46
0.55
0.51
0.66
0.83

Size
138
303
532
1,182
850
1,638
2,682

Figure 5: The running time (ms) and online communication
size (bytes) of the two PSI protocols when executed with κs-bit
strings and input sets of size B.

κs = κb = 40

Circuit

[23]

This

LAN

AES

SHA256

N
32
128
1024
32
128
1024
32
128
1,024

32
128
1,024

Online
1.7
1.5
1.3
10.0
8.8
8.4
190
191
189
194
192
191
Figure 6: Amortized running times per execution (reported in
ms) for [23] and our prototype. We used bucket size B = 6,5,4
for N = 32,128,1024.

Ofﬂine
197
114
74
459
275
206
1,126
919
760
3,638
3,426
2,992

Ofﬂine
45
16
5.1
136
78
48
282
71
34
777
399
443

Online
12
10
7
50
40
33
163
164
160
290
256
207

WAN

AES

SHA256

due to the extra data sent by the 2-round protocol. Specif-
ically, the asynchronous protocol sends O(B2κsκc) bytes
while the synchronous one sends O(Bκs + B2κc). In the
remaining comparisons, we always use the PSI protocol
with lowest latency, according to Figure 5.
9.2 Comparison to the LR protocol
We compare our prototype to that of [23] with 40-bit se-
curity. That is, we use κb = κs = 40; both protocols have
identical security and use the same bucket size. We use
identical AWS instances and a similar number of threads
to those reported in [23].

Figure 6 shows the results of the comparison in the
LAN setting. It can be seen that our online times are 5
to 7 times faster and our ofﬂine times are 4 to 15 times
faster. Indeed, for N = 1024 our total (online plus ofﬂine)
time is less than the online time of [23].

In the WAN setting with small circuits such as AES
where the input size is minimal we see [23] achieve faster
online times. Their protocol has one fewer round than
ours protocol, which contributes 38ms to the difference
in performance. However, for the larger SHA256 cir-
cuit our implementation outperforms that of [23] by 16
to 100ms per execution and we achieve a much more ef-

308  25th USENIX Security Symposium 

USENIX Association

12

Circuit

AES

SHA-256

2048

CBC-MAC

N
32
128
1,024

32
128
1,024

32
128
1,024

κb = κs = 80

Storage Ofﬂine Online
2.3
2.1
1.8
15.7
12.3
11.4
22.7
18.1
15.8

0.21
0.88
6.8
6.8
8.7
62.1
3.8
15.4
109.5

69
25
16
234
190
131
621
450
378

κb = κs = 40

Storage Ofﬂine Online
1.7
1.4
1.3
10.0
8.8
8.4
14.9
13.4
12.3

0.12
0.32
1.6
1.3
3.5
15.6
2.4
6.2
31.0

45
16
5.1
136
78
48
655
191
95

κb = 20; κs = 40

Storage Ofﬂine Online
1.1
1.1
1.0
7.6
6.4
6.3
11.1
10.6
10.6

0.06
0.38
0.76
0.68
4.4
8.8
1.2
7.9
15.6

40
16
2.4
65
95
24
247
246
71

Figure 7: Amortized running times per execution (reported in ms) and total ofﬂine storage (reported in GB) for our prototype in
the LAN conﬁguration. The peak ofﬂine storage occurs before the cut and choose, consisting of the circuits, commitments, and
OT messages. For κb = 80 we use parameters (N,B) ∈ {(32,12), (128,9), (1024,7)}. For κb = 40 we use parameters (N,B) ∈
{(32,6), (128,5), (1024,5)}. For κb = 20 we use parameters (N,B) ∈ {(32,3), (128,2), (1024,2)}.

ﬁcient ofﬂine phase ranging from 4 to 22 times faster for
both circuits.

As discussed in Section 2.3, our protocol has asymp-
totically lower online communication cost, especially for
computations with larger inputs. Since both protocols are
more-or-less I/O bound in these experiments, the differ-
ence in communication cost is signiﬁcant. Concretely,
when evaluating AES with N = 1024 and B = 4 our pro-
tocol sends 16,384 bytes of wire labels and just 564 bytes
of PSI data. The online phase of [23] reports to use
170,000 bytes with the same parameters. Even using our
asynchronous PSI sub-protocol, the total PSI cost is only
10,280 bytes.
9.3 Effect of security parameters
We show in Figure 7 how our prototype scales for differ-
ent settings of security parameters in the LAN setting. In
particular, the security properties of our protocol allow
us to consider smaller settings of parameters than are ad-
vised with traditional cut-and-choose protocols such as
[23]. As a representative example, we consider κb = 20
and κs = 40 which means that our protocol will leak a
single bit only with probability 1/220 but guarantee all
other security properties with probability 1− 1/240.
Our protocol scales very well both in terms of secu-
rity parameter and circuit size. Each doubling of κs only
incurs an approximate 25% to 50% increase in running
time. This is contrasted by [23] reporting a 200% to
300% increase in running time for larger security pa-
rameters. Our improvement is largely due to reducing
the number of cryptographic steps and no cheat-recovery
circuit which consume signiﬁcant online bandwidth.

We see a more signiﬁcant trend in the total storage re-
quirement of the ofﬂine phase. For example, when per-
forming N = 1024 AES evaluations for security parame-
ter κb = 20 the protocol utilizes a maximum of 0.76 GB
of storage while κb = 40 requires 1.6 GB of storage. This
further validates κb = 20 as a storage and bandwidth sav-
ing mechanism. [23] reports that 3.8 GB of ofﬂine com-

κs

40

80

B
2
3
4
6
5
7
9

LAN

Time Bandwidth
327
0.26
353
0.41
381
0.56
465
0.82
0.75
568
725
1.01
2.42
465

WAN

Time Bandwidth
144
0.63
206
0.72
213
1.01
293
1.32
1.39
300
366
2.02
3.41
331

Figure 8: Maximum amortized throughput (ms/execution) and
resulting bandwidth (Kbps) when performing many parallel
evaluations of AES with the given bucket size B and statisti-
cal security κs.

munication for N = 1024 and 40-bit security.
9.4 Throughput & Bandwidth
In addition to considering the setting when executions
are performed sequentially, we tested our prototype
when performing many executions in parallel to maxi-
mize throughput. Figure 8 shows the maximum aver-
age throughput for AES evaluations that we were able to
achieve, under different security parameters and bucket
sizes. The time reported is the average number of mil-
liseconds per evaluation.

In the LAN setting, 8 evaluations were performed in
parallel and achieved an amortized time of 0.26ms per
evaluation for bucket size B = 2. A bucket size of 2
can be obtained by performing a modest number (say
N = 256) of executions with κb = 20, or a very large
number of executions with κb = 40. We further tested our
prototype in the WAN setting where we obtain a slightly
decreased throughput of 0.72ms per AES evaluation with
40-bit security.
References
[1] AFSHAR, A., MOHASSEL, P., PINKAS, B., AND RIVA,
B. Non-interactive secure computation based on cut-and-
choose. In EUROCRYPT 2014 (May 2014), P. Q. Nguyen

USENIX Association  

25th USENIX Security Symposium  309

13

and E. Oswald, Eds., vol. 8441 of LNCS, Springer, Hei-
delberg, pp. 387–404.

[2] BEAVER, D.

Precomputing oblivious transfer.

In
CRYPTO’95 (Aug. 1995), D. Coppersmith, Ed., vol. 963
of LNCS, Springer, Heidelberg, pp. 97–109.

[3] BELLARE, M., HOANG, V. T., KEELVEEDHI, S., AND
ROGAWAY, P. Efﬁcient garbling from a ﬁxed-key block-
cipher. In 2013 IEEE Symposium on Security and Privacy
(May 2013), IEEE Computer Society Press, pp. 478–492.
[4] BELLARE, M., HOANG, V. T., AND ROGAWAY, P.
Adaptively secure garbling with applications to one-time
programs and secure outsourcing. In ASIACRYPT 2012
(Dec. 2012), X. Wang and K. Sako, Eds., vol. 7658 of
LNCS, Springer, Heidelberg, pp. 134–153.

[5] BELLARE, M., HOANG, V. T., AND ROGAWAY, P. Foun-
dations of garbled circuits. In ACM CCS 12 (Oct. 2012),
T. Yu, G. Danezis, and V. D. Gligor, Eds., ACM Press,
pp. 784–796.

[6] CANETTI, R. Universally composable security: A new
paradigm for cryptographic protocols.
In 42nd FOCS
(Oct. 2001), IEEE Computer Society Press, pp. 136–145.
[7] CHOU, T., AND ORLANDI, C. The simplest protocol
for oblivious transfer. In Progress in Cryptology - LAT-
INCRYPT 2015 (2015), K. E. Lauter and F. Rodr´ıguez-
Henr´ıquez, Eds., vol. 9230 of Lecture Notes in Computer
Science, Springer, pp. 40–58.

[8] DAMGAARD, I., LAURITSEN, R., AND TOFT, T. An
empirical study and some improvements of the Mini-
Mac protocol for secure computation. Cryptology ePrint
Archive, Report 2014/289, 2014.
http://eprint.
iacr.org/2014/289.

[9] DAMG ˚ARD, I., PASTRO, V., SMART, N. P., AND ZA-
KARIAS, S. Multiparty computation from somewhat ho-
momorphic encryption. In CRYPTO 2012 (Aug. 2012),
R. Safavi-Naini and R. Canetti, Eds., vol. 7417 of LNCS,
Springer, Heidelberg, pp. 643–662.

[10] DAMG ˚ARD, I., AND ZAKARIAS, R. W. Fast oblivi-
ous AES: a dedicated application of the MiniMac proto-
col. Cryptology ePrint Archive, Report 2015/989, 2015.
ia.cr/2015/989.

[11] DAMG ˚ARD, I., AND ZAKARIAS, S. Constant-overhead
secure computation of boolean circuits using preprocess-
ing. In TCC 2013 (Mar. 2013), A. Sahai, Ed., vol. 7785
of LNCS, Springer, Heidelberg, pp. 621–641.

[12] FREDERIKSEN, T. K., JAKOBSEN, T. P., AND NIELSEN,
J. B. Faster maliciously secure two-party computation
using the GPU. In SCN 14 (Sept. 2014), M. Abdalla and
R. D. Prisco, Eds., vol. 8642 of LNCS, Springer, Heidel-
berg, pp. 358–379.

[13] HUANG, Y., KATZ, J., AND EVANS, D. Efﬁcient secure
two-party computation using symmetric cut-and-choose.
In CRYPTO 2013, Part II (Aug. 2013), R. Canetti and
J. A. Garay, Eds., vol. 8043 of LNCS, Springer, Heidel-
berg, pp. 18–35.

[14] HUANG, Y., KATZ, J., KOLESNIKOV, V., KUMARESAN,
R., AND MALOZEMOFF, A. J. Amortizing garbled cir-
cuits. In CRYPTO 2014, Part II (Aug. 2014), J. A. Garay
and R. Gennaro, Eds., vol. 8617 of LNCS, Springer, Hei-
delberg, pp. 458–475.

[15] KELLER, M., ORSINI, E., AND SCHOLL, P. Ac-
tively secure OT extension with optimal overhead.
In
CRYPTO 2015, Part I (Aug. 2015), R. Gennaro and
M. J. B. Robshaw, Eds., vol. 9215 of LNCS, Springer,
Heidelberg, pp. 724–741.

[16] KOLESNIKOV, V., MOHASSEL, P., RIVA, B., AND RO-
SULEK, M. Richer efﬁciency/security trade-offs in 2PC.
In TCC 2015, Part I (Mar. 2015), Y. Dodis and J. B.
Nielsen, Eds., vol. 9014 of LNCS, Springer, Heidelberg,
pp. 229–259.

[17] KOLESNIKOV, V., AND SCHNEIDER, T. Improved gar-
bled circuit: Free XOR gates and applications.
In
ICALP 2008, Part II (July 2008), L. Aceto, I. Damg˚ard,
L. A. Goldberg, M. M. Halld´orsson, A. Ing´olfsd´ottir, and
I. Walukiewicz, Eds., vol. 5126 of LNCS, Springer, Hei-
delberg, pp. 486–498.

[18] KREUTER, B., SHELAT, A., AND SHEN, C. Billion-gate
secure computation with malicious adversaries. In Pro-
ceedings of the 21th USENIX Security Symposium (2012),
T. Kohno, Ed., USENIX Association, pp. 285–300.

[19] LINDELL, Y. Fast cut-and-choose based protocols for
malicious and covert adversaries. In CRYPTO 2013, Part
II (Aug. 2013), R. Canetti and J. A. Garay, Eds., vol. 8043
of LNCS, Springer, Heidelberg, pp. 1–17.

[20] LINDELL, Y., AND PINKAS, B. An efﬁcient protocol
for secure two-party computation in the presence of ma-
licious adversaries. In EUROCRYPT 2007 (May 2007),
M. Naor, Ed., vol. 4515 of LNCS, Springer, Heidelberg,
pp. 52–78.

[21] LINDELL, Y., AND PINKAS, B.

Secure two-party
computation via cut-and-choose oblivious transfer.
In
TCC 2011 (Mar. 2011), Y. Ishai, Ed., vol. 6597 of LNCS,
Springer, Heidelberg, pp. 329–346.

[22] LINDELL, Y., AND RIVA, B. Cut-and-choose Yao-based
secure computation in the online/ofﬂine and batch set-
tings. In CRYPTO 2014, Part II (Aug. 2014), J. A. Garay
and R. Gennaro, Eds., vol. 8617 of LNCS, Springer, Hei-
delberg, pp. 476–494.

[23] LINDELL, Y., AND RIVA, B. Blazing fast 2PC in the
ofﬂine/online setting with security for malicious adver-
saries. In Proceedings of the 22nd ACM SIGSAC Confer-
ence on Computer and Communications Security (2015),
I. Ray, N. Li, and C. Kruegel, Eds., ACM, pp. 579–590.
[24] MALKHI, D., NISAN, N., PINKAS, B., AND SELLA, Y.
Fairplay - secure two-party computation system. In Pro-
ceedings of the 13th USENIX Security Symposium (2004),
M. Blaze, Ed., USENIX, pp. 287–302.

[25] MOHASSEL, P., AND FRANKLIN, M. Efﬁciency trade-
offs for malicious two-party computation. In PKC 2006
(Apr. 2006), M. Yung, Y. Dodis, A. Kiayias, and
T. Malkin, Eds., vol. 3958 of LNCS, Springer, Heidelberg,
pp. 458–473.

[26] MOHASSEL, P., AND RIVA, B. Garbled circuits check-
ing garbled circuits: More efﬁcient and secure two-party
computation.
In CRYPTO 2013, Part II (Aug. 2013),
R. Canetti and J. A. Garay, Eds., vol. 8043 of LNCS,
Springer, Heidelberg, pp. 36–53.

[27] NIELSEN, J. B., NORDHOLT, P. S., ORLANDI, C., AND
BURRA, S. S. A new approach to practical active-secure

310  25th USENIX Security Symposium 

USENIX Association

14

two-party computation. In CRYPTO 2012 (Aug. 2012),
R. Safavi-Naini and R. Canetti, Eds., vol. 7417 of LNCS,
Springer, Heidelberg, pp. 681–700.

[28] PEIKERT, C., VAIKUNTANATHAN, V., AND WATERS,
B. A framework for efﬁcient and composable oblivious
transfer. In CRYPTO 2008 (Aug. 2008), D. Wagner, Ed.,
vol. 5157 of LNCS, Springer, Heidelberg, pp. 554–571.

[29] PINKAS, B., SCHNEIDER, T., SMART, N. P., AND
WILLIAMS, S. C. Secure two-party computation is prac-
tical. In ASIACRYPT 2009 (Dec. 2009), M. Matsui, Ed.,
vol. 5912 of LNCS, Springer, Heidelberg, pp. 250–267.

intersection based on OT extension.

[30] PINKAS, B., SCHNEIDER, T., AND ZOHNER, M. Faster
private set
In
Proceedings of the 23rd USENIX Security Symposium
(2014), K. Fu and J. Jung, Eds., USENIX Association,
pp. 797–812.

[31] SHELAT, A., AND SHEN, C.-H. Two-output secure
computation with malicious adversaries.
In EURO-
CRYPT 2011 (May 2011), K. G. Paterson, Ed., vol. 6632
of LNCS, Springer, Heidelberg, pp. 386–405.

[32] SHELAT, A., AND SHEN, C.-H. Fast two-party secure
computation with minimal assumptions. In ACM CCS 13
(Nov. 2013), A.-R. Sadeghi, V. D. Gligor, and M. Yung,
Eds., ACM Press, pp. 523–534.

[33] SMART, N. Personal communication, November 2015.
[34] YAO, A. C.-C. Protocols for secure computations (ex-
tended abstract). In 23rd FOCS (Nov. 1982), IEEE Com-
puter Society Press, pp. 160–164.

[35] ZAHUR, S., ROSULEK, M., AND EVANS, D. Two halves
make a whole - reducing data transfer in garbled circuits
using half gates.
In EUROCRYPT 2015, Part II (Apr.
2015), E. Oswald and M. Fischlin, Eds., vol. 9057 of
LNCS, Springer, Heidelberg, pp. 220–250.

A Adaptively Secure Garbling Schemes
A garbling scheme
algorithms
(Gb, En, Ev, De) with the following syntax and se-
mantics. All algorithms accept a security parameter as
explicit input, which we leave implicit.

tuple of

is

a

• Gb( f ,d) → (F,e); Here f is a boolean circuit with
m inputs and n outputs; d is an n× 2 array of (out-
put) wire labels; F is a garbled circuit; and e is an
m× 2 array of input wire labels.
By wire labels, we simply mean strings (i.e., ele-
ments of {0,1}κc). We deviate from [5] in requiring
the output wire labels d to be chosen by the caller of
Gb, rather than chosen by Gb itself. In the notation
of [5], we assume that the scheme is projective in
both its input and output encodings, meaning that e
and d consist of two possible wire labels for each
wire.

• En(e,x) → X takes an m × 2 array of wire la-
bels e and a plaintext input x ∈ {0,1}m and out-
puts a garbled encoding X of x. By assuming
that the scheme is projective, we assume that X =
(X1, . . . ,Xm) where Xi = e[i,xi].

• Ev(F,X) → Y ; takes a garbled circuit F and garbled
encoding X of an input, and returns a garbled en-
coding of the output Y .

• (cid:31)De(Y ) → y. We assume a way to decode a garbled

output to a plaintext value. It is a deviation from [5]
to allow this to be done without the decoding infor-
mation d. Rather, we may assume that the garbled
outputs contain the plaintext value, say, as the last
bit of each wire label.

Our correctness condition is that for the variables de-
ﬁned above, we have Ev(F, En(e,x)) = En(d, f (x)) and

(cid:31)De(Ev(F, En(e,x))) = f (x) for all inputs x to the circuit

f . In other words, evaluating the garbled circuit should
result in the garbled output that encodes f (x) under the
encoding d.

In our construction, an adversary sees the garbled cir-
cuit F ﬁrst, then it receives some of the garbled inputs
(corresponding to the k-probe matrix encoded inputs).
Finally in the online phase it is allowed to choose the
rest of its input to the ciruict and receive the rest of the
garbled inputs. Hence, our security game considers an
adversary that can obtain the information in this order.

We overload the syntax of the encoding algorithm En.
Since En is projective, we write En(e,i,b) to denote the
component ei,b — that is, the garbled input for the ith
wire corresponding to truth value b. Recall that we also
garble a circuit with output wire labels d speciﬁed (rather
than chosen by the Gb algorithm). Our security deﬁnition
lets the adversary choose d.

Deﬁnition 6. For a garbling scheme (Gb, En, Ev, De),
an interactive oracle program Adv,
and algo-
rithms S = (S0,S1,S2), we deﬁne the following two
games/interactions:

G Adv
real :
get f ,d from AdvH
(F,e) ← Gb( f ,d)
give F to AdvH
for i = 1 to m:

get xi from AdvH
Xi ← En(e,i,xi)
give Xi to AdvH
AdvH outputs a bit

:

G Adv,S
ideal
get f ,d from AdvS0
F ← S1( f )
give F to AdvS0
for i = 1 to m− 1:
get xi from AdvS0
Xi ← S2(i)
give Xi to AdvS0
get xm from AdvS0
y = f (x1···x m)
Y ← En(d,y)
Xm ← S2(m,y,Y )
give Xm to AdvS0
AdvS0 outputs a bit

In Gideal, H is a random oracle.
In Gideal, the tuple
S = (S0,S1,S2) all share state. All algorithms receive
the security parameter as implicit input.

15

USENIX Association  

25th USENIX Security Symposium  311

Then the garbling scheme is adaptively secure if there
exists a simulator S such that for all polynomial-time ad-
versaries Adv, we have that

is negligible in the security parameter.

Adv,S

ideal outputs 1](cid:31)(cid:31)

real outputs 1]− Pr[G

(cid:31)(cid:31)Pr[G Adv

Note that in the Gideal game, the simulator receives no
information about the input x as it produces the garbled
circuit F and all but one of the garbled input components.
Finally when producing the last garbled input compo-
nent, the simulator learns f (x) and its garbled output en-
coding En(d, f (x)). In particular, the simulator receives
no information about x, so its outputs carry no informa-
tion about x beyond f (x). The game also implies an
authenticity property for garbled outputs of values other
than f (x) — the simulator’s total output contains no in-
formation about the rest of the garbled outputs d.

In Figure 9 we describe a generic, random-oracle
transformation from a standard (static-secure) garbling
scheme to one with this ﬂavor of adaptive security. The
construction is quite similar to the transformations in
[4], with some small changes. First, since we know in
advance which order the adversary will request its gar-
bled inputs, we include the random oracle nonce R in the
last garbled input value (rather than secret-sharing across
all garbled inputs). Second, since we garble a circuit
with particular garbled output values in mind, we provide
“translation values” that will map the garbled outputs of
the static scheme to the desired ones. These translation
values also involve the random oracle, so they can be
equivocated by the simulator.

If

Theorem 7.
is a doubly-
projective garbling scheme satisfying the (static) prv and
aut properties of [5] then the scheme in Figure 9 satisﬁes
adaptive security notion of Deﬁnition 6 in the random or-
acle model.

(Gb, En, Ev, De,(cid:30)De)

The proof is very similar to analogous proofs in [4].
The main idea is that the simulator can choose the

“masked” (cid:29)F and δ translation values upfront. Then it

is only with negligible probability that an adversary will
call the random oracle on the secret nonce R, so the rel-
evant parts of the oracle are still free to be programmed
by the simulator. When the adversary provides the ﬁnal
bit of input, the simulator gets f (x) and can obtain a sim-
ulated garbled circuit F and garbled outputs d from the
static-secure scheme. Then it can program the random
oracle to return the appropriate masks.8

i

1,e0

1,e1

2,e1

(cid:28)Gb( f ,(cid:29)d):
(F,e,d) ← Gb( f )
R ← {0,1}κ
for each output wire i:
δ b
i ← H(R(cid:27)out(cid:27)i(cid:27)b(cid:27)db
i )⊕(cid:29)db
(cid:29)F ← (F ⊕ H(R(cid:27)gc),{δ b
i })
2, . . . ,e 0
(cid:29)e ← (e0
m(cid:27)R,e1
m(cid:27)R)
return ((cid:29)F,(cid:29)e)
(cid:28)Ev((cid:29)F,(cid:29)X):
parse (cid:29)Xm as Xm(cid:27)R and (cid:29)F as (F(cid:25),δ )
X ← ((cid:29)X1,(cid:29)X2, . . . ,Xm)
Y ← Ev(F(cid:25) ⊕ H(R(cid:27)gc),X)
y ←(cid:30)De(Y )
for each output wire i:
(cid:29)Yi = δ yi
return(cid:29)Y

i ⊕ H(R(cid:27)out(cid:27)i(cid:27)yi(cid:27)Yi)

Figure 9:

Transformation from a static-secure doubly-

projective garbling scheme (Gb, En, Ev, De,(cid:30)De) to one satis-

fying Deﬁnition 6.

8Technically, the proof assumes that the simulator for the static-
secure scheme can set the (simulated) garbled input encoding arbitrar-
ily. This is true for common existing schemes; e.g., [35].

16

312  25th USENIX Security Symposium 

USENIX Association

Setup stage: On common input (sid, SETUP, f ,N,ε), where f is a boolean circuit, N is the number of executions. The parties

agree on parameters B,(cid:31)N derived from Lemma 1. Let M ∈ {0,1}µ×n be a κs-probe resistant matrix for each party’s input of
size n. Let a ∈ {0,1} denote the role of the current party and b = a⊕ 1. Note: the protocol is symmetric where both parties
simultaneously play the roles of Pa and Pb.
• Cut-and-Choose Commit: Pa chooses at random the cut and choose set σa ⊂ [(cid:31)N] of size (cid:31)N − NB. Pa send
(COMMIT, (sid, CUT-AND-CHOOSE,a),σa) to Fcom. For j ∈ [(cid:31)N]:
j ,e j) ←(cid:30)Gb( f (cid:23),d j) and sends the Fa

µ
rot and receives choice bits ca
– OT Init: Pa sends (INIT, (sid, OT,a, j)) to F
– Send Circuit: Pa chooses random output wire labels d j, computes (Fa
j ,eb

Pb where f (cid:23)(xa,r, ˜xb) = f (xa,Mr⊕ ˜xb) and r, ˜xb are Pb’s inputs. Let ea
xa, ˜xb,r, for circuit Fa

to
j respectively be the labels encoding

j and e∗j,t,h index the label of the tth wire with value h in the set e∗j

j in response.

j ,er

j

– Input Commit: Pa sends the following to Fcom:

(cid:31) (COMMIT, (sid,xa-INPUT,a, j,t,h),ea
(cid:31) (COMMIT, (sid,xb-INPUT,a, j,t,h),eb
(cid:31) (COMMIT, (sid, r-INPUT,a, j,t,h),er

j,t,Mc[t]⊕h)t∈[n],h∈{0,1}.
)t∈[n],h∈{0,1}
)t∈[µ],h∈{0,1}

j,t,h
j,t,h

– Output Commit: Pa sends (COMMIT, (sid, OUTPUT,a, j), d j) to Fcom.

• Cut-and-Choose: Pb sends (OPEN, (sid, CUT-AND-CHOOSE,b)) to Fcom and Pa receives σb. For j ∈ σb:
j . Pb veriﬁes the correctness of Fa
j .

– OT Decommit: Pa sends (OPEN, (sid, OT,a, j)) to F
– Check Circuit: Pa sends Pb the d j and coins used to garble Fa
– Input Decommit: Let ea
j be the veriﬁed labels as above.

µ
rot and Pb receives choice bits cb
j.

j ,eb

j ,er

(cid:31) Pa sends (OPEN, (sid,xa-INPUT,a, j,t,h))∀t,h to Fcom and Pb receives labels e(cid:23)a.
(cid:31) Pa sends (OPEN, (sid,xb-INPUT,a, j,t,h))∀t,h to Fcom and Pb receives labels e(cid:23)b.
(cid:31) Pa sends (OPEN, (sid, r-INPUT,a, j,t,h))∀t,h to Fcom and Pb receives labels e(cid:23)r.
(cid:31) If there exists a e(cid:23)a

t,h (cid:20)= ea

j, or e(cid:23)r (cid:20)= er
• Bucketing: Pb randomly maps the indices of [(cid:31)N]− σb into sets β a

– Output: Pa sends (OPEN, (sid, OUTPUT,a, j)) to Fcom. Pb receives d(cid:23) and return ABORT if d(cid:23) (cid:20)= d j.
– Bucket Labels: Pa generates random output labels Oa

N s.t. |β a
i . For j ∈ β a
i , Pa send the output translation
i,t,h) to Pb, where d j are the output labels of Fa
j .

1 , ...,β a
i for bucket β a

j [t]⊕h, or e(cid:23)b (cid:20)= eb

i | = B. For i ∈ [N]:

j, Pb returns ABORT .

j,t,Mcb

– Ofﬂine Inputs:

i,t,h ⊕ d j,t,h}t,h and H(Oa

j := {Oa
T a
(cid:31) Pa sends (AGGREGATE, (sid, OT-AG,a,i),{(sid, OT,a, j)| j ∈ β b
tion strings δ a
(cid:31) Pb sends (DELIVER, (sid, OT-AG,a,i),{er
{(sid,r-INPUT,b, j,t,h)}t,h.
(cid:31) For j ∈ β b
i , Pa receives X r
j and Wj from F
and receives X(cid:23)r

j for j ∈ β a
i .

j,w j| j ∈ β b

i }) to F

µ
rot. Pa send (OPEN, (sid,r-INPUT,b, j,t,ca
(cid:20)= X r
j .
Execution stage: On common bucket index i and Pa’s input xa.

j . Pa returns ABORT if X(cid:23)r
j

µ
rot and Pb receives the OT aggrega-

i }) to F
µ
rot where w j are the decommitment strings to

j [t]),Wj,t )∀t to Fcom

(sid, OT,a, j(cid:23)). For all j ∈ β b
i :

• Receiver’s Inputs: Let j(cid:23) be the ﬁrst index in β a

i . Pa sends ˜xa := xa ⊕ Mca

j(cid:23) to Pb where ca

j(cid:23) are the choice bits of

j encodes ˜xa for Fb

j and w j are the

j,t )∀t to Fcom and receives X(cid:23)a

j . Pa

j )[t]}t to Pa where ea
j )[t]),W a

– Pb sends X a

– Pa receives X a

j )[t]}t and W a

j := {w j,( ˜xa⊕Mδ a

• Sender’s Inputs: For j ∈ β b

j := {ea
decommitments string to {(sid,xa-INPUT,b, j,t,h)}t,h.
j ,W a
returns ABORT if X a
j

j,t,( ˜xa⊕Mδ a
j and sends (OPEN, (sid,xa-INPUT,b, j,t, (xa ⊕ Mca

(cid:20)= X(cid:23)a
j .
i , Pb sends (OPEN, (sid,xb-INPUT,b, j,t, (xb ⊕ Mcb
j . Pa returns ABORT if ˜xb ⊕ Mδ b
X b
i , let Yj :=(cid:30)Ev(Fb

(cid:20)= (xb ⊕ Mcb
j ).
• Evaluate: For j ∈ β b
j , (X b
j ,X r
j ,X a
• PSI Commit: For ∀ j,t, if (H(Yj,t ) (cid:20)= H(Ob
• Output Decommit: For j ∈ β b
If there exists j, j(cid:23) s.t. d(cid:23)j,t,h ⊕ T b
CHEATING!, else PA returns y j s.t. Ij ∈ R.

j )) with semantic value y j.

j

i , Pb sends (OPEN, (sid, OUTPUT,b, j)) to Fcom and Pa receives d(cid:23)j.
j,t,h (cid:20)= d(cid:23)j(cid:23),t,h ⊕ T b

j(cid:23),t,h, Pa returns ABORT.

j,t,y j[t] ⊕ Oa
Pa pads I to size B with random values and sends (INPUT, (sid, PSI,i),I) to Fpsi and receives (INPUT,Pb).

i,t,y j[t])), then Yj,t ← {0,1}κc. Let I := {(cid:29)t Yj,t ⊕ T b

i,t,y j[t]} j∈β b

i

.

• PSI Decommit: Pb sends (OPEN, (sid, PSI,i)) to Fpsi and Pa receives the intersection R.

If |R| (cid:20)= 1, Pa returns

j )[t]))∀t to Fcom. Pa receives the labels

Figure 15: Malicious secure online/ofﬂine dual-execution 2PC protocol Πmulti-sfe.

USENIX Association  

25th USENIX Security Symposium  313

17

Parameters: Two parties: a sender P1 and receiver P2;
(cid:30) = bit-length of items in the set; n = size of parties’
sets; F = a PRF.
Ofﬂine phase: Parties perform random OTs, resulting
in P1 holding strings mi,t
{0,1} ← {0,1}κc; and P2 holding
ci and mi,t
Input committing phase:

ci[t]. Here, ci ∈ {0,1}(cid:30) and i ∈ [n],t ∈ [(cid:30)].

• On input (INPUT,{A2,1, . . . ,A 2,n}) to P2, P2 ran-
domly permutes its input and then sends di :=
A2,i ⊕ ci for each i ∈ [n].
• On input (INPUT,{A1,1, . . . ,A 1,n}) for P1, P1 ran-
domly permutes its input and then computes
Si, j =(cid:31)t F(mi,t
• P1 sends (COMMIT, sid, (S1,1, . . . ,S n,n)) to Fcom.
P1
receives
then outputs

Output
sends
(OPENED, sid, (S1,1, . . . ,S n,n)).

On
to Fcom and P2

di[t]⊕A1, j[t], j) for i, j ∈ [n].

(OUTPUT),

(OPEN, sid)

phase:

input

P2

{A2,i | ∃ j :(cid:31)t F(mi,t

ci[t], j) =S i, j}.

Figure 13: Weakly-malicious-secure, synchronous (3-round),
two-phase PSI protocol Πsync-psi.
Parameters: Two parties: a sender P1 and receiver P2;
(cid:30) = bit-length of items in the set; n = size of parties’
sets; F = a PRF.
Ofﬂine phase: Parties perform random OTs, resulting
in P1 holding strings mi,t
{0,1} ← {0,1}κc; and P2 holding
ci and mi,t
For i ∈ [n], P1 chooses πi ← {0,1}(cid:30). Then for i, j ∈ [n],
party P1 does the following:
• For t ∈ {0,1}(cid:30), choose zi, j
t ← {0,1}(cid:30) subject to
(cid:31)t zi, j
t = 0
• for
t ∈ [(cid:30)],b ∈ {0,1}; P1 sends (COMMIT,

ci[t]. Here, ci ∈ {0,1}(cid:30) and i ∈ [n],t ∈ [(cid:30)].

(sid,i, j,t,b),F(mi,t

π j[t]⊕b, j)⊕ zi, j

t ) to Fcom.

committing

Input
phase:
put
(INPUT,{A1,1, . . . ,A 1,n})
(INPUT,{A2,1, . . . ,A 2,n}) for P2,
domly permute their
do:

in-
for
and
the parties ran-
inputs and asynchronously

On
P1

Parameters: A sender P1 and receiver P2.
Setup: On common input S from both parties,
for every s ∈ S choose random m0,m1 ← {0,1}κc
and random c ← {0,1}.
Internally store a tuple
(s,m0,m1,c).
P1 output: On input (GET,s) from P1, if there is
a tuple (s,m0,m1,c) for some m0,m1,c then give
(OUTPUT,s,m0,m1) to P1.
P2 output: On input (GET,s) from P2, if there is
a tuple (s,m0,m1,c) for some m0,m1,c then give
(OUTPUT,s,c,mc) to P2.

Figure 10: Random OT functionality Fot.

Parameters: A sender P1 and receiver P2.
Commit: On input (COMMIT, sid,v) from P1:
If
a tuple of the form (sid,·,·) is stored, then abort.
If P1 is corrupt, then obtain value r from the ad-
versary; otherwise choose r ← {0,1}κc and give r
to P1.
Internally store a tuple (sid,r,v) and give
(COMMITTED, sid) to P2.
Reveal: On input (OPEN, sid,r(cid:26)) from P2:
a tuple (sid,r(cid:26),v) is stored for some v,
give (OPENED, sid,v) to P2.
(ERROR, sid) to P2.
Figure 11: Non-interactive commitment functionality Fcom.

if
then
Otherwise, give

Parameters: Two parties: a sender P1 and receiver
P2; (cid:30) = length of items; n = size of parties’ sets.

First phase (input commitment): On input
(INPUT,Ai) from party Pi (i ∈ {1,2}), with Ai ⊆
{0,1}(cid:30) and |Ai| = n: If this is the ﬁrst such command
from Pi then internally record Ai and send message
(INPUT,Pi) to both parties.

Second phase (output): On input (OUTPUT) from
Pi, deliver (OUTPUT,A1 ∩ A2) to the other party.
Figure 12: Two-phase private set intersection (PSI) functional-
ity F

n,(cid:30)
psi .

• P1 sends d1, j := A1, j ⊕ π j for each j ∈ [n]
• P2 sends d2,i := A2,i ⊕ ci for each i ∈ [n]

to Fcom and P2

Output phase: On input (OUTPUT):
for i, j ∈ [n],
t ∈ [(cid:30)], party P1 sends (OPEN, (sid,i, j,t,d1, j[t] ⊕
expects
to receive
d2,i[t]))
(OPENED, (sid,i, j,t,d1, j[t]⊕ d2,i[t]),ρi, j
t ).
P2 outputs {A2,i | ∃ j :(cid:31)t F(mi,t

ci[t], j) =(cid:31)t ρi, j
t }

Figure 14: Weakly-malicious-secure, asynchronous (2-round),
two-phase PSI protocol Πasync-psi.

314  25th USENIX Security Symposium 

USENIX Association

18

