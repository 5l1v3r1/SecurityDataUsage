UC-Secure Searchable Symmetric Encryption

Kaoru Kurosawa and Yasuhiro Ohtaki

Ibaraki University, Japan

{kurosawa, y.ohtaki}@mx.ibaraki.ac.jp

Abstract. For searchable symmetric encryption schemes (or symmetric-
key encryption with keyword search), the security against passive adver-
saries (i.e. privacy) has been mainly considered so far. In this paper, we
ﬁrst deﬁne its security against active adversaries (i.e. reliability as well as
privacy). We next formulate its UC-security. We then prove that the UC-
security against non-adaptive adversaries is equivalent to our deﬁnition
of privacy and reliability. We further present an eﬃcient construction
which satisﬁes our security deﬁnition (hence UC-security).

Keywords: searchable symmetric encryption, UC-security, symmetric-
key encryption

1

Introduction

We consider the following problem [8]: a client wants to store his ﬁles (or docu-
ments) in an encrypted form on a remote ﬁle server (in the store phase). Later (in
the search phase), the client wants to eﬃciently retrieve some of the encrypted
ﬁles containing (or indexed by) speciﬁc keywords, keeping the keywords them-
selves secret and not jeopardizing the security of the remotely stored ﬁles. For
example, a client may want to store old email messages encrypted on a server
managed by Google or another large vendor, and later retrieve certain messages
while traveling with a mobile device. Such a scheme is called a searchable sym-
metric encryption (SSE) scheme because symmetric key encryption schemes are
used.

For this problem, the security against passive adversaries (i.e. privacy) has
been mainly considered so far. After a series of works [10, 9, 1, 8], Curtmola,
Garay, Kamara and Ostrovsky [6, 7] showed a rigorous deﬁnition of security
about the client’s privacy against a passive server, and an eﬃcient scheme which
satisﬁes their deﬁnition.

However, an active adversary (i.e. a server) may forge the encrypted ﬁles
and/or delete some of them. Even if the clients uses MAC to authenticate
the encrypted ﬁles, a malicious server may replace (Ci, MAC(Ci)) with some
(Cj, MAC(Cj)) in the search phase, where Ci is an encrypted ﬁle which should be
returned. Then the client cannot detect cheating.

In this paper, we ﬁrst formulate the security of veriﬁable SSE schemes against
active adversaries by using the notion of privacy and reliability. Our deﬁnition of
privacy is slightly stronger than “adaptive semantic security” of Curtmola et al.

[7, Deﬁnition 4.11]. Our deﬁnition of reliability means that even if the server is
malicious, the client can receive the corresponding ﬁles correctly, or he outputs
fail in the search phase.
We next formulate its UC-security, where UC means universal composability.
(In the UC framework [3–5], the security of a protocol Σ = (P1,··· , Pn) is
maintained under a general protocol composition if Σ is UC-secure.) We then
prove that the UC-security against non-adaptive adversaries is equivalent to our
deﬁnition of privacy and reliability.

We further present an eﬃcient scheme which satisﬁes our deﬁnition (hence
UC-security). The communication overhead of our search phase is proportional
to N , where N is the number of stored ﬁles. (It is independent of the size of each
ﬁle.) It will be an open problem to construct a UC-secure scheme such that the
communication overhead of the search phase is sublinear in N .

2 Veriﬁable Searchable Symmetric Encryption (SSE)

In this section, we deﬁne veriﬁable searchable symmetric encryption (veriﬁable
SSE) scheme and its security.
– Let D = {D1,··· , DN} be a set of documents (or ﬁles).
– Let W ⊆ {0, 1}(cid:96) be a set of keywords.
– Let D(w) denote the set of documents which contain a keyword w ∈ W.
If X is a string, then |X| denotes the bit length of X. If X is a set, then |X|

(Hence (cid:96) denotes the bit length of each keyword.)

denotes the cardinality of X. PPT means probabilistic polynomial time.

2.1 Veriﬁable SSE

A veriﬁable SSE scheme consists of six polynomial time algorithms

vSSE = (Gen, Enc, Trpdr, Search, Dec, Verify)

such that
– K ← Gen(1k): is a probabilistic algorithm which generates a key K, where
k is a security parameter.
– (I,C) ← Enc(K,D,W): is a probabilistic encryption algorithm which out-
puts an encrypted index I and C = {C1,··· , CN}, where Ci is a ciphertext
of Di.
– t(w) ← Trpdr(K, w): is a deterministic algorithm which outputs a trapdoor
– (C(w), T ag) ← Search(I,C, t(w)): is a deterministic search algorithm, where

t(w) for a keyword w.

C(w) = {Ci | Ci is a ciphertext of Di ∈ D(w)}

(1)
– accept/reject← Verify(K, t(w), ˜C(w), T ag): is a deterministic veriﬁcation

algorithm which checks the validity of ˜C(w).

– D ← Dec(K, C): is a deterministic decryption algorithm, where D is a doc-

ument and C is a string.

For the set of documents D = {D1,··· , DN} and a keyword w ∈ W, it must be
that

– Di = Dec(K, Ci) if Ci is a ciphertext of Di.
– Verify(K, t(w), C(w), T ag) = accept if (I,C) is output by Enc(K,D,W),
t(w) is output by Trpdr(K, w) for w ∈ W, and (C(w), T ag) is output by
Search(I,C, t(w)).
The deﬁnition of usual searchable symmetric encryption (SSE) schemes [6,

7] is obtained by deleting T ag and Verify from the veriﬁable SSE schemes.

We next translate a vSSE into a protocol Σvsse which is a protocol between a
client and a server. It consists of the store phase and the search phase as shown
below, where the store phase is executed once, and the search phase is executed
for polynomially many times.






Store phase:

1. The client generates a key K ← Gen(1k) and keeps it secret.
2. On input (D,W), the client computes (I,C) ← Enc(K,D,W) and store
them to the server,
where D is a set of documents, W is the set of keywords, I is an en-
crypted index and C is a ciphertext of D.

Search phase:

1. On input a keyword w ∈ W, the client computes a trapdoor t(w) ←
2. The server computes (C(w), T ag) ← Search(I,C, t(w)) and sends them

Trpdr(K, w) and sends it to the server.

to the client (where C(w) is deﬁned by eq.(1)).

3. If the client received (˜C(w), T ag) from the server,

then the client computes Verify(K, t(w), ˜C(w), T ag).

– If the result is accept, then the client decrypts each ciphertext Ci
in C(w) to the document Di by using Dec(K,·), and outputs the set
of such Di as D(w).

– Otherwise the client outputs fail.



2.2 Privacy
In the above protocol, the server learns |D1|,··· ,|DN| and

List(w) = {i | Di contains w}

for each keyword w that is searched by the client. We require that the server
should not be able to learn any more information. Based on the work of Curt-
mola, Garay, Kamara and Ostrovsky [6, 7], this security notion is formulated as
follows.















We consider a real game Gamereal and a simulation game Gamesim as shown
below, where Gamereal is played by a challenger and an adversary A, and Gamesim
is played by a simulator Sim as well.

Real Game (Gamereal)

– Adversary A chooses (D,W) and sends them to the challenger.
– The challenger generates K ← Gen(1k),
– For i = 1,··· , q, do:

and then sends (I,C) ← Enc(K,D,W) to A.
1. A chooses a keyword wi ∈ W and sends it to the challenger.
2. The challenger sends a trapdoor t(wi) ← TrpdrK(wi) to A.

– A outputs a bit b.

Simulation Game (Gamesim)

where D = {D1,··· , DN} and (cid:96) is the length of a keyword.

– A chooses (D,W) and sends them to the challenger.
– The challenger sends |D1|,··· ,|DN| and (cid:96) to simulator Sim,
– Sim computes (I(cid:48), C(cid:48)) from |D1|,··· ,|DN| and (cid:96),
and sends them to the challenger.
– The challenger relays (I(cid:48), C(cid:48)) to A.
– For i = 1,··· , q, do:








1. A chooses wi ∈ W and sends it to the challenger.
2. The challenger sends List(wi) to Sim.
3. Sim computes t(wi)(cid:48) from List(wi) and sends it to the challenger.
4. The challenger relays t(wi)(cid:48) to A.

– A outputs a bit b.

Deﬁnition 1. We say that a veriﬁable SSE satisﬁes privacy if there exists a
PPT simulator Sim such that

| Pr(A outputs b = 1 in Gamereal) − Pr(A outputs b = 1 in Gamesim)|

(2)

is negligible for any PPT adversary A.

“Adaptive semantic security” of Curtmola et al. [7, Deﬁnition 4.11] requires
that for any PPT adversary A, there exists a PPT Sim such that eq.(2) is
negligible. On the other hand, our deﬁnition requires that there exists a PPT Sim
such that for any PPT adversary A, eq.(2) is negligible. Hence our deﬁnition is
slightly stronger. This small change is important when we prove the relationship
with UC-security. (See Remark 1 in the proof of Theorem 2.)

2.3 Reliability

In addition to the privacy, the server (an adversary A) should not be able to forge
(C(w), T ag) in the search phase. We formulate this security notion as follows.

Fix (D,W) and search queries w1,··· , wq ∈ W arbitrarily. In the store phase,

suppose that the client generated K and then computed (I, C).

– We say that C(w)∗ is invalid for t(w) if C(w)∗ (cid:54)= C(w), where (C(w), T ag) ←
Search(I,C, t(w)).
– We say that A wins if she can return (C(wi)∗, T ag∗) for some query t(wi) such
that C(wi)∗ is invalid for t(wi) and Verify(K, t(wi), C(wi)∗, T ag) = accept.

Deﬁnition 2. We say that a veriﬁable SSE satisﬁes reliability if for any PPT
adversary A, Pr(A wins) is negligible for any (D,W) and any search queries
w1,··· , wq.

3 UC-Secure SSE

3.1 UC Security
The security of a protocol Σ = (P1,··· , Pn) is maintained under a general pro-
tocol composition if Σ is secure in the universally composable (UC) security
framework [3–5].
In this framework, there exists an environment Z which generates the input
to all parties, reads all outputs, and in addition interacts with an adversary A
in an arbitrary way throughout the computation.
A protocol Σ is said to securely realize a given functionality F if for any
adversary A, there exists an ideal-world adversary S such that no environment
Z can tell whether it is interacting with A and parties running the protocol, or
with S and parties that interact with F in the ideal world.

The following universal composition theorem is proven in [3, 4]. Consider
a protocol Σ that operates in a hybrid model of computation where parties
can communicate as usual, and in addition have ideal access to (an unbounded
number of copies of) some ideal functionality F. Let ρ be a protocol that securely
realizes F as sketched above, and let Σρ be the composed protocol. That is, Σρ
is identical to Σ with the exception that each interaction with some copy of
F is replaced with a call to (or an invocation of) an appropriate instance of ρ.
Similarly, ρ-outputs are treated as values provided by the appropriate copy of F.
Then Σ and Σρ have essentially the same input/output behavior. In particular,
if Σ securely realizes some ideal functionality G given ideal access to F, then Σρ
securely realizes G from scratch.

For more details, see [3, 4].

3.2 Ideal Functionality of Veriﬁable SSE
We deﬁne the ideal functionality FvSSE of veriﬁable SSE protocols as follows.



Ideal Functionality FvSSE

Running with parties client P1, server P2 and adversary S.
Store: Upon receiving input (store, sid, D1,··· , DN ,W) from P1, verify

that this is the ﬁrst input from P1 with (store, sid).
If so, store D1,··· , DN , and send |D1|,··· ,|DN| and (cid:96) to S.
Otherwise ignore this input.

Search: Upon receiving (search, sid, w) from P1, send List(w) to S.



1. If S returns OK, then send D(w) to P1.
2. If S returns ⊥, then send ⊥ to P1.





We say that a veriﬁable SSE protocol ΣvSSE is UC-secure if it securely

realizes the ideal functionality FvSSE.

4 Equivalence

In this section, we prove that the UC-security notion of SSE is equivalent to the
deﬁnitions of privacy and reliability presented in Sec.2. In the UC framework, a
non-adaptive adversary corrupts some parties at the beginning of the protocol
execution.

Theorem 1. A veriﬁable SSE scheme vSSE satisﬁes privacy and reliability if
the corresponding protocol Σvsse is UC-secure against non-adaptive adversaries.

(Proof) Assume that vSSE does not satisfy (one of) privacy or reliability. We
show that Σvsse does not securely realize FvSSE.
This is done by constructing an environment Z and an adversary A such
that for any ideal world adversary S, Z can tell whether it is interacting with A
in Σvsse, or with S in the ideal world which interacts with FvSSE.
(I) Assume that vSSE does not satisfy the privacy property deﬁned by Def.1.
That is, for any simulator Sim, there exists an adversary B such that eq.(2) is
non-negligible.
Z asks A or S to corrupt P2 (server) so that P2 relays each message which
he received from P1 (client) to Z (in the real world). Except for this, P2 behaves
honestly. Z then internally runs B as follows.
– If B sends (D,W) to the challenger, then

1. Z activates P1 (client) with input (store, sid,D,W).
2. In the real world,

In the ideal world,

P1 sends (I, C) to P2(= A), and P2(= A) relays it to Z.
P1 sends (store, sid,D,W) to FvSSE.
FvSSE sends |D1|,··· ,|DN| and (cid:96) to S(= P2).
S(= P2) computes (I(cid:48), C(cid:48)), and sends it to Z.

3. Z sends (I, C) or (I(cid:48), C(cid:48)) to B.

– If B sends wi to the challenger, then

1. Z activates P1 with input (search, sid, wi).
2. In the real world,

In the ideal world,

P1 sends t(wi) to P2, and P2 relays it to Z.
P1 sends (search, sid, wi) to FvSSE.
FvSSE sends List(wi) to S(= P2).
S(= P2) computes t(wi)(cid:48), and sends it to Z.

3. Z sends t(wi) or t(wi)(cid:48) to B.

Finally Z outputs 1 if and only if B outputs 1.
If Z interacts with Σvsse (i.e. the real world), then it is easy to see that
Gamereal is simulated for B. On the other hand, suppose that Z interacts with
S in the ideal world. Then Gamesim is simulated for B because the ideal func-
tionality FvSSE plays the role of the challenger and the ideal world adversary S
plays the role of Sim.

Now from our assumption, for any ideal world adversary S, there exists some
B which can distinguish Gamereal from Gamesim. This means that for any ideal
world adversary S, there exists some Z which can distinguish Σvsse (the real
world) from the ideal world.

(II) Assume that vSSE does not satisfy reliability, i.e. there exists an adversary
B which breaks the reliability deﬁned by Def.2. Z asks A to corrupt P2 (server)
so that P2 behaves in the same way as B. Z ﬁnally outputs 1 if and only if Z
receives some set of documents D(cid:48) from P1 such that D(cid:48) (cid:54)= D(w) for some w.
If Z interacts with Σvsse, then B wins with non-negligible probability from
our assumption. Hence Z outputs 1 with non-negligible probability. On the other
hand, if Z interacts with S in the ideal world, Z never receives such D(cid:48) from
P1. Hence Z never outputs 1. This means that Z can distinguish Σvsse from the
ideal world for any ideal world adversary S.

Q.E.D.

Theorem 2. ΣvSSE is UC-secure against non-adaptive adversaries if the un-
derlying vSSE satisﬁes privacy and reliability.
(Proof) Assume that ΣvSSE does not securely realize FvSSE against non-adaptive
adversaries. That is, there exists some Z who can distinguish between the real
world and the ideal world.

We show that vSSE does not satisfy (one of) privacy or reliability. Assume
that vSSE satisﬁes privacy. (Otherwise the theorem is proven). Then there exists
a simulator Sim which satisﬁes Def.1.
Suppose that the real world adversary A does not corrupt any party. Then
it is easy to see that no Z can distinguish the real world from the ideal world.
(Note that Z interacts only with P1.)
Suppose that Z asks A to corrupt P1 (client). Note that A can report the
communication pattern of P1 to Z. Consider an ideal world adversary S who
runs A internally by playing the role of P2. Note that S can play the role of P2
faithfully because P2 has no interaction with Z and FvSSE. Hence it is easy to

see that no Z can distinguish the real world from the ideal world in this case,
too.
Suppose that Z asks A to corrupt P2 (server), but P2 can not break the
reliability at all. That is, Pr(P2 wins) = 0 in Def.2. A may report the communi-
cation pattern of P2 to Z. Then our ideal world adversary S behaves in the same
way as the above mentioned Sim, where the ideal functionality FvSSE plays the
role of the challenger. In this case, no Z can distinguish between the real world
and the ideal world from the deﬁnition of privacy.

Remark 1. Def.1 says that there exists a Sim such that for any interactive dis-
tinguisher (Z in the above case), eq.(2) is negligible. This is the point where the
privacy deﬁnition of of Curtmola et al. [7, Deﬁnition 4.11] does not work.

Suppose that Z asks A to corrupt P2 (server), and P2 breaks the reliability
with negligible probability. That is, Pr(P2 wins) is negligible in Def.2. Then
similarly to the above, no Z can distinguish between the real world and the
ideal world.
Therefore it must be that Z asks A to corrupt P2 (server), and P2 breaks
reliability with non-negligible probability. That is, Pr(P2 wins) is non-negligible
in Def.2. (Otherwise no Z can distinguish between the real world and the ideal
world.) This means that vSSE does not satisfy reliability.

Q.E.D.

5 Construction

In this section, we construct an eﬃcient veriﬁable SSE scheme which satisﬁes
Def.1 and Def.2. Our scheme is based on SSE-2 of Curtmola et al. [6, 7]. (Note
that SSE-2 is not veriﬁable).

5.1 Overview

We ﬁrst illustrate SSE-2 of Curtmola et al. [6, 7] by using an example.
(Store phase:) The client constructs an array I as follows. Let πK be a pseudo-
random permutation, where K is the secret key of the client. Suppose that
D(Austin) = (D3, D6, D10). That is, D3, D6 and D10 contains a keyword Austin.
First the client computes

for i = 1,··· , N . Next let

addrAustin,i = πK(Austin, i)

I(addrAustin,1) = 3, I(addrAustin,2) = 6, I(addrAustin,3) = 10

and

I(addrAustin,i) = dummy

(3)

(4)

for i = 4,··· , N . Do the same thing for all the other keywords. Finally the client
stores I and C = {C1,··· , CN} to the server, where Ci is a ciphertext of Di.
(Search phase:) Suppose that the client wants to retrieve the documents which
contain Austin. Then the client sends

t(Austin) = (addrAustin,1,··· , addrAustin,N )

to the server. From eq.(3) and eq.(4), the server sees that List(Austin) =
{3, 6, 10}. The server then returns (C3, C6, C10) to the client. The client ﬁnally
decrypts them to obtain (D3, D6, D10).

The above scheme satisﬁes privacy, but not reliability. To achieve reliability,
a naive approach is to replace Ci with ˆCi = (Ci, MAC(Ci)). The client stores the
set of such ˆCi to the server. For a query t(Austin), an (honest) server returns
( ˆC3, ˆC6, ˆC10) to the client. However, a malicious server would return ( ˆC3, ˆC6, ˆC11)
or just ( ˆC3, ˆC6). Then the client cannot detect any cheating.

To overcome this problem, we construct I as follows.

I(addrAustin,1) = (3, tag1 = MAC(addrAustin,1, C3))
I(addrAustin,2) = (6, tag2 = MAC(addrAustin,2, C6))
I(addrAustin,3) = (10, tag3 = MAC(addrAustin,3, C10))

and

I(addrAustin,i) = (dummy, tagi = MAC(addrAustin,i, dummy))

for i = 4,··· , N . For a query t(Austin), the server returns (C3, C6, C10) and
(tag1,··· , tagN ) to the client.

The client checks the validity of each tagi. This approach works because the
input to MAC includes addrAustin,i, and addrAustin,i is computed by the client.
Another subtle point is that the index of each Di should appear in I the same
number of times, say max times. (Otherwise the simulator Sim in the deﬁnition
of privacy cannot construct I(cid:48) which is indistinguishable from I. Remember that
Sim must be able to construct I(cid:48) only from |D1|,··· ,|DN| and (cid:96).)

For this problem, Curtmola et al. described the following method in SSE-2

[7, Fig.2].

For each index i:
– let c be the number of entries in I that already contain i.
– for 1 ≤ (cid:96) ≤ max − c, set I[πK(0(cid:96), n + (cid:96))] = i.
The last line is strange because (cid:96) is used in two diﬀerent meanings. (In [7], (cid:96) is
also deﬁned as the bit length of each keyword.) Hence it must be that
– for 1 ≤ k ≤ max − c, set I[πK(0(cid:96), n + k)] = i.
Even so, the above line does not work as shown below. For simplicity, suppose
that c = max− 1 for i = 1,··· , N . Then we have I[πK(0(cid:96), n + 1)] = N at the end
because the entry of I[πK(0(cid:96), n + 1)] is overwritten for i = 1,··· , N . This means
that in I, only N appears max times and the other each i appears max− 1 times.

We will show how to ﬁx this ﬂaw, too.

5.2 Proposed Veriﬁable SSE
Let SKE = (G, E, E−1) be a symmetric-key encryption scheme, where G is a
key generation algorithm, E is an encryption algorithm and E−1 is a decryption
algorithm.
Remember that the set of documents is D = {D1,··· , DN}, and the set of
keywords is W =⊆ {0, 1}(cid:96). Let π : {0, 1}k ×{0, 1}(cid:96)+1+log N → {0, 1}(cid:96)+1+log N be
a pseudo-random permutation. For simplicity, we will write y = π(x) instead of
y = π(K, x), where K is a key.
Let M AC : {0, 1}k × {0, 1}∗ → {0, 1}n be a MAC (a tag generation algo-
rithm). For simplicity, we write tag = MAC(m) instead of tag = MAC(K, m), where
K is a key and m is a message.

Now the proposed veriﬁable SSE scheme is as follows.

Gen(1k): Run G to generate a key K0 of SKE. Choose a key K1 ∈ {0, 1}k of π
Enc(K,D,W): First compute Ci = E(K0, Di) for each Di ∈ D and let C =

and a key K2 ∈ {0, 1}k of MAC randomly. Let K = (K0, K1, K2).
{C1,··· , CN}. Next let I be an array of size 2 × 2(cid:96)N as follows.
1. First let

I(i) ← (dummy, MAC(i, dummy))

2. Next for each w ∈ {0, 1}(cid:96), suppose that D(w) = (Ds1 ,··· , Dsm ). Then

for all i = 1,··· , 2 · 2(cid:96)N .
for j = 1,··· , m, let

addr = π(0, w, j)
tagw,j = MAC(addr, Csj )
I(addr) ← (sj, tagw,j).

3. The index k of each Dk should appear the same number of times in I.
So for each Dk ∈ D, suppose that the index k already appears Nk times
in I. Then for j = 1,··· , 2(cid:96) − Nk, let

addr = π(1, j, k)
tagj,k = MAC(addr, Ck)
I(addr) ← (i, tagj,k)

It is now easy to see that each index i appears 2(cid:96) times in I.
Example 1. Suppose that D(Austin) = (D3, D6, D10). Then

I(π(0, Austin, 1)) = (3, tag(Austin,1))
I(π(0, Austin, 2)) = (6, tag(Austin,2))
I(π(0, Austin, 3)) = (10, tag(Austin,3))

I(π(1, 1, 3)) = (3, tag(1,3))

...

I(π(1, 2(cid:96) − N3, 3)) = (3, tag(2(cid:96)−N3,3))

and etc.

Trpdr(K, w): Output

t(w) = (π(0, w, 1),··· , π(0, w, N )).

Search(I,C, t(w)): Parse t(w) as t(w) = (addr1,··· , addrN ). Suppose that

I(addri) = (si, tagi)

for i = 1,··· , N . First let C(w) ← empty. Next for i = 1,··· , N , add Csi to
C(w) if si (cid:54)= dummy. Finally let

T ag = (tag1,··· , tagN )

Output (C(w), T ag).

Verify(K, t(w), ˜C(w), T ag): Parse t(w), ˜C(w) and T ag as

t(w) = (addr1,··· , addrN )
˜C(w) = ( ˜C1,··· , ˜Cm)
T ag = (tag1,··· , tagN )

First let Xi ← ˜Ci for i = 1,··· , m. Next let Xi ← dummy for i = m+1,··· , N .
Finally if tagi = MAC(addri, Xi) for i = 1,··· , N , then output accept.
Otherwise output reject.

Dec(K, C): Output a document D = E−1(K0, C) for a ciphertext C.

5.3 Security
We assume that the symmetric-key encryption scheme SKE = (G, E, E−1) is
left-or-right (LOR) CPA secure as deﬁned by [2]. The common counter mode
with AES satisﬁes this condition, where AES is assumed to be a pseudo-random
permutation. We also assume that MAC is unforgeable against chosen message
attack.

Theorem 3. The above scheme satisﬁes privacy (see Def.1).

(Proof) We construct a simulator Sim as follows. In the store phase, Sim is
given |D1|,··· ,|DN| and (cid:96).
1. Sim runs Gen(1k) to generate K = (K0, K1, K2).
2. Let C(cid:48)
3. Construct I(cid:48) as if D(w) = (D1,··· , DN ) for all w ∈ {0, 1}(cid:96). This means that

i = E(K0, 0|Di|) for i = 1,··· , N , and let C(cid:48) = {C(cid:48)

1,··· , C(cid:48)

N}.

for each w ∈ {0, 1}(cid:96),

I(cid:48)(π(0, w, i)) = (i, tagi) for i = 1,··· , N
I(cid:48)(π(1, w, i)) = (dummy, tag(cid:48)

i) for i = 1,··· , N

(5)

(6)

where tagi = MAC(π(0, w, i), C(cid:48)

i) and tag(cid:48)

i = MAC(π(1, w, i), dummy).

That is,

I(cid:48)(π(0, w, 1)) = (1, tag1),

I(cid:48)(π(1, w, 1)) = (dummy, tag(cid:48)
1)

...

...

I(cid:48)(π(0, w, N )) = (N, tagN ),

4. Return (I(cid:48),C(cid:48)).

I(cid:48)(π(1, w, N )) = (dummy, tag(cid:48)
N )

In the search phase, for i = 1,··· , q, Sim is given
List(wi) = {s1,··· , sm}

(but not wi). Then Sim returns

t(wi)(cid:48) = (π(0, i, s1),··· , π(0, i, sm), π(1, i, m + 1),··· , π(1, i, N )).

(7)

We will prove that any A cannot distinguish between Gamereal and Gamesim

by using a series of games Game0,··· , Game2, where Game0 = Gamereal. Let

pi = Pr(A outputs b = 1 in Gamei).

– Game1 is the same as Game0 except for that Ci is replaced with C(cid:48)

i of the
above for i = 1,··· , N . Then |p0 − p1| is negligible from our assumption on
SKE.
– Game2 is the same as Game1 except for that I is replaced with I(cid:48) of the above,
and t(wi) is replaced with t(wi)(cid:48) of the above.
Note that the index i of each Di appears 2(cid:96) times in both I and I(cid:48).
Next on t(wi)(cid:48), let

addr1 = π(0, i, s1),··· , addrm = π(0, i, sm),

addrm+1 = π(1, i, m + 1),··· , addrN = π(1, i, N ).

Then from eq.(5) and eq.(6), it is easy to see that

I(cid:48)(addr1) = (s1, tag1),··· ,I(cid:48)(addrm) = (sm, tagm),

I(cid:48)(addrm+1) = (dummy, tag(cid:48)

m+1),··· ,I(cid:48)(addrN ) = (dummy, tag(cid:48)
N )

The value of such I(cid:48)(addri) is the same as the real one. Further π is a
pseudo-random permutation. Hence |p1 − p2| is negligible.

Consequently |p0 − p2| is negligible. Further it is clear that Game2 = Gamesim.
This means that Gamereal and Gamesim are indistinguishable for any A.

Q.E.D.

Theorem 4. The above scheme satisﬁes reliability (see Def.2).

(Proof) Suppose that there exists an adversary A who breaks the reliability for
some (D,W) and some search queries w1,··· , wq. We will show a forger B for
the underlying MAC.
B runs A by playing the role of a client, where the input to the client is
(D,W) in the store phase, and w1,··· , wq in the search phase. In the search
phase, B uses his MAC oracle to compute I.
From our assumption, A returns (C(w)∗, T ag∗) for some query t(w) such that
C(w)∗ is invalid for t(w) and

Verify(K, t(w), C(w)∗, T ag∗) = accept
with non-negligible probability, where w ∈ {w1,··· , wq}. Let

(C(w), T ag) ← Search(I,C, t(w)).

Then C(w)∗ (cid:54)= C(w) because C(w)∗ is invalid for t(w). Suppose that

(8)

(9)

t(w) = (addr1,··· , addrN )
C(w) = (C1,··· , Ck)
1 ,··· , C∗
C(w)∗ = (C∗
m)
1,··· , tag∗
T ag∗ = (tag∗
N )

Since C(w)∗ (cid:54)= C(w), there are three cases.

Case 1: m = k and there exists some C∗
Case 2: m < k.
Case 3: m > k.

i such that C∗

i (cid:54)= Ci.

i = MAC(addri, C∗

i as a forgery. We will
i ) and B

If (Case 1) occurs, then B outputs (addri, C∗

show that this is a valid forgery on MAC. That is, tag∗
never queried (addri, C∗

i ) and tag∗

i ) to the MAC oracle.
i = MAC(addri, C∗

i ) from eq.(8).

First it is clear that tag∗
Next it is easy to see that B queried (addri, Ci) to his MAC oracle when
computing I from eq.(9). It means that B did not query (addri, C∗
i ) to the
MAC oracle because B does not query addri to the MAC oracle more than once
when computing I. This means that B succeeds in forgery.
m) and tag∗
If (Case 3) occurs, then B outputs (addrm, C∗
show that these are valid forgeries on MAC similarly.

If (Case 2) occurs, then B outputs (addrm+1, dummy) and tag∗

m+1 as a forgery.
m as a forgery. We can

This is against our assumption on MAC. Hence our scheme satisﬁes reliability.
Q.E.D.

Corollary 1. The corresponding protocol ΣvSSE is UC-secure against non-adaptive
adversaries.

(Proof) From Theorem 2.

Q.E.D.

References

1. S.Bellovin and W.Cheswick: Privacy-Enhanced Searches Using Encrypted Bloom
Filters, Cryptology ePrint Archive, Report 2006/210, http://eprint.iacr.org/
(2006)

2. M. Bellare, A. Desai, E. Jokipii, P. Rogaway: A Concrete Security Treatment of

Symmetric Encryption. FOCS 1997: pp.394–403 (1997)

3. Ran Canetti, Universally Composable Security: A New Paradigm for Crypto-

graphic Protocols, Revision 1 of ECCC Report TR01-016 (2001)

4. Ran Canetti, Universally Composable Signatures, Certiﬁcation and Authentica-

tion, Cryptology ePrint Archive, Report 2003/239 http://eprint.iacr.org/ (2003)

5. Ran Canetti, Universally Composable Security: A New Paradigm for
2000/067

ePrint Archive, Report

Cryptographic Protocols, Cryptology
http://eprint.iacr.org/ (2005)

6. R.Curtmola, J.A. Garay, S.Kamara, R.Ostrovsky: Searchable symmetric encryp-
tion: improved deﬁnitions and eﬃcient constructions. ACM Conference on Com-
puter and Communications Security 2006: pp.79–88 (2006)

7. Full version of

the above: Cryptology ePrint Archive, Report 2006/210,

http://eprint.iacr.org/ (2006)

8. Y.Chang and M.Mitzenmacher: Privacy Preserving Keyword Searches on Remote

Encrypted Data. ACNS 2005: pp.442–455 (2005)

9. Eu-Jin Goh: Secure Indexes. Cryptology ePrint Archive, Report 2003/216,

http://eprint.iacr.org/ (2003)

10. D.Song, D.Wagner, A.Perrig: Practical Techniques for Searches on Encrypted Data.

IEEE Symposium on Security and Privacy 2000: pp.44–55 (2000)

