Take This Personally: Pollution Attacks  

on Personalized Services

Xinyu Xing, Wei Meng, and Dan Doozan, Georgia Institute of Technology;  

Alex C. Snoeren, University of California, San Diego;  

Nick Feamster and Wenke Lee, Georgia Institute of Technology

Open access to the Proceedings of the 22nd USENIX Security Symposium is sponsored by USENIXThis paper is included in the Proceedings of the 22nd USENIX Security Symposium.August 14–16, 2013 • Washington, D.C., USAISBN 978-1-931971-03-4Take This Personally: Pollution Attacks on Personalized Services

Xinyu Xing, Wei Meng, Dan Doozan, Alex C. Snoeren†, Nick Feamster, and Wenke Lee

Georgia Institute of Technology and †UC San Diego

Abstract

Modern Web services routinely personalize content
to appeal to the speciﬁc interests, viewpoints, and con-
texts of individual users. Ideally, personalization allows
sites to highlight information uniquely relevant to each
of their users, thereby increasing user satisfaction—and,
eventually, the service’s bottom line. Unfortunately, as
we demonstrate in this paper, the personalization mech-
anisms currently employed by popular services have not
been hardened against attack. We show that third parties
can manipulate them to increase the visibility of arbi-
trary content—whether it be a new YouTube video, an
unpopular product on Amazon, or a low-ranking website
in Google search returns. In particular, we demonstrate
that attackers can inject information into users’ proﬁles
on these services, thereby perturbing the results of the
services’ personalization algorithms. While the details of
our exploits are tailored to each service, the general ap-
proach is likely to apply quite broadly. By demonstrating
the attack against three popular Web services, we high-
light a new class of vulnerability that allows an attacker
to affect a user’s experience with a service, unbeknownst
to the user or the service provider.

1

Introduction

The economics of the Web ecosystem are all about clicks
and eyeballs. The business model of many Web services
depends on advertisement: they charge for prime screen
real estate, and focus a great deal of effort on develop-
ing mechanisms that make sure that the information dis-
played most prominently is likely to create revenue for
the service, either through a direct ad purchase, com-
mission, or at the very least improving the user’s ex-
perience. Not surprisingly, malfeasants and upstanding
business operators alike have long sought to reverse engi-
neer and exploit these mechanisms to cheaply and effec-
tively place their own content—whether it be items for

sale, malicious content, or afﬁliate marketing schemes.
Search engine optimization (SEO), which seeks to im-
pact the placement of individual Web pages in the results
provided by search engines, is perhaps the most widely
understood example of this practice.

Modern Web services are increasingly relying upon
personalization to improve the quality of their customers’
experience. For example, popular websites tailor their
front pages based on a user’s previous browsing history
at the site; video-sharing websites such as YouTube rec-
ommend related videos based upon a user’s watch his-
tory; shopping portals like Amazon make suggestions
based on a user’s previous purchases; and search engines
such as Google return customized results based upon a
wide variety of user-speciﬁc factors. As the Web be-
comes increasingly personal, the effectiveness of broad-
brush techniques like SEO will wane. In its place will
rise a new class of schemes and outright attacks that ex-
ploit the mechanisms and algorithms underlying this per-
sonalization. In other words, personalization represents
a new attack surface for all those seeking to steer user
eyeballs, regardless of their intents.

In this paper, we demonstrate that contemporary per-
sonalization mechanisms are vulnerable to exploit.
In
particular, we show that YouTube, Amazon, and Google
are all vulnerable to the same class of cross-site scripting
attack, which we call a pollution attack, that allows third
parties to alter the customized content the services return
to users who have visited a page containing the exploit.
Although the attack is quite effective, we do not claim
that it is the most powerful, broadly applicable, or hard
to defeat. Rather, we present it as a ﬁrst example of a
class of attacks that we believe will soon—if they are not
already—be launched against the relatively unprotected
underbelly of personalization services.

Our attack exploits the fact that a service employing
personalization incorporates a user’s past history (includ-
ing, for example, browsing, searching and purchasing ac-
tivities) to customize the content that it presents to the

USENIX Association  

22nd USENIX Security Symposium  671

1

user. Importantly, many services with personalized con-
tent log their users’ Web activities whenever they are
logged in regardless of the site they are currently visiting;
other services track user activities on the site even if the
user is logged out (e.g., through a session cookie). We
use both mechanisms to pollute users’ service proﬁles,
thereby impacting the customized content returned to the
users in predictable ways. Given the increasing portfolio
of services provided by major players like Google and
Amazon, it seems reasonable to expect that a large frac-
tion of users will either be directly using the service or at
least logged in while browsing elsewhere on the Web.

We show that pollution attacks can be extremely effec-
tive on three popular platforms: YouTube, Google, and
Amazon. A distinguishing feature of our attack is that
it does not exploit any vulnerability in the user’s Web
browser. Rather, it leverages these services’ own person-
alization mechanisms to alter user’s experiences. While
our implementation employs cross-site request forgery
(XSRF) [13], other mechanisms are possible as well.

The ability to trivially launch such an attack is es-
pecially worrisome because it indicates the current ap-
proach to Web security is ill-equipped to address the
vulnerabilities likely to exist in personalization mecha-
nisms. In particular, today’s Web browsers prevent ex-
ploits like cross-site scripting and request forging by en-
forcing boundaries between domains though “same ori-
gin” policies. The limitations of these approaches are
well known, but our attack represents a class of exploits
that cannot be stopped by client-side enforcement: in an
attempt to increase the footprint of its personalization en-
gine (e.g., Google recording search queries that a user
enters on a third-party page), a service with personalized
services is providing the cross-site vector itself. Hence,
only the service can defend itself from such attacks on its
personalization. Moreover, enforcing isolation between
independent Web sessions seems antithetical to the goal
of personalization, which seeks to increase the amount of
information upon which to base customization attempts.

This paper makes the following contributions:

• We describe pollution attacks

three
platforms—YouTube, Google, and Amazon—that
allow a third party to alter the personalized content
these services present
to users who previously
visited a Web page containing the exploit.

against

• We study the effectiveness of our attack on each of
these platforms and demonstrate that it (1) can in-
crease the visibility of almost any YouTube chan-
nel; (2) dramatically increase the ranking of most
websites in the short term, and even have lasting im-
pacts on the personalized rankings of a smaller set
of sites, and (3) cause Amazon to recommend rea-
sonably popular products of the attacker’s choosing.

2

• Our attack and its effectiveness illustrates the im-
portance of securing personalization mechanisms in
general. We discuss a number of implications of our
study and ways for websites to mitigate similar vul-
nerabilities in the future.

The rest of the paper is organized as follows. Section 2
provides a general overview of pollution attacks on per-
sonalized services. Sections 3, 4, and 5 introduce speciﬁc
attacks that can be launched against YouTube, Google,
and Amazon, respectively, and report on our success. We
survey related work in Section 6 and discuss limitations
of our work and possible defenses in Section 7 before
concluding in Section 8.

2 Overview and Attack Model

In this section, we present a brief overview of personal-
ization as it is used by popular Web services. We then
present a model of pollution attacks, which we apply
to three different scenarios later in the paper: YouTube,
Amazon, and Google.

2.1 Personalization
Online services are increasingly using personalization to
deliver information to users that is tailored to their inter-
ests and preferences. Personalization potentially creates
a situation where both the service provider and the user
beneﬁt: the user sees content that more closely matches
preferences, and the service provider presents products
that the user is more likely to purchase (or links that the
user is more likely to click on), thus potentially resulting
in higher revenues for the service provider.

The main instrument that a service provider can use to
affect the content that a user sees is modifying the choice
set, the set of results that a user sees on a particular screen
in response to a particular query. The size of a choice
set differs for different services. For example, YouTube
shows the user anywhere from 12–40 videos; Amazon
may show the user up to ﬁve sets of recommended prod-
ucts; Google’s initial search results page shows the top
ten results. Figure 1 shows several examples of choice
sets on different sites.

When a user issues a query, a service’s personaliza-
tion algorithm affects the user’s choice set for that query.
The choice set that a personalization algorithm produces
depends on a user query, as well as a number of auxil-
iary factors, including the universe of all possible con-
tent and the user’s browsing history. Previous work has
claimed that many factors, ranging from geography to
time of day, may affect the choice set that a user sees.
For the purposes of the attacks in this paper, we focus on
how changes to a user’s history can affect the choice set,

672  22nd USENIX Security Symposium 

USENIX Association

USENIX Association  

22nd USENIX Security Symposium  673

(a)CustomizedYouTube.(b)CustomizedAmazon.(c)CustomizedGoogle.Figure1:websiteswithpersonalizedservices(personalizedservicestailorthedataintheredrectangles).Figure2:Overviewofhowhistorypollutioncanulti-matelyaffecttheuser’schoiceset.holdingotherfactorsﬁxed.Inparticular,westudyhowanattackercanpollutetheuser’shistorybygeneratingfalseclicksthroughcross-siterequestforgery(XSRF).Wedescribetheseattacksinthenextsection.2.2PollutionAttacksTheobjectiveofapollutionattackistoaffectauser’schoiceset,givenaparticularinput.Insomecases,auser’schoicesetappearsbeforetheuserentersanyin-put(e.g.,uponaninitialvisittothepage).Inthiscase,theattacker’sgoalmaybetoaffectadefaultchoiceset.Figure2showsanoverviewoftheattacker’sgoal:theattackeraimstoaffecttheresultingchoicesetbyalter-ingtheuser’shistorywithfalseclicks,usingcross-siterequestforgeryastheattackvector.Thisattackrequiresthreesteps:1.Modeltheservice’spersonalizationalgorithm.Weassumethattheattackerhassomeabilitytomodelthepersonalizationalgorithmthatthesiteusestoaf-fecttheuser’schoiceset.Inparticular,theattackermusthavesomeideaofhowtheuser’spasthistoryaffectstheuser’schoiceset.Thisinformationisof-tenavailableinpublishedwhitepapers,butinsomecasesitmayrequireexperimentation.2.Createa“seed”topollutetheuser’shistory.Givensomeknowledgeofthepersonalizationalgorithmandagoalforhowtoaffectthechoiceset,theat-tackermustdesigntheseedthatisusedtoaffecttheuser’schoiceset.Dependingontheservice,theseedmaybequeries,clicks,purchases,oranyotheractivitythatmightgointotheuser’shistory.Agoodseedcanaffecttheuser’schoicesetwithaminimalnumberof“falseclicks”,aswedescribenext.3.Injecttheseedwithavectoroffalseclicks.Topol-luteauser’shistory,inmostcaseswerequirethattheuserbesignedintothesite.(Forsomeservices,pollutioncantakeplaceevenwhentheuserisnotsignedin.)Then,theattackercanuseamechanismtomakeitappearasthoughtheuseristakingactionontheWebsiteforaparticularservice(e.g.,click-ingonlinks)usingaparticularattackvector.Inthefollowingsections,weexplorehowanattackercanapplythissameproceduretoattackthepersonalizationalgorithmsofthreedifferentservices:YouTube,Ama-zon,andGooglesearch.3PollutionAttacksonYouTubeInthissection,wedemonstrateourattackonYouTube1.FollowingtheattackstepswedescribedinSection2,weﬁrstmodelhowYouTubeusesthewatchhistoryofaYouTubeuseraccounttorecommendvideosbyreview-ingtheliterature[5].Second,wediscusshowtoprepareseeddata(i.e.,seedvideos)topromotetargetdata(i.e.,targetvideosbelongingtoaspeciﬁcchannel).Third,weintroducehowtoinjecttheseedvideostoaYouTubeuseraccount.Finally,wedesignexperimentsandquantifytheeffectivenessofourattack.3.1YouTubePersonalizationYouTubeconstructsapersonalizedlistofrecommendedvideosbaseduponthevideosauserhaspreviouslyviewed[5].YouTubeattemptstoidentifythesubsetofpreviouslyviewedvideosthattheuserenjoyedbycon-sideringonlythosevideosthattheuserwatchedforalongperiodoftime.Typically,YouTuberecommendsvideosthatotheruserswithsimilarviewinghistories1Ademovideoisavailableathttp://www.youtube.com/watch?v=8hij52ws98A.3have also enjoyed. YouTube tracks the co-visitation re-
lationship between pairs of videos, which reﬂects how
likely a user who watched a substantial portion of video
X will also watch and enjoy video Y . In general, there
may be more videos with co-visitation relationships than
there is display area, so YouTube prioritizes videos with
high rankings. YouTube will not recommend a video the
user has already watched.

YouTube displays recommended videos in the sugges-
tion list placed alongside with a playing video (e.g., Fig-
ure 5) and in the main portion of the screen at the end of
a video (Figure 1(a)). A suggestion list appearing next to
a video typically contains 20–40 suggested videos, two
of which are recommended based upon personalization.
At the end of a video, YouTube shows an more concise
version of the suggestion list that contains only twelve of
the videos from the full list; these videos may or may not
contain personal recommendations.

3.2 Preparing Seed Videos
YouTube organizes videos into channels, where each
channel corresponds to the set of uploads from a particu-
lar user. In our attack, we seek to promote a set of target
videos, ΩT , all belonging to the same YouTube channel,
C. To do so, we will use an additional set of seed videos,
ΩS, that have a co-visitation relationship with the target
videos. By polluting a user’s watch history with videos in
ΩS, we can cause YouTube to recommend videos in ΩT .
There are two ways to obtain ΩS: we can identify videos
with pre-existing co-visitation relationships to the target
videos, or we can create the relationships ourselves.

Existing Relationships.
In the simplest version of the
attack, the attacker identiﬁes existing videos to use as
the seed set. For example, given a target video set
ΩT belonging to channel C,
the attacker could con-
sider all of the other videos in the channel, C − ΩT ,
as candidate seeds. For every candidate video, the at-
tacker checks which videos YouTube recommends when
a fresh YouTube account (i.e., a YouTube account with
no history) watches it. YouTube allows its users to view
their recommended videos at http://www.youtube.
com/feed/recommended.
If the candidate video trig-
gers YouTube to recommend a video in ΩT , then the at-
tacker adds the injected video to seed video set ΩS.

In general, this process allows the attacker to identify
seed videos for every target video in ΩT . The attacker
cannot yet launch the attack, though, because a YouTube
video in ΩS may trigger YouTube to also recommend
videos not in ΩT . To address this issue, the attacker can
simply add these unwanted videos to the seed video set
ΩS because YouTube does not recommend videos that
the user has already watched. As we will show later, the

attacker can convince YouTube that the user watched, but
did not enjoy, these unwanted videos, so their inclusion
in ΩS will not lead to additional recommendations.

Fabricating Relationships. For some videos, it may
be difﬁcult to identify a seed set ΩS that recommends all
of the elements of ΩT due to lack of co-visitation rela-
tionships for some of the target elements. Instead, attack-
ers who upload their own content to use as the seed set
can create co-visitation relationships between this con-
tent and the target set. In particular, an attacker uploads
a set of videos, Ω0, and establishes co-visitation relation-
ships between Ω0 and ΩT through crowd-sourcing (e.g.,
Mechanical Turk or a botnet): YouTube visitors need
only watch a video in Ω0 followed by a video in ΩT .
After a sufﬁcient number of viewing pairs, the attacker
can use videos in Ω0 as the seed set. As we will show in
Section 3.4.1, a relatively small number of viewing pairs
sufﬁces.

3.3

Injecting Seed Videos

To launch the attack and inject seed videos into a
victim’s YouTube watch history, an attacker can harness
XSRF to forge the following two HTTP requests for each
video in the seed set: (1) http://www.youtube.com/
user_watch?plid=<value>&video_id=<value>,
and (2) http://www.youtube.com/set_awesome?
plid=<value>&video_id=<value>, where
plid
and video id correspond to the values found in the
source code of the seed video’s YouTube page. The
ﬁrst HTTP request spoofs a request from the victim to
start watching the seed video, and the second convinces
YouTube that the victim watched the video for a long
period of time. Both HTTP requests are required for
videos in ΩS to trigger the recommendation of videos in
ΩT , but only the ﬁrst HTTP request is needed to prevent
the recommendation of unwanted videos.

3.4 Experimental Design

We evaluated the effectiveness of our attack both in con-
trolled environments and against real YouTube users. We
ﬁrst validated the the attack in the simplest scenario,
where the attack promoted existing YouTube channels
through existing co-visitation relationships. We then
considered the scenario where an attack seemed to up-
load and promote content from a channel that the attacker
created. Finally, we conducted a small-scale experiment
to demonstrate the effectiveness of the attack against a
volunteer set of real YouTube users.

674  22nd USENIX Security Symposium 

USENIX Association

4

3.4.1 New Accounts
We ﬁrst promoted existing YouTube channels by launch-
ing our attack against victims with fresh YouTube user
accounts. This experiment conﬁrms the effectiveness of
our approach in the absence of other, potentially counter-
vailing inﬂuences, such as recommendations based on a
user’s existing history.

We began by selecting 100 existing YouTube channels
at random from the list of the top 2,000 most-subscribed
channels published by VidStatsX [19]. For each of the
selected YouTube channels, we randomly selected 25
videos from the channel as the target video set, used the
method described in the previous section to identify a
seed video set, and injected the seed videos to a fresh
YouTube account.

We then considered promoting new content by creat-
ing our own YouTube channel and similarly attacking
fresh YouTube accounts. Our YouTube channel contains
two 3-minute videos. We selected one of the videos as
a one-element target video set and used the other as the
seed set. We created a co-visitation relationship by em-
bedding both videos on a web page and recruiting volun-
teers to watch both videos sequentially. We obtained 65
and 68 views for our seed and target video respectively.

3.4.2 Existing Accounts
We studied the effectiveness of our pollution attack using
real YouTube user accounts. We recruited 22 volunteers
with extensive pre-existing YouTube watch histories. To
limit the inconvenience to our volunteers, we limited our
study to attempting to promote one moderately popular
YouTube channel based upon existing co-visitation rela-
tionships. We selected a moderately popular account be-
cause a popular channel may be recommended anyway
(regardless of out attack); conversely, an entirely new
channel requires a certain amount of effort to establish
the co-visitation relationships as described above and we
have limited volunteer resources.

Based on these parameters, we arbitrarily selected the
channel OnlyyouHappycamp. We believe this selection
is a reasonable candidate to be promoted using our attack
for several reasons. First, compared to popular chan-
nels, most videos in OnlyyouHappycamp have low view
counts (about 2,000 view counts per video on average)
and the number of subscribers to the channel is a simi-
larly modest 3,552. Both of these are easily achievable
by an attacker at fairly low cost2. Second, most videos in
OnlyyouHappycamp are 22 minutes long, which makes
them suitable for promotion. As we will explain in Sec-
tion 3.5.1, the length of a target video affects its likeli-

2According to the prices in underground markets such as
freelancer.com and fiverr.com, 40,000 view counts and 10,000
subscribers cost $15 and $30 US dollars, respectively.

e

t

a
r
 

n
o

i
t

o
m
o
r
P

3

.

0

2

.

0

1

.

0

0

.

0

1

3

5

7

14

9 11
17
Target video ID

20

23

Figure 3: The promotion rate for each of the 25 target
videos in channel lady16makeup. Two videos were rec-
ommended in each of the 114 trials.

hood for being recommended as a result of a co-visitation
relationship with another video.

Similar to the experiments with new accounts, we ran-
domly selected 15 target videos from channel Onlyy-
ouHappycamp, identiﬁed a seed set, and injected the
seed videos into the volunteers’ YouTube accounts. Af-
ter pollution, the volunteers were asked to use their ac-
counts to watch three videos of their choice and report
the suggestion list displaying alongside each of their
three videos.

3.5 Evaluation
We evaluated the effectiveness of our pollution attacks
by logging in as the victim user and viewing 114 repre-
sentative videos3. We measured the effectiveness of our
attack in terms of promotion rate: the fraction of the 114
viewings when at least one of the target videos was con-
tained within the video suggestion list. Recall that the
list contains at most two personalized recommendations
(see Section 3.1); we deem the attack successful if one
or both of these videos are videos that were promoted as
a result of a pollution attack.

3.5.1 New Accounts

Pollution attacks successfully promoted target videos
from each of the 100 selected existing channels: Each
time we injected seed videos for a particular channel, we
observed the target videos in the suggestion list for each
of the 114 videos. Since these are fresh accounts, there
is no other history, so our targeted videos always occupy
both of the personalized recommendation slots.

In addition, we observed the particular target videos
shown in the suggestion video list varied, even when

3We attempted to view 150 videos random from a trace of YouTube
usage at our institution over the course of several months. Unfortu-
nately, 36 of the videos were no longer available at the time of our
experiment.

USENIX Association  

22nd USENIX Security Symposium  675

5

676  22nd USENIX Security Symposium 

USENIX Association

123456789Target video rankPromotion rate0.00.10.20.30.40.50.6(a)Higherrankedvideo12345678911Target video rankPromotion rate0.00.10.20.30.40.50.6(b)LowerrankedvideoFigure4:Distributionofthesuggestionslotsoccupiedbyeachofthetwosuccessfullypromotedtargetvideos.wewereviewingthesamevideousingthesamevictimYouTubeaccount.Inotherwords,everytargetvideohasachancetobepromotedandshownonthesuggestionvideolistnomatterwhichvideoavictimplays.Fig-ure3showsthefrequencywithwhicheachofthe25tar-getvideosforarepresentativechannel,lady16makeup.Inanattempttoexplainthisvariation,wecomputed(1)thePearsoncorrelationbetweentheshowingfrequenciesandthelengthsofthetargetvideosforeachchannel(ρt);(2)thePearsoncorrelationbetweentheshowingfrequen-ciesandtheviewcountsofthesetargetvideosforeachchannel(ρcnt).WefoundtheaveragePearsoncorrela-tionvaluesaremedium(ρt=0.54)andmoderate(ρcnt=0.23),respectively.Thissuggeststhatboththelengthandviewcountofatargetvideoinﬂuenceitsrecommenda-tionfrequency,butthelengthofatargetvideoisamoresigniﬁcantfactor.Sincescreenrealestateisprecious,anduserstypicallyfocusontheﬁrstfewitemsofalist,wereportonthepo-sitionwithinthesuggestedvideoliststhatourtargetedvideosoccupiedwhentheywerepromoted.Weobservedthatthetwotargetvideoswereusuallyplacedback-to-backonthesuggestionlist.Figure4showsthatYouTubeusuallyplacedourtargetvideosamongthetopfewspotsofavictim’ssuggestionlist:inourtestswithnewac-counts,thetargetvideoswerealwaysrecommendedandplacedonthetop12,whichmeanttheyalsoappearedattheendofviewedvideos.Thisﬁndingisparticu-larlysigniﬁcantbecauseitimpliesthatourtargetvideosareshownevenifavictimﬁnisheswatchingaYouTubevideoonathird-partywebsite(whichtypicallyembedsonlytheview-screenportionoftheYouTubepage,andnotthefullsuggestionlist).Ourattacksweresimilarlycompletelysuccessfulinpromotingnewlyuploadedcontent.Asacontrol,wealsosignedinasnon-pollutedfreshYouTubeaccountsand,unsurprisingly,didnotﬁndanyofournewcon-tentamongthevideosinthesuggestionlist.Inotherwords,thevideoswererecommendedexclusivelybe-causeofourattacks;ourexperimentsweresufﬁcientlyFigure5:Suggestionlistsbefore(left)andafter(right)apollutionattackagainstafreshYouTubeuseraccount.Thevideohighlightedinredisouruploadedvideo.200500100020005000100000.20.40.60.81.0Watch historyPromotion rateFigure6:Promotionsuccessratesfor10realYouTubeuseraccountswithvaryingwatchhistorylengths.smallthatwedidnotleadYouTubetoconcludethatourcontentwas,infact,universallypopular.Figure5showsasamplescreenshotcomparingthesuggestionlistsfromavictimaccountandanother,non-exploitedfreshac-count.Finally,wefoundthatoneofourtargetvideosoccupiedthetopsuggestionslotwhileviewing80outofthe114testvideos.3.5.2ExistingAccountsOurattacksweresomewhatlesssuccessfulonrealYouTubeaccounts.Wefoundthat14outofthe22volun-teerYouTubeusersreportedthatatleastoneofourtar-getvideosfromchannelOnlyyouHappycampappearedinthesuggestionlistduringeachoftheirthreevideoviewings,a64%promotionrate.Tounderstandwhywewereabletoexploitsomeac-countsandnotothers,weaskedourvolunteerstosharetheirYouTubewatchhistories.Tenofourvolunteerssharedtheirhistorieswithusandallowedustosigninto6their YouTube accounts to conduct a further study. The
number of videos in the watch histories of the ten vol-
unteers ranged from a few hundred to tens of thousands.
Figure 6 shows the relationship between the number of
watched videos in a watch history and the number of
times that at least one of our target videos is displayed
along with a playing video. While there appears to be an
intuitive decreasing trend (i.e., the longer the history an
account has the more resistant it is to pollution), there are
obvious outliers. For example, one account with almost
3,500 previous viewings in its history succumbed to our
attacks almost 80% of the time.

Consistent with the Pearson coefﬁcients reported ear-
lier, we found that the success of our attacks depends on
the rankings and lengths of the videos that are otherwise
suggested based upon a user’s history. In particular, we
observed that the majority of the videos recommended
to users for whom our attacks have low promotion rates
have longer lengths and more view counts than our tar-
get videos, while the videos that YouTube recommends
based on the watch history of the user with 3,500 previ-
ous viewings have shorter lengths than our target videos
(though they generally have higher view counts than our
targets).

Although we believe our attack demonstrates that
YouTube’s personalization mechanism is subject to ex-
ploit, the persistence of the attack effects is unclear. In
our experiments, volunteers watched arbitrary YouTube
videos right after being attacked, but we believe our pol-
lution attacks on YouTube are likely to last for some
time. Although YouTube does not explicitly disclose
how time factors into their recommendation system (if
at all) [5], analysis of volunteers’ watch histories indi-
cates that a YouTube video that was watched as long as
two weeks prior is still used for generating recommended
videos.

4 Google Personalized Search

In this section, we show how history pollution attacks
can be launched against Google’s search engine4. The
goal of our attack is to promote a target webpage’s rank
in the personalized results that Google returns for an ar-
bitrary search term by injecting seed search terms into a
victim’s search history.

4.1 Search Personalization
Search personalization customizes search results using
information about users, including their previous query
terms, click-through data and previously visited web-
sites. The details of Google’s personalization algorithms
4A demo video is available at http://www.youtube.com/

watch?v=73E5CLFYeu8.

are not public, but many previous studies have explored
aspects of personalized search [2,4,6,7,9,10,14–18]. We
describe two classes of personalization algorithms: con-
textual personalization and persistent personalization.
According to recent reports [11,12], many search engines
including Google, Bing, and Yahoo! apply both types of
personalization.

Contextual personalization constructs a short-term
user proﬁle based on recent searches and clicks-
through [4, 16]. When a user searches for “inexpen-
sive furniture” followed by “maternity clothes,” Google’s
contextual personalization algorithm typically promotes
search results that relate to “inexpensive maternity
clothes” for the next few searches (we provide an anal-
ysis of precisely how long this effect
lasts in Ap-
pendix A.2). In contrast, persistent personalization uses
the entire search history—as opposed to only recent
searches—to develop a user proﬁle [9, 15]. Personaliza-
tion that occurs over the longer term may not affect a
user’s search results as dramatically, but can have longer-
lasting effects for the results that a user sees. For exam-
ple, searching for “Egypt” using different accounts may
result in two distinct result sets: one about tourism in
Egypt and one related to the Arab Spring.

Identifying Search Terms

4.2
Given the differing underlying algorithms that govern
contextual and persistent personalization, an attacker
needs to select different sets of seed search terms depend-
ing on the type of attack she hopes to launch.

Contextual Personalization. For the contextual per-
sonalization attack, the keywords injected into a user’s
search history should be both relevant to the promot-
ing keyword and unique to the website being promoted.
In particular, the keywords should be independent from
other websites that have similar ranking in the search re-
sults, to ensure that only the target website is promoted.
Presumably, an attacker promoting a speciﬁc website is
familiar with the website and knows what keywords best
meet these criteria, but good candidate keywords are also
available in a website’s meta keyword tag. While Google
no longer incorporates meta tags into their ranking func-
tion [3], the keywords listed in the meta keyword tag still
provide a good summary of the page’s content.

Persistent Personalization. Launching a persistent
personalization attack requires a different method of ob-
taining keywords to inject. In this case, the size of the
keyword set should be larger than that used for a contex-
tual attack in order to have a greater effect on the user’s
search history. Recall that contextual attacks only affect
a user’s current session, while persistent attacks pollute

USENIX Association  

22nd USENIX Security Symposium  677

7

a user’s search history in order to have a lasting effect on
the user’s search results. An attacker can determine suit-
able keywords using the Google AdWords tool, which
takes as an input a search term and URL and produces a
list of about one hundred related keywords. Ideally, an
attacker could pollute a user’s search history with each
of these terms, but a more efﬁcient attack should be ef-
fective with a much smaller set of keywords. We deter-
mined that an attacker can safely inject roughly 50 key-
words a minute using cross-site request forgery; more
rapid search queries are ﬂagged by Google as a screen-
scraping attack. For this study, we assume an attacker
can inject at most 25 keywords into a user’s proﬁle, but
the number of keywords can increase if the user stays on
a webpage for more than 30 seconds. Not all keyword
lists that AdWords returns actually promote the target
website. The effectiveness of this attack likely depends
on several factors, including the user’s current search his-
tory. In Section 4.5, we evaluate the effectiveness of this
attack under different conditions.

Injecting Search Terms

4.3
As with the pollution attacks on YouTube, the attack on
Google’s personalized search also uses XSRF to inject
the seeds. For example, an attacker can forge a Google
search by embedding https://www.google.com/
search?hl=en&site=&q=usenix+security+2013
into an invisible iframe. A Web browser will issue
an embedded HTTP request, even if Google search
response has an enabled X-Frame-Option header.
Injecting search terms into a Google user’s account
affects the search results of
the user’s subsequent
searches. The number and set of search terms to inject
differs depending on whether an attacker can execute a
contextual or persistent personalization attack.

4.4 Experimental Design
To cleanly study the effects of our proposed attacks on
contextual and persistent search personalization, we con-
ducted most of our experiments using Google accounts
with no search history. To validate whether our results
apply to real users, we also conducted a limited number
of tests using accounts that we constructed to mimic the
personae of real users.

To quantify the effectiveness of our attack in general,
we must select an unbiased set of target web pages whose
rankings we wish to improve. We built two test corpora,
one for attacks on contextual personalization, and one for
attacks on persistent personalization. We attempted to
promote existing web sites using only their current con-
tent and link structure; we did not perform any SEO on
websites before conducting the attacks. We believe this

represents a conservative lower bound on the effective-
ness of the attack, as any individual website owner could
engineer the content of their site to tailor it for promotion
through search history pollution.

4.4.1 Contextual Pollution

We started by scraping 5,671 shopping-related keywords
from made-in-china.com to use as search terms. We
then entered each of these terms into Google one-by-one
to obtain the top 30 (un-personalized) search results for
each. Since some of our search terms are related, not all
of these URLs are unique. Additionally, we cannot hope
to improve the URLs that are already top-ranked for each
of the search terms. We obtained 151,363 URLs whose
ranking we could hope to improve.

Because we cannot manually inspect each of these
websites to determine appropriate seed search terms, we
instead focused a subset that include the meta keyword
tag. For the approximately 90,000 such sites, we ex-
tracted the meta keywords or phrases from the website.
Many of these keywords are generic and will appear in
a wide variety of websites. To launch the attack, we re-
quire keywords that are unique to the website we wish to
promote (at least relative to the other URLs returned in
response to the same query), so we ignored any keywords
that were associated with multiple URLs in the same set
of search results.

This procedure ultimately yielded 2,136 target URLs
spanning 1,739 different search terms, for which we had
a set of 1–3 seed keywords to try to launch a contextual
pollution attack. The average search term has 1.23 results
whose ranking we tried to improve. Figure 11 in the Ap-
pendix shows the distribution of the original rankings for
each of these target websites; the distribution is skewed
toward highly ranked sites, perhaps because these sites
take care in selecting their meta tag keywords.

4.4.2 Persistent Pollution

Once again, we begin by selecting 551 shopping-related
search terms and perform Google searches with each of
the search terms to retrieve the top 30 search results. As
opposed to the contextual attack, where we search for
keywords that differentiate the results from one another,
we aim to determine search terms that will be associated
with the website and search-term pair for the long term.
As described in Section 4.2, we use a tool provided by
Google AdWords to obtain a set of keywords that Google
associates with the given URL and search term. Con-
structing related keyword lists for each of the 29 search
returns (again excluding the top hit, which we cannot
hope to improve) and 551 search terms yields 15,979 dis-
tinct URLs with associated lists of keywords.

678  22nd USENIX Security Symposium 

USENIX Association

8

For each URL, we select 25 random keywords from
the AdWords list for 25 distinct trials. If a trial improved
a URL’s ranking, we then test the persistence of the at-
tack by performing 20 subsequent queries, each with
a randomly chosen set of Google trending keywords.
These subsequent queries help us verify that the URL
promotion is not just contextual, but does not vanish
when a user searches other content. If after all 25 trials
we ﬁnd no keyword sets that promote the URL’s ranking
and keep it there for 20 subsequent searchers, we deem
this URL attempt a failure. If multiple keyword sets suc-
ceed, we select the most effective (i.e., the set of 25 key-
words that induces the largest ranking improvement) trial
to include in the test set.

4.5 Evaluation
In this section, we quantify the effectiveness of search
history pollution with attacks that aimed to promote the
target websites identiﬁed in the previous section. To
scope our measurements, we consider the effectiveness
of the attacks only for the set of search terms that we
identify; it is quite possible, of course, that our pollution
attacks also affect the rankings of the targeted URLs for
other search terms.

When measuring the effectiveness of our attack, we
use two different criteria, depending upon a website’s
original position in the search results.
In the case of
URLs that are already in the ﬁrst ten search results but
not ranked ﬁrst, we consider the pollution attack success-
ful if it increases the ranking of a URL at all. For URLs
subsequent pages, we consider the attack successful only
if the attack moves the URL to the ﬁrst page of search
results, since improved ranking on any page that is not
the ﬁrst page is unlikely to have any utility.

4.5.1 Top-Ranked Sites

For the 2,136-page contextual attack test corpus, of the
846 pages that appeared on the front page prior to our
attack, we improved the ranking of 371 (44%). The per-
sistent attack was markedly less effective, with only 851
(17%) of the 4,959 test cases that originally appeared
on the ﬁrst page of the search results had ranking im-
provements surviving the persistence test (i.e., they re-
mained promoted after 20 random subsequent queries).
In both cases, however, the probability of success de-
pends greatly on the original ranking of the targeted
URL. For example, promoting a second-ranked URL
to the top-ranked position for contextual personalization
succeeded 1.1% of the time, whereas promoting a tenth-
ranked URL by at least one position succeeded 62.8%
of the time. Similarly, for attacks on persistent person-
alization, moving a second-ranked URL to the top suc-

ceeded 4.3% of the time, and moving a tenth-ranked
URL to a higher-ranked position succeeded 22.7% of the
time. These results make sense, because second-ranked
sites can only move into the top-ranked position, whereas
sites that are ranked tenth can move into any one of nine
higher spots.

To illustrate this effect and illuminate how far each
webpage was promoted, Figure 7 shows the PDF of an
improved webpage’s rank after contextual history pol-
lution, based upon its position in the non-personalized
search results. We observed that contextual pollution was
able to promote most webpages by one or two spots, but
some low-ranking webpages were also promoted to very
high ranks. Similarly, Figure 8 shows the distributions
for each result ranking for those websites whose rankings
were improved by a persistent history pollution attack.
Here, the distributions appear roughly similar (although
the absolute probability of success is much lower), but
it is difﬁcult to draw any strong conclusions due to the
small number of promoted sites of each rank for either
class of attack.

4.5.2 The Next Tier

The remaining 1,290 test websites for the contextual at-
tack were initially on the second or third page of search
results. By polluting a user’s search history with the
unique meta tag keywords associated with each site, we
promoted 358 of them (28%) to the front page. Fig-
ure 7(j) shows that these websites were more likely to
appear at the top of the results than those pages that were
initially at the bottom of the ﬁrst page. We suspect this
phenomenon results from the choice of keywords used
in pollution: because their original rankings were low,
the pollution attack requires a distinguishing keyword to
move one of the webpages to the front page at all.
If
such a keyword can move a search result to the ﬁrst page,
it might also be a good enough keyword to promote the
page to a high rank on the ﬁrst page, as well.

The results from the persistent test set are markedly
different. Figure 8(j) shows that sites starting on the sec-
ond or third page are unlikely to end up at the very top
of the result list due to a persistent history attack: Only
80 (less than 1%) of the 11,020 attacks that attempted
to promote a website appearing on the 2nd or 3rd page
of results was successful in moving it to the front page
(and keeping it there). This results shows that persis-
tent search history attacks are generally best launched for
sites that are already highly ranked, as opposed to con-
textual attacks, which can help even lower-ranked sites.

USENIX Association  

22nd USENIX Security Symposium  679

9

e
t
a
r
 
n
o
i
t
o
m
o
r
P

6

.

0

4

.

0

2

.

0

0

.

0

1

7

5

3

9
Personalized rank

e
t
a
r
 
n
o
i
t
o
m
o
r
P

6

.

0

4

.

0

2

.

0

0

.

0

1

7

5

3

9
Personalized rank

e
t
a
r
 
n
o
i
t
o
m
o
r
P

6

.

0

4

.

0

2

.

0

0

.

0

1

7

5

3

9
Personalized rank

e
t
a
r
 
n
o
i
t
o
m
o
r
P

6

.

0

4

.

0

2

.

0

0

.

0

1

7

5

3

9
Personalized rank

e
t
a
r
 
n
o
i
t
o
m
o
r
P

6

.

0

4

.

0

2

.

0

0

.

0

1

7

5

3

9
Personalized rank

(a) Non-personalized rank
= 2

(b) Non-personalized rank
= 3

(c) Non-personalized rank
= 4

(d) Non-personalized rank
= 5

(e) Non-personalized rank
= 6

e
t
a
r
 
n
o
i
t
o
m
o
r
P

6

.

0

4

.

0

2

.

0

0

.

0

1

7

5

3

9
Personalized rank

e
t
a
r
 
n
o
i
t
o
m
o
r
P

6

.

0

4

.

0

2

.

0

0

.

0

1

7

5

3

9
Personalized rank

e
t
a
r
 
n
o
i
t
o
m
o
r
P

6

.

0

4

.

0

2

.

0

0

.

0

1

7

5

3

9
Personalized rank

e
t
a
r
 
n
o
i
t
o
m
o
r
P

6

.

0

4

.

0

2

.

0

0

.

0

1

7

5

3

9
Personalized rank

e
t
a
r
 
n
o
i
t
o
m
o
r
P

6

.

0

4

.

0

2

.

0

0

.

0

1

7

5

3

9
Personalized rank

(f) Non-personalized rank
= 7

(g) Non-personalized rank
= 8

(h) Non-personalized rank
= 9

(i) Non-personalized rank =
10

(j) Non-personalized rank
> 10

Figure 7: Promotion rates of promoted Google search rankings for successful contextual history pollution attacks.

4.5.3 Real Users

We also evaluate the effectiveness of pollution attacks
on ten volunteers’ accounts with extensive pre-existing
search histories. We ﬁnd that, on average, 97.1% of our
729 previously successful contextual attacks remain suc-
cessful, while only 77.78% of the persistent pollution at-
tacks that work on fresh accounts achieve similar suc-
cess. We believe that users’ search histories sometimes
interfere with the attacks, and that user history inter-
feres more with the attacks on persistent personalization.
Contextualized attacks rely only on a small set of re-
cent search terms to alter the personalized search results,
which is unlikely to be affected by a user’s search history.
In contrast, pollution attacks against persistent personal-
ization rely on more of a user’s search history. If relevant
keywords are already present in a user’s search history,
keyword pollution may be less effective. In any event,
both attacks are relatively robust, even when launched
against users with long search histories.

5 Pollution Attacks on Amazon

Of the three services, Amazon’s personalization is per-
haps the most evident to the end user. On one hand, this
makes pollution-based attacks less insidious, as they will
be visible to the observant user. On the other, of the three
services, Amazon has the most direct monetization path,
since users may directly purchase the goods from Ama-
zon. Therefore, exploitation of Amazon’s personaliza-
tion may be proﬁtable to an enterprising attacker.

Amazon tailors a customer’s homepage based on the

previous purchase, browsing and searching behavior of
the user. Amazon product recommendations consider
each of these three activities individually and explicitly
labels its recommendations according to the aspect of the
user’s history it used to generate them. We focused on the
personalized recommendations Amazon generates based
on the browsing and searching activities of a customer
because manipulating the previous purchase history of a
customer may have unintended consequences.

5.1 Amazon Recommendations
Amazon displays ﬁve recommendation lists on a cus-
tomer’s homepage that are ostensibly computed based on
the customer’s searching and browsing history. Four of
these lists are derived from the products that the customer
has recently viewed (view-based recommendation); the
ﬁfth is based on the latest search term the customer en-
tered (search-based recommendation). For each of the
view-based recommendation lists, Amazon uses relation-
ships between products that are purchased together to
compute the corresponding recommended products; this
concept is similar to the co-visitation relationship that
YouTube uses to promote videos. For the recommenda-
tion list that is computed based on the latest search term
of a customer, the recommended products are the top-
ranked results for the latest search term.

In contrast to the types of personalization used for
YouTube and Google Search, Amazon’s personalization
is based on history that maintained by the user’s web
browser, not by the service. Because customers fre-
quently brows Amazon without being signed in, both the

680  22nd USENIX Security Symposium 

USENIX Association

10

e
t
a
r
 
n
o
i
t
o
m
o
r
P

0
3

.

0

0
2

.

0

0
1

.

0

0
0

.

0

1

7

5

3

9
Personalized rank

e
t
a
r
 
n
o
i
t
o
m
o
r
P

0
3

.

0

0
2

.

0

0
1

.

0

0
0

.

0

1

7

5

3

9
Personalized rank

e
t
a
r
 
n
o
i
t
o
m
o
r
P

0
3

.

0

0
2

.

0

0
1

.

0

0
0

.

0

1

7

5

3

9
Personalized rank

e
t
a
r
 
n
o
i
t
o
m
o
r
P

0
3

.

0

0
2

.

0

0
1

.

0

0
0

.

0

1

7

5

3

9
Personalized rank

e
t
a
r
 
n
o
i
t
o
m
o
r
P

0
3

.

0

0
2

.

0

0
1

.

0

0
0

.

0

1

7

5

3

9
Personalized rank

(a) Non-personalized rank
= 2

(b) Non-personalized rank
= 3

(c) Non-personalized rank
= 4

(d) Non-personalized rank
= 5

(e) Non-personalized rank
= 6

e
t
a
r
 
n
o
i
t
o
m
o
r
P

0
3

.

0

0
2

.

0

0
1

.

0

0
0

.

0

1

7

5

3

9
Personalized rank

e
t
a
r
 
n
o
i
t
o
m
o
r
P

0
3

.

0

0
2

.

0

0
1

.

0

0
0

.

0

1

7

5

3

9
Personalized rank

e
t
a
r
 
n
o
i
t
o
m
o
r
P

0
3

.

0

0
2

.

0

0
1

.

0

0
0

.

0

1

7

5

3

9
Personalized rank

e
t
a
r
 
n
o
i
t
o
m
o
r
P

0
3

.

0

0
2

.

0

0
1

.

0

0
0

.

0

1

7

5

3

9
Personalized rank

e
t
a
r
 
n
o
i
t
o
m
o
r
P

0
3

.

0

0
2

.

0

0
1

.

0

0
0

.

0

1

7

5

3

9
Personalized rank

(f) Non-personalized rank
= 7

(g) Non-personalized rank
= 8

(h) Non-personalized rank
= 9

(i) Non-personalized rank =
10

(j) Non-personalized rank
> 10

Figure 8: Promotion rates of promoted Google search rankings for successful persistent history pollution attacks.

latest viewed products and search term of the customer
are stored in session cookies on the user’s browser rather
than in proﬁles on Amazon servers.

Extractor”, an attacker can use XSRF to inject the search
term “Breville BJE200XL” to replace an Amazon cus-
tomer’s latest search term.

Identifying Seed Products and Terms

5.2
Because Amazon computes the view and search-based
recommendation lists separately, the seed data required
exploit each list must also be different.

Visit-Based Pollution. To promote a targeted product
in a view-based recommendation list, an attacker must
identify a seed product as follows. Given a targeted prod-
uct that an attacker wishes to promote, the attacker visits
the Amazon page of the product and retrieves the related
products that are shown on Amazon page of the targeted
product. To test the suitability of these related products,
the attacker can visit the Amazon page of that product
and subsequently check the Amazon home page. If the
targeted product appears in a recommendation list, the
URL of the candidate related product can serve as a seed
to promote the targeted product.

Search-Based Pollution. To promote a targeted prod-
uct in a search-based recommendation list, it sufﬁces to
identify an appropriate search term. If automation is de-
sired, an attacker could use a natural language toolkit to
automatically extract a candidate keyword set from the
targeted product’s name. Any combination of these key-
words that successfully isolates the targeted product can
be used as the seed search term for promoting the tar-
geted product. For example, to promote product “Bre-
ville BJE200XL Compact Juice Fountain 700-Watt Juice

Injecting Views and Searches

5.3
As with the attacks on the previous two services, the at-
tacker embeds the Amazon URLs of the desired seed
items or search queries into a website that the victim’s
browser is induced to visit with XSRF. For example, if
one seed search terms is “Coffee Maker”, the seed URL
would be something like http://www.amazon.com/s/
?field-keywords=Coffee+Maker. Similarly, an at-
tacker could embed the URL of a seed product into an
invisible img tag as the src of the image. When a victim
visits the attacker’s website, Amazon receives the request
for that particular query or item and customizes the vic-
tim’s Amazon website based on that search.

5.4 Experiment Design
To evaluate the effectiveness of the pollution attack
against, we conducted two experiments. The ﬁrst exper-
iment measured the effectiveness of our attack when tar-
geted toward popular items across different categories of
Amazon products. The second quantiﬁed the effective-
ness of our attack on randomly selected, mostly unpopu-
lar Amazon products.

5.4.1 Popular Products

Amazon categorizes sellers’ products into 32 root cat-
egories. To select products from each category, we

USENIX Association  

22nd USENIX Security Symposium  681

11

t

e
a
r

n
o

1.0
0.8
0.6
0.4
0.2
0.0

i
t

o
m
o
r
P

View based 

Search based 

Magazines
Kitchen.Dining
Jewelry
Beauty
Baby
Home.Improvement
Clothing
Appliances
Arts.Crafts.Sewing
Toys.Games
Computers.Accessories
enood
Sports.Outdoors
Pet.Supplies
Books
Movies.TV
Music.Albums
Electronics
Automotive
Watches
uments
Gift.Cards.Store
Software
Cell.Phones.Accessories
Video.Games
Industrial.Scientific
Health.Personal.Care
Shoes
Camera.Photo
ucts
nstrGarden
Home.Kitch
t.F
.Prod
rocery.Gourme
Patio.Lawn.
e 
Offic
Musical.I

G

Figure 9: Promotion rates across Amazon categories.

scraped the top 100 best-selling products in each cate-
gory in January 2013 and launched a separate attack tar-
geting each of these 3,200 items.

5.4.2 Random Products

To evaluate the effectiveness of the polution attack for
promoting arbitrary products, we also selected prod-
ucts randomly. We downloaded a list of Amazon Stan-
dard Identiﬁcation Number (ASIN) [1] that includes
75,115,473 ASIN records. Because each ASIN repre-
sents a Amazon product, we randomly sampled ASINs
from the list and constructed a set of 3,000 products cur-
rently available for sale. For every randomly selected
product in the list, we recorded the sale ranking of that
product in its corresponding category.

5.5 Evaluation
Because Amazon computes search and visit-based rec-
ommendations based entirely upon the most recent his-
tory, we can evaluate the effectiveness of the pollution
attack without using Amazon accounts from real users.
Thus, we measured the effectiveness of our attack by
studying the success rate of promoting our targeted prod-
ucts for fresh Amazon accounts.

5.5.1 Promoting Products in Different Categories

To evaluate the effectiveness of the pollution attack for
each targeted product, we checked whether the ASIN of
the targeted product matches the ASIN of an item in the
recommendation lists on the user’s customized Amazon
homepage.

Figure 9 illustrates the promotion rate of target prod-
ucts in each category. The view-based and search-based

attacks produced similar promotion rates across all cate-
gories, about 78% on average. Two categories had sig-
niﬁcantly lower propotion rates: Gift-Cards-Store and
Movies-TV (achieving 5% and 25%, respectively).

To understand why these categories yielded lower pro-
motion rates, we analyzed the top 100 best selling prod-
ucts for each category. For Gift-Cards-Store, we found
that there were two factors that distinguish gift cards
from other product types. First, the gift cards all had
similar names;
therefore, using the keywords derived
from the product name resulted in only a small number
of speciﬁc gift cards being recommended. Second, we
found that searching any combination of keywords ex-
tracted from the product names always caused a promo-
tion of Amazon’s own gift cards, which may imply that
it is more difﬁcult to promote product types that Amazon
competes with directly.

Further investigation into the Movies-TV category re-
vealed that Amazon recommends TV episodes differ-
ently. In our attempts to promote speciﬁc TV episodes,
we found that Amazon recommends instead the ﬁrst or
latest episode of the corresponding TV series or the en-
tire series. Because we declared a promotion success-
ful only if the exact ASIN appears in the recommenda-
tion lists, these alternate recommendations are consid-
ered failures. These cases can also be considered suc-
cessful because the attack caused the promotion of very
similar products. Therefore, we believe that for all cat-
egories except for Gift-Cards-Store, an attacker has a
signiﬁcant chance of successfully promoting best-selling
products.

5.5.2 Promoting Randomly Selected Products
We launched pollution attacks on 3,000 randomly se-
lected products. We calculated the Cumulative Success
Rate of products with respect to their rankings. The Cu-

682  22nd USENIX Security Symposium 

USENIX Association

12

a complex network infrastructure, which may consist
of hundreds of search-indexed websites (preferably with
non-trivial reputations at established search engines) to
coordinate and form a link farm [20]. These infrastruc-
tures not only require a considerable amount of money
to build and maintain, but also take time to mature and
reach their full effectiveness [8]. By contrast, launching
a search history pollution attack is signiﬁcantly easier.

We showed in Section 4 that a user’s personalized
search results can be manipulated simply by issuing
crafted search queries to Google. Without requiring any
external support, the entire process happens instantly
while the user is visiting the offending Web page. Al-
though our attack targets individual search users (i.e., the
polluted result is only visible to individual victims), it by
no means limits the scale of the victim population, espe-
cially if an exploit is placed on a high-proﬁle, frequently
visited website.

7 Discussion

Our current study has several limitations. Most notably,
the scale of our experiments is modest, but because we
typically randomly select the target items, we believe that
the results of our experiments are representative, and that
they illustrate the substantial potential impacts of pollu-
tion attacks. Similarly, our speciﬁc pollution attacks are
fragile, as each service can take relatively simple steps to
defend againt them.

A possible defense against pollution attacks arises
from the fact
that cross-site request forgery can be
stopped if requests to a website must carry tokens issued
by the site. Enforcing this constraint, however, also pre-
vents information and behaviors at third-party sites from
being harvested for personalization and hampers the cur-
rent trend of increasing the scope of data collection by
websites for improved personalization. One short-term
effect from this study may be that (some) websites will
begin to consider the tradeoffs between the security and
beneﬁts of personalization.

YouTube in particular uses two separate HTTP re-
quests to track a YouTube’s user viewing activity that
are independent from the act of streaming of the video.
One straightforward defense against pollution attacks is
to monitor the time between the arrivals of the two HTTP
requests. If YouTube ﬁnds the interval is substantially
less than the length of the video, it could ignore the sig-
nal. An attacker can still always inject a short video or
control the timing of the HTTP requests in an effort to
bypass such a defense mechanism. We did notice that
an injected short video can be used to promote multi-
ple longer videos; for example, watching a single two-

Figure 10: Cumulative promotion rates across varying
product ranks for different Amazon pollution attacks.

mulative Success Rate for a given range of product rank-
ings is deﬁned as the ratio of the number of successfully
promoted products to the number of target products in
that range.

Figure 10 shows the cumulative promotion rate for dif-
ferent product rankings for the two different types of pol-
lution attacks. As the target product decreases in popu-
larity (i.e., has a higher ranking position within its cat-
egory) pollution attacks become less effective, but this
phenomenon reﬂects a limitation of Amazon recommen-
dation algorithms, not our attack. Products with low
rankings might not be purchased as often; as a result,
they may have few and weak co-visit and co-purchase re-
lationships with other products. Our preliminary inves-
tigation ﬁnds that products which rank 2,000 or higher
within their category have at least a 50% chance of be-
ing promoted by a visit-based pollution attack, and prod-
ucts with rankings 10,000 and higher have at least a 30%
chance to be promoted using search-based attacks.

6 Related Work

To the best of our knowledge, the line of work most
closely related to ours is black-hat search engine op-
timization (bSEO). Although sharing a common goal
as search history pollution—illicitly promoting website
rankings in search results—bSEO follows a completely
different approach, exploiting a search engine’s reliance
on crawled Web content. Blackhat SEO engineers the
content of and links to Web pages to obtain a favorable
ranking for search terms of interest [8]. Thus, techniques
that address bSEO are unlikely to be effective against
pollution attacks. On the other hand, because bSEO
targets the general indexing and ranking process inside
search engines, any successfully promoted website will
be visible to all search engine users, potentially signiﬁ-
cantly boosting the volume of incoming trafﬁc. Yet, ef-
fective bSEO campaigns typically involve support from

USENIX Association  

22nd USENIX Security Symposium  683

13

second video5 causes YouTube to recommend several
long videos.

International ACM SIGIR Conference on Research and
Development in Information Retrieval (2011).

8 Conclusion

In this paper, we present a new attack on personalized
services that exploits the fact that personalized services
use a user’s past history to customize content that they
present to the user. Our attack pollutes a user’s history
by using cross-site request forgery to stealthily inject and
execute a set of targeted browsing activities in the user’s
browser, so that when the user subsequently accesses the
associated service speciﬁc content is promoted. We illus-
trate how an attacker can pollute a user’s history to pro-
mote certain content across three platforms. While our
attack is simple, its impact can be signiﬁcant if enough
users’ histories are compromised.

As personalization algorithms and mechanisms in-
creasingly control our interactions with the Internet, it is
inevitable that they will become the targets of ﬁnancially
motivated attacks. While we demonstrate pollution at-
tacks on only YouTube, Google, and Amazon, we believe
that our methods are general and can be widely applied to
services that leverage personalization technologies, such
as Facebook, Twitter, Netﬂix, Pandora, etc. The attacks
we present here are just the ﬁrst few examples of poten-
tially many possible attacks on personalization. With in-
creasingly complex algorithms and data collection mech-
anisms aiming for ever higher ﬁnancial stakes, there are
bound to be vulnerabilities that will be exploited by moti-
vated attackers. The age of innocence for personalization
is over; we must now face the challenge of securing it.

Acknowledgments

This research was supported in part by the National
Science Foundation under grants CNS-1255453, CNS-
1255314, CNS-1111723, and CNS-0831300, and the Of-
ﬁce of Naval Research under grant no. N000140911042.
Any opinions, ﬁndings, and conclusions or recommenda-
tions expressed in this material are those of the authors
and do not necessarily reﬂect the views of the National
Science Foundation or the Ofﬁce of Naval Research.

References

[1] Amazon.com product identiﬁers.

org/details/asin_listing.

http://archive.

[2] BENNETT, P. N., RADLINSKI, F., WHITE, R. W., AND
YILMAZ, E. Inferring and using location metadata to per-
sonalize web search. In Proceedings of the 34th Annual

5http://www.youtube.com/watch?v=UPXK3AeRvKE

[4] DAOUD, M.,

[3] CUTTS, M. Does Google use the “keywords” meta tag?
http://www.youtube.com/watch?v=jK7IPbnmvVU.
AND
A session based personalized
BOUGHANEM, M.
search using an ontological user proﬁle.
In Proceed-
ings of The 24th Annual ACM Symposium on Applied
Computing (2009).

TAMINE-LECHANI,

L.,

[5] DAVIDSON, J., LIEBALD, B., LIU, J., NANDY, P.,
VAN VLEET, T., GARGI, U., GUPTA, S., HE, Y., LAM-
BERT, M., LIVINGSTON, B., AND SAMPATH, D. The
YouTube video recommendation system. In Proceedings
of the 4th ACM Conference on Recommender Systems
(2010).

[6] DOU, Z., SONG, R., AND WEN, J.-R. A large-scale
evaluation and analysis of personalized search strategies.
In Proceedings of the 16th ACM International Conference
on the World Wide Web (2007).

[7] LIU, F., YU, C., AND MENG, W. Personalized web
search by mapping user queries to categories.
In Pro-
ceedings of the 11th ACM International Conference on
Information and Knowledge Management (2002).

[8] LU, L., PERDISCI, R., AND LEE, W. Surf: detecting
and measuring search poisoning. In Proceedings of the
18th ACM Conference on Computer and communications
security (2011).

[9] MATTHIJS, N., AND RADLINSKI, F. Personalizing Web
search using long term browsing history. In The Fourth
ACM International Conference on Web Search and Data
Mining (2011).

[10] QIU, F., AND CHO, J. Automatic identication of user
interest for personalized search.
In Proceedings of the
15th ACM International Conference on the World Wide
Web (2006).

[11] SEARCH ENGINE LAND. Bing results get localized
http://searchengineland.com/

& personalized.
bing-results-get-localized-personalized-
64284.

[12] SEARCH ENGINE LAND. Google now personalizes
everyones search results. http://searchengineland.
com/google-now-personalizes-everyones-
search-results-31195.

[13] SHIFLETT,

C.

Cross-site

request

forgeries.

http://shiflett.org/articles/cross-site-
request-forgeries, 2004.

[14] SIEG, A., MOBASHER, B., AND BURKE, R. Web search
personalization with ontological user proﬁles.
In Pro-
ceedings of the 16th ACM Conference on Conference on
Information and Knowledge Management (2007).

[15] SONTAG, D., COLLINS-THOMPSON, K., BENNETT,
P. N., WHITE, R. W., DUMAIS, S., AND BILLERBECK,
B. Probabilistic models for personalizing Web search. In
Proceedings of the 5th ACM International Conference on
Web Search and Data Mining (2012).

684  22nd USENIX Security Symposium 

USENIX Association

14

[16] SRIRAM, S., SHEN, X., AND ZHAI, C. A session-based
search engine. In Proceedings of the 27th Annual Inter-
national ACM SIGIR Conference on Research and Devel-
opment in Information Retrieval (2004).

[17] TAN, C., GABRILOVICH, E., AND PANG, B. To each
his own: personalized content selection based on text
comprehensibility.
In Proceedings of the 5th ACM In-
ternational Conference on Web Search and Data Mining
(2012).

[18] TEEVAN, J., DUMAIS, S. T., AND HORVITZ, E. Person-
alizing search via automated analysis of interests and ac-
tivities. In Proceedings of the 28th Annual International
ACM SIGIR Conference on Research and Development in
Information Retrieval (2005).

[19] VIDSTATSX. Youtube channel, subscriber, & video

statistics. http://vidstatsx.com/.

[20] WU, B., AND DAVISON, B. D.

Identifying link farm
spam pages. In Proceedings of the Special Interest Tracks
and Posters of the 14th ACM International Conference on
the World Wide Web (2005).

A Appendix

Here we provide more details regarding the actual exploit
and test corpora for the search personalization attack.

A.1 Search Term Variance
As with the various product categories on Amazon, it is
reasonable to expect that the effectiveness of search his-
tory pollution depends on the value of the search term
being polluted. In other words, just as Amazon tightly
controls the gift cards it recommends, it might be the case
that a website cannot be promoted in Google’s search re-
sults as easily for a highly competitive search term, such
as “laptop”, as it can for relatively uncontested search
terms. To obtain an estimate of the value of differ-
ent search terms, we again turned to Google’s AdWords
Keyword Tool. The tool provides a function that asso-
ciates a given search term with a level of competition.
The competition level is a measure of how expensive
it would be for URL to consistently pay enough to be
ranked at the top of the list of advertisers for a particular
search term. Competition level is expressed as a value
from 0 to 1, with 0 having no competition and 1 having
ﬁerce competition.

Recall that out of the 2,136 webpages that we at-
tempted to promote using a contextual pollution attack,
729 were successful. It is important to note that some
of the promoted results were for the same initial search
terms. Therefore, the number of search terms asso-
ciated with the webpages are 1,740 and 606, respec-
tively. As an example, we attempted to promote both
made-in-china.com and DHgate.com with respect to

s
e
g
a
p
b
e
w

 
f

o

 
r
e
b
m
u
N

0
2
1

0
8

0
4

0

2 4 6 8

11 14 17 20 23 26 29

Non−personalized rank

Figure 11: Google’s original rank distribution for the
2,136 webpages whose ranking we attempt to improve
with contextual search history pollution.

the original search term “watch”. The keywords injected
by the pollution attack differ, however, and are “China”
and “China wholesale” respectively. For the persistent
attacks, we were successful in promoting at least one re-
turned website for 247 out of the 551 search terms.

Figure 12 shows the competition level distribution for
both types of attacks. Figures 12(a) and 12(b) corre-
spond to the 1,740 search terms associated with our en-
tire contextual test corpus and the 606 search terms for
which there was a website we could promote. Like-
wise, Figures 12(c) and 12(d) plot the competitiveness
of the search terms for the 551 tested and the 247 suc-
cessful persistent pollution attacks. Although the distri-
butions are different between test corpora, in both cases,
the distributions suggest there is no obvious correlation
between search term competition or value and the like-
lihood of being able to launch a search history pollution
attack.

A.2 Robustness
Because a contextual history pollution attack uses only
a few recent search history entries to promote a website,
the lifetime of this attack is limited to the period when
Google’s personalization algorithm considers this con-
textual information. We empirically determine Google’s
timeout threshold by injecting sets of contextual key-
words into a Google search proﬁle and then pausing
Google’s history collection. We then search alternatively
for two distinct search terms—one that we know is af-
fected by the injected keywords, and another we know is
not. We continue to search for these two terms, recording
and time stamping all the search returns.

Our analysis of many such tests with different sets
of search terms indicates that Google appears to en-
force a ten-minute threshold on context-based personal-
ized search, which thereby limits the scope of the con-
textual pollution attack. Similarly, there are limits on
how many different searches can be conducted before the

USENIX Association  

22nd USENIX Security Symposium  685

15

y
c
n
e
u
q
e
r
F

0
0
3

0
0
2

0
0
1

0

0.0

y
c
n
e
u
q
e
r
F

0
2
1

0
8

0
4

0

1.0

0.0

y
c
n
e
u
q
e
r
F

0
0
3

0
0
2

0
0
1

0

1.0

0.0

0.4

0.6

0.2
0.8
Competition level

y
c
n
e
u
q
e
r
F

0
2
1

0
8

0
4

0

1.0

0.2

0.6

0.4
0.8
Competition level

1.0

0.6

0.4

0.2
0.8
Competition level

0.6

0.4

0.2
0.8
Competition level

(a) Entire corpus, contextual

(b) Successful attacks, contextual

(c) Entire corpus, persistent

(d) Successful attacks, persistent

Figure 12: Distribution of search-term competition levels.

injected context is no longer used to personalize subse-
quent queries. Our initial testing indicates that person-
alization falls off after the fourth search. Hence, we
conclude that the pollution attack can last for at most
four subsequent queries or ten minutes, whichever comes
ﬁrst.

Our testing of persistent attacks shows that if a web-
page remains promoted after several search terms, it will
remain promoted for a long time. To determine how

long, we identiﬁed a set of 100 webpages and search
terms on which we launch a successful persistent pol-
lution attack. We then inject additional randomly se-
lected trending keywords one-by-one and continually
check whether the promotion remains. 72% of the web-
sites remain promoted after 60 additional keywords, indi-
cating that, when successful, persistent pollution attacks
are likely to remain effective for quite some time.

686  22nd USENIX Security Symposium 

USENIX Association

16

