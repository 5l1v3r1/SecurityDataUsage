Security Analysis of Pseudo-Random Number Generators

with Input: /dev/random is not Robust ∗

Yevgeniy Dodis

Dept. of Computer Science

New York University

David Pointcheval

DI/ENS

ENS-CNRS-INRIA

Sylvain Ruhault

DI/ENS

ENS-CNRS-INRIA
and Oppida, France

Damien Vergnaud

DI/ENS

ENS-CNRS-INRIA

Daniel Wichs

Dept. of Computer Science

Northeastern University

ABSTRACT
A pseudo-random number generator (PRNG) is a determin-
istic algorithm that produces numbers whose distribution
is indistinguishable from uniform. A formal security model
for PRNGs with input was proposed in 2005 by Barak and
Halevi (BH). This model involves an internal state that is re-
freshed with a (potentially biased) external random source,
and a cryptographic function that outputs random numbers
from the continually internal state. In this work we extend
the BH model to also include a new security property captur-
ing how it should accumulate the entropy of the input data
into the internal state after state compromise. This prop-
erty states that a good PRNG should be able to eventually
recover from compromise even if the entropy is injected into
the system at a very slow pace, and expresses the real-life
expected behavior of existing PRNG designs.

Unfortunately, we show that neither the model nor the
speciﬁc PRNG construction proposed by BH meet this new
property, despite meeting a weaker robustness notion intro-
duced by BH. From a practical side, we give a precise assess-
ment of the Linux PRNGs, /dev/random and /dev/urandom.
In particular, we show attacks proving that these PRNGs
are not robust according to our deﬁnition, due to vulnera-
bilities in their entropy estimator and their internal mixing
function. Finally, we propose a simple PRNG construction
that is provably robust in our new and stronger adversarial
model and we show that it is more eﬃcient than the Linux
PRNGs. We therefore recommend to use this construction
whenever a PRNG with input is used for cryptography.

Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection—
Cryptographic controls; G.3 [Mathematics of Comput-
∗A full version of this paper is available at Cryptology ePrint
Archive, Report 2013/338

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516653.

ing]: Probability and Statistics—Random number genera-
tion

Keywords
Randomness; Entropy; Security models; /dev/random

1.

INTRODUCTION

Generating random numbers is an essential task in cryp-
tography. Random numbers are necessary not only for gen-
erating cryptographic keys, but are also needed in steps
of cryptographic algorithms or protocols (e.g.
initializa-
tion vectors for symmetric encryption, password generation,
nonce generation,
. . . ). Cryptography practitioners usu-
ally assume that parties have access to perfect randomness.
However, quite often this assumption is not realizable in
practice and random bits in protocols are generated by a
Pseudo-Random Number Generator (PRNG). When this is
done, the security of the scheme depends of course in a cru-
cial way on the quality of the (pseudo-)randomness gen-
erated.
If a user has access to a truly random bit-string,
he can use a deterministic (or cryptographic) PRNG to ex-
pand this short seed into a longer sequence which distribu-
tion is indistinguishable from the uniform distribution to a
computationally-bounded adversary (which does not know
the seed). However, in many situations, it is unrealistic to
assume that users have access to secret and perfect random-
ness. In a PRNG with input, one only assumes that users
can store a secret internal state and have access to a (po-
tentially biased) random source.

In spite of being widely deployed in practice, PRNGs with
input were only formalized by Barak and Halevi in 2005 [1].
They proposed a security notion, called robustness, to cap-
ture the fact that the bits generated should look random to
an observer with (partial) knowledge of the internal state
and (partial) control of the entropy source. Combining the-
oretical and practical analysis of PRNGs with input, this pa-
per presents an extension of the Barak-Halevi security model
and analyses the Linux PRNGs /dev/random and /dev/u-
random.
Randomness weaknesses in cryptography. The lack of
insurance about the generated random numbers can cause
serious damages in cryptographic protocols, and vulnerabil-
ities can be exploited by attackers. One striking example is
the recent failure in the Debian Linux distribution [4], where
a commented code in the OpenSSL PRNG with input led

647to insuﬃcient entropy gathering and then to concrete at-
tacks on TLS and SSH protocols. More recently, Lenstra,
Hughes, Augier, Bos, Kleinjung and Wachter [15] showed
that a non-negligible percentage of RSA keys share prime
factors. Heninger, Durumeric, Wustrow and Halderman [9]
presented an analysis of the behavior of Linux PRNG that
explains the generation of low entropy keys when these keys
are generated at boot time. Moreover, cryptographic algo-
rithms are highly vulnerable to weaknesses in the underly-
ing random number generation process. For instance, sev-
eral works demonstrated that if nonces for DSS signature
algorithm are generated with a weak PRNG then the secret
key can be quickly recovered after seeing a few signatures
(see [16] and references therein). This illustrates the need
for precise evaluation of PRNGs based on clear security re-
quirements.
Security Models. Descriptions of PRNGs with input are
given in various standards [12, 10, 7]. They identiﬁed the
following core components: the entropy source which is the
source of randomness used by the generator to update an in-
ternal state which consists of all the parameters, variables,
and other stored values that the PRNG uses for its opera-
tions.

Several desirable security properties for PRNGs with in-
put have been identiﬁed in [10, 12, 7, 2]. These standards
consider adversaries with various means: those who have ac-
cess to the output of the generator; those who can (partially
or totally) control the source of the generator and those who
can (partially or totally) control the internal state of the gen-
erator (and combination of them). Several security notions
have been deﬁned:
• Resilience: an adversary must not be able to predict
future PRNG outputs even if he can inﬂuence the en-
tropy source used to initialize or refresh the internal
state of the PRNG;
• Forward security ( resp. backward security): an ad-
versary must not be able to predict past (resp. future)
outputs even if he can compromise the internal state
of the PRNG.

Desai, Hevia and Yin [5] modelled a PRNG as an iterative al-
gorithm and formalized the above security properties in this
context. Barak and Halevi [1] model a PRNG with input as
a pair of algorithms (refresh, next) and deﬁne a new security
property called robustness that implies resilience, forward
and backward security. This property actually assesses the
behavior of a PRNG after compromise of its internal state
and responds to the guidelines for developing PRNG given
by Kelsey, Schneier, Wagner and Hall [11].
Linux PRNG. In Unix-like operating systems, a PRNG
with input was implemented for the ﬁrst time for Linux
1.3.30 in 1994. The entropy source comes from device drivers
and other sources such as latencies between user-triggered
events (keystroke, disk I/O, mouse clicks, . . . ). It is gathered
into an internal state called the entropy pool. The internal
state keeps an estimate of the number of bits of entropy in
the internal state and (pseudo-)random bits are created from
the special ﬁles /dev/random and /dev/urandom. Barak and
Halevi [1] discussed brieﬂy the PRNG /dev/random but its
conformity with their robustness security deﬁnition is not
formally analyzed.

The ﬁrst security analysis of these PRNGs was given in
2006 by Gutterman, Pinkas and Reinman [8]. It was com-
pleted in 2012 by Lacharme, R¨ock, Strubel and Videau [14].

Gutterman et al. [8] presented an attack based on kernel ver-
sion 2.6.10 for which a ﬁx has been published in the following
versions. Lacharme et al. [14] gives a detailed description of
the operations of the PRNG and provides a result on the
entropy preservation property of the mixing function used
to refresh the internal state.

Our Contributions. From a theoretical side, we propose a
new formal security model for PRNGs with input, which en-
compasses all previous security notions [1]. This new prop-
erty captures how a PRNG with input should accumulate
the entropy of the input data into the internal state. This
property was not initially formalized in [1] but it actually
expresses the real-life expected behavior of a PRNG after
a state compromise, where it is expected that the PRNG
quickly recovers enough entropy.

On a practical side, we give a precise assessment of the two
Linux PRNGs, /dev/random and /dev/urandom. We prove
that these PRNGs are not robust and do not accumulate
entropy properly, due to the behavior of their entropy esti-
mator and their internal mixing function. We also analyze
the PRNG with input proposed by Barak and Halevi. This
scheme was proven robust in [1] but we prove that it does
not generically satisfy our expected property of entropy ac-
cumulation. On the positive side, we propose a PRNG con-
struction that is robust in the standard model and in our
new stronger adversarial model.

Finally, we perfome benchmarks between our construction
and the Linux PRNGs and we show that it is far more eﬃ-
cient than the Linux PRNGs for both internal state recovery
and key generation.

2. PRELIMINARIES
Probabilities. When X is a distribution, or a random vari-
able following this distribution, we denote x $← X when x
is sample according to X. We denote by M (X) the distri-
bution probability of the output of the Turing machine M ,
while running on the input x drawn according to X, and
with its random coins (if any). The notation X ← Y says
that X is assigned with the value of the variable Y , and
that X is a random variable with distribution equal to that
of Y . For a variable X and a set S (e.g., {0, 1}m for some
integer m), the notation X $← S denotes both assigning X a
value uniformly chosen from S and letting X be a uniform
random variable over S. The uniform distribution over n
bits is denoted Un.
Indistinguishability. Two distributions X and Y are said
(t, ε)-computationally indistinguishable, (CDt(X, Y ) ≤ ε),
if for any distinguisher A running within time t, Pr[A(X) =
1] − Pr[A(Y ) = 1] ≤ ε. When t = ∞, meaning A is un-
bounded, we say that X and Y are ε-close, and their statis-
tical distance is at most ε: SD(X, Y ) ≤ ε.
SD(X, Y |Z) ≤ ε (resp. CDt(X, Y |Z) ≤ ε) is a shorthand
for SD((X, Z), (Y, Z)) ≤ ε (resp. CDt((X, Z), (Y, Z)) ≤ ε.
Entropy. For a discrete distribution X over a set S, we
denote its min-entropy by

{− log Pr[X = x]}

H∞(X) = min

x∈Supp(X)

where Supp(X) ⊆ S is the support of the distribution X. A
distribution X is called a k-source if H∞(X) ≥ k. We also
deﬁne worst-case min-entropy of X conditioned on another

648random variable Z by:

H∞(X|Z) = − log

 max

x∈Supp(X),
z∈Supp(Z)

 (1)

Pr[X = x|Z = z]

It is worth noting that conditional min-entropy is deﬁned
more conservatively than usual, so that it satisﬁes the fol-
lowing relations (the ﬁrst of which, called the chain rule, is
not true for the “average-case” variant of conditional min-
entropy):

H∞(X, Z) − H∞(Z) ≥ H∞(X|Z)

≥ H∞(X, Z) − |Z| ≥ H∞(X) − |Z|

(2)

where |Z| is the bit-length of Z. Extractors. Let H =
{hX :
{0, 1}n → {0, 1}m}X∈{0,1}d be a hash function
family. We say that H is a (k, ε)-extractor if for any ran-
dom variable I over {0, 1}n with H∞(I) ≥ k, the distri-
butions (X, hX (I)) and (X, U ) are ε-close where X is uni-
formly random over {0, 1}d and U is uniformly random over
{0, 1}m. We say that H is ρ-universal if for any inputs
I (cid:54)= I(cid:48) ∈ {0, 1}n we have PrX∈{0,1}d [hX (I) (cid:54)= hX (I(cid:48))] ≤ ρ.
Lemma 1 (Leftover-Hash Lemma). Assume that H is ρ-
universal where ρ = (1 + α)2−m for some α > 0. Then, for
√
2m−k + α.
any k > 0, it is also a (k, ε)-extractor for ε = 1
2

See Theorem 8.37 in [19] for a nicely explained proof of

the above lemma.

Pseudorandom Generators. We say that a function G :
{0, 1}m → {0, 1}n is a (deterministic) (t, ε)-pseudorandom
generator (PRG) if CDt(G(Um),Un) ≤ ε.
Game Playing Framework. For our security deﬁnitions
and proofs we use the code-based game playing framework of
[3]. A game GAME has an initialize procedure, procedures to
respond to adversary oracle queries, and a ﬁnalize procedure.
A game GAME is executed with an adversary A as follows.
First, initialize executes, and its outputs are the inputs to A.
Then A executes, its oracle queries being answered by the
corresponding procedures of GAME. When A terminates,
its output becomes the input to the ﬁnalize procedure. The
output of the latter is called the output of the game, and
we let GAMEA ⇒ y denote the event that this game out-
In the next section, for all GAME ∈
put takes value y.
{RES, FWD, BWD, ROB, SROB}, AGAME denotes the output
= 2×Pr[GAMEA ⇒ 1]−1.
of the adversary. We let AdvGAMEA
Our convention is that Boolean ﬂags are assumed initialized
to false and that the running time of the adversary A is de-
ﬁned as the total running time of the game with the adver-
sary in expectation, including the procedures of the game.

3. PRNG WITH INPUT: MODELING AND

SECURITY

Definition (PRNG with input) A PRNG with input is
a triple of algorithms G = (setup, refresh, next) and a triple
(n, (cid:96), p) ∈ N3 where:

• setup: it is a probabilistic algorithm that outputs some
public parameters seed for the generator.
• refresh: it is a deterministic algorithm that, given seed,
a state S ∈ {0, 1}n and an input I ∈ {0, 1}p, outputs
a new state S(cid:48) = refresh(S, I) = refresh(seed, S, I) ∈
{0, 1}n.

• next:

it is a deterministic algorithm that, given seed
and a state S ∈ {0, 1}n, outputs a pair (S(cid:48), R) =
next(S, I) = next(seed, S, I) where S(cid:48) ∈ {0, 1}n is the
new state and R ∈ {0, 1}(cid:96) is the output.

The integer n is the state length, (cid:96) is the output length and
p is the input length of G.

Before moving to deﬁning our security notions, we no-
tice that there are two adversarial entities we need to worry
about: the adversary A whose task is (intuitively) to distin-
guish the outputs of the PRNG from random, and the distri-
bution sampler D whose task is to produce inputs I1, I2, . . .,
which have high entropy collectively, but somehow help A
in breaking the security of the PRNG. In other words, the
distribution sampler models potentially adversarial environ-
ment (or “nature”) where our PRNG is forced to operate.
Unlike prior work, we model the distribution sampler explic-
itly, and believe that such modeling is one of the important
technical and conceptual contributions of our work.
3.1 Distribution Sampler

The distribution sampler D is a stateful and probabilistic
algorithm which, given the current state σ, outputs a tuple
(σ(cid:48), I, γ, z) where: (a) σ(cid:48) is the new state for D; (b) I ∈
{0, 1}p is the next input for the refresh algorithm; (c) γ is
some fresh entropy estimation of I, as discussed below; and
(d) z is the leakage about I given to the attacker A.
We denote by qD the upper bound on number of execu-
tions of D in our security games, and say that D is legitimate
if:1

H∞(Ij | I1, . . . , Ij−1, Ij+1, . . . , IqD ,

z1, . . . , zqD , γ1, . . . , γqD ) ≥ γj

(3)
for all j ∈ {1, . . . , qD} where (σi, Ii, γi, zi) = D(σi−1) for
i ∈ {1, . . . , qD} and σ0 = 0.
We now explain the reason for explicitly requiring D to
output the entropy estimate γj used in (3). Most complex
PRNGs, including the Linux PRNG, are worried about the
situation where the system might enter a prolonged state
where no new entropy is inserted in the system. Correspond-
ingly, such PRNGs typically include some ad hoc entropy
estimation procedure E whose goal is to block the PRNG
from outputting output value Rj until the state has not ac-
cumulated enough entropy γ∗ (for some entropy threshold
γ∗). Unfortunately, it is well-known that even approximat-
ing the entropy of a given distribution is a computation-
ally hard problem [18]. This means that if we require our
PRNG G to explicitly come up with such a procedure E, we
are bound to either place some signiﬁcant restrictions (or
assumptions) on D, or rely on some hoc and non standard
assumptions. Indeed, as part of these work we will demon-
strate some attacks on the entropy estimation of the Linux
PRNG, illustrating how hard (or, perhaps, impossible?) it
is to design a sound entropy estimation procedure E. Fi-
nally, we observe that the design of E is anyway completely
independent of the mathematics of the actual refresh and
next procedures, meaning that the latter can and should be
evaluated independently of the “accuracy” of E.

Motivated by these considerations, we do not insist on
any “entropy estimation” procedure as a mandatory part
1Since conditional min-entropy is deﬁned in the worst-case
manner in (1), the value γj in the bound below should not
be viewed as a random variable, but rather as an arbitrary
ﬁxing of this random variable.

649of the PRNG design, allowing us to elegantly side-step the
practical and theoretical impossibility of sound entropy es-
timation. Instead, we chose to place the burden of entropy
estimations on D itself, which allows us to concentrate on
the provable security of the refresh and next procedures. In
particular, in our security deﬁnition we will not attempt
to verify if D’s claims are accurate (as we said, this ap-
pears hopeless without some kind of heuristics), but will
only require security when D is legitimate, as deﬁned in (3).
Equivalently, we can think that the entropy estimations γj
come from the entropy estimation procedure E (which is
now “merged” with D), but only provide security assuming
that E is correct in this estimation (which we know is hard
in practice, and motivates future work in this direction).

However, we stress that: (a) the entropy estimates γj will
only be used in our security deﬁnitions, but not in any of
the actual PRNG operations (which will only use the “input
part” I returned by D); (b) we do not insist that a legitimate
D can perfectly estimate the fresh entropy of its next sample
Ij, but only provide a lower bound γj that D is “comfortable”
with. For example, D is free to set γj = 0 as many times
as it wants and, in this case, can even choose to leak the
entire Ij to A via the leakage zj!2 More generally, we allow
D to inject new entropy γj as slowly (and maliciously!) as
it wants, but will only require security when the counter c
keeping track of the current “fresh” entropy in the system3
crosses some entropy threshold γ∗ (since otherwise D gave
us “no reason” to expect any security).

3.2 Security Notions

In the literature, four security notions for a PRNG with
input have been proposed: resilience (RES), forward security
(FWD), backward security (BWD) and robustness (ROB),
with the latter being the strongest notion among them. We
now deﬁne the analogs of this notions in our stronger adver-
sarial model, later comparing our modeling with the prior
modeling of [1]. Each of the games below is parametrized by
some parameter γ∗ which is part of the claimed PRNG se-
curity, and intuitively measures the minimal “fresh” entropy
in the system when security should be expected. In partic-
ular, minimizing the value of γ∗ corresponds to a stronger
security guarantee.
All four security games (RES(γ∗), FWD(γ∗), BWD(γ∗),
ROB(γ∗)) are described using the game playing framework
discussed earlier, and share the same initialize and ﬁnalize
procedures in Figure 1 below. As we mentioned, our overall
adversary is modeled via a pair of adversaries (A,D), where
A is the actual attacker and D is a stateful distribution
sampler. We already discussed the distribution sampler D,
so we turn to the attacker A, whose goal is to guess the
correct value b picked in the initialize procedure, which also
returns to A the public value seed, and initializes several
important variables: corruption ﬂag corrupt, “fresh entropy
counter” c, state S and sampler’s D initial state σ.4 In each
of the games (RES, FWD, BWD, ROB), A has access to

2Jumping ahead,
setting γj = 0 corresponds to the
bad-refresh(Ij) oracle in the earlier modeling of [1], which
is not explicitly provided in our model.
3Intuitively, “fresh” refers to the new entropy in the system
since the last state compromise.
4With a slight loss of generality, we assume that when S is
random it is safe to set the corruption ﬂag corrupt to false.

several oracles depicted in depicted in Figure 2. We brieﬂy
discuss these oracles:
D-refresh. This is the key procedure where the distribution
sampler D is run, and where its output I is used to refreshed
the current state S. Additionally, one adds the amount of
fresh entropy γ to the entropy counter c, and resets the
corrupt ﬂag to false when c crosses the threshold γ∗. The
values of γ and the leakage z are also returned to A. We
denote by qD the number of times A calls D-refresh (and,
hence, D), and notice that by our convention (of including
oracle calls into run-time calculations) the total run-time of
D is implicitly upper bounded by the run-time of A.
next-ror/get-next. These procedures provide A with either
the real-or-random challenge (provided corrupt = false) or
the true PRNG output. As a small subtlety, a “premature”
call to get-next before corrupt = false resets the counter c to
0, since then A might learn something non-trivial about the
(low-entropy) state S in this case.5 We denote by qR the
total number of calls to next-ror and get-next.
get-state/set-state. These procedures provide A with the
ability to either learn the current state S, or set it to any
value S∗. In either case c is reset to 0 and corrupt is set to
true. We denote by qS the total number of calls to get-state
and set-state.

We can now deﬁne the corresponding security notions for
PRNGs with input. For convenience, in the sequel we some-
time denote the “resources” of A by T = (t, qD, qR, qS).

Definition (Security of PRNG with input) A pseudo-
random number generator with input G = (setup, refresh,
next) is called (T = (t, qD, qR, qS), γ∗, ε)-robust (resp. re-
silient, forward-secure, backward-secure), if for any adver-
sary A running in time at most t, making at most qD calls
to D-refresh, qR calls to next-ror/get-next and qS calls to
get-state/set-state, and any legitimate distribution sampler
D inside the D-refresh procedure, the advantage of A in game
ROB(γ∗) (resp. RES(γ∗), FWD(γ∗), BWD(γ∗)) is at most ε,
where:

to make the above calls.

to get-state/set-state (i.e., qS = 0).

• ROB(γ∗) is the unrestricted game where A is allowed
• RES(γ∗) is the restricted game where A makes no calls
• FWD(γ∗) is the restricted game where A makes no calls
to set-state and a single call to get-state (i.e., qS = 1)
which is the very last oracle call A is allowed to make.
• BWD(γ∗) is the restricted game where A makes no
calls to get-state and a single call to set-state (i.e., qS =
1) which is the very ﬁrst oracle call A is allowed to
make.

Intuitively, (a) resilience protects the security of the PRNG
when not corrupted against arbitrary distribution samplers
D, (b) forward security protects past PRNG outputs in case
the state S gets compromised, (c) backward security secu-
rity ensures that the PRNG can successfully recover from
state compromise, provided enough fresh entropy is injected
into the system, (d) robustness ensures arbitrary combina-
tion of the above. Hence, robustness is the strongest and

5We could slightly strengthen our deﬁnition, by only reduc-
ing c by (cid:96) bits in this case, but chose to go for a more con-
servative notion.

650proc. initialize
seed $← setup; σ ← 0; S $← {0, 1}n; c ← n; corrupt ← false; b $← {0, 1}
OUTPUT seed

proc. ﬁnalize(b∗)
IF b = b∗
ELSE RETURN 0

RETURN 1

Figure 1: Procedures initialize and ﬁnalize for G = (setup, refresh, next)

proc. D-refresh
(σ, I, γ, z) $← D(σ)
S ← refresh(S, I)
c ← c + γ
IF c ≥ γ∗,

corrupt ← false

OUTPUT (γ, z)

proc. next-ror
(S, R0) ← next(S)
R1
IF corrupt = true,

$← {0, 1}(cid:96)
c ← 0
RETURN R0
ELSE OUTPUT Rb

proc. get-next
(S, R) ← next(S)
IF corrupt = true,

c ← 0
OUTPUT R

proc. get-state
c ← 0, corrupt ← true
OUTPUT S
proc. set-state(S∗)
c ← 0, corrupt ← true
S ← S∗

Figure 2: Procedures in games RES(γ∗), FWD(γ∗), BWD(γ∗), ROB(γ∗) for G = (setup, refresh, next)

the resilience is the weakest of the above four notions. In
particular, all our provable constructions will satisfy the ro-
bustness notion, but we will use the weaker notions to better
pinpoint some of our attacks.
3.3 Comparison to Barak-Halevi Model
Barak-Halevi Construction. We brieﬂy recall the ele-
gant construction of PRNG with input due to Barak and
Halevi [1], since it will help us illustrate the key new elements
(and some of the deﬁnitional choices) of our new model.
This construction (which we call BH) involves a random-
ness extraction function Extract : {0, 1}p −→ {0, 1}n and a
standard deterministic PRG G : {0, 1}n −→ {0, 1}n+(cid:96). As
we explain below, the modeling of [1] did not have an ex-
plicit setup algorithm, and the refresh and next algorithms
are given below:

• refresh(S, I) = G(cid:48)(S ⊕ Extract(I))
• next(S) = G(S)

Above G(cid:48) denotes the truncation of G to the ﬁrst n output
bits. However, as we explain later, we will also consider the
“simpliﬁed BH” construction, where G(cid:48) is simply the identity
function (i.e., refresh(S, I) = S ⊕ Extract(I)).
Entropy Accumulation. Barak and Halevi proved the ro-
bustness of this construction in a model very similar to ours
(indeed, their model was the inspiration for this work), but
with several important diﬀerences. The most crucial such
diﬀerence involves the modeling of the inputs Ij which are
fed to the refresh procedure. Unlike our modeling, where the
choice of such inputs and their “fresh entropies” γj is com-
pletely left to the distribution sampler D (via the D-refresh
procedure), the BH modeling only considered the following
two extremes of our model. The attacker could either call
the good-refresh procedure, which must produce an input I
of fresh entropy γ higher than the entropy threshold γ∗, or
call the bad-refresh procedure with an arbitrary, maliciously
speciﬁed input I∗. Informally, the call to bad-refresh should
not compromise the PRNG security whenever the compro-
mised ﬂag corrupt = false, while the call to good-refresh
should result in an immediate “recovery”, and always resets
corrupt = true.

Hence, our key conceptual strengthening of the work of
[1] will require security even if the entropy is accumulated
slowly (and maliciously!), as opposed to in “one shot” (or
“delayed” by calls to bad-refresh). Namely, we insist that

a good PRNG with input should be able to recover from
compromise as long as the total amount of fresh entropy
accumulated over some potentially long period time crosses
the threshold γ∗, instead of insisting that there must be
one very high-entropy sample to aid the recovery. We in-
formally term this new required property of PRNGs with
input (which is very closely related to our formal notion of
backward security) entropy accumulation, and notice that
practical PRNGs, such a the Linux PRNG, seem to place a
lot of (heuristic) eﬀort in trying to achieve this property.

Unfortunately, we will show that the BH construction is
not entropy accumulating, in general. Hence, their construc-
tion does not necessarily meet our stronger notion of robust-
ness (or even backward security). Before presenting our at-
tack on the BH construction, though, we discuss some other
less critical diﬀerences between our models, since they will
also help to simplify our presentation of the attack.

Entropy Estimates. Related to the above, [1] did not re-
quire D to explicitly output the entropy estimate γ. As we
mentioned, though, this was replaced by the implicit require-
ment that the call to good-refresh must produce an input I
with fresh entropy γ ≥ γ∗. In contrast, our explicit mod-
eling (justiﬁed in detail in Section 3.1) allows us to mean-
ingfully formalize the notion of “entropy accumulation”, by
keeping a well deﬁned fresh entropy counter c, and resetting
corrupt = false when c ≥ γ∗.

Importance of setup. As we mentioned, the modeling of
[1] did not have an explicit setup algorithm to initialize pub-
lic parameters seed. Instead, they assumed that the required
randomness extractor Extract in their construction is good
enough to extract nearly ideal randomness from any high-
entropy distribution I output by the good-refresh procedure.
Ideally, we would like to make no other assumptions about
I except its min-entropy. Unfortunately, it is well known
that no deterministic extractor is capable to simultaneously
extract good randomness from all eﬃciently samplable high-
entropy distributions (e.g., consider nearly full entropy dis-
tribution I which is random, except the ﬁrst bit of Extract(I)
is 0). This leaves us with two options. The ﬁrst option,
which seemed to be the preferred choice by [1], is to restrict
the family of permitted high-entropy distributions I. While
following this option is theoretically possible in our model as
well, we ﬁnd it to be somewhat restrictive and cumbersome
to deﬁne, since we would like to allow our distribution sam-

651pler to output “variable-length” high-entropy distributions,
where entropy might be accumulated very slowly over time.
Instead, we chose to follow the second option, which is
much more universally accepted in the randomness extrac-
tor literature [17]: to assume the existence of the setup pro-
cedure which will output some public parameters seed which
could be used by the procedures next and refresh. Applied
to the construction of [1], for example, this will allow one to
consider a seeded extractor Extract inside their next proce-
dure, which can now extract entropy from all high-entropy
distributions (see the resulting deﬁnition of seeded (k, ε)-
extractors in Section 2). As a warning, this nice extra gen-
erality comes at a price that the public parameter seed is not
passed to the distribution sampler D, since otherwise D can
still produce high-entropy (but adversarial) samples I such
that next(refresh(0n, I)) always starts with a 0 bit. Although
slightly restrictive, this elegantly side-steps the impossibil-
ity result above, while accurately modeling many real-life
situations, where it is unreasonable to assume that the “na-
ture” D would somehow bias its samples I depending on
some random parameter seed chosen inside the initialization
procedure.
State Pseudorandomness. Barak and Halevi [1] also in-
sisted that the state S is indistinguishable from random once
corrupt = false. While true in their speciﬁc construction (an-
alyzed in their weaker model), we think that demanding this
property is simultaneously too restrictive and also not very
well motivated. For example, imagine a PRNG where the
state S includes a (never random) Boolean ﬂag which keeps
track if the last PRNG call was made to the next procedure.
We see a potential eﬃciency beneﬁt gained by keeping such
a ﬂag (e.g., to speed up the subsequent next procedure when
the ﬂag is true), but see no reason why storing such a harm-
less ﬂag makes such this PRNG design “insecure”. In fact,
our main construction in Section 4 also will not satisfy this
property the very moment corrupt = false, but will only
make S pseudorandom when the ﬁrst call to next is made
(which is the only thing that matters at the end).
In particular, looking at the analysis of [1], the (truncated)
PRG G(cid:48) inside the refresh procedure is only needed to en-
sure the state pseudorandomness of their construction. In
other words, if one drops (only the) state pseudorandom-
ness from the BH model, the “simpliﬁed BH” construction
is already robust in their model. Motivated by this, we ﬁrst
give a very strong attack on the simpliﬁed BH construction
in our stronger model, for any extractor Extract and PRG
G. This already illustrates the main diﬀerence between our
models in terms of entropy accumulation. Then we show a
more artiﬁcial (but still valid) attack on the “full BH” con-
struction.
Attack on Simpliﬁed BH. Consider the following very
simply simple distribution sampler D. At any time period,
it simply sets I = αp for a fresh and random bit α, and also
sets entropy estimate γ = 1 and leakage z = ∅. Clearly, D is
legitimate. Hence, for any entropy threshold γ∗, the simpli-
ﬁed BH construction must regain security after γ∗ calls to
the D-refresh procedure following a state compromise. Now
consider the following simple attacker A attacking the back-
ward security (and, thus, robustness) of the simpliﬁed BH
construction. It calls set-state(0n), and then makes γ∗ calls
to D-refresh followed by many calls to next-ror. Let us de-
note the value of the state S after j calls to D-refresh by
Sj, and let Y (0) = Extract(0p), Y (1) = Extract(1p). Then,

recalling that refresh(S, I) = S ⊕ Extract(I) and S0 = 0n,
we see that Sj = Y (α1) ⊕ . . . Y (αj), where α1 . . . αj are
random and independent bits. In particular, at any point
of time there are only two possible values for Sj:
if j is
even, then Sj ∈ {0n, Y (0) ⊕ Y (1)}, and, if j is odd, then
Sj ∈ {Y (0), Y (1)}.
In other words, despite receiving γ∗
random and independent bits from D, the refresh procedure
failed to accumulate more than 1 bit of entropy in the ﬁnal
state S∗ = Sγ∗ . In particular, after γ∗ calls to D-refresh,
A can simply try both possibilities for S∗ and easily distin-
guish real from random outputs with advantage arbitrarily
close to 1 (by making enough calls to next-ror).

This shows that the simpliﬁed BH construction is never
backward secure, despite being robust (modulo state pseu-
dorandomness) in the model of [1].

Attack on “Full” BH. The above attack does not immedi-
ately extend to the full BH construction, due to the presence
of the truncated PRG G(cid:48). Instead, we show a less general at-
tack for some (rather than any) extractor Extract and PRG
G. For Extract, we simply take any good extractor (possi-
bly seeded) where Extract(0p) = Extract(1p) = 0n. Such an
extractor exists, since we can take any other initial extrac-
tor Extract(cid:48), and simply modify it on inputs 0p and 1p, as
above, without much aﬀecting its extraction properties on
high-entropy distributions I. By the same argument, we can
take any good PRG G where G(0n) = 0n+(cid:96), which means
that G(cid:48)(0n) = 0n.
With these (valid but artiﬁcial) choices of Extract and G,
we can keep the same distribution sampler D and the at-
tacker A as in the simpliﬁed BH example. Now, however,
we observe that the state S always remains equal to 0n, ir-
respective of whether is it updated with I = 0p or I = 1p,
since the new state S(cid:48) = G(cid:48)(S⊕Extract(I)) = G(cid:48)(0n⊕0n) =
0n = S. In other words, we have not gained even a single bit
of entropy into S, which clearly breaks backward security in
this case as well!

One may wonder if we can have a less obvious attack for
any Extract and G, much like in the simpliﬁed BH case.
This turns out to be an interesting and rather non-trivial
question. Indeed, the value of the state Sj after j calls to
D-refresh with inputs I1 . . . Ij is equal to the “CBC-MAC”
computation, with input (cid:126)Y = (Y1 . . . Yj) and the initial value
S0, where Yj = Extract(Ij):

Sj = G

(cid:48)

(Yj ⊕ G

(cid:48)

(Yj−1 . . . ⊕ G

(cid:48)

(Y1 ⊕ S0) . . .))

Moreover, we only care about the case when H∞((cid:126)I) ≥ γ∗,
which, under appropriate assumptions on Extract, would
translate to a high-entropy guarantee on (cid:126)Y .
In this case,
it is tempting to use the work of [6], who showed that the
CBC-MAC is a good randomness extractor on high-entropy
inputs (cid:126)Y , provided that the truncated PRG G(cid:48) is modeled
as a random permutation. This result gives us hope that the
full BH construction might be secure in our model, possibly
under strong enough assumptions on the PRG G and/or the
extractor Extract. Unfortunately, aside from assuming that
G(cid:48) is (close to) a random permutation, we cannot directly
use the results of [6], since the initial state S0 could be set
by A in a way correlated with the inputs Yj, as well as the
“block cipher” G(cid:48) (which invalidates the analysis of [6]).

Instead of following this interesting, but rather speculative
direction, below we give an almost equally simple construc-
tion which is provably robust in the standard model, without
any idealized assumptions.

6523.4 Simpler Notions of PRNG Security

We deﬁne two properties of a PRNG with input which
are intuitively simpler to analyze than the full robustness
security. We show that these two properties, taken together,
imply robustness.
Recovering Security. We deﬁne a notion of recovering se-
curity. It considers an attacker that compromises the state
to some arbitrary value S0. Following that, suﬃciently many
D-refresh calls with suﬃcient entropy are made so as to set
the corrupt ﬂag to false and resulting in some updated state
S. Then the output (S∗, R) ← next(S) looks indistinguish-
able from uniform. The formal deﬁnition is slightly more
complicated since the attacker also gets to adaptively choose
when to start using D-refresh calls to update the state. For-
mally, we consider the following security game with an at-
tacker A, a sampler D, and bounds qD, γ∗.

• The challenge chooses a seed seed $← setup, and a bit
b $← {0, 1} uniformly at random. It sets σ0 := 0. For
k = 1, . . . , qD, the challenger computes
(σk, Ik, γk, zk) ← D(σk−1).

• The attacker A gets seed and γ1, . . . , γqD , z1, . . . zqD .
It gets access to an oracle get-refresh() which initially
sets k := 0 on each invocation increments k := k + 1
and outputs Ik. At some point the attacker A outputs
a value S0 ∈ {0, 1}n and an integer d such that k + d ≤

qD and(cid:80)k+d

j=k+1 γj ≥ γ∗.

• For j = 1, . . . , d, the challenger computes
Sj := refresh(Sj−1, Ik+j, seed).

If b = 0 it sets (S∗, R) ← next(Sd) and if b = 1 is
sets (S∗, R) ← {0, 1}n+(cid:96) uniformly at random. The
challenger gives Ik+d+1, . . . , IqD , and (S∗, R) to A.

• The attacker A outputs a bit b∗.

We deﬁne the advantage of the attacker A and sampler D
in the above game as |2 Pr[b∗ = b] − 1|.
Definition (Recovering Security ) A PRNG with input
has (t, qD, γ∗, ε)-recovering security if for any attacker A and
legitimate sampler D, both running in time t, the advantage
of the above game with parameters qD, γ∗ is at most ε.

Preserving Security. We deﬁne a simple notion of pre-
serving security.
Intuitively, it says that if the state S0
starts uniformly random and uncompromised, and then is
refreshed with arbitrary (adversarial) samples I1, . . . , Id re-
sulting in some ﬁnal state Sd, then the output (S∗, R) ←
next(Sd) looks indistinguishable from uniform.
attacker A.

Formally, we consider the following security game with an

• The challenger chooses an initial state S0 ← {0, 1}n, a
seed seed ← setup, and a bit b ← {0, 1} uniformly at
random.
• A gets seed and speciﬁes arbitrarily long sequence of
values I1, . . . , Id with Ij ∈ {0, 1}n for all j ∈ [d].
• The challenger sequentially computes

Sj = refresh(Sj−1, Ij, seed)

for j = 1, . . . , d. If b = 0, A is given (S∗, R) = next(Sd)
and if b = 1, A is given (S∗, R) ← {0, 1}n+(cid:96).

• A outputs a bit b∗.

We deﬁne the advantage of the attacker A in the above game
as |2 Pr[b∗ = b] − 1|.

Definition (Preserving Security ) A PRNG with input
has (t, ε)-preserving security if the advantage of any attacker
A running in time t in the above game is at most ε.

We now show that, taken together, recovering and pre-
serving security notions imply the full notion of strong ro-
bustness (see Appendix A for proof).
Theorem 2. If a PRNG with input has both (t, qD, γ∗, εr)-
recovering security and (t, εp)-preserving security, then it is
((t(cid:48), qD, qR, qS), γ∗, qR(εr + εp))-robust where t(cid:48) ≈ t.

4. PROVABLY SECURE CONSTRUCTION
Let G : {0, 1}m → {0, 1}n+(cid:96) be a (deterministic) pseu-
dorandom generator where m < n. We use the notation
1 to denote the ﬁrst m bits of y ∈ {0, 1}n. Our construc-
[y]m
tion of PRNG with input has parameters n (state length), (cid:96)
(output length), and p = n (sample length), and is deﬁned
as follows:

• setup(): Output seed = (X, X(cid:48)) ← {0, 1}2n.
• S(cid:48) = refresh(S, I): Given seed = (X, X(cid:48)), current state
S ∈ {0, 1}n, and a sample I ∈ {0, 1}n, output: S(cid:48) :=
S · X + I, where all operations are over F2n .
• (S(cid:48), R) = next(S): Given seed = (X, X(cid:48)) and a state
S ∈ {0, 1}n, ﬁrst compute U = [X(cid:48) · S]m
1 . Then output
(S(cid:48), R) = G(U ).

Notice that we are assuming each input I is in {0, 1}n. This
is without loss of generality: we can take shorter inputs and
pad them with 0s, or take longer inputs and break them up
into n-bit chunks, calling the refresh procedure iteratively.

On-line Extractor. Let’s look at what happens if we start
in some state S and call the refresh procedure d-times with
the samples Id−1, . . . , I0 (it will be convenient to index these
in reverse order). Then the new state at the end of this
process will be

(cid:48)

S

:= S · X d + Id−1 · X d−1 + ··· + I1 · X + I0.

evaluation hash function deﬁned by hX ( ¯I) :=(cid:80)d−1

Let ¯I := (Id−1, . . . , I0) be the concatenation of all d sam-
ples. In the analysis we rely on the fact that the polynomial
j=0 Ij · X j
is (d/2n)-universal meaning that the probability of any two
distinct inputs colliding is at most d/2n over the random
choice of X. In particular, we can think of our refresh pro-
cedure as computing this hash function in an on-line man-
ner, processing the inputs Ij one-by-one without knowing
the total number of future samples d, and keeping only a
short local state.6 In particular, the updated state after the
d refreshes is S(cid:48) = S · X d + hX ( ¯I). Unfortunately, hX (·) is
not suﬃciently universal to make it a good extractor, and
therefore we cannot argue that S(cid:48) itself is random as long as
¯I has entropy. Therefore, we need to apply an additional
X(cid:48) (Y ) = [X(cid:48) · Y ]m
hash function h(cid:48)
1 which takes as input
Y ∈ {0, 1}n and outputs a value hX(cid:48) (T ) ∈ {0, 1}m. We
show that the composition function h∗
X(cid:48) (hX ( ¯I))
is a good randomness extractor. Therefore, during the eval-
uation of (S(cid:48)(cid:48), R) = next(S(cid:48)), the value
(cid:48) · S · X d]m

X,X(cid:48) ( ¯I) = h(cid:48)

U = [X

∗
X,X(cid:48) ( ¯I)

]m
1 = [X

(cid:48) · S

(cid:48)

1 + h

6The fact that polynomial evaluation can be computed in
such on-line manner is called Horner’s method. It has count-
less applications in algorithm design and many areas of com-
puter science.

653hX ( ¯I) :=

d−1(cid:88)

j=0

is uniformly random as long as the refreshes ¯I jointly have
suﬃcient entropy. This is the main idea behind our con-
struction. We formalize this via the following lemma, which
provides the key to proving our main theorem.
Lemma 3. Let d, n, m be integers, let X, X(cid:48), Y ∈ F2n , ¯I =
(Id−1, . . . , I0) ∈ Fd

2n . Deﬁne the hash function families:

(cid:48)
X(cid:48) (Y ) := [X

∗
X,X(cid:48) ( ¯I) := h

(cid:48) · d−1(cid:88)

(cid:34)
(cid:48)
X(cid:48) (hX ( ¯I)) =
Then the hash-family H = {h∗
X,X(cid:48)} is 2−m(1 + d · 2m−n)-
universal. In particular it is a (k, ε)-extractor as long as:
k ≥ m + 2 log(1/ε) + 1 and n ≥ m + 2 log(1/ε) + log(d) + 1.
Proof. For the ﬁrst part, ﬁx any ¯I = (Id−1, . . . , I0) (cid:54)= ¯I(cid:48) =
(I(cid:48)
d−1, . . . , I(cid:48)

X,X(cid:48) ( ¯I) = hX,X(cid:48) ( ¯I(cid:48))] is less than

0): PrX,X(cid:48) [h∗

(cid:48) · Y ]m
1 .

Ij · X j,

Ij · X j

(cid:35)m

.

1

h

X

j=0

h

(cid:21)

(cid:20) hX ( ¯I)
(cid:104)(cid:80)d−1

= hX ( ¯I(cid:48))

PrX

+ PrX,X(cid:48)

 hX(cid:48) (Y )
(cid:105)

= hX(cid:48) (Y (cid:48))
+ 2−m

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)



Y (cid:54)= Y (cid:48)

Y := hX ( ¯I),
Y (cid:48) := hX ( ¯I(cid:48))

j) · X j = 0

j=0 (Ij − I(cid:48)

≤ PrX
≤ d/2n + 2−m = 2−m(1 + d2m−n).
For the second part, we use the fact that hX,X(cid:48) is 2−m(1+
α)-universal for α = d · 2m−n. Hence, it is also a (k, ε)-
√
extractor where ε ≤ √
2m−k + d2m−n (See

2m−k + α =

Lemma 1). This is ensured by our parameter choice.
Theorem 4. Let n > m, (cid:96), γ∗ be integers. Assume that G :
{0, 1}m → {0, 1}n+(cid:96) is a deterministic (t, εprg)-pseudorandom
generator. Let G = (setup, refresh, next) be deﬁned as above.
Then G is a ((t(cid:48), qD, qR, qS), γ∗, ε)-robust PRNG with input
where t(cid:48) ≈ t, ε = qR(2εprg + q2Dεext + 2−n+1) as long as
γ∗ ≥ m+2 log(1/εext)+1, n ≥ m+2 log(1/εext)+log(qD)+1.

The proof is deferred to Appendix A.

Benchmarks. Benchmarks between our contruction and
Linux PRNGs are detailled in the full version. They are
based on an optimistic hypothesis for Linux PRNGs, and
even with this hypothesis, our construction appears to be
more eﬃcient: a full internal state recovery is two times
faster and a 2048-bits key generation is ten times faster.
5. ANALYSIS OF THE LINUX PRNGS

The Linux operating system contains two PRNGs with in-
put, /dev/random and /dev/urandom. They are part of the
kernel and used in the OS security services or some crypto-
graphic libraries. We give a precise description7 of them in
our model as a triple LINUX = (setup, refresh, next) and we
prove the following theorem:

Theorem 5. The Linux PRNGs /dev/random and /dev/u-
random are not robust.

Since the actual generator LINUX does not deﬁne any seed
(i.e. the algorithm setup always outputs ∅), as mentioned
above, it cannot achieve the notion of robustness. However,
in Sections 5.4 and 5.6, we additionally mount concrete at-
tacks that would work even if LINUX had used a seed. The
attacks exploit two independent weaknesses, in the entropy
estimator and the mixing functions, which would need both
to be ﬁxed in order to expect the PRNGs to be secure.
7All descriptions were done by source code analysis. We
refer to version 3.7.8 of the Linux kernel.

5.1 General Overview
Security Parameters. The LINUX PRNG uses parame-
ters n = 6144, (cid:96) = 80, p = 96. The parameter n can be mod-
iﬁed (but requires kernel compilation), and the parameters
(cid:96) (size of the output) and p (size of the input) are ﬁxed. The
PRNG outputs the requested random numbers by blocks of
(cid:96) = 80 bits and truncates the last block if needed.

Internal State. The internal state of LINUX PRNG is
a triple S = (Si, Su, Sr) where |Si| = 4096 bits, |Su| =
1024 bits and |Sr| = 1024 bits. New data is collected in Si,
which is named the input pool. Output is generated from Su
and Sr which are named the output pools. When a call to
/dev/urandom is made, data is generated from the pool Su
and when a call to /dev/random is made, data is generated
from the pool Sr.
Functions refresh and next. There are two refresh func-
tions, refreshi that initializes the internal state and refreshc
that updates it continuously. There are two next functions,
nextu for /dev/urandom and nextr for /dev/random.
Mixing Function. The PRNG uses a mixing function M,
described in Section 5.5, to mix new data in the input pool
and to transfer data between the pools.

Entropy Estimator. The PRNG uses an entropy esti-
mator, described in Section 5.3, that estimates the entropy
of new inputs and the entropy of the pools. The PRNG
uses these estimations to control the transfers between the
pools and how new input is collected. This is illustrated in
Figure 3 and described in details in Section 5.2. The estima-
tions are named Ei (entropy estimation of Si), Eu (of Su),
Er (of Sr).
5.2 Detailled Description

As illustrated in Figure 3, functions refresh and next are
controlled by Ei, Eu, Er. All functions rely on the same
built-in function extract buf that calls the mixing function
M, a hash function H (the SHA1 function) and a folding
function F deﬁned with F(w0,··· , w4) = (w0 ⊕ w3, w1 ⊕
w4, w2[0···15] ⊕ w2[16···31] ).
Initial refreshi. refreshi(0, I) = M(0, I).
Continuous refreshc. For all I, if Ei ≥ 3584 input I is
ignored (except 1 byte over 4096). When I is used Ei is in-
creased with the estimated entropy of I and refreshc(S, I) =
M(Si, I).
If Er ≥ 8t, then the output
PRNG Output with nextr.
is generated directly from Sr: LINUX ﬁrst calculates a hash
across Sr, then mixes this hash back with Sr, hashes again
the output of the mixing function and folds the result in half,
giving R = F◦H◦M(Sr, H(Sr)) and S(cid:48)
r = M(Sr, H(Sr)). This
decreases Er by 8t and the new value is Er − 8t. If Er < 8t,
then depending on Ei, data is transferred from Si to Sr. Let
αr = min(min(max(t, 8), 128),(cid:98)Ei/8(cid:99)).

• If αr ≥ 8, then αr bytes are transferred between Si
and Sr (so at least 8 bytes and at most 128 bytes
are transferred between Si and Sr, and Si can con-
tain 0 entropy. The transfer is made in two steps:
ﬁrst LINUX generates from Si an intermediate data
Ti = F ◦ H ◦ M(Si, H(Si)) and then it mixes it with
Sr, giving the intermediate states S(cid:48)
i = M(Si, H(Si))
and S∗
r = M(Sr, Ti). This decreases Ei by 8αr and in-
creases Er by 8αr. Finally LINUX outputs t bytes from

654(I)

(0, I)

refreshi→ S

(S, I) refreshc→ S(cid:48)

(Sr → S(cid:48)
r)

(Su → S(cid:48)
u)

S nextr→ (S(cid:48), R)

(Si → S(cid:48)
i)

S nextu→ (S(cid:48), R)

(I)

/dev/random

(Si, Su, Sr)

/dev/urandom

Ei < 3584

no

yes

(S(cid:48)
i, Su, Sr)
(S, I) refreshc→ S(cid:48)

(I)

(Si, Su, Sr)
refreshi→ S(cid:48)

(S, I)

(Si, Su, Sr)

Eu > 8t

yes

no

no

αu > 8

yes

(Si, S(cid:48)

u, Sr, R)

i, S(cid:48)
(S(cid:48)
S nextu→ (S(cid:48), R)

u, Sr, R)

(Si, Su, Sr)

wait

Er > 8t

no

αr > 8

no

yes
(Si, Su, S(cid:48)

yes
i, Su, S(cid:48)

r; R)

(S(cid:48)
r; R)
S nextr→ (S(cid:48), R)

Figure 3: Relations between functions and pools for LINUX

r , H(S∗
r ))
r )). This decreases Er by
• If αr < 8, then LINUX blocks and waits until Si gets

S∗
r , this produces the ﬁnal states S(cid:48)
and R = F ◦ H ◦ M(S∗
8t.
refreshed with I and until αr ≥ 8.

r = M(S∗

r , H(S∗

If Eu ≥ 8t then LINUX ap-
PRNG Output with nextu.
plies the same process as in the non-blocking case, outputs
R = F ◦ H ◦ M(Su, H(Su))) and sets S(cid:48)
u = M(Su, H(Su)).
If Eu < 8t then LINUX behaves diﬀerently. Let αu =
min(min(max(t, 8), 128),(cid:98)Ei/8(cid:99) − 16):

• If αu ≥ 8, the process is the same as in the non-
blocking case, but with Su, Eu and αu instead of Sr,
Er and αr.
• If αu < 8, then LINUX outputs the requested bytes
from Su without transferring data from Si. Hence
LINUX behaves as if Eu ≥ 8t: R = F◦H◦M(Su, H(Su)),
and S(cid:48)
u = M(Su, H(Su)). This decreases Eu by 8t and
the new value is 0.

This illustrates the diﬀerence between /dev/urandom and
/dev/random: If the estimated entropy of the blocking pool
Sr is less than 8t and no transfer is done, then /dev/random
blocks, whereas /dev/urandom does never block and outputs
the requested t bytes from the non-blocking pool Su.
5.3 The Entropy Estimator

i = δi − δi−1, δ3

The entropy estimator is implemented in the built-in func-
tion add timer randomness which is used for refresh. Entropy
is not estimated using input distribution but only using
its timing.
It calculates diﬀerences between timings asso-
ciated with each event: t0, t1, t2, . . . are the jiﬃes of events,
δi = ti − ti−1, δ2
i−1. Then, it calcu-
lates ∆i = min(|δi|,|δ2
i |) and ﬁnally applies a logarith-
mic function to give the estimated entropy Hi = 0 if ∆i < 2,
Hi = 11 if ∆i > 212, and Hi = (cid:98)log2(∆i)(cid:99) otherwise.
5.4 Attacks Based on the Entropy Estimator
As shown in Appendix B, it is possible to build a distri-
bution D0 of null entropy for which the estimated entropy
is high (cf. Lemma 6) and a distribution D1 of high entropy

i − δ2

i |,|δ3

i = δ2

for which the estimated entropy is null (cf. Lemma 7). It
is then possible to mount attacks on both /dev/random and
/dev/urandom, which show that these two generators are not
robust.
/dev/random is not robust. Let us consider an adver-
sary A against the robustness of /dev/random, and thus in
the game ROB(γ∗), that makes the following oracle queries:
one get-state, several next-ror, several D-refresh and one ﬁ-
nal next-ror. Then the state (Si, Sr, Su), the parameters
Ei, Eu, Er and the counter c deﬁned in ROB(γ∗) evolve the
following way:
• get-state: After a state compromise, A knows all pa-
rameters (but needs Si, Sr, Ei, Er) and c = 0.
• next-ror: After (cid:98)Ei/10(cid:99) + (cid:98)Er/10(cid:99) queries to next-ror,
Ei = Er = 0, A knows Si and Sr and c = 0.
• D-refresh:
In a ﬁrst stage, A refreshes LINUX with
input from D0. After 300 queries, Ei = 3584 and Er =
0. A knows Si and Sr and c = 0.
In a second stage, A refreshes LINUX with input J $←
U128. As Ei = 3584, these inputs are ignored as long
as I contains less than 4096 bytes. After 30 queries, A
knows Si and Sr and c = 3840.
• next-ror: Since Er = 0, a transfer is necessary between
Si and Sr before generating R. Since Ei = 3584, then
αb = 10, such a transfer happens. But as A knows Si
and Su, then A knows R.
Therefore, in the game ROB(γ∗) with b = 0, A obtains a
10-bytes string in the last next-ror-oracle that is predictable,
whereas when b = 1, this event occurs only with probability
2−80. It is therefore straightforward for A to distinguish the
real and the ideal world.
/dev/urandom is not robust. Similarly, let us consider an
adversary A against the robustness of /dev/urandom in the
game ROB(γ∗) that makes the following oracle queries: one
get-state that allows it to know Si, Su, Ei, Eu; (cid:98)Ei/10(cid:99) +
(cid:98)Eu/10(cid:99) next-ror, making Ei = Eu = 0; 100 D-refresh with
D1; and one next-ror, so that R will only rely on Sr as no
transfer is done between Si and Su since Ei = 0. Then A is
able to generate a predictable output R and to distinguish
the real and the ideal worlds in ROB(γ∗).

6555.5 The Mixing Function

The Mixing function M is the core of LINUX PRNG. It
is implemented in the built-in function mix pool bytes. We
give a complete description of M as it is used for refresh, its
description for next diﬀers only from internal parameters. It
takes as input I of size one byte, the input pool Si, con-
sidered as 128 32-bits words S0, . . . , S127. It mixes I with
7 words of Si (selected with an index k) and replaces one
word of Si with the result. Another index d deﬁnes a word
rotation. In details:

• The byte I is converted into a 32-bit word, using stan-
dard C implicit cast, and rotated by d bits. At initial-
ization, d = 0, and for each M call, if k = 0 mod 128
then d = d + 14 mod 32 else d = d + 7 mod 32.
• The obtained word is xor-ed with Sk+j mod 128 for j ∈
{0, 1, 25, 51, 76, 103}8.
• The obtained word is mixed with a built-in twist ta-
ble that is the binary representations of {0, α32∗j}, j =
1, . . . 7 in the ﬁeld (F2)/(Q), where Q(x) is the CRC32
polynom9 used for Ethernet protocol [13]. Denoting
the primitive element α, this is described as W →
W.α3 +R(Q(W, α29).α32, Q), where Q(A, B) is the quo-
tient and R(A, B)) the remainder in division A/B.
• Then Sk is replaced by the last word and k = k + 1.

5.6 Attack Based on the Mixing Function

In [14], a proof of state entropy preservation is given for
one iteration of the mixing function M, assuming that the in-
put and the internal state are independent: H∞(M(S, I)) ≥
H∞(S) and H∞(M(S, I)) ≥ H∞(I).
Indeed, without in-
dependence and with more than one iteration of M, LINUX
does not recover from state compromise. This contradicts
the backward security and therefore the robustness.
LINUX is not backward secure. As shown in Appendix B,
with Lemma 8, it is possible to build an input distribu-
tion D2 with arbitrary high entropy such that, after several
D-refresh, H∞(S) = 1. Let us consider an adversary A
that generates an input of distribution D2, and that makes
the following oracle queries: set-refresh, γ∗ calls to D-refresh
and many calls to next-ror. Then the state (Si, Sr, Su), the
parameters Ei, Eu, Er, k, d and the counter c of BWD(γ∗)
evolve the following way:

• set-refresh: A sets Si = 0, Sr = Su = 0, d = 0, k =
• D-refresh: A refreshes LINUX with D2. After γ∗ oracle
• next-ror: Since H∞(S) = 1, H∞(R) = 1.

127, and c = 0.
queries, until c ≥ γ∗, H∞(S) = 1.

Therefore, in the game BWD(γ∗) with b = 0, A always ob-
tains an output in the last next-ror query with H∞(R) = 1,
whereas in b = 1, this event occurs only with negligible prob-
ability. It is therefore straightforward for A to distinguish
the real and the ideal world.

6. CONCLUSION

We have proposed a new property for PRNG with in-
put, that captures how it should accumulate entropy into
the internal state. This property actually expresses the
8Similarly, the words chosen from Sr and Su will be
Sk+j mod 32 for j ∈ {0, 1, 7, 14, 20, 26}.
9Q(x) = x32 + x26 + x23 + x22 + x16 + x12 + x11 + x10 + x8 +
x7 + x5 + x4 + x2 + x + 1.

real expected behavior of a PRNG after a state compro-
mise, where it is expected that the PRNG quickly recovers
enough entropy. We gave a precise assessment of the Linux
PRNGs /dev/random and /dev/urandom. We proved that
these PRNGs do not achieve this property, due to the be-
havior of their entropy estimator and their mixing function.
As pointed by Barak and Halevi [1], who advise against us-
ing run-time entropy estimation, our attacks are due to its
use when data is transferred between pools in Linux PRNG.
We therefore recommend that the functions of a PRNG do
not rely on such an estimator.
Finally, we proposed a construction that meets our new
property in the standard model and we showed that it is no-
ticeably more eﬃcient than the Linux PRNGs. Thus, from
the perspective of speed and provable security, our construc-
tion appears vastly superior to Linux PRNGs. We therefore
recommend to use this construction whenever a PRNG with
input is used for cryptography.

7. ACKNOWLEDGMENTS

Yevgeniy Dodis’ research was partially supported by the
gift from VMware Labs and NSF grants 1319051, 1314568,
1065288, 1017471. Damien Vergnaud’s research was sup-
ported in part by the French ANR-12-JS02-0004 ROMAn-
TIC Project. Daniel Wichs’s research was partially sup-
ported by NSF grant 1314722.

8. REFERENCES
[1] Barak, B., and Halevi, S. A model and

architecture for pseudo-random generation with
applications to /dev/random. In ACM CCS 05: 12th
Conference on Computer and Communications
Security (Nov. 2005), V. Atluri, C. Meadows, and
A. Juels, Eds., ACM Press, pp. 203–212.

[2] Barker, E., and Kelsey, J. Recommendation for

random number generation using deterministic
random bit generators. NIST Special Publication
800-90A, 2012.

[3] Bellare, M., and Rogaway, P. The security of
triple encryption and a framework for code-based
game-playing proofs. In Advances in Cryptology –
EUROCRYPT 2006 (May / June 2006), S. Vaudenay,
Ed., vol. 4004 of Lecture Notes in Computer Science,
Springer, pp. 409–426.

[4] CVE-2008-0166. Common Vulnerabilities and

Exposures, 2008.

[5] Desai, A., Hevia, A., and Yin, Y. L. A

practice-oriented treatment of pseudorandom number
generators. In Advances in Cryptology –
EUROCRYPT 2002 (Apr. / May 2002), L. R.
Knudsen, Ed., vol. 2332 of Lecture Notes in Computer
Science, Springer, pp. 368–383.

[6] Dodis, Y., Gennaro, R., H˚astad, J., Krawczyk,
H., and Rabin, T. Randomness extraction and key
derivation using the CBC, cascade and HMAC modes.
In Advances in Cryptology – CRYPTO 2004 (Aug.
2004), M. Franklin, Ed., vol. 3152 of Lecture Notes in
Computer Science, Springer, pp. 494–510.

[7] Eastlake, D., Schiller, J., and Crocker, S. RFC

4086 - Randomness Requirements for Security, June
2005.

656[8] Gutterman, Z., Pinkas, B., and Reinman, T.

Analysis of the linux random number generator. In
2006 IEEE Symposium on Security and Privacy (May
2006), IEEE Computer Society Press, pp. 371–385.

[9] Heninger, N., Durumeric, Z., Wustrow, E., and
Halderman, J. A. Mining your Ps and Qs: Detection
of widespread weak keys in network devices. In
Proceedings of the 21st USENIX Security Symposium
(Aug. 2012).

[10] Information technology - Security techniques -

Random bit generation. ISO/IEC18031:2011, 2011.

[11] Kelsey, J., Schneier, B., Wagner, D., and Hall,

C. Cryptanalytic attacks on pseudorandom number
generators. In Fast Software Encryption – FSE’98
(Mar. 1998), S. Vaudenay, Ed., vol. 1372 of Lecture
Notes in Computer Science, Springer, pp. 168–188.

[12] Killmann, W. and Schindler, W. A proposal for:
Functionality classes for random number generators.
AIS 20 / AIS31, 2011.

[13] Koopman, P. 32-bit cyclic redundancy codes for
internet applications. In Proceedings of the 2002
International Conference on Dependable Systems and
Networks (Washington, DC, USA, 2002), DSN ’02,
IEEE Computer Society, pp. 459–472.

[14] Lacharme, P., Rock, A., Strubel, V., and
Videau, M. The linux pseudorandom number
generator revisited. Cryptology ePrint Archive, Report
2012/251, 2012.

[15] Lenstra, A. K., Hughes, J. P., Augier, M., Bos,

J. W., Kleinjung, T., and Wachter, C. Public
keys. In Advances in Cryptology – CRYPTO 2012
(Aug. 2012), R. Safavi-Naini and R. Canetti, Eds.,
vol. 7417 of Lecture Notes in Computer Science,
Springer, pp. 626–642.

[16] Nguyen, P. Q., and Shparlinski, I. The insecurity
of the digital signature algorithm with partially known
nonces. Journal of Cryptology 15, 3 (2002), 151–176.

[17] Nisan, N., and Zuckerman, D. Randomness is

linear in space. J. Comput. Syst. Sci. 52, 1 (1996),
43–52.

[18] Sahai, A., and Vadhan, S. P. A complete problem
for statistical zero knowledge. J. ACM 50, 2 (2003),
196–249.

[19] Shoup, V. A computational introduction to number

theory and algebra. Cambridge University Press, 2006.

APPENDIX
A. PROOFS FOR STANDARD-MODEL PRNG
A.1 Proof of Theorem 2

We will refer to the attacker’s queries to either the get-next
or next-ror oracle in the robustness game as “next queries”.
We assume that the attacker makes exactly qR of them. We
say that a next query is uncompromised if corrupt = false
during the query, and we say it is compromised otherwise.
Without loss of generality, we will assume that all compro-
mised next queries that the attacker makes are to get-next
and not next-ror (since next-ror does not do/output anything
when corrupt = true).

We partition the uncompromised next queries into two
subcategories: preserving and recovering. We say that an

uncompromised next query is preserving if the corrupt ﬂag
remained set to false throughout the entire period between
the previous next query (if there is one) and the current
one. Otherwise, we say that an uncompromised next query
is recovering. With any recovering next query, we can as-
sociate a corresponding most recent entropy drain (mRED)
query which is the most recent query to either get-state,
set-state, get-next that precedes the current next query. An
mRED query must set the cumulative entropy estimate to
c = 0. Moreover, with any recovering next query, we asso-
ciate a corresponding sequence of recovering samples ¯I =
(Ij, . . . , Ij+d−1) which are output by all the calls to the
D-refresh oracle that precede the recovering next query, but
follow the associated mRED query.
It is easy to see that
any such sequence of recovering samples ¯I must satisfy the
γi ≥ γ∗ where the ith call to
D-refresh oracle outputs (Ii, γi, zi).

entropy requirements(cid:80)j+d−1

i=j

We deﬁne several hybrid games. Let Game 0 be the real-
or-random security game as deﬁned in Figure 2. Let Game
i be a modiﬁcation of this game where, for the ﬁrst i next
queries, if the query is uncompromised, then the challenger
always chooses (S, R) ← {0, 1}(cid:96)+n uniformly at random dur-
ing the query rather than using the next() function. As an
intermediate, we also deﬁne a hybrid Game (i + 1
2 ), which
lies between Game i and Game (i + 1). In particular, in
Game (i + 1
2 ), if the (i + 1)st next query is preserving than
the challenger acts as in Game(i + 1) and chooses a ran-
dom S, R, and otherwise it acts as in Game i and follows
the original oracle speciﬁcation. In all of these games, the
output of the game is the output of the ﬁnalize oracle at the
end, which is 1 if the attacker correctly guesses the challenge
bit, and 0 otherwise.
We claim that for all i ∈ {0, . . . , qR − 1}, Game i is in-
2 ), that in turn is indistin-

distinguishable from Game (i + 1
guishable from Game (i + 1)10.

1

Claim 1. Assuming that the PRNG has (t, εp)-preserving
security, then for any attacker/distinguisher A,D running
in time t(cid:48) ≈ t, we have | Pr[(Game i) = 1] − Pr[(Game i +
2 ) = 1]| ≤ εp.
Claim 2. If the PRNG is (t, qD, γ∗, εr)-recovering secure,
then for any attacker/distinguisher A,D running in time
t(cid:48) ≈ t, we have | Pr[(Game i + 1
2 ) = 1]− Pr[(Game i + 1) =
1]| ≤ εr.

Combining the above two claims, and using the hybrid

argument, we get:
| Pr[(Game 0) = 1] − Pr[(Game qR) = 1]| ≤ qR(εr + εp).
Moreover Game qR is completely independent of the chal-
lenger bit b. In particular, all next-ror queries return a ran-
dom R $← {0, 1}(cid:96) independent of the challenge bit b. There-
fore, we have Pr[(Game qR) = 1] = 1
2 . Combining with the
above, we see that the attacker’s advantage in the original

robustness game is(cid:12)(cid:12)Pr[(Game 0) = 1] − 1

(cid:12)(cid:12) ≤ qR(εr + εp).

2

A.2 Proof of Theorem 4

We show that G satisﬁes (t(cid:48), qD, γ∗, (εprg+q2Dεext)-recovering

security and (t(cid:48), (εprg + 2−n+1))-preserving security. Theo-
rem 4 then follows directly from Theorem 2.

10The proofs of these two claims are simple and we defer to
them to the full version.

657Claim 3. The PRNG G has (t(cid:48), εprg + 2−n+1)-preserving
security

Proof. Let Game 0 be the original preserving security game:
the game outputs a bit which is set to 1 iﬀ the attacker
guesses the challenge bit b∗ = b.
If the initial state is
$← {0, 1}n, the seed is seed = (X, X(cid:48)), and the adversar-
S0
ial samples are Id−1, . . . , I0 (indexed in reverse order where
Id−1 is the earliest sample) then the refreshed state that in-
j=0 Ij·X j.
As long as X (cid:54)= 0, the value Sd is uniformly random (over
the choice of S0). We consider a modiﬁed Game 1, where
the challenger simply chooses Sd

corporates these samples will be Sd := S0·X d +(cid:80)d−1

$← {0, 1}n and we have

| Pr[(Game 0) = 1] − Pr[(Game 1) = 1]| ≤ 2

−n.

Let U = [Sd · X(cid:48)]m
1 be the value computed by the challenger
during the computation (S, R) ← next(Sd) when the chal-
lenge bit is b = 0. Then, as long as X(cid:48) (cid:54)= 0, the value U is
uniformly random (over the choice Sd). Therefore, we can
deﬁne Game 2 where the challenger choose U $← {0, 1}n
during this computation and we have:

| Pr[(Game 1) = 1] − Pr[(Game 2) = 1]| ≤ 2

−n.

Finally (S, R) = next(Sd, seed) = G(U ). Then (S, R) is
(t, εprg) indistinguishable from uniform. Therefore we can
consider a modiﬁed Game 3 where the challenger just choos-
ing (S, R) at random even when the challenge bit is b = 0.
Since the attacker runs in time t(cid:48) ≈ t, we have:

| Pr[(Game 3) = 1] − Pr[(Game 2) = 1]| ≤ εprg.

2| ≤ εprg + 2−n+1.

2 and therefore | Pr[(Game 0) =

Since Game 3 is independent of the challenge bit b, we
have Pr[(Game 3) = 1] = 1
1] − 1
Claim 4. The PRNG G has (t(cid:48), qD, γ∗, (εprg + q2Dεext))-
recovering security.

Proof. Let Game 0 be the original recovering security game:
the game outputs a bit which is set to 1 iﬀ the attacker
guesses the challenge bit b∗ = b. We deﬁne Game 1 where,
during the challenger’s computation of (S∗, R) ← next(Sd)
for the challenge bit b = 0, it chooses U $← {0, 1}m uniformly
at random rather than setting U := [X(cid:48) · Sd]m
1 . We argue
that

| Pr[(Game 0) = 1] − Pr[(Game 1) = 1]| ≤ q2Dεext.

The loss of q2D comes from the fact that the attacker can
choose the index k and the value d adaptively depending on
the seed. In particular, assume that the above does not hold.
Then there must exist some values k∗, d∗ ∈ [qD] such that
the above distance is greater than εext conditioned on the
attacker making exactly k∗ calls to get-refresh and choosing
d∗ refreshes in the game. We show that this leads to a
contradiction. Fix the distribution on the subset of samples
¯I = (Ik∗+1, . . . , Ik+d∗ ) output by D during the ﬁrst step of
the game, which must satisfy

U := [X

(cid:48) · Sd]m

1 = [X

(cid:48) · S0X d]m

1 + hX,X(cid:48) ( ¯I)

H∞( ¯I | γ1, . . . , γqD , z1, . . . , zqD ) ≥ γ

∗

.

By Lemma 3, the function hX,X(cid:48) ( ¯I) is a (γ∗, εext)-extractor,
meaning that (X, X(cid:48), hX,X(cid:48) ( ¯I)) is εext-close to (X, X(cid:48), Z)
where Z is random an independent of X, X(cid:48). Then, for any
ﬁxed choice of k∗, d∗, the way we compute U in Game 0:

is εexst close to a uniformly random U as chosen in Game
1. This leads to a contradiction, showing that the equation
holds.
Finally, we deﬁne Game 2 where, during the challenger’s
computation of (S∗, R) ← next(Sd) for the challenge bit
b = 0, it chooses (S∗, R) uniformly at random instead of
(S∗, R) ← G(U ) as in Game 1. Since the attacker runs in
time t(cid:48) ≈ t, we have:

| Pr[(Game 2) = 1] − Pr[(Game 1) = 1]| ≤ εprg.

2| ≤ εprg.

2 and therefore | Pr[(Game 0) =

Since Game 2 is independent of the challenge bit b, we
have Pr[(Game 2) = 1] = 1
1] − 1
B. DISTRIBUTIONS USED FOR ATTACKS
B.1 Distributions Used in Attacks Based on

the Entropy Estimator

1

2, W i
, W i

1 = 212, W i

3]) $← D0(i), where W 0
2 = W i

Lemma 6. There exists a stateful distribution D0 such that
H∞(D0) = 0, whose estimated entropy by LINUX is high.
Proof. Let us deﬁne the 32-bits word distribution D0. On
input a state i, D0 updates its state to i + 1 and outputs a
triple (i + 1, [W i
1, W i
1 =
(cid:98)cos(i).220(cid:99) + W i−1
3 = 0. For each state, D0
outputs a 12-bytes input containing 0 bit of random data,
we have H∞(D0) = 0 conditioned on the previous and the
future outputs (i.e. D0 is legitimate only with γi = 0 for all
i). Then ∆i > 212 and Hi = 11.
Lemma 7. There exists a stateful distribution D1 such that
H∞(D1) = 64, whose estimated entropy by LINUX is null.
Proof. Let us deﬁne the 32-bits word distribution D1. On
input a state i, D1 updates its state to i + 1 and outputs a
$←
triple: (i + 1, [W i
$← U32. For each state, D1 outputs a 12-bytes
U32 and W3
input containing 8 bytes of random data, we have H∞(D1) =
64 conditioned on the previous and the future outputs (i.e.
D1 is legitimate with γi = 64 for all i). Then δi = 1, δ2
i = 0,
δ2
i−1 = 0, δ3
B.2 Distribution Used in Attack Based on the

3]) $← D1(i), where Wi = i, W2

i = 0, ∆i = 0 and Hi = 0.

1, W i

2, W i

Mixing Function

Lemma 8. There exists a stateful distribution D2 such that
H∞(D2) = 1, for which H∞(S) = 1 after t refresh, for
arbitrary high t.
Proof. Let us deﬁne the byte distributions Bi,b and Bi,$:

Bi,b = {(0,··· , b,··· , 0), bi ← b, bj = 0 if i (cid:54)= j}
Bi,$ = {(b0,··· , b7), bi
$← {0, 1}, bj = 0 if i (cid:54)= j}
Let us deﬁne the 12 bytes distribution D2. On input a state
i, D2 updates its state to i + 1 and outputs 12 bytes:
4 ← B7,$,

0, . . . , Bi
(i + 1, [Bi
5 ← B3,b, B10i+2
B10i
← B1,b, B10i+8
B10i+6

11]) $← D2(i), where B10i
← B5,b,
10 ← B0,b, with b = Bi

← B2,b, B10i+4

For each state i, D2 outputs a 12-bytes input containing 1
bit of random data (for i = 0 mod 10) or 0 bit of random
data (for i (cid:54)= 0 mod 10). If d = 0, k = 127 and S is known,
and noting St = refresh(S, refresh(St−1, [Bt−1
11 ])),
St = St
127, then St contains 1 random bit in word
St

127, at position 10, for all t.

, . . . , Bt−1

0, . . . , St

4,7

0

4

7

6

658