Secure Outsourced Garbled Circuit Evaluation 

for Mobile Devices

Henry Carter, Georgia Institute of Technology; Benjamin Mood, University of Oregon;  
Patrick Traynor, Georgia Institute of Technology; Kevin Butler, University of Oregon

Open access to the Proceedings of the 22nd USENIX Security Symposium is sponsored by USENIXThis paper is included in the Proceedings of the 22nd USENIX Security Symposium.August 14–16, 2013 • Washington, D.C., USAISBN 978-1-931971-03-4Secure Outsourced Garbled Circuit Evaluation for Mobile Devices

Henry Carter

Georgia Institute of Technology

carterh@gatech.edu

Patrick Traynor

Georgia Institute of Technology

traynor@cc.gatech.edu

Benjamin Mood

University of Oregon

bmood@cs.uoregon.edu

Kevin Butler

University of Oregon
butler@cs.uoregon.edu

Abstract

Garbled circuits provide a powerful tool for jointly
evaluating functions while preserving the privacy of each
user’s inputs. While recent research has made the use
of this primitive more practical, such solutions generally
assume that participants are symmetrically provisioned
with massive computing resources. In reality, most peo-
ple on the planet only have access to the comparatively
sparse computational resources associated with their mo-
bile phones, and those willing and able to pay for ac-
cess to public cloud computing infrastructure cannot be
assured that their data will remain unexposed. We ad-
dress this problem by creating a new SFE protocol that
allows mobile devices to securely outsource the major-
ity of computation required to evaluate a garbled circuit.
Our protocol, which builds on the most efﬁcient gar-
bled circuit evaluation techniques, includes a new out-
sourced oblivious transfer primitive that requires signiﬁ-
cantly less bandwidth and computation than standard OT
primitives and outsourced input validation techniques
that force the cloud to prove that it is executing all pro-
tocols correctly. After showing that our extensions are
secure in the malicious model, we conduct an extensive
performance evaluation for a number of standard SFE
test applications as well as a privacy-preserving naviga-
tion application designed speciﬁcally for the mobile use-
case. Our system reduces execution time by 98.92% and
bandwidth by 99.95% for the edit distance problem of
size 128 compared to non-outsourced evaluation. These
results show that even the least capable devices are ca-
pable of evaluating some of the largest garbled circuits
generated for any platform.

1

Introduction

Secure Function Evaluation (SFE) allows two parties to
compute the result of a function without either side hav-
ing to expose their potentially sensitive inputs to the
other. While considered a generally theoretical curios-

ity even after the discovery of Yao’s garbled circuit [43],
recent advances in this space have made such computa-
tion increasingly practical. Today, functions as complex
as AES-128 and approaching one billion gates in size are
possible at reasonable throughputs, even in the presence
of a malicious adversary.

While recent research has made the constructions in
this space appreciably more performant, the majority of
related work makes a crucial assumption - that both par-
ties are symmetrically provisioned with massive comput-
ing resources. For instance, Kreuter et al. [25] rely on the
Ranger cluster at the Texas Advanced Computing Center
to compute their results using 512 cores. In reality, the
extent of a user’s computing power may be their mobile
phone, which has many orders of magnitude less compu-
tational ability. Moreover, even with access to a public
compute cloud such as Amazon EC2 or Windows Azure,
the sensitive nature of the user’s data and the history of
data leakage from cloud services [40, 42] prevent the di-
rect porting of known SFE techniques.

In this paper, we develop mechanisms for the secure
outsourcing of SFE computation from constrained de-
vices to more capable infrastructure. Our protocol main-
tains the privacy of both participant’s inputs and outputs
while signiﬁcantly reducing the computation and net-
work overhead required by the mobile device for garbled
circuit evaluation. We develop a number of extensions
to allow the mobile device to check for malicious behav-
ior from the circuit generator or the cloud and a novel
Outsourced Oblivious Transfer for sending garbled input
data to the cloud. We then implement the new proto-
col on a commodity mobile device and reasonably provi-
sioned servers and demonstrate signiﬁcant performance
improvements over evaluating garbled circuits directly
on the mobile device.

We make the following contributions:
• Outsourced oblivious transfer & outsourced con-
sistency checks:
Instead of blindly trusting the
cloud with sensitive inputs, we develop a highly

USENIX Association  

22nd USENIX Security Symposium  289

1

efﬁcient Outsourced Oblivious Transfer primitive
that allows mobile devices to securely delegate the
majority of computation associated with oblivious
transfers. We also provide mechanisms to outsource
consistency checks to prevent a malicious circuit
generator from providing corrupt garbled values.
These checks are designed in such a way that the
computational load is almost exclusively on the
cloud, but cannot be forged by a malicious or “lazy”
cloud. We demonstrate that both of our additions
are secure in the malicious model as deﬁned by Ka-
mara et al. [21].

• Performance Analysis: Extending upon the imple-
mentation by Kreuter et al. [25], we conduct an ex-
tensive performance analysis against a number of
simple applications (e.g., edit distance) and crypto-
graphic benchmarks (e.g., AES-128). Our results
show that outsourcing SFE provides improvements
to both execution time and bandwidth overhead. For
the edit distance problem of size 128, we reduce ex-
ecution time by 98.92% and bandwidth by 99.95%
compared to direct execution without outsourcing
on the mobile device.

• Privacy Preserving Navigation App: To demon-
strate the practical need for our techniques, we de-
sign and implement an outsourced version of Dijk-
stra’s shortest path algorithm as part of a Naviga-
tion mobile app. Our app provides directions for
a Presidential motorcade without exposing its loca-
tion, destination, or known hazards that should be
avoided (but remain secret should the mobile device
be compromised). The optimized circuits generated
for this app represent the largest circuits evaluated
to date. Without our outsourcing techniques, such
an application is far too processor, memory and
bandwidth intensive for any mobile phone.

While this work is similar in function and provides
equivalent security guarantees to the Salus protocols re-
cently developed by Kamara et al. [21], our approach
is dramatically different. The Salus protocol frame-
work builds their scheme on a completely different as-
sumption, speciﬁcally, that they are outsourcing work
from low-computation devices with high communication
bandwidth. With provider-imposed bandwidth caps and
relatively slow and unreliable cellular data connections,
this is not a realistic assumption when developing solu-
tions in the mobile environment. Moreover, rather than
providing a proof-of-concept work demonstrating that
ofﬂoading computation is possible, this work seeks to
develop and thoroughly demonstrate the practical poten-
tial for evaluating large garbled circuits in a resource-
constrained mobile environment.

The remainder of this work is organized as follows:
Section 2 presents important related work and discusses

how this paper differs from Salus; Section 3 provides
cryptographic assumptions and deﬁnitions; Section 4 for-
mally describes our protocols; Section 5 provides secu-
rity discussion - we direct readers to our technical re-
port [6] for full security proofs; Section 6 shows the re-
sults of our extensive performance analysis; Section 7
presents our privacy preserving navigation application
for mobile phones; and Section 8 provides concluding
remarks.

2 Related Work

Beginning with Fairplay [32], several secure two-party
computation implementations and applications have
been developed using Yao garbled circuits [43] in the
semi-honest adversarial model [3, 15, 17, 19, 26, 28, 31,
38]. However, a malicious party using corrupted in-
puts or circuits can learn more information about the
other party’s inputs in these constructions [23]. To re-
solve these issues, new protocols have been developed to
achieve security in the malicious model, using cut-and-
choose constructions [30], input commitments [41], and
other various techniques [22,34]. To improve the perfor-
mance of these schemes in both the malicious and semi-
honest adversarial models, a number of circuit optimiza-
tion techniques have also been developed to reduce the
cost of generating and evaluating circuits [8, 11, 24, 35].
Kreuter et al. [25] combined several of these techniques
into a general garbled circuit protocol that is secure in
the malicious model and can efﬁciently evaluate circuits
on the order of billions of gates using parallelized server-
class machines. This SFE protocol is currently the most
efﬁcient implementation that is fully secure in the mali-
cious model. (The dual execution construction by Huang
et al. leaks one bit of input [16].)

Garbled circuit protocols rely on oblivious transfer
schemes to exchange certain private values. While sev-
eral OT schemes of various efﬁciencies have been de-
veloped [1, 30, 36, 39], Ishai et al. demonstrated that any
of these schemes can be extended to reduce kc oblivi-
ous transfers to k oblivious transfers for any given con-
stant c [18]. Using this extension, exchanging potentially
large inputs to garbled circuits became much less costly
in terms of cryptographic operations and network over-
head. Even with this drastic improvement in efﬁciency,
oblivious transfers still tend to be a costly step in evalu-
ating garbled circuits.

Currently, the performance of garbled circuit protocols
executed directly on mobile devices has been shown to
be feasible only for small circuits in the semi-honest ad-
versarial model [5, 13]. While outsourcing general com-
putation to the cloud has been widely considered for im-
proving the efﬁciency of applications running on mobile
devices, the concept has yet to be widely applied to cryp-

290  22nd USENIX Security Symposium 

USENIX Association

2

tographic constructions. Green et al. began exploring
this idea by outsourcing the costly decryption of ABE
ciphertexts to server-class machines while still maintain-
ing data privacy [12]. Considering the costs of exchang-
ing inputs and evaluating garbled circuits securely, an
outsourcing technique would be useful in allowing lim-
ited capability devices to execute SFE protocols. Naor
et al. [37] develop an oblivious transfer technique that
sends the chooser’s private selections to a third party,
termed a proxy. While this idea is applied to a limited
application in their work, it could be leveraged more gen-
erally into existing garbled circuit protocols. Our work
develops a novel extension to this technique to construct
a garbled circuit evaluation protocol that securely out-
sources computation to the cloud.

In work performed concurrently and independently
from our technique, Kamara et al. recently developed
two protocols for outsourcing secure multiparty compu-
tation to the cloud in their Salus system [21]. While their
work achieves similar functionality to ours, we distin-
guish our work in the following ways: ﬁrst, their protocol
is constructed with the assumption that they are outsourc-
ing work from devices with low-computation but high-
bandwidth capabilities. With cellular providers impos-
ing bandwidth caps on customers and cellular data net-
works providing highly limited data transmission speed,
we construct our protocol without this assumption using
completely different cryptographic constructions. Sec-
ond, their work focuses on demonstrating outsourced
SFE as a proof-of-concept. Our work offers a rigorous
performance analysis on mobile devices, and outlines a
practical application that allows a mobile device to par-
ticipate in the evaluation of garbled circuits that are or-
ders of magnitude larger than those evaluated in the Salus
system. Finally, their protocol that is secure in the ma-
licious model requires that all parties share a secret key,
which must be generated in a secure fashion before the
protocol can be executed. Our protocol does not require
any shared information prior to running the protocol, re-
ducing the overhead of performing a multiparty fair coin
tossing protocol a priori. While our work currently con-
siders only the two-party model, by not requiring a pre-
liminary multiparty fair coin toss, expanding our proto-
col to more parties will not incur the same expense as
scaling such a protocol to a large number of participants.
To properly compare security guarantees, we apply their
security deﬁnitions in our analysis.
3 Assumptions and Deﬁnitions
To construct a secure scheme for outsourcing garbled cir-
cuit evaluation, some new assumptions must be consid-
ered in addition to the standard security measures taken
in a two-party secure computation. In this section, we
discuss the intuition and practicality of assuming a non-

colluding cloud, and we outline our extensions on stan-
dard techniques for preventing malicious behavior when
evaluating garbled circuits. Finally, we conclude the sec-
tion with formal deﬁnitions of security.

3.1 Non-collusion with the cloud
Throughout our protocol, we assume that none of the
parties involved will ever collude with the cloud. This
requirement is based in theoretical bounds on the efﬁ-
ciency of garbled circuit evaluation and represents a re-
alistic adversarial model. The fact that theoretical limi-
tations exist when considering collusion in secure multi-
party computation has been known and studied for many
years [2, 7, 27], and other schemes considering secure
computation with multiple parties require similar restric-
tions on who and how many parties may collude while
preserving security [4, 9, 10, 20, 21]. Kamara et al. [21]
observe that if an outsourcing protocol is secure when
both the party generating the circuit and the cloud eval-
uating the circuit are malicious and colluding, this im-
plies a secure two-party scheme where one party has
sub-linear work with respect to the size of the circuit,
which is currently only possible with fully homomor-
phic encryption. However, making the assumption that
the cloud will not collude with the participating parties
makes outsourcing securely a theoretical possibility. In
reality, many cloud providers such as Amazon or Mi-
crosoft would not allow outside parties to control or af-
fect computation within their cloud system for reasons
of trust and to preserve a professional reputation.
In
spite of this assumption, we cannot assume the cloud
will always be semi-honest. For example, our protocol
requires a number of consistency checks to be performed
by the cloud that ensure the participants are not behaving
maliciously. Without mechanisms to force the cloud to
make these checks, a “lazy” cloud provider could save
resources by simply returning that all checks veriﬁed
without actually performing them. Thus, our adversar-
ial model encompasses a non-colluding but potentially
malicious cloud provider that is hosting the outsourced
computation.

3.2 Attacks in the malicious setting
When running garbled circuit based secure multiparty
computation in the malicious model, a number of well-
documented attacks exist. We address here how our sys-
tem counters each.
Malicious circuit generation: In the original Yao gar-
bled circuit construction, a malicious generator can gar-
ble a circuit to evaluate a function f (cid:31) that is not the func-
tion f agreed upon by both parties and could compromise
the security of the evaluator’s input. To counter this, we

USENIX Association  

22nd USENIX Security Symposium  291

3

employ an extension of the random seed technique devel-
oped by Goyal et al. [11] and implemented by Kreuter et
al. [25]. Essentially, the technique uses a cut-and-choose,
where the generator commits to a set of circuits that all
presumably compute the same function. The parties then
use a fair coin toss to select some of the circuits to be
evaluated and some that will be re-generated and hashed
by the cloud given the random seeds used to generate
them initially. The evaluating party then inspects the cir-
cuit commitments and compares them to the hash of the
regenerated circuits to verify that all the check circuits
were generated properly.

Selective failure attack: If, when the generator is send-
ing the evaluator’s garbled inputs during the oblivious
transfer, he lets the evaluator choose between a valid gar-
bled input bit and a corrupted garbled input, the evalua-
tor’s ability to complete the circuit evaluation will reveal
to the generator which input bit was used. To prevent this
attack, we use the input encoding technique from Lindell
and Pinkas [29], which lets the evaluator encode her in-
put in such a way that a selective failure of the circuit
reveals nothing about the actual input value. To prevent
the generator from swapping garbled wire values, we use
a commitment technique employed by Kreuter et al. [25].

Input consistency: Since multiple circuits are evaluated
to ensure that a majority of circuits are correct, it is pos-
sible for either party to input different inputs to differ-
ent evaluation circuits, which could reveal information
about the other party’s inputs. To keep the evaluator’s
inputs consistent, we again use the technique from Lin-
dell and Pinkas [29], which sends all garbled inputs for
every evaluation circuit in one oblivious transfer execu-
tion. To keep the generator’s inputs consistent, we use
the malleable claw-free collection construction of shelat
and Shen [41]. This technique is described in further de-
tail in Section 4.

Output consistency: When evaluating a two-output
function, we ensure that outputs of both parties are kept
private from the cloud using an extension of the tech-
nique developed by Kiraz [23]. The outputs of both par-
ties are XORed with random strings within the garbled
circuit, and the cloud uses a witness-indistinguishable
zero-knowledge proof as in the implementation by
Kreuter et al. [25]. This allows the cloud to choose a
majority output value without learning either party’s out-
put or undetectably tampering with the output. At the
same time, the witness-indistinguishable proofs prevent
either party from learning the index of the majority cir-
cuit. This prevents the generator from learning anything
by knowing which circuit evaluated to the majority out-
put value.

Bob

(generator)

Phase 1
Phase 2
Phase 3

Alice

(evaluator)

Phase 1
Phase 2
Phase 3
Phase 5

P hase 1
P hase 3
P hase 5

Phase 4

cloud

(outsourcing agent)

Figure 1: The complete outsourced SFE protocol.

3.3 Malleable claw-free collections
To prevent the generating party from providing differ-
ent inputs for each evaluation circuit, we implement the
malleable claw-free collections technique developed by
shelat and Shen [41]. Their construction essentially al-
lows the generating party to prove that all of the garbled
input values were generated by exactly one function in
a function pair, while the ability to ﬁnd an element that
is generated by both functions implies that the genera-
tor can ﬁnd a claw.
It is composed of a four-tuple of
algorithms (G,D,F,R), where G is the index selection
algorithm for selecting a speciﬁc function pair, D is an
algorithm for sampling from the domain of the function
pair, F is the algorithm for evaluating the functions in the
pair (in which it should be difﬁcult to ﬁnd a claw), and R
is the “malleability” function. The function R maps ele-
ments from the domain of F to the range of F such that
for b ∈ {0,1}, any I in the range of G, and any m1,m2 in
the domain of F, we have for the function indexed by I
and b f b
I (m1)(cid:28)RI(m2), where (cid:30) and (cid:28) rep-
resent the group operations over the domain and range of
F. We provide full deﬁnitions of their construction in our
technical report [6].

I (m1 (cid:30)m2) = f b

3.4 Model and Deﬁnitions
The work of Kamara et al. [21] presents a deﬁnition
of security based on the ideal-model/real-model secu-
rity deﬁnitions common in secure multiparty computa-
tion. Because their deﬁnition formalizes the idea of a
non-colluding cloud, we apply their deﬁnitions to our
protocol for the two-party case in particular. We sum-
marize their deﬁnitions below.
Real-model execution. The protocol takes place be-
tween two parties (P1,P2) executing the protocol and a
server P3, where each of the executing parties provides
input xi, auxiliary input zi, and random coins ri and the
server provides only auxiliary input z3 and random coins
r3. In the execution, there exists some subset of indepen-
dent parties (A1, ..,Am),m ≤ 3 that are malicious adver-
saries. Each adversary corrupts one executing party and

292  22nd USENIX Security Symposium 

USENIX Association

4

does not share information with other adversaries. For all
honest parties, let OUTi be its output, and for corrupted
parties let OUTi be its view of the protocol execution.
The ith partial output of a real execution is deﬁned as:

REAL(i)(k,x;r) ={OUT j : j ∈ H}∪OUTi

where H is the set of honest parties and r is all random
coins of all players.
Ideal-model execution. In the ideal model, the setup of
participants is the same except that all parties are inter-
acting with a trusted party that evaluates the function. All
parties provide inputs xi, auxiliary input zi, and random
coins ri. If a party is semi-honest, it provides its actual
inputs to the trusted party, while if the party is malicious
(and non-colluding), it provides arbitrary input values.
In the case of the server P3, this means simply providing
its auxiliary input and random coins, as no input is pro-
vided to the function being evaluated. Once the function
is evaluated by the trusted third party, it returns the result
to the parties P1 and P2, while the server P3 does not re-
ceive the output. If a party aborts early or sends no input,
the trusted party immediately aborts. For all honest par-
ties, let OUTi be its output to the trusted party, and for
corrupted parties let OUTi be some value output by Pi.
The ith partial output of an ideal execution in the pres-
ence of some set of independent simulators is deﬁned as:

IDEAL(i)(k,x;r) ={OUT j : j ∈ H}∪OUTi

where H is the set of honest parties and r is all random
coins of all players. In this model, the formal deﬁnition
of security is as follows:

Deﬁnition 1. A protocol securely computes a function
f if there exists a set of probabilistic polynomial-time
(PPT) simulators {Simi}i∈[3] such that for all PPT ad-
versaries (A1, ...,A3), x, z, and for all i ∈ [3]:

{REAL(i)(k,x;r)}k∈N

c

≈ {IDEAL(i)(k,x;r)}k∈N

Where S = (S1, ...,S3), Si = Simi(Ai), and r is random
and uniform.

4 Protocol

Our protocol can be divided into ﬁve phases, illustrated
in Figure 1. Given a circuit generator Bob, and an eval-
uating mobile device Alice, the protocol can be summa-
rized as follows:

• Phase 1: Bob generates a number of garbled cir-
cuits, some of which will be checked, others will be
evaluated. After Bob commits to the circuits, Alice
and Bob use a fair coin toss protocol to select which
circuits will be checked or evaluated. For the check

Inputs: Alice has a string of encoded input bits ea of
length (cid:29)·n and Bob has pairs of input values (x0, j,x1, j)
for j = 1...(cid:29)· n.
1. Setup: Alice generates random matrix T of size
(cid:29)· n× t, Bob generates random string s of length
t.
2. Primitive OT: Alice and Bob execute t 1-
out-of-2 oblivious transfers with Alice inputting
(T i,T i⊕ea) and Bob inputting selection bits s (T i
denotes the ith column of the T matrix). Bob sets
the resulting columns as matrix Q.

3. Permuting the output: Alice generates random

string p of length (cid:29)· n and sends it to Bob.
4. Encrypting the output: Bob sets the en-
crypted output pairs y0, j,y1, j where yb, j = xb, j ⊕
H1( j,Q j ⊕ (b· s)) (Q j denotes the jth row of the
Q matrix).
5. Permuting the outputs: Bob permutes the en-
crypted output pairs as y0⊕p j, j,y1⊕p j, j and sends
the resulting set of pairs Y to the cloud.
6. Decrypting the output: Alice sends h = ea ⊕
p and T to the cloud. The cloud recovers z j =
yh j, j ⊕ H1( j,Tj) for j = 1...(cid:29) · n (Tj denotes the
jth row of the T matrix).

Figure 2: The Outsourced Oblivious Transfer protocol

circuits, Bob sends the random seeds used to gener-
ate the circuits to the cloud and the hashes of each
circuit to Alice. These are checked to ensure that
Bob has not constructed a circuit that is corrupted
or deviates from the agreed-upon function.

• Phase 2: Alice sends her inputs to Bob via an out-
sourced oblivious transfer. Bob then sends the cor-
responding garbled inputs to the cloud. This allows
the cloud to receive Alice’s garbled inputs without
Bob or the cloud ever learning her true inputs.

• Phase 3: Bob sends his garbled inputs to the cloud,
which veriﬁes that they are consistent for each eval-
uation circuit. This prevents Bob from providing
different inputs to different evaluation circuits.

• Phase 4: The cloud evaluates the circuit given Alice
and Bob’s garbled inputs. Since the cloud only sees
garbled values during the evaluation of the circuit,
it never learns anything about either party’s input or
output. Since both output values are blinded with
one-time pads, they remain private even when the
cloud takes a majority vote.

• Phase 5: The cloud sends the encrypted output val-
ues to Alice and Bob, who are guaranteed its au-
thenticity through the use of commitments and zero-
knowledge proofs.

USENIX Association  

22nd USENIX Security Symposium  293

5

4.1 Participants
Our protocols reference three different entities:
Evaluator: The evaluating party, called Alice, is as-
sumed to be a mobile device that is participating in a
secure two-party computation.
Generator: The party generating the garbled circuit,
called Bob, is an application- or web- server that is the
second party participating with Alice in the secure com-
putation.
Proxy: The proxy, called cloud, is a third party that is
performing heavy computation on behalf of Alice, but is
not trusted to know her input or the function output.

a

two

that

is

securely

a function f (x,y)
claw-free
hash

4.2 Outsourced Protocol
Common inputs:
to
computed,
be
collection
(GCLW ,DCLW ,FCLW ,RCLW ),
functions
H1 : {0,1}∗ → {0,1}n and H2 : {0,1}∗ → {0,1}w,
a primitive 1-out-of-2 oblivious transfer protocol, a per-
fectly hiding commitment scheme comH (key,message),
and security parameters for the number of circuits built
k, the number of primitive oblivious transfers t, and the
number of encoding bits for each of Alice’s input wires
(cid:30).
Private inputs: The generating party Bob inputs a bit
string b and a random string of bits br that is the length
of the output string. The evaluating party Alice inputs a
bit string a and a random string of bits ar that is the length
of the output string. Assume without loss of generality
that all input and output strings are of length |a| = n.
Output: The protocol outputs separate private values f a
for Alice and f b for Bob.
Phase 1: Circuit generation and checking

1. Circuit preparation: Before beginning the protocol,
both parties agree upon a circuit representation of
the function f (a,b), where the outputs of the func-
tion may be deﬁned separately for Alice and Bob as
fA(a,b) and fB(a,b). The circuit must also meet the
following requirements:
(a) Additional XOR gates must be added such that
Bob’s output is set to f b = fB(a,b)⊕ br and
Alice’s output is set to f a = fA(a,b)⊕ ar.
(b) For each of Alice’s input bits, the input wire
wi is split into (cid:30) different input wires w j,i
such that wi = w1,i ⊕ w2,i ⊕ ... ⊕ wl,i follow-
ing the input encoding scheme by Lindell and
Pinkas [29]. This prevents Bob from correlat-
ing a selective failure attack with any of Al-
ice’s input bit values.

2. Circuit garbling: the generating party, Bob, con-
structs k garbled circuits using a circuit garbling

technique Garble(·,·). When given a circuit rep-
resentation C of a function and random coins
rc, Garble(C,rc) outputs a garbled circuit GC
that evaluates C. Given the circuit C and ran-
dom coins rc1...rck, Bob generates garbled circuits
Garble(C,rci) =GC i for i = 1...k. For Bob’s jth in-
put wire on the ith circuit, Bob associates the value
H2(βb, j,i) with the input value b, where βb, j,i =
FCLW (b,I,αb, j,i). For Alice’s jth input wire, Bob as-
sociates the value H2(δb, j,i) with the input value b,
where δb, j,i = FCLW (b,I,γb, j,i). All the values αb, j,i
and γb, j,i for b = {0,1}, j = 1...n,i = 1...k are se-
lected randomly from the domain of the claw-free
pair using D.

3. Circuit commitment: Bob generates commitments
for all circuits by hashing H1(GCi) = HCi for i =
1...k. Bob sends these hashes to Alice. In addition,
for every output wire wb, j,i for b = {0,1}, j = 1...n
and i = 1...k, Bob generates commitments CO j,i =
comH (ck j,i, (H2(w0, j,i),H2(w1, j,i))) using commit-
ment keys ck j,i for j = 1...n and i = 1...k and sends
them to both Alice and the cloud.

4. Input label commitment: Bob commits to Alice’s
garbled input values as follows:
for each gener-
ated circuit i = 1...k and each of Alice’s input wires
j = 1...(cid:30)· n, Bob creates a pair of commitment keys
ik0, j,i,ik1, j,i and commits to the input wire label
seeds δ0, j,i and δ1, j,i as CIb, j,i = comH (ikb, j,i,δb, j,i).
For each of Alice’s input wires j = 1...(cid:30)·n, Bob ran-
domly permutes the commitments within the pair
CI0, j,i,CI1, j,i across every i = 1...k. This prevents
the cloud from correlating the location of the com-
mitment with Alice’s input value during the OOT
phase.

5. Cut and choose: Alice and Bob then run a fair coin
toss protocol to agree on a set of circuits that will
be evaluated, while the remaining circuits will be
checked. The coin toss generates a set of indices
Chk ⊂ {1, ...,k} such that |Chk| = 3
5 k, as in shelat
and Shen’s cut-and-choose protocol [41]. The re-
maining indices are placed in the set Evl for eval-
uation, where |Evl| = e = 2
5 k. For every i ∈ Chk,
Bob sends rci and the values [αb,1,i, ...,αb,n,i] and
[γb,1,i, ...,γb,(cid:30)·n,i] for b = {0,1} to the cloud. Bob
also sends all commitment keys ck j,i for j = 1...n
and i ∈ Chk to the cloud. Finally, Bob sends the
commitment keys ikb, j,i for b = {0,1}, i ∈ Chk, and
j = 1...(cid:30) · n to the cloud. The cloud then gener-
ates Garble(C,rci) =GC (cid:22)i for i ∈ Chk. For each
i ∈ Chk, the cloud then hashes each check circuit
H1(GC(cid:22)i) =HC (cid:22)i and checks that:

294  22nd USENIX Security Symposium 

USENIX Association

6

formed

value b for Bob’s jth input wire

value b for Alice’s jth input wire

• each commitment CO j,i for j = 1...n is well
• the value H2(βb, j,i) is associated with the input
• the value H2(δb, j,i) is associated with the input
• for every bit value b and input wire j, the val-
If any of these checks fail, the cloud immediately
aborts. Otherwise, it sends the hash values HC(cid:30)i for
i ∈ Chk to Alice. For every i ∈ Chk, Alice checks
if HCi = HC(cid:30)i. If any of the hash comparisons fail,
Alice aborts.

ues committed in CIb, j,i are correct

Phase 2: Outsourced Oblivious Transfer (OOT)

1. Input encoding: For every bit j = 1...n in her input
a, Alice sets encoded input ea j as a random string
of length (cid:29) such that ea1, j ⊕ ea2, j ⊕ ...⊕ eal, j = a j
for each bit in ea j. This new encoded input string
ea is of length (cid:29)· n.

2. OT setup: Alice initializes an (cid:29)· n×t matrix T with
uniformly random bit values, while Bob initializes
a random bit vector s of length t. See Figure 2 for a
more concise view.

3. Primitive OT operations: With Alice as the sender
and Bob as the chooser, the parties initiate t 1-out-
of-2 oblivious transfers. Alice’s input to the ith in-
stance of the OT is the pair (T i,T i ⊕ ea) where T i
is the ith column of T , while Bob’s input is the ith
selection bit from the vector s. Bob organizes the t
selected columns as a new matrix Q.

follows:

for Alice’s

5. Encrypting the commitment keys:

4. Permuting the selections: Alice generates a random
bit string p of length (cid:29)· n, which she sends to Bob.
Bob gen-
erates a matrix of keys
that will open the
committed garbled input values and proofs of
in-
consistency as
put bit, Bob creates a pair (x0, j,x1, j), where
xb, j = [ikb, j,Evl1,ikb, j,Evl2, ...,ikb, j,Evle]||[γb j, j,Evl2 (cid:28)
(γb j, j,Evl1)−1,γb j, j,Evl3 (cid:28) (γb j, j,Evl1)−1, ...,γb j, j,Evle (cid:28)
(γb j, j,Evl1)−1] and Evli denotes the ith index in the
set of evaluation circuits. For j = 1...(cid:29)· n, Bob pre-
pares (y0, j,y1, j) where yb, j = xb, j ⊕ H1( j,Q j ⊕ (b·
s)). Here, Q j denotes the jth row in the Q matrix.
Bob permutes the entries using Alice’s permutation
vector as (y0⊕p j, j,y1⊕p j, j). Bob sends this permuted
set of ciphertexts Y to the cloud.

jth

6. Receiving Alice’s garbled inputs: Alice blinds her
input as h = ea ⊕ p and sends h and T to the
cloud. The cloud recovers the commitment keys

7

and consistency proofs xb, j = yh j, j ⊕ H1( j,Tj) for
j = 1...(cid:29) · n. Here, h j denotes the jth bit of the
string h and Tj denotes the jth row in the T ma-
trix. Since for every j ∈ Evl, the cloud only has
the commitment key for the b garbled value (not the
b⊕1 garbled value), the cloud can correctly decom-
mit only the garbled labels corresponding to Alice’s
input bits.

7. Verifying

pre

and

Alice’s

[γb j, j,Evl2

the modiﬁed

across
decommitted

(cid:28) (γb j, j,Evl1)−1,γb j, j,Evl3

in-
values
im-
(cid:28)
the

consistency
puts:
Given
the
[δb,1,i, ...,δb,(cid:29)·n,i]
ages
(γb j, j,Evl1)−1, ...,γb j, j,Evle (cid:28) (γb j, j,Evl1)−1],
cloud checks that:
δb j, j,i = δb j, j,Evl1 (cid:23) RCLW (I,γb j, j,i (cid:28) (γb j, j,Evl1)−1)
for i = 2...e. If any of these checks fails, the cloud
aborts the protocol.

Phase 3: Generator input consistency check

1. Delivering inputs:

for

every

Bob delivers

the hash
seeds
for each of his garbled input values
[βb1,1,i,βb2,2,i, ...,βbn,n,i]
evaluation
circuit i ∈ Evl to the cloud, which forwards a copy
of these values to Alice. Bob then proves the
consistency of his inputs by sending the modiﬁed
[αb j, j,Evl2 (cid:28) (αb j, j,Evl1)−1,αb j, j,Evl3 (cid:28)
preimages
(αb j, j,Evl1)−1, ...,αb j, j,Evle (cid:28) (αb j, j,Evl1)−1] such that
FCLW (bi,I,αbi, j,i) = βbi, j,i for j = 1...n and i ∈ Evl
such that GCi was generated with the claw-free
function pair indexed at I.

2. Check consistency: Alice then checks that all the
hash seeds were generated by the same function by
checking if:
βb j, j,i = βb j, j,Evl1 (cid:23) RCLW (I,αb j, j,i (cid:28) (αb j, j,Evl1)−1)
for i = 2...e.
If any of these checks fails, Alice
aborts the protocol.

Phase 4: Circuit evaluation

1. Evaluating the circuit:For each evaluation circuit,
the cloud evaluates GCi(gai,gbi) for i ∈ Evl in the
pipelined manner described by Kreuter et al.
in
[25]. Each circuit produces two garbled output
strings, (g f ai,g f bi).

2. Checking the evaluation circuits: Once these output
have been computed, the cloud hashes each evalua-
tion circuit as H1(GCi) =HC (cid:30)i for i ∈ Evl and sends
these hash values to Alice. Alice checks that for ev-
ery i,HCi = HC(cid:30)i. If any of these checks do not pass,
Alice aborts the protocol.

USENIX Association  

22nd USENIX Security Symposium  295

Phase 5: Output check and delivery

1. Committing the outputs:The cloud then generates
random commitment keys kai,kbi and commits the
output values to their respective parties according to
the commitment scheme deﬁned by Kiraz [23], gen-
erating CA j,i = commit(ka j,i,g f a j,i) and CB j,i =
commit(kb j,i,g f b j,i) for j = 1...n and i = 1...e. The
cloud then sends all CA to Alice and CB to Bob.

2. Selection of majority output: Bob opens the com-
mitments CO j,i for j = 1...n and i = 1...e for both
Alice and the Cloud. These commitments contain
the mappings from the hash of each garbled output
wire H2(wb, j,i) to real output values b j,i for j = 1...n
and i = 1...e. The cloud selects a circuit index ma j
such that the output of that circuit matches the ma-
jority of outputs for both Alice and Bob. That is,
f ama j = f ai and f bma j = f bi for i in a set of indices
IND that is of size |IND| > e

2

3. Proof of output consistency: Using the OR-proofs
as described by Kiraz [23], the cloud proves to
Bob that CB contains valid garbled output bit val-
ues based on the de-committed output values from
the previous step. The cloud then performs the same
proof to Alice for her committed values CA. Note
that these proofs guarantee the output was generated
by one of the circuits, but the value ma j remains
hidden from both Alice and Bob.

4. Output release: The cloud then decommits g f ama j
to Alice and g f bma j to Bob. Given these garbled
outputs and the bit values corresponding to the hash
of each output wire, Alice recovers her output string
f a, and Bob recovers his output string f b.

5. Output decryption: Alice recovers her output
fA(a,b) = f a ⊕ ar, while Bob recovers fB(a,b) =
f b⊕ br.

5 Security Guarantees

In this section, we provide a summary of the security
mechanisms used in our protocol and an informal se-
curity discussion of our new outsourced oblivious trans-
fer primitive. Due to space limitations, we provide fur-
ther discussion and proofs of security in our technical
report [6].

Recall from Section 3 that there are generally four se-
curity concerns when evaluating garbled circuits in the
malicious setting. To solve the problem of malicious cir-
cuit generation, we apply the random seed check vari-
ety of cut-&-choose developed by Goyal et al. [11]. To

solve the problem of selective failure attacks, we em-
ploy the input encoding technique developed by Lin-
dell and Pinkas [29]. To prevent an adversary from us-
ing inconsistent inputs across evaluation circuits, we em-
ploy the witness-indistinguishable proofs from shelat and
Shen [41]. Finally, to ensure the majority output value
is selected and not tampered with, we use the XOR-
and-prove technique from Kiraz [23] as implemented by
Kreuter et al. [25].
In combination with the standard
semi-honest security guarantees of Yao garbled circuits,
these security extensions secure our scheme in the mali-
cious security model.
Outsourced Oblivious Transfer: Our outsourced obliv-
ious transfer is an extension of a technique developed by
Naor et al. [37] that allows the chooser to select entries
that are forwarded to a third party rather than returned
to the chooser. By combining their concept of a proxy
oblivious transfer with the semi-honest OT extension by
Ishai et al. [18], our outsourced oblivious transfer pro-
vides a secure OT in the malicious model. We achieve
this result for four reasons:

1. First, since Alice never sees the outputs of the OT
protocol, she cannot learn anything about the gar-
bled values held by the generator. This saves us
from having to implement Ishai’s extension to pre-
vent the chooser from behaving maliciously.

It is important to note that this particular application of
the OOT allows for this efﬁciency gain since the evalua-
tion of the garbled circuit will fail if Alice behaves ma-
liciously. By applying the maliciously secure extension
by Ishai et al. [18], this primitive could be applied gen-
erally as an oblivious transfer primitive that is secure in
the malicious model. Further discussion and analysis of
this general application is outside the scope of this work.
We provide the following security theorem here,
which gives security guarantees identical to the Salus
protocol by Kamara et al. [21]. However, we use dif-
ferent constructions and require a completely different
proof, which is available in our technical report [6].
Theorem 1. The outsourced two-party SFE protocol se-
curely computes a function f (a,b) in the following two

2. Since the cloud sees only random garbled values
and Alice’s input blinded by a one-time pad, the
cloud learns nothing about Alice’s true inputs.

3. Since Bob’s view of the protocol is almost identical
to his view in Ishai’s standard extension, the same
security guarantees hold (i.e., security against a ma-
licious sender).

4. Finally, if Alice does behave maliciously and uses
inconsistent inputs to the primitive OT phase, there
is a negligible probability that those values will hash
to the correct one-time pad keys for recovering ei-
ther commitment key, which will prevent the cloud
from de-committing the garbled input values.

296  22nd USENIX Security Symposium 

USENIX Association

8

(1)The cloud is malicious and
corruption scenarios:
non-cooperative with respect to the rest of the parties,
while all other parties are semi-honest, (2)All but one
party is malicious, while the cloud is semi-honest.

6 Performance Analysis

We now characterize how garbled circuits perform in the
constrained-mobile environment with and without out-
sourcing.1 Two of the most important constraints for
mobile devices are computation and bandwidth, and we
show that order of magnitude improvements for both fac-
tors are possible with outsourced evaluation. We begin
by describing our implementation framework and testbed
before discussing results in detail.
6.1 Framework and Testbed
Our framework is based on the system designed by
Kreuter et al. [25], hereafter referred to as KSS for
brevity. We implemented the outsourced protocol and
performed modiﬁcations to allow for the use of the
mobile device in the computation. Notably, KSS uses
MPI [33] for communication between the multiple nodes
of the multi-core machines relied on for circuit evalu-
ation. Our solution replaces MPI calls on the mobile
device with sockets that communicate directly with the
Generator and Proxy. To provide a consistent compari-
son, we revised the KSS codebase to allow for direct eval-
uation between the mobile device (the Evaluator) and the
cloud-based Generator.2

Our deployment platform consists of two Dell R610
servers, each containing dual 6-core Xeon processors
with 32 GB of RAM and 300 GB 10K RPM hard drives,
running the Linux 3.4 kernel and connected as a VLAN
on an internal 1 Gbps switch. These machines perform
the roles of the Generator and Proxy, respectively, as de-
scribed in Section 4.1. The mobile device acts as the
Evaluator. We use a Samsung Galaxy Nexus phone with
a 1.2 GHz dual-core ARM Cortex-A9 processor and 1
GB of RAM, running the Android 4.0 “Ice Cream Sand-
wich” operating system. We connect an Apple Airport
Express wireless access point to the switch attaching the
servers, The Galaxy Nexus communicates to the Airport
Express over an 802.11n 54Mbps WiFi connection in
an isolated environment to minimize co-channel interfer-
ence. All tests are run 10 times with error bars on ﬁgures
representing 95% conﬁdence intervals.

1We contacted the authors of the Salus protocol [21] in an attempt
to acquire their framework to compare the performance of their scheme
with ours, but they were unable to release their code.

2The full technical report [6] describes a comprehensive list of mod-
iﬁcations and practical improvements made to KSS, including ﬁxes that
were added back into the codebase of KSS by the authors. We thank
those authors for their assistance.

 1e+06

 100000

)
s
m

(
 

e
m
T

i

 10000

 1000

 100

Outsourced
Non-Outsourced

ED2

ED4

ED8

ED16

Program Size

ED32

ED64

ED128

Figure 3: Execution time for the Edit Distance program
of varying input sizes, with 2 circuits evaluated.

We measured both the total execution time of the pro-
grams and microbenchmarks for each program. All re-
sults are from the phone’s standpoint. We do not mea-
sure the time the programs take to compile as we used
the standard compiler from Kreuter et al. For our mi-
crobenchmarks, the circuit garbling and evaluation pair
is referred to as the ‘evaluation’.

6.2 Execution Time
Our tests evaluated the following problems:
Millionaires: This problem models the comparison of
two parties comparing their net worth to determine who
has more money without disclosing the actual values. We
perform the test on input values ranging in size from 4 to
8192 bits.
Edit (Levenshtein) Distance: This is a string compari-
son algorithm that compares the number of modiﬁcations
required to covert one string into another. We performed
the comparison based on the circuit generated by Jha et
al. [19] for strings sized between 4 and 128 bytes.
Set Intersection: This problem matches elements be-
tween the private sets of two parties without learning
anything beyond the intersecting elements. We base our
implementation on the SCS-WN protocol proposed by
Huang et al. [14], and evaluate for sets of size 2 to 128.
AES: We compute AES with a 128-bit key length, based
on a circuit evaluated by Kreuter et al. [25].

Figure 3 shows the result of the edit distance compu-
tation for input sizes of 2 to 128 with two circuits evalu-
ated. This comparison represents worst-case operation
due to the cost of setup for a small number of small
circuits—with input size 2, the circuit is only 122 gates in
size. For larger input sizes, however, outsourced compu-
tation becomes signiﬁcantly faster. Note that the graph
is logarithmic such that by the time strings of size 32
are evaluated, the outsourced execution is over 6 times

USENIX Association  

22nd USENIX Security Symposium  297

9

Evaluation
Checks
OT

 1e+06

 100000

)
s
m

(
 

e
m
T

i

 10000

 1000

 100

         NON

OUT        
         NON

         NON
OUT        

OUT        

ED2

ED4

ED8

         NON

OUT        

ED16
Progam

         NON

        NON

         NON

OUT        

OUT        

OUT        

ED32

ED64

ED128

 1e+06

 100000

)
s
m

(
 

e
m
T

i

 10000

 1000

 100

Outsourced
Non-Outsourced

2

4

8

16
32
Circuits Evaluated

64

128

256

Figure 4: Execution time for signiﬁcant stages of garbled
circuit computation for outsourced and non-outsourced
evaluation. The Edit Distance program is evaluated with
variable input sizes for the two-circuit case.

Figure 5: Execution time for the Edit Distance problem
of size 32, with between 2 and 256 circuits evaluated. In
the non-outsourced evaluation scheme, the mobile phone
runs out of memory evaluating 256 circuits.

faster than non-outsourced execution, while for strings of
size 128 (comprising over 3.4 million gates), outsourced
computation is over 16 times faster.

The reason for this becomes apparent when we exam-
ine Figure 4. There are three primary operations that
occur during the SFE transaction: the oblivious transfer
(OT) of participant inputs, the circuit commit (including
the circuit consistency check), and the circuit generation
and evaluation pair. As shown in the ﬁgure, the OT phase
takes 292 ms for input size 2, but takes 467 ms for input
size 128. By contrast, in the non-outsourced execution,
the OT phase takes 307 ms for input size 2, but increases
to 1860 ms for input size 128. The overwhelming fac-
tor, however, is the circuit evaluation phase. It increases
from 34 ms (input size 2) to 7320 ms (input size 128)
for the outsourced evaluation, a 215 factor increase. For
non-outsourced execution however, this phase increases
from 108 ms (input size 2) to 98800 ms (input size 128),
a factor of 914 increase.

6.3 Evaluating Multiple Circuits
The security parameter for the garbled circuit check is
2−0.32k [25], where k is the number of generated cir-
cuits. To ensure a sufﬁciently low probability (2−80) of
evaluating a corrupt circuit, 256 circuits must be eval-
uated. However, there are increasing execution costs
as increasing numbers of circuits are generated. Fig-
ure 5 shows the execution time of the Edit Distance
problem of size 32 with between 2 and 256 circuits be-
ing evaluated.
In the outsourced scheme, costs rise as
the number of circuits evaluated increases. Linear re-
gression analysis shows we can model execution time
T as a function of the number of evaluated circuits k
with the equation T = 243.2k + 334.6 ms, with a coef-

ﬁcient of determination R2 of 0.9971. However, note
that in the non-outsourced scheme, execution time in-
creases over 10 times as quickly compared to outsourced
evaluation. Regression analysis shows execution time
T = 5435.7k + 961 ms, with R2 = 0.9998. Because in
this latter case, the mobile device needs to perform all
computation locally as well as transmit all circuit data
to the remote parties, these costs increase rapidly. Fig-
ure 6 provides more detail about each phase of execution.
Note that the OT costs are similar between outsourced
and non-outsourced execution for this circuit size, but
that the costs of consistency checks and evaluation vastly
increase execution time for non-outsourced execution.

Note as well that in the non-outsourced scheme, there
are no reported values for 256 circuits, as the Galaxy
Nexus phone ran out of memory before the execution
completed. We observe that a single process on the
phone is capable of allocating 512 MB of RAM before
the phone would report an out of memory error, provid-
ing insight into how much intermediate state is required
for non-outsourced evaluation. Thus, to handle circuits
of any meaningful size with enough check circuits for
a strong security parameter, the only way to be able to
perform these operations is through outsourcing.

Table 1 presents the execution time of a representative
subset of circuits that we evaluated. It spans circuits from
small to large input size, and from 8 circuits evaluated to
the 256 circuits required for a 2−80 security parameter.
Note that in many cases it is impossible to evaluate the
non-outsourced computation because of the mobile de-
vice’s inability to store sufﬁcient amounts of state. Note
as well that particularly with complex circuits such as set
intersection, even when the non-outsourced evaluation is
capable of returning an answer, it can require orders of

298  22nd USENIX Security Symposium 

USENIX Association

10

Program

Millionaires 128
Millionaires 1024
Millionaires 8192
Edit Distance 2
Edit Distance 32
Edit Distance 128
Set Intersection 2
Set Intersection 32
Set Intersection 128

AES-128

8 Circuits

32 Circuits

128 Circuits

256 Circuits

Outsourced
2150.0 ± 1%
4670.0 ± 6%
17280.0 ± 0.9%
1268.0 ± 0.9%
2860.0 ± 3%
12800.0 ± 2%
1598.0 ± 0.8%
5200.0 ± 10%
24300.0 ± 2%
2450.0 ± 2%

KSS

6130.0 ± 0.6%
46290.0 ± 0.4%
368800.0 ± 0.4%
794.0 ± 1%
44610.0 ± 0.7%
702400.0 ± 0.5%
1856.0 ± 0.9%
96560.0 ± 0.6%
1398000.0 ± 0.4%
15040.0 ± 0.7%

Outsourced
8210.0 ± 3%
17800.0 ± 1%
76980.0 ± 0.5%
4060.0 ± 1%
7470.0 ± 5%
30300.0 ± 2%
5720.0 ± 0.7%
13800.0 ± 1%
55400.0 ± 3%
9090.0 ± 5%

KSS

23080.0 ± 0.6%
180500.0 ± 0.3%
1519000.0 ± 0.4%
2125.0 ± 0.7%
175600.0 ± 0.5%
2805000.0 ± 0.8%
6335.0 ± 0.4%
400800.0 ± 0.6%
5712000.0 ± 0.4%
58920.0 ± 0.5%

Outsourced
38100.0 ± 7%
75290.0 ± 1%
351300.0 ± 0.7%
19200.0 ± 2%
30500.0 ± 3%
106200.0 ± 0.6%
26100.0 ± 2%
59400.0 ± 1%
1998000.0 ± 0.5%
39000.0 ± 2%

KSS

91020.0 ± 0.8%
744500.0 ± 0.7%
-
7476.0 ± 0.5%
699000.0 ± 2%
-
24420.0 ± 0.6%
-
-
276200.0 ± 0.6%

Outsourced
75700.0 ± 1%
151000.0 ± 1%
880000.0 ± 20%
42840.0 ± 0.4%
63600.0 ± 1%
213400.0 ± 0.3%
56350.0 ± 0.8%
125300.0 ± 0.9%
395200.0 ± 0.8%
81900.0 ± 1%

KSS

180800.0 ± 0.5%
1507000.0 ± 0.5%
-
14600.0 ± 0.8%
-
-
48330.0 ± 0.6%
-
-
577900.0 ± 0.5%

Table 1: Execution time (in ms) of outsourced vs non-outsourced (KSS) evaluation for a subset of circuits. Results
with a dash indicate evaluation that the phone was incapable of performing.

)
s
m

(
 

e
m
T

i

 1e+06

Evaluation
Checks
OT

 100000

        NON

 10000

          NON

        NON

        NON

        NON

        NON

        NON

OUT       

OUT       

OUT       

OUT       

OUT       

OUT       

OUT       

OUT       

 1000

 100

2

4

8

16
32
Circuits Evaluated

64

128

256

)
s
e

t
y
b
(
 
h
t

i

d
w
d
n
a
B

 1e+09

 1e+08

 1e+07

 1e+06

 100000

 10000

 1000

 100

Outsourced
Non-Outsourced

ED2

ED4

ED8

ED16

Program Size

ED32

ED64

ED128

Figure 6: Microbenchmarks of execution time for Edit
Distance with input size 32, evaluating from 2 to 256
circuits. Note that the y-axis is log-scale; consequently,
the vast majority of execution time is in the check and
evaluation phases for non-outsourced evaluation.

magnitude more time than with outsourced evaluation.
For example, evaluating the set intersection problem with
128 inputs over 32 circuits requires just over 55 seconds
for outsourced evaluation but over an hour and a half
with the non-outsourced KSS execution scheme. Out-
sourced evaluation represents a time savings of 98.92%.
For space concerns, we have omitted certain values; full
results can be found in our technical report [6].

Multicore Circuit Evaluation We brieﬂy note the ef-
fects of multicore servers for circuit evaluation. The
servers in our evaluation each contain dual 6-core CPUs,
providing 12 total cores of computation. The compu-
tation process is largely CPU-bound: while circuits on
the servers are being evaluated, each core was reporting
approximately 100% utilization. This is evidenced by
regression analysis when evaluating between 2 and 12
circuit copies; we ﬁnd that execution time T = 162.6k +
1614.6 ms, where k is the number of circuits evaluated,
with a coefﬁcient of determination R2 of 0.9903. As
the number of circuits to be evaluated increases beyond
the number of available cores, the incremental costs of

Figure 7: Bandwidth measurements from the phone to
remote parties for the Edit Distance problem with vary-
ing input sizes, executing two circuits.

adding new circuits becomes higher; in our observation
of execution time for 12 to 256 circuits, our regression
analysis provided the equation T = 247.4k − 410.6 ms,
with R2 = 0.998. This demonstrates that evaluation of
large numbers of circuits is optimal when every evalu-
ated circuit can be provided with a dedicated core.

The results above show that as many-way servers are
deployed in the cloud, it becomes easier to provide op-
timal efﬁciency computing outsourced circuits. A 256-
core machine would be able to evaluate 256 circuits in
parallel to provide the accepted standard 2−80 security
parameter. Depending on the computation performed,
there can be a trade-off between a slightly weaker se-
curity parameter and maintaining optimal evaluation on
servers with lower degrees of parallelism. In our testbed,
optimal evaluation with 12 cores provides a security pa-
rameter of 2−3.84. Clearly more cores would provide
stronger security while keeping execution times propor-
tional to our results. A reasonable trade-off might be 32
circuits, as 32-core servers are readily available. Evalu-
ating 32 circuits provides a security parameter of 2−10.2,
equivalent to the adversary having less than a 1
512 chance
of causing the evaluator to compute over a majority of
corrupt circuits. Stronger security guarantees on less par-

USENIX Association  

22nd USENIX Security Symposium  299

11

32 Circuits

Program

Millionaires 128
Millionaires 1024
Millionaires 8192
Edit Distance 2
Edit Distance 32
Edit Distance 128
Set Intersection 2
Set Intersection 32
Set Intersection 128

AES-128

Outsourced

336749
2280333
17794637

56165
134257
350721
117798
1173844
4490932
367364

KSS

1445369
11492665
91871033
117245
41889641
682955633

519670
84841300
1316437588

9964576

Factor

Improvement

4.29X
5.04X
5.16X
2.09X
312.01X
1947.29X

4.41X
72.28X
293.13X
27.12X

Table 2: Total Bandwidth (Bytes) transmitted to and
from the phone during execution.

allel machines can be achieved at the cost of increasing
execution time, as individual cores will not be dedicated
to circuit evaluation. However, if a 256-core system is
available, it will provide optimal results for achieving a
2−80 security parameter.
6.4 Bandwidth
For a mobile device, the costs of transmitting data are in-
trinsically linked to power consumption, as excess data
transmission and reception reduces battery life. Band-
width is thus a critical resource constraint. In addition,
because of potentially uncertain communication chan-
nels, transmitting an excess of information can be a rate-
limiting factor for circuit evaluation. Figure 7 shows
the bandwidth measurement between the phone and re-
mote parties for the edit distance problem with 2 circuits.
When we compared execution time for this problem in
Figure 3, we found that trivially small circuits could ex-
ecute in less time without outsourcing. Note, however,
that there are no cases where the non-outsourced scheme
consumes less bandwidth than with outsourcing.

This is a result of the signiﬁcant improvements gar-
nered by using our outsourced oblivious transfer (OOT)
construction described in Section 4. Recall that with the
OOT protocol, the mobile device sends inputs for eval-
uation to the generator; however, after this occurs, the
majority of computation until the ﬁnal output veriﬁca-
tion from the cloud occurs between the generator and
the cloud, with the mobile device only performing mi-
nor consistency checks. Figure 7 shows that the amount
of data transferred increases only nominally compared
to the non-outsourced protocol. Apart from the ini-
tial set of inputs transmitted to the generator, data de-
mands are largely constant. This is further reﬂected
in Table 2, which shows the vast bandwidth savings
over the 32-circuit evaluation of our representative pro-
grams. In particular, for large, complex circuits, the sav-
ings are vast: outsourced AES-128 requires 96.3% less
bandwidth, while set intersection of size 128 requires
99.7% less bandwidth than in the non-outsourced evalua-

tion. Remarkably, the edit distance 128 problem requires
99.95%, over 1900 times less bandwidth, for outsourced
execution. The full table is in our technical report [6].

The takeaway from our evaluation is simple: outsourc-
ing the computation allows for faster and larger circuit
evaluation than previously possible on a mobile device.
Speciﬁcally, outsourcing allows users to evaluate garbled
circuits with adequate malicious model security (256 cir-
cuits), which was previously not possible on mobile de-
vices. In addition, outsourcing is by far the most efﬁcient
option if the bandwidth use of the mobile devices is a
principle concern.
7 Evaluating Large Circuits

Beyond the standard benchmarks for comparing garbled
circuit execution schemes, we aimed to provide com-
pelling applications that exploit the mobile platform with
large circuits that would be used in real-world scenar-
ios. We discuss public-key cryptography and the Dijk-
stra shortest path algorithm, then describe how the latter
can be used to implement a privacy-preserving naviga-
tion application for mobile phones.

7.1 Large Circuit Benchmarks
Table 3 shows the execution time required for a blinded
RSA circuit of input size 128. For these tests we used
a more powerful server with 64 cores and 1 Terabyte
of memory. Our testbed is able to give dedicated CPUs
when running 32 circuits in parallel. Each circuit would
have 1 core for the generation and 1 core for the evalu-
ation. As described in Section 6, larger testbeds capable
of executing 128 or 256 cores in parallel would be able to
provide similar results for executing the 256 circuits nec-
essary for a 2−80 security parameter as they could evalu-
ate the added circuits in parallel. The main difference in
execution time would come from the multiple OTs from
the mobile device to the outsourced proxy. The RSA cir-
cuit has been previously evaluated with KSS, but never
from the standpoint of a mobile device.

We only report the outsourced execution results, as the
circuits are far too large to evaluate directly on the phone.
As with the larger circuits described in Section 6, the
phone runs out of memory from merely trying to store
a representation of the circuit. Prior to optimization, the
blinded RSA circuit is 192,537,834 gates and afterward,
comprises 116,083,727 gates, or 774 MB in size.

The implementation of Dijkstra’s shortest-path algo-
rithm results in very large circuits. As shown in Table 3,
the pre-optimized size of the shortest path circuit for
20 vertices is 20,288,444 gates and after optimization
is 1,653,542 gates. The 100-node graph is even larger,
with 168,422,382 gates post optimization, 1124 MB in
size. This ﬁnal example is among the largest evaluated

300  22nd USENIX Security Symposium 

USENIX Association

12

RSA128
Dijkstra20
Dijkstra50
Dijkstra100

64 Circuits (ms)
128 Circuits (ms)
32 Circuits Time (ms)
734000.0 ± 4% 1420000.0 ± 1%
505000.0 ± 2%
25800.0 ± 2%
49400.0 ± 1%
106000.0 ± 1%
197000.0 ± 3%
389000.0 ± 2%
135000.0 ± 1%
892000.0 ± 2% 1300000.0 ± 2% 2560000.0 ± 1%

Optimized Gates

Unoptimized Gates

Size (MB)

116,083,727
1,653,542
22,109,732
168,422,382

192,537,834
20,288,444
301,846,263
2,376,377,302

774
11
147
1124

Table 3: Execution time for evaluating a 128-bit blinded RSA circuit and Dijkstra shortest path solvers over graphs
with 20, 50, and 100 vertices. All numbers are for outsourced evaluation, as the circuits are too large to be computed
without outsourcing to a proxy.

(a) 20 identiﬁed intersections.

(b) 50 identiﬁed intersections.

(c) 100 identiﬁed intersections.

Figure 8: Map of potential presidential motorcade routes through Washington, DC. As the circuit size increases, a
larger area can be represented at a ﬁner granularity.

garbled circuits to date. While it may be possible for
existing protocols to evaluate circuits of similar size, it
is signiﬁcant that we are evaluating comparably massive
circuits from a resource-constrained mobile device.

7.2 Privacy-Preserving Navigation
Mapping and navigation are some of the most popular
uses of a smartphone. Consider how directions may be
given using a mobile device and an application such as
Google Maps, without revealing the user’s current loca-
tion, their ultimate destination, or the route that they are
following. That is, the navigation server should remain
oblivious of these details to ensure their mutual privacy
and to prevent giving away potentially sensitive details if
the phone is compromised. Speciﬁcally, consider plan-
ning of the motorcade route for the recent Presidential
inauguration. In this case, the route is generally known
in advance but is potentially subject to change if sudden
threats emerge. A ﬁeld agent along the route wants to re-
ceive directions without providing the navigation service
any additional details, and without sensitive information
about the route loaded to the phone. Moreover, because
the threats may be classiﬁed, the navigation service does
not want the holder of the phone to be given this infor-
mation directly. In our example, the user of the phone is
trying to determine the shortest path.

To model this scenario, we overlay a graph topology
on a map of downtown Washington D.C., encoding in-
tersections as vertices. Edge weights are a function of
their distance and heuristics such as potential risks along
a graph edge. Figure 8 shows graphs generated based
on vertices of 20, 50, and 100 nodes, respectively. Note
that the 100-node graph (Figure 8c) encompasses a larger
area and provides ﬁner-grained resolution of individual

intersections than the 20-node graph (Figure 8a).

There is a trade-off between detail and execution time,
however; as shown in Table 3, a 20-vertex graph can be
evaluated in under 26 seconds, while a 100-vertex graph
requires almost 15 minutes with 32 circuits in our 64-
core server testbed. The 64 circuit evaluation requires
more time: almost 50 seconds for the 20-vertex graph,
and almost 22 minutes for a 100-vertex graph. We an-
ticipate that based on the role a particular agent might
have on a route, they will be able to generate a route that
covers their particular geographical jurisdiction and thus
have an appropriately sized route, with only certain users
requiring the highest-resolution output. Additionally, as
described in Section 6.3, servers with more parallel cores
can simultaneously evaluate more circuits, giving faster
results for the 64 circuit evaluation.

Figure 9 reﬂects two routes. The ﬁrst, overlaid with a
dashed blue line, is the shortest path under optimal con-
ditions that is output by our directions service, based on
origin and destination points close to the historical start
and end points of the past six presidential inaugural mo-
torcades. Now consider that incidents have happened
along the route, shown in the ﬁgure as a car icon in a
hazard zone inside a red circle. The agent recalculates
the optimal route, which has been updated by the navi-
gation service to assign severe penalties to those corre-
sponding graph edges. The updated route returned by
the navigation service is shown in the ﬁgure as a path
with a dotted purple line. In the 50-vertex graph in Fig-
ure 8, the updated directions would be available in just
over 135 seconds for 32-circuit evaluation, and 196 and
a half seconds for 64-circuit evaluation.

USENIX Association  

22nd USENIX Security Symposium  301

13

START 
POINT

Modiﬁed Route

Optimal Route

END 
POINT

Figure 9: Motorcade route with hazards along the route. The dashed blue line represents the optimal route, while the
dotted violet line represents the modiﬁed route that takes hazards into account.

8 Conclusion

While garbled circuits offer a powerful tool for secure
function evaluation, they typically assume participants
with massive computing resources. Our work solves
this problem by presenting a protocol for outsourcing
garbled circuit evaluation from a resource-constrained
mobile device to a cloud provider in the malicious
setting. By extending existing garbled circuit evaluation
techniques, our protocol signiﬁcantly reduces both com-
putational and network overhead on the mobile device
while still maintaining the necessary checks for mali-
cious or lazy behavior from all parties. Our outsourced
oblivious transfer construction signiﬁcantly reduces the
communication load on the mobile device and can easily
accommodate more efﬁcient OT primitives as they are
developed. The performance evaluation of our protocol
shows dramatic decreases in required computation and
bandwidth. For the edit distance problem of size 128
with 32 circuits, computation is reduced by 98.92% and
bandwidth overhead reduced by 99.95% compared to
non-outsourced execution. These savings are illustrated
in our privacy-preserving navigation application, which
allows a mobile device to efﬁciently evaluate a massive
garbled circuit securely through outsourcing. These
results demonstrate that
improvements in
garbled circuit efﬁciency can be applied in practical
privacy-preserving mobile applications on even the most
resource-constrained devices.

the recent

Acknowledgments This material is based on research
sponsored by DARPA under agreement number FA8750-
11-2-0211. The U.S. Government is authorized to repro-
duce and distribute reprints for Governmental purposes
notwithstanding any copyright notation thereon. The
views and conclusions contained herein are those of the
authors and should not be interpreted as necessarily rep-
resenting the ofﬁcial policies or endorsements, either ex-
pressed or implied, of DARPA or the U.S. Government.
We would like to thank Benjamin Kreuter, abhi shelat,
and Chih-hao Shen for working with us on their garbled
circuit compiler and evaluation framework; Chris Peikert
for providing helpful feedback on our proofs of security;
Thomas DuBuisson and Galois for their assistance in the
performance evaluation; and Ian Goldberg for his guid-
ance during the shepherding process.

References

[1] M. Bellare and S. Micali. Non-interactive obliv-
In Advances in

ious transfer and applications.
Cryptology–CRYPTO, 1990.

[2] M. Ben-Or, S. Goldwasser, and A. Wigder-
son. Completeness theorems for non-cryptographic
fault-tolerant distributed computation. In Proceed-
ings of the annual ACM symposium on Theory of
computing, 1988.

302  22nd USENIX Security Symposium 

USENIX Association

14

[3] J. Brickell and V. Shmatikov. Privacy-preserving
graph algorithms in the semi-honest model. In Pro-
ceedings of the international conference on Theory
and Application of Cryptology and Information Se-
curity, 2005.

[14] Y. Huang, D. Evans, and J. Katz. Private set in-
tersection: Are garbled circuits better than custom
protocols? In NDSS ’12: Proceedings of the 19th
ISOC Symposium on Network and Distributed Sys-
tems Security, San Diego, CA, USA, Feb. 2012.

[4] R. Canetti, Y. Lindell, R. Ostrovsky, and A. Sahai.
Universally composable two-party and multi-party
secure computation. In Proceedings of the annual
ACM symposium on Theory of computing, 2002.

[5] H. Carter, C. Amrutkar, I. Dacosta, and P. Traynor.
Efﬁcient oblivious computation techniques for
privacy-preserving mobile applications. Journal of
Security and Communication Networks (SCN), To
appear 2013.

[6] H. Carter, B. Mood, P. Traynor, and K. Butler. Se-
cure outsourced garbled circuit evaluation for mo-
bile devices. Technical Report GT-CS-12-09, Col-
lege of Computing, Georgia Institute of Technol-
ogy, 2012.

[7] D. Chaum, C. Cr´epeau, and I. Damgard. Multiparty
unconditionally secure protocols. In Proceedings of
the annual ACM symposium on Theory of comput-
ing, 1988.

[8] S. G. Choi, J. Katz, R. Kumaresan, and H.-S. Zhou.
On the security of the ”free-xor” technique. In Pro-
ceedings of the international conference on Theory
of Cryptography, 2012.

[9] I. Damg˚ard and Y. Ishai. Scalable secure multi-
party computation.
In Proceedings of the annual
international conference on Advances in Cryptol-
ogy, 2006.

[10] I. Damg˚ard and J. B. Nielsen. Scalable and un-
conditionally secure multiparty computation.
In
Proceedings of the annual international cryptology
conference on Advances in cryptology, 2007.

[11] V. Goyal, P. Mohassel, and A. Smith. Efﬁcient two
party and multi party computation against covert
adversaries. In Proceedings of the theory and ap-
plications of cryptographic techniques annual in-
ternational conference on Advances in cryptology,
2008.

[12] M. Green, S. Hohenberger, and B. Waters. Out-
sourcing the decryption of abe ciphertexts.
In
Proceedings of the USENIX Security Symposium,
2011.

[13] Y. Huang, P. Chapman, and D. Evans. Privacy-
Preserving Applications on Smartphones. In Pro-
ceedings of the USENIX Workshop on Hot Topics
in Security, 2011.

[15] Y. Huang, D. Evans, J. Katz, and L. Malka. Faster
secure two-party computation using garbled cir-
cuits. In Proceedings of the USENIX Security Sym-
posium, 2011.

[16] Y. Huang, J. Katz, and D. Evans. Quid-pro-quo-
tocols: Strengthening semi-honest protocols with
dual execution. In Proceedings of the IEEE Sympo-
sium on Security and Privacy, 2012.

[17] A. Iliev and S. W. Smith. Small, stupid, and scal-
able: Secure computing with faerieplay.
In The
ACM Workshop on Scalable Trusted Computing,
2010.

[18] Y. Ishai, J. Kilian, K. Nissim, and E. Petrank. Ex-
tending oblivious transfers efﬁciently. In Proceed-
ings of the Annual International Cryptology Con-
ference, 2003.

[19] S. Jha, L. Kruger, and V. Shmatikov. Towards prac-
tical privacy for genomic computation. In Proceed-
ings of the IEEE Symposium on Security and Pri-
vacy, 2008.

[20] S. Kamara, P. Mohassel, and M. Raykova. Out-
sourcing multi-party computation.
Cryptology
ePrint Archive, Report 2011/272, 2011. http:
//eprint.iacr.org/.

[21] S. Kamara, P. Mohassel, and B. Riva. Salus: A sys-
tem for server-aided secure function evaluation. In
Proceedings of the ACM conference on Computer
and communications security (CCS), 2012.

[22] M. S. Kiraz. Secure and Fair Two-Party Compu-
tation. PhD thesis, Technische Universiteit Eind-
hoven, 2008.

[23] M. S. Kiraz and B. Schoenmakers. A protocol is-
sue for the malicious case of yaos garbled circuit
construction. In Proceedings of Symposium on In-
formation Theory in the Benelux, 2006.

[24] V. Kolesnikov and T. Schneider.

Improved gar-
bled circuit: Free xor gates and applications.
In
Proceedings of the international colloquium on
Automata, Languages and Programming, Part II,
2008.

[25] B. Kreuter, a. shelat, and C. Shen. Billion-gate se-
In

cure computation with malicious adversaries.

USENIX Association  

22nd USENIX Security Symposium  303

15

Proceedings of the USENIX Security Symposium,
2012.

[26] L. Kruger, S. Jha, E.-J. Goh, and D. Boneh. Se-
cure function evaluation with ordered binary deci-
sion diagrams.
In Proceedings of the ACM con-
ference on Computer and communications security
(CCS), 2006.

[27] Y. Lindell. Lower bounds and impossibility results
for concurrent self composition. Journal of Cryp-
tology, 21(2):200–249, 2008.

[28] Y. Lindell and B. Pinkas. Privacy preserving data
mining. In Proceedings of the Annual International
Cryptology Conference on Advances in Cryptology,
2000.

[29] Y. Lindell and B. Pinkas. An efﬁcient protocol
for secure two-party computation in the presence of
malicious adversaries. In Proceedings of the annual
international conference on Advances in Cryptol-
ogy, 2007.

[30] Y. Lindell and B. Pinkas. Secure two-party com-
putation via cut-and-choose oblivious transfer. In
Proceedings of the conference on Theory of cryp-
tography, 2011.

[31] L. Malka. Vmcrypt: modular software architecture
for scalable secure computation. In Proceedings of
the 18th ACM conference on Computer and com-
munications security, 2011.

[32] D. Malkhi, N. Nisan, B. Pinkas, and Y. Sella.
Fairplay–a secure two-party computation system.
In Proceedings of the USENIX Security Sympo-
sium, 2004.

[37] M. Naor, B. Pinkas, and R. Sumner. Privacy pre-
serving auctions and mechanism design.
In Pro-
ceedings of the ACM conference on Electronic com-
merce, 1999.

[38] N. Nipane, I. Dacosta, and P. Traynor. “Mix-In-
Place” anonymous networking using secure func-
tion evaluation. In Proceedings of the Annual Com-
puter Security Applications Conference (ACSAC),
2011.

[39] C. Peikert, V. Vaikuntanathan, and B. Waters. A
framework for efﬁcient and composable oblivious
transfer.
In Advances in Cryptology (CRYPTO),
2008.

[40] W. Rash.

Dropbox password breach high-
http:

lights cloud security weaknesses.
//www.eweek.com/c/a/Security/
Dropbox-Password-Breach-Highlights
-Cloud-Security-Weaknesses-266215/,
2012.

[41] a. shelat and C.-H. Shen. Two-output secure com-
putation with malicious adversaries.
In Proceed-
ings of the Annual international conference on The-
ory and applications of cryptographic techniques,
2011.

[42] K. Thomas. Microsoft cloud data breach heralds
things to come. http://www.pcworld.com/
article/214775/microsoft_cloud_
data_breach_sign_of_future.html,
2010.

[43] A. C. Yao. Protocols for secure computations. In
Proceedings of the Annual Symposium on Founda-
tions of Computer Science, 1982.

[33] Message Passing
passing

message
http://www.mcs.anl.gov/research/
projects/mpi/, 2009.

Interface Forum.
interface
(mpi)

The
standard.

[34] P. Mohassel and M. Franklin. Efﬁciency tradeoffs
for malicious two-party computation. In Proceed-
ings of the Public Key Cryptography conference,
2006.

[35] B. Mood, L. Letaw, and K. Butler. Memory-
efﬁcient garbled circuit generation for mobile de-
vices.
In Proceedings of the IFCA International
Conference on Financial Cryptography and Data
Security (FC), 2012.

[36] M. Naor and B. Pinkas. Efﬁcient oblivious transfer
protocols. In Proceedings of the annual ACM-SIAM
symposium on Discrete algorithms, 2001.

304  22nd USENIX Security Symposium 

USENIX Association

16

