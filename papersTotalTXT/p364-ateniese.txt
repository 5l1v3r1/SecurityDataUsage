Subversion-Resilient Signature Schemes

Giuseppe Ateniese

Dipartimento di Informatica
Sapienza Università di Roma
Via Salaria 113, Rome, Italy
ateniese@di.uniroma1.it

Bernardo Magri

Dipartimento di Informatica
Sapienza Università di Roma
Via Salaria 113, Rome, Italy
magri@di.uniroma1.it

Daniele Venturi

Dipartimento di Informatica
Sapienza Università di Roma
Via Salaria 113, Rome, Italy
venturi@di.uniroma1.it

ABSTRACT
We provide a formal treatment of security of digital signa-
tures against subversion attacks (SAs). Our model of subver-
sion generalizes previous work in several directions, and is in-
spired by the proliferation of software attacks (e.g., malware
and buﬀer overﬂow attacks), and by the recent revelations of
Edward Snowden about intelligence agencies trying to sur-
reptitiously sabotage cryptographic algorithms. The main
security requirement we put forward demands that a signa-
ture scheme should remain unforgeable even in the presence
of an attacker applying SAs (within a certain class of allowed
attacks) in a fully-adaptive and continuous fashion. Pre-
vious notions—e.g., security against algorithm-substitution
attacks introduced by Bellare et al. (CRYPTO ’14) for sym-
metric encryption—were non-adaptive and non-continuous.
In this vein, we show both positive and negative results

for constructing subversion-resilient signature schemes.

• Negative results. As our main negative result, we
show that a broad class of randomized schemes is un-
avoidably insecure against SAs, even if using just a
single bit of randomness. This improves upon earlier
work that was only able to attack schemes with larger
randomness space.

When designing our attack we consider undetectabil-
ity to be an explicit adversarial goal, meaning that
the end-users (even the ones knowing the signing key)
should not be able to detect that the signature scheme
was subverted.

• Positive results. We complement the above negative
results by showing that signature schemes with unique
signatures are subversion-resilient against all attacks
that meet a basic undetectability requirement. A sim-
ilar result was shown by Bellare et al. for symmetric
encryption, who proved the necessity to rely on state-
ful schemes; in contrast unique signatures are stateless,
and in fact they are among the fastest and most estab-
lished digital signatures available.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
© 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813635.

We ﬁnally show that it is possible to devise signa-
ture schemes secure against arbitrary tampering with
the computation, by making use of an un-tamperable
cryptographic reverse ﬁrewall (Mironov and Stephens-
Davidowitz, EUROCRYPT ’15), i.e., an algorithm that
“sanitizes” any signature given as input (using only
public information). The ﬁrewall we design allows
to successfully protect so-called re-randomizable sig-
nature schemes (which include unique signatures).

While our study is mainly theoretical, due to its strong prac-
tical motivation, we believe that our results have important
implications in practice and might inﬂuence the way digital
signature schemes are selected or adopted in standards and
protocols.

Categories and Subject Descriptors
E.3 [Data Encryption]: Public key cryptosystems

General Terms
Security, Algorithm, Design

Keywords
Digital signatures; Subversion; Malware; Tampering

1.

INTRODUCTION

Balancing national security interests with the rights to pri-
vacy of lawful citizen is always a daunting task. It has been
particularly so in the last couple of years after the revela-
tions of Edward Snowden [36] that have evidenced a massive
collection of metadata and other information perpetrated by
several intelligence agencies. It is now clear that intelligence
operators were not just interested in collecting and mining
information but they also actively deployed malware, ex-
ploited zero-day vulnerabilities, and carried out active at-
tacks against standard protocols.
In addition, it appears
some cryptographic protocol speciﬁcations were modiﬁed to
embed backdoors.

Whether this activity was eﬀective or even allowed by the
constitution is open to debate and it is indeed being furi-
ously discussed among policy makers, the public, and the
intelligence community. Ultimately, a balance between se-
curity and privacy must be found for a free and functioning
society.

The ability of substituting a cryptographic algorithm with
an altered version was ﬁrst considered formally by Young

364and Yung (extending previous works of Simmons on sublimi-
nal channels [40]), who termed this ﬁeld kleptography [43,44].
The idea is that the attacker surreptitiously modiﬁes a cryp-
tographic scheme with the intent of subverting its secu-
rity. This research area has recently been revitalized by
Bellare et al. [6] who considered encryption algorithms with
the possibility of mass surveillance under the algorithm-
substitution attack. They analyzed the possibility of an in-
telligence agency substituting an encryption algorithm with
the code of an alternative version that undetectably reveals
the secret key or the plaintext. What they uncovered is that
any randomized and stateless encryption scheme would fall
to generic algorithm-substitution attacks. The only way to
achieve a meaningful security guarantee (CPA-security) is
to use a nonce-based encryption that must keep state. Un-
fortunately, only stateless schemes are deployable eﬀectively
with the current network technology and indeed all encryp-
tion algorithms currently in use are in this class.

In this paper we analyze digital signature schemes under
the so-called subversion attacks (SAs), that in particular in-
clude algorithm-substitution and kleptographic attacks as a
special case, but additionally cover more general malware
and virus attacks (see below). Unlike encryption, we show
positive results and truly eﬃcient schemes that provide the
strongest security guarantee and can thus be deployed within
real systems. We stress that our intention is not to propose
schemes that can be abused by criminals to avoid monitor-
ing. We are motivated by pure scientiﬁc curiosity and aspire
to contribute to an active ﬁeld of research.

1.1 Our Results and Techniques

We introduce a new and generic framework and deﬁnitions
for subversions of digital signatures. In the standard black-
box setting, a signature scheme should remain unforgeable
even against an adversary able to obtain signatures on (poly-
nomially many) chosen messages. Our security deﬁnitions
empower the adversary with the ability of continuously sub-
verting the signing algorithm within a class A of allowed
SAs. For each chosen subversion in the class, the adver-
sary can access an oracle that answers (polynomially many)
signature queries using the subverted signature algorithm.
Importantly, the diﬀerent subversions can be chosen in a
fully-adaptive manner possibly depending on the target ver-
iﬁcation key of the user.

We believe our model is very general and ﬂexible, as it
nicely generalizes previous models and deﬁnitions. First oﬀ,
when the class A consists of a set of algorithms contain-
ing a secretly embedded backdoor, and in case the adver-
sary is restricted to non-adaptively choose only a single sub-
version algorithm from this class, we obtain the setting of
algorithm-substitution and kleptographic attacks as a spe-
cial case. However, we note that the above deﬁnition is far
more general as it covers (fully-adaptive and continuous)
tampering with the computation performed by the signing
algorithm (within the class A). This models, for instance,
a machine running a signature software infected by a mal-
ware, e.g., via a buﬀer overﬂow attack as described by Pincus
and Baker at Oakland ’04 [37]; we also obtain memory and
randomness tampering (see Section 1.3) as a special case.
We refer the reader to Section 3.1 (where we introduce our
model formally) for a more comprehensive discussion.
Clearly, without making any restriction on the class A (or
without making additional assumptions) there is no hope for

security: An arbitrary subverted signature algorithm could,
for instance, just ignore all inputs and output the secret key.
In this paper we investigate two approaches to tackle attacks
of this sort and obtain positive results.

• Limiting the adversarial power. We consider a
setting where the adversarial goal is to subvert the
signature algorithm in a way that is undetectable to
the end-user (or at least allows to maintain plausible
deniability). For instance the simple attack above—
where the subversion outputs the secret key—is easily
detectable given only public information. As we show
in Section 5, requiring that the class A satisﬁes a basic
undetectability requirement already allows for inter-
esting positive results.

• Using a Reverse Firewall.

In Section 6 we show
that security against arbitrary tampering with the com-
putation can be achieved, by making the additional as-
sumption of an un-tamperable cryptographic reverse
ﬁrewall (RF) [33]. Roughly, a RF takes as input a
message/signature pair and is allowed to “sanitize” the
input signature using only public information.

A more detailed description of our techniques follows.
Negative results. We deﬁne what it means for a class A of
SAs to be undetectable; roughly this means that a user,
given polynomially many queries, cannot distinguish the
output of the genuine signature algorithm from the output of
the subverted algorithm. See Section 3.2 for a precise deﬁni-
tion. Our deﬁnitions of undetectability are similar in spirit
to the ones put forward by [6] for the setting of symmet-
ric encryption. Importantly we distinguish the case where
the user (trying to detect the attack) knows only public or
private information (i.e., it knows the secret key).1

Next, we explore the possibility of designing classes of SAs
that are (even secretly) undetectable and yet allow for com-
plete security breaches. This direction was already pursued
by Bellare et al., who showed that it is possible to stealthily
bias the random coins of suﬃciently randomized symmetric
encryption schemes in a way that allows to extract the se-
cret key after observing a suﬃcient number of (subverted)
ciphertexts. As a ﬁrst negative result, we explain how to
adapt the “biased randomness attack” of [6] to the case of
signature schemes.

The above generic attack requires that the underlying sig-
nature scheme uses a minimal amount of randomness (say,
7 bits). This leaves the interesting possibility that less ran-
domized schemes (such as the Katz-Wang signature scheme
introduced at CCS ’03 [29], using only one bit of random-
ness) might be secure. In Section 4, we present a new attack
showing that this possibility is vacuous: Our attack allows
to stealthily bias the randomness in a way that later be-
comes possible to extract the signing key—regardless of the
number of random bits required by the scheme—assuming
that the targeted signature scheme is coin-extractable. The
latter roughly means that the random coins used for generat-
ing signatures can be extracted eﬃciently from the signature
itself; as we discuss in more detail in Section 4.2 many real
schemes (including Katz-Wang) are coin-extractable.

1As we show, secret and public undetectability are not
equivalent, in that there exist natural classes of SAs that
are publicly undetectable but secretly detectable.

365Positive results. We complement the above negative re-
sults by showing that deterministic schemes with unique2
signatures are subversion-resilient against the class of SAs
that satisﬁes the so-called veriﬁability condition.3 This es-
sentially means that—for all values in the message space—
signatures produced by the subverted signature algorithm
should (almost always) verify correctly under the target ver-
iﬁcation key. Note that both attacks mentioned above fall
into this category.

Clearly, the assumption that the veriﬁability condition
should hold for all messages is quite a strong one. Unfor-
tunately, as recently shown by Degabriele et al. [15] for the
case of symmetric encryption, it is not possible to relax the
veriﬁability condition to hold for all but a negligible frac-
tion of the messages and still prove security under chosen-
message attacks (where the adversary has full control on
the messages to be signed). In the full version of this pa-
per [3] we prove that one can relax the veriﬁability condition
and still obtain a positive result for unique signatures under
random-message attacks (where the adversary is only al-
lowed to see signatures of random messages). Interestingly,
this has useful applications, e.g., to construct subversion-
resilient identiﬁcation schemes (similar in spirit to leakage-
and tamper-resilient identiﬁcation [2, 12, 21, 22, 35]).

Next, we shift our focus to the more ambitious goal of
protecting signature schemes against arbitrary SAs, using
cryptographic RFs. The latter primitive was recently intro-
duced in [33] to model the security of arbitrary two-party
protocols run on machines possibly corrupted by a virus.
On a high level, a RF for a signature scheme is a trusted
piece of software taking as input a message/signature pair
(m, σ) and some public state, and outputting a “patched”
signature (m, σ(cid:48)); the initial state of the ﬁrewall is typically
a function of the veriﬁcation key vk . A good RF should
maintain functionality, meaning that whenever the input is
a valid message/signature pair the patched signature (almost
always) veriﬁes correctly under the target veriﬁcation key.
Moreover, we would like the ﬁrewall to preserve unforge-
ability; this means that patched signatures (corresponding
to signatures generated via the subverted signing algorithm)
should not help an adversary to forge on a fresh message.

We prove that re-randomizable signature schemes [26] ad-
mit a RF that preserves unforgeability against arbitrary
SAs. Re-randomizable signatures admit an eﬃcient algo-
rithm ReRand that takes as input a tuple (m, σ, vk ) and
outputs a signature σ(cid:48) that is distributed uniformly over
the set of all valid signatures on message m (under vk );
unique signatures, for instance, are re-randomizable. Upon
input a pair (m, σ) our ﬁrewall uses the public state to verify
(m, σ) is valid under vk , and, in case the test passes, it runs
ReRand on (m, σ) and outputs the result. Otherwise the ﬁre-
wall simply returns an invalid symbol ⊥ and self-destructs,
i.e., it stops processing any further query.4 The latter is a

2A signature scheme is unique if for a honestly generated
veriﬁcation key there is a single valid signature for each mes-
sage.
3One might ask whether a similar result holds for all de-
terministic schemes where signatures are not unique; in the
full version of this paper [3] we answer this question in the
negative.
4This can be implemented, for instance, by having the public
state include a single one-time writable bit used to signal a
self-destruction took place.

requirement that we prove to be unavoidable: No RF can
at the same time maintain functionality and preserve un-
forgeability of a signature scheme without the self-destruct
capability.

We remark that our results for the setting of RFs are in-
comparable to the ones in [33]. The main result of Mironov
and Stephens-Davidowitz is a compiler that takes as input
an arbitrary two-party protocol and outputs a functionally
equivalent (but diﬀerent) protocol that admits a RF pre-
serving both functionality and security. Instead, we model
directly security of RFs for signatures schemes in the game-
based setting; while our goal is more restricted (in that
we only design RFs for signatures), our approach results
in much more eﬃcient and practical solutions.

Multi-user setting. Our discussion so far only considered
a single user.
In the full version [3] we discuss how our
models and results can be extended to the important (and
practically relevant) multi-user scenario. In particular, sim-
ilarly to [6], we generalize our undetectability and security
notions to a setting with u > 1 users, where each user has
a diﬀerent signing/veriﬁcation key. As we argue, security in
the single-user setting already implies security in the multi-
user setting (by a standard hybrid argument). This does not
hold for undetectability, as there exists classes of SAs that
are undetectable by a single user but can be eﬃciently de-
tected by more than one user. However, as we show in [3],
the concrete attacks analysed in Section 4 can be modiﬁed
to remain undetectable even with multiple users.
1.2 Impact

Our study has strong implications in practice and might
inﬂuence the way digital signature schemes are selected or
adopted in standards and protocols. A subverted signature
scheme is arguably even more deceitful and dangerous in
practice than subverted encryption. Indeed, it is well-known
that authenticated encryption must involve digital certiﬁ-
cates that are signed by Certiﬁcation Authorities (CAs). If
a CA is using a subverted signature scheme, it is reason-
able to expect the signing key will eventually be exposed.
With knowledge of the signing key, it is possible to imper-
sonate any user and carry out elementary man-in-the-middle
attacks. This renders the use of any type of encryption ut-
terly pointless and underlines the important role played by
signatures in the context of secure communications.

Unfortunately, signature schemes currently employed to
sign digital certiﬁcates, or used in protocols such as OTR,
TLS/SSL, SSH, PGP, etc., are all susceptible to a subversion
attack and their use should possibly be discontinued. The
positive news however is that there already exist signature
schemes that are subversion-resilient and they are eﬃcient
and well-established. This is in contrast with encryption
where good schemes are not deployable in all contexts since
they require retention of state information (see [6]).
1.3 Related Work

Sabotage of cryptographic primitives before and during
their deployment has been the focus of extensive research
over the past years. We review the main results below.

Subliminal channels and beyond. After their introduc-
tion, the potential of subliminal channels has been explored
in several works (e.g., [10, 16]); this line of research led for

366instance to the concept of divertible protocols, that are in-
timately related to reverse ﬁrewalls.

The setting of backdoored implementations has also been
the focus of extensive research. This includes, in particular,
the realm of kleptography and SETUP attacks (see [45] for
a survey). In recent work, Dodis et al. [18] provide a formal
treatment of trapdoored pseudorandom generators (building
on previous work of Vazirani and Vazirani [41]); this setting
is of particular importance, given the potential sabotage of
the NIST Dual EC PRG. We refer the reader to [39] for a
complete taxonomy of these (and more) types of attacks.

Tampering attacks. A related line of research analyzes the
security of cryptosystems against tampering attacks. Most
of these works are restricted to the simpler setting of memory
tampering (sometimes known as related-key security), where
only the secret key of a targeted cryptoscheme is subject to
tampering. In this context we know of many positive results,
both for speciﬁc (e.g., [5, 13, 28]) and arbitrary primitives
(e.g., [14, 20, 23, 30]).

An alternative setting is that of randomness tampering,
where the random coins of a cryptographic algorithm are
subject to tampering. For instance Austrin et al. [4] consid-
ers so-called p-tampering attacks, that can eﬃciently tamper
with each bit of the random tape with probability p. In this
setting they show that some cryptographic tasks (including
commitment and zero-knowledge protocols) are impossible
to achieve, while other tasks (in particular signature and
identiﬁcation schemes) can be securely realized.

2. PRELIMINARIES
2.1 Notation
For a string x, we denote its length by |x|; if X is a set, |X|
represents the number of elements in X . When x is chosen
randomly in X , we write x ←$ X . When A is an algorithm,
we write y ← A(x) to denote a run of A on input x and
output y; if A is randomized, then y is a random variable
and A(x; r) denotes a run of A on input x and randomness r.
An algorithm A is probabilistic polynomial-time (PPT) if A is
randomized and for any input x, r ∈ {0, 1}∗ the computation
of A(x; r) terminates in at most poly(|x|) steps.
We denote with κ ∈ N the security parameter. A function
: N → R is negligible in the security parameter (or
negl
simply negligible) if it vanishes faster than the inverse of
any polynomial in κ, i.e. negl (κ) = κ−ω(1).
(cid:80)
The statistical distance between two random variables
A and B deﬁned over the same domain D is deﬁned as
x∈D |P [A = x] − P [B = x]|. We rely on
SD (A; B) = 1
the following lemma (which follows directly from the deﬁni-
tion of statistical distance):

2

Lemma 1. Let A and B be a pair of random variables,
and E be an event deﬁned over the probability space of A
and B. Then, SD (A; B) ≤ SD (A; B|¬E) + P [E].
2.2 Signature Schemes

A signature scheme is a triple of algorithms SS = (KGen,
Sign, Vrfy) speciﬁed as follows: (i) KGen takes as input the
security parameter κ and outputs a veriﬁcation/signing key
pair (vk , sk) ∈ VK×SK, where VK := VKκ and SK := SKκ
denote the sets of all veriﬁcation and secret keys produced by
KGen(1κ); (ii) Sign takes as input the signing key sk ∈ SK,

a message m ∈ M and random coins r ∈ R, and outputs a
signature σ ∈ Σ; (iii) Vrfy takes as input the veriﬁcation key
vk ∈ VK and a pair (m, σ), and outputs a bit that equals 1
iﬀ σ is a valid signature for message m under key vk .

Correctness of a signature scheme says that verifying hon-
estly generated signatures always works (with overwhelming
probability over the randomness of all involved algorithms).

Deﬁnition 1. Let SS = (KGen, Sign, Vrfy) be a signature

scheme. SS satisﬁes νc-correctness if for all m ∈ M

P(cid:104) Vrfy(vk , (m, Sign(sk , m))) = 1 :

(cid:105) ≥ 1 − νc,

(vk , sk ) ← KGen(1κ)

where the probability is taken over the randomness of KGen,
Sign, and Vrfy.

The standard notion of security for a signature scheme
demands that no PPT adversary given access to a signing
oracle, can forge a signature on a “fresh” message (not asked
to the oracle).

Deﬁnition 2. Let SS = (KGen, Sign, Vrfy) be a signature
scheme. We say that SS is (t, q, ε)-existentially unforgeable
under chosen-message attacks ((t, q, ε)-ufcma in short) if for
all PPT adversaries A running in time t it holds:

(cid:34) Vrfy(vk , (m∗, σ∗)) = 1 ∧ m∗ (cid:54)∈ Q :

(cid:35)

(vk , sk ) ← KGen(1κ);
(m∗, σ∗) ← ASign(sk ,·)(vk )

≤ ε,

P

where Q = {m1, . . . , mq} denotes the set of queries to the
signing oracle.

Unique signatures. For our positive results we rely on so
called unique signatures, that we deﬁne next.
Informally
a signature scheme is unique if for any message there is a
single signature that veriﬁes w.r.t. a honestly generated ver-
iﬁcation key.

Deﬁnition 3. Let SS be a signature scheme. SS satisﬁes

νu-uniqueness if ∀m ∈ M and ∀σ1, σ2 s.t. σ1 (cid:54)= σ2

(cid:35)

(cid:34)

P

Vrfy(vk , (σ1, m)) = Vrfy(vk , (σ2, m)) = 1 :
(vk , sk ) ← KGen(1κ)

≤ νu,

where the probability is taken over the randomness of the

veriﬁcation and key generation algorithms.

Full Domain Hash signatures with trapdoor permutations,
for instance RSA-FDH [7], are unique. Sometimes unique
signatures are also known as veriﬁable unpredictable func-
tions (VUFs).5 Known constructions of VUFs exist based
on strong RSA [32], and on several variants of the Diﬃe-
Hellman assumption in bilinear groups [1, 17, 19, 27, 31].

5Strictly speaking, VUFs satisfy a stronger requirement—
namely the uniqueness property holds even for maliciously
generated veriﬁcation keys; the weak variant above is suﬃ-
cient for the results of this paper.

3672.3 Pseudorandom Functions
Let F : {0, 1}κ × X → Y be an eﬃcient keyed function,
where X and Y denote the domain and the range of F .
Denote by F the set of all functions mapping X into Y.

Deﬁnition 4. A function F : {0, 1}κ×X → Y is a (t, q, ε)-
secure pseudorandom function (PRF), if for all adversaries
D running in time at most t we have

P

s ←$ {0,1}κ

DFs (·)(1κ) = 1

Df (·)(1κ) = 1

(cid:12)(cid:12)(cid:12)(cid:12)

(cid:104)

(cid:105) − P

f ←$ F

(cid:104)

(cid:105)(cid:12)(cid:12)(cid:12)(cid:12) ≤ ε,

• Choose an algorithm(cid:101)Aj ∈ A, for j ∈ [n], and give

it to the challenger.

• Forward a pair (j, mi,j) to the challenger, where
i ∈ [q] and j ∈ [n]. The answer to each query de-
pends on the value of the secret bit b. In partic-
ular, if b = 1, the output is σi,j ← Sign(sk , mi,j);

if b = 0, the output is(cid:101)σi,j ←(cid:101)Aj(sk , mi,j).

3. Finally, B outputs a value b(cid:48) ∈ {0, 1}; we say that B

wins iﬀ b(cid:48) = b.

where D asks at most q queries to its oracle.

SK, a message m ∈ M, random coins r ∈ R, and

3. SUBVERTING SIGNATURES
We proceed to deﬁne what it means for an adversary B
to subvert a signature scheme SS = (KGen, Sign, Vrfy). We
model subversion as the ability of the adversary to replace
the genuine signing algorithm with a diﬀerent algorithm
within a certain class A of Subversion Attacks (SAs). A

subversion of SS is an algorithm(cid:101)A ∈ A, speciﬁed as follows.
• Algorithm (cid:101)A(·,·;·) takes as input a signing key sk ∈
outputs a subverted signature (cid:101)σ ∈ Σ, where (cid:101)σ :=
(cid:101)A(sk , m; r). Notice that algorithm (cid:101)A is completely ar-
In particular, algorithm (cid:101)A can hard-wire arbitrary informa-
In general we also allow algorithm (cid:101)A to be

bitrary, with the only restriction that it maintains the
same input-output interfaces as the original signing al-
gorithm.

tion chosen by the adversary, which we denote by a string
α ∈ {0, 1}∗.
stateful, even in case the original signing algorithm is not,
and we denote the corresponding state by τ ∈ {0, 1}∗; the
state is only used internally by the subverted algorithm and
never outputted to the outside.

In Section 3.1 we deﬁne what it means for a signature
scheme to be secure against a certain class of SAs. In Sec-
tion 3.2 we deﬁne what it means for a class of SAs to be
undetectable by a user. Some of our deﬁnitions are similar
in spirit to the ones put forward in [6], except that our mod-
elling of subversion is more general (see below for a more
detailed comparison).
3.1

Impersonation

We consider two security deﬁnitions, corresponding to dif-
ferent adversarial goals. In the ﬁrst deﬁnition, it is required
that an adversary B having access to polinomially many sub-
version oracles chosen adaptively (possibly depending on the
user’s veriﬁcation key), cannot distinguish signatures pro-
duced via the standard signing algorithm from subverted
signatures.

Deﬁnition 5. Let SS = (KGen, Sign, Vrfy) be a signature
scheme, and A be some class of SAs for SS. We say that
SS is (t, n, q, ε)-indistinguishable w.r.t continuous A-SAs
if for all PPT adversaries B running in time t, we have

(cid:12)(cid:12) ≤ ε(κ) in the following game:

(cid:12)(cid:12)P [B wins] − 1

2

1. The challenger runs (vk , sk ) ← KGen(1κ), samples a

bit b ←$ {0, 1}, and gives vk to B.

2. The adversary B can ask the following two types of
queries; the queries can be speciﬁed adaptively and in
an arbitrary order:

We also consider an alternative (strictly weaker—see the
full version [3]) deﬁnition, where the goal of the adversary
is now to forge a signature on a “fresh” message (not asked
to any of the oracles).

Deﬁnition 6. Let SS = (KGen, Sign, Vrfy) be a signature
scheme, and A be some class of SAs for SS. We say that
SS is (t, n, q, ε)-hard to impersonate w.r.t. continuous A-
SAs if for all PPT adversaries B running in time t, we have
P [B wins] ≤ ε(κ) in the following game:

1. The challenger runs (vk , sk ) ← KGen(1κ), and gives vk

to B.

2. The adversary B is given oracle access to Sign(sk ,·).
Upon input the i-th query mi, this oracle returns σi ←
Sign(sk , mi); let Q = {m1, . . . , mq} be the set of all
queried messages.

3. For each j ∈ [n], the adversary B can adaptively choose

an algorithm (cid:101)Aj ∈ A. For each algorithm, B is given
oracle access to (cid:101)Aj(sk ,·). Upon input a message (cid:101)mi,j,
the oracle returns(cid:101)σi,j ←(cid:101)Aj(sk ,(cid:101)mi,j); let (cid:101)Qj = {(cid:101)m1,j,
. . . ,(cid:101)mq,j} be the set of all queried messages to the
oracle (cid:101)Aj.
iﬀ Vrfy(vk , (m∗, σ∗)) = 1 and m∗ (cid:54)∈ Q∪ (cid:101)Q, where (cid:101)Q :=
(cid:83)n
j=1 (cid:101)Qj.

4. Finally, B outputs a pair (m∗, σ∗); we say that B wins

Some remarks on the above deﬁnitions are in order.
• First, note that it is impossible to prove that a signa-
ture scheme SS satisﬁes Deﬁnition 5 (and consequently
Deﬁnition 6) for an arbitrary class A, without making
further assumptions.6 To see this, consider the sim-
ple algorithm that ignores all inputs and outputs the
secret key.7

• We observe that continuous A-SAs security, implies
security against continuous tampering attacks with the
secret key. This can be seen by considering a class
functions such that each f ∈ F has a type f : SK →
SK, and for all f ∈ F, m ∈ M and r ∈ R we have

of algorithms Akey = {(cid:101)Af}f∈F , where F is a class of
that (cid:101)Af (·, m; r) := Sign(f (·), m; r).8

6Looking ahead, one of our positive results achieves security
w.r.t. arbitrary SAs assuming the existence of a crypto-
graphic reverse ﬁrewall. See Section 6.
7In case the secret key is too long, one can make the algo-
rithm stateful so that it outputs a diﬀerent chunk of the key
at each invocation.
8It is worth noting that already for n = 1 Deﬁnition 6 im-
plies non-adaptive key tampering, as the subverted algo-
rithm can hard-wire (the description of) polynomially many
pre-set tampering functions.

368• It is useful to compare Deﬁnition 5 to the deﬁnition of
security against algorithm-substitution attacks given
in [6] (for the case of symmetric encryption). In the
language of Bellare et al. [6], a subversion of a sig-

run by the challenger in order to obtain a trapdoor
α ∈ {0, 1}∗ and some initial state τ ∈ {0, 1}∗ which

nature scheme would be a triple of algorithms (cid:102)SS =
((cid:94)KGen,(cid:103)Sign,(cid:103)Vrfy), where in the security game (cid:94)KGen is
are both hard-wired in the algorithm (cid:103)Sign := (cid:103)Signα,τ
considering the class of SAs ABRP14 := {(cid:101)Aα,τ : (α, τ ) ←

(and given to B).9
The above setting can be cast in our framework by

(cid:94)KGen(1κ)}, and by setting n = 1 in Deﬁnition 5. Our
deﬁnition is more general, as it accounts for arbitrary
classes of SAs and moreover allows B to subvert a user’s
algorithm continuously and in a fully-adaptive fashion
(possibly depending on the target veriﬁcation key).

3.2 Public versus Secret Undetectability

We say that A meets the veriﬁability condition relative

to SS if for all (cid:101)A ∈ A and for all m ∈ M the signatures
produced using the subverted signing algorithm (cid:101)A (almost)

always verify under the corresponding veriﬁcation key vk .
Such a veriﬁability condition is a very basic form of (public)
undetectability.

Deﬁnition 7. Let A be some class of SAs for a signature
scheme SS. We say that A satisﬁes νv-veriﬁability if for all

(cid:101)A ∈ A and for all m ∈ M

P(cid:2)Vrfy(vk , (m,(cid:101)A(sk , m))) = 1 :

(vk , sk ) ← KGen(1κ)(cid:3) ≥ 1 − νv,

where the probability is taken over the randomness of all

involved algorithms.

By undetectability, we mean the inability of ordinary users
to tell whether signatures are computed using the subverted
or the genuine signing algorithm. We will distinguish be-
tween the case where a subversion is publicly or secretly un-
detectable. Roughly speaking, public undetectability means
that no user can detect subversions using the veriﬁcation key
vk only (i.e., without knowing the signing key sk ); secret un-
detectability means that no user, even with knowledge of the
signing key sk , can detect subversions.

A formal deﬁnition follows. While reading it, bear in mind
that the challenger plays the role of the “bad guy” trying to
sabotage the signature scheme without being detected.

such that(cid:12)(cid:12)P [U wins] − 1

Deﬁnition 8. Let SS = (KGen, Sign, Vrfy) be a signature
scheme, and A be some class of SAs for SS. We say that
A is secretly (t, q, ε)-undetectable w.r.t. SS if for all PPT
users U running in time t, there exists an eﬃcient challenger

(cid:12)(cid:12) ≤ ε(κ) in the following game:
algorithm (cid:101)A ∈ A (possibly depending on vk ), samples

1. The challenger runs (vk , sk ) ← KGen(1κ), chooses an

2

b ←$ {0, 1} and gives (vk , sk ) to U.

2. The user U can ask queries mi ∈ M, for all i ∈ [q].
The answer to each query depends on the secret bit

9The algorithm (cid:103)Vrfy can be considered as part of the adver-

sary itself.

b. In particular, if b = 1, the challenger returns σi ←

Sign(sk , mi); if b = 0, the challenger returns (cid:101)σi ← (cid:101)A(

sk , mi).

3. Finally, U outputs a value b(cid:48) ∈ {0, 1}; we say that U

wins iﬀ b(cid:48) = b.

We say that A is publicly undetectable w.r.t. SS if in step
1. of the above game, U is only given the veriﬁcation key.

Our deﬁnition of undetectability is similar to the corre-
sponding deﬁnition considered by Bellare et al. [6] for the
case of symmetric encryption. One key diﬀerence is that,
in the deﬁnition above, the challenger is allowed to choose
the subversion algorithm possibly depending on the veriﬁ-
cation key of the user. While one could in principle deﬁne
even stronger forms of undetectability, e.g. by requiring that
continuous and fully-adaptive SAs remain undetectable, we
do not pursue this direction here. The reason for this is
that the attacks we analyze in Section 4 are non-adaptive
and only require to use a single subversion.

Secret vs. public undetectability. Whereas secret unde-
tectability implies public undetectability, the converse is not
true. A separation is provided by looking at derandomized
schemes that rely on a PRF with key s to compute the ran-
domness r used by the signing algorithm Sign(sk , m; r). It is
not hard to show that the class of SAs considered by Bellare
et al. [6], when adapted and applied to derandomized signa-
ture schemes (see Section 4.1), is publicly undetectable, but
secretly detectable.

Amsg = {(cid:101)A ¯m} ¯m∈M that behaves identically to the original

Public undetectability vs. veriﬁability. One might be-
lieve that veriﬁability is a special case of public undetectabil-
ity. However, this is not true and in fact Deﬁnition 7 and 8
are incomparable. To see this, consider the class of SAs
signing algorithm, except that upon input ¯m ∈ M it out-
puts an invalid signature. Clearly, Amsg satisﬁes public un-
detectability as a user has only a negligible chance of hitting
the value ¯m; yet Amsg does not meet the veriﬁability condi-
tion as the latter is a property that holds for all messages.
On the other hand, consider the class of SAs Adet that
is identical to the original signing algorithm, except that it
behaves deterministically on repeated inputs. Clearly, Adet
meets the veriﬁability condition relative to any (even ran-
domized) signature scheme SS; yet Adet does not satisfy
public undetectability, as a user can simply query the same
message twice in order to guess the value of the hidden bit
b with overwhelming probability.

4. MOUNTING SUBVERSION ATTACKS

In Section 4.1 we show that the biased-randomness attack
of [6] (adapted to the case of signatures), satisﬁes secret un-
detectability as per Deﬁnition 8 while allowing to recover
the user’s signing key with overwhelming probability. This
attack allows to break all signature schemes using a suf-
ﬁcient amount of randomness; in Section 4.2 we present a
new attack allowing to surreptitiously subvert even signature
schemes using only little randomness (say 1 bit), provided
that the targeted scheme satisﬁes an additional property.

369SA class AF

bias

Let SS = (KGen, Sign, Vrfy) be a randomized signature scheme with randomness space R, and F : {0, 1}κ × {0, 1}∗ → {0, 1}
be a pseudorandom function. The class AF
class behaves as follows:

bias consists of a set of algorithms {(cid:101)As,τ}s∈{0,1}κ,τ =1, where each algorithm in the

• For |sk| = (cid:96), let i := τ mod (cid:96).

(cid:101)As,τ (sk , m):
• Deﬁne the function g(·) := Sign(sk , m;·)||τ and sample a random element(cid:101)r from the distribution
• Return the signature σ := Sign(sk , m;(cid:101)r), and update the state τ ← τ + 1.

(cid:101)RF (s,·),g(·)(sk [i],R) := {r ∈ R : F (s, g(r)) = sk [i]}.

(1)

Extracting the signing key. Given as input a vector of signatures (cid:126)σ = (σ1, ..., σ(cid:96)), for each signature σi ∈ (cid:126)σ try to extract
the i-th bit of the signing key by deﬁning sk(cid:48)[i] := F (s, σi||i). Return the signing key sk(cid:48) := (sk(cid:48)[1], . . . , sk(cid:48)[(cid:96)]).

Figure 1: The biased-randomness attack

4.1 Attacking Randomized Schemes

The following attack is based on the biased-randomness
attack from [6]. Roughly, what it does is to embed a trap-
door —a key for a pseudorandom function—in the subverted
signing algorithm and to “bias” the randomness in a way that
it becomes possible to any party that knows the trapdoor
to leak one bit of the signing key for each signed messaged
under that signing key. Hence, if the adversary can obtain
at least |sk| signed messages then it can later extract the
entire signing key in full.

For the analysis, which appears in the full version [3], we
will need to assume the signing function is coin-injective, i.e.
it is injective w.r.t. its random coins.

Theorem 1. Let F : {0, 1}κ × {0, 1}∗ → {0, 1} be a
(tprf , qprf , εprf )-secure PRF. For a randomized, coin-injective
signature scheme SS with randomness space of size ρ = |R|,
consider the class of SAs AF
(i) AF

bias is secretly (t, q, ε)-undetectable for t ≈ tprf , q ≈
qprf and ε ≤ q · 2−(ρ+1) + εprf .

bias described in Fig. 1. Then,

(ii) Each (cid:101)A ∈ AF

bias recovers the signing key of the user
with probability at least (1 − (0.5 + εprf )ρ)(cid:96), where (cid:96) is
the size of the key.

Notice that for the attack to be undetectable with high
probability, the underlying signature scheme needs to rely
on a minimal amount of randomness, say ρ ≥ 27.

Making the attack stateless. Note that the attack of Fig. 1
requires the subverted signature algorithm to be stateful.
See the full version [3] for a stateless version of the same
attack.
4.2 Attacking Schemes with Small Random-

ness

The attack on Section 4.1 allows to break all suﬃciently
randomized schemes. This leaves the interesting possibility
to show a positive result for schemes using less random-
ness, e.g., the Katz-Wang scheme [29] that uses a single bit
of randomness. In this section we present a simple attack
(cf. Fig. 2) ruling out the above possibility for all signature

schemes that are coin-extractable, a notion which we deﬁne
next.

Deﬁnition 9. Let SS = (KGen, Sign, Vrfy) be a signature
scheme. We say that SS is νext-coin-extractable if there
exists a PPT algorithm CExt such that for all m ∈ M

σ = Sign(sk , m; r) :

(vk , sk ) ← KGen(1κ);
σ = Sign(sk , m);
r ← CExt(vk , m, σ)

≥ 1 − νext.

(cid:34)

P

(cid:35)

We point that many existing signature schemes are coin-

extractable:

• All public-coin signature schemes [38], where the ran-
dom coins used to generate a signature are included
as part of the signature. For instance, the schemes
in [9, 24, 34], and the Unstructured Rabin-Williams
scheme [8] are all public-coin.

• The Katz-Wang scheme [29], where the signature on
a message m is computed as σ = f−1(H(m||r)) such
that f is a trapdoor permutation, H is a hash function,
and r is random bit. Given a pair (m, σ) the extractor
simply sets r = 1 iﬀ f (σ) = H(m||1).
• The PSS signature standard [7, 11].

Theorem 2. For a νext-coin-extractable, randomized sig-
nature scheme SS with randomness space R of size ρ = 2d,
consider the class of SAs Acext described in Fig. 2. Then,
(i) Acext is secretly (t, q, 0)-undetectable for t, q ∈ N.

(ii) Each(cid:101)A ∈ Acext recovers the signing key of the user with

probability at least (1 − νext)(cid:96)/d, where (cid:96) is the size of
the key.

Proof. (i) Let G be the game described in Deﬁnition 8,

where the challenger picks (cid:101)A ←$ Acext uniformly at random

(and independently of the user’s veriﬁcation key). Consider
the game G0, an identical copy of game G when b = 0, and
consider the game G1, an identical copy of game G when
b = 1. For the ﬁrst part of the proof the objective is to show
that G0 ≈ G1.

370SA class Acext

Let SS = (KGen, Sign, Vrfy) be a coin-extractable, randomized signature scheme with randomness space R of size ρ = 2d. For
simplicity assume that d|(cid:96), where (cid:96) is the size of the signing key (a generalization is straightforward). The class Acext consists

of a set of algorithms {(cid:101)As,τ}s∈{0,1}(cid:96),τ =0, where each algorithm in the class behaves as follows:

(cid:101)As,τ (sk , m):

• If τ ≥ (cid:96) output a honestly generated signature σ := Sign(sk , m; r).
• Else,

– for each value j ∈ [d] compute the biased random bit(cid:101)r[j] := s[τ + j] ⊕ sk [τ + j];
– return the signature σ := Sign(sk , m;(cid:101)r), and update the state τ ← τ + d.

Extracting the signing key. Given as input a vector of signatures (cid:126)σ = (σ1, . . . , σ(cid:96)/d), parse the trapdoor s as (cid:96)/d chunks of
d bits s = {s1, . . . , s(cid:96)/d}. For each signature σi ∈ (cid:126)σ try to extract the d-bit chunk sk(cid:48)

i of the signing key as follows.

• Extract the randomness from the i-th signature(cid:101)r ← CExt(vk , mi, σi).
i[j] :=(cid:101)r[j] ⊕ si[j].

• For each value j ∈ [d] compute the secret key bit sk(cid:48)

Return the signing key sk(cid:48) := (sk(cid:48)

1, . . . , sk(cid:48)

(cid:96)/d).
Figure 2: The small-randomness attack

Claim 1. |P [U wins in G0] − P [U wins in G1]| = 0.
Proof. Abusing notation, let us write G0 and G1 for
the distribution of the random variables corresponding to
U’s view in games G0 and G1 respectively. For an index
i ∈ [0, q] consider the hybrid game Hi that answers the ﬁrst
i queries as in game G0 while all the subsequent queries are
answered as in G1. We note that H0 ≡ G1 and Hq ≡ G0.
We claim that for all i ∈ [q], we have Hi−1 ≡ Hi. To see

this, ﬁx some i ∈ [q] and denote with R (resp. (cid:101)R) the random
variable deﬁned by sampling an element from R (resp. (cid:101)R)
uniformly at random. It is easy to see that R and (cid:101)R are

identically distributed, as the biased distribution consists of
a one-time pad encryption of (part of) the signing key with
a uniform key. The claim follows.

(cid:101)r of each σi ∈ {σ1, . . . , σ(cid:96)/d} and computes the chunk ski of

(ii) For the second part of the proof we note that the
attack of Fig. 2 successfully recovers the biased randomness
the signing key with probability at least 1− νext. This gives
a total probability of recovering the entire signing key of at
least (1 − νext)(cid:96)/d.

Making the attack stateless. Note that the attack of Fig. 2
requires the subverted signature algorithm to be stateful.
See the full version [3] for a stateless version of the same
attack.
5. SECURITY OF UNIQUE SIGNATURES
The theorem below shows that unique signature schemes
(cf. Deﬁnition 3) are secure against the class of all SAs that
meet the veriﬁability condition (cf. Deﬁnition 7).

Theorem 3. Let SS = (KGen, Sign, Vrfy) be a signature
scheme with νc-correctness and νu-uniqueness, and denote
by Aνv
ver the class of algorithms that satisfy νv-veriﬁability rel-
ative to SS. Then SS is (t, n, q, ε)-indistinguishable against
continuous Aνv
ver-SAs, for all n, q ∈ N and for ε ≤ qn · (νc +
νv + νu).

Proof. Let G be the game described in Deﬁnition 5.

Consider the game G0, an identical copy of game G when
b = 0, and consider the game G1, an identical copy of game
G when b = 1. The objective here is to show that G0 ≈ G1.
For an index k ∈ [0, n], consider the hybrid game Hk that
answers each query (j, mi,j) such that j ≤ k as in game G0
(i.e., by running Sign(sk , mi,j)), while all queries (j, mi,j)
such that j > k are answered as in G1 (i.e., by running

(cid:101)Aj(sk , mi,j)). We note that H0 ≡ G1 and Hn ≡ G0. Abus-

ing notation, let us write Gk for the distribution of the ran-
dom variable corresponding to B’s view in games Gk.
Fix a particular k ∈ [0, n], and for an index l ∈ [0, q]
consider the hybrid game Hk,l that is identical to Hk except
that queries (k, mi,k) with i ≤ l are treated as in game
G0, while queries (k, mi,k) with i > l are treated as in G1.
Observe that Hk,0 ≡ Hk−1, and Hk,q ≡ Hk.

Claim 2. Fix some k ∈ [0, n]. For each l ∈ [0, q], we

have SD (Hk,l−1, Hk,l) ≤ νc + νv + νu.

Proof. Notice that the only diﬀerence between Hk,l−1
and Hk,l is how the two games answer the query (k, ml,k):
Game Hk,l−1 returns σl,k ← Sign(sk , ml,k), whereas game

Hk,l returns(cid:101)σl,k ←(cid:101)Ak(sk , ml,k). Now let El,k be the event
that σl,k (cid:54)=(cid:101)σl,k. We can write

SD (Hk,l−1, Hk,l) ≤ SD (Hk,l−1; Hk,l|¬El,k) + P [El,k] (2)
(3)

≤ νc + νu + νv.

Eq. (2) follows by Lemma 1 and Eq. (3) follows by the fact
that Hk,l−1 and Hk,l are identically distributed conditioned
on El,k not happening, and moreover P [El,k] ≤ νc + νu + νv.
The latter can also be seen as follows. By the correctness
condition of SS we have that σl,k is valid for ml,k under
vk except with probability at most νc. By the assumption

that (cid:101)Ak ∈ Aνv
ver we have that (cid:101)σl,k is also valid for ml,k un-
uniqueness property of SS we have that σl,k and (cid:101)σl,k must

der vk except with probability at most νv. Finally, by the

be equal except with probability at most νu. It follows that
P [El,k] ≤ νc + νu + νv, as desired.

371The statement now follows by the above claim and by the
triangle inequality, as

SD (G0, G1) ≤ n(cid:88)
≤ n(cid:88)

k=1

q(cid:88)

SD (Hk−1, Hk)

SD (Hk,l−1, Hk,l)

k=1

l=1

≤ qn · (νc + νu + νv).

6. FIREWALLS FOR SIGNATURES

In Section 5 we have shown that unique signatures are
secure against a restricted class of SAs, namely all SAs that
meet the so-called veriﬁability condition. As discussed in
Section 3, by removing the latter requirement (i.e., allowing
for arbitrary classes of SAs in Deﬁnition 5 and 6) would
require that a signature scheme SS remains unforgeable even
against an adversary allowed arbitrary tampering with the
computation performed by the signing algorithm. This is
impossible without making further assumptions.

In this section we explore to what extent one can model
signature schemes secure against arbitrary tampering with
the computation, by making the extra assumption of an
un-tamperable cryptographic reverse ﬁrewall (RF) [33].
Roughly, a RF for a signature scheme is a (possibly state-
ful) algorithm that takes as input a message/signature pair
and outputs an updated signature; importantly the ﬁrewall
has to do so using only public information (in particular,
without knowing the signing key).

Deﬁnition 10. Let SS be a signature scheme. A RF for
SS is a pair of algorithms FW = (Setup, Patch) speciﬁed
as follows: (i) Setup takes as input the security parameter
and a veriﬁcation key vk ∈ VK, and outputs some initial
(public) state δ ∈ {0, 1}∗; (ii) Patch takes as input the cur-
rent (public) state δ, and a message-signature pair (m, σ)
and outputs a possibly modiﬁed signature or a special sym-
bol ⊥ and an updated (public) state δ(cid:48). We write this as
σ(cid:48) ← Patchδ(m, σ) (and omit to denote the updated state δ(cid:48)
as an explicit output).
6.1 Properties
Below, we discuss the correctness and security require-
ments of cryptographic RF FW for a signature scheme SS.

Maintaining functionality. The ﬁrst basic property of a
RF is that it should preserve the functionality of the under-
lying signature scheme, i.e. if a signature σ on a message m
is computed using signing key sk , and the ﬁrewall is initial-
ized with the corresponding veriﬁcation key vk , the patched
signatures σ(cid:48) should (almost always) be a valid signatures
for m under vk . More precisely, we say that FW is function-
ality maintaining for SS, if for any polynomial p(κ) and any
vector of inputs (m1, . . . , mp) ∈ M, there exists a negligible
function ν : N → [0, 1] such that



P

∃i ∈ [p] s.t. Vrfy(vk , (mi, σ(cid:48)

i)) = 0 :
(vk , sk ) ← KGen(1κ), δ ← Setup(vk , 1κ);
σ1 ← Sign(sk , m1), . . . , σp ← Sign(sk , mp);
p ← Patchδ(mp, σp)

1 ← Patchδ(m1, σ1), . . . , σ(cid:48)
σ(cid:48)

 ≤ ν(κ),

where the probability is taken over the coin tosses of all in-
volved algorithms. Recall that each invocation of algorithm
Patch updates the (public) state δ of the RF.

Preserving Unforgeability. The second property of a RF
is a security requirement. Note that a ﬁrewall can never “cre-
ate” security (as it does not know the signing key). Below
we deﬁne what it means for a RF to preserve unforgeability
of a signature scheme against arbitrary tampering attacks.
Deﬁnition 11. Let SS = (KGen, Sign, Vrfy) be a signature
scheme with RF FW = (Setup, Patch). We say that FW
(t, n, q, ε)-preserves unforgeability for SS against continuous
SAs if for all adversaries B running in time t we have that
P [B wins] ≤ ε in the following game:

1. The challenger runs (vk , sk ) ← KGen(1κ), computes

δ ← Setup(vk , 1κ), and gives (vk , δ) to B.

2. The adversary B is given oracle access to Sign(sk ,·).
Upon input the i-th query mi, this oracle returns σi ←
Sign(sk , mi). Let Q = {m1, . . . , mq} be the set of all
signature queries.

3. The adversary B can adaptively choose an arbitrary

algorithm(cid:101)Aj, and correspondingly obtain oracle access
to Patchδ(·,(cid:101)Aj(sk ,·)):
• Upon input the i-th query (cid:101)mi,j, for i ∈ [q] and
j ∈ [n], the oracle returns (cid:101)σi,j ← Patchδ((cid:101)mi,j,
(cid:101)Aj(sk ,(cid:101)mi,j)) and updates the public state δ;
• Whenever(cid:101)σi,j = ⊥ the oracle enters a special self-
Let (cid:101)Qj = {(cid:101)m1,j, . . . ,(cid:101)mq,j} be the set of all queries for
each (cid:101)Aj.
iﬀ Vrfy(vk , (m∗, σ∗)) = 1 and m∗ (cid:54)∈ Q∪ (cid:101)Q, where (cid:101)Q :=
(cid:83)n
j=1 (cid:101)Qj.
Whenever A speciﬁes all of its queries {(cid:101)Aj,(cid:101)mi,j}j∈[n],i∈[q]

destructs mode, in which the answer to all future
queries is by default set to ⊥.

4. Finally, B outputs a pair (m∗, σ∗); we say that B wins

at the same time we say that FW non-adaptively preserves
unforgeability.

We observe that Deﬁnition 11 is very similar to Deﬁni-
tion 6, except for a few crucial diﬀerences. First, note that
the above deﬁnition considers arbitrary classes of SAs in-
stead of SAs within a given class A; this is possible because
the output of each invocation of the subverted signing algo-
rithm is patched using the ﬁrewall (which is assumed to be
un-tamperable).

Second, observe that the above deﬁnition relies on the
so-called self-destruct capability: Whenever the ﬁrewall re-
turns ⊥, all further queries to any of the oracles results in
⊥; as we show in Section 6.2 this is necessary as without
such a capability there exists simple generic attacks that
allow for complete security breaches. We stress, however,
that the assumption of the self-destruct capability does not
make the problem of designing an unforgeability preserv-
ing reverse ﬁrewall trivial. In fact, the attacks of Section 4
allow to break all randomized scheme without ever provok-
ing a self-destruct. On the positive side, in Section 6.3, we
show how to design an unforgeability preserving RF for any
re-randomizable signature scheme.

372Exﬁltration resistance. More in general, one might require
a stronger security property from a RF. Namely, we could
ask that patched signatures are indistinguishable from real
signatures to the eyes of an attacker. This property, which is
called exﬁltration resistance in [33], would be similar in spirit
to our deﬁnition of indistinguishability w.r.t.
continuous
SAs (see Deﬁnition 5).

It is not hard to see that exﬁlatration resistance against
arbitrary SAs is impossible to achieve in the case of signature
schemes; this is because the attacker could simply set the
subverted signing algorithm to always output the all-zero
string, in which case the RF has no way to patch its input
to a valid signature.10
6.2 Necessity of Self-Destruct

We show that no RF can preserve both functionality and
unforgeability, without assuming the self-destruct capabil-
ity. This is achieved via a generic (non-adaptive) attack
that allows to extract the secret key in case the RF does not
self-destruct. The attack itself is a generalization of a simi-
lar attack by Gennaro et al. [25] in the context of memory
tampering.

Theorem 4. Let SS be a ufcma signature scheme. No
RF FW can be functionality maintaining and non-adaptively
(poly(κ), 1, poly(κ), negl (κ))-preserve unforgeability for SS,
without assuming the self-destruct capability.

Proof sketch. Consider the following adversary B play-
ing the game of Deﬁnition 11 (omitting the self-destruct ca-
pability).

• Upon input the veriﬁcation key vk , and the initial state

δ, initialize τ := 1.

• Forward (cid:101)Aτ to the challenger, where algorithm (cid:101)Aτ is
deﬁned as follows: Upon input a message (cid:101)mi, set j =
– If sk [j] = 1, output(cid:101)σi ← Sign(sk ,(cid:101)mi).

τ mod (cid:96) (where (cid:96) := |sk|) and

– Else, output 0|σ|.

Update τ ← τ + 1.

• Let ( ¯m,(cid:101)σ(cid:48)
B, where (cid:101)σ(cid:48)
Vrfy(vk , ( ¯m,(cid:101)σ(cid:48)

1), . . . , ( ¯m,(cid:101)σ(cid:48)
i ← Patchδ( ¯m,(cid:101)Aτ (sk , ¯m)). Deﬁne sk(cid:48)[i] =

(cid:96)) be the set of tampered signa-
ture queries (and answers to these queries) asked by
i)) and return sk(cid:48) := (sk(cid:48)[1], . . . , sk(cid:48)[(cid:96)]).
Notice that B speciﬁes its queries non-adaptively, and
moreover it only uses one subversion which is queried upon a
ﬁxed message ¯m ∈ M. We will show that the extracted key
sk(cid:48) is equal to the original secret key sk with overwhelm-
ing probability, which clearly implies the statement. The
proof is by induction; assume that the statement is true up
to some index i ≥ 1. We claim that sk(cid:48)[i + 1] = sk [i + 1]
with all but negligible probability. To see this, deﬁne the
i+1)) = 1 or
i+1)) = 0. By the assump-
tion that the RF does not self-destruct and is functionality
maintaining, we get that the latter sub-case happens only

event Ei+1 that sk [i + 1] = 0 and Vrfy(vk , ( ¯m,(cid:101)σ(cid:48)
sk [i + 1] = 1 and Vrfy(vk , ( ¯m,(cid:101)σ(cid:48)

10We note, however, that our techniques from Section 5 can
be extended to design a RF that is weakly exﬁltration re-
sistant, namely it is exﬁltration resistant against restricted
SAs that satisfy the veriﬁability condition.

Alice

m ∈ M(cid:101)σ ←(cid:101)A(sk , m)

m,(cid:101)σ−−−−→

RAlice’s Firewall R

Read δ = (vk , β)

If β = 1 set(cid:101)σ(cid:48) = ⊥
Else if Vrfy(vk , (m,(cid:101)σ)) = 1
(cid:101)σ(cid:48) ← ReRand(vk , m,(cid:101)σ)
Else set(cid:101)σ(cid:48) = ⊥ and β = 1
Forward (m,(cid:101)σ(cid:48))

Figure 3: A cryptographic reverse ﬁrewall preserving un-
forgeability of any re-randomizable signature scheme against
arbitrary SAs.

with negligible probability. On the other hand, if the for-
mer sub-case happens we get that the RF forged a signature
on ¯m, which contradicts ufcma security of SS. By a union
bound, we get that P [Ei+1] is negligible as desired.
6.3 Patching Re-Randomizable Signatures

We design a RF preserving unforgeability of so-called re-
randomizable signature schemes (that include unique signa-
tures as a special case).

Deﬁnition 12. We say that SS = (KGen, Sign, Vrfy) is
eﬃciently νr -re-randomizable, if there exists a PPT algo-
rithm ReRand such that for all messages m ∈ M and for
all (vk , sk ) ← KGen(1κ) and σ ← Sign(sk , m), we have that
SD(ReRand(vk , m, σ), Sign(sk , m)) ≤ νr .

Note that unique signatures are eﬃciently re-randomizable,
for ReRand(vk , m, σ) = σ and νr = 0; Waters’ signature
scheme [42], and its variant by Hofheinz et al. [26], are also
eﬃciently re-randomizable.

Our ﬁrewall, which is formally described in Fig. 3, ﬁrst
checks if σ is a valid signature on message m under key vk
(provided that a self-destruct was not provoked yet). If not,
it self-destructs and returns ⊥; otherwise it re-randomizes σ
and outputs the result. The self-destruct capability is im-
plemented using a one-time writable bit β (which is included
in the public state).

Theorem 5. Let SS be a (t, (q + 1)n, ε)-ufcma signature
scheme that is eﬃciently νr -re-randomizable and that satis-
ﬁes νc-correctness. Then, the RF of Fig. 3 maintains func-
tionality and (t(cid:48), q, ε(cid:48))-preserves unforgeability for SS, where
t(cid:48) ≈ t and ε(cid:48) ≤ qn · (νc + νr + ε).

Proof. The fact that the ﬁrewall maintains functionality

follows directly by νc-correctness of SS.
We now show the ﬁrewall preserves unforgeability. Let G
be the game of Deﬁnition 11; we write (i∗, j∗) ∈ [q] × [n]
for the pair of indexes in which the ﬁrewall self-destructs
(if any). Consider the modiﬁed game H that is identical to
G except that tampered signature queries are answered as
described below:

• For all j < j∗, upon input (j,(cid:101)mi,j) return σi,j ←
Sign(sk ,(cid:101)mi,j) for all i ∈ [q].
• For j = j∗, upon input (j,(cid:101)mi,j) if i < i∗ return σi,j ←
Sign(sk ,(cid:101)mi,j); else return ⊥.

373• For all j > j∗, upon input message (cid:101)mi,j return ⊥ for

all i ∈ [q].

Claim 3. |P [B wins in G]− P [B wins in H]| ≤ qn· (νc +

νr ).

Proof. For an index k ∈ [0, n], consider the hybrid game

Hk that answers each query (j,(cid:101)mi,j) such that j ≤ k as
in game G, while all queries (j,(cid:101)mi,j) such that j > k are

answered as in H. We note that H0 ≡ H and Hn ≡ G.
Abusing notation, let us write Hk for the distribution of the
random variable corresponding to B’s view in game Hk.
We will show that SD (Hk−1, Hk) ≤ q · (νc + νr ) for all k.
Fix a particular k ∈ [0, n], and for an index l ∈ [0, q] consider
the hybrid game Hk,l that is identical to Hk except that it

answers queries (k,(cid:101)mi,k) with i ≤ l as in game G, while all
queries (k,(cid:101)mi,k) with i > l are treated as in H. Observe

that Hk,0 ≡ Hk−1, and Hk,q ≡ Hk.
We argue that for each l ∈ [q], one has that SD(Hk,l−1,
Hk,l) ≤ νc + νr . Observe that, since for k > j∗ both games
always return ⊥, we can assume without loss of generality
that k ≤ j∗. Note that the only diﬀerence between Hk,l−1

and Hk,l is how the two games answer the query (k,(cid:101)ml,k):
Hk,l−1 returns σl,k ← Sign(sk ,(cid:101)ml,k) whereas Hk,l returns
l,k ← Patchδ((cid:101)ml,k,(cid:101)σl,k) where (cid:101)σl,k ← (cid:101)Ak(sk ,(cid:101)ml,k). Let
(cid:101)σ(cid:48)
El,k be the event that Vrfy(vk , ((cid:101)ml,k, σl,k)) = 0. We have

SD (Hk,l−1; Hk,l) ≤ SD (Hk,l−1; Hk,l|¬El,k) + P [El,k] (4)
(5)

≤ νr + νc.

Eq. (4) follows by Lemma 1 and Eq. (5) by the fact that
Hk,l−1 and Hk,l are statistically close (up to distance νr )
conditioned on El,k not happening, and moreover P [El,k] ≤
νc. The former is because signatures are re-randomizable,
and thus (as long as the ﬁrewall did not self-destruct) the
output of ReRand is statistically close (up to distance νr ) to
the output of the original signing algorithm; the latter fol-
lows by νc-correctness of the signature scheme. The state-
ment now follows by the above argument and by the triangle
inequality, as

SD (G, H) ≤ n(cid:88)
≤ n(cid:88)

k=1

q(cid:88)

SD (Hk−1, Hk)

SD (Hk,l−1, Hk,l)

k=1

l=1

≤ qn · (νc + νr ).

Claim 4. P [B wins in H] ≤ qn · ε.

Proof. Towards a contradiction, assume B wins in game
H with probability larger than qn · ε. Wlog. we assume
that B always outputs its forgery after provoking a self-
destruct.11 We build an adversary B(cid:48) (using B) that breaks
ufcma of SS. Adversary B(cid:48) is described below.
Adversary B(cid:48):

• Receive the veriﬁcation key vk from the challenger,
sample a random pair (j∗, i∗) ←$ [n] × [q], and return
vk to B.

11If not we can always modify B in such a way that it asks
one additional query provoking a self-destruct; this clearly
does not decrease B’s advantage.

follows:

• Upon input the i-th signature query mi, forward this
value to the signing oracle receiving back a signature
σi ← Sign(sk , mi). Return σi to B.

• Upon input a query of the form (j,(cid:101)mi,j) answer as
– In case j < j∗, forward (cid:101)mi,j to the signing oracle,
obtaining (cid:101)σi,j ← Sign(sk ,(cid:101)mi), and return (cid:101)σi,j to
– In case j = j∗, if i < i∗ forward (cid:101)mi,j to the signing
oracle, obtaining (cid:101)σi,j ← Sign(sk ,(cid:101)mi), and return
(cid:101)σi,j to B. Else, return ⊥.

B.

– In case j > j∗ answer with ⊥.

• Whenever B outputs (m∗, σ∗), output (m∗, σ∗).
For the analysis, note that B(cid:48) runs in time similar to that
of B and asks a total of at most q +qn signing queries. More-
over, deﬁne the event E that B(cid:48) guesses correctly the query
(j∗, i∗) where B provokes a self-destruct. Clearly, in case E
happens we have that B(cid:48) perfectly simulates the distribu-
tion of game H. Hence P [B(cid:48) wins] ≥ (qn · ε)/(qn) = ε, a
contradiction.

The proof follows by combining the above two claims.

Acknowledgements
This work was supported by the European Commission (Di-
rectorate General Home Aﬀairs) under the GAINS project
HOME/2013/CIPS/AG/4000005057, and by the European
Union’s Horizon 2020 research and innovation programme
under grant agreement No 644666.

We are grateful to Abhishek Jain for his insightful com-
ments, suggestions, and contributions during the early stages
of this work.

7. REFERENCES
[1] Michel Abdalla, Dario Catalano, and Dario Fiore.

Veriﬁable random functions: Relations to
identity-based key encapsulation and new
constructions. J. Cryptology, 27(3):544–593, 2014.

[2] Jo¨el Alwen, Yevgeniy Dodis, and Daniel Wichs.
Leakage-resilient public-key cryptography in the
bounded-retrieval model. In CRYPTO, pages 36–54,
2009.

[3] Giuseppe Ateniese, Bernardo Magri, and Daniele

Venturi. Subversion-resilient signature schemes. IACR
Cryptology ePrint Archive, 2015:517, 2015.

[4] Per Austrin, Kai-Min Chung, Mohammad Mahmoody,

Rafael Pass, and Karn Seth. On the impossibility of
cryptography with tamperable randomness. In
CRYPTO, pages 462–479, 2014.

[5] Mihir Bellare, David Cash, and Rachel Miller.

Cryptography secure against related-key attacks and
tampering. In ASIACRYPT, pages 486–503, 2011.

[6] Mihir Bellare, Kenneth G. Paterson, and Phillip

Rogaway. Security of symmetric encryption against
mass surveillance. In CRYPTO, pages 1–19, 2014.

[7] Mihir Bellare and Phillip Rogaway. The exact security

of digital signatures—How to sign with RSA and
Rabin. In EUROCRYPT, pages 399–416, 1996.

374[8] Daniel J. Bernstein. Proving tight security for

[26] Dennis Hofheinz, Tibor Jager, and Edward Knapp.

Rabin-Williams signatures. In EUROCRYPT, pages
70–87, 2008.

Waters signatures with optimal security reduction. In
PKC, pages 66–83, 2012.

[9] Dan Boneh and Xavier Boyen. Short signatures

[27] Tibor Jager. Veriﬁable random functions from weaker

without random oracles and the SDH assumption in
bilinear groups. J. Cryptology, 21(2):149–177, 2008.

[10] Mike Burmester, Yvo Desmedt, Toshiya Itoh, Kouichi

Sakurai, and Hiroki Shizuya. Divertible and
subliminal-free zero-knowledge proofs for languages. J.
Cryptology, 12(3):197–223, 1999.

[11] Jean-S´ebastien Coron. Optimal security proofs for

PSS and other signature schemes. In EUROCRYPT,
pages 272–287, 2002.

[12] Ivan Damg˚ard, Sebastian Faust, Pratyay Mukherjee,

and Daniele Venturi. Bounded tamper resilience: How
to go beyond the algebraic barrier. In ASIACRYPT,
pages 140–160, 2013.

[13] Ivan Damg˚ard, Sebastian Faust, Pratyay Mukherjee,

and Daniele Venturi. Bounded tamper resilience: How
to go beyond the algebraic barrier. In ASIACRYPT,
pages 140–160, 2013.

assumptions. In TCC, pages 121–143, 2015.

[28] Yael Tauman Kalai, Bhavana Kanukurthi, and Amit

Sahai. Cryptography with tamperable and leaky
memory. In CRYPTO, pages 373–390, 2011.

[29] Jonathan Katz and Nan Wang. Eﬃciency

improvements for signature schemes with tight
security reductions. In ACM CCS, pages 155–164,
2003.

[30] Feng-Hao Liu and Anna Lysyanskaya. Tamper and

leakage resilience in the split-state model. In
CRYPTO, pages 517–532, 2012.

[31] Anna Lysyanskaya. Unique signatures and veriﬁable
random functions from the DH-DDH separation. In
CRYPTO, pages 597–612, 2002.

[32] Silvio Micali, Michael O. Rabin, and Salil P. Vadhan.
Veriﬁable random functions. In FOCS, pages 120–130,
1999.

[14] Ivan Damg˚ard, Sebastian Faust, Pratyay Mukherjee,

[33] Ilya Mironov and Noah Stephens-Davidowitz.

and Daniele Venturi. The chaining lemma and its
application. In ICITS, pages 181–196, 2015.

[15] Jean Paul Degabriele, Pooya Farshim, and Bertram

Poettering. A more cautious approach to security
against mass surveillance. In FSE, 2015. To appear.

[16] Yvo Desmedt. Abuses in cryptography and how to

ﬁght them. In CRYPTO, pages 375–389, 1988.

[17] Yevgeniy Dodis. Eﬃcient construction of (distributed)
veriﬁable random functions. In PKC, pages 1–17, 2003.
[18] Yevgeniy Dodis, Chaya Ganesh, Alexander Golovnev,

Ari Juels, and Thomas Ristenpart. A formal
treatment of backdoored pseudorandom generators. In
EUROCRYPT, pages 101–126, 2015.

[19] Yevgeniy Dodis and Aleksandr Yampolskiy. A

veriﬁable random function with short proofs and keys.
In PKC, pages 416–431, 2005.

[20] Stefan Dziembowski, Krzysztof Pietrzak, and Daniel

Wichs. Non-malleable codes. In Innovations in
Computer Science, pages 434–452, 2010.

[21] Antonio Faonio, Jesper Buus Nielsen, and Daniele

Venturi. Mind your coins: Fully leakage-resilient
signatures with graceful degradation. In ICALP, pages
456–468, 2015.

[22] Sebastian Faust, Carmit Hazay, Jesper Buus Nielsen,

Peter Sebastian Nordholt, and Angela Zottarel.
Signature schemes secure against hard-to-invert
leakage. In ASIACRYPT, pages 98–115, 2012.

[23] Sebastian Faust, Pratyay Mukherjee, Jesper Buus

Nielsen, and Daniele Venturi. Continuous
non-malleable codes. In TCC, pages 465–488, 2014.

[24] Rosario Gennaro, Shai Halevi, and Tal Rabin. Secure
hash-and-sign signatures without the random oracle.
In EUROCRYPT, pages 123–139, 1999.

[25] Rosario Gennaro, Anna Lysyanskaya, Tal Malkin,

Silvio Micali, and Tal Rabin. Algorithmic
tamper-proof (ATP) security: Theoretical foundations
for security against hardware tampering. In TCC,
pages 258–277, 2004.

Cryptographic reverse ﬁrewalls. In EUROCRYPT,
pages 657–686, 2015.

[34] David Naccache, David Pointcheval, and Jacques

Stern. Twin signatures: an alternative to the
hash-and-sign paradigm. In ACM CCS, pages 20–27,
2001.

[35] Jesper Buus Nielsen, Daniele Venturi, and Angela
Zottarel. Leakage-resilient signatures with graceful
degradation. In PKC, pages 362–379, 2014.

[36] Nicole Perlroth, Jeﬀ Larson, and Scott Shane. N.S.A.

able to foil basic safeguards of privacy on web. The
New York Times, September 2013.

[37] Jonathan D. Pincus and Brandon Baker. Beyond stack

smashing: Recent advances in exploiting buﬀer
overruns. IEEE Security & Privacy, 2(4):20–27, 2004.

[38] Sven Sch¨age. Strong security from probabilistic
signature schemes. In PKC, pages 84–101, 2012.
[39] Bruce Schneier, Matthew Fredrikson, Tadayoshi
Kohno, and Thomas Ristenpart. Surreptitiously
weakening cryptographic systems. IACR Cryptology
ePrint Archive, 2015:97, 2015.

[40] Gustavus J. Simmons. The prisoners’ problem and the

subliminal channel. In CRYPTO, pages 51–67, 1983.
[41] Umesh V. Vazirani and Vijay V. Vazirani. Trapdoor
pseudo-random number generators, with applications
to protocol design. In FOCS, pages 23–30, 1983.
[42] Brent Waters. Eﬃcient identity-based encryption
without random oracles. In EUROCRYPT, pages
114–127, 2005.

[43] Adam L. Young and Moti Yung. The dark side of

“black-box” cryptography, or: Should we trust
Capstone? In CRYPTO, pages 89–103, 1996.

[44] Adam L. Young and Moti Yung. Kleptography: Using
cryptography against cryptography. In EUROCRYPT,
pages 62–74, 1997.

[45] Adam L. Young and Moti Yung. Malicious

Cryptography: Exposing Cryptovirology. John Wiley &
Sons, Inc., ﬁrst edition, 2004.

375