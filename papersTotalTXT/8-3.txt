GMW vs. Yao? Eﬃcient Secure Two-Party

Computation with Low Depth Circuits

Thomas Schneider and Michael Zohner

Engineering Cryptographic Protocols Group (ENCRYPTO),

European Center for Security and Privacy by Design (EC SPRIDE),

Technische Universit¨at Darmstadt, Germany

{thomas.schneider,michael.zohner}@ec-spride.de

Abstract. Secure two-party computation is a rapidly emerging ﬁeld of
research and enables a large variety of privacy-preserving applications
such as mobile social networks or biometric identiﬁcation. In the late
eighties, two diﬀerent approaches were proposed: Yao’s garbled circuits
and the protocol of Goldreich-Micali-Wigderson (GMW). Since then, re-
search has mostly focused on Yao’s garbled circuits as they were believed
to yield better eﬃciency due to their constant round complexity.
In this work we give several optimizations for an eﬃcient implementa-
tion of the GMW protocol. We show that for semi-honest adversaries
the optimized GMW protocol can outperform today’s most eﬃcient im-
plementations of Yao’s garbled circuits, but highly depends on a low
network latency. As a ﬁrst step to overcome these latency issues, we
summarize depth-optimized circuit constructions for various standard
tasks. As application scenario we consider privacy-preserving face recog-
nition and show that our optimized framework is up to 100 times faster
than previous works even in settings with high network latency.

Keywords: GMW protocol, optimizations, privacy-preserving face recognition

1

Introduction

Generic secure two-party computation allows two parties to jointly compute
any function on their private inputs without revealing anything but the result.
Interestingly, two diﬀerent approaches have been introduced at about the same
time in the late eighties: Yao’s garbled circuits [33] and the protocol of Goldreich-
Micali-Wigderson (GMW) [11, 12]. Both protocols allow secure evaluation of a
function that is represented as a Boolean circuit and, in their basic form, provide
security against semi-honest adversaries who honestly follow the protocol but try
to learn additional information from the observed messages – this widely used
model allows to construct highly eﬃcient protocols and is the focus of our paper.
As Yao’s protocol has a constant number of rounds and requires Oblivious
Transfers (OTs) only for the inputs of one of the parties while the secure evalua-
tion of a gate requires only symmetric cryptographic operations, it was believed
to be more eﬃcient than the GMW protocol, which requires an interactive OT

for each AND gate (see for example [13, Sect. 1.2]). In fact, many subsequent
works presented improvements to Yao’s protocol and showed that it can be made
truly practical and applied to a large variety of privacy-preserving applications,
e.g., [14, 15, 19, 20, 24, 29].

In a recent work [5], it was shown that by implementing OTs eﬃciently
using symmetric cryptographic primitives, the semi-honest version of the GMW
protocol can outperform previous secure computation protocols with n ≥ 3
parties. However, for the two-party case, the authors of [5] state that they expect
their implementation to be roughly a factor of two slower than today’s fastest
implementation of Yao’s garbled circuit protocol of [15]. For stronger active
adversaries, it has been shown in [27] that an extension of the GMW protocol
achieves a performance that can compete with garbled circuit-based protocols.

1.1 Outline and Our Contributions

In this work we show that the GMW protocol is truly practical in the setting
with two semi-honest parties and in fact has some advantages over Yao’s garbled
circuits protocol. Our contribution is threefold:

Depth-Eﬃcient Circuits. As the GMW protocol requires interaction for the
secure evaluation of AND gates, the dependence on the latency can be reduced
by using circuit constructions that have both, low size and depth. We give a
summary of such circuit constructions for standard functionalities in §3.

Implementation-Speciﬁc Optimizations. We extend the implementation of the
GMW protocol of [5] with various optimizations to yield better performance in
the setting with two parties. Our optimizations are described in §4 and include
load balancing (to distribute the workload equally among the parties) and pro-
cessing multiple gates in parallel. Overall, our optimized implementation yields
a more than 10 times faster runtime compared to the implementation of [5] for
an example circuit with about 800,000 gates.
Performance Evaluation. Finally, in §5, we compare the optimized GMW
protocol with today’s most eﬃcient techniques for garbled circuits on a concep-
tual level (independent of the implementation). Afterwards, we experimentally
measure and evaluate the performance of our implementation for two example
applications: a mobile social network [5] and privacy-preserving face recognition
using Eigenfaces [9, 14, 30] and the Hamming distance [28] in a desktop envi-
ronment that has a network with high bandwidth. In settings with low network
latency our implementation is able to process up to 1,000,000 AND gates (1-
out-of-4 OTs) per second in the setup phase and 50,000,000 AND gates per
second in the online phase. Our evaluation indicates that the GMW protocol is
a noticeable alternative to previous protocols based on garbled circuits.

1.2 Related Work

Circuit Optimizations. Since the communication complexity of garbled circuits
is independent of the depth of the evaluated circuit, cryptographic literature
mostly focused on minimizing the multiplicative size of circuits, i.e., the number

2

of AND gates where XOR gates are free, e.g. [4,18,29]. Most of the existing work
on minimizing circuit depth originates from the area of electrical engineering
(cf. [8, 31, 32]), where the circuit depth directly aﬀects the computation latency.
Our setting for circuit optimization is slightly diﬀerent from this as we can
evaluate XOR gates for free, can store intermediate results indeﬁnitely, and have
unbounded fan-out.

Garbled Circuit Frameworks. Starting with Fairplay [24] that demonstrated
the practical feasibility of Yao’s garbled circuits, various frameworks for secure
two-party computation have been developed. The currently fastest garbled cir-
cuits framework with security in the semi-honest model is [15]. A garbled circuit
framework secure against malicious adversaries was given in [20].

GMW Frameworks. The implementation of [5] showed that for semi-honest
adversaries the GMW protocol can outperform previous secure multi-party com-
putation frameworks for circuits that can be eﬃciently represented as Boolean
circuits. However, they show this only for the setting with n ≥ 3 parties and
expect that their implementation requires about twice the computation time
of [15] in the two-party setting (cf. [5, Sect. 1.2]). The GMW protocol was re-
cently extended into a new approach for secure two-party computation with
security against malicious adversaries in [27].

Other Frameworks. For completeness we mention that there exist also other
approaches for secure two-party computation (beyond garbled circuits and the
GMW protocol) that evaluate arithmetic instead of Boolean circuits. These ap-
proaches use additively homomorphic encryption as implemented in the VIFF
framework [6] or the SPDZ framework [7] and can even be combined with garbled
circuits as implemented in [14]. Although these approaches are well-suited for
outsourcing computations in scenarios where one party has substantially more
computing power than the other party (e.g., cloud computing), they involve rel-
atively expensive public-key operations in the online phase. Hence, these works
are orthogonal to the protocols we consider that require only fast operations per
gate and allow to distribute the workload equally among the parties.

2 Preliminaries

2.1 Oblivious Transfer
Oblivious Transfer (OT) is a cryptographic protocol executed between a sender S
and a receiver R in which R obliviously selects one of the inputs provided by S.
(cid:96) , S provides m n-tuples (x11, . . . , x1n), . . . ,
More speciﬁcally, in 1-out-of-n OTm
(xm1, . . . , xmn) of (cid:96)-bit strings; R provides m selection numbers r1, . . . , rm with
1 ≤ ri ≤ n and obtains xjrj (1 ≤ j ≤ m) as output. The widely used Naor-Pinkas
OT protocol [25] is secure against semi-honest adversaries under the Decisional
Diﬃe-Hellman (DDH) assumption in the random-oracle model and requires both
parties to perform O(m) modular exponentiations. The following two techniques
can be used to substantially speed up OTs.

OT pre-computations [2] allows to pre-compute the OTs on random inputs
and later on in the online phase use these pre-computed values as one-time pads

3

to run the OT on the actual inputs. In the online phase, R sends one message
of size m log2 n bits to S who sends back a message of size mnl bits.

OT extensions [16, 22] allow to perform a large number of m OTs (OTm
(cid:96) )
using a small number of t base OTs on t-bit keys (OTt
t), where t is a security
parameter. The marginal cost for each additional OT is a small number of eval-
uations of a cryptographic hash function (modeled as random oracle) and of a
pseudo-random function. More speciﬁcally, for each of the m OTs, S computes
n hash evaluations and t(1 + log2 n) pseudo-random bits, whereas R computes 1
hash evaluation and t(1 + n) pseudo-random bits. The communication complex-
ity is one message from R to S of size mnt bits and one in the opposite direction
of size mn(cid:96) bits.

2.2 Approaches for Secure Two-Party Computation

We summarize the main approaches for secure two-party computation of Boolean
circuits next: Yao’s garbled circuits (§2.2.1) and the GMW protocol (§2.2.2).

2.2.1 Yao’s Garbled Circuits Protocol [33]. The basic idea of Yao’s gar-
bled circuits is to let one party, called creator, encrypt the function to be com-
puted. For this, the plain values are mapped to random-looking symmetric keys
and for each gate an encryption table is generated that allows to compute the
gate’s output key given its input keys. The creator then transmits the encrypted
circuit along with the corresponding encrypted inputs to the other party, called
evaluator. The creator sends his encrypted inputs directly to the evaluator and
the evaluator obtains his encrypted inputs obliviously via 1-out-of-2 OT. The
evaluator then uses the encrypted inputs to evaluate the encrypted function
gate by gate. Finally, the creator provides a mapping from the encrypted out-
put to plain output. As the evaluation of Yao’s garbled circuits is performed
non-interactively, the resulting protocol has a constant number of rounds.

The following extensions enhance the speed of Yao’s garbled circuits proto-
col: point-and-permute [24], free XOR [19], eﬃcient encryption with a crypto-
graphic hash function [23], garbled row reduction [26, 29], and pipelining [15].
Put together, these techniques allow “free” evaluation of XOR gates (i.e., no
communication and negligible computation), interweaving circuit generation and
evaluation, and per non-XOR gate 4 evaluations of a cryptographic hash func-
tion for the creator, transmissions of an encrypted gate table with 3 entries, and
1 evaluation of a cryptographic hash function for the evaluator.

2.2.2 GMW Protocol [11, 12]. In the GMW protocol two parties interac-
tively compute a function using secret-shared values. For this, the value v of each
input and intermediate wire is shared among the two parties with a 2-out-of-2
secret sharing scheme such that each party holds a random-looking share vi with
v = v1 ⊕ v2. As XOR is an associative operation, XOR gates can be securely
evaluated locally by XORing the shares. For secure evaluation of AND gates,
the parties run an interactive protocol using one of the two techniques described

4

below. We note that AND gates of the same layer in the circuit can be computed
in parallel. Finally, the parties send the respective shares of the output wires to
the party that should obtain the output.

Oblivious Transfers. To securely evaluate an AND gate on input shares x1, x2
and y1, y2, the two parties can run a 1-out-of-4 OT1
1 protocol. Here, the chooser
inputs its shares x1, y1 and the sender chooses a random output share z2 and
provides four inputs to the OT protocol such that the chooser obliviously obtains
its output share z1 = z2 ⊕ ((x1 ⊕ x2) ∧ (y1 ⊕ y2)). As described in §2.1, all OTs
can be moved into a pre-processing phase such that the online phase is highly
eﬃcient (only two messages and inexpensive one-time-pad operations).

Multiplication Triples. An alternative method to securely evaluate an AND
gate on input shares x1, x2 and y1, y2 are multiplication triples [1]. Multiplication
triples are random shares ai, bi, ci satisfying (c1⊕c2) = (a1⊕a2)∧(b1⊕b2). They
can be generated in the setup phase using a 1-out-of-4 OT1
1 protocol in a similar
way to the OT-based solution described above. In the online phase the parties
use these pre-generated multiplication triples to mask the input shares of the
AND gate, exchange di = xi ⊕ ai and ei = yi ⊕ bi, and compute d = d1 ⊕ d2 and
e = e1⊕e2. The output shares are computed as z1 = (d∧e)⊕(b1∧d)⊕(a1∧e)⊕c1
and z2 = (b2 ∧ d) ⊕ (a2 ∧ e) ⊕ c2. The advantage of multiplication triples over
the OT-based solution is that, per AND gate, each party needs to send only
one message (independent of each other) and the size of the messages is slightly
smaller (2 + 2 bits instead of 2 + 4 bits).

2.3 Evaluation Metrics and Notation

Motivated by the fact that both approaches for secure two-party computation
summarized in §2.2 provide free XORs, we consider the (multiplicative) size S(C)
of a circuit C as the number of AND gates in C and the (multiplicative) depth
D(C) as the maximum number of AND gates on any path from an input to an
output of C.

1...n is a sequence of n (cid:96)-bit values x(cid:96)

We denote a bit sequence of length (cid:96) bits as x(cid:96) and use xi to refer to its i-th
bit, starting with the least-signiﬁcant bit x1. ¯x(cid:96) denotes the bitwise complement
of x(cid:96). x(cid:96)
n. A circuit C that processes
n values of ((cid:96)1, (cid:96)2, ..., (cid:96)n)-bits each is denoted by C(((cid:96)1,(cid:96)2,...,(cid:96)n),n). If all inputs n
have the same length (cid:96), we shorten the notation to C((cid:96),n). When n is clear
from the context we use C(cid:96) instead. We use the standard notations for binary
operations, i.e. concatenation ||, bitwise XOR ⊕, bitwise AND ∧, and bitwise
OR ∨.

1, x(cid:96)

2, ..., x(cid:96)

3 Circuit Constructions with low Depth and Size

In the following we brieﬂy summarize circuit building blocks that have low depth
and only a slightly larger size compared to constructions that are optimized for
size only. A detailed list of constructions is given in Appendix A, Tab. 7 (due to
space restrictions we defer details to the full version).

5

3.1 Addition

The standard method for adding two (cid:96)-bit numbers is the Ripple-carry adder
ADD(cid:96)
RC) = (cid:96) [18]. In
the following we summarize techniques for addition in sub-linear depth.

RC that has linear size and depth, S(ADD(cid:96)

RC)=D(ADD(cid:96)

3.1.1 Ladner-Fischer Adder. The Ladner-Fischer adder ADD(cid:96)
LF [21] is a
so-called parallel preﬁx adder that adds two (cid:96)-bit values x(cid:96) and y(cid:96) in logarithmic
depth. The idea of parallel preﬁx adders is to evaluate multiple carry-bits in
parallel. During the computation of the sum, the Ladner-Fischer adder computes
a parity bit pi,j and a carry bit ci,j in each node at bit position i (1 ≤ i ≤ (cid:96))
and level j (0 ≤ j ≤ (cid:100)log2 (cid:96)(cid:101)). At level 0, the Ladner-Fischer adder computes
pi,0 = xi ⊕ yi and ci,0 = xi ∧ yi. Then, for every node at level j > 0, the
parity and carry bit are computed as pi,j = pi,j−1 ∧ pk,j−1 and ci,j = (pi,j−1 ∧
ck,j−1) ∨ ci,j, where k is the node that propagates the carry-bit to position i.
Lastly, at level (cid:100)log2 (cid:96)(cid:101) + 1, the sum s(cid:96)+1 is computed as s(cid:96)+1 = c(cid:96),(cid:100)log2 (cid:96)(cid:101),
si = pi,0 ⊕ ci−1,(cid:100)log2(i−1)(cid:101) for 1 < i ≤ (cid:96), and s1 = p1,0. The Ladner-Fischer adder
LF ) = 2(cid:100)log2 (cid:96)(cid:101) + 1.
has size S(ADD(cid:96)

LF ) = 1.25(cid:96)(cid:100)log2 (cid:96)(cid:101) + (cid:96) and depth D(ADD(cid:96)

3.1.2 Carry-Save Adder. The carry-save adder ADD((cid:96),3)
CSA [8] converts the
sum of three (cid:96)-bit unsigned integers x(cid:96), y(cid:96), and z(cid:96) into two (cid:96) + 1-bit unsigned
integers p(cid:96)+1 and c(cid:96)+1 such that p(cid:96)+1 + c(cid:96)+1 = x(cid:96) + y(cid:96) + z(cid:96). To obtain the
result of the addition in sub-linear depth, p(cid:96)+1 and c(cid:96)+1 can again be added
using the Ladner-Fischer adder (cf. §3.1.1). The carry-save adder is composed
from (cid:96) 1-bit full-adders that compute the parity pi = xi ⊕ yi ⊕ zi and the carry
ci+1 = zi ⊕ ((zi ⊕ xi) ∧ (zi ⊕ yi)) in parallel for every bit position 1 ≤ i ≤ (cid:96).
Finally, p(cid:96)+1 and c1 are set to 0.

CSA) = 1+D(ADD((cid:96)+1)

The carry-save adder has linear size and constant depth, allowing three (cid:96)-
CSA) = (cid:96)+S(ADD((cid:96)+1)
LF )
LF ). Multiple carry-save adders can be
CSN that converts n (cid:96)-bit num-
with
2i + S(ADD((cid:96)+(cid:100)log2 n(cid:101))
) ≈ (cid:96)n− 2(cid:96) + n−
i n
CSN ) = (cid:100)log2 n(cid:101) + D(ADD((cid:96)+(cid:100)log2 n(cid:101))
)

bit numbers to be added with a circuit of size S(ADD((cid:96),3)
and depth D(ADD((cid:96),3)
combined to create a carry-save network ADD((cid:96),n)
bers to two (cid:96) + (cid:100)log2 n(cid:101)-bit numbers and adds them using ADD(cid:96)+(cid:100)log2 n(cid:101)
S(ADD((cid:96),n)
(cid:100)log2 n(cid:101) + S(ADD((cid:96)+(cid:100)log2 n(cid:101))
[31].

CSN ) = ((cid:96)− 1)(n− 2) +(cid:80)(cid:100)log2 n(cid:101)

) and D(ADD((cid:96),n)

i=0

LF

LF

LF

LF

3.2 Squaring

multiplication circuit MUL(cid:96) [18] computes the product x(cid:96)x(cid:96) as(cid:80)(cid:96)

Although the square of a number can be computed with a multiplication circuit,
a squaring circuit is smaller by a factor of about two. The standard school method
i=1 2i−1(x(cid:96)xi).
Since each xjxi with i (cid:54)= j is computed twice, xjxi + xixj can be simpliﬁed to
2xixj and xixi can be replaced with xi [34]. The corresponding depth-eﬃcient
LF ) = (cid:96)2 + 1.25(cid:96)(cid:100)log2 (cid:96)(cid:101) − 1.5(cid:96) − 2 and
squarer circuit SQR(cid:96)
depth D(SQR(cid:96)

LF )+1 = 3(cid:100)log2 (cid:96)(cid:101) + 3.

LF )=D(ADD(2(cid:96),(cid:100)(cid:96)/2(cid:101))

LF has size S(SQR(cid:96)

)+D(ADD2(cid:96)

CSA

6

3.3 Comparison

S)=D(GT(cid:96)

A circuit that checks the equality of two values EQ(cid:96) has linear size S(EQ(cid:96))
= (cid:96) − 1 [19] and can be built in a pairwise tournament fashion to achieve
logarithmic depth D(EQ(cid:96)) = (cid:100)log2 (cid:96)(cid:101). The standard greater than circuit GT(cid:96)
S
that checks whether one number is greater than another has linear size, but
also linear depth S(GT(cid:96)
S)= (cid:96) [18]. The greater than operation can
be computed in logarithmic depth using the circuit GT(cid:96)
DC of [10] that recur-
sively splits the (cid:96)-bit parameters into half. More precisely, let x(cid:96) = (xH||xL)
2(cid:101)-bit and xL,
and y(cid:96) = (yH||yL) be two (cid:96)-bit integers with xH , yH being (cid:100) (cid:96)
yL being (cid:98) (cid:96)
DC is then recursively computed as
(cid:98) (cid:96)
2(cid:99)
GT(cid:96)
DC (xL, yL) until x and
y are bits for which GT1
DC)
= 3(cid:96) − (cid:100)log2 (cid:96)(cid:101) − 2 and depth D(GT(cid:96)

2(cid:99)-bit unsigned integers. GT(cid:96)
(cid:100) (cid:96)
2(cid:101)
DC (xH , yH ) ⊕ EQ(cid:100) (cid:96)

DC(xi, yi) = xi ∧ ¯yi. The circuit has size S(GT(cid:96)

2(cid:101)(xH , yH ) ∧ GT
DC) = (cid:100)log2 (cid:96)(cid:101) + 1.

DC(x(cid:96), y(cid:96)) = GT

3.4 Hamming Weight

computes its Hamming weight dH (x(cid:96)) =(cid:80)(cid:96)

The Hamming weight circuit CNT(cid:96) counts the number of one entries in x(cid:96), i.e., it
i=1 xi. In [4], a Hamming weight cir-
BP was given that splits a value x(cid:96) into three parts of length m = (cid:100) (cid:96)−1
2 (cid:101),
cuit CNT(cid:96)
2 (cid:99), and one bit, respectively: x(cid:96) = (xm||xn||x1). CNT(cid:96)
n = (cid:98) (cid:96)−1
BP is then com-
puted recursively as CNT(cid:96)
BP (xn), x1)
where x1 can be provided as carry-in to the addition circuit at no extra cost.
BP ) = (cid:98)log2 (cid:96)(cid:99).
The circuit has size S(CNT(cid:96)

BP (x(cid:96)) = ADD
BP ) = (cid:96) − dH ((cid:96)) and depth D(CNT(cid:96)

BP (xm), CNTn

(cid:100)log2 (cid:96)(cid:101)
RC

(CNTm

4 Optimizations for Two-Party GMW

The original paper of [5] provides an implementation of the GMW protocol
and gives performance numbers for n ≥ 3 parties. For two parties, they expect
that their implementation is slower than the currently fastest garbled circuit
implementation of [15] by a factor of two (cf. [5, Sect. 1.2]). We modiﬁed and
extended their GMW implementation for better eﬃciency in the two-party set-
ting. In the following we give an overview of our modiﬁcations that improved
the overall performance the most. We list the modiﬁcations in the order they
were implemented and summarize the performance numbers in Tab. 1. Hence,
the performance numbers for each modiﬁcation include the improvement of all
previous optimizations. In total, we improve the overall runtime of the following
example application by more than a factor of 10.

Benchmarking Environment. In our experiments we evaluate the time for the
setup phase (Naor-Pinkas OTs and OT extension), online phase (sharing of
inputs, circuit evaluation, and combining output shares), and the overall time
(circuit construction, setup phase, and online phase). We perform the comparison
on an unoptimized 512-bit multiplication circuit C with S(C) = 800,227 and

7

D(C) = 38 using the average time of 100 executions. For the Naor-Pinkas OT
p with |p|= 512 bit, also used in [5]. For the OT extensions we
we use the group Z∗
set the security parameter to t = 80. The server and client run on two 2.5 GHz
Intel Core2Quad CPU (Q8300) Desktop PCs with 4 GB RAM each that are
connected via Gigabit LAN with a ping latency of 0.2 ms.

Optimization

None MT
§4.1
Setup Phase [s] 13.39 13.82
0.70
Online Phase [s] 0.73

[5]

PRF
§4.2
11.41
0.70

LB GMP Bytewise SHA-1 SIMD
§4.3
§4.5
0.84
7.41
0.012
0.71

§4.4
6.87
0.70

§4.4
1.68
0.31

§4.4
0.89
0.32

Overall Time [s] 14.19 14.52

12.16

8.14

7.60

2.10

1.35

0.85

Table 1: Time improvements for the individual optimizations.

4.1 Multiplication Triples

To reduce the impact of the latency during the online time we use Beaver’s
multiplication triples [1] instead of pre-computed OTs for secure evaluation of
AND gates (cf. §2.2.2). This results in a slightly slower setup phase (13.82 s
instead of 13.39 s) due to the additional overhead for computing c2 (instead
of using random inputs). However, the online phase gets more eﬃcient (0.70 s
instead of 0.73 s) as we only require one instead of two interaction steps and 4
instead of 6 bits sent per AND gate.

4.2 Using AES instead of SHA as Pseudo-Random Function

The original implementation of [5] used SHA-1 not only for instantiating the
random oracle, but also for generating pseudo-random values in the OT exten-
sion. To reduce the computational complexity, we use AES in the counter mode
as pseudo-random function (PRF). More precisely, we benchmarked the SHA-1
implementation of PolarSSL that was used in [5] against the SHA-1 implemen-
tation (sha1-x86 64) and the AES128 (aes-x86 64) implementation of OpenSSL
v. 1.0.1c. The results for 109 iterations are depicted in Tab. 2. This decreased the
number of expensive hash function calls per AND gate (to instantiate the ran-
dom oracle) from 3.5 to 1 for the receiver R and from 4.5 to 4 for the sender S;
additionally, R performs 3.1 AES calls and S performs 0.65 AES calls per AND
gate (to instantiate the PRF). Overall, using AES as PRF decreased the setup
time from 13.82 s to 11.41 s. We note that the performance could be improved
even further by using the Intel AES New Instructions (AES-NI) provided by
recent CPUs.

8

Algorithm

Iterations/s Bits/s
1.30 · 106 2.08 · 108
SHA-1 PolarSSL
3.65 · 106 5.83 · 108
SHA-1 OpenSSL
AES128 OpenSSL 4.99 · 106 6.39 · 108

Table 2: Comparison of SHA-1 and AES128 implementations for 109 iterations.

4.3 Load Balancing

In the OT extension protocol executed in the setup phase, the sender and the
receiver have diﬀerent computational workload (cf. §4.2). As the multiplication
triples used in the online phase (cf. §4.1) are symmetric, we can run the OTs
to generate them in the setup phase in either direction. Hence, to balance the
workload, we run two instantiations of the OT protocol (each for half of the AND
gates) in parallel with the roles reversed. With this optimization, each party has
the same workload: 2.5 SHA-1 invocations and 1.8 AES invocations per AND
gate. Note that now we also need to run the Naor-Pinkas OT protocol for the
seed OTs twice, which however amortizes fairly quickly (35 ms computation
time and 10 kByte to be transferred). Since the original implementation of [5]
already used multi-threading for implementing the OT extensions, we now use
four parallel threads during the setup phase (two for each role such that one
thread evaluates the pseudo-random function in the ﬁrst round and the other
the random oracle in the second round of the protocol). Overall, load balancing
decreased the setup time from 11.41 s to 7.41 s.

4.4 Implementation-Speciﬁc Optimizations

In order to further speed up the execution time we performed several implementa-
tion-speciﬁc optimizations as summarized next.

Arithmetic. For modular arithmetics within the Naor-Pinkas base OTs we
replaced the Number Theory Library (NTL) v. 5.5.2 used in [5] with the GNU
Multiple Precision Arithmetic Library (GMP ) v. 5.0.5. This decreased the time
for the Naor-Pinkas base OTs from 590 ms using NTL to 35 ms using GMP for
modular operations on 512 bit values.

Bytewise Operations. A major bottleneck was the bitwise processing order
during the OT extension step and the online phase. We reduced the impact of
the processing order by performing the operations bytewise instead of bitwise.
For the setup phase we thereby gained a decrease in time from 6.87 s to 1.68 s.
For the online phase we achieved a decrease in time from 0.70 s to 0.31 s.

SHA-1. Afterwards, the evaluation of SHA-1 for the random oracle became
the major bottleneck for the OT extension. We replaced the implementation of
SHA-1 from PolarSSL used in [5] with an assembler implementation of OpenSSL
v. 1.0.1c (sha1-x86 64). This decreased the setup time from 1.68 s to 0.89 s.

9

4.5 Single Instruction Multiple Data (SIMD) Operations

The Sharemind framework [3] for secure three-party computation showed that
Single Instructions Multiple Data (SIMD) operations can result in substantial
performance gains. The idea of SIMD operations is to replace the evaluation of
n identically copies of the same sub-circuit on one-bit values by one evaluation
of the sub-circuit on n-bit values. This optimization reduces the overall compu-
tation time and the memory footprint as the circuit needs to be generated only
once. SIMD operations are especially beneﬁcial in data mining applications [3].
We show the beneﬁt of SIMD operations by running the benchmarking circuit
C 32 times in parallel on diﬀerent inputs, resulting in a circuit Cpar with S(Cpar)
= 32 · S(C) = 25,607,264 and D(Cpar) = D(C) = 38. The evaluation without
SIMD operations required 36.44 s (i.e., amortized 1.13 s for each circuit C), of
which 26.76 s (0.84 s) were spent in the setup phase and 2.87 s (0.09 s) in the
online phase. Using the SIMD operations, the overall time decreased to 27.34 s
(0.85 s), with similar setup time of 26.74 s (0.82 s) but 7.5 times faster online
time of 0.38 s (0.012 s). In our implementation the RAM requirement of one
gate without the SIMD extension is 14 Byte. C has 3,168,202 gates (including
XOR gates) in total and requires 42.3 MByte of memory. To store Cpar without
the SIMD extension we therefore would need 1.32 GByte of memory. The SIMD
extension increases the size per gate to 25 Byte plus one bit for each parallel
exection and adds a negligible management overhead for the conversion between
bitwise and SIMD operations. In total, the SIMD circuit for Cpar requires only
88.6 MByte of memory, which corresponds to 6.5% of the non-SIMD variant.

5 Evaluation

We consider two application scenarios to evaluate the beneﬁts of depth-optimized
circuits (§3) and the optimizations of the GMW protocol (§4): privacy-preserving
mobile social networks (§5.1) and privacy preserving face-recognition (§5.2).

Conceptual Performance Comparison. We ﬁrst give a conceptual comparison
between the GMW protocol, optimized as described in §4, with today’s most
eﬃcient techniques for garbled circuits, as summarized in Tab. 3. Both techniques
provide free XOR gates. Unlike garbled circuits, for each AND gate, the GMW
protocol allows to shift all usage of symmetric cryptography into the setup phase
(cf. §2.2.2) and to distribute the workload equally among client C and server S (cf.
§4.3). Since GMW operates on single bits during the online phase, multiple gates
can be evaluated in one instruction (cf. §4.4 and §4.5), whereas garbled circuits
need to evaluate each gate individually. However, the total communication per
AND gate for the GMW protocol is slightly larger. The memory requirement
during secure evaluation of the circuit is smaller for the GMW protocol as for
every wire of the circuit each party only needs to store a 1-bit share instead
of an 80-bit wire label. Also the inputs are cheaper in the GMW protocol as
only one random bit needs to be chosen and sent to the other party, whereas in
garbled circuits a random 80-bit key needs to be chosen and sent to the evaluator

10

(using OT for evaluator’s inputs). The main disadvantage of the GMW protocol
is its need for interaction during evaluation of AND gates which becomes an
inevitable performance bottleneck for high network latency as shown in our
practical experiments next.

Properties

Free XOR
per AND gate:

setup computation
setup communication [bit]
online computation
online communication [bit]

Garbled Circuits

Optimized GMW

yes

yes

-
-

C: 1×SHA; S: 4×SHA

C←S: 240

C&S: 2.5×SHA+1.8×AES

C→S&C←S: 162
C→S&C←S: 2

negligible

per wire storage C&S [bit]
per input: rnd bits | comm. [bit] 80 | C: OT resp. S: 80

80

1

1 | 1

Table 3: Conceptual Comparison between state-of-the-art Garbled Circuits (us-
ing Point-and-Permute, Free XORs, Garbled Row Reduction, and Pipelining)
and the GMW Protocol (using optimizations of §4) for security parameter
t = 80 bits. C: client, S: server, SHA: SHA-1, AES: AES128.

Benchmarking Environment. We measure runtimes for diﬀerent (round-trip)
latencies that are typical for the following network types: LAN (0.2 ms), intra-
country internet (10 ms), and trans-atlantic internet (100 ms). The latency on
the network interfaces was enforced by changing the traﬃc control settings on
Linux using the tc command. We used the same benchmarking environment as
described in §4, but use a subgroup of order q with |q| = 128 and |p| = 1024 in
the Naor-Pinkas OT to match the parameters of previous works. The time for
the Naor-Pinkas OT on 1024 bit values in the LAN setting is 2,950 ms for the
original implementation of [5] and 170 ms for our implementation.

5.1 Mobile Social Networks

In the mobile social network scenario of [5] one party inputs a database of N users
Ui (1 ≤ i ≤ N ) that each have a set of interests Hi (represented as (cid:96)-bit vector)
and a m-bit location Li. The other party is a user U who can identify the user
Uk that shares the most interests among all users Ui within a certain distance
δm+1. As a result, U obtains in a privacy-preserving way only the identity k of
Uk and 0 otherwise. We give more details on the circuit in §C.

In our experiments we use N = 128 users, m = 32-bit locations Li, and
(cid:96) = 255-bit sets of interests Hi. We build two versions of the circuit, a size-
eﬃcient version MSNS with S(MSNS) = 89,321 and D(MSNS) = 98 and a
depth-eﬃcient version MSND with S(MSND) = 203,102 and D(MSND) = 68.
We compare the performance on both circuits for the original implementation
of [5] to our implementation in Tab. 4.

11

For the LAN setting (0.2 ms) our implementation outperforms the original
implementation by factor 13 (factor 3 in the online phase). Due to the multi-
plication triple optimization (cf. §4.1), the online time of our implementation
increases only half as much as the original implementation with rising latency.
While the online time of MSND is marginally higher than MSNS in the LAN
setting (0.2 ms), the latency becomes the dominant factor in the overall execu-
tion time for the intra-country internet setting (10 ms) and the trans-atlantic
internet setting (100 ms), i.e., MSND is better for settings with higher latency.

Framework
Circuit
Latency [ms]

[5]

This work

MSNS

MSND

MSNS

MSND

0.2 10

100

0.2 10

100

0.2 10 100 0.2 10 100

Setup phase [s] 4.65 4.82 6.27 6.48 6.62 8.24 0.30 0.51 1.62 0.42 0.62 1.92
Online phase [s] 0.15 1.12 9.94 0.23 0.92 7.04 0.05 0.54 4.92 0.06 0.40 3.55
Overall time [s] 4.83 5.97 16.24 6.73 7.57 15.31 0.36 1.06 6.58 0.50 1.03 5.50

Table 4: Runtimes for secure evaluation of mobile social networks.

5.2 Privacy-Preserving Face Recognition

To show the performance of our framework on large circuits we benchmark it
on circuits for privacy-preserving face recognition. Here, the client holds a query
face and wants to determine whether it matches one of the faces input by the
server. We consider two commonly used face-recognition algorithms: Eigenfaces
(§5.2.1) and the index-based Hamming distance scheme of SCiFI [28] (§5.2.2).

5.2.1 Using Eigenfaces. Here, the client inputs a query face image Γ with N
pixels of b-bits each. The server inputs M faces projected into a K-dimensional
feature space Ω1, ..., ΩM . If Γ matches one of the faces in the database, the
client receives the index imin of the closest match (see §D for details). A privacy-
preserving protocol based on additively homomorphic encryption was given in [9]
and subsequently improved by combining it with garbled circuits [14, 30].
We use the same parameters as [9, 14, 30]: N = 10,304; b = 8; K = 12. Using
the depth-optimized circuits of §3 results in a circuit for 320 faces in the database
FR320
Eig) = 120 and a circuit for 1,000
faces FR1000

Eig) = 14,887,713 and D(FR320

Eig with S(FR320

Eig with S(FR1000

Eig ) = 22,811,392 and D(FR1000

Eig ) = 128.

The performance of our implementation in comparison with previous works
is shown in Tab. 5 (similar machines connected via LAN). Our implementation
outperforms previous work by at least factor 8 in the online phase for a database
with 320 faces (factor 10 for 1,000 faces) while maintaining a fast setup time.
Also, our implementation scales very well with increasing database size due to
the SIMD operations of §4.5 (≈ 0.33 ms online time per face in the database).

12

Faces in Database
Framework

Setup phase [s]
Online phase [s]

320

1,000

[9]

18
22

[14]

38.1
41.5

[30] This work

n/a
8.4

15.7
1.1

[9]

n/a
n/a

[14]

83.4
56.2

[30] This work

n/a
13

24.0
1.3

Overall time [s]
Table 5: Runtimes for Eigenfaces-based face recognition (on similar machines).

139.6

17.7

76.9

n/a

40

n/a

n/a

26.3

5.2.2 Using Hamming Distance. In the Hamming distance based algo-
rithm proposed in [28], the client maps his query face to an (cid:96)-bit index vector
that represents the characteristics of the face. Face recognition is done by com-
puting the Hamming distance between the client’s index vector and each of the
server’s M index vectors of faces in the database and checking whether this dis-
tance is below a pre-computed, face-speciﬁc threshold. The original protocols
proposed in SCiFI [28] were based on additively homomorphic encryption and
later improved by the garbled circuits framework of [15].

We construct a circuit FR((cid:96),N )
SCI

SCI ) = N ((cid:96) + (cid:100)log2 (cid:96) + 1(cid:101) − dH ((cid:96))) and D(FR((cid:96),N )

for the SCiFI recognition algorithm that con-
sists of N parallel instantiations of the Boyar-Peralta count circuit CNT(cid:96)
BP (cf.
(cid:100)log2 (cid:96)+1(cid:101)
§3.4)1 and the size-optimized greater than circuit GT
(cf. §3.3) with
S
SCI ) = (cid:100)log2 (cid:96) + 1(cid:101) + 1.
S(FR((cid:96),N )
Similar to previous works we choose (cid:96) = 900, resulting in a circuit with 906 AND
gates per face in the database and a depth of 11. Tab. 6 shows a performance
comparison between the original protocols of [28] and the framework of [15] and
our framework, both evaluating the SCiFI circuit FR(900,N )

.

SCI

The original SCiFI protocols [28] require a constant setup time of 213 s and
an online time of 0.31 s per face in the database. Their main advantage is that
the online phase can be parallelized on multiple servers. For the circuit-based
approaches we can observe that our framework outperforms [15] in online time
by factor 300 for 100 faces (factor 500 for 320 faces) in the LAN setting and
by factor 4 (factor 10 for 320 faces) in the trans-atlantic internet setting. Most
notable is the sub-linear scaling in the database size due to the SIMD operations
(cf. §4.5), which enable our framework to process large-scale databases within a
very short online time (18 µs per face in the LAN setting and 60 µs per face in
the trans-atlantic internet setting). In contrast, the main performance bottleneck
of the [15] framework is the time for generating large circuits, i.e., the diﬀerence
between overall time and setup plus online time.

Acknowledgement. This work was supported by the German Federal Ministry
of Education and Research (BMBF) within EC SPRIDE and by the Hessian
LOEWE excellence initiative within CASED.

1 This circuit has about half the size of the count circuit proposed in [15].

13

Framework
[28]
Faces in Database 100
Latency [ms]

[15]

This work

100

320

100

320

50,000

LAN 0.2

100

0.2

100

0.2

100

0.2

100

0.2

100

Setup phase [s]
Online phase [s]
Overall time [s]

213
31
244

0.40 0.67 0.40 0.67
1.75 2.18 5.14 6.34 0.006 0.53 0.01 0.62
8.79 9.85 42.9 44.5

0.30 1.09 0.49 1.35 44.85 55.87
0.90 3.02
0.31 1.64 0.51 2.01 45.98 59.68

Table 6: Runtimes for index-based face recognition (on similar machines).

References

1. Beaver, D.: Eﬃcient multiparty protocols using circuit randomization. In: Ad-
vances in Cryptology – CRYPTO’91. LNCS, vol. 576, pp. 420–432. Springer (1991)
2. Beaver, D.: Precomputing oblivious transfer. In: Advances in Cryptology –

CRYPTO’95. LNCS, vol. 963, pp. 97–109. Springer (1995)

3. Bogdanov, D., Jagom¨agis, R., Laur, S.: A universal toolkit for cryptographically
secure privacy-preserving data mining. In: Paciﬁc Asia Workshop on Intelligence
and Security Informatics (PAISI’12). LNCS, vol. 7299, pp. 112–126. Springer (2012)
4. Boyar, J., Peralta, R.: Concrete multiplicative complexity of symmetric functions.
In: Mathematical Foundations of Computer Science (MFCS’06). LNCS, vol. 4162,
pp. 179–189. Springer (2006)

5. Choi, S.G., Hwang, K.W., Katz, J., Malkin, T., Rubenstein, D.: Secure multi-party
computation of Boolean circuits with applications to privacy in on-line market-
places. In: Cryptographers’ Track at the RSA Conference (CT-RSA’12). LNCS,
vol. 7178, pp. 416–432. Springer (2012)

6. Damg˚ard, I., Geisler, M., Krøigaard, M., Nielsen, J.B.: Asynchronous multiparty
computation: Theory and implementation. In: Public Key Cryptography (PKC’09).
LNCS, vol. 5443, pp. 160–179. Springer (2009)

7. Damg˚ard, I., Pastro, V., Smart, N.P., Zakarias, S.: Multiparty computation from
somewhat homomorphic encryption. In: Advances in Cryptology – CRYPTO’12.
LNCS, vol. 7417, pp. 643–662. Springer (2012)

8. Earle, L.G.: Latched carry-save adder. IBM Technical Disclosure Bulletin 7(10),

909–910 (1965)

9. Erkin, Z., Franz, M., Guajardo, J., Katzenbeisser, S., Lagendijk, I., Toft, T.:
Privacy-preserving face recognition. In: Privacy Enhancing Technologies Sympo-
sium (PETS’09). LNCS, vol. 5672, pp. 235–253. Springer (2009)

10. Garay, J., Schoenmakers, B., Villegas, J.: Practical and secure solutions for integer
comparison. In: Public Key Cryptography (PKC’07). LNCS, vol. 4450, pp. 330–
342. Springer (2007)

11. Goldreich, O.: Foundations of Cryptography, vol. 2: Basic Applications. Cambridge

University Press (2004)

12. Goldreich, O., Micali, S., Wigderson, A.: How to play any mental game or a com-
pleteness theorem for protocols with honest majority. In: Symposium on Theory
of Computing (STOC’87). pp. 218–229. ACM (1987)

13. Hazay, C., Lindell, Y.: Eﬃcient Secure Two-Party Protocols: Techniques and Con-

structions. Springer, 1st edn. (2010)

14. Henecka, W., K¨ogl, S., Sadeghi, A.R., Schneider, T., Wehrenberg, I.: TASTY: Tool
for Automating Secure Two-partY computations. In: Computer and Communica-
tions Security (CCS’10). pp. 451–462. ACM (2010)

14

15. Huang, Y., Evans, D., Katz, J., Malka, L.: Faster secure two-party computation

using garbled circuits. In: Security Symposium. USENIX (2011)

16. Ishai, Y., Kilian, J., Nissim, K., Petrank, E.: Extending oblivious transfers eﬃ-
ciently. In: Advances in Cryptology – CRYPTO’03. LNCS, vol. 2729, pp. 145–161.
Springer (2003)

17. Kerschbaum, F.: Automatically optimizing secure computation. In: Computer and

Communications Security (CCS’11). pp. 703–714. ACM (2011)

18. Kolesnikov, V., Sadeghi, A.R., Schneider, T.: Improved garbled circuit building
blocks and applications to auctions and computing minima. In: Cryptology And
Network Security (CANS’09). LNCS, vol. 5888, pp. 1–20. Springer (2009)

19. Kolesnikov, V., Schneider, T.: Improved garbled circuit: Free XOR gates and appli-
cations. In: International Colloquium on Automata, Languages and Programming
(ICALP’08). LNCS, vol. 5126, pp. 486–498. Springer (2008)

20. Kreuter, B., Shelat, A., Shen, C.H.: Billion-gate secure computation with malicious

adversaries. In: Security Symposium. USENIX (2012)

21. Ladner, R.E., Fischer, M.J.: Parallel preﬁx computation. Journal of the ACM 27(4),

831–838 (1980)

22. Li, B., Li, H., Xu, G., Xu, H.: Eﬃcient reduction of 1 out of n oblivious transfers

in random oracle model. Cryptology ePrint Archive, Report 2005/279 (2005)

23. Lindell, Y., Pinkas, B., Smart, N.P.: Implementing two-party computation eﬃ-
ciently with security against malicious adversaries. In: Security and Cryptography
for Networks (SCN’08). LNCS, vol. 5229, pp. 2–20. Springer (2008)

24. Malkhi, D., Nisan, N., Pinkas, B., Sella, Y.: Fairplay — a secure two-party com-

putation system. In: Security Symposium. pp. 287–302. USENIX (2004)

25. Naor, M., Pinkas, B.: Computationally secure oblivious transfer. Journal of Cryp-

tology 18(1), 1–35 (2005)

26. Naor, M., Pinkas, B., Sumner, R.: Privacy preserving auctions and mechanism

design. In: Electronic Commerce (EC’99). pp. 129–139. ACM (1999)

27. Nielsen, J.B., Nordholt, P.S., Orlandi, C., Burra, S.S.: A new approach to practical
active-secure two-party computation. In: Advances in Cryptology – CRYPTO’12.
LNCS, vol. 7417, pp. 681–700. Springer (2012)

28. Osadchy, M., Pinkas, B., Jarrous, A., Moskovich, B.: SCiFI - a system for secure
face identiﬁcation. In: Symp. on Security and Privacy. pp. 239–254. IEEE (2010)
29. Pinkas, B., Schneider, T., Smart, N.P., Williams, S.C.: Secure two-party computa-
tion is practical. In: Advances in Cryptology – ASIACRYPT’09. LNCS, vol. 5912,
pp. 250–267. Springer (2009)

30. Sadeghi, A.R., Schneider, T., Wehrenberg, I.: Eﬃcient privacy-preserving face
recognition. In: International Conference on Information Security and Cryptology
(ICISC’09). LNCS, vol. 5984, pp. 229–244. Springer (2009)

31. Savage, J.E.: Models of Computation: Exploring the Power of Computing. Addison-

Wesley Pub, Boston, MA, USA, 1st edn. (1997)

32. Sklansky, J.: An evaluation of several two-summand binary adders. IRE Transac-

tions on Electronic Computers EC-9(2), 213–226 (1960)

33. Yao, A.C.: How to generate and exchange secrets. In: Foundations of Computer

Science (FOCS’86). pp. 162–167. IEEE (1986)

34. Yoo, J.T., Smith, K.F., Gopalakrishnan, G.: A fast parallel squarer based on divide-

and-conquer. IEEE Journal of Solid-State Circuits 32, 909–912 (1995)

15

A Summary of Circuit Building Blocks

Circuit
Addition
Ripple-carry ADD/SUB(cid:96)
Ladner-Fischer ADD(cid:96)
LF subtraction SUB(cid:96)
Carry-save ADD((cid:96),3)
CSA
RC network ADD((cid:96),n)
RC

LF

LF

RC

CSA network ADD((cid:96),n)
CSA

CSN

RC

LF

RC

DC

Multiplication
RCN school method MUL(cid:96)
CSN school method MUL(cid:96)
RC squaring SQR(cid:96)
LF squaring SQR(cid:96)
Comparison
Equality EQ(cid:96)
Sequential greater than GT(cid:96)
S
D&C greater than GT(cid:96)
Selection
Multiplexer MUX(cid:96)
Minimum MIN((cid:96),n)
Minimum index MIN((cid:96),n)
IDX
Set Operations
Set union ∪(cid:96)
Set intersection ∩(cid:96)
Set inclusion ⊆(cid:96)
Count
Full Adder count CNT(cid:96)
F A
Boyar-Peralta count CNT(cid:96)
Distances
Manhattan distance DST(cid:96)
M

BP

Euclidean distance DST(cid:96)
E

Size S

Depth D

(cid:96)

1.25(cid:96)(cid:100)log2 (cid:96)(cid:101) + (cid:96)
1.25(cid:96)(cid:100)log2 (cid:96)(cid:101) + 2(cid:96)
(cid:96) + S(ADD(cid:96))

(cid:96)n − (cid:96) + n − (cid:100)log2 n(cid:101) − 1
(cid:96)n − 2(cid:96) + n − (cid:100)log2 n(cid:101)
+S(ADD(cid:96)+(cid:100)log2 n(cid:101)
)

LF

(cid:96)

2(cid:100)log2 (cid:96)(cid:101) + 1
2(cid:100)log2 (cid:96)(cid:101) + 2
D(ADD(cid:96))+1
(cid:100)log2 n − 1(cid:101) + (cid:96)
(cid:100)log2 n − 1(cid:101)
+D(ADD(cid:96)+(cid:100)log2 n(cid:101)

LF

)

2(cid:96)2 − (cid:96)
(cid:96)2 − (cid:96)

2(cid:96)2 + 1.25(cid:96)(cid:100)log2 (cid:96)(cid:101) − (cid:96) + 2
(cid:96)2 + 1.25(cid:96)(cid:100)log2 (cid:96)(cid:101) − 1.5(cid:96) − 2

(cid:96) − 1

(cid:96)

3(cid:96) − (cid:100)log2 (cid:96)(cid:101) − 2

2(cid:96) − 1
2(cid:96) − 3

3(cid:100)log2 (cid:96)(cid:101) + 4
3(cid:100)log2 (cid:96)(cid:101) + 3

(cid:100)log2 (cid:96)(cid:101)
(cid:100)log2 (cid:96)(cid:101) + 1

(cid:96)

(cid:96)

(n − 1)(S(GT(cid:96))+(cid:96))

(n − 1)(S(GT(cid:96))+(cid:96) + (cid:100)log2 n(cid:101))

(cid:96)
(cid:96)

2(cid:96) − 1

2(cid:96) − (cid:100)log2 (cid:96)(cid:101) − 2

(cid:96) − dH ((cid:96))

1

(cid:100)log2 n(cid:101)(D(GT(cid:96))+1)
(cid:100)log2 n(cid:101)(D(GT(cid:96))+1)

1
1

(cid:100)log2 (cid:96)(cid:101) + 1
(cid:100)log2 (cid:96)(cid:101)
(cid:98)log2 (cid:96)(cid:99)

2S(SUB(cid:96))+S(ADD((cid:96),3))+1 D(SUB(cid:96))+D(ADD((cid:96),3))+1

2S(SUB(cid:96))+2S(SQR(cid:96))

D(SUB(cid:96))

+D(SQR(cid:96))+3
Table 7: Size and Depth of Circuit Constructions (dH : Hamming weight).

+S(ADD(2(cid:96),4))+2S(MUX(cid:96))

B Depth Eﬃcient Distance Circuits

2, y(cid:96)

B.1 Manhattan Distance
The Manhattan distance DST(cid:96)
(x(cid:96)
vertical moves and is computed as |x(cid:96)
DST(cid:96)
4 multiplexer circuits MUX(cid:96) (cf. [18]), 2 GT(cid:96)
(cf. [18]), and one ADD(cid:96)

1) and p2 =
2) is the distance in a two dimensional space allowing only horizontal and
2|. [5] give such a circuit
M,C) = 2(cid:96) + 2. They use
RC circuits

M between two points p1 = (x(cid:96)

1 − y(cid:96)
M,C) = 9(cid:96) and depth D(DST(cid:96)
RC circuit (§3.1).

2| + |y(cid:96)
S circuits (§3.3), 2 SUB(cid:96)

M,C with size S(DST(cid:96)

1 − x(cid:96)

1, y(cid:96)

16

Optimization. We build a more eﬃcient Manhattan distance circuit DST(cid:96)

M as

2),

1, x(cid:96)

x(cid:96)+1 = SUB(cid:96)(x(cid:96)
1 = (x(cid:96)+1||x(cid:96)+1||...)(cid:96) ⊕ (x(cid:96)...1)(cid:96),
b(cid:96)
DST(cid:96)
1, b(cid:96)

M (p1, p2) = ADD((cid:96),3)(b(cid:96)

1, y(cid:96)
2)

y(cid:96)+1 = SUB(cid:96)(y(cid:96)
2 = (y(cid:96)+1||y(cid:96)+1||...)(cid:96) ⊕ (y(cid:96)...1)(cid:96)
b(cid:96)
2, 0(cid:96)−2||x(cid:96)+1 ∧ y(cid:96)+1||x(cid:96)+1 ⊕ y(cid:96)+1).

We can choose between the size-optimized Ripple-carry and the depth-opti-
mized Ladner-Fischer instantiations of SUB(cid:96) and ADD(cid:96) (§3.1). Using the Ripple-
M,RC with S(DST(cid:96)
carry adder yields DST(cid:96)
M,RC)
= 2(cid:96) + 2. The Ladner-Fischer variant DST(cid:96)
M,LF )
= 3.75(cid:96)(cid:100)log2 (cid:96)(cid:101) + 7(cid:96) + 1 and D(DST(cid:96)

M,RC) = 4(cid:96) + 1 and D(DST(cid:96)
M,LF has approximately S(DST(cid:96)

M,LF ) = 4(cid:100)log2 (cid:96)(cid:101) + 6.

B.2 Euclidean Distance

is computed as (cid:112)(x(cid:96)

The Euclidean distance DST(cid:96)
1 − x(cid:96)

2, y(cid:96)
2)
2)2. Since computing the square root is
very ineﬃcient, the square of the Euclidean distance is often used instead (cf. [9]).
We propose an eﬃcient (squared) Euclidean distance circuit DST(cid:96)

E between two points p1 = (x(cid:96)

1) and p2 = (x(cid:96)

2)2 + (y(cid:96)

1 − y(cid:96)

1, y(cid:96)

E as

2),

1, x(cid:96)

x(cid:96)+1 = SUB(cid:96)(x(cid:96)
a(cid:96) = (x(cid:96)+1||x(cid:96)+1||...)(cid:96) ⊕ (x(cid:96)...1)(cid:96),
c(cid:96) = MUX(cid:96)((0||0||...)(cid:96), a(cid:96), x(cid:96)+1),
DST(cid:96)

1, y(cid:96)
2)

y(cid:96)+1 = SUB(cid:96)(y(cid:96)
b(cid:96) = (y(cid:96)+1||y(cid:96)+1||...)(cid:96) ⊕ (y(cid:96)...1)(cid:96)
d(cid:96) = MUX(cid:96)((0||0||...)(cid:96), b(cid:96), y(cid:96)+1)

E(p1, p2) = ADD(2(cid:96),4)(SQR(cid:96)(a(cid:96)), c(cid:96)||x(cid:96)+1, SQR(cid:96)(b(cid:96)), d(cid:96)||y(cid:96)+1).

where MUX(cid:96)((0||0||...)(cid:96), a(cid:96), x(cid:96)+1) is a multiplexer that selects (0||0||...)(cid:96) if x(cid:96)+1
is 0, and a(cid:96) else. Note that adding c(cid:96)||x(cid:96)+1 and d(cid:96)||y(cid:96)+1 in the last step can be
done as part of an addition network (§3.1.2), requiring only 2(cid:96)+2 additional AND
gates and a constant overhead in depth. DST(cid:96)
E can be instantiated with depth
or size eﬃcieny in mind. The size-eﬃcient variant DST(cid:96)
E,RC uses the Ripple-
carry adder and has size S(DST(cid:96)
E,RC)
= 3(cid:96) + 2. The depth-eﬃcient variant DST(cid:96)
E,LF uses the Ladner-Fischer adder
and has S(DST(cid:96)
E,LF )
= 5(cid:100)log2 (cid:96)(cid:101) + 9.

E,RC) = 2(cid:96)2 + 6(cid:96) + 2 and depth D(DST(cid:96)
E,LF ) = 2(cid:96)2 + (7.5(cid:96) + 2)(cid:100)log2 (cid:96)(cid:101) + 11(cid:96) − 5 and D(DST(cid:96)

C Mobile Social Network Circuit

The mobile social network circuit MSN(((cid:96),m),N ) has two steps. First, the Manhat-
tan distance between U and each user Ui in the database is computed and com-
pared to the threshold δm+1, resulting in a bit ci = GEm+1(δm+1, DSTm
M (Lr, Li))
which is used to multiplex between 0 and the size of the set intersection as
si=MUX(cid:100)log2 (cid:96)(cid:101)(0(cid:100)log2 (cid:96)(cid:101),CNT(cid:96)(∩(cid:96)(Hr, Hi)), ci), where MUX is a multiplexer cir-
cuit (cf. [18]) and ∩ is a circuit for set-intersection (cf. [5]). Next, the index k

17

C

C

IDX

of the user Uk with maximum value si is determined using the MAXIDX cir-
cuit (cf. [18]): MSN(((cid:96),m),N )(H1...N , L1...N ) = MAX((cid:100)log2 (cid:96)(cid:101),N )
(s1...N ). The origi-
nal circuit MSNC in [5] has approximately size S(MSN(((cid:96),m),N )
)= N (10m + 3(cid:96) +
)= 2m+(cid:100)log2 N(cid:101)((cid:100)log2 (cid:96)(cid:101)+1)+7.
2(cid:100)log2 (cid:96)(cid:101)+(cid:100)log2 N(cid:101)) and depth D(MSN(((cid:96),m),N )
Using the optimized circuit building blocks CNTBP (§3.4), DSTM,RC (§B.1),
and GTS (§3.3) we obtain a size-eﬃcient variant MSNS with approximately size
) = N (5m + 2(cid:96) + 3(cid:100)log2 (cid:96) + 1(cid:101) +(cid:100)log2 N(cid:101)− dH ((cid:96)) + 2) and depth
S(MSN(((cid:96),m),N )
) = 2m + (cid:100)log2 N(cid:101)((cid:100)log2 (cid:96) + 1(cid:101) + 1) + 4. Alternatively, using
D(MSN(((cid:96),m),N )
DSTM,LF (§B.1) and GEDC (§3.3) yields a depth-eﬃcient variant MSND which
)= N (3.75m(cid:100)log2 m(cid:101)+9m+3(cid:96)+4(cid:100)log2 (cid:96)+1(cid:101)+(cid:100)log2 N(cid:101))
has size S(MSN(((cid:96),m),N )
)= 5(cid:100)log2 m(cid:101) + (cid:100)log2 N(cid:101)((cid:100)log2(cid:100)log2 (cid:96) + 1(cid:101)(cid:101) + 2) + 8.
and depth D(MSN(((cid:96),m),N )
The diﬀerence between the two circuits is that the size of the depth-eﬃcient
circuit is larger by approximately N (3.75m(cid:100)log2 m(cid:101) + 4m + (cid:96)) whereas its depth
decreases logarithmically in m and log2 (cid:96).

D

D

S

S

D Face Recognition Circuit

j=1 ui,jΓj −(cid:80)N

for i = 1, . . . , K: ωi = (cid:80)N
Eigenfaces ui,j and the average face Ψ and locally precomputes −(cid:80)N
projected faces Ω1, ..., ΩM is computed as Dj = (cid:80)K

The circuit for face recognition FR implements the Eigenface recognition algo-
rithm (cf. [30] for a detailed description) by ﬁrst projecting the face image Γ into
the K-dimensional Eigenface space. The projection is performed by computing
j=1 ui,jΨj where the server inputs the
j=1 ui,jΨj.
Afterwards, the square of the Euclidean distance between the ωi and the server’s
i=1(Ωj,i − ωi)2, for j =
1, . . . , M . Finally, the minimum distance Dmin is selected and compared to a
pre-determined threshold τ , input by the server. If Dmin ≤ τ the client learns
jmin and ⊥ otherwise.
As squaring is cheaper than multiplying (cf. §3.2), we optimize computation
i,j−Γ 2
.
Although this form might look more complex at a ﬁrst glance, the resulting cir-
cuit requires only around half the number of AND gates compared to [30]. Using
i,j and

of the projection phase by computing (cid:80)N
the optimization of [17], the server locally computes and inputs −(cid:80)N
the client locally computes and inputs −(cid:80)N

j=1 ui,jΓj as (cid:80)N

(ui,j +Γj )2−u2

j=1 u2

j=1

2

j

As building blocks we use a generalization of the Euclidean distance circuit
DSTE (§B.2) to K dimensions, ADDCSA and ADDRC (§3.1), GTDC (§3.3), and
a circuit for computing the minimum index MINIDX,DC (cf. [18]).

j=1 Γ 2
j .

18

