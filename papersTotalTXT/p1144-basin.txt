Automated Symbolic Proofs of Observational Equivalence

David Basin

Inst. of Information Security
Dept. of Computer Science

ETH Zurich, Switzerland
basin@inf.ethz.ch

Jannik Dreier

Inst. of Information Security
Dept. of Computer Science
jannik.dreier@inf.ethz.ch

ETH Zurich, Switzerland

Ralf Sasse

Inst. of Information Security
Dept. of Computer Science
ETH Zurich, Switzerland
ralf.sasse@inf.ethz.ch

ABSTRACT
Many cryptographic security deﬁnitions can be naturally
formulated as observational equivalence properties. How-
ever, existing automated tools for verifying the observational
equivalence of cryptographic protocols are limited: they do
not handle protocols with mutable state and an unbounded
number of sessions. We propose a novel deﬁnition of obser-
vational equivalence for multiset rewriting systems. We then
extend the Tamarin prover, based on multiset rewriting, to
prove the observational equivalence of protocols with muta-
ble state, an unbounded number of sessions, and equational
theories such as Diﬃe-Hellman exponentiation. We demon-
strate its eﬀectiveness on case studies, including a stateful
TPM protocol.

Categories and Subject Descriptors
D.2.4 [Software/Program Veriﬁcation]: Formal meth-
ods; K.4.4 [Electronic Commerce]: Security

General Terms
Security, Veriﬁcation

Keywords
Protocol veriﬁcation, observational equivalence, symbolic model

1.

INTRODUCTION

Security protocols are the backbone of secure communi-
cation in open networks. It is well known that their design
is error-prone and formal proofs can increase conﬁdence in
their correctness. Most tool-supported proofs have focused
on trace properties, like secrecy as reachability and authenti-
cation as correspondence. But observational equivalence has
received increasing attention and it is frequently used to ex-
press security properties of cryptographic protocols. Exam-
ples include stronger notions of secrecy and privacy-related
properties of voting and auctions [12, 14, 15, 16], game-based

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813662.

notions such as ciphertext indistinguishability [5], and au-
thenticated key-exchange security [6, 18].

Our focus in this paper is on symbolic models [4] for ob-
servational equivalence. The key advantage of using a sym-
bolic model is that it enables a higher degree of automation
in tools [9, 11, 8, 7, 25] for protocol analysis. These tools can
quickly ﬁnd errors in protocols or demonstrate their correct-
ness with respect to symbolic abstractions. Moreover, they
do not require a manual, tedious, and error-prone proof for
each protocol. Unfortunately, none of the above tools are
capable of analyzing protocols with mutable state for an
unbounded number of sessions with respect to a security
property based on observational equivalence. Note that mu-
table state is a key ingredient for many kinds of protocols
and systems, for example to specify and analyze security
APIs for hardware security modules [19].

In this paper, we develop a novel and general deﬁnition of
observational equivalence in the symbolic setting of multiset
rewriting systems. We present an algorithm suitable for pro-
tocols with mutable state, an unbounded number of sessions,
as well as equational properties of the cryptographic opera-
tions, such as Diﬃe-Hellman exponentiation. Our algorithm
is sound but not complete, yet it succeeds on a large class of
protocols. We illustrate this through case studies using our
implementation of the algorithm in the Tamarin prover.

As case studies we verify the untraceability of an RFID
protocol, and ﬁnd an attack on the TPM Envelope protocol
when using deterministic encryption. Note that some proto-
cols, such as TPM Envelope, have been analyzed before with
symbolic methods [13]. However, their analyses were carried
out with respect to weaker trace-based security properties
such as the unreachability of a state where the adversary
can derive secrets. Formulating security properties in terms
of observational equivalence is much closer to the properties
used in game-based cryptographic proofs than trace prop-
erties are. For example, game-based protocol analysis often
uses the standard test [21] of distinguishing real–or–random,
where the adversary is unable to distinguish the real secret
from an unrelated randomly generated value.

Contribution. We give a novel deﬁnition of observational
equivalence in the multiset rewriting framework and an as-
sociated algorithm which is the ﬁrst that supports mutable
state, an unbounded number of sessions, and Diﬃe-Hellman
exponentiation. We implement this algorithm in an exten-
sion of the Tamarin prover and we demonstrate its practi-
cality in diﬀerent case studies that illustrate its features.
The resulting proofs are largely automated, with limited
manual input needed to select proof strategies in some cases.

1144Structure. We introduce our general system model based
on multiset rewriting in Section 2. We motivate and de-
ﬁne observational equivalence for multiset rewrite systems
in Section 3. We show how to prove observational equiv-
alence in Section 4 and sketch its implementation in the
Tamarin prover. Afterwards we present our case studies in
Section 5. We close with related work and draw conclusions
in Section 6.

2. PRELIMINARIES AND MODEL
Let S∗ denote the set of sequences over S. For a sequence
s, we write si for its i-th element, |s| for its length, and
idx(s) = {1, . . . ,|s|} for the set of its indices. We use []
to denote the empty sequence, [s1, . . . , sk] to denote the se-
quence s of length k, and s · s(cid:48) to denote the concatenation
of the sequences s and s(cid:48).

We specify properties of functions by equations. Given a
signature ΣFun of functions and a set V of variables, TΣFun (V )
denotes the set of terms built using functions from ΣFun and
variables from V . Terms without variables are called ground
terms and denoted TΣFun . An equation over the signature
ΣFun is an unordered pair of terms s, t ∈ TΣFun (V ), written
s (cid:39) t. An equational presentation is a pair E = (ΣFun; E) of
a signature ΣFun and a set of equations E. The correspond-
ing equational theory =E is the smallest ΣFun-congruence
containing all instances of the equations in E. We often
leave the signature ΣFun implicit and identify the equations
E with the equational presentation E. Similarly, we use =E
for the equational theory =E . We say that two terms s and
t are equal modulo E iﬀ s =E t. We use the subscript E to
denote the usual operations on sets, sequences, and multi-
sets where equality is modulo E instead of syntactic equality.
For example, we write ∈E for set membership modulo E.

Example 1. To model symmetric key encryption, let ΣFun
be the signature consisting of the functions enc(·,·) and
dec(·,·) together with the equation dec(enc(x, k), k) (cid:39) x.

We model systems using multiset rewrite rules. These
rules manipulate multisets of facts which model the current
state of the system, with terms as arguments. Formally,
given a signature ΣFun and a (disjoint) set of fact symbols
ΣFact, we deﬁne Σ = ΣFun ∪ ΣFact, and we deﬁne the set of
facts as F = {F (t1, . . . , tn)|ti ∈ TΣFun , F ∈ ΣFact of arity n}.
We assume that ΣFact is partitioned into linear and persis-
tent fact symbols; a fact F (t1, . . . , tn) is called linear if its
function symbol F is linear, and persistent if F is persis-
tent. Linear facts model resources that can only be con-
sumed once, whereas persistent facts can be consumed as
often as needed. We denote by F (cid:93) the set of ﬁnite multisets
built using facts from F, and by G(cid:93) the set of multisets of
ground facts.

The system’s possible state transitions are modeled by
labeled multiset rewrite rules. A labeled multiset rewrite rule
is a tuple (id, l, a, r), written id : l−−[ a ]→r, where l, a, r ∈ F (cid:93)
and id ∈ I is a unique identiﬁer. Given a rule ri = id :
l−−[ a ]→r, name(ri) = id denotes its name, prems(ri) = l
its premises, acts(ri) = a its actions, and concs(ri) = r its
conclusions. Finally ginsts(R) denotes the ground instances
of a set R of multiset rewrite rules, lfacts(l) is the multiset
of all linear facts in l, and pfacts(l) is the set of all persistent
facts in l. We use mset(s) to highlight that s is a multiset,
and we use set(s) for the interpretation of s as a set, even if

it is a multiset. We use regular set notation {·} for multisets
as well, whenever it is clear from the context whether it is a
set or a multiset.

Example 2. The following multiset rewrite rules describe
a system that constructs terms containing nested applica-
tions of the functions one(·) and two(·) inside a fact built
with the symbol M using the ﬁrst three rules below. Using
the ﬁnal rule, Echeck, the system can compare a constructed
term with the value stored in the InEnv(·) fact.
Env = { Enull : −−[]→M(null),

Eone : M(x)−−[]→M(one(x)),
Etwo : M(x)−−[]→M(two(x)),
Echeck : M(x), InEnv(x)−−[]→OutEnv(true) }

In our semantics of multiset rewriting, we associate each
fact F with a recipe recipe(F ), representing how this fact
was derived. This will be important for deﬁning observa-
tional equivalence later. Speciﬁcally, we deﬁne a sequence
of the premises seq≤(l) and conclusions seq≤(r) of a rule
id : l−−[ a ]→r by ordering all facts under the total order ≤.
Usually, ≤ will just be the lexicographic order, where if the
same fact symbol appears repeatedly, we order the instances
of each such fact lexicographically by the terms inside the
fact. If these terms are also identical, the facts can appear
in any order. Given a rule id : l−−[ a ]→r, for a fact F ∈ r,
where k is the index of F in seq≤(r), and l1, . . . , ln = seq≤(l),
we have

recipe(F ) = idk(newvars(F ), [recipe(l1), . . . , recipe(ln)]),

where newvars(F ) denotes the list of new variables. New
variables are those that appear in F but not in any of the
premises. Thus, we include their instantiations, e.g., [{a/x}]
for the list containing the new variable x instantiated with a.
This list is ordered by the appearance of the new variables
inside F . This deﬁnition requires computing the recipes for
the facts l1, . . . , ln recursively. Moreover, by abuse of nota-
tion, we deﬁne the recipe of a rule id as

recipe(id) = id([newvars(r1), . . . , newvars(rm)],

[recipe(l1), . . . , recipe(ln)]),

where r1, . . . , rm = seq≤(r). It consists of the list of lists of
new variables and the list of all recipes of the premises. We
denote by ρ the set of all recipes of rules.
The semantics of a set of multiset rewrite rules P are given
by a labeled transition relation →P ⊆ G(cid:93) × (G(cid:93) × ρ) × G(cid:93),
deﬁned by the transition rule:

ri = id : l−−[ a ]→r ∈E ginsts(P )
lfacts(l) ⊆(cid:93) S
pfacts(l) ⊆ S

S

set(a)

−−−−−−→

recipe(id)

P ((S \(cid:93) lfacts(l)) ∪(cid:93) mset(r))

Note that the initial state of an LTS derived from multiset
rewrite rules is the empty set of facts ∅. Each transition
transforms a multiset of facts S into a new multiset of facts,
according to the rewrite rule used. Moreover each transition
is labeled by the actions a of the rule, as well as the rule’s
recipe recipe(id). These labels are used in our deﬁnition of
observational equivalence below, for example that each in-
terface transition must be simulated by the same transition.
Since we perform multiset rewriting modulo E, we use ∈E
for the rule instance. As linear facts are consumed upon

1145System Sys

InSys

OutSys

Interface

IF

OutEnv

InEnv

Environment Env

Figure 1: System model

rewriting, we use multiset inclusion, written ⊆(cid:93), to check
that all facts in lfacts(l) occur suﬃciently often in S. For
persistent facts, we only check that each fact in pfacts(l)
occurs in S. To obtain the successor state, we remove the
consumed linear facts and add the generated facts.

Example 3

(Pairs). Consider two systems, where the

ﬁrst system outputs a pair of identical values

SA = { A : −−[]→OutSys((x, x)) }

and the second system may output two diﬀerent values

SB = { B : −−[]→OutSys((x, y)) } .

In SA, we have that

∅ −−−−−−−−→
A([{m/x}],[])

{OutSys((m, m))} .

In SB, we can either take a similar transition

∅ −−−−−−−−−−−→
B([{m/x,m/y}],[])

{OutSys((m, m))}

or alternatively

∅ −−−−−−−−−−−→
B([{m/x,n/y}],[])

{OutSys((m, n))} .

3. OBSERVATIONAL EQUIVALENCE

Observational equivalence expresses that two systems ap-
pear the same to the environment. This can be used to
specify security properties such as the inability of an at-
tacker to distinguish between two instances of a protocol. It
also has applications in system veriﬁcation, for example in
formalizing that the environment sees no diﬀerence between
interacting with an ideal system or a concrete implementa-
tion. To deﬁne observational equivalence, we must model
the system, the environment, and their interface.

In our model, depicted in Fig. 1, we model both the Sys-
tem Sys and the environment Env using multiset rewrite
rules. We require that the sets of facts and rules used by the
system and the environment are disjoint, and that their sig-
natures provide “communication facts” OutSys, InSys, OutEnv,
and InEnv as an interface for interaction. Their interaction
is described by the following interface rules.

OUT = {OU T : OutSys(M )−−[ O ]→InEnv(M )}

IN = {IN : OutEnv(M )−−[ I ]→InSys(M )}
IF = OUT ∪ IN

The OUT rule forwards the system’s output to the environ-
ment’s input and the IN rule forwards the environment’s
output to the system’s input.

In our interface rules, each input and output is labeled
using the action O, for system output, or I, for system
input. We model that the environment can only observe
these interactions, but not the internal state or transitions
within the system, which should be invisible to the environ-
ment. We reﬂect this in the recipes by deﬁning the recipe
of the InEnv(M ) fact as a conclusion of the OUT-rule diﬀer-
ently from other facts in the system or environment rules.
Namely, we deﬁne recipe(InEnv(M )) = OUT1([], x), where x
is a new variable. Similarly we deﬁne the recipe of the rule as
recipe(OUT) = OUT([], x). This replaces the recipe of the
OutSys(M ) fact, which is considered to be internal to the
system, with a variable. Note that this replacement makes
the book-keeping of recipes inside the system unnecessary;
however we keep them in our formalization as it simpliﬁes
the deﬁnition of the LTS as we therefore do not need to
distinguish between system and environment transitions.

Example 4

(Pairs revisited). Consider the two sys-
tems from Example 3 and the following environment, which
can check whether the two values in a pair are equal:
Env = { C : InEnv(x, x)−−[]→OutEnv(true) } .

Then in SA ∪ IF ∪ Env we have

∅ −−−−−−−−→
A([{m/x}],[])
O−−−−−−→
−−−−−−−−−−−→

OUT([],z)

{OutSys((m, m))}

{InEnv((m, m))}

{OutEnv(true)} .
In SB ∪ IF ∪ Env we have similar transitions:
{OutSys((m, m))}

C([],[OUT1([],z)])

∅ −−−−−−−−−−−→
B([{m/x,m/y}],[])
O−−−−−−→
−−−−−−−−−−−→

OUT([],z)

C([],[OUT1([],z)])

{InEnv((m, m))}

{OutEnv(true)} .

Note that the ﬁrst transition has a diﬀerent recipe as we also
must instantiate y, but the output replaces this recipe with a
new variable z, which is the same on both sides. This hides
from the environment how the term was constructed. How-
ever, in SB∪IF ∪Env we also have the following transitions:

∅ −−−−−−−−−−−→
B([{m/x,n/y}],[])
O−−−−−−→

OUT([],z)

{InEnv((m, n))} .

{OutSys((m, n))}

Note that the ﬁrst transition has a diﬀerent recipe as we
instantiate y diﬀerently, but again the output replaces this
recipe with a new variable z, which is the same on both sides.
3.1 Deﬁnition

We formalize observational equivalence in the context of
labeled transition systems (LTS) induced by two multiset
rewrite systems. Since the environment does not know with
which system it is interacting, each transition caused by an
environment rule must be matched by the same rule oper-
ating on facts with the same recipes, ensuring that the en-
vironment makes the same choices in both cases. Otherwise
the environment could trivially distinguish any two systems
by choosing transitions depending on which system it inter-
acts with. Similarly, all interface rules must be matched by

1146themselves, ensuring that an input can only be matched by
an input, and an output only by an output.

In contrast to the above, transitions inside one system can
be matched by any number of transitions in the other system
since the environment cannot observe these steps. This is
reﬂected by the OUT rule, where the recipe of a system
output is removed, ensuring that the environment does not
know how the term was constructed. Note that this still
allows the environment to distinguish both systems if their
behavior on a given input diﬀers, or if they output terms that
can be distinguished by the environment. An example of the
latter is when a transition in the environment requiring the
equality of two terms with the same recipes (i.e., deduced
using the same steps from the same outputs) is possible in
one system, but not in the other.

Definition 1

(Observational Equivalence ≈).

Two sets of multiset rewrite rules SA and SB are observa-
tional equivalent with respect to an environment given by
a set of multiset rewrite rules Env, written SA ≈Env SB,
if, given the LTS deﬁned by the rules SA ∪ IF ∪ Env and
SB ∪ IF ∪ Env, there is a relation R containing the initial
states, such that for all states (SA,SB) ∈ R we have:

1. If SA

r

r

l−→

l(cid:48)−→

A,S(cid:48)

B) ∈ R.

A and r is the recipe of a rule in Env ∪ IF,
S(cid:48)
B ∈ G(cid:93) such that

then there exists actions l(cid:48) ∈ F (cid:93) and S(cid:48)
SB

B, and (S(cid:48)
S(cid:48)
S(cid:48)
A and r is the recipe of a rule in SA, then
there exist recipes r1, . . . , rn ∈ ρ of rules in SB, actions
l1−→
l1, . . . , ln ∈ F (cid:93), n ≥ 0, and S(cid:48)
B) ∈ R.

B ∈ G(cid:93) such that SB

B, and (S(cid:48)
S(cid:48)

A,S(cid:48)

ln−→

l−→

. . .

r1

r

2. If SA

rn

Additionally, we have the same in the other direction:

3. If SB

r

r

l−→

l(cid:48)−→

A,S(cid:48)

B) ∈ R.

B and r is the recipe of a rule in Env ∪ IF,
S(cid:48)
A ∈ G(cid:93) such that

then there exists actions l(cid:48) ∈ F (cid:93) and S(cid:48)
SA

A, and (S(cid:48)
S(cid:48)
S(cid:48)
B and r is the recipe of a rule in SB, then
there exist recipes r1, . . . , rn ∈ ρ of rules in SA, actions
l1, . . . , ln ∈ F (cid:93), n ≥ 0, and S(cid:48)
l1−→
B) ∈ R.

A ∈ G(cid:93) such that SA

S(cid:48)
A, and (S(cid:48)

A,S(cid:48)

ln−→

l−→

. . .

r1

r

4. If SB

rn

3.2 Examples

We now illustrate this deﬁnition on several examples.

Example 5

environment from Example 4. In SB ∪ IF ∪ Env we have

(Pairs). Consider the two systems and the

∅ −−−−−−−−−−−→
B([{m/x,n/y}],[])
O−−−−−−→

OUT([],z)

{InEnv((m, n))} .

{OutSys((m, n))}

The only way for SA ∪ IF ∪ Env to simulate this would be

∅ −−−−−−−−→
A([{m/x}],[])
O−−−−−−→

OUT([],z)

{OutSys((m, m))}

{InEnv((m, m))} .

and potentially further transitions using rule A, adding more
OutSys((m, m)) facts to the state. Note that there can only
be one InEnv((m, m))-fact in the resulting state as the out-
put transition can only be used once. This implies that for
the resulting state S we have ({S},{InEnv((m, n))}) ∈ R.
However we have

S −−−−−−−−−−−→

{OutEnv(true)},

C([],[OUT1([],z)])

but in state {InEnv((m, n))} no transition with the same
recipe is possible, hence SA (cid:54)≈Env SB.

This simple example illustrates that if the environment can
do something on one side, but not on the other, then the two
sides are distinguishable and therefore not observationally
equivalent. The next example illustrates the importance of
recipes in our deﬁnition of observational equivalence.

Example 6. Consider the two systems from Example 4,

but a diﬀerent environment Env(cid:48):

Env(cid:48) = { Ef st : InEnv((x, y))−−[]→M(x),
Esnd : InEnv((x, y))−−[]→M(y),
Ecmp : M(x), M(x)−−[]→OutEnv(true) },

where M(·) is a persistent fact. Intuitively we would expect
that this environment can distinguish SA and SB, as it can
compare the ﬁrst and second value of the tuple. We now try
to apply the same reasoning as in Example 5. Consider

{OutSys((m, n))}

∅ −−−−−−−−−−−→
B([{m/x,n/y}],[])
O−−−−−−→
−−−−−−−−−−−−−→
−−−−−−−−−−−−−→

Ef st([],[OUT1([],z)])

{InEnv((m, n))}
{M(m)}
{M(m), M(n)} .

OUT([],z)

Esnd([],[OUT1([],z)])

In SA ∪ IF ∪ Env(cid:48) this can be simulated as follows:

{OutSys((m, m))}

∅ −−−−−−−−→
A([{m/x}],[])
O−−−−−−→
−−−−−−−−−−−−−→
−−−−−−−−−−−−−→

Ef st([],[OUT1([],z)])

{InEnv((m, m))}
{M(m)}
{M(m), M(m)} .

OUT([],z)

Esnd([],[OUT1([],z)])

Moreover, we can compare the ﬁrst and second value of the
tuple with

{M(m), M(m)} −→

r1

{M(m), M(m), OutEnv(true)} ,

where

r1 = Ecmp([], [Ef st,1([], [OUT1([], z)]),

Esnd,1([], [OUT1([], z)])]) .

This transition cannot be matched by SB ∪ IF ∪ Env(cid:48). Note
however that the following transition is possible for SB∪IF∪
Env(cid:48):

{M(m), M(n)} −→

r2

{M(m), M(n), OutEnv(true)} ,

where

r2 = Ecmp([], [Ef st,1([], [OUT1([], z)]),

Ef st,1([], [OUT1([], z)])]) .

1147The only diﬀerence between the two transition is the diﬀerent
recipe: instead of comparing the ﬁrst and the second value
of the tuple, we simply compared the ﬁrst value to itself, and
therefore they are not observational equivalent. This exam-
ple shows that with a diﬀerent environment the two systems
are still distinguishable.

The next example shows how two diﬀerent systems can be-
have in an equivalent way, and how equations can be used
to model the equivalence of terms.

Example 7

(Coins). Consider a vending machine, in
particular the part that returns coins as change when the
money inserted was not fully spent. For simplicity we con-
sider only 1 e and 2 e coins, represented by the functions
one and two, and a constant null representing no coins.
Now suppose we want to return 3 e. The preferred solution
would be to return two coins: 1 e and 2 e. Yet returning
three 1 e coins is also possible and, moreover, the order of
the coins could be permuted.

Consider again two systems. The ﬁrst system speciﬁes the

optimal behavior of returning just two coins:

SA = { A : −−[]→OutSys(two(one(null))) }.

The second system, representing the actual implementation,
may also return other combinations of coins. It is given by

SB = { B1 : −−[]→OutSys(two(one(null))),
B2 : −−[]→OutSys(one(one(one(null)))),
B3 : −−[]→OutSys(one(two(null)))

} .

We now deﬁne an environment that checks whether the im-
plementation is correct with respect to the speciﬁcation.
Namely, the vending machine returns the same amount of
money using the same coins returned in the same order:
Env = { Enull : −−[]→M(null),

Eone : M(x)−−[]→M(one(x)),
Etwo : M(x)−−[]→M(two(x)),
Echeck : M(x), InEnv(x)−−[]→OutEnv(true) } .
The environment’s test works as follows. Using the ﬁrst
three rules, the environment can build any amount of money
from the two kinds of coins. Then, using the Echeck rule,
this can be compared to the system’s output. Hence, for
SA ≈Env SB to hold, both systems must output the same
amount of money using the same coins in the same order,
otherwise Echeck is applicable only on one side. We have
SA (cid:54)≈Env SB as the amount of money returned is the same,
but the coins may diﬀer: SA can only return two coins,
while SB could also return three. More precisely, the en-
vironment could build the fact M(two(one(null))), and try
to apply the rule Echeck. This would work for the system
SA provided an output was made, but not necessarily for
the system SB as the output could, for example, have been
one(one(one(null))).

Suppose that we add the equation two(x) = one(one(x)),
stating that a 2 e coin is equivalent to two 1 e coins. Then
SA ≈Env SB as the amount of money output by both ma-
chines is the same and two(one(null)) = one(two(null)) =
one(one(one(null))). Hence the environment successfully
checks whether both systems output the same amount of mo-
ney, independent of the coins used.

Naturally we can also have other environments. Assuming

no equations, consider the environment

(cid:48)

= {Ecomp : InEnv(x), InEnv(x)−−[]→OutEnv(true)} .

Env

This environment compares whether two system outputs are
equal, which is not necessarily the case for SB, but holds for
SA.

These examples illustrate the generality of our deﬁnition of
observational equivalence: as it is parametrized by the en-
vironment, it can be instantiated in diﬀerent ways depend-
ing on the application context. In protocol veriﬁcation, this
could for example be used to model diﬀerent types of attack-
ers. Note also that in other process algebras used for proto-
col veriﬁcation, such as the applied π-calculus, the environ-
ment is typically implicitly deﬁned and cannot be changed.

4. PROVING OBSERVATIONAL

EQUIVALENCE

To automate proofs of observational equivalence we intro-

duce the notion of a bi-system.
4.1 Bi-Systems
A bi-system is a multiset rewrite system where terms may
be built using the special operator diﬀ[·,·], indicating two
possible instantiations corresponding to the left and right
subterm. This use of diﬀ operators was ﬁrst introduced in
ProVerif [7] where bi-processes are handled in a similar
fashion. Using diﬀ-terms, one can specify two systems (left
and right) with almost identical rules by one multiset rewrit-
ing system, where the only diﬀerence is how the diﬀ-terms
are instantiated. This simpliﬁes the search for the simulation
relation, as we can simply assume that each rule simulates
itself, modulo the diﬀ-terms. Nevertheless, this notion is
expressive enough to specify many relevant security proper-
ties. These include all the examples mentioned in the intro-
duction: our desired real–or–random test, privacy-related
properties of voting and auctions, indistinguishability prop-
erties such as ciphertext indistinguishability, and authenti-
cated key-exchange security. Moreover, as we show below,
all examples from Section 3 can also be expressed this way.
For S a bi-system, we can obtain its left instance L(S)
by replacing each term diﬀ[M, N ] in S with M . Similarly,
we can obtain S’s right instance R(S) by replacing each
term diﬀ[M, N ] with N . These are both standard multiset
rewrite systems. The goal of the algorithm we give is to
prove that given a bi-system S, L(S) and R(S) are observa-
tionally equivalent.

We now revisit the Examples 3 and 7, starting with the

tuple example.

Example 8

(Tuples with diff). Using diﬀ-terms we
can deﬁne a single bi-system S that combines SA and SB as

S = { AB : −−[]→OutSys((x, diﬀ[x, y])) },
where L(S) = SA and R(S) = SB, as in Example 3.

Example 9

(Coins with diff). We create a bi-system
S that merges SA and SB. The left-hand side of each diﬀ-
term is the speciﬁcation, while the right-hand side is the im-
plementation:

S = { AB1 : −−[]→OutSys(diﬀ[two(one(null)),
two(one(null))]),
AB2 : −−[]→OutSys(diﬀ[two(one(null)),
one(one(one(null)))]),
AB3 : −−[]→OutSys(diﬀ[two(one(null)),

one(two(null))]) }.

1148Keeping the environment Env identical to Example 7 results
in the bi-system S not satisfying observational equivalence.
But, if we add the equation two(x) = one(one(x)), then S
satisﬁes observational equivalence.
4.2 Dependency Graph Equivalence

To simplify reasoning, our algorithm works with depen-
dency graphs rather than with the labeled transition sys-
tem. Dependency graphs are a data structure that formalize
the entire structure of a system execution, including which
facts originate from which rules, similar to recipes. We
have several reasons for using dependency graphs. First,
by capturing the entire system state, they are well-suited
for automated analysis using constraint solving. Second,
this representation is already implemented and supported
in the Tamarin prover [24, 22], which we extend. Finally,
dependency graphs naturally give rise to an equivalence re-
lation that implies observational equivalence; however, it is
substantially simpler to verify.

Definition 2

(Dependency Graph). Let E be an
equational theory, R be a set of labeled multiset rewriting
protocol rules, and Env an environment. We say that the
pair dg = (I, D) is a dependency graph modulo E for R if
I ∈E ginsts(R ∪ IF ∪ Env)∗, D ∈ P(N2 × N2), and dg sat-
isfy the three conditions below. To state these conditions, we
deﬁne the following notions. Let I be a sequence of rule in-
stances whose indices, idx(I), represent the nodes of dg. We
call D the edges of dg and write (i, u) (cid:26) (j, v) for the edge
((i, u), (j, v)). A conclusion of dg is a pair (i, u) such that i
is a node of dg and u ∈ idx(concs(Ii)). The corresponding
conclusion fact is (concs(Ii))u. A premise of dg is a pair
(j, v) such that j is a node of dg and v ∈ idx(prems(Ij)).
The corresponding premise fact is (prems(Ij))v. A conclu-
sion or premise is linear if its fact is linear.
DG1 For every edge (i, u) (cid:26) (j, v) ∈ D, it holds that i < j
and the conclusion fact of (i, u) is equal modulo E to
the premise fact of (j, v).

DG2 Every premise of dg has exactly one incoming edge.

DG3 Every linear conclusion of dg has at most one outgoing

edge.

We denote the set of all dependency graphs of R modulo E
by dgraphsE(R). Moreover, by state(dg) we denote the set of
all conclusion facts in dg that are either persistent or (if they
are linear) do not have an outgoing edge. This intuitively
corresponds to the state of the LTS after all transitions in
the dependency graph have been executed.

Figures 2 and 3 contain dependency graphs corresponding

to evaluations based on Examples 6 and 7, respectively.

Using dependency graphs, we can deﬁne a stronger version
of observational equivalence, which is used by our algorithm.
For this, we deﬁne the dependency graphs of a rule, which
intuitively corresponds to the set of all dependency graphs
having the rule as root. Given a rule r ∈ R ∪ IF ∪ Env,
its dependency graphs dgraphsE(r) contain all dependency
graphs where the last node, i.e., the node (i, u) with max-
imal i, is an instance of the rule r. Moreover, by new diﬀ-
variables we mean the new variables of a rule that only ap-
pear in one of its two diﬀ-variants, e.g., y in the case of a
rule Out((x, diﬀ[x, y])), where x and y are new variables.

A:O

OutSys((m, m))

Out: O

OutSys((m, m))
InEnv((m, m))

Ef st:

InEnv((m, m))

M(m)

Esnd:

InEnv((m, m))

M(m)

Ecmp:

M(m) M(m)
OutEnv(true)

Figure 2: Dependency graph for Example 6

Enull:

M(null)

Eone:

M(null)

M(one(null))

A: O

OutSys(two(one(null)))

Etwo:

M(one(null))

M(two(one(null)))

Out: O

OutSys(two(one(null)))
InEnv(two(one(null)))

Echeck:

M(two(one(null)))

InEnv(two(one(null)))

OutEnv(true)

Figure 3: Dependency graph for Example 7

Finally, we deﬁne the mirrors of dependency graphs. In-
tuitively, given a dependency graph, its mirrors contain all
dependency graphs on the other side of the bi-system with
the same structure, notably the same edges and where the
nodes are instances (potentially diﬀerent due to the diﬀ-
terms) of the same rules.

Suppose that for all dependency graphs of all rules, the
set of its mirrors contains all “necessary” instances. We then
know that – independently of the current state of the system
– if a transition is enabled by a rule on one side, the same
rule also enables a transition on the other side, implying
observational equivalence. This is formalized in Deﬁnition 4
below as Dependency Graph Equivalence.

Definition 3

(Mirroring Dependency Graphs).

Let S be a protocol bi-system and Env be an environment.
Consider the multiset rewrite systems L = L(S) ∪ IF ∪ Env
and R = R(S) ∪ IF ∪ Env.
Let dgL = (IL, DL) ∈ dgraphs(L) be a dependency graph.
We denote by mirrors(dgL) the set of all dependency graphs
dgR = (IR, DR) ∈ dgraphs(R), such that DR = DL, |IL| =
|IR|, idx(IL) = idx(IR) and for all i ∈ idx(IL) the ground
rule instances (IL)i and (IR)i are ground instances of the
same rules, i.e., rules with the same identiﬁer, where new
variables of rules keep their instantiation.
The set of mirrors of a dependency graph dgR = (IR, DR) ∈
dgraphs(R), denoted by mirrors(dgR), is deﬁned analogously,
replacing R by L uniformly in the above deﬁnition.

Using these notions, we now deﬁne dependency graph equiv-

1149alence. Intuitively, this deﬁnition captures that for all de-
pendency graphs on one side of the bi-system, there is a
mirroring dependency graph on the other side that respects
its instantiations of new diﬀ-variables.

Definition 4

(Dependency Graph Equivalence).
Let S be a bi-system. Consider the multiset rewrite systems
L = L(S) ∪ IF ∪ Env and R = R(S) ∪ IF ∪ Env. We
say that L and R are dependency graph equivalent, written
L(S) ∼DG,Env R(S), if for all dependency graphs dg of rules
r ∈ L ∪ R, the set mirrors(dg) is non-empty and contains
dependency graphs for all possible instantiations of new diﬀ-
variables.

Note that this deﬁnition requires that if, for example,
there are new variables in the rules R not appearing in
the rules from L used in dg, then mirrors(dg) must contain
instances for all possible instantiations of these variables.
For instance, in the case of a rule producing a conclusion
Out((x, diﬀ[x, y])), then for all possible instantiations of y,
an instance must be in mirrors(dg).

It turns out that dependency graph equivalence is a suf-
ﬁcient (but not necessary) criterion for observational equiv-
alence.
Intuitively, dependency graph equivalence veriﬁes
that the left-hand side instance of a rule can always be sim-
ulated by its right-hand side, and vice versa.

Theorem 1. Let S be a bi-system.

R(S) then L(S) ≈Env R(S).

If L(S) ∼DG,Env

Proof. Consider the multiset rewrite systems L = L(S)∪

IF ∪ Env and R = R(S) ∪ IF ∪ Env, and the relation R:
R = {(SA,SB) | SA = state(dgL),SB = state(dgR),
∪ {(SA,SB) | SA = state(dgL),SB = state(dgR),

dgR ∈ mirrors(dgL), dgL ∈ dgraphs(L)}
dgL ∈ mirrors(dgR), dgR ∈ dgraphs(R)}.
First note that (∅,∅) ∈ R. We now show that R is an
observational equivalence relation as deﬁned in Deﬁnition 1.
For this, we must show that for all states (SA,SB) ∈ R we
have:

1. If SA

r

l−→

A and r is the recipe of a rule in IF ∪ Env,
S(cid:48)
B ∈ G(cid:93) such

then there exists actions l(cid:48) ∈ F (cid:93) and S(cid:48)
that SB

B, and (S(cid:48)
S(cid:48)

B) ∈ R.

A,S(cid:48)

l(cid:48)−→

r

2. If SA

r

l−→

S(cid:48)
A and r is the recipe of a rule in SA, then
there exist recipes r1, . . . , rn ∈ ρ of rules in SB, actions
l1, . . . , ln ∈ F (cid:93), n ≥ 0, and S(cid:48)
l1−→
B) ∈ R.

B ∈ G(cid:93) such that SB

S(cid:48)
B, and (S(cid:48)

A,S(cid:48)

ln−→

. . .

r1

rn

We distinguish the following cases:
l−→

1. Assume (SA,SB) ∈ R, SA

r

S(cid:48)
A for a rule instance
ri, and r is the recipe of a rule in IF ∪ Env. Then,
by the deﬁnition of R, there is a dependency graph
dgL ∈ dgraphs(L) with SA = state(dgL), and a depen-
dency graph dgR ∈ dgraphs(R) with SB = state(dgR).
A is possible in SA, dgL
Since the transition SA
S(cid:48)
can be extended to dg(cid:48)
L with the rule instance ri cor-
L) = S(cid:48)
responding to this transition, and state(dg(cid:48)
A.

l−→

r

R ∈ mirrors(dg(cid:48)
L), dg(cid:48)

L ∈ dgraphs(L), and by L(S) ∼DG,Env R(S)
Then dg(cid:48)
we have that for all possible instantiations of new diﬀ
R ∈
variables, the corresponding dependency graph dg(cid:48)
dgraphs(R). By the deﬁnition of R, in dgR the in-
stantiations of the new variables (including the new
diﬀ-variables) correspond to the instantiations of some
dg(cid:48)
L). Then, by the construction of
mirrors(dg(cid:48)
R is identical to dgR except for the
last rule instance ri(cid:48). Moreover, by the construction
of mirrors(dg(cid:48)
L), ri(cid:48) is an instance of the rule with the
same identiﬁer. Since the dependency graph dg(cid:48)
R has
L and all rules in IF ∪ Env
the same structure D as dg(cid:48)
have no new diﬀ-variables, there exists a transition
SB
(S(cid:48)
graphs for S(cid:48)
The symmetric case is analogous.

l(cid:48)−→
S(cid:48)
B with the same recipe as ri. Moreover,
A,S(cid:48)
B) ∈ R since there are mirroring dependency

A and S(cid:48)
B.

r

2. Alternatively, assume (SA,SB) ∈ R, SA

r

r

l−→

l−→

L) = S(cid:48)

A. Then dg(cid:48)

S(cid:48)
A is possible, dgL can be extended to dg(cid:48)

S(cid:48)
A, and r
is the recipe of a rule in L(S). Then, by the deﬁnition
of R, there is a dependency graph dgL ∈ dgraphs(L)
with SA = state(dgL). Since in this state the transition
SA
L with
the rule instance ri corresponding to this transition,
L ∈ dgraphs(L), and by
and state(dg(cid:48)
L(S) ∼DG,Env R(S) we have that for all possible in-
stantiations of new diﬀ variables, the corresponding de-
R ∈ dgraphs(R). By the deﬁnition
pendency graph dg(cid:48)
of R, there is a dependency graph dgR ∈ dgraphs(R)
with SB = state(dgR), where the instantiations of the
new variables (including the new diﬀ-variables) corre-
R ∈ mirrors(dg(cid:48)
spond to the instantiations of some dg(cid:48)
L).
Then, by the construction of mirrors(dg(cid:48)
L), this graph
dg(cid:48)
R is identical to dgR except for the last rule instance.
By assumption, ri was an instance of a rule in L(S).
Therefore, by the construction of mirrors(dg(cid:48)
L), the
last rule instance ri(cid:48) in dg(cid:48)
R is an instance of the rule
with the same identiﬁer. Hence there exists a transi-
B) ∈ R since there
tion SB
are mirroring dependency graphs for S(cid:48)
Again, the symmetric case is analogous.

B. Moreover, (S(cid:48)

A and S(cid:48)
B.

l(cid:48)−→
r(cid:48) S(cid:48)

A,S(cid:48)

As shown in [24], we can use constraint solving to ﬁnd
(restricted) normal dependency graphs; for a detailed dis-
cussion about the constraint solving procedure used and the
link to restricted normal dependency graphs, see the ex-
tended version of this paper [1]. This provides the basis
for our algorithm, depicted in Figure 4, which determines
whether L(S) ∼DG R(S) holds. For each rule r in L(S),
R(S), and the environment, the algorithm ﬁnds all corre-
sponding normal dependency graphs with r as a root using
constraint solving. For each of these dependency graphs,
it then checks whether the set of mirrors contains all in-
stances required for normal dependency graph equivalence.
If this holds, it reports that veriﬁcation is successful; other-
wise it returns the dependency graph that lacks a mirroring
instance as a counterexample. Note that these instances are
counterexamples to dependency graph equivalence, but not
necessarily to observational equivalence because of the ap-
proximation requiring that each rule is simulated by itself.

11501: function Verify(S)
RU ← L(S) ∪ R(S) ∪ IF ∪ Env
2:
while RU (cid:54)= ∅ do
3:
4:
5:
6:
7:
8:

choose r ∈ RU , RU ← (RU \ {r})
compute DG← dgraphs(r) by constraint solving
if ∃dg∈DG s.t.mirrors(dg) lacks ground instances
then return “potential attack found: ”, dg

return “veriﬁcation successful”

Figure 4: Pseudocode of our veriﬁcation algorithm.

This is due to the undecidability of the initial problem, and
all related tools [9, 11, 8, 7, 25] also have this limitation.

We now explain how we adapt and use this algorithm in

Tamarin. We provide examples of its use in Section 5.
4.3 Tamarin

The Tamarin prover [24, 22] is a security protocol ver-
iﬁcation tool that supports both the falsiﬁcation and un-
bounded veriﬁcation of security protocols speciﬁed as multi-
set rewriting systems with respect to trace-based properties.
In Tamarin, a security protocol P ’s executions are mod-
eled by its set of traces, deﬁned as the concatenation of the
sets of action labels at each step. A trace is a sequence of
facts denoting the sequence of actions taken during a proto-
col’s execution. The trace of an execution

S0, (l1

a1−−−→

rec1

r1), S1, . . . , Sk−1, (lk

ak−−−→

reck

rk), Sk

is the sequence of the multisets of its action labels [a1, . . . , ak] .
We now brieﬂy recall the Tamarin prover’s adversary
message derivation rules M D. To deﬁne the protocol and
adversary rules, we assume that ΣFact includes the persistent
fact symbol K modeling messages known to the adversary,
the linear fact symbol Out modeling messages sent by the
protocol, and the linear fact symbol In modeling messages
sent by the adversary. The adversary’s message deduction
capabilities are captured by the following set of rules.
MD = { Out(t)−−[]→K(t), K(t)−−[ K(t) ]→In(t),

Fr(x : fr)−−[]→K(x : fr), []−−[]→K(x : pub) }

∪ { K(t1), . . . , K(tn)−−[]→K(f (t1, . . . , tn)) | f ∈ Σn

Fun }
The adversary learns all messages that are sent and it can
send any message it knows (i.e., it learns or can derive) to
the protocol. It can generate fresh values and it knows all
public values. Additionally, the adversary can apply all op-
erators to terms it knows. When using an equational the-
ory, each of the equations gives rise to a deconstruction
rule that lets the intruder derive the result. For example
for symmetric encryption and decryption, with the equation
sdec(senc(m, k), k) = m, Tamarin automatically generates
the rule K(senc(m, k)), K(k)−−[]→K(m), which the adversary
uses to decrypt messages.

We also add one new adversary deduction rule to M D,
which we call IEquality, which allows the adversary to com-
pare two values for equality:
↓
IEquality : K

(x)−−[]→ .

↑
(x), K

The use of K↓ and K↑ in this rule restricts how the adver-
sary can derive the terms.1 Here, this annotation is crucial
1In all other rules K is actually also either K↓ or K↑. How-
ever, this distinction is required only for automation (namely

as we want to compare two terms that are derived separately.
Moreover, it also prevents immediate non-termination: oth-
erwise, once two values are successfully compared, one could
compare their hashes, followed by their hashes, etc.

The IEquality rule is applicable whenever one side of a
bi-system can construct the same value twice (but in dif-
ferent ways), that is it has dependency graphs as premises
for both instances of x. Note that the other bi-system side
trivially has the mirroring dependency graph if an output
is compared with itself (same dependency graph twice), for
example. But, if on one side the adversary can decrypt
a message and compare it with the content, while on the
other side that is not possible, then the IEquality rule will
expose this. The analysis of the IEquality rule presented in
Examples 10 and 11 illustrates this point in more detail.

For the details of our modiﬁcation to the Tamarin prover
we refer the reader to the extended version of this paper [1].
There we show how our model can be instantiated for
Tamarin, and present an implementation of the above algo-
rithm for verifying observational equivalence with Tamarin.
Note that just like the algorithm outlined in Figure 4 (line
4), Tamarin carries out a rule-by-rule analysis.

The main challenges in implementing our algorithm in the
Tamarin prover relate to limiting the size of the state-space,
which requires ﬁne-tuning Tamarin’s internal heuristic. To
aid termination, we restrict traces to normal forms as much
as possible. Moreover, compared to the original Tamarin
prover, we needed to remove some of its normal form condi-
tions because they are sound for trace properties, but not for
observational equivalence. One such example is the normal
form condition prohibiting repeated adversarial derivation
of a term. However, equality comparison with previous val-
ues must be possible, e.g., to test whether the output equals
the input in the protocol In(x), Fr(y)−−[]→Out(diﬀ(x, y)).

5. CASE STUDIES

We now present four case studies. We ﬁrst apply Tamarin
to two standard examples that have been analyzed using
other tools. Afterwards we present two examples: one that
is outside the scope of previous work and one that veri-
ﬁes a practical RFID protocol that had previously received
manual analysis only. Note that all proofs are constructed
in our tool completely automatically, with the exception of
the attack on TPM Envelope. For this protocol, interac-
tion was limited to human input at a few key choice points
and the remainder was automated. We provide a ﬁle con-
taining the steps necessary to derive the identiﬁed attack
for TPM Envelope. For the other protocols, we just give
their speciﬁcation as Tamarin’s built-in strategy ﬁnds the
proofs. All example ﬁles can be loaded into our extension of
Tamarin and are available at [1], together with Tamarin.
From now on, we use Tamarin to refer to our extension,
instead of the original Tamarin.
5.1 Motivating examples

We start with two well-known examples from [7, 10]. For
each example, we explain how Tamarin determines obser-
vational equivalence using the algorithm Verify, presented
in Figure 4.

state-space reduction and improving termination) so we have
omitted it for ease of presentation. Full details can be found
in the extended version [1].

1151Example 10

(Probabilistic encryption). Consider

the equational theory:

pdec(penc(m, pk(k), r), k) (cid:39) m .

This equation gives rise to the following decryption rule for
probabilistic encryption for the adversary, which is automat-
ically generated by Tamarin:

Dpenc : K(penc(m, pk(k), r)), K(k)−−[]→K(m) .

We now express, as a bi-system, that a probabilistic en-

cryption cannot be distinguished from a random value:

S = { GEN : Fr(k)−−[]→Key(k), Out(pk(k))

EN C : Key(k), Fr(r1), Fr(r2), In(x)−−[]→
Out(diﬀ[r1, penc(x, pk(k), r2)])

} .

We summarize below how Tamarin automatically proves
this property. The algorithm Verify (line 2) ﬁrst constructs
the set RU of rules to be analyzed,

RU = { L(GEN ), R(GEN ), L(EN C), R(EN C),
FreshSys, FreshEnv, IEquality, Dpenc} ,

together with the remaining rules in IF and Env. Recall
that L(name) represents the rule name instantiated with
the left side of the diﬀ-term, and likewise for R(name) with
the right side. Then Verify iterates over all rules (lines
3–4) until either an attack is found (line 7) or all rules have
been checked and the veriﬁcation is complete (line 8), which
happens in this example.

We now describe, for each rule, how Verify processes
it. Verify ﬁrst generates dependency graphs with the rule
as the root (line 5). Afterwards, for each resulting depen-
dency graph, it looks for a mirror (line 6) that contains all
instances required by the deﬁnition of normal dependency
graph equivalence. In this example, it always ﬁnds a mirror
and veriﬁcation therefore succeeds. Due to space and read-
ability constraints, we present the left-diﬀ instantiation and
right-diﬀ instantiation of each rule together, even though
Tamarin analyzes them independently. Due to space con-
straints, we also do not explicitly present the dependency
graphs; however, we do explain how they are mirrored in
each case so that the veriﬁcation succeeds.

• As rule GEN does not contain a diﬀ-term, the left
diﬀ-instantiation of this rule is identical to the right
diﬀ-instantiation. The rule has only a single fresh fact
as its premise and thus any dependency graph with this
rule at its root contains only those two rule instances
and is trivially mirrored by itself.

• The rule EN C has the same premises in the left- and
right-hand side system and is therefore identical for
the purpose of dependency graph computation with
the EN C rule as root. (Note that outputs will be con-
sidered using the equality rule below.) The two fresh
premises will result in identical dependency graphs,
while the key and message reception input are inde-
pendent. Hence both of them will have identical de-
pendency graphs as premises, and the resulting de-
pendency graphs are identical (up to the outputs) and
therefore mirror each other.

• The fresh rules FreshSys and FreshEnv have no pre-
mises. Hence the dependency graphs with them as
root are just their instances, which mirror each other
in the left- and right-hand system.

• For an equality rule instance of IEquality as the root
of a dependency graph, the two premises are the same
instance of a variable x. If both of the premises are
adversary generated, then the resulting dependency
graphs are the same in the left- and right-hand sys-
tem, and thus will mirror themselves trivially. Alter-
natively, if one of the premises uses the output of an
instance of either the EN C rule or the GEN rule,
then there is no dependency graph with a matching
second premise. This is because all system outputs,
pk(k) for GEN and r1 or penc(x, pk(k), r2) for EN C,
contain a fresh value, k, r1, respectively r2, that is
never available to the intruder. As this will never al-
low a complete dependency graph to be derived, no
mirroring dependency graph is needed.

• For the decryption rule generated for the probabilis-
tic encryption, this rule is never applicable on either
side as the adversary never receives the keys needed
for decrypting system generated encryptions. As there
is no dependency graph, no mirroring one is needed.
(One might mistakenly think that this rule might apply
to intruder-generated terms. However, this is not the
case due to the restrictions on how the adversary may
combine its knowledge (K↓ vs K↑) and, in any case,
both sides would use the same dependency graphs as
premise, so the result would be the same.)

• For all other adversary rules, it is obvious that they
result in identical dependency graphs on both sides.
More precisely:
construction rules have adversary
knowledge input and thus the same dependency graphs
as premises. For the deconstruction rules, the only rel-
evant one is the previous decryption rule, as that is the
only one that can use information coming out of the
system; all other rules can only be used on adversary-
generated terms and thus have the same dependency
graphs as premises.

This completes our summary of Tamarin’s veriﬁcation of
observational equivalence for this example. Tamarin auto-
matically constructs the proof in under 0.2 seconds.

Our next example is Decisional Diﬃe-Hellman as discussed
in [7, Example 2]. Tamarin veriﬁes the expected result that
the adversary cannot distinguish a Diﬃe-Hellman tuple from
a random tuple. Note that in contrast to [7], which uses
an equational theory restricted just to the commutativity
of two exponents, Tamarin supports a substantially more
comprehensive model of Diﬃe-Hellman exponentiation.

Example 11

(Decisional Diffie-Hellman). We use
the equational theory for Diﬃe-Hellman exponentiation with
an abelian group of exponents as provided by Tamarin.
Hence no additional adversary rules are needed.

We consider a single rule, which outputs the two half-keys
and challenges the adversary to distinguish the actual key
from an unrelated randomly generated key:
Fr(a1), Fr(a2), Fr(a3)−−[]→
Out(ba1 , ba2 , diﬀ[ba3 , (ba1 )a2 ]) .

GEN :

Using the Verify algorithm, Tamarin collects the rules

RU = { L(GEN ), R(GEN ),

FreshSys, FreshEnv, IEquality} ,

1152together with the remaining rules in IF and Env. We con-
sider the processing of these rules below, where we again
combine the treatment of left-diﬀ instantiations and right-
diﬀ instantiations of system rules to improve readability.

• The rule GEN has only fresh facts as premise and
thus any dependency graph with this rule at its root
contains at most four rule instances, three of fresh rules
and one of GEN itself. Thus, it is mirrored trivially
by itself. The mirror is actually identical (up to the
output).

• The fresh rules FreshSys and FreshEnv do not have
premises. Hence the dependency graphs with them as
roots are just their instances, which mirror each other
on the left- and right-hand side.

• For an equality rule instance of IEquality as the root
of a dependency graph, the two premises are the same
instance of a variable x. If both of the premises are
adversary generated, then the resulting dependency
graphs are the same in the left- and right-hand sys-
tem, and thus will mirror themselves trivially. Alter-
natively, if one of the premises uses the output of an
instance of the GEN rule, then there is no dependency
graph with a matching second premise, except the one
using the same source twice. This is because all of
the system outputs cannot be related in meaningful
fashion within the Diﬃe-Hellman exponentiation the-
ory as it does not allow the extraction of exponents,
which corresponds to computing discrete logs. As this
will never allow a complete dependency graph to be
derived, no mirroring dependency graph is needed. In
the case of the same source being used twice, i.e., a
value being compared with itself, the same premise
dependency graphs work for both systems.

Additionally, note that multiple instances of the GEN
rule are entirely unrelated and do not provide any ad-
vantage for the adversary. Tamarin analyzes this and
computes all possible variants, determining that no
combination is useful.

• For all other adversary rules, it is obvious that they
result in identical dependency graphs on both sides.
Namely, the construction rules have adversary knowl-
edge input and thus the same dependency graphs as
premises.

The Verify algorithm therefore returns that veriﬁcation is
successful. Tamarin veriﬁes this, completely automatically,
in 15.2 seconds.

This concludes our two motivating examples. They were
small enough that we could give relatively detailed descrip-
tions of Verify’s workings. For subsequent examples, we
will be more concise. Readers interested in the full gory de-
tails may generate them themselves by using Tamarin and
running the ﬁles for each case study.
5.2 Feldhofer’s RFID protocol

The RFID protocol due to Feldhofer et al. [17] is of prac-
tical interest as it can be implemented with relatively few
logic gates using AES encryption and hence it ﬁts well with
the requirements of current RFID chips. We use the descrip-
tion from [26] as the basis of our model, which we present in

R → T : nr
T → R : {|nr, nt|}k(R,T )
R → T : {|nt, nr|}k(R,T )

Figure 5: RFID protocol

Figure 5 using Alice&Bob notation. The protocol is between
a reader R and a tag T that share a key k(R, T ). Note that
{| . . .|}k denotes symmetric encryption in this example.

In the ﬁrst message, the reader sends a random nonce
to the tag. In the second message, the tag sends back that
nonce and one of its own choosing, encrypted with the shared
key. In the third message, the reader responds with the same
nonces in reverse order, also encrypted.

The desired security property for this protocol is privacy
for the tags. Namely, if at least two tags share a key with
a reader (and in practice, there will be many such tags),
then the adversary cannot determine which tag is actually
communicating with the reader. Tamarin veriﬁes this in
under 1.6 seconds.
5.3 TPM_Envelope protocol

We ﬁrst brieﬂy explain the key part of this protocol [13]
and afterwards present the Tamarin rules along with fur-
ther details. A stateful Trusted Platform Module (TPM)
creates a one-use public/private key pair, and publishes the
public key. A participant Alice then encrypts a nonce (the
secret) with the public key (creating an envelope), which she
sends to a participant Bob. Bob then either requests from
the TPM the envelope’s content, learning the secret, or re-
quests a TPM-signed certiﬁcate stating that he did not ask
for the content. In both cases, the TPM complies with the
request and changes its state in such a way that it can after-
wards only comply with repetitions of the ﬁrst request, but
never with the other request. This is where mutable state
is crucial, i.e., the original capability of issuing either the
certiﬁcate or the secret is revoked once the choice is made.
The trace-based secrecy property veriﬁed in [13] states that
the adversary may learn either the certiﬁcate or the secret,
but not both.

We investigated whether this protocol additionally satis-
ﬁes the real–or–random property for the secret. We therefore
added a real–or–random challenge to the end of Alice’s pro-
tocol execution, which sends out either the real secret or a
random value. Tamarin fails to prove this property and in-
stead returns a simple attack, provided the encryption used
is deterministic. The attack is as follows: the adversary (im-
personating Bob) asks for the proof of never having received
the secret from the TPM, and thus he must be unable to
learn the secret. But, he can still distinguish whether the
real–or–random challenge emits the real secret or a random
value. He does this using the previously published public
key, and encrypting the emitted value with it. Afterwards,
he compares the resulting encryption to the envelope, and
he learns that it is the real secret if it matches the envelope
and a random value otherwise.

Inspecting this attack it is easy to see that it fails when
probabilistic encryption is used instead. The adversary can
still encrypt the emitted value with the public key, but the
equality check against the envelope will always fail because
the added randomness is diﬀerent in the envelope and the
adversary-generated comparison encryption.

In Figure 6 we present the rules used to model the pro-

1153tocol TPM Envelope in Tamarin. Note that we omit here
some details, which can be found in the model ﬁle included
at [1]. First we explain the rules concerning the TPM’s plat-
form conﬁguration registers (PCR). The Init rule initializes
the PCR to the initial string (cid:48)pcr0(cid:48), and generates the fresh
authentication identiﬁcation key aik stored in the persistent
AIK fact and sends out the public key pk(aik). This models
a long-term key for the TPM. The extension rule Extend
allows any PCR to be extended to the hash of the concate-
nation of its previous value and an input. This is used when
a client later either extends the PCR with (cid:48)deny(cid:48) or (cid:48)obtain(cid:48).
This changes the TPM’s state to allow creation of a certiﬁ-
cate that the envelope was not opened ((cid:48)deny(cid:48)), or respec-
tively opens the envelope ((cid:48)obtain(cid:48)). Rule CertK certiﬁes
a public key for which the TPM has stored the associated
private key in the persistent key table fact KT with a par-
ticular lock. Locks are PCR values and the TPM will only
extract the private key when the PCR value matches this
lock. In the rule Quote, the current PCR value is sent out
authentically, signed with the TPM’s long-term key. The
TPM’s last rule is U nbind. It takes an envelope as input,
and if the public key used to encrypt the envelope matches
the private key in the key table, where additionally the lock
in the key table matches the current PCR value, then the
message in the envelope is decrypted and sent out.

The participant Alice requests an envelope key in her ﬁrst
rule A1 by extending the PCR with a nonce n of her choice.
In rule A2, she creates the secret to be put in the enve-
lope encryption and checks that the TPM certiﬁes that the
key can only be obtained if the PCR state is extended with
(cid:48)obtain(cid:48) and then she uses the certiﬁed public key to encrypt
her secret. Alice then publishes the envelope while keeping
state in A2 for her next rule and in A2ror for the real–or–
random challenge. Rule A3 uses the state in A2 to check that
the TPM’s PCR was extended with (cid:48)deny(cid:48) (which means it
has not yet, and can now no longer, decrypt the envelope)
and then notes the action Denied. We are only interested
in traces where the adversary can show this certiﬁcate. The
rule CLKey is used with (cid:48)obtain(cid:48) as the lock input to add
a new private key to the TPM’s key table that is used in
rule A2.
It can of course be used with other inputs, but
the resulting keys are not interesting to us. Now the key
can only be extracted with a PCR extended with (cid:48)obtain(cid:48),
and thus the certiﬁcate with (cid:48)deny(cid:48) is unavailable. The last
rule is the ROR rule; this either outputs the real secret or
a random value.

The Tamarin prover ﬁnds the attack described above for
the observational equivalence of the TPM Envelope proto-
col. Note that this is a stronger property than trace-based
secrecy, which had been veriﬁed by [13], so the two results
are compatible. We therefore conclude that this protocol
should only be used with probabilistic encryption, and not
with deterministic encryption.

This example illustrates Tamarin’s handling of mutable
state, which other tools cannot handle. It also illustrates the
diﬀerence between trace-based properties and observational
equivalence-based properties.

6. RELATED WORK AND CONCLUSION
We have shown how to take the well-established model-
ing formalism of multiset rewriting and extend it with a
novel deﬁnition of observational equivalence. The result is
well-suited for the veriﬁcation of cryptographic protocols,

Init : Fr(aik)−−[]→PCR((cid:48)pcr0(cid:48)), AIK(aik), Out(pk(aik))
Ext : PCR(x), In(y)−−[]→PCR(h(x, y))

CertK : AIK(aik), KT(lock, sk)−−[]→
Quote : PCR(x), AIK(aik)−−[]→
U nbind : PCR(x), KT(x, sk), In(aenc(m, pk(sk)))−−[]→

Out(sign((cid:104)(cid:48)certk(cid:48), lock, pk(sk)(cid:105), aik))
PCR(x), Out(sign((cid:104)(cid:48)certcpr(cid:48), x(cid:105), aik))

PCR(x), Out(m)

A1 : Fr(n), PCR(x)−−[]→PCR(h(x, n)), A1(n)
A2 : Fr(s), A1(n), AIK(aik),

In(sign((cid:104)(cid:48)certk(cid:48), h(h((cid:48)pcr0(cid:48), n),(cid:48) obtain(cid:48)), pk(cid:105), aik))
−−[]→Out(aenc(s, pk)), A2(n, s), A2ror(s)
In(sign((cid:104)(cid:48)certpcr(cid:48), h(h((cid:48)pcr0(cid:48), n),(cid:48) deny(cid:48))(cid:105), aik)),
A2(n, s), AIK(aik)−−[ Denied(s) ]→

A3 :

CLKey : Fr(sk), PCR(x), In(lock)−−[]→

PCR(x), KT(h(x, lock), sk), Out(pk(sk))

ROR : A2ror(s), Fr(f )−−[]→K(diﬀ[s, f ])

Figure 6: Rule set modeling the TPM envelope

as well as other applications. Based on this, we have imple-
mented an algorithm to prove observational equivalence for
protocols speciﬁed in multiset rewriting and demonstrated
its eﬀectiveness on a number of case studies. Combining
Tamarin’s constraint solving with the bi-system notion re-
sults in our approach’s high degree of automation.

Our equivalence notion has similarities with other notions
of observational equivalence considered in the literature, in-
cluding trace equivalence [11], bisimulation [2], and notions
based on contexts [2, 11, 7]. However, multiset rewriting
and our observational equivalence deﬁnition are more ﬂexi-
ble than the previous approaches as we can choose the en-
vironment as well as the underlying equational theory. As
illustrated in Example 5 in Section 3, this can, for exam-
ple, be used to model diﬀerent types of attackers. In pro-
cess algebras used for protocol veriﬁcation, like the applied
π-calculus, the environment is implicitly deﬁned and can-
not be changed. Moreover, we support mutable state and
a larger set of equational theories than other approaches as
detailed below.

Various other tools exist for verifying notions of obser-
vational equivalence. APTE [9, 11] and AKISS [8] both
verify trace equivalence, but are limited to a bounded num-
ber of sessions. Moreover, AKISS does not support non-
trivial else branches or private channels. ProVerif [7] ver-
iﬁes observational equivalence in the applied π-calculus for
an unbounded number of sessions, but it cannot handle mu-
table state [3], for example, a protocol that switches be-
tween the states a and b. Extensions for ProVerif that
can deal with Diﬃe-Hellman equational theories [20] do not
support observational equivalence. Note that our approach’s
restriction to bi-systems is similar to ProVerif’s restric-
tion to bi-processes. SPEC [25] veriﬁes open bisimulation
in the spi-calculus, but unlike our approach it only supports
a ﬁxed number of cryptographic primitives and is limited to
a bounded number of sessions.

In contrast to the above, there are tools like StatVerif [3]
and SAPIC [19] that support mutable state. However, they
cannot verify observational equivalence. Similarly, Tamarin,
which is used as SAPIC’s back-end, supports mutable state,
an unbounded number of sessions, and also Diﬃe-Hellmann
equational theories. However, prior to our extension,
it

1154could not prove any notion of observational equivalence.

[13] St´ephanie Delaune, Steve Kremer, Mark Dermot

Another multiset rewriting-based approach that supports
observational equivalence is Maude-NPA [23]. It creates the
synchronous product of two very similar protocols, similar
to our use of bi-systems. Their approach suﬀers from termi-
nation problems [23] and thus presents only attacks.

As future work, we plan to extend our approach so that
the veriﬁcation of observational equivalence is also possi-
ble when one rule must be matched by a diﬀerent rule, or
even by multiple rules. We will also tackle protocols with
loops, where proofs will likely require induction. Moreover,
we intend to look at larger protocols, such as authenticated
key exchange protocols with perfect forward secrecy, such as
NAXOS and its variants.

7. REFERENCES
[1] Tamarin – tool and extended papers. http://www.

infsec.ethz.ch/research/software/tamarin.html.
[2] Mart´ın Abadi and C´edric Fournet. Mobile values, new

names, and secure communication. In Proceedings of
the 28th Symposium on Principles of Programming
Languages (POPL’01), pages 104–115, New York,
2001. ACM.

[3] Myrto Arapinis, Joshua Phillips, Eike Ritter, and

Mark Dermot Ryan. Statverif: Veriﬁcation of stateful
processes. Journal of Computer Security,
22(5):743–821, 2014.

[4] David Basin, Cas Cremers, and Catherine Meadows.

Model checking security protocols. In Handbook of
Model Checking, chapter 24. Springer, 2015. To
appear.

[5] Mihir Bellare, Anand Desai, David Pointcheval, and

Phillip Rogaway. Relations among notions of security
for public-key encryption schemes. In CRYPTO,
volume 1462 of LNCS, pages 26–45. Springer, 1998.

[6] Mihir Bellare and Phillip Rogaway. Entity

authentication and key distribution. In CRYPTO,
volume 773 of LNCS, pages 232–249. Springer, 1993.
[7] Bruno Blanchet, Mart´ın Abadi, and C´edric Fournet.

Automated veriﬁcation of selected equivalences for
security protocols. Journal of Logic and Algebraic
Programming, 75(1):3–51, February–March 2008.

[8] Rohit Chadha, ¸Stefan Ciobˆac˘a, and Steve Kremer.
Automated veriﬁcation of equivalence properties of
cryptographic protocols. In Helmut Seidl, editor,
ESOP, volume 7211 of LNCS, pages 108–127.
Springer, 2012.

[9] Vincent Cheval. APTE: An algorithm for proving

trace equivalence. In TACAS, volume 8413 of LNCS,
pages 587–592. Springer, 2014.

[10] Vincent Cheval and Bruno Blanchet. Proving more

observational equivalences with ProVerif. In Principles
of Security and Trust (POST), volume 7796 of LNCS,
pages 226–246. Springer, 2013.

[11] Vincent Cheval, V´eronique Cortier, and St´ephanie

Delaune. Deciding equivalence-based properties using
constraint solving. Theor. Comput. Sci., 492:1–39,
2013.

[12] St´ephanie Delaune, Steve Kremer, and Mark Ryan.

Verifying privacy-type properties of electronic voting
protocols. Journal of Computer Security, 17:435–487,
December 2009.

Ryan, and Graham Steel. Formal analysis of protocols
based on TPM state registers. In CSF, pages 66–80.
IEEE, 2011.

[14] Jannik Dreier, Pascal Lafourcade, and Yassine

Lakhnech. Deﬁning privacy for weighted votes, single
and multi-voter coercion. In ESORICS, volume 7459
of LNCS, pages 451–468. Springer, 2012.

[15] Jannik Dreier, Pascal Lafourcade, and Yassine

Lakhnech. A formal taxonomy of privacy in voting
protocols. In Proceedings of IEEE International
Conference on Communications (ICC’12), pages
6710–6715, Ottawa, ON, Canada, 2012. IEEE.
[16] Jannik Dreier, Pascal Lafourcade, and Yassine

Lakhnech. Formal veriﬁcation of e-auction protocols.
In Proceedings of the 2nd Conference on Principles of
Security and Trust (POST’13), volume 7796 of LNCS,
pages 247–266, Rome, Italy, 2013. Springer Verlag.
[17] Martin Feldhofer, Sandra Dominikus, and Johannes

Wolkerstorfer. Strong authentication for RFID
systems using the aes algorithm. In Cryptographic
Hardware and Embedded Systems-CHES 2004, pages
357–370. Springer, 2004.

[18] Mich`ele Feltz and Cas Cremers. On the limits of

authenticated key exchange security with an
application to bad randomness. Cryptology ePrint
Archive, Report 2014/369, 2014.

[19] Steve Kremer and Robert K¨unnemann. Automated

analysis of security protocols with global state. In
2014 IEEE Symposium on Security and Privacy, SP
2014, Berkeley, CA, USA, May 18-21, 2014, pages
163–178. IEEE Computer Society, 2014.

[20] Ralf K¨usters and Tomasz Truderung. Using ProVerif

to analyze protocols with Diﬃe-Hellman
exponentiation. In Computer Security Foundations
Symposium (CSF), pages 157–171. IEEE, 2009.

[21] Brian LaMacchia, Kristin Lauter, and Anton

Mityagin. Stronger security of authenticated key
exchange. In Provable Security, pages 1–16. Springer,
2007.

[22] Simon Meier, Benedikt Schmidt, Cas Cremers, and

David Basin. The TAMARIN Prover for the Symbolic
Analysis of Security Protocols. In CAV, volume 8044
of LNCS, pages 696–701. Springer, 2013.

[23] Sonia Santiago, Santiago Escobar, Catherine

Meadows, and Jos´e Meseguer. A formal deﬁnition of
protocol indistinguishability and its veriﬁcation using
Maude-NPA. In Security and Trust Management
(STM) 2014, pages 162–177. Springer, 2014.

[24] Benedikt Schmidt, Simon Meier, Cas Cremers, and
David Basin. Automated analysis of Diﬃe-Hellman
protocols and advanced security properties. In
Computer Security Foundations Symposium (CSF),
pages 78–94. IEEE, 2012.

[25] Alwen Tiu and Jeremy E. Dawson. Automating open

bisimulation checking for the spi calculus. In CSF,
pages 307–321. IEEE Computer Society, 2010.

[26] Ton Van Deursen, Sjouke Mauw, and Saˇsa

Radomirovi´c. Untraceability of RFID protocols. In
Information Security Theory and Practices. Smart
Devices, Convergence and Next Generation Networks,
pages 1–15. Springer, 2008.

1155