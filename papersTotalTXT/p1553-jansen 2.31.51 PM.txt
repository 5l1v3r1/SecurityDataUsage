Safely Measuring Tor

Rob Jansen and Aaron Johnson

U.S. Naval Research Laboratory

Washington, D.C.

{rob.g.jansen, aaron.m.johnson}@nrl.navy.mil

ABSTRACT
Tor is a popular network for anonymous communication.
The usage and operation of Tor is not well-understood, how-
ever, because its privacy goals make common measurement
approaches ineffective or risky. We present PrivCount, a sys-
tem for measuring the Tor network designed with user pri-
vacy as a primary goal. PrivCount securely aggregates mea-
surements across Tor relays and over time to produce differ-
entially private outputs. PrivCount improves on prior ap-
proaches by enabling ﬂexible exploration of many diverse
kinds of Tor measurements while maintaining accuracy and
privacy for each. We use PrivCount to perform a measure-
ment study of Tor of sufﬁcient breadth and depth to inform
accurate models of Tor users and trafﬁc. Our results indi-
cate that Tor has 710,000 users connected but only 550,000
active at a given time, that Web trafﬁc now constitutes 91%
of data bytes on Tor, and that the strictness of relays’ connec-
tion policies signiﬁcantly affects the type of application data
they forward.

1.

INTRODUCTION

The Tor network [10] is among the most popular tools for
digital privacy. Users such as journalists, activists, and law
enforcement use its onion-routing protocol to keep private
what Web sites they are visiting, media they are watching,
and emails they are sending. As of May 2016, the network
consists of around 7000 volunteer-run relays that forward user
trafﬁc to its destination, the network collectively forwards
nearly 75 Gbps of trafﬁc, and an estimated 1.75 million users
connect every day [4].

Statistics such as these are critical to understand the impact
Tor is currently having and how it can be improved. How-
ever, typical methods for network monitoring cannot be di-
rectly applied to Tor because of its strong privacy goals. For
example, simply measuring the number of users is very dif-
ﬁcult as Tor is designed to keep users anonymous, and in-
formation about their identities should not be collected even
when available to protect against legal or technical compro-

This paper is authored by an employee(s) of the United States Government and is in the
public domain. Non-exclusive copying or redistribution is allowed, provided that the
article citation is given and the authors and agency are clearly identiﬁed as its source.
CCS’16, October 24 - 28, 2016, Vienna, Austria

ACM ISBN 978-1-4503-4139-4/16/10. . . $15.00
DOI: http://dx.doi.org/10.1145/2976749.2978310

mise of the data. Tor itself currently gathers few measure-
ments and many of these using heuristic techniques of un-
known accuracy (including its number of users).

The research community has largely left this problem alone
due to the privacy risks involved. McCoy et al. [23] in 2008
performed some of the ﬁrst research measuring Tor by run-
ning a relay and examining the types of trafﬁc observed ex-
iting Tor. However, this approach was widely debated [28]
due to the risks that collecting such data poses to user pri-
vacy. Some studies in 2010 [8, 22] performed measurement
of Tor’s users and trafﬁc, but there has otherwise been rela-
tively little follow-up. Over the same time great advances in
privacy-preserving data publishing have developed, includ-
ing differential privacy [11] and practical privacy-preserving
aggregation [6].

We build on this recent work to develop PrivCount, an ef-
ﬁcient and ﬂexible system for privacy-preserving measure-
ment on Tor. PrivCount extends the PrivEx system of Elahi
et al. [14], designed speciﬁcally for private Tor measurement,
by making it suitable for the kinds of exploratory measure-
ments used during research. To PrivEx, PrivCount adds re-
peatable measurement phases in order to make iterative mea-
surements feasible. It also provides a comprehensive method
to apply differential privacy to multiple and diverse Tor statis-
tics while maintaining high accuracy for each. We develop
an open-source tool implementing PrivCount that is robust,
secure, and particularly convenient to use for research on
Tor [1].

We use the PrivCount tool to perform a measurement study
of Tor users and trafﬁc with a scope similar to past work but
with user privacy as a foremost consideration. Our research
deployment of PrivCount involves 6 independent contribu-
tors in 4 different countries of which all would need to be
compromised in order to violate the security properties of
the system. We perform aggregation of measurements across
7 Tor relays, which prevents any one from being identiﬁed as
the source of a particular trafﬁc characteristic.

We collect client and destination statistics with the particu-
lar goal of informing future models of Tor trafﬁc and network
improvement. Our results on exit trafﬁc indicate that trafﬁc
to Web ports now constitutes 91% of data bytes on Tor, up
from 42% in 2010 [8]. We also provide a ﬁrst estimate of the
number of Tor users outside of Tor’s own measurement us-
ing an entirely different method. Our data indicate that in
any given 10 minutes an average of 710 thousand users are
connected to Tor, of which just over 550 thousand (77%) are
active. We also look at the effect of exit policies, which relays
use to limit which ports and IPs they will connect to, and

1553we provide evidence that exit policies signiﬁcantly affect the
type of trafﬁc exiting a relay, a factor that previous studies
did not consider.

Our results show that many of the Tor measurements of
most interest can be done privately and practically. Low-cost
research efforts can productively use PrivCount, while the
Tor Project itself could beneﬁt from its security and privacy
properties that exceed in many ways the security of Tor’s
own measurement methods.
2. PRIVATE COUNTING WITH PrivCount
In order to safely gather statistics from the Tor network, we
designed and implemented a privacy-preserving data collec-
tion and aggregation system called PrivCount that expands
upon the secret-sharing variant of PrivEx [14] (i.e. PrivEx-S2).
This section provides a self-contained description of Priv-
Count, noting throughout how it differs from PrivEx (see
Section 6 for a summary of these differences).
2.1 Overview of Roles and Architecture

PrivCount is a distributed counting system which relies on
multiple nodes and entities to achieve privacy and security.
A PrivCount deployment contains a tally server (TS) node,
one or more data collector (DC) nodes, and one or more share
keeper (SK) nodes.
Tally Server. The PrivCount TS is the central point of the
system. The TS authenticates the DC and SK nodes before
admitting them, tracks their availability and status, and syn-
chronizes system operations. In order to minimize the attack
surface of a PrivCount deployment, the TS acts as a central
proxy for all communication between the other nodes. The
TS server port is the only port that is required to be open and
Internet-accessible in the entire PrivCount system; the DCs
and SKs only make outgoing connections to the TS. This cen-
tralized control is in contrast to PrivEx, where SKs and DCs
run autonomously and communicate directly. However, de-
spite its more central position, the TS is still untrusted, and
all communication between DCs and SKs is encrypted and
authenticated.
Data Collectors. PrivCount DCs are the main nodes for pro-
cessing measurements. DCs are responsible for collecting
events from a locally running Tor process, computing statis-
tics from those events, and maintaining counts for each statis-
tic over time. Each counter is initialized with the sum of
normally-distributed random noise and uniformly-random
numbers shared pairwise with each SK in the system. The
noise serves to provide differential privacy [11] of the ﬁnal,
aggregated value. The shared numbers serve to “blind” the
counter; the numbers are encrypted, one for each SK, and
then each is sent to the corresponding SKs (through the TS
proxy) before being securely erased at the DC. This process
ensures forward privacy: any compromise of a DC will not
leak past local counter values (the counters will appear uni-
formly random). The DCs increment the counters during the
collection period, and then send the ﬁnal counts (the sum of
the true counts, noise, and shared numbers) to the TS during
aggregation.
Share Keepers. PrivCount SKs are responsible for storing the
shared numbers assigned to it by the DCs; for each counter,
each SK will have received one shared value from each DC.
During aggregation, each SK for each counter sums the shared
values they received from the DCs and sends the sum to
the TS. Once the TS receives all counts from the DCs and

all summed shared values from the SKs, the TS sums the
counts from all DCs for each counter and then “de-blinds”
each counter by subtracting the summed shared values. The
ﬁnal aggregated count for each counter is only meaningful
after all summed secrets from all SKs are removed. As long
as at least one SK acts honestly in summing the secret num-
bers, the TS cannot learn individual DC counts, and nothing
is revealed but the ﬁnal aggregated count, which is protected
under differential privacy.
2.2 Protocol Speciﬁcation

Consider a PrivCount deployment with one tally server
T , n data collectors Di, i ∈ {1, ..., n}, and m share keepers
Sj, j ∈ {1, ..., m}. Further, suppose that l statistics are be-
ing collected; let sk be the value computed for the kth statis-
tic, k ∈ {1, ..., l}. As in PrivEx, the value of a statistic can
be a single integer, but PrivCount also allows the value of a
statistic to be a vector of integers representing a histogram.
Single numbers are implemented with one counter, which
is an integer and is the fundamental data structure in Priv-
Count. Histograms are implemented with ck counters sk =
(sk,1, . . . , sk,ck ), where each counter represents a bin in the
histogram. The range of each bin sk,b is [Lk,b, Rk,b), where
Lk,b < Rk,b ≤ Lk,b+1 for all b. When a measurement is made
for sk with value x, the bin sk,b for which Lk,b ≤ x < Rk,b
is incremented by one. We extend some of this notation to
those sk that are single numbers by letting ck = 1 and letting
sk = sk,1. The counters are kept at all DCs, and we denote
by si
k,b the counter stored at Di for sk,b. Addition at a counter
is performed modulo q, where q is a number large enough
that the aggregated noisy value is almost certainly within
(−q/2, q/2). Output values in [q/2, q) are interpreted as neg-
ative values, which can occur even for non-negative statistics
due to the random noise added.

i=1 si

The goal of PrivCount is to privately measure all statistics
locally and then reveal only the differentially-private counts
aggregated across all DCs, i.e., to compute ∑n
k,b + Ni
k,b,
where Ni
k,b is Di’s component of the random noise that pro-
vides (, δ)-differential privacy [12]. PrivCount divides the
steps accomplishing this aggregation into phases that permit
an iterative collection process in which initial results can be
used to inform later rounds of data collection.
In contrast
to PrivEx, which assumes continuous and static data collec-
tion, this design enables ﬂexibility in measurement type and
length with minimal coordination among the independent
parties running the protocol, while still maintaining its se-
curity properties. Because human operators facilitating the
data exploration are a key component of this process, we in-
clude in our description how these operators interact with
the automated system. The phases of operation for Priv-
Count are as follows:

Initialization

2.2.1
The initialization phase contains all actions that require
the participation of the DC and SK operators. Coordination
among multiple operators is difﬁcult and time-consuming,
and so PrivCount concentrates their involvement at the be-
ginning phase, which allows later phases to be performed
multiple times at the discretion of just the TS operator. Thus
the TS operator is able to quickly and conveniently explore
interesting phenomena in the Tor network without becom-
ing a single point of compromise for the system.

1554We assume that a public-key infrastructure (PKI) securely
provides signing and encryption keys to all PrivCount par-
ticipants. These keys are used implicitly throughout the pro-
tocol when a message is encrypted to or signed by a party,
and all messages are sent on secure channels implemented
via these keys. Moreover, we assume that code correctly
implementing PrivCount has already been installed on each
protocol entity. Note that at several points individual opera-
tors are required to verify that certain settings provide “ad-
equate” privacy and security. This determination would be
made in accordance with an out-of-band discussion among
all participants in the speciﬁc PrivCount deployment.

During this phase, the TS operator should conﬁgure the
TS with a deployment document that will be shared among all
protocol participants. The deployment document includes
the public keys of the desired DCs and SKs. It also includes
the following parameters governing the amount of privacy-
preserving noise to add to the statistics: the differential pri-
vacy parameters  and δ, the sensitivity of each statistic (i.e.
the maximum amount the statistic can change given a certain
limited amount of change in a user’s activities), the reconﬁg-
uration time that must pass between collection periods with
different conﬁgurations, and the noise weight wi (i.e. the rela-
tive amount of noise provided by DC Di). These parameters
are described fully in Section 2.3. The deployment document
also includes the minimal subsets of DCs that must provide
measurements for the SKs to allow an aggregate output to be
produced. The TS then sends the deployment document to
each DC and SK in the document.

After receiving the deployment document, to ensure con-
sistency each party sends the deployment document (with
the TS signature) to the other parties and waits until it has
received an identical copy of the document from them. The
operators should then verify that the participants, noise pa-
rameters, and the minimal required DC subsets provide ade-
quate privacy. The acceptance or rejection is then sent to the
TS.

The keys and parameters conﬁgured during the initializa-
tion phase will not be modiﬁed in later phases, and doing
so requires re-initializing the system. We note that, to make
larger deployments efﬁcient, consistency of the deployment
document could instead be achieved by obtaining signatures
from a small set of ﬁxed authorities (e.g. the Tor Directory
Authorities).

2.2.2 Conﬁguration
The TS should only proceed to the conﬁguration phase if
all DCs and SKs accepted the deployment document. Dur-
ing the conﬁguration phase, the TS sets features of data col-
lection to which the DCs and SKs automatically adjust in
order to maintain PrivCount’s privacy guarantees. There-
fore, the TS operator can unilaterally and repeatedly con-
ﬁgure new measurements without the TS becoming a single
point of compromise, which signiﬁcantly improves the speed
and convenience of using PrivCount compared to PrivEx.
The following features are set at the TS during this phase:
(i) the start and end time of the collection, (ii) the statistics sk
that will be collected (iii) the number ck of counters used to
count each statistic, (iv) the range [Lk,b, Rk,b) of each bin, and
(v) an estimated value vk for each statistic that will guide Priv-
Count in determining how to add noise such that relative
accuracy per-statistic is maximized while providing (, δ)-
differential privacy across all statistics (see Section 2.3).

These conﬁguration features are collected in a conﬁgura-
tion document, which is sent to each DC and SK. To ensure
consistency, each SK sends a copy of the signed document to
each other SK and each DC. Each SK and each DC waits until
it has received an identical copy of the conﬁguration docu-
ment from each SK. Once received, each DC then determines
the noise magnitude σk for each statistic sk. This calculation
is based on the noise parameters set during initialization as
well as the statistics selected and estimated by T during con-
ﬁguration (see Section 2.3 for details on computing the σk).
2.2.3 Execution
The execution phase is divided into setup, collection, and

aggregation processes.
Setup. During the setup process, each DC Di produces noise
for each counter si
k,b by sampling from the normal distribu-
tion with mean 0 and standard deviation wiσk to produce a
noise value Ni
k,b ∼ Round(Normal(0, wiσk)).1 Then Di ini-
tializes the counter as si
k,b mod q. The noise val-
ues, when aggregated across all DCs, implement the Gaus-
sian mechanism [12] and thus provide differential privacy
for the ﬁnal output (see Section 3 for a privacy analysis of
PrivCount).

k,b = Ni

k,b ← si

Each Di then, for each counter, generates m uniformly ran-
dom integers to produce for each SK Sj a value
Bi,j
k,b ∼ Uniform({0, . . . , q − 1})2 that will be shared with Sj,
and Di increments the counter by these values: si
k,b +
j=1 Bi,j
∑m
k,b mod q. Each counter now has m + 1 values added
to it: the noise and the m shared values. The shared values
Bi,j
k,b serve to blind counter si
k,b to provide forward privacy
and will be removed later during the aggregation process.
Each Di sends each shared value Bi,j
k,b to Sj via T and then se-
curely erases the locally-stored shared values. Each SK stores
the received shared values for the duration of the collection
process.
Collection. During the collection process, each DC monitors
events from its local Tor instance and adjusts the counters.
When an observation is made at Di that affects statistic sk,
Di adjusts one of its counters si
k,b. For single-number statis-
tics, the observed number is added to the counter. For his-
tograms, the bin si
k,b in which the observation falls is incre-
mented. For example, if the statistic is a histogram of the
number of streams per circuit, and the DC observes the end
of a circuit that carried 10 streams during its lifetime, then the
bin containing 10 is incremented by one. The collection pro-
cess lasts for the length of time set during the conﬁguration
phase.
Aggregation. Once the collection process ends, T requests
the counter values from each DC Di. Each Di then sends the
value of each counter si
k,b to T . T considers as successful the
set of DCs that provide values for all counters within a cer-
tain time, S ⊆ {1, . . . , n}. Then T requests from each SK a
sum of the values shared with the successful DCs for each
counter. Recall that each SK Sj is storing n · ∑l
k=1 ck shared
values, one from each DC for each counter. If the successful

1Round is the nearest integer function, and Normal(µ, σ)
is the distribution with density function φ(µ, σ; x) =
e−(x−µ)2/(2σ2)/(σ√2π).
2Uniform(S) is the uniform distribution over set S.

1555k,b = ∑i∈S Bi,j

DCs are a superset of some minimal set of required DCs, as
listed in the deployment document, each Sj adds the shared
values of the successful DCs for each counter and sends the
resulting sums Bj
k,b to T . After receiving all
shared-value sums Bj
k,b from each Sj, T computes the ﬁnal
tallies for each counter by adding the counters from the suc-
cessful DCs and subtracting the corresponding shared-value
sums from the SKs. That is, T computes sk,b = ∑i∈S si
k,b −
j=1 Bj
∑m
k,b mod q and publishes these values as the output
of the aggregation process. PrivCount may then be recon-
ﬁgured before starting another execution phase, but it does
not need to be re-initialized. In addition, the DCs and SKs
will not accept a new conﬁguration document unless it starts
collection after the reconﬁguration time in the deployment
document has passed.

Note that tolerating the failure of DCs is of critical impor-
tance in a large distributed system such as Tor. PrivCount
provides this enhancement to PrivEx at the minor cost of
storing an extra n − 1 values per counter at the SKs between
setup and aggregation. We observe that SK failures can be
tolerated at some cost simply by running several collections
in parallel with different subsets of the SKs and choosing a
ﬁnal output from any of the successful SK subsets. SK fail-
ure is of much less concern, however, as the number of SKs
is expected to be small even for very large deployments, and
they are speciﬁcally chosen for their reliability and trustwor-
thiness.
2.3 Privacy-Preserving Noise

PrivCount adds random noise to each counter in order to
provide privacy to individual Tor user actions that contribute
to its value. As in PrivEx, the formal notion of privacy used
in PrivCount is (, δ)-differential privacy [12]. However, we
modify and extend PrivEx in several ways to allow for an ex-
panded set of statistics and to make it suitable for a smaller-
scale research deployment.
Deﬁning privacy. PrivCount provides privacy for a certain
amount of user activity. The differential privacy guarantee
applies to “adjacent” databases, where databases are typi-
cally considered to be adjacent if they differ by the input of
a single user [24]. PrivEx deﬁnes adjacency as differing by
at most 6 exit connections from different circuits per hour on
average. This essentially protects a certain number of user
connections rather than providing per-user privacy, as users
may make an arbitrary number of circuits per hour. Indeed
per-user privacy in Tor measurement is inherently difﬁcult to
provide accurately, as a single user can in theory constitute
most of the activity being measured on the network.

We thus adopt a notion of privacy for a bounded amount
activity within a given length of time and extend it to in-
clude other types of user activity. We note that Tor itself has
taken a similar approach in its use of differential privacy to
publish per-relay onion-service statistics [16]. The differen-
tial privacy guarantee under this notion is that, for two sets
of actions within the activity bound that both occur within
a certain length of time, an adversary is nearly as likely to
see a given output whether a user performed one set or the
other. PrivCount protects bounded numbers of the following
types of user actions in a given time period: (i) connection to
a guard, (ii) using a guard from a distinct IP address, (iii) cir-
cuit creation, (iv) stream creation, (v) sending or receiving a
byte of data.

An input “database” in the context of measuring Tor is the
activity on the Tor network. Given bound ax for activity of
type x and a time bound t, two sequences of network activity
are then adjacent if they only differ in the actions of a single
user in some time period of length t and in at most ax actions
for each type of activity x. The difference can be in the exis-
tence of such actions or in attributes of those actions. Note
that these bounds apply simultaneously to different types of
activity and thus can be used to provide privacy for the en-
tirety of a user’s impact on Tor if it falls within the activity
and time bounds. For example, suppose that two sequences
of network activity N1 and N2 differ only in the actions of
one user in a day, and in N2 that user both created an addi-
tional circuit and kept a stream open in N2 for longer than
it was in N1. Then N1 and N2 would be considered adjacent
if t is at least one day, acirc ≥ 1, and astream ≥ 1, where acirc
and astream are the bounds for activities of type (iii) and (iv),
respectively. We describe concrete activity bounds ax and t
in Section 4.2.
Determining noise per statistic. Given the above notion
of adjacency, PrivCount provides (, δ)-differential privacy
by adding normally-distributed noise to its counters, as in
PrivEx. However, instead of ﬁrst choosing σ to limit the ad-
versary’s “advantage” and then determining the resulting 
and δ, we use the more typical method of ﬁrst setting  and
δ to achieve desired privacy and then computing the neces-
sary σ. Tor itself is using this approach [16] (with  = 0.3 and
δ = 0), and this method makes it straightforward to allocate
the privacy “budgets”  and δ across statistics to minimize
relative noise. Moreover, the guarantees of (, δ)-differential
privacy have a direct Bayesian intepretation [27] that applies
to an adversary with any amount of prior knowledge, unlike
the notion of adversary advantage.

PrivCount sets  and δ and then divides each among the
l statistics (this division is detailed below, in the next para-
graph). Let k, δk be the allocation of these parameters to the
kth statistic sk, that is, ∑k k =  and ∑k δk = δ for k, δk ≥ 0.
The noise to add to a statistic depends on its sensitivity. The
sensitivity of a statistic that is a single number is the maxi-
mum amount that number can change between adjacent in-
puts. The sensitivity of a histogram is twice the number of
histogram elements that can change their bin, be added, or
be removed [13] (the factor of 2 appears because changing the
bin of an input reduces one bin count and increases another).
We describe in Section 4.2 how we determine sensitivities for
the speciﬁc statistics we collected. Given the sensitivity for
the kth statistic, PrivCount uses an iterative search to com-
pute σ∗(k, δk), the smallest normal standard deviation such
that the set of outputs that satisfy k-differential privacy has
probability at least 1 − δk. PrivCount uses this value for the
noise of the kth statistic: σk = σ∗(k, δk). This will guar-
antee (k, δk)-differential privacy of the statistic and enable
the guarantees to compose across statistics to provide (, δ)-
differential privacy overall. Note that the formula given by
Elahi et al. [14, Section 4.4.1] that relates σk to k and δk some-
times yields parameters that do not provide differential pri-
vacy. See Appendix A for details about calculating σk and a
counterexample to the formula of Elahi et al.
Allocating the privacy budget across statistics. Given to-
tal privacy budgets  and δ, PrivCount divides them among
the l statistics such that each statistic has high relative accu-
racy while providing (, δ)-differential privacy to the collec-
tive set. This improves upon PrivEx, which neither considers

1556how the activity of a single user might affect multiple statis-
tics nor how best to allocate a global privacy budget among
the different statistics. As suggested by the bound on σ by

Dwork et al. [12] (viz. σ ≤ ∆−1(cid:112)2 ln(2/δ), where ∆ is the

sensitivity), δ affects σ far less than , and thus PrivCount
simply divides it evenly: δk = δ/l for all k. PrivCount then
uses an estimated value vk for each sk to allocate  such that
the added noise values are expected to be proportional to the
values of the statistics. If sk represents a histogram, then vk
is the estimated total count across all bins, that is, vk is an
estimate for ∑b sk,b, which will help ensure that some bin has
low relative noise while not requiring that good estimates are
available for each bin. Estimating values can be a very effec-
tive method to improve the speed and accuracy of gathering
many, diverse statistics, as the speed at which the statistics
change over time can vary wildly (e.g. the frequency of Tor
connections to Web ports is typically orders of magnitude
larger than the frequency of connections to IRC ports). Esti-
mates can be obtained from data that Tor currently publishes,
from published measurement studies of Tor, or from some
earlier rounds of PrivCount measurement. If no reasonable
estimates are available, an equal allocation of  (i.e. k = /l)
can be obtained simply by using the same, arbitrary value as
an estimate for each statistic. Section 4.2 describes how we
estimated values for our data collection.

∑i w2

∑i w2

Given the estimated values vk, PrivCount allocates  in or-
der to minimize over all statistics the maximum ratio of the
noise standard deviation to the estimated value. That is, the
i σk/vk, where
values k are set to minimize ρ = maxk
σk = σ∗(k, δk) (note that the total noise standard deviation
for sk after aggregation is
i σk). PrivCount uses an iter-
ative search on ρ, each value of which determines an alloca-
tion of , to compute the optimal allocation. See Appendix A
for details on this computation.
Selecting noise weights. Noise with standard deviation σk
would provide (, δ)-differential privacy across all statistics
at each DC. However, the noise values get aggregated across
DCs and thus potentially result in more noise than necessary.
PrivCount therefore adjusts the noise across DCs by the noise
weight wi that is applied at each Di. The values wi are used
to set the desired balance between excessive noise in the ag-
gregated result and maintaining privacy even if some DCs
are malicious and do not add their component of the noise.
PrivEx uses noise weight similarly and sets each wi propor-
tional to the consensus-weight fraction of the Tor relay moni-
tored by Di under the assumption that PrivEx runs on all Tor
relays of which some fraction by consensus weight is hon-
est. However, for smaller-scale measurement deployments,
it is more appropriate to instead assume that some number of
DCs are honest. For example, if we assume that d of n DCs

are honest, then we can set wi = 1/√d at each Di.
3. SECURITY AND PRIVACY ANALYSIS

(cid:113)

(cid:113)

We abstract the information revealed by PrivCount with an
ideal functionality in the UC-framework [7]. The initializa-
tion and conﬁguration phases of PrivCount guarantee that
there exists some set of initialization and conﬁguration val-
ues such that each honest party either uses those values or
does not participate in aggregation. This is implemented
in these phases with a protocol for broadcast with abort [21],
which is captured by the macro MBA in Figure 1. The Priv-

Macro MBA(sid, P,B)

Start: Upon receipt of (sid, m) from P, store (sid, P,B, m, ∅).
Send: Upon input (sid, P(cid:48), m) from P, if (sid, P,B, m,P ) is cur-
rently stored for sid, P(cid:48) (cid:54)= P, and P(cid:48) /∈ P then send m to P(cid:48) and
update the stored value to (sid, P,B, m,P + P(cid:48)).
Abort: Upon input (sid, P(cid:48),⊥) from P, if (sid, P,B, m,P ) is cur-
rently stored for sid, P(cid:48)
(cid:54)= P, P(cid:48) /∈ P, and some P ∈ B
is corrupt, then send ⊥ to P(cid:48) and update the stored value to
(sid, P,B, m,P + P(cid:48)).

Figure 1: Macro for broadcast with abort from P to B

Count functionality FPC uses the MBA macro and is given
in Figure 2. Several security and privacy properties are evi-
dent from FPC, and, by the following theorem, they apply to
PrivCount:

THEOREM 1. PrivCount UC-realizes FPC in the hybrid PKI

model against any adversary that does not corrupt all SKs.

PROOF. See Appendix B.

By Thm. 1 and examining FPC, we can conclude that Priv-
Count securely aggregates the inputs and noise added by the
honest DCs as long as one SK is honest; that is, the adver-
sary only learns their sum. We can further observe that Priv-
Count provides forward privacy in that the adversary does
not learn the DC inputs during data collection that occurred
before corruption. We can also see that the adversary can ar-
bitrarily modify the output of the TS for sk,b even if it is not
compromised by choosing ∆k,b. We note that FPC and Thm. 1
demonstrate how to deﬁne and prove privacy for PrivEx-S2
as well, which was not shown by Elahi et al. [14].

We can show that sufﬁciently stringent policies on deploy-
ment documents ensure (, δ)-differential privacy, as shown
by the following theorem:

THEOREM 2. If at least one SK Si is honest, and if, for each
minimal subset S of DCs in the deployment document that Si re-
Di∈H w2
i ≥ 1, then the
ceives with honest subset H ⊆ S,
output of PrivCount is (, δ)-differentially private.

∑

(cid:113)

PROOF. See Appendix B.

We do note that differential privacy only provides privacy
for a limited amount of time and user activity, and an active
user will eventually exceed that amount. Thus, as the num-
ber of measurement rounds increases, the chance of revealing
something private about user activity increases. For exam-
ple, the existence of a regular Tor user may become apparent
over time even if it cannot be identiﬁed in the statistics from
any single measurement round. Goulet et al. [16] choose to
round differentially-private outputs in an attempt to avoid
such an information leak. This technique could be applied to
PrivCount’s statistics as well.

4. METHODOLOGY

In this section we describe our open-source prototype im-
plementation of PrivCount [1] and provide details about the
deployment that we set up and used to measure Tor. As the
privacy of Tor users is a primary concern, we practice data

1557Functionality FPC

Let A be the adversary. Copies of all inputs and outputs are sent to A except those with the input command. When a party is corrupted by
A, and all future inputs and outputs are with A.
Initialization: A deployment and its TS are established by receiving TS from some party PTS and PTS from each other party. Then the
macro MBA(init, PTS,P ) is run, where P is all parties except PTS, which receives the deployment document from the TS and broadcasts it
to the other parties. After MBA sends document Dinit to P, P aborts if Dinit = ⊥; otherwise, a bit b is accepted from P, where b = 1 indicates
acceptance of Dinit, and forwards it to PTS.
Conﬁguration: If each honest party has accepted Dinit and no party is currently in execution, the macro MBA(conﬁg, PTS,PSK) is run,
where PSK is the set of SKs, which receives a new conﬁguration document from PTS and broadcasts it to the other parties.
Execution setup: Once Pi has received a conﬁguration document Dconﬁg (cid:54)= ⊥, for each statistic sk, based on the values in Dinit and Dconﬁg,
ck counters are created, and the noise magnitude σk is computed, and the counters are each initialized with random noise sampled from
Normal(0, wiσk) and rounded. At this point SKs in the Dinit skip collection and enter aggregation.
Execution collection: Upon receiving (start, Pi) from PTS, if Pi has completed setup and is a DC in the Dinit, then it enters data collection.
While in data collection, Pi accepts inputs (input, Pi, k, x) as long as Pi is not corrupt. If statistic sk is a single number, then its counter is
increased by x, and if it is a histogram, the bin b such that Lk,b ≤ x < Rk,b is incremented by one. If Pi becomes corrupt, then its counters
cease to be incremented. Upon receiving (stop, Pi) from PTS, a Pi in data collection ends execution and waits for the next conﬁguration
document.
Execution aggregation: Upon receiving (share,Si, Pi) from PTS, if Pi is in aggregation, then Pi leaves execution and waits for the next
conﬁguration document. Then, once all honest parties have left execution, suppose that the honest DCs in Si are the same for all the honest
SKs and each Si contains some minimal subset of required DCs in Dinit. Let yk,b be the sum of the counters si
k,b summed over the DCs Di.
If PTS is corrupt, then the yk,b are output to the adversary, and otherwise, upon receiving ∆k,b from the adversary, yk,b is added to ∆k,b and
the values are output to PTS. Suppose instead some Si doesn’t contain any minimal subset of required DCs. Then, if PTS is corrupt, ⊥ is
output to the adversary, and otherwise ⊥ is output to PTS. Otherwise it must be that the Si of two SKs disagree on honest DCs, and then a
uniformly random integer mod q is output to the adversary if PTS is corrupt and otherwise is output to PTS.

Figure 2: Ideal functionality for PrivCount

minimization during the measurement process: we focus our
collection of statistics on only those that aid Tor trafﬁc model-
ing efforts [18]. Measurements from both entry and exit relay
positions are considered as both positions provide unique in-
formation that is useful for modeling purposes.

4.1 Measuring Tor with PrivCount

We use PrivCount to safely measure Tor. While the Priv-
Count protocol was described in Section 2, we now explain
how we collect and process the Tor events that will allow us
to compute our statistics of interest.
Collecting Events. To facilitate the collection and processing
of events from Tor, we extended the Tor control protocol [2]
with a new asynchronous event of type PRIVCOUNT. Once
an application authenticates with Tor and registers for our
new event, our modiﬁed Tor software will then emit the fol-
lowing whenever any of the sub-events occur: (i) exit stream
end: channel id, circuit id, stream id, num bytes read, num
bytes written, exit port, start time, end time; (ii) exit circuit
end: channel id, circuit id; (iii) entry circuit end: channel id,
circuit id, num client-bound cells, num exit-bound cells, start
time, end time, client IP; and (iv) entry connection end: channel
id. Each PrivCount DC connects to a Tor relay running our
modiﬁed software to collect this information, and processes
it as follows.
Classifying Streams. In order to better understand likely sim-
ilar behaviors of Tor users, DCs classify streams into trafﬁc
classes based on each stream’s exit port. Whenever an exit
stream end event is received, a DC will label the stream with
one of the following trafﬁc classes: HTTP/S ports 80 and 443
are labeled as Web; SSH and common IRC ports3 are labeled
as Interactive; and any remaining port is labeled as Other.

322, 194, 994, [6660, 6670], 6679, 6697, and 7000

Classifying by exit port only provides a rough approxima-
tion of behaviors: the classiﬁcation does not perfectly seg-
ment application protocols since different applications can
use the same port. However, our method reduces the privacy
risk over more accurate techniques like protocol snifﬁng via
deep packet inspection, and does not require the processing
and storage overhead of statistical learning.
Classifying Circuits. We classify circuits into those that ap-
pear to be used and those that do not. Whenever an exit cir-
cuit end event is received, a DC will label the circuit as active
if at least one stream was completed on that circuit and inac-
tive otherwise. Additionally, the circuit is labeled as carrying
Web, Interactive, and Other trafﬁc if at least one Web, Interac-
tive, and Other stream completed on the circuit, respectively.
Whenever an entry circuit end event is received, the circuit is
labeled as active if at least 8 cells have been transferred on
that circuit (6 cells for circuit setup, and at least 1 more in
each direction for circuit usage), and inactive otherwise.
Rotating IP Address Maps. PrivCount uses a mapping of
client IP address to count unique per-client statistics. Be-
cause of the sensitivity of storing client IP addresses in mem-
ory, we limit the amount of time over which we count per-
client statistics before clearing the map to 20 minutes. This
is comparable to the default circuit lifetime in Tor of 10 min-
utes, and we also note that the Tor Project takes a similar
approach for maintaining statistics such as per-country user
numbers but is currently storing client IP addresses over a
much longer and less-safe period of 24 hours.

4.2 PrivCount Deployment

We deployed PrivCount on the live Tor network with 1
tally server, 6 share keepers, and 7 data collectors monitoring
one Tor relay each. Our SKs were each run independently,
with 6 different operators on 6 different machines in 4 dif-
ferent countries. Our DCs and Tor relays were run by 2 op-

1558Table 1: Relays & DC machines in PrivCount deployment

Nickname

Fingerprint

NoneRunLong
PhantomTrain1
PhantomTrain2
PhantomTrain3
PhantomTrain4
PhantomTrain5
PhantomTrain6

0x9068A1E53C98
0x7EE45524BCA7
0xF789CB84E7C6
0x412BDCB24295
0x3A8A5432C008
0x3C0AD8F7DFC1
0x653632EEF25D

Host
1
2
2
3
3
3
3

Link Speed
100 Mbit/s
100 Mbit/s

1 Gbit/s

Table 2: Exploratory measurement round periods

Start Consensus (UTC)

End Consensus (UTC)

2016-05-17-14-00-00
2016-04-29-15-00-00
2016-05-15-02-00-00
2016-05-13-23-00-00
2016-05-16-05-00-00
2016-05-08-18-00-00

2016-05-18-13-00-00
2016-04-30-14-00-00
2016-05-16-01-00-00
2016-05-14-22-00-00
2016-05-17-04-00-00
2016-05-09-17-00-00

Name
Strict
Default
FS
FS+
FS++
Open

Table 3: In-depth measurement round periods

Start Consensus (UTC)

End Consensus (UTC)

2016-08-11-03-00-00
2016-07-16-18-00-00

2016-08-15-02-00-00
2016-08-06-17-00-00

Stat. Type
Entry
Exit

erators on 3 different host machines (see Table 1 for details).
We focused on providing a highly-secure SK infrastructure
to demonstrate the feasibility of running PrivCount with any
number of Tor relays, and indeed our SK setup requires 6 op-
erator or machine compromises to subvert, which provides
comparable security to Tor’s current set of 9 Directory Au-
thorities of which only 5 need to be compromised in order to
control the network consensus and thus Tor itself. We used
PGP keys as the PKI.
Collection Rounds and Statistics. We collected Tor mea-
surements in multiple rounds of different lengths. The main
constraint driving this approach is the need to add sufﬁcient
noise to obscure the impact of a user’s activity across all statis-
tics. Given the size of the relays in our deployment, collect-
ing as few as a dozen statistics requires on the order of a day
for the added noise to be less than 10% of the estimated value
of each. Thus we ran multiple exploratory rounds of 1 day
each and in-depth rounds of varying length. The two round
types are interleaved, although most exploratory rounds came
ﬁrst so that their results could inform the in-depth rounds.
Each collected statistic is either an entry statistic, that is, only
incremented when the relay is in the entry position of a Tor
circuit, or an exit statistic, that is, only incremented in the exit
position. This ensures that each statistic is only incremented
by the DC of one relay, thus limiting its sensitivity and re-
ducing the added noise.

In the exploratory rounds, we collected 13 of the single-
number type of statistics with the purpose of obtaining es-
timates of the average levels of various types of Tor activ-
ity. We present in Section 5.2 the results from running our
PrivCount deployment 6 times, where each collection phase
ran for 24 hours with a different exit policy (see Table 2 for
details). Before starting each collection phase, we adjusted
our exit relays’ exit policies and veriﬁed that the new policy
was correctly propagated to the ofﬁcial Tor consensus. Over
all exploratory collection phases, the mean probability of se-
lecting our relays in the entry position was 0.196% and the
mean probability of selecting our relays in the exit position
was 1.283%.

The statistics collected during the exploratory rounds are
single numbers. The only entry statistic is the sum of unique
client IPs observed in consecutive 10-minute time slices. The
exit statistics count active and inactive circuits, streams, and
data bytes sent or received. Each of these items is counted
overall as well as per-class (i.e. Web, Interactive, and Other).
In the in-depth rounds, we focused on statistics describing
the most signiﬁcant types of Tor activity, as determined from
the exploratory rounds. In some of the in-depth rounds we
focused on entry statistics while in others we focused on exit
statistics. When counting exit statistics, we used histograms
to get distributions of activity instead of simply averages. We
used only 3–4 bins per histogram in order to obtain sufﬁcient
relative accuracy of at least the most popular bins, given the
added noise. Multiple in-depth rounds were run to adjust
the bin ranges to obtain a more even distribution of the bin
counts.

In Section 5.3, we present 4 entry statistics (4 single num-
bers) collected throughout an in-depth measurement phase
that we ran for 4 days, and 26 exit statistics (10 single num-
bers and 16 histograms) collected throughout an in-depth
measurement phase that we ran for 21 days (see Table 3 for
details). The mean probability of choosing our relays in the
entry position was 0.130% during the entry statistics collec-
tion phase, and the mean probability of choosing our relays
in the exit position was 0.914% during the exit statistics col-
lection phase.

The entry statistics collected during the in-depth rounds
include the addition of the number of active and inactive
clients over 10-minute time slices as well as the total number
of client connections. The exit statistics collected include the
addition of a histogram tabulating circuit lifetimes as well as
histograms for circuits of the Web and Other classes measur-
ing the number of streams each circuit carries. In addition,
a histogram for inter-stream creation times is added for all
streams, Web streams, and Other streams. Histograms are
also added just for Web and Other streams that measure the
number of bytes out to the destination, the number of bytes
in to the client, and the ratio of bytes out to bytes in.

Because our exploratory measurements and analysis in-
dicated that Interactive-type trafﬁc is a minor part of Tor’s
trafﬁc distribution, we chose not to collect Interactive-related
statistics during our in-depth phases (to reduce the risk to
privacy and increase accuracy of the other measurements).
Relatedly, we chose to collect in-depth measurements using
the default exit policy because we found that it is the most
supported policy: 84.7% of exit relays accept ports 80 or 443
and block or partially block all ports that are also blocked by
the default policy.
Noise. Our PrivCount deployment uses differential-privacy
parameters of  = 0.3 and δ = 10−3. The  value is the
same used by Tor for hidden-service statistics [16]. δ can be
viewed as an upper bound on the probability of choosing a
noise value that violates -differential privacy.

We use a reconﬁguration time of 24 hours. Table 4 gives
the action bounds (see Section 2.3) that deﬁne the privacy af-
forded by our collection. Tor clients by default maintain one
entry connection, and so we provide privacy for 24 hours
worth of client observations at the entry as well as 12 total
entry connections (i.e. a new one every 2 hours). Tor clients
by default create 2 preemptive circuits and use each circuit
for 10 minutes. Therefore, we protect 24 hours of continu-
ous circuit use: 146 = 24 · 60/10 + 2. Note that we protect

1559Table 4: Action bounds in PrivCount deployment

Action
Simultaneous open entry connections
Time each entry connection open
New entry connections
New circuits

New Interactive circuits

New streams

Bound
1
24 hrs
12
146
20
30,000
20
144
10 MiB

New Interactive streams
New Other streams

Data sent or received

a smaller number of Interactive circuits (20), which typically
are used longer and thus created less frequently than those of
other classes. We protect 30,000 streams, which in particular
covers 100 Web pages with at most 300 requests per page, an
amount that includes 95% of Web pages measured by HTTP
Archive [5]. For Interactive and Other streams, we protect
only one stream for every circuit created within the action
bound (20 and 144, respectively). We also protect 10MiB of
trafﬁc in either direction. This covers 95% of Web pages mea-
sured by HTTP Archive, and it is ten times the trafﬁc amount
protected in Tor’s hidden-service statistics [16].

Setting the action bounds requires balancing between pri-
vacy and accuracy. To obtain reasonable accuracy, we must
choose bounds that aren’t high relative to actual activity on
Tor (and in particular on relays in our deployment). Thus,
we choose to provide stronger protection for actions that are
quite frequent (e.g. creating a Web stream) than for those
that are less frequent (e.g. creating an Interactive stream).
This might appear inconsistent, but we argue that the pri-
vacy protections are sufﬁcient in every case and are simply
even better in some cases than others.

The sensitivities of the statistics are easily determined from
these action bounds. For example, the sensitivity of the statis-
tic counting active circuits is simply 146, the action bound
for creating circuits. Note that the histograms are sensitive
to the number of inputs that can change value and not to the
change in their values. For example, the sensitivity of the his-
togram of inter-stream creation times is 60,000, because we
allow a single user to change the lifetimes and existence of
30,000 streams, and the sensitivity of a histogram is twice the
number of inputs that can change. Using per-statistic sensi-
tivities to determine the noise standard deviation is in gen-
eral a worst-case approximation that allows all statistics to si-
multaneously change by as much as their sensitivities, but for
our deployment the statistics can in fact all simultaneously
change by that much.

We set noise weights to provide differential privacy if at
least one machine running DCs is honest. The 3 machines in
our deployment run 1, 2, and 4 DCs (recall that each DC is
paired with a Tor relay). For a machine running k ∈ {1, 2, 4}
DCs, the noise weight of its DCs is 1/√k. Thus any one hon-
est machine contributes all the necessary noise, and if all are
honest then √3 times as much noise is added as is necessary.
We include the entire set of DCs as the minimal set, as in
our relatively small deployment losing the input of any relay
would signiﬁcantly affect the accuracy of our statistics.
Estimating values. For exploratory rounds, we estimated the
values of the statistics using the extra-info documents pub-
lished by Tor relays ( [3], Section 2.1.2). These documents in-
clude per-relay statistics, including in particular data about

(i) users seen at entries; (ii) circuits, including their trafﬁc
amounts; and (iii) streams at exits, including per-port num-
bers and trafﬁc amounts. The data from these three cate-
gories are incomplete because they are all turned off by de-
fault and are thus reported by a minority of relays. Moreover,
they are limited to only those statistics Tor has built in, and
their accuracy is generally poor, as each relay obfuscates its
data (e.g. rounding up to a given multiple), thus producing
noise that scales with the number of relays. We also note that
these statistics generally do not satisfy any formal privacy
notion, and their accuracy and frequency is chosen via ad hoc
privacy arguments. However, they provide enough data for
us to produce reasonable estimates for each of the statistics
in our exploratory rounds. We produce estimates from the
extra-info values by adjusting them for our relays’ weights
and the length of the exploratory round, making educated
guesses to ﬁll in a few gaps (e.g. guessing the number of Web
circuits based on the number of observed Web streams).

For the in-depth rounds, we use the results from our ex-
ploratory rounds, adjusted for the change in round length.
Most of the statistics added to the in-depth over exploratory
rounds are histograms. For these, we only need to estimate
the total number of inputs (i.e. not their values), and the ex-
ploratory rounds provide such estimates.
Research Ethics. The Tor Project issues safety guidelines4 for
researchers studying the live Tor network to help them con-
sider how their research might impact Tor users. We care-
fully consider these guidelines when designing our measure-
ments. We would highlight that we practice data minimiza-
tion by limiting the statistics we gather to just those needed
to understand the major features of client and exit trafﬁc for
purposes of modeling Tor (e.g. in Shadow [18]) and improv-
ing Tor’s performance. We also note that all of our mea-
surements are designed to preserve user privacy and are safe
to release publicly. Overall, measuring Tor while protecting
users is a primary challenge addressed by this work.

5. MEASUREMENT RESULTS

In this section, we provide details about our measurement

strategy while describing the measurement results.
5.1 Exit Policy Analysis

Each Tor relay is conﬁgured with an exit policy which spec-
iﬁes the destination ports5 to which the relay is and is not al-
lowed to connect. The exit policies of all relays are included
in Tor consensus documents and are used by Tor clients to
choose suitable exit nodes for their intended destination port.
As a result, an exit relay with a very restrictive exit policy (e.g.
one that allows only port 22) will potentially observe signif-
icantly different trafﬁc characteristics than an exit relay that
allows all ports (including ports 80 and 443).

In order to ensure that the measurements taken at our exit
relays provide us with an accurate view of all Tor network
trafﬁc, we conducted an analysis of the exit policies used by
Tor exit relays. After analyzing multiple consensuses that
were produced during April 2016, we found that all 219 ports
rejected in Tor’s default exit policy6 (most of which are re-
4https://research.torproject.org/safetyboard.html
5Our usage of exit policies only involves port numbers, al-
though IP addresses may also be speciﬁed.
6reject 25, 119, [135-139], 445, 563, 1214, [4661-4666], [6346-
6429], 6699, [6881-6999]; accept *

1560Table 5: Ports considered for exploratory measurements

Trafﬁc Type

HTTP/S
BitTorrent Base
BitTorrent Extended
Other File-Sharing
Various

Label
web
btb
bte
ofs
var

Ports

80,443
[6881-6889]
[6890-6999]
1214,[4661-4666],[6346-6429],6699
25,119,[135-139],445,563

Table 6: Policies considered for exploratory measurements
and weighted exit bandwidth supporting each policy

Name
Strict
Default
FS
FS+
FS++
Open

Policy by Label (see Table 5)
reject web, btb, bte, ofs, var

accept web; reject btb, bte, ofs, var
accept web, ofs; reject btb, bte, var
accept web, bte, ofs; reject btb, var
accept web, btb, bte, ofs; reject var

accept web, btb, bte, ofs, var

Exit BW (%)
14
68
3.7
2.7
9.9
1.1

lated to ﬁle-sharing) constituted the 219 most rejected ports
in Tor. We also found that similar fractions of exit bandwidth
are available for several of the ports that are blocked by de-
fault. Table 5 shows these similarly grouped ports and the
type of trafﬁc commonly associated with them, as well as the
ports of the most accepted trafﬁc type (HTTP/S).

We continued our analysis to understand which combina-
tions of the groups of ports in Table 5 are accepted and re-
jected by each relay. We computed the percentage of exit
relays, weighted by their probability of selection in the exit
position, that accepted or rejected each group of ports. Of
the 25 = 32 possible combinations of these exit policies, only
7 of them were valid (that is, at least one exit matched the
policy). Table 6 lists the top 6 policies7 and the percentage
of exit bandwidth that supported each policy (we ignore the
remaining valid exit policy as it was supported by less than
0.1% of exit bandwidth).

We found that the default policy is by far the most popu-
lar policy: it is supported by 68% of relays and supports exit
to the 65,315 most allowed ports. We also found that 17%
of exits support at least some of the ports commonly asso-
ciated with ﬁle-sharing, even though those ports are among
the least allowed ports. Finally, over 14% of exit bandwidth
does not support exiting to the HTTP/S ports 80 and 443,
although it is the most allowed trafﬁc type in Tor. We se-
lected the exit policies to use on our exit relays during the
exploratory phase based on the results of this analysis.

5.2 Exploratory Measurements

We ﬁrst discuss the measurement results collected with
our PrivCount deployment before describing how to use them
to infer full Tor network statistics.
Results. Our primary measurement results related to trafﬁc
distribution are shown in Figure 3. Figure 3a shows the total
number of active circuits (circuits with at least one completed
stream) as counted by our exit relays over the 24 hour collec-
tion intervals and according to the trafﬁc type classiﬁed by
PrivCount. Figure 3b similarly shows the number of streams
(TCP connections that exit the Tor network) observed by our
exit relays, and Figure 3c shows the sum of the amount of
data transferred in both directions on those streams. The col-
lected measurement results for each of the exit policies from

7All policies are prepended to Tor’s default policy.

(a) Counts of active Tor circuits

(b) Counts of connections exiting Tor

(c) Counts of data transferred on connections exiting Tor

Figure 3: Measurement results collected while using vari-
ous exit policies, by the trafﬁc type classiﬁed by PrivCount.
Error bars show 95 percent conﬁdence intervals.

Table 6 are shown with 95% conﬁdence intervals that account
for the noise that was probabilistically added to each counter.
Consistent across all six exit policies and all three statis-
tics shown in Figure 3, we observed very low counts for In-
teractive trafﬁc relative to Web or Other. This indicates that
Interactive trafﬁc is a very minor part of Tor’s overall trafﬁc
distribution and so may be safely ignored during later mea-
surement periods.

We also observed that the number of circuits (3a) and the
number of streams (3b) for the Web class remained relatively
consistent across all of the exit policies that we used dur-
ing measurement, except for the strict policy. The number
of streams did show some ﬂuctuation among exit policies,
which we attribute to the somewhat large error bounds for
the Web class. Note that the strict exit policy does not allow
trafﬁc that would have been classiﬁed as Web, and therefore
the positive counts for Web under the strict policy in Fig-
ure 3 correspond directly to the noise that was added to those
counters by PrivCount.

InteractiveWebOther0123456NumberofCircuits×1064,78056,315397,9796,6451,415,683490,7442,8171,129,0561,126,7311,8801,608,1164,927,4503611,467,0243,513,1196,7571,422,4201,890,266StrictDefaultFSFS+FS++OpenInteractiveWebOther0.00.51.01.52.02.53.03.54.04.5NumberofStreams×10711,5787,551,9812,518,2658,90531,335,1621,863,0136,99528,947,6112,467,31415,60123,581,9707,403,54810,23134,608,62610,011,7628,47532,297,26615,694,073StrictDefaultFSFS+FS++OpenInteractiveWebOther0.00.51.01.52.02.5StreamDataTransferred(GiB)×10321541062,28435811,68135831,48560441,8531,127134771,295StrictDefaultFSFS+FS++Open1561Table 7: 10-minute mean Tor network activity inferred from exploratory measurements
Trafﬁc
Class

Stream Data (GiB)
Count

Streams (×103)

95% CI

Count

Total
Interactive
Web
Other

Active Circuits (×103)
95% CI
Count
1,200 (100%) ±500 (42%)
±2 (67%)
3 (0%)
640 (53%)
±80 (13%)
±50 (9%)
580 (48%)

17,000 (100%) ±4,000 (24%)
±4 (80%)
5 (0%)
15,000 (88%)
±4,000 (27%)
±200 (11%)
1,900 (11%)

95% CI
1,100 (100%) ±300 (27%)
±1 (33%)
3 (0%)
1,000 (91%)
±300 (30%)
±40 (15%)
260 (24%)

Although Web circuits and streams remain relatively con-
sistent across exit policies, Other circuits and streams do not.
The number of observed Other circuits (3a) increases dra-
matically and somewhat sporadically when using exit poli-
cies that allow exiting to ﬁle-sharing ports. The number of
observed Other streams (3b) similarly increases when ﬁle-
sharing ports are allowed, and the number of streams trends
higher as less restrictive exit policies are used (and therefore
more ﬁle-sharing ports are allowed). These observations fol-
low common trafﬁc patterns of ﬁle-sharing protocols, which
tend to create many connections with their peers in order to
decrease download times for large ﬁles.

Similar to the circuit and stream count trends, we observed
that the amount of Other stream data transferred on con-
nections exiting Tor (3c) also increases signiﬁcantly as the
number of ﬁle-sharing ports that our exit relays allow in-
creases. However, unlike the Web circuit and stream counts
(which are mostly unaffected by the increase in Other cir-
cuits and streams), the amount of Web data transferred de-
creases as the amount of Other data transferred increases.
This suggests a crowding-out situation, where each of the
trafﬁc classes are in direct competition for the limited band-
width of our exit relays and ﬁle-sharing trafﬁc wins the com-
petition. The number of Web circuits (3a) and streams (3b)
are consistent even when the amount of transferred Web data
(3c) decreases, indicating that the performance for the web
streams that coexist with ﬁle-sharing streams may be sig-
niﬁcantly reduced. If this hypothesis holds true, then users
could potentially improve their web browsing experience sim-
ply by excluding those exit relays that allow ﬁle-sharing ports
in their exit policies when building circuits. This presents an
interesting area for future work.

Finally, we observed that restricting Web trafﬁc from exit-
ing our relays using the strict policy did not result in a dra-
matic increase in circuits, streams, or data transferred for
either the Interactive or Other classes. This increases our
conﬁdence that there are not other ports whose activity is
crowded out by the activity associated with the Web ports.
Inferring Network Totals. Our results from the exploratory
phase improve our understanding of how trafﬁc character-
istics vary with different exit policies. However, the results
can be somewhat misleading when compared directly with-
out accounting for the relative exit bandwidth support avail-
able for each exit policy type. Accounting for the popularity
of each exit policy used during measurement will provide a
better estimate of the overall trafﬁc characteristics over the
entire Tor network. We now produce such an inference.

We collected the 24 consensus ﬁles (one for each hour) that
were produced during each of the 6 exploratory measure-
ment rounds presented above (24 · 6 = 144 ﬁles total). For
each set of 24 ﬁles, which corresponds to a single exit pol-
icy and a collection of measurement results, we computed
the mean fractional weight for selecting our relays in the en-
try position as Wg, the mean fractional weight for selecting

Table 8: Comparison of exit trafﬁc distribution
This Work

Trafﬁc Class

2008 [23]

s HTTP/S

n
n
o
C
s HTTP/S

Interactive
Other

Interactive
Other

e
t
y
B

2010 [8]
96.51% 70.40%
0.08%
1.72%
3.41% 27.88%
59.52% 41.81%
0.23%
0.26%
51.82% 57.92%

88%
0%
11%
91%
0%
24%

our relays in the exit position as We, and the mean fractional
weight of other relays supporting the exit policy that we used
during that collection phase as Wp. We then scale our mea-
sured entry statistics by Wp/Wg and our measured exit statis-
tics by Wp/We, and sum the scaled results from all phases to
produce a ﬁnal network total estimate.

Table 7 shows the inferred estimates of the number of ac-
tive circuits, streams, and total amount of data transferred
on streams for each trafﬁc class and across the entire Tor net-
work during an average 10-minute interval. Note that for
the statistics that don’t sum to 100%, the percentages shown
in the table are calculated using a separate, single total count
that we collected (e.g. total active circuits) rather than a sum
of the three class-speciﬁc individual counts. This was done
to avoid aggregating noise and improve the accuracy of the
estimate where possible. The conﬁdence intervals shown in-
clude the uncertainty associated with the noise added to the
counters as well as the sampling error.

As with our direct measurements, our inference indicates
that Interactive trafﬁc is a very minor contributor to the over-
all inferred activity on Tor. Our inference also indicates that
Web trafﬁc is the dominant type of trafﬁc seen on the network
for all three of the statistics shown in the table. In particular,
we found that Web trafﬁc accounts for 88% of the streams
created in Tor and 91% of the stream data. A comparison to
previous measurement studies is given in Table 8. Overall,
our results indicate that HTTP/S usage has increased since
2010 relative to other protocols, which we suggest is due to
usability improvements in browsing the web with Tor (e.g.
Tor Browser).
5.3 In-Depth Measurements

We present the results from our in-depth rounds as in-
ferred Tor network totals that we computed by adjusting each
entry and exit statistic by our mean entry and exit probability,
respectively. Note that the inferences based on exit statistics
assume that relays using non-default exit policies observe
trafﬁc characteristics similar to those observed while using
the default policy. Future work should consider taking these
measurements with different exit policies (e.g., that allow or
partially allow ﬁle-sharing ports).
Entry Statistics. The entry statistics that we collected focused
on counting the number of observed unique clients and the
number of those clients that were active and inactive. Re-

1562Table 9: 10-minute mean Tor network activity inferred from
single-counter in-depth entry statistics

Statistic

Unique Clients (×103)
Active
Inactive
Client Conns (×103)

Count

95% CI
710 (100%) ±85 (12%)
550 (77%)
±70 (13%)
140 (20%)
±30 (21%)
560 (100%) ±60 (11%)

Table 10: 10-minute mean Tor network activity inferred
from single-counter in-depth exit statistics

Statistic

Active Circuits (×103)
Web
Other
Inactive Circuits (×103)
Streams (×103)
Web
Other

Stream Data (GiB)

Web
Other

Count

95% CI
±200 (14%)
1,400 (100%)
±100 (14%)
700 (50%)
±50 (7%)
680 (49%)
±100 (8%)
1,300 (100%)
15,000 (100%) ±3,000 (20%)
17,000 (113%) ±3,000 (18%)
±200 (13%)
1,600 (11%)
±200 (15%)
1,300 (100%)
900 (70%)
±200 (22%)
±40 (17%)
230 (18%)

call that the unique client IP addresses were recounted over
10-minute intervals for privacy reasons. Table 9 shows the
mean inferred counts over all 10-minute intervals that oc-
curred during our 4-day entry measurement period (there
are 4 · 24 · 6 = 576 such intervals) as well as the conﬁdence
intervals (accounting for noise and sampling error).
We found that Tor has about 700 thousand unique clients
connecting to the network during an average 10-minute in-
terval. Compared to Tor’s own estimate of about 1.75 million
clients per day in May 2016 [4], this suggests that the client
population turns over about 2.5 times a day. Somewhat sur-
prisingly, we found that about 130 thousand clients have in-
active circuits during an average 10 minutes. Also, we found
fewer connections from clients compared to the number of
unique clients, but we note that the client connections that
did not close during our 4 day measurement period would
not have been counted (because PrivCount counts connec-
tions when they are closed).
Exit Statistics. Our exit statistics focus on circuit and stream
statistics to help better understand Tor trafﬁc. Table 10 shows
the mean inferred counts over all 10-minute intervals that oc-
curred during our 21-day exit measurement period (there are
21 · 24 · 6 = 3024 such intervals) as well as the conﬁdence in-
tervals (accounting for noise and sampling error). Although
all of the counts were taken over the entire 21-day exit mea-
surement period, we show the counts as 10-minute means
for clarity of presentation.

We inferred that there are 1.4 million active circuits used
during an average 10 minutes, which corresponds to between
2 and 3 active circuits per active client. We also found about
the same number of inactive circuits as active circuits during
an average 10 minutes, which may not be surprising given
the large number of inactive clients we inferred from the en-
try statistics and also given that some of Tor’s circuits that are
preemptively generated for performance reasons may never
be used. As in the exploratory rounds, we found that a ma-
jority of the active circuits carry Web trafﬁc, and that an over-
whelming majority of streams and stream data corresponds
to Web trafﬁc. Our inferences indicate that there are an av-
erage of about 25 Web streams per Web circuit, and that exit

relays exchange an average of about 50 KiB with the desti-
nation for each such stream. Similarly, there are an average
of about 2 Other streams per Other circuit, and an average
of about 150 KiB is exchanged with the destination per Other
stream.

The histogram statistics are shown in Table 11. For each
statistic, the table shows the bin ranges and the relative counts
as percentages of the number of times the statistic fell within
each bin range, and the 95% conﬁdence interval that applies
to each bin count. The percentages shown were computed
by taking the bin count as a fraction of the single-counter to-
tal counts (i.e. number of circuits, streams, and stream data)
for each trafﬁc type (i.e. Total, Web, and Other), and there-
fore the conﬁdence intervals account for the ranges of both
the total and the bin counts. We believe that this data would
be useful for modeling Tor trafﬁc distributions in tools like
Shadow [19]. In the remainder of this section, we highlight
some of the results.

We found that a majority of Web streams per circuit have
fewer than 7 streams; by comparison, HTTP Archive [5] re-
ports that 23% of pages have less than 10 connections per
page. One potential reason for the relatively lower stream
count may be because Tor Browser blocks javascript by de-
fault, which would prevent loading many embedded page
objects. Most Other circuits have fewer than 3 streams.

We found that exit relays read less than 2 KiB and between
2 KiB and 16 KiB from 33% and 37% of Web streams, respec-
tively, while they read less than 2 KiB from 56% of Other
streams. Exit relays write less than 1 KiB to 77% of Web
streams and 46% of Other streams. We also measured the
“Bytes Per Stream Ratio” statistic that was computed using
log2(byteswritten/bytesread) as input to the histogram for each
stream. Under this interpretation, the range (-∞,-1) corre-
sponds to the number of streams where the exit relay read
more than twice as many bytes as wrote, the range [-1,1) cor-
responds to the number of streams where the exit relay read
and wrote about the same amount, and the range [1,∞) cor-
responds to streams where the exit relay read less than half
as much as wrote. Our results indicate that exit relays are
mostly reading from Web streams, but that a bimodal distri-
bution exists for Other streams where the exit relay writes
more than reads for 12% of streams. Finally, we found that
68% of Web streams on the same circuit were created within
1 seconds of one another, while Other streams were more
evenly dispersed across the bins we counted.

6. RELATED WORK
Privacy-Preserving Data Aggregation. There are many de-
signs for privacy-preserving data aggregation in networks
[6, 9, 15, 25]. The most relevant of these, and work that we
build on directly, is the PrivEx system of Elahi et al. This sys-
tem is designed speciﬁcally to gather statistics on Tor. PrivEx
provides the S2 protocol, which we build on to create Priv-
Count, and the D2 protocol. The D2 protocol uses homomor-
phic encryption and zero-knowledge proofs to provide some
additional security and tolerance against Tally Key Server
(i.e., PrivCount SK) faults. We choose to build on the simpler
and faster S2 protocol because the security improvements of
D2 are relatively minor, and we are able to add fault toler-
ance of the more error prone DCs to S2.

PrivCount expands on PrivEx-S2 in many ways to make
it more ﬂexible and practical. In general, the modiﬁcations
make the protocol suitable for exploratory and diverse Tor

1563Table 11: Distributions of Tor network activity from histogram-counter in-depth exit statistics

Bin Ranges and Count Distribution (with ± 95% CI)

Statistic

Active Circuit Life Time (s)
Streams Per
Circuit

Total

Client-bound
Bytes Per Stream

Server-bound
Bytes Per Stream

Bytes Per
Stream Ratio

Inter-stream
Creation Time (s)

[1, 480):
[1, 3):
[1, 3):
[1, 3):
[1, 2048):
[1, 2048):
[1, 2048):
[1, 512):
[1, 512):
[1, 512):
(-∞, -1):
(-∞, -1):
(-∞, -1):
[0, 1):
[0, 1):
[0, 1):

57%±44% [480, 720):
46%±43% [3, 7):
36%±37% [3, 7):
78%±15% [3, 7):
60%±40% [2048, 16384):
33%±33% [2048, 16384):
56%±21% [2048, 16384):
57%±39% [512, 1024):
41%±35% [512, 1024):
40%±19% [512, 1024):
80%±45% [-1, 1):
70%±42% [-1, 1):
45%±20% [-1, 1):
87%±47% [1, 5):
68%±41% [1, 5):
16%±16% [1, 5):

45%±42% [720, 1200):
38%±41% [7, 15):
22%±33% [7, 15):
10%±9% [7, 15):
38%±35% [16384, 65536):
37%±34% [16384, 65536):
9%±15% [16384, 65536):
25%±31% [1024, 4096):
36%±34% [1024, 4096):
6%±14% [1024, 4096):
25%±31% [1, ∞):
15%±28% [1, ∞):
14%±16% [1, ∞):
16%±29% [5, 10):
8%±27% [5, 10):
10%±15% [5, 10):

Web
Other
Total

Web
Other
Total

Web
Other
Total

Web
Other
Total

Web
Other

0%±33% [1200, ∞):
31%±40% [15, ∞):
13%±31% [15, ∞):
0%±8% [15, ∞):
32%±33% [65536, ∞):
5%±26% [65536, ∞):
8%±15% [65536, ∞):
38%±34% [4096, ∞):
23%±30% [4096, ∞):
15%±16% [4096, ∞):
0%±21%
0%±21%
12%±15%
1%±25% [10, ∞):
13%±28% [10, ∞):
3%±14% [10, ∞):

0%±35%
9%±37%
3%±28%
2%±8%
6%±26%
0%±24%
11%±15%
0%±24%
2%±25%
1%±14%

0%±23%
14%±28%
12%±15%

measurements by a small deployment while maintaining its
suitability for Tor-wide measurement. Major contributions of
the PrivCount design over PrivEx include multi-phase itera-
tive measurement, an expanded privacy notion that simul-
taneously handles multiple types of measurements, optimal
allocation of the  privacy budget across multiple statistics,
and a composable security deﬁnition and proof. Our imple-
mentation is also a more capable and reliable tool, with 29
new Tor statistics, resilience against node failure and reboots,
and simpler conﬁguration and setup.
Measurement. There have been few published studies mea-
suring Tor network trafﬁc characteristics. Perhaps the most
well-known is the 2008 study by McCoy et al. [23] in which
the authors ran an exit relay and used tcpdump to capture
the ﬁrst 150 bytes of every packet (which included up to 96
bytes of application payloads). The study raised ethical and
legal questions [28], as they collected, stored, and manually
analyzed sensitive data. Chaabane et al. [8] conducted a simi-
lar study, but used a customized deep packet inspection soft-
ware (OpenDPI) to further analyze packets by protocol.

Although we also measure Tor, privacy is a primary mo-
tivation of our work: PrivCount provides formal guarantees
about security and privacy and the only outputs from the
measurement process are the aggregated, noisy counts that
are safe to share publicly. Further, to the best of our knowl-
edge, neither of the previously mentioned studies used a non-
default exit policy, while we found that a non-trivial shift in
trafﬁc type occurs when switching from the default exit pol-
icy to one that allows common ﬁle-sharing ports (Section 5).
In a case study on Tor measurement, Loesing et al. [22]
measured countries of connecting clients and exiting trafﬁc
by port while providing guidelines for safely measuring po-
tentially sensitive data in anonymity networks. They obfus-
cate the true measured values by rounding them to common
multiples, but unlike PrivCount they do not aggregate across
relays or provide any formal deﬁnitions of security or pri-
vacy. Tor currently allows relays to enable the collection and
distribution [4] of statistics implemented by Loesing et al.,
but it is not currently enabled by default.

Tor hidden service usage has also been measured more
recently [16, 26]. We chose not to focus on hidden services
because they account for less than 4% of all Tor trafﬁc [20].
However, PrivCount provides a promising way to measure
hidden-service statistics that cannot be safely gathered with-

out aggregation, such as the number of hidden-service con-
nections (see [16, Section 4]).

7. CONCLUSION

We build on recent advancements in privacy-preserving
aggregation to develop a Tor measurement system called Priv-
Count. We detailed the PrivCount protocol and provided for-
mal arguments about its security and privacy properties. We
also implemented PrivCount and used it to perform a mea-
surement study on Tor users and trafﬁc. Among the mea-
sured statistics that we collected, we found that on average
710 thousand clients are connected to Tor at any given time,
of which 550 thousand (77%) are active. Although Tor has
its own estimates of the number of clients, we are the ﬁrst to
measure the distinct number of active clients. We also mea-
sured Tor trafﬁc characteristics under various exit policies,
providing the ﬁrst analysis of how exit policies affect trafﬁc
distribution to the best of our knowledge. We found that Web
ports account for 91% of bytes exiting Tor.
Future Work. Future work should consider taking measure-
ments over longer time periods and with various exit policies
in order to improve inference accuracy. Additional insights
could be obtained with our tools and methods by extending
the set of collected statistics to include onion service statis-
tics. More robust and secure methods for counting the client
population over varying time periods and without sacriﬁc-
ing privacy could allow for analysis of client churn. Finally,
our measurements are well-suited to advance Tor research,
especially in the area of trafﬁc modeling and simulation.
Acknowledgments. We thank the anonymous reviewers for
their suggestions and feedback which have helped to im-
prove this paper. We also thank Tim Wilson-Brown, Tariq
Elahi, David Goulet, and Micah Sherr for their assistance in
running share keepers for our deployment. This work has
been partially supported by the Defense Advanced Research
Project Agency (DARPA), the National Science Foundation
(NSF) under grant number CNS-1527401, and the Depart-
ment of Homeland Security (DHS) Science and Technology
Directorate, Homeland Security Advanced Research Projects
Agency, Cyber Security Division under agreement number
FTCY1500057. The views expressed in this work are strictly
those of the authors and do not necessarily reﬂect the ofﬁcial
policy or position of DARPA, NSF, DHS, or the U.S. Naval
Research Laboratory.

15648. REFERENCES
[1] PrivCount source code.

https://github.com/privcount/privcount.

[2] TC: A Tor control protocol (Version 1). https://gitweb.

torproject.org/torspec.git/tree/control-spec.txt.
[3] Tor directory protocol, version 3. https://gitweb.

torproject.org/torspec.git/plain/dir-spec.txt.
[4] Tor Metrics. https://metrics.torproject.org/.
[5] HTTP Archive. http://httparchive.org/, May 2016.
[6] BURKHART, M., STRASSER, M., MANY, D., AND

DIMITROPOULOS, X. A. SEPIA: Privacy-preserving
aggregation of multi-domain network events and
statistics. In USENIX Security Symposium (2010).

[7] CANETTI, R. Universally composable security: A new

paradigm for cryptographic protocols. In IEEE
Symposium on Foundations of Computer Science (2001).

[8] CHAABANE, A., MANILS, P., AND KAAFAR, M.

Digging into anonymous trafﬁc: A deep analysis of the
Tor anonymizing network. In IEEE Network and System
Security (2010).

[9] CHEN, R., REZNICHENKO, A., FRANCIS, P., AND

GEHRKE, J. Towards statistical queries over distributed
private user data. In USENIX NSDI (2012).

[10] DINGLEDINE, R., MATHEWSON, N., AND SYVERSON,
P. Tor: The second-generation onion router. In USENIX
Security (2004).

[11] DWORK, C. Differential privacy. In International

Colloquium on Automata, Languages and Programming
(2006).

[12] DWORK, C., KENTHAPADI, K., MCSHERRY, F.,

MIRONOV, I., AND NAOR, M. Our data, ourselves:
Privacy via distributed noise generation. In Eurocrypt.
2006.

[13] DWORK, C., MCSHERRY, F., NISSIM, K., AND SMITH,

A. Calibrating noise to sensitivity in private data
analysis. In Theory of Cryptography Conference (2006).
[14] ELAHI, T., DANEZIS, G., AND GOLDBERG, I. Privex:
Private collection of trafﬁc statistics for anonymous
communication networks. In ACM Conference on
Computer and Communications Security (2014).

[15] ERLINGSSON, U., PIHUR, V., AND KOROLOVA, A.

Rappor: Randomized aggregatable privacy-preserving
ordinal response. In ACM Conference on Computer and
Communications Security (2014).

[16] GOULET, D., JOHNSON, A., KADIANAKIS, G., AND
LOESING, K. Hidden-service statistics reported by
relays. Tech. rep., The Tor Project, Inc., April 2015.
[17] HARDT, M., AND ROTH, A. Beating randomized

response on incoherent matrices. In ACM Symposium on
Theory of Computing (2012).

[18] JANSEN, R., BAUER, K., HOPPER, N., AND

DINGLEDINE, R. Methodically modeling the Tor
network. In USENIX Conference on Cyber Security
Experimentation and Test (2012).

[19] JANSEN, R., AND HOPPER, N. Shadow: Running Tor in

a box for accurate and efﬁcient experimentation. In
Network and Distributed System Security Symposium
(2012).

[20] KADIANAKIS, G., AND LOESING, K. Extrapolating
network totals from hidden-service statistics. Tech.
rep., The Tor Project, January 2015.

[21] LINDELL, Y. Composition of Secure Multi-Party Protocols,

A Comprehensive Study. Lecture Notes in Computer
Science. Springer, 2003.

[22] LOESING, K., MURDOCH, S. J., AND DINGLEDINE, R.

A case study on measuring statistical data in the Tor
anonymity network. In Financial Cryptograpy and Data
Security (2010).

[23] MCCOY, D., BAUER, K., GRUNWALD, D., KOHNO, T.,

AND SICKER, D. Shining light in dark places:
Understanding the Tor network. In Privacy Enhancing
Technologies Symposium (2008).

[24] MCSHERRY, F., AND MIRONOV, I. Differentially private
recommender systems: building privacy into the net. In
ACM knowledge discovery and data mining (KDD) (2009).

[25] MELIS, L., DANEZIS, G., AND CRISTOFARO, E. D.
Efﬁcient private statistics with succinct sketches. In
Network and Distributed System Security Symposium
(2015).

[26] OWEN, G., AND SAVAGE, N. Empirical analysis of Tor

hidden services. IET Information Security (2016).

[27] SHIVA PRASAD KASIVISWANATHAN, A. S. On the

‘semantics’ of differential privacy: A bayesian
formulation. J. of Privacy and Conﬁdentiality 6, 1 (2014).

[28] SOGHOIAN, C. Enforced community standards for
research on users of the Tor anonymity network. In
Workshop on Ethics in Computer Security Research (2011).

1565APPENDIX
A. DETERMINING OPTIMAL NOISE

Given  and δ for the statistics, PrivCount allocates  and
δ across the statistics by choosing k and δk for each statis-
tic sk. Then, given k and δk, it computes a value σk such
that the Gaussian mechanism [12] with standard deviation
σk provides k-differential privacy with probability 1 − δk.
This guarantees (, δ)-differential privacy across all statistics.
We ﬁrst give an algorithm to compute σk, next give a coun-
terexample showing that the formula of Elahi et al. [14] (Sec-
tion 4.4.1) does not guarantee (, δ)-differential privacy, and
ﬁnally give an algorithm to allocate  to minimize across all
statistics the maximum ratio of σk to the estimated value of
the statistic vk.
A.1 Computing σ∗(, δ)

Simple formulas to determine σ given  and δ are pre-
sented for the single-dimensional case by Dwork et al. [12]
(Section 2.1) and for the multi-dimensional case by Hardt
and Roth [17] (Theorem 2.6). However, for the single-dimensional
Gaussian mechanism, we can slightly improve upon this while
still providing (, δ)-differential privacy across all statistics.
Let D be the set of possible inputs among which we have
deﬁned adjacency (see Section 2.3 for a discussion of adja-
cency). Let D ∼ D(cid:48) indicate that inputs D, D(cid:48) ∈ D are ad-
jacent. Let mechanism M : D → R be a randomized al-
gorithm with some output space R. The deﬁnition of (, δ)-
differential privacy is as follows:

DEFINITION 1. M satisﬁes (, δ)-differential privacy if, for

all adjacent inputs D and D(cid:48) and all S ⊆ R,

Pr[M(D) ∈ S] ≤ ePr[M(D(cid:48)) ∈ S] + δ.

Let f : D → R be some query. The Gaussian mechanism
depends on the sensitivity of f , which is deﬁned as follows:

DEFINITION 2. The sensitivity of f is

∆ f = max
D∼D(cid:48):
D,D(cid:48)∈D

| f (D) − f (D(cid:48))|.

To deﬁne the Gaussian mechanism formally, recall from
Section 2.2 that Normal(µ, σ) denotes the normal distribution
with mean µ and standard deviation σ. Given ∆ f , the Gaus-
sian mechanism using the bound for σ of Dwork et al. [12] is
as follows:

DEFINITION 3. Let σ(, δ) = ∆ f −1(cid:112)2 ln(2/δ). Let N ∼

Normal(0, σ(, δ)). The Gaussian mechanism G : R → R is

G(x) = f (x) + N.

G satisﬁes (, δ)-differential privacy for , δ ≤ 1 [12].
Recall (Section 2.2) that φ(µ, σ; x) denotes the probability
density function of the normal distribution with mean µ and
standard deviation σ. Similarly, let Φ(µ, σ; x) denote the cu-
mulative distribution function of the normal distribution. The
value σ(, δ) is chosen such that the set of values x such that
φ(0, σ; x) ≤ eφ(∆ f , σ; x) has probability at least 1 − δ. We
simply performs binary search in (0, ∆ f −1(cid:112)2 ln(2/δ)] for
can reduce the noise variance somewhat by ﬁnding the small-
est value σ∗ with this property. To compute σ∗, PrivCount
the smallest value σ such that Φ(0, σ; x∗) ≤ δ, where x∗ =
−(σ∗2/∆ f ) + ∆ f /2, which is the smallest value x satisfying
φ(0, σ; x)/φ(∆ f , σ; x) ≤ e.

A.2 Counterexample for PrivEx σ

We show that Elahi et al. provide an invalid formula relat-
ing σ, , and δ (see [14], Section 4.4.1). They state that, after
determining a σ that provides the desired limit on the adver-
sary’s “advantage”, (, δ)-differential privacy holds for any 
and δ such that the following is satisﬁed:

(cid:115)

(cid:18) 1.25

(cid:19)

.

δ

ln

∆ f


σ ≥

However, the following counterexample shows that this is
incorrect.

Suppose that  = 0.2, δ = 10−6, and ∆ f = 1. Then set

(cid:115)

(cid:18) 1.25

(cid:19)

10−6

ln

≈ 18.734.

σ =

1
0.2

Then let

x∗ = −

σ2
∆ f

+

∆ f
2 ≈ −69.693.

Then Φ(0, σ; x∗) = 9.956 · 10−5, and Φ(∆ f , σ; x∗) = 8.048 ·
10−5. Thus, Φ(0, σ; x∗) − eΦ(∆ f , σ; x∗) = 1.257 · 10−6 > δ,
which violates (, δ)-differential privacy.
A.3 Optimally allocating 

Given δk = δ/l for all l, PrivCount divides  among the
statistics in order to make their noise proportional to their
expected values vk. More precisely, it chooses k > 0 mini-
mizing maxk √nσk/vk, where σk = σ∗(k, δk) and ∑k k = .
This is equivalent to ﬁnding some global noise ratio ρ and
k such that √nσk/vk = ρ, for all k, because otherwise the
maximum ratio could be decreased be increasing the k of
the maximizing statistic and decreasing by the same amount
the k of some statistic with a smaller noise ratio.
Given some global ratio ρ, it must be that σk = ρvk/√n.
Then each k can be computed from σk and δk via binary
search in a process very similar to that used to calculate σk
from k and δk. Such ρ is feasible if and only if ∑k k ≤ .
Thus we can ﬁnd the optimal allocation for  by performing
a binary search for the smallest ratio ρ that is feasible. Let ρ∗
be this smallest ratio.

To determine a range in which to search for ρ∗, we begin
by computing an optimal allocation using the upper bound
of the values σk from Dwork et al. [12]:

(cid:113)

σ(cid:48)(k, δk) = ∆k−1
k

2 ln(2/δk),

where ∆k is the sensitivity of statistic sk. We can solve for the
optimal allocation (cid:48)k using σ(cid:48) for the σk by setting the noise
ratios all equal:

∀k
∆1

⇔ ∀k

√nσ(cid:48)((cid:48)1, δ1)

(cid:112)2 ln(2/δ1)

v1

(cid:48)1v1
⇔ ∀k

∆1
(cid:48)1v1

=

=

=

⇔ ∀k(cid:48)k =
⇒ (cid:48)1 =

√nσ(cid:48)((cid:48)k, δk)

(cid:112)2 ln(2/δk)

∆k

vk

(cid:48)kvk

∆k
(cid:48)kvk
∆kv1(cid:48)1
∆1vk



1 + ∑k>1(∆kv1)/(∆1vk)

,

1566(cid:34)

where the last line holds because ∑k (cid:48)k = .

Given this allocation, we can be certain that

ρ∗ ∈

min

k

√nσ∗((cid:48)k, δk)

vk

, max

k

√nσ∗((cid:48)k, δk)

vk

(cid:35)

,

which is true for any allocation of  because adjusting the
given allocation in order to equalize the noise ratios can only
decrease the maximum noise ratio and increase the mini-
mum noise ratio. Using the σ(cid:48) approximation as a basis for
determining this range is particularly good to the extent that
σ(cid:48) is generally close to the optimal σ∗. In fact, if σ(cid:48) ≤ cσ∗
for some c ≥ 1 (recall that we already have that σ∗ ≤ σ(cid:48)),
then computing ρ∗ to within some accuracy ι takes at most
log2((1 − 1/c)ρ∗/ι) rounds during the binary search. To see
this, let ρ(cid:48) = (√nσ(cid:48)((cid:48)k, δk))/vk, which is well-deﬁned be-
cause the (cid:48)k are set such that this ratio is equal for all k. Then
observe that

√nσ∗((cid:48)k, δk)

vk

max

k

≤ ρ(cid:48)

because σ∗ ≤ σ(cid:48) and that

√nσ∗((cid:48)k, δk)

vk

min

k

≥ ρ(cid:48)/c

because σ∗ ≥ σ(cid:48)/c. Finally, observe that ρ(cid:48) − ρ(cid:48)/c ≥ ρ∗ −
ρ∗/c because ρ(cid:48) ≥ ρ∗.
B. SECURITY AND PRIVACY PROOFS

model against any adversary that does not corrupt all SKs.

THEOREM 1. PrivCount UC-realizes FPC in the hybrid PKI
PROOF. The simulator runs the PrivCount protocol inter-
nally with the given adversary A. For honest parties, it re-
ceive the inputs up to the execution phase, and so it can sim-
ulate PrivCount in the ﬁrst two phases. The PKI ensures au-
thenticity of all messages in both the real and simulated pro-
tocols.

During broadcast, an abort message corresponds to a party
receiving an inconsistent “rebroadcast” from another party.
This event can only occur with a corrupt TS, and so the sim-
ulator can always observe it and can translate the event be-
tween the simulated protocol and the ideal world in either
direction.

During aggregation, for each honest DC or SK Pi the sim-
ulator can use as counter values the initialization values that
it sampled for the DCs. It can also use shared values created
at honest DCs and SKs.

If the TS is corrupt, then after the last honest party Pi leaves
execution, the simulator will receive the aggregated output
of honest DCs y. It can than send as the ﬁnal value to the
TS from Pi to be to be value left after subtracting from y the
sum of the initial counter values of all honest DCs. This is
indistinguishable from a real PrivCount execution from the
view of the adversary because (i) in both cases each value

from a DC is independent and uniformly random by virtue
of its shared value with any given one of the honest SKs, say,
Pi; (ii) the value from each honest SK except Pi is independent
and uniformly random by virtue of its shared value with any
honest DC, and (iii) Pi is the one value such that the ﬁnal sum
is y plus any values shared between honest DCs and corrupt
SKs and between honest SKs and corrupt DCs.
If the TS is not corrupt, then the simulator can extract the
change in counter value ∆k,b that adversary claims in its val-
ues to the TS by subtracting from the sum of ﬁnal values
from corrupt DCs and SKs the sum of the values shared be-
tween corrupt DCs and honest SKs and the initial values of
the counters of corrupt DCs. Then the output value from the
TS is the same in the real and ideal worlds.

Finally, suppose that a corrupt TS sends a subset Si that
doesn’t contain a minimal DC set. Then the simulator re-
ceives no output from aggregation (just ⊥), but it needs none
because some SK never provides a ﬁnal value to the TS. If
instead a corrupt TS sends as inputs to two honest SKs sub-
sets Si that contain different honest DCs, then the simulator
can send random ﬁnal values to the TS from all DCs and SKs,
because in the real PrivCount execution such subsets would
also result in uniformly random ﬁnal values as each SK con-
tains a shared value not included in any other sum.

THEOREM 2. If at least one SK Si is honest, and if, for each
minimal subset S of DCs in the deployment document that Si re-
Di∈H w2
ceives with honest subset H ⊆ S,
i ≥ 1, then the
output of PrivCount is (, δ)-differentially private.

∑

(cid:113)

∑

(cid:113)

Di∈H w2

PROOF. Because we have an honest SK, we can apply Thm. 1
and examine the output of FPC. That functionality outputs
to the environment or the adversary either something uncor-
related with the inputs or the sum of the initialized coun-
ters. The latter output has noise with standard deviation at
i σk ≥ σk in each counter. The values σk are
least
calculated such that for each k the set of values x such that
φ(0, σk; x) ≤ ek φ(∆k, σk; x) has probability at least 1 − δk,
where ∆k is the sensitivity of the kth statistic. Thus the set of
outputs x = (x1, . . . , xl) such that φ(0, σk; xk) > ek φ(∆k, σk; xk)
for some k has probability at most ∑k δk = δ. For all other
output vectors x, φ(0, σk; xk) ≤ ek φ(∆k, σk; xk) for all k, and
so the set of such vectors S has probability under any input
D at most e∑k k = e times the probability of S under an ad-
jacent input D(cid:48). Thus, the set of output statistics from FPC
in a given collection period is collectively (, δ)-differentially
private. Moreover, it is sufﬁcient just to show that the func-
tionality output from a single collection period is differen-
tially private because adjacent inputs databases only differ
in behavior during some period no longer than the reconﬁg-
uration time, and the functionality will not change its con-
ﬁguration and start new measurements without waiting for
that length of time.

1567