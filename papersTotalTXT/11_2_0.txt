Clear and Present Data: Opaque Trafﬁc and its Security Implications for the Future

Andrew M. White∗, Srinivas Krishnan∗, Michael Bailey†, Fabian Monrose∗, Phillip Porras‡

∗University of North Carolina at Chapel Hill
{amw,krishnan,fabian}@cs.unc.edu

†University of Michigan

‡SRI International

mibailey@eecs.umich.edu

porras@csl.sri.com

Abstract—Opaque trafﬁc,

i.e., trafﬁc that is compressed
or encrypted,
incurs particularly high overhead for deep
packet inspection engines and often yields little or no useful
information. Our experiments indicate that an astonishing
89% of payload-carrying TCP packets — and 86% of bytes
transmitted — are opaque, forcing us to consider the challenges
this class of trafﬁc presents for network security, both in the
short-term and, as the proportion of opaque trafﬁc continues to
rise, for the future. We provide a ﬁrst step toward addressing
some of these challenges by introducing new techniques for
accurate real-time winnowing, or ﬁltering, of such trafﬁc based
on the intuition that the distribution of byte values found in
opaque trafﬁc will differ greatly from that found in transparent
trafﬁc. Evaluation on trafﬁc from two campuses reveals that
our techniques are able to identify opaque data with 95%
accuracy, on average, while examining less than 16 bytes of
payload data. We implemented our most promising technique
as a preprocessor for the Snort IDS and compared the per-
formance to a stock Snort instance by running both instances
live, on identical trafﬁc streams, using a Data Acquisition and
Generation (DAG) card deployed within a campus network.
Winnowing enabled Snort to handle a peak load of 1.2Gbps,
with zero percent packet loss, and process almost one hundred
billion packets over 24 hours — a 147% increase over the
number processed by the stock Snort instance. This increase
in capacity resulted in 33,000 additional alerts which would
otherwise have been missed.

I. INTRODUCTION

The successful monitoring of security policies via Intru-
sion Detection Systems (IDS) critically depends on scalable
and accurate techniques for inspecting trafﬁc. Deep packet
inspection (DPI) is a common method for performing such
inspection, especially when security policies require deter-
minations based on information not accurately reﬂected by
network ports, protocols, or hosts. In fact, the market for
DPI appliances alone reached almost $1 billion in 2009, and
continues to grow.1 Since DPI must deal with huge volumes
and signiﬁcant heterogeneity of trafﬁc, DPI designers often
trade off accuracy of detection with resource demands [34].
DPI systems cannot generally derive useful information from
opaque (i.e., encrypted or compressed) packets; thus, we
propose improving the performance versus quality curve
through the quick and accurate winnowing, i.e., ﬁltering,
of opaque trafﬁc, and evaluate a number of techniques for
doing so. Such techniques can improve the performance

of DPI engines by quickly and accurately separating out
low-value packets from the data stream they inspect; this
is particularly important in high-performance environments,
where the sheer volume of trafﬁc can be staggering. At
our campus, encrypted trafﬁc alone appears to make up
an average of 13% of the total
trafﬁc, based solely on
port and protocol assumptions. We believe that the fraction
of encrypted trafﬁc on real networks will only continue
to rise, as more web services follow in the footsteps of
Google and Facebook in offering encrypted connections and
the movement toward ubiquitous end-to-end encryption [2]
gains steam. In particular, private corporate networks, where
secure communications are often required, undoubtedly see
signiﬁcantly higher proportions of encrypted trafﬁc. The
class of opaque trafﬁc encompasses not only encrypted
connections, but also compressed entities, which,
in the
modern era of streaming video, comprise an even more
signiﬁcant fraction of network trafﬁc: some sources indicate
that streaming video accounts for 35% of peak network
usage, a proportion which is only increasing.2

In fact, our experiments revealed a surprising preponder-
ance of opaque trafﬁc: in a 24-hour weekday period, nearly
90% of TCP packets traversing a major university network
(with peak loads of 1.2Gbps) were found to be opaque. This
truly staggering ﬁgure suggests a broader issue for the secu-
rity community moving forward: as more and more payloads
become opaque to DPI engines, how can we detect and pre-
vent obscured threats? While content-based signatures will
continue to be relevant as a detection mechanism for direct
attacks (e.g., those exploiting buffer overﬂows in networking
routines) against networked systems, bypassing current DPI
engines can be as simple as encrypting the relevant exploit
code, particularly for indirect attack vectors (e.g., exploits
embedded in documents). Thus we, as a community, face
both an immediate need to separate the wheat from the
chaff—to winnow low-value, i.e., opaque, packets to enable
our existing detection methods to operate in high-speed
environments—and a long-term need to develop methods for
coping with attacks embedded in opaque, and particularly
encrypted, trafﬁc. This work represents a ﬁrst step toward
solving both problems: our techniques enable the fast and
accurate identiﬁcation of opaque packets, either as chaff to

1Gartner’s Magic Quadrant for NIPS (Dec 2010).

2Sandvine’s Global Internet Phenomena Report (Fall 2011).

be discarded, or as the inputs to specialized detection engines
targeting opaque trafﬁc.

Unfortunately, the identiﬁcation of opaque network trafﬁc
is very challenging. While signatures can identify many
known opaque protocols (e.g., SSL/TLS, SSH), some pro-
tocols (e.g., Bittorrent’s Message Stream Encryption) are
speciﬁcally designed to avoid signature matching. In addi-
tion, signature-based approaches for identifying new opaque
protocols require constructing and deploying new signatures
for each new protocol. More importantly, existing techniques
for identifying opaque data often require examination of
a large number of bytes, which can be computationally
and memory intensive on high-speed networks [5, 12].
Similarly, inspecting application-layer content-types to de-
termine opacity requires resource-intensive ﬂow reassembly.
To compound matters, such detectors cannot rely on HTTP
content-types as they are often inaccurate (see §III).

As a ﬁnal note, opaque trafﬁc identiﬁcation has value that
extends beyond ﬁltering to policy monitoring and enforce-
ment. For instance, operators may wish to monitor and en-
force policies within their network (e.g., ﬂagging encrypted
packets tunneled over unencrypted connections, an odd
practice used by botmasters to hide command-and-control

We take a ﬁrst step toward addressing these challenges
by providing novel methods for quickly and accurately
determining whether a packet is opaque. Our techniques are
both port- and protocol-agnostic, allowing for the detection
of opaque trafﬁc regardless of the port(s) or protocol(s)
involved. We concentrate on efﬁcient techniques which can
operate on limited portions of packet payload, such as
small-sample ﬁxed-size and sequential hypothesis tests, in
order to minimize overhead and allow scarce computational
resources to be reserved for high-value analyses.

In the present work, we necessarily evaluate our tech-
niques in isolation, i.e., without attempting to fully integrate
our approach with a particular system or methodology,
in order to minimize the number of factors potentially
biasing our results. That said, we envision the identiﬁcation
of opaque trafﬁc not as the relatively standalone system
portrayed herein — there is no “silver bullet” for network
intrusion detection — but rather as an efﬁcient new tool
in the network analyst’s toolbox. In particular, forensic
recording systems, such as Time Machine [23], often avoid
archiving full connections in order to reserve limited storage
space for the higher-value packets at the beginning of a
connection. An admitted weakness of this design decision
is that attacks in the discarded portions of these connections
go unnoticed. Our techniques mitigate this concern to an
extent by providing a means for such a system to detect po-
tentially high-value plaintext packets in lengthy connections.
Similarly, our tests are simple and can be implemented on an
FPGA, providing a beneﬁt even to systems which make use
of a hardware component, such as those following shunting
approach proposed by Gonzalez et al. [15].

messages in otherwise mundane HTTP trafﬁc [6, 38]).
Similarly, one might wish to ﬂag unencrypted trafﬁc where
encrypted trafﬁc is expected, such as might occur if an SSH
connection is subverted [27], or on institutional networks
where end-to-end encryption is required. Identifying opaque
trafﬁc may also help to discover applications tunneled over
other protocols (e.g., video trafﬁc tunneled over HTTP), or to
provide sanity checking for strongly typed networking [26].
Our contributions include: 1) the concept of opaque trafﬁc
as a distinguishable class of network trafﬁc; 2) the devel-
opment, evaluation and comparison of multiple techniques
for detecting such trafﬁc (Section §II, Appendix §A); 3) an
operational analysis of modern network trafﬁc with respect
to opacity (Section §III-A); and 4) an evaluation, at scale,
of the potential of our techniques for reducing the load on
modern intrusion detection systems (Section §III-B).

II. APPROACH

An important requirement of ours is to minimize the
amount of a packet’s payload that we must inspect, as doing
otherwise is both computationally and memory intensive
on high-speed networks [5, 12]. These overheads severely
restrict the numbers of samples available to us for any of
the tests we explore. Therefore, for the remaining discussion,
we propose detectors based on small-sample ﬁxed-size hy-
pothesis tests and sequential hypothesis testing. The latter
allows us to make decisions quickly by examining only as
many samples as needed to support a given hypothesis.

i.e.,

Our detectors are based on determining whether the bytes
examined are drawn from a uniform distribution or some
other, unknown, distribution. Our ﬁrst instinct, when faced
with the problem of measuring the uniformity of a set of
samples, was to use entropy-based measures. However, as
we show later, accurate entropy testing requires signiﬁcantly
more samples than is practical in our setting, and is less
efﬁcient than more direct methods based on the samples
themselves rather than on a derived statistic such as entropy.
Both encrypted and compressed trafﬁc will exhibit high
entropy,
the distribution of bytes will be close to
uniform. In this paper, we consider these two cases as
belonging to the same equivalence class of “opaque” objects
as far as DPI engines are concerned. That is, regardless of
whether the packets that belong to a session are compressed
versus encrypted, they will be forced to go through the slow
path wherein the engine must analyze all packets of these
sessions, but will still fail to derive any useful information
in the vast majority of cases. Hence, from the perspective of
DPI engines, there is little value in attempting to analyze
these packets. As Cascarano et al. [5] observed in their
experimental evaluations, these slow paths incurred CPU
overheads that can be several orders of magnitude higher
than the average case for transparent trafﬁc.

In our search for the best performing test for our goals,
we examine several ﬁxed sample-size hypothesis tests. There

are a number of standard techniques for testing uniformity;
however, many of these are designed for testing the unifor-
mity of the outputs of a pseudo-random number generator,
and thus assume access to millions of samples (e.g., [25]).
These tests are unsuitable in our context because our sample
size is extremely limited. We instead evaluate the appropriate
ﬁxed-size tests (the likelihood ratio test and the discrete
Kolmogorov-Smirnov test) and two variants of the sequential
probability ratio test. We assess the effectiveness of each
test in two scenarios, differentiated by the domain of the
underlying distribution. In the ﬁrst scenario, we directly test
the distribution of byte values in the packet; for the second,
we instead test the distribution of entropy values over n-byte
“blocks” in the packet.

When the need arises for a probability density function for
the alternative hypothesis, we use a simple distribution based
on the intuition that plaintext packets will have a higher
frequency of bytes whose values are less than 128 (as are the
ASCII values). We parameterize this distribution by setting
δ to the cumulative density of those values. For example, at
δ = 0.75 the alternative hypothesis is that 75% of the bytes
in the packet have values less than 128.

Likelihood Ratio Test: A well-known theorem of hypoth-
esis testing is the Neyman-Pearson lemma, which states that
the most powerful test, i.e., that with the lowest expected
false positive rate for a given false negative rate, of one

For pedagogical reasons, we leave descriptions of the
less successful tests, along with the details of the parameter
exploration experiment itself, to §A2, and discuss only the
more effective tests here. In summary, the closely-related
likelihood ratio and sequential probability ratio tests, operat-
ing directly on the byte values instead of on derived entropy
values, consistently outperform the other tests. The poor
performance of the entropy tests is related to the birthday
problem, in that the (byte-)entropy of any n bytes is the same
unless there is a collision (e.g., there are two bytes which
share the same value). According to the birthday paradox,
the a priori probability of a collision in 8 bytes, even when
choosing only from only the 95 printable ASCII characters,
is only about 26%. This means that the entropy of 8 ASCII
bytes is indistinguishable from that of 8 unique bytes 74%
of the time. Thus entropy-based tests require substantially
more than the number of samples available in our context to
be effective. However, our parameter exploration experiment
(see §A2) reveals that the the more successful tests require
examining only 16 bytes of payload to be effective.

Since our goal is to discard opaque trafﬁc (albeit en-
crypted or compressed), we let our null hypothesis be that
the packet is opaque and our general alternative be that
the packet is transparent. Speciﬁcally, the null hypothesis is
that the values of the bytes in the packet are approximately
uniformly distributed (e.g.,
is compressed or
encrypted); the alternative is that the distribution is non-
uniform (e.g., ASCII text).

the packet

Suppose we wish to test

simple hypothesis against another is the likelihood ratio
test [41]. For a single sample, the likelihood ratio statistic
is simply the ratio of the likelihood of the sample under the
alternative hypothesis to the likelihood of the sample under
the null hypothesis. For multiple samples, these likelihoods
are replaced with the corresponding joint likelihoods.
the simple null hypothesis
H0 : θ = θ0 against the simple alternative H1 : θ = θ1 given
a random sample ¯X. Then the Neyman-Pearson lemma [42,
Theorem 10.1] states that the most powerful test of H0
against H1 is that where one rejects H0 if Λ( ¯X) ≥ q and
accepts H0 if Λ( ¯X) < q, where q is determined by the
desired level of statistical signiﬁcance and Λ( ¯X) is the ratio
of the likelihood of ¯X under the alternative to the likelihood
of ¯X under the null hypothesis.

Sequential Probability Ratio Test: Sequential analysis is
often used when there is a desire, such as in our context,
to limit the number of samples examined. In fact, Wald
and Wolfowitz have shown that, among all tests of two
simple hypotheses with ﬁxed error probabilities, the sequen-
tial probability ratio test (SPRT) minimizes the expected
number of samples required for a decision under either
hypothesis [43]. Sequential
testing works by examining
samples one-by-one, rather than all at once, and evaluating
a decision function at each sample. This allows the test to
stop examining samples as soon as it has found enough
“evidence” for one hypothesis or the other.
Speciﬁcally, let α = P (accept H1|H0) be the proba-
bility of a false negative, that is, an erroneous prediction
that the vi are not uniformly distributed; similarly, deﬁne
β = P (accept H0|H1) as the probability of a false positive.
In order to perform the test, we iterate through some
sequence of samples X1, X2, ...; according to Wald’s theory
of sequential hypothesis testing [42], we choose at each
iteration m one of three actions: accept H0, accept H1,
or continue, as follows:

accept H0 if
accept H1 if
continue

Λm(X1, X2, ..., Xm) ≤ g0(m)
Λm(X1, X2, ..., Xm) ≥ g1(m)
otherwise.

Setting g0(m) = β
probabilities of false positives and false negatives.

1−α and g1(m) = 1−β

α gives the desired

A known drawback of this test is that it may not terminate
within an acceptable number of samples. We alleviate this
concern by exploring two variants, which we refer to as the
truncated and restricted SPRTs. For the truncated SPRT,
we specify a maximum number of samples which the test is
allowed to examine; if this limit is reached without making
a decision, then the ﬁxed-size likelihood ratio test is applied
to the samples examined so far. The restricted SPRT, on
the other hand, works by sloping the decision boundaries
such that they intercept the axis after the given number of
samples. For the restricted case, we follow the approach

suggested by Bussgang and Marcus [4].
Based on the results of the parameter exploration exper-
iment (see §A2), we use the truncated sequential method
(α = 0.005, β = 0.005, δ = 0.85) for the remainder of the
experiments in this work.

III. EVALUATION

In order to ascertain the effectiveness of our techniques
in different scenarios, we perform a number of experiments
in both ofﬂine and online settings. First we show, in a
controlled, ofﬂine experiment, that our techniques are able
to accurately identify the opacity of different ﬁle types. We
then verify the accuracy of our techniques under real-world
network conditions by evaluating our detectors on trafﬁc logs
and traces collected at two major universities, an analysis
which produced a number of interesting anomalies which we
investigated with the help of a network operator. Finally, we
show the utility of winnowing by comparing two otherwise
identical Snort IDS deployments under identical trafﬁc loads.

A. Ofﬂine Analysis

File Type Identiﬁcation: To gain an understanding of how
well our techniques were able to label the opacity of various
common data types, we collected a set of ﬁles with known
ground truth, including compressed archives and streams,
encrypted ﬁles, executable binaries, and text ﬁles. We also
attempted to cover different sub-types; e.g., we included ﬁve
different text ﬁle encodings. The details of this set, which
we believe to be a reasonable cross-section of common ﬁle
types, are presented in Table I.

We gathered a base set of ﬁles from multiple sources, then
applied standard compression and encryption algorithms to
these ﬁles to create the remainder of the dataset. For exe-
cutables, we used ELF binaries from the bin directories of
a basic Ubuntu Server 10.04.3 installation (that we used for
testing Bro and Snort). The ﬁles in each directory, including
a number of Perl scripts, were then individually compressed
using tar (which in turn uses gzip and bzip2) to provide
gzip and bz2 ﬁles and encrypted using openssl to
provide examples of the RC4 and AES ciphers. The text
ﬁles are the contents of the man path directory of the
same Ubuntu installation, uncompressed and processed by
groff into different encodings (ASCII, UTF-8, -16, and -
32, and latin1); the PDF ﬁles are the archive of proceedings
from a major computer security conference. Finally, the
images were JPEGs scraped from public websites, including
a departmental website and nasa.gov.

To simulate a network environment, we transmitted each
object over an individual TCP connection on the loopback
device of an Ubuntu virtual machine. We used nc to both
send and receive, and tcpdump to collect the resulting
packets. We report the proportion of opaque and transparent
packets observed for each type of ﬁle in Table I.

Our test labeled more than 95% of compressed, encrypted
and image ﬁle packets as opaque, as expected. Similarly,
even with multiple different encodings, our techniques la-
beled more than 99.99% of text ﬁle packets correctly as
transparent. Our test is less consistent on the executables.
Inspection of the binaries revealed a large number of null
bytes, suggesting that a more targeted alternative hypothesis,
perhaps counting only the set of printable ASCII bytes
rather than simply those with value less than 128, may
improve our results. However, this must be contrasted with
the straightforwardness and efﬁciency of checking whether
the value of a byte is greater than 128 (which amounts to
simply checking the high-order bit).

Type
compressed
encrypted
text
images
executable
pdf

Objects
1410
1410
5802
205
498
1006

Size (MB)

40
91
176
12
43
75

True Positive Rate

97.8
98.9
100.0
94.4
34.5
13.5

Table I

FILE TYPE ANALYSIS

Content Type Matching: To assess the accuracy and per-
formance of the techniques in §II, we instrumented the Bro
IDS (version 1.6-dev-1491) to log packet-level information
(with only coarse-grained payload information), providing
a form of ground truth. Due to privacy restraints, we were
unable to record full packet traces at scale; therefore, the
experiments in this section are performed on logs generated
by our instrumented version of Bro. For these experiments,
we collected two logs (log1 and log2) from two large
university campuses.3 Both logs were collected over several
hours during a weekday. For simplicity, we only consider
IPv4 TCP trafﬁc. We labeled each packet by protocol using
Bro’s dynamic protocol detection [13], and restricted our
analysis to two encrypted protocols (SSL and SSH) and two
unencrypted protocols (HTTP and SMTP).

For each packet, we log the source and destination ports,
the HTTP message type, the HTTP message encoding, and
the payload length; we also store coarse-grained statistics
in the form of a binary value for each byte of the payload
(indicating whether the byte’s value is less than 128), and the
byte-value frequencies for each n-byte block of the payload.
The latter are needed to calculate sample entropy at the block
level and for the frequency-based tests (i.e., χ2 and discrete
K-S; see §A). In all cases, we only log information for the
ﬁrst 256 bytes of the payload.

We labeled each packet as ‘opaque’ or ‘transparent’
according to the expected data type for that packet: SSL
and SSH packets are labeled opaque and SMTP packets are
labeled transparent. For HTTP, we labeled packets based

3Our efforts to maintain data privacy and ensure IRB compliance for this

collection effort are detailed in §VII.

on the HTTP Content-Type and Content-Encoding header
ﬁelds (as given by the sender) for the corresponding HTTP
message (see §B for details of the labeling). This allows
us to further restrict our attention to only those content-
types for which opacity should be predictable and consistent.
For instance, the HTTP 1.1 speciﬁcation states that “HTTP
entities with no speciﬁed Content-Type should be identiﬁed
by inspection of the contents” [14]; we remove any such
packets from our analysis because we have no way of
determining ground truth. However, as we discovered during
the course of this work, the HTTP content-type headers are
often inaccurate and misleading (details are given in the
following sections).

Unfortunately, Bro suffers from performance problems
(see [12]) on high-speed networks, especially when port-
based analysis is disabled (as is necessary to force Bro to
determine protocols solely by inspection). Therefore, we dis-
card any HTTP packets which belong to ﬂows in which Bro
experienced losses. We do so because the dropped packet(s)
could have contained essential labeling information (e.g., a
message header) necessary for determining the content-type
and encoding.

After ﬁltering the logs down to only those packets which
met the criteria outlined above, over 39 million packets
(across ≈ 3.8 million bi-directional ﬂows) remained from
log1 and over 24 million (across ≈ 2.3 million bi-
directional ﬂows) remained from log2. The trafﬁc makeup
for both logs is shown in Figure 1.

The content-type distribution (Figure 2) for the top content
types in both logs reveals some interesting contrasts between
the two. In particular, video types are prevalent in log2
while log1 consists mainly of web-browsing trafﬁc (over
80% of log1 HTTP packets have content type ‘image/jpeg’
or ‘text/html’, compared to 40% in log2). The content-
encoding ﬁeld is only speciﬁed for a small proportion of
packets in our logs, and the only signiﬁcant encoding is
‘gzip,’ at 4.0% in log1 and 6.5% in log2. All other
encodings combined account for less than a tenth of a
percent of packets in each log.

We performed a large-scale analysis on both log1 and
log2; the overall results are given in Table II. Examining
only 16 bytes per packet, offset 8 bytes from the start of
each packet, we achieve a match rate, i.e., the percentage
of examples for which our techniques produced the same
label as expected from the content type, of 95.1% on log1
and 96.0% on log2. We refer to ‘match’ rates here, rather
than false-positive or false-negative rates, due to the large
quantity of mislabeled content-types we encountered.

In the case of encrypted trafﬁc (i.e., TLS/SSL) we accu-
rately classiﬁed approximately 95% of the trafﬁc. However,
the mismatches are particularly interesting. Figure 3 shows
the distribution of packet IDs, where a packet’s ID is its
position in the bi-directional ﬂow (i.e., a packet with ID zero
is the ﬁrst packet sent by the originator of the connection).

(a) log1

(b) log2

Figure 1. CDFs of payload size for the protocols examined in the two
campus network logs

log1

log2

Protocol
SSH
SSL/TLS
SMTP
HTTP
Total

Match Rate

94%
96%
86%
91%
94%

Examples Match Rate

7.3m
16.4m
3.35m
9.7m
36.7m

97%
94%
80%
85%
96%

Examples
157k
5.5m
1.4m
13.8m
20.8m

EXPERIMENTAL RESULTS (log1 AND log2)

Table II

Notice that 94.8% of the mismatches for SSL/TLS occur
within the ﬁrst 5 packets, and 95% within the ﬁrst 6 packets
for SSH. These packets are all in the connection set-up
phase and hence are not, in fact, encrypted. Moreover, these
connection set-up packets, particularly any SSL certiﬁcates
(typically around ID 2), may be of interest to DPI engines
even when the encrypted payload is not.

A closer analysis of our overall results reveals that 50% of
the transparent-as-opaque mismatches for log1, and 15%
for log2, are from SMTP trafﬁc, which we surmise includes
opaque attachments for which we do not have accurate

0200400600800100012001400PayloadSize0.00.51.01.52.02.5NumberofPackets×107OverallSMTPSSHSSLHTTP0.00.20.40.60.81.0PercentageofPackets0200400600800100012001400PayloadSize0.00.20.40.60.81.01.21.41.6NumberofPackets×107OverallSMTPSSHSSLHTTP0.00.20.40.60.81.0PercentageofPacketsFigure 2. HTTP Content-Type Distribution

(a) SSL/TLS

(b) SSH

Figure 3. CDFs of Packet IDs

labeling information. Of the HTTP transparent-as-opaque
mismatches (Figure 4), many are PDF and Flash (both of
which can serve as a container for many other object types),
but a surprising proportion are of type text/plain.

We investigated the text/plain mismatches from
log1 further and concluded, based on the observed byte-
value distributions, that if these packets are in fact plaintext,
the method used for encoding is non-standard. Figure 5(a)
depicts the byte-value distribution for the mismatches and
for the text/plain packets where the encoding was
speciﬁed explicitly as one of UTF-8, UTF-16, US-ASCII

Figure 4. HTTP Mismatched Content-Types

or ISO-8859-1. As expected,
the latter distribution has
signiﬁcant mass around the ASCII characters ‘A’-‘z’ (values
65 − 122 in Figure 5) while the former does not. A simi-
lar ﬁnding holds for the opaque-as-transparent mismatches
in the image/jpeg case: the distribution (bottom, Fig-
ure 5(b)) has striking similarities to that observed for the
case of known plaintext encodings (top, Figure 5(a)), and
moreover, is quite different from that of the opaque JPEGs
(top, Figure 5(b)). Unfortunately, without access to actual
payloads for these two traces, we cannot say what was the
underlying cause for the peculiar distribution in the content
ﬂagged by our methods, but we believe this underscores the
utility of our techniques — i.e., we successfully identiﬁed
anomalous instances in both cases. We revisit this issue in
the next section.

Finally, we examined the number of iterations needed by
the truncated test to make a decision regarding each packet.
With the maximum sample size set at 16 bytes, 45% of the
packets can be classiﬁed in 12 bytes or less.

Operator Analysis: To gain deeper insights into the
issue of Content-Type mismatches, we performed another
experiment in which a resident network operator was able to
manually inspect payload data from a third dataset, for which
we were able to collect full payloads under the supervision of
our local network operator. This trace covers four weekday
afternoon hours of trafﬁc from a university computer science
department, and consists of 27 million packets. To enable
this inspection, we instrumented Bro (version 2.0) to save
both HTTP entities and the payloads of TCP connections to
disk. We then ran the instrumented Bro against the port 80
(HTTP) and port 443 (SSL) trafﬁc in the trace.

We determined the opacity of each packet, saving those
entities and connection payloads wherein the ﬁrst ﬁve pack-
ets were mismatches. For the HTTP entities, we deﬁne a
mismatch as having an opacity different from that implied by
the Content-Type or Content-Encoding. For the streams on
port 443, we consider transparent packets to be mismatches.
We also captured relevant metadata, such as the URI, Host,
and MIME-type of the resulting ﬁle (determined using Bro’s
libmagic interface).

We discovered a number of mismatched HTTP entities
in the trace, of both the transparent-as-opaque and opaque-

0.00.10.20.30.4PercentageofHTTPPacketstext/htmlimage/jpegapp/pdfvideo/x-ﬂvtext/plainimage/pngvideo/mp4image/gifapp/zipaudio/mp4trace1trace20246810PacketID0.00.20.40.60.81.0PercentageofPacketsAllFalseNegatives0246810PacketID0.00.20.40.60.81.0PercentageofPacketsAllFalseNegatives0.000.010.020.030.040.050.060.07PercentageofHTTPPacketsapp/pdftext/plainimage/jpegapp/x-shk-ﬂashtext/htmltrace1trace2comprised: cleartext Yahoo Voice connection information
(including account names), names and email addresses from
a social networking chat site, and what appeared to be IM
conversations. As an aside, in looking at ﬂagged mismatches
while testing, one of the authors discovered his AIM contact
list transmitted in the clear over port 443 by Adium!
B. Online Analysis

To further demonstrate the utility of winnowing opaque
trafﬁc in a real-world environment, we implemented our
techniques as a preprocessor to the Snort IDS. Much of
Snort’s functionality, such as stream reassembly and HTTP
inspection, is implemented as preprocessors which are exe-
cuted after network and transport layer packet decoding but
before engaging the rule-matching engine. We positioned our
winnowing preprocessor to intercept packets before reaching
the stream reassembly module.4 This allows us to drop
opaque packets early enough to avoid incurring the overhead
(over 30% of Snort’s run-time in some experiments) of
stream reassembly and long before reaching the pattern
matching engine.

The ruleset used was provided by a major university,
which uses Snort primarily for post-facto forensics, and
contains 1606 rules. As a sanity check, and to provide
results on a public dataset which could therefore be easily
reproduced, we evaluated both stock Snort and Snort with
our winnowing preprocessor on the (admittedly controver-
sial) DARPA/MITLL 1999 intrusion detection dataset. Both
conﬁgurations produced exactly the same set of alerts.

For our online experiments, we made use of an Endace
9.2X2 Data Acquisition and Generation (DAG) card to run
two Snort (version 2.9.1.2) instances in parallel, one with
stock Snort and the other with winnowing enabled, on
live trafﬁc. The DAG uses a packet processor to capture
and timestamp packets at line rate, and employs an on-
board direct memory access (DMA) engine to zero copy
packets into the host’s memory. The DMA engine can also
be programmed to duplicate trafﬁc over multiple memory
buffers (called “streams”), which enables us to simultane-
ously run multiple experiments, thereby comparing different
approaches on the same trafﬁc. We use a 10Gbps DAG
connected to a 2.53 Ghz Intel Xeon 6 core host with 16
GB of memory. As in our earlier experiments, we only
examined trafﬁc on ports 22, 25, 80 and 443; this ﬁltering
was performed on the DAG and therefore CPU resources
are used exclusively for payload inspection. Beyond the
winnowing preprocessor, there were no differences between
the two conﬁgurations: both used the same ruleset with the
default Snort options (including inspection of gzipped HTTP
entities and the bypassing of the detection algorithms by
SSL application data packets in established streams), and
each was allocated 2GB of memory on the DAG.

4Our preprocessor only drops packets with TCP payloads and therefore

does not interfere with connection tracking at the transport layer.

(a) text/plain (top: known encodings (transparent), bottom: opaque)

(b) image/jpeg (log-scaled; top: opaque, bottom: transparent)

Figure 5. Byte-value Distributions for Anomalies

as-transparent varieties. In the former case, many of these
mismatches were HTTP entities labeled with Content-Type
‘text/plain’ and no stated encoding; we determined from
the metadata that most of these were either images or
compressed bundles. These compressed bundles included
what appear to be updates to Symantec antivirus, extensions
to the Plex media center, and an installer for the DivX
video codec (a .cab ﬁle). The images were identiﬁed by
MIME-type as JPEGs. One interesting mismatch declared a
Content-Type of ‘text/javascript’, with no encoding, while
the MIME-type reported was ‘application/octet-stream’ and
the ﬁlename .gz.

Of the opaque-as-transparent mismatches, a number of
entities were labeled as JPEG and GIF images by Content-
and MIME- type but were ﬂagged as transparent by our
techniques. Many of these contain signiﬁcant text, which we
speculate may be metadata. We also found a large number
of streams on port 443 with predominantly transparent
packets. According to our network operator, these streams

050100150200250Value12345Count×1050.010.020.030.04Percentage12345Count×1050.010.020.030.04Percentage050100150200250Value104105106Count10−210−310−410−510−6Percentage104105106Count10−210−310−410−510−6Percentagerunning on a dedicated core. However, due to trafﬁc bursts,
the stock Snort instances still dropped signiﬁcant numbers of
packets despite our attempts to optimize its handling of the
trafﬁc. While this underscores the need for techniques like
ours, we remind the reader that the advantages of winnowing
trafﬁc are not limited to situations of overload: the signiﬁcant
throughput increase allows systems to evaluate more rules
than stock conﬁgurations under the same trafﬁc conditions.

(a) Packets

(b) Alerts

Figure 6. Number of alerts and number of packets processed by Snort
with winnowing and Snort without (in 15-minute windows).

Our primary experiment lasted for 24 hours and encom-
passed more than 7.6 terabytes of trafﬁc; the load reached
1.2Gbps at peak. Figure 6(a) shows the number of packets
which each instance of Snort was able to process in 15-
minute intervals. Even at peak load, our winnowing Snort
instance is able to handle the full volume with zero percent
packet loss. In contrast, the stock Snort instance dropped
nearly 60% of the 98.9 billion packets observed during
the 24-hour window. In fact, the winnowing Snort instance
processed 147% more packets, resulting in over 33,000
additional alerts (see Figure 6(b)). We note that as the drops
suffered by the unmodiﬁed Snort are lost when Snort is
unable to copy packets out of the network buffer fast enough
to avoid old packets being overwritten by the kernel (or the
DAG, in this case), and therefore Snort has no control over
which packets are dropped [31].

In a second experiment, we partitioned one of the two
identical
the DAG into four disjoint
streams, each of which was passed to a stock Snort instance

trafﬁc streams at

Figure 7. CDF of payload size for both opaque and transparent trafﬁc.

We stress that, apart from the winnowing preprocessor,
instances in each experiment were identically
the Snort
conﬁgured and saw exactly the same trafﬁc. The substantial
improvement in capacity arises due to the surprisingly high
proportion of opaque trafﬁc, which, as discussed in §II,
incurs high CPU overheads (conﬁrmed in our experiments
by an observed 30% increase in average per-packet pro-
cessing time compared to transparent packets). In total, an
astonishing 89% of the payload-carrying TCP packets ob-
served in our primary experiment were classiﬁed as opaque,
representing 86% of the bytes transmitted. We hypothesize
that this is due to the prevalence of streaming video services
such as Hulu, Netﬂix, and YouTube operating on port 80.
Differences in the packet size distributions (see Figure 7)
indicate that MTU-sized packets are far more often opaque
than not, which suggests that large, compressed streams
(e.g., the aforementioned streaming video), are prevalent.
These streams may also account for the bursty nature of
trafﬁc observed in the multiple core experiment.

Operational Impact: Since winnowing opaque packets
fundamentally changes the mix of trafﬁc which reaches the
rules-matching engine in an IDS, its inﬂuence could lead
to deeper insights about network activities. To evaluate this
further, we compared the alerts generated by both instances
of Snort. In total, the stock Snort instance generated 25,081
alerts, while the Snort instance augmented with winnowing
produced 58,297 alerts—a 118% increase. Of these, the
three most prevalent in both cases remained the same; two

20:000:004:008:0012:0016:0020:00Time0.00.20.40.60.81.01.21.41.61.8AnalyzedPackets×108stocksnortwinnowing20:000:004:008:0012:0016:0020:00Time020040060080010001200Alertsstocksnortwinnowing0200400600800100012001400PayloadSize1071081091010101110121013NumberofPackets(log-scale)opaquetransparentbothinstance, we argue that

overﬂow attack detections and a ﬁle-type identiﬁcation alert
(for portable executable binaries). We found the differences
between the distributions of rules triggered by the stock
Snort and by Snort with winnowing to be particularly in-
teresting. One PowerPoint administrator privilege escalation
attack rule was triggered 2000% more times by the winnow-
ing Snort instance, an almost 10-fold increase over what one
might expect just from the increased trafﬁc volume. We also
found a 760% increase in alerts for PDFs with embedded
Javascript. While ascertaining whether winnowing induces
any false positives is impossible due to the losses sustained
by the stock Snort
intelligently
dropping packets, as we do, is no more likely to induce false
positives than dropping random packets due to overload.
The only class of rules which produced fewer alerts when
winnowing opaque trafﬁc were for HTTP connections to
blacklisted domains; these are the only clear false negatives.
Since HTTP headers are in plaintext, and hence not dropped
by Winnow, we suspect that the missed alerts are due to
Snort failing to recover from missing (opaque) packets in a
stream. Since parsing of HTTP headers is possible even in
the presence of missing payload packets, we believe such
alerts would be triggered if the IDS was better equipped to
recover from such midstream losses. Alternatively, a more
mature implementation of the winnowing preprocessor could
inform Snort of the dropped packets.

Nevertheless, the instantiation of our prototype on a major
campus network has already provided valuable information
to its network operators, clearly showing that their network
security exposure differs from what they originally thought.

IV. LIMITATIONS

While our focus on minimizing payload inspection sug-
gests a trivial method for an attacker to bypass DPI engines
using our technique (by padding the beginning of the packet
with ASCII bytes),
in current systems an attacker need
do nothing more than “encrypt” their exploit code (e.g., a
simple XOR may sufﬁce) to bypass content-based signature
matching engines. Furthermore, our techniques comprise a
method for ﬂagging the likely presence of such encrypted
objects based on nothing more than the ciphertext itself.

that

At ﬁrst blush, it may appear that binary protocols present
an insurmountable problem for our methodology. However,
we point out
the majority of trafﬁc (i.e., 80% on
our network) is HTTP, a text protocol. Furthermore, the
high-volume binary protocols (SSL, RTMP, and Bittorrent)
transport primarily,
if not exclusively, opaque data. We
believe that a different alternative hypothesis, such as that
mentioned earlier in the context of identifying ﬁle types,
could provide improved accuracy for binary protocols.

Additionally, while it may seem that the ﬂow level, as
opposed to the packet-level, is the natural vantage point for
identifying opaque trafﬁc, our work concentrates on packet-
level analysis. We argue that the presence of tunneled trafﬁc,

and container formats such as PDF, mandates identiﬁcation
of opaque trafﬁc on a per-packet basis. In the speciﬁc case of
encrypted connections, many protocols (e.g., SSH and SSL)
begin with unencrypted, connection set-up packets; some
protocols (e.g., STARTTLS) are even designed speciﬁcally
to enable upgrading a connection from unencrypted to
encrypted mid-stream. Furthermore, packet-level techniques
can be used in situations where ﬂow state is not kept, such as
on DAG cards. Finally, by performing packet-level analysis,
we can winnow opaque packets before they reach the stream
reassembly engine, signiﬁcantly reducing overhead. That
said, there are beneﬁts to incorporating ﬂow-level analysis.
One interesting direction might be to limit packet-level
misclassiﬁcations by utilizing information from prior and
subsequent packets.

We remind the reader that our techniques are not intended
to be used in isolation, but rather as components in larger
systems. Therefore, the limitations of our techniques can
be mitigated by the strengths of the remainder of the system
architecture, such as by coordinating ﬂow-level analysis with
packet-level opacity checking. This would provide a layered
defense against, e.g., attacks embedded in lengthy streams to
evade systems using selective packet discarding [31], which
is discussed in the next section, or approaches similar to the
afore-mentioned Time Machine (see Section I).

V. RELATED WORK

The related problem of forensic ﬁle and data type identi-
ﬁcation has been extensively explored over the past decade.
Many of these efforts have focused on analyses of byte
frequency distributions, i.e., the frequency of each byte value
in the data of interest. For the most part, these approaches
work by creating signatures for known ﬁle types (i.e., HTML
or PDF) based on byte frequency distributions, and then
comparing unknown ﬁles to pre-existing signatures to deter-
mine the ﬁle type (see, e.g., Ahmed et al. [1]). Veenman
[40] and Hall [17] examined entropy and compressibility
measurements as indicators of ﬁle type, while others have
explored techniques for directly modeling the structure of
ﬁles [16, 18, 21, 32]. The closest work to the problem at
hand is that of Conti et al. [8], who consider distinguishing
between random, encrypted and compressed ﬁles using k-
nearest-neighbor classiﬁcation. Shannon entropy and the χ2
statistic, among other measures, are evaluated as distance
metrics over sliding windows of 1KB or more. Similar ideas
were explored by Shamir and Someren [33] for identifying
cryptographic keys on disk. However, as our empirical
analyses showed, the forensics scenario is fundamentally
distinct from the setting we explore in this work: for real-
time analysis on the network, the amount of data available
is constrained and computational resources are scarce.

Approaches based on byte-frequency [44, 46] and en-
tropy [22, 35, 36, 45] have also been applied in the context
of malware identiﬁcation and analysis, both on disk and in

network trafﬁc. These approaches are not well suited for our
task, as they require large sample sizes for their statistical
tests to be valid and/or impose high computational costs.

Most germane to our work is the scheme proposed by
Olivain and Goubault-Larrecq, which uses hypothesis test-
ing of the sample entropy statistic to determine whether
packets are encrypted [27]. Similarly, Dorﬁnger proposed
an approach for detecting encrypted trafﬁc using entropy
estimation, intended as a pre-ﬁltering step for a Skype ﬂow
detection engine [3, 9–11, 39]. Their encryption detection
scheme shares much in common with that of Olivain and
Goubault-Larrecq, and is based on calculating the sample
entropy for the packet payload and comparing that entropy
value to the expected entropy value for a sequence of
uniformly randomly distributed bytes of the same length.
However, their entropy estimation approach does not scale
well to situations where the number of samples is small [28–
30]. For our entropy-based tests, we addressed this issue
head on by calculating the exact probability distribution
function (see §A)for the (byte-)entropy of n bytes, for small
n. Malhotra compared a number of standard statistical
tests, including the χ2 and Kolmogorov-Smirnov tests, for
identifying encrypted trafﬁc [24]. As with Olivain and
Goubault-Larrecq, their approaches required at least 1 KB of
data per trial. In any case, our byte-value tests outperformed
all of these approaches.

From a systems perspective, similar notions have been
suggested in the context of improving the ability of NIDS
to weather inevitable trafﬁc spikes by the selective discard-
ing [31] of packets when the system is under load. Similar
to Time Machine, Papadogiannakis et al. propose discarding
packets from lengthy ﬂows, reasoning that these packets are
less likely to trigger alerts. We believe our approach is more
general, both in that we enable new policy decisions, as
discussed earlier, and our techniques can operate on ﬂows
of any length. That said, our techniques are certainly ripe
to be employed in a load-dependent fashion, but we focus
on the more difﬁcult load-independent setting in order to
explore the limits of our techniques.

Hardware-based approaches for reducing the load on
NIDS have also been proposed. That most closely related
to our work is the notion of shunting [15], in which packets
are matched in hardware against a dynamic list of rules
which the IDS/IPS updates periodically. For each packet, the
FPGA-based shunt decides, based on these lists, whether to
drop, pass, or forward the packet to the IDS/IPS. Again,
we see our techniques for the identiﬁcation of opaque
trafﬁc as complementary to the shunting approach. Since
the likelihood-ratio test can be, in the extreme, simpliﬁed to
counting high-value bits, it can be easily implemented on
an FPGA, allowing the NIDS to specify opacity-based rules
for packet forwarding decisions.

Lastly, the application of sequential hypothesis testing to
computer security problems is not new. For instance, Jung

et al. [20] applied sequential hypothesis testing to portscan
detection; Jaber and Barakat [19] proposed an iterative
approach that used the size and direction of each packet
to determine the most
likely application generating the
observed trafﬁc; and Thatte et al. [37] proposed a distributed
denial-of-service detector based on a bivariate SPRT.

VI. SUMMARY

In this paper, we propose the notion of quick and accurate
winnowing of opaque trafﬁc as a mechanism for reducing
the demands upon DPI engines, and introduce a number
of statistical techniques for performing such winnowing.
Our techniques are compared against those that might be
considered common wisdom, and through extensive evalua-
tion, we show that our statistical approaches perform best.
Our results demonstrate that we are able to identify opaque
data with 95% accuracy (Section §III-A). By implementing
our approach with the Snort IDS, we demonstrate that
winnowing vastly improves the rate at which an IDS can
process packets without adversely impacting accuracy. Our
experiments show that winnowing enables Snort to process
147% more packets and generate 135% more alerts over a
24-hour period featuring a peak trafﬁc volume of 1.2Gbps.
It is our hope that the ability to classify trafﬁc in the
ways proposed in this paper will provide signiﬁcant beneﬁts
by enabling second-line (e.g., DPI) analysis engines to
target each class with specialized approaches, rather than
attempting to apply heavy-weight analyses to a general
mix of trafﬁc. That said, our real-world evaluations offer
a cautionary tale; our experiments indicate that the vast
majority—89% of payload-carrying TCP packets on our
network—of modern network trafﬁc is opaque. This ﬁnding
was certainly a surprising result to us, and we believe it
may have far reaching consequences in its own right. At
the least, it calls into question the long-term viability of
DPI techniques, and warrants revived interest in ﬁnding new
ways for trafﬁc monitoring and policy enforcement. We hope
that this paper stimulates discussions along those lines.

VII. ACKNOWLEDGMENTS

We thank Kevin Snow, Teryl Taylor, Vinod Yegneswaran
and the anonymous reviewers for their valuable suggestions
on ways to improve this paper. We also express our grat-
itude to our campus networking gurus (Bill Hays, Murray
Anderegg, and Jim Gogan) for their tremendous efforts in
helping deploy the infrastructure for this study, to Alex
Everett for providing access to university rulesets, and to
Jake Czyz for his assistance with data collection.

The researchers and their respective Technology Service
Ofﬁces have longstanding memorandums of understanding
(MoU) in place to collect anonymized network trafﬁc. The
MoU covers speciﬁc uses and types of networking data,
as well as conditions for securing and accessing such data.
To be compliant with our pre-existing Institutional Review

Board (IRB) policies, all computations on payloads were
performed in memory. For this speciﬁc collection effort,
the Institutional Review Board (IRB) concluded that, as
we collect only coarse-grained statistics regarding packet
payloads, the activities in our application “do not meet the
regulatory deﬁnition of human subjects research under the
Common Rule” and are therefore not regulated.

This work was

supported in part by the Depart-
ment of Homeland Security (DHS) under contract num-
ber D08PC75388, the U.S. Army Research Ofﬁce (ARO)
under Cyber-TA Grant no. W911NF-06-1-0316, and the
National Science Foundation (NSF) award no. 0831245.
Any opinions, ﬁndings, and conclusions or recommendations
expressed in this material are those of the authors and do
not necessarily reﬂect the views of DHS, NSF, or ARO.

REFERENCES

[1] I. Ahmed, K.-s. Lhee, H. Shin, and M. Hong. Fast ﬁle-
type identiﬁcation. In Proceedings of the Symposium
on Applied Computing, pages 1601–1602, 2010.

[2] A. Bittau, M. Hamburg, M. Handley, D. Mazi`eres,
and D. Boneh. The case for ubiquitous transport-level
encryption. In USENIX Security Symposium, 2010.

[3] D. Bonﬁglio, M. Mellia, M. Meo, D. Rossi, and
P. Tofanelli. Revealing Skype trafﬁc: when randomness
plays with you. Comp. Commun. Review, pages 37–48,
2007.

[4] J. J. Bussgang and M. B. Marcus. Truncated sequential
IEEE Transactions on Information

hypothesis tests.
Theory, 13(3), July 1967.

[5] N. Cascarano, A. Este, F. Gringoli, F. Risso, and
L. Salgarelli. An experimental evaluation of the com-
In Global
putational cost of a DPI trafﬁc classiﬁer.
Telecommunications Conference, pages 1–8, 2009.

[6] K. Chiang and L. Lloyd. A case study of the Rustock
In Proceedings of the First
rootkit and spam bot.
Workshop on Hot Topics in Understanding Botnets,
2007.

[7] W. J. Conover. A Kolmogorov goodness-of-ﬁt test for
discontinuous distributions. Journal of the American
Statistical Association, 67:591–596, 1972.

[8] G. Conti, S. Bratus, A. Shubina, B. Sangster, R. Rags-
dale, M. Supan, A. Lichtenberg, and R. Perez-Alemany.
Automated mapping of large binary objects using prim-
itive fragment type classiﬁcation. Digital Investigation,
7(Supplement 1):S3 – S12, 2010.

[9] P. Dorﬁnger. Real-time detection of encrypted trafﬁc
based on entropy estimation. Master’s thesis, Salzburg
University of Applied Sciences, 2010.

[10] P. Dorﬁnger, G. Panholzer, B. Trammell, and T. Pepe.
real-time
Entropy-based trafﬁc ﬁltering to support
In Proceedings of the 6th Interna-
Skype detection.
tional Wireless Communications and Mobile Comput-
ing Conference, pages 747–751, 2010.

[11] P. Dorﬁnger, G. Panholzer, and W. John. Entropy
estimation for real-time encrypted trafﬁc identiﬁcation.
In Trafﬁc Monitoring and Analysis, volume 6613 of
Lecture Notes in Computer Science. 2011.

[12] H. Dreger, A. Feldmann, V. Paxson, and R. Sommer.
Operational experiences with high-volume network in-
In Proceedings of the 11th ACM
trusion detection.
conference on Computer and Communications Secu-
rity, 2004.

[13] H. Dreger, A. Feldmann, M. Mai, V. Paxson, and
R. Sommer. Dynamic application-layer protocol anal-
ysis for network intrusion detection. In Proceedings of
the 15th USENIX Security Symposium, 2006.

[14] R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Masin-
ter, P. Leach, and T. Berners-Lee. RFC 2616, Hypertext
Transfer Protocol – HTTP/1.1, 1999.

[15] J. M. Gonzalez, V. Paxson, and N. Weaver. Shunting:
a hardware/software architecture for ﬂexible, high-
performance network intrusion prevention. In Proceed-
ings of the 14th ACM conference on Computer and
Communications Security, 2007.

[16] J. Haggerty and M. Taylor. Forsigs: Forensic sig-
nature analysis of the hard drive for multimedia ﬁle
In Proceedings of IFIP International
ﬁngerprints.
Information Security Conference, 2006.

[17] G. A. Hall.

Sliding window measurement for ﬁle
type identiﬁcation. ManTech Security and Mission
Assurance, 2006.

[18] R. M. Harris. Using artiﬁcial neural networks for
forensic ﬁle type identiﬁcation. Master’s thesis, Purdue
University, 2007.

[19] M. Jaber and C. Barakat. Enhancing application identi-
ﬁcation by means of sequential testing. In Proceedings
of the 8th International IFIP-TC 6 Networking Confer-
ence, 2009.

[20] J. Jung, V. Paxson, A. Berger, and H. Balakrishnan.
Fast portscan detection using sequential hypothesis
testing. In IEEE Symposium on Security and Privacy,
pages 211 – 225, may 2004.

[21] B. Li, Q. Wang, and J. Luo. Forensic analysis of
In International
document fragment based on SVM.
Conference on Intelligent Information Hiding and Mul-
timedia Signal Processing, Dec. 2006.

[22] R. Lyda and J. Hamrock. Using entropy analysis to
IEEE Security

ﬁnd encrypted and packed malware.
and Privacy, 5:40–45, Mar. 2007.

[23] G. Maier, R. Sommer, H. Dreger, A. Feldmann, V. Pax-
son, and F. Schneider. Enriching network security
analysis with time travel. In Proceedings of the ACM
SIGCOMM 2008 Conference on Applications, Tech-
nologies, Architectures, and Protocols for Computer
Communications, pages 183–194, 2008.

[24] P. Malhotra. Detection of encrypted streams for egress
monitoring. Master’s thesis, Iowa State University,

2007.

[25] U. Maurer. A universal statistical test for random bit

generators. Journal of Cryptology, 5:89–105, 1992.

[26] C. Muthukrishnan, V. Paxson, M. Allman, and
A. Akella. Using strongly typed networking to architect
for tussle. In Proceedings of the 9th ACM SIGCOMM
Workshop on Hot Topics in Networks, 2010.

[27] J. Olivain and J. Goubault-Larrecq. Detecting sub-
verted cryptographic protocols by entropy checking.
Research Report LSV-06-13, Laboratoire Sp´eciﬁcation
et V´eriﬁcation, ENS Cachan, France, June 2006.

[28] L. Paninski. Estimation of entropy and mutual infor-
mation. Neural Computation, 15(6):1191–1253, 2003.
[29] L. Paninski. Estimating entropy on m bins given fewer
IEEE Transactions on Information

than m samples.
Theory, 50(9):2200–2203, 2004.

[30] L. Paninski and M. Yajima. Undersmoothed kernel
entropy estimators. IEEE Transactions on Information
Theory, 54(9):4384–4388, 2008.

[31] A. Papadogiannakis, M. Polychronakis, and E. P.
Markatos. Improving the accuracy of network intrusion
detection systems under load using selective packet
the Third European
discarding.
Workshop on System Security, EUROSEC, 2010.

In Proceedings of

[32] V. Roussev and S. L. Garﬁnkel. File fragment clas-
siﬁcation - the case for specialized approaches. IEEE
International Workshop on Systematic Approaches to
Digital Forensic Engineering, pages 3–14, 2009.

[33] A. Shamir and N. v. Someren. Playing “hide and
In Proceedings of the Third
seek” with stored keys.
International Conference on Financial Cryptography,
pages 118–124, 1999.

[34] R. Sommer. Viable Network Intrusion Detection in
High-Performance Environments. Doktorarbeit, Tech-
nische Universit¨at M¨unchen, Munich, Germany, 2005.
[35] S. J. Stolfo, K. Wang, and W. jen Li. Fileprint analysis
for malware detection. Technical report, Columbia
University, 2005.

[36] S. M. Tabish, M. Z. Shaﬁq, and M. Farooq. Malware
detection using statistical analysis of byte-level ﬁle
In KDD Workshop on CyberSecurity and
content.
Intelligence Informatics, pages 23–31, 2009.

[37] G. Thatte, U. Mitra, and J. Heidemann. Parametric
Methods for Anomaly Detection in Aggregate Trafﬁc.
ACM Transactions on Networking, 2011.

[38] K. Thomas and D. Nicol. The koobface botnet and the
In Malicious and Unwanted

rise of social malware.
Software (MALWARE), pages 63 –70, oct. 2010.

[39] B. Trammell, E. Boschi, G. Procissi, C. Callegari,
P. Dorﬁnger, and D. Schatzmann.
Identifying Skype
trafﬁc in a large-scale ﬂow data repository. In Trafﬁc
Monitoring and Analysis, volume 6613 of Lecture
Notes in Computer Science, pages 72–85. 2011.

[40] C. J. Veenman. Statistical disk cluster classiﬁcation for

ﬁle carving. In Proceedings of the Third International
Symposium on Information Assurance and Security,
pages 393–398, 2007.

[41] D. D. Wackerly, W. M. III, and R. L. Scheaffer.
Mathematical Statistics with Applications. Duxbury
Press, Paciﬁc Grove, CA, sixth edition, 2002.

[42] A. Wald. Sequential tests of statistical hypotheses. The
Annals of Mathematical Statistics, 16(2):117–186, June
1945.

[43] A. Wald and J. Wolfowitz. Optimum character of the
sequential probability ratio test. Annals of Mathemati-
cal Statistics, 19(3):326–339, 1948.

[44] K. Wang and S. J. Stolfo. Anomalous payload-based
In Recent Advances in

network intrusion detection.
Intrusion Detection, pages 203–222, 2004.

[45] M. Weber, M. Schmid, D. Geyer, and M. Schatz.
Peat - a toolkit for detecting and analyzing malicious
In Proceedings of the 18th Annual Com-
software.
puter Security Applications Conference, pages 423–
431, 2002.

[46] L. Zhang and G. B. White. An approach to detect
executable content for anomaly based network intru-
In IEEE International Parallel and
sion detection.
Distributed Processing Symposium, pages 1–8, 2007.

APPENDIX

This appendix presents various methods for opaque traf-
ﬁc identiﬁcation, an extensive parameter space exploration
experiment to compare these methods and provide optimal
values for their parameters, the asymptotic efﬁciency of each
method, and a description of the HTTP content-type labeling
rules we used to determine ground truth in our experiments.

A. Comparison of Methods

1) Preliminaries: For all tests, let H0 be the hypothesis
that the vi are approximately uniformly distributed (e.g.,
is compressed or encrypted), and let H1 be
the packet
the alternative hypothesis, i.e., that the vi are distributed
according to some distribution that is not uniform (e.g.,
corresponding to a transparent packet).

In what follows, we examine approaches that can be
broadly classiﬁed under two different models, which we
refer to as operating on the entropy or byte-value domains.
For the entropy domain, the basic unit is the (byte-) entropy
of a block of bytes, where the number of bytes n in a block
is parameterized. In other words, if X is a random variable
in the entropy domain, then the support of X is the set of
all possible values for the byte-entropy of n bytes. If X is a
random variable in the byte-value domain, then the support
of X is the set of integers 0 through 255. That is, for the
byte-value domain, the basic unit is simply the byte.

Before delving into details of the various tests we explore,
we ﬁrst present necessary notation, summarized in Table III.
To represent the packet payload, let v = {v1, v2, ..., vN} be

Symbol

n
k
N
M
vi
wi
v
w
α
β
δ
T

Meaning

size (in bytes) of a block

size of domain (e.g., 256 for bytes)
(maximum) number of payload bytes

(maximum) number of samples

observation (byte)
observation (block)

sequence of observations (bytes)
sequence of observations (blocks)

expected false negative rate
expected false positive rate
alternative hypothesis weight

offset (in bytes)

Table III
NOTATION

a sequence of observations (e.g., payload bytes), such that
vi ∈ {0, 1, ..., k−1} ∀ i ∈ {1, ..., N}. That is, for a sequence
v of bytes, k = 256. In the entropy domain, we operate on
a sequence w of blocks of bytes w = {v1, v2, ..., vN/n}.
Notice that while the density function for the byte-value
domain is well-known and easy to compute, the entropy
domain is more complicated. For many of the tests we
examine, we need to evaluate the probability mass function
(PMF) over possible values for the sample entropy of n
bytes for each hypothesis. Simple threshold checking of the
sample entropy fails to leverage the distribution of sample
entropy values, missing important
the
relative likelihood of the values observed.

information about

Due to space limitations, we omit

the details of the
derivation of this PMF: the essential idea is that the sample
entropy of n bytes is the same regardless of the arrangement
of those bytes. We can then enumerate the possible ways of
arranging n bytes, for small n, to calculate the corresponding
PMF. We implemented such an enumeration using NVIDIA’s
CUDA GPU parallel programming toolkit, yielding a PMF
for n = 8.

Discrete Kolmogorov-Smirnov Test: Another appropriate
test for determining whether a sample is drawn from a
particular distribution is the Kolmogorov-Smirnov (K-S)
test. The K-S test is often used because of its generality
and lack of restricting assumptions. The test is based on
quantifying the difference between the cumulative distri-
bution functions of the distributions of interest. However,
we note that the traditional Kolmogorov-Smirnov test is
only valid for continuous distributions, and Conover has
already shown that the p-values for the continuous K-S test
applied to discrete or discontinuous distributions can differ
substantially from those of the discrete analog. Therefore,
we apply the discrete version as described by Conover [7].
Lastly, we note that Pearson’s χ2 test also seems appro-
priate in this setting. However, Pearson’s χ2 test assumes
that samples are independent, the sample size is large, and
the expected cell counts are non-zero — but, the latter two
assumptions do not necessarily hold in our setting as the
goal is to examine as few bytes as possible. Nevertheless,
we include such analyses for the sake of comparison to

Domain

Entropy

0.001, 0.005, 0.01, 0.05
0.001, 0.005, 0.01, 0.05

0.65, 0.75, 0.85

Param.

α
β†
δ‡
N
T

Bytevalue∗
(no addl.)
(no addl.)
(no addl.)

4, 12, 20

8, 16, 24, 32, 48, 64, 80, 128

4, 12, 20, 28, 32, 40

0, 8, 16, 24

† Applicable only for sequential tests.
‡ Not applicable for χ2 or discrete K-S tests.
∗ In addition to those for the entropy tests.

PARAMETER SPACE EXPLORED BY DOMAIN

Table IV

prior work [24], but omit the derivation since the test is
in common usage and our application is no different.

2) Parameter Space Exploration: We now present the re-
sults of a parameter space exploration experiment examining
all of the hypothesis tests with varying parameter values.
We present ROC (receiver operating characteristic) plots
that simultaneously examine the true positive rate and false
positive rate as a parameter (e.g., a threshold) varies. A set
of ROC plots, one for each classiﬁer, can then be used
to compare classiﬁers across a range of parameter values,
allowing one to judge the relative performance of classiﬁers.
There are several knobs we can turn. For the sequential
tests we explore the desired maximum false positive rate
α,
the desired maximum false negative rate β, and the
maximum number of payload bytes N. The parameter values
we examined for ﬁxed tests included the desired signiﬁcance
level α and number of payload bytes N. In all experiments,
the maximum number of samples for the sequential tests
equals the sample size for the ﬁxed tests.

We consider different alternative hypotheses by changing
the relative weight, δ, of the lower 128 byte values versus
the higher 128 byte values. The δ parameter takes values
in (0.5, 1.0], and indicates the expected percentage of byte
values less than 128. By changing the value, we alter our
model of transparent trafﬁc. In addition to measuring unifor-
mity, this class of alternative hypotheses has the advantages
of being extremely efﬁcient to implement (as determining
whether a byte value is less than 128 is a simple bit mask
operation) and of accounting for the prevalence of ASCII
characters in network trafﬁc.

Figure 8.

Illustration of length (N), offset (T ), and block size (n)

Finally, we explore starting our analysis at different points
within the packet, represented by the offset value T (in

Offset (T)0...T-1...Packet iBlock 0Block 1Block 0BlockSample(s){Block Size (n)EntropyTest0...T-1v0v1v2v3...Packet iSequence Size (N)viByte-ValueTestOffset (T)bytes). As shown pictorially in Figure 8, T indicates how
many bytes into the payload, i.e., past the end of the TCP
header, our analysis begins. The speciﬁc values explored for
each parameter are given in Table IV. Our dataset for the
exploration experiment consists of the ﬁrst 100,000 packets
from trace1, and we consider only encrypted data as
positive examples.

Figure 9 shows a single point for each unique set of
parameter values (over 10,000) in our experiments. Superior
classiﬁers should evidence a high true positive rate and a
low false positive rate, represented on a ROC plot by a
predominance of points in the upper-left corner of the plot.
Since the byte-value tests evidence the points closest to
the upper-left corner, the plots indicate that the sequential
tests and the likelihood-ratio test in the byte-value domain
are able to more accurately classify packets than the other
tests. We can also compare our techniques based on their
theoretical computational efﬁciency (see §A3); again, the
byte-value sequential tests are the clear winners.

We also determine which speciﬁc values for the various
parameters provide the optimal performance. In order to
do so, we make use of the so-called F -score, which is
a weighted harmonic mean of the precision and recall
metrics.5 Precision is deﬁned as the ratio of the number
of packets correctly classiﬁed as opaque, i.e., true positives,
to the total number of packets classiﬁed as opaque. Recall
is deﬁned as the ratio of the number of true positives to
the number of packets which are opaque according to our
ground truth. Said another way, precision can be seen as
measuring how often packets labeled as opaque are actually
opaque (but says nothing about how often opaque packets
are correctly identiﬁed), while recall indicates how often the
method correctly identiﬁes opaque packets (but says nothing
about how often transparent packets are mislabeled).

We now examine each parameter in isolation by varying
the parameter of interest while ﬁxing the other parameters
at default values (δ = 0.85, α = β = 0.005, N = 32,
and T = 8). As might be expected, the number of bytes
examined has a substantial effect on the performance of
the detectors (Figure 10(a)); this effect drops off over time,
suggesting that less than 32 bytes are needed in the general
case to make a decision and less than 16 bytes are needed by
the truncated test in the byte-value domain. The byte-value
tests are the clear winners; all three sequential methods and
the likelihood-ratio method performed equally well, each
attaining precision over 90%. The entropy tests performed
unexpectedly poorly, in few cases obtaining scores close
to those of the other tests. In addition, we found that the
restricted entropy test did not behave as we expected with
regard to increasing the number of samples involved; an
investigation revealed no underlying patterns in labels of

5More precisely, we use the F1-score, where recall and precision are

evenly weighted.

the misclassiﬁed examples. We suspect that the particular
decision boundaries (§II) used are simply poorly suited for
the tests between entropy distributions.

With regard to changes in offset (Figure 10(b)), we see no
clear improvement in classiﬁcation for offset values larger
than 8 bytes. Changes to the desired false positive and
negative rates similarly had limit impact on the performance
of the detectors, and so we omit those ﬁgures for brevity.
Performance when varying the δ parameter, which controls
the alternative hypothesis, peaks at δ = 0.85.

Changes to the desired false positive rate (Figure 11(a)),
similarly, have little impact on the performance of the
detectors (the case for the false negative rate β is the same;
we omit the ﬁgure for brevity). In either case, the parameters
have little effect on the entropy tests (due to the small
number of samples for the entropy tests, e.g., 4 samples
at N = 32 bytes); we therefore omit the entropy ﬁgures due
to space constraints.

We also examine changes to the δ parameter, which con-
trols the alternative hypothesis. Notice that in Figure 11(b),
the sequential
tests appear to fail most often when the
byte value distribution under H1 is assumed to be close
to uniform; this is due to a large number of trials failing to
make a decision, or forcibly making the wrong decision,
when faced with too few samples to effectively choose
between two similar distributions.

Summary of Findings: Our analysis shows that we can
narrow the ﬁeld to the likelihood-ratio and sequential tests
in the byte-value domain based on accuracy rates alone.
Perhaps surprisingly,
the entropy-based methods do not
perform as accurately as those in the byte-value domain; we
believe that this indicates that accurate entropy tests require
more samples than are available in our context. In addition,
examining more than 16 bytes provided little beneﬁt in
terms of accuracy. Interestingly, the offset parameter had
little effect in our tests. In summary, we found the truncated
sequential test to one of the most accuracy and efﬁcient tests,
and therefore made use of this technique for the experiments
in the body of the text.

3) Theoretical Efﬁciency: We can also compare our tech-
niques based on their theoretical computational efﬁciency
(Table V), in terms of the number of online ﬂoating-point
operations required for each case. In the following, any
operations which can be precomputed are omitted. In the
byte-value domain, the sequential tests each require only a
single multiplication and comparison per iteration, so the
number of standard ﬂoating-point operations is no more
than 2M for M samples (in the byte-value domain, samples
are bytes, so M = N); the likelihood ratio test is the
same, but with equality in the relation. Working in the
entropy domain introduces the overhead both of binning
the samples (M = N/n operations) and of computing the
sample entropy (3k standard operations plus k logarithms).
Pearson’s χ2 test requires M operations to bin the samples

Figure 9. ROC plots for the techniques examined in this work.

and 3k operations, where k is the size of the domain (e.g.,
k = 256 for the byte-value domain), to sum the squared
difference between the observed count and expected count
over all bins. Finally,
is O(M 2).
Obviously, from a performance standpoint, neither the K-
S test nor the entropy tests are a good choice.

the discrete K-S test

Test Type
Sequential

Likelihood Ratio

Pearson’s χ2
Discrete K-S

Floating-Point Operations

≤ 2M
2M

M + 3k
O(M 2)

Table V

THEORETICAL EFFICIENCY

B. HTTP Labeling Rules

Base Type

image, video, audio

text

application
application
application

*

Sub-type

pdf, xml, ﬂash

gzip, zip

*
*

*
*

Action/Label

opaque

transparent
transparent

opaque
omit
omit

HTTP CONTENT-TYPE FILTERING RULES

Table VI

To determine ground truth for HTTP packets, we ﬁrst ex-
amine the content-encoding: if the strings ‘gzip’ or ‘deﬂate’
appear in the content-encoding, the packet is labeled opaque;
otherwise, the label is determined by content type. HTTP
content-type ﬁelds contain a base type, such as ‘text’ or
‘video’, a sub-type, such as ‘html’ or ‘mp4’, and optional
parameters, such as ‘charset=us-ascii’. For our ﬁltering, if
the base type is ‘image’, ‘video’, or ‘audio’, the trafﬁc
is labeled opaque; if the base type is ‘text’, the trafﬁc is
labeled transparent. For the ‘application’ base type, we also
consider the sub-type: ‘zip’ and ‘x-gzip’ are considered
opaque, while ‘xml’, ‘pdf’, and ‘x-shockwave-ﬂash’ are
considered transparent. While some of these sub-types (e.g.,
PDF) can be containers for many other formats, we choose to
be conservative and simply classify them as transparent since
we have no clear cut way of drawing the line between semi-
structured and more opaque formats. All other sub-types
are dropped, since hand-labeling of all potential content-
types is infeasible and error-prone. Our HTTP ﬁltering and
labeling rules are summarized in Table VI (given in order
of application).

(a) F1-Score for sample size

(b) F1-Score for offset

Figure 10. Effects on accuracy when varying sample size and byte offset

(a) F1-Score for signiﬁcance level

(b) F1-Score for alternative hypothesis

Figure 11. Effects on accuracy when varying signiﬁcance level and alternative hypothesis

222324252627Length0.00.20.40.60.81.0F-ScoreBytevalueRestrictedLikelihoodRatioTruncated222324252627Length0.00.20.40.60.81.0F-ScoreBytevalueDiscreteK-SChisquare222324252627Length0.00.20.40.60.81.0F-ScoreEntropyRestrictedLikelihoodRatioTruncated22232425Oﬀset0.00.20.40.60.81.0F-ScoreBytevalueRestrictedLikelihoodRatioTruncated22232425Oﬀset0.00.20.40.60.81.0F-ScoreBytevalueDiscreteK-SChisquare22232425Oﬀset0.00.20.40.60.81.0F-ScoreEntropyRestrictedLikelihoodRatioTruncated10−310−210−1Alpha0.00.20.40.60.81.0F-ScoreBytevalueRestrictedLikelihoodRatioTruncated10−310−210−1Alpha0.00.20.40.60.81.0F-ScoreBytevalueDiscreteK-SChisquare0.650.700.750.800.85Delta0.00.20.40.60.81.0F-ScoreBytevalueRestrictedLikelihoodRatioTruncated