Controlled Functional Encryption

Muhammad Naveed1, Shashank Agrawal1, Manoj Prabhakaran1,

Xiaofeng Wang2, Erman Ayday3, Jean-Pierre Hubaux3 and Carl A. Gunter1

1University of Illinois at Urbana-Champaign

2Indiana University Bloomington

3École polytechnique fédérale de Lausanne

ABSTRACT
Motivated by privacy and usability requirements in various sce-
narios where existing cryptographic tools (like secure multi-party
computation and functional encryption) are not adequate, we in-
troduce a new cryptographic tool called Controlled Functional En-
cryption (C-FE). As in functional encryption, C-FE allows a user
(client) to learn only certain functions of encrypted data, using keys
obtained from an authority. However, we allow (and require) the
client to send a fresh key request to the authority every time it wants
to evaluate a function on a ciphertext. We obtain efﬁcient solu-
tions by carefully combining CCA2 secure public-key encryption
(or rerandomizable RCCA secure public-key encryption, depend-
ing on the nature of security desired) with Yao’s garbled circuit.
Our main contributions in this work include developing and for-
mally deﬁning the notion of C-FE; designing theoretical and prac-
tical constructions of C-FE schemes achieving these deﬁnitions for
speciﬁc and general classes of functions; and evaluating the perfor-
mance of our constructions on various application scenarios.

Categories and Subject Descriptors
K.6.5 [Computing Milieux]: Management Of Computing And In-
formation Systems—Security and Protection; E.3 [Data]: Data En-
cryption

Keywords
functional encryption, computation over encrypted data, ﬁne-grained
data control

1.

INTRODUCTION

Suppose volunteers would like to offer their genomic data for re-
search, as long as a strong privacy policy can be enforced without
having to trust individual researchers. We remark that beyond being
an illustrative example for us, abuse of sensitive data by researchers
who ignore or are unaware of the limits set by the data owner is in
fact a real problem, as evidenced by the case of the Havasupai tribe
against the Arizona State University [4, 5]. In 1989, researchers
from Arizona State University partnered with the Havasupai Tribe,

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
Copyright 2014 ACM 978-1-4503-2957-6/14/11 ...$15.00.
http://dx.doi.org/10.1145/2660267.2660291.

a community with high rates of Type II Diabetes, to study links
between genes and diabetes risk. When the researchers were not
successful in ﬁnding a genetic link, they used the DNA from blood
samples for other unrelated studies such as schizophrenia, migra-
tion, and inbreeding, all of which are taboo topics for the Havasu-
pai [4]. Such unfortunate incidents can be avoided if researchers
do not have direct access to this data, but can only carry out com-
putations on this data that are subject to restrictions speciﬁed by
the data owners. The restriction can include a limit on the total
amount of information (number of bits) revealed to the researchers
by a contributed piece of data over its life-time, a restriction on
the kind of functions that can be computed on the contributed data
or a requirement that certain amount of noise be added to any in-
formation computed from this data, a restriction on the number or
class of researchers who can access it, etc. On the other hand, the
researchers are typically not willing to publicly reveal the speciﬁc
functions they are interested in. Solving this problem satisfactorily
for all parties calls for leveraging tools from modern cryptography.
Where existing approaches fail. One approach to solving this
problem would be to use secure two-party computation, given the
recent advances in practical implementations of this tool [48, 36,
46, 45, 38, 47, 37, 61]. While this would indeed address all the
privacy concerns, this solution is not suited for our scenario for a
couple of reasons: ﬁrstly, this requires each volunteer to interact
separately with each researcher interested in using their genomic
data; secondly, the researchers need to decide what all functions
they need to compute by the time they interact with each volunteer,
which will prevent them from adapting their functions as research
progresses.

Another potential (albeit currently experimental) solution offered
by modern cryptography would be to use functional encryption or
FE – ﬁrst formalized in [19], which covers popular cryptographic
primitives like Identity Based Encryption (IBE), Attribute Based
Encryption (ABE), etc. as special cases [57, 34, 17, 44, 52, 31, 33,
28, 30]. An FE scheme would allow volunteers to encrypt their
data in such a way that for each function, a researcher can use a
key issued by a trusted authority to compute just that function of
the data. This shifts the responsibility of limiting the information
revealed about each genome from individual volunteers to an au-
thority, without the need to trust the authority with the genomic
data itself. However, functional encryption does not provide a suit-
able solution to our problem for a few reasons. Firstly, functional
encryption schemes tend to be extremely inefﬁcient. Also, im-
portantly, functional encryption currently relies on relatively new
and untested cryptographic assumptions. Further, to ensure that
when the authority issues a key for one ciphertext, it does not allow
computing the function on other ciphertexts (belonging to the same
data-owner, or different data-owners), one will need to employ ad-

1280ditional mechanisms and also use functional encryption for a more
complex function family than is originally required.
Our Contribution: Controlled Functional Encryption. These
limitations lead us to formulating a new notion of functional en-
cryption — called controlled functional encryption (C-FE) — which
addresses all the above privacy and usability issues, as well as re-
lies only on mature and efﬁcient cryptographic tools (unlike the
standard notion of functional encryption). Our main contributions
in this work are:

the data belonging to individual data owners. The data owners will
contribute their data to the system once, with attached policy pa-
rameters (e.g., number of times it can be used in a computation)
and go ofﬂine. They rely on the central authority to ensure that var-
ious policies are enforced regarding what functions of their data can
be computed by the clients.1 Further, the (honest-but-curious) cen-
tral authority itself should not learn any information about the data
(except policy parameters explicitly speciﬁed by the data owner),
and the data owners should not learn anything about how their data
is being used, except for the fact that their policies will be enforced.

1. Deﬁnitions. We present carefully formulated security deﬁnitions
for various forms of C-FE. We use simulation-based secu-
rity deﬁnitions, which give comprehensive security guarantees
against corrupt data users (clients).

2. Constructions. We design theoretical and practical construc-
tions of C-FE schemes achieving these deﬁnitions for speciﬁc
and general classes of functions. Our constructions, even for ar-
bitrary functions, are practically efﬁcient and rely only on well-
studied cryptographic primitives.

3. Applications and Performance Evaluation. We conﬁrm that our
proposed constructions are indeed practical by evaluating their
performance on large scale data. We also discuss the applica-
tions of C-FE to personalized medicine, patient similarity, pa-
ternity test and kinship test.

It is instructive to compare C-FE with FE: both rely on a central
authority to issue keys that have customized functionality. FE has
the feature that one key can be used on several ciphertexts, where
as C-FE forbids this. C-FE has several advantages over FE, in
situations where it is applicable. Firstly, C-FE avoids various im-
possibility results that affect FE. In particular, simulation-based
security deﬁnitions are typically impossible to achieve for func-
tional encryption (e.g., [53, 19, 8]), unless severe limitations are
placed on the number of keys that can be issued (e.g., [32, 30]).
Secondly, as we show in this work, even for arbitrary functions,
C-FE admits more practical constructions than are known to be
possible for FE (e.g., [33, 28, 29]); also FE constructions often
use relatively untested assumptions (e.g., sub-exponential Learn-
ing With Errors assumption, or assumptions related to multi-linear
maps) which are hard to rely on given fast improvements in crypt-
analysis (e.g., [41]), whereas C-FE constructions can be based on
much more well understood cryptographic primitives like public-
key encryption and oblivious transfer. In short, we present C-FE
as a practical tool, with strong security guarantees and efﬁcient con-
structions based on mature cryptographic primitives, that has direct
applications to several practical scenarios for which concepts like
secure multi-party computation and FE do not provide satisfactory
solutions.
Roadmap. The rest of the paper is organized as follows: Section 2
provides an overview of C-FE, Section 3 explains preliminaries,
Section 4 provides formal deﬁnition of C-FE functionality and
simulation based security deﬁnition, Section 5 describes general
and inner-product C-FE constructions, Section 6 reports on the im-
plementation and evaluation of the C-FE schemes, Section 7 high-
lights some applications of C-FE and describes the performance
of C-FE for these applications, Section 8 reviews the related work,
and Section 9 concludes the paper.

2. OVERVIEW
Deﬁning C-FE. In C-FE, the parties can be Data Owners, Clients
or a Central Authority. The clients wish to compute functions of

Figure 1: Components of a C-FE scheme, described formally in Section 4.

Each time a client wishes to evaluate a function f of a piece
of data x given to it (as a ciphertext), it makes a “key-request” to
the authority. From this key-request, the authority can recover the
policy parameter λ attached to x, and decide (using arbitrary logic
extraneous to the C-FE scheme) whether to issue a key or not. If it
issues a key, the client can use it to extract f (x) (and nothing else).
We shall require security against clients who behave arbitrarily
(i.e., not necessarily following the scheme); but the central author-
ity is considered to be honest-but-curious (i.e., possibly monitored
by a passive, eavesdropping adversary, but otherwise, following the
speciﬁed scheme). We require that a corrupt (honest-but-curious)
authority does not collude with any other parties. The other parties
may collude arbitrarily. On a technical note, our main security def-
inition is essentially Universally Composable (UC) security, except
for the above restrictions on the corruption of the authority.

There are several optional variations to this basic set of require-
ments that is important in many applications, and can be accommo-
dated in our constructions (often with little overhead).

1. Tweaks. We may allow the authority to tweak the function,
possibly using randomness hidden from the client. For instance,
the authority can add noise to an outcome. More generally, tweaks
can be used to restrict the class of functions that can be computed
(without the authority learning the exact function being computed).
2. Function Hiding. We can consider the requirement that the
authority should not learn the speciﬁc function computed by the
client on the data owner’s data, or that it learns only partial infor-
mation about the function.2

3. Pattern Hiding. Another optional security requirement would
be to allow a client to hide from the authority whether or not, in
two separate computations, it is computing with the same piece of
data from a data owner. Instead, if we require that the authority is
told when the same piece of data is computed on again, we say the
C-FE scheme is pattern revealing.

We remark that if a scheme is indeed pattern hiding, then certain
policies like ‘allow researchers to compute only 10 functions on my
1The policies themselves are extraneous to the C-FE scheme.
2Note that allowing the authority to learn more information
about the function would make it easier to enforce more complex
policies, at some privacy cost to the clients. In settings like research
on genomic data, the data from the data owners are considered
much more sensitive than the inputs from the clients (researchers),
and the latter may be trusted with a central authority.

Policy policy paramstweakData OwnerClientCentral AuthoritykeyrequestoutputfunctionKeyGenciphertextdata & policy paramssecret keypublic keyExtractKeyReqDecSetupEnc1281data’ cannot be enforced. This is just the price one has to pay in
order to provide more security to the clients.

We also remark that the various design choices above are made
to not only allow practically efﬁcient constructions, but also to suit
the security and usability requirements of the applications that mo-
tivated this work. In particular, the non-interactive nature (encryp-
tions instead of protocols) and the ofﬂine nature of data owners
make a C-FE scheme much easier to deploy in these applications
than a solution relying on, say, secure multi-party computation.
Constructing C-FE. We present a collection of constructions
meeting different levels of security, efﬁciency and generality.

1. First, we present a construction for the inner product func-
tion, wherein the data owner’s input is a vector of integers and the
function to be computed by the client is also speciﬁed by a simi-
lar vector; the output of the function is the inner product of these
two vectors.3 This construction is extremely efﬁcient, and is based
solely on (CCA2 secure) public-key encryption (instantiated using
a hybrid encryption scheme involving RSA-OAEP for key encap-
sulation and AES for data encapsulation). This construction allows
for an additive tweak, but does not allow function hiding or pattern
hiding.
This is a primitive with numerous applications, as various other
functions can be reduced to the secure computation of the inner
product function, possibly with tweaks. For instance, set-intersection
cardinality (size of the intersection of two sets) can be modeled as
the inner product of binary vectors representing the two sets, mod-
ulo a number N that is no less than the dimension of the vectors.

2. Next we present a general construction relying on the power-
ful garbled circuit construction due to Yao (or more generally, us-
ing any decomposable randomized encoding [39]). This construc-
tion admits any arbitrary function family, with arbitrary tweaks.
More precisely, for any (efﬁciently computable) function F , the
client obtains the outcome F (f, x, w), where x is the data, f is the
function speciﬁcation from the client, and w is the tweak speciﬁca-
tion from the authority (with pre-determined bounds on the size of
x, f and w). Prior to this, the authority obtains the policy parame-
ter λ attached to x, and can use this to determine whether to issue
a key to the client or not, and if so what value of w to use.
There are three variants of this construction, with different levels of
efﬁciency.
(a) Without Function Hiding or Pattern Hiding. This variant re-
lies solely on CCA2 secure public-key encryption and a block-
cipher (for implementing the garbled circuits).

(b) With Function Hiding but not Pattern Hiding. This variant ad-
ditionally requires an oblivious transfer (OT) primitive. Sev-
eral practical OT schemes are known, and are used along with
garbled circuits in practical implementations of secure 2-party
computation.

(c) With Function Hiding and Pattern Hiding. This variant is sim-
ilar to the above construction, but the CCA2 secure encryption
is replaced by Rerandomizable Replayable CCA encryption.
This is a relatively recent primitive, currently with only one
construction in the literature [55], which achieves provable

3The inner product is deﬁned over the ring of integers modulo
some integer N. In typical applications, like set-intersection cardi-
nality or set-union cardinality, N is chosen to be large relative to the
individual entries in the vectors and the dimension of the vectors,
so that the outcome is the inner product over integers (not modulo
any integer). We point out that this function is different from the
inner product predicate considered in the functional encryption lit-
erature, which only computes whether the inner product is zero or
not: the two functions are incomparable.

security based on the well-studied Decisional Difﬁe Hellman
(DDH) assumption. Its efﬁciency is comparable to that of (un-
optimized) OT schemes, but it is likely that further (possibly
heuristic) efﬁciency improvements are possible.

An important extension that naturally applies to all the above vari-
ants is that of multi-input C-FE: this allows the client to compute
a function not just on a single piece of data obtained from a data
owner, but also a function that takes as input multiple such pieces
of data. One can also obtain straightforward extensions that em-
ploy digital signatures to authenticate the information provided by
the data owners (when there is a public-key infrastructure). For
simplicity, we do not discuss these extensions in detail as they are
relatively straightforward.
We point out that many recent advances in cryptography like Func-
tional Encryption currently rely on new and largely untested hard-
ness assumptions (related to bilinear pairings and lattices). Given
the fast improvements in cryptanalysis (e.g., [41]), these should
still be considered at an experimental stage, and several years from
practical adoption. Unlike these tools, the above constructions of
C-FE use only mature cryptographic tools and assumptions (public-
key and symmetric-key encryption, DDH assumption, OT), that can
be readily deployed today.
Applications and Performance Evaluation. Firstly, we revisit
the example considered at the beginning of this section. Suppose
that each volunteer wishes to enforce a limit on the total number
of one-bit functions that can be computed on their genome. Given
a (pattern revealing) C-FE scheme for the family of functions that
the researchers are interested in (with or without function hiding
depending on the requirements of the researchers, and with or with-
out tweaks depending on the privacy requirements of the data own-
ers), we let each volunteer play the role of a data owner, each re-
searcher a client, along with a central authority that enforces the
policy; the policy parameter λ attached to each genome will in-
clude a bound on number of times that genome can be used by a
researcher. When a researcher wants to evaluate a one-bit func-
tion on an input, she makes a key-request. The authority recovers
the policy parameter speciﬁed by the genome owner, and using the
pattern information so far, determines if the key-request should be
honored or not. If it decides to respond, it uses the C-FE scheme
to send the key to the researcher.

We point out that this solution simultaneously resolves all the

competing privacy and usability requirements in our scenario.

Other application scenarios that motivated this work include per-
sonalized medicine, “patient-similarity,” “paternity and kinship.”
The function families that need to be supported in these applica-
tions are varied: examples include inner product between the input
vector and a vector given by the client (over integers), Hamming
or Levenshtein distance of the input vector with a given vector,
Smith-Waterman algorithm for aligning a sequence with a given
sequence, etc.4 We evaluate the performance of our general con-
struction when instantiated for each of these function families. We
use recent off-the-shelf implementations of Yao’s garbled circuit
protocol (along with OTs used in these implementations) and stan-
dard public-key and symmetric-key encryption algorithms (RSA-
OAEP and AES). Our evaluations conﬁrm that the schemes are
highly practical.

We also evaluate the performance of our Superfast inner prod-
uct C-FE scheme, which proves remarkably efﬁcient (at the cost

4In the multi-input variant, we can also support these functions
when both arguments to the function are inputs from data owners;
the performance will be essentially identical in the two cases.

1282of not being function hiding) given that it involves only standard
encryption and decryption operations.

3. PRELIMINARIES

In this section, we describe the tools we use to build our schemes,

explain the adversary model, and establish notation.
IND-CCA2 Secure Encryption. IND-CCA2 encryption provides
security against adaptive chosen-ciphertext attacks. It has the fol-
lowing useful non-malleability property: given an encryption of a
message m, it is infeasible for a computationally bounded adver-
sary to create an encryption of a message related to m. The security
requirement is formally captured via an indistinguishability based
security game which we brieﬂy describe here. An adversary out-
puts two messages m0 and m1 and is given a ciphertext c – an
encryption of either m0 or m1. Even with access to a decryption
oracle which can be used to decrypt any ciphertext except c itself,
adversary should not be able to tell which message c corresponds
to. Very efﬁcient IND-CCA2 encryption schemes are known in the
random oracle model, for instance RSA-OAEP [27]. A detailed
discussion of the relationship among different notions of security
for public-key encryption can be found in [14].
Oblivious transfer. Oblivious transfer (OT) is one of the most
widely studied fundamental primitives in cryptography. It is a two
party protocol between a sender, who has two strings x0 and x1,
and a chooser with choice bit b. While sender does not learn any-
thing about the bit b (chooser’s security) in the protocol, chooser
only learns the value of xb (sender’s security).

In the common random string (CRS) model, Piekert et al. [54]
give an efﬁcient, one-round (ﬁrst message from chooser to sender,
next one from sender to chooser), UC-secure protocol for OT under
the well-studied DDH assumption (as well as a variety of other
hardness assumptions). We use this protocol, denoted by ΠOT, in
our general construction in Section 5.2.
Garbled Circuits. The main component of our general construc-
tion is garbled circuits (GC), introduced by Yao in [60]. See [15]
for a recent treatment of this tool. Several implementations of GC
already exist [48, 36], and lately, much work has been going into
making it more secure and efﬁcient [46, 45, 38, 47, 37, 61].
Adversary model. The two most widely studied corruption mod-
els in literature are honest-but-curious and malicious5. Honest-but-
curious parties follow their designated protocol diligently but try
to learn the secrets of other parties from the interactions they have
with them. On the other hand, malicious parties behave the way
they like: not only they try to learn more information, but also exe-
cute any protocol of their choice in order to do so. In this work, our
constructions provide security against honest-but-curious authori-
ties and malicious clients.
Notation. We use κ to denote the security parameter. A function
is negligible in κ (denoted negl(κ)) if it is smaller than the inverse
of any polynomial, for all large enough values of κ. A probabilistic
polynomial time algorithm, denoted in short by PPT, is an algo-
rithm whose running time is bounded by some polynomial in κ on
all inputs. This algorithm may use random coin tosses during its
execution.
We use ZN to denote the ring of integers modulo N (consisting
of 0 and ﬁrst N − 1 positive integers with addition and multipli-
cation deﬁned modulo N). A vector of (cid:96) elements in this ring is

5Honest-but-curious adversaries are also referred to as semi-
honest or passive. Malicious adversaries are sometimes called ac-
tive.

denoted by (cid:126)x = (x1, x2, . . . , x(cid:96)), where every xi ∈ ZN . En-
cryption of a vector (cid:126)x means encryption of the concatenation of the
elements of (cid:126)x.
We use [1, n] to denote the set {1, 2, . . . , n}. For two strings a
and b, a ◦ b denotes their concatenation and a ⊕ b denotes their
bit-wise XOR. We denote the inner-product of two vectors (cid:126)x and (cid:126)y
as (cid:104)(cid:126)x, (cid:126)y(cid:105)
On using honest-but-curious third party. We assume the exis-
tence of an honest-but-curious third party (central authority) that is
trusted not to collude with the party computing a function (client).
In general, the whole public key infrastructure (PKI) depends upon
trusted third parties called certiﬁcate authorities (CAs). PKI is
widely used for securing communication on Internet. CAs are trusted
not to collude with the adversary, but still be secure enough against
attacks. This type of non-collusion assumption is widely used in lit-
erature. Indeed, primitives like Identity-Based Encryption, Attribute-
Based Encryption, etc., all involve a central authority trusted to not
collude with other parties in the system. Nikolaenko et al. [51,
50] use similar non-collusion assumption where they trust the third
party (garbled circuit generator) not to collude with the garbled
circuit evaluator. Protocols for outsourcing multi-party computa-
tion [23, 22, 42, 43] use similar non-collusion assumptions to out-
source evaluation of the garbled circuits.
4. DEFINING C-FE

In this section, we formally deﬁne controlled functional encryp-

tion (C-FE) and the security models under which we study it.

Our deﬁnition of C-FE differs from the deﬁnition of FE [19] in
a crucial way. In FE, once a client receives a key for a function f
from the authority, it can use the key to decrypt any number of ci-
phertexts it wants. However, in our controlled setting, every time a
client wants to decrypt a ciphertext CTx with f, a key is requested
from the authority. The authority generates a one-time key which
could only be used to compute f (x). In order to decrypt a different
ciphertext, a new key request must be submitted. Consequently, we
have an additional algorithm KeyReq in our deﬁnition of C-FE be-
low. Further, the authority will need to extract the policy parameter
attached to CTx from the key request, before it can decide whether
to honor the request; for this, an algorithm Extract is used.
Syntax. We start by deﬁning the syntax and (perfect) correctness
requirement for the six algorithms that form a C-FE scheme. The
role of these algorithms is illustrated in Figure 1.

DEFINITION 4.1. A controlled functional encryption (C-FE) scheme

for a function family Fκ deﬁned over (Fκ,Xκ, Λκ) consists of
six PPT algorithms (Setup, Enc, KeyReq, Extract, KeyGen, Dec)
satisfying the following correctness condition for all κ ∈ N, x ∈
Xκ, λ ∈ Λκ and f ∈ Fκ. Consider the following experiment:

(MPK, MSK) ← Setup(1κ)

CT ← Enc(x, λ, MPK)
(ρ, ζ) ← KeyReq(CT, f )
, ξ) ← Extract(ρ, MSK)
(cid:48)
(λ
τ ← KeyGen(ξ)
z ← Dec(ζ, τ )

Then we require λ(cid:48) = λ (the authority receives the policy parame-
ter correctly) and z = Fκ(f, x) (the decryption yields the correct
output) with probability 1.
Note that instead of writing f (x), we have denoted it as Fκ(f, x),
where Fκ could be considered a function family, and f speciﬁes
which function in the family should be applied to x.

1283The above syntax does not explicitly accommodate a function-
revealing or pattern-revealing C-FE scheme.
In these variants,
the output of Extract will contain not just λ, but also f and/or a
unique identiﬁer that can identify CT. To accommodate tweaks,
we modify the deﬁnition of KeyGen to take a tweak w ∈ Wκ as
an additional input, and change the ﬁnal correctness requirement to
z = Fκ(f, x, w).
Security Deﬁnition. To cleanly capture the security guarantees
of C-FE, we use an ideal functionality, in the spirit of Universally
Composable (UC) security [21]. In UC security, ideal functionality
is simply an ideal trusted party that captures the security guaran-
tees: the various parties in the system (data owners, clients, author-
ity) can learn only as much information as they can learn when in-
teracting with this trusted party, and can inﬂuence the system only
as much as the trusted party lets them. Our security deﬁnition is
also along the lines of UC security, except that we consider an ad-
versarial model in which the authority can only be corrupted pas-
sively (honest-but-curious) and only by itself (no collusion); while
clients can be actively corrupted and may collude with each other.
Ideal World. We deﬁne the C-FE ideal functionality F that inter-
acts with several “data owners,” several “clients,” and one “author-
ity” as follows. (We omit routine details like initializing a session
and how parties can join a session.) F can come in four modes
of security, depending on whether it is function-hiding or function-
revealing, and whether it is pattern-hiding or pattern-revealing.
1. A data-owner can upload a pair (x, λ) to F. Then F picks a
handle h (a κ-bit random string) and sends it to all the clients.
Internally, F records (h, x, λ) in a table.

2. A client can send an evaluation request (f, h) to F. Then F

proceeds as follows:
(a) First, depending on its mode of security, F sends one of the
following to the authority.
• (f, h, λ), if function and pattern-revealing.
• (h, λ), if function-hiding and pattern-revealing.
• (f, λ), if function-revealing and pattern-hiding.
• λ, if function and pattern-hiding.
(b) Then it awaits for a command from the authority, either
denying or allowing evaluation. In the former case, it sends a
special symbol ⊥ to the client. In the latter case, it receives a
tweak w from the authority and sends F (f, x, w) to the client.
Real World. In the “real world” execution, interaction with F is
replaced by calls to a C-FE scheme, as follows. To initialize the
system, the authority runs Setup ﬁrst and publishes M P K (for the
data owners). Instead of uploading (x, λ) to F, a data owner would
run Enc and privately communicate the resulting ciphertext CT to
all the clients (in an implementation, an access controlled bulletin-
board could be used to do this). Instead of sending an evaluation
request to F, a client would run KeyReq and send its output to
the authority; the authority, instead of receiving λ (and possibly
f and/or a handle for CT), uses Extract to obtain it. Then it can
use an external decision process to decide whether or not to honor
the key-request, and if it is to be honored, what the tweak value
w should be. Then, instead of sending w to F, the authority runs
KeyGen to obtain a key that it sends to the client. Instead of receiv-
ing the output from F, the client would compute it using Dec.

DEFINITION 4.2. A C-FE scheme is simulation secure if for
every adversary Adv in the real world who actively corrupts a sub-
set of clients or only passively corrupts the authority alone, there is

a simulator Sim in the ideal world execution, which also corrupts
only the same set of parties, and produces an output identically
distributed to Adv’s output in the real world.

A more precise deﬁnition refers to “environments” in which the
execution — real or ideal — takes place; for more details, we refer
the reader to [21] and subsequent formulations of UC security.

5. CONSTRUCTIONS

In this section, we describe two C-FE schemes secure under the
deﬁnitions discussed above. The ﬁrst one is a simple and extremely
efﬁcient scheme for the inner-product functionality FIP.
It pro-
vides practical solutions to common problems like weighted aver-
age, hamming distance, etc. The second one is a general construc-
tion for any polynomial-time computable functionality. Though not
as efﬁcient as the ﬁrst one, this construction is still practical for
many problems of interest (as demonstrated by our experiments)
and provides more security.
5.1 Inner Product

Let FIP = {f(cid:126)v | (cid:126)v ∈ Z(cid:96)

family, where f(cid:126)v((cid:126)x) = (cid:104)(cid:126)v, (cid:126)x(cid:105) = (cid:80)(cid:96)

We ﬁrst describe an efﬁcient and simple way to compute inner-
product between two vectors in our controlled functional encryp-
tion setting. Our scheme is secure against malicious clients and
honest-but-curious authorities in the non-function hiding security
model. Once again, note that we are able to compute the actual
value of inner product, and not just whether it is zero or not.
N} denote the inner-product function
i=1 vi · xi mod N for all
(cid:126)x ∈ Z(cid:96)
N . Note that to specify a function in this family, one only
needs to provide the index (cid:126)v. (For simplicity we have omitted the
security parameter κ in the description.)
Overview. We ﬁrst provide an overview of the construction. To
encode an input vector (cid:126)x, the data owner chooses a random vector
(cid:126)r of the same dimension as (cid:126)x over ZN .
It then outputs ((cid:126)y, σ),
where σ = EncP K ((cid:126)r) and Enc is a CCA2 secure PKE, and (cid:126)y =
(cid:126)x + (cid:126)r (all operations over ZN ). Note that (cid:126)y and (cid:126)r form an additive
secret sharing of (cid:126)x, and neither by itself contains any information
about (cid:126)x. The key-request computing (cid:104)(cid:126)x, (cid:126)v(cid:105) consists of (σ, (cid:126)v). The
authority will decrypt σ to obtain (cid:126)r and returns (cid:104)(cid:126)v, (cid:126)r(cid:105) to the client.
The client locally computes (cid:104)(cid:126)v, (cid:126)y(cid:105) and adds it to the negative of the
value obtained from the authority, to obtain

(cid:104)(cid:126)v, (cid:126)y(cid:105) − (cid:104)(cid:126)v, (cid:126)r(cid:105) = (cid:104)(cid:126)v, (cid:126)x(cid:105).

Even if the client sends the same σ to the authority several times, it
is easy to show that the client’s view can be simulated perfectly in
an ideal world, where the client only obtains (cid:104)(cid:126)v, (cid:126)x(cid:105) for the values
of (cid:126)v it sent to the authority. As in the general construction, using
CCA2 secure encryption ensures that a malicious client obtains no
advantage by sending a σ it did not obtain from a data owner.

Note that the authority’s computation here involves a decryption,
and an inner product computation, and the client’s computation in-
volves merely an inner product computation. Further, this scheme
can exploit the sparsity of (cid:126)v, i.e. the client’s computation is propor-
tional to the number of non-zero elements in (cid:126)v. In fact, even if all
vector elements are non-zero, our performance evaluations show
that this construction is extremely fast for genomic-scale inputs.
Construction. A (function and pattern revealing) C-FE scheme
ΠIP for the function family FIP is presented in Figure 2 and a proof
of security is described below. Correctness of ΠIP follows easily
from construction and the linearity of dot product:

(cid:104)(cid:126)v, (cid:126)y(cid:105) − τ = (cid:104)(cid:126)v, (cid:126)x + (cid:126)r(cid:105) − (cid:104)(cid:126)v, (cid:126)r(cid:105) = (cid:104)(cid:126)v, (cid:126)x(cid:105).

1284Note that we can allow the authority to add noise to the outcome
using a tweak: KeyGenIP will take the noise w as an additional
input and set τ = (cid:104)(cid:126)v, (cid:126)r(cid:105) − w, so that the outcome obtained by the
client is (cid:104)(cid:126)v, (cid:126)x(cid:105) + w.

Protocol ΠIP

and MSK to be PK and SK respectively.

• SetupIP(1κ): Run SetupCCA2(1κ) to obtain (PK, SK). Set MPK
• EncIP((cid:126)x, λ, MPK): Choose (cid:96) numbers r1, r2, . . . , r(cid:96) uniformly at
random from ZN . Let (cid:126)r = (r1, r2, . . . , r(cid:96)). Output the ciphertext
CT = ((cid:126)x + (cid:126)r, EncCCA2((cid:126)r, λ, MPK)).
• KeyReqIP(CT, (cid:126)v): Let CT = ((cid:126)y, σ). Output ρ = (σ, (cid:126)v) and ζ =
• ExtractIP(ρ, MSK): Let ρ = (σ, (cid:126)v). Run DecCCA2(σ, MSK) to ob-
tain ((cid:126)r, λ). Output ((λ, σ), ξ) where σ is used to reveal the pattern,
and ξ = ((cid:126)v, (cid:126)r).

((cid:126)v, (cid:126)y).

• KeyGenIP(ξ): Let ξ = ((cid:126)v, (cid:126)r). Output τ = (cid:104)(cid:126)v, (cid:126)r(cid:105).
• DecIP(ζ, τ ): Let ζ = ((cid:126)v, (cid:126)y). Output (cid:104)(cid:126)v, (cid:126)y(cid:105) − τ.
Figure 2: Superfast Construction for computing actual inner product.

Proof of Security. A simple simulator, combined with the CCA2
security of the encryption scheme can be used to prove the security.
The interesting case is when a client is corrupt. To translate the
ideal world view to the real world view of the client, we consider
the following simulator.

First, the simulator picks a pair of keys (MPK, MSK) to sim-
ulate the setup. Then, when it receives a handle h, it creates a
simulated ciphertext CT(cid:48) = ( (cid:126)yh, ch), where (cid:126)yh is a random vector
(which is identically distributed as (cid:126)x + (cid:126)r in the real ciphertext), and
ch ← EncCCA2(0|(x,λ)|, MPK) is a ciphertext encrypting a string
of zeros (which will be indistinguishable from the encryption of
(x, λ)). Later, if the client sends out a key-request of the form
(σ, (cid:126)v), the simulator checks if σ = ch for some handle h. There
are two cases:

1. σ = ch for some h: Then the simulator forwards an evalua-
tion request (h, (cid:126)v) to the ideal functionality, which will return z =
(cid:104)(cid:126)v, (cid:126)x(cid:105). The simulator creates a simulated value τ(cid:48) = (cid:104)(cid:126)v, (cid:126)yh(cid:105) + z.
In this case, τ(cid:48) is identically distributed as the value τ the client
receives in the real execution.

2. There is no h s.t. σ = ch: In this case the simulator acts
like the authority. i.e., It decrypts σ and (if the decryption is valid)
obtains some vector (cid:126)r; then it returns τ(cid:48) = (cid:104)(cid:126)v, (cid:126)r(cid:105).

In the second case above the ciphertext σ sent by the client to
the authority does not correspond to any (simulated) ciphertext it
received (from any simulated data owner). However, the client
could have created σ in an arbitrary fashion, without necessarily
encrypting a value r that it knows. To argue that the simulation
is indistinguishable from the real execution, we need to argue that
the dummy ciphertexts ch created by the simulator remain indis-
tinguishable from real ciphertexts, even though the simulator car-
ries out decryptions of arbitrary ciphertexts σ that the adversary
presents (other than the dummy ciphertexts themselves). This is
possible, thanks to the CCA2 security of the encryption scheme:
a distinguisher between the real execution and the simulation can
be turned into an adversary that distinguishes the encryptions of
real messages and dummy messages, with the help of a decryption
oracle (to which it never sends challenge ciphertexts).
5.2 General construction
In this section, we construct a controlled FE scheme Π for any
polynomial-time computable family of functions F, which take in-
puts from the domain X . Without loss of generality, we assume
that an element f ∈ F can be represented by (cid:96) bits, and an element

x ∈ X can be represented by k bits, where both (cid:96) and k are some
polynomial in κ.
Overview. We start by sketching an intuitive construction, which
is neither secure nor efﬁcient enough, and then describe how to
ﬁx these issues. For simplicity, we start with a function revealing,
pattern revealing construction, with no tweaks, for general func-
tion evaluation. That is, we are given an arbitrary (efﬁciently com-
putable) function F so that the client should be able to compute
F (f, x), if the authority, after seeing λ (and pattern information),
allows the client to do so, where (x; λ) is a piece of data and as-
sociated policy parameter from a data owner, and f is a function
speciﬁcation from the client.

First, the authority runs a Setup algorithm: it picks an encryption-

decryption key pair (MPK, MSK) for a public-key encryption scheme,
and publishes the public key. The encryption algorithm used by
the data owner takes (x, λ) and creates two ciphertexts (α, σ), ob-
tained by encrypting (x, λ) respectively, under P K. The client
will receive (α, σ) and when it wants to evaluate f (x), it sends
a key-request to the authority consisting of (f, σ). The authority
can recover λ by decrypting σ; it can also update the pattern infor-
mation, if necessary, by comparing λ with previous key requests it
received. Then, if it decides to honor the key-request, it engages
in a one-round 2-party secure computation (using garbled circuits
and a one-round OT protocol, for instance) to compute the follow-
ing function F (cid:48). F (cid:48) takes α as input from the client and (f, SK)
as input from the authority, and outputs F (DecSK (α), f ) to the
client. Note that DecSK (α) = x. This would ﬁt the syntax of
C-FE, if the key-request includes the ﬁrst message from the client
to the authority in the secure computation protocol. As for security,
since a secure computation protocol is used, the client should learn
nothing other than F (f, x).

There are two major problems with this solution:

1. Firstly, it is not secure against malicious clients. In particular,
suppose the client feeds not α, but a related ciphertext α(cid:48) to
the secure computation protocol. Then the client can potentially
learn F (x(cid:48), f ) where x(cid:48) = DecSK (α(cid:48)) is related to x.

2. Secondly, the above solution has a serious drawback in terms of
efﬁciency. Often F is a very simple function (like inner product
or Hamming distance), and can be very efﬁciently implemented
using a 2-party secure computation protocol. However, the se-
cure computation protocol used above is not for evaluating F ,
but for evaluating F (cid:48). Note that F (cid:48) involves a (public-key) de-
cryption operation. This decryption applies to a ciphertext of
the entire input x. This makes the scheme vastly inefﬁcient and
often impractical.

The ﬁrst problem is easy to ﬁx. To thwart all such malleability
attacks we can use a CCA2 secure public-key encryption scheme.
(One should also bind α and σ together using a random nonce, so
that the client cannot replace the policy of one data owner with that
of another; our ﬁnal solution will not have this structure, and hence
will not need the use of a random nonce.)
To address the second problem, we need to ensure that the secure
computation is for F itself, and not a function like F (cid:48). To achieve
this, we take a closer look at how a garbled circuit based 2-party
computation protocol proceeds. The client can evaluate a garbled
circuit only for an input for which it holds the requisite “labels”:
each bit position of input has two labels associated with it, corre-
sponding to the values 0 and 1, that are picked at random by the
garbled circuit generator. To let a client evaluate the circuit on a
k-bit input x (belonging to the generator) that the client does not

1285know, the generator sends the k labels corresponding to x, without
revealing whether each label corresponds to value 0 or 1.

In our case, unfortunately, the garbled circuit is generated by the
authority who also does not know x, and it will not be able to send
just the relevant labels. However, it can take the help of the data
owner (who is ofﬂine), as follows.

Recall that the data owner encodes x as (α, σ) where α is given
to the client and σ to the authority. σ will contain a set of 2k keys
for symmetric-key encryption (SKE), encrypted under the author-
ity’s public-key. The authority will encrypt all the 2k labels (2
per bit position of x) under these keys. Further, the message in-
side σ will also specify a random order for the 2 encrypted labels
for each bit position. The authority will send all the encrypted la-
bels to the client in this order. Note that σ contains no information
about x itself. Now, the client needs to recover only the k labels
corresponding to x from these 2k encrypted labels. For this, α will
include k SKE keys (in the clear), one out of the two keys for each
bit position, corresponding to the bit value of x at that position.
α will also indicate, for each bit position, whether the given key
corresponds to the ﬁrst or the second one in the pair of encrypted
labels that will be sent to the client by the authority. This allows
the client to decrypt exactly the k labels corresponding to the bit
values of x. Note that the client’s view too does not contain any
information about x, since which one in a pair of encrypted labels
corresponds to the bit value 0 and which one to 1 is not known to
the client.

We have another construction which is actually a slight optimiza-
tion of the above scheme, that avoids the 2k encryptions by the
authority and the k decryptions by the client, by having σ and α
specify the labels themselves. The authority will pick all other la-
bels for the garbled circuit freshly, but the 2k labels corresponding
to the input wires for x remain the same.

Note that when f is known to the authority, the only labels that
the authority cannot send directly to the client are those for x. In
this case, the entire scheme is based only on public and symmetric-
key encryption schemes. However, if we require function hiding,
the authority will need to transfer the correct labels corresponding
to f via oblivious-transfer.

The variants can be easily accommodated in this construction.
Firstly, the message in the ciphertext σ can also contain the policy
parameters λ associated with a piece of data x. Tweaks are sim-
ply additional inputs to F that the authority can hard-wire into the
circuit, while creating the garbled circuit. To allow pattern hiding,
we replace CCA2 secure encryption with Rerandomizable RCCA
secure encryption.
Construction.
For the sake of simplicity, we ignore the pol-
icy parameter λ in the construction; this lets us merge the algo-
rithms Extract and KeyGen (ignoring the need to extract λ). Let
(SetupSKE, EncSKE, DecSKE) be a symmetric key encryption scheme
which generates keys of length κ and encrypts κ-length messages.
Also, let ΠOT be a one-round oblivious transfer protocol where the
ﬁrst message is sent from chooser to sender and the second message
from sender to chooser (for more details, see the paragraph ‘obliv-
ious transfer’ in Section 3). Using these tools along with others,
we present a formal construction of Π in Figure 3. The two mes-
sages (from the client to the authority, and back) in the OT protocol
are combined with key-request and key-generation algorithms, so
that the syntax of C-FE is respected. A proof of security is given
below. We also present an alternate construction, which is slightly
more efﬁcient, in Appendix A.
Proof of security. We provide a sketch of the proof of security
of Π. Once again, the interesting case is when a client is mali-

Protocol Π

1 ◦ r0

1 ◦ r1

2 ◦ r1

k ◦ r1

1 ◦ ru2

2 . . . ◦ r0

MSK to be PK and SK respectively.

i . Let ˆr = r0
2 . . . ruk

• Setup(1κ): Run SetupCCA2(1κ) to obtain (PK, SK). Set MPK and
• Enc(x, MPK): For i ∈ [1, k] and b ∈ {0, 1}, run SetupSKE(1κ) to
k. Choose
obtain a key rb
a uniformly random k-bit string v, and let u = x ⊕ v. Now, let ru
denote ru1
k , where ui is the ith bit of u. Output the
ciphertext CTx = ((ru, u), EncCCA2(ˆr ◦ v, MPK)).
• KeyReq(CT, f ): Let CT = (α, σ) and f = (f1, f2, . . . , f(cid:96)). For
j ∈ [1, (cid:96)], run the ﬁrst step of the oblivious transfer protocol ΠOT
with chooser’s input being fj. Let Mj be the ﬁrst message output
by this protocol and Rj be the coin tosses used. Now, let M denote
(M1, . . . , M(cid:96)) and R denote (R1, . . . , R(cid:96)). Output ρ = (σ, M )
and ζ = (α, f, M, R).
• KeyGen(ρ = (σ, M ), MSK): Run DecCCA2(σ, MSK) to obtain
k) and v. Consider the circuit C which takes as
(r0
input a k-bit string z and an (cid:96)-bit function g, and computes F (g, z).
Construct a projective PrvSimG,φ(f )=f,S garbled version of this
circuit as described in [15] and call it ˆC, choosing keys at random for
each and every wire of the circuit, including input wires. Let the key
k).
pairs corresponding to the k-bit string z be (t0
For i ∈ [1, k] and b ∈ {0, 1}, run EncSKE(tb
) to obtain a
ciphertext cb⊕vi
Let the key pairs corresponding to the (cid:96)-bit function input g be
(cid:96) ). Parse M as (M1, . . . , M(cid:96)). For j ∈ [1, (cid:96)],
(s0
run ΠOT with sender’s input being (s0
j ) and message received
from chooser being Mj. Let M(cid:48)
j be the second message output
by this protocol. Let M(cid:48) denote (M(cid:48)
(cid:96)). Output τ =
( ˆC, (c0

j , s1
1, . . . , M(cid:48)

, where vi is the ith bit of v.

1, t1
i , rb⊕vi

1), . . . , (r0

1), . . . , (s0

1), . . . , (t0

k, r1

(cid:96) , s1

1, r1

1, s1

k, t1

i

i

1, c1

k, c1

1, . . . , c0

k), (M(cid:48)

• Dec(ζ, τ ): Parse τ as ( ˆC, (c0

1, . . . , M(cid:48)
(cid:96)))
and ζ as ((ru, u), f, (M1, . . . , M(cid:96)), (R1, . . . , R(cid:96))). For j ∈ [1, (cid:96)],
run ΠOT with chooser’s input fj, coin tosses Rj, ﬁrst round message
Mj, and second round message M(cid:48)
j, to obtain the key for the jth bit
of g. Parse ru as ru,1 . . . ru,k. To ﬁnd the key for the ith bit of z,
run DecSKE(cui
i . Now, evaluate ˆC to obtain the
i
value of f (x).

, ru,i) to obtain txi

1, c1

1, . . . , c0

k, c1

k), M(cid:48)).

Figure 3: General C-FE Construction

cious. Let SimGC be the simulator S of the projective prv.sim se-
cure garbling scheme6 with circuit being the side information i.e.
PrvSimG,φ,S where φ(f ) = f, as described in [15]. We construct
a simulator Sim which uses SimGC to simulate the view of a corrupt
client Adv in the ideal world.

Sim runs Adv internally as a black-box. He ﬁrst executes Setup(1κ)

2 . . . r0

2 ◦ r1

1 ◦ r1

1 ◦r0

to obtain (MPK, MSK), and sends MPK to Adv. When he re-
ceives a handle h from the ideal functionality, he chooses (r0
1, r1
1),
2 . . .◦ r0
k◦ r1
k,
k) and v at random. Let ˆr = r0
. . . , (r0
k, r1
1 ◦ r0
k, 0|x|). Sim provides (α, σ) as ciphertext to
and α = (r0
Adv, where σ = EncCCA2(ˆr ◦ v, MPK)).
When Adv initiates a key request ρ = (σ(cid:48), M ), Sim ﬁrst extracts
an f from M (note that since ΠOT is a UC-secure protocol, this can
be done). He then checks whether σ(cid:48) = σ for some h or not. If
σ(cid:48) (cid:54)= σ for any h, Sim simply runs KeyGen with (σ(cid:48), M, MSK),
and returns the output to Adv. In case there is equality for some hx,
he sends f and hx to Eval, and obtains F (f, x). He now invokes
SimGC with inputs (f, F (f, x)) to obtain a fake garbled circuit
ˆCFake. Having obtained the circuit, Sim runs the rest of KeyGen
with (r0
k) and v (decrypted value of σ) and re-
k), M(cid:48)) to Adv. This completes the
turns ( ˆCFake, (c0
1, c1
description of Sim.

1), . . . , (r0

1, . . . , c0

k, r1

k, c1

1, r1

6The simulation based garbling schemes (prv.sim) and indis-
tinguisbility based garbling scheme (prv.ind) schemes of [15] are
equivalent in our setting.

1286Note that in the ideal world, when Sim receives a key request
with σ(cid:48), he generates a fake garbled circuit (GC) as opposed to a
real circuit (if Sim creates a real GC, Adv would evaluate it to re-
cover f (0|x|), and distinguish the two worlds). However, a fake
GC has the property that no matter what combination of keys a
party uses for the input wires of the bits of x, the circuit always
evaluates to F (f, x). Therefore, even if Adv uses keys correspond-
ing to 0|x| to evaluate ˆCFake, it will still recover F (f, x). Hence, it
cannot distinguish between a fake and a real GC.
Correctness follows easily from construction.

6.

IMPLEMENTATION AND EVALUATION
We implemented our C-FE constructions: general as well as
Superfast construction. Experiments were conducted on synthetic
data, however, size of the data was inspired by the applications
discussed in Section 7. We evaluated our general construction on
a powerful machine but used a laptop to evaluate our Superfast
inner-product construction.
6.1 Superfast Inner-Product Construction

Our Superfast inner-product construction is implemented in Java.
We use RSA-OAEP [16] (RSA-Optimal Asymmetric Encryption
Padding) implementation of the Java Cryptography Extension (JCE)
and evaluated the construction with 1024-bit, 2048-bit and 4096-bit
keys.
Experiments. Our Superfast inner-product construction is very
light, so we used a laptop – with Intel Core i7 3615QM processor,
8GB memory and Mac OS X 10.9 – for the experiments.
Vector sizes. We used data vector of size 4,000,0007 integers (4-
byte) and varied the function vector size according to the different
applications discussed in Section 7. We also used data vectors of
size 40,000,0008 integers for the evaluation.

Encryption in Superfast scheme has two parts: additive secret
sharing of plaintext’s ﬁeld elements and public key-encryption of
one share of each plaintext element. We concatenate several vec-
tor elements to be encrypted in one block to avoid blow up in the
ciphertext size.
Ideally, size of ciphertext in our scheme should
be double the size of plaintext due to additive secret sharing. As,
we use RSA-OAEP, padding makes size of the ciphertext little bit
more than double. Per block padding size is same for different key
sizes, but, as larger keys have larger block sizes, the ciphertext size
decreases as the key size increases, as shown in Table 1.

Plaintext size

(4-byte alphabet)

Plaintext
size(MB)
Key size

(bits)

Ciphertext
size(MB)
Encryption

time(s)

4,000,000

40,000,000

15.26

152.59

1024

2048

4096

1024

38.51

33.68

31.95

385.10

12.86

15.70

24.81

126.04

Table 1: Encryption time and ciphertext size of Superfast C-FE scheme:
As, encryption time and ciphertext size in our scheme depend only on the
plaintext size, we present it separately from Table 2. Experiments were
performed on a laptop with Intel Core i7 3615QM processor, 8GB memory
and Mac OS X 10.9. Each measurement is an average of 10 runs. We
evaluated 4,000,000 and 40,000,000

7The number is based on the fact that each human has 4,000,000

variants.

different locations.

84 million variants in each individual can appear at 40 million

We present the performance of Superfast scheme in Table 1
and Table 2. Function vector is chosen randomly to account for
worst case scenarios. As, we pack several secret shares in each
public key encryption by concatenating them in a single block, se-
quential function vectors would result in a very small number of
public key decryptions at the authority for key generation. Our
plaintext has millions of elements, so, very small random function
vectors (e.g., with 1000 elements) would result in number of pub-
lic key decryptions same as the size of the function vector. But, as
the function vector size increases the number of public key decryp-
tions decreases. The maximum possible size of the function vector
is when it is equal to the size of plaintext. As, shown in Table 2,
this case is much efﬁcient than small function vectors. Note that in
practical scenarios function vectors are not random and our scheme
will perform much better than this analysis. The key request mes-
sage size depends upon the function vector size. Function key size
is constant in our scheme. Decryption stage is very efﬁcient and
constitutes simple additions and multiplications and only depends
upon the plaintext size.

6.2 General C-FE scheme

Our general construction is based on Yao’s garbled circuits. We
use FastGC [35] for Yao’s garbled circuits implementation. Our
general C-FE construction also requires hybrid encryption, which
we implement using AES (with 128-bit key) and RSA-OAEP (with
4096-bit key). To implement hybrid encryption we use Java Cryp-
tography Extension (JCE). For AES, we use AES counter-mode
implementation of JCE, and for RSA we use RSA-OAEP imple-
mentation of JCE. RSA-OAEP is a non-malleable encryption scheme
secure against IND-CCA2 attacks in the random oracle model [16].
Moreover, our prototype is single-threaded. We implement the al-
ternate construction (with function hiding) described in Appendix A,
which is slightly more efﬁcient. This construction requires minor
modiﬁcations to the garbled circuit implementation, so in principle
it is very easy to reproduce our results. We require extra code for
(i) hybrid encryption, and (ii) partial reuse of the wire labels.
Experiments. We tested our general C-FE construction on a
Dell PowerEdge R720 computer with dual Intel Xeon E5-2670
(2.60GHz) processors (computer has 16 cores in total, but our im-
plementation is sequential) and 128GB of memory. Scientiﬁc Linux
6.3 (kernel version: 2.6.32) was installed on the computer. We al-
located 30GB heap memory for the garbled circuit generator and
another 30GB heap memory for the garbled circuit evaluator. We
note that FastGC Java implementation is memory intensive and
even with 30GB heap memory (maximum allowable by JVM is
less than 32GB), we ran out of memory. Kreuter et al. introduced
PCF (Portable Circuit Format) framework which is much better in
terms of memory consumption, partially because PCF is written in
C++ [45]. Both generator and evaluator programs were executed
simultaneously on the same machine. Amount of data transfered
between generator and evaluator was recorded to report network
bandwidth usage.

We evaluated performance of our system on very large problem
instances. As shown in Table 3 performance of our scheme is negli-
gible over plain garbled circuits. We evaluated the general scheme
with function hiding capability. It is clear from Table 3 that our
scheme has negligible overhead on top of plain garbled circuits.
Note that Ofﬂine computation time is a one-time cost that’s in-
curred ﬁrst time the computation is done and there is no computa-
tion cost when the same computation is repeated again. The ofﬂine
computation includes generating plaintext digital circuit from the
code.

1287Key size (bits)

Key generation

Decryption

Function vector size

(4 byte alphabet)

1,000
1,000
1,000
10,000
10,000
10,000
20,000
20,000
20,000

4,000,000
4,000,000
4,000,000
40,000,000

Time
(s)
1.21
6.55
42.52
11.66
61.95
377.23
22.37
116.83
658.67
226.19
495.31
1512.44
1947.32

1024
2048
4096
1024
2048
4096
1024
2048
4096
1024
2048
4096
1024

Data sent
(KBytes)
132.46
256.21
501.26
1295.96
2422.85
4414.68
2529.26
4551.33
7732.90

55059.63(=53.77MB)
50118.00(=48.94MB)
483444.50(=47.21MB)
240209.11(=234.60MB)

Data received

(Bytes)

8
8
8
8
8
8
8
8
8
8
8
8
8

Time
(ms)
0.07
0.07
0.07
0.04
0.04
0.04
0.07
0.08
0.17
20.58
22.81
23.03
19.90

Table 2: Performance evaluation of our Superfast inner-product construction: Experiments were performed on a laptop with Intel Core i7 3615QM processor,
8GB memory and Mac OS X 10.9. Each measurement is average of 10 runs.

Problem

Hamming 10,000bits
Hamming 16,000bits
Hamming 20,000bits
Hamming 60,000bits

Hamming 1,500,000bits

Levenshtein 100x100 (2-bit alphabet)
Levenshtein 1000x1000 (2-bit alphabet)
Levenshtein 20000x50 (2-bit alphabet)
Levenshtein 20000x200 (2-bit alphabet)
SmithWaterman 50x50 (32-bit alphabet)

AES (16 Bytes)

Dot Product 100x100 (8- & 2-bit alphabets)
Dot Product 1000x1000 (8- & 2-bit alphabets)
Dot Product 2500x2500 (8- & 2-bit alphabets)

Encryption

Time(ms)

Time(ms)

1024
2.87
4.15
5.16
14.88
364.33
0.35
0.90
0.36
0.35
0.35
0.50
0.34
0.79
1.70

4096
3.74
5.15
6.09
15.66
379.27
1.52
1.75
2.46
1.10
1.05
1.05
1.04
1.47
2.24

Decryption(ms)
4096
1024
59.30
5.56
7.27
61.09
61.88
8.10
72.92
18.12
453.59
408.94
57.22
3.75
55.87
3.96
1.00
55.80
55.31
2.17
56.03
2.55
56.91
3.73
55.55
2.62
2.94
56.09
57.15
4.12

Keygen
GC Gen(s)

Ofﬂinea, Online

3.81, 0.30
3.95, 0.47
6.19, 0.55
11.15, 1.52
469.78, 45.81

1.47, 3.47
1.57, 498.38
1.64, 650.73
1.24, 2714.76
2.47, 197.51
1.50, 0.17
2.62, 51.80
60.59, 0.29
531.46, 1.08

Comm

919.09KB
1470.61KB
1838.46KB
5515.99KB

135MB

10725.26KB

1534MB
2098MB
8402MB
580MB
306.33KB
61.78KB
617.76KB
1700.62KB

Decryption
GC Eval(s)

Ofﬂinea,Online

2.19, 0.31
2.70, 0.45
4.70, 0.52
88.34, 0.44
426.50, 44.26

0.59, 3.50
0.64, 498.40
0.70, 650.45
0.80, 2714.75
1.58, 197.54
0.64, 193.10
1304, 77.40
592.51, 0.33
686.71, 1.11

Table 3: Performance evaluation of our general Controlled Functional Encryption (C-FE) with function-hiding construction: Experiments were performed
on a Dell R720 computer with dual Intel Xeon E5-2670 (2.60GHz) processors, 128GB of memory and Scientiﬁc Linux 6.3. Each measurement is average
of 10 runs. Note the negligible performance overhead due to hybrid encryption on top of plain garbled circuits. Evaluator’s computation is only 1
4 th of the
generator’s computation. Both evaluator and generator are taking approx. the same time, because due to pipelining, evaluator is waiting for the partial circuit to
be generated and delivered before it can evaluate it. 1024 and 4096 in the third row of the table shows the public key sizes (in bits) used for hybrid encryption.
aThe ofﬂine cost shown in the table is a one-time cost and is only incurred for the ﬁrst time and does not need to be repeated for every computation of the

same function. It can be done well before the online phase.

Hamming distance. We evaluated our schemes with Hamming
distance problems of size upto 1.5 million bits. Most of the com-
mercial services such as 23andme provides human SNP proﬁle with
0.5 million SNPs (recently they started to provide 1 million SNPs).
To compare two SNP proﬁles, direct Hamming distance doesn’t
work as each SNP is of two bits. We designed the following sim-
ple encoding after which we can use Hamming distance to compute
the similarity: SNP can have value of either 0, 1 or 2, we represent
0 as 001, 1 as 010 and 2 as 100. After this encoding, computing
Hamming distance will give us number of common SNPs between
two SNP proﬁles. As, we represent each SNP with 3 bits, for a
0.5 million SNP proﬁle, we require 1.5 million bits. Therefore, we
conducted experiments with 1.5 million bits and our results shows
that it requires less than 8 minutes and 135MB network commu-
nication to ﬁnd similarity between two SNP proﬁles of 0.5 million
SNPs each (using our encoding scheme). Note that our Superfast
scheme can also be used for computing Hamming distance, but it
doesn’t provide function hiding, the general scheme provides func-
tion hiding but takes more time.
Levenshtein Distance. Levenshtein distance is also a commonly
used similarity measure and is computationally much more involved
than Hamming distance. Levenshtein distance is computed using

dynamic programming algorithm. We ran relatively large problem
instance; ﬁnding Levenshtein distance between 20,000 and 200 let-
ters strings (from a 2-bit alphabet). Levenshtein distance requires a
lot of time and bandwidth but this is due the inefﬁciency of under-
lying garbled circuits.
Inner-product. We implemented inner-product functionality into
FastGC family to compare the performance of our Superfast C-FE
scheme and general C-FE scheme. We used simple modular mul-
tiplier circuit [2] to realize multipliers for our inner-product imple-
mentation. Inner-product computation in our general model incurs
large one-time cost, but is efﬁcient in the online stage. As, can
be seen in the last row of Table 3, inner-product have reasonable
computation and communication cost.
Other problems: We also tested our general function C-FE scheme
on other problems such as AES and SmithWaterman score. Results
are shown in Table 3.

7. APPLICATIONS
Personalized Medicine. Personalized medicine is a revolution-
ary concept in healthcare. Different from a “one-size-ﬁts-all” ap-
proach, it enables physicians to prescribe medicine based on the

1288patients’ genomic build-up. Several cryptographic protocols have
been proposed for personalized medicine [13, 25]. These proto-
cols are inefﬁcient and incur very high computation and commu-
nication costs. Recently, additive homomorphic encryption based
protocols have been proposed [10, 11, 12]. These schemes are rel-
atively efﬁcient, but they are very interactive. They require the pa-
tient to be online and possess a computer that will be used during
a disease susceptibility test. This makes them more difﬁcult to de-
ploy in practice. More seriously, patient computers could get com-
promised, resulting in leaking their genomic data. We show that
our Superfast C-FE schemes can be used to achieve a much more
practical scheme: it doesn’t require any direct interaction with the
patient9, is much more computationally and storage efﬁcient, and
securer as we are using non-malleable public-key encryption as op-
posed to homomorphic encryption which allows the ciphertext to
be arbitrarily modiﬁed.

Using our technique, DNA is ﬁrst digitized through sequencing
or genotyping by an external agency. This sequencing agency can
encrypt the patient’s genome under our Superfast C-FE scheme
with a public key issued by the authority and then publish the ci-
phertext. Later, when a medical unit wants to do some disease sus-
ceptibility test, it obtains the encrypted genome and asks the au-
thority for a one-time function key corresponding to the required
disease-susceptibility test. The maximum number of disease mark-
ers for a disease susceptibility test are no more than 50 Single Nu-
cleotide Polymorphisms (single nucleotide variation between two
species) (SNPs) [6]. We conducted our experiments with 1000
SNPs disease test to show the efﬁciency of our scheme. As shown
in Table 2, our scheme can compute disease susceptibility tests very
efﬁciently.
Patient Similarity.
Suppose Alice is suffering from a cancer
and her physician wants to search (on a nation-wide scale) for an-
other patient with similar symptoms and genetic build-up treated
for the same cancer, in a hope that if some therapy and treatment
worked or didn’t work, it would help to treat Alice’s cancer. Hos-
pitals are typically reluctant to share data with each other without
proper security protection, due to concerns about privacy and li-
ability. Putting effective protection in place is highly nontrivial,
given the scale of the problem: there are 5723 registered hospitals
in United States [3] and more than 15 million patients suffering
from cancer in US alone [1]. It can be difﬁcult for hospitals to even
share the data such as the total number of diabetic patients to form
cohorts for medical studies. In this situation, sharing genomic data
is extremely far-fetched.

Many schemes [40, 20, 26, 58, 18, 9, 59] have been proposed for
measuring similarity between genomes but they are designed for
comparing two genomes and none of them can actually gracefully
scale to handle the complete human SNP proﬁle similarity compar-
ison (i.e. 4 million letters of 2-bit alphabet). Comparing one SNP
proﬁle to potentially thousands or hundred of thousands is out of
question for current schemes. We show that our Superfast C-FE
scheme can efﬁciently support complete human SNP proﬁle com-
parison and is highly scalable to be used for comparison with a very
large population.

Each human has 4 million SNPs. Comparing similarity of the
complete 4 million SNP proﬁle requires 226 seconds in our scheme
and is highly parallelizable. Assuming that the pricing model of
the authority is similar to Amazon EC2, similarity comparison of

9If patient wishes, she can opt to be asked by the authority for
permission to conduct test using email, SMS, phone call or some
other method; alternatively patient can decide beforehand which
parties are allowed to learn which functions.

the complete genome would cost only $0.014 per single 4 million
SNPs proﬁle comparison. Most of the time complete SNP pro-
ﬁle comparison is not required and that’s why we also conducted
experiments with small function vector size (10,000 and 20,000).
Comparison with function vector of size 20,000 can be done in
22.37 seconds and it would cost $0.0014 per comparison. Finding
a similar genome in a collection of 100,000 genomes would cost
only $1414 when comparing all 4 million SNPs, while it would
cost only $140 when comparing any random 20,000 SNPs.
Paternity and Kinship. For privacy-preserving paternity and kin-
ship tests, Baldi et al. make use of both cryptographic tools (i.e.,
private set intersection) and biological tools (e.g., emulating the
Restriction Fragment Length Polymorphism chemical test in soft-
ware) [13]. Furthermore, their subsequent work demonstrates a
framework for conducing such tests on a Android smartphone [25].
Baldi et al. have a very elegant idea of exploiting domain knowl-
edge to bring privacy-preserving genomic computation to the world
of plausibility. Their scheme is based on private-set intersection
protocol and is not general enough to be used for other types of ge-
nomic computation. Moreover, they assume that user is storing her
own genome which is not a very practical assumption. Also, their
scheme requires access to the complete genome (i.e. 3 billion let-
ters), which is very expensive. Moreover, they only show how they
can ﬁnd paternity test, we can also support other relations such as
sibling, uncle, cousin, etc. Our approach can support paternity and
kinship inference using human SNP proﬁle that can be obtained for
less than $100 (e.g., from 23andme). Our constructions can be used
to implement kinship inference algorithms described in [49].

8. RELATED WORK

In this section, we talk about the work most closely related to

ours, namely functional encryption schemes that support any polynomial-
time computation.

Sahai et al. proposed single-query functional encryption scheme
that supports any polynomial-time computation on the ciphertext
only once [56]. Their construction is based on Yao’s garbled cir-
cuits [60]. In the encryption phase, a garbled circuit is generated
with input of the encryption party embedded in the circuit. Each
input wire label of this garbled circuit is encrypted using a different
public key. The garbled circuit and encryption of the wire labels
are sent to the decryption party. Decryption party asks the author-
ity for the decryption keys of the wire labels corresponding to the
function to be computed and it decrypts the wire labels using these
keys After obtaining the wire labels the decryption party can eval-
uate the garbled circuit to compute the function. As they need to
encrypt each wire label with a different public key, packing is not
possible and ciphertext size blows up signiﬁcantly. Typically, 80
bit wire labels are used in Yao’s garbled circuit implementation and
encrypting each wire label with public key will blow up the cipher-
80 × the plaintext size. Moreover, the limitation
text size by keysize
of computing only single function makes the scheme not useful
for many practical applications. In fact, the scheme was presented
as a public key encryption scheme, where encryptor can encrypt
ciphertext without worrying about the credentials of the receiver.
The receiver can only decrypt if it has appropriate credentials. The
limit of computing single function comes from the reusability issue
of Yao’s garbled circuit. Feasibility of reusable garbled circuit has
been shown by it very inefﬁcient to be of any practical use [30].

Gorbunov et al. proposed a scheme based on Sahai et al. scheme
that supports computation of q-functions over the ciphertext, where
q depends on different parameters and increasing q affects the over-
all efﬁciency of the scheme [31]. They addresses the reusability is-

1289sue of garbled circuit in Sahai et al. construction but this makes
the scheme very inefﬁcient. Even with overwhelming overhead
the scheme supports limited number of functions to be computed.
While theoretically, interesting the scheme is very far from being
practical and would take hundreds of years even for very small val-
ues of q (e.g., 100).

Chung et al. proposed a functional encryption scheme based
on stateless hardware tokens that are identical for all users [24].
However, they rely on computationally intensive operations (fully
homomorphic encryption schemes) as well as a powerful tamper
proof token carrying out signiﬁcant computation (signature, non-
interactive zero knowledge proofs (NIZK) and succinct non-interactive
arguments (SNARGs) veriﬁcation). Moreover, it has been shown
that secrets can be easily stolen from tamper-proof hardware [7], so
that a single token can be attacked to compromise the entire system.
Overall, it is not clear if token based approach would be practical
in various applications.

9. CONCLUSION

Functional encryption has emerged as a fascinating primitive in
cryptography recently. We have proposed a complementary variant
— called controlled functional encryption (C-FE) — which allows
a more ﬁne-grained access control than FE allows, but relies on a
semi-trusted authority. Our proposal is motivated by several appli-
cations where C-FE provides a natural solution. Further, we give
efﬁcient constructions for C-FE, relying only on well-known cryp-
tographic assumptions. We evaluate the performance of our C-FE
schemes on large scale data and demonstrate its efﬁciency.

10. ACKNOWLEDGMENTS

This work was partially supported by CNS-1228856, CNS-1017782,
CNS-1117106, CNS-1223477, CNS-1223495, CNS-1330491 (THaW),
and HHS 90TR0003-01 (SHARPS). The views expressed are those
of the authors only.

11. REFERENCES
[1] Cancer facts and statistics.

http://www.cancer.org/research/cancerfactsstatistics/.

[2] A combinational multiplier using the xilinx spartan ii fpga. http://

ecen3233.okstate.edu/PDF/Labs/Combinational%20Multiplier.pdf .

[3] Fast facts on US hospitals.

http://www.aha.org/research/rc/stat-studies/fast-facts.shtml.

[4] Havasupai tribe and the lawsuit settlement aftermath.

http://genetics.ncai.org/case-study/havasupai-Tribe.cfm.

[5] Indian tribe wins ﬁght to limit research of its dna. http://www.

nytimes.com/2010/04/22/us/22dna.html?pagewanted=all&_r=1&.

[6] List of genetic diseases with associated genes and snp’s.

http://www.eupedia.com/genetics/genetic_diseases.shtml.

[7] Tpm reset attack. http://www.cs.dartmouth.edu/~pkilab/sparks/.
[8] S. Agrawal, S. Gurbanov, V. Vaikuntanathan, and H. Wee. Functional

encryption: New perspectives and lower bounds. In Crypto, 2013.

[9] M. J. Atallah and J. Li. Secure outsourcing of sequence comparisons.

International Journal of Information Security, 4(4):277–287, 2005.

[10] E. Ayday, J. L. Raisaro, and J.-P. Hubaux. Privacy-enhancing

technologies for medical tests using genomic data. In NDSS, 2013.
[11] E. Ayday, J. L. Raisaro, P. J. McLaren, J. Fellay, and J.-P. Hubaux.
Privacy-preserving computation of disease risk by using genomic,
clinical, and environmental data. In HealthTech, 2013.

[12] E. Ayday, J. L. Raisaro, J. Rougemont, and J.-P. Hubaux. Protecting

and evaluating genomic privacy in medical tests and personalized
medicine. In WPES, 2013.

[13] P. Baldi, R. Baronio, E. De Cristofaro, P. Gasti, and G. Tsudik.

Countering gattaca: efﬁcient and secure testing of fully-sequenced
human genomes. In CCS, pages 691–702, 2011.

[14] M. Bellare, A. Desai, D. Pointcheval, and P. Rogaway. Relations
among notions of security for public-key encryption schemes. In
CRYPTO ’98, number 1462, pages 26–45.

[15] M. Bellare, V. T. Hoang, and P. Rogaway. Foundations of garbled

circuits. In CCS, pages 784–796, 2012.

[16] M. Bellare and P. Rogaway. Optimal asymmetric encryption. In

EUROCRYPT, pages 92–111, 1995.

[17] J. Bethencourt, A. Sahai, and B. Waters. Ciphertext-policy

attribute-based encryption. In IEEE S&P, pages 321–334, 2007.

[18] M. Blanton, M. J. Atallah, K. B. Frikken, and Q. Malluhi. Secure and

efﬁcient outsourcing of sequence comparisons. In ESORICS, pages
505–522. 2012.

[19] D. Boneh, A. Sahai, and B. Waters. Functional encryption:
Deﬁnitions and challenges. In TCC, pages 253–273, 2011.

[20] F. Bruekers, S. Katzenbeisser, K. Kursawe, and P. Tuyls.

Privacy-preserving matching of DNA proﬁles. IACR Cryptology
ePrint Archive, 2008:203, 2008.

[21] R. Canetti. Universally composable security: A new paradigm for

cryptographic protocols. In FOCS, pages 136–145, 2001.

[22] H. Carter, C. Amrutkar, I. Dacosta, and P. Traynor. For your phone
only: custom protocols for efﬁcient secure function evaluation on
mobile devices. SCN, 2013.

[23] H. Carter, B. Mood, P. Traynor, and K. Butler. Secure outsourced
garbled circuit evaluation for mobile devices. In USENIX Security,
pages 289–304, 2013.

[24] K.-M. Chung, J. Katz, and H.-S. Zhou. Functional encryption from

(small) hardware tokens. In ASIACRYPT, pages 120–139. 2013.

[25] E. De Cristofaro, S. Faber, P. Gasti, and G. Tsudik. Genodroid: are
privacy-preserving genomic tests ready for prime time? In WPES,
pages 97–108, 2012.

[26] D. Eppstein, M. T. Goodrich, and P. Baldi. Privacy-enhanced

methods for comparing compressed DNA sequences. arXiv preprint
arXiv:1107.3593, 2011.

[27] E. Fujisaki, T. Okamoto, D. Pointcheval, and J. Stern. RSA-OAEP is
secure under the RSA assumption. In CRYPTO, number 2139, pages
260–274. Jan. 2001.

[28] S. Garg, C. Gentry, S. Halevi, M. Raykova, A. Sahai, and B. Waters.
Candidate indistinguishability obfuscation and functional encryption
for all circuits. STOC, pages 40–49, 2013.

[29] S. Garg, C. Gentry, S. Halevi, A. Sahai, and B. Waters.

Attribute-based encryption for circuits from multilinear maps. In
CRYPTO 2013, number 8043, pages 479–499. 2013.

[30] S. Goldwasser, Y. Kalai, R. A. Popa, V. Vaikuntanathan, and

N. Zeldovich. Reusable garbled circuits and succinct functional
encryption. In STOC, pages 555–564, 2013.

[31] S. Gorbunov, V. Vaikuntanathan, and H. Wee. Functional encryption
with bounded collusions from multiparty computation. In CRYPTO,
2012.

[32] S. Gorbunov, V. Vaikuntanathan, and H. Wee. Functional encryption
with bounded collusions via multi-party computation. In CRYPTO,
pages 162–179. 2012.

[33] S. Gorbunov, V. Vaikuntanathan, and H. Wee. Attribute-based

encryption for circuits. In STOC, pages 545–554, 2013.

[34] V. Goyal, O. Pandey, A. Sahai, and B. Waters. Attribute-based

encryption for ﬁne-grained access control of encrypted data. In CCS,
pages 89–98, 2006.

[35] Y. Huang, D. Evans, and J. Katz. Private set intersection: Are garbled

circuits better than custom protocols. In NDSS, 2012.

[36] Y. Huang, D. Evans, J. Katz, and L. Malka. Faster secure two-party

computation using garbled circuits. In USENIX Security, volume
201, 2011.

[37] Y. Huang, J. Katz, and D. Evans. Quid-pro-quo-tocols: Strengthening

semi-honest protocols with dual execution. In IEEE S&P, pages
272–284, 2012.

[38] Y. Huang, J. Katz, and D. Evans. Efﬁcient secure two-party

computation using symmetric cut-and-choose. In CRYPTO, pages
18–35. 2013.

[39] Y. Ishai. Randomization techniques for secure computation. Secure

Multi-Party Computation, 10:222–248, 2013.

[40] S. Jha, L. Kruger, and V. Shmatikov. Towards practical privacy for

genomic computation. In IEEE S&P, pages 216–230, 2008.

1290[41] A. Joux. Faster index calculus for the medium prime case application

to 1175-bit and 1425-bit ﬁnite ﬁelds. In EUROCRYPT, pages
177–193, 2013.

[42] S. Kamara, P. Mohassel, and M. Raykova. Outsourcing multi-party

computation. IACR Cryptology ePrint Archive, 2011:272, 2011.

[43] S. Kamara, P. Mohassel, and B. Riva. Salus: a system for

server-aided secure function evaluation. In CCS, pages 797–808,
2012.

[44] J. Katz, A. Sahai, and B. Waters. Predicate encryption supporting

disjunctions, polynomial equations, and inner products. In
EUROCRYPT, pages 146–162, 2008.

[45] B. Kreuter, B. Mood, A. Shelat, and K. Butler. Pcf: A portable circuit
format for scalable two-party secure computation. USENIX Security,
2013.

[46] B. Kreuter, A. Shelat, and C.-H. Shen. Billion-gate secure

computation with malicious adversaries. In USENIX Security, pages
14–14, 2012.

[47] Y. Lindell. Fast cut-and-choose based protocols for malicious and

covert adversaries. In CRYPTO, pages 1–17. 2013.

[48] D. Malkhi, N. Nisan, B. Pinkas, and Y. Sella. Fairplay-secure

two-party computation system. In USENIX Security, pages 287–302,
2004.

[49] A. Manichaikul, J. C. Mychaleckyj, S. S. Rich, K. Daly, M. Sale, and

W.-M. Chen. Robust relationship inference in genome-wide
association studies. Bioinformatics, 26(22):2867–2873, 2010.

[50] V. Nikolaenko, S. Ioannidis, U. Weinsberg, M. Joye, N. Taft, and
D. Boneh. Privacy-preserving matrix factorization. In CCS, pages
801–812, 2013.

[51] V. Nikolaenko, U. Weinsberg, S. Ioannidis, M. Joye, D. Boneh, and
N. Taft. Privacy-preserving ridge regression on hundreds of millions
of records. In IEEE S&P, pages 334–348, 2013.

[52] T. Okamoto and K. Takashima. Fully secure functional encryption

with general relations from the decisional linear assumption. In
CRYPTO 2010, number 6223, pages 191–208. 2010.

[53] A. O’Neill. Deﬁnitional issues in functional encryption. Cryptology

ePrint Archive, Report 2010/556, 2010.

[54] C. Peikert, V. Vaikuntanathan, and B. Waters. A framework for
efﬁcient and composable oblivious transfer. In CRYPTO 2008,
number 5157, pages 554–571. 2008.

[55] M. Prabhakaran and M. Rosulek. Rerandomizable rcca encryption. In

CRYPTO, pages 517–534, 2007.

[56] A. Sahai and H. Seyalioglu. Worry-free encryption: functional

encryption with public keys. In CCS, pages 463–472, 2010.
[57] A. Sahai and B. Waters. Fuzzy identity-based encryption. In

EUROCRYPT, pages 457–473, 2005.

[58] D. Szajda, M. Pohl, J. Owen, B. G. Lawson, and V. Richmond.

Toward a practical data privacy scheme for a distributed
implementation of the smith-waterman genome sequence comparison
algorithm. In NDSS, 2006.

[59] R. Wang, X. Wang, Z. Li, H. Tang, M. K. Reiter, and Z. Dong.

Privacy-preserving genomic computation through program
specialization. In CCS, pages 338–347, 2009.

[60] A. C.-C. Yao. How to generate and exchange secrets. In FOCS, pages

162–167, 1986.

[61] S. Zahur and D. Evans. Circuit structures for improving efﬁciency of

security and privacy tools. In IEEE S&P, pages 493–507, 2013.

APPENDIX
A. ALTERNATE GENERAL CONSTRUCTION

Before a formal description, we give some intuition about the
construction. At a high-level, our plan is to let the client use a
garbled circuit generated by the authority to evaluate the function
on the input x. The circuit in question evaluates the function F ,
which takes x and f as inputs (and optionally, a tweak w, which we
ignore for simplicity). f is known to the client, and in the function-
revealing case, to the authority as well. But note that neither the
client nor the authority knows the input x (which was generated by

a data owner).10 Thus, it is not clear how a garbled circuit for F
can be used in our setting.

0, ri
1

(cid:9)k

In our solution, the data owner will arrange for the client to have
the labels corresponding to the input x, without either the client or
the authority knowing x. The key idea is that the authority does
not pick all the labels for all the wires in the garbled circuit itself.
Instead, the data owner would specify the labels used for the input
wires corresponding to input x. More precisely, suppose x is k bits

long. Then the data owner picks 2k random labels (cid:8)ri

i=1
and encrypts them (using a CCA2 secure public-key encryption
scheme) for the authority. The encryption is required because it
is important that these labels are not all known to the client. Dur-
ing the key-request, the client is expected to send this part of the
ciphertext to the authority. While a garbled circuit is generated,
for each wire u in the circuit, two freshly chosen random labels
(R(u)
1 ) are required; but for the wires corresponding to the
input xi (i.e., the ith bit of x), the authority uses the pair (ri
0, ri
1)
instead. (Labels for all the other wires are picked freshly.) Now,
the data owner knows both x and the labels for the input wires used
in the garbled circuit. So it can simply provide the correct labels to
the client as part of the encryption of x. More precisely, the client
will be given the k labels rx1
k . On obtaining the garbled
circuit, it simply evaluates the garbled circuit using these labels for
the wires corresponding to x.

1 , . . . , rxk

0 , R(u)

We remark that typically, it is important that a garbled circuit is
not reused – i.e., evaluated on different inputs. Our solution could
be viewed as a safe way of reusing parts of a garbled circuit. In
particular, if different functions are evaluated on the same input x,
the same labels can be used for x. (In a standard 2-party computa-
tion, this observation could be used to replace multiple OT protocol
invocations, with a single OT protocol; in our case, since the data
owner is ofﬂine, this property is crucial.)

Protocol Π(cid:48)

i , r1

2 , . . . ◦ rxk
2 ◦ r1
1 ◦ r0

Since Π(cid:48) is a slight modiﬁcation of Π, we only describe what changes
need to be made to the algorithms of Π in order to obtain the ones for
Π(cid:48).
• Setup(cid:48)(1κ): Stays the same as Setup.
• Enc(cid:48)(x, MPK): Randomly pick 2k bit strings of length κ each. Let
i ) denote the ith pair among them, where 1 ≤ i ≤ k. Let
(r0
1 ◦ rx2
rx = rx1
k , where xi denotes the ith bit of x. Also,
1 ◦ r1
k ◦ r1
let ˆr = r0
k be the concatenation of
all the randomly chosen strings (in the speciﬁed order). Output the
ciphertext CTx = (rx, EncCCA2(ˆr, MPK)).
• KeyReq(cid:48)(CT, f ): Stays the same as KeyReq.
• KeyGen(cid:48)(ρ = (σ, M ), MSK): Run DecCCA2(σ, MSK) to obtain
k). Consider a circuit C which takes as input a
(r0
k-bit string z and an (cid:96)-bit function g, and computes F (g, z). Con-
struct a garbled circuit ˆC for C, but with (r0
i ) as keys for the
input bit zi (i ∈ [1, k]). All the other keys required for creating the
garbled circuit are chosen at random. M(cid:48) is computed in the same
way as KeyGen. Output τ = ( ˆC, M(cid:48)).

2 . . . ◦ r0

1), . . . , (r0

• Dec(cid:48)(ζ, τ ): Key for the jth bit of g (j ∈ [1, (cid:96)]) is obtained in the
same way as described in Dec. On the other hand, key for the ith bit
of z is part of ζ. Now, evaluate ˆC to obtain the value of f (x).

k, r1

i , r1

1, r1

Figure 4: Alternate C-FE Construction

10Further, as we consider malicious client which may attempt
to alter the input on which the garbled circuit is evaluated, which
rules out a simple solution in which x is kept secret-shared between
the client and the authority (unless, cryptographic operations are
incorporated into the garbled circuit).

1291