How to challenge and cast your e-vote

Sandra Guasch1, Paz Morillo2

Scytl Secure Electronic Voting1, Universitat Politecnica de Catalunya2

sandra.guasch@scytl.com, paz@ma4.upc.com

Abstract. An electronic voting protocol provides cast-as-intended ver-
iﬁability if the voter can verify that her encrypted vote contains the
voting options that she selected. There are some proposals of protocols
with cast-as-intended veriﬁability in the literature, but all of them have
drawbacks either in terms of usability or in terms of security. In this
paper, we propose a new voting scheme with cast-as-intended veriﬁabil-
ity which allows to audit the vote to be cast, while providing measures
for avoiding coercion by allowing the voter to create fake proofs of the
content of her vote. We provide an eﬃcient implementation and formally
analize its security properties.

1

Introduction

In remote e-voting schemes the vote is encrypted at the same voter device
used to choose the selections and cast the vote. This way voter choices
remain secret during their transmission and storage in the remote voting
server. Encrypted voting options cast by the voters are anonymized prior
to decryption at the counting phase, in order to maintain voter privacy.
This introduces new concerns on e-voting systems: how can voters be
sure that (i) the vote that their device encrypted contains their selec-
tions, (ii) the vote which was stored in the remote voting server is the
same that their device encrypted and (iii) the anonymization and decryp-
tion processes were done correctly? To provide assurance to the voters
that the vote casting, vote storage and vote counting processes were done
following the speciﬁed protocol, the notions of cast-as-intended veriﬁa-
bility, recorded-as-cast veriﬁability and counted-as-recorded veriﬁability
have been introduced in the literature.

There are some satisfying solutions for both recorded-as-cast veriﬁa-
bility and counted-as-recorded veriﬁability. Recorded-as-cast veriﬁability
can be achieved by publishing all encrypted votes received at the re-
mote voting server in a Bulletin Board [17], where voters can check for
their cast votes, and making sure that only the votes which are in the
Bulletin Board are tallied. For examples of protocols providing counted-
as-recorded veriﬁability, see [27] or [12], where veriﬁable mix-nets and
veriﬁably homomorphic tally schemes are introduced, respectively.

2

Sandra Guasch, Paz Morillo

However, proposed schemes achieving cast-as-intended veriﬁability still
have some drawbacks, either in usability or security terms. For example,
some of these systems, known as challenge-or-cast, do not allow to audit
the same vote to be cast. In case such systems allowed to verify the same
ballot to be cast, they would fail on fulﬁlling other security requirements
for electronic voting systems such as protection against voter coercion
and vote selling, given that their veriﬁcation involves providing the ran-
domness of the encrypted vote.

In this paper, we propose a new voting scheme which provides cast-
as-intended veriﬁability. In our scheme, the voter can audit the same
encrypted vote that she will later cast, what we think is an improvement
from the point of view of soundness of the veriﬁcation and of the usability
of the system: it represents a more straightforward process for average
voters to audit the vote that is going to be cast. Still, measures are applied
in order to ensure that this veriﬁcation does not provide the voter with a
receipt that can be used to sell her vote. We call this variant challenge-
and -cast.

Related Work There have been several proposals of cast-as-intended
veriﬁcation schemes during the last two decades. In Helios [2], the voter’s
device encrypts a vote and the voter is allowed to challenge the encryp-
tion and obtain the randomness used for encrypting the voting options,
to check that the encrypted vote was constructed correctly. However, in
order to prevent vote selling, the vote has to be encrypted again with new
randomness, after auditing. In particular, this means that the voter’s de-
vice has a small probability of cheating, which decreases with the number
of challenged encryptions.

Other methods to provide cast-as-intended veriﬁcation are those based
in return codes, such as [18]. In these schemes, a secondary channel is used
to deliver reference codes assigned to voting options to each voter before
the voting phase. During voting, the remote voting server, computes re-
turn codes from received votes and sends them back to the voters, who
verify that they match the expected reference codes. These solutions are
more usable than previous proposals, but they require a secondary chan-
nel, which may not always be available.

Some code voting schemes (Surevote [8], Pretty Good Democracy [26])
or veriﬁable DRE-based schemes (MarkPledge [24], Moran-Naor’s receipt-
free voting system [23]) also provide cast-as-intended veriﬁability. How-
ever, they present their own limitations: while the ﬁrst category relies on
the voter having to enter one randomized code for each voting option she

How to challenge and cast your e-vote

3

selects, with the corresponding drawbacks on usability, the second one
requires speciﬁc hardware (such as printers with protected output trays)
which cannot be assumed to be available in remote voting scenarios.

Finally, there are systems such as [10] which use trapdoor commit-
ments, as our solution, in order to provide receipt-freeness in blind signa-
ture voting schemes. However they struggle on the way of providing the
voter with the trapdoor key. Although we also use trapdoor commitments
in our scheme, we have naturally associated the trapdoor key to a voting
credential needed to cast a ballot, in order to improve the usability and
understandability of the scheme. Moreover, the protocol we present here
does not aim to solve the problem of receipt-freeness. Getting a receipt
of your vote is a possibility inherent to most the electronic voting sys-
tems where the vote is encrypted at the voting device, such as Helios [2].
Instead, our motivation is to provide a method for cast-as-intended veriﬁ-
cation which does not involve providing a receipt to the voter (or that at
least allows to fake it for a possible coercer). A future work will consist on
analyzing how this cast-as-intended veriﬁcation method can be combined
with other systems providing receipt-freeness or even coercion-resistance,
such as JCJ [21].

Overview The solution is the following: the voting device encrypts the
vote and shows the resulting ballot to the voter, together with a zero-
knowledge proof of knowledge (ZKPK) of the encryption randomness in-
stead of revealing the plain value, as in the challenge-or-cast mechanisms.
After the voter agrees on the proof, the ballot is cast and published on the
bulletin board, so that the voter can check that her ballot has been cor-
rectly received at the voting platform. The voter agreement of the proof is
represented with an authentication of the ballot, and only authenticated
ballots are accepted in the system (posted on the bulletin board).

The cast-as-intended veriﬁcation is still sound compared to prior sys-
tems, thanks to the properties of the proofs of knowledge: the veriﬁcation
of the proof will succeed only in case the voter’s device is honest (i.e., the
device is encrypting the voting options selected by the voter). In case of
a dishonest device, the probability of the proof being successfully veriﬁed
(and thus, the voter being cheated without notice) is negligible. At the
same time, the scheme provides protection in front of vote selling/voter
coercion scenarios thanks to the fact that it generates a ZKPK instead
of providing the value itself. With the proof itself, the voter can be easily
coerced or she can sell her vote. However, we take advantage of the fact
that ZKPKs can be simulated to give a chance to the voter to cheat the

4

Sandra Guasch, Paz Morillo

coercers/vote buyers: In our scheme, the voter is allowed to generate fake
proofs that will look like good proofs to anyone else.

This paper is organized as follows: Section 2 gives an introduction to
the techniques used for the simulation of the proofs of the ballot content;
Section 3 presents the syntax and description of the protocol, as well
as the trust assumptions; Section 4 provides an eﬃcient instantiation; a
discussion about the voter experience using this protocol is provided in
Section 5. Finally, an extension for multiple voting is provided in Section
6. The annexes contain some security deﬁnitions of the scheme and the
result of the security analysis.

2 Proof simulation

The scheme uses Designated Veriﬁer Proofs [20], which allow a designated
proof veriﬁer to get convinced of a statement, while she is able to simu-
late proofs for other statements (which are not true) to other veriﬁers. In
our scheme, the prover is the voting device, who proves knowledge of the
encryption randomness, and the designated veriﬁer is the voter. Other
veriﬁers such as possible coercers or vote buyers cannot be convinced
by the proof. Designated Veriﬁer Proofs use trapdoor commitments, also
known as chameleon commitments [7]. The trapdoor information is only
available to the designated veriﬁer of the proof, who can use it to gener-
ate simulated proofs for other veriﬁers. In non-interactive settings, such
as in non-interactive zero-knowledge proofs of knowledge (NIZKPKs),
Chameleon hashes [22] are used rather than chameleon commitments.

Chameleon Hashes A chameleon hash function is a trapdoor collision-
resistant hash function. Without knowledge of the trapdoor, the chameleon
hash behaves as an ordinary collision-resistant hash function. However,
using the trapdoor, collisions can be found eﬃciently.

A chameleon hash function is composed by three p.p.t. algorithms:
Gench takes as input a security parameter 1k, outputs an evaluation key
ekch and a trapdoor key tkch, and deﬁnes a message space Mch, a random-
ness space Rch and a hash space Ych; Hch takes as input an evaluation key
ekch, a message m ∈ Mch and a random value rch ∈ Rch and outputs a
hash value cch ∈ Ych; H−1
ch takes as input the trapdoor tkch, two messages
m, m(cid:48) ∈ Mch and a random rch ∈ Rch, and returns a value rch
(cid:48) ∈ Rch
such that Hch(ekch, m, rch) = Hch(ekch, m(cid:48), rch
(cid:48)).
Chameleon hashes have the following properties:

How to challenge and cast your e-vote

5

(cid:48)) is negligible in polynomial time.

Collision resistance. Provides that, given only the evaluation key
ekch, the probability of ﬁnding (m, rch) (cid:54)= (m(cid:48), rch
Hch(ekch, m, rch) = Hch(ekch, m(cid:48), rch
Trapdoor collision. Provides that there is an eﬃcient algorithm H−1
which ﬁnds two pairs (m, rch) (cid:54)= (m(cid:48), rch
(cid:48)) for which Hch(ekch, m, rch) =
Hch(ekch, m(cid:48), rch
Uniformity. For any message m ∈ Mch, and any rch uniformly dis-
tributed in Rch, the hash value cch is uniformly distributed in Ych. There-
fore the probability of an adversary of distinguishing between the hash
value of m and m(cid:48), both in Mch is negligible in polynomial time.

(cid:48)), using the trapdoor key tkch.

(cid:48)) such that

ch

2.1 A simulatable NIZK proof using chameleon hashes

Although examples of simulatable NIZKPK proofs are given by the au-
thors in [20], here we provide a formal description of the algorithms that
will be used in further sections, in order to prove their properties and
those of the scheme where they are used.
In a Σ-protocol, in order to prove that a statement x belongs to LR,
a prover P and a veriﬁer V engage in an interactive protocol where ﬁrst,
P sends a commitment message a to V ; then V replies with a random
challenge e; ﬁnally, P sends an answer z to V . Interactive zero-knowledge
protocols such as Σ proofs can be turned into non-interactive using the
Fiat-Shamir [16] transformation, where a hash function is used to compute
the random challenge e.

The transformation into a (trapdoor) simulatable NIZKPK works by
substituting the challenge e with the result of a chameleon hash: P chooses
a random value rch and evaluates the chameleon hash function Hch on
the message m = H(x, a) using the randomness rch, where H is a regular
collision-resistant hash function. The challenge of the Σ-protocol is then
deﬁned as e = Hch(H(x, a); rch). In addition, P also sends the randomness
rch which he used in the computation of the chameleon hash.

This non-interactive protocol allows to simulate valid proofs by means
of the trapdoor key of the chameleon hash scheme: indeed, given a trap-
door tkch for the chameleon hash, the simulator can compute the triplet
(a∗, e∗, z∗) as the simulator of the Σ-protocol would do. Then, by using
the trapdoor of the chameleon hash, the simulator will be able to ﬁnd
∗). The uniformity
a random value rch
property of the chameleon hash scheme guarantees that simulated proofs
have the same distribution than honest proofs.

∗ such that e∗ = Hch(H(x∗, a∗); rch

6

Sandra Guasch, Paz Morillo

Concretely, the trapdoor-simulatable NIZKPK scheme to be used in
our protocol uses a Σ-protocol, a chameleon hash scheme (Gench, Hch,
H−1
ch ) and two hash functions H1 : {0, 1}∗ → Mch and H2 : {0, 1}∗ → CH
(the challenge space). Then, the NIZK proof is given by the following
algorithms:

- GenCRS: on input a security parameter, it runs Gench and outputs

crs = ekch and tk = tkch.

- NIZKProve: on input the common reference string crs, a statement x

and a witness w, it follows the next steps:
1. Run the ﬁrst phase of the prover P of the Σ-protocol, which out-
2. Sample a random rch ∈ Rch and compute e = H2(Hch(H1(x, a), rch)).
3. Run the second phase of the prover P of the Σ-protocol, obtaining

puts a commitment a.

an answer z.

4. Deﬁne the proof π = (a, e, rch, z).
- NIZKVerify: on input a proof π and a statement x, return 1 if e =
H2(Hch(H1(x, a), rch) and the veriﬁcation checks of the Σ-protocol
pass on (a, e, z), 0 otherwise.

- NIZKSimulate: on input a statement x and a trapdoor tk, the simulator
runs the following steps:
1. Run the simulator S of the Σ-protocol to obtain a triplet (a∗, e∗, z∗).
∗ s.t. e∗ = H2(Hch(H1(x,
2. Use the trapdoor tkch to obtain a value rch
∗, z∗)
3. Output a simulated proof π∗ = (a∗, e∗, rch

a∗), rch

∗))

A NIZKPK satisﬁes the properties of completeness, knowledge sound-

ness and zero-knowledge [13], [28].

3 Protocol syntax

In this section we deﬁne a syntax for the proposed voting protocol. We use
as a basis the syntax deﬁned in [31] and [11] for analyzing the properties
of the Helios voting protocol [2], and add an auditing phase for the cast
as intended veriﬁcation functionality.

The following are the participants of the voting protocol: the Elec-
tion Authorities conﬁgure the election and tally the votes to produce the
election result; the Registrars registers the voters and provide them with
information for participating in the election; Voters participate in the
election by providing their choices; the Voting Device generates and casts
a vote given the voting options selected by the voter; an Audit Device is

How to challenge and cast your e-vote

7

used by the voter to verify cryptographic evidences; the Bulletin Board
Manager receives and publishes the votes cast by the voters in the bulletin
board BB; ﬁnally the Auditors are responsible of verifying the integrity
of the procedures run in the counting phase.
Consider that the list of voting options V = {v1, . . . , vn} in the elec-
tion is deﬁned in advance. The counting function ρ : (V ∪ {⊥})∗ → R,
where ⊥ denotes an invalid vote and R is the set of results, is a multiset
function which provides the set of cleartext votes cast by the voters in a
random order [5].

The voting protocol uses an encryption scheme with algorithms (Gene,
Enc, Dec, EncVerify), a signature scheme (Gens, Sign, SignVerify) and a mix-
net with algorithms Mix and MixVerify. It additionally uses a trapdoor-
simulatable NIZKPK scheme denoted by the algorithms (GenCRS,
NIZKProve, NIZKVerify, NIZKSimulate).

- Setup(1λ) chooses p and q for the ElGamal encryption scheme and
runs Gene. Then it sets the election public key pk = (pke, G) and the
election private key sk = (ske, pke). Finally it generates the empty
list of credentials ID.

- Register(1λ, id) takes the public parameters deﬁned by pk, runs GenCRS
from the NIZKPK scheme and Gens from the signature scheme, and
sets pkid = (crs, pks) and skid = (tk, sks).

- CreateVote(vi, pkid) runs Enc from the encryption scheme with in-
puts pk and vi and obtains the ciphertext cs. Then it parses cs as
(c1, c2, h, z) and pkid as (crs, pks), and runs NIZKProve from the NIZKPK
scheme, using as input crs, the statement (c1, c2/vi) and the witness
r, where r is the random element in Zq used during encryption. The
result is set to be σ, while the ballot b takes the value of cs.

- AuditVote(vi, b, σ, pkid) parses b as (c1, c2, h, z) and pkid as (crs, pks),
then runs NIZKVerify from the NIZKPK scheme with inputs the proof
σ, the common reference string crs and the statement (c1, c2/vi). It
outputs the result of the proof veriﬁcation.

- CastVote(b, skid, id) runs Sign with inputs the voter’s signing private
key sks and the ballot b to be signed together with the voter identity
id. The output is the authenticated ballot ba = (id, b, ψ).

- FakeProof(b, skid, pkid, vj) parses b as (c1, c2, h, z), pkid as (crs, pks)
and skid as (tk, sks). Then it runs NIZKSimulate from the NIZKPK
scheme for the statement (c1, c2/vj). Then the simulated encryption
proof data σ(cid:48) is the simulated proof π∗.
- ProcessBallot(BB, ba) parses ba as (id, b, ψ) and b as (c1, c2, h, z). Then
it proceeds to perform some validations: It checks that there is not

8

Sandra Guasch, Paz Morillo

already an entry in the bulletin board for the same id and that this
id is present in the list ID, or with the same ciphertext (c1, c2). It
also runs EncVerify to verify the proof (h, z) and the voter’s signature
running SignVerify (for which it picks the corresponding public key
pkid from the list ID). If any of these validations fail, the process
stops and outputs 0. Otherwise it outputs 1.

- VerifyVote(BB, b, id) checks that there is an entry in the bulletin board
for the identity id. In the aﬃrmative case, it parses the authenticated
ballot b(cid:48)
a as (id, b(cid:48), ψ(cid:48)) and checks that all the ﬁelds in b(cid:48) are equal to
all the ﬁelds in b.

- Tally(BB, sk) runs ProcessBallot over the individual entries of the bal-
lot box. For those who passed the veriﬁcations, it parses each one as
(id, (c1, c2, h, z), ψ), it takes the pairs (c1, c2) and runs Mix((c1
2), . . . ,
(cn
2 )), which denotes a veriﬁable mixnet such as [3] or [32]. Then the
ciphertexts are decrypted running the Dec algorithm and a proof of
correct decryption is produced. The outputs are the list of decrypted
votes r and the proofs of correct mixing and decryption, Π.

1 , cn

1, c1

- VerifyTally(BB, r, Π) in the ﬁrst place performs the same validations
than the ProcessBallot algorithm over the ballots in BB: for each one,
it checks that there is only one entry in the ballot box per id and
per (c1, c2). In case it founds any coincidence, it halts and outputs
⊥. Otherwise, it continues with the validations and discards all the
ballot box entries for which EncVerify or SignVerify output 0. Finally
it veriﬁes the proofs Π of correct mixing and decryption, using the
ciphertexts of the entries which have passed the validation and the
result r.

The voting protocol algorithms are organised in the following phases:
Conﬁguration phase: in this phase, the election authorities set up
the public parameters of the election such as the list of voting options
{vi} ∈ V and the result function ρ. They also run the Setup algorithm
and publish the resulting election public key pk and the empty credential
list ID in the bulletin board. The private key sk is kept in secret by the
electoral authorities.

Registration phase: in this phase the registrars register the voters to
vote in the election. For each voter with identity id, the registrars run
Register and update the credential list ID in the bulletin board with the
pair (id, pkid). The key pair (pkid, skid) is provided to the voter.
Voting phase: in this phase the voter chooses a voting option vi ∈ V
and interacts in the following way with the voting device, in order to cast
a vote:

How to challenge and cast your e-vote

9

1. The voter provides her identity id and the voting option vi to the
voting device, which gathers the corresponding public key pkid from
the bulletin board and runs the CreateVote algorithm. The outputs b
and σ are provided to the voter.

2. The voter uses an audit device to run AuditVote using b and σ provided
by the voting device. The voter may enter pkid herself, or her identity
id so that the audit device picks the corresponding public key pkid
from the list ID. A positive result means that b is encrypting the
voter’s selection vi and the voter can continue the process. Otherwise,
the voter is instructed to abort the process and choose another voting
device to cast her vote, since the one she is using is corrupted and did
not encrypt what the she selected.

3. As a sign of approval of the generated ballot, the voter provides her
private key skid to the voting device, which proceeds to run CastVote.
The resulting authenticated ballot is sent to the bulletin board man-
ager.
4. Then the voting device runs FakeProof using a voting option vj ∈ V
as input (supposedly the one requested by the coercer/vote buyer,
otherwise it may be a random value from the set V ), and provides the
simulated encryption data σ(cid:48) to the voter.
The bulletin board manager runs the ProcessBallot algorithm. If the
result is positive, the authenticated ballot ba is posted in the bulletin
board. Otherwise, the bulletin board is left unchanged, and the voter
receives a negative response. From that point, the voter can run VerifyVote
to check that her vote has been posted in the bulletin board.
From this point, the voter can provide the ballot b and the simulated
encryption data σ(cid:48) to a coercer, who might want to check that a ballot for
the requested voting option vj is present in the bulletin board by running
the AuditVote and VerifyVote algorithms.

Counting phase: in this phase, the election authorities provide the
election private key sk and run the Tally algorithm on the contents of
the bulletin board. The obtained result r and the proof Π are posted
in the bulletin board. The auditors then run the VerifyTally algorithm.
In case the veriﬁcation is satisfactory, the election result is considered to
be correct. Otherwise, an investigation is opened in order to detect any
manipulation that could lead to a corrupted result.

3.1 Trust model

Security deﬁnitions and analysis results are provided in the Annex, while
complete demonstrations are included in the full version [19]. However,

10

Sandra Guasch, Paz Morillo

here we informally introduce the trust assumptions we make on the scheme
regarding privacy and integrity:

We assume that voters follow the protocol in the correct way. We also
assume the voter to follow the audit processes indicated and complain in
case of any irregularity.

In order to simplify the analysis, we consider that the election author-
ities, and the registrars as well, behave properly in the sense that they
generate correct and valid key pairs, and that they do not divulge the
secret keys to unintended recipients. Multiparty computation techniques
such as [25] or [14] can be used in order to distributely generate secrets
among a set of trustees, ensuring their privacy and a correct generation
in case a subset of them is honest.

From the point of view of privacy, the voting device is trusted not to
leak the randomness used for the encryption of the voter’s choices. While
this assumption may seem too strong, it is in fact needed in any voting
scheme where the voting options are encrypted at the voting device (no
pre-encrypted ballots are used) and the vote is not cast in an anonymous
way. However, for the point of view of integrity, we consider that a mali-
cious voting device may ignore the selections made by the voter and put
another content in the ballot to be cast.

As in similar schemes such as Helios [2] or Wombat [1], the audit
device is trusted both from the point of view of privacy (it is assumed not
to divulge the voter’s selections) and from the point of view of integrity
(it is assumed to honestly transmit the result of the proofs veriﬁcation to
the voter).

The bulletin board manager is trusted to accept and post on the
bulletin board all the correct votes. No assumptions are done in the topic
of privacy. Finally, auditors are assumed to honestly transmit the result
of their veriﬁcation. However, we assume them to be curious and try to
ﬁnd out the content of voter’s votes from the information they get.

4 Concrete instantiation

In this Section, we provide a concrete instantiation based on ElGamal
over a ﬁnite ﬁeld.

Encryption scheme The Signed ElGamal encryption scheme [30] is
used in our instantiation of the protocol. It is a combination of the ElGa-
mal encryption scheme [15] and a proof of knowledge of the encryption

How to challenge and cast your e-vote

11

randomness, which is based in the Schnorr signature scheme [29] (some-
times we will refer to this proof of knowledge as the Schnorr proof). In
our notation, (c1, c2) represent the single ElGamal ciphertext, while (h, z)
represent the Schnorr signature.

According to the work in [6], this variant of ElGamal is NM-CPA

secure.

Chameleon hash The following instantiation of a chameleon hash (Gench,
Hch,H−1
ch ) based on the discrete logarithm problem [22] is used: Gench re-
ceives a group G of prime order q of elements in Z∗
p with generator g. An
element x is sampled uniformly from Zq and h = gx is computed. Then,
the evaluation key ekch is deﬁned as ekch = (G, g, h) and the trapdoor key
tkch is deﬁned as tkch = (ekch, x). The message space and the random-
ness space are Zq and the hash space is G. The algorithm Hch is deﬁned
for (m, rch) ∈ Zq × Zq to output cch = gm · hrch. Finally, H−1
ch (m, rch, m(cid:48))
outputs rch

(cid:48) = (m − m(cid:48)) · x−1 + rch.

Σ-proof We use a simulatable NIZKPK based on a Σ-proof which proves
that a speciﬁc plaintext corresponds to a given ciphertext. The Σ-proof
e · m)
computed over an ElGamal ciphertext of the form (c1, c2) = (gr, pkr
is as follows:

1. Prover computes (a1, a2) = (gs, pks

∈ Zq, and provides them to the veriﬁer.

e), where s is a random element

2. Veriﬁer provides a challenge e.
3. Prover provides to the veriﬁer z = s + re. The veriﬁer checks that

gz = a1 · ce

1 and that hz = a2 · (c2/m)e.

This Σ-proof can be simulated in the following way: the simulator
1 = gz∗ · c−e∗
2 = hz∗ · (c2/m)−e∗
. The resulting (a∗, e∗, z∗) values have the same

samples a random z∗ ∈ G, a random e∗ ∈ Zq and computes a∗
and a∗
distribution than the original ones.

1

Simulatable NIZKPK The algorithms of the NIZKPK scheme are then
deﬁned by using the discrete log-based chameleon hash scheme and the
Σ-proof deﬁned above, as well as two hash functions H1, H2 mapping
inputs to Zq, as follows:

- GenCRS runs Gench and outputs crs = (G, g, h) and tk = (crs, x);

12

Sandra Guasch, Paz Morillo

- NIZKProve receives crs, the statement x = (c1, c2/m) and the witness
r, and computes: (1) the commitment (a1, a2) = (gs, pks
e), (2) the
non-interactive challenge e = H2(g(H1(x,a)) · hrch), where rch is picked
at random from Zq, (3) the answer z = s + re, and (4) provides the
proof π = (a, e, rch, z);
- NIZKVerify checks that gz = a1 · ce
1, hz = a2 · (c2/m)e, and that
e = H2(g(H1(x,a)) · hrch);
- NIZKSimulate receives as input a statement x∗ = (c1, c2/m∗) and the
trapdoor tk, and does the following: takes at random z∗ ∈ G and
random pair (α, β) ∈ Zq, and sets e∗ = H2(gα · hβ). Then it com-
1 = gz∗ · c−e∗
putes a∗
, and ﬁnally it ob-
∗ = (α − H1(x∗, a∗)) · x−1 + β. The simulated proof is then
tains rch
∗, z∗).
π∗ = (a∗, e∗, rch

2 = hz∗ · (c2/m∗)−e∗

and a∗

1

The full version of this paper [19] provides a proof that the described
simulatable NIZK proof fulﬁlls the properties of completeness, knowledge
soundness and zero-knowledge of NIZKPKs.

Additionally, we use the RSA Full Domain Hash (RSA-FDH) [4] algo-
rithm for the signature scheme (Gens, Sign, SignVerify), and a proof of cor-
rect decryption based on the Chaum-Pedersen protocol [9], as described
in [12].

4.1 Performance

This instantiation is simple and eﬃcient. For a k-out-of-n voting scheme,
where k options can be encrypted into one ElGamal ciphertext, the en-
cryption of the voter selections using the Signed ElGamal encryption
scheme requires 3 exponentiations. The computation of the NIZKPK re-
quires 6 additional exponentiations (2 of them for the computation of the
chameleon hash), and 6 more for veriﬁcation. Each proof simulation costs
6 exponentiations.

An important detail is that, for eﬃciency purposes, the prime group
and the generator of such group used in all these primitives must be the
same.

5 Voting Experience

It is important to recall the criticity of the voter’s trapdoor key. A voter
who has not access to it will not be able to simulate a proof. Thus,
the cast-as-intended veriﬁcation mechanism will no longer protect the

How to challenge and cast your e-vote

13

privacy of the voter. On the other hand, the voter device has to learn the
trapdoor key only after it has already generated a honest proof for the
voter. Otherwise, the device could simulate a proof the voter expects to
be honest, and the scheme would no longer be cast-as-intended veriﬁable.
In order to present an easy and intuitive voting process for the voter,
we have related the private information she uses to authenticate her vote
(for example, her private signing key) with the trapdoor key which is
used to generate false proofs. We think that it is meaningful that the
voter provides both secrets at the same time, as a conﬁrmation that she
agrees to cast that vote (which she is expected to do only after verifying
the honest proof). Before the voter provides these secrets, the voting
device can neither cast a valid vote, nor cheat the voter by generating a
fake proof.

Therefore, at the voter registration stage each voter may be issued
both key pairs (the signing key pair to authenticate their vote, and the
evaluation/trapdoor key pair for the NIZKPK scheme), where the private
keys are password-protected. Later on, during the voting stage, the voter’s
selections are encrypted by the voting device, and the resulting ciphertext
and the proof of content are shown to the voter, who then can use an
audit device to check that the ciphertext contents match her selections
(for example, her smartphone). After a positive audit, the voter enters
her password into the voting device, which recovers both private keys,
using the private signing key part to digitally sign the vote to be cast,
and the NIZKPK trapdoor key part to generate one or several fake proofs
for alternative voting options which may be deﬁned by the voter. The fake
proofs have to be presented in the same way than the honest one, so that
they cannot be distinguished by a potential coercer. Finally, the vote is
sent to the bulletin board manager which publishes it the bulletin board,
so that the voter can check that her audited vote has been correctly
received.

6 Protocol extension for multiple voting

The possibility of multiple voting may be interesting in case something
goes wrong or for anti-coercion measures. However, it has to be taken into
account that in this case the voting device learns the trapdoor key after
the ﬁrst vote, and could cheat the voter in further ballot generations.

An approach for allowing multiple voting consists on delegating the
generation of simulated proofs to the bulletin board manager, who keeps
the voters’ trapdoor keys and provides simulated proofs to the voting

14

Sandra Guasch, Paz Morillo

devices only when receiving conﬁrmed ballots (which means that voters
already veriﬁed their contents and agreed with them). Although this does
not endanger the voter’s privacy, a collusion of the bulletin board man-
ager and the voting device may defeat the property of cast-as-intended
veriﬁability by simulating proofs in advance or refuse to generate them. A
distributed setting, where multiple bulletin board managers hold shares of
the voters’ trapdoor keys generated with a threshold scheme can be used
to enforce this property, even if a subset of the bulletin board managers
are malicious.

References

1. Wombat voting system. Available at http://www.wombat-voting.com/ (2015)
2. Adida, B.: Helios: Web-based open-audit voting. In: van Oorschot, P.C. (ed.)

USENIX Security Symposium. pp. 335–348. USENIX Association (2008)

3. Bayer, S., Groth, J.: Eﬃcient zero-knowledge argument for correctness of a shuﬄe.

In: Advances in Cryptology–EUROCRYPT 2012, pp. 263–280. Springer (2012)

4. Bellare, M., Rogaway, P.: Random oracles are practical: A paradigm for designing

eﬃcient protocols. In: CCS’93, Proceedings. pp. 62–73. NY, USA (1993)

5. Bernhard, D., Cortier, V., Galindo, D., Pereira, O., Warinschi, B.: A comprehensive
analysis of game-based ballot privacy deﬁnitions. IACR Cryptology ePrint Archive
2015, 255 (2015)

6. Bernhard, D., Pereira, O., Warinschi, B.: On necessary and suﬃcient conditions

for private ballot submission. IACR Cryptology ePrint Archive 2012, 236 (2012)

7. Brassard, G., Chaum, D., Cr´epeau, C.: Minimum disclosure proofs of knowledge.

J. Comput. Syst. Sci. 37(2), 156–189 (Oct 1988)

8. Chaum,

D.:

Surevote:

technical

report

(2001),

http://www.iavoss.org/mirror/wote01/pdfs/surevote.pdf

9. Chaum, D., Pedersen, T.P.: Wallet databases with observers. In: Advances in Cryp-
tology - CRYPTO ’92, Proceedings. LNCS, vol. 740, pp. 89–105. Springer (1992)
10. Chen, X., Wu, Q., Zhang, F., Tian, H., Wei, B., Lee, B., Lee, H., Kim, K.: New
receipt-free voting scheme using double-trapdoor commitment. Information Sci-
ences 181(8), 1493–1502 (2011)

11. Cortier, V., Galindo, D., Glondu, S., Izabach`ene, M.: Election veriﬁability for he-
lios under weaker trust assumptions. In: Computer Security - ESORICS 2014,
Proceedings Part II. LNCS, vol. 8713, pp. 327–344. Springer (2014)

12. Cramer, R., Gennaro, R., Schoenmakers, B.: A secure and optimally eﬃcient
multi-authority election scheme. In: EUROCRYPT. LNCS, vol. 1233, pp. 103–118.
Springer (1997)

13. Damg˚ard, I.: Commitment schemes and zero-knowledge protocols. In: Lectures on

Data Security, LNCS, vol. 1561, pp. 63–86. Springer (1999)

14. Damg˚ard, I., Mikkelsen, G.L.: Eﬃcient, robust and constant-round distributed
RSA key generation. In: TCC 2010, Proceedings. LNCS, vol. 5978, pp. 183–200.
Springer (2010)

15. ElGamal, T.: A public key cryptosystem and a signature scheme based on discrete
logarithms. In: CRYPTO ’84, Proceedings. LNCS, vol. 196, pp. 10–18. Springer
(1984)

How to challenge and cast your e-vote

15

16. Fiat, A., Shamir, A.: How to prove yourself: Practical solutions to identiﬁcation and
signature problems. In: CRYPTO ’86, Proceedings. LNCS, vol. 263, pp. 186–194.
Springer (1986)

17. Gharadaghy, R., Volkamer, M.: Veriﬁability in electronic voting - explanations for
non security experts. In: EVOTE 2010, Proceedings. LNI, vol. 167, pp. 151–162.
GI (2010)

18. Gjøsteen, K.: Analysis of an internet voting protocol. IACR Cryptology ePrint

Archive 2010, 380 (2010)

19. Guasch, S., Morillo, P.: How to challenge and cast your e-vote. IACR Cryptology

ePrint Archive, to be published (2016)

20. Jakobsson, M., Sako, K., Impagliazzo, R.: Designated veriﬁer proofs and their

applications. In: EUROCRYPT’96, Proceedings. pp. 143–154 (1996)

21. Juels, A., Catalano, D., Jakobsson, M.: Coercion-resistant electronic elections. In:

WPES’05, Proceedings. pp. 61–70. ACM (2005)

22. Krawczyk, H., Rabin, T.: Chameleon hashing and signatures. IACR Cryptology

ePrint Archive 1998, 010 (1998)

23. Moran, T., Naor, M.: Receipt-free universally-veriﬁable voting with everlasting
privacy. In: CRYPTO 2006, Proceedings. LNCS, vol. 4117, pp. 373–392. Springer
(2006)

24. Neﬀ, C.A.: Practical high certainty intent veriﬁcation for encrypted votes (2004)
25. Pedersen, T.: A threshold cryptosystem without a trusted party. In: Advances in

Cryptology EUROCRYPT 91, LNCS, vol. 547, pp. 522–526. Springer (1991)

26. Ryan, P.Y.A., Teague, V.: Pretty good democracy. In: Security Protocols XVII,
17th International Workshop, Cambridge, UK, 2009. Revised Selected Papers.
LNCS, vol. 7028, pp. 111–130. Springer (2009)

27. Sako, K., Kilian, J.: Receipt-free mix-type voting scheme - a practical solution to
the implementation of a voting booth. In: EUROCRYPT ’95, Proceedings. LNCS,
vol. 921, pp. 393–403. Springer (1995)

28. Santis, A.D., Persiano, G.: Zero-knowledge proofs of knowledge without interaction

(extended abstract). In: FOCS. pp. 427–436. IEEE Computer Society (1992)

29. Schnorr, C.: Eﬃcient identiﬁcation and signatures for smart cards. In: CRYPTO

’89, Proceedings. LNCS, vol. 435, pp. 239–252. Springer (1989)

30. Schnorr, C.P., Jakobsson, M.: Security of signed elgamal encryption. In: ASI-

ACRYPT 2000, Proceedings. LNCS, vol. 1976, pp. 73–89. Springer (2000)

31. Smyth, B., Frink, S., Clarkson, M.R.: Computational election veriﬁability: Deﬁni-
tions and an analysis of helios and JCJ. IACR Cryptology ePrint Archive 2015,
233 (2015)

32. Wikstr¨om, D.: A commitment-consistent proof of a shuﬄe. IACR Cryptology

ePrint Archive 2011, 168 (2011)

A Security Deﬁnitions and Analysis results

A.1 Deﬁnitions

In this section we deﬁne the notions of ballot privacy, and cast as in-
tended veriﬁability for an electronic voting scheme such as that described
in Section 3. We take as basis the deﬁnitions from [5] and then adapt
them to the particularities of our scheme. Other deﬁntions such as strong
consistency or strong correctness are available in the full version [19].

16

Sandra Guasch, Paz Morillo

Ballot privacy It is deﬁned by means of an experiment where an adver-
sary is presented with two experiments and has to be able to distinguish
between them. In each experiment the adversary has indirect access to
a ballot box which receives the ballots created by honest voters, as well
as ballots cast by the adversary itself on behalf of corrupted voters. In
the case of honest voters, we let the adversary choose two possible votes
which they will use to create their ballots. Which vote is used to cast a
voter’s ballot that goes to a speciﬁc ballot box depends on the experiment
that is taking place.

At the end of the experiment, the adversary is presented with the
result of tallying the ballot box, which is the same regardless of the ex-
periment. As noted in [5], revealing the true tally in each experiment
would easily allow the adversary to distinguish between both ballot boxes.
Additionally, for the votes cast by honest voters, we provide the result-
ing encryption proof data to the adversary in order to model a coercer
which uses it to learn something about the vote. We will use a simulation
functionality to generate fake proofs when required.

Exppriv,βA,V :
1. Setup phase: The challenger C sets up two empty bulletin boards
BB0 and BB1 and runs the Setup(1λ) algorithm to obtain the election
key pair (pk, sk) and the empty list of credentials ID. A is given access
to BB0 when β = 0 and to BB1 when β = 1.
2. Registration phase: The adversary may make the following query:
– ORegister(id): A provides an identity id (cid:54)∈ ID. C runs Register(1λ,
id), provides the voter key pair (pkid, skid) to A, and adds (id, pkid)
to ID.

3. Voting phase: The adversary may make the following types of queries:
– OVoteLR(id, v0, v1): this query models the votes cast by honest
voters. A provides an identity id ∈ ID and two possible votes v0,
v1 ∈ V . The challenger C does the following:
• It picks the corresponding pkid from ID and executes CreateVote
(v0, pkid) and CreateVote(v1, pkid) which produce the ballots b0
and b1 respectively and their encryption proof data σ0 and σ1.
• Then it executes CastVote(b0, skid, id), CastVote(b1, skid, id)
a and b1
a, and ProcessBallot
a). If both processes return
a and b1
a

to obtain the authenticated ballots b0
a) and ProcessBallot(BB1, b1
(BB0, b0
1, the ballot boxes BB0 and BB1 are updated with b0
respectively. Otherwise, C stops and returns ⊥.

How to challenge and cast your e-vote

17

• Finally, C executes FakeProof(bβ, skid, pkid, vβ) and provides
σβ and the simulated encryption proof data σ∗
– OCast(ba): this query models the votes cast by corrupted vot-
ers. A provides an authenticated ballot ba, and then C executes
ProcessBallot with ba and each ballot box. If both algorithms re-
turn 1, both ballot boxes are updated with ba. Otherwise, C halts
and none of the ballot boxes are updated.

β to A.

4. Counting phase: The challenger runs Tally(BB0, sk) and obtains the
result r and the tally proof Π, which are provided to A in case β = 0.
In case β = 1, C runs SimProof(BB1, r) to obtain Π∗, and provides
(r, Π∗) to A.

5. Output: The output of the experiment is the guess of the adversary

for the bit β.

We say that a voting protocol as deﬁned in Section 3 has ballot privacy
if there exists an algorithm SimProof such that for any probabilistic poly-
nomial time (p.p.t.) adversary A, the following advantage is negligible in
the security parameter λ:

AdvprivA = | Pr[Exppriv,0A,V = 1] - Pr[Exppriv,1A,V = 1] |

Cast-as-Intended veriﬁability A voting system is deﬁned to be cast-
as-intended veriﬁable if a corrupt voting device is unable to cast a vote
on behalf of a voter, with a voting option diﬀerent than the one chosen
by the voter, without being detected. In our deﬁnition, we consider an
adversary who posts ballots in the bulletin board on behalf of honest
and corrupt voters. In case of honest voters, they follow the protocol and
perform some validations before approving the ballot to be cast. Corrupt
voters provide their approval without doing any prior veriﬁcation.

ExpCaIA,V :
1. Setup phase: The challenger C runs the Setup(1λ) algorithm and
provides the election key pair (pk, sk) to A. Then it publishes the
empty lists of voter credentials IDh and IDc such that ID = (IDh∪IDc).
Finally A is given read access to BB.
2. Registration phase: The adversary may make the following queries:
– ORegisterHonest(id): A provides an identity id (cid:54)∈ ID. The chal-
– ORegisterCorrupt(id): A provides an identity id (cid:54)∈ ID. The

lenger C runs Register(1λ, id), and adds (id, pkid) to IDh.
challenger C runs Register(1λ, id), and adds (id, pkid) to IDc.

18

Sandra Guasch, Paz Morillo

3. Voting phase: The adversary may make the following types of queries:
– OVoteHonest(id, vi, b, σ): this query models the votes cast by
honest voters. A provides an identity id ∈ IDh, a ballot b, an
encryption proof data σ and the voting option vi. The challenger
C runs AuditVote(vi, b, σ, pkid), and only if the result is 1 it provides
skid to A.
– OVoteCorrupt(b, id): this query models the votes cast by cor-
rupted voters. A provides a ballot b and an identity id ∈ IDc. C
answers with skid.
a = (id(cid:48), b(cid:48),
ψ(cid:48)). The output of the experiment is 1 if the following conditions hold:
– id(cid:48) ∈ IDh
– ProcessBallot(BB, b(cid:48)
a) = 1
– VerifyVote(BB, b(cid:48), id(cid:48)) = 1
a; sk) (cid:54)= v(cid:48)
– Extract(b(cid:48)
i, where v(cid:48)

4. Output: The adversary submits an authenticated ballot b(cid:48)

the adversary in the OVoteHonest query.

i is the voting option submitted by

We say that a voting protocol as deﬁned in Section 3 has cast-as-
intended veriﬁability if, given an Extract algorithm for which the protocol
is consistent with respect to ρ, the following advantage is negligible in
the security parameter λ for any probabilistic polynomial time (p.p.t.)
adversary A:

AdvCaIA = | Pr[ExpCaI,0A,V = 1] |

A.2 Security analysis results

In this section we provide the results of our security analysis, which is
available in the full version of this paper [19].

Theorem 1. Let (Gene, Enc, Dec) be an NM-CPA secure encryption scheme
and (GenCRS, NIZKProve, NIZKVerify, NIZKSimulate) a NIZKPK which pro-
vides zero-knowledge. Then the protocol presented in Section 3 satisﬁes the
ballot privacy property.

Theorem 2. Let (Gene, Enc, Dec, EncVerify) be a probabilistic encryption
scheme, (GenCRS, NIZKProve, NIZKVerify, NIZKSimulate) a NIZKPK which
is sound and (Gens, Sign, SignVerify) an unforgeable signature scheme. Then
the protocol presented in Section 3 satisﬁes the cast-as-intended veriﬁa-
bility property.

