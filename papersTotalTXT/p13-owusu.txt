OASIS: On Achieving a Sanctuary for Integrity and Secrecy

on Untrusted Platforms∗

Emmanuel Owusu†

Jorge Guajardo‡
Adrian Perrig†

Jonathan McCune†

Jim Newsome†

Amit Vasudevan†

†CyLab, Carnegie Mellon University – {eowusu, jonmccune, jnewsome, perrig, amitvasudevan}@cmu.edu
‡Bosch Research and Technology Center, Robert Bosch LLC – jorge.guajardomerchan@us.bosch.com

ABSTRACT
We present OASIS, a CPU instruction set extension for ex-
ternally veriﬁable initiation, execution, and termination of
an isolated execution environment with a trusted computing
base consisting solely of the CPU. OASIS leverages the hard-
ware components available on commodity CPUs to achieve
a low-cost, low-overhead design.

Categories and Subject Descriptors
C.0 [General]: Miscellaneous—Hardware/Software Inter-
faces, Instruction Set Design; K.6.5 [Management of Com-
puting and Information Systems]: Security and Protec-
tion—Physical Security, Unauthorized Access

General Terms
Design, Security

Keywords
Secure Execution, Remote Attestation,
Instruction Set Extension

1.

INTRODUCTION

Despite numerous attacks against a wide spectrum of or-
ganizations [6, 29], secure execution environments protected
by TCG have not seen widespread application – even in
cloud computing, where customers want to verify execu-
tion [2, 41]. Perhaps this lack of application is due, in part,
to the lack of end-to-end application software that beneﬁt
from TCG properties, lack of trust in the TPM vendors,

∗This research was supported in part by CyLab at Carnegie
Mellon under grants DAAD19-02-1-0389 from the Army Re-
search Oﬃce, and by a gift from Robert Bosch LLC. The
views and conclusions contained here are those of the au-
thors and should not be interpreted as necessarily represent-
ing the oﬃcial policies or endorsements, either expressed or
implied, of ARO, Robert Bosch LLC, CMU, CyLab, or the
U.S. Government or any of its agencies.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2477-9/13/11 ...$15.00..

lack of protection against local adversaries, and concerns
over poor performance.

Many designs for an isolated execution environment (IEE)
have been proposed, but an interesting question remains:
What minimal additions do we need to add to a modern
CPU to achieve a highly eﬃcient isolated execution envi-
ronment with remote attestation properties? This work in-
vestigates what minimal architectural changes are required
to obtain the essential Trusted Computing Base (TCB) – an
isolated execution environment completely contained inside
a modern CPU – providing resilience against several classes
of hardware attacks. In addition, we design this architecture
such that minimal changes to a modern commodity CPU are
required for deployment. In keeping with minimalist design,
we provide a simple programming interface consisting of few
instructions.

Contributions

• We present an instruction set for remotely veriﬁable,

eﬃcient code execution requiring a minimal TCB.

• We propose an API where the CPU provides unique

cryptographic keys to security-sensitive applications.

• Our deployment model precludes the need for a dis-
tributor or manufacturer to protect platform secrets
on behalf of the end-user or their customers.

• Our system is designed for deployment on existing

commodity CPUs with minimal modiﬁcations.

• Contrary to prior approaches, our solution does not
require on-chip non-volatile memory to store secrets.
Thus, in addition to avoiding the strong assumption
of secure non-volatile memory, our solution is cheaper
to implement in practice as it leverages semiconductor
processes already used in modern CPUs.

2. PROBLEM DEFINITION

2.1 Model and Assumptions
Deployment Model. Our use case deﬁnes outsourced
computation in the sense advocated by public cloud comput-
ing. Thus, we identify three key parties; and their diﬀerent
roles and levels of trust as a device moves from production
to use:

(i) The processor hardware manufacturer (HWM). The
HWM is trusted to manufacture the CPU to initialize a cryp-
tographic device key with a Physically Unclonable Function.
(ii) The service provider (or device owner) that oﬀers the
device as a platform to customers who wish to lease them
for a certain amount of time or computation.

13Finally, (iii) the user (or cloud customer) who wishes to
lease computing resources. Users are interested in verifying
the trustworthiness of devices leased to them, guaranteeing
the integrity and conﬁdentiality of their computations and
data.

In the remainder of this paper, we refer to the service
provider’s device simply as the platform or P and to the
user’s device as the veriﬁer or V .

P 2 Economical. We would like the following economic

objectives to be satisﬁed:

P 2.1 Low-cost. No substantial increase of manufactur-

ing cost or complexity (e.g., by requiring non-volatile
memory within the CPU).

P 2.2 Self-contained. No requirement for additional hard-
ware support such as secure co-processors or TPMs.

Adversary Model. We assume a sophisticated adversary
with physical access to the computing platform. In particu-
lar, the adversary can introduce malware into the comput-
ing platform (e.g., to compromise an application, the OS, or
ﬁrmware), has access to the external ports of the platform to
physically attach malicious peripherals to P . Similarly, the
adversary can probe and tamper with low-speed and high-
speed buses (e.g., to eavesdrop on a memory or PCI bus),
and/or inject code and/or modify data. However, the adver-
sary cannot perform attacks that require complete unscru-
tinized access to the CPU for extended periods of time. In
particular, this implies that the service provider has organi-
zational procedures in place to prevent attacks, but cannot
guarantee the absence of a small set of rogue employees.1
We consider denial-of-service, side-channel, and fault injec-
tion attacks beyond the scope of this paper.

Assumptions. With respect to the service provider, we
assume that the CPU on the untrusted platform P is not
malicious (i.e., we trust the processor). We assume that
this CPU contains a Physically Unclonable Function that
can only be accessed through the speciﬁed APIs. Addition-
ally, we assume that the CPU has a true random number
generator. We assume that the CPU is tamper-resistant.
Thus, physical security is not a requirement. Finally, we
assume that the veriﬁer V has the correct public key of the
provider’s platform P .

2.2 Desired Properties
The following list contains the desired properties for OASIS.

P 1 Secure. We would like the following security objec-

tives to be satisﬁed:

P 1.1 Externally Veriﬁable. Attestable code execution
that guarantees platform integrity, code integrity,
launch point integrity, and unmodiﬁed code exe-
cution on the untrusted platform.

P 1.2 Key Code Binding. Ensure that a unique crypto-
graphic key is available to each distinct code mod-
ule that executes in the isolated environment.

P 1.3 Program State Binding. The ability to bind data

to code.

P 1.4 Device Transferability. The ability to transfer own-
ership of a chip without exposing the secrets of the
previous owner.

P 1.5 Limited Trust. The HWM should not have access

to any device secrets.

P 3 Essential. We aim for a balanced and simple design:

P 3.1 Minimal TCB. On-die isolated execution environ-
ment with trustworthy computing primitives en-
tirely within the CPU package.

P 3.2 Minimal Interface. Minimal interface with min-
imal controls, which presents a usable program-
ming abstraction.

P 3.3 Minimal Setup. Eﬃcient environment setup where
expensive operations are bypassed during repeated
invocation.

3. HARDWARE BUILDING BLOCKS

3.1 PUFs, Fuzzy Extractors, and TRNGs

Pappu et al. introduce the concept of Physical Unclon-
able Functions (PUFs), which are functions where the re-
lationship between input (or challenge) C and output (or
response) pe is deﬁned via a physical system [15, 35]. The
physical system has the additional properties of being ran-
dom and unclonable. The system’s unclonability originates
from random variations in a device’s manufacturing process,
which even the manufacturer cannot control. In their most
general form, PUFs can accept a large number challenge-
response pairs. Examples of PUF constructions include:
optical PUFs [35], silicon PUFs [15, 14], coating PUFs [45],
SRAM PUFs [16, 17], reconﬁgurable PUFs [23], and Flash
memory-based PUFs [48].

Because of PUF variability across diﬀerent environmental
conditions (voltage, temperature, humidity, etc.), when a
PUF is challenged with Ci, a response p′
e (a noisy version of
pe) is obtained. In applications where the PUF response is
used as a cryptographic key this noisy response p′
e is not ac-
ceptable. To solve this problem, algorithms known as fuzzy
extractors leverage non-secret helper data to work around
the noisy nature of physical measurements typical of PUF
applications [21, 27, 10]. We assume that the fuzzy extractor
is implemented in a silicon block and is accessible as a func-
tion that is used (in combination with the PUF interface)
to realize our instructions.

While stability is fundamental for PUFs, variation in un-
stable bits can be leveraged for random number genera-
tion [17, 44, 48]. For the purposes of this paper, we focus on
PUFs based on memory arrays, such as SRAM commonly
used in CPU caches. SRAM memory can be used as the raw
source for a PUF as well as the entropy source for a True
Random Number Generator (TRNG).2

1For example, a cloud service provider may unintentionally
grant datacenter access to malicious [20] or negligent [43]
employees.

2The new Intel random number generator is based on the
instability of a couple of cross-coupled inverters, which are
the basic building block of an SRAM cell [44].

143.2 Cache-as-RAM (CAR) Mode

Cache memory is ubiquitous across CPU architectures.
Traditionally, SRAM is used to implement a cache. Mod-
ern CPUs often include several megabytes of memory on-die
which can be leveraged to create a Cache-as-RAM (CAR)
execution environment [28]. Typically, CAR mode is used
to perform system boot-up tasks while DRAM (external to
the CPU) is initialized. Prior work has demonstrated that
the CPU cache subsystem can be repurposed as a general-
purpose memory area for isolated code execution and data
read/write operations [46]. The CPU CAR environment of-
fers an isolated execution environment using exclusively on-
die hardware.

4. OASIS CPU INSTRUCTION SET

We ﬁrst provide a high-level overview of the design, de-
scribing the requirements, execution model, and implemen-
tation rationale for the instruction set extension (ISE) pro-
posed in the paper. The notation used in the remainder of
the paper is summarized in Table 1.

Requirements. OASIS is a set of new CPU instructions
that aim to enable an isolated execution environment con-
tained entirely on chip by leveraging CAR mode execution,
and by creating a secret key only available to the CPU (e.g.,
derived from an SRAM PUF). OASIS is designed for ease of
adoption and deployment with respect to existing comput-
ing systems.

A central feature of OASIS is the PUF-derived secret key
Kp only available within the CPU and which is used as the
root of trust of the whole environment. OASIS is based
on SRAM-PUFs [16, 17]. This has several advantages: (i)
SRAM is already available on modern CPUs in the form
of the cache, (ii) SRAM PUFs need to be powered to cre-
ate the secret key material, thus, they cannot be read of-
ﬂine making them resistant against scanning electron micro-
scope based attacks, (iii) because of their properties, PUFs
are tamper-evident (and in some cases tamper-resistant), a
property which other technologies do not oﬀer [16], and (iv)
SRAM is manufactured using the standard semiconductor
process, which leads to decreased costs when compared to
non-volatile memory.

OASIS assumes the availability of external non-secure non-
volatile memory. This memory is used to store public helper
data as well as state and/or programs. External storage is
plentiful and does not further complicate the OASIS design
since no special security guarantees are assumed.
In par-
ticular, alterations to the public helper data can be easily
detected through the use of robust fuzzy extractors [5, 9].

Root-of-Trust Instantiation. The SRAM-PUF response,
pe, serves as a unique cryptographic secret which is used to
bootstrap a unique device identity, per-application encryp-
tion and authentication keys, and random number gener-
ation. The resulting key material is unique not just per
physical device, but per device owner. The SRAM-PUF re-
sponse is used to derive the secret root key, Kp, which never
leaves the processor and is never directly accessible by any
party (including any software running on the processor).

The PUF-derived secret root key, Kp, enables the deriva-
tion of a key hierarchy as follows. The device owner de-
rives a key (Kpo) unique to themselves and the device via a

Table 1: Notation used in Instruction Set and Protocol

Notation

hw_inst[]

f_hw_func[]

hardware instructions that make up the OA-
SIS programming interface are denoted using
a ﬁxed-width font

hardware functions are only accessible by OA-
SIS hardware instructions and are denoted us-
ing a ﬁxed-width font identiﬁer starting with
the letter f

y ← x

the value of x is assigned to variable y

⊥ this symbol is used to denote a failed platform

operation

x||y

concatenation of x and y

x.param returns parameter param of variable x

x.∗

data element formed by concatenating all pa-
rameters of variable x

A → B : hmi A sends message hmi to B

R
←−{0, 1}ℓ

r

assigns a random integer of ℓ bits to r

KX
X , K−1

X

K+

party X’s symmetric key

party X’s public and private asymmetric key
pair

{P }K

the resulting ciphertext of plaintext P en-
crypted using key K

H (x)

cryptographic hash function with input x

EncK(P )

encrypt plaintext P using key K

DecK(C)

decrypt ciphertext C using key K

KDFK(x)

key derivation function of key K and non-
secret parameter x

MACK(x) message authentication code of x under key K

Sign

K

(m)

−1
X
(m, σ)

Verify

K

+
X

Certy(x, K+
X )

sign message m with party X’s private key K−
X

verify signature σ on message m using party
X’s public key K+
X

certiﬁcate issued by y that binds the identity
x to the public key K+
X

key derivation function (KDF), which accepts as inputs an
owner supplied seed, So, and the PUF-derived secret root
key, Kp. This master processor secret, Kpo, can then be
used, in turn, to derive symmetric keys for bulk encryption,
authentication, and asymmetric operations. The details are
provided in Section 4.1.

All keys are stored inside the CPU in a set of special pur-
pose cache registers (CR.∗) which are only available within
the OASIS environment and only accessible by the OASIS
instructions. Table 2 lists the keys stored in CR.∗. Observe
that the root key, Kp, is only used for the derivation of the
master processor secret. More importantly, the entire key
hierarchy is based on an owner seed (So), enabling person-
alization and device transferability.

ISE Overview and Flow. Next, we describe how the
PUF-based root-of-trust is used to enable the desired secu-
rity objectives of Section 2.2 by deﬁning ﬁve new instruc-
tions: init[], create[], launch[], unbind[], and bind[].
We distinguish between three stages in the life cycle of the
CPU. The ﬁrst stage is performed by the hardware manufac-
turer (Figure 1(a)). After manufacture, the HWM initializes
the master processor key Kp by calling init[]. The output
of this operation is helper data he and a hash H(pe, he),

15Table 2: Variables used in Instruction Set and Protocol.

Hidden Variables: values accessible by processor

IEE entry

IEE entry

IEE entry

init[]

create[]

launch[]

Raw PUF response

Root key generated from PUF

pe

Kp

So

Secret seed value set by platform owner

IEE exit

IEE exit

unbind[]

p∗,q∗

Primes corresponding to an RSA private key

CR.Kpo Master platform secret for a speciﬁc owner

seed

CR.Kpo auth

Platform key for authenticating data from un-
trusted storage

CR.Kpo encr

Platform key for encrypting data before trans-
fer to untrusted storage

CR.Kpo code

Platform key used to derive code speciﬁc keys

CR.Spo bind

Platform binding secret used to derive asym-
metric binding keys

CR.K−1

po bind

Platform private binding key, derived deter-
ministically from CR.Spo bind

CR.P CR Platform conﬁguration registers

CR.KC

Unique cryptographic key for code C′

Visible Variables: values accessible by software

K+

po bind

Platform public binding key, derived deter-
ministically from CR.Spo bind

he Helper data used for noise reduction of pe

hP K

Helper data used for generating asymmetric
keys

which is published and available to anyone using the de-
vice. We assume that the function init[] can be called
only once or a limited number of times to prevent attacks
that exploit repeated invocations of the generator function
f_init_PUF[] (described below) to learn pe [9]. Given that
the HWM does not have control of the PUF response pe (or
by extension Kp as it is derived from pe), the init[] instruc-
tion enables the limited trust (P 1.5), low cost (P 2.1), self
contained (P 2.2), and the minimal TCB (P 3.1) properties
of Section 2.2.

The second stage corresponds to the set-up of the key
hierarchy for OASIS, performed by the device owner (Fig-
ure 1(b)). This is accomplished by calling the create[]
instruction, whose main purpose is to derive symmetric and
asymmetric keys. These keys will be used to exchange conﬁ-
dential and authenticated messages between the prover (de-
vice owner) and the veriﬁer (user) and to guarantee external
veriﬁability (P 1.1). The main output of the instruction is a
public key, which has been derived from the PUF-based root
key Kp and a seed So known only to the device owner. This
allows for transferability of the platform (P 1.4) as a new
device owner can create his/her own public/private keypair
(K +
o. Fur-
thermore, even though the device owner initiates generation
of the public/private keypair, only the CPU can access the
private key and thus decrypt messages encrypted with the
public key.

po bind) by choosing a diﬀerent seed S′

po bind, K −1

The third and last stage corresponds to the execution of
code on the device by the user (Figure 1(c)). Users will
launch the code to be executed by issuing the launch[]
instruction. This instruction populates the CR.∗ registers
with the symmetric keys derived from the PUF helper data
he, the device owner’s seed So, and the public key informa-

(a)

(b)

bind[]

IEE exit

(c)

Figure 1: OASIS session during (a) initialization by
the manufacturer, (b) setup by the device owner,
and (c) code execution by the user.

tion generated using create[] in the previous stage. Then,
the unbind[] instruction can be called to check the input’s
integrity with respect to a code-speciﬁc key and decrypt any
input whose conﬁdentiality is preserved by the veriﬁer. The
instruction provides two options, one using public-key and
one using symmetric-key primitives. The asymmetric option
is used the ﬁrst time the application is called to transmit a
secret symmetric key, KV P , only known to the veriﬁer (user)
of the platform P . After this initial set-up, the veriﬁer can
use fast symmetric-key operations to verify integrity and
conﬁdentiality of its data (P 3.3). At this point the code C
can be executed in the isolated execution environment, state
is saved (and encrypted if desired), and integrity informa-
tion is computed on the state using bind[] (P 1.3). Finally,
all OASIS memory and internal registers are cleared out,
and control is returned to the OS. Observe that any pro-
gram can in principle be executed in a secure environment
using these last three instructions, providing for a minimal
and simple programming interface (P 3.2). Furthermore, the
bind[] and unbind[] instructions, together with the key hi-
erarchy derived with the help of create[], enable external
veriﬁability (P 1.1) and program state binding (P 1.2), not
only to a particular program but also to a speciﬁc CPU, a
property unique to OASIS.

4.1 OASIS Functions and Instructions

We describe the functions and instructions used in the
design of OASIS. We make a distinction between functions
(which are only internally available to instructions) and in-
structions, (which are externally available for call by execut-
ing software).3 In practice, functions and instructions might
be implemented as digital logic, integrity-checked ﬁrmware,
microcode, or another process-speciﬁc mechanism.

4.1.1 Function Descriptions

We have omitted explicit pseudocode deﬁnitions for sev-
eral functions where the speciﬁc implementation is left to
the hardware manufacturer. Table 3 lists these functions.
The functionality of f_read_PUF[], f_init_PUF[] and f_
fuzzy_extract_PUF[] is brieﬂy discussed next.

3Instructions and functions are denoted using a ﬁxed-width
identiﬁer. Functions begin with ‘f_’. See Table 1.

16Table 3: Hardware Manufacturer Implemented Functions

pe ← f_read_PUF[]

he, H(pe, he) ← f_init_PUF[pe, rand]

Kp ← f_fuzzy_extract_PUF[pe, he, H(pe, he)]

p, q ← f_find_primes[Spo_bind, RSAParam.size]

po bind,

K+
K−1

po bind

← f_rsa_key_gen[p, q, e]

The function f_read_PUF[] does not accept any inputs;
it simply outputs the raw PUF response pe. We provide
two functions to interact with a (robust) fuzzy extractor [5,
9] as is common in the literature: (1) The function f_init_
PUF[pe, rand] accepts a raw PUF response pe and a random
value rand and outputs helper data he and a hash H(pe, he).
The helper data he can be used to reconstruct a uniformly
random value Kp from a noisy raw PUF response p′
e. The
hash is used to guarantee that only values of Kp constructed
with the original helper data he are used for further process-
ing in OASIS. (2) The function f_fuzzy_extract_PUF[p′
e,
he, H(pe, he)] accepts a (noisy) raw PUF response p′
e and
helper data he and outputs a uniformly random value Kp
which can be used as a cryptographic key. The function f_
fuzzy_extract_PUF[] checks for correctness in the value of
H(pe, he) and outputs a special symbol ⊥ if the input does
not correspond to the computed value. If the output is ⊥,
the instruction calling f_fuzzy_extract_PUF[] should take
appropriate action. In the case of OASIS, we clear all key
registers and abort execution.

We assume the use of existing hardware-supported fuzzy
extractor implementations [4, 30]. The functions f_read_
PUF[], f_init_PUF[] and f_fuzzy_extract_PUF[] are only
available to the OASIS hardware instructions deﬁned in Sec-
tion 4 and they cannot be accessed by any software directly.

Func 1 Spo bind ← f_create_sym_keys[So, he, H(pe, he)]

e, he, H(pe, he)]

p′
e ← f_read_PUF[]
Kp ← f_fuzzy_extract_PUF[p′
Clear p′
e
CR.Kpo ← KDFKp (So)
Spo bind ← KDFCR.Kpo (“bind”)
CR.Kpo auth ← KDFCR.Kpo (“auth”)
CR.Kpo encr ← KDFCR.Kpo (“encr”)
CR.Kpo code ← KDFCR.Kpo (“code”)
if Kp =⊥ then

Clear CR.∗
Spo bind ←⊥

Clear Kp
return Spo bind

Function 1. This function loads the helper parameter h′
e
and the hash H(pe, he) into memory. Next, the PUF is
read and the fuzzy extractor is invoked to generate the plat-
form symmetric secret key, Kp. Internally, the fuzzy extrac-
tor checks whether the inputs H(pe, he) and he correspond
with the reconstructed value. A special symbol ⊥ is output
should the values be diﬀerent.

The key Kp and the (device owner) supplied seed So are
used to derive the master processor secret, CR.Kpo. The
seed value So allows the device owner to personalize the
processor keys. The symmetric key CR.Kpo is used for the

derivation of four symmetric platform keys: (i) CR.Spo bind,
the platform binding secret, (ii) CR.Kpo auth, the platform
key used for authenticating data residing in untrusted stor-
age from prior invocations (iii) CR.Kpo encr, the platform
key used for encrypting data and (iv) CR.Kpo code, the plat-
form key used to derive code-speciﬁc keys.
In all cases,
keys are derived via a KDF, which in turn may use pseudo-
random functions (e.g., HMAC, CMAC) as building blocks.
Constructions of key derivation functions accepting secret
and public parameters are well-known [7, 22]. At the end
of the process, the function checks if the fuzzy extractor
returned the special symbol ⊥, which would indicate that
either the PUF response was too noisy and therefore it was
not possible to reconstruct Kp or H(pe, he) 6= H(p′
e). In
either case, all OASIS registers are cleared and the function
returns the special symbol ⊥ indicating failure. After the
check, Kp is cleared and Spo bind is returned.

e, h′

Func 2a hP K ← f_create_asym_keys[Spo_bind]

p, q, ← f_find_primes[Spo_bind, RSAParam.size]

po bind,

( K+

po bind) ← f_rsa_key_gen[p, q, e]

CR.K−1
po bind}CR.Kpo encr ← EncCR.Kpo encr (CR.K−1
po bind}CR.Kpo encr , K+

{K−1
τ ← MACCR.Kpo auth({K−1

po bind)
po bind)

hP K ← n{K−1

if Spo bind =⊥ then

po bind}CR.Kpo encr , K+

po bind, τo

Clear CR.∗
Clear hP K
return hP K

Function 2a. This function generates the processor asym-
metric keys. The f_find_primes[] function picks a random
seed value of size RSAParam.size and begins search until the
ﬁrst prime is found. The process is repeated for the second
prime using a new seed value. f_find_primes[] returns se-
cret primes, p and q. The function f_rsa_key_gen[] takes
the primes and a public exponent as inputs and generates
the keypair K +
po bind. Notice that the RSA private
key K −1
po bind is composed of p, q, and the inverse of the RSA
public exponent modφ(N ), where N = p · q. Methodolo-
gies to generate primes are well-understood and standard-
ized [18]. The RSA private key K −1
po bind is encrypted us-
ing CR.Kpo encr, and a message authentication code τ is
computed over this value and the corresponding public key
K +
po bind. Finally, a data store hP K , containing the asym-
metric keys and τ , is returned.

po bind, K −1

Func 2b hP K ← f_create_asym_keys[Spo_bind]

po bind,

( K+

po bind) ← f_ecc_key_gen[Spo_bind, ECCParam]

CR.K−1
po bind}CR.Kpo encr ← EncCR.Kpo encr (CR.K−1
po bind}CR.Kpo encr , K+

{K−1
τ ← MACCR.Kpo auth({K−1

po bind)
po bind)

hP K ← n{K−1

if Spo bind =⊥ then

po bind}CR.Kpo encr , K+

po bind, τo

Clear CR.∗
Clear hP K
return hP K

Function 2b. We describe an alternative implementation
of the f_create_asym_keys[] (Function 2a) using elliptic
curves in Function 2b. The implementation of this function

17is analogous but much more eﬃcient than its RSA counter-
part, since there is no prime search step. Key generation
is a single elliptic curve multiplication, which in general is
eﬃcient. In addition, this version has the advantage of small
area overhead, if support for asymmetric operations is im-
plemented at the hardware level. These advantages come
at the cost of a signiﬁcant increase in the time required to
perform a signature veriﬁcation operation (when compared
to RSA). It is up to the HWM to decide which implementa-
tion is more appropriate based on its own requirements and
constraints.

Func 3 K +

po bind ← f_read_asym_keys[hP K]

τ ′ ← MACCR.Kpo auth (cid:16)hP K .n{K−1

po bind}CR.Kpo encr , K+

po bindo(cid:17)

if hP K .τ 6= τ ′ then

Clear CR.∗
Clear hP K .K+

po bind

else

CR.K−1

po bind ← DecCR.Kpo encr (hP K .{K−1

po bind}CR.Kpo encr )

return hP K .K+

po bind

Function 3. This function is very eﬃcient as it only re-
quires symmetric cryptographic operations.
In particular,
f_read_asym_keys[] checks tag hP K .τ to ensure that in-
put data has not been tampered with.
If this veriﬁcation
passes, the function decrypts the private binding key to
CR.K −1
po bind, using the symmetric key CR.Kpo encr. Note
that the corresponding read functions, for create functions 2a
and 2b, are the same except for the sizes of the operands,
outputs, and registers required to store private and public
keys.

4.1.2

Instruction Descriptions

Inst 1 {he, H(pe, he)} ← init[]

R
←−{0, 1}ℓ

pe ← f_read_PUF[]
rand
{he, H(pe, he)} ← f_init_PUF[pe, rand]
Clear pe, rand
return {he, H(pe, he)}

Instruction 1. This instruction initializes the helper data
he used to de-noise the raw SRAM PUF value pe. The func-
tions f_read_PUF[] and f_init_PUF[] read the raw PUF
value and instantiate the helper data, as described in Sec-
tion 4.1.1. The hash value H(pe, he) will be used by later
instructions to prevent modiﬁed helper data from being used
in attempts to learn information about the PUF. Observe
that a hardware-generated random number, rand, is used to
introduce entropy in the resulting helper data’s value.

The variable rand needs to remain secret and exposed
It is also assumed that he can
only inside the processor.
only be set once (or a limited number of times) to prevent
exposing the output of the fuzzy extractor. This can be
achieved during the initialization, which is performed by
the HWM. Because of our use of robust fuzzy extractors
[5, 9], we do not require any secure non-volatile memory.
All data is stored outside the chip, either locally or ex-
ternally published on a website. An additional step, not
shown and not performed as part of Instruction 1 is the

−1
T T P

signing of he||H(pe, he) by the HWM or a TTP with output
σhe ← SignK
(he||H(pe, he)). This guarantees to any
third party (users, system integrators, device owners, etc.)
that the helper data was created by the HWM and not some
other (untrusted) party. Notice this is done only once during
the lifetime of the device.

Inst 2 hP K ← create[So, he, H(pe, he), σhe , K +

T T P ]

if Verify

K

+
T T P

(he||H(pe, he), σhe ) = accept then
Spo bind ← f_create_sym_keys[So, he, H(pe, he)]
hP K ← f_create_asym_keys[Spo_bind]
Clear Spo bind
return hP K

else

ABORT

Instruction 2. This instruction generates a hierarchy of
cryptographic keys from the raw PUF response pe. Symmet-
ric and asymmetric keys are generated by f_create_sym_
keys[] (Function 1) and f_create_asym_keys[] (Function 2a
or 2b), respectively.

po bind, K −1

The hP K variable is assigned the {K +

po bind} key-
pair generated by f_create_asym_keys[]. Observe that
hP K is encrypted and contains authentication information,
which is veriﬁed internally by OASIS using a key derived
from the internal PUF key and the seed So. Lastly, note
that veriﬁcation of the signature σhe is most eﬃcient if the
signature algorithm is based on RSA using a small exponent
(e.g., 3, 17, or 216 + 1). Regardless of the latency due to sig-
nature veriﬁcation, we expect that this step is performed
rarely – e.g., whenever the device changes ownership or if a
user desires to setup the environment for future use.

Inst 3 launch[C, C.inputs, So, he, H(pe, he), hP K ]

Conﬁgure CPU into CAR Mode
Load C into the CPU cache
Spo bind ← f_create_sym_keys[So, he, H(pe, he)]
K+
CR.P CR ← H (C)
CR.KC ← KDFCR.Kpo code (H (C))
if (Spo bind =⊥) then

po bind ← f_read_asym_keys[hP K ]

Clear CR.∗
ABORT

Clear Spo bind
Transfer control to C’s entry point

Instruction 3. The launch[] instruction is designed to
setup the OASIS environment for code C and populate all
necessary registers.
It begins by setting up a clean-slate
CAR environment, including disabling interrupts and hard-
ware debugging access. It then reads and loads CR.∗ regis-
ters with cryptographic key material for further processing
by other instructions.4

4A possible optimization is to conditionally invoke f_cre-
ate_sym_keys[] and f_read_asym_keys[]. For example,
launch[] can be modiﬁed to only invoke f_create_sym_
keys[] once after the processor reboots and maintain the re-
sulting keys in CR.* during successive OASIS sessions. This
optimization must be carefully considered and constructed
by the implementer to manage the security trade-oﬀ (PUF-
derived secrets persisting between invocations). Addition-

18To avoid the expensive operations performed in create[]
for asymmetric key generation (e.g., prime generation), an
encrypted data store hP K is returned by f_create_asym_
keys[] and f_read_asym_keys[hP K] is used on subsequent
invocations. This function’s overhead is equivalent to a few
eﬃcient symmetric-key operations.

Observe that if we want to make the public binding key
available outside the environment, Instruction 2 must be
called ﬁrst. Also note that Instruction 2 veriﬁes the signa-
ture σhe every time it executes, whereas Instruction 3 does
not. We expect that signature veriﬁcation will be performed
at most once per session, where each session might call the
launch[] instruction multiple times. Notice that even if
the signature veriﬁcation function is performed every time,
the overhead should be minimal, assuming RSA signatures.
Refer to Figure 1 for details on when instructions are called.
Next, launch[] stores a hash of the target code C to the
platform conﬁguration register CR.P CR. Finally, a sym-
metric key KC is generated using a key derivation function
based on CR.Kpo code and a hash of target code C. KC is
used for encrypting and authenticating the executing code’s
state for local storage to untrusted memory.

At the end of launch[], the following registers have been

populated: CR.Kpo, CR.Kpo auth, CR.Kpo encr, CR.Kpo code,
CR.K −1

po bind, CR.P CR, and CR.KC .

po bind

, which

generate a related ciphertext {X, P CR ver′}K+
the device would be willing to decrypt for diﬀerent code
with measurement P CR ver′. To prevent this, the encryp-
tion scheme must be non-malleable – i.e., an attacker can-
not use one ciphertext to generate a second ciphertext that
decrypts to a plaintext related to the original plaintext.
The formal deﬁnition of non-malleable is known as Cho-
sen Ciphertex Attack of type 2 or CCA2. Examples of
CCA2 (non-malleable) asymmetric encryption schemes in-
clude RSA-OAEP and RSA-OAEP+ [39].5 An alternative
strategy to using a non-malleable public-key encryption scheme
is to use the secret encrypted with the asymmetric primitive
to derive two keys: an encryption key and a MAC key. The
MAC key should be used to compute a MAC over the bulk-
encrypted ciphertext, and the receiver should reject cipher-
texts with an inconsistent MAC. This is the strategy used
in the Integrated Encryption Scheme [38]. In this work, we
simply assume that we are using a CCA2 public-key encryp-
tion scheme regardless of its particular implementation.

Inst 5 out ← bind[KV P , stateOS, hashInputs, resultV, update]

Inst 4 X ← unbind[{X1, P CR_ver}K+

po_bind

, {X2, P CR_ver}KC ]

if {X1, P CR ver}

K

+
po bind

6= N U LL then

X, P CR ver ← Dec

CR.K

−1
po bind

({X1, P CR ver}

K

+
po bind

)

else if {X2, P CR ver}KC 6= N U LL then

X, P CR ver ← AuthDecCR.KC ({X2, P CR ver}KC )

else

X ←⊥

if CR.P CR 6= P CR ver then

X ←⊥
return X

Instruction 4. Inputs X1 and X2 contain data values that
should only be released to the code that generated the data.
The unbind instruction provides assurance to the veriﬁer
that the inputs will only be released to the code with mea-
surement P CR ver. Note that unbind[] can decrypt data
encrypted under either of the binding key K +
po bind or the
application secret key KC .

In the protocol described in Section 5, included in X2 is a
symmetric key KV P , which is generated by the veriﬁer V for
bulk encryption of data to be transferred between V and the
platform P . Notice that we do not suggest using the public
binding key, K +
Instead, sym-
metric keys should be used for bulk encryption operations
and the public binding key for storing bulk encryption keys.
This is a common practice used to avoid the performance
cost of public key cryptography.

po bind, for bulk encryption.

In choosing the asymmetric encryption scheme, some care
must be taken to prevent an attacker from using the ci-
phertext {X, P CR ver}K+
, which is intended to be de-
crypted only by the code with measurement P CR ver, to

po bind

ally, the call to f_read_asym_keys[] may be skipped for
sessions that only require symmetric keys.

if update 6= N U LL then

C′ ← AuthDecKV P (update)
if C′ 6=⊥ then

CR.P CR ← H (C′)
CR.KC ← KDFCR.Kpo code (CR.P CR)

out.OS ← AuthEncCR.KC (stateOS, CR.P CR)
V.hosstate ← H(stateOS)
V.hinp ← hashInputs
V.encK ← AuthEncCR.KC (KV P , CR.P CR)
V.res ← resultV
out.V ← AuthEncKV P (V )
Clear CR.∗
Clear all state
return out

Instruction 5. The bind[] instruction prepares data for
transfer to the untrusted code. This instruction should be
called by the executing code right before returning. Inputs
to this instruction include a shared secret KV P , the applica-
tion state stateOS, a hash of application input hashInputs,
and the application results results. The variables out.OS
and out.V are ciphertext to be stored in local memory and
sent to the veriﬁer, respectively. Please note that out.OS
and V.encK bind stateOS and KV P to the launch point
measurement of executing code C. Finally, observe that
bind[] enables program code C updates. This is enabled
by checking whether the update has been encrypted and au-
thenticated with the shared secret KV P and upon successful
veriﬁcation, updating CR.P CR and CR.KC , accordingly.

5Note that it is possible for an encryption scheme to be
semantically secure while still being malleable [11]. For ex-
ample, in a hybrid scheme where RSA is used to encrypt
a symmetric key, which is in turn used in a block cipher
to encrypt the bulk data, then clearly the last block of the
bulk-encrypted data can be modiﬁed without changing the
decryption of the preceding plaintext blocks. This could al-
low the attacker to change the speciﬁed PCR if it appears
at the end of bulk encrypted data. Even if the authorized
PCR is at the beginning, the attacker would still be able to
modify the end of the bulk data without changing the value
of the preceding ciphertext.

195. SECURE REMOTE EXECUTION

Figure 2 shows the protocol for the initial and subsequent
executions of security sensitive application f oo(). We as-
sume that the remote veriﬁer V has a copy of the public
platform binding key, K +
po bind. Similarly, the veriﬁer can
keep a certiﬁcate that is used to conﬁrm the authenticity of
the public key it receives from the platform. We also assume
that the veriﬁer has access to the plaintext code.

In Step 1, the veriﬁer V initiates an isolated execution
session with the platform. V generates an encryption key
KV P , and binds the hash of the code f oo() with KV P . Bind
allows the veriﬁer to encrypt data using the public part of
the platform key while ensuring that only the correct code
running in a correctly setup execution environment can ac-
cess the data. The inputs along with the code are sent to
the platform.

In Step 2, the OS calls the hardware instruction launch[]
using the plaintext code f oo(), the veriﬁer inputs V.inp, and
the previously stored state OS.inp as inputs. If it is the ﬁrst
code execution OS.inp is empty.

In Step 3, the isolated execution environment IEE ﬁrst
checks inputs received from the veriﬁer. If a “setup” com-
mand was received from the veriﬁer the IEE attempts to
unbind the encrypted inputs from V as follows. The IEE
releases shared encryption key KV P , using the unbind[]
instruction, and decrypts any private inputs, aborting exe-
cution if either operation fails. These checks prevent unau-
thorized code from proceeding. After the checks, the ap-
plication logic is executed. For example, if the application
is a secure counter, during the ﬁrst iteration the counter is
set to zero. In the case of an encrypted database, the ﬁrst
records could be stored in the database or all records could
be initialized to zero.

Steps 4 and 5 show the parameters returned to the OS
and the veriﬁer, respectively. Step 5 is critical as it pro-
vides evidence to the veriﬁer that the computation has been
performed on the correct inputs and, in particular, that the
inputs have not been manipulated prior to entering OASIS.

6. DISCUSSION

6.1 Linkable Code Blocks

So far, we have presented how an application C that is
fully contained within the CPU cache is executed in OASIS.
Recall that the unbind[] instruction guarantees that only
C can access its protected state during future invocations
by verifying that the loaded application has measurement
H(C) before decrypting.

Now we consider the case of an application that has size
greater than the cache (e.g., application C = C0|C1| . . . |Cn
where Ci refers to the ith application code block). Execu-
tion of more complex applications is achieved by computing
a Merkle hash tree over the entire program, and binding
the resulting tree’s root value to the application state. The
loaded code block Ci is accepted if and only if the hash tree
validation succeeds.

The hash tree construction provides several nice proper-
ties. First, it extends state protection and load-time in-
tegrity checking to applications of arbitrary size. Second, it
maintains a small TCB. Third, it enables eﬃcient execution
because code block Ci may be safely executed before the
entire application C has been hashed.

Setup Session
1. V

: V.inp.cmd ← command
: V.inp.pubdata ← pubInputs

: if (V.inp.cmd = “setup”)

R
←−{0, 1}ℓ

: KV P
:
:

V.inp.privdata ← AuthEncKV P (privInputs)
V.inp.encsym ← Enc

({KV P , H (foo())})

K

+
po bind

V → OS

Launch Codea
2. OS

Execute Code
3. IEE

V.inp.privdata ←

: else if (V.inp.cmd = “compute”)
:
:
:
: hfoo(), V.inpi

V.inp.encsym ← outV.encK

AuthEncKV P (privInputs, outV.hosstate)

: else /* other functionality */. . .

: OS.inp ← out.OS
: launch[foo(), {V.inp, OS.inp}]

ksym ← unbind[V.inp.encsym, N U LL]
if (ksym =⊥) then ABORT
data1 ← V.inp.pubdata
if (V.inp.privdata 6= N U LL) then

: if (V.inp.cmd = “setup”) then
:
:
:
:
:
:
:
:
:
:

data2 ← AuthDecksym(V.inp.privdata)
if (data2 =⊥) then ABORT

state ← doWork1(data1, data2)
out ← bind[ksym, state, H(V.inp), N U LL]

data2 ← N U LL

else

ksym ← unbind[N U LL, V.inp.encsym]
if (ksym =⊥) then ABORT
data1 ← V.inp.pubdata
if (V.inp.privdata 6= N U LL) then

: else if (V.inp.cmd = “compute”)then
:
:
:
:
:
:
:
:
:
:
:

data2 ← AuthDecksym(V.inp.privdata)
if (data2 =⊥) then ABORT

stateold ← unbind[N U LL, OS.inp]
if (data2.V hosstate 6= H (stateold)) then ABORT
{statenew, res} ← doWork2 (stateold,

out ← bind[ksym, statenew, H(V.inp), res]

data1, data2)

: else /* other functionality */. . .

Save State
4. IEE → OS : hout.OS, out.V i

OS

: store hfoo(), out.OSi

Verify Execution
5. OS → V

V

: hout.V i
: outV ← AuthDecKV P (out.V )
: if (outV =⊥) then
:
: if (outV.hinp 6= H(V.inp)) then
:

reject: invalid computation

reject: invalid inputs

a

Please note that OS.inp is assigned N U LL during the ﬁrst

launch.

Figure 2: OASIS Execution Protocol: This proto-
col shows the interaction between the veriﬁer V and
untrusted system OS during the initial invocation
(setup) and repeated invocations (compute) of code
foo() within isolated execution environment IEE.
During the initial invocation the veriﬁer V uses the
public platform key K +
po bind to establish shared se-
cret KV P which is used for repeat invocations.

206.2 Rollback Prevention

6.4 Version Updating

A rollback attack occurs when old state is presented to
the isolated execution environment. Since the stale state is
cryptographically consistent, an isolated execution environ-
ment implemented without rollback prevention will incor-
rectly accept it – potentially bypassing stateful protection
mechanisms to, for example, undo the append-only prop-
erty of an audit log. Thus, rollback resistance is needed to
guarantee state continuity of the executing application.

One technique for ensuring state continuity is to include
a protected monotonic counter as part of the state [33]. An-
other technique for rollback prevention is to keep a trusted
summary (e.g., a hash) of the expected state. Parno et al.
include a summary of the state history to permit revert-
ing to a safe state in the case of an unexpected crash [36].
These methods can be achieved by using protected non-
volatile memory for persistent storage of data describing
the expected state. However, we seek a rollback prevention
mechanism that enables OASIS to remain stateless between
invocations. Additionally, we rule out using a trusted third
party for state management.

What follows is a description of how the veriﬁer can con-
ﬁrm state continuity using the OASIS instruction set. Dur-
ing the execution protocol, the unbind[] instruction is in-
voked to decrypt any state belonging to code C (Figure 2
step 3). After executing code C, the bind[] instruction is
invoked to protect state destined for the OS as well as out-
put destined for the veriﬁer. Included in the output for the
veriﬁer is a summary of the current state, H (stateOS). The
veriﬁer output is encrypted under key KV P before transfer-
ring control to untrusted OS code for delivery to the veri-
ﬁer. The veriﬁer includes this state summary as an input
during the next invocation.
If the state presented by the
untrusted OS matches the expected state, the code executes
and the new state summary is communicated to the veriﬁer
as acknowledgment. Otherwise, the protocol aborts. In this
fashion, we achieve rollback prevention without requiring
persistent application state in the OASIS TCB.

6.3 Distributed Deployment

We have presented cryptographic techniques for data se-
crecy, authenticity, and freshness. Still, the rollback pre-
vention mechanism described thus far is insuﬃcient if we
consider the distributed deployment model where multiple
veriﬁers collaborate through a remote service provider. In
this asynchronous context, even if cryptographic techniques
prevent forged responses and data snooping, a compromised
OS can launch forking attacks by concealing the operations
of one veriﬁer from another. For example, a compromised
server may simply omit the current state and replay an old
state to the other veriﬁers.

Fork consistency ensures that all veriﬁers see the same
operations log before an omission but no veriﬁer can see
any other veriﬁer’s operations after an omission fault (fork).
Furthermore, the fork consistency condition enables the ver-
iﬁers to detect a misbehaving service provider after a single
omission.

Li et al. present a protocol for achieving fork consistency

where each veriﬁer maintains a signed version structure list [25].
Each veriﬁer signs increasing version numbers and appends
these to their respective lists, allowing them to compare lists
and detect a fork attack.

To support version updating (i.e., updating code C to le-
gitimate new code C′), the application must implement an
update command which calls bind[] with parameter update
set (where the update parameter contains the new code ver-
sion C′ encrypted under key KV P ). The bind[] instruction
ﬁrst checks parameter update for authenticity and then up-
dates CR.P CR and CR.KC using the new code version C′
(refer to Table 2 for deﬁnitions of variables and Instruction 5
for details on bind[]). In this way the application state of
the current software version C is bound to the new software
version C′. Accordingly, the next invocation of unbind[]
will release the application state to C′.

The decryption and authentication operations prove to
OASIS that the software originated from the veriﬁer V as
she is the only one in possession of the key KV P . It is pos-
sible to design an alternative update mechanism based on
asymmetric operations which has the advantage that an en-
tity diﬀerent from V can provide an update C′, thus granting
it access to the current OASIS state. However, this comes
at the cost of requiring certiﬁcation which would add com-
plexity and computational overhead.

6.5 Device Transferability

Recall that the device owner selects seed value So during
key generation (refer to Function 1 for details). The seed
value So enables derivation of owner-speciﬁc processor keys.
Customization, via the owner-generated seed So, precludes
previous device owners, including the manufacturer, from
generating the same platform secret as the current owner.
Thus, the device can be safely transferred. This protects the
owners of new devices by limiting the ability of malicious
parties (e.g., along the supply chain) to learn the platform
secrets of the end user. This allows, for example, a device
to be repurposed at a new business unit or sold to a new
owner.

Please note that the owner-generated seed So eﬀectively
disassociates any resulting key material from the device man-
ufacturer. Nevertheless, the owner needs a mechanism to
prove the authenticity of their processor to a third party.
A default seed value that is ﬁxed for the life of the device
may be included to support secure device transfer while still
providing a mechanism for proving the authenticity of the
executing platform. We refer to this default seed value as
∗. Next, a master signing key is
the identity seed value or So
∗. Certiﬁca-
derived from root secret Kp and identity seed So
tion can be handled by a third party for further unlinkability.
In this way, secrets linked to the hardware are derived from
∗ whereas secrets exclusive to the
the ﬁxed identity seed So
owner are derived from the custom owner seed So.

Allowing the owner to choose any So as often as they
like may allow an attacker to leak the root platform key
Kp through cryptanalysis. This can be mitigated by rate-
limiting requests for a fresh So. Upon request, the device
generates a fresh seed value So and computes a MAC over it
using a key derived from the root secret Kp and the identity
∗. This ensures that chosen values of So cannot
seed value So
be correlated with a response, during device initialization,
to learn the root platform key Kp.

217. PERFORMANCE EVALUATION

7.1 System Conﬁguration

We model our proposed processor instruction set using
Simics, a full-system simulator [31]. We build a prototype
system by adding our new instructions to the x86-hammer
model.6 We model a 2 GHz processor with non-uniﬁed L1
cache (64 KB data and instruction caches). We use a mod-
iﬁed Linux 2.6.32 kernel as our target operating system.

7.2 Microbenchmark Results

To evaluate micro- and macro-level benchmarks, we mea-
sure the performance of our implementation against TCG-
style implementations of common security-sensitive code op-
erations. We use a pessimistic benchmark for the OASIS
isolated execution environment and compare it to an opti-
mistic benchmark for TCG 1.2. See Table 4 for a list of the
platform primitives and their associated costs. See Table 5
for a comparison of performance overheads for OASIS and
DRTM-based implementations.7

We base the median performance costs associated with
the cryptographic primitives by leveraging open source li-
braries LibTomCrypt and OpenSSL.8 It is likely that these
functions further increase in performance with a hardware
implementation.

7.3 Performance Advantages

We now present the performance advantages of our archi-

tecture as compared to a TPM implementation.

In terms of processor speed, cryptographic applications
beneﬁt from running on a processor core instead of a TPM.
For example, the Inﬁneon TPM co-processor operates at
33 MHz, which pales in comparison to even mid and low-end
commodity processor speeds.

In terms of communication overhead, we avoid costly com-
munication overheads by implementing cryptographic func-
tions on chip instead of on a co-processor. For example, the
TPM interfaces using the Low Pin Count (LPC) bus. The
LPC is used to connect low-bandwidth devices to the CPU
(4-bit-bus on a 33 MHz clock).

8. RELATED WORK
Architecture Extensions. Hardware-based security mech-
anisms have been proposed and implemented by both com-
mercial and academic groups. In terms of commercial hardware-
based IEE technologies, the main components are the Trusted
Execution Environment (TEE) which provides capabilities
for isolated execution and ensuring software is in a known
good state before launch, and the Trusted Platform Mod-
ule (TPM) which provides remote attestation, binding, and
sealing capabilities. Popular TEE implementations include
ARM Trust Zone [1], and Intel TXT [3]. More recently, Intel
has improved on the TXT architecture with the development
of Intel SGX [19]. These techniques can be combined with
the OASIS API. For example, Enclaves from SGX would

6x86-hammer is a hardware model representing a generic
64-bit AMD Operteron processor sans on-chip devices [47].
7We have based performance overheads in Table 5 on TPM
benchmarks from [37] where the reference DRTM implemen-
tation does not provide performance numbers for 2048-bit
RSA operations.
8LibTom: www.libtom.org. OpenSSL: www.openssl.org.

Table 4: Performance overheads for platform operations
used to instrument the OASIS isolated execution environ-

ment hardware simulation. Times are based on a 2 GHz

processor clock.

avg (of 210 executions)

cycles

time(ms)

Platform Support

R
←−{0, 1}ℓ

rand
f_read_PUF
f_init_PUF
f_fuzzy_extract_PUF

1.6 K 7.91 · 10−4
2.55 · 10−5
˜
2.40 · 10−5
˜
3.30 · 10−5
˜

Crypto
H(pe)
KDFCR.Kpo
f_sym_encrypt
f_sym_decrypt
f_rsa_key_gen
f_rsa_encrypt
f_rsa_decrypt
Sign

(m)

(m, σ)

+
X

K

−1
X

K
Verify

4.9 K 2.49 · 10−3
20.9 K 1.04 · 10−2
1.2 K 6.02 · 10−4
1.2 K 6.12 · 10−4
1.61 · 10+3
3.2 B
3.08 M 1.54 · 10+0
65.7 M 3.29 · 10+1
65.9 M 3.30 · 10+1

3.1 M 1.53 · 10+0

OASIS Functions
f_create_sym_keys
f_create_asym_keys
f_read_asym_keys

104 K 5.21 · 10−2
1.84 · 10+3
3.7 B
18.5 K 9.26 · 10−3

OASIS Instructions
init
create
launch
unbind with asym
unbind with sym
bind

7.2 K 3.58 · 10−3
2.16 · 10+3
4.3 B
137 K 6.84 · 10−2
68.1 M 3.40 · 10+1
17.9 M 8.95 · 10+0
3.12 M 1.56 · 10+0

replace CAR mode based memory isolation to support ap-
plications of much larger size.

Similar to our work, Defrawy et al. propose SMART, an
architecture for establishing a dynamic root of trust in re-
mote devices [13]. SMART focuses on remote embedded de-
vices (in particular, low-end microcontroller units (MCUs))
whereas we are applicable to high-end processors. Addition-
ally, SMART investigates the usage of secret key material
to establish a root of trust, assuming the existence of secure
non-volatile memory to store the secret. In contrast, OASIS
is based on the use of SRAM memory–based PUFs [16, 17].
Previous work has explored hardware extensions designed
for an adversary model where software and physical attacks
are possible. Lie et al. present XOM, a hardware imple-
mentation of eXecute-only-memory [26]. Similar to our ad-
versary model, XOM assumes a completely untrusted OS.
Unlike OASIS, XOM assumes a secure manufacturing pro-
cess, allows secure XOM applications to access the plat-
form secret, and requires secure non-volatile memory. Lee
et al. present SP, a processor architecture for isolated ex-
ecution [24, 12]. Similar to OASIS, SP does not require a
secure manufacturing process; however, SP includes no im-
mutable device secret which makes it a challenge to prove
the authenticity of the executing platform to a third party.
Memory cloaking provides secrecy and integrity of appli-
cation data while allowing the OS to carry on most of its
memory management tasks by limiting the OS’s data access
to ciphertext. More recently, Williams et al. (Secure Exe-

22Scenario

One Time

Table 5: Comparison of performance overheads by invocation scenario.

OASIS

DRTM

operation(s)

init[]

operation(s)

time

ref.

NV Write, TPM 2048 Root Key Generation

> 25 sec

[37]

time

3.6 µsec

2.6 sec

34.1 msec

One Time per Owner

create[]

Per Module Launch
(First Time)

launch[] and
unbind[] with K+
encrypted input

po bind

Per Module Launch
(Repeated Invocation)

launch[] and
unbind[] with KC
encrypted input

TrustVisor-modeled AIK Generation:
TPM and µT P M 2048 AIK Generation

TrustVisor-modeled DRTM:
Transfer SLB over LPC, Unseal µT P M keys,
quote SLB, µT P M HV Quote of PAL

> 25 sec

[37]

> 1.8 sec [32]

22 msec

[32]

9.0 msec

TrustVisor-modeled DRTM:
Set-up and HV Quote of PAL

cutables [49]) and Chhabra et al. (SecureMe [8]) propose an
isolated execution environment using hardware-based mem-
ory cloaking. Secure Executables uses CPU-protected mem-
ory regions to store the register set (e.g., while a Secure
Executable is suspended during a system call). This solu-
tion has the advantage of avoiding cryptographic operations;
however, direct memory attacks may be possible (e.g., by a
DMA-enabled hardware component). The root of trust in
Secure Executables is based on a public/private keypair that
is installed in the CPU during manufacturing. In our design,
the manufacturer and the device owner (or system integra-
tor) both contribute to initializing a root of trust. This
reduces the possibility of any large-scale data breaches and
also facilities repurposing the device for new owners. Se-
cureMe improves upon previous cloaking methods by ensur-
ing that the entire address space of the application remains
protected at all times. OASIS diﬀers from SecureMe in its
usage model. Unlike SecureMe, OASIS enforces isolation in
the strictest sense by suspending the OS for the duration of
its sessions.

PUF-Based Secrets. Similar to our work, Suh et al. pro-
pose a secure processing architecture, AEGIS, that makes
use of Physical Unclonable Functions for creating and pro-
tecting secrets [42]. AEGIS consigns security-sensitive OS
functionality (e.g., context switching and virtual memory
management) to a security kernel. However, this approach
faces the same problem as the trusted OS model – the re-
sulting TCB can be quite large.

Alternate Deployment Models. Our ISE is inspired by
the recommendations of McCune et al. [34] but in contrast
to previous approaches that use a TPM as the root of trust,
we use a PUF-derived key, integrated within the processor.
This integration increases performance and diminishes the
possibility of attacks on the buses connecting the platform
to the TPM.

We use hardware instructions to ensure strong isolation
properties during the execution of self-contained security-
sensitive code. Another alternative is to use a special-purpose
hypervisor instead of additional hardware instructions. The
hypervisor provides a less expensive alternative to hardware
instruction set extensions and is signiﬁcantly smaller than
a full OS. Nonetheless, a disadvantage of this approach is
that the hypervisor is trusted to enforce memory isolation
and DMA protection for executing code and, accordingly,
must be included in the TCB.

An alternative to extending functionality to the CPU is

to use a secure co-processor [40]. A dedicated TPM is the
approach endorsed by the TCG. In terms of manufactur-
ing, this approach has the advantage of decoupling system
security from the production of traditional processors. A
drawback of using co-processors, however, is a reduction of
physical security due to the exposed bus. Additionally, the
performance hit due to communicating over the bus is not
suitable for minimal TCB execution where sessions are re-
peatedly setup and torn down.

Alternatively, a co-processor could be included as an IP
on a SoC which would provide speed, tighter control, and
enhanced security. The motivation for extending the pro-
cessor ISA rather than a SoC TPM implementation is cost
savings.

9. CONCLUSION

Currently, TPM-based solutions have not reached wide-
spread application in security-sensitive contexts, perhaps
because TCG solutions lack protection against a more re-
sourceful adversary, lack suﬃcient properties for end-to-end
application protection, lack architectural safeguards against
supply-chain compromises, or concerns over poor perfor-
mance. OASIS oﬀers a stronger degree of protection through
highly eﬃcient isolated execution with no hardware depen-
dencies outside the CPU.

We have explored the extent to which minimal modiﬁca-
tions to commodity CPUs can support isolated code exe-
cution. The ISA extensions explored in this research enable
compute service providers and application developers to pro-
vide high-security assurance at low cost in terms of platform
and software complexity.

10. ACKNOWLEDGMENTS

We are thankful to Olatunji Ruwase, Chen Chen, Yan-
lin Li, and Siddhartha Chhabra for their insightful discus-
sions and for making valuable suggestions for completing
this work, and to the anonymous reviewers for their detailed
comments and valuable feedback.

11. REFERENCES
[1] ARM Security Technology - Building a Secure System using

TrustZone Technology, 2009. Available at
http://infocenter.arm.com/.

[2] The CDW 2011 Cloud Computing Tracking Poll, 2011.

Available at www.cdw.com.

[3] Intel Trusted Execution Technology (Intel TXT) - Software
Development Guide, 2013. Document Number: 315168-009
Available at www.intel.com.

23[4] B¨osch, C., Guajardo, J., Sadeghi, A.-R., Shokrollahi, J., and

Tuyls, P. Eﬃcient Helper Data Key Extractor on FPGAs. In
Cryptographic Hardware and Embedded Systems (CHES)
(2008).

[5] Boyen, X., Dodis, Y., Katz, J., Ostrovsky, R., and Smith, A.

Secure Remote Authentication Using Biometric Data. In
Advances in Cryptology (EUROCRYPT) (2005).

[6] Brian Krebs. Coordinated ATM Heist Nets Thieves $13M,

2011. Available at http://krebsonsecurity.com.

[7] Chen, L. Recommendation for Key Derivation Using

Pseudorandom Functions (Revised). NIST Special Publication
800-108, 2009.

In International conference on Audio and Video Based
Biometric Person Authentication (AVBPA) (2003).

[28] Lu, Y., Lo, L.-T., Watson, G., and Minnich, R. CAR: Using

Cache as RAM in LinuxBIOS, 2012. Available at
http://rere.qmqm.pl/ mirq.

[29] Lucian Constantin. One year after DigiNotar breach, Fox-IT

details extent of compromise, 2012. Available at
www.wired.com.

[30] Maes, R., Tuyls, P., and Verbauwhede, I. Low-Overhead

Implementation of a Soft Decision Helper Data Algorithm for
SRAM PUFs. In Cryptographic Hardware and Embedded
Systems (CHES) (2009).

[8] Chhabra, S., Rogers, B., Solihin, Y., and Prvulovic, M.

[31] Magnusson, P., Christensson, M., Eskilson, J., Forsgren, D.,

SecureME: A Hardware-Software Approach to Full System
Security. In ACM International conference on
Supercomputing (ICS) (2011).

Hallberg, G., Hogberg, J., Larsson, F., Moestedt, A., and
Werner, B. Simics: A full system simulation platform.
Computer (2002).

[9] Dodis, Y., Katz, J., Reyzin, L., and Smith, A. Robust Fuzzy

[32] McCune, J. M., Li, Y., Qu, N., Zhou, Z., Datta, A., Gligor,

Extractors and Authenticated Key Agreement from Close
Secrets. In Advances in Cryptology (CRYPTO) (2006).

[10] Dodis, Y., Reyzin, M., and Smith, A. Fuzzy Extractors: How to

Generate Strong Keys from Biometrics and Other Noisy Data.
In Advances in Cryptology (EUROCRYPT) (2004).
[11] Dolev, D., Dwork, C., and Naor, M. Non-Malleable

Cryptography. In SIAM Journal on Computing (2000).

[12] Dwoskin, J. S., and Lee, R. B. Hardware-rooted trust for secure

key management and transient trust. In ACM conference on
Computer and communications security (CCS) (2007).

[13] El Defrawy, K., Francillon, A., Perito, D., and Tsudik, G.

SMART: Secure and Minimal Architecture for (Establishing a
Dynamic) Root of Trust. In Network and Distributed System
Security Symposium (NDSS) (2012).

[14] Gassend, B., Clarke, D., van Dijk, M., and Devadas, S.

Controlled Physical Random Functions. In Proceedings of
Annual Computer Security Applications Conference
(ACSAC) (2002).

[15] Gassend, B., Clarke, D., van Dijk, M., and Devadas, S. Silicon
Physical Random Functions. In ACM conference on Computer
and Communications Security (CCS) (2002).

[16] Guajardo, J., Kumar, S. S., Schrijen, G.-J., and Tuyls, P.
FPGA Intrinsic PUFs and Their Use for IP Protection. In
Cryptographic Hardware and Embedded Systems (CHES)
(2007).

[17] Holcomb, D. E., Burleson, W. P., and Fu, K. Power-Up SRAM
State as an Identifying Fingerprint and Source of True Random
Numbers. IEEE Trans. Computers (2009).

[18] IEEE. IEEE Standard Speciﬁcations for Public-Key

Cryptography — IEEE Std 1363T M -2000, 2000. Available at
www.ieee.org.

[19] Ittai Anati, Shay Gueron, S. P. J. Innovative Technology for

CPU Attestation and Sealing. In Workshop on Hardware
Architecture for Security and Privacy (2013).

[20] Jason Kincaid. Google Conﬁrms That It Fired Engineer For

Breaking Internal Privacy Policies, 2010. Available at
http://techcrunch.com.

[21] Juels, A., and Wattenberg, M. A Fuzzy Commitment Scheme.

In ACM conference on Computer and Communications
Security (CCS) (1999).

[22] Krawczyk, H. Cryptographic Extraction and Key Derivation:

The HKDF Scheme. In Advances in Cryptology (2010),
CRYPTO.

[23] Kursawe, K., Sadeghi, A.-R., Schellekens, D., Skoric, B., and

Tuyls, P. Reconﬁgurable Physical Unclonable Functions –
Enabling Technology for Tamper-Resistant Storage. In IEEE
International Workshop on Hardware-Oriented Security and
Trust (HOST) (2009).

[24] Lee, R., Kwan, P., McGregor, J., Dwoskin, J., and Wang, Z.

Architecture for Protecting Critical Secrets in Microprocessors.
In Proceedings of the International Symposium on Computer
Architecture (ISCA) (2005).

[25] Li, J., Krohn, M., Mazi`eres, D., and Shasha, D. Secure

Untrusted Data Depository (SUNDR). In USENIX Symposium
on Operating Systems Design & Implementation (OSDI)
(2004).

[26] Lie, D., Thekkath, C., Mitchell, M., Lincoln, P., Boneh, D.,

Mitchell, J., and Horowitz, M. Architectural Support for
Copy and Tamper Resistant Software. ACM SIGPLAN Notices
(2000).

[27] Linnartz, J.-P., and Tuyls, P. New Shielding Functions to

Enhance Privacy and Prevent Misuse of Biometric Templates.

V. D., and Perrig, A. TrustVisor: Eﬃcient TCB Reduction and
Attestation. In IEEE Symposium on Security and Privacy
(S&P) (2010).

[33] McCune, J. M., Parno, B., Perrig, A., Reiter, M. K., and
Isozaki, H. Flicker: An Execution Infrastructure for TCB
Minimization. In ACM European Conference in Computer
Systems (EuroSys) (2008).

[34] McCune, J. M., Parno, B., Perrig, A., Reiter, M. K., and
Seshadri, A. How Low Can You Go? Recommendations for
Hardware-Supported Minimal TCB Code Execution. In ACM
Conference on Architectural Support for Programming
Languages and Operating Systems (ASPLOS) (2008).

[35] Pappu, R. S., Recht, B., Taylor, J., and Gershenfeld, N.
Physical One-way Functions. Science (2002). Available at
web.media.mit.edu.

[36] Parno, B., Lorch, J. R., Douceur, J. R., Mickens, J. W., and

McCune, J. M. Memoir: Practical state continuity for protected
modules. In IEEE Symposium on Security and Privacy (S&P)
(2011).

[37] Schmitz, J., Loew, J., Elwell, J., Ponomarev, D., and

Abu-Ghazaleh, N. B. TPM-SIM: A Framework for Performance
Evaluation of Trusted Platform Modules. In ACM Design
Automation Conference (DAC) (2011).

[38] Shoup, V. A Proposal for an ISO Standard for Public Key

Encryption. Version 2.1, 2001. Available at www.shoup.net.
[39] Shoup, V. OAEP Reconsidered. In Advances in Cryptology

(CRYPTO) (2001). Available at www.shoup.net.

[40] Smith, S. W., and Weingart, S. ”building a high-performance,

programmable secure coprocessor”. Computer Networks (1999).

[41] Song, D., Shi, E., Fischer, I., and Shankar, U. Cloud data

protection for the masses. IEEE Computer (2012).

[42] Suh, G. E., O’Donnell, C. W., and Devadas, S. AEGIS: A

Single-Chip Secure Processor. Information Security Technical
Report (2005).

[43] Symantec. Symantec-Sponsored Ponemon Report Finds

Negligent Employees Top Cause of Data Breaches in the U.S.
While Malicious Attacks Most Costly, 2012. Available at
www.symantec.com.

[44] Taylor, G., and Cox, G. Behind Intel’s New Random-Number

Generator. IEEE Spectrum (2011). Available at
http://spectrum.ieee.org.

[45] Tuyls, P., Schrijen, G.-J., Skoric, B., van Geloven, J.,

Verhaegh, N., and Wolters, R. Read-Proof Hardware from
Protective Coatings. In Cryptographic Hardware and
Embedded Systems (CHES) (2006).

[46] Vasudevan, A., McCune, J., Newsome, J., Perrig, A., and van

Doorn, L. CARMA: A Hardware Tamper-Resistant Isolated
Execution Environment on Commodity x86 Platforms. In ACM
Symposium on Information, Computer and Communications
Security (ASIACCS) (2012).

[47] Virtutech. Simics x86-440BX Target Guide, 2010.
[48] Wang, Y., kei Yu, W., Wu, S., Malysa, G., Suh, G. E., and

Kan, E. C. Flash Memory for Ubiquitous Hardware Security
Functions: True Random Number Generation and Device
Fingerprints. In IEEE Symposium on Security and Privacy
(S&P) (2012).

[49] Williams, P., and Boivie, R. CPU Support for Secure

Executables. In Trust and Trustworthy Computing (2011).

24