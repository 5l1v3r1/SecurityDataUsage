Harvesting Inconsistent Security Configurations  
in Custom Android ROMs via Differential Analysis

Yousra Aafer, Xiao Zhang, and Wenliang Du, Syracuse University

 https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/aafer

This paper is included in the Proceedings of the 25th USENIX Security SymposiumAugust 10–12, 2016 • Austin, TXISBN 978-1-931971-32-4Open access to the Proceedings of the 25th USENIX Security Symposium is sponsored by USENIX Harvesting Inconsistent Security Conﬁgurations in Custom Android ROMs

via Differential Analysis

Yousra Aafer, Xiao Zhang, and Wenliang Du

Syracuse University

{yaafer, xzhang35, wedu}@syr.edu

Abstract
Android customization offers substantially different ex-
periences and rich functionalities to users. Every party
in the customization chain, such as vendors and carri-
ers, modify the OS and the pre-installed apps to tailor
their devices for a variety of models, regions, and custom
services. However, these modiﬁcations do not come at
no cost. Several existing studies demonstrate that mod-
ifying security conﬁgurations during the customization
brings in critical security vulnerabilities. Albeit these
serious consequences, little has been done to systemat-
ically study how Android customization can lead to se-
curity problems, and how severe the situation is. In this
work, we systematically identiﬁed security features that,
if altered during the customization, can introduce poten-
tial risks. We conducted a large scale differential analy-
sis on 591 custom images to detect inconsistent security
features. Our results show that these discrepancies are
indeed prevalent among our collected images. We have
further identiﬁed several risky patterns that warrant fur-
ther investigation. We have designed attacks on real de-
vices and conﬁrmed that these inconsistencies can indeed
lead to actual security breaches.

1

Introduction

When vendors, such as Samsung, LG and HTC, put An-
droid AOSP OS on their devices, they usually conduct
extensive customization on the system. The reasons for
customization can be many, including adding new func-
tionalities, adding new system apps, tailoring the device
for different models (e.g., phone or tablet), or carriers
(e.g., T-mobile and AT&T), etc. Further complicating
the process is Android updates pushed to the devices: the
updates might target a new Android or app version.

This fragmented eco-system brings in several secu-
rity risks when vendors change the functionalities and
conﬁgurations without a comprehensive understanding

of their implications. Previous work has demonstrated
some aspects of these changes and the resulting risks.
Wu et al. [25] analyze several stock Android images from
different vendors, and assess security issues that may be
introduced by vendor customization. Their results show
that customization is responsible for a number of secu-
rity problems ranging from over-privileged to buggy sys-
tem apps that can be exploited to mount permission re-
delegation or content leaks attacks. Harehunter [5] re-
veals a new category of Android vulnerabilities, called
Hares, caused by the customization process. Hares oc-
cur when an attribute is used on a device but the party
deﬁning it has been removed during the customization.
A malicious app can “impersonate” the missing attribute
to launch privilege escalation, information leakage and
phishing attacks. ADDICTED [29] ﬁnds that many cus-
tom Android devices do not properly protect Linux de-
vice drivers, exposing them to illegitimate parties.

All the problems reported so far on Android cus-
tomization are mainly caused by vendors’ altering of crit-
ical conﬁgurations. They change security conﬁgurations
of system apps and Linux device drivers; they also re-
move, add, and alter system apps. Although the exist-
ing work has studied several aspects of security problems
in the changes of system/app conﬁgurations, there is no
work that systematically ﬁnds all security conﬁguration
changes caused by vendor customization, how likely it
can lead to security problems, what risky conﬁguration
changes are often made by vendors, etc.

In this work, we make the ﬁrst attempt to systemat-
ically detect security conﬁguration changes introduced
by parties in the customization chain. Our key intu-
ition is that through comparing a custom device to simi-
lar devices from other vendors, carriers, and regions, or
through comparing different OS versions, we might be
able to ﬁnd security conﬁguration changes created unin-
tentionally during the customization. More importantly,
through a systematic study, we may be able to ﬁnd valu-
able insights in vendor customization that can help ven-

USENIX Association  

25th USENIX Security Symposium  1153

dors improve the security of their future customizations.
We propose DroidDiff, a tool that detects inconsistent
security conﬁgurations in a large scale, and that can be
employed by vendors to locate risky conﬁgurations.

The ﬁrst challenge that we face in our systematic study
is to identify what conﬁgurations are security relevant
and are likely to be customized. We start from the An-
droid layered architecture and list access control checks
employed at each layer. Then, for each check, we rely on
Android documentation and our domain knowledge to
deﬁne corresponding security features. We further ana-
lyze how different conﬁgurations of these features across
custom images can lead to inconsistencies and thus af-
fect the access control check semantics. As a result, we
have identiﬁed ﬁve categories of features. DroidDiff then
extracts these features from 591 custom Android ROMs
that we collected from multiple sources. This step pro-
duces the raw data that will be used for our analysis.

The next challenge is how to compare these images
to ﬁnd out whether they have inconsistent values for the
features that we extracted. Given a set of images, con-
ducting the comparison itself is not difﬁcult; the difﬁ-
culty is to decide the set of images for comparison. If
we simply compare all the 591 images, it will not pro-
vide much insight, because it will be hard to interpret
the implications of detected inconsistencies. To gain
useful insights, we need to select a meaningful set of
images for each comparison. Based on our hypothesis
that inconsistencies can be introduced by vendors, device
models, regions, carriers, and OS versions, we devel-
oped ﬁve differential analysis algorithms: Cross-Vendor,
Cross-Model, Cross-Region, Cross-Carrier, and Cross-
Version analyses, each targeting to uncover inconsisten-
cies caused by customization of different purposes. For
example, in the Cross-Vendor analysis, we aim to know
how many inconsistencies are there among different ven-
dors; in the Cross-Model analysis, we attempt to identify
whether vendors may further introduce inconsistencies
when they customize Android for different models (e.g.
Samsung S4, S5, S6 Edge).

DroidDiff results reveal that indeed the customization
process leads to many inconsistencies among security
features, ranging from altering the protection levels of
permissions, removing protected broadcasts deﬁnitions,
changing the requirement for obtaining critical GIDs,
and altering the protection conﬁguration of app compo-
nents. We present our discoveries in the paper to show
the inconsistency situations among each category of fea-
tures and how versions, vendors, models, region, and car-
riers customizations impact the whole situation.

Not all

inconsistencies are dangerous, but some
changes patterns are deﬁnitely risky and warrant further
investigation. We have identiﬁed such risky patterns,
and presented results to show how prevalent they are in

the customization process. The inconsistencies expose
systems to potential attacks, but if the vendors under-
stand fully the implication of such customization, they
will more likely remedy the introduced risks by putting
proper protection at some other places. Unfortunately,
most of the inconsistencies seem to be introduced by de-
velopers who do not fully understand the security im-
plications. Therefore, our DroidDiff can help vendors
to identify the inconsistencies introduced during their
customization, so they can question themselves whether
they have implemented mechanisms to remedy the risks.
To demonstrate that the identiﬁed inconsistencies, if
introduced by mistakes, can indeed lead to attacks, we
picked few cases detected through our differential anal-
ysis, and designed proof-of-concept attacks on physical
devices1. We have identiﬁed several real attacks. To il-
lustrate, we found that a detected inconsistency on Nexus
6 can be exploited to trigger emergency broadcasts with-
out the required system permission and another similar
one on Samsung S6 Edge allows a non-privileged app to
perform a factory reset without a permission or user con-
ﬁrmation. Through exploiting another inconsistency on
Samsung Note 2, an attacker can forge SMS messages
without the SEND_SMS permission. Moreover, an in-
consistency related to permission to Linux GID mapping
allows apps to access the camera device driver with a nor-
mal protection level permission. We have ﬁled security
reports about the conﬁrmed vulnerabilities to the corre-
sponding vendors. We strongly believe that vendors, who
have source code and know more about their systems,
can ﬁnd more attacks from our detected risky inconsis-
tencies. We also envision that in the future, vendors can
use our proposed tool and database to improve their cus-
tomization process.

Contributions. The scientiﬁc contributions of this pa-
per are summarized as the followings:

• We have systematically identiﬁed possible security
features that may hold different conﬁgurations be-
cause of the Android customization process.

• We have developed ﬁve differential analysis algo-
rithms and conducted a large-scale analysis on 591
Android OS images. Our results produce signiﬁcant
insights on the dangers of vendor customization.

• We have identiﬁed risky conﬁguration inconsisten-
cies that may have been introduced unintentionally
during customization. Our results can help vendors’
security analysts to conduct further investigation to
conﬁrm whether the risks of the inconsistencies are
offset in the system or not. We have conﬁrmed via
our own attacks that some inconsistencies can in-
deed lead to actual security breaches.

1Due to resource limitation, we could not design the attacks for all

the cases identiﬁed in our analysis.

1154  25th USENIX Security Symposium 

USENIX Association

(cid:3)(cid:23)(cid:21)(cid:12)(cid:18)(cid:22)(cid:1)

(cid:6)(cid:22)(cid:23)(cid:31)(cid:20)(cid:15)(cid:14)(cid:16)(cid:15)(cid:1)

(cid:2)(cid:22)(cid:14)(cid:24)(cid:23)(cid:18)(cid:14)(cid:1)

(cid:3)(cid:23)(cid:13)(cid:30)(cid:21)(cid:15)(cid:22)(cid:26)(cid:12)(cid:27)(cid:23)(cid:22)(cid:1)

(cid:2)(cid:25)(cid:25)(cid:21)(cid:19)(cid:16)(cid:14)(cid:28)(cid:24)(cid:23)(cid:1)

(cid:2)(cid:25)(cid:25)(cid:21)(cid:19)(cid:16)(cid:14)(cid:28)(cid:24)(cid:23)(cid:1)(cid:1)

(cid:9)(cid:17)(cid:12)(cid:25)(cid:15)(cid:1)(cid:5)(cid:1)

(cid:9)(cid:17)(cid:12)(cid:25)(cid:15)(cid:1)(cid:5)(cid:5)(cid:1)

(cid:6)(cid:11)(cid:3)(cid:1)

(cid:11)(cid:17)(cid:26)(cid:22)(cid:19)(cid:27)(cid:27)(cid:19)(cid:24)(cid:23)(cid:1)(cid:34)(cid:1)(cid:13)(cid:6)(cid:4)(cid:1)(cid:16)(cid:18)(cid:17)(cid:16)(cid:20)(cid:1)

(cid:2)(cid:25)(cid:25)(cid:21)(cid:19)(cid:16)(cid:14)(cid:28)(cid:24)(cid:23)(cid:1)(cid:5)(cid:26)(cid:14)(cid:22)(cid:17)(cid:31)(cid:24)(cid:26)(cid:20)(cid:1)

(cid:9)(cid:19)(cid:15)(cid:26)(cid:14)(cid:26)(cid:19)(cid:17)(cid:27)(cid:1)

(cid:7)(cid:10)(cid:6)(cid:1)

(cid:7)(cid:10)(cid:6)(cid:1)

Component Visibility 
Permission Check 
Protected Broadcast 

UID Check 

(cid:9)(cid:19)(cid:23)(cid:30)(cid:32)(cid:1)(cid:4)(cid:2)(cid:3)(cid:1)
(cid:9)(cid:19)(cid:23)(cid:30)(cid:32)(cid:1)(cid:8)(cid:17)(cid:26)(cid:23)(cid:17)(cid:21)(cid:1)

(cid:1)

(cid:12)(cid:14)(cid:31)(cid:1)(cid:12)(cid:17)(cid:27)(cid:24)(cid:30)(cid:26)(cid:16)(cid:17)(cid:27)(cid:1)

Figure 2: Android Security Model

many high-level services such as Package Manager, Ac-
tivity Manager, Notiﬁcation Manager and many others.
These services mediate access to system resources and
enforce proper access control based on the app’s user
id and its acquired Android permissions. Additionally,
certain services might enforce access control based on
the caller’s package name or certiﬁcate. Right below
the framework layer lies the Libraries layer, which is a
set of Android speciﬁc libraries and other necessary li-
braries such as libc, SQLite database, media libraries,
etc. Just like the framework services, certain Android
speciﬁc libraries perform various access control checks
based on the caller’s user id and its permissions as well.
At the bottom of the layers is Linux kernel which pro-
vides a level of abstraction between the device hardware
and contains all essential hardware drivers like display,
camera, etc. The Linux kernel layer mediates access to
hardware drivers and raw resources based on the standard
Discretionary Access Control (DAC).

To encourage collaboration and functionality re-use
between apps, Android apps are connected together by
Inter-Component Communication (ICC). An app can in-
voke other apps’ components (e.g. activities and ser-
vices) through the intent mechanism. It can further con-
ﬁgure several security parameters to protect its resources
and functionalities. As summarized in Figure 2, it can
make its components private, require the caller to have
certain permissions or to belong to a certain process.

Based on Figure 2, we summarize the Access Con-
trol (AC) checks employed by Android in Table 1. We
specify the ones whose security features might be altered
statically during device customization. By static modi-
ﬁcation, we refer to any modiﬁcation that can be per-
formed through changing framework resources ﬁles (in-
cluding framework-res*.xml which contains most con-
ﬁgurations of built-in security features), preloaded apps’
manifest ﬁles and other system-wide conﬁguration ﬁles

Feature Selection 
F t

S l
S

ti

(cid:2)(cid:22)(cid:14)(cid:24)(cid:23)(cid:18)(cid:14)(cid:1)
(cid:10)(cid:8)(cid:7)(cid:25)(cid:1)

Data Generation 

G

(cid:10)(cid:12)(cid:31)(cid:1)(cid:3)(cid:12)(cid:26)(cid:12)(cid:1)

Methodology: 

odo

Differential Analysis 

(cid:5)(cid:22)(cid:13)(cid:23)(cid:22)(cid:25)(cid:18)(cid:25)(cid:26)(cid:15)(cid:22)(cid:13)(cid:32)(cid:1)(cid:10)(cid:15)(cid:25)(cid:30)(cid:20)(cid:26)(cid:25)(cid:1)

(cid:9)(cid:17)(cid:12)(cid:25)(cid:15)(cid:1)(cid:5)(cid:5)(cid:5)(cid:1)

(cid:3)(cid:12)(cid:22)(cid:16)(cid:15)(cid:24)(cid:23)(cid:30)(cid:25)(cid:1)
(cid:9)(cid:12)(cid:29)(cid:15)(cid:24)(cid:22)(cid:25)(cid:1)

Result Analysis 

t A

(cid:10)(cid:18)(cid:25)(cid:19)(cid:32)(cid:1)(cid:4)(cid:18)(cid:22)(cid:14)(cid:18)(cid:22)(cid:16)(cid:25)(cid:1)

(cid:9)(cid:17)(cid:12)(cid:25)(cid:15)(cid:1)(cid:5)(cid:11)(cid:1)

Figure 1: Investigation Flow

2

Investigation & Methodology

In this research work, we investigate Android’s secu-
rity features which are conﬁgurable during customiza-
tion at the level of the framework and preloaded apps.
Figure 1 depicts our investigation ﬂow. As our work is
data driven, the ﬁrst and second phase are mainly con-
cerned with locating and extracting meaningful security
features from our collected Android custom ROMs. The
two phases generate a large data set of conﬁgurations of
the selected security features per image. The third phase
performs differential analysis on the generated data ac-
cording to our proposed algorithms to ﬁnd any conﬁg-
uration discrepancies.
It should be noted that it is out
of our scope to ﬁnd any security feature that is wrongly
conﬁgured on all images, as obviously, it would not be
detected through our differential analysis.

In the last phase, we analyze the detected discrepan-
cies to pinpoint risky patterns. We have conﬁrmed that
they are indeed dangerous through high impact attacks.
We discuss in the next sections each phase in details.

3 Feature Extraction

In this phase, we aim to extract security features that can
cause potential vulnerabilities if altered incautiously dur-
ing the customization process. To systematically locate
these security features, we start from the Android lay-
ered architecture (Figure 2) and study the security en-
forcement employed at each layer.

As Figure 2 illustrates, Android is a layered operating
system, where each layer has its own tasks and responsi-
bilities. On the top layer are preloaded apps provided by
the device vendors and other third parties such as carri-
ers. To allow app developers to access various resources
and functionalities, Android Framework layer provides

USENIX Association  

25th USENIX Security Symposium  1155

(platform.xml and *.xml under /etc/permissions/).

In the following section, we describe in details each
conﬁgurable AC check and deﬁne its security features
based on Android documentation and our domain knowl-
edge. We further justify how inconsistent conﬁgurations
of these features across custom images can bring in po-
tential security risks. Please note that we do not discuss
AC checks based on Package Names as previous work
[5] has covered the effects of customizing them.

Before we proceed, we present some notations that we
will be referring to in our analysis. IMG denotes a set
of our collected images. EP, EGID, EPB and EC represent
a set of all deﬁned permissions, GIDs, protected broad-
casts and components on IMG, respectively.

These

3.1 Permissions
Default and custom Android Permissions are used
inner components, data and function-
to protect
alities.
The protection level of a permission can
either Normal, Dangerous, Signature,
be
or SystemOrSignature.
protection
should be picked carefully depending on
levels
the resource to be protected.
Signature and
SystemOrSignature level permissions are used
to protect the most privileged resources and will be
granted only to apps signed with the same certiﬁcate
as the deﬁning app. Dangerous permissions protect
private data and resources or operations affecting the
user’s stored data or other apps such as reading contacts
or sending SMS messages. Requesting permissions of
Dangerous levels requires explicit user’s conﬁrmation
before granting them. Normal level on the other hand,
is assigned to permissions protecting least privileged
resources and do not require user’s approval.
The
following is an example of a permission declaration:

<permission android:name="READ_SMS"

android:protectionLevel="Dangerous">

We aim to ﬁnd if a permission has different protection
levels across various images. For example, on vendor
A, a permission READ_A is declared with Normal pro-
tection level, while on vendor B, the same permission is
declared with a Signature one. This would expose
the underlying components that are supposed to be pro-
tected with more privileged permissions. It would also
create a big confusion for developers, as the same per-
mission holds different semantics across images.

Formally, for each deﬁned permission e ∈ EP, we de-

ﬁne the security feature f ne as the following:

f ne = ProtectionLevel(e)

f ne is in the set {Normal,
The potential values of
Dangerous, Signature, Unspeciﬁed, 0}. We map

Table 1: Security Checks

AC Checks

Layer

Conﬁgurable

UID
GID

Package Name

Package Signature

Permission

Protected Broadcast
Component Visibility
Component Protection

Kernel, Framework

Library, App

Kernel

Framework, App
Framework, App

Framework, Library

App

App Layer
App Layer
App Layer

No
Yes
Yes
No
Yes
Yes
Yes
Yes

SignatureOrSystem level to Signature, as both
of them cannot be acquired by third party apps without
a signature check. An unspecified value refers to
a permission that has been deﬁned without a protection
level, while 0 refers to a permission that is not deﬁned
on an image.

3.2 GIDs
Certain lower-level Linux group IDs (GIDs) are mapped
to Android permissions. Once an app process acquires
these permissions, it will be assigned the mapped GID,
which will be used for access control at the kernel. Per-
missions to GID mappings for built-in and custom per-
missions are deﬁned mostly in platform.xml and other
xml ﬁles under /etc/permissions/. The following is an
example of a permission to GID mapping:

<permission android:name =

"android.permission.NET_TUNNELING">

<group gid="vpn" />

</permission>

In the above example, any process that has been
granted NET_TUNNELING permission (deﬁned with a
Signature level) will be assigned the vpn GID, and
consequently perform any ﬁlesystem (read, write, exe-
cute) allowed for this GID.

Android states that any change made incautiously to
platform.xml would open serious vulnerabilities.
In
this analysis, we aim to ﬁnd if the customization par-
ties introduce any modiﬁcations to these critical map-
pings and if so, what damages this might create. More
speciﬁcally, we want to reveal if vendors map per-
missions of lower protection levels to existing privi-
leged GIDs, which can result in downgrading their priv-
ileges. Following the same example above, assume
that on a custom image, the vendor maps a permission
vendor.permission (deﬁned with Normal protec-
tion) to the existing vpn GID. This new mapping would
downgrade the privilege of vpn GID on the custom im-
age as it can be acquired with a Normal permission in-
stead of a Signature one. Thus, any third party app
granted vendor.permission will run with vpn GID

1156  25th USENIX Security Symposium 

USENIX Association

attached to its process, which basically allows it to per-
form any ﬁlesystem permissible for vpn GID, usually
allowed to only system processes.

To allow discovering vulnerable GID to permission
mappings, we extract the minimum permission require-
ment needed for acquiring a certain GID on a given im-
age; i.e. the minimum protection level for all permissions
mapping to it. If the same GID has different minimum re-
quirements on 2 images, then it is potentially vulnerable.
For the previous example, we should be able to reveal
that vpn GID is problematic as it can be acquired with a
Normal permission level on the custom image and with
a Signature one on other images.

For each deﬁned GID e ∈ EGID, let Pe denote the per-

mission set mapping to e, we deﬁne the feature f ne:

f ne = GIDProtectionLevel(e), where :

GIDProtectionLevel(e) = min
∀p∈Pe

ProtectionLevel(p)

3.3 Protected Broadcasts
Protected broadcasts are broadcasts that can be sent only
by system-level processes. Apps use protected broad-
casts to make sure that no process, but system-level pro-
cesses can trigger speciﬁc broadcast receivers. System
apps can deﬁne protected broadcasts as follows:

<protected-broadcast android:name="broadcast.name"/>

Another app can use the above deﬁned protected-
broadcast through the following:

<receiver android:name="ReceiverA">

<intent-filter>

<action = "broadcast.name"/>

<intent-filter/>

<receiver/>

The above ReceiverA can be triggered only by
system processes broadcasting broadcast.name pro-
tected broadcast. The app can alternatively use protected
broadcast through dynamically registered broadcast re-
ceivers. As it is known, during the customization pro-
cess, certain packages are removed and altered. We hy-
pothesize that because of this, certain protected broad-
casts’ deﬁnitions will be removed as well. We aim to un-
cover if these inconsistently non-protected broadcasts are
still being used though, as action ﬁlters within receivers.
This might open serious vulnerabilities, as the receivers
that developers assumed to be only invocable by system
processes will now be invocable by any third-party app
and consequently expose their functionalities.

Formally, for each Protected Broadcast e ∈ EPB, we

deﬁne the following:

Where DeﬁneUse(e) is deﬁned as the following:

De f ineUse(e) =⎧⎨⎩

1 if e is used on an image but not deﬁned
0 for other cases

3.4 Component Visibility
Android allows developers to specify whether their de-
clared components (activities, services, receivers and
content providers) can be invoked externally from other
apps. The visibility can be set through the exported
ﬂag in the component declaration within the app’s mani-
fest ﬁle. If this ﬂag is not speciﬁed, the visibility will be
implicitly set based on whether the component deﬁnes
intent ﬁlters. If existing, the component is exported; oth-
erwise, it is not as illustrated in the following snippet.

// Service1 is private to the app
<service android:name="Service1"/>
// Service2 is not private to the app
<service android:name="Service2">

<intent-filter> ... <intent-filter/>

</service>

We would like to uncover any component that has been
exposed on one image, but not on another. We assume
that if the same component name appears on similar im-
ages (e.g. same models, same OS version), then most
likely, the component is providing the same functional-
ity or protecting the same data (for content providers).
Thus, its visibility should be the same across all images.
To account for the cases where a component has been
exported but with an added signature permission re-
quirement, we consider them as implicitly unexposed.

Formally, for each deﬁned component e ∈ EC, we ex-

tract the following feature:

f ne = Exported(e)

The potential values of f ne is either {true, false, 0}. 0
refers to a non-existing component on a studied image.

3.5 Component Protection
Apps can use permissions to restrict the invocation of
their components (services, activities, receivers).
In
the next code snippet, ServiceA can be invoked if
the caller acquires vendor.permissionA. More-
over, an app can use permissions to restrict reading and
writing to its content provider, as well as to speciﬁc
paths within it. android:readPermission and
android:writePermission take precedence over
android:permission if speciﬁed, as shown in the
code snippet. Components inherit their parents’ permis-
sion if they do not specify one.

f ne = De f ineUse(e),

<service android:name="ServiceA"

android:permission="vendor.permissionA"/>

USENIX Association  

25th USENIX Security Symposium  1157

<provider android:authorities="providerId"

android:name="providerB"
android:Permission="vendor.permissionB"
android:readPermission="vendor.read"
android:writePermission="vendor.write">

We aim to ﬁnd if the same component has different
protection requirements on similar images. Protection
mismatch might not necessarily indicate a ﬂaw if the
component is not exposed. That’s why, we only consider
protection mismatches in case of exported components.
We list three cases where a component can be unin-
tentionally exposed on one image, but protected on other
images. First is the permission requirement is removed
from the component’s declaration. Second is the permis-
sion protecting it is of lower privilege compared to other
images. Third, the permission used is not deﬁned within
the image, which makes it possible for any third-party
app to deﬁne it and consequently invoke the underly-
ing component. To discover components with conﬂict-
ing protections, we map used permissions to their dec-
larations within the same image. Any mismatch would
indicate a possible security ﬂaw for this component.

Formally, let Pe represents the permission protecting a

component e ∈ Ec. We deﬁne the following feature:

f ne = Protection(e);

Where Protection(e) is deﬁned as:

Protection(e) =⎧⎪⎪⎪⎨⎪⎪⎪⎩

0 if e is not deﬁned
1 if Pe is None; i.e. e is not protected
ProtectionLevel(Pe) otherwise

In the case where e is a content provider, we deﬁne Pread
and Pwrite representing its read and write permissions and
extract f ne for both cases.

4 Data Generation

To reveal whether customization parties change the con-
ﬁgurations of the mentioned security features, we con-
duct a large scale differential analysis. We collected
591 Android ROMs from Samsung Updates [4], other
sources [3, 1, 2], and physical devices. These images
are customized by 11 vendors, for around 135 models,
45 regions and 8 carriers. They operate Android ver-
sions from 4.1.1 to 5.1.1. Details about the collected im-
ages are in Table 2. In total, these images include on av-
erage 157 apps per image and 93169 all together apps.
To extract the values of the selected security features
on each image, we developed a tool called DroidDiff.
For each image, DroidDiff ﬁrst collects its framework
resources Apks and preloaded Apks then runs Apktool
to extract the corresponding manifest ﬁles. Second, it
collects conﬁguration ﬁles under /etc/permission/. Then,

Table 2: Collected Android Images

Version
Jelly Bean

KitKat
Lollipop

Total

# of Distinct Vendors

# of images

9
9
8
11

102
177
312
591

Table 3: Security Conﬁgurations Map

Image

I1: Xiaomi RedMi 1

Version: 4.4.2

I2: Xiaomi Mi 2A

Version: 4.1.1

e ∈ EP

MIPUSH_RECEIVE

e ∈ EGID
camera GID

Signature

Normal

e ∈ EC
sms
True

Unspeciﬁed

Dangerous

False

DroidDiff searches the extracted manifests and conﬁgu-
ration ﬁles for the deﬁnitions of the targeted entities (EP,
EPB, EGID and EC). Finally, DroidDiff runs the generated
values through our differential analysis methodologies,
discussed in the next section.

5 Differential Analysis

In our analysis, we aim to detect any feature f ne hav-
ing inconsistent values throughout a candidate set of im-
ages. Any inconsistency detected indicates a potential
unintentional conﬁguration change introduced by a cus-
tomization party and requires further security analysis to
assess possible consequent damages.

Let f v( f ne,img) represent the value of the feature f ne
on a given image img. To illustrate f ne to f v( f ne,img)
mappings, consider this real world example depicted
in Table 3. As shown, we extract 3 security features
and their corresponding values from 2 Xiaomi images.
For the custom permission e = MIPUSH_RECEIVE,
our feature extraction step generates the following val-
ues
f v( f ne,I1) = Signature, and f v( f ne,I2) =
Unspecified.

Let IMG denote a set of candidate images to be com-

pared, we deﬁne a feature f ne as inconsistent if:

C( f ne) = ∃ x ∃ y [ x ∈ IMG∧ y ∈ IMG

∧ x �= y∧ f v ( f ne ,x) �= f v ( f ne ,y) ]

The above statement means that we consider the feature
f ne inconsistent across the set IMG if there exists at least
two different images where the value of f ne is not equal.
It should be noted that we do not consider any cases
where f v( f ne,img) = 0 for e ∈ {EP, EGID and EC}.
Sample Selection. To discover meaningful inconsis-
tencies through differential analysis, our collected im-
ages should be clustered based on common criteria. A
meaningful inconsistency would give us insights about
the responsible party that introduced it. For example,

1158  25th USENIX Security Symposium 

USENIX Association

to reveal if inconsistencies are introduced by an OS up-
grade, it would not make sense to select images from all
vendors, as the inconsistency could be due to customiz-
ing the device for a speciﬁc vendor, rather than because
of the OS upgrade. Similarly, to uncover if a speciﬁc
vendor causes inconsistencies in a new model, it is not
logical to compare it with models from other vendors.
Rather, we should compare it with devices from the same
vendor. Besides, to avoid detecting a change caused by
OS version mismatches, the new model should be com-
pared to a model running the same OS version.

We designed ﬁve different algorithms that target to un-
cover meaningful inconsistencies. Speciﬁcally, by care-
fully going through each party within the customization
chain, we designed algorithms that would reveal incon-
sistencies (if any) caused by each party. Further, for each
algorithm, we select our candidate images based on spe-
ciﬁc criteria that serve the purpose of the algorithm,

We describe each algorithm as well as the sample se-

lection criteria in the next sections.
A1: Cross-Version Analysis. This analysis aims to
uncover any inconsistent security features caused by OS
version upgrades. We select candidate image sets run-
ning similar device models to make sure that the incon-
sistency is purely due to OS upgrade. For instance,we
would pick 2 Samsung S4 devices running 4.4.4 and
5.0.1 as a candidate image set, and would reveal if up-
grading this model from 4.4.4 to 5.0.1 causes any secu-
rity conﬁguration changes. Formally, let IMGMODEL de-
note the candidate image set as the following:

IMGMODEL ={img1,img2, ...,imgn}

such that imgi ∈ IMGMODEL if model(imgi) =MODEL

Based on our collected images, this algorithm generated
135 candidate image sets (count of distinct model).

Let f v( f ne,img) denote a value for a feature f ne in img ∈
IMGMODEL. We deﬁne the inconsistency condition under
Cross-Version analysis algorithm as follows,

CVersion( f ne) = ∃ x ∃ y [ x ∈ IMGMODEL ∧ y ∈ IMGMODEL

∧ x �= y∧ f v ( f ne ,x) �= f v ( f ne ,y)
∧ version(x) �= version(y)]

The above condition implies that f ne is inconsistent if
there exist two same model images running different ver-
sions, and where the values of f ne is not the same. Droid-
Diff runs the analysis for each of the 135 candidate sets
and generate the number of inconsistencies detected.
A2: Cross-Vendor Analysis. This analysis aims to re-
veal any feature f ne that is inconsistent across vendors.
To make sure that we are comparing images of similar
criteria across different vendors, we pick candidate im-
age sets running the same OS version (e.g. HTC M8 and

Nexus 6 both running 5.0.1). Our intuition here is that
if an inconsistency is detected, then the vendor is the re-
sponsible party. We formally deﬁne the candidate image
set as the following:

IMGVERSION ={img1,img2, ...,imgn}

such that imgi ∈ IMGV ERSION if version(imgi) = V ERSION
This algorithm generated 12 candidate image sets (count
of distinct OS versions that we collected).

Let f v( f ne,img) denote a value for a feature f ne in img
∈ IMGV ERSION. We redeﬁne the inconsistency condition
under Cross-Vendor analysis as follows:

CVendor( f ne) = ∃ x ∃ y [ x ∈ IMGV ERSION ∧ y ∈ IMGV ERSION

∧ x �= y∧ f v ( f ne ,x) �= f v ( f ne ,y)
∧ vendor(x) �= vendor(y)]

The last condition implies that f ne is inconsistent if there
exists two images from different vendors, but running the
same OS version, where its value is not equal.

A3: Cross-Model Analysis.
In this analysis, we want
to uncover any feature f ne that is inconsistent through
different models. For example, we want to compare the
conﬁgurations on Samsung S5 and Samsung S4 mod-
els, running the same OS versions. To ascertain that any
inconsistency is purely due to model change within the
same vendor, we pick our candidate image sets running
the same OS version, deﬁned as IMGVERSION in the previ-
ous example. We further make sure that we are compar-
ing models from the same vendor by adding a new check
in the next condition.

Let

f v( f ne,img) denote a value for

in img ∈
IMGV ERSION. We redeﬁne the inconsistency condition un-
der Cross-Model analysis as follows:

f ne

CModel ( f ne) = ∃ x ∃ y [ x ∈ IMGV ERSION ∧ y ∈ IMGV ERSION

∧ x �= y∧ f v ( f ne ,x) �= f v ( f ne ,y)
∧ vendor(x) =vendor (y) ∧ model(y) �= model(x)]
The last condition implies that f ne is inconsistent if there
exists two images from the same vendor, running the
same OS version, but customized for different models,
where its value is not equal.

A4: Cross-Carrier Analysis. We aim to uncover any
inconsistent security features f ne through different car-
riers (e.g., a MotoX from T-Mobile, versus another one
from Sprint). To make sure that we are comparing im-
ages running the same OS version, we pick our candi-
date image sets from IMGVERSION. We further make sure
that we are comparing images running the same model

USENIX Association  

25th USENIX Security Symposium  1159

as shown in the following inconsistency condition:

CCarrier( f ne) = ∃ x ∃ y [ x ∈ IMGV ERSION ∧ y ∈ IMGV ERSION

∧ x �= y∧ f v ( f ne ,x) �= f v ( f ne ,y)
∧ carrier(x) �= carrier(y) ∧ model(y) =model (x)]
The last conditions in the above deﬁnition of CCarrier
implies that f ne is inconsistent if there exists two images
running the same model and OS versions, but from dif-
ferent carriers where its value is not the same.
A5: Cross-Region Analysis. This analysis intends to
ﬁnd any inconsistencies in the conﬁguration of security
features f ne through different regions (e.g. LG G4, Ko-
rean edition versus US edition). Any inconsistencies de-
tected will be attributed to customizing a device for a
speciﬁc region. We pick our candidate image sets from
IMGVERSION to make sure that we are comparing images
running the same OS version. We deﬁne the inconsis-
tency count under Cross-Carrier analysis as follows:

CRegion( f ne) = ∃ x ∃ y [ x ∈ IMGV ERSION ∧ y ∈ IMGV ERSION

∧ x �= y∧ f v ( f ne ,x) �= f v ( f ne ,y)
∧ region(x) �= region(y) ∧ model(y) =model (x)]
The last conditions in the above deﬁnition of CRegion
implies that f ne is inconsistent if there exists two images
running the same model and OS versions, but from dif-
ferent regions where its value is not the same.

6 Results and Findings

We conduct a large-scale differential analysis on our col-
lected images using the aforementioned methodologies
with the help of DroidDiff. The analysis discovered a
large number of discrepancies with regards to our se-
lected features.
In this section, we present the results
and ﬁndings.

6.1 Overall Results
Figure 3 shows the overall changes detected from our
analysis. We plot the average percentage of inconsisten-
cies detected for each feature category using the ﬁve dif-
ferential analysis algorithms. To provide an estimate of
the inconsistencies count, each box plot shows an aver-
age number of total common entities (appearing on at
least 2 images) in the image sets studied; we depict this
number as # total in the graph. Let us use the ﬁrst box
plot as an example to illustrate what the data means: un-
der the Cross-Version analysis (A1), DroidDiff generated
on average 673 common permissions per each studied
candidate sets. 50% of the candidate image sets contain
at least 4.8% of total permissions (around 32 out of 673)

having inconsistent protection levels; those in the top 25
percentile (shown in the top whisker) have at least 6%
(40) inconsistent permissions. Figure 3 also depicts the
image sets that are outliers, i.e., they have particularly
higher number of inconsistencies compared to the other
image sets in the same group. For instance, the candi-
date image set IMGVersion=4.4.2 in the Cross-Vendor analy-
sis (A2) contains around 10% of GIDs whose protections
are inconsistent.

As depicted in Figure 3, the Cross-Version analysis
(A1) detects the highest percentage of inconsistencies in
all 5 categories, which means that upgrading the same
device model to a different OS version introduces the
highest security conﬁguration changes. An intuitive rea-
son behind this is that through a new OS release, Android
might enforce higher protections on the corresponding
entities to ﬁx some discovered bugs (e.g. adding a per-
mission requirement to a privileged service). However,
we found out that through newer OS releases, certain se-
curity features are actually downgraded, leading to po-
tential risks if done unintentionally. We discuss this ﬁnd-
ing in more details in Section 6.6.

Through the Cross-Vendor analysis (A2), DroidDiff
detects that several security features are inconsistent
among vendors, even though they are of the same OS ver-
sion. We have further analyzed the vendors that cause the
highest number of inconsistencies. An interesting obser-
vation is that smaller vendors, such as BLU, Xiaomi and
Digiland caused several risky inconsistencies.
In fact,
all inconsistent GIDs are caused by these 3 companies.
Probably, small vendors may not have enough expertises
to fully evaluate the security implications of their actions.
The Cross-Model analysis (A3) also detects a num-
ber of inconsistencies, which means that different de-
vice models from the same vendor and OS version, might
have different security conﬁgurations.

Although the Cross-Carrier (A4) and Cross-Region
(A5) analyses detect a smaller percentage of inconsis-
tencies, it is still signiﬁcant to know that the same device
model running the same OS version might have some
different conﬁgurations if it is customized for different
carriers or regions. Our results shows that the inconsis-
tencies are less common in North America region, and
more prevalent in Chinese editions.

6.2 Permissions Changes Pattern
Protection level mismatch. DroidDiff results conﬁrm
that Android permissions may hold different protection
levels across similar images. As Figure 3 illustrates,
more than 50% of the candidate image sets contain at
least 32 (out of 673), 9 (out of 817) permissions having
inconsistent protection levels in the Cross-Version (A1)
and Cross-Model (A3) analyses, respectively. To reveal

1160  25th USENIX Security Symposium 

USENIX Association

A1: Cross-Version, A2: Cross-Vendor, A3: Cross-Model, A4: Cross-Carrier, A5: Cross-Region

Figure 3: Overall Inconsistencies Detected

more insights, we checked which combination of protec-
tion level changes are the most common. That is, which
combination out of the following 3 possible combina-
tions is the most common (Normal, Dangerous), (Normal,
Signature) or (Dangerous, Signature). We have calcu-
lated the occurrence of each pattern, and present the re-
sults in Figure 4. As shown, (Normal, Signature) combi-
nation is the most common pattern. This is quite serious
as several permissions that hold a Signature protection
level on some images are deﬁned with a Normal protec-
tion level on others. We present here two permissions
holding inconsistent protection levels:

• com.orange.permission.SIMCARD_AUTHENTICATION
holds Signature and Normal protection on Sam-
sung S4(4.2.2) and Sony Experia C2105 (4.2.2),
respectively.

• com.sec.android.app.sysscope.permission.RUN_
SYSSCOPE holds Dangerous and Signature protec-
tion on Samsung Note4 (5.0.1) and S4(5.0.1).

Usage of unspeciﬁed protection level. Android allows
developers to deﬁne a permission without specifying a
protection level, in which case, the default protection
level is Normal.
In our investigation, we found that it
is not clear whether developers really intended to use
Normal as the protection level. We found that a large
percentage of these permissions (with unspeciﬁed pro-
tection level) hold conﬂicting protections on other im-
ages. Overall, 2% of the permissions studied were de-
ﬁned without a speciﬁed protection level in at least one
image. To check if developers intended to use Normal
as the protection level, for each permission that has been
deﬁned without a protection level, we check its corre-
sponding deﬁnitions on other images to see if it has a
protection level speciﬁed. We then compare the other
speciﬁcation to see it it is Normal or not. As Figure 5(a)
illustrates, on average, 91% of these permissions holding

(cid:13)(cid:16)(cid:1)

(cid:5)(cid:10)(cid:16)(cid:1)

(cid:5)(cid:7)(cid:16)(cid:1)

Vendor 

(cid:9)(cid:4)(cid:16)(cid:1)

(cid:8)(cid:5)(cid:16)(cid:1)

Model 

(cid:11)(cid:5)(cid:16)(cid:1)

(cid:5)(cid:11)(cid:16)(cid:1)

(cid:7)(cid:12)(cid:16)(cid:1)

Version 

(cid:8)(cid:9)(cid:16)(cid:1)

(cid:6)(cid:7)(cid:16)(cid:1)

(cid:5)(cid:8)(cid:16)(cid:1)

Carrier 

(cid:6)(cid:16)(cid:1)

(cid:6)(cid:7)(cid:16)(cid:1)

Region 

(cid:18)(cid:3)(cid:12)(cid:13)(cid:10)(cid:5)(cid:9)(cid:17)(cid:1)(cid:2)(cid:5)(cid:11)(cid:7)(cid:6)(cid:13)(cid:12)(cid:16)(cid:14)(cid:19)(cid:1)

(cid:18)(cid:3)(cid:12)(cid:13)(cid:10)(cid:5)(cid:9)(cid:17)(cid:1)(cid:4)(cid:8)(cid:7)(cid:11)(cid:5)(cid:15)(cid:16)(cid:13)(cid:6)(cid:19)(cid:1)

(cid:18)(cid:2)(cid:5)(cid:11)(cid:7)(cid:6)(cid:13)(cid:12)(cid:16)(cid:14)(cid:17)(cid:1)(cid:4)(cid:8)(cid:7)(cid:11)(cid:5)(cid:15)(cid:16)(cid:13)(cid:6)(cid:19)(cid:1)

(cid:10)(cid:7)(cid:16)(cid:1)

(cid:11)(cid:9)(cid:16)(cid:1)

Figure 4: Protection Level Changes Patterns

unspeciﬁed protection level hold a Signature protection
on at least 1 other image, which indicates that developers
probably intended to use the Signature protection level.
We illustrate this ﬁnding with 2 permissions:

• com.sec.android.phone.permission.UPDATE_

MUTE_STATUS holds Unspecified and Signature
protections on Samsung E7 (5.1.1) and S6
Edge(5.1.1), respectively.

• com.android.chrome.PRERENDER_URL

holds
Unspecified and Signature protections on LG
Vista (4.4.2) and Nexus7 (4.4.2), respectively.

6.3 Permission-GID Mapping
By analyzing the differential analysis results of the map-
pings between GIDs and permissions, we have con-
ﬁrmed that customization introduces problematic GID-
to-permission mappings that can lead to serious vul-
nerabilities in the victim images. Through the Cross-
Vendor analysis (A2), DroidDiff detects 3 inconsis-
tent cases (out of 25 common GIDs), in which ven-
dors mapped less privileged permissions to privileged
GIDs.
This dangerous pattern leads to downgrad-

USENIX Association  

25th USENIX Security Symposium  1161

(cid:3)(cid:8)(cid:1)
(cid:4)(cid:8)(cid:1)

(cid:5)(cid:2)(cid:8)(cid:1)

(cid:19)(cid:4)(cid:13)(cid:14)(cid:11)(cid:6)(cid:10)(cid:18)(cid:1)(cid:3)(cid:9)(cid:15)(cid:15)(cid:9)(cid:12)(cid:8)(cid:20)(cid:1)
(cid:19)(cid:2)(cid:6)(cid:12)(cid:8)(cid:7)(cid:14)(cid:13)(cid:17)(cid:15)(cid:18)(cid:1)(cid:3)(cid:9)(cid:15)(cid:15)(cid:9)(cid:12)(cid:8)(cid:20)(cid:1)
(cid:19)(cid:5)(cid:9)(cid:8)(cid:12)(cid:6)(cid:16)(cid:17)(cid:14)(cid:7)(cid:18)(cid:1)(cid:3)(cid:9)(cid:15)(cid:15)(cid:9)(cid:12)(cid:8)(cid:20)(cid:1)

(a) Unspeciﬁed Protection Level Change
Patterns

(cid:7)(cid:10)(cid:1)

(cid:5)(cid:3)(cid:10)(cid:1)

(cid:6)(cid:4)(cid:10)(cid:1)

(cid:2)(cid:7)(cid:8)(cid:11)(cid:7)(cid:6)(cid:1)
(cid:3)(cid:10)(cid:13)(cid:13)(cid:10)(cid:11)(cid:9)(cid:1)(cid:15)(cid:1)(cid:4)(cid:12)(cid:14)(cid:1)(cid:5)(cid:13)(cid:7)(cid:6)(cid:1)
(cid:3)(cid:10)(cid:13)(cid:13)(cid:10)(cid:11)(cid:9)(cid:1)(cid:15)(cid:1)(cid:5)(cid:13)(cid:7)(cid:6)(cid:1)

(cid:5)(cid:3)(cid:9)(cid:1)

(cid:4)(cid:3)(cid:9)(cid:1)

(cid:6)(cid:3)(cid:9)(cid:1)

(cid:4)(cid:19)(cid:18)(cid:21)(cid:10)(cid:8)(cid:22)(cid:18)(cid:17)(cid:1)(cid:5)(cid:10)(cid:16)(cid:18)(cid:24)(cid:7)(cid:15)(cid:1)

(cid:6)(cid:17)(cid:9)(cid:10)(cid:11)(cid:17)(cid:10)(cid:9)(cid:1)(cid:4)(cid:10)(cid:19)(cid:16)(cid:14)(cid:20)(cid:20)(cid:14)(cid:18)(cid:17)(cid:20)(cid:1)

(cid:4)(cid:10)(cid:19)(cid:16)(cid:14)(cid:20)(cid:20)(cid:14)(cid:18)(cid:17)(cid:1)(cid:3)(cid:10)(cid:24)(cid:10)(cid:15)(cid:1)(cid:2)(cid:13)(cid:7)(cid:17)(cid:12)(cid:10)(cid:1)

(b) Protected Broadcast Inconsisten-
cies
Figure 5: Inconsistency Breakdown

(c) Causes of Components Protection Mis-
match

ing the protection level of these GIDs. We illustrate
this ﬁnding with one detected example. On AOSP
images and several customized images (running 4.4.4
and below), camera GID is mapped to a Dangerous
level permission (android.permission.CAMERA). How-
ever, on Neo 4.5 (BLU), we found out
the
same GID is mapped to a Normal level permission:
android.permission.ACCESS_MTK_MMHW. This case indi-
cates that BLU has downgraded the requirement for apps
to obtain the camera GID. Our analysis reveals that the
requirements for two more GIDs, system GID and media
GID, have been downgraded. These two GIDs, protected
by a Signature permission on most devices, can be ac-
quired with a Normal permission on the victim devices.

that

6.4 Protected Broadcasts Changes Pattern

DroidDiff further reveals that protected broadcasts’ def-
initions might be removed from some images during the
customization process. As illustrated in Figure 5(b),
through the Cross-Version analysis (A1), we detected
that 70% of protected broadcast are not deﬁned on at
least one vendor. This might not necessarily be prob-
lematic if the broadcast is not used. However, our in-
vestigation shows that around 9% of these inconsistently
unprotected broadcasts (28 on average per image set) are
used as intent-ﬁlters actions for broadcast receivers. This
inconsistency across versions is quite alarming as a priv-
ileged receiver that was supposed to be invoked by sys-
tem processes can be invoked by any unprivileged app on
certain versions. As Figure 3 further illustrates, Cross-
Vendor (A2) and Cross-Model (A3) analyses reveal that
more than 25% of candidate image sets contain at least
2% broadcasts which are inconsistently protected, but
still being used as intent-ﬁlter actions.

6.5 Component Security Changes Pattern
Visibility mismatch. DroidDiff results conﬁrm that
app components may have a conﬂicting visibility. That
is, the component is exposed on one image but not on an-
other. As Figure 3 illustrates, 50% of the candidate im-
age sets contain at least 3.9% components (around 222)

and 2% (133) holding inconsistent visibility through var-
ious versions (A1) and models (A3), respectively. To
provide insights about which components hold more
visibility inconsistencies, we break down our ﬁndings
to activities, services, receivers, and content providers.
We plot the results in Figure 6. As depicted, content
providers and activities have the highest visibility mis-
match. In fact, 25% of the candidate image sets contain
at least 20% (53) and 14% (21) content providers hold-
ing a different visibility in different versions (A1) and
vendors (A2), respectively. Similarly, 4% (139) and 3%
(45) of activities hold a conﬂicting visibility in 50% of
the studied sets based on A1 and A2, respectively.

Permission mismatch. DroidDiff further reveals that
components may hold inconsistent protections across im-
ages. We break down our ﬁndings in Figure 8 (see ap-
pendix). Our results show that content providers ex-
hibit the highest number of protection inconsistencies. In
fact, more than 25% of the candidate images sets include
at least 19% (51) and 10% (33) content providers hav-
ing different protections in the Cross-Version (A1) and
Cross-Model (A3) analyses, respectively. We have fur-
ther analyzed these inconsistent components and catego-
rized the reason behind the discrepancies. As Figure 5(c)
illustrates, in the majority of the cases (60%), the dis-
crepancy is caused by the same component being pro-
tected with a permission on one image, but not protected
at all on others. The second common reason (30%) is that
the same component is protected with permissions hold-
ing different protection levels across the studied images.
Using non-deﬁned permissions to protect a component is
third common reason (10%).

Duplicate components declaration. Based on our
analysis of the inconsistent broadcast receivers (partic-
ularly high on Lollipop images), we found out that most
of them are caused by a non-safe practice that developers
follow. Developers declare duplicate broadcast receivers
names in the same app, but assign them different pro-
tections. After further investigation, we found out that
it is not a safe practice to do as it will be possible to
bypass any restrictions put on the ﬁrst deﬁned receiver.
To illustrate, consider the following receivers, deﬁned in
Samsung’s preloaded PhoneErrorService app:

1162  25th USENIX Security Symposium 

USENIX Association

Figure 6: Breaking Down Components: Visibility Mismatch

<receiver android:name="PhoneErrorReceiver"

android:permission="android.permission.REBOOT">

<intent-filter>

<action android:name="REFRESH_RESET_FAIL"/>
...

</intent-filter>

</receiver>
<receiver android:name="PhoneErrorReceiver">

<intent-filter>

<action

</intent-filter>

</receiver>

android:name="DATA_ROUTER_DISPLAY"/>

In the above code,

the developer decided to pro-
tect the functionality triggered when receiving the ac-
tion REFRESH_RESET_FAIL with the permission REBOOT
(Signature level).
In the other case, she decided not
to require any permissions when invoking the function-
ality triggered by the action DATA_ROUTER_DISPLAY. At
ﬁrst glance, the above duplicate components declaration
might look ﬁne. However, we found out that the Pack-
ageManagerService does not carefully handle the regis-
tration of duplicate receivers. On one hand, it correctly
handles mapping each ﬁlter to the required permission,
used for implicit intents routing (e.i., sending the action
REFRESH_RESET_FAIL requires REBOOT permission, while
sending DATA_ROUTER_DISPLAY does not require any per-
mission). On the other hand, however, it does not cor-
rectly map each component name to the required per-
mission, used for explicit intents routing (e.i., the ﬁrst
PhoneErrorReceiver should require REBOOT while the
second one should not). In fact, it turns out that the sec-
ond declaration of the component name replaces the ﬁrst
one. Thus, any protection requirement on the second re-
ceiver would replace the ﬁrst receiver’s permission re-
quirement in case of explicit invocation. Consequently, in
the above example, invoking PhoneErrorReceiver ex-
plicitly does not require any permission. The explicit in-

(cid:33)(cid:32)(cid:32)(cid:44)(cid:1)

(cid:40)(cid:32)(cid:44)(cid:1)

(cid:38)(cid:32)(cid:44)(cid:1)

(cid:36)(cid:32)(cid:44)(cid:1)

(cid:34)(cid:32)(cid:44)(cid:1)

(cid:32)(cid:44)(cid:1)

(cid:39)(cid:40)(cid:29)(cid:33)(cid:40)(cid:1)

(cid:39)(cid:34)(cid:29)(cid:35)(cid:34)(cid:1)

(cid:34)(cid:33)(cid:29)(cid:40)(cid:34)(cid:1)

(cid:34)(cid:39)(cid:29)(cid:38)(cid:40)(cid:1)

(cid:38)(cid:33)(cid:29)(cid:38)(cid:41)(cid:1)

(cid:35)(cid:40)(cid:29)(cid:35)(cid:33)(cid:1)

(cid:36)(cid:39)(cid:29)(cid:32)(cid:33)(cid:1)

(cid:37)(cid:34)(cid:29)(cid:41)(cid:41)(cid:1)

(cid:44)(cid:5)(cid:23)(cid:14)(cid:12)(cid:21)(cid:22)(cid:1)

(cid:44)(cid:4)(cid:19)(cid:26)(cid:18)(cid:13)(cid:21)(cid:8)(cid:11)(cid:12)(cid:1)

(cid:6)(cid:12)(cid:21)(cid:17)(cid:15)(cid:22)(cid:22)(cid:15)(cid:19)(cid:18)(cid:1)

(cid:6)(cid:21)(cid:19)(cid:23)(cid:12)(cid:10)(cid:23)(cid:12)(cid:11)(cid:1)
(cid:2)(cid:21)(cid:19)(cid:8)(cid:11)(cid:10)(cid:8)(cid:22)(cid:23)(cid:1)

(cid:3)(cid:19)(cid:17)(cid:20)(cid:19)(cid:18)(cid:12)(cid:18)(cid:23)(cid:1)

(cid:7)(cid:15)(cid:22)(cid:15)(cid:9)(cid:15)(cid:16)(cid:15)(cid:23)(cid:27)(cid:1)

(cid:3)(cid:19)(cid:17)(cid:20)(cid:19)(cid:18)(cid:12)(cid:18)(cid:23)(cid:1)
(cid:6)(cid:21)(cid:19)(cid:23)(cid:12)(cid:10)(cid:24)(cid:19)(cid:18)(cid:1)

Figure 7: Percentage of Security Features Downgrades

tent can further set the action REFRESH_RESET_FAIL and
thus trigger the privileged functionality (rebooting the
phone) without the required REBOOT permission. We have
conﬁrmed this dangerous pattern in several preloaded
apps and were able to achieve various damages. We ﬁled
a bug report about this discovered vulnerability to An-
droid Security team and informed other vendors about it.

6.6 Downgrades Through Version Analysis

A dangerous pattern that we are interested in is whether
there are any security downgrades through versions. For
example, unlike a security conﬁguration upgrade, possi-
bly attributed to ﬁxing discovered bugs in earlier images,
downgrading a security conﬁguration is quite dangerous
as it will lead to a potential exposure of privileged re-
sources that were already secured on previous versions.
For each security conﬁguration, we report in Figure 7,
the percentage of security conﬁguration downgrades out
of all detected cases. As Figure 7 illustrates, a large num-
ber of conﬁgurations are indeed downgraded. For exam-
ple, 52% of inconsistent component protection mismatch
are actually caused by downgrading the protection.

USENIX Association  

25th USENIX Security Symposium  1163

7 Attacks

We would like to ﬁnd out whether the risky patterns dis-
covered can actually lead to actual vulnerabilities. To do
that, we have selected some high impact cases, and tried
to design attacks to verify whether these cases can be-
come vulnerabilities. Due to resources limitations, our
veriﬁcation is driven by the test devices that we have,
including Samsung Edge 6 Plus (5.1.1), Edge 6 (5.0.1),
Nexus 6 (5.1.1), Note2 (4.4.2), Samsung S4 (5.0.1), Mo-
toX (5.0.1), BLU Neo4 (4.2.2), and Digiland DL700D
(4.4.0). We have found 10 actual attacks, some of which
were conﬁrmed on several devices. We have ﬁled secu-
rity reports for the conﬁrmed vulnerabilities to the corre-
sponding vendors. We discuss here 6 attacks. At the end
of this section, we discuss possible impacts of 40 ran-
domly selected cases in other devices to demonstrate the
signiﬁcance of inconsistent security conﬁgurations.

Stealing emails. SecEmailSync.apk is a preloaded app
on most Samsung devices. It includes a content provider,
called "com.samsung.android.email.otherprovider",
which maintains a copy of user’s emails received
through the default Samsung email app. Our Cross-
Model and Cross-Region analyses reveal inconsistent
permission protections on this provider among several
Samsung images. The Read and Write accesses to this
provider are protected with a Signature permission
"com.samsung.android.email.permission.ACCESS_
PROVIDER" on Samsung Grand On(5.1.1, India), S6
Edge (5.1.1, UAE), and other devices. However, this
provider is not protected with any permission on several
other devices such as our test device S6 Edge (5.1.1,
Global edition). We wrote an attack app that queries
this content provider. It was able to access user’s private
emails on the victim device without any permission.

Forging premium SMS messages. The TeleService
package (com.android.phone) is preloaded on many
Samsung devices, and provides several services for
phone and calls management. A notable service is
.TPhoneService, which performs some major phone
functionalities such as accepting voice and video calls,
dialing new phone numbers, sending messages (e.g.
to inform why a call cannot be received), as well as
recording voice and video calls. Our Cross-Model and
Cross-Version analyses reveal a permission mismatch
on this critical service. On several devices, such as
Samsung S5 LTE-A (4.4.2, Korea), the access to this
service is protected with the Signature permission
com.skt.prod.permission.OEM_PHONE_SERVICE,
which makes
party apps.
such Samsung Note 2 (4.4.2, Global
this

the
to third-
However, on several other devices
edition),
service is protected with another permission

service unaccessible

app

functionalities

It

factory

reset. The

this critical broadcast

receiver.

ServiceModeApp_FB.apk

includes a broadcast
that

preloaded
per-
related to sensitive
receiver
listens
intent ﬁlters including the action ﬁlter

com.skt.prod.permission.PHONE_SERVICE for which
our analysis reveals a missing deﬁnition. We built an
attack app that deﬁnes the missing permission with
a Normal protection level. Our app was able to suc-
cessfully bind to com.android.phone.TPhoneService
and invoke the send-message API on Samsung Note 2,
allowing to forge SMS messages without the usually
required SEND_SMS.
Unauthorized
Samsung
forms various
phone settings.
ServiceModeAppBroadcastReceiver
to several
com.samsung.intent.action.SEC_FACTORY_RESET_
WITHOUT_FACTORY_UI that allows to factory reset the
phone and delete all data without user conﬁrma-
tion. Our Cross-Version analysis reveals a protection
In
mismatch for
most devices running Kitkat and below,
this re-
ceiver
is protected with the Signature permission
com.sec.android.app.servicemodeapp.permission.
KEYSTRING. However, on several Lollipop images, it is
not correctly protected. Further investigation reveals that
this is caused by the duplicate receiver pattern discussed
in Section 6.5. The declaration of the receiver has
been duplicated on the victim images such that the ﬁrst
one requires a Signature permission while the second
one does not. As discussed in Section 6.5, using this
risky pattern allows a caller app to bypass any restric-
tions on the ﬁrst declared broadcast receivers through
explicit invocation. We wrote an attacking app that
invokes the broadcast receiver explicitly with the action
com.samsung.intent.action.SEC_FACTORY_RESET_
WITHOUT_FACTORY_UI and were able to factory reset
several victim devices including the latest S6 Edge Plus
5.1.1, S6 Edge 5.0.1, and S4 5.0.1.
Accessing critical drivers with a normal per-
mission. Our Cross-Vendor
a
the system GID.
critical protection downgrade of
On some images,
such as Samsung S5 (4.4.2),
this GID is mapped to the Signature permission
com.qualcomm.permission.IZAT. Nevertheless,
on
other images (e.g., Redmi Note 4.4.2 and Digiland
DL700D 4.4.0), this GID is mapped to a Normal level
android.permission.ACCESS_MTK_MMHW,
permission
indicating that any third-party app can easily get the
system GID. Table 4 lists the device drivers that are
accessible via the system GID on the Digiland DL700D
Tablet. These are privileged drivers, but they can now be
accessible to normal apps.
Triggering emergency broadcasts without permis-
sion. CellBroadcastReceiver is a preloaded Google

analysis

reveals

1164  25th USENIX Security Symposium 

USENIX Association

Table 4: Drivers accessible to System GID

Driver

bootimg; devmap; mtk_disp; pro_info; preloader; recovery
pro_info; devmap; dkb; gps; gsensor; hdmitx; hwmsensor;
kb; logo; misc; misc-sd; nvram; rtc0; sec; seccfg ; stpwmt

touch; ttyMT2 ; wmtWiﬁ; wmtdetect

cpuctl

ACL
r –

rw-

r-x

analyses
this

discovered

a

receiver

among

PrivilegedCellBroadcastReceiver

several
For instance, on Nexus S 4G 4.1.1,

functionalities based on
app that performs critical
It registers the broadcast
received cell broadcasts.
receiver
that
allows receiving emergency broadcasts from the cell
providers (e.g., evacuation alerts, presidential alerts,
amber alerts, etc.) and displaying corresponding alerts.
This critical functionality can be triggered if the ac-
tion
android.provider.Telephony.SMS_EMERGENCY_
CB_RECEIVED is received.
Our Cross-Vendor and
protection
Cross-Version
de-
mismatch
on
vices.
this
receiver is protected with the Signature permission
android.permission.BROADCAST_SMS. However,
on
other devices (e.g., Nexus6 5.1.1 and MotoX XT1095
it
5.0.1),
is protected with the Dangerous permis-
android.permission.READ_PHONE_STATE. Our
sion
investigation reveals that this is also due to the du-
plicate receivers risky pattern (Section 6.5). On the
victim devices,
PrivilegedCellBroadcastReceiver
has been declared twice such that its ﬁrst declaration
requires a Signature permission and handles the action
android.provider.Telephony.SMS_EMERGENCY_CB
_RECEIVED, while the second declaration handles less
privileged actions and requires a Dangerous permission.
As discussed, any third-party app can bypass the permis-
sion requirement on the ﬁrst receiver through explicit
invocation. We wrote an attack app that was able to
trigger this receiver and show various emergency alerts.

Tampering with system wide settings. SystemUI is a
preloaded app that controls system windows. It handles
and draws a lot of system UIs such as top status bar,
system notiﬁcation and dialogs. To manage the top status
bar, the custom Samsung SystemUI includes a service
com.android.systemui.PhoneSettingService, which
handles incoming requests to turn on/off a variety of sys-
tem wide settings appearing on the top status bar. These
settings include turning on/off wiﬁ, bluetooth, location,
mobile data, nfc, driving mode, etc; that are usually done
with user consent. Our analysis shows a protection mis-
match for this service. On S5(4.4.2) and Note8(4.4.2),
this service is protected with a signature permission
com.sec.phonesettingservice.permission.PHONE_
SETTING, while on Note 2, 4.4.2,
the service is not
protected with any permission. We wrote an attack app

that successfully asks the privileged service to turn on
all the settings mentioned above without any permission.
Other Randomly Selected Cases. The impact of in-
consistent security conﬁgurations are signiﬁcant. In ad-
dition to end-to-end attacks we built, we also randomly
sampled 40 inconsistencies and manually analyzed what
could happen once they were exploited. Note that due to
the lack of physical devices, all we could do is just static
analysis to infer possible consequences once an exploit
succeeds. Such an analysis may not be accurate, but it is
still important for understanding the impacts of inconsis-
tent security conﬁgurations. The outcomes of our analy-
sis are shown in Table 5. Please note that we could not
assess the impact in 5 cases (heavily obfuscated code),
while we conﬁrmed that 2 cases have been hardened via
runtime checks.

8 Limitations

In this section, we discuss some limitations of our pro-
posed approach.

Components
implementation changes. A static
change of a component’s security conﬁgurations (vis-
ibility or permission protection) might not necessarily
indicate a security risk all the time. In fact, a developer
might intentionally decide to export a component or down-
grade its permission protection in the following cases:
the component’s operations or supplied data are not priv-
ileged anymore or the component’s implementation is
hardened via runtime checks of the caller’s identity (e.g.,
binder.getCallingUid() or Context.checkPermission()
APIs). Our solution pinpoints these possibly unintentional
risky conﬁgurations changes and demands
further
investigation to conﬁrm whether the change was indeed
intentional or not.

Components renaming. Our approach would miss de-
tecting inconsistent conﬁgurations of components which
have been renamed during the customization.
In fact,
as Android relies heavily on implicit intents for inter-app
communication, vendors might rename their components
to reﬂect their organization identity.

9 Related Work
Security risks in Android customization. The exten-
sive Android vendor customization have been proven to
be problematic in prior studies. At the Kernel level, AD-
DICTED [29] ﬁnds under-protected Linux device drivers
on customized ROMs by comparing them with their
counterparts on AOSP images. Our ﬁnding on inconsis-
tent GID to permission mappings demonstrates another

USENIX Association  

25th USENIX Security Symposium  1165

Table 5: Impact of Inconsistent Security Conﬁgurations

Inconsistent Conﬁguration Category

Permission Protection Change
Removed Protected Broadcasts

Impact

Change System / App Wide Settings

Trigger Dangerous Operations and events

Non-Protected Content Providers

Non-Protected Content Providers

Data Pollution

Data Leaks

Non-Protected Services
Non-Protected Activities
Non-Protected Receivers

Trigger Dangerous Operations
Change System wide Settings
Trigger Dangerous Operations

Speciﬁc Examples

Xiaomi Cloud Settings, Activate SIM

Trigger data sync, SMS received
Airplane mode active, SIM is full
Write to system logs, Add contacts

Change instant messaging conﬁgurations

Read emails, Read contacts
Read blocked contact lists

Access Location, Bind to printing services

Kill speciﬁc apps, Trigger backup

Change Telephony settings, Access hidden activities

Send SMS messages, Trigger fake alerts

Alter telephony settings , Issue SIM commands

way that can expose critical device drivers. At the frame-
work/ app level, Harehunter [5] reveals the Hanging At-
tributes References (Hares) vulnerability caused by the
under-regulated Android customization. The Hare vul-
nerability happens when an attribute is used on a device
but the party deﬁning it has been removed. A malicious
app can then ﬁll the gap to acquire critical capabilities,
by simply disguising as the owner of the attribute. Previ-
ous works [13, 14, 25] have also highlighted security is-
sues in the permission and components AC in preloaded
apps. Gallo et al
[13] analyzed ﬁve different devices
and concluded that serious security issues such as poorer
permission control grow sharply with the level of cus-
tomization. Other prominent work [25] analyzes the
pre-installed apps on 10 factory images and reports the
presence of known problems such as over-privilege [11],
permission re-delegation [12], etc. Our study is fun-
damentally different from the above work [25] which
ﬁnds speciﬁc known vulnerabilities on a customized im-
age through conducting a reachability analysis from an
open entry point to privileged sinks. Instead, we lever-
age a differential analysis to point out inconsistencies in
components’ protection, and consequently detect unin-
tentionally exposed ones. Our analysis further gives in-
sights about possible reasons behind the exposure.

Demystiﬁcation of Android security conﬁgurations.
The high ﬂexibility of Android’s security architecture de-
mands a complete understanding of conﬁgurable security
parameters. Stowaway [11] and PScout [7] lead the way
by mapping individual APIs to the required permission.
Understanding these parameters provides the necessary
domain knowledge in our feature selection. This under-
standing has inspired other researchers to detect vulner-
abilities in apps. The prevalence of misconﬁgured con-
tent providers, activities and services is studied in [30, 8],
respectively. These vulnerabilities are due to develop-
ers’ exposing critical components or misinterpreting An-
droid’s security protection. Instead of focusing on ana-
lyzing an individual app to ﬁnd if it is vulnerable, our
approach learns from the conﬁgurations of the same app
on other ROMs to deduct if it should be protected or not.

Android vulnerability analysis. Prior research has
also uncovered security issues rooted in non-customized
AOSP images. PileUp [26] brings to attention the prob-
lematic Android upgrading process. Two recent stud-
ies examine the crypto misuse in Android apps [9, 16].
Other works evaluate the security risks resulting from
design ﬂaws in the push-cloud messaging [18], in the
multi-user architecture [24], in Android app uninstalla-
tion process [28] and in Android’s Clipboard and shar-
ing mechanism [10]. Other researchers
[20, 15] fo-
cused on uncovering vulnerabilities within speciﬁc An-
droid apps in the web landscape. These vulnerabili-
ties are complementary to the security issues detected
in vendor customization, and jointly present a more
complete picture of Android ecosystem’s security land-
scape. To analyze Android vulnerabilities, static and
dynamic analysis techniques have been proposed to ad-
dress the special characteristics of Android platform.
CHEX [19], Epicc [21], and FlowDroid [6] apply static
analysis to perform vulnerability analysis. Other works
[23, 22, 17, 27] employ dynamic analysis to accurately
understand app’s behaviors. Both techniques are bene-
ﬁcial to our research. Dynamic analysis can help us ex-
ploit the likely risky inconsistencies, while static analysis
can bring the control/data ﬂow of framework/ app code
as another security feature into our differential analysis.
We will explore these ideas in future work.

10 Conclusion

In this paper, we make the ﬁrst attempt to systematically
detect security conﬁguration changes introduced by An-
droid customization. We list the security features applied
at various Android layers and leverage differential analy-
sis among a large set of custom ROMs to ﬁnd out if they
are consistent across all of them. By comparing security
conﬁgurations of similar images (from the same vendor,
running the same OS version, etc.), we can ﬁnd critical
security changes that might have been unintentionally in-
troduced during the customization. Our analysis shows
that indeed, customization parties change several conﬁg-

1166  25th USENIX Security Symposium 

USENIX Association

urations that can lead to severe vulnerabilities such as
private data exposure and privilege escalation.

11 Acknowledgement

We would like to thank our anonymous reviewers for
their insightful comments. This project was supported
in part by the NSF grant 1318814.

References
[1] Android Revolution. http://goo.gl/MVigfq.

[2] Factory Images for Nexus Devices.

i0RJnN.

https://goo.gl/

[3] Huawei ROMs. http://goo.gl/dYPTE5.

[4] Samsung Updates. http://goo.gl/RVU84V.

[5] AAFER, Y., ZHANG, N., ZHANG, Z., ZHANG, X., CHEN, K.,
WANG, X., ZHOU, X., DU, W., AND GRACE, M. Hare hunting
in the wild android: A study on the threat of hanging attribute
references. In Proceedings of the 22Nd ACM SIGSAC Conference
on Computer and Communications Security (2015), CCS ’15.

[6] ARZT, S., RASTHOFER, S., FRITZ, C., BODDEN, E., BARTEL,
A., KLEIN, J., LE TRAON, Y., OCTEAU, D., AND MCDANIEL,
P. Flowdroid: Precise context, ﬂow, ﬁeld, object-sensitive and
lifecycle-aware taint analysis for android apps. PLDI ’14.

[7] AU, K. W. Y., ZHOU, Y. F., HUANG, Z., AND LIE, D. Pscout:
Analyzing the android permission speciﬁcation. In Proceedings
of the 2012 ACM Conference on Computer and Communications
Security (New York, NY, USA, 2012), CCS ’12, ACM.

[8] CHIN, E., FELT, A. P., GREENWOOD, K., AND WAGNER, D.
Analyzing inter-application communication in android. In Pro-
ceedings of the 9th International Conference on Mobile Systems,
Applications, and Services (2011), MobiSys ’11, ACM.

[9] EGELE, M., BRUMLEY, D., FRATANTONIO, Y., AND
KRUEGEL, C. An empirical study of cryptographic misuse in an-
droid applications. In Proceedings of the 2013 ACM SIGSAC con-
ference on Computer & communications security (2013), ACM.

[10] FAHL, S., HARBACH, M., OLTROGGE, M., MUDERS, T., AND
SMITH, M. Hey, you, get off of my clipboard. In In proceeding
of 17th International Conference on Financial Cryptography and
Data Security (2013).

[11] FELT, A. P., CHIN, E., HANNA, S., SONG, D., AND WAG-
NER, D. Android permissions demystiﬁed. In Proceedings of the
18th ACM conference on Computer and communications security
(New York, NY, USA, 2011), CCS ’11, ACM.

[12] FELT, A. P., WANG, H. J., MOSHCHUK, A., HANNA, S., AND
In

CHIN, E. Permission re-delegation: Attacks and defenses.
Proceedings of the 20th USENIX Security Symposium (2011).

[13] GALLO, R., HONGO, P., DAHAB, R., NAVARRO, L. C.,
KAWAKAMI, H., GALVÃO, K., JUNQUEIRA, G., AND RIBEIRO,
L. Security and system architecture: Comparison of android cus-
tomizations. In Proceedings of the 8th ACM Conference on Se-
curity & Privacy in Wireless and Mobile Networks (2015).

[14] GRACE, M., ZHOU, Y., WANG, Z., AND JIANG, X. Systematic
detection of capability leaks in stock Android smartphones. In
Proceedings of the 19th Network and Distributed System Security
Symposium (NDSS) (Feb. 2012).

[15] JIN, X., HU, X., YING, K., DU, W., YIN, H., AND PERI, G. N.
Code injection attacks on html5-based mobile apps: Characteri-
zation, detection and mitigation. In Proceedings of the 2014 ACM
SIGSAC Conference on Computer and Communications Security
(New York, NY, USA), CCS ’14, ACM.

[16] KIM, S. H., HAN, D., AND LEE, D. H. Predictability of android
openssl’s pseudo random number generator.
In Proceedings of
the 2013 ACM SIGSAC Conference on Computer and Communi-
cations Security (New York, NY, USA, 2013), CCS ’13, ACM.

[17] KLIEBER, W., FLYNN, L., BHOSALE, A., JIA, L., AND
BAUER, L. Android taint ﬂow analysis for app sets.
In Pro-
ceedings of the 3rd ACM SIGPLAN International Workshop on
the State of the Art in Java Program Analysis (2014), SOAP ’14.
[18] LI, T., ZHOU, X., XING, L., LEE, Y., NAVEED, M., WANG,
X., AND HAN, X. Mayhem in the push clouds: Understanding
and mitigating security hazards in mobile push-messaging ser-
vices. In Proceedings of the 2014 ACM SIGSAC Conference on
Computer and Communications Security (2014), CCS ’14, ACM.
[19] LU, L., LI, Z., WU, Z., LEE, W., AND JIANG, G. Chex: stat-
ically vetting android apps for component hijacking vulnerabili-
ties. In Proceedings of the 2012 ACM conference on Computer
and communications security (2012), CCS ’12.

[20] LUO, T., HAO, H., DU, W., WANG, Y., AND YIN, H. Attacks

on webview in the android system. ACSAC ’11.

[21] OCTEAU, D., MCDANIEL, P., JHA, S., BARTEL, A., BODDEN,
E., KLEIN, J., AND LE TRAON, Y. Effective inter-component
communication mapping in android with epicc: An essential step
towards holistic security analysis.
In Proceedings of the 22Nd
USENIX Conference on Security (2013), SEC’13.

[22] POEPLAU, S., FRATANTONIO, Y., BIANCHI, A., KRUEGEL, C.,
AND VIGNA, G. Execute This! Analyzing Unsafe and Malicious
Dynamic Code Loading in Android Applications. NDSS 14’.

[23] RASTOGI, V., CHEN, Y., AND ENCK, W. Appsplayground: Au-
tomatic security analysis of smartphone applications. In Proceed-
ings of the Third ACM Conference on Data and Application Se-
curity and Privacy (New York, NY, USA, 2013), CODASPY ’13.
[24] RATAZZI, P., AAFER, Y., AHLAWAT, A., HAO, H., WANG,
Y., AND DU, W. A systematic security evaluation of Android’s
multi-user framework. In Mobile Security Technologies (MoST)
2014 (San Jose, CA, USA, 2014), MoST’14.

[25] WU, L., GRACE, M., ZHOU, Y., WU, C., AND JIANG, X. The
impact of vendor customizations on android security. In Proceed-
ings of the 2013 ACM SIGSAC conference on Computer commu-
nications security (New York, NY, USA, 2013), CCS ’13, ACM.
[26] XING, L., PAN, X., WANG, R., YUAN, K., AND WANG, X.
Upgrading your android, elevating my malware: Privilege esca-
lation through mobile os updating. In Proceedings of the 2014
IEEE Symposium on Security and Privacy (2014), SP ’14.

[27] YAN, L. K., AND YIN, H. Droidscope: seamlessly reconstruct-
ing the os and dalvik semantic views for dynamic android mal-
ware analysis. In Proceedings of the 21st USENIX conference on
Security symposium (2012), Security’12.

[28] ZHANG, X., YING, K., AAFER, Y., QIU, Z., AND DU, W. Life
after app uninstallation: Are the data still alive? data residue
attacks on android. In NDSS (2016).

[29] ZHOU, X., LEE, Y., ZHANG, N., NAVEED, M., AND WANG, X.
The peril of fragmentation: Security hazards in android device
driver customizations. In 2014 IEEE Symposium on Security and
Privacy, SP 2014, Berkeley, CA, USA.

[30] ZHOU, Y., AND JIANG, X. Detecting passive content leaks and

pollution in android applications. In NDSS (2013).

USENIX Association  

25th USENIX Security Symposium  1167

12 Appendix

Figure 8: Components Protection Mismatch Breakdown

1168  25th USENIX Security Symposium 

USENIX Association

