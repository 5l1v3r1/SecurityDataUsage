Leakage-Abuse Attacks Against Searchable Encryption

David Cash

Rutgers University

110 Frelinghuysen Road

Piscataway, NJ 08854

david.cash@cs.rutgers.edu

∗

Jason Perry
Lewis University

One University Parkway

Romeoville, IL 60446

perryjn@lewisu.edu

Paul Grubbs

Skyhigh Networks Inc. & Cornell University

Ithaca, NY 14853

paul@skyhighnetworks.com

Thomas Ristenpart

Cornell Tech

111 8th Avenue #302
New York, NY 10011

ristenpart@cornell.edu

ABSTRACT

Schemes for secure outsourcing of client data with search capabil-
ity are being increasingly marketed and deployed.
In the litera-
ture, schemes for accomplishing this efﬁciently are called Search-
able Encryption (SE). They achieve high efﬁciency with provable
security by means of a quantiﬁable leakage proﬁle. However, the
degree to which SE leakage can be exploited by an adversary is not
well understood.

To address this, we present a characterization of the leakage pro-
ﬁles of in-the-wild searchable encryption products and SE schemes
in the literature, and present attack models based on an adversar-
ial server’s prior knowledge. Then we empirically investigate the
security of searchable encryption by providing query recovery and
plaintext recovery attacks that exploit these leakage proﬁles. We
term these leakage-abuse attacks and demonstrate their effective-
ness for varying leakage proﬁles and levels of server knowledge,
for realistic scenarios. Amongst our contributions are realistic ac-
tive attacks which have not been previously explored.

Keywords

Searchable encryption; leakage

1.

INTRODUCTION

Encryption protects data stored at an untrusted service provider,
but introduces complications. Amongst these, the service provider
is unable to process the encrypted data as freely and efﬁciently
as it can plaintext data, making access cumbersome for the data
owner. To address the difﬁculty of retrieving encrypted text ef-
ﬁciently, increasingly practitioners turn to searchable encryption
(SE) schemes, ﬁrst introduced by Song, Wagner, and Perrig [18].
An SE scheme encrypts a set of documents in a way that allows

∗Work completed while at Rutgers University.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
c(cid:13) 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813700.

the data owner to delegate search capabilities to the provider with-
out decrypting the documents. For example, using SE, a user may
encrypt her email, store it at the remote provider, and later have
the provider fulﬁll keyword search queries. If the SE scheme is
dynamic, then she will also be able to add encrypted documents
efﬁciently [11].

Many SE constructions can be implemented using only symmet-
ric cryptography, and some are even legacy-compatible, requiring
no modiﬁcation at the provider. A commonly deployed example of
the latter, and one suggested in recent research papers [8, 14], is to
append to a conventional encryption of the document a sequence of
outputs of a secret-keyed pseudorandom function (PRF) on individ-
ual keywords. Search is performed by submitting the PRF output
of the desired search term, and documents can easily be added or
removed.

All efﬁcient SE constructions expose some information, called
leakage, about the plaintext to the service provider. Typically, SE
schemes allow the provider to learn about the underlying data by
observing statistics like the number and frequency of encrypted
documents accessed during searches. Song et al. recommended pe-
riodic re-encryption to address what they call statistical attacks, but
did not investigate this further. Islam, Kuzu, and Kantarcioglu [9]
(IKK) initiated the study of the empirical security of SE by show-
ing that a user’s keyword search queries can be guessed with high
accuracy when used on a dataset known to an honest-but-curious
service provider. Their attacks, and the more general statistical at-
tacks alluded to by Song et al., are possible even when a scheme has
been proven secure under a standard assumption. In other words,
the attacks are permitted by the security deﬁnition.

The risk posed by leakage has not been closely scrutinized be-
yond the work of IKK. The current literature leaves a practitioner
with few concrete recommendations for conﬁguring and deploying
SE. The risk is not merely abstract; several deployments of SE may
be easily broken depending on how they are used.

Our contributions. The present paper studies the leakage of SE
in order to understand its practical security. We consider a range
of threats including IKK’s query-identiﬁcation setting, and against
various approaches to building SE. We enumerate new threat mod-
els that describe attacks against suggested SE use-cases, such as
encrypted email, and explore the efﬁcacy of several attacks against
different constructions of SE. In each case, we design attacks that
exploit the leakage rather than any particular construction. We term
these leakage abuse attacks (LAAs), and explore several LAAs

668Objective

Prior Knowledge

Pas/Act

Min Leakage Known Constructions

Where

Query Recovery
Query Recovery

Plaintext Recovery
Plaintext Recovery
Plaintext Recovery

Fully Known Docs

Partially Known Docs

Known Doc Subset

Passive
Passive
Passive

Distributional
Distributional

Chosen Doc
Chosen Doc

L1
L1
L3
L3
L2

All
All
–
–

Shadowcrypt, Mimesis

[9], § 4.2

§ 4.3
§ 5.1
§ 5.2
§ 5.2

Figure 1: Summary of successful leakage-abuse attacks on searchable encryption schemes. In all cases the adversary sees the
transcript of communications to the server, in addition having the indicated knowledge and, in the last two cases, the ability to mount
active chosen document attacks. Leakage levels L1, L2, and L3 are ordered in increasing amount of leakage; see § 2.

against leakage proﬁles for constructions that are found in the liter-
ature and deployed in practice.

New threat models. We investigate a range of threat models for
SE. In terms of adversarial goals, we focus on search query recov-
ery, following IKK, as well as attacks that may perform (partial)
plaintext recovery. The latter has not before been looked at despite
an intuitive relationship with query recovery (as queries are by def-
inition part of the plaintext) and the fact that such attacks are likely
to be more damaging in practice. For each of these adversarial
goals, we also explore a number of adversarial capability models,
for example the kind of partial information about the document set
known to attackers and whether they can insert chosen documents.

Broader treatment of SE. This work considers a range of SE ap-
proaches, including schemes that leak more information to servers
than the academic schemes that followed from the early SE works [6,
19]. Weaker schemes are used in practice due to their simplicity
and compatibility with legacy servers, and have also been suggested
for use in a number of recent research systems as well [8, 14]. The
essential intuitive difference in leakage is that they leak informa-
tion to the server even before a search is issued, while the more
advanced schemes hide almost all information about plaintexts un-
til keyword searches begin. In the body we make this precise by
deﬁning a series of leakage levels L1–L4, where L1 is the least
amount of leakage corresponding to the Curtmola et al. security
notion, L2 leaks all the information of L1 and more, and so on with
L4 the most leaky.

Query recovery attacks. We build leakage-abuse attacks against
a variety of leakage models. As mentioned, LAA attacks work
against any scheme admitting the targeted amount of leakage (or
more). We perform experiments using public email data sets as
stand-ins for conﬁdential emails. For a summary of the attack re-
sults in this paper, see the table in Figure 1.

We ﬁrst revisit the query recovery attack setting of IKK in which
the adversary knows the entire plaintext document set and we target
L1 leakage, the hardest setting. We emphasize that while knowing
all the plaintexts exactly does not seem very realistic, such knowl-
edge does not make query recovery trivial and IKK uses a relatively
complex attack that uses simulated annealing to attempt to match
queries with keywords based on the pattern of which documents are
returned. We give a signiﬁcantly simpler, faster, and more accurate
attack that we call the count attack. The observation is that a large
fraction of keywords will match against a unique number of docu-
ments, and so an adversary in the IKK setting can simply count the
number of documents returned by each keyword and compare to
the number of documents matched by a query. When multiple key-
words return the same number of documents, one can disambiguate
using the pattern of keywords across returned documents.

It seems unlikely that adversaries in practice will know all doc-
uments. On the other hand, assuming knowledge of no documents
is a step too far: the adversary may incidentally know that a user
has one or more widely-circulated emails in her repository, for ex-

ample. We explore relaxing the assumption of full document set
knowledge to partial knowledge, and show that the IKK attack does
not perform well even when just a small fraction of documents are
unknown to the attacker; our count attack’s efﬁcacy degrades as
well but not so severely. We also explore whether an obvious po-
tential countermeasure to the count attack, padding out the number
of documents returned for queries, bears fruit: unfortunately our
experiments indicate that at least a 1.6x increase in index size is
needed to prevent our attack.

Partial plaintext recovery attacks. We also explore, for the ﬁrst
time, active attacks in which an adversary can induce a user to in-
sert chosen documents. We consider these attacks to be a realis-
tic threat against deployments such as automatically-updated email
repositories. In this setting, an adversary may simply send the user
an email and learn from the subsequent leakage. We stress that the
email is, in every technical sense, a valid email from a sender un-
connected to the adversary, so preventing such an attack would re-
quire semantic analysis or some other major change to the deploy-
ment. In the body we discuss how active attacks might be mounted
against other systems such as those appearing in [8, 14].

We show that either knowing a few documents or being able to
insert documents enable easy attacks that extract signiﬁcant infor-
mation about plaintexts in the L2 and L3 leakage settings. As one
example using the Enron email dataset for simulations, we show
that a server that happens to know even a single email sent to 500
Enron employees learns on average 35% of the keywords of all
other encrypted emails.

Summary. We are the ﬁrst to investigate the implications of com-
mon SE leakage models related to schemes used in industry and
in academic works [8, 14]. Our experimental analyses show that
efﬁcient and easy-to-mount attacks can reveal a signiﬁcant amount
of information about email plaintexts. We expect the attacks will
work against other document types that are similar to email (e.g.,
tweets, free-text web site form data, etc.), though the exact efﬁcacy
will vary with context.

The consequences for the security of deployed systems is less
clear.
In contexts where searchability is requisite, SE schemes
provably revealing only L1 or, at least, L2 leakage is clearly better
than not having any encryption at all. Future work should explore
the incorporation of countermeasures: periodically re-encrypting
content, adding noise at the expense of query performance, or at-
tempting to make practical mechanisms from the oblivious RAM
literature [7]. At the end of this paper we provide some additional
reﬂection on the implications of these attacks.

2. SE SCHEMES AND THEIR LEAKAGE

In this section we recall what are SE schemes, give an overview
of common schemes, and explain their leakage proﬁles. We will
incorporate as well some discussion of schemes used to build sys-
tems in the research literature and in commercial products, as well

669as how threat models map onto real systems. First we ﬁx some
notation from the SE literature.

APIs. This eases the route to deployment, at the cost of more leak-
age.

SE basics. We let D = (D1, ..., Dn) denote a collection of n >
0 plaintext documents, where each document is a variable-length
string from a known character set. We denote the length of a doc-
ument in characters by |Di|. A keyword extraction procedure takes
as input a character string Di and outputs a vector Wi, the keywords,
where each component is a character string. A typical keyword ex-
traction will ﬁrst parse Di into words, drop common words such
as articles and propositions, stem the remaining individual words,
and remove duplicate keywords. We assume keyword extraction
is deterministic and, looking ahead, known to the adversary. We
denote by ci the count of unique keywords in, or equivalently the
dimension of, Wi. Let W = (W1, . . . ,Wn) be the ordered list of all
the documents’ keyword vectors.

An SE scheme consists of encryption, search, and (possibly) up-
date algorithms. The encryption algorithm takes as input a secret
key K, documents D and emits a ciphertext. Search takes as input
a secret key K, a keyword w, and outputs a query message. If a
scheme includes the update algorithm, it is known as a dynamic SE
scheme. The update algorithm takes as input K and a document D,
and outputs an update message. We assume non-interactive settings
in which query and update messages are sent to the server, the lat-
ter executing some algorithm and returning a result. The client can
then process the result, e.g., decrypting recovered documents due
to a search query. Several examples of schemes are given below.

2.1 A Leakage Hierarchy for SE

Starting with the work of Curtmola et al. [6], research on SE for-
malize security by deﬁning a leakage proﬁle that characterizes the
information an adversary may learn. One proves that an adversary’s
view during an attack can be simulated given the leakage proﬁle. A
long line of work follows in this vein [3, 4, 6, 10–13, 15, 16, 20].
Such analyses rule out adversarial attacks that obtain information
not captured by the leakage model. However, this does not clarify
what an attacker can learn from the information that is leaked. The
goal of our work is to do exactly that.

We developed a scale for characterizing leakage, deﬁning a set of
four leakage proﬁles. The attacks we will present in later sections
target any scheme with a given leakage proﬁle or greater. The leak-
age of SE schemes often includes additional items of information
(c.f., Figure 1 of [4]), such as the number of documents, number
of unique keywords, and when the same query is repeated. When
such items are not implied by a given leakage proﬁle, we ignore
them in our attacks. We note, however, that certain statistics like
the plaintext lengths, when queries repeat, and even a query’s time
of day or client IP address may lead to improved attacks beyond
the ones we explore.

The deﬁnitions of leakage proﬁles follow along with the descrip-
tion of schemes that instantiate them. The descriptions progress in
order from greatest leakage (L4) to least (L1). We also stress that
the same leakage proﬁle may arise for two very different schemes
(we note an example below for L2). Below we explain leakages si-
multaneously with example classes of schemes that achieve them.
For the sake of brevity we will typically only informally describe
the portions of SE schemes that are not relevant to our results.

2.1.1 In-place SE schemes

The ﬁrst two schemes we describe are called in-place because
they involve direct uploading of encrypted document data, and the
server searches by iterating over keywords on a per-document ba-
sis. These are the simplest to implement, and have the distinct ad-
vantage of being compatible with many existing storage and search

Full-text substitution cipher. This is the simplest type of search-
able encryption. The client parses each input document and per-
forms keyword extraction to produce keywords Wi that are in or-
der with repeats. Then, it applies a deterministic cipher E to each
word. The resulting collection of ciphertexts is uploaded. The
client searches by sending the enciphered version of a keyword to
the server. The server scans the encrypted documents to match the
term ciphertext or, alternatively, it may use an inverted index pre-
computed over the individual encrypted keywords in the ciphertext.
This scheme supports not only keyword search queries, but also
boolean and phrase searches. However, stemming, wildcard, and
approximate-match searching are not supported. This is because
the value indexed by the server is a pseudorandom token which has
no relation to the plaintext. So, for example, a wildcard search like
“s*” would fail because the tokens for keywords starting with “s”
do not themselves start with “s”.

This simple in-place scheme has the largest leakage of any that

we discuss. We deﬁne its leakage proﬁle as:

L4: Full plaintext under deterministic word-substitution cipher.
The server learns the pattern of locations in the text where
each word occurs and its total number of occurrences in the
document collection.

Schemes with L4 leakage support searching for speciﬁc phrases,
among other kinds of queries beyond exact keyword match. Com-
panies including Skyhigh Networks [17] and CipherCloud [5],
whose products are discussed further below, make use of schemes
with L4 leakage. That said, our attacks focus on the more restricted
leakage models below; they apply against schemes with L4 leakage
as well.

We note that the original searchable encryption scheme of Song
et al. [18] is a deterministic encryption scheme like that described
above, but with the additional use of a separate stream cipher for
each keyword. The cipher iterates sequentially over each occur-
rence of the keyword in the document set. Thus, in the uploaded
data each occurrence of a keyword has a different ciphertext, and
the server initially cannot observe the pattern of repeated keywords.
To search, the client sends a ciphertext corresponding to the ﬁrst lo-
cation of the search term, and the server iterates the cipher to ﬁnd
all word matches in the document set. The word occurrence pat-
tern is revealed progressively as queries are issued. Thus if all key-
words are queried this becomes equivalent to L4 leakage. We omit
for brevity deﬁning a leakage model reﬂective of this scheme, and
only comment that it would be less leakage than L4, an orthogonal
amount of leakage to L2 and L2 deﬁned below, and strictly more
leakage than L1 (also deﬁned below).

Appended-keywords SE. Another class of SE schemes encrypts
each document Di using conventional randomized symmetric en-
cryption, and appends to the resulting ciphertext as well an encod-
ing of the values

FK(Wi[1]) , . . . , FK(Wi[ci])

where K is a secret key and FK is a pseudorandom function (PRF)
such as HMAC. The document ciphertext and its keyword hashes
are uploaded as-is to the server. Search on a keyword w is easy:
compute FK(w) and request the server to perform a search on it.

As discussed at length in [8,14], the beneﬁt of appended-keyword
SE schemes is that they are legacy-compatible: the server can per-
form indexing on the uploaded keyword hashes, addition and re-
moval of keywords is straightforward, etc. Also, and unlike the

670simple deterministic encryption scheme above, here one can per-
form stemming during keyword extraction.

Such a scheme provides no additional hiding of occurrence pat-
terns prior to search. Thus co-occurrence relationships (that a key-
word appears in a particular subset of documents), counts of the
number of unique indexed keywords, ciphertext lengths, and the
order of keyword appearance in the can be learned by the server
immediately upon upload. More formally, we have the following
leakage proﬁle:

L3: Fully-revealed occurrence pattern with keyword order. Intu-
itively, this leakage proﬁle fully reveals the pattern of key-
word occurrences in documents, in the order of their ﬁrst ap-
pearance, but not the occurrence counts within a document.
Formally, using the notation from above and ﬁxing some or-
der over all possible keywords w1, . . . , wN , the proﬁle outputs
the sequence of sets

{(i, j) : Wi[ j] = w1}, . . . , {(i, j) : Wi[ j] = wN } .

So the ﬁrst set includes all pairs (i, j) where the ﬁrst keyword
is the j-th term in the processed version of document i.

We note that if one were to change the scheme above to additionally
include repeats (say, to allow frequency-informed search), then the
scheme would have L4 leakage (assuming the same keyword ex-
traction algorithm).

In some implementations of the appended PRF scheme the client
will sort the PRF values before uploading. This is actually better
for security, as information about the order of ﬁrst occurrences of
keywords in each document is not leaked. The leakage is captured
by the following model.

L2: Fully-revealed occurrence pattern. This proﬁle is similar to
leakage proﬁle L3 in that the occurrence patterns of key-
words are revealed for every term, yet not in document or-
der. Formally, if the documents collectively contain terms
Si Wi = {w1, . . . , wN }, then the proﬁle leaks the full collec-
tion of sets

{i : w1 ∈ Wi}, . . . , {i : wN ∈ Wi}.

We consider both ordered and unordered appended PRF schemes
because we believe the difference in security is not widely appre-
ciated. See also the discussion below on research systems use of
appended-PRF schemes.

Use of appended-PRF SE. Due to their simplicity, these schemes
have seen a variety of use. Commercial encryption products from
Skyhigh Networks [17], CipherCloud [5], bitglass [2], and oth-
ers use these schemes (or variants of them) to support keyword
search on encrypted data uploaded to cloud services. An enter-
prise customer works with one of these encryption providers to ar-
range for their employees’ connections to cloud services like Sales-
Force, Box, Dropbox, and others to be intercepted by their man-
aged encryption proxy service. The proxy performs encryption on
the clients’ behalf using a key originally owned by the enterprise
customer. The appended-PRF SE, being legacy compatible, works
well within the existing APIs of the cloud services to support both
insertion and search over ciphertexts. The security goal is to en-
sure that the cloud service, should it be compromised, cannot learn
information about the customer’s data.

Appended-PRF schemes have also been suggested for use in a
number of recent academic research prototypes. The goal of Shad-
owCrypt [8] is to secure on the client side a user’s inputs to a ma-
licious web page. It does this using ShadowDOM, a new standard

Set-up:

User 

(e.g. browser)

plaintext doc d

encrypted doc E(d)

Proxy 

(e.g. plugin)

Server 

(e.g. gmail)

Searching:

User 

query q

(e.g. browser)

response r

Proxy 

(e.g. plugin)

query q1

response r1

…

Server 

(e.g. gmail)

Figure 3: Architecture for a legacy-compliant SE scheme.

for building DOM trees (or sub-trees) on top of the existing web-
page. The browser should enforce that the ShadowDOM cannot be
scripted by the (malicious) webpage. To use ShadowCrypt, a user
simply clicks a lock next to the ﬁeld and enters his or her input as
usual. Then, the ShadowCrypt plugin encrypts the input before the
actual webpage has access to it. ShadowCrypt supports searching
on the encrypted input by applying a keyed pseudorandom function
(PRF) to each of the keywords and appending the resulting values
to the end of the ciphertext. The paper leaves ambiguous whether
PRF values should be sorted; the open-source prototype does in-
deed sort the values. A diagram of highlighting ShadowCrypt’s
architecture when it comes to search is shown in Figure 3.

Mimesis Aegis [14] aims to allow inputing conﬁdential data into
untrusted mobile applications. It does so by arranging for the op-
erating system to interpose a transparent encryption layer on top of
the GUI of mobile applications. As with ShadowCrypt where the
web page is untrusted, here the application may be malicious, and
still the encryption should prevent the application from learning
information about the plaintext data. To enable searching, Mime-
sis Aegis employs a technique called easily-deployable efﬁciently-
searchable symmetric encryption, or EDESE. The work discusses
different ways of accomplishing this functionality, but for the pur-
poses of our security analysis they are all equivalent to the tech-
nique used by ShadowCrypt. They also leave implicit whether or-
dering of hash values is critical to security, though we their con-
structions do sort the PRF values1 and meeting their deﬁnition of
security for EDESE would seem to rule out schemes with L3 leak-
age.

2.1.2 Encrypted-index SE

Most academic work has been on (what we call) encrypted-index
SE [3,4,6,10–13,15,16,19,20]. In these schemes, clients construct
an encrypted index before upload.

To describe these schemes, we need to introduce additional no-
tation. For these schemes, the client generates an inverted index I.
This is (abstractly) an m × n matrix where entry Ii, j = 1 iff docu-
ment D j contains word wi. All other entries are zero. The m × m
co-occurrence count matrix C contains in location Ci, j the number
of documents in which wi and w j both occur. This can be normal-
ized to produce an empirical co-occurrence probability matrix ˆC.
Searching the index I requires the client to generate a per-query
trapdoor, which is sent to the server. The trapdoor can be thought
of as allowing the server to decrypt only those document identi-
ﬁers corresponding to the search term.
In some cases, a special
search protocol is performed with the trapdoor by the server on the
encrypted index. For instance, the protocol of [4] employed an in-
teractive protocol to carry out Boolean searching. Unlike in-place

1In fact they insert the PRF values into a bloom ﬁlter, to lessen
the amount of storage required. This has the same effect as sorting
them.

671Document 1 
8OG4qbr  Wavtgpc  TP1l2tf  optdn0n  
t2EK8Sp  5LLEuwc  SflnwMp  FzlwsWH  
bZO1Hpf  hB1iYbT 

Document 2 
Ba2donz  aSby7AV  Pk9MnzP  KJvrBga  
ojtE0fS  t2EK8Sp  isxWNuS 

0  D02  D08  D10  D11  D19  D77  D84 

1  D05  D08  D12  D35 

2  D11  D24  D55  D61  D63  D69  D71  D77  D91 

3  D18  D35  D40  D59  D84  D85 

Cz1  J57  Eyj  FG0  SQJ  Kot  vXT  e23  u47 

PId  F17  RN7  hB0  BJI  GGI  wZV  l8H  aHc 

tvo  0G0  1YC  mlz  3dT  jO7  imb  g3L  j6n 

“dog” → Wavtgpc 

“dog” → 1 

“dog” → <key> 

Document 1 
8OG4qbr  Wavtgpc  TP1l2tf  optdn0n  
t2EK8Sp  5LLEuwc  Wavtgpc  FzlwsWH  
bZO1Hpf  hB1iYbT 

Document 2 
Ba2donz  aSby7AV  Pk9MnzP  KJvrBga  
ojtE0fS  Wavtgpc isxWNuS 

0  D02  D08  D10  D11  D19  D77  D84 

Cz1  D05  Eyj  FG0  SQJ  Kot  vXT  e23  u47 

1  D05  D08  D12  D35 

PId  F17  RN7  D08  BJI  GGI  D12  l8H  aHc 

2  D11  D24  D55  D61  D63  D69  D71  D77  D91 

tvo  0G0  1YC  mlz  3dT  D35  imb  g3L  j6n 

3  D18  D35  D40  D59  D84  D85 

Figure 2: Server’s view of SE data structures for the same plaintexts before and after searching for the keyword ‘dog’. From left to
right, the schemes are examples of leakage proﬁles L4, L2, L1.

schemes, index-based schemes inherently hide the document word
order.

Unencrypted inverted index. In this scheme, the inverted index
I (table of document IDs) is sent unencrypted to the server. We
assume that the document ID’s are meaningless to the server (e.g.
randomly assigned serial numbers). The client randomly permutes
the rows of the index before uploading, perhaps according to a PRP,
so the server does not learn the correspondence between rows and
keywords. The trapdoor for a query is simply an index to a row of
I, and the server fulﬁlls the query by returning the selected row to
the client.

Since this scheme is essentially giving to the server the exact
document-term matrix, the server can, prior to any queries being
issued, directly observe the length of all result sets and also con-
struct the co-occurrence matrix C for all keywords. In fact, this
scheme has leakage proﬁle L2, equivalent to the appended-hash
scheme described above. Note that in this scheme, Boolean queries
can be fulﬁlled at no additional security loss, since the server sees
the entire index at upload time.

Encrypted inverted index, no result length hiding. This scheme
differs from the above in that each row of the index is encrypted
as a whole (say with a block cipher in some randomized chaining
mode), so that no repeated document IDs can be read from the in-
dex before queries are issued. However, the length of each row is
not hidden; before any queries are issued, the server can observe
the result count for every row.

The client searches by sending a trapdoor allowing the server to
decrypt the index row corresponding to the keyword. As queries
are fulﬁlled, the server gains information about the overlap of doc-
uments in result sets.

In this scheme the server can fulﬁll Boolean queries by obtain-
ing the decryption key for every keyword in the query. However,
this results in the server learning additional document ID’s beyond
those satisfying the query.

We do not deﬁne a separate leakage proﬁle for this scheme, but

consider it under proﬁle L1, described below.

Fully length-hiding SE. In this strongest class of searchable en-
cryption schemes that we consider, the length of individual result
sets is hidden in the initially uploaded index, so that before queries
are issued the server learns nothing except the total size of the in-
dex. It was suggested by Song et al. [18] that the length of result
lists could be partially hidden by padding the shorter lists to a ﬁxed
size. A solution to completely hide result lengths without using

padding was ﬁrst presented in Curtmola et al. [6], by the use of an
interwoven linked list data structure. Recent work has shown that it
is possible to fulﬁll Boolean queries in this setting while revealing
less information than the entire row for all words in the query [4].
We deﬁne the leakage of fully-length-hiding SE, the smallest

leakage proﬁle we consider, as L1:

L1: Query-revealed occurrence pattern. Intuitively, this proﬁle
reveals the same information as L2, but only for terms that
have been queried. This is the class of leakage achieved by
the schemes of [6] and its derivatives. In this proﬁle, initially
only basic size information (e.g. the total length of the doc-
uments) is leaked. When a trapdoor is sent, the server learns
the access pattern of the query, which in the case of keyword
search means the identiﬁers of documents containing w.

Formally, when D is processed into W and encrypted, and a
sequence of queries q1, q2, · · · , qQ is issued, then the leakage
proﬁle includes the sequence of sets

{i : q1 ∈ Wi}, {i : q2 ∈ Wi}, . . . .{i : qQ ∈ Wi}.

Depending on the setting, the leakage function may permute
the indices i randomly to hide the initial correspondence be-
tween the plaintexts and ciphertexts. Thus, for each queried
term, the proﬁle leaks the number of documents containing
the term, and for multiple queries, the proﬁle reveals which
documents they have (or don’t have) in common.

See Figure 2 for an intuitive picture of what the server “sees”
before and after a query is issued, for schemes with leakage proﬁles
L4, L2 and L1,

Use of encrypted-index SE. While at the time of writing are un-
aware of any deployment of these schemes in practice, recent work
has shown that they scale to large datasets [4]. Given this and the
signﬁciantly improved leakage proﬁle over the in-use appended-
PRF schemes, we expect that practitioners will increasingly transi-
tion to using some form of encrypted-index SE.

2.2 Attack Models

We classify attack models along two axes. First, we consider
the mode of the attack, meaning whether the server is passively or
actively mounting attacks, and second, we specify the prior knowl-
edge of the server regarding the documents and queries.

Attack modes. In SE the server receives the encrypted dataset and
query requests from a client, and an adversarial server may use its

672position to extract private information. We classify the following
three attack modes (where the last two may be utilized simultane-
ously in one attack). In each case, the adversary is a server follow-
ing the SE protocols, but it may take actions to induce the client to
run with certain inputs.

behavior to accurately guess some queries. Formally, in this
setting we will draw some queries q′
k from a distribu-
tion that all become known to the adversary, and then other
queries q1, . . . , qQ from a distribution that the adversary will
not know.

1, . . . , q′

• An honest-but-curious server follows the protocol and takes
no actions beyond those of an honest server, and attempts
to learn about the plaintext of documents or terms that were
queried.

• An active adversary can carry out a chosen-document attack
in which it tricks the client into including a chosen document
in the document set.

• An adversarial server may mount a chosen-query attack by
inducing the client into issuing certain queries, thereby re-
vealing whatever is leaked by that query. Our attacks will
not use this attack mode, as it seems less realistic, but it con-
ceivable that a deployment scenario would enable this ability
in some form.

We note that the danger of active attacks have not, to the best of
our knowledge, been given a treatment in academic literature on
SE. Unfortunately active attacks seem to be relatively straightfor-
ward to mount in most SE deployment settings, particularly so
for chosen-document attacks.
(Note that for the appended-PRF
schemes a chosen-query attack can be mounted using a chosen-
document attack with a single-word document.) Consider using
SE to automatically encrypt and back-up one’s email inbox. The
malicious server can then arrange for an email message of their
choosing to be sent to the victim. As long as it is not deleted by a
spam ﬁlter before going to the victim’s inbox, this will succeed in
forcing SE to be applied to the message with resulting ciphertext
subsequently observed by the server.

As another example consider ShadowCrypt. Recall that here
users click on a button within a webpage to indicate to the browser
that it should encrypt the data in some form ﬁeld. The web page
is considered malicious. Here click-jacking-type techniques can
be used to mount chosen-document attacks. The web page has an
“encrypt ﬁeld” button hidden behind an innocuous-looking frame
that the user must click in normal interaction with the site. The web
page can use such a technique to have the user unknowingly instruct
ShadowCrypt to encrypt data of the web page’s choosing. The au-
thors acknowledge that click-jacking attacks are possible against
their system, and indeed they might give rise to more direct attack
vectors than we consider here. Nevertheless this serves to show
that active attacks are often going to be possible for determined
adversaries.

Adversary knowledge. One of our theses is that an SE server’s
prior knowledge of the documents and queries may enable the ex-
traction of more information. We specify the following possible
types of prior knowledge. Depending on the setting, multiple types
of knowledge may be available to the adversary.

• Distributional query knowledge models a typical case where
an adversary has some idea about the queries being issued.
For instance, if encrypted chat logs are being searched, an
adversary can refer to typical user behavior regarding such
searches to inform its attack.

• Known queries occur when the server knows some of the
terms input by the client for a search. In practice an adversar-
ial server may use contextual information about the client’s

• Distributional document knowledge models the contextual
information an adversary will have about the documents (e.g.
whether they are emails, or corporate sales documents, or
something else). Formally we will model this by considering
a distribution on documents. In our experiments, we model
this by dividing a large data set into training and test sets, and
give the training set to the attacker.

• Known documents models scenarios where an attacker will
know certain plaintext documents or perhaps have signiﬁ-
cant information about them. For example, an attacker might
know that a widely-distributed email exists in a user’s repos-
itory. In our attack experiments we model this situation by
drawing documents as above, and then either hand-selecting
likely known documents or choosing some at random.

• Fully-known document set is the setting explored by IKK [9],
where all of the documents are known to the adversary, and
only some or all of the queries are unknown.

Attack objectives. We next identify possible objectives for an ad-
versary controlling the server in an SE scheme.

• Query recovery (QR) is the goal of determining the plain-
text of queries that have been issued by the client. This
was the objective of the ﬁrst known attack on SE by Islam
et al. [9]. QR can be considered in any setting where some
of the queries are unknown, including cases where the docu-
ments are fully or partially known.

• Partial plaintext recovery (PR). In PR attacks, the adver-
sary’s goal is to reconstruct as much as possible of the client’s
indexed documents, primarily by learning a mapping of key-
words to their encrypted versions. A PR attack may reveal
plaintexts as a “bag-of-words” or in document order; for the
attacks we present, this depends on the scheme and is inde-
pendent of the attack method itself.

We point out that there is an intimate relationship between query re-
covery and partial plaintext recovery, as any query that is revealed
immediately indicates that a document contains that particular key-
word.
If a full document is revealed, then queries against it are
narrowed down to a set of keywords.

Of course, query and plaintext recovery are not the only attack
objectives: for completeness we brieﬂy point out two others, docu-
ment presence and document identiﬁcation. In a document presence
attack, the adversary simply wishes to determine whether a known
plaintext document is present in the client’s index. In a document
identiﬁcation attack, the server seeks to ﬁnd the correspondence of
known documents to the document IDs revealed by the SE scheme.
Also note that attack objectives are interrelated. In particular, a suc-
cessful plaintext recovery attack will make document identiﬁcation
trivial.

In the subsequent sections we describe our attack results for
meaningful combinations of attack objective, leakage proﬁle, and
server knowledge. See the table in Figure 1 for a summary.

6733. EXPERIMENTAL METHODOLOGY

We investigated the vulnerability of the described leakage pro-
ﬁles by means of simulated query recovery and plaintext recovery
attacks, using two separate publicly available email datasets. The
ﬁrst is emails from 150 employees of the Enron corporation from
2000-2002, available online [1]. In order to focus on intra-company
email, following the approach of [9], we took emails from each em-
ployee’s sent mail folder, resulting in 30,109 total documents. The
on-disk size of the data set is 50 megabytes. The second dataset we
used is a subset of the Apache mailing list archives. Speciﬁcally,
we used the “java-user” mailing list from the lucene project for the
years 2005-2011. This consists of 50,582 emails, with an on-disk
size of 338 megabytes.

For each dataset, one email message is considered as one docu-
ment. Fixed-size vocabularies were established by taking the most
frequently occurring keywords from each dataset, after removal of
200 stopwords. The typical vocabulary size used in our experi-
ments was 5000, which represents the upper limit at which the at-
tack of the prior work succeeds, as seen in Figure 4. This gives an
average of 93 words per document in the Enron corpus, and 291 in
the Apache dataset. We will further discuss the impact of vocabu-
lary size on our results as we present them.

Keywords are stemmed using the standard Porter stemming algo-
rithm. Stemming is a crucial feature of usable search functionality,
as it provides more ﬂexible matching, e.g., a search for “cat” will
also match the word “cats”. Stemming has a two-sided effect on
the attacks that we evaluated. On one hand, it limits an attack to
reconstructing only the stems of plaintext words, causing loss of
information relative to the original plaintext. On the other hand,
stemming reduces the total vocabulary size and increases repeti-
tions of terms, making our attacks easier.

4. QUERY RECOVERY ATTACKS

As stated above, the adversary’s goal in query recovery attacks is
to recover the correct plaintext keywords corresponding to queries
that the client has issued to the SE server. These attacks apply to
any of the leakage proﬁles deﬁned above (L1 or greater), being
originally designed for the fully-hiding SE schemes described in
Section 2.1.2. Though the attacks work under the lowest leakage
proﬁle, they require the server to have more extensive knowledge
of the document set that is indexed. These attacks also depend on
multiple queries being issued, so that term access patterns can be
correlated.

4.1 Prior Work: The IKK Attack

Islam et al. [9] give the ﬁrst successful experimental attack on
searchable encryption that we are aware of. Theirs is a query recov-
ery attack on SE (leakage proﬁle L1), using full document knowl-
edge and partial query knowledge. They give experimental results
using the Enron email dataset, achieving recovery rates of over 80%
of issued queries for some vocabulary sizes.

The attack assumes that the server knows a ﬁxed set of m poten-
tial search terms, and the server’s knowledge of D is distributional,
in the form of the m × m matrix ˆC of word co-occurrence probabili-
ties. Note that this can be computed exactly if the server knows the
true document-term matrix for the indexed documents.

The server mounts the attack by observing the document access
pattern revealed by the client’s queries. Let q be the number of
unique query tokens observed. These are used to construct a q × q
term co-occurrence matrix Ct and its normalized version ˆCt . This
is a permutation of an unknown submatrix of ˆC (approximate if the
server’s knowledge of D is not exact.) Then, simulated annealing
is used to ﬁnd the best match of ˆCt to ˆC. The output is a mapping

of rows of Ct to rows of ˆC; this is the set of guesses for the query
terms. We note that in leakage proﬁle L2 or greater, the attack can
be carried out using the entire keyword set prior to observing any
queries.

The authors give experimental results for the Enron email dataset.
The keywords are taken to be the m most common stemmed words
in the document set after stopword removal, and the queries are
chosen uniformly at random from among these. They measure
recovery rate as the percent of unique queries correctly guessed.
The recovery rate reported varies from near perfect with 500 key-
words to approximately 0.65 with 2500 keywords, for a constant
150 unique queries. Their experiments also include the case where
a number of the client’s queries are initially known to the server;
their results show that the recovery rate is essentially independent
of this prior knowledge. We re-implemented the attack to conﬁrm
these results and make further comparisons.

One strength of the attack, henceforth called the IKK attack, is
that the success rate is largely independent of the number of queries
issued. The median number of queries in the results of [9] is 150,
which we also use as a default in our experiments. We consider
that this many queries could be observed by an adversarial in a
reasonable amount of time, and it is a sufﬁcient number for the
attacks to be effective.

A signiﬁcant weakness of the attack is that the adversary’s ad-
vantage does depend strongly on the number m of keywords under
consideration. The authors of [9] do not report on experiments with
keyword sets larger than 2500. In our experiments, the annealing
attack performs poorly on queries for vocabulary sizes over 5000.
This is shown in Figure 4. Thus the attack of [9], while valuable
for illustrating the vulnerabilities of SE, is fairly non-scalable.

As will be shown in Section 4.3, while the IKK attack algorithm
only requires the server to have distributional document knowledge
in the form of keyword co-occurrence probabilities, in practice the
accuracy of this knowledge required for the attack to succeed is
so high that we believe it can only be obtained by a server that
has explicit knowledge of the true document set. Thus, in the next
section we present a simpler and more effective attack that can be
carried out when the server does have more explicit knowledge of
the indexed documents.

4.2 Query Recovery with a Counting Attack

When the adversarial server, in addition to knowing the co-occur-
rence pattern of keywords, also knows the number of documents in
the indexed set that match each keyword—the result lengths—a
much more efﬁcient and accurate query recovery attack is appli-
cable. This length-based query recovery attack is applicable to all
schemes with leakage proﬁle L1, and requires no numerical opti-
mization techniques.

Attack Description. As in the IKK attack scenario, the adversarial
server knows a keyword co-occurrence matrix C of size m × m. In
addition, we assume that the server knows, for each keyword w, the
number of matching documents count(w) in the true document set.
Note that all this information can be easily computed if the server
has access to the explicit document set.

The ﬁrst observation is that if any keyword with a unique result
count is queried using trapdoor q, then a server with knowledge of
the true document set can immediately recover the query, by ﬁnding
the word w such that count(w) = count(q).

In the Enron email dataset with the same setup as [9], if we con-
sider the 500 most common non-stopwords as keywords, 63% of
them have a unique result count. If 2000 keywords are considered,
then 24% are unique. Note that due to the Zipﬁan character of
word distribution in natural-language text, the unique result counts

674will come from the more frequently occurring keywords. If queries
are assumed to be drawn uniformly from this set of keywords, then
these percentages can be considered a baseline rate for query recov-
ery when the server knows result counts. Also note that the larger
the document collection, the larger the number of keywords that
have a unique result count.

Of course, many key content words are singletons and can never
be recovered using unique counts alone. Beginning with this base-
line knowledge, our attack algorithm proceeds to recover queries
that do not have a unique result count by comparing term co-occur-
rence counts. See Algorithm 1.

t

e
a
r
n
o

i
t
c
u
r
t
s
n
o
c
e
R

1

0.5

0

Input: Unencrypted keyword index Index, observed query

tokens t and results

Initialize known query map K with queries (q, k) having
unique result lengths;
Compute co-occurrence counts Cq for observed queries and CI
for Index;
while size of K is increasing do

for each unknown query q ∈ t − K do
Set candidate keywords S ⊆ K =
{s : count(s) = count(q)};
for s ∈ S do

for known queries (q′, k) ∈ K do

if Cq[q, q′] 6= CI[s, k] then

remove s from S;

end

end

end
if one word s remains in S then

add (q, s) to K;

end

end

end

Algorithm 1: The count attack algorithm.

In contrast to the IKK attack, in the count attack the adversary
deﬁnitely knows which queries have been correctly reconstructed,
and has partial information about others in the form of the candidate
set.

Count Attack Analysis. Figure 4 shows the query reconstruction
results from our implementation of the count attack in the same
setup as [9], but with the server having no initial knowledge of any
queries. The graph shows accuracy results for varying number of
keywords from 2500 to 7500, in each case assuming that 10% of
the keywords under consideration have been queried. The attack
achieved perfect reconstruction for keyword counts less than 2500.
Since the count attack takes only a few seconds to run, compared
with hours for the simulated annealing, we could run it with much
larger numbers of keywords than IKK [9].

Our experiments indicate that once even a small number of queries
is initially disambiguated, the co-occurrence counting phase can
successfully recover nearly all the queries.

Padding Countermeasures. We then considered whether the ef-
fectiveness of the count attack could be decreased by a client who
pads the index with additional entries for bogus document ID’s, to
disguise the true counts. These bogus ID’s can be ﬁltered from
search results by the client.

We consider a scheme in which the number of entries in each
index row is padded up to the nearest multiple of an integer n. This
can be thought of as constructing “buckets” within which keywords

Count Attack

IKK Attack

500

1500

2500

3500

4500

5500

7500

Number of keywords considered

Figure 4: Comparison of IKK and Count attacks for query re-
construction by vocabulary size. Enron dataset, 150 keywords
queried.

will have the same result length. Changing the padding size n al-
lows us to adjust the space-security tradeoff. To prevent the adver-
sary from performing statistical analysis to determine which docu-
ment IDs are used as padding, a bogus document set can be con-
structed by sampling from the same term distribution as the true
documents. Then the desired padding entries can be chosen from
among these.

Qualitatively, this affects the count attack in two ways: Firstly, it
reduces the number of unique result lengths, increasing the number
of candidate matches for a given query. Secondly, it prevents the
co-occurrence counting stage of the count attack from being car-
ried out exactly: The number of co-occurrences of two keywords in
the padded index may exceed the co-occurrence count of the cor-
responding keywords computed from the true document set. The
attacker must allow for this and cannot eliminate as many candi-
dates.

The count attack as described above completely fails once the
padding size n is increased to the point that no keyword has a
unique result count; in this case there are no initial known queries
with which to bootstrap the co-occurrence counting. However, we
can modify the algorithm to allow the attack to be carried out with
reduced information. This generalized count attack has two mod-
iﬁcations: Firstly, knowing that the padding can cause additional
“false co-occurrences”, the co-occurrence count matches within a
window as large as the maximum number of false co-occurrences,
rather than requiring an exact match. Secondly, we remove the
algorithm’s dependence on initially ﬁnding a query with a unique
result count. This is done by making an initial guess mapping a
query to one of the candidate keywords of matching result length,
and then running the remainder of the algorithm. If the guess is
wrong, the co-occurrence counting phase detects an inconsistency,
and the next candidate will be tried.

These modiﬁcations to the count attack algorithm maintain its
correctness. Figure 5 shows the effect of padding on the general-
ized count attack for query reconstruction.

Up to a padding level that increases the index size by about 15%
for the Enron data, and 30% for the Apache data, the attack’s suc-
cess rate is unaffected. We believe the attack is more robust on
the Apache email because the dataset is more dense—each docu-
ment has more words, so there is more co-occurrence information.
The recovery rate drops off rapidly after this, as the data becomes
sufﬁciently noisy to prevent any disambiguation.

675t

e
a
r

n
o

i
t
c
u
r
t
s
n
o
c
e
R

1

0.8

0.6

0.4

0.2

0

1

Enron emails

Apache “java-user”

1.2

1.4

1.6

1.8

2

Padding overhead – index expansion factor

t

e
a
r

y
r
e
v
o
c
e
r

y
r
e
u
Q

1

0.8

0.6

0.4

0.2

0

IKK Attack

Count Attack

50

60

70

80

90

100

% of dataset known to server

Figure 5: Generalized count attack results for padded index,
5000 keywords considered, 10% of keywords queried.

Figure 6: Query recovery rates when server has partial knowl-
edge of true document set. Enron dataset, 500 keywords, 150
queried uniformly.

4.3 Query Recovery from Partially Known

Documents

In this section we analyze the above attacks on L1 leakage (with
slight modiﬁcations) in the case when the server has only partial
knowledge of the document set, to better understand the server
knowledge level required to carry out these attacks.

Analysis of the IKK attack with partial knowledge. Because the
IKK attack only directly makes use of word co-occurrence prob-
abilities, technically it does not require the server to have explicit
knowledge of the documents themselves. However, the effective-
ness of the attack depends strongly on the accuracy of the co-occur-
rence matrix. The authors discuss this and give results of an experi-
ment in which random Gaussian noise is added to the co-occurrence
matrix. In their experiment, the recovery rate drops from 85% to
65% at the ﬁrst increment of added noise.

To understand better how real-world limitations on a server’s
knowledge affect the accuracy of the attack, we devised a new ex-
periment. Instead of adding noise to the co-occurrence matrix, we
assume the server knows only a certain fraction of the true docu-
ments, and computes the co-occurrence probabilities from the doc-
uments it knows. We duplicated the experiments of [9] with the
server’s co-occurrence matrix constructed from a randomly chosen
subset of the true documents. See results in the ﬁrst plot of Figure
6, which relates the recovery rate to the percentage of the dataset
known to the server. In brief, these results indicate that unless the
server has access to 99% of the true document data, the query re-
covery rate of the IKK attack is quite poor.

Generalized count attack for partial knowledge. We also modi-
ﬁed the generalized count attack described in the previous section
to allow query reconstruction when the server does not know the
full document set. As with the case of a padded index, this re-
quires the algorithm to allow keyword candidates within a window
of co-occurrence counts, rather than requiring exact equality. These
results are found in the second plot of Figure 6. Note that the count
attack performs better, requiring the server to know only 80% of the
dataset for signiﬁcant query recovery. Due to the discrete nature of
the count attack, in contrast to the IKK attack, the recovery rate
jumps from zero to a signiﬁcant percentage once there is sufﬁcent
co-occurrence information.

We emphasize that these experiments are for the case where the
server knows a subset of the true documents. We also conducted
experiments in which the server is trained on a random subset of
documents, while the client queries a disjoint subset from the same

corpus—in other words, the unknown documents case. Here both
out attack and the IKK attack fail completely.

Our results support the conclusion that attacks on L1 leakage
require a signiﬁcant amount of server knowledge of the document
set, but are nonetheless possible with less-than-perfect knowledge.

5. PARTIAL PLAINTEXT RECONSTRUC-

TION ATTACKS

In this section we present attacks that enable the adversary to
learn the mappings of keywords of the client’s documents to the
ciphertexts stored by the SE scheme. This keyword recovery can
then be used to partically reconstruct the plaintexts of stored docu-
ments, either as a “bag of words” in appended-keywords schemes,
or ordered plaintext if document text is encrypted using in-order
word hashes.

These attacks exploit leakage proﬁles L2 and L3 or higher. For
instance, they apply to searchable encryption schemes that store en-
crypted words on a per-document basis using a PRF or hash func-
tion, as in the “in-place” schemes described in Section 2.1.1. We
show realistic known-document (passive) and chosen-document (ac-
tive) attacks in this scenario. We present the success of the attacks
quantitatively in the form of percentage of total non-stopwords re-
covered, and then demonstrate how this allows a highly revealing
partial plaintext reconstruction.

5.1 Known-Document Attacks

This subsection presents and analyzes two keyword-based plain-
text recovery attacks by a passively adversarial server that correctly
executes the SE scheme algorithms and that knows the plaintext of
a small number of the stored documents. The ﬁrst attack is against
L3 leakage and the second against L2.

5.1.1 Order of Hashes Known (L3)

To start with the simpler case, we consider a scheme in which the
order of appended hashed keywords is not changed from the order
in which the keywords appear in the document—that is, leakage
proﬁle L3. In this case, the attack is almost trivial: the server can
immediately observe the hash values of all the indexed keywords in
the known documents. Unlike the experiments of Section 4, there
is no need to assume a ﬁxed vocabulary beforehand; the vocabu-
lary is derived from the known documents. We present the results
of statistical experiments quantifying the advantage gained by an
attacking server in this scenario.

676s
t
n
e
m
u
c
o
d

f

o
n
o

i
t
c
a
r
f

e
v
i
t

l

a
u
m
u
C

1

0.8

0.6

0.4

0.2

0

0

Enron-2

Enron-20

Apache-2

Apache-20

0.2

0.4

0.6

0.8

1

Keyword recovery rate

Figure 7: Keyword recovery rates for Enron and Java-user
datasets from known documents for an in-place SE scheme with
ordered keyword hashes.

Random Documents. To quantify the fraction of plaintext key-
words learned by an adversarial server that knows a small number
of the stored documents, we plotted the fraction of documents in
our datasets for which a given percentage of keywords is recovered,
at 5% intervals, when the adversary is given either 2 or 20 random
known documents. Each rate is averaged over 10 random selections
of known documents. Results for the two datasets are summarized
in cumulative style in Figure 7. The curves that fall further to the
right are indicative of a larger percentage of documents having high
keyword recovery rates. For example, in the Apache “java-user”
dataset, if the server knows only two document encryptions, 80%
of the documents will have 40% of their keywords exposed.

As mentioned, the Enron and Apache datasets have over 30,000
and 50,000 documents, respectively, so the known documents are a
very small fraction of the amount of data revealed. We conjecture
that the attack is more effective for the Apache dataset because this
set has a “critical mass” of vocabulary that is common to most of
the documents, as the topic of discussion in a software mailing list
is likely to be more uniform than all the emails sent by a large
company’s employees.

To gauge the ability of a human attacker to gain information from
this reconstruction attack, we visually inspected the output of the
attack on a random selection of Enron emails, printing out in docu-
ment order the keyword stems learned from a 20 known document
trial, omitting stopwords. The result for a sample email is shown
in Figure 8, together with the original plaintext. Note that poten-
tially sensitive information has been revealed, including the name
of a company (ENA) involved in a contract. We conclude that this
attack reveals sufﬁcient information for a human inspecting the out-
put to gain a strong sense of document content.

Known Public Documents. Though choosing documents at ran-
dom is important for statistically understanding the power of at-
tacks, the source of a real-world known-document attack would
likely not be emails chosen uniformly at random. A more prob-
able source might be a message that has a wide distribution, such
as a company-wide announcement. The more recipients an email
has, the more likely it is that its plaintext will become known to an
attacker.

To test this, we ran the same experiment with a single email from
the Enron dataset that was sent to 500 recipients.
It was an an-
nouncement sent to an entire division, four paragraphs long, with

The attached contract is ready for

I will return an original

Or

Please print 2 documents and

signature.
have Atmos execute both and return same to
my attention.
for their records after ENA has signed.
if you prefer, please provide me with the
name / phone # / address of your customer
and I will Fed X the Agreement.
attach contract signatur pleas print 2
document have execut both same will origin
ena sign prefer provid name agreement

Figure 8: (Top) An example plaintext email from the Enron
corpus. (Bottom) The stemmed words recovered by our attack
when given 20 randomly selected known emails.

832 unique keywords, containing an announcement of an upcoming
survey of the organization by an outside consulting group. From
this single document, an average of 35% of the indexed keywords
in every document could be recovered. If it is the case that pub-
licly distributed emails are longer than average, with large vocab-
ularies relative to brief, person-to-person emails, then this attack
is potentially even more damaging than the statistics using random
documents indicate.

5.1.2 Order of Hashes Unknown (L2)

In leakage proﬁle L2, for example, an in-place scheme when the
keyword hashes are stored in randomized order, a server that knows
a number of document plaintexts cannot immediately determine the
mapping of every keyword hash in the document, though it knows
the set of hashes that correspond to the keywords in the document.
We can quantify the ambiguity of words in the known docu-
ments. A keyword which the server knows the hash of has am-
biguity 1 (no ambiguity). If the number of indexed keywords in a
document known to the server is c1, then for each word there are
c1 different possibilities for its hash. If this is the only document
known to the server, we say the average ambiguity of all the key-
words in the known document set is c1.

When more than one document is known by the server, the ambi-
guity can be reduced, again by use of the co-occurrence pattern of
keywords in the known documents. We omit a full analysis of this
approach. A more powerful attack for unknown order of hashes is
possible when the server is able to plant documents, as shown in
section 5.2.2.

5.2 Active Attacks

We now consider the power of an attacking server who, in ad-
dition to observing the client’s uploaded data, can “plant” docu-
ments that will be processed by the client and added to the up-
loaded dataset. Note that the protocol itself is not attacked; the
server still fulﬁlls requests following the rules of the scheme. This
attack model can be seen as the analogue of the chosen-plaintext
attack model (CPA) for encryption.

We can easily imagine real-world scenarios where attacks of this
nature can be carried out—it can be as simple as a malicious server
sending a client an email, which is then indexed by the client and
uploaded to the server. As another example, a malicious server
might make an invisible-to-the-user attack on ShadowCrypt using
UI redressing.

The attacks described below apply to in-place schemes, as de-
scribed in Section 2.1.1. We assume that by observing the payload
length and/or the time at which documents are uploaded, the adver-
sary can determine which index or database entry corresponds to

677the document he planted. For each attack we measure the level of
plaintext recovery as percentage of keywords reconstructed.

5.2.1 Hash order known (L3), chosen document

Recall that searchable encryption schemes with leakage proﬁle
L3 preserve the document order of encrypted keywords stored at
the server, either by deterministic word-based encryption of the
document itself or by storing keyword hashes in their order of ap-
pearance. In this case then an adversarial server can carry out a
simple but devastating attack. He can plant a single document in
the database with any desired set of keywords, and then from its
encryption can learn all of the hashes of those keywords. We do
not explore this simplistic, though obviously very damaging attack,
further.

5.2.2 Hash order unknown (L2), chosen documents
Lastly, we consider schemes in which the hashes of keywords
are stored at the server in random order. As in the known-document
case, an adversary who plants a chosen document will only learn
the set of keyword hashes for the document, not the one-to-one
mapping of keywords to hashes. Clearly, the server can learn a sin-
gle word unambiguously by planting a one-word document. Adopt-
ing a more sophisticated strategy, an adversary may seek to insert
documents so as to maximize the “yield” of keywords learned per
inserted document, and minimize the number of potential errors.
We present and analyze an attack based on frequency analysis of
a related corpus, which allows the server to trade off error proba-
bility against the size and number of inserted documents, giving an
effective and ﬂexible attack strategy.

Attack description. From a known related corpus, the adversary
generates a list of (possibly stemmed) keywords ranked by fre-
quency. Fixing a document size k, the adversary divides the ranked
keyword list into k equal-sized slices. He then generates a k-word
document by choosing the top word from each slice. The goal is
to maximize the frequency distance between keywords in a given
document.

The adversary also computes the frequency distribution of key-
word hashes in the data uploaded by the client. After observing
the hashes of the words in the planted document, the adversary
ranks them by their frequency in the uploaded dataset, and guesses
that the hashes correspond to the keywords of the same rank based
on his own corpus. All k guesses are correct as long as there are
no rank reversals in their keyword frequencies between the two
datasets. The adversary can repeat this process for all known key-
words or for as many documents as he is able to insert.

Experimental setup. We used two setups, the ﬁrst one to model
an adversarial server that has access to a closely related corpus, the
second to model a server having access only to unrelated corpus
in the same language. For the ﬁrst, we divided a single data set in
half, with the server “training” on 50% of the documents to learn
keyword frequencies, while the client processes the documents in
the other half and uploads encrypted keywords to the server. For
the second, we used keyword sets and frequencies from the Enron
dataset to attack the Apache dataset, and vice versa.

In each experiment, we generated chosen documents to cover all
the keywords known to the server and measured the average re-
covery rate as well as error rate of client keywords. The plots in
Figure 9 show the tradeoff between number of words per chosen
document and error rate. The data are averaged over 10 runs per
dataset and the two datasets. As expected, the larger the number
of slices/keywords per document k, the greater the probability of
error, as the words in a document will be closer in frequency, in-

s
d
r
o
w
y
e
k

f

o

n
o

i
t
c
a
r
F

1

0.8

0.6

0.4

0.2

0

0

Recovery rate

Error rate

Recovery, unrelated

Error, unrelated

5

10

15

20

Keywords per chosen document

Figure 9: Keyword recovery rate and error rate for planted
documents, unknown order of keyword hashes, 5000 keywords
considered.

creasing the likelihood of a rank reversal between the client and
server datasets.

The recovery rate is lower than 1 minus the error rate, because
not all of the client-indexed keyword hashes will occur in the server’s
dataset; these are not a source of errors, as the adversary knows he
has no information on them.

For the single-dataset 50% split scenario, at around k = 19 key-
words per document, the error rate becomes higher than the recov-
ery rate, and thus the attacker will gain very little information. Also
as expected, for the unrelated-corpus scenario, the recovery rate
starts much lower, and a smaller slice size must be used to avoid
too many errors. However, the error rate is not worse in the cross-
dataset experiment, showing that word frequency rank is fairly con-
sistent across these two email domains.

To recover w keywords, the adversary must plant at least w/k
documents, more to allow for the error rate. The choice of docu-
ment size must be informed by the attacker’s desired error rate and
the probability of detection. At any rate, the attack allows even an
adversary who can plant a small number of documents to learn a
sensitive selection of keywords.

6. CONCLUSION

We close with a summary of the lessons learned from this work.
Our attacks begin to map the risks in using SE at various leakage
levels.

First, we conclude that it is dangerous to attempt to protect queries
on known document sets using SE schemes, even those proven to
only admit L1 leakage. This reinforces the work of IKK, our at-
tacks improve on theirs to show that L1 leakage can be used to
learn query values even when the search space becomes very large.
In this case one might consider more secure but unfortunately sig-
niﬁcantly slower primitive like oblivious ORAM [7].

Second, we conclude that leakage levels L2 and L3 are risky
for deployments that enable active insertion of documents or in-
sert a few publicly-known documents. Both are a threat against
outsourced email storage, and the latter may be applicable in other
scenarios (e.g., a user downloads and stores public documents). We
note that future work is likely to show damaging L2 and L3 leakage

678attacks that are passive, relying only on more nuanced statistical
analysis of an index’s revealed co-occurrence relationships.

Our second conclusion motivates the usage of SE with L1 level
leakage over weaker variants. But we cannot conclude that L1 is
necessarily safe. In settings where a large fraction of the possible
keywords are queried, L1 leakage devolves to that of L2 leakage.
Future work may seek leakage levels even lower than L1, for exam-
ple by accepting some small amount of false positives and/or false
negatives in search.

Acknowledgements

Cash was supported in part by NSF grant CNS-1453132. This
work was done in part while Cash was visiting the Simons Insti-
tute for the Theory of Computing, supported by the Simons Foun-
dation and by the DIMACS/Simons Collaboration in Cryptography
through NSF grant CNS-1523467. Ristenpart was supported in part
by NSF grants CNS-1546033, CNS-1330308, and CNS-1065134
and a generous gift from Microsoft. Perry was supported in part by
DARPA under agreement number FA8750-13-2-005.

Grubbs and Ristenpart have large ﬁnancial stakes in Skyhigh
Networks. The opinions of this paper do not necessarily reﬂect
those of the authors’ employers or the funding agencies that sup-
ported this work.

7. REFERENCES
[1] Enron email dataset.

https://www.cs.cmu.edu/~./enron/. Accessed:
2015-05-13.

[2] Bitglass. Security, Compliance, and Encryption.

http://www.bitglass.com/solutions/
salesforce-encryption.

[3] D. Cash, J. Jaeger, S. Jarecki, C. S. Jutla, H. Krawczyk,

M.-C. Rosu, and M. Steiner. Dynamic searchable encryption
in very-large databases: Data structures and implementation.
In NDSS 2014, San Diego, California, USA, Feb. 23–26,
2014. The Internet Society.

[4] D. Cash, S. Jarecki, C. S. Jutla, H. Krawczyk, M.-C. Rosu,

and M. Steiner. Highly-scalable searchable symmetric
encryption with support for boolean queries. In R. Canetti
and J. A. Garay, editors, CRYPTO 2013, Part I, volume 8042
of LNCS, pages 353–373, Santa Barbara, CA, USA,
Aug. 18–22, 2013. Springer, Berlin, Germany.

[5] CipherCloud. Cloud Data Encryption. http://www.

ciphercloud.com/technologies/encryption/.

[6] R. Curtmola, J. A. Garay, S. Kamara, and R. Ostrovsky.

Searchable symmetric encryption: improved deﬁnitions and
efﬁcient constructions. In A. Juels, R. N. Wright, and
S. Vimercati, editors, ACM CCS 06, pages 79–88,
Alexandria, Virginia, USA, Oct. 30 – Nov. 3, 2006. ACM
Press.

[7] O. Goldreich and R. Ostrovsky. Software protection and

simulation on oblivious RAMs. Journal of the ACM,
43(3):431–473, 1996.

[8] W. He, D. Akhawe, S. Jain, E. Shi, and D. Song.

Shadowcrypt: Encrypted web applications for everyone. In
Proceedings of the 2014 ACM SIGSAC Conference on
Computer and Communications Security, pages 1028–1039.
ACM, 2014.

[9] M. S. Islam, M. Kuzu, and M. Kantarcioglu. Access pattern

disclosure on searchable encryption: Ramiﬁcation, attack
and mitigation. In 19th Annual Network and Distributed
System Security Symposium, NDSS 2012. The Internet
Society, 2012.

[10] S. Kamara and C. Papamanthou. Parallel and dynamic

searchable symmetric encryption. In A.-R. Sadeghi, editor,
FC 2013, volume 7859 of LNCS, pages 258–274, Okinawa,
Japan, Apr. 1–5, 2013. Springer, Berlin, Germany.

[11] S. Kamara, C. Papamanthou, and T. Roeder. Dynamic

searchable symmetric encryption. In T. Yu, G. Danezis, and
V. D. Gligor, editors, ACM CCS 12, pages 965–976, Raleigh,
NC, USA, Oct. 16–18, 2012. ACM Press.

[12] K. Kurosawa. Garbled searchable symmetric encryption. In
N. Christin and R. Safavi-Naini, editors, FC 2014, volume
8437 of LNCS, pages 234–251, Christ Church, Barbados,
Mar. 3–7, 2014. Springer, Berlin, Germany.

[13] K. Kurosawa and Y. Ohtaki. How to update documents

veriﬁably in searchable symmetric encryption. In
M. Abdalla, C. Nita-Rotaru, and R. Dahab, editors, CANS
13, volume 8257 of LNCS, pages 309–328, Paraty, Brazil,
Nov. 20–22, 2013. Springer, Berlin, Germany.

[14] B. Lau, S. Chung, C. Song, Y. Jang, W. Lee, and

A. Boldyreva. Mimesis aegis: A mimicry privacy shield–a
systems approach to data privacy on public cloud. In
Proceedings of the 23rd USENIX conference on Security
Symposium, pages 33–48. USENIX Association, 2014.

[15] M. Naveed, M. Prabhakaran, and C. A. Gunter. Dynamic

searchable encryption via blind storage. In 2014 IEEE
Symposium on Security and Privacy, pages 639–654,
Berkeley, California, USA, May 18–21, 2014. IEEE
Computer Society Press.

[16] W. Ogata, K. Koiwa, A. Kanaoka, and S. Matsuo. Toward

practical searchable symmetric encryption. In K. Sakiyama
and M. Terada, editors, IWSEC 13, volume 8231 of LNCS,
pages 151–167, Okinawa, Japan, 2013. Springer, Berlin,
Germany.

[17] I. Skyhigh Networks. Skyhigh for Salesforce.

https://www.skyhighnetworks.com/product/
salesforce-encryption/.

[18] D. X. Song, D. Wagner, and A. Perrig. Practical techniques

for searches on encrypted data. In 2000 IEEE Symposium on
Security and Privacy, Berkeley, California, USA, May 14-17,
2000, pages 44–55. IEEE Computer Society, 2000.

[19] D. X. Song, D. Wagner, and A. Perrig. Practical techniques

for searches on encrypted data. In 2000 IEEE Symposium on
Security and Privacy, pages 44–55, Oakland, California,
USA, May 2000. IEEE Computer Society Press.

[20] E. Stefanov, C. Papamanthou, and E. Shi. Practical dynamic

searchable encryption with small leakage. In NDSS 2014,
San Diego, California, USA, Feb. 23–26, 2014. The Internet
Society.

679