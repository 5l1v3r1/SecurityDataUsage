An Empirical Study of Web Vulnerability Discovery

Ecosystems

Mingyi Zhao

Pennsylvania State University

muz127@ist.psu.edu

Jens Grossklags

Pennsylvania State University

jensg@ist.psu.edu

Peng Liu

Pennsylvania State University

pliu@ist.psu.edu

ABSTRACT
In recent years, many organizations have established bounty
programs that attract white hat hackers who contribute vul-
nerability reports of web systems. In this paper, we collect
publicly available data of two representative web vulnera-
bility discovery ecosystems (Wooyun and HackerOne) and
study their characteristics, trajectory, and impact. We ﬁnd
that both ecosystems include large and continuously grow-
ing white hat communities which have provided signiﬁcant
contributions to organizations from a wide range of business
sectors. We also analyze vulnerability trends, response and
resolve behaviors, and reward structures of participating or-
ganizations. Our analysis based on the HackerOne dataset
reveals that a considerable number of organizations exhibit
decreasing trends for reported web vulnerabilities. We fur-
ther conduct a regression study which shows that monetary
incentives have a signiﬁcantly positive correlation with the
number of vulnerabilities reported. Finally, we make recom-
mendations aimed at increasing participation by white hats
and organizations in such ecosystems.

Keywords
Bug Bounty; Vulnerability Discovery; Vulnerability Disclo-
sure; Monetary Incentives

1.

INTRODUCTION

Websites are critical pathways to facilitate e-commerce,
customer service, input procurement, and employee connec-
tivity, and they continue to reach signiﬁcant penetration in
various business sectors. Most large businesses are hosting
web services, and over 50% of small businesses are now oﬀer-
ing web accessibility [10]. As such, web security has become
critically important for most organizations, and the preven-
tion of security compromises enabled by web vulnerabili-
ties is gaining increasingly the attention of company lead-
ership and the broader security community. Nevertheless,
web vulnerabilities are the likely causes of many recent se-

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
c(cid:13) 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
http://dx.doi.org/10.1145/2810103.2813704.

curity breaches contributing to massive disclosure of user
data, leakage of business information, and other losses.

To reduce the number of web vulnerabilities, organizations
can use automated web vulnerability scanners which how-
ever have been shown to only have limited coverage [16, 37].
In response, organizations more recently started to directly
collaborate with or indirectly beneﬁt from outside security
researchers. These so-called white hat researchers spend
time to analyze organizations’ web systems and report vul-
nerabilities to self-run bug bounty programs of organizations
such as Facebook, Github and PayPal, or to correspond-
ing programs on third-party bug bounty platforms such as
Wooyun, HackerOne, BugCrowd, Cobalt, etc.

White hats contribute in many positive ways to the discov-
ery of web vulnerabilities. First, they can complement the
limitations of automated scanners [16] by reaching deeper
states of web applications, and may better understand the
application logic. Second, with a mindset comparable to
attackers, white hats are good at ﬁnding many exploitable
vulnerabilities of high severity. Third, the large and diverse
group of potential white hat contributors outnumbers inter-
nal security teams or penetration testing teams and could
therefore cover a wider range of security issues.

White hats’ considerable eﬀorts are rewarded in diﬀer-
ent ways. Organizations or bug bounty platforms may pro-
vide monetary incentives based on severity and originality of
the discovered issue, or publicize white hats’ contributions
to enhance their reputations. Previous studies and reports
have shown that the cost of utilizing the white hat commu-
nity may be lower compared with hiring internal security
researchers [20] or using services from penetration testing
companies [5].

The resulting interactions extend beyond organizational
boundaries and form web vulnerability discovery ecosystems
including businesses/organizations, white hats, and third-
party vulnerability disclosure reward/bounty programs (Fig-
ure 1). These ecosystems have been growing rapidly and are
becoming more prominent in the battle against malicious ac-
tors on the Internet. However, detailed studies of these web
vulnerability ecosystems to understand their characteristics,
trajectories, and impact are notably absent.

In this work, we conduct the ﬁrst empirical study of two
major web vulnerability discovery ecosystems. We base our
analyses on publicly available data. The ﬁrst dataset is col-
lected from Wooyun1, the predominant and likely the oldest
web vulnerability discovery ecosystem in China. Our data
contains 64,134 vulnerabilities aﬀecting a total of 17,328 or-

1www.wooyun.org

1105Platforms
Wooyun
Facebook (2013) [4]
BugCrowd [12]
Loudong 360
Cobalt
HackerOne
Vulbox
Sobug

HQ

Start
2010-07 China
US
2011-08
US
2012-09
China
2013-03
2013-07
US
2013-11 US
2014-05
2014-05

China
China

# Vuln. # WHat # Org.
17,328
64,134
687
1
166
7,958
2,271
54,727
230
8,119
99 (Public)
10,997
10,000
Unknown
285
3,270

7,744
330
566
14,104
2,600*
1,653
20,000*
8,611*

Bounty Paid
Disclosure
Unknown
Full
$1.5M
No
$0.7M
No
$0.7M
Partial
Unknown
Partial
$3.64M
Partial
Unknown
Partial
$0.8M (Budget) Partial

Table 1: Statistics for representative bug bounty platforms sorted by their start time. The two platforms studied in this paper
are highlighted. Numbers were obtained from the cited references, or platforms’ websites directly in early August of 2015.
The exact deﬁnitions of each metric for diﬀerent platforms may vary. For example, some platforms count registered white
hats (marked with *), while others such as HackerOne count white hats that have made at least one valid contribution.

ganizations including almost all popular Chinese web com-
panies. We additionally collect publicly available data from
HackerOne2, a US-based start-up company which hosts bug
bounty programs for hundreds of organizations, such as Ya-
hoo, Mail.ru and Twitter, from many parts of the world.
The Wooyun dataset is larger due to its coercive partici-
pation model for involving organizations, and also contains
more detailed vulnerability information due to its delayed
full disclosure policy. The HackerOne dataset is smaller
and not all of its reports can be accessed. However, it cov-
ers a diﬀerent set of organizations and also contains mone-
tary reward information that does not exist for the Wooyun
dataset. By combining these two complementary datasets,
we are able to explore a wide range of topics and gain a
better understanding of the structure and dynamics of such
ecosystems and their impact on Internet security. We antic-
ipate that our study will be a valuable reference for organi-
zations who want to create or optimize their existing bounty
programs.

We make the following contributions:

• Our analysis shows how many white hats have been
attracted by these ecosystems and how the number
of contributing white hats evolves over time. We fur-
ther assess their diversity in terms of productivity and
breadth of vulnerability discovery (e.g., types of vul-
nerabilities and aﬀected organizations) by studying in-
dividual contributions but also contributions by groups
of white hats with high/medium/low productivity. We
also analyze the potential (learning) value of disclosing
vulnerabilities to the white hat community.

• We then quantitatively analyze participating organi-
zations from several dimensions, including the vulner-
ability trends, the coverage of diﬀerent business sec-
tors, the response and resolve behaviors, and reward
structures. We evaluate the trend of reported vulner-
abilities for representative organizations.

• Our study further measures the impact of diﬀerent
In particular, we
factors on vulnerability discovery.
quantify the eﬀect of oﬀering monetary incentives for
attracting white hats and reporting discovered vulner-
abilities. Based on these analyses, we discuss the ben-
eﬁts of disclosing vulnerability information, oﬀer sug-
gestions on how to improve the eﬀectiveness of the
collaboration between white hats and organizations,

2hackerone.com

discuss insights for relevant policy making (e.g., the
Wassenaar Arrangement), and identify important re-
search questions for future studies.

We proceed as follows. In Section 2, we discuss related
In Section 3, we provide background information
work.
about Wooyun and HackerOne, and discuss the collection
of the datasets. We present our data analysis results in
Section 4, and provide a discussion in Section 5. We oﬀer
concluding remarks in Section 6.

2. RELATED WORK
2.1 Software Vulnerability Datasets

Previous work has studied various software vulnerabil-
ity datasets to understand vulnerability discovery, patching
and exploitation. This research is relevant for the debate
on whether vulnerability disclosure programs are beneﬁcial
to society [18]. That is, if the number of potential vulner-
abilities is large with respect to the eﬀort of white hats,
and vulnerabilities are found in no particular order, then
black hats could frequently discover and exploit vulnera-
bilities that are not covered by white hats’ contributions;
thereby questioning their eﬀectiveness. On the one hand,
Rescorla studied the ICAT dataset of 1,675 vulnerabilities
and found very weak or no evidence of vulnerability deple-
tion. He thus suggested that the vulnerability discovery ef-
forts might not provide much social beneﬁt [34]. On the
other hand, this conclusion is challenged by Ozment and
Schechter, who showed that the pool of vulnerabilities in
the foundational code of OpenBSD is being depleted with
strong statistical evidence [31, 32]. Ozment also found that
vulnerability rediscovery is common in the OpenBSD vul-
nerability discovery history [31]. Therefore, they gave the
opposite conclusion, i.e., vulnerability hunting by white hats
is socially beneﬁcial. More recently, Shahzad et al. [36] con-
ducted a large-scale study of the evolution of the vulnera-
bility life cycle using a combined dataset of NVD, OSVDB
and FVDB. Their study provided three positive signs for
increasing software security: (1) monthly vulnerability dis-
closures are decreasing since 2008, (2) exploitation diﬃculty
of the identiﬁed vulnerabilities is increasing, and (3) soft-
ware companies have become more agile in responding to
discovered vulnerabilities. In another study, Frei et al. stud-
ied a security ecosystem including discovers, vulnerability
markets, criminals, vendors, security information providers
and the public, based on 27,000 publicly disclosed vulnera-

1106bilities [21]. They focus on vulnerability exploits and patch-
ing of native software, while we study the ecosystem around
the discovery of web vulnerabilities, and our main focus are
the behaviors and dynamics of white hats and organizations
that compose such ecosystems.
2.2 Vulnerability Discoverers

Most of the existing research on software security focuses
on vulnerabilities, aﬀected software products or vulnerabil-
ity discovery tools. More recently, researchers started to pay
attention to the humans who make vulnerability discoveries.
Edmundson et al. conducted a code review experiment for
a small web application with 30 subjects [17]. One of their
ﬁndings is that none of the participants was able to ﬁnd
all 7 Web vulnerabilities embedded in the test code, but a
random sample of half of the participants could cover all vul-
nerabilities with a probability of about 95%, indicating that
a suﬃciently large group of white hats is required for ﬁnding
vulnerabilities eﬀectively. This is consistent with our anal-
ysis in Section 4.2.2 and Section 4.3.7. However, the code
review process they focused on is mainly conducted inside an
organization with source code available; while the vulnera-
bility hunting focused on in this paper is conducted outside
an organization. Finifter et al. provided contribution and
payment statistics of participants in Google Chrome VRP
and Mozilla Firefox VRP [20], and suggested that VRPs
are more cost-eﬀective compared to hiring full-time secu-
rity researchers. Previous work has also reported that many
discoverers primarily rely on their expertise and insights,
and limited types of tools such as fuzzers and debuggers,
rather than sophisticated automated vulnerability discovery
tools [13, 19]. Zhao et al. conducted an initial exploratory
study of white hats on Wooyun [38] and uncovered the di-
versity of white hat behaviors on productivity, vulnerability
type specialization, and discovery transitions.
2.3 Vulnerability Markets

B¨ohme oﬀers a terminology for organizational principles of
vulnerability markets by comparing bug challenges, vulner-
ability brokers, exploit derivatives and cyber-insurance [14].
Algarni and Malaiya analyzed data of several existing vul-
nerability markets and showed that the black market oﬀers
much higher price for zero-day vulnerabilities, and govern-
ment agencies make up a signiﬁcant portion of the buy-
ers [13]. Ozment proposed a vulnerability auction mecha-
nism that allows a software company to measure its soft-
ware quality based on the current bounty level, and to con-
duct vulnerability discovery at an acceptable cost [30]. This
auction model can potentially be incorporated into today’s
vulnerability discovery ecosystems. A panel discussion at
the New Security Paradigms Workshop examined ethics and
implications for vulnerability markets [18]. Finally, Kannan
and Telang showed that unregulated vulnerability markets
almost always perform worse than regulated ones, or even
no market at all [24]. They also found that it is socially ben-
eﬁcial to oﬀer rewards for benign vulnerability discoverers.

3. METHODOLOGY
3.1 Analysis Overview

We organize our analysis around three components: the
vulnerabilities disclosed, the white hats, and the involved
businesses/organizations. Figure 1 outlines the structure of

Figure 1: Structure of a web vulnerability discovery ecosys-
tem.

a representative web vulnerability discovery ecosystem. In
the following, we describe our data collection eﬀorts.
3.2 Data Collection

We have collected publicly available data from Wooyun
and HackerOne. The processed data and related Python
scripts can be shared upon request in order to reproduce
and extend our research.

3.2.1 Wooyun
Wooyun is the predominant web vulnerability disclosure
program in China launched in May 2010. It has attracted
7,744 white hats who contributed 64,134 vulnerability re-
ports related to 17,328 organizations. In most cases, Wooyun
does not oﬀer monetary rewards.

We choose Wooyun as one of the data sources for our study
for several reasons. First, Wooyun insists on a delayed full
disclosure policy, which states that the vulnerability will be
disclosed 45 days after the submission of the report, irre-
spective of whether the organization has addressed the issue
or not. To the best of our knowledge, it is the only plat-
form that has such a disclosure policy. We will focus on this
aspect in Section 5.1. Second, Wooyun covers the longest
period of time and the largest number of contributions com-
pared with other platforms (Table 1). It also includes a large
number of organizations from several diﬀerent sectors, as we
will discuss in Section 4.3.3. This is because Wooyun has a
very relaxed submission rule compared with other US-based
platforms: white hats can submit a vulnerability report to
Wooyun for almost any organization, and Wooyun will pub-
lish it as long as the report is considered valid.

We crawled the vulnerability reports on Wooyun pub-
lished from May 2010 to early August 2015. For each vul-
nerability report, we collected the following data ﬁelds: (1)
white hat’s registration name, (2) target organization, (3)
vulnerability type, (4) severity and (5) submission time. We
further explain key data types below.

Vulnerability type: Each vulnerability report on Wooyun
has a vulnerability type from a predeﬁned list. However, we
also observe that for some reports, the vulnerability types
used are not in the list, possibly due to mistakes. We manu-
ally corrected these instances. We also translated the types
from Chinese into English and list them in Figure 5.

Severity: The severity level of a vulnerability reﬂects its
impact on the target organization. There are three levels:
high, medium and low. We mainly use the severity level as-
signed by the aﬀected organization or by the Wooyun plat-

Stockpiled Vulnerabilities Black Hats Public Bug Bounty Platform Organizations White Hats Disclosed Vulnerabilities Respond & Reward Submit Vulnerability Reports Reduce Learn Discover and Exploit Vulnerabilities Personal Data Security Assessment 1107form. If this information is missing (e.g., when the organiza-
tion does not respond to the report), we will use the severity
level provided by the white hat reporter.

We have also collected the following data:
Organization website’s URL and Alexa rank : To examine
whether a website’s popularity is related to vulnerability dis-
covery, we collected the website’s rank from the Alexa Top
Sites service. Since Wooyun does not provide the URL for
all organizations, we wrote a script that queries the orga-
nization’s name on Google and takes the ﬁrst result as the
URL. We then retrieved the Alexa rank of all websites from
the Alexa Top Sites service. Since most websites on Wooyun
are Chinese, we use the Chinese Alexa rank, rather than the
global rank.

Organization sector : We also categorized organizations
into diﬀerent sectors. The deﬁnition of sectors are based
on previous studies [15, 6]. The categorization is initially
based on patterns in the organization’s name. For example,
universities have names like “XX university” or “university
of XX”. After this step, we further manually categorized the
remaining organizations that have received more than 40
vulnerabilities into diﬀerent sectors.

Our dataset cannot contain all vulnerabilities discovered
by white hats for organizations. First, due to the large vol-
ume of vulnerability reports received, Wooyun may ignore
vulnerabilities that are considered irrelevant or of very low
importance, such as many reﬂected XSS vulnerabilities [2].
The impact of this initial expert selection is ambiguous, but
we expect that our analysis may beneﬁt from a heightened
focus on valuable contributions. Second, white hats are
starting to use alternative platforms such as Vulbox which
do not have a public disclosure policy. As Wooyun remains
the dominant platform for Chinese website vulnerabilities,
we anticipate that the latter eﬀect is relatively small.

3.2.2 HackerOne
HackerOne is a US-based bug bounty platform started in
November 2013. As of early August 2015, it facilitates 99
public bug bounty programs for global companies such as
Yahoo, Mail.ru and Twitter. Unlike Wooyun, white hats on
HackerOne can only submit reports for these organizations.
HackerOne also hosts invitation-only programs. To be eligi-
ble white hats must reach a reputation score threshold. Sim-
ilar programs, such as BugCrowd also separate bounty pro-
grams into public and invitation-only [12]. Unfortunately,
invitation-only programs cannot be accessed publicly, so our
dataset only includes public programs.

Our HackerOne dataset includes contributions from 1,653
white hats. An organization can either reward white hats
with reputation scores or monetarily compensate them. Un-
like Wooyun, HackerOne does not have a delayed public
disclosure policy. A vulnerability report can only be dis-
closed if both the white hat and the organization commit
to its publication. As a result, only a small fraction (732 of
10,997) of all reports are publicly disclosed. For other re-
ports, we only know limited metadata, including submission
times, white hat identiﬁers, and the names of the aﬀected
organizations for each vulnerability. We are able to collect
the metadata of 6,876 reports from public bounty programs
in total. They constitute 62.5% of all resolved reports. We
assume the remainder to be reports for invitation-only pro-
grams. In addition, HackerOne hosts bounty programs for
several open source software projects, such as Perl, Python,

OpenSSL. We exclude 69 reports for these bounty programs
since they are not related to web vulnerabilities. Our data
includes 3,886 reports with bounties paid during the study
period. However, some organizations choose not to disclose
the bounty amount; i.e., only 1,638 reports have exact mone-
tary payment information. We calculate the average amount
of monetary reward paid by an organization, and refer to this
value as the expected reward.

4. RESULTS
4.1 Vulnerability Disclosure Trends

Severity Levels

We ﬁrst provide an overview of the disclosed vulnerabil-
ities. Since the HackerOne dataset does not include data
about the vulnerability type and severity, we will mainly
focus on the Wooyun dataset.
4.1.1 Number of Vulnerabilities
The number of vulnerabilities accepted by the bug bounty
platforms provides an initial overview of the productivity
of the web vulnerability discovery ecosystems, and also re-
ﬂects the time trend of web security. Table 1 shows that
each of the major bug bounty platforms has published a
large number of vulnerability reports. Figure 2 further dis-
plays the number of vulnerabilities accepted by Wooyun and
HackerOne every month. For Wooyun, the number of vul-
nerabilities accepted per month continues to grow rapidly
in the 5-year span. After an initial growth, the number of
vulnerabilities for HackerOne’s public bounty programs is
relatively stable at around 400 per month. We suspect that
an inclusion of data for invitation-only programs would also
result in an upward trend for the HackerOne trajectory.
4.1.2
We break down the overall vulnerability trend on Wooyun
by severity in Figure 3. While the percentage of low sever-
ity vulnerabilities is decreasing, the percentage of published
high severity reports is increasing over time. One known
reason is the intentional omission of certain low severity
reports, as we have discussed in Section 3.2.1.
It is also
possible that white hats are becoming more skilled in ﬁnd-
ing severe vulnerabilities over time. Another hypothesis is
that low severity vulnerabilities are easier to discover and
thus are usually reported well before more severe problems.
Further investigation of these possible causes would be an
interesting research question. Overall, the displayed trend
indicates that organizations inside this ecosystem are still at
risk, and more eﬀorts from both the white hat community
and the involved organizations are required.
4.1.3 Vulnerability Types
We next examine vulnerability reports on Wooyun accord-
ing to their types. Figure 4 shows the trend for the top 3
most common vulnerability types. While the percentage of
XSS reports is decreasing (possibly due to ﬁltering as men-
tioned previously), we observe a small relative increase of
SQL injection reports. The high amount of XSS is expected
for web applications; other platforms, such as BugCrowd,
have also reported that XSS is the most common vulner-
ability type (17.9%) [12]. In contrast, the high amount of
SQL injection vulnerabilities on Wooyun is particularly sur-
prising, since SQL injection vulnerabilities are not common
on other platforms such as BugCrowd (only 1.3%) [12]. A

1108Figure 2: Number of vulnerabilities
reported per month on Wooyun and
HackerOne (public data).

Figure 3: Trend of vulnerabilities with
diﬀerent severity on Wooyun.

Figure 4: Trend of top 3 vulnerability
types on Wooyun.

recent study also reveals that many Chinese websites are
generally less secure [15]. However, the observed diﬀerences
could also be caused by the particular organization partici-
pation model of Wooyun, which is able to cover much more
poorly secured websites. We will discuss more on this in
Section 5.4.

Figure 5: Number of reports for each vulnerability type on
Wooyun (log scale). The compact visualization uses three
colors to represent the percentage of three severity levels.
Note that percentages are not aﬀected by the log scale.
Types in bold font also appear in OWASP’s 2013 top 10 [1].

Figure 5 further shows the number of published reports,
and the breakdown in severity categories for all vulnerabil-
ity types on Wooyun. The distribution across vulnerability
types is comparable to other sources [12, 1]. We also observe
that some types have a larger proportion of high severity
vulnerabilities; for example, SQL injection attacks and ma-
licious ﬁle uploads may frequently open up a direct pathway
to sensitive data.

In summary, data from bug bounty platforms can be used
to meaningfully aggregate valuable security information. Dis-
closing such information, even at the aggregate level, can
help the defense side to update its strategies and to allocate
resources against diﬀerent types of threats.
4.2 The White Hat Community

In this section, we ﬁrst look at the size and growth of the
white hat communities on Wooyun and HackerOne. Then,

we discuss signiﬁcant diﬀerences regarding productivity and
accuracy among white hats using the two datasets. Next, we
investigate diﬀerent skills and strategies of white hats. Fi-
nally, we analyze how disclosure of reports can have positive
eﬀects on the white hat community.

Size and Growth

4.2.1
The outcome of a web vulnerability discovery ecosystem is
closely related to the size of the white hat community, who
is the “supplier” of vulnerability reports. Table 1 shows that
these ecosystems have accumulated large white hat commu-
nities with tens of thousands of contributors, who may come
from all over the world [12, 4]. Later, we will analyze how
the size and the diversity within the white hat community
correlate with vulnerability discovery outcomes.

We ﬁrst examine how the size of the white hat community
changes over time, using two metrics: the number of white
hats who reported at least one vulnerability in each month
(active white hats), and the number of white hats who sub-
mitted their ﬁrst vulnerability in each month (new white
hats). The diﬀerence between the number of active white
hats and the number of new white hats is the number of re-
peat contributors. We report these two metrics for Wooyun
and HackerOne in Figure 6. For Wooyun, the number of ac-
tive white hats per month gradually grows to 700 per month.
The number of new white hats per month is about 200 in the
past 2 years, which means that there is a relatively constant
ﬂow of newcomers joining the ecosystem. The trend for the
public programs of HackerOne is similar. In summary, both
platforms attract a relatively constant number of white hats
who contribute in a given month, while the overall size of
the white hat community keeps increasing.

4.2.2 Productivity and Accuracy
While the size of the community matters, we also care
about the individual productivity of a white hat, i.e., the
number of vulnerabilities found by each white hat. In Fig-
ure 7, we plot the distribution of vulnerabilities found by
individual white hats on both Wooyun and HackerOne. We
observe that the distributions on both platforms are very
skewed. Of 7,744 white hats on Wooyun, the top 1 has
found 521 vulnerabilities, the top 100 have published more
than 147 reports per person on average, but 3725 of the
white hats have contributed only once. Similar observations
can be made for white hats on HackerOne. Such long-tail
pattern has also been found in other domains, such as sci-
entiﬁc productivity [26].

2010-072010-102011-012011-042011-072011-102012-012012-042012-072012-102013-012013-042013-072013-102014-012014-042014-072014-102015-012015-042015-0705001000150020002500300035004000CountWooyunHackerOneP2010-072010-102011-012011-042011-072011-102012-012012-042012-072012-102013-012013-042013-072013-102014-012014-042014-072014-102015-012015-042015-070.00.10.20.30.40.50.60.70.8PercentageHighSeverityMediumSeverityLowSeverity2010-072010-102011-012011-042011-072011-102012-012012-042012-072012-102013-012013-042013-072013-102014-012014-042014-072014-102015-012015-042015-070.00.10.20.30.40.50.60.7PercentageSQLInjectionDesignFlaws/LogicErrorsXSSSQLInjectionDesignFlaws/LogicErrorsXSSSensitiveInfo.LeakageCodeExecutionWeakPasswordUnauth.Access/Priv.Esc.System/ServiceMisconﬁg.FileUploadSuccessfulIntrusionPathTraversalWeakAccessControlUnpatchedSystem/ServiceCSRFApplicationMisconﬁgurationDenialofServiceFileInclusionAuthenticationBypassURLRedirectPhishingMaliciousContent100101102103104105Count(log)HighSeverityMediumSeverityLowSeverity1109Figure 6: Number of new white hats
and active white hats per month on
Wooyun and HackerOne.

Figure 7: Contribution count of white
hats on Wooyun and HackerOne (log-
log). Vertical bars: thresholds for dif-
ferent productivity groups on Wooyun.

Figure 8: Distribution of follower count
for vulnerabilities with diﬀerent severity
(log-log).

Another important aspect associated with productivity
is accuracy. Many existing public bounty programs have
complained about the low signal-to-noise ratio and the ef-
fort required to deal with a large amount of invalid re-
ports, which generally include duplications, non-security is-
sues, out-of-scope, false positives, or even spam [12, 9, 4, 8].
The signal-to-noise ratio is roughly 20% for platforms such
as HackerOne and BugCrowd, and even lower for individu-
ally hosted bounty programs by Facebook and Github [12,
8]. In addition, HackerOne has reported that in general more
productive researchers have a higher signal-to-noise ratio [8].
Based on [8], we estimate that the top 1% researchers on
HackerOne have an average ratio of 0.54, while the bottom
50% only have an average ratio of 0.03, indicating that ap-
proximately among 100 reports submitted by them, only 3
are expected to be valid vulnerability reports. Bug bounty
platforms have introduced various data-driven approaches,
including reputation systems and rate limiting, to improve
the signal-to-noise ratio [8]. This partly explains the higher
signal-to-noise ratio of bounty platforms over individually
hosted bounty programs. However, the low signal-to-noise
ratio remains a key challenge for eﬀective vulnerability dis-
covery and requires more research eﬀort.

The long-tailed distribution of contribution levels as well
as concerns about accuracy lead to an increased focus on the
top contributors in today’s bug bounty programs, since they
are on average much more productive, and more accurate.
As a result, existing bounty platforms such as HackerOne
and BugCrowd have created private bounty programs that
only invite a small number of top contributors [12, 9, 8].
In some cases, the top contributors were directly hired by
organizations or bounty platforms [4, 7].

Less attention is given to white hats with lower produc-
tivity. However, taken as a group, they contribute a sizable
number of accepted reports. As such, the question arises
how to evaluate their contributions. To do an initial com-
parative assessment, we split the white hat community on
Wooyun into three groups of diﬀerent levels of productiv-
ity. The two thresholds, displayed in Figure 7, are chosen so
that the three groups have approximately the same number
of reports, thus allowing us to compare other dimensions of
their contributions.

We report the results in Table 2. Unsurprisingly, the av-
erage number of accepted reports diﬀers substantially across
these groups. In contrast, an interesting observation is that
the less productive groups have contributed reports for a

Variable
# white hats
Total # vuln.
Average # vuln.
# contributed org.
Alexa 1-200 (%)
Alexa 201-2000 (%)
Alexa > 2000 (%)
Severity High (%)
Severity Medium (%)
Severity Low (%)

Productivity Groups
High Medium Low
6,972
142
17,595
17,611
2.5
124
4,727
7,247
33.1
32.5
34.0
32.4
33.3
33.7
38.4
28.1
36.1
31.3
25.1
40.4

658
17,586
27
5,686
34.4
33.6
32.9
33.5
32.5
34.5

Table 2: Comparison across three white hat groups of dif-
ferent productivity levels on Wooyun.

considerably larger number of organizations. There could
be multiple reasons to explain this diﬀerence. First, the
less productive groups have many more white hats, leading
to more “manpower” and more diverse interests covering a
wider range of websites. Meanwhile, white hats in the highly
productive group have more limited attention or may ben-
eﬁt from an increased focus on a speciﬁc set of websites.
Second, some websites may have been particularly popular
targets for white hats, and easy-to-be-found vulnerabilities
are already removed. For many low productive white hats
who may also have limited expertise, spending eﬀort on such
websites might not be cost-eﬀective. Thus, they shift their
attention to other websites, which are more likely to yield
discoveries.

The broader coverage of websites by less productive white
hats has a positive impact on the security of the Inter-
net, since even less popular sites still receive a considerable
amount of visitors every day. In addition, the security of or-
ganizations is rather connected in many ways [22, 33]. For
example, a user could use the same username and password
across multiple sites, and the compromise of one of them will
jeopardize others. Therefore, by complementing the limited
attention of top white hats, the less productive white hat
groups make diﬀerent but important contributions.

We further break down the contributions of each group
by target websites’ popularity and by vulnerability severity.
Rows 5 - 7 of Table 2 show that for the diﬀerent popularity
categories the contributions (in %) across the three produc-
tivity groups are remarkably consistent. In particular, the

2010-072010-102011-012011-042011-072011-102012-012012-042012-072012-102013-012013-042013-072013-102014-012014-042014-072014-102015-012015-042015-070100200300400500600700800CountActive(Wooyun)New(Wooyun)Active(HackerOneP)New(HackerOneP)100101102103104Whitehatranked100101102103VulnerabilityCount(log)WooyunHackerOneP100101102103104105Vulnerabilityranked100101102103FollowerCountTotalHighMediumLow1110least productive group also reports a signiﬁcant percentage
of discoveries for popular websites. Row 8 shows that more
productive white hats have a larger percentage of contri-
butions with high severity vulnerabilities, but 28.1% of high
severity vulnerabilities were still discovered by the least pro-
ductive white hats.

In summary, the results support the existence of a sub-
stantial expertise and productivity gap on an individual
level, but from a collective perspective the diﬀerence is smaller
than perhaps expected. How to better utilize the potential
of these diﬀerent groups of white hats is an interesting chal-
lenge. In particular, it would be useful to think about how to
boost the productivity of less productive white hats through
better incentives, training, and other measures.

4.2.3 Skills and Strategies
Next to productivity, we measure two additional metrics:
the number of diﬀerent organizations an individual white hat
investigated, and the number of diﬀerent vulnerability types
an individual white hat reported. These two metrics partly
reﬂect the skills, experiences and strategies of white hats.
Figure 9 shows the distribution of these two metrics for white
hats on Wooyun with more than 5 discoveries. The average
number of organizations investigated by a white hat of this
group is 18, while the average number of vulnerability types
found is 7. The most productive individuals (i.e., red trian-
gles in the ﬁgure) generally surpass others in both metrics
which partially explains the productivity diﬀerence. First,
top white hats’ broad knowledge of diﬀerent types of vulner-
abilities may enable them to discover more vulnerabilities.
Second, they may ﬁnd more vulnerabilities because their
strategy is to investigate a larger number of websites. Fur-
thermore, we hypothesize that there is a trade-oﬀ between
exploration vs. exploitation: to ﬁnd more vulnerabilities, a
white hat must develop a good balance between spending
eﬀort at one particular website and exploring opportunities
on other sites. However, diﬀerent successful strategies co-
exist. For example, our dataset includes several white hats
in the bottom left corner of Figure 9 that is much more fo-
cused on exploitation. Similarly, a white hat named ‘meals’
ranked 4th on HackerOne only focuses on Yahoo’s bounty
platform, and has to-date found 155 vulnerabilities.

Investigating the optimal degree of strategy diversiﬁcation
during web vulnerability hunting is an interesting area for
future work.

4.2.4 Disclosure and Learning
A primary consideration of previous research was to un-
derstand how vulnerability disclosure pushes software ven-
dors to ﬁx ﬂaws in their products [35, 36]. However, when
considering the whole ecosystem, we question whether vul-
nerability disclosures also have positive eﬀects on the white
hat community itself. One possible eﬀect is to enable white
hats to learn valuable technical insights and skills from oth-
ers’ ﬁndings. Another eﬀect is to obtain valuable strate-
gic information for their own vulnerability discovery activ-
ities, such as which organizations to investigate. Both ef-
fects likely improve white hats’ productivity and accuracy.
In addition, the software engineering community and peer
organizations can also learn valuable lessons from vulnera-
bility reports to avoid making similar mistakes in the future.
While the latter factor may be of high practical relevance,

Figure 9: Scatter plot of white hats’ vulnerability type count
and targeted organization count on Wooyun. Each dot rep-
resents a white hat who has found more than 5 vulnerabil-
ities in total. The red triangle dots are white hats of the
high productivity group deﬁned in Section 4.2.2.

we are unaware of related research. In this paper, we inves-
tigate the ﬁrst eﬀect using data from Wooyun.

The Wooyun platform allows white hats to mark and fol-
low a particular report. Therefore, we can use the number
of followers of a vulnerability report as an approximate indi-
cator of its learning value to white hats. In Figure 8, we plot
the distribution of this follower count for all vulnerabilities
on Wooyun, and also break down the data by diﬀerent sever-
ity levels. We observe that the distribution is very skewed.
There are 9,489 reports that have at least 10 followers, in-
dicating that white hats have been actively learning from a
broad portion of reports. On average, high severity vulnera-
bilities have more followers, which is not surprising, as more
severe vulnerabilities tend to have a more signiﬁcant secu-
rity impact, and higher discovery and exploit complexity.
What might be counter-intuitive is that some low severity
vulnerabilities still receive more than 100 followers.

To examine why some vulnerabilities have received much
more attention than others, and why some low severity vul-
nerabilities are followed by many, we selected the 30 most
followed vulnerabilities from each severity level. We then
manually examined these 90 vulnerabilities. We ﬁnd that
these vulnerabilities mostly belong to one or more of the
following categories: (1) Vulnerabilities with signiﬁcant im-
pact (e.g., with a potential for massive user data leakage,
or an XSS inside the site statistics javascript code from a
major search engine company); (2) Vulnerabilities that are
associated with novel discovery or exploitation techniques;
(3) Vulnerabilities of widely used web applications, such as
CMS; (4) Vulnerabilities that are explicitly organized as tu-
torials. We found 21 such tutorial-style reports belonging to
a series about XSS, which are all of low severity, yet they

050100150200250NumberofOrganizations0510152025NumberofVuln.Types0501001502000501001502002501111still receive a lot of attention because of the emphasis on
learning. We also examined a subset of disclosed reports
from HackerOne and have discovered that some organiza-
tions make disclosures3 to teach the writing of concise re-
ports.

In summary, our analysis provides evidence of how white
hats are learning from vulnerability reports; a typically over-
looked beneﬁt of vulnerability disclosure to the white hat
community. We will discuss additional facets of disclosure
in Section 5.1.
4.3 Organizations

We now shift our focus to the organizations who have
participated in vulnerability discovery ecosystems. These
organizations harvest vulnerability reports from the white
hat community, ﬁx security ﬂaws, and thereby ultimately
improve the security of the whole Internet (e.g., by reduc-
ing the impact of security interdependencies [22, 33]). How-
ever, collecting data about them is non-trivial because many
organizations, such as banks, are still reluctant to collabo-
rate with white hats due to various concerns [3]. In addi-
tion, for many organizations who joined platforms such as
HackerOne, data about discovered vulnerabilities, monetary
rewards and other important factors is often not publicly
disclosed.

Wooyun provides a valuable opportunity to study the im-
pact of such ecosystems on organizations; and not only be-
cause of the existence of the delayed public full disclosure
policy. More importantly, an organization is rather coerced
to join this ecosystem once a white hat publishes a vul-
nerability on Wooyun aﬀecting the organization. This coer-
cive model is diﬀerent from most other platforms which only
host bounty programs for organizations that agree to par-
ticipate (i.e., voluntary model ). Due to the diversity of the
large white hat community, Wooyun covers a broad range
of organizations from many sectors, as we will show in Sec-
tion 4.3.3. As a result, observations made from this dataset
do not only help us understand the web vulnerability dis-
covery ecosystem in China, and the general security status
of the Chinese web, but also help us to envision the impact
of the bug bounty model for organizations in other parts of
the world.
4.3.1 Size and Growth
Table 1 lists the number of organizations participating in
representative vulnerability discovery ecosystems. We ob-
serve that Wooyun aﬀects a larger number of organizations
compared with US-based platforms, who typically have tens
or hundreds of participating organizations. The diﬀerence
is partly due to the coercive versus voluntary ways of in-
volving organizations. Therefore, the Wooyun ecosystem
roughly represents an upper bound of coverage (growth) for
other ecosystems. We also investigate the trajectory of the
growth of the number of organizations covered on Wooyun.
Figure 10 shows that in every month, there are about 300
organizations beneﬁting from white hats’ eﬀorts. Around
150 of them are new organizations, which implies that the
white hat community is continuously broadening its horizon.
It would be interesting to understand whether this eﬀect re-
lies on the fact that new businesses are founded (or new
websites become public), or that white hats are moving to
already established but previously unresearched websites.
3For example: https://hackerone.com/reports/32825.

4.3.2 Vulnerability Distribution
For both Wooyun and HackerOne, Figure 11 shows that
only few organizations receive a high number of vulnerabil-
ity reports, while most organizations receive very few vul-
nerability reports. We hypothesize that the number of vul-
nerabilities received by organizations is related to multiple
factors, such as the complexity of the web system, the exis-
tence of monetary incentives, the popularity of the website,
etc. We will further investigate the relation between these
factors and the number of published vulnerability reports in
Section 4.3.7.
4.3.3
To investigate the diversity within participating organiza-
tions, we have manually tagged organizations on HackerOne
based on their business types. We ﬁnd that all participat-
ing companies are IT-focused and cater to diﬀerent busi-
ness/consumer needs which are shown in Table 3.

Impact on Different Sectors

social network (13), security (9), content sharing (9)
payment(8), communication (8), bitcoin (6),
cloud (5), customer management (5),
site builder (5), ﬁnance (4), ecommerce (4)

Table 3: Frequency of IT-business types within the group
of publicly available bounty programs on HackerOne. Only
tags with frequency greater than 3 are shown.

Due to its coercive model for involving organizations, the
Wooyun dataset includes a larger and more diverse set of
organizations (see Figure 12). Further, it shows that white
hats do not exclusively focus on certain business sectors.

For non-IT organizations, two sectors with many vulnera-
bility reports are government and ﬁnance. We consider this
ﬁnding surprising since these sectors have robust incentives
for security investments. While the ﬁnance sector, and pos-
sibly the government sector as well, are often not willing
to collaborate with non-commercial white hats [3], we infer
from the Wooyun data that they can disproportionally bene-
ﬁt from the involvement of the white hat community. Partic-
ipating in disclosure programs may also reduce the likelihood
that vulnerabilities ﬂow into the black market [21].

Portal sites, telecommunication and e-commerce organi-
zations have the highest number of vulnerability reports
in the IT-sector. A possible explanation is that web ser-
vices and systems from these domains are large and com-
plex which increases the amount of latent vulnerabilities.
Further, these companies serve substantial user populations
which increases their desirability for vulnerability researchers.
4.3.4 Response and Resolution
After the initial submission of a vulnerability report, the
typical follow-up process on most bounty platforms con-
tains the following steps: triage/conﬁrm, resolve, and dis-
close. During this process, the white hat and the secu-
rity/development team of the organization may collaborate
together to address the identiﬁed problem. A delayed re-
sponse likely increases the risk of a security breach, since it
increases the time frame for rediscovery of the vulnerabil-
ity, and stealthy exploitation of stockpiled vulnerabilities by
malicious agents. Given its full disclosure policy, a delayed
response to a submission on Wooyun may be even more se-
rious because details will be disclosed publicly after 45 days.

1112Figure 10: Count for new and total
number of organizations with vulnera-
bility reports (per month) on Wooyun.

Figure 11: Number of vulnerabili-
ties by organizations on Wooyun and
HackerOne.

Figure 12: Number of vulnerability re-
ports for non-IT businesses (left), and
IT-sector businesses (right) on Wooyun.

Our data allows us to examine how organizations respond
and resolve vulnerability reports in the studied ecosystems.
HackerOne maintains a detailed handling history for each
vulnerability report. Unfortunately, only a small portion of
all resolved reports (732 of 10,997) are publicly disclosed.
For these disclosed reports, we determined the time distri-
bution for three types of response activities (see Figure 13).
The median time for the ﬁrst response (e.g., a conﬁrma-
tion of receiving the report) is 0.18 days, and the median
time for triage is 0.88 days. The median resolve time is 6.49
days, and 75% of the disclosed reports are resolved in 25
days. However, one should be cautious when generalizing
from these observations since the data is possibly biased.
Particularly, the analysis likely underestimates the time re-
quired for triaging and resolving vulnerabilities, since the
organizations that are willing to disclose vulnerabilities may
be more eﬃcient in handling reports and may have more
experience in running bounty programs.

Figure 13: Boxplots for the time of three types of response
activities based on publicly disclosed reports on HackerOne.

Wooyun shows four types of responses by organizations:
conﬁrmed by organization (CO), conﬁrmed and handled by
a third party such as CNCERT (CT), ignored by the or-
ganization (IG), and no response (NO). Since all reports
are classiﬁed in this way, the Wooyun response data is con-
siderably larger, but provides less details. For example, it is
diﬃcult to discern whether the organization eventually ﬁxed
the vulnerability (or not), but the ﬁrst two types of response
can serve as an indication that the organizations recognizes
the problem. The third type of response suggests that the
organization considers the vulnerability report invalid. The
fourth type means that the organization did not respond to
the report at all. We use the count of the fourth type as
a rough estimate for the number of cases when an organi-
zation fails to address a vulnerability report, and consider

the other three types of responses as situations when the
vulnerability is likely being handled.

Overall (%)
Organizations:
- Alexa 1 - 200 (%)
- Alexa 201 - 2000 (%)
- Alexa > 2000 (%)

CO CT IG NO
40

23

34

3

71
57
28

13
18
44

5
4
1

12
20
26

Table 4: Percentages of diﬀerent types of responses by or-
ganizations on Wooyun.

Table 4 shows the percentages for the diﬀerent types of
response as a breakdown by the popularity of the websites.
We observe that overall, the majority (77%) of the vulnera-
bility reports have been handled. Popular websites address
more vulnerabilities by themselves, while less popular web-
sites rely more often on third parties. In addition, less pop-
ular websites have a higher rate of no response, possibly due
to limited resources for vulnerability management.
4.3.5 Monetary Rewards
We also examine the role of monetary rewards oﬀered by
some organizations. We observe that in their absence, white
hats still make contributions to Wooyun and HackerOne for
the purpose of making the Internet safer and for reputation
gains. For example, 33 of the public programs on HackerOne
do not provide monetary rewards, yet they still have received
1201 valid reports from the white hat community. But as
Table 1 shows, most platforms oﬀer monetary rewards as an
additional incentive for white hats to contribute their time
and expertise.

We conduct a preliminary analysis based on the disclosed
bounties for public programs on HackerOne. Given a total of
3886 bounties, 1638 have the amount information disclosed.
The maximum bounty is $7560, paid by Twitter, and the
average bounty amount is $424 which varies considerably
by organizations. Yahoo pays $800 on average, followed by
Dropbox ($702) and Twitter ($611). We hypothesize that
the current reward level is attractive to many white hats,
and we explore this topic in more detail with a regression
study in Section 4.3.7.
4.3.6
Improvements to Organizations’ Web Security
The participation in a bug bounty program should over
time improve the web security of an organization in a no-
ticeable way. In particular, it is reasonable to expect that the

2010-072010-102011-012011-042011-072011-102012-012012-042012-072012-102013-012013-042013-072013-102014-012014-042014-072014-102015-012015-042015-07020040060080010001200140016001800CountTotalOrg.NewOrg.100101102103104105Organizationsranked100101102103104NumberofVuln.WooyunHackerOnePGovernmentEducationFinanceTransportationTravel&HotelMediaHealthcareManufactoringEnergy&UtilitiesEntertainmentFood&DrinkPortalTelecomm.E-commerceGamingInformationVideo&PhotoOfﬁceCMSSecuritySocialNetworksForumHRMobileBrowser0100020003000400050006000FirstResponseTriageResolve10−510−410−310−210−1100101102103DaysSinceReportFiled(log)1113number of latent vulnerabilities in an average organization’s
web systems (and the stockpile of web vulnerabilities held
by black hats) would gradually diminish. Our data allows us
to investigate whether the number of vulnerability reports
per month is changing over time which is a relevant metric
in this context. Moreover, it is a type of analysis that can be
conducted by external evaluators if the bug bounty program
is public, and provides stakeholders an indication of the web
security of an organization. For example, the Cobalt bounty
platform oﬀers security seals for organizations that use their
services, which is expected to improve the public percep-
tion of the organization’s security [37]. Other services (e.g.,
cyber-insurance companies), can also beneﬁt from such se-
curity assessments (e.g., for the determination of insurance
premiums) [23, 25].

Figure 14: Trend of vulnerability report count for three or-
ganizations on Wooyun.

To initially explore this question, we show the vulnerabil-
ity report trends for three large organizations on Wooyun in
Figure 14. While one notices a slight decreasing trend for
Tencent, it is hard to observe a clear tendency for the other
two organizations. More importantly, Wooyun may not ex-
clusively host these organizations’ bounty programs which
could inﬂuence the analysis.

Figure 15: Trend of vulnerability report count for three or-
ganizations on HackerOne.

In contrast, HackerOne is tasked to exclusively host bounty
programs for participating organizations which ensures a
more reliable analysis. We show the vulnerability trends
for the three organizations with the most vulnerabilities on
HackerOne (Figure 15).
Interestingly, these organizations
have received a large volume of vulnerability reports right
after the launch of their bounty programs. We propose three
possible explanations. First, the monetary compensation of-
fered by HackerOne provides stronger incentives for white
hats to compete for vulnerability discoveries in the early
stage of a bounty program since the bounty program only
rewards the ﬁrst discoverer. Second, the target range for

white hats on HackerOne is much more limited compared
to Wooyun, thus concentrating white hats’ focus. Third,
some white hats might have stockpiled vulnerabilities to of-
ﬂoad them for reward in anticipation of the opening of new
reward programs. After these initial spikes, the number
of vulnerability reports on HackerOne drops signiﬁcantly,
possibly because the diﬃculty of ﬁnding new vulnerabilities
is increasing. However, even though we observe decreasing
trends, these organizations still receive a positive number of
vulnerability reports every month. These additional discov-
eries may either be related to further latent vulnerabilities
in existing code or stem from new code. Therefore, we sug-
gest that organizations continuously collaborate with white
hats.

To further examine the vulnerability trends for organiza-
tions, we apply the Laplace test [32] to the vulnerability
history of organizations who have received at least 50 re-
ports and have a bounty program for more than 4 months.
We also excluded data before 2012-02 and 2014-02 (the ini-
tial growth periods), for Wooyun data and HackerOne data,
respectively. This test indicates whether there is an increas-
ing trend, a decreasing trend, or no trend for the number of
reported vulnerabilities for a given organization (Table 5).

Platform Decrease
Wooyun
HackerOne

11
32

Increase No Trend
81
8

17
9

Table 5: Trend test results for organizations on Wooyun and
HackerOne. The conﬁdence level is 0.95.

Only 11 of the 109 organizations on Wooyun (which match
the criteria) ﬁt a decreasing trend, while most selected orga-
nizations have an increasing trend for the number of vulner-
ability reports. The data omission bias discussed previously
could be one reason of the result. A suﬃciently large pool
of latent vulnerabilities in combination with increasing ac-
tivity on Wooyun could serve as an alternative explanation.
For organizations on HackerOne, 32 of 49 have a decreasing
trend indicating a positive eﬀect of the vulnerability discov-
ery ecosystem.

The trend test, however, cannot completely assess the web
security status of an organization for several reasons which
we have partly discussed above. Further, as a possible part
of their vulnerability discovery strategy (see Section 4.2.3),
white hats might switch to new organizations or newly de-
ployed web systems which are expected to have more low
hanging fruits. In general, we suggest that a reliable assess-
ment requires careful modeling and statistical analysis of the
whole ecosystem which is an important area for future work.
4.3.7 Attracting Vulnerability Reports
How can an organization harvest more vulnerability re-
ports from the white hat community to improve its web
security? To address this question, we ﬁrst study the corre-
lation between the number of vulnerability reports per or-
ganization and the number of contributing white hats.

Figure 16 plots the number of white hats that have made
at least one discovery, and the number of vulnerabilities, for
each organizations (with at least 20 vulnerability reports) on
Wooyun and HackerOne. We observe very strong positive
linear (Pearson) correlations for these measures (as shown
in the ﬁgures). Therefore, the following strategies are likely

07/1011/1103/1307/140102030405060Tencent07/1011/1103/1307/1451015202530354045Sina07/1011/1103/1307/14051015202530354045Baidu11/1305/1411/1405/15050100150200Yahoo!11/1305/1411/1405/15020406080100120140Mail.Ru11/1305/1411/1405/15020406080100Slack1114(1)

(2)

(3)

# Vuln. # Vuln. # Vuln.

VARIABLES

Expected Reward (Ri)

Alexa [log] (Ai)

Platform Manpower (Mi)

0.04***
(0.01)

0.03***
(0.01)
-2.52*
(1.20)

Constant

R-squared

16.12**
(6.39)
0.39
Standard errors in parentheses
*** p<0.01, ** p<0.05, * p<0.1

3.21*
(1.88)
0.35

0.03***
(0.01)
-2.70**
(1.21)
10.54
(10.14)
-133.05
(143.66)

0.40

Figure 16: Scatter plots of organizations’ white hat count
and vulnerability count for Wooyun and HackerOne public
programs (excluded Yahoo and Mail.ru as outliers).

Table 6: Results of regression analysis. There are 60 obser-
vations (HackerOne).

beneﬁcial: (1) While paying special attention to top con-
tributors is a useful strategy, it is also important to increase
the total number of contributors. A possible reason to ex-
plain the observed eﬀect is that vulnerability discovery re-
quires diversity, i.e., investigators with diﬀerent expertise
using diﬀerent tools may ﬁnd diﬀerent vulnerabilities; (2) It
is important to incentivize new participation, for example,
by oﬀering an extra bonus (e.g., badge or money) for the
ﬁrst valid submission of a white hat to a platform or speciﬁc
program.

Other factors such as the popularity of the target, the
expected bounty amount, and the number of alternative
choices are all related to a bounty program’s attractiveness
to white hats. To better understand these factors, we con-
duct a linear regression by taking the number of vulnerabil-
ity reports as the dependent variable and other factors as
independent variables, as the following equation shows:

Vi = β0 + β1Ri + β2Ai + β3Mi + i

where for each organization, Vi is the average number of
vulnerabilities per month, Ri is the expected reward, Ai is
the log Alexa rank of i’s website, and Mi is the average
platform manpower during the lifetime of organization i’s
bounty program. Mi is deﬁned as the time-weighted number
of white hats divided by the time-weighted number of peer
organizations during the lifetime of i’s bounty program:

N W1Ti +(cid:80)Ti
N O1Ti +(cid:80)Ti

Mi =

k=2(N Wk − N Wk−1)(Ti − k + 1)
k=2(N Ok − N Ok−1)(Ti − k + 1)

Here, Ti is the number of months for i’bounty program.
N Wk and N Ok are the accumulated number of white hats
and the number of peer organizations on the whole platform
at the kth month for organization i, respectively.

Table 6 shows three variations of the regression model. In
all three models, we ﬁnd a highly signiﬁcant positive corre-
lation between the expected reward oﬀered and the number
of vulnerabilities received by that organization per month.
Roughly speaking, a $100 increase in the expected vulnera-
bility reward is associated with an additional 3 vulnerabil-
ities reported per month. We also ﬁnd a signiﬁcant nega-
tive correlation between the Alexa rank and the number of
vulnerabilities in models (2) and (3) suggesting that rank

determines the attractiveness of a website to white hats.
However, it is also possible that less popular websites are
in general less complex in design and implementation, and
thus contain less vulnerabilities. For model (3), we expect
that with higher average platform manpower, an organiza-
tion will receive more attention from white hats and thus will
have more vulnerability reports. However, the analysis does
not yield a conclusive answer, possibly due to the omission
of invitation-only programs and limited sample size.

The quantiﬁed model can be used by organizations when
determining their bug bounty policies and attracting an ef-
fective white hat following. In particular, oﬀering higher re-
wards and running the program for a longer time contributes
to a higher number of reports. The model also contributes
to the security assessment question in Section 4.3.6. Nev-
ertheless, our regression model is only a ﬁrst step towards
modeling the dynamics of the web vulnerability discovery
ecosystem.
It could be extended with more independent
variables, such as the business type of organizations (see
Section 4.3.3), or the expected rewards from peer organiza-
tions in the ecosystem.

5. DISCUSSION

5.1 Importance of Disclosure

Based on our analysis, we believe that disclosing impor-
tant information about vulnerability discovery (such as the
resolve time for each vulnerability, bounty amounts, and
even the detailed reports) is important for the success of
a web vulnerability discovery ecosystem. For the white hat
community, disclosing more vulnerability information not
only enables them to learn and improve, but also poten-
tially allows to make better decisions on target selection, as
we have discussed in Section 4.2.4. The transparency as-
sociated with disclosure could also reduce conﬂicts between
organizations and white hats on issues like the validity of a
report or the reasonableness of a bounty amount. For or-
ganizations, disclosing more information enables the public
(e.g., Internet users, or cyber-insurance providers) to better
assess the security of an organization (Section 4.3.6). Dis-
closure is also vital for the research community to tackle
some of the challenging issues and future research questions
we have discussed. In addition, a platform such as Wooyun

0100200300400500600700800Wh.count(Wooyun)0500100015002000Vulnerabilitycountr=0.98p=0.00020406080100120140160Wh.count(HackerOneP)0100200300400500r=0.95p=0.001115with a delayed full disclosure policy also pushes organiza-
tions to ﬁx their reports sooner.

However, there are also potentially less desirable conse-
quences of disclosing vulnerabilities about organizations’ web
systems, such as the leakage of critical information that can
be utilized by black hats. An ideal disclosure policy has
to balance the potential beneﬁts and disadvantages to the
ecosystem or a speciﬁc organization. Several disclosure pro-
grams are moving towards this direction. For example, some
programs on HackerOne disclose only a subset of their vul-
nerabilities to the public. The Github bounty program dis-
closes data about every vulnerability discovered by white
hats, yet intentionally redacts certain details. Further an-
alyzing the beneﬁts and risks of disclosing vulnerability in-
formation, and designing improved disclosure policies is im-
portant future work.
5.2 Potential Incentive Structure Evolution

Our study shows that monetary incentives increase the
number of vulnerability reports (Section 4.3.7). We antic-
ipate that more organizations will start paying bounties,
as more organizations are joining vulnerability disclosure
ecosystems and are competing for the limited attention of
white hats. The amount of an average bounty will likely
rise not only for the purpose of attracting more white hats,
but also for compensating the increasing cost incurred by
white hats to discover vulnerabilities (e.g., to compete with
black hats). In addition, high reward amounts can also be a
positive signal of an organization’s security practices to the
public, similar to the proposal in [30].

Many organizations will continue to not oﬀer bounties.
For small organizations with limited revenues, maintaining
a competitive bounty level could be challenging.
It has
also been suggested that an organization could start with
no bounty ﬁrst, and gradually increase the reward level, to
alleviate the initial surge of reports (including many invalid
submissions) [27], as we have shown in Figure 15. Organiza-
tions that cannot aﬀord paying bounties can resort to other
forms of incentives, such as reputation scores, hall-of-fame
memberships, or even public disclosure.
5.3 Encouraging White Hat Participation

Increasing the size of the white hat community allows
more organizations to be covered and more vulnerabilities to
be found (see Section 4.2.2). A larger white hat community
might also decrease the cost of running bounty programs for
organizations, similar to the increase of supply in any eco-
nomic market. Therefore, potential regulations that hinder
the collaboration between white hats and organizations are
likely detrimental. One such example is the proposed up-
date of the Wassenaar Arrangement, which aims to control
the export of intrusion software. The utilized overly broad
deﬁnition of intrusion software could easily limit the partici-
pation of white hats [29], particularly considering the global
nature of the white hat community [4, 12].

To encourage more white hats to join the ecosystem, or-
ganizations can try to oﬀer a ﬁrst time bonus (see Sec-
tion 4.3.7), organize capture-the-ﬂag activities, etc. In ad-
dition, by analyzing the behavioral patterns and dynamics
of white hats (e.g., Section 4.2.3), bounty platforms can de-
sign customized services for white hats, such as target se-
lection or recommender systems, which match white hats’
skills and organizations’ requirements. For this purpose, it

would be helpful to further investigate vulnerability discov-
ery by white hats (e.g., tool usage) through interview or
survey studies [19].

5.4 Stimulate Participation by Organizations
Our study results provide incentives for organizations to
join vulnerability discovery ecosystems and to beneﬁt from
white hats’ eﬀorts. In addition, government agencies such as
the Federal Trade Commission also encourage organizations
to have a process of receiving and addressing vulnerability
reports [11], which can be achieved by running a bounty
program.

In our work, we contrast two participation models from
the organizations’ perspective. The ﬁrst one is the coercive
participation model, represented by China-based platforms
such as Wooyun. That is, an organization is coerced to join
the ecosystem once a white hat has submitted a vulnerabil-
ity for that organization. The second participation model,
represented by US-based platforms including HackerOne, is
voluntary, i.e., companies explicitly authorize external re-
searchers to study the security of their web systems. Both
models have their advantages and disadvantages. Our re-
sults show that the ﬁrst model is capable of covering a wider
range of organizations, although varying legal conditions in
diﬀerent countries might not allow for such an approach (see,
for example, [28]). Also, this model might allow many severe
vulnerabilities to be found earlier in websites that are not
willing to participate bug bounty and are poorly secured.
This could partly explains the high percentage of SQL in-
jection on Wooyun in Section 1. The coercive model might
be more attractive to white hats, for example, since they
may feel more in control. The second model clearly grows
more slowly when considering the number of participating
organizations. However, voluntary participation likely en-
courages a better response behavior to vulnerability reports,
as we have discussed in Section 4.1.3. To encourage organi-
zations to participate in the voluntary model, future work
is needed to identify and address organizations’ concerns in-
cluding the perceived lack of trustworthiness of the white
hat population [3], misuse of automated vulnerability scan-
ners, and time wasted due to false reports [8].

6. CONCLUSION

In this paper, we have studied emerging web vulnerability
discovery ecosystems, which include white hats, organiza-
tions and bug bounty platforms, based on publicly available
data from Wooyun and HackerOne. The data shows that
white hat security researchers have been making signiﬁcant
contributions to the security of tens of thousands of organi-
zations on the Internet.

We conducted quantitative analyses for diﬀerent aspects
of the web vulnerability discovery ecosystem. Based on our
results, we suggest that organizations should continuously
collaborate with white hats, actively seek to enlarge the
contributor base, and design their recognition and reward
structure based on multiple factors. We have also proposed
future work directions to help to increase the impact and
coverage of these ecosystems.

1116Acknowledgments
We thank the anonymous reviewers for their helpful com-
ments. The authors would also like to thank Yue Zhang,
Aron Laszka, Kai Chen and Zhaohui Wu for their valuable
comments on earlier drafts of this paper. Peng Liu was sup-
ported in part by ARO W911NF-09-1-0525 (MURI), CNS-
1422594, and ARO W911NF-13-1-0421 (MURI).

7. REFERENCES
[1] OWASP 2013 Top 10.

www.owasp.org/index.php/Top_10_2013-Top_10.

[2] Updates on vulnerability handling process.

www.wooyun.org/notice.php?action=view&id=28,
2013.

[3] Banks reluctant to use ’white hat’ hackers to spot

security ﬂaws. NPR, 2014.

[4] Bug bounty highlights and updates. Facebook, 2014.
[5] How Bugcrowd uses crowdsourcing to uncover security

ﬂaws faster than the bad guys do (Interview).
VentureBeat, 2014.

[6] Website security statistics report. White Hat Security,

2014.

[7] CSUS student hunts for computer bugs as a ‘white

hat’. www.sacbee.com/news/business/
article5014716.html, 2015.

[8] Improving signal over 10,000 bugs.

https://hackerone.com/blog, 2015.

[9] LinkedIn’s private bug bounty program: Reducing

vulnerabilities by leveraging expert crowds.
security.linkedin.com, 2015.

[10] Small business website statistics.

www.statisticbrain.com/
small-business-website-statistics/, 2015.

[11] Start with security: A guide for business. FTC, 2015.
[12] The state of bug bounty. BugCrowd, 2015.
[13] A. Algarni and Y. Malaiya. Software vulnerability

markets: Discoverers and buyers. International
Journal of Computer, Information Science and
Engineering, 8(3):71–81, 2014.

[14] R. B¨ohme. A comparison of market approaches to

software vulnerability disclosure. In Emerging Trends
in Information and Communication Security. 2006.

[15] P. Chen, N. Nikiforakis, L. Desmet, and C. Huygens.

Security analysis of the Chinese web: How well is it
protected? In Workshop on Cyber Security Analytics,
Intelligence and Automation, 2014.

[16] A. Doup´e, M. Cova, and G. Vigna. Why Johnny can’t

pentest: An analysis of black-box web vulnerability
scanners. In Detection of Intrusions and Malware, and
Vulnerability Assessment, 2010.

[17] A. Edmundson, B. Holtkamp, E. Rivera, M. Finifter,

A. Mettler, and D. Wagner. An empirical study on the
eﬀectiveness of security code review. In Engineering
Secure Software and Systems, 2013.

[18] S. Egelman, C. Herley, and P. van Oorschot. Markets
for zero-day exploits: Ethics and implications. In New
Security Paradigms Workshop, 2013.

[19] M. Fang and M. Haﬁz. Discovering buﬀer overﬂow

vulnerabilities in the wild: An empirical study. In 8th
ACM/IEEE International Symposium on Empirical
Software Engineering and Measurement, 2014.

[20] M. Finifter, D. Akhawe, and D. Wagner. An empirical

study of vulnerability rewards programs. In USENIX
Security Symposium, 2013.

[21] S. Frei, D. Schatzmann, B. Plattner, and B. Trammell.

Modeling the security ecosystem - The dynamics of
(in)security. In Economics of Information Security and
Privacy, 2009.

[22] J. Grossklags, N. Christin, and J. Chuang. Secure or

insure? A game-theoretic analysis of information
security games. In 17th International Conference on
World Wide Web, 2008.

[23] B. Johnson, R. B¨ohme, and J. Grossklags. Security

games with market insurance. In Decision and Game
Theory for Security, 2011.

[24] K. Kannan and R. Telang. Market for software

vulnerabilities? Think again. Management Science,
51(5):726–740, 2005.

[25] A. Laszka and J. Grossklags. Should cyber-insurance

providers invest in software security? In 20th European
Symposium on Research in Computer Security, 2015.

[26] A. Lotka. The frequency distribution of scientiﬁc

productivity. Journal of Washington Academy
Sciences, 16(12):317–323, 1926.

[27] R. McGeehan and L. Honeywell. Bounty launch

lessons. medium.com/@magoo/
bounty-launch-lessons-c7c3be3f5b, 2015.

[28] E. Messmer. Hacker group deﬁes U.S. law, defends

exposing McAfee website vulnerabilities. Network
World, 2011.

[29] K. Moussouris. You need to speak up for internet

security. Right now. Wired, 2015.

[30] A. Ozment. Bug auctions: Vulnerability markets
reconsidered. In Workshop on the Economics of
Information Security, 2004.

[31] A. Ozment. The likelihood of vulnerability rediscovery

and the social utility of vulnerability hunting. In
Workshop on the Econ. of Information Security, 2005.

[32] A. Ozment and S. Schechter. Milk or wine: Does
software security improve with age? In USENIX
Security Symposium, 2006.

[33] S. Preibusch and J. Bonneau. The password game:

Negative externalities from weak password practices.
In International Conference on Decision and Game
Theory for Security, 2010.

[34] E. Rescorla. Is ﬁnding security holes a good idea?

IEEE Security & Privacy, 3(1):14–19, 2005.
[35] G. Schryen. Is open source security a myth?

Communications of the ACM, 54(5):130–140, 2011.

[36] M. Shahzad, M. Shaﬁq, and A. Liu. A large scale
exploratory analysis of software vulnerability life
cycles. In International Conference on Software
Engineering, 2012.

[37] T. Van Goethem, F. Piessens, W. Joosen, and
N. Nikiforakis. Clubbing seals: Exploring the
ecosystem of third-party security seals. In ACM
Conference on Computer and Communications
Security, 2014.

[38] M. Zhao, J. Grossklags, and K. Chen. An exploratory

study of white hat behaviors in a web vulnerability
disclosure program. In 2014 ACM CCS Workshop on
Security Information Workers, 2014.

1117