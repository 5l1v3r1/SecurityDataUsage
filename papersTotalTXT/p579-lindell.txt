Blazing Fast 2PC in the Ofﬂine/Online Setting with Security

for Malicious Adversaries∗

Yehuda Lindell

Department of Computer Science

Bar-Ilan University, Israel

lindell@biu.ac.il

Ben Riva

Department of Computer Science

Bar-Ilan University, Israel
benr.mail@gmail.com

ABSTRACT
Recently, several new techniques were presented to dramatically
improve key parts of secure two-party computation (2PC) proto-
cols that use the cut-and-choose paradigm on garbled circuits for
2PC with security against malicious adversaries. These include
techniques for reducing the number of garbled circuits (Lindell 13,
Huang et al. 13, Lindell and Riva 14, Huang et al. 14) and tech-
niques for reducing the overheads besides garbled circuits (Mohas-
sel and Riva 13, Shen and Shelat 13).

We design a highly optimized protocol in the ofﬂine/online set-
ting that makes use of all state-of-the-art techniques, along with
several new techniques that we introduce. A crucial part of our
protocol is a new technique for enforcing consistency of the inputs
used by the party who garbles the circuits. This technique has both
theoretical and practical advantages over previous methods.

We present a prototype implementation of our new protocol. This
is the ﬁrst implementation of the amortized cut-and-choose tech-
nique of Lindell and Riva (Crypto 2014). Our prototype achieves
a speed of just 7 ms in the online stage and just 74 ms in the of-
ﬂine stage per 2PC invoked, for securely computing AES in the
presence of malicious adversaries (using 9 threads on a 2.9GHz
machine). We note that no prior work has gone below one second
overall on average for the secure computation of AES for malicious
adversaries (nor below 20ms in the online stage). Our implementa-
tion securely evaluates SHA-256 (which is a much bigger circuit)
with 33 ms online time and 206 ms ofﬂine time, per 2PC invoked.

1.

INTRODUCTION

Secure two-party computation enables a pair of parties with pri-
vate inputs to compute a joint function of their inputs. The compu-
tation should maintain privacy (meaning that the legitimate output
but nothing else is revealed), correctness (meaning that the out-
put is correctly computed), and more. These properties should be
∗Supported by the European Research Council under the ERC con-
solidators grant agreement n. 615172 (HIPS), and by the BIU Cen-
ter for Research in Applied Cryptography and Cyber Security in
conjunction with the Israel National Cyber Bureau in the Prime
Minster’s Ofﬁce.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
c(cid:13) 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813666.

maintained even if one of the parties is corrupted. The feasibility
of secure computation was demonstrated in the 1980s, where it was
shown that any probabilistic polynomial-time functionality can be
securely computed [32, 13].

The goal of constructing efﬁcient secure two-party (2PC) com-
putation protocols in the presence of malicious adversaries has been
an active area of research in the recent years. One of the most popu-
lar approaches for constructing such protocols is based on applying
the cut-and-choose technique to Yao’s garbled-circuit protocol. In
this technique, one of the parties prepares many garbled circuits,
and the other asks to open a random subset of them in order to ver-
ify that they are correct; the parties then evaluate the remaining,
unchecked circuits. This forces the party generating the garbled
circuits to make most of them correct, or it will be caught cheating
(solving perhaps the biggest problem in applying Yao’s protocol
to the malicious setting, which is that an incorrect garbled circuit
that computes the wrong function cannot be distinguished from a
correct garbled circuit). Many different works 2PC protocols have
been designed based on this approach [24, 20, 22, 29, 14, 19, 25,
30], and several implementations have been presented to study the
concrete efﬁciency of it in practice (e.g.[27, 29, 17, 30, 2]). In this
work we focus on the cut-and-choose approach.

The number of garbled circuits. Let s be a statistical security
parameter such that the probability that a malicious party can cheat
should be bounded by 2−s (plus a function that is negligible in n,
where n is the computational security parameter). Then, the exact
number of garbled circuits needed for achieving this bound was
reduced in the past years from 17s [20], to approximately 3s [20,
29], and recently to s [19].

In [15, 23], it was shown that if multiple 2PC executions are
needed, then the amortized number of garbled circuits per 2PC can
be reduced even below s (i.e., for N 2PC executions, only O(
logN )
garbled circuits are needed per 2PC). In addition, [15, 23] present
protocols that work in the online/ofﬂine setting, where most of the
computation and communication intensive steps are carried out in
the ofﬂine stage, resulting in a very efﬁcient online stage.

s

Checking input consistency. Running cut-and-choose itself does
not sufﬁce for obtaining a secure protocol since it only deals with
the correctness of the garbled circuits. To make the protocol se-
cure, we must additionally include mechanisms for ensuring that
the party that prepares the garbled circuits (a) uses the same input
in all the evaluated garbled circuits, and (b) provides correct inputs
to the OTs for the other party to learn the input labels for its input.
We refer to the ﬁrst problem as P1’s input consistency check and the
second as preventing a selective OT attack. (We note that it is easy
to ensure that the party P2 who evaluates the garbled circuits uses
the same input in all circuits, by running a single OT for each bit of

579P2’s input for all circuits being evaluated. We therefore do not refer
to this problem further.)
It is possible to check the consistency of P1’s input using O(s2)
inexpensive (symmetric) cryptographic operations per input bit [24,
20], but this results in huge communication. Alternate solutions us-
ing O(s) exponentiations per input bit were presented in [22, 29];
this reduces the communication size while signiﬁcantly increasing
the computation time. Recently, [30, 25] presented solutions that
require only O(s) inexpensive (symmetric) cryptographic opera-
tions per input bit, resulting in only a minor overhead on top of the
cut-and-choose protocol itself (as it already requires O(s) gates per
input bit).
Implementations of cut-and-choose based 2PC. The ﬁrst imple-
mentation which evaluated the cut-and-choose approach in practice
was [27]. In [29, 30], implementations with additional algorithmic
improvements were presented. Both results focus on reducing the
overheads of the input-consistency checks, and work with approxi-
mately 3s garbled circuits for soundness 2−s. In [17], the protocol
of [29] is implemented using mass parallelism, resulting in a system
that utilizes a cluster of several hundreds of machines in parallel.
Parallelism was taken a step further in [11, 10], who designed and
implemented protocols on GPUs.

The fastest published secure computation of AES based on cut-
and-choose on garbled circuits, that we are aware of, in the single-
execution, non-massively concurrent setting is of [2]. This imple-
mentation requires approximately 6.39 seconds for a single eval-
uation of AES. However, massive concurrency can drastically im-
prove performance. Using several tens of machines (each with 8
CPU cores), AES can be computed in about 40.6 seconds for 1024
executions, with security parameter s = 80 [30]. Using GPUs, AES
can be computed in only 0.46 seconds, for s = 40 [10].
1.1 Our Contributions

We start by presenting a new technique for checking that P1
uses the same input in all (good) garbled circuits. Our method
has both theoretical and practical advantages over previous tech-
niques. Then, we describe an optimized protocol for 2PC in the on-
line/ofﬂine setting, based on the protocol of [23]; our protocol uses
our new consistency check, plus the state-of-the-art techniques for
the other checks and additional small optimizations. We present
a prototype implementation of our optimized protocol, which is
the ﬁrst implemented 2PC protocol based on the cut-and-choose
method that requires less then s garbled circuits per 2PC compu-
tation. Last, we evaluate the prototype with different circuits and
sets of parameters. We proceed to provide more details on each
contribution.
New P1’s input consistency check. Previous techniques for en-
suring that P1 uses the same input in all good garbled circuits have
signiﬁcant disadvantages. The best known methods to date require
O(s) symmetric cryptographic operations per input bit, and are due
to [25] and [30]. However, it is unclear how to use the technique
of [30] in the online/ofﬂine setting (when many 2PC executions are
needed), and the technique of [25] is (arguably) complicated and
thus very difﬁcult to implement.
Our new solution requires O(s) symmetric cryptographic opera-
tions per garbled circuit, rather than per input bit; in most cases this
is much smaller, and especially in the ofﬂine/online setting where
the number of circuits per execution is very small (about 5-10 for
typical parameters). In addition, our solution is very simple to de-
scribe and implement, and can be plugged-in in a modular way into
most 2PC protocols (based on the cut-and-choose method), includ-
ing the ones in the online/ofﬂine setting. Our protocol can be im-
plemented using only standard cryptographic assumptions (at the

expense of adding 2 exponentiations per circuit which is negligible
in the overall cost) or in the random oracle model (in which case no
exponentiations are needed). We remark that our new consistency
check is the best option today, even for single-execution protocols.
Optimized protocol in the ROM. We apply the new technique
for checking P1’s input consistency and the randomized encoding
technique of [20] for protecting against selective OT attacks, to the
protocol of [23] in the online/ofﬂine setting. We further optimize
several parts of the protocol in the random-oracle model, including
further elimination of exponentiations, reducing communication,
and more.

The online stage of the protocol is highly efﬁcient. It requires
only four messages between the players and the overall communi-
cation size depends only on the input length and the security param-
eters. (Note that the online stage of the fastest 2PC implementation
in the online/ofﬂine setting, shown in [26], requires a number of
rounds that depends on the depth of the circuit in use, and its com-
munication size depends on the circuit size.) This is the ﬁrst im-
plemented protocol with online communication that is independent
of the circuit size (and is concretely very small, as shown by our
experiments).
Prototype implementation and evaluation. We implemented our
optimized protocol on top of the SCAPI library [9, 1]. Our pro-
totype uses state-of-the-art techniques like AES-NI instructions,
ﬁxed-key garbling [4], and the optimized OT-extension protocol
of [3]. We evaluated the prototype on Amazon AWS machines.
Performance of the online stage itself is three orders of magnitude
better than previous protocols (without massive parallelism). For
example, evaluating the AES circuit between two machines in the
same region costs only 7 ms in the online stage. Furthermore, the
ofﬂine stage costs only 74 ms per 2PC computation (for some sets
of parameters). Even when the parties communicate via the In-
ternet, the cost of the online stage remains small as our protocol
requires only four rounds of communication. Speciﬁcally, we eval-
uated AES in 160 ms with a network roundtrip of 75 ms (so at least
150 ms is spent on communication). Observe that the ofﬂine stage
itself is very competitive when compared to previous results. In
particular, the sum of both the ofﬂine and online stages is far better
than any single execution reported (81ms only). Thus, we do not
obtain a fast online phase at the expense of a slow ofﬂine one. See
Section 6 for more details and a comparison of our results with the
performance of previous implementations.

2. PRELIMINARIES

Let H(·) denote a hash function, and commit(x) (respectively,
commit(x,r)) denote a commitment to x (resp., a commitment to
x using randomness r). We denote by l the length of each party’s
input, by In(C,x) the set of wire indexes of a boolean circuit C that
correspond to a given input x, and by Out(C) the set of wire indices
of the output wires of C.
2.1 Efﬁcient Perfectly/Statistically-Hiding Ex-

tractable Commitment

Let ExtractCom(m) be a perfectly- or statistically-hiding ex-
tractable commitment. In the full version we review the perfectly-
hiding extractable commitment of [18] that works in the standard
model and is secure under the DDH assumption. In the random-
oracle model,
easily deﬁned by
ExtractCom(m) = H(m;r) where r is random. Note that this is not
perfectly hiding. However it is statistically hiding (in the random
oracle model) to any algorithm who can make only a polynomial
number of queries to H, and this sufﬁces for our needs.

such commitments

are

5802.2 Adaptively-Secure Garbling

The standard security notion of garbled circuits (e.g., [21]) deals
with a static adversary, meaning that the adversary picks its input
before seeing the garbled circuit. However, in the online/ofﬂine
setting, inputs are chosen only in the online stage, and if we wish
to send all garbled circuits in the ofﬂine stage then the static secu-
rity notion does not sufﬁce. (Note that it is possible to only commit
to the garbled circuits in the ofﬂine phase. However, in order to
achieve the necessary security here, the decommitment would be
the same size as the circuit, resulting in signiﬁcant communication.)
The security of garbled circuits in the presence of an adaptive ad-
versary was deﬁned in [5]; in this deﬁnition, the adversary ﬁrst gets
the garbled circuit and only then chooses its input. As discussed in
[23], this allows proving security in the online/ofﬂine setting, even
if all garbled circuits are sent in the ofﬂine stage.

We use the method described in [23] that slightly modiﬁes the
ﬁxed-key AES-NI garbling scheme of [4] to be adaptively secure
in the random-permutation model,. Adaptive security is immediate
in the (programmable) random-permutation model if P2 (the evalu-
ator) chooses its input in a single query. However, this is not true in
case P2 can obtain some valid input labels before all its input bits
are chosen (and therefore evaluate some of the gates before the in-
put is fully determined). This is a problem since the gates need to be
“programmed” (in the random-oracle/random-permutation model)
after the inputs are received. This is solved by ensuring that P2 is
unable to decrypt any gate before receiving all labels. We achieve
this by having P1 choose a random λ (of the same length as the gar-
bled labels), and whenever P2 should learn a label for some input
bit, it actually learns the label XORed with λ . After P2 receives
all the garbled values (XORed with λ ), P1 reveals λ , and then P2
XORs its labels and can evaluate the circuit. (The value of λ can be
viewed as part of the last label, which will be longer than the pre-
vious ones). We prove security of this method in the full version.
2.3 The Selective-OT Attack Solution of [20]
A solution for the selective-OT attack, which works with any
oblivious transfer in a black-box way, was presented in [20]. The
solution works by encoding P2’s input in a way that any leakage of
a small portion of the bits does not reveal signiﬁcant information
about P2’s input. Formally, the encoding can be carried out using a
Boolean matrix E that is s-probe-resistant, as deﬁned below.

DEFINITION 2.1

(BASED ON [20, 30]). Matrix E ∈{0,1}l×n
for some l,n ∈ N is called s-probe-resistant for some s ∈ N if for
i∈L Ei is at least

any L ⊂ {1,2, . . . ,l}, the Hamming distance of(cid:76)

s, where Ei denotes the i-th row of E.

Such a matrix E can be constructed with n = max(4l, 20s

3 ), as
shown in [20]. A different construction with n ≤ lg(l) + l + s +
s · max(lg(4l),lg(4s)) was presented in [30]. We note that both
constructions can result in a matrix E for which there exists a vector
y that for all vectors y(cid:48), Ey(cid:48) (cid:54)= y (meaning that some input cannot be
encoded). We therefore take E to be [E(cid:48)|Il] ∈ {0,1}l×(n+l), where
E(cid:48) is an s-probe-resistant matrix and Il is the identity matrix of
size l. E is clearly also s-probe-resistant, and now, any vector y
can be encoded using a vector y(cid:48) that has random bits in the ﬁrst n
elements, and “corrections” in the rest of the bits so that Ey(cid:48) = y.
Instead of working with the function f (x,y), the parties work
with the function f (cid:48)(x,y(cid:48)) = f (x,Ey(cid:48)) and P2 chooses a random y(cid:48)
such that y = Ey(cid:48) (this ensures that f (cid:48)(x,y(cid:48)) = f (x,y)). As long as
E is s-probe-resistant, even if P1 learns s(cid:48) < s bits of y(cid:48), it cannot
learn any information about y. This is due to the fact that for every
s(cid:48) < s bits of y(cid:48) and every y, there exists a y(cid:48)(cid:48) that is consistent
with them (i.e., Ey(cid:48)(cid:48) = y and y(cid:48)(cid:48) = y(cid:48) on the s(cid:48) < s bits revealed).

Now, in order to learn s bits, P1 has to carry out a selective-OT
attack on s wires. However, for every such wire it is caught with
probability 1/2, which means that if it tries to attack s wires, it gets
caught with probability at least 1−2−s. In addition to working with
f (cid:48)(x,y(cid:48)), the parties can use one OT invocation for many circuits,
allowing P2 to input the same y(cid:48) for many circuits while learning the
corresponding labels in all of them together. Therefore, the number
of OTs needed is n for the entire set of evaluated circuits.
As shown in [30], since E is a binary matrix the subcircuit that
computes Ey(cid:48) can be garbled very efﬁciently using the Free-XOR
technique [16], with only O(n) symmetric-key operations. This
modiﬁcation requires assuming that the garbling scheme in use is
secure with the Free-XOR technique (see [6]). Moreover, assuming
correlation-robust hash functions, many OTs can be implemented
very efﬁciently (i.e., with a small number of symmetric-key opera-
tions per OT) using an efﬁcient OT extension protocol. Speciﬁcally,
the above solution can be implemented by O(n) symmetric-key op-
erations, and only O(s) seed-OTs [3].

2.4 Cut-and-Choose Parameters

The ofﬂine/online method for cut-and-choose uses the following
parameters: (a) the number of circuits B evaluated per online 2PC;
(b) the number of 2PC executions N; (c) the fraction of circuits
evaluated p (and so a 1− p fraction are checked); and (d) the statis-
tical security parameter s. A comprehensive analysis of the sound-
ness of the amortized cut-and-choose, with respect to the above
parameters, was presented by [23].

For completeness, we repeat the description of the cut-and-
choose game in terms of balls and bins. From here on, a ball refers
to a garbled circuit, and a cracked ball is an incorrect garbled cir-
cuit that was maliciously generated; a single execution in the online
phase uses a full bucket of unchecked “balls”. Recall that in the
cheating recovery method of [19] there are actually two garbled-
circuit evaluations: the main circuit for computing the function is
evaluated, and a very small auxiliary circuit is computed that is
used for P2 to learn P1’s input in case P1 cheated. The balls and
bins game is such that for the main circuit the adversary can cheat
if there exists a bucket where all the balls are cracked, and for the
small cheating recovery circuit the adversary can cheat if there is a
bucket where a majority of the balls are cracked.

(cid:108) NB

(cid:109)

p

P2 chooses three parameters p,N and B, and sets M =

and
m = NB. (Note that p < 1 and so M > m.) A potentially adversarial
P1 (who we will denote by Adv) prepares M balls and sends them
to P2. Then, party P2 chooses at random a subset of the balls of size
M − m; these balls are checked by P2 and if one of them is cracked
then P2 aborts. Denote the balls that are not checked by 1, . . . ,m.
Then, P2 chooses a random mapping function π : [m] → [N] that
places the unchecked balls in buckets of size B.

In [23], bounds were shown on the probabilities that P2 does not
abort and (1) there exists a fully-cracked bucket (i.e., all balls in
some bucket are cracked), or (2) there exists a majority-cracked
bucket (i.e., at least B/2 balls in some bucket are cracked).

When considering composition of protocols (as done in [23]), in-
deed the overall cheating probability is the natural soundness one
should work with. However, we believe that is it more natural to
focus on the cheating probability in a single 2PC execution (espe-
cially, since this enables a direct comparison to single-execution
implementations). We will therefore be interested in the probabili-
ties that P2 does not abort and some speciﬁc bucket is fully cracked,
or, that some speciﬁc bucket is majority-cracked.

In addition to the bounds shown in [23], a few concrete exam-
ples are presented there to exemplify that those bounds are not

581tight. Since we mostly care here about concrete efﬁciency, we im-
plemented a program that ﬁnds the parameters analytically, based
on the following tighter approximations that are derived from the
analysis of [23]; see Table 1 for results.

LEMMA 2.2. Let N,B, p,M be parameters as described above.

The probability that a bucket is fully-cracked is at most

LEMMA 2.3. Let N,B, p,M parameters as described above. The

probability that a bucket is majority-cracked is at most

(cid:19)(cid:18)NB

(cid:19)−1(cid:35)NB

.

t=B

B

B

NB

NB−t

(cid:18) t

(cid:34)(cid:0) M−t
(cid:1)
(cid:1) ·
(cid:0) M
(cid:34)(cid:0) M−t
(cid:1)
(cid:1) · 2B−1(cid:16) t
(cid:0) M

NB−t

NB

NB

(cid:17)(cid:100)B/2(cid:101)(cid:35)NB

.

t=B

max

max

3. COMMITMENT WITH ZK PROOF OF

DIFFERENCE

The aim of this section is to construct a commitment scheme with
an efﬁcient zero-knowledge proof of difference; we will show later
how it is used to prove P1’s input consistency. Given commit(x1)
and commit(x2) and ∆ = x1⊕x2, the aim is to efﬁciently prove that
the XOR of the decommitments is indeed ∆. Formally, one party
inputs (x1,x2), and the other party chooses to either learn x1 ⊕ x2
or the pair (x1,x2) itself. (Thus, the ﬁrst party is committed to the
pair, and must either decommit or prove their difference, depending
on P2’s choice.) Our constructions are based on ideas of [28].

We start by describing a basic functionality (presented in Fig-
ure 3.1), prove its correctness, and then describe how to extend
it to work with many commitments so we can use it for input-
consistency checks. The detailed extended protocol appears in the
full version.

FIGURE 3.1

(FUCTIONALITY FCom∆ZK).
FCom∆ZK runs with parties P1 and P2, as follows:
Input: FCom∆ZK receives a pair of messages (x1,x2) from P1, and
a bit b from P2.
Output: FCom∆ZK sends ∆ = x1 ⊕ x2 to P2 if b = 0, and sends
(x1,x2) to P2 if b = 1. In addition, FCom∆ZK sends b to P1.
The Simple Commit-and-Difference Proof Functionality

3.1 A Warm-Up – Only Two Messages

In this section, we show how to securely realize the functionality
from Figure 3.1. The idea behind the construction is as follows.
We deﬁne a split commitment of a value x to be a pair of commit-
ments to random values [commit(x⊕ r), commit(r)] whose XOR
equals x. Party P1 sends P2 a set of s split commitments to x1 and s
split commitments to x2. If P2 asks to decommit (i.e., b = 1) then
P1 simply decommits using the standard (canonical) decommiment
and P2 checks that the XORs in all split commitments to a value
In contrast, if b = 0, then P1 sends P2 the XORs
are the same.
of the split commitment values. Speciﬁcally, let [commit(x1 ⊕
ri), commit(ri)] and [commit(x2 ⊕ρi), commit(ρi)] be the ith split
i = x1 ⊕
commitment of x1 and x2, respectively. Then, P1 sends δ 0
ri ⊕ x2 ⊕ ρi and δ 1
i = ri ⊕ ρi to P2, for every i = 1, . . .s, as well
as ∆ = x1 ⊕ x2. Observe that for every i it holds that δ 0
i ⊕ δ 1
i =
x1 ⊕ x2 = ∆, and so P2 checks that for every i it indeed holds that
i ⊕ δ 1
δ 0
i = ∆. Then, given these values, P2 sends a random s-bit
“challenge string” W to P1, indicating to P1 which value in each
split commitment to open. Letting W = W1, . . . ,Ws, party P1 de-
commits to both left commitments in the ith split commitments of

x1 and x2 if Wi = 0; otherwise it decommits to both right commit-
ments in the ith split commitments of x1 and x2. Observe that if
Wi = 0 then P2 receives x1⊕ri and x2⊕ρi and so can verify that δ 0
i
was correctly constructed. In contrast, if Wi = 1 then P2 receives ri
and ρi and so can check that δ 1
i was correctly constructed. Thus, if
x1 ⊕ x2 (cid:54)= δ , then P1 must cheat on at least one side of every split
commitment, and so will be caught with probability 1− 2−s. Ob-
serve that this check is very simple and very efﬁcient; when using a
hash function to commit it requires 2s hash computations only per
value.
Despite its simplicity, we remark that in order to simulate this
protocol (in the sense of securely computing FCom∆ZK in the ideal/
real model paradigm), we need to have P2 commit to its challenges
b and W before the protocol begins. If an extractable commitment
is used, then the simulator can learn the challenges ahead of time
and therefore “cheat”. Fortunately, this comes at very little over-
head, as can be seen in the full protocol. See Figure 3.2 for the
detailed protocol.
Proving consistency. Before proceeding to prove security, we ex-
plain how this functionality can be used to force P1 to use the same
input in two different garbled circuits. The values x1,x2 are the sig-
nal bits over all of P1’s input wires in the ﬁrst and second garbled
circuits, respectively. (Recall that the signal bit determines whether
the keys on the wire are given in the “correct” order or reversed or-
der. In some works this value is also called the permutation bit.)
Now, P1 provides (standard) commitments to the garbled values on
these input wires (this is standard in all cut-and-choose protocols);
we call them wire-commitments. However, P1 provides the wire-
commitments in the order determined by the signal bit. Now, when
two circuits are opened to be checked, then P2 provides input b = 1
to FCom∆ZK, and so all values are decommitted. This enables P2
to check that the split commitment was constructed correctly and
that the wire-commitments were indeed given in the correct order,
according to the signal bits. In contrast, when two circuits are to
be evaluated, then P2 provides input b = 0 to FCom∆ZK. As a re-
sult, P2 will receive the XOR of the signal bits in the two circuits.
Thus, if the XOR equals 0, then P2 knows that P1 must either de-
commit to the ﬁrst wire-commitment in both circuits or decommit
to the second wire-commitment in both circuits. (Since P2 knows
that the signal bit is the same in both cases – without knowing its
value – this ensures that the same input bit is used by P1 in both.)
In contrast, if the XOR equals 1, then P2 knows that P1 must ei-
ther decommit to the ﬁrst wire-commitment in the ﬁrst circuit and
the second wire-commitment in the second circuit, or vice versa.
(Once again, since P2 knows that the signal bit is different in both
cases, this ensures that the same input bit is used by P1 in both.)
3.1.1 Proof of Security
Let x ∈ {0,1}n. Denote c ∈ SC(x) if there exists randomness
so that c = SC(x); otherwise denote c /∈ SC(x). Denote SC =
{c | ∃x : c = SC(x)}; i.e., the set of all valid commitments. De-
note by commit2s the set of all series c of 2s commitments (thus
SC ⊂ commit2s). We will be interested in commitments c ∈ SC
versus commitments c ∈ commit2s \SC. Note that since commit
is perfectly binding, these sets are well deﬁned.

In the full version, we prove that the proof in Protocol 3.2 (for
b = 0) is an interactive proof for the promise problem (P,Q), where

(cid:110)
(cid:111)
(cid:110)
(c,d,∆) | ∃x1,x2 s.t. c ∈ SC(x1)∧ d ∈ SC(x2)
P =
(c,d,∆) | ∃x1,x2 s.t. c ∈ SC(x1)∧ d ∈ SC(x2)∧ x1 ⊕ x2 = ∆
The promise problem (P,Q) considers the question of whether an
input (c,d,∆) ∈ Q, under the promise that (c,d,∆) ∈ P. In words,

and
Q =

,

(cid:111)

.

582FIGURE 3.2

(TWO COMMITMENTS WITH PROOF OF DIFFERENCE).

Inputs: P1 has a pair (x1,x2) and P2 has a bit b.
Commit to Challenge: P2 chooses a random W ∈ {0,1}s. Then, P1 and P2 run a perfectly (or statistically) hiding extractable commitment
scheme ExtractCom, in which P2 commits to b and W . (A Pedersen commitment with a zero-knowledge proof of knowledge of the committed
value sufﬁces, or a simple hash with a random string in the random oracle model.)
Commit to x1,x2: Deﬁne the split commitment SCom(xk,r) = [commit(x⊕ r), commit(r)]. Then:
i ,d1
i

1. For i = 1, . . . ,s, P1 chooses ri,ρi ← {0,1}n and computes(cid:2)c0

(cid:3) = SCom(x1,ri) and(cid:2)d0

(cid:3) = SCom(x2,ρi).

i ,c1
i

2. Denote c1 = SC(x1) = (cid:104)SCom(x1,r1), . . . , SCom(x1,rs)(cid:105) and c2 = SC(x2) = (cid:104)SCom(x2,ρ1), . . . , SCom(x2,ρs)(cid:105).

P1 sends (commit,c1,c2) to P2.
Decommit to b: P2 decommits to the value b. (At the end of the protocol, P1 outputs b.)
If b = 1, P1 decommits to x1,x2: P1 sends x1,x2 and all of the randomness used to generate the commitments c1,c2. P2 veriﬁes that all
commitments were correctly constructed, and if yes it outputs (x1,x2).
If b = 0, P1 provides a proof of difference:

1. For every i = 1, . . . ,s, party P1 deﬁnes δ 0

2. P1 sends(cid:8)(δ 0

i )(cid:9)s

i ,δ 1

i = x1 ⊕ ri ⊕ x2 ⊕ ρi and δ 1

i = ri ⊕ ρi (note that δ 0
i=1 and ∆ = x1 ⊕ x2 to P2, who checks that for every i it holds that δ 0
(cid:16)

(cid:17)

i ⊕ δ 1
i ⊕ δ 1

i = x1 ⊕ x2)
i = ∆.

3. P2 decommits to W = W1, . . . ,Ws.
4. For i = 1, . . . ,s, party P1 sends decommitments Decom

(cid:16)
(cid:17)
(cid:17)⊕ Decom

cWi
i

(cid:16)

(cid:16)

cWi
i

, Decom

to P2.

(cid:17)

dWi
i
= δWi
i

.

dWi
i

5. For i = 1, . . . ,s, party P2 veriﬁes that Decom
6. If all checks pass, then P2 outputs ∆.

we are given an input (c,d,∆) and we are guaranteed that there
exist x1,x2 such that c ∈ SC(x1) and d ∈ SC(x2). The “aim” is then
just to determine if x1⊕x2 = ∆ or x1⊕x2 (cid:54)= ∆. (Note that if c and d
are such that they are not valid commitments at all, then this will be
detected in the checks carried out in the cut-and-choose protocol;
i.e., when b = 1.)

We follow the deﬁnition of [12] regarding interactive proofs for
promise problems. Informally, completeness must hold for every
(c,d,∆) ∈ P∩ Q, soundness guarantees that the veriﬁer will reject
for any (c,d,∆) ∈ P\ Q, and nothing is required for (c,d,∆) /∈ P.
In addition to the above, we prove that Protocol 3.2 securely
computes the functionality FCom∆ZK, deﬁned in Figure 3.1, in the
presence of a corrupt P2. We stress that in the case that P1 is cor-
rupted we rely on the soundness property of the proof (since Pro-
tocol 3.2 does not securely compute FCom∆ZK in the presence of a
corrupt P1).

In the full version we prove the following:
THEOREM 3.3. If commit is a perfectly-binding commitment
scheme and ExtractCom is a perfectly-hiding extractable commit-
ment scheme, then the commitment phase of Protocol 3.2 is a
perfectly-binding commitment scheme, and the proof phase is an
interactive proof system for the promise problem (P,Q) deﬁned
above. In addition, Protocol 3.2 securely computes FCom∆ZK in
the presence of a corrupt P2.
3.1.2 Replacing the Perfectly-Binding Commitment
Note that so far we have assumed that commit(·) is a perfectly-
binding commitment. In practice, perfectly-binding commitments
are less efﬁcient than computationally binding ones. For example,
with an appropriate assumption on the cryptographic hash function,
commit(x) = H(x;r) is a computationally binding and computa-
tionally hiding commitment. If we model H as a random oracle,
then commit is still only computationally binding. However, it is
extractable, and thus we can prove the interactive proof of Proto-
col 3.2 to be a proof of knowledge. This achieves the same effect
as soundness. (Note that once we model H as a random oracle, we
can also use it as the statistically-hiding extractable commitment.)
In order to use any computationally-binding commitments, in-
cluding like that above but without resorting to the random ora-

cle model, the following change can be made to Protocol 3.2. Let
σ be a seed to a pseudorandom generator G, and deﬁne SC(x) as
(i.e., SC(x) = (cid:104)SCom(x,r1), . . . , SCom(x,rs)(cid:105)) where the underly-
ing commitment uses H, but all of the randomness in generating
SC is taken from G(σ ), and a perfectly-binding extractable com-
mitment is given to σ alone. This has the advantage that a single
perfectly-binding commitment to a short string sufﬁces to deﬁne
all of SC as perfectly binding. The promise problem used to model
the interactive proof, and the proof of soundness then remains the
same (with the additional requirement that P1 is polynomial time
and cannot efﬁciently open any of the individual commitments to
anything else). This adds one extractable commitment per circuit
(which can be implemented via El Gamal and so costs 2 exponen-
tiations per circuit), plus a single zero-knowledge proof of knowl-
edge of the El Gamal private key generated by P1 (that is done only
once for all circuits and costs just 9 exponentiations).
3.2 Extending to Many Messages

The functionality of Figure 3.1 works with only two messages
from P1 (and so only for two circuits). We would like to use it
for a larger number of messages, where P2 can choose any subset
of them to be revealed and learn the XOR differences between the
remaining ones (as in the cut-and-choose case where a random sub-
set of the circuits are evaluated and consistency must be proved for
them). In addition, for our online/ofﬂine 2PC protocol we would
like P2 to be able to pick different subsets of the unrevealed mes-
sages, and learn the XOR differences for all the messages in each
subset (in the online/ofﬂine setting, the evaluated circuits are ran-
domly thrown into buckets and each bucket is used for a different
execution; thus the XOR differences is needed inside each bucket).
The extended functionality is deﬁned in Figure 3.4. The subsets
I1, . . . ,IN are the buckets of circuits to be evaluated in the online
phase (each bucket is of size B). Thus, P2 learns the XOR differ-
ences between every pair in each bucket; this enables it to verify
consistency as described above. Observe that the indices of values
not in any of I1, . . . ,IN are circuits that are checked; thus, the values
corresponding with these indices are revealed.

The main difference between the protocol that securely computes
the extended functionality in Figure 3.4 and the protocol in Fig-

583ure 3.2 is that in the general case, P2 commits to all of the subsets
I1, . . . ,IN initially (and not just a single bit b). The detailed protocol
appears in the full version.

FIGURE 3.4

(FUNCTIONALITY FExCom∆ZK).

FExCom∆ZK runs with parties P1 and P2, a public index M (saying
how many inputs there are), a public constant N (saying how many
subsets there are), and a public constant B (saying how big each
subset is), as follows:
Input: FExCom∆ZK receives M messages (x1, . . . ,xM) from P1, and
a series of subsets I1, . . . ,IN ⊂ [M] from P2.
Output: For j ∈ [N], let Ij = {i1
⊕
}B−1
k=1 . Then, FExCom∆ZK sends ∆1, . . . ,∆N to P2. In addition,
xik+1
. Finally,

FExCom∆ZK sends P2 the value xi, for every i /∈(cid:16)(cid:83)N

j } and let ∆ j be the set {xik

FExCom∆ZK sends I1, . . . ,IN to P1.
The Extended Commit-and-Difference Proof Functionality

j , . . . ,iB

j

j

(cid:17)

j=1 Ij

3.3 Using FExCom∆ZK in Cut-and-Choose

As we have mentioned, for every circuit in the cut-and-choose,
P1 commits to the string m which contains all of the “signal” bits σ
on its input wires (this requires 2s basic commitments commit). In
addition, the input garbled labels are committed; the commitments
are in the correct order (with the 0 label ﬁrst) if σ = 0, and in the
opposite order if σ = 1. When checking a circuit, these commit-
ments are also veriﬁed. For the evaluation circuits, let gc1, . . . ,gcl
be the circuits to be evaluated, and let m1, . . . ,ml be their commit-
ted signal bit labels. Then, for every i = 1, . . . ,l, party P1 sends P2
the string ˆxi = mi⊕x, where x is its input to the secure computation.
In addition, for every i = 1, . . . ,l − 1, it deﬁnes ∆i = ˆxi ⊕ ˆxi+1 and
proves that mi ⊕ mi+1 = ∆i (using FExCom∆ZK). The overall cost
is 2s basic commitments commit per circuit plus two extractable
commitments, which is very cheap.
Advantages Over Previous Input Consistency Proofs. Note that
the number of commitments in Protocol 3.2 is only 2s for every
circuit. In the online/ofﬂine setting, the number of circuits is very
small (typically 5-10, depending on the parameters) and thus this
costs signiﬁcantly less than a single commitment per input bit (un-
less the input is very small). When commit is implemented as
described above using computationally-binding commitment, the
resulting protocol is more efﬁcient than those of [25, 30], and sig-
niﬁcantly more simple to understand and implement. From a theo-
retical standpoint, our protocol can also be based on very standard
assumptions (though with the additional negligible overhead of the
two exponentiations needed by the El Gamal encryption used to
implement a perfectly-binding commitment), whereas [25] requires
correlation robustness and [30] requires Free-XOR.

Another advantage of our new consistency check is for amortized
cut-and-choose protocols like [15, 23] in the online/ofﬂine setting.
Both works use inefﬁcient solutions for the input-consistency is-
sue (i.e., using discrete-log ZK proofs). It is unclear how to adapt
those results to work with the protocol of [30] (when P1 has many
different inputs). Note that [23] mentions that its protocol can be
adapted to work with the protocol [25]. However, the resulting pro-
tocol seems to be very complicated and difﬁcult to implement. We
believe that simplicity is a very important factor for secure proto-
cols, and we ﬁnd our solution to be more simple to describe and
implement than the one of [25].
4. OPTIMIZED 2PC IN THE ONLINE/ OF-

FLINE SETTING

We base our protocol on the results of [23], where a protocol
for multiple 2PCs in the online/ofﬂine model is shown. First, we

adapt it to use the technique of [20, 25, 30] for protecting against
selective-OT attacks. Next, we plug in our new technique for check-
ing P1’s input consistency as discussed in Section 3.3. These two
modiﬁcations essentially replace all the exponentiations required
by the protocol of [23] for the input wires with cheaper crypto-
graphic operations (and a small number of exponentiations that is
independent of the input size).

Since our goal is to minimize the cost of the online stage, we
chose to work in the random-oracle model, so we could construct
adaptively secure garbled circuits in an efﬁcient way. We there-
fore further utilize the power of the random-oracle model and op-
timize other parts of the protocol. For example, we replace all ex-
tractable commitments (that require exponentiations) with random-
oracle based commitments (that requires only hash function calls),
and we reduce the number of encryptions needed for the cheating
recovery method presented in [23].

The protocol is described in Appendix A in Figures A.2 and A.3
and uses the sub-protocols of Figure A.1. In the full version we
prove the following:

THEOREM 4.1. Let commit and ExtractCom be implemented
using a random oracle H (i.e., commit(m,r) = ExtractCom(m,r) =
H(m;r)). For any function f , if PRF is a secure pseudorandom
function and the garbling scheme in use is adaptively secure, then
Protocols A.2-A.3 securely compute f with multiple executions (ac-
cording to the deﬁnition of [23]).

We remark that the protocol can be slightly modiﬁed to be secure
given an adaptively secure garbling scheme and without utilizing
the random oracle for commit and ExtractCom. The only modi-
ﬁcation needed is to commit on all the commitments of the input
labels using a trapdoor commitment, so that in the simulation in
case P1 is corrupted, the simulator could change the commitments
on the input labels after it learns P1’s input. The cost of this mod-
iﬁcation is small – only one additional trapdoor commitment per
garbled circuit.

5. PROTOTYPE IMPLEMENTATION

Our goal is to provide an end-to-end system for multiple 2PC
executions in the online/ofﬂine setting. First, the system can pro-
vide the user very good sets of parameters. Next, the system is
optimized both crypto-wise (e.g., using the random-oracle where
suitable) and engineering-wise (e.g., using parallelism where pos-
sible). Some key parts of the system are the following:
Additional optimizations in the random-oracle model. First, re-
call that everywhere we use an extractable commitment, we actu-
ally use commit(x;r) = H(x;r). Second, since the labels of P2’s
input wires are random, we can use a second random-oracle H2,
and ask P1 to commit on label W just by sending H2(W ). This re-
duces P1’s inputs to the OTs by a factor of two, and still preserves
security as H2(W ) does not reveal any information about W if W
has enough entropy (which happens in our case, as W is at least 80
bits long random string).
Finding good parameters. We implemented a program that is
given the values of s (statistical security parameter) and N (the over-
all number of executions desired), and calculates the parameters
(based on Lemmas 2.2 and 2.3) that minimize the overall number
of circuits (to minimize the run-time of the ofﬂine stage) or the
number of evaluation circuits per bucket (to minimize the run-time
of the online stage). Similarly to what was observed by [23], the
parameters we get are much better than what the upper bounds of
[23] give. See Table 1 for several example sets of parameters for

584N
8

32

128

1024

4096

Total number of

circuits

136
165
362
437
998
1143
5627
5689
18005
25600

Number of eval
circuits per 2PC

10
8
7
6
6
5
5
4
4
3

Number of

circuits per 2PC

16.95
20.51
11.29
13.63
7.79
8.92
5.49
5.55
4.39
6.25

N
8

32

128

1024
4096

Total number of

circuits

277
296
706
771
1995
2246
10843
36294

Number of eval
circuits per 2PC

19
17
15
13
12
10
9
7

Number of

circuits per 2PC

34.54
36.95
22.05
24.07
15.58
17.54
10.58
8.86

Table 1: Several sets of parameters for Lemma 2.2 with s = 40 (left) and s = 80 (right). Note the tradeoff between the total number
of circuits (which affects the ofﬂine stage efﬁciency) and the number of evaluation circuits per bucket (which affects the online stage
efﬁciency).

the cut-and-choose of C. We also implemented a program that re-
ceives a circuit C and calculates the encoding matrices E and E(cid:48),
used for protecting P2’s input from selective-OT attacks.

In contrast to [23], we have set the statistical security parameter
s to be such that the probability that an adversary cheats in a single
2PC execution is 2−s. (In [23], they set 2−s to be the probabil-
ity that an adversary cheats in at least one of the many executions
overall). Indeed, this is merely a different way of looking at the
parameters, but we believe that for most users, considering security
of a single execution is more natural.
Handling large inputs. Calculating a probe-resistant matrix ac-
cording to the algorithm of [30] is a very computation intensive task
when the input is large (e.g., 1000-bit long). Instead, when dealing
with long inputs, our system constructs the probe-resistant matrix
using a composition of smaller probe-resistant matrices (such that
each can be generated very efﬁciently). While this method results
in a slightly larger matrix used in the protocol (and, thus, more
OTs), it dramatically reduces the time needed for generating the
probe-resistant matrix (from hours to seconds).
Architecture. We use the SCAPI library [9, 1] for implementing
the high-level steps of the protocols, while using more optimized
C/C++ code for steps that are more computation intensive (e.g.,
computing the large amount of XORs of the probe-resistant ma-
trix). We use the OT-extension implementation of [3], a new SCAPI
garbling library that uses ﬁxed-key AES for garbling, as suggested
by [4], and the SCAPI wrapper of OpenSSL for AES and SHA-1.
The prototype is able to generate and evaluate many garbled cir-
cuits (and carry out other operations) in parallel, using multiple
threads.
In addition, before the online stage begins, all relevant
ﬁles are loaded to memory so once the interaction starts, no I/O de-
lays occur. (We do not include disk I/O time in our measurements
as in practice loading to memory should always occur before actual
inputs are received )

6. PERFORMANCE EVALUATION
Setup. We ran the prototype on two types of Amazon AWS in-
stances: c4.8xlarge (with 64GB RAM and 36 virtual 2.9GHz CPUs)
and c4.2xlarge (with 15GB RAM and 8 virtual 2.9GHz CPUs). On
both instances, garbling 1000 AES circuits in isolation took about
470 ms. Unless stated otherwise, all the tests in this section were
ran on the c4.8xlarge instances. We ran tests with LAN conﬁgu-
ration, where both parties were in the same AWS region and the
roundtrip was less than 1 ms, and with a WAN conﬁguration, where
the parties were in different regions (speciﬁcally, eu-west and us-
east) and the roundtrip was 75 ms.

We tested the prototype with the following circuits: (1) ADD:
receives two 32-bit integers and outputs their sum (the circuit has

127 AND gates); (2) AES: receives two 128-bit inputs and outputs
the encryption of the ﬁrst input using the second input as the key
(the circuit has 6800 AND gates); (3) SHA-1: receives two 256-bit
inputs and outputs the SHA-1 hash digest of the XOR of the two in-
puts (the circuit has 37300 AND gates); (4) SHA-256: receives two
256-bit inputs and outputs the SHA-256 hash digest of the XOR of
the two inputs (the circuit has 90825 AND gates).
Results. In the following, all experiments use the sets of parame-
ters from Table 1, and unless said otherwise, s = 40. See Table 2 for
the results of the implementation on these circuits; the online time
given is the average over all executions. We can see that, for exam-
ple, the total time it takes to evaluate a single AES (i.e.. the sum
of the online and ofﬂine stages timings) ranges from around 210ms
(for N = 32) to around 80ms (for N = 1024). See Table 3 for re-
sults with s = 80. In Table 4 we show an example of the effect of the
number of threads on the ofﬂine stage performance. Even though
performance is far from linear in the number of threads, it is clear
that parallelism helps, and we expect that further optimizations uti-
lizing multithreading will further improve performance. We also
ran these experiments for other settings and veriﬁed that this effect
is consistent. (For s = 80, the numbers are about 2-2.5 times larger.)
As discussed earlier, there is a tradeoff between the total number
of circuits and the number of evaluation circuits per online stage.
This affects the performance of the two stages. See Table 1 for
examples of those tradeoffs. In addition to the tests described in
Table 2, we also tested how this tradeoff is reﬂected in practice:
Instead of running AES with s = 80, N = 128 and bucket size 12,
we ran it with bucket size 10 which increases the total number of
circuits from 1995 to 2246; the ofﬂine running time was 310 ms per
2PC (with 9 threads) and the online running time was 31/16/17
ms for 1/5/9 threads (respectively). This is about 13% slower in
the ofﬂine phase and around 10% faster in the online phase, which
roughly matches the differences in the numbers of circuits and so
is as expected. Thus, it is possible to obtain different tradeoffs,
depending on whether it is more important to reduce the overall
cost or the online latency.

We also tested the prototype in the WAN conﬁguration, since
in many real-world scenarios the participating parties may be far
apart. Note that in these scenarios, the Yao-based approach has a
signiﬁcant advantage over TinyOT [26] and SPDZ [7] who have a
number of rounds that depends on the circuit depth. See Tables 5, 6
and 4 for the results of those tests. We note that our online phase re-
quires four rounds of interaction (two messages in each direction),
and since the roundtrip in our WAN conﬁguration is 75 ms, the cost
of our online stage cannot go below 150 ms. Our tests show that
in this case, the majority of the time spent is on communication,
and the cost of the actual steps of our protocol (i.e., excluding com-
munication) is very low. We remark that protocols which require a

585Online time per bucket

1 thread

5 threads

9 threads

Circuit

Number of buckets

Ofﬂine total Ofﬂine per bucket

ADD

AES

SHA-1

SHA-256

32
128
1024
32
128
1024
32
128
1024
32
128
1024

4266
9735
49590
6310
14539
75879
10042
24201
127555
14699
35243
210935

133
76
48
197
114
74
314
189
125
459
275
206

10
7
5
18
13
9
40
31
20
75
62
44

52
34
24
176
129
100

6
5
4
13
10
7
29
24
15
62
50
33

29
17
13
123
87
79

8
4
4
12
10
7
26
22
15
50
40
33

30
20
14
129
96
76

Table 2: Running times of the different circuits in LAN conﬁguration (in ms). For N = 32 we use buckets of 7 circuits of C and 20
of C(cid:48); for N = 128 we use buckets of 6 circuits of C and 14 of C(cid:48); for N = 1024 we use buckets of 4 circuits of C and 10 of C(cid:48) (C is the
main circuit and C(cid:48) is the auxiliary cheating-recovery circuit). Ofﬂine times are for execution with 9 threads.

Circuit

Number of buckets

Ofﬂine total Ofﬂine per bucket

AES

SHA-256

32
128
1024
32
128
1024

13901
35031
164937
29041
74120
662640

434
274
161
908
579
647

Online time per bucket

1 thread

5 threads

9 threads

Table 3: Running times for AES circuit in LAN conﬁguration for s = 80. For N = 32 we use buckets of 15 circuits of C and 46 of C(cid:48);
for N = 128 we use buckets of 12 circuits of C and 28 of C(cid:48); for N = 1024 we use buckets of 9 circuits of C and 20 of C(cid:48).
round of communication for every level of the circuit in the online
phase will perform poorly in this scenario. (For example, the best
AES circuit has depth 50 and thus the online time will not be able
to be less than 3750 ms in this setting.)

we believe that it is clear that our prototype costs several orders of
magnitude less than previous non-massively parallel implementa-
tions, and has the potential to cost much less in the massively paral-
lel setting (since all the expensive steps of the protocol can be done
in parallel). We stress that the ofﬂine/online setting is preferable to
the batch setting since online executions can be run in isolation.

Last, we tested the prototype on a weaker AWS instance, i.e.,
c4.2xlarge, for computation of AES. See Table 7. As expected,
performance is mostly worse than on the stronger instance but for
some parameters they are still very close. This is mainly because of
memory issues, and thus is mostly reﬂected in the ofﬂine stage (our
current implementation of the ofﬂine stage stores many garbled cir-
cuits in memory). Indeed, the online times are almost the same.

Communication in the ofﬂine stage mostly consists of the gar-
bled circuits, whereas the communication in the online stage is
very small. For example, with s = 40, for AES computation with
N = 32, about 260MB are transmitted in the ofﬂine stage and only
about 312KB per online execution; for N = 128, about 698MB are
transmitted in the ofﬂine stage and only about 238 KB per online
execution; for N = 1024, about 3850MB are transmitted in the of-
ﬂine stage and less than 170KB in the online stage. (Recall that
the number of circuits per bucket is larger for N = 32 than for
N = 128,1024, and thus the communication in the online stage is
larger.) For s = 80, these numbers are about double, as expected
since the number of circuits is about double.

Comparison with related work. We focus here on comparing our
results with the ones reported by previous works. We leave the
comprehensive benchmarking of all relevant protocols using simi-
lar hardware, network conﬁguration, and so on to future work.

As discussed in Section 1, the fastest published implementation
of cut-and-choose based 2PC on standard machines (without mas-
sive parallelism) is of [2] which requires more than 6 seconds for a
single secure computation of AES. In, [30, 10], it is shown how to
reduce costs drastically using massive parallelism, requiring only
several tens of ms per 2PC invoked. Note, however, that our pro-
tocol works in the online/ofﬂine setting, while [2, 10] work in the
single-execution setting and [30] works in the batch setting. Still,

Different 2PC protocols, that are not based on the cut-and-choose
technique for garbled circuits, are presented in [26] and [7]. Both
protocols have an ofﬂine stage in which the parties work indepen-
dently of their inputs, and a much shorter online stage in which the
players use their inputs and compute the function of interest. The
cryptographic work required by these protocols during the online
stage is very small (if any), however, both protocols require a num-
ber of interaction rounds that depends on the depth of the circuit
being evaluated.

The overall online stage of [26] costs 4 seconds (for a single
computation) for computing AES, while the ofﬂine is at least 1
second (even when amortized for many computations). For many
computations (135), the total online time is 15 seconds. This gives
a low amortized time, but high latency. The average total running
time (i.e., the sum of the ofﬂine and online timings for a single
AES computation) is at least 1.6 seconds (for all numbers tested in
[26]). In [8], optimizations and improvements were made to [26]
that enables running many AES executions in parallel. The best
results obtained there provide an online time of 9962 ms for 680
AES operations in parallel. This yields a low average cost (about
14 ms per AES), but a high latency. The online time for a single
execution is expected to be similar to [26]. Regarding [7], the cost
of the ofﬂine stage for computing AES is about 156 seconds and
the cost of the online stage (with 50 rounds of communication) is
about 20 ms [31]. However, both [26] and [7] have many rounds
of communication; thus in slower networks (e.g., between different
Amazon regions) they will perform poorly.

We note that in [26] and [7], the ofﬂine stage is independent
of the circuit being evaluated in the online stage, whereas in our

586Number
of buckets

32
128
1024

1 thread
10129
23961
125993

Ofﬂine total
5 threads

6905
15819
82476

9 threads

6310
14539
75879

Number
of buckets

32
128
1024

1 thread
36483
113352
815313

Ofﬂine total
5 threads
35725
111586
778010

9 threads
36039
117650
778235

Table 4: Running times (in ms) of the ofﬂine stage for the AES circuit in LAN conﬁguration for s = 40 in LAN conﬁguration (left)
and WAN conﬁguration (right). The number of circuits per bucket is as in Table 2. (For s = 80, the times are 2-2.5 larger.)

Circuit

Number of buckets

Ofﬂine total Ofﬂine per bucket

AES

SHA-1

32
128
1024
32
128
1024

36039
117650
778235
52463
152509
2936775

1126
919
759
1639
1191
2867

Online time per bucket

9 threads

1 thread

5 threads

171
166
162
194
194
184

164
163
160
185
182
173

163
164
160
176
180
175

Table 5: Running times of AES and SHA-1 in WAN conﬁguration using the parameters of Table 2 (in ms) for s = 40. The roundtrip
between the parties was 75 ms.

protocol, a single circuit is ﬁxed for all computations. Thus, they
are better suited for settings in which the function to be computed
is not known ahead of times. In addition, [7] has two signiﬁcant
advantages over our protocol: (1) it can work with more than two
parties, and (2) it can work with arithmetic circuits, which for some
types of computations is more efﬁcient.

7. CONCLUSION

The ﬁrst evaluation of cut-and-choose based 2PC was presented
in [27] in 2009. It required 1114 seconds for a single computation
of AES. Since then, many algorithmic and engineering improve-
ments have been presented, gradually reducing the cost of AES
computation to 264 seconds [29], to 6 seconds [2], and to even
1.4 seconds [17] and 0.46 seconds [10] when using massive paral-
lelism. This work continues this line of work and shows how the
costs can be further reduced using recent and new algorithmic im-
provements (though in a slightly different, yet very natural setting).
When preprocessing 1024 executions, the average online time is
less than 10 ms and the amortized ofﬂine time is only 74 ms. As
we use most state-of-the-art techniques (e.g., the protocol of [23],
the garbling scheme of [4], and the OT extension of [3]), these tim-
ings are the result of incredible work carried out by the community
on all aspects of the protocol, together with our new consistency
check. We ﬁnd these results to be exciting as they are more than
four orders of magnitude better than the one of [27], carried out just
6 years ago.

We believe that our results can be further improved using better
multithreading, and are currently working on modifying our proto-
type to use multiple cores and even machines in parallel (in a sim-
ilar manner to the work of [17]). We leave the goal of optimizing
and evaluating our protocol for GPUs for future work.
Acknowledgements. We would like to thank Moriya Farbstein,
Meital Levy and Asaf Cohen for the implementation of the protocol
and its extensive performance evaluation.

8. REFERENCES
[1] SCAPI, 2015. http://crypto.biu.ac.il/scapi and

https://github.com/cryptobiu/scapi.

[2] A. Afshar, P. Mohassel, B. Pinkas, and B. Riva.

Non-interactive secure computation based on
cut-and-choose. In EUROCRYPT 2014, Springer (LNCS
8441), pages 387–404, 2014.

[3] G. Asharov, Y. Lindell, T. Schneier, and M. Zohner. More

efﬁcient oblivious transfer extensions with security for
malicious adversaries. In EUROCRYPT 2015, Springer
(LNCS 9056), pages 673–701, 2015.

[4] M. Bellare, V. T. Hoang, S. Keelveedhi, and P. Rogaway.
Efﬁcient garbling from a ﬁxed-key blockcipher. In IEEE
Symposium of Security and Privacy, 2013.

[5] M. Bellare, V. T. Hoang, and P. Rogaway. Adaptively secure
garbling with applications to one-time programs and secure
outsourcing. In ASIACRYPT 2012, Springer (LNCS 7658),
pages 134–153, 2012.

[6] S. G. Choi, J. Katz, R. Kumaresan, and H.-S. Zhou. On the

security of the “free-XOR” technique. In TCC, Springer
(LNCS 7194), pages 39–53, 2012.

[7] I. Damgård, V. Pastro, N. P. Smart, and S. Zakarias.

Multiparty computation from somewhat homomorphic
encryption. In CRYPTO 2012, Springer (LNCS 7417), pages
643–662, 2012.

[8] I. Damgård, R. Lauritsen, and T. Toft. An empirical study

and some improvements of the minimac protocol for secure
computation. In SCN 2014, Springer (LNCS 8642), pages
398–415, 2014.

[9] Y. Ejgenberg, M. Farbstein, M. Levy, and Y. Lindell. SCAPI:
The secure computation application programming interface.
Cryptology ePrint Archive, Report 2012/629, 2012.
http://eprint.iacr.org/.

[10] T. K. Frederiksen, T. P. Jakobsen, and J. B. Nielsen. Faster
maliciously secure two-party computation using the GPU.
Cryptology ePrint Archive, Report 2014/270, 2014.
http://eprint.iacr.org/.

[11] T. K. Frederiksen and J. B. Nielsen. Fast and maliciously

secure two-party computation using the GPU. In ACNS 2013,
Springer (LNCS 7954), pages 339–356, 2013.

[12] O. Goldreich and E. Kushilevitz. A perfect zero-knowledge

proof system for a problem equivalent to the discrete
logarithm. In Journal of Cryptology, 6(2):97–116, 1993.

[13] O. Goldreich, S. Micali, and A. Wigderson. How to play any
mental game. In the 19th ACM STOC, pages 218–229, 1987.
[14] Y. Huang, J. Katz, and D. Evans. Efﬁcient secure two-party
computation using symmetric cut-and-choose. In CRYPTO
2013, Springer (LNCS 8043), pages 18–35, 2013.

587Circuit

Number of buckets

Ofﬂine total Ofﬂine per bucket

AES

SHA-1

32
128
1024
32
128
1024

54467
165239
1102191
89860
314239
1412681

1702
1291
1076
2808
2455
1380

Online time per bucket

1 thread

5 threads

9 threads

204
190
178
268
236
213

180
172
167
227
210
196

180
176
169
234
211
196

Table 6: Running times of AES and SHA-1 in WAN conﬁguration using the parameters of Table 3 (in ms) for s = 80. The roundtrip
between the parties was 75 ms.

Number of buckets

Ofﬂine total Ofﬂine per bucket

32
128
1024

6915
18367
93613

216
143
91

Online time per bucket

1 thread

5 threads

9 threads

17
12
8

12
10
6

12
10
6

Table 7: Running times of AES (in ms) in LAN conﬁguration using the parameters of Table 2 on c4.2xlarge instances. (The costs for
s = 80 are about 2-3 times larger.)

[15] Y. Huang, J. Katz, V. Kolesnikov, R. Kumaresan, and A. J.

Malozemoff. Amortizing garbled circuits. In CRYPTO 2014,
Springer (LNCS 8617), pages 458–475, 2014.

[16] V. Kolesnikov and T. Schneider. Improved garbled circuit:
Free xor gates and applications. In ICALP 2008, Springer
(LNCS 5126), pages 486–498, 2008.

[17] B. Kreuter, A. Shelat, and C.-H. Shen. Billion-gate secure

computation with malicious adversaries. In USENIX
Security, pages 14–14, 2012.

[18] Y. Lindell. Highly-efﬁcient universally-composable

commitments based on the DDH assumption. In
EUROCRYPT 2011, Springer (LNCS 6632), pages 446–466,
2011.

[19] Y. Lindell. Fast cut-and-choose based protocols for malicious

and covert adversaries. In CRYPTO 2013, Springer (LNCS
8043), pages 1–17, 2013.

[20] Y. Lindell and B. Pinkas. An efﬁcient protocol for secure

two-party computation in the presence of malicious
adversaries. In EUROCRYPT 2007, Springer (LNCS 4515),
pages 52–78, 2007.

[21] Y. Lindell and B. Pinkas. A proof of security of Yao’s

protocol for two-party computation. Journal of Cryptology,
22(2):161–188, 2009.

[22] Y. Lindell and B. Pinkas. Secure two-party computation via
cut-and-choose oblivious transfer. In the 8th TCC, Springer
(LNCS 6597), pages 329–346, 2011.

[23] Y. Lindell and B. Riva. Cut-and-choose yao-based secure

computation in the online/ofﬂine and batch settings. In
CRYPTO 2014, Springer (LNCS 8617), pages 476–494,
2014.

[24] P. Mohassel and M. K. Franklin. Efﬁciency tradeoffs for
malicious two-party computation. In PKC 2006, Springer
(LNCS 3958), pages 458–473, 2006.

[25] P. Mohassel and B. Riva. Garbled circuits checking garbled

circuits: More efﬁcient and secure two-party computation. In
CRYPTO 2013, Springer (LNCS 8043), pages 36–53, 2013.
[26] J. B. Nielsen, P. S. Nordholt, C. Orlandi, and S. S. Burra. A

new approach to practical active-secure two-party
computation. In CRYPTO 2012, Springer (LNCS 7417),
pages 681–700, 2012.

[27] B. Pinkas, T. Schneider, N. P. Smart, and S. C. Williams.

Secure two-party computation is practical. In ASIACRYPT
2009, Springer (LNCS 5912), pages 250–267, 2009.

[28] M. O. Rabin, Y. Mansour, S. Muthukrishnan, and M. Yung.

Strictly-black-box zero-knowledge and efﬁcient validation of
ﬁnancial transactions. In ICALP 2012, Springer (LNCS
7391), pages 738–749, 2012.

[29] A. Shelat and C.-H. Shen. Two-output secure computation

with malicious adversaries. In EUROCRYPT 2011, Springer
(LNCS 6632), pages 386–405. Springer, 2011.

[30] A. Shelat and C.-h. Shen. Fast two-party secure computation

with minimal assumptions. In ACM CCS, pages 523–534,
2013.

[31] N. Smart. Personal communication, February 2015.
[32] A. C.-C. Yao. How to generate and exchange secrets. In

FOCS, pages 162–167, 1986.

APPENDIX
A. THE FULL PROTOCOL

SPECIFICATION

FIGURE A.1

(THE OFFLINE STAGE).

Setup:

(cid:104)

that

x,y(1),y(2)(cid:17)
(cid:16)

x, (Ey(1))⊕ y(2)(cid:17)
(cid:16)

• s is a statistical security parameter, N is the number of online
2PC executions that P2 wishes to run, p, p(cid:48) are probabilities,
and B,B(cid:48) are chosen according to Lemmas 2.2 and 2.3.

computes

• The parties decide on two circuits:
f

(1) A circuit
C
,
with y(2) being public-input wires.
(2) A cheating-
C(cid:48)(x,D,d(1),d(2))
that
computes
recovery
D = ((E(cid:48)d(1))⊕ d(2)) ? x | 0
, with d(2) and D being
public-input wires. E and E(cid:48) are chosen at random by P2 as
discussed in Section 2.3.
For simplicity of the description here, we require that both
circuits are constructed as described in Section 2.3 so that
the value of Ey(1) (or E(cid:48)d(1)) remains private even if s − 1
bits of y(1) (or d(1)) are revealed.

circuit

(cid:105)

Running the cut-and-choose for C and for C(cid:48):

• The parties run the cut-and-choose sub protocol from Fig-

ure A.1 with the circuit C and parameters p,N and B.

• The parties run the cut-and-choose sub protocol from Fig-
ure A.1 with the circuit C(cid:48) and parameters p(cid:48),N and B(cid:48). (Note
that the same N is used in both cut-and-choose, so both result
in the same number of buckets.)

588FIGURE A.2

(THE OFFLINE STAGE (CONTINUED) AND SUB-PROTOCOLS).

The Ofﬂine Stage – Continued

Running the cut-and-choose for C and for C(cid:48) (cont.): We chose to simplify the description by using the cut-and-choose as a sub-protocol.
However, the calls to FExCom∆ZK for the masks of C and C(cid:48) must be done together since P2 should learn the XORs of the masks for the circuits
that are placed in the same bucket. In the proof, we assume that the steps of the two cut-and-choose sub protocols are done in parallel, and thus
the calls to FExCom∆ZK can be done together.
From now on, we refer to the elements of the second cut-and-choose with prime. E.g. π(cid:48) is the mapping function of the second execution from
above (while π is of the ﬁrst one). Also, denote the remaining garbled circuits according to their placement by π, i.e. let gc j,i be the ith circuit
of the jth bucket (for j = 1, . . . ,N and i = 1, . . . ,B).
Running OTs for C and for C(cid:48):
1 , . . . ,y(1)

• P2 chooses y(1)
• P1 acts as the sender in Fot and P2 as the receiver. For bucket j = 1, . . . ,N, the parties execute |y(1)| OTs, in which in the ith OT P2
, and P1 inputs the set of labels that correspond to 0 in the ith bit, and the set of labels that correspond to 1, both

N ∈R {0,1}|y(1)|, and d(1)

N ∈R {0,1}|d(1)|.

1 , . . . ,d(1)

inputs the ith bit of y(1)
j
concatenated with their decommitments related to lc-s. (Recall that the labels are XORed with λ j.)
The players do the same for circuit C(cid:48), where P2 inputs the bits of d(1)
j,i .

Storing buckets for the online stage: For bucket j = 1, . . . ,N:

• P1 stores (seed j,i,m j,i,lc j,i, ld j,i,λ j,i) for i = 1, . . . ,B, and similarly for all the bundles of C(cid:48).
• P2 stores y(1)

, lc j,i and gc j,i for i = 1, . . . ,B. In addition, it stores the labels it has received for its input y(1)
j

j

∆ j, and similarly for all the bundles of C(cid:48).

from the OTs, the values of

• A circuit C(x,y(1),y(2)) with y(2) being public-input wires, or, a circuit C(x,D,y(1),y(2)) with D,y(2) being public-input wires

Creating a Garbled-Circuit Bundle

Public Parameters:

Constructing the bundle:

• Pick a seed seed ∈R {0,1}k. All the randomness needed in the next steps is derived from PRFseed (·). Pick m ∈R {0,1}|x|.
• Construct a garbled circuit gc in which the output-wire labels are the actual output bits concatenated with random labels. (E.g., the
output label for bit zero is 0|l where l ∈R {0,1}k). We use an adaptively-secure garbling scheme as discussed in Section 2.2, in which
all input-wire labels are XORed with λ .

(cid:110)(cid:16)

• Commit to x’s input-wire labels, permuted according to m, by

i ))(cid:9)
• Commit to all input-wire labels of y(1) and y(2) by(cid:8)(i, commit(λ ⊕W 0
• If D is an input to the circuit, commit to all input-wire labels of D by(cid:8)(i, commit(λ ⊕W 0
(cid:1) .
• Commit to all output-wire labels by commit(cid:0){i,W 0

i ), commit(λ ⊕W 1

i, commit(λ ⊕W mi
i

i ,W 1

i }i∈Out(C)

), commit(λ ⊕W 1−mi

)

i

.

i∈In(C,x)

i∈In(C,y(1))∪In(C,y(2)).

i ), commit(λ ⊕W 1

i∈In(C,D).

• Let lc be the union of the above sets of label commitments, and let ld be the set of all the corresponding decommitments.
• Output (gc,lc;seed,ld,m,λ ).

(cid:17)(cid:111)
i ))(cid:9)

Public parameters:

The Cut-and-Choose Mechanism

• Let s,N,B ∈ N and p ∈ (0,1) parameters. Let M = NB

p . (Assume no rounding of M is needed.) Denote the circuit by C.

Picking the cut, the buckets, and the ofﬂine inputs:

• The cut: P2 sets σ to be a random string of length M that has exactly NB ones.
• The mapping: P2 picks a PRF seed seedπ and uses PRFseedπ (·) to compute a mapping function π : [N · B] → [N] that maps exactly B
elements to each bucket.
Deﬁne πσ : [M] → [N] to be the function that maps an index j that is the ith non-zero bit in σ to π(i). Let Bi be the set { j|πσ ( j) = i}
for i = 1, . . . ,N.

• P2 commits on σ and seedπ using ExtractCom(·).

The cut-and-choose:

ExtractCom(λ1), . . . , ExtractCom(λM).

• P1 runs the garbled-circuit bundle procedure above with the circuit C, and receives (gc j,lc j; seed j,ld j,m j,λ j), for j = 1, . . . ,M.
• P1 sends gc1, . . . ,gcM and lc1, . . . ,lcM, and commits on their seeds and λ s by ExtractCom(seed1), . . . , ExtractCom(seedM) and
• P2 inputs to FExCom∆ZK the sets Bi, for i = 1, . . . ,N, while P1 inputs the values m1, . . . ,mM. P2 learns the sets ∆i for each bucket,
• P2 decommits σ and seedπ . P1 veriﬁes that they are consistent with J and the Bi-s received in the last step.
• Let J be the indexes that did not appear in any Bi. For j ∈ J, P1 asks FExCom∆ZK to reveal m j, and in addition decommits seed j and λ j.
• P2 computes the set {gci,lci} j∈J using the seeds it received and veriﬁes that everything is correct.

whereas P1 learns sets Bi-s.

589FIGURE A.3

(THE ONLINE STAGE).

We focus here on a single 2PC with a single bucket. For simplicity, we omit the bucket index j when we refer to its garbled circuits, etc.
Private inputs: P1’s input is x. P2’s input is y.
Evaluating C:

• P2 sends y(2) = y⊕ y(1)
• P1 sends x1 = x⊕ m1.
• For i = 1, . . . ,B,

j E.

– P1 decommits λi.
– P1 sends the input-wire labels for y(2) and for xi = x1⊕m1⊕mi in gci, and the decommitments of those labels for the corresponding

commitments in lci. (Recall that P2 knows m1 ⊕ mi from ∆ j, thus, can compute the value of xi by itself.)

• P1 picks D ∈R {0,1}k.
• For v ∈ Out(C),

i,v be the b-th label of output wire v of gci, where v ∈ Out(C). P1 sends W 0

– P1 chooses Rv ∈R {0,1}k.
– Let W b
• P1 sends H(D).
• P2 evaluates gci, for i = 1, . . . ,B, and then uses the output wire labels to “decrypt” the associated Rv and Rv ⊕ D values. In case it learns
both Rv and Rv ⊕ D for some output wire, it checks if the XOR of them is indeed D (by applying H(·) and comparing with the value
that P1 has sent). If so, it sets d to D. Otherwise, it sets d ∈ {0,1}s.

i,v ⊕ Rv ⊕ D for i = 1, . . . ,B.

i,v ⊕ Rv,W 1

• If all evaluations (that ended) returned the same output, set z to be that output.

Evaluating C(cid:48):

• Let d(1) the input that P2 used in the OTs for circuit C(cid:48) in bucket j. P2 sends d(2) = d ⊕ d(1)E(cid:48).
• P1 sends D, and for i = 1, . . .B(cid:48), and:

for C).

• P1 decommits the commitments on the output labels of gci, for i = 1, . . .B (i.e. revealing all output wire labels of the garbled circuits
• P2 veriﬁes all decommitments, all the value W 0
i,v ⊕ Rv ⊕ D, for i = 1, . . . ,B and v ∈ Out(C), and the hash H(D), and aborts if
• P2 evaluates gc(cid:48)

i, for i = 1, . . .B(cid:48), and takes the majority output to be ˆx.

i,v ⊕ Rv,W 1

there is a problem.

P2’s output:

• If all evaluation circuits of C returned the same output z, then P2 outputs z.
• Else, if P2 has learned earlier d such that H(d) = H(D), then it outputs f ( ˆx,y).
• Else, let gci be a circuit for which all the output labels that P2 received from its evaluation were also the labels that were decommitted

earlier from lci. P2 outputs the output of gci.

– P1 decommits λ(cid:48)
i .
– Sends the labels that correspond to D and d(2) in gc(cid:48)
i in gc(cid:48)
– Sends the input-wire labels for x(cid:48)
i from ∆ j.)

i. (Again, recall that P2 knows m1 ⊕ m(cid:48)

i = x1⊕m1⊕m(cid:48)

in lc(cid:48)

i, and decommits the corresponding commitments from lc(cid:48)
i.
i, and the decommitments of those labels for the corresponding commitments

590