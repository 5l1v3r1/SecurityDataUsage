2012 IEEE Symposium on Security and Privacy

Secure and Scalable Fault Localization under Dynamic Trafﬁc Patterns

Xin Zhang

CyLab / Carnegie Mellon University

Chang Lan

Tsinghua University

Adrian Perrig

CyLab, Carnegie Mellon University

Abstract—Compromised and misconﬁgured routers are a
well-known problem in ISP and enterprise networks. Data-
plane fault localization (FL) aims to identify faulty links
of compromised and misconﬁgured routers during packet
forwarding, and is recognized as an effective means of achieving
high network availability. Existing secure FL protocols are
path-based, which assume that the source node knows the
entire outgoing path that delivers the source node’s packets
and that the path is static and long-lived. However, these
assumptions are incompatible with the dynamic trafﬁc patterns
and agile load balancing commonly seen in modern networks.
To cope with real-world routing dynamics, we propose the
ﬁrst secure neighborhood-based FL protocol, DynaFL, with
no requirements on path durability or the source node knowing
the outgoing paths. Through a core technique we named
delayed key disclosure, DynaFL incurs little communication
overhead and a small, constant router state independent of the
network size or the number of ﬂows traversing a router. In
addition, each DynaFL router maintains only a single secret
key, which based on our measurement results represents 2–4
orders of magnitude reduction over previous path-based FL
protocols.

I. INTRODUCTION

Modern ISP, enterprise, and datacenter networks demand
reliable data delivery to support performance-critical ser-
vices, thus requiring the data plane to correctly forward
packets along the routing paths. However, real-world inci-
dents [2], [3], [7], [21], [25], [32] reveal the existence of
compromised routers in ISP and enterprise networks that
sabotage network data delivery. Also, in a 2010 worldwide
security survey [1], 61% of network operators ranked infras-
tructure outages due to misconﬁgured network equipment
such as routers as the No. 2 security threat. Such misbehav-
ing routers can easily drop, modify, delay or inject packets
into data plane to mount Denial-of-Service, surveillance,
man-in-the-middle attacks, and data exﬁltration where a
malicious router may replicate some packets and send them
along other unexpected paths.
Unfortunately, current networks lack a reliable and se-
cure way to identify misbehaving routers that jeopardize
packet delivery. For example, a malicious or misconﬁgured
router can “correctly” respond to ping or traceroute
probes while corrupting other data packets, thus cloaking
the attacks from ping or traceroute. Data-plane fault
localization (FL) aims to localize faulty links that sabotage
packet delivery in the data plane, thus providing data-plane
accountability. By removing the identiﬁed faulty links from

the routing tables or bypassing the faulty links in route
selection, FL enables network communication to be carried
only on non-faulty links, thus yielding high packet delivery
guarantees [9], [14], [34].
Existing FL protocols that are secure against sophisticated
packet modiﬁcation and fabrication attacks [11], [14], [34]
require that the sender know the entire path that delivers
the source node’s packets, and that the path be long-lived
(e.g., stable over transmitting 108 packets [14]) to obtain
a statistically accurate FL. However, recent measurement
studies [10], [18], [20] show that a considerable fraction
of current network ﬂows are short-lived “mice” and routing
paths are highly dynamic. Furthermore, emerging enterprise
and datacenter networks call for more agile load balancing
and dynamic routing paths. For example, a recently proposed
datacenter routing architecture, VL2 [20], employs Valiant
Load Balancing [24], [37] to spread trafﬁc uniformly across
network paths via random packet deﬂection. In this case, the
actual routing path is determined on the ﬂy during forward-
ing and thus cannot be predicted and known by the sender.
Given the conﬂict between the “static-path” assumption
and the “dynamic-path” reality, researchers have concluded
that existing FL protocols are impractical for widespread
deployment
in large-scale networks with dynamic trafﬁc
patterns [14].
in existing secure FL protocols, a router
In addition,
must share some secret (e.g., cryptographic keys) with each
source node sending trafﬁc traversing that router, making
the key storage overhead at an intermediate router linear
in the number of end nodes. The proliferation of key copies
shared by routers with all end nodes under non-uniform (and
generally poor) administration also increases the risk of key
compromise thereby enabling undetected attacks. In existing
secure FL protocols, a router also needs to maintain per-
path state for each path traversing that router, making the
FL unscalable for large-scale networks.
We aim to bridge the current gap between the security
of FL against strong adversaries and the ability to support
dynamic trafﬁc patterns in modern networks such as ISP,
enterprise, and datacenter networks. More speciﬁcally, the
desired FL protocol should be secure against sophisticated
packet dropping, modiﬁcation, fabrication, and delaying
attacks by colluding routers, while retaining the following
properties:
• Path obliviousness: A source node or a router does not

© 2012, Xin Zhang. Under license to IEEE.
DOI 10.1109/SP.2012.27

317

If TSA!=TSB
accuse lAB

TSD

TSC

TSA

TSB

S

A

B

C

D

Figure 1. Path-based FL. TSr denotes the trafﬁc summary generated by
router r. For brevity, “TSA!=TSB” refers to “TSA deviates from TSB more
than a certain threshold”.

N(s)

i

j

N(r)

s

p

r

q

b

N(a)

a

c

Figure 2. A neighborhood example.

• Volatile path support: The FL protocol requires no
• Constant router state: A router does not need to
• O(1) key storage: A router only manages a small

need to know the outgoing/downstream path.
maximum duration for a forwarding path.
maintain per-path, per-ﬂow, or per-source state.
number of keys regardless of the network size.

that

Path obliviousness and volatile path support together enable
agile (e.g., packet-level) load balancing and dynamic routing
paths (e.g., Valiant load-balanced paths). These two prop-
erties also decouple the data-plane FL from routing, thus
enabling it to support a wide array of routing protocols.
Finally, constant router state provides scalability in large-
scale networks and O(1) key storage reduces the key setup
overhead.
We observe that the “static-path” assumption in existing
secure FL protocols stems from the fact
those FL
protocols operate on entire end-to-end paths (path-based),
to localize the fault to one speciﬁc link. As Figure 1 shows,
each router maintains a certain “trafﬁc summary” (e.g., a
counter, packet hashes, etc.) for each path that traverses
the router (thus requring per-path state), and sends the
trafﬁc summary to the source node S of each path. S can
then detect a link l as malicious if the trafﬁc summaries
from l’s two adjacent nodes deviate greatly, as Figure 1
illustrates. Hence, S needs to know the entire path topology
to compare trafﬁc summaries of adjacent nodes, and needs
to send a large number of packets over the same path so that
the deviation in trafﬁc summaries can reﬂect a statistically
accurate estimation of link quality. Finally, to authenticate
the communication between the source and each router in
the path, a router needs to share a secret key with each
source that sends trafﬁc through it.

In this paper, we explore neighborhood-based FL ap-
proaches, where a router r’s data-plane faults (if any) can
be detected by checking the consistency (or conservation)
of the trafﬁc summaries generated by the 1-hop neighbors
of r (denoted by N(r) in Figure 2). That is, in benign cases,
the packets sent to r will be consistent with the packets
received from r by all of r’s neighbors as reﬂected in their
trafﬁc summaries. In this way, the FL is independent of
routing paths and only depends on 1-hop neighborhoods,
thus supporting arbitrary routing protocols and dynamic load
balancing. Additionally, each router in a neigbhorhood-based
approach only needs to maintain state for each neighbor.
In summary, neighborhood-based FL localizes faults to a
speciﬁc 1-hop neighborhood to reduce further investigation,
to trade localization precision for practicality in modern
networks with dynamic trafﬁc patterns.
Though promising, neighborhood-based FL is susceptible
to sophisticated packet modiﬁcation and collusion attacks
due to several security and scalability challenges. For exam-
ple, for the sake of scalability, the trafﬁc summary cannot
be a copy of all the original packets (or even their hashes),
but have to be a compact representation of the original
packets via a certain ﬁngerprinting function F. On one
hand, if F generates trafﬁc summaries at different nodes
without using different secret keys, a malicious router can
predict
the outputs of F at other nodes and tactically
modify packets such that the outputs of F will stay the
same as with the original packets. On the other hand, if
F at different nodes uses different secret keys, we cannot
compare and run consistency check over different nodes’
trafﬁc summaries. To address these challenges, we propose
DynaFL, a protocol that employs a core technique called
delayed key disclosure, which discloses the same key for
computing F to different routers after they have forwarded
the packets. To further minimize the protocol overhead,
DynaFL employs a secure sampling mechanism also based
on the delayed key disclosure, so that a malicious router
cannot know if a packet is sampled or not at the time it
forwards (corrupts) the packet. Finally, a router in DynaFL
only shares a secret key with a centralized controller, thus
achieving O(1) key storage.
Contributions. Our contributions are three-fold:
1. We raise the importance of pursuing a secure FL design
to cope with dynamic trafﬁc patterns in real-world networks
with a small constant router state and key storage.
2. To the best of our knowledge, DynaFL is the ﬁrst secure
neighborhood-based FL protocol that achieves path oblivi-
ousness and volatile path support, and is secure against both
packet loss and sophisticated packet modiﬁcation/injection
attacks.
3. In addition, a DynaFL router requires only about 4MB
per-neighbor state based on our AMS sketch [6] implementa-
tion, whereas path-based FL protocols require per-path state.

318

We also show through measurements that the number of
keys a router needs to manage in path-based FL protocols
is 2 - 3 orders of magnitude higher than that in DynaFL
(which is a single key shared with a centralized controller).
Finally, our simulation results demonstrate DynaFL’s small
detection delay and negligible communication overhead.

II. PROBLEM STATEMENT

In this section, we formalize the notation, network setting,

adversary model, and problem statement.
A. Notation

S

i

j

!

!

traversing a neighborhood N(s),

We use the terms node and router interchangeably to gen-
erally refer to devices that either perform layer-2 switching
or layer-3 routing (so nodes do not include end servers).
We denote the 1-hop neighborhood (or neighborhood, for
brevity) of a node s as N(s), as Figure 2 illustrates. For
a particular packet
the
neighbor sending that packet to node s is called an ingress
node in N(s) for that packet, and the node receiving that
packet from s is called an egress node. We term a sequence
of packets as a packet stream S. Particularly, we denote the
packet stream sent from node i to node j as Sij, and this
and S←i
,
packet stream is seen by nodes i and j as S→j
respectively. The difference of two packet streams S and
!, denoted by ∆(S
), refers to the number of packets in
one packet stream but not in the other, without considering
the variable IP header ﬁelds such as the TTL and checksum
ﬁelds.
B. Network Setting

, S

We consider a network with dynamic trafﬁc patterns and
a relatively static network topology, which is best exem-
pliﬁed by today’s ISP, enterprise, and datacenter networks.
To provide maximum ﬂexibility to support various routing
protocols, and even packet-level load balancing, we pose
no restriction on the routing protocols and load balancing
mechanisms used in the network. We assume a trusted
administrative controller
(AC) in the network, which
shares a pairwise secret key with each router in the network.
As we will show later,
the AC is mainly in charge of
analyzing the trafﬁc summaries gathered from different
nodes and localizing any neighborhood with data-plane
faults. Finally, we require nodes in the network be loosely
time-synchronized, e.g., on the order of milliseconds. Loose
time synchronization represents a common requirement for
detecting packet delaying attacks [8], [9], [29] and nowadays
even high-precision clock synchronization is available given
the advent of GPS-enabled clocks and the adoption of IEEE
1588 [23].
C. Adversary Model

We consider a sophisticated adversary controlling multiple
malicious nodes. Speciﬁcally, a malicious node corrupts

data-plane packets by unexpectedly dropping, modifying
and delaying legitimate packets sent by the source, and
fabricating bogus packets that are not sent by the source.
A malicious node can corrupt both the data packets and
control packets, such as trafﬁc summaries sent from a node
to the AC and certain administrative messages sent from
the AC to nodes. Furthermore, a sophisticated adversary
has knowledge of and tries to disrupt the FL protocol to
evade detection. Multiple colluding nodes can collectively
perform the above data-plane attacks, conspiring to evade
detection or frame benign nodes. The colluding nodes know
each other’s security credentials (e.g., secret keys used in
the FL protocol).
Such a strong attacker model is not merely a theoretical
conception, but has been widely witnessed in practice. For
example, outsider attackers have leveraged social engineer-
ing, phishing [3], and exploration of router software vul-
nerabilities [2], [7] or weak passwords [21] to compromise
ISP and enterprise routers [32]. In addition, a majority of
network operators in a recent worldwide security survey [1]
listed router misconﬁguration, which also falls under our ad-
versary model, as a primary cause of network outages [25].
As we will show in Section III-C, achieving FL security
against surreptitious packet modiﬁcation/fabrication attacks
is challenging and dramatically complicates the protocol
design.
D. Problem Formulation

Our goal is to design a practical and secure neighborhood-
based FL protocol to identify a suspicious neighborhood
(if any) that contains at least one malicious node. Recall
that practicality translates to path obliviousness, volatile path
support and constant router state as stated in Section I. We
further adopt the (α, β,δ )-accuracy [19] to formalize the
security requirements as below:

• If more than β fraction of the packets are corrupted
by a malicious node m, the FL protocol will raise
a neighborhood containing m or one of its colluding
nodes as suspicious with probability at least 1 − δ.
• In benign cases, if no more than α fraction of the
packets are spontaneously corrupted (e.g., dropped)
the FL protocol will raise the
in a neighborhood,
neighborhood as suspicious with probability at most δ.
The thresholds α and β are introduced to tolerate spon-
taneous failures (e.g., natural packet loss) and are set by
the network administrator based on her experience and
expectation of network performance.
Neighborhood-based FL enables the network administra-
tor to scope further investigation to a 1-hop neighborhood to
ﬁnd out which router is compromised. It is also possible to
further employ dedicated monitoring protocols, which only
need to monitor a small region (the identiﬁed neighborhood)
of the network to ﬁnd the speciﬁc misbehaving router.

319

III. CHALLENGES AND OVERVIEW

In this section, we ﬁrst describe the high-level steps of
general neighborhood-based FL and then explain the security
challenges in the presence of strong adversaries. Finally,
we present the key ideas in DynaFL that address these
challenges.
A. High-Level Steps

The general steps a neighborhood-based FL takes are
(i) recording local trafﬁc summaries, (ii) reporting the trafﬁc
summaries to the AC, and (iii) detecting suspicious neigh-
borhoods by the AC based on the received trafﬁc summaries,
as we sketch below. Though intuitive, these general steps
face several potential security vulnerabilities and scalability
challenges as Section III-C will show.
Recording. We divide the time in a network into consec-
utive epochs, which are synchronous among all the nodes
including the AC in the network. For each neighbor r, a
node s locally generates trafﬁc summaries, denoted by TS→r
and TS←r
, for the packet streams Ssr and Srs in each
epoch, respectively. Figure 3 depicts the router state in a
toy example.

s

s

{F(S→s

r

), t

→s
r

, n→s

TS→s

r

r

TS←s

r

Srs

Ssr

r }
TS←r

s

TS→t

s

s

TS→r

s

TS←t

s

Sst

Sts

TS←s

t

t

TS→s

t

Figure 3. Router state for trafﬁc summaries.

The trafﬁc summary recorded by a node s should reﬂect
both the packet contents and the arrival/departure time seen
at node s to enable the detection of malicious packet
corruption and delay. For the sake of scalability, the trafﬁc
summary can not simply be an entire copy of all the original
packets (or their hashes using a cryptographic hash function
such as SHA-1 which provides one-wayness and collusion
resistance) and their timing information. Instead, we use
a ﬁngerprinting function F to reﬂect the aggregates of
packet contents to reduce both router state and bandwidth
consumption for reporting the trafﬁc summaries to the AC.
We denote the ﬁngerprint for a packet stream Srs generated
), as Figure 3 depicts. In addition, as Figure 3
by r as F(S→s
shows, for a packet stream Srs (or Ssr), the trafﬁc summary
(or
of node r also contains the average departure time t→s
(or
) and the total number of packetsn →s
arrival time t←s
) in Srs (or Ssr) seen in the current epoch to enable the
n←s
detection of packet delay attacks.
Reporting. At the end of each epoch, each node s sends its
local trafﬁc summaries to the AC.

r

r

r

r

r

320

!

!

!

!

!

Detection. After receiving the trafﬁc summaries at the end
of an epoch, the AC runs a consistency check over the trafﬁc
summaries in each neighborhood. A large inconsistency
of the trafﬁc summaries in a certain neighborhood N(s)
indicates that N(s) is suspicious.
B. The Fingerprinting Function F

) = F(S) ∪F (S

Before we present the instantiation of F, we ﬁrst describe
the general properties that F should satisfy. To enable the
AC to detect suspicious neighborhoods, F should generate
trafﬁc summaries with the following two properties:
!,
Property 1: Given any two packet streams S and S
) can give an
the “difference” between F(S) and F(S
!, denoted by:
estimation of the difference between S and S
) ! ∆(S, S
).
∆(F(S), F(S)
Deﬁning the “difference” between F(S) and F(S
) is F-
speciﬁc, as we show shortly.
!,
Property 2: Given any two packet streams S and S
).
F(S ∪ S
The ∪ operator on the left-hand side denotes a union
!. The∪ operator
operation of the two packet streams S and S
on the right-hand side denotes a “combination” of F(S) and
F(S
These two properties enable the conversion from checking
packet stream conservation to checking the conservation of
trafﬁc summaries in a neighborhood. In other words, these
two properties enable nodes to simply store the compact
packet ﬁngerprints instead of the original packet streams
while still enabling the AC to detect the number of pack-
ets dropped, modiﬁed, and fabricated between two packet
streams from their corresponding ﬁngerprints.
the AC only
Speciﬁcally, during the detection phase,
needs to compare the difference between (i) the combined
trafﬁc summaries for packets sent to node s in N(s), i.e.,
), and (ii) the combined trafﬁc summaries for
∪i∈N(s) F(S→s
).
packets received from node s in N(s), i.e., ∪i∈N(s) F(S←s
By Properties 1 and 2:
), ∪
∆( ∪

), which isF -speciﬁc and deﬁned shortly.

F(S→s

F(S←s

))

i

i

!

!

i

i

i

i

, ∪i∈N(s) S←s

(1)
) reﬂects the discrep-
Note that ∆(∪i∈N(s) S→s
ancy between packets sent to and received from node s, and
a large discrepancy indicates packet dropping, modiﬁcation,
and fabrication attacks in N(s).
Sketch for F. The pthmoment estimation sketch [5], [17],
[33]
for path-based
FL) serves as a good candidate for F. More speciﬁcally,
pthmoment estimation schemes use a random linear map
to transform a packet stream into a short vector, called the
sketch, as the trafﬁc summary. In benign cases, packets, if

(as used by Goldberg et al.

[19]

i∈N(s)

=∆( F( ∪

i∈N(s)

i∈N(s)
), F( ∪

S→s

i

! ∆( ∪

i∈N(s)

S→s

i

, ∪
i∈N(s)

S←s

i

)) based on Property 2
based on Property 1

i∈N(s)
S←s
)

i

viewed as 1.5KB (the Maximum Transmission Unit) bit-
vectors, are “randomly” drawn from {0, 1}1536×8. Hence,
different packet streams will result in different sketches with
a very high probability (w.h.p.). Goldberg et al. [19] also
extensively studied how to estimate the number of packets
dropped, injected, or modiﬁed between two packet streams
from the “difference” of two corresponding sketch vec-
tors, thus satisfying Property 1. Speciﬁcally, the difference
) (used in Property 1) between two sketch
∆(F(S), F(S)
vectors is deﬁned as:

!

!

) = ||F(S) −F (S)

(2)
∆(F(S), F(S)
where ||x||p
p denotes the pthmoment of the vector x. We
can further prove that the sketch satisﬁes Property 2 and
! used in Property 2 is
the combination of F(S) and F(S)
deﬁned as:

||p
p

!

!

!

F(S) ∪F (S)

= F(S) + F(S)

(3)
where + denotes the addition of two vectors. The proof is
as follows.
Proof: A sketch function F over a set of elements S =
{p1, p2, . . . , pn} can be implemented in a “streaming” mode
using a hash function h [19], where:
h(pi) → $vi

(4)

and $vi denotes a vector. More speciﬁcally:
F(S) = F({p1, p2, . . . , pn}) = h(p1) +h( p2) +. . . + h(pn)
(5)
Hence, given two packet streams S = {p1, p2, . . . , pn}

and S

!

= {p

!

!

1, p

2, . . . , p

!

F(S ∪ S

) =F ({p1, . . . , pn, p

!

n!}, we have:
1, . . . , p

!

!

n!})

!

= h(p1) + . . . + h(pn) +h( p

1) + . . . + h(p

!

n!)
(6)

and:
F(S) +F (S

!

) =F ({p1, . . . , pn}) + F({p

!

!

1, . . . , p

n!})

!

= h(p1) + . . . + h(pn) + h(p

1) + . . . + h(p
(7)
From Equations 6 and 7 we can see that: when F(S) ∪
) =

) is deﬁned as F(S) +F (S

), we have F(S ∪ S

!

!

!

), thus proving Property 2 for Sketch.

F(S
F(S) ∪F (S

!

!

n!)

C. Challenges in a Neighborhood-based FL

From Property 1, we can further derive the following
conditions on the ﬁngerprinting function F. Given any two
packet streams Sr and St seen at nodes r and t, respectively,
a ﬁngerprinting function computed by r and t should satisfy:
(8)
(9)

if Sr = St, F(Sr) = F(St)
if Sr $= St, F(Sr) $= F(St) w.h.p.

321

F(S→s

r

) →

0001

!

Find a S
F(S

t such that
t) →

0001

!

!

F(S

t) →

0001

r

Srs

s

!

t (!= Srs)

S

t

F(S→s

r

) = F(S

!

t), no faults detected!

Figure 4. An example of stealthy packet modiﬁcation attacks when nodes
do not use different secret keys for computing F. For simplicity, the sketch
vector is represented as a ‘0-1’ bit vector. The malicious node s modiﬁes
t still
the packet stream in such a way that the modiﬁed packet stream S
results in the same sketch vector as Srs at node t.

!

The ﬁrst condition ensures the consistency of trafﬁc sum-
maries (more precisely, sketches in the trafﬁc summaries) in
the benign case when the packet streams are not corrupted
between nodes r and t. The second condition ensures
that if packet corruption happens between nodes r and t,
inconsistency of the trafﬁc summaries will be observed,
which will then enable the estimation of packet difference
in the corresponding packet streams (Property 1). However,
these two conditions tend to be contradicting and lead to the
following dilemma.
F without different secrets. If the random linear map in
F (which can be implemented as a hash function [14]), is
not computed with different secret keys by different nodes,
a malicious node can predict the F output of any other node
for any packet. Since F maps a set of packets (or their 160-
bit cryptographic hashes) to a much smaller sketch, hash
collisions will exist where two different packets produce the
same F output (since sketch is not proven to perserve the
collision resistance property of the cryptographic hash func-
tion). Hence, a malicious node can leverage such collisions
to modify packets such that the modiﬁed/fabricated packets
will produce the same F output at other nodes, violating the
condition in (9). Figure 4 depicts such an example.
F with different secrets. If nodes compute F with different
secret keys to satisfy the condition in (9), it is hard for
the AC to perform a consistency check among the resulting
sketches. For example, even the same packet stream would
result in different sketches at different nodes, thus violating
the condition in (8). Figure 5 depicts such an example. Since
the sketch is only a compact and approximate representation
of the original packet stream, the AC cannot revert the
received sketches to the original packet streams to check
packet stream conservation.
Scalability vs. sampling. Even with F for packet ﬁnger-
printing, a trafﬁc summary over a huge number of packets
can become too bandwidth-consuming to be sent frequently
to the AC (e.g., every 20 milliseconds). For example, the
number of packets for an OC-192 link (10Gbps) can be
on the order of 107 per second in the worst case, which

replacements

F(S→s

r

) →

0001

F(S←s

t

) →

1001

r

Srs

s

Sst(= Srs)

t

F(S→s

r

) != F(S←s

t

), suspicious!

Figure 5.
Illustration of the difﬁculty in using different secret keys when
computing F. The sketch vector is represented as a ‘0-1’ bit vector for
simplicity. In this example, nodes r, s and t use different secret keys when
computing the Sketch to generate their trafﬁc summaries.

swells the size of a sketch to hundreds of bytes to bound
the false positive rate below 0.001 [19] and may require
several KB/s bandwidth for the reporting by each node.
Packet sampling represents a popular approach to reducing
bandwidth consumption, where each node only samples a
subset of packets to feed into F for generating the trafﬁc
summaries. To enable a consistency check of the trafﬁc
summaries in a neighborhood, all nodes in a neighborhood
should sample the same subset of packets, and the challenge
is how to efﬁciently decide which subset of packets all
nodes should agree to sample. For security, the sampling
scheme must ensure that a malicious node cannot predict
whether a packet to be forwarded will be sampled or not.
Otherwise, the malicious node can drop any non-sampled
packets without being detected.

The problem is further complicated by the presence of
collusion attacks in our strong adversary model as well as
our path obliviousness requirement. Several existing sam-
pling schemes are broken when applied to our setting. For
example, in Symmetric Secure Sampling (SSS) [19], the
packet sender and receiver use a shared Pseudo-Random
Function (PRF) P to coordinate their sampling. Imported
to our setting, e.g., using the neighborhood example in
Figure 5, nodes r and t share a secret key Krt and a PRF P,
compute P with Krt for each packet, and sample the packet
if the PRF output is within a certain range. In this way, node
s itself cannot know whether a packet is sampled or not.
However, this approach fails in our setting. We consider the
topology in Figure 5 for example:

• If s and r collude, r can inform s of which packets are
sampled, so that s can safely drop non-sampled packets
and not be detected.
• Due to the dynamic trafﬁc pattern, an ingress node r of
a neighborhood N(s) does not know which egress node
a packet will traverse in N(s) (if s has more neighbors
besides r and t, there exist multiple possible egress
nodes than t). Hence, r does not know which PRF
or secret key to use for packet sampling, given that
r shares a different secret key with each node in N(s).

D. DynaFL Key Ideas

s and K e

In DynaFL, nodes temporarily store the cryptographic
hashes (which are collision-resistant) for all packets re-
ceived/sent per neighbor in an epoch. At the end of each
epoch e, nodes use epoch sampling to decide if packets in the
epoch are to be ﬁngerprinted; if so, nodes generate the trafﬁc
summaries and report them to the AC. This reduces both the
communication overhead for sending the trafﬁc summaries
to the AC and the computational overhead for generating
and checking the trafﬁc summaries. Speciﬁcally, nodes ﬁrst
use the network-wide identical per-epoch sampling key K e
(described shortly) for computing a PRF P to determine if
the current epoch is “selected”; if and only if the current
epoch is selected, nodes will use F with the network-
wide identical per-epoch ﬁngerprinting key K e
f (described
shortly) to map packets into per-neighbor trafﬁc summaries.
f enables consistency checking
Using the same K e
over the trafﬁc summaries from different nodes.
To address the packet modiﬁcation attacks and collusion
attacks mentioned earlier, nodes do not know the per-epoch
s and K e
f until the end of each epoch e, after theyhave
K e
forwarded (or possibly corrupted) packets in epoch e. Thus,
when a packet is to be forwarded (or corrupted), a malicious
f, and thus cannot predict
node does not know K e
whether this epoch is selected for sending trafﬁc summaries,
and if selected, what the sketch output will be for this
packet. To achieve this property, in DynaFL, the trusted
f via key
AC periodically sends the per-epoch K e
disclosure messages to all nodes at the end of each epoch
in a reliable way (described later) and nodes use the received
s and K e
f to select epochs and ﬁngerprint packets that have
K e
already been forwarded or corrupted.
A malicious node may ﬁrst attempt to locally hold all
the packets in an epoch e, and only forward or corrupt
packets at the end of e when the malicious node learns K e
and K e
f, thus being able to launch the packet modiﬁcation
and selective packet corruption attacks as mentioned ear-
lier. However, since the trafﬁc summaries also include the
average departure/arrival time of the sent/received packets,
the malicious node will be detected with packet delay
misbehavior in the detection phase.
Sections IV, V, and VI detail the recording, reporting,
and detection phases in DynaFL, respectively. Section VII
presents the security analysis and Section VIII evaluates
DynaFL’s performance through measurements and simula-
tions.

s and K e

s and K e

s

s

IV. RECORDING TRAFFIC SUMMARIES

The main technical challenges in the recording phase are
how to deal with imperfect
time synchronization among
nodes and packet transmission delay, and how to efﬁciently
protect the key disclosure message from adversarial corrup-
tion. We explain how DynaFL solves these challenges in
turn below.

322

A. Storing Packets

In the “ideal” case (with perfect time sychronization and
no packet transmission delay), nodes simply need to store
packets for the single “current” epoch and at the end of each
epoch send the trafﬁc summaries to the AC for that epoch.
However, in practice, routers need to determine which epoch
an incoming packet belongs to (or whether a received packet
belongs to the current epoch or a previous, outdated epoch).
One might attempt to let routers map received packets into
epochs based on their local packet arrival time. However,
this approach would introduce large errors for the following
reasons:

• Though all the nodes in the network are loosely time-
synchronized, e.g., ±1 millisecond, the epoch intervals
at different nodes may still be misaligned by up to a few
milliseconds. This misalignment will result in a consid-
erable number of packets being attributed to different
epochs at different nodes, thus causing inconsistencies
in the corresponding packet ﬁngerprints.
• Due to the network transmission delay, a packet sent
by a source at epoch e may arrive at another node at
a different epoch e + i. In other words, a packet may
have been received by an ingress node but not the egress
node of a neighborhood at the end of an epoch when
nodes need to generate their packet ﬁngerprints, thus
producing inconsistencies in the trafﬁc summaries.

To deal with imperfect time synchronization, the source
in DynaFL embeds a local timestamp when sending each
packet. Such a timestamp can be added as an additional ﬂow
header, using the TCP timestamp, or in the IP option ﬁeld,
etc. Any router in the forwarding path will determine the
corresponding epoch for each packet based on the embedded
timestamp. In this way, we ensure that all routers put each
packet in the same epoch for updating the trafﬁc summaries.
For example, if the timestamp embedded by the source is
ts and the epoch length is L, then all routers will map the
L &.
packet into epoch % ts
To eliminate trafﬁc summary inconsistencies due to packet
transmission delay, we also need to ensure that when gen-
erating trafﬁc summaries for a certain epoch e, packets
that are sent and not corrupted in epoch e are received
by all
the nodes in the forwarding paths. To this end,
if the epoch length is set to L and the expected upper
bound on the one-way packet
transmission delay in the
network is D, each router stores packets sent in the current
L ( epochs, denoted by
epoch e as well as in previous ’ D
L (. We call these epochs live epochs.
e − 1, e − 2, . . . , e − ’ D
Then at the end of an epoch e, nodes will generate and send
to the AC the trafﬁc summaries for the oldest live epoch
L (, in which the packets have either traversed all nodes
e−’ D
in their forwarding paths or been corrupted. The periodic key
disclosure messages that the AC broadcasts synchronize the
current epoch ID and the oldest live epoch ID for which

s

s

s

and S←r

• The packet cache C↔r

trafﬁc summaries are needed for reporting.
Hence, a node s maintains the following data structures
for each neighbor r for each epoch, as Figure 6 also shows.
temporarily stores hashes for
that are seen in a live
packets in both S→r
epoch (using a cryptographic hash function such as
SHA-1). Each entry contains the packet hash and a bit
indicating if the packet belongs to S→r
• The router stores the sum of packet departure times-
and the sum of packet arrival
seen in S→r
tamps t→r
in a live epoch with
timestamps t←r
microsecond precision.
• Finally, the router stores the total number of packets
in a live epoch.
In DynaFL, a router s also needs to consider the case where
its next-hop neighbor r is the destination for a certain packet,
so that r will naturally not forward the packet. If it is the
case for a certain packet, router s does not cache that packet
for neighbor r.

seen in S←r

seen in S→r

seen in S←r

and n←r

or S←r

n→r

.

s

s

s

s

s

s

s

s

s

s

crypto hash

Srs or Ssr?

.
.
.
 
.
.
.

.
.
.
 
.
.
.

Epoch ID

t←r
s

n←r

s

t→r
s

n→r

s

C↔r

s

s

s

s

s

s

, t→r

Figure 6. Router per-neighbor state details.
, n←r

, andn →r
Among these data structures, t←r
require small constant storage, around 8 or 4 bytes for each.
s will be used for packet ﬁngerprinting. The size of C↔r
C↔r
depends only on the epoch length L and link bandwidth,
but not the number of ﬂows/paths traversing node s. As
Section VIII-A shows, with an epoch length of 20 millisec-
onds and one-way network latency of 20 milliseconds, each
router line-card requires only around 4MB of memory for
an OC-192 link, which is practical today.
to denote the
by node s, respectively.
packets cached for S→r
B. Secure Key Disclosure

For simplicity’s sake, we use C→r

and C←r

and S←r

and ﬁngerprinting key K

At the end of each epoch e, the AC discloses the sam-
to all
pling key K
nodes in the network via a key disclosure message dAC,
and requests the trafﬁc summaries for the most recently
L (. Obviously, dAC itself needs to be
retired epoch e − ’ D
protected from data-plane attacks (dropping, modiﬁcation,
fabrication, or delaying) by a malicious node during end-
of-epoch broadcasting. It might be tempting to let the AC
use digital signatures to authenticate dAC in order to address
malicious modiﬁcation and fabrication; however, frequently

e−( D
f

e−( D
s

L )

L )

s

s

s

s

323

dAC

i

dAC

m

j

drop dAC?

s

m

lower TTL
in m to ‘2’

p

r

q

b

c

m

a

TTL= 0 in m
drop m

Figure 7.
Possible attacks in the recording phase. A malicious nodes
may attempt to drop the key disclosure message dAC, or manipulate the
TTL value to cause packets to be dropped at a remote place (node a in this
example), thus framing a remote neighborhood (N(a) in this example).

generating and verifying the signatures on a per-epoch basis
can be expensive (e.g., an epoch can be as short as 20
milliseconds and signature generation and veriﬁcation time
could be on the order of milliseconds).
Our key observation is that, the key disclosure message
dAC is transmitted at the end of each epoch synchronously
among all the nodes. If a malicious node s drops dAC, the AC
will fail to receive the trafﬁc summaries of certain neighbors
of s, thus detecting N(s) as suspicious. For example in
Figure 7, if s drops dAC instead of forwarding it to its
neighbor r, node r cannot ﬁngerprint the packets to generate
trafﬁc summaries,
thus failing the consistency check of
trafﬁc summaries in N(s). As we show in Section V, the AC
expects to receive trafﬁc summaries within a short amount
of time after each epoch ends; delaying dAC more than
that amount of time is effectively equivalent to dropping
dAC and causes the malicious node’s neighborhood to be
detected. Thus, the remaining problem is to prevent the
modiﬁcation and fabrication of dAC, which is equivalent to
authenticating dAC to all nodes in the network without the
use of digital signatures. Section VII further elaborates why
the authentication of dAC is needed for security purposes.
The dAC for epoch j includes an epoch key K j, based
s and the epoch ﬁn-
on which the epoch sampling key K j
f can be derived using a Pseudo-Random
gerprinting key K j
Function (PRF), e.g.:

K j

f ← P RFKj (2)

s ← P RFKj (1), K j

(10)
Furthermore in DynaFL, time in the network is loosely
time-synchronized and divided into consecutive epochs; the
authentication of dAC is required only once per epoch.
s for each epoch,
Hence, we just need to authenticate K j
which can be efﬁciently achieved via a one-way hash chain.
As Figure 8 shows, the AC applies a one-way function H
(a cryptographic hash function) repeatedly on the root key
K r to derive a set of epoch keys. The AC publishes K0 in a
bootstraping broadcast message through the network so that
nodes can verify if any given epoch key is indeed derived

324

K 0

H(K 1)

H(K 2)

H(K r−1)

H(K r)

... ...

K r−1
K 1
Figure 8. One-way hash chain example.

K r

s

t

f

t

f

(C→r

t

and T←r

t

from the genuine one-way hash chain and is thus authentic.
We assume each node in the network has the correct public
key of the AC, so that the AC can authenticate K0 via
digital signatures during the bootstraping phase. Along with
K0, an epoch number is included and authenticated in the
bootstraping broadcast message to enable switching to a new
key chain whenever needed.
Furthermore, DynaFL creates a spanning tree in the
network rooted at the AC, along which dAC is delivered
to each node. Since DynaFL uses a pre-generated, static
spanning tree for the broadcast messages, there is no need
for dynamic path support when protecting dAC.
C. Sampling and Fingerprinting

s and K j

Given the disclosed K j

f at the end of an epoch
s,
e, each node t ﬁrst uses the sampling PRF P with K j
, to determine if the oldest live epoch j is
denoted by PKj
selected. If so, node t then uses the ﬁngerprinting function
F to map the cached packet hashes in each per-neighbor
),
stream into a sketch vector, i.e., FKj
(C←r
f. Finally, node t generates two
computed with the given K j
trafﬁc summaries T→r
includes a ﬁngerprint
,
t = t→r
of packets seen in S→r
in
includes a ﬁngerprint
,
t = t←r
of packets seen in S←r
in

• T→r
t
FKj
and the total number n→r
epoch j;

) or FKj
for a neighbor r:

for packet stream S←r
(C←r

• T←r
t
FKj
and the total number n←r
epoch j.

for packet stream S→r
(C→r

), average packet departure time t→r

), average packet arrival time t←r

K j

s <λ · 2n

Figure 9 summarizes the FL-related packet processing
inside a DynaFL router. We detail P and F in the following.
Implementing P. A n-bit epoch sampling key K j
s is derived
via a PRF (Equation 10) and is thus uniformly distributed
in [0, 2n − 1]. Given asampling rate λ ∈ (0, 1), an epoch j
is selected iff:
(11)
In this way, on average a fraction λ of the epochs will
be selected. Since nodes use the same K j
s for epoch sam-
pling, benign nodes will select the same set of epochs,
thus ensuring the consistency of the trafﬁc summaries in
a neighborhood.
Implementing F. We use the second-moment sketch
f as a case study to implement F, and
computed with K j
analyze the size of the sketch vector to achieve Property 1
with (α, β,δ )-accuracy. We assume 107 packets per second
in the worst case for an OC-192 link with an epoch length

t

n→r

t

t

n←r

t

t

t

t

t

t

t

f

f

t

t

Per-packet operations

packet p

forward p

hash (e.g., SHA1)

store hash

per-neighbor cache

cache entries 
  for epoch j

fingerprinting 
     key

Kj
f

oldest live 
  epoch j

sampling key

Kj
s

 epoch 
sampling

selected

fingerprinting

not selected

clear cache entries 
       for epoch j

traffic summaries
   sent to the AC

Per-epoch operations

Figure 9. FL-related packet processing inside a DynaFL router.

of L (seconds). Then, the number of packets η in a sampled
epoch is η = L · 107. Using the classical Sketch due to Alon
et al. [6] for example, the storage requirement for the sketch
is given by:

In Section VIII-A we derive numeric values for the size of
the sketch vector based on the epoch length L.
Dealing with TTL attacks. Certain ﬁelds in the IP header,
such as the TTL, checksum, and some IP option ﬁelds, will
change at each hop. Both sampling and ﬁngerprinting in
DynaFL need to properly deal with these variant ﬁelds. Take
the TTL ﬁeld for instance hereinafter (though the arguments
apply similarly to other variant ﬁelds). On the one hand, if
F is computed over the entire packet including the TTL
ﬁeld, even in the benign case the same packet stream will
leave different trafﬁc summaries (or precisely, the sketch
vectors) at ingress and egress nodes. On the other hand, if
F is computed over the entire packets excluding the TTL
ﬁeld, a malicious node can modify the TTL ﬁeld at liberty
without affecting the trafﬁc summaries. Figure 7 depicts an
example TTL attack, where the malicious node s lowers the
TTL value to 2 in the packets and causes the packets to be
dropped at the 2-hop-away downstream node a, thus framing
neighborhood N(a).

M × log2!2η ln(
where M >
and  =

12
2
β − α
β + α

.

1

ln

3 − 2

200N

δ

)

1
δ

(12)

(13)

r

Rr=Tr|| MAC(Tr)

Rj=Ti|| MAC(Ti||Rj||Rs||Rr)

AC

Rk=Tk|| MAC(Tk)

k

j

i

Rj=Tj || MAC(Tj ||Rk)

Rs=Ts|| MAC(Ts)

s

Figure 10.
Example of secure transmission of trafﬁc summary reports.
For brevity, we denote the trafﬁc summaries of a node i as Ti and omit
the secret key for the MAC notation.

To address the TTL attacks, when computing F, each

node r performs either of the following:

• For a packet received from a neighbor, node r computes
F over the entire packet including the TTL ﬁeld.
• For a packet sent to a neighbor, node r computes and
F over the packet, but with the TTL ﬁeld additionally
decreased by 2 (equal to the TTL value at the 2-hop-
away egress node in N(r)).

In this way, node r in Figure 7 simply uses the TTL value as
contained in the packets received from s when computing
F, since the ingress nodes in N(s) (nodes i and j) must
have computed F with an adjusted TTL value equal to that
at node r.
The TTL value in a packet is also decremented by one
for every second the packet is buffered at a router. Holding
a packet longer than one second at a router is treated as a
packet delaying attack and will be detected due to the use
of the above construction.

V. REPORTING TRAFFIC SUMMARIES

t

t

If an epoch is selected, after the ﬁngerprinting procedure,
and T←r
a node t generates two trafﬁc summaries T→r
for each neighbor r, and sends them to the AC in a
trafﬁc summary report denoted by Rt. The challenge in the
recording phase is to protect the trafﬁc summary reports
from being corrupted.
In DynaFL, nodes form a static spanning tree rooted at
the AC for sending the trafﬁc summaries. Given the spanning
tree, the goal is to protect the trafﬁc summary reports Rts
from different nodes destined to the AC. Although Rts are
also subject to data-plane attacks, they are transmitted over
static and pre-generated paths in the spanning tree. Hence,
dynamic trafﬁc is no longer a concern, thus substantially
simplifying the problem. Speciﬁcally, DynaFL utilizes an
Onion Authentication approach [34], [36] to protect
the
transmission of dAC along each path in the spanning tree.
In a nutshell, within a short timer at the end of each epoch,
each node t needs to send its trafﬁc summary report Rt
to the AC, and Rt is authenticated with a MAC computed
using a pairwise secret key shared between node t and the

325

AC. The trafﬁc summary reports from different nodes are
sent in an onion fashion. For example in Figure 10, Rj
includes the report Rk of node k. In this way, DynaFL
efﬁciently protects the key disclosure message dAC without
the use of expensive asymmetric cryptography. Section VII
gives a more detailed security analysis of such an Onion
Authentication approach.

VI. DETECTION

The AC performs consistency checks for each neigh-
borhood N(r) based on the received trafﬁc summaries.
However, since an epoch may only have a small number
of packets, detecting a suspicious neighborhood based on
the consistency checks for individual epochs can introduce
a large error rate. Take an extreme case for example: if in a
certain epoch a neighborhood N(r) only transmits a single
packet and the packet was spontaneously lost, concluding
that the packet loss rate is 100% and N(r) is suspicious
would be inaccurate.
To deal with this problem, the AC still performs the
consistency checks and estimates the discrepancy for in-
dividual epochs; but it makes the detection based on the
aggregated discrepancies over a set of E epochs (called
accumulated epochs), so that the total number of packets
over the E epochs is more than a certain threshold N to give
a high enough accuracy (e.g., > 99.9%) on the detection
results. Section VIII studies the value of N. Therefore, the
AC stores the trafﬁc summaries for each neighborhood and
makes detection when the total number of packets N is
x (e) denote
reached. More speciﬁcally, let n←y
x ) in
and n→y
the packets received from / sent to x (n←y
the trafﬁc summary for epoch e, respectively; for a certain
neighborhood N(r), whenever

x (e) and n→y

x

i

n→r

n←r

i

(e)} > N

(14)

max{"e "i

(e),"e "i
indicating N is reached,

(where i ∈ N(r) and e iterates over all the accumulated
epochs),
the AC performs the
following checks to inspect if N(r) is suspicious:
1. Flow conservation. The AC ﬁrst extracts n→r
(e) and
(e) for each node i in N(r) for each epoch e, and
n←r
calculates the difference between the number of packets sent
to r and the number of packets received from r over all the
E accumulated epochs. If the ratio of the difference to the
total number of packets in all the E accumulated epochs is
larger than a threshold β, i.e.:

i

i

i

i

i

>β

(e)|
(e)}

|#e#i n→r
max{#e#i n→r

(e) −#e#i n←r
(e),#e#i n←r

(15)
then the AC detects N(r) as suspicious. The threshold β is
set based on the administrator’s expectation of the natural
packet loss rate; e.g., in the simulations in Section VIII we
set β to be four times of the natural packet loss rate in a
neighborhood.

i

2. Content conservation. The AC then extracts the sketches
in the trafﬁc summaries in N(r), and estimates the discrep-
ancy δf between the sketches for packets sent to r and the
sketches for packets received from r. The AC detects N(r)
as malicious if δf is larger than a certain threshold, i.e.,:

2αβ
α + β

δf >
where
δf = ||∪ i∈N(r) FKj

× max{"e "i

n→r

i

(e),"e "i

n←r

i

(e)}

(C←r

i

) − ∪i∈N(r)FKj

(C→r

i

)||2
2

f

f

(16)
It has been proven [19] that the above threshold can satisfy
the (α, β,δ )-accuracy deﬁned in Section II-D.
3. Timing consistency. Finally, the AC extracts the differ-
ence between the average packet departure time and arrival
time, and concludes that N(r) is suspicious if the difference
is larger than the expected upper bound on the 2-hop link
latency.

VII. SECURITY ANALYSIS

We show that DynaFL is secure against all attacks that
are possible in the misbehavior space given our adversary
model. By our deﬁnition, a malicious router can drop,
modify, fabricate, and delay packets. In addition, a malicious
router can attack data packets, key disclosure messages dAC,
and reporting messages. We ﬁrst show DynaFL’s security
against a single malicious node and then sketch DynaFL’s
security against colluding nodes.
Security against corrupting the data packets. Dropping,
modifying, and fabricating data packets in a neighbor-
hood N(m) will cause inconsistencies between sketches
in N(m) as mentioned earlier. Delaying data packets in
N(m) will cause abnormal deviation between average packet
arrival/departure timestamps in N(m). If a malicious router
changes the timestamps in data packets embedded by the
source nodes,
to modifying packets and
packets may be mapped to different epochs, in which case
such an attack will manifest itself by causing inconsistencies
in the sketches of a neighborhood containing the malicious
router.
Security against corrupting dAC. As we mentioned earlier,
if a malicious node m drops the dAC, some nodes adjacent
to m will fail
trafﬁc summaries to
the AC, thus causing a neighborhood containing m to be
detected. We note that the authentication of dAC is needed
(through the one-way hash chain). Otherwise, a malicious
node can replace the sampling and ﬁngerprinting keys with
its own fake keys, by which the malicious node can predict
the output of other nodes’s sketches and perform packet
modiﬁcation attacks. In addition, if the epoch IDs in dAC
were not authenticated, a malicious node can replace the
oldest live epoch ID in dAC for which the trafﬁc summaries

to send the correct

is equivalent

it

326

100

100

100

drops 50
50

a

b

c

d

e

Figure 11.
number denotes the packet count each node sends.

Example of DynaFL’s security against colluding nodes. A

are requested with the current epoch ID. In this way,
inconsistencies of trafﬁc summaries can be detected for some
benign neighborhood due to the packet transmission delay
as Section IV-A describes. With the (delayed) authentication
of dAC, any attempt to modify dAC will be detected (after
L ( epochs).
’ D
It is noteworthy that the dAC sent at the end of epoch e
cannot simply disclose the MAC secret key Ke−1 for the
previous epoch e − 1. This is because at the time Ke−1
is disclosed, the dAC sent at the end of epoch e − 1 may
not have yet reached all nodes. Hence, a malicious node
which has already received Ke−1 might send Ke−1 to a
downstream colluding node via an out-of-band channel, so
that the colluding node can break the authenticity of the
dAC sent in epoch e − 1. Hence, at the end of an epoch e,
L ( to ensure the
we disclose the MAC key for epoch e − ’ D
dAC sent in epoch e − ’ D
L ( has reached all the nodes in the
network.
Security against corrupting reporting messages. First, due
to the use of the Onion Authentication, a malicious node m
cannot selectively drop the reporting messages of a remote
(non-adjacent) node r, to frame a neighborhood containing
node r. Since all the accumulated reporting messages are
“combined” at each hop, m can only drop the reporting
messages from its immediate neighbors, which will manifest
a neighborhood containing m as suspicious.
Security against colluding attacks. We illustrate DynaFL’s
security against colluding attacks via a toy example shown
in Figure 11. We show that for a malicious node m which
actually corrupts packets, as long as one benign node exists
in N(m), a neighborhood containing either m or one of its
colluding nodes will be detected. The key observation is that
since the trafﬁc summaries are sent to the AC and the AC
performs the detection, each node can only claim one trafﬁc
summary per selected epoch. To simplify the analysis while
still unveiling the intuition, we only consider the number (but
not the payload) of packets sent by each node, as shown
in Figure 11. Suppose nodes c and d are colluding, and
node d drops 50 packets. As long as node e is benign in
N(d), to cover the misbehavior of d, the colluding node c
has to send a trafﬁc summary to the AC falsely claiming it
sent “50” packets to d (and thus received “50” packets from
node b). However, this claim will make the neighborhood
N(b) suspicious since the benign node a will claim it sent
100 packets to b.

327

)

B
M

(
 

e
z
S

i

 500

 480

 460

 440

 420

 400

 380

 360

 340

 0  20  40  60  80  100  120  140  160  180  200

Epoch Length (ms)

Figure 12.
of 300 bytes and δ = 0.001.

Sketch size for an OC-192 link with the average packet size

VIII. PERFORMANCE EVALUATION

In this section, we analyze the protocol overhead and
study the detection efﬁciency of DynaFL via measurements
and simulations, with our implementation of the classic
Sketch [6] in C++.
A. Storage Overhead

DynaFL incurs only per-neighbor state while existing
secure path-based FL protocols require per-source and per-
path state. In this section, we quantify the per-neighbor
storage overhead of a DynaFL router, which primarily
includes the packet cache and the sketch for each neighbor.
Sketch size. We derive numeric values of the sketch size
based on Equations 12 and 13, using an example setting
where the average packet size is 300 bytes and the link’s
capacity is 10 Gbps (an OC-192 link). Furthermore, we
consider δ = 0.001, α = 0.002, and β = 2α for the
(α, β,δ )-accuracy,
the false positive rate and false
negative rate of the sketch-based detection are limited under
0.001. Figure 12 plots the result, from which we can see
that a sketch with fewer than 500 bytes can already yield a
desirable accuracy.
Cache size and per-neighbor storage overhead. We now
study the cache size for temporarily storing packet hashes in
live epochs, which, together with the sketch size analyzed
above, constitutes the per-neighbor storage overhead of a
DynaFL router. We denote the upper bound of one-way
network latency as D, epoch length as L, and the number
of packets per second as η. Using 20-byte packet hashes,
the cache size is given by:

i.e.,

the 1-bit

+ 1(· 20 · η · L

(17)
D
’
L
indicator for each packet hash entry
We omit
to indiciate which packet stream the packet belongs to
(see Figure 6). Assuming the per-neighbor sketch size is
500 bytes, one-way latency D = 20ms, and the average
packet size is 300 bytes for an OC-192 link, we derive

)

B
M

(
 

e
z
S

i

 16

 14

 12

 10

 8

 6

 4

 2

 0

 0  10  20  30  40  50  60  70  80  90  100

Epoch Length (ms)

Figure 13. Router per-neighbor state for an OC-192 link with the average
packet size of 300 bytes and one-way network latency as 20ms.

s
y
e
k
 
f

o

 
r
e
b
m
u
n

 100000

 10000

 1000

 100

 10

 1

Path-based
DynaFL

ATT Sprint L3

I2 BCube VL2 DCell

Figure 14. Key management overhead at each router. A router in DynaFL
always requires just one key shared with the AC.

the per-neighbor storage overhead of a DynaFL router with
different epoch lengths shown in Figure 13. We can observe
that, with an epoch length of 20ms, only around 4MB is
required per-neighbor. The “humps” exist in the curve due
to the use of the ceiling function in Equation 17.
B. Key Management Overhead

One distinct advantage DynaFL presents is that each
router in DynaFL shares only one secret key with the AC,
whereas in path-based FL protocols it is necessary for each
router to share a secret key with each source node in the
network in the worst case [14], which dramatically compli-
cates the key management and broadens the vulnerability
surface. To quantify DynaFL’s advantage over path-based
FL protocols, we leverage the measured ISP topologies
from the Rocketfuel dataset [31] and the topology from
Internet2 [4]. Figure 14 shows the maximum number of keys
each router needs to manage in path-based FL protocols;
and a router in DynaFL always requires only one secret
key shared with the AC (thus invisible in the ﬁgure). We
can see that the number of keys a router needs to manage in
path-based FL protocols is 100 to 10000 times higher than
that in DynaFL.

C. Bandwidth Overhead

We analyze the bandwidth consumption on each link by
the reporting trafﬁc summaries based on the measured ISP
topologies from the RocketFuel dataset [31]. Recall that the
reporting messages are transmitted along a spanning tree
rooted at the AC. Hence, the bandwidth consumption by the
reporting messages on a link is determined by the number
of children below that link and the degrees of the children.
For each ISP topology, we ﬁrst select a “central” node
as the AC, which is the node in the network that has the
highest fraction of all shortest paths that pass through that
node. Then, we create a minimum spanning tree rooted
at the central node (or the AC) for transmitting reporting
messages to the AC. We consider the epoch length L=20ms,
a per-neighbor trafﬁc summary as 500 bytes, and the epoch
sampling rate is 1%. Hence, on average, each node only
sends one reporting packet in every two seconds. Figure 15
plots the results for ISPs with AS numbers 1221, 1239, 1755,
3257, 3967, and 6461. From the results, we can see that the
fraction of bandwidth used for reporting trafﬁc summaries
on a link is small for all topologies (e.g., between 0.002%
and 0.012% for an OC-192 link).
D. Detection Delay

As Section VI states, the AC performs consistency checks
and detects any anomalies only when the total number of
packets over multiple epochs is accumulated more than a
certain threshold N in order to give a low false positive and
negative rate (e.g., <0.1%) on the detection results. Hence,
the number of packets N characterizes the detection delay
of the FL protocol. We fully implement the classic Sketch
due to Alon et al. [6] in C++ with a four-way hash function,
and perform simulations to study N.

Figure 16. False positive rates with no malicious activity in a neighborhood
with different numbers of nodes. The natural packet loss rate in a neigh-
borhood is 0.001 and the detection thresholds for both ﬂow conservation
and content conservation are Td = β = 2α = 0.004.

Since in DynaFL, neighborhoods are inspected by the AC
independently, we also perform simulations for independent

328

(a) ISP 1221

(b) ISP 1239

(c) ISP 1755

(d) ISP 3257

(e) ISP 3967

(f) ISP 6461

Figure 15. CDF of per-link bandwidth consumption for the reporting messages in DynaFL.

Figure 17.
False negative rates in a malicious neighborhood with ﬁve
nodes, where the malicious node only drops packets. The natural packet
loss rate in a neighborhood is 0.001, the detection thresholds for both ﬂow
conservation and content conservation are Td = β = 2α = 0.004, and the
malicious packet dropping rate is 0.005.

Figure 18.
False negative rates in a malicious neighborhood with
ﬁve nodes, where the malicious node both drops packets and modiﬁes
packets. The natural packet loss rate in a neighborhood is 0.001, the
detection thresholds for both ﬂow conservation and content conservation
are Td = β = 2α = 0.004, the malicious packet dropping rate is 0.005,
and the malicious packet modiﬁcation rate is 0.005.

neighborhoods with different sizes. Since we showed Dy-
naFL’s security against colluding attacks in Section VII,
we emulate a single malicious node in our simulations.
Our setting is as follows. The natural packet
loss rate
in a neighborhood is 0.001 and the detection thresholds
for both ﬂow conservation and content conservation are
β = 2α = 0.004. Figure 16 depicts the false positive

rates in benign cases where no malicious routers exist in
the neighborhood. We can see that with N > 5000 packets,
the false positive rate is under 1%.

Figure 17 shows the false negative rates with a malicious
router which only drops packets with a probability of 0.005.
Figure 18 plots the false negative rates with a malicious

329

router which both drops and modiﬁes packets with a prob-
ability of 0.005, respectively. We can see that the sketch-
based approach is effective in detecting packet modiﬁcation
attacks, since by modifying packets the malicious router is
detected faster in Figure 18 than in Figure 17.

IX. RELATED WORK AND DISCUSSION

Realizing its importance, researchers have recently pro-
localization.
posed several approaches for network fault
As aforementioned,
the known secure FL protocols are
all path-based, failing to support dynamic routing paths,
requiring per-path state at routers, and incurring per-source
key sharing and management. Besides these fundamental
limitations, we show that most FL protocols also suffer either
from security vulnerabilities or high protocol overhead.
For example, WATCHERS [16], [22], AudIt [8] and
Fatih [29] implement
the trafﬁc summaries using either
counters or Bloom Filters [15] with no secret keys, thus
remaining vulnerable to packet modiﬁcation attacks as Sec-
tion III-C shows.
Both ODSBR [12], [13] and Secure Traceroute [30] acti-
vate FL only when the end-to-end packet loss rate exceeds a
certain threshold. However, a malicious node can safely drop
packets when FL is not activated, and behave “normally”
when FL is invoked. In addition, ODSBR does not consider
natural packet loss, which can make the algorithm either
not converge or incur high false positives by incriminating
benign links.
Liu et al. propose enabling two-hop-away routers in the
path to monitor each other [26] by using 2-hop acknowl-
edgment packets. However, such a 2-hop-based detection
scheme is vulnerable to colluding neighboring routers. Sim-
ilarly, both Watchdog [28] and Catch [27] can identify
and isolate malicious routers for wireless ad hoc networks,
where a sender S veriﬁes if the next-hop node fi indeed
forwards S’s packets by promiscuously listening to fi’s
transmission. Both Watchdog and Catch are vulnerable to
collusion attacks, where a malicious node fm drops the
packets of a remote sender S (which is out of the promiscu-
ous listening range of fm) while the colluding neighbors in
the promiscuous listening range of fm intentionally do not
report the packet dropping behavior of fm.
Among the known secure proposals, the protocol due to
Avramopoulos et al. [11] incurs high computational and
communication overhead, because it requires acknowledg-
ments from all routers in the path, and requires multiple
digital signature generation and veriﬁcation operations for
each data packet. Recently proposed PAAI-1 [34], Statistical
FL [14], and ShortMAC [36] all require stable routing paths
and per-path state at routers. TrueNet [35] leverages trusted
computing to achieve FL with constant small router state.
However, TrueNet requires special hardware support such
as a TPM.

X. CONCLUSION AND FUTURE WORK

In this paper, we ﬁrst raise the awareness of achieving a
practical and scalable network fault localization protocol
that can cope with dynamic trafﬁc patterns and routing
paths with constant, small router state. After identifying
the fundamental limitations of previous FL protocols which
are all path-based, we explore a neighborhood-based FL
approach; we also propose DynaFL, which utilizes delayed
key disclosure, a novel technique that enables secure yet
efﬁcient checking of packet content conservation.
While existing path-based FL protocols aim to identify
a speciﬁc faulty link (if any), DynaFL localizes data-plane
faults to a coarser-grained 1-hop neighborhood, to achieve
four distinct advantages. First, DynaFL does not require
any minimum duration time of paths or ﬂows in order to
detect data-plane faults as path-based FL protocols do. Thus,
DynaFL can fully cope with short-lived ﬂows which are
popularly seen in modern networks. Second, in DynaFL,
a source node does not need to know the exact outgoing
path, unlike path-based FL protocols. Hence, DynaFL can
support agile (e.g., packet-level) load balancing such as
VL2 routing [20] for datacenter networks. Third, a DynaFL
router only needs around 4MB per-neighbor state based on
our classic Sketch implementation, while a router in a path-
based FL protocol requires per-path state. Finally, a DynaFL
router only maintains a single secret key shared with the AC,
while a router in a path-based FL protocol needs to manage
100 to 10000 secret keys in measured ISP topologies.
DynaFL focuses mainly on unicast communication, while
multicast and broadcast communication may cause the detec-
tion of “packet injection”, since a packet may be “benignly”
duplicated during the transmission. As future work, we plan
to deal with multicast and broadcast scenarios.

XI. ACKNOWLEDGMENTS

The authors gratefully thank Hsu-Chun Hsiao and Patrick
Tague for constructive discussions and insightful sugges-
tions, and the anonymous reviewers for their valuable feed-
back. This research was supported by CyLab at Carnegie
Mellon under grants DAAD19-02-1-0389, W911NF-09-1-
0273, and MURI W 911 NF 0710287 from the Army
Research Ofﬁce, and by support from NSF under award
CNS-1040801. The views and conclusions contained here
are those of the authors and should not be interpreted as
necessarily representing the ofﬁcial policies or endorse-
ments, either express or implied, of ARO, CMU, NSF or
the U.S. Government or any of its agencies.

REFERENCES

[1] Arbor networks: Infrastructure security survey. http://www.

arbornetworks.com/sp security report.php.

[2] Cisco security hole a whopper.

politics/security/news/2005/07/68328.

http://www.wired.com/

330

[22] J. R. Hughes, T. Aura, and M. Bishop. Using conservation of
ﬂow as a security mechanism in network protocols. In IEEE
Symposium on Security and Privacy, 2000.

IEEE 1588 standard for a precision
[23] J.Eidson and K. Lee.
clock synchronization protocol for networked measurement
In Sensors for Industry Conference,
and control systems.
2nd ISA/IEEE., 2002.

[24] M. Kodialam, T. V. Lakshman, and S. Sengupta. Efﬁcient and
robust routing of highly variable trafﬁc. In In Proceedings of
ACM HotNets, 2004.

[25] C. Labovitz, A. Ahuja, and M. Bailey. Shining light on dark

address space. Technical report, Arbor Networks.

[26] K. Liu, J. Deng, P. K. Varshney, and K. Balakrishnan. An
acknowledgement-based approach for the detection of routing
misbehavior in MANETs.
IEEE Transactions on Mobile
Computing, 2007.

[27] R. Mahajan, M. Rodrig, D. Wetherall, and J. Zahorjan.
In

Sustaining cooperation in multi-hop wireless networks.
Usenix NSDI, 2005.

[28] S. Marti, T. J. Giuli, K. Lai, and M. Baker. Mitigating routing
misbehavior in mobile ad hoc networks. In ACM Mobicom,
2000.

[29] A. T. Mizrak, Y. chung Cheng, K. Marzullo, and S. Savage.
Fatih: Detecting and isolating malicious routers.
In IEEE
Transactions on Dependable and Secure Computing, 2005.
[30] V. N. Padmanabhan and D. R. Simon. Secure traceroute
to detect faulty or malicious routing. SIGCOMM Computer
Communication Review (CCR), 33(1):77–82, 2003.

[31] N. Spring, R. Mahajan, and D. Wetherall. Measuring isp

topologies with rocketfuel. In ACM SIGCOMM, 2002.

[32] R. Thomas. ISP security BOF, nanog 28. http://www.nanog.

org/mtg-0306/pdf/thomas.pdf.

[33] M. Thorup and Y. Zhang. Tabulation based 4-universal hash-
ing with applications to second moment estimation. SODA,
2004.

[34] X. Zhang, A. Jain, and A. Perrig. Packet-dropping adversary
identiﬁcation for data plane security. In ACM CoNext, 2008.
[35] X. Zhang, Z. Zhou, G. Hasker, A. Perrig, and V. Gligor.
Network fault localization with small TCB. In Proceedings
of the IEEE International Conference on Network Protocols
(ICNP), 2011.

[36] X. Zhang, Z. Zhou, H.-C. Hsiao, A. Perrig, and P. Tague.
In Pro-
the Network and Distributed System Security

Shortmac: Efﬁcient data plane fault localization.
ceedings of
Symposium (NDSS), 2012.

[37] R. Zhang-shen and N. Mckeown. Designing a predictable
internet backbone with valiant load-balancing. In in IWQoS,
2005.

[3] Symantec warns of

router compromise.

routersusa.com/symantec-warns-of-router-compromise-2.
html.

http://www.

[4] This project has beneﬁted from the use of measurement data
collected on the internet2 network as part of the internet2
observatory project. http://netﬂow.internet2.edu/.

[5] D. Achlioptas. Database-friendly random projections.

Proceedings of PODS.

In

[6] N. Alon, Y. Matias, and M. Szegedy. The space complexity

of approximating the frequency moments. STOC, 1996.

[7] X. Ao. Report on dimacs workshop on large-scale in-
ternet attacks. http://dimacs.rutgers.edu/Workshops/Attacks/
internet-attack-9-03.pdf.

[8] K. Argyraki, P. Maniatis, O. Irzak, S. Ashish, and S. Shenker.
Loss and delay accountability for the Internet. In IEEE ICNP,
2007.

[9] K. Argyraki, P. Maniatis, and A. Singla. Veriﬁable network-

performance measurements. In ACM CoNext, 2010.

[10] B. Augustin, T. Friedman, and R. Teixeira. Measuring load-

balanced paths in the internet. In ACM IMC, 2007.

[11] I. Avramopoulos, H. Kobayashi, R. Wang, and A. Krishna-
murthy. Highly secure and efﬁcient routing. In IEEE Infocom,
2004.

[12] B. Awerbuch, R. Curtmola, D. Holmer, C. Nita-Rotaru, and
H. Rubens. ODSBR: An on-demand secure byzantine resilient
routing protocol for wireless ad hoc networks. ACM Trans
Inform. Syst. Secur, 2008.

[13] B. Awerbuch, D. Holmer, C. Nita-Rotaru, and H. Rubens.
An on-demand secure routing protocol resilient to byzantine
failures. In ACM WiSe, 2002.

[14] B. Barak, S. Goldberg, and D. Xiao. Protocols and lower
In EURO-

bounds for failure localization in the Internet.
CRYPT, 2008.

[15] B. H. Bloom. Space/time trade-offs in hash coding with

allowable errors. Commun. ACM, 13(7):422–426, 1970.

[16] K. A. Bradley, S. Cheung, N. Puketza, B. Mukherjee, and
R. A. Olsson. Detecting disruptive routers: A distributed net-
work monitoring approach. In IEEE Symposium on Security
and Privacy, May 1998.

[17] M. Charikar, K. Chen, and M. Farach-Colton.

Finding
frequent items in data streams. Theoretical Computer Science,
2004.

[18] I. Cunha, R. Teixeira, and C. Diot. Measuring and charac-
terizing end-to-end route dynamics in the presence of load
balancing. In PAM, 2011.

[19] S. Goldberg, D. Xiao, E. Tromer, B. Barak, and J. Rexford.
In

Path-quality monitoring in the presence of adversaries.
Proceedings of SIGMETRICS, 2008.

[20] A. Greenberg, N. Jain, S. Kandula, C. Kim, P. Lahiri,
D. Maltz, P. Patel, and S. Sengupta. VL2: A scalable and
ﬂexible data center network. In ACM SIGCOMM, 2009.

[21] K. J. Houle, G. M. Weaver, N. Long, and R. Thomas. Trends
in denial of service attack technology. Technical report, CERT
Coordination Center.

331

