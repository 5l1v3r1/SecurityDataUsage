2016 IEEE Symposium on Security and Privacy
2016 IEEE Symposium on Security and Privacy

Back in Black: Towards Formal, Black Box Analysis

of Sanitizers and Filters

George Argyros
Columbia University

argyros@cs.columbia.edu

Ioannis Stais

University of Athens

i.stais@di.uoa.gr

Aggelos Kiayias
University of Athens
aggelos@di.uoa.gr

Angelos D. Keromytis

Columbia University

angelos@cs.columbia.edu

Abstract—We tackle the problem of analyzing ﬁlter and
sanitizer programs remotely, i.e. given only the ability to query
the targeted program and observe the output. We focus on two
important and widely used program classes: regular expression
(RE) ﬁlters and string sanitizers. We demonstrate that existing
tools from machine learning that are available for analyzing
RE ﬁlters, namely automata learning algorithms, require a very
large number of queries in order to infer real life RE ﬁlters.
Motivated by this, we develop the ﬁrst algorithm that infers
symbolic representations of automata in the standard mem-
bership/equivalence query model. We show that our algorithm
provides an improvement of x15 times in the number of queries
required to learn real life XSS and SQL ﬁlters of popular web
application ﬁrewall systems such as mod-security and PHPIDS.
Active learning algorithms require the usage of an equivalence
oracle, i.e. an oracle that tests the equivalence of a hypothesis
with the target machine. We show that when the goal is to audit a
target ﬁlter with respect to a set of attack strings from a context
free grammar, i.e. ﬁnd an attack or infer that none exists, we
can use the attack grammar to implement the equivalence oracle
with a single query to the ﬁlter. Our construction ﬁnds on average
90% of the target ﬁlter states when no attack exists and is very
effective in ﬁnding attacks when they are present.

For the case of string sanitizers, we show that existing
algorithms for inferring sanitizers modelled as Mealy Machines
are not only inefﬁcient, but lack the expressive power to be able
to infer real life sanitizers. We design two novel extensions to
existing algorithms that allow one to infer sanitizers represented
as single-valued transducers. Our algorithms are able to infer
many common sanitizer functions such as HTML encoders and
decoders. Furthermore, we design an algorithm to convert the
inferred models into BEK programs, which allows for further
applications such as cross checking different sanitizer implemen-
tations and cross compiling sanitizers into different languages
supported by the BEK backend. We showcase the power of
our techniques by utilizing our black-box inference algorithms
to perform an equivalence checking between different HTML
encoders including the encoders from Twitter, Facebook and
Microsoft Outlook email, for which no implementation is publicly
available.

I.

INTRODUCTION

Since the introduction and popularization of code injection
vulnerabilities as major threats for computer systems, saniti-
zation and ﬁltering of unsafe user input is paramount to the
design and implementation of a secure system. Unfortunately
correctly implementing such functionalities is a very challeng-
ing task. There is a large literature on attacks and bypasses in
implementations both of ﬁlter and sanitizer functions [1]–[3].
The importance of sanitizers and ﬁlters motivated the
development of a number of algorithms and tools [4]–[7] to

analyze such programs. More recently, the BEK language [8]
was introduced. BEK is a Domain Speciﬁc Language(DSL)
which allows developers to write string manipulating functions
in a language which can then be compiled into symbolic ﬁ-
nite state transducers(SFTs). This compilation enables various
analysis algorithms for checking properties like commutativity,
idempotence and reversibility. Moreover, one can efﬁciently
check whether two BEK programs are equal and,
in the
opposite case to obtain a string in which the two programs
differ.

The BEK language offers a promising direction for the
future development of sanitizers where the programs developed
for sanitization will be formally analyzed in order to verify
that certain desired properties are present. However, the vast
majority of code is still written in languages like PHP/Java and
others. In order to convert the sanitizers from these languages
to BEK programs a signiﬁcant amount of manual effort is
required. Even worst, BEK is completely unable to reason for
sanitizers whose source code is not available. This signiﬁcantly
restricts the possibilities for applying BEK to ﬁnd real life
problems in deployed sanitizers.

In this paper we tackle the problem of black-box analysis
of sanitizers and ﬁlters. We focus our analysis on regular
expression ﬁlters and string sanitizers which are modelled as
ﬁnite state transducers. Although regular expression ﬁlters are
considered suboptimal choices for building robust ﬁlters [9],
their simplicity and efﬁciency makes them a very popular
option especially for the industry.

Our analysis is black-box, that is, without access to any sort
of implementation or source code. We only assume the ability
to query a ﬁlter/sanitizer and obtain the result. Performing a
black-box analysis presents a number of advantages; ﬁrstly,
our analysis is generic, i.e. indepedent of any programming
language or system. Therefore, our system can be readily ap-
plied to any software, without the need for a large engineering
effort to adjust the algorithms and implementation into a new
programming language. This is especially important since in
today’s world, the number of programming languages used
varies signiﬁcantly. To give an example, there are over 15
different programming languages used in the backend of the
15 most popular websites [10].

The second advantage of performing a black-box analysis
comes out of necessity rather than convience. Many times,
access to the source code of the program to be analyzed is
unavailable. There are multiple reasons this may happen; for
one, the service might be reluctant to share the source code

2375-1207/16 $31.00 © 2016 IEEE
© 2016, George Argyros. Under license to IEEE.
DOI 10.1109/SP.2016.14
DOI 10.1109/SP.2016.14

91
91

of its product website even with a trusted auditor. This is
the reason, that a large percentage of penetration tests are
performed in a black-box manner. Furthermore, websites such
as the ones encountered in the deep web, for example TOR
hidden services, are designed to remain as hidden as possible.
Finally, software running in hardware systems such as smart
cards is also predominately analyzed in a black-box manner.
Our algorithms come with a formal analysis; for every
algorithm we develop, we provide a precise description of the
conditions and assumptions under which the algorithm will
work within a given time bound and provide a correct model
of the target ﬁlter or sanitizer.

Our goal is to build algorithms that will make it easier
for an auditor to understand the functionality of a ﬁlter or
sanitizer program without access to its source code. We begin
by evaluating the most common machine learning algorithms
which can be used for this task. We ﬁnd that these algorithms
are not ﬁt for learning ﬁlters and sanitizers for different
reasons: The main problem in inferring regular expressions
with classical automata inference algorithms is the explosion in
the number of queries caused by the large alphabets over which
the regular expressions are deﬁned. This problem also occurs in
the analysis of regular expressions in program analysis appli-
cations (whitebox analysis), which motivated the development
of the class of symbolic ﬁnite automata which effectively
handles these cases [11]. Motivated by these advances, we
design the ﬁrst algorithm that infers symbolic ﬁnite automata
(SFA) in the standard active learning model of membership and
equivalence queries. We evaluate our algorithm in 15 real life
regular expression ﬁlters and show that our algorithm utilizes
on average 15 times less queries than the traditional DFA
learning algorithm in order to infer the target ﬁlter.

The astute reader will counter that an equivalence oracle
(i.e., an oracle that one submits a hypothesized model and a
counterexample is returned if there exists one) is not available
in remote testing and thus it has to be simulated at potentially
great cost in terms of number of queries. In order to address
this we develop a structured approach to equivalence oracle
simulation that is based on a given context free grammar G.
Our learning algorithm will simulate equivalence queries by
drawing a single random string w from L(G) \ L(H) where
L(H) is the language of the hypothesis. If w belongs to the
target we have our counterexample, while if not, we have found
a string w that is not recognized by the target. In our setting
strings that are not recognized by the target ﬁlter can be very
valuable: we set G to be a grammar of attack strings and we
turn the failure of our equivalence oracle simulation to the
discovery of a ﬁlter bypass! This also gives rise to what we
call Grammar Oriented Filter Auditing (GOFA): our learning
algorithm, equipped with a grammar of attack strings, can be
used by a remote auditor of a ﬁlter to either ﬁnd a vulnerability
or obtain a model of the ﬁlter (in the form of an SFA) that
can be used for further (whitebox) testing and analysis.

Turning our attention to sanitizers, we observe that in-
ferring ﬁnite state transducers suffers from even more fun-
damental problems. Current learning algorithms infer models
as Mealy machines, i.e. automata where at each transition one
input symbol is consumed and one output symbol is produced.
However, this model is very weak in capturing the behavior of
real life sanitizers where for each symbol consumed multiple,

or none, symbols are produced. Even worse, many modern
sanitizers employ a “lookahead”, i.e. they read many symbols
from the input before producing an output symbol. In order
to model such behavior the inferred transducers must be
non deterministic. To cope with these problems we make
three contributions: First, we show how to improve the query
complexity of the Shabaz-Groz algorithm [12] exponentially.
Second, we design an extension of the Shabaz-Groz algorithm
which is able to handle transducers which output multiple
or no symbols in each transition. Finally, we develop a new
algorithm, based on our previous extension, which is able to
infer sanitizers that employ a lookahead, i.e., base their current
output by reading ahead more than one symbol.

To enable more ﬁne grained analysis of our inferred
models we develop an algorithm to convert (symbolic) ﬁnite
transducers with bounded lookahead into BEK programs. This
algorithm enables an interesting application: In the original
BEK paper [8] the authors manually converted different HTML
encoder implementations into BEK programs and then used the
BEK infrastructure to check equivalence and other properties.
Our algorithms enable these experiments to be performed
automatically, i.e. without manually converting each imple-
mentation to a BEK program and more importantly, being ag-
nostic of the implementation details. In fact, we checked seven
HTML encode implementations: three PHP implementations,
one implementation from the AntiXSS library in .NET and we
also included models infered from the HTML encoders used
by the websites of Twitter and Facebook and by the Microsoft
Outlook email service. We detected differences between many
implementations and found that Twitter and Facebook’s HTML
encoders match the htmlspecialcharacters function of
PHP although the Outlook service encoder does not match the
MS AntiXSS implementation in .NET. Moreover, we found
that only one of these implementations is idempotent.

Finally, we point out

that although our algorithms are
focused on the analysis of sanitizers and ﬁlters they are general
enough to potentially being applied in a number of different
domains. For example, in appendix D, we show how one
can use an SFA to model decision trees over the reals. In
another application, Doupe et al. [13] create a state aware
vulnerability scanner, where they model the different states
of the application using a Mealy machine. In their paper
they mention they considered utilizing inference techniques
for Mealy machines but that this was infeasible, due to the
large number of transitions. However, our symbolic learning
algorithms are able to handle efﬁciently exactly those cases
and thus, we believe several projects will be able to beneﬁt
from our techniques.

A. Limitations

Since the analysis we perform is black-box, all of our
techniques are necessarily incomplete. Speciﬁcally, there might
be some aspect of the target program that our algorithms will
fail to discover. Our algorithms are not designed to ﬁnd, for
example, backdoors in ﬁlters and sanitizers where a “magic
string” is causing the program to enter a hidden state. Such
programs will necessarily require an exponential number of
queries in the worst case in order to analyze completely.
Moreover, our algorithms are not geared towards discovering
new attacks for certain vulnerability classes. We assume that

9292

the description of the attack strings for a certain vulnerability
class, for example XSS, is given in the form of a context free
grammar.

B. Contributions

To summarize, our paper makes the following contribu-

tions:
Learning Algorithms: We present the ﬁrst, to the best of
our knowledge, algorithm that learns symbolic ﬁnite automata
in the standard membership and equivalence query model.
Furthermore, we improve the query complexity of the Shabaz-
Groz algorithm [12], a popular Mealy machine learning al-
gorithm and present an extension of the algorithm capable
of handling Mealy Machines with ε-input transitions. Finally,
we present a novel algorithm which is able to infer ﬁnite
transducers with bounded lookahead. Our transducer learning
algorithms can also be easily extended in the symbolic setting
by expanding our SFA algorithm.
Equivalence Query Implementation: We present the Gram-
mar Oriented Filter Auditing (GOFA) algorithm which imple-
ments an equivalence oracle with a single membership query
for each equivalence query and demonstrate that it is capable
to either detect a vulnerability in the ﬁlter if one is present or,
if no vulnerability is present, to recover a good approximation
of the target ﬁlter.
Conversion to BEK programs: We present, in appendix C
an algorithm to convert our inferred models of sanitizers into
BEK programs which can then be analyzed using the BEK
infrastructure enabling further applications.
Applications/Evaluation: We showcase the wide applicability
of our algorithms with a number of applications. Speciﬁcally,
we perform a thorough evaluation of our SFA learning al-
gorithm and demonstrate that it achieves a big performance
increase on the total number of queries performed. We also
evaluate our GOFA algorithm and demonstrate that it is able
to either detect attacks when they are present or give a good
approximation of the target ﬁlter. To showcase our transducer
learning algorithms we infer models of several HTML en-
coders, convert them to BEK program and check them for
equivalence.

We point out that, due to lack of space all proofs have been

moved into the appendix.

II. PRELIMINARIES

A. Background in Automata Theory
If M is a deterministic ﬁnite automaton (DFA) deﬁned over
alphabet Σ, we denote by |M| the number of states of M and
by L(M ) the language that is accepted by M. For any k we
denote by [k] the set {1, . . . , k}. We denote the set of states
of M by QM . A certain subset F of QM is identiﬁed as the
set of ﬁnal states. We denote by l : QM → {0, 1} a function
which identiﬁes a state as ﬁnal or non ﬁnal. The program of
the ﬁnite automaton M is determined by a transition function
δ over QM × Σ → QM . For an automaton M we denote by
¬M the automaton M with the ﬁnal states inverted.

A push-down automaton (PDA) M extends a ﬁnite au-
tomaton with a stack. The stack accepts symbols over an

alphabet Γ. The transition function is able to read the top of the
stack. The transition function is over QM × Σ × (Γ ∪ {ε}) →
QM × (Γ∪{ε}). A context-free grammar (CFG) G comprises
a set of rules of the form A → w where A ∈ V and
w ∈ (Σ ∪ V )
∗ where V is a set of non-terminal symbols.
The language deﬁned by a CFG G is denoted by L(G).

A transducer T extends a ﬁnite automaton with an output
tape. The automaton is capable of producing output in each
transition that belongs to an alphabet Γ. The transition function
is deﬁned over QM × (Σ ∪ {ε}) → QM × (Γ ∪ {ε}). A
Mealy Machine M is a deterministic transducer without ε
transitions where,
in addition, all states are ﬁnal. A non-
deterministic transducer has a transition function which is a
relation δ ⊆ QM × (Σ ∪ {ε}) × QM × (Γ ∪ {ε}). For general
transducers (deterministic or not), following [8], we extend
∗. A
the deﬁnition of a transducer to produce output over Γ
non-deterministic transducer is single-valued if it holds that
∗ there exists at most one γ ∈ Γ
for any w ∈ Σ
∗ such
that T on w outputs γ. A single-valued transducer T has
the bounded lookahead property if there is a k such that
any sequence of transitions involves at most k consecutive
non-accepting states. We call such a sequence a lookahead
path or lookahead transition. In a single valued transducer
with bounded lookahead we will call the paths that start and
ﬁnish in accepting states and involve only non-accepting states
as lookahead paths. The path in its course consumes some
input w ∈ Σ
∗. The bounded
lookahead property deﬁnition is based on the one given by
Veanes et al. [14] for Symbolic Transducers, however our
deﬁnition better ﬁts our terminology and the intuition behind
our algorithms.

∗ and outputs some γ ∈ Γ

For a given automaton M, we denote by Mq[s] the state
reached when the automaton is executed from state q on input
s. When the state q is omitted we assume that M is executed
from the initial state. Let l : Q → {0, 1} be a function denoting
whether a state is ﬁnal. We deﬁne the transduction function
TM (u) as the output of a transducer/Mealy Machine M on
input u omitting the subscript M when the context is clear.
For transducers we will also use the notation u[M ]v to signify
that TM (u) = v for a transducer M.

For a string s, denote by si the i-th character of the string.
In addition, we denote by s>i the substring s starting after si.
The operators s<i, s≥i, s≤i are deﬁned similarly. We denote
by suﬀ(s, k) the sufﬁx of s of length k.
Given two DFA’s M1, M2 it is possible to compute the
intersection M = M1 ∩ M2 of the two as follows. The set of
states of M is the Cartesian product Q1×Q2 and the transition
function combines the two individual transition functions to
traverse over the pair of states simultaneously. The accepting
states of QM are those that are simultaneously accepting for
M1, M2. We can use exactly the same algorithm to obtain the
intersection between a DFA M1 and a PDA M2. The resulting
machine M is a PDA that inherits the stack operations of M2.
Moreover, one can trivially compute the completement of a
DFA by switching all terminal states with non terminal and
vice-versa.

Transducers are not closed under intersection and dif-
ference, and if the transducer is non-deterministic checking
properties as simple as equality is undecidable. However,

9393

in the case the transducer is determinsitic or single valued
then equality can be efﬁciently computed and in the case the
transducers are not equal one can exhibit a string in which the
two transducers are different efﬁciently [15].

B. Symbolic Finite State Automata

Symbolic Finite Automata (SFA) [16] extend classical
automata by allowing transitions to be labelled with predicates
rather than with concrete alphabet symbols. This allows for
more compact representation of automata with large alphabets
and it could allow automata that are impossible to model as
DFAs when the alphabet size is inﬁnite, as in the case where
Σ = Z. For the following we refer to a set of predicates P as
a predicate family.
Deﬁnition 1. (Adapted from [16]) A symbolic ﬁnite automa-
ton or SFA A is a tuple (Q, q0, F,P, Δ), where Q is a ﬁnite
set of states, q0 ∈ Q the initial state, F ⊆ Q is the set of ﬁnal
states, P is a predicate family and Δ ⊆ Q × P × Q is the
move relation.

A move (p, φ, q) ∈ Δ is taken when φ is satisﬁed from the
current symbol α. We will also use an alternative notation for
a move (p, φ, q) as p φ−→ q. We denote by guard(q) the set of
predicate guards for the state q, in other words:

guard(q) := {φ : ∃p ∈ Q, (q, φ, p) ∈ Δ}

In this paper we are going to work with deterministic SFAs,
which we deﬁne as follows:
Deﬁnition 2. A SFA A is deterministic if for all states q ∈
Q and all distinct φ, φ(cid:5) ∈ guard(q) we have that φ ∧ φ(cid:5) is
unsatisﬁable.

Finally, we also assume that for any state q and for any
symbol a in the alphabet there exists φ ∈ guard(q) such that
φ(a) is true. We call such an SFA complete.

Finally, we deﬁne symbolic ﬁnite state transducers, the
corresponding symbolic extension of transducers similarly to
SFAs.
Deﬁnition 3. (Adapted from [15]) A symbolic ﬁnite trans-
ducer or SFT T is a tuple (Q, q0, F,P, Δ, Γ(x)), where Q is
a ﬁnite set of states, q0 ∈ Q the initial state, F ⊆ Q is the set
of ﬁnal states, P is a predicate family, Γ(x) is a set of terms
representing functions over Σ → Γ and Δ ⊆ Q×P×Γ(x)×Q
is the move relation.

C. Access and Distinguishing Strings

We will now deﬁne two sets of strings over an automaton

that play a very important role in learning algorithms.
Access Strings: For an automaton M we deﬁne the set of
access strings A as follows: For every state q ∈ QM , there is
a string sq ∈ A such that M [sq] = q. Given a DFA M, one
can easily construct a minimal set of access strings by using
a depth ﬁrst search over the graph induced by M.

Distinguishing Strings: We deﬁne the set of distinguishing
strings D for a minimal automaton M as follows: For any pair
of states qi, qj ∈ QM , there exists a string di,j ∈ D such that

exactly one state of Mqi [di,j] and Mqj [di,j] is accepting. A set
of distinguishing strings can be constructed using the Hopcroft
algorithm for automata minimization [17].

The set of Access and Distinguishing strings play a central
role in automata learning since learning algorithms try to
construct these sets by querying the automaton. Once these
sets are constructed then, as we will see, it is straightforward
to reconstruct the automaton.

D. Learning Model

Our algorithms work in a model called exact learning
from membership and equivalence queries [18], which is a
form of active learning where the learning algorithm operates
with oracle access to two types of queries:

–

– Membership queries: The algorithm is allowed to

submit a string s and obtain whether s ∈ L(M ).
Equivalence queries: The algorithm is allowed to
submit a hypothesis H which is a ﬁnite automaton
and obtain either a conﬁrmation that L(H) = L(M )
or a string z that is a counterexample, i.e., a string z
that belongs to L(H)(cid:9)L(M ). 1

The goal of the learning algorithm is to obtain an exact
model of the unknown function. Note that, this model extends
naturally to the case of deterministic Mealy machines and
transducers by deﬁning the membership queries to return the
output of the transducer for the input string. We say that an
algorithm gets black box access to an automaton/transducer
when the algorithm is able to query the automaton with an
input of his choice and obtain the result. No other information
is obtained about the structure of the automaton.

III. LEARNING ALGORITHMS

In this section we present two learning algorithms that
form the basis of our constructions, Angluin’s algorithm for
DFA’s [19] as optimized by Rivest and Schapire [20] and the
Shabhaz-Groz (SG) algorithm for Mealy machines [12].

A. Angluin’s Algorithm

Consider a ﬁnite automaton M. Angluin [19] suggested an
algorithm (referred to as L∗) for learning M. The intuition
behind the functionality of Angluin’s algorithm is to construct
the set of access and distinguishing strings given the two
oracles available to it. Intuitively, the set of access strings
will suggest the set of states of the reconstructed automaton.
Furthermore, a transition from a state labeled with access string
s to a state labelled with access string s(cid:5) while consuming a
symbol b will take place if and only if the string sb leads to a
state that cannot be distinguished from s(cid:5).

In order to reconstruct the set of access and distinguishing
strings the algorithm starts with the known set of access strings
(initially just {ε}) and, using equivalence queries, expands
the set of access and distinguishing strings until the whole
automaton is reconstructed.

1We denote by (cid:2) the symmetric difference operation.

9494

Technical Description. The variant L∗ we describe below is
due to Rivest and Schapire [20]. The main data structure used
by the L∗ algorithm is the observation table.
Deﬁnition 4. An observation table OT with respect to an
automaton M is a tuple OT = (S, W, T ) where

S ⊆ Σ
–
– W ⊆ Σ

∗ is a set of access strings.
∗ is a set of distinguishing strings which we

will also refer to as experiments.
∗ × Σ
T is a partial function T : Σ

∗ → {0, 1}.

–

The function T maps strings into their respective state label
in the target automaton, i.e., T (s, d) = l(M [s · d]). We note
here that T is deﬁned only for those strings s, d such that s· d
was queried using a membership query.

Next we deﬁne an equivalence relation between strings

with respect to a set of strings and a ﬁnite automaton M.
Deﬁnition 5. (Nerode Congruence) Given a ﬁnite automaton
M, for a set W ⊆ Σ

∗ and two strings s1, s2 we say that
s1 ≡ s2 mod W

when for all w ∈ W we have that l(M [s1· w]) = l(M [s2· w]).
Note that for any M there will be a ﬁnite number of differ-
ent equivalence classes for any set W (this stems immediately
from the fact that M is a ﬁnite automaton). This relates to the
Myhill-Nerode theorem [21] that, for the above equivalence
deﬁned over a language L (i.e., requiring that either both
s1 · w, s2 · w ∈ L or none), it states that having a ﬁnite number
of equivalence classes for L is equivalent to L being regular.
The observation table is going to give us a hypothesis
automaton H when the property of closedness holds for the
table.
Deﬁnition 6. Let OT = (S, W, T ) be an observation table.
We say that OT is closed when, for all t ∈ S · Σ, there exists
s ∈ S such that t ≡ s mod W .

Given a closed observation table we can produce a hy-
pothesis automaton as follows: For each string s ∈ S we
create a state qs. The initial state is qε. For a state qs and
a symbol b ∈ Σ we set δ(qs, b) = qt iff s· b ≡ t mod W . By
the closedness property there will be always at least one such
string. In the following, we will also see that by the way we
ﬁll the table that string will always be unique.
We are now ready to describe the algorithm: Initially we
start with the observation table OT = (S = {ε}, W = {ε}, T ).
The table T has |Σ| + 1 rows and is ﬁlled by querying an
equal number of membership queries. The table is checked
for closedness. If the table is not closed then let t ∈ S · Σ be
a string such that for all s ∈ S, we have that s (cid:11)≡ t mod W .
Then, we set S = S ∪ {t}, complete remaining entries of
the table via |Σ| membership queries and we check again
for closedness. Eventually the table becomes closed and we
create a hypothesis automaton H. Observe that the number
of times we will repeat the above process until we reach a
closed table cannot exceed |QM|. A useful invariant in the
above algorithmic process is the property of the observation
table OT to be reduced: for all s, s(cid:5) ∈ S it holds that

s (cid:11)= s(cid:5)
mod W . Observe that the initial OT is trivially reduced
while augmenting the set S with a new state as described above
preserves the property.

Now suppose that we have a hypothesis automaton H
produced by a closed and reduced observation table. Given
H, the algorithm makes an equivalence query and based on
the outcome either the algorithm stops (no counterexample
exists) or the counterexample z is processed and the set of
distinguishing strings W is augmented by one element as
shown below.
Processing a counterexample. For any i ∈ {0, . . . ,|z|} deﬁne
αi to be the outcome (that is accept or reject) that is produced
by processing the ﬁrst i symbols of z with the hypothesis H
and the remaining with M in the following manner. Given i
we simulate H on the ﬁrst i symbols of z to obtain a state
si ∈ S. Let z>i be the sufﬁx of z that is not processed
yet; by submitting the membership query siz>i we obtain αi.
Observe that based on the fact that z is a counterexample
it holds that α0 (cid:11)= α|z|. It follows that there exists some
i0 ∈ {0, . . . ,|z|− 1} for which αi0
(cid:11)= αi0+1. We can ﬁnd such
i0 via a binary search using O(log |z|) membership queries.
The new distinguishing string d will be deﬁned as the sufﬁx
of z>i0 that excludes the ﬁrst symbol b (denoted as z>i0+1).
We observe the following: recall that αi0 is the outcome of the
membership query of si0 z>i0 = si0 bz>i0+1 and αi0+1 is the
outcome of the membership query si0+1z>i0+1. Furthermore,
in H, si0 transitions to si0+1 by consuming b, hence we have
b ≡ si0+1 mod W . By adding d = z>i0+1 to W we
that si0
b, z>i0+1) (cid:11)= T (si0+1, z>i0+1) and hence the
have that T (si0
state si0+1 and the state that is derived by si0 consuming b
should be distinct (while H pronounced them equal). We ob-
serve that the new observation table OT is not closed anymore:
b (cid:11)≡ si0+1 mod W ∪ {d}
on the one hand, it holds that si0
(note that since ε ∈ W it should be that d (cid:11)= ε), while if
si0 b ≡ sj mod W ∪{d} for some j (cid:11)= i0 + 1 this would imply
that si0 b ≡ sj mod W and thus si0+1 ≡ sj mod W as well.
This latter equality contradicts the property of the OT being
reduced. Hence we conclude that the new OT is not closed
and the algorithm continues as stated above (speciﬁcally it will
introduce si0

b as a new state in S and so on).

We remark that originally, L∗ as described by Angluin
added all preﬁxes of a counterexample in S and thus violated
the reduced table invariant (something that lead to a sub-
optimal number of membership queries). The variant of L∗ we
describe above due to [20] maintains the reduced invariant.

For a target automaton M with n states, the total number
of membership queries required by the algorithm is bounded
by n2(|Σ| + 1) + n log m where m is the length of the longest
counterexample.

B. The Shabhaz-Groz (SG) Algorithm

In [12], Shabhaz and Groz extended Angluin’s algorithm
to the setting of Mealy machines which are deterministic
Transducers without ε-transitions.

The core of the algorithm remains the same: a table
OT will be formed and as before will be based on rows
corresponding to S ∪ S × Σ and columns corresponding to
distinguishing strings W . The table OT will not be a binary

9595

∗.
table in this case, but
instead it will have values in Γ
Speciﬁcally, the partial function T in the SG observation table
is deﬁned as T (s, d) = suﬀ(T (sd),|d|). The rows of T satisfy
the non-equivalence property, i.e., for any s, s(cid:5) ∈ S it holds
that s (cid:11)≡ s(cid:5)
mod W , thus as in the Rivest-Schapire variant of
L∗ each access string corresponds to a unique state in the
hypothesis automaton. Further, provided that Σ ⊆ W , we
have for each s ∈ S, the availability of the output symbol
produced when consuming any b ∈ Σ is given by T (s, b).
In this way a hypothesis Mealy machine can be constructed
in the same way as in the L∗ algorithm. On the other hand,
Shabhaz and Groz [12] contribute a new method for processing
counterexamples described below.

Let z be a counterexample, i.e., it holds that the hypothesis
machine H and the target machine produce a different output
in Γ. Let s be the longest preﬁx of z that belongs to the access
strings S. If s·d = z, in [12] it is observed that they can add d
as well as all of its sufﬁxes as columns in OT . The idea is that
at least one of the sufﬁxes of d will contain a distinguishing
string and thus it can be used to make the table not closed.In
addition, this method of processing counterexamples makes
the set W sufﬁx closed. After adding all sufﬁxes and making
the corresponding membership queries, the algorithm proceeds
like the L∗ algorithm by checking the table for closedness.
The overall query complexity of the algorithm is bounded by
O(|Σ|2n + |Σ|mn2) queries, where n, m, Σ are deﬁned as in
the L∗ algorithm.

IV. LEARNING SYMBOLIC AUTOMATA

In this section we present our algorithm for learning
symbolic ﬁnite automata for general predicate families. Then,
we specialize our algorithm for the case of regular expression
ﬁlters.

A. Main Algorithm

Symbolic ﬁnite automata extend classical ﬁnite automata
by allowing transitions to be labelled by predicate formulas
instead of single symbols. In this section we will describe the
ﬁrst, to the best of our knowledge, algorithm to infer SFAs
from membership and equivalence queries. Our algorithm,
contrary to previous efforts to infer symbolic automata [22]
which required the counterexample to be of minimal length,
works in the standard membership and equivalence query
model under a natural assumption, that the guards themselves
can be inferred using queries.

The main challenge in learning SFA’s is that counterexam-
ples may occur due to two distinct reasons: (i) a yet unlearned
state in the target automaton (which is the only case in the L∗
algorithm), (ii) a learned state with one of the guards being
incorrect and thus, leading to a wrong transition into another
already discovered state. Our main insight is that it is possible
to distinguish between these two cases and suitably adjust
either the guard or expand the hypothesis automaton with a
new state.
Technical Description. The algorithm is parameterized by
a predicate family P over Σ. The goal of the algorithm is
to both infer the structure of the automaton and label each
transition with the correct guard φ ∈ P. Compared to the L∗
algorithm, our learning algorithm, on top of the ability to make

membership and equivalence queries will also require that the
guards come from a predicate family for which there exists a
guard generator algorithm that we deﬁne below.
Deﬁnition 7. A guard generator algorithm guardgen() for
a predicate family P over an alphabet Σ takes as input a
sequence R of pairs (b, q) where b ∈ Σ and q an arbitrary
label and returns a set of pairs G of the form (φ, q) such that
the following hold true:

(Completeness) ∀(b, q) ∈ R ∃φ : (φ, q) ∈ G ∧ φ(b).
(Uniqueness) ∀φ, φ(cid:5), q : (φ, q), (φ(cid:5), q) ∈ G → φ = φ(cid:5).
(Determinism) ∀b ∈ Σ ∃!(φ, q) ∈ G : φ(b).

–
–
–

The algorithm fails if such set of pairs does not exist.

Given a predicate family P that is equipped with a guard
generator algorithm, our SFA learning algorithm employs a
special structure observation table SOT = (S, W, Λ, T ) so
that the table T has labelled rows for each string in S ∪ Λ
where Λ ⊆ S · Σ. The initial table is SOT = {S = {ε}, W =
{ε}, Λ = ∅, T}. Closedness of SOT is determined by checking
that for all s ∈ S it holds that sb ∈ Λ → ∃s(cid:5) ∈ S : (sb ≡
s(cid:5)
mod W ). Furthermore the table is reduced if and only if
for all s, s(cid:5) ∈ S it holds that s (cid:11)≡ s(cid:5)
mod W . Observe that the
initial table is (trivially) closed and reduced.

Our algorithm operates as follows. At any given step, it
will check T for closedness. If a table is not closed, i.e., there
is a sb ∈ Λ such that sb (cid:11)≡ s(cid:5) for any s(cid:5) ∈ S, the algorithm
will add sb to the set of access strings S updating the table
accordingly.
On the other hand, if the table is closed, a hypothesis SFA
H = (QH , qε, F,P, Δ) will be formed in the following way.
For each s ∈ S we deﬁne a state qs ∈ QH. The initial state
is qε. A state qs is ﬁnal iff T (s, ε) = 1. Next, we need to
determine the move relation that contains triples of the form
) with φ ∈ P. The information provided by SOT for
(q, φ, q(cid:5)
each qs is the transitions determined by the rows T (sb) for
which it holds sb ∈ Λ. Using this we form the pairs (b, qs(cid:2) )
such that sb ≡ s(cid:5)
mod W (the existence of s(cid:5) is guaranteed
by the closedness property). We then feed those pairs to the
guardgen() algorithm that returns a set Gqs of pairs of the
form (φ, q). We set guard(qs) = {φ | (φ, q) ∈ Gqs
} and
add the triple (qs, φ, q) in Δ. Observe that by deﬁnition the
above process when executed on the initial SOT returns as
the hypothesis SFA a single state automaton with a self-loop
marked with true as the single transition over the single state.
Processing Counterexamples. Assume now that we have a
hypothesis SFA H which we submit to the equivalence oracle.
In case H is correct we are done. Otherwise, we obtain a coun-
terexample string z. First, as in the L∗ algorithm, we perform
a binary search that will identify some i0 ∈ {0, 1, . . . ,|z|− 1}
for which the response of the target machine is different
for the strings si0 z>i0 and si0+1z>i0+1. This determines a
new distinguishing string deﬁned as d = z>i0+1. Notice that
b (cid:11)≡ si0+1 mod W ∪ {d} something that reﬂects that si0
si0
over b should not transition to si0+1 as the hypothesis has
b (cid:11)≡ sj mod W ∪ {d} for any j, the
predicted. In case si0
table will become not closed if augmented by d and thus
the algorithm will proceed by adding d to W and update

9696

the table accordingly (this is the only case that occurs in
the L∗ algorithm). On the other hand, it may be the case
that adding d to SOT preserves closedness as it may be that
si0 b ≡ sj mod W ∪ {d} for some j (cid:11)= i0 + 1. This does
not contradict the fact that the table prior to its augmentation
was reduced, as in the case of the L∗ algorithm, since the
transition si0 to si0+1 when consuming b that is present in
the hypothesis could have been the product of guardgen()
and not an explicit transition deﬁned in Λ. In such case Λ
b and the algorithm will issue another
is augmented with si0
equivalence query, continuing in this fashion until the SOT
becomes not closed or the hypothesis is correct.

The above state of affairs distinguishes our symbolic learn-
ing algorithm from learning via the L∗ algorithm: not every
equivalence query leads to the introduction of a new state.
We observe though that some progress is still being made:
if a new state is not discovered by an equivalence query, the
set Λ will be augmented making a transition that was before
implicit (deﬁned via a predicate) now explicit. For suitable
predicate families this augmentation will lead to more reﬁned
guard predicates which in turn will result to better hypothesis
SFA’s submitted to the equivalence oracle and ultimately to
the reconstruction of an SFA for the target.

In order to establish formally the above we need to prove
that the algorithm will converge to a correct SFA in a ﬁnite
number of steps (note that the alphabet Σ may be inﬁnite
for a given target SFA and thus the expansion of Λ by each
equivalence query is insufﬁcient by itself to establish that the
algorithm terminates).
Convergence can be shown for various combinations of
predicate families P and guardgen() algorithms that relate to
the ability of the guardgen() algorithm to learn guard predi-
cates from the family P. One such case is when guardgen()
learns predicates from P via counterexamples. Let G ⊆ 2
P a
guard predicate family. Intuitively, the guardgen() algorithm
operates on a training set containing actual transitions from
a state that were previously discovered. Given the symbols
labeling those transitions, the algorithm produces a candidate
guard set for that state. If the training set is small the candidate
guard set is bound to be wrong and a counterexample will
exist. The guardgen() algorithm learns the guard set via
counterexamples if by adding a counterexample in the training
set in each iteration will eventually stabilize the output of
the algorithm to the correct guard set. We will next deﬁne
what a counterexample means with respect to the guardgen()
algorithm, a set of predicates φ and an input to guardgen()
which is consistent with φ. Recall that inputs to guardgen()
are sets R of the form (b, si) where b is a symbol and si is a
label; a set R is consistent with φ if it holds that φi(b) is true
for all (b, si) ∈ R (we assume a ﬁxed correspondence between
the labels si and the predicates φi of φ). A counterexample
would be a pair (b∗, s∗
) where s∗ labels a predicate φj in φ
but the output predicate φ of guardgen() that is labelled by sj
disagrees with φj on symbol b∗. More formally we give the
following deﬁnition.
Deﬁnition 8. For k ∈ N, consider a set of predicates
φ = {φ1, . . . , φk} ∈ G labelled by s = (s1, . . . , sk) so that
φi is labelled by si and a sequence of samples R containing
pairs of the form (b, si) where φi(b) for some i ∈ [k]. A
counterexample (b∗, s∗
) for (R, φ, s) w.r.t. guardgen() is a

pair such that if G = guardgen(R) it holds that there is a
) (cid:11)= φj(b∗
j ∈ {1, . . . , k} with sj = s∗, (φ, sj) ∈ G and φ(b∗
).
Let t be a function of k. A guard predicate family G is t-
learnable via counterexamples if it has a guardgen() algorithm
such that for any φ = (φ1, . . . , φk) ∈ G labelled by s =
(s1, . . . , sk), it holds that the sequence R0 = ∅, Ri = Ai ∪
Ri−1 where Ai is a singleton containing a counterexample
for (Ri−1, φ, s) w.r.t. guardgen() (or empty if none exist),
satisﬁes that guardgen(Rj) = {(φi, si) | i = 1, . . . , k} for any
j ≥ t. In other words, a guard predicate family is t-learnable if
the guardgen() converges to the target guard set in t iterations
when in each iteration the training set is augmented with a
counterexample from the previous guard set.

We are now ready to prove the correctness of our SFA
learning algorithm.
Theorem 1. Consider a guard predicate family G that is t-
learnable via counterexamples using a guardgen() algorithm.
The class of deterministic symbolic ﬁnite state automata with
guards from G can be learned in the membership and equiva-
lence query model using at most O(n(log m+n)t(k)) queries,
where n is size of the minimal SFA for the target language,
m is the maximum length of a counterexample, and k is the
maximum outdegree of any state in the minimal SFA of the
target language.

In appendix D we describe an example of a guardgen()

algorithm when SFAs are used to model decision trees.

B. A Learning Algorithm for RE Filters

∗<a>(.)

Consider the SFA depicted in ﬁgure 1 for the regular
∗. This represents a typical regular ex-
expression (.)
pression ﬁlter automaton where a speciﬁc malicious string is
matched and at that point any string containing that malicious
substring is accepted and labeled as malicious. When testing
regular expression ﬁlters many times we would have to test
different character encodings. Thus, if we assume that the
alphabet Σ is the set of two byte chatacter sequences as
then each state would have 216
it would be in UTF-16,
different transitions, making traditional learning algorithms too
inefﬁcient, while we point out that the full unicode standard
contains around 110000 characters.

We will now describe a guard generator algorithm and
demonstrate that it efﬁciently learns predicates resulting from
regular expressions. The predicate family used by our algo-
rithm is P = 2Σ where Σ is the alphabet of the automaton,
for example UTF-16. The guard predicate family Gl,k is
parameterized by integers l, k and contains vectors of the form
(cid:15)φ1, . . . , φk(cid:2)(cid:16) with k(cid:5) ≤ k, so that φi ∈ P and2 |φi| ≤ l
for any i, except for one, say j, for which it holds that
φj = ¬(∨i(cid:6)=jφi). The main intuition behind this algorithm
is that, for each state all but one transitions contain a limited
number of symbols, while the remaining symbols are grouped
into a single (sink) transition.
) is called normal
if |φ| ≤ l. A transition that is not normal is called a sink
transition. Our algorithm updates transitions lazily with new

In an SFA over Gl,k, a transition (q, φ, q(cid:5)

2We use the notation |φ| = |{b | φ(b) = 1}|.

9797

x (cid:11)=<

q0

x (cid:11)= a
x =<

q1

x = a

q2

x =>

q3

true

A. Improved learning of Mealy machines

x (cid:11)=>

Fig. 1. SFA for regular expression (.)∗<a>(.)∗.

symbols whenever a counterexample shows that a symbol
belongs to a different transition, while the transition with the
largest size is assigned as the sink transition.
Consider R, an input sequence for the guard generator
algorithm. We deﬁne Rq = {(b, q) | (b, q) ∈ R}. If |Rq| ≤ l
then we deﬁne the predicate for Rq denoted by φq. Let q(cid:5) be
such that |Rq(cid:2)| ≥ |Rq| for all q. We deﬁne σ = Σ
∗ \∪q(cid:6)=q(cid:2) Rq.
The output is the set G = {(φq, q) | q (cid:11)= q(cid:5)} ∪ {(σ, q(cid:5)
)}. In
case R = ∅ the algorithm returns Σ
∗ as the single predicate.
We observe now that Gl,k is t-learnable via counterex-
amples with t = O(lk). Indeed, note that counterexamples
will be augmenting the cardinality of the predicates that
are constructed by the guard generator. At some point one
predicate will exceed l elements and will correctly be identiﬁed
as the sink transition. We conclude that the target SFA will be
inferred using O(nlk(log m + n)) queries.

V. LEARNING TRANSDUCERS

In this section we present our learning algorithms for
transducers. We start with our improved algorithm for Mealy
machines and then we move to single-valued transducers with
bounded lookahead. We conclude with how to extend our
results to the symbolic transducer setting. To motivate this
section we present in Figure 5 three examples of common
string manipulating functions. For succinctness we present the
symbolic versions of all three sanitizers. The ﬁrst example is
a typical tolowercase function which converts uppercase
ascii
letters to lowercase and leaves intact any other part
of the input. The second example is a simpliﬁed HTML
Encoder which only encodes the character “<”. In this case,
the transition reading the input symbol “<” needs to produce
multiple output symbols that represent the encoded version
of the symbol. An equivalent formulation of this property is
to assume that the resulting Mealy machine is deterministic
but allow ε-transitions. This transformation is not expressible
with a Mealy machine which requires that only one output
symbol will be produced for each input symbol consumed.
Finally, the third sanitizer is a transformation function used
by mod-security, a popular web application ﬁrewall, in order
to remove comments from an SQL expression. This helps
to deobfuscate the input before passing it through regular
expression ﬁlters. In this case, to match the beggining of
an SQL comment, i.e. the string “/*”, the transducer need
to employ an 1-lookahead. This transformation can only be
modelled using non determinism in the resulting ﬁnite state
transducer model. In the learning algorithms of this section,
we will replace membership queries with transduction queries
that output the result of the transduction of the input string.

In this section we describe two improvements of the SG
algorithm for Mealy machines. In the ﬁrst one we provide an
efﬁciency improvement over SG on the number of transduction
queries required in order to learn a target Mealy machine of
size n. Speciﬁcally we drop the counterexample processing
complexity from O(m · n) to O(m + log n) where m is the
length of the counterexample. Our main observation is that
contrary to what is implied by Shabaz and Groz, processing
Mealy machine counterexamples can take advantage of the
binary-search counter example processing similar to Rivest-
Schapire’s version of the L∗ algorithm something that leads
to major improvements in the query complexity of the algo-
rithm. In our second improvement we show how the learning
algorithm can handle a more general class of Mealy Machines
which are deterministic but also allow ε-transitions in the input.
In practice, this modiﬁcation allows for multiple symbols in the
output to be produced for each single input symbol. This case
is particularly relevant to our setting as such Mealy machines
are very frequently encountered in practice notably as string
encoders such url and HTML encoders, cf. Figure 5.

Improved Counterexample Processing: We now intro-
duce a new way of handling counterexamples in the SG
algorithm that is based on Rivest and Schapire’s version of
the L∗ algorithm [20]. Recall that in the SG algorithm all the
sufﬁxes of a counterexample are added as new experiments in
the table and therefore, in the worst case, O(m·n) new entries
must be ﬁlled in the table using transduction queries where m
is the length of the counterexample and n is the number of
access strings.

Our improved counterexample processing operates as fol-
lows. Suppose that z is the given counterexample, i.e. it is a
string where the target machine and the hypothesis disagree.
Furthermore suppose that the hypothesis transducer is pro-
duced by a reduced observation table. We notice that even
though the last state reached in the counterexample may be
identical in both cases, we can ﬁnd a point where a wrong
state is traversed by the counterexample by inspecting the
transduction of z. Indeed, there exists a (smallest) index i such
that TH (z)i (cid:11)= TM (z)i. Therefore we can conclude that z<i
reaches different states in the hypothesis and target machine.
It follows we can trim the counterexample to z(cid:5)
= z≤i and
this way we know that
the last symbol produced by the
counterexample is wrong in the hypothesis automaton.

We now describe formally our improved counterexample
processing algorithm. For any j ∈ {0, . . . ,|z(cid:5)|} let γj be a
string that is produced as follows: ﬁrst run the hypothesis H
machine on z(cid:5)
j ; the hypothesis terminates on a
state sj; subsequently submit sjz(cid:5)
>j to M in order to obtain a
· suﬀ(γM
j ,|z(cid:5)| − j) and observe that
string γM
γ0 = TM (z(cid:5)

) and γ0 (cid:11)= γ|z(cid:2)|.

≤j to obtain γH

j . Let γj = γH
j

), γ|z(cid:2)| = TH (z(cid:5)

The binary search then is performed in this fashion. The
initial range is [0,|z(cid:5)|] and the middle point is j = (cid:19)|z(cid:5)|/2(cid:20).
Given a range [jleft, jright] and a middle point position j, we
check whether γj = γ0; if this is the case we set the new range
as [j, jright] else we set the new range as [jleft, j − 1] and we
continue recursively. The process ﬁnishes when the range is a
singleton [j0, j0] which is the output of the search.

9898

Fig. 2.
machine.

ToLowerCase function. Mealy

Fig. 3. Simpliﬁed version of HTML Encoder
function. Deterministic Transducer with mul-
tiple output symbols per transition.

Fig. 4. ReplaceComments Mod-security
transformation function. Non deterministic
Transducer with  transitions and 1-lookhead.

Fig. 5. Three different sanitizers implementing widely used functions and their respective features when modeled as transducers. Only the ﬁrst sanitizer can
be inferred using existing algorithms.

Theorem 2. The binary search process described above re-
turns j0 ∈ {0, . . . ,|z(cid:5)| − 1} such that γj0 (cid:11)= γj0+1.

–

Given such j0, we observe that since the preﬁxes of
, γj0+1 that correspond to the processing of z≤j0 are identi-
γj0
cal by deﬁnition, the difference between the strings should lie
in their sufﬁxes. Furthermore, (γj0 )j0+1 = (γj0+1)j0+1 since
the former is the last output symbol produced by H when
consuming z≤j0 b and the latter is the last symbol produced by
M when consuming sj0 b, where b = z(cid:5)
j0+1 is the (j0 + 1)-th
symbol of the counterexample. As a result the difference of
γj0 , γj0+1 is in their (|z(cid:5)|−j0−1)-sufﬁxes that by deﬁnition are
equal to the same length sufﬁxes of γM
j0+1. This implies
that j0 < |z(cid:5)|− 1 and thus we can deﬁne a new distinguishing
j0
string d = z(cid:5)
>j0+1. The observation table augmented by this
new string d is not closed any more: the string sj0 bd = sj0 z(cid:5)
>j0
when queried to M produces the string γM
j0 which disagrees
in its |d|-sufﬁx with the string γM
j0+1 produced by M on input
sj0+1d. Closing the table will now introduce the new access
string sjb and hence the algorithm continues by expanding the
hypothesis machine.

, γM

The approach we outlined above offers a signiﬁcant ef-
ﬁciency improvement over the SG algorithm. Performing the
binary search detailed above requires merely O(log m) queries
where m is the length of the counterexample. This gives a total
of O(n + log m) queries for processing a counterexample as
opposed to the O(n · m) of the SG algorithm where n is the
number of access strings in the observation table.

Handling ε-transitions: We next show how to tackle the
problem of a Mealy machine that takes ε-transitions but still
is deterministic in its output. The effect of such ε-transitions
is that many or no output symbols may be generated due to a
single input symbol. Even though this is a small generalization
it complicates the learning process. First, if more than one
output symbols are produced for each input symbol our coun-
terexample processing method will fail because the breakpoint
output symbol (TM (z))i may be produced by less than i
symbols of z. Further, in the observation table, bookkeeping
will be inaccurate since, if we keep only the suﬀ(TM (sd),|d|)
string in each table entry, then this might not correspond to
the output symbols that correspond to last d symbols of the
input string.

We show next how to suitably modify our bookkeeping
and counterexample processing so that Mealy machines with
ε-transitions are handled.

Instead of keeping in each table entry the string
suﬀ(TM (sd),|d|) we only keep the output that corre-
sponds to the experiment d. While in standard Mealy
machines this is simply suﬀ(TM (sd),|d|), when ε-
transitions are used the output may be longer or
shorter. Therefore, we compute the output of the ex-
periment as the substring of TM (sd) when we subtract
the longest common preﬁx with the string TM (s).
Intuitively, we keep only the part of the output that
is produced by the experiment d. Given that we do
not know the length of that output we subtract the
output produced by the access string s. Notice that,
because the observation table is preﬁx closed, we can
obtain the output TM (s) without making an additional
transduction query to the target M.

– When processing a counterexample, the method we
outlined above can still be used. However, as we men-
tioned, the index i where the output of the hypothesis
and the target machine differ may not be the correct
index in which we must trim the input at. Speciﬁcally,
if TH (z) and TM (z) differ in position i (and i is the
smallest such position), then we are looking for an
index i(cid:5) ≤ i such that TM (z≤i(cid:2) ) = TM (z)≤i. Given
i, such a position i(cid:5) can be found with log |z| queries
using a binary search on the length of the output of
each substring of z. We will then deﬁne z(cid:5)
= z≤i(cid:2).

j ,|γM

j | − j(cid:5)

· suﬀ(γM

Given the above modiﬁcations we will seek j0 via a binary
search as in Theorem 2 but using the strings γj that are
= |TM (sj)|
deﬁned as γH
for j = 0, . . . ,|z(cid:5)|. Then, the same proof as in Theorem 2
j
applies. Further, using a similar logic as before we argue that
the string d = z>j0+1 is non-empty and it can be used as a
new distinguishing string. The asymptotic complexity of the
algorithm will remain the same.

) where j(cid:5)

B. Learning Transducers with Bounded Lookahead

It is easy to see that if the target machine is a single-
valued non-deterministic transducer with the bounded looka-
head property the algorithm of the previous section fails. In
fact the algorithm may not even perform any progress beyond
the initial single state hypothesis even if the number of states
of the target is unbounded; for instance, consider a transducer
that modiﬁes only a certain input symbol sequence w (say
by redacting its ﬁrst symbol) while leaving the remaining
input intact. The algorithm of the previous section will form a

9999

hypothesis that models the identity function and obtain from
the equivalence oracle, say, the string w as the counterexample
(any string containing w would be a counterexample, but w
is the shortest one). The binary search process will identify
j0 = 0 (it is the only possibility) and will lead the algorithm to
the adoption of d = w>1 as the distinguishing string. However,
bd) = TM (w) = w>1, and also TM (sj0+1d) = w>1
TM (sj0
b ≡ sj0+1 mod W ∪ {d}. At
hence d is not distinguishing: sj0
this moment the algorithm is stuck: the table remains closed
and no progress can be made. For the following we assume that
∗, i.e. for every string
the domain of the target transducer is Σ
∗ such that TM (α) = γ.
∗ there exists exactly one γ ∈ Γ
α ∈ Σ
Technical Description. The algorithm we present builds on
our algorithm of the previous section for Mealy Machines
with ε-transitions. Our algorithm views the single-valued trans-
ducer as a Mealy Machine with ε-transitions augmented with
certain lookahead paths. As in the previous section we use
an observation table OT that has rows on S ∪ S × Σ and
columns corresponding to the distinguishing strings W . In
addition our algorithm holds a lookahead list L of quadraples
(src, dst, α, γ) where src, dst are index numbers of rows in
the OT , α ∈ Σ
∗ is the input string consumed by the lookahead
path, while γ ∈ Γ
∗ is the output produced by the lookahead
path. Whenever a lookahead path is detected, it is added in
the lookahead transition list L. Our algorithm will also utilize
the concept of a preﬁx-closed membership query: In a preﬁx
closed membership query, the input is a string s and the result
is the set of membership queries for all the preﬁxes of s. Thus,
if O is the membership oracle, then a preﬁx-closed member-
ship query on input a string s will return {O(s≤1), . . . , O(s)}.
We will now describe the necessary modiﬁcations in order to
detect and process lookahead transitions.
Detecting and Processing lookahead transitions. Observe
that in a deterministic transducer the result of a preﬁx-closed
query on a string s would be a preﬁx closed set r1, . . . , rt.
The existence of i0 ∈ {1, . . . , t} with ri0 not a strict preﬁx
of ri0+1 suggests that a lookahead transition was followed.
Let rj0 be the longest common preﬁx of r1, . . . , ri0+1. The
state src = sj0 that corresponds to qj0 is the state that the
lookahead path commences while the state dst = si0+1 that
corresponds to input qi0+1 is the state the path terminates. The
path consumes the string α that is determined by the sufﬁx of
qi0+1 starting at the (j0 + 1)-position. The output of the path
is γ = suﬀ(ri0+1,|ri0+1| − |rj0|).

The algorithm proceeds like the algorithm for Mealy ma-
chines with ε-transitions. However, all membership queries are
replaced with preﬁx-closed membership queries. Every query
is checked for a lookahead transition. In case a lookahead
transition is found, it is checked if it is already in the list L. In
the opposite case the quadraple (src, dst, α, γ) is added in L
and all sufﬁxes of α are added as columns in the observation
table. The reason for the last step is that every lookahead
path of length m deﬁnes m − 2 ﬁnal states in the single-
valued transducer. The sufﬁxes of α can be used to distinguish
these states. Finally, when the table is closed, a hypothesis is
generated as before taking care to add the respective lookahead
transitions, removing any other transitions which would break
the single-valuedness of the transducer.
Processing Counterexamples. For simplicity, in this algo-
rith we utilize the Shabaz-Groz counterexample processing

method. We leave the adjustment of our previous binary
search counterexample method as future work. Notice that,
a counterexample may occur either due to a hidden state or
due to a yet undiscovered lookahead transition. We process a
counterexample string as follows: We follow the counterex-
ample processing method of Shabaz Groz and we add all
the sufﬁxes of the counterexample string as columns in the
OT . Since the SG method already adds all sufﬁxes, this also
covers our lookahead path processing. In case we detect a
lookahead we also take care to add the respective transition in
the lookahead list L. Notice that, following the same argument
as in the analysis of the SG algorithm, one of the sufﬁxes will
be distinguishing, thus the table will become not closed and
progress will be made.

Regarding the correctness and complexity of our algorithm

we prove the following theorem.
Theorem 3. The class of non-deterministic single-valued
transducers with the bounded lookahead property and domain
∗ can be learned in the membership and equivalence query
Σ
model using at most O(|Σ|n(mn+|Σ|+kn)(n+max{m, n}))
membership queries and at most n + k equivalence queries
where m is the length of the longest counterexample, n is the
number of states and k is the number of lookahead paths in
the target transducer.

C. Learning Symbolic Finite Transducers

The algorithm for inferring SFAs can be extended naturally
in order to infer SFTs. Due to space constraints we won’t
describe the full algorithm here rather sketch certain aspects
of the algorithm.

The main difference between the SFA algorithm and the
SFT algorithm is that on top of inferring predicates guards,
the learning algorithm for SFTs need to also infer the term
functions that are used to generate the output of each transition.
This implies that there might be more than one transition
from a state si to a state sj due to differences in the term
functions of each transition. This scenario never occurs in
the case of SFAs. Thus, the guardgen() algorithm on an
SFT inference algorithm should also employ a termgen()
algorithm which will work as a submodule of guardgen()
in order to generate the term functions for each transition and
possibly split a predicate guard into more.

Finally, we point out that in our implementation we utilized
a simple SFT learning algorithm which is a direct extension of
our RE ﬁlter learning algorithm in the sense that we generalize
the pair (predicate, term) with the most members to become
the sink transition for each state.

VI.

IMPLEMENTING AN EQUIVALENCE ORACLE

In practice a membership oracle is usually easy to obtain
as the only requirement is to be able to query the target ﬁlter
or sanitizer and inspect the output. However, simulating an
equivalence oracle is not trivial. A straightforward approach is
to perform random testing in order to ﬁnd a counterexample
and declare the machines equal if a counterexample is not
found after a number of queries. Although this is a feasible
approach,
it requires a very large number of membership
queries.

100100

Taking advantage of our setting, in this section we will
introduce an alternative approach where an equivalence oracle
is implemented using just a single membership query. To
illustrate our method consider a scenario where an auditor is
remotely testing a ﬁlter or a sanitizer. For that purpose the
auditor is in possession of a set of attack strings given as a
context free grammar (CFG).

The goal of the auditor is to either ﬁnd an attack-string
bypassing the ﬁlter or declare that no such string exists and
obtain a model of the ﬁlter for further analysis. In the latter
case, the auditor may work in a whitebox fashion and ﬁnd new
attack-strings bypassing the inferred ﬁlter, which can be used
to either obtain a counterexample and further reﬁne the model
of the ﬁlter or actually produce an attack. Since performing
whitebox testing on a ﬁlter is much easier than black-box,
even if no attack is found the auditor has obtained information
on the structure of the ﬁlter.

Formally, we deﬁne the problem of Grammar Oriented

Filter Auditing as follows:
Deﬁnition 9. In the grammar oriented ﬁlter auditing problem
(GOFA), the input is a context free grammar G and a mem-
bership oracle for a target DFA F . The goal is to ﬁnd s ∈ G,
such that s (cid:11)∈ F or determine that no such s exists.

One can easily prove that in the general case the GOFA
problem requires an exponential number of queries. Simply
consider the CFG L(G) = Σ
∗ and a DFA F such that
∗ \ {random-large-string}. Then, the problem re-
L(F ) = Σ
duces in guessing a random string which requires an exponen-
tial number of queries in the worst case. A formal proof of a
similar result was presented by Peled et al. [23].

Our algorithm for the GOFA problem uses a learning
algorithm for SFAs utilizing Algorithm 1 as an equivalence
oracle. The algorithm takes as input a hypothesis machine H. It
then ﬁnds a string s ∈ L(G) such that s (cid:11)∈ L(H). If the string
s is an attack against the target ﬁlter, the algorithm outputs
the attack-string and terminates. If it is not it returns the string
as a counterexample. On the other hand if there is no string
bypassing the hypothesis, the algorithm terminates accepting
the hypothesis automaton H. Note that,
this is the point
where we trade completeness for efﬁciency since, even though
L(G ∩ ¬H) = ∅, this does not imply that L(G ∩ ¬F ) = ∅.

Algorithm 1 GOFA Algorithm
Require: Context Free Grammar G, membership oracle O

function EQUIVALENCE ORACLE(H)

GA ← G ∩ ¬H
if L(GA) = ∅ then
return Done
else
s ← L(GA)
if O(s) = T rue then

return Counterexample, s

return Attack, s

else

end if

end if

end function

IDS RULES

DFA LEARNING

SFA LEARNING

ID

STATES

ARCS MEMBER

EQUIV MEMBER

EQUIV

SPEEDUP

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

7
16
25
33
52
60
66
70
86
115
135
139
146
164
179

13
35
33
38
155
113
82
99
123
175
339
964
380
191
658

4389
21720
56834
102169
193109
250014
378654
445949
665282
1150938
1077315
1670331
1539764
2417741
770237

3
3
6
7
6
7
14
15
27
31
24
29
28
29
14

118
763
6200
3499
37020
38821
35057
17133
34393
113102
433177
160488
157947
118611
80283

8
24
208
45
818
732
435
115
249
819
4595
959
1069
429
1408
AVG=

34.86
27.60
8.87
28.83
5.10
6.32
10.67
25.86
19.21
10.10
2.46
10.35
9.68
20.31
9.43
15.31

TABLE I.

SFA VS. DFA LEARNING

Fig. 6. Speedup of SFA vs. DFA learning.

Adaptation to sanitizers. The technique above can be
generilized easily to sanitizers. Assume that we are given a
grammar G as before and a target transducer T implementing
a sanitization function. In this variant of the problem we would
like to ﬁnd a string sA such that there exists s ∈ L(G) for
which sA[T ]s holds.

In order to determine whether such a string exists, we
ﬁrst construct a pushdown transducer TG with the following
property: A string s will reach a ﬁnal state in TG if and only
if s ∈ L(G). Moreover, every transition in TG is the identity
function, i.e. outputs the character consumed. Therefore, we
have a transducer which will generate only the strings in L(G).
Finally, given a hypothesis transducer H, we compute the
pushdown transducer H◦TG and check the resulting transducer
for emptiness. If the transducer is not empty we can obtain a
string sA such that sA[H ◦ TG]s. Since TG will generate only
strings from L(G) it follows that sA when passed through
the sanitizer will result in a string s ∈ L(G). Afterwards, the
GOFA algorithm continues as in the DFA case.

In appendix A, B we describe a comparison of the GOFA
algorithm with random testing as well as ways in which an
complete equivalence oracle may be implemented.

VII. EVALUATION

A. Implementation

We have implemented all the algorithms described in the
previous sections. In order to evaluate our DFA/SFA learn-
ing algorithms in the standard membership/equivalence query
model we implemented an equivalence oracle by computing

101101

DFA LEARNING

ID MEMBER

EQUIV

LEARNED MEMBER

SFA LEARNING

EQUIV

LEARNED

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

3203
18986
52373
90335
176539
227162
355458
420829
634518
1110346
944058
1645751
1482134
1993469
14586

2
2
5
5
4
5
12
13
25
29
19
28
26
24
5

AVG=

100.00%
100.00%
100.00%
96.97%
98.08%
96.67%
98.48%
98.57%
98.84%
99.13%
94.81%
100.00%
97.95%
90.85%
8.94%
91.95

81
521
1119
2155
4301
5959
8103
11013
15221
27972
100522
113714
45494
45973
428

5
11
7
10
38
32
17
34
30
54
955
662
143
32
22

AVG=

100.00%
100.00%
96.00%
96.97%
80.77%
96.67%
98.48%
98.57%
98.84%
99.13%
93.33%
96.40%
93.15%
90.85%
8.94%
89.87%

TABLE II.

SFA VS. DFA LEARNING + GOFA

SPEEDUP

37.27
35.69
46.52
41.73
40.69
37.92
43.78
38.10
41.61
39.62
9.30
14.39
32.48
43.33
32.42
35.66

Fig. 7. Speedup of SFA vs. DFA learning with GOFA.

the symmetric difference of each hypothesis automaton with
the target ﬁlter. In order to evaluate regular expression ﬁl-
ters we used the ﬂex regular expression parser to generate
a DFA from the regular expressions and then parsed the
code generated by ﬂex to extract the automaton. In order to
implement the GOFA algorithm we used the FAdo library [24]
to convert a CFG into Chomsky Normal Form(CNF) and
then we convert from CNF to a PDA. In order to compute
the intersection we implemented the product construction for
pushdown automata and then directly checked the emptiness
of the resulting language, without converting the PDA back to
CNF, using a dynamic programming algorithm [25]. In order
to convert the inferred models to BEK programs we used the
algorithm described in appendix C.

B. Testbed

Since our focus is on security related applications, in order
to evaluate our SFA learning and GOFA algorithms we looked
for state-of-the-art regular expression ﬁlters used in security
applications. We chose ﬁlters used by Mod-Security [26]
and PHPIDS [27] web application ﬁrewalls. These systems
contain well designed, complex regular expressions rulesets
that attempt to protect against vulnerability classes such as
SQL Injection and XSS, while minimizing the number of false
positives. For our evaluation we chose 15 different regular
expression ﬁlters from both systems targetting XSS and SQL
injection vulnerabilities. We chose the ﬁlter in a way that
they will cover a number of different sizes when they are
represented as DFAs. Indeed, our testbed contains ﬁlters with
sizes ranging from 7 to 179 states. Our sanitizer testbed is
described in detail in section VII-E. Finally, for testing our

102102

GOFA and ﬁlter ﬁngerprinting algorithms we also incorporated
two additional WAF implementations, Web Knight and Web
Castelum and Microsoft’s urlscan with a popular set of SQL
Injection rules [28]. For the evaluation of our SFA and DFA
learning algorithms we used an alphabet of 92 ASCII char-
acters. We believe that this is an alphabet size which is very
reasonable for our domain. It contains all printable characters
and in addition some non printable ones. Since many attacks
contain unicode characters we believe that alphabets will only
tend to grow larger as the attack and defense technologies
progress.

C. Evaluation of DFA/SFA Learning algorithms

We ﬁrst evaluate the performance of our SFA learning algo-
rithm using the L∗ algorithm as the baseline. We implemented
the algorithms as we described them in the paper using only
an additional optimization both in the DFA and SFA case: we
cached each query result both for membership and equivalence
queries. Therefore, whenever we count a new query we verify
that this query wasn’t asked before. In the case of equivalence
queries, we check that the automaton complies with all the
previous counterexamples before issuing a new equivalence
query.

In table I we present numerical results from our experi-
ments that reveal a signiﬁcant advantage for our SFA learning
over DFA: it is approximately 15 times faster on the average.
The speedup as the ratio between the DFA and the SFA number
of queries is showin in Figure 6. An interesting observation
here is that the speedup does not seem to be a simple function
of the size of the automaton and it possibly depends on many
aspects of the automaton. An important aspect is the size of the
sink transition in each state of the SFA. Since our algorithm
learns lazily the transitions, if the SFA incorporates many
transitions with large size, then the speedup will be less than
what it would be in SFAs were the sink transition is the only
one with big size.

D. Evaluation of GOFA algorithm

In this section we evaluate the efﬁciency of our GOFA
algorithm. In our evaluation we used both the DFA and the
SFA algorithms. Since our SFA algorithm uses signiﬁcantly
more equivalence queries than the L∗ algorithm, we need to
evaluate whether this additional queries would inﬂuence the
accuracy of the GOFA algorithm. Speciﬁcally, we would like
to answer the following questions:

1)

2)

How good is the model inferred by the GOFA algo-
rithm when no attack string exists in the input CFG?
Is the GOFA algorithm able to detect a vulnerability
in the target ﬁlter if one exists in the input CFG?

Making an objective evaluation on the effectiveness of the
GOFA algorithm in these two questions is tricky due to the
fact that the performance of the algorithm depends largely on
the input grammar provided by the user. If the grammar is too
expressive then a bypass will be trivially found. On the other
hand if no bypass exists and moreover, the grammar represents
a very small set of strings, then the algorithm is condemned
to make a very inaccurate model of the target ﬁlter. Next, we
tackle the problem of evaluating the two questions about the
algorithm separetely.

DFA model generation evaluation. Intuitevely, the GOFA
algorithm is efﬁcient in recovering a model for the target ﬁlter
if the algorithm is in possesion of the necessary information
in order to recover the ﬁlter in the input CFG and is able to do
so. Therefore, in order to evaluate experimentally the accuracy
of our algorithm in producing a correct model for the target
ﬁlter independently of the choice of the grammar we used as
input grammar the target ﬁlter itself. This choice is justiﬁed
as setting as input grammar the target ﬁlter itself we have
that a grammar that, intuitively, is a maximal set without any
vulnerability.

In table II we present the numerical results of our exper-
iments over the same set of ﬁlters used in the experiments
of Section VII-C. The learning percentage of both DFA and
SFA with simulated equivalence oracle via GOFA is quite high
(close to 90% for both cases). The performance beneﬁt from
our SFA learning is even more dramatic in this case reaching
an average of ≈ 35 times faster than DFA. The speedup is
also pictorially presented in Figure 7. We also point out the
even though the DFA algorithm checks all transitions of the
automaton explicitily (which is the main source of overhead),
the loss in accuracy between the L∗ algorithm and our SFA
algorithm is only 2%, for a speedup gain of approximately
x35.

Vulnerability detection evaluation. In evaluating the vul-
nerability detection capabilities of our GOFA algorithm we ran
into the same problem as with the model generation evaluation;
namely, the efﬁciency of the algorithm depends largely on
the input grammar given by the user. If the grammar is more
expressive than the targeted ﬁlter then a bypass can be trivially
found. On the other hand if it is too restrictive maybe no bypass
will exist at all.

For our evaluation we targetted SQL Injection vulnerabil-
ities. In our ﬁrst experiment we utilized ﬁve well known web
application ﬁrewalls and used as an input grammar an SQL
grammar from the yaxx project [29]. In this experiment the
input ﬁlter was running on live ﬁrewall installations rather
than on the extracted rules. We checked whether there were
valid SQL statements that one could pass through the web
application ﬁrewalls.

The results of this experiment can be found in table IV. We
found that in all cases a user can craft a valid SQL statement
that will bypass the rules of all ﬁve ﬁrewalls. For the ﬁrst
4 products where more complex rules are used the simple
statement “open a” is not ﬂagged as malicious. This statement
allows the execution of statements saved in the database system
before using a “DECLARE CURSOR” statement. Thus, these
attacks could be part of an attack which reexecutes a statement
already in the database in a return oriented programming
manner.

The open statement was ﬂagged malicious by urlscan, in
which case GOFA succesfully detected that and found an
alternative vector, “replace”. We also notice, that using GOFA
with the SFA learning algorithm makes a minimum number
of queries since our SFA algorithm adds new edges to the
automaton only lazily to update the previous models, thus
making GOFA a compelling option to use in practice.

against the composition of two rules targetting SQL Injection
attacks from PHPIDS. In order to achieve that we started with
a small grammar which contains the combination of some
attack vectors and, whenever a vector is identiﬁed bypassing
the ﬁlter, we remove the vector from the grammar and rerun
it with a smaller grammar until no attack is possible. Here
we would like to ﬁnd out whether the GOFA algorithm can
operate under restricted grammars that require many updates
on the hypothesis automaton. The succssive vectors we used
as input grammar can be found in full version of the paper.
The results of the experiment can be found in table IV. To
check whether a vulnerability exists in the ﬁlter we computed
the symmetric difference between the input grammar and the
targetted ﬁlters. We note that this step is the reason we did not
perform the same experiment on live WAF installations, since
we do not have the full speciﬁcation as a regular expression
and thus cannot check if a bypass exists in an attack grammar.
We notice that in this case as well, GOFA was succesfull
in updating the attack vectors in order to generate new attacks
bypassing the ﬁlter. However, in this case the GOFA algorithm
generated as many as 61 states of the ﬁlter in the DFA case
and 31 states in the SFA case until a succesfull attack vector
was detected. Against we notice that the speedup of using the
SFA algorithm is huge.

To conclude with the evaluation of the GOFA algorithm,
although as we already discussed in section VI, the GOFA
algorithm is necessarily either incomplete or inefﬁcient
in
the worst case, it performs well in practice detecting both
vulnerabilities when they exist and inferring a large part of
the targetted ﬁlter when it is not able to detect a vulnerability.

E. Cross Checking HTML Encoder implementations

To demonstrate the wide applicability of our sanitizer
inference algorithms we reconsider the experiment performed
in the original BEK paper [8]. The authors, payed a number of
freelancer developers to develop HTML encoders. Then they
took these HTML encoders, along with some other existing im-
plementations and manually converted them to BEK programs.
Then, using BEK the authors were able to ﬁnd differences in
the sanitizers and check properties such as idempotence.

Using our learning algorithms we are able to perform a
similar experiment but this time completely automated and in
fact, without any access to source code of the implementation.
For our experiments we used 3 different encoders from the
PHP language, the HTML encoder from the .net AntiXSS
library [30] and then, we also inferred models for the HTML
encoders used by Twitter, Facebook and Microsoft Outlook
email service.

We used our transducer learning algorithms in order to infer
models for each of the sanitizers which we then converted to
BEK programs and checked for equivalence and idempotence
using the BEK infrastrucure. A function f is idempotent if ∀x,
f (x) = f (f (x)) or in other words, reapplying the sanitizer to a
string which was already sanitized won’t change the resulting
string. This is a nice property for sanitizers because it means
that we easily reapply sanitization without worrying about
breaking the correct semantics of the input string.

In the second experiment we performed we tested what
will happen if we have a much more constrained grammar

In our algorithm, we used a simple form of symbolic
transducer learning, as sketched in section V-C, where we gen-

103103

GRAMMAR

DFA LEARNING

SFA LEARNING

VULNERABILITY

ID

STATES

ARCS

FOUND STATES MEMBERSHIP

EQUIVALENCE

FOUND STATES MEMBERSHIP

EQUIVALENCE

SPEEDUP

EXISTS

FOUND

1

2

3

4

128

111

92

43

175

146

120

54

61

61

61

61

155765

155765

155765

155764

3

3

3

3

31

31

31

31

1856

1811

1793

1770

8

7

6

7

AVG=

83.56

85.68

86.58

87.65
85.87

TRUE

TRUE

TRUE

FALSE

union select
load_file(’0\0\0’)
union select 0 into outfile
’0\0\0’
union select case when
(select user_name()) then 0
else 1 end
None

TABLE III.

BYPASSES DETECTED BY SUCCESIVELY REDUCING THE ATTACK GRAMMAR SIZE FOR RE RULES PHPIDS 76 & 52 COMPOSED

WAF

Target

DFA LEARNING

SFA LEARNING

VULNERABILITY

FOUND STATES MEMBERSHIP

EQUIVALENCE

FOUND STATES MEMBERSHIP

EQUIVALENCE

SPEEDUP

EXISTS

FOUND

PHPIDS 0.7

MODSECURITY 2.2.9
WEBCASTELLUM 1.8.3

WEBKNIGHT 4.2

URLSCAN Common Rules

2
1
1
1
4

186
186
94
94
1835

1
1
1
1
2

0
0
0
0
5

3
3
3
3
40

1
1
1
1
2

AVG=

46.75
46.75
23.75
23.75
43.73
36.94

TRUE
TRUE
TRUE
TRUE
TRUE

open a
open a
open a
open a

rollback work

TABLE IV.

RUNNING THE GOFA ALGORITHM WITH AN SQL GRAMMAR ON COMMON WEB APPLICATIONS FIREWALLS

eralized the most commonly seen output term to all alphabet
members not explicitily checked.

As an alphabet, we used a subset of characters including
standard characters that should be encoded under the HTML
stnadard and moreover, a set of other characters, including
unicode characters, to provide completeness against different
implementations. For the simulation of the equivalence oracle
we produced random strings from a predeﬁned grammar
including all the characters of the alphabet and in addition
many encoded HTML character sequences. The last part is
important for detecting if the encoder is idempotent.

Figure 8 shows the results of our experiment. We found
that most sanitizers are different and only one sanitizer is
idempotent. All the entries of the ﬁgure represent the character
or string that the two sanitizers are different or a tick if they are
equal. One exception is the entries labelled with u8249 which
denotes the unicode character with decimal representation
&#8249;. We included the decimal representation in the table
to avoid confusion with the “<” symbol. The idempotent
sanitizer is a version of htmlspecialcharacters func-
tion with a special ﬂag disabled, that instructs the function
not to rencode already encoded html entities. We would like
to point out that although in general html encoders can be
represented by single state transducers, making the encoder
idempotent requires a large amount of lookahead symbols
to detect whether the current character is part of an already
encoded HTML entity.

Another suprising result is that the .net HTML encode
function did not match the one in the MS Outlook email
service. The encoder in the outlook email seems to match an
older encoder of the AntiXSS library which was encoding all
HTML entities in their decimal representations. For example,
this encoder is the only one encoding the semicolon symbol.
On the other hand the .net AntiXSS implementation will
encode unicode characters in their decimal representations but
will skip encoding the semicolon, as did every other sanitizer
that we tested.

At this point, we would like to stress that our results are not

PHP2
PHP3
u8249 &amp;
u8249





PHP1



PHP1
PHP2
PHP3
.NET
TW
FB
MS

FB


TW


.NET
u8429
u8294
u8429
&amp; &amp; &amp;
u8429

u8429



u8429






MS
;
;
;
;
;
;


Idempotent









Fig. 8. Equivalence Checking of HTML encoder implementations.

conclusive. For example, the fact that we found that the twitter
and facebook encoders are equal does not mean that there is no
string in which the two sanitizers differ. This is fundamental
limitation of all black-box testing algorithms. In fact, even the
results on differences between sanitizers might be incorrect
in principle. However, in this case we can easily verify the
differences and, if necessary, update the corresponding models
for the encoders.

VIII. RELATED WORK

Our work is mainly motivated by recent advances in
the analysis of sanitizers and regular expressions, a line of
work which was initiated with the introduction of symbolic
automata [11], although similar constructions were suggested
much earlier [31]. The BEK language was introduced by
Hooimeijer et al. [8] and the theory behind symbolic ﬁnite
state transducers was extended in a follow up paper [15].
Symbolic automata, transducers and the BEK language is a
very active area of research [14], [32]–[35] and we expect that
BEK programs will get more widespread adoption in the near
future. In the inference of symbolic automata and transducers
there are two relevant recent works. Botincan and Babic [36]
used symbolic execution in combination with the Shabaz-Groz
algorithm in order to infer symbolic models of programs as
symbolic lookback transducers. Although the authors claim
that equivalence of symbolic lookback transducers(SLT) is
decidable a paper published recently by Veanes [37] shows
that equivalence of SLTs is in fact undecidable. Moreover,
although [36] implements a symbolic version of Angluin’s
algorithm, in their system the predicates are obtained through

104104

symbolic execution, and therefore, there is no need to infer
the predicate guards or infer the correct transitions for each
state. Since their system is using the Shabaz-Groz algorithm,
our improved counterexample processing would provide an
exponentially faster way to handle counterexamples in their
case too.

The second closely related work in the inference of sym-
bolic automata was done by Maller and Mens [22].They
describe an algorithm to infer automata over ordered alpha-
bets which is a speciﬁc instantiation of symbolic automata.
However, in order to correctly infer such an automaton the
authors assume that the counterexample given by the equiv-
alence oracle is of minimal length and this assumption is
used in order to distinguish between a wrong transition in the
hypothesis or a hidden state. Unfortunately, verifying that a
counterexample is minimal requires an exponential number of
queries and thus this assumption does not lead to a practical
algorithm for inferring symbolic automata. On the other hand,
our algorithm is more general, as it works for any kind of
predicate guards as long as they are learnable, and moreover
does not assume a minimal length counterexample making the
algorithm practical.

The work on active learning of DFAs was initiated by An-
gluin [19] after a negative result of Gold [38] who showed that
it is NP-Hard to infer the minimal automaton consistent with
a set of samples. After its introduction, Anlguin’s algorithm
was improved and many variatons were introduced; Rivest and
Schapire [20] showed how to improve the query complexity
of the algorithm and introduced the binary search method for
processing counterexamples. Balcazar et al. [39] describe a
general approach to view the different variations of Angluin’s
algorithm.

Shabaz and Groz [12] extended Angluin’s algorithm to
handle Mealy Machines and introduced the counterexamlpe
processing we discussed above. Their approach was then
extended by Khalili and Tacchella [40] to handle non deter-
ministic Mealy Machines. However, as we point out above
mealy machines in general are not expressive enough to model
complex sanitization functions. Moreover, the algorithm by
Khalili and Tacchella uses the Shabaz-Groz counterexample
processing thus it can be improved using our method. Since
Shabaz-Groz is used in many contexts including the reverse en-
gineering of Command and Control servers of botnets [41], we
believe that our improved counterexample processing method
will ﬁnd many applications. Lately, inference techniques were
developed for more complex classes of automata such as
register automata [42]. These automata are allowed to use a
ﬁnite number of registers [43]. Since registers were also used
in some case during the analysis of sanitizer functions [15], and
speciﬁcally decoders, we believe that expanding our work to
handle register versions of symbolic automata and transducers
is a very interesting direction for future work.

The implementation of our equivalence oracle is inspired
by the work of Peled et al. [23]. In their work, a similar
equivalence oracle implementation is described for checking
Buichi automata, however, their implentation also utilizes the
Vasileski-Chow algorithm [44], an algorithm for checking
compliance of two automata, given an upper bound on the
size of the black-box automaton. This algorithm however,
has a worst case exponential complexity a fact which makes

it inpractical for real applications. On the other hand, we
demonstrate that our GOFA algorithm is able to infer 90%
of the states of the target ﬁlter on average.

The algorithm for initializing the observation table was ﬁrst
described by Groce et al. [45]. In their paper they describe
the initialization procedure and prove two lemmas regarding
the efﬁciency of the procedure in the context of their model
checking algorithm. However, the lemma proved just shows
convergence and they are not concerned with the reduction of
equivalence queries as we prove.

There is a large body of work regarding whitebox pro-
gram analysis techniques that aim at validating the security
of sanitizer code. The SANER [4] project uses static and
dynamic analysis to create ﬁnite state transducers which are
overapproximations of the sanitizer functions of programs.
Minamide [5] constructs a string analyzer for PHP which
is used to detect vulnerabilities such as cross site scripting.
He also describes a classiﬁcation of various PHP functions
according to the automaton model needed to describe them.
The Reggae system [6] attempts to generate high coverage test
cases with symbolic execution for systems that use complex
regular expressions. Wasserman and Su [7] utilize Context free
grammars to construct overapproximations of the output of
a web application. Their approach could be used in order
to implement a grammar which can then be used as an
equivalence oracle when applying the cross checking algorithm
for verifying equality between two different implementations.

IX. CONCLUSIONS AND FUTURE WORK

Clearly, we are light of need for robust and complete black-
box analysis algorithms for ﬁlter programs. In this paper we
presented a ﬁrst set of algorithms which could be utilized to
analyze such programs. However, the space for research in this
area is still vast. We believe that our algorithms can be further
tuned in order to achieve an even larger performance increase.
Moreover, more complex automata model which are currently
being used [14], [43] can be also utilized to further reduce the
number of queries required to infer a sanitizer model. Finally,
we point out that totally different models might be necessary
to handle other types of ﬁlters programs which are based on
big data analytics or on the analysis of network protocols.
Thus, to conclude we believe that black-box analysis of ﬁlters
and sanitizers presents a fruitful research area which deserves
more attention due to both scientiﬁc interest and practical
applications.

ACKNOWLEDGEMENTS

This work was supported by the Ofﬁce of Naval Research
(ONR) through contract N00014-12-1-0166. Any opinions,
ﬁndings, conclusions, or recommendations expressed herein
are those of the authors, and do not necessarily reﬂect those
of the US Government or ONR.

REFERENCES

[1] D. L. Eduardo Vela, “Our favorite xss ﬁlters/ids and how to attack

them,” in Black Hat Brieﬁngs, 2009.

[2] D. Evteev, “Methods to bypass a web application methods to
bypass a web application ﬁrewall.” http://ptsecurity.com/download/
PT-devteev-CC-WAF-ENG.pdf.

105105

[3] S. Esser, “Web application ﬁrewall bypasses and php exploits
http://www.suspekt.org/downloads/

-rss‘09
RSS09-WebApplicationFirewallBypassesAndPHPExploits.pdf.

november

2009.”

[4] D. Balzarotti, M. Cova, V. Felmetsger, N. Jovanovic, E. Kirda,
C. Kruegel, and G. Vigna, “Saner: Composing static and dynamic
analysis to validate sanitization in web applications,” in Security and
Privacy, 2008. SP 2008. IEEE Symposium on, pp. 387–401, IEEE, 2008.
[5] Y. Minamide, “Static approximation of dynamically generated web
pages,” in Proceedings of the 14th international conference on World
Wide Web, pp. 432–441, ACM, 2005.

[6] N. Li, T. Xie, N. Tillmann, J. de Halleux, and W. Schulte, “Reg-
gae: Automated test generation for programs using complex regular
expressions,” in Automated Software Engineering, 2009. ASE’09. 24th
IEEE/ACM International Conference on, pp. 515–519, IEEE, 2009.

[7] G. Wassermann and Z. Su, “Sound and precise analysis of web
applications for injection vulnerabilities,” in ACM Sigplan Notices,
vol. 42, pp. 32–41, ACM, 2007.

[8] P. Hooimeijer, P. Saxena, B. Livshits, M. Veanes, and D. Molnar, “Fast
and precise sanitizer analysis with bek,” in In 20th USENIX Security
Symposium, 2011.

[9] D. Bates, A. Barth, and C. Jackson, “Regular expressions considered
harmful in client-side xss ﬁlters,” in Proceedings of the 19th interna-
tional conference on World wide web, pp. 91–100, ACM, 2010.
“Programming
https://en.wikipedia.org/wiki/Programming languages used in most
popular websites. Accessed: 2015-11-10.

popular websites.”

languages

in most

used

[10]

[11] M. Veanes, P. d. Halleux, and N. Tillmann, “Rex: Symbolic regular
expression explorer,” in Proceedings of the 2010 Third International
Conference on Software Testing, Veriﬁcation and Validation, ICST ’10,
(Washington, DC, USA), pp. 498–507, IEEE Computer Society, 2010.
[12] M. Shahbaz and R. Groz, “Inferring mealy machines,” in Proceedings
of the 2Nd World Congress on Formal Methods, FM ’09, (Berlin,
Heidelberg), pp. 207–222, Springer-Verlag, 2009.

[13] A. Doup´e, L. Cavedon, C. Kruegel, and G. Vigna, “Enemy of the
state: A state-aware black-box web vulnerability scanner.,” in USENIX
Security Symposium, pp. 523–538, 2012.

[14] M. Veanes, T. Mytkowicz, D. Molnar, and B. Livshits, “Data-parallel
string-manipulating programs,” in Proceedings of
the 42nd Annual
ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages, pp. 139–152, ACM, 2015.

[15] N. Bjorner, P. Hooimeijer, B. Livshits, D. Molnar, and M. Veanes,
“Symbolic ﬁnite state transducers, algorithms, and applications,” in IN:
PROC. 39TH ACM SYMPOSIUM ON POPL., 2012.

[16] M. Veanes, P. De Halleux, and N. Tillmann, “Rex: Symbolic regular
expression explorer,” in Software Testing, Veriﬁcation and Validation
(ICST), 2010 Third International Conference on, pp. 498–507, IEEE,
2010.
J. Hopcroft, “An n log n algorithm for minimizing states in a ﬁnite
automaton,” tech. rep., DTIC Document, 1971.

[17]

[18] M. J. Kearns and U. V. Vazirani, An introduction to computational

learning theory. MIT press, 1994.

[19] D. Angluin, “Learning regular sets from queries and counterexamples,”

Information and computation, vol. 75, no. 2, pp. 87–106, 1987.

[20] R. L. Rivest and R. E. Schapire, “Inference of ﬁnite automata using
homing sequences,” Information and Computation, vol. 103, no. 2,
pp. 299–347, 1993.
J. E. Hopcroft, Introduction to automata theory, languages, and com-
putation. Pearson Education India, 1979.

[21]

[22] O. Maler and I.-E. Mens, “Learning regular languages over large
alphabets,” in Tools and Algorithms for the Construction and Analysis
of Systems, pp. 485–499, Springer, 2014.

[23] D. Peled, M. Y. Vardi, and M. Yannakakis, “Black box checking,” in
Formal Methods for Protocol Engineering and Distributed Systems,
pp. 225–240, Springer, 1999.
“Fado library.” https://pypi.python.org/pypi/FAdo. Accessed: 2015-11-
10.

[24]

[25] A. Carayol and M. Hague, “Saturation algorithms for model-checking

pushdown systems,” EPTCS, vol. 151, pp. 1–24, 2014.
“Mod-security.” https://www.modsecurity.org/. Accessed: 2015-11-10.

[26]

[27]

[28]

[29]

[30]

“Phpids source code.” https://github.com/PHPIDS/PHPIDS. Accessed:
2015-11-10.
“How to conﬁgure urlscan 3.0 to mitigate sql injection attacks.” http:
//goo.gl/cmU0ze. Accessed: 2015-11-10.
“Yaxx project.” https://code.google.com/p/yaxx/. Accessed: 2015-11-
10.
“Microsoft antixss library.” https://msdn.microsoft.com/en-us/security/
aa973814.aspx. Accessed: 2015-11-10.

[31] B. W. Watson, “Implementing and using ﬁnite automata toolkits,”

Natural Language Engineering, vol. 2, no. 04, pp. 295–302, 1996.

[32] L. D’Antoni and M. Veanes, “Minimization of symbolic automata,” in

ACM SIGPLAN Notices, vol. 49, pp. 541–553, ACM, 2014.

[33] L. DAntoni and M. Veanes, “Equivalence of extended symbolic ﬁnite
transducers,” in Computer Aided Veriﬁcation, pp. 624–639, Springer,
2013.

[34] M. Veanes, “Symbolic string transformations with regular lookahead
and rollback,” in Perspectives of System Informatics, pp. 335–350,
Springer, 2014.

[35] R. A. Cochran, L. D’Antoni, B. Livshits, D. Molnar, and M. Veanes,
“Program boosting: Program synthesis via crowd-sourcing,” in ACM
SIGPLAN Notices, vol. 50, pp. 677–688, ACM, 2015.

[36] M. Botinˇcan and D. Babi´c, “Sigma*: symbolic learning of input-output
speciﬁcations,” ACM SIGPLAN Notices, vol. 48, no. 1, pp. 443–456,
2013.

[37] L. DAntoni and M. Veanes, “Extended symbolic ﬁnite automata and

transducers,” Formal Methods in System Design, July 2015.

[39]

[38] E. M. Gold, “Complexity of automaton identiﬁcation from given data,”

Information and control, vol. 37, no. 3, pp. 302–320, 1978.
J. L. Balc´azar, J. D´ıaz, R. Gavalda, and O. Watanabe, Algorithms for
learning ﬁnite automata from queries: A uniﬁed view. Springer, 1997.
[40] A. Khalili and A. Tacchella, “Learning nondeterministic mealy ma-
chines,” in Proceedings of the 12th International Conference on Gram-
matical Inference, ICGI 2014, Kyoto, Japan, September 17-19, 2014.,
pp. 109–123, 2014.

[41] C. Y. Cho, D. Babic, E. C. R. Shin, and D. Song, “Inference and
analysis of formal models of botnet command and control protocols,”
in Proceedings of the 17th ACM Conference on Computer and Com-
munications Security, CCS 2010, Chicago, Illinois, USA, October 4-8,
2010, pp. 426–439, 2010.

[42] F. Howar, B. Steffen, B. Jonsson, and S. Cassel, “Inferring canonical
register automata,” in Veriﬁcation, Model Checking, and Abstract Inter-
pretation, pp. 251–266, Springer, 2012.

[43] S. Cassel, F. Howar, B. Jonsson, M. Merten, and B. Steffen, “A succinct
canonical register automaton model,” Journal of Logical and Algebraic
Methods in Programming, vol. 84, no. 1, pp. 54–66, 2015.

[44] T. S. Chow, “Testing software design modeled by ﬁnite-state machines,”
IEEE transactions on software engineering, no. 3, pp. 178–187, 1978.
[45] A. Groce, D. Peled, and M. Yannakakis, “Adaptive model checking,”
in Tools and Algorithms for the Construction and Analysis of Systems,
pp. 357–370, Springer, 2002.
“Xss
Evasion Cheat Sheet. Accessed: 2016-01-10.

https://www.owasp.org/index.php/XSS Filter

sheet.”

cheat

[46]

[47] L. Pitt and M. K. Warmuth, “The minimum consistent dfa problem
cannot be approximated within any polynomial,” Journal of the ACM
(JACM), vol. 40, no. 1, pp. 95–142, 1993.
“Bek guide.” http://www.rise4fun.com/Bek/tutorial/guide2. Accessed:
2015-11-10.

[48]

[49] Y. Freund and R. E. Schapire, “Large margin classiﬁcation using the
perceptron algorithm,” Mach. Learn., vol. 37, pp. 277–296, Dec. 1999.

APPENDIX

A. Comparison of GOFA algorith with random testing

Regarding the usefulness of GOFA algorithm as a security
auditing method it is important to consider it in comparison
to random testing/fuzzing. Currently, most tools in the black-
box testing domain, such as web vulnerability scanners, work

106106

by fuzzing the target ﬁlter with various attack strings until a
bypass is found or the set of attack strings is exhausted.

We argue that our GOFA algorithm is superior to fuzzing

for two reasons:

program name(input){

return iter(c in input)[registers]
{cases}end{cases};

}

1)

2)

the size of

The number of queries of the GOFA algorithm is
the grammar. On the
independent of
other hand, when producing random strings from a
grammar in order to test a ﬁlter a very large number
of strings has to be produced. Moreover, testing for
modern vulnerabilities such as XSS is very complex,
since there is a large number of variations that one
should consider(cf. [46]).
Random testing produces no information on the struc-
ture of the ﬁlter if no attack is found. Consider the
case where one produces a large number of candidate
attack strings, but no bypass is found. Then, the audi-
tor is left with no additional information for the ﬁlter,
other than it rejected the set of strings that was tested.
One approach would be to try to infer the structure of
an automaton from that set of strings. Unfortunately,
inferring the minimal automaton which is consistent
with a set of strings is NP-Hard to approximate even
within any polynomial factor [47]. On the other hand,
as we demonstrate our GOFA algorithm is able to
recover on average 90% of the states of the target
ﬁlter in cases where no attack exists and an expressive
enough grammar is given as input.

B. Approximating a Complete Equivalence Oracle

Although the GOFA algorithm is a suitable equivalence
oracle implementation in the case the goal is to audit a target
ﬁlter, in some cases one would like to recover a complete
model of the target ﬁlter/sanitizer. In such cases, ﬁnding a
bypass is not enough. Since we only assume black-box access
to the target ﬁlter, in order for this problem to be even solvable
we have to assume an upper bound on the size of the target
ﬁlter. In this case, The Vasilevskii-Chow(VC) algorithm [44]
exists for checking compliance between a DFA and a target
automaton given black-box access to the second.

However, if the DFA at hand has n states and the upper
bound given is m then the VC algorithm is exponential
in m − n. Moreover, the algorithm suffers from the same
limitations in the alphabet size as DFA learning algorithms
since every possible transition of the black-box automaton
must be checked. Creating a symbolic version of the VC
algorithm may be possible however, we will again only get
probabilistic guarantees on the correctness of our equivalence
oracle.

Another option is to construct a context free grammar
describing the input protocol under which the sanitizer should
operate and then use random sampling from that grammar
to test whether the hypothesis and the target programs are
complying. For example, when we test HTML Encoders we
might want to construct a grammar with a number of different
character sequences such as encoded HTML entities or special
characters and test the behavior of the encoder under these
strings. We employ this approach in our experiments.Finally,
static analysis techniques [7] can be used to generate a CFG
describing the output of another implementation of the same

Fig. 9. General structure of a BEK program.

sanitizer or ﬁlter and then cross check the generated CFG with
the target sanitizer using our ﬁngerprint algorithm.

C. Converting Transducers to BEK Programs

In this section we will describe our algorithm to convert
ﬁnite state transducers into BEK programs. The assumptions
we have is that the transducers given to our algorithm are
single-valued transducers with bounded lookahead and domain
∗. Due to lack of space, we won’t describe here the full
Σ
speciﬁcation of the BEK language. We urge the interested
reader to refer to the original BEK paper [8] as well as to
the online tutorial [48].

Figure 9 presents the general template of a BEK program.
In a nutshell
the BEK language allows one to deﬁne an
iterator over the input string. In addition, a predeﬁned number
of registers taking integer values can be used. Inside the
iterator loop an outer switch-case statement is placed, with
guards deﬁned by the programmer. Inside each case loop the
programmer is allowed to place an if-then-else statement with
an arbitrary number of else-if statements and a ﬁnal else
statement. In order to produce an output symbol the yield
statement is used, which can also produce multiple output
symbols. After the main iteration over the input is over, a BEK
program can have a ﬁnal series of case statements which will
be evaluated over the register variables deﬁned on the program
after exiting the input iteration. We call these statements the
end part of the iterator.

The overall construction is straightforward in the case the
transducer is determinstic: We deﬁne a register s which at
each point of the computation holds the current state of the
transducer. The outer case loop of the program checks the
state number while, an internal if-then-else chain matches the
current input character and afterwards, sets the next state and
yields the corresponding symbol of the transition, if any.

Unfortunately, when a bounded lookahead is present a
more complicated situtation arises, because the BEK language
cannot process more than one input characters at each iteration.
Thus, the program needs to manually store a buffer and keep
track of all the alternative states the transducer might be in
until a lookahead is matched or discarded.

In fact, as we demonstrate in appendix E, this complexity
can easily lead to errors in BEK programs. Indeed, we found
a problem in an HTML decoder program which was given
as an example in the BEK tutorial. The problem occured
because the BEK program was not taking into account all
possibilities when a lookahead string was partially matched
and then discarded.

The overall structure of a BEK program with lookahead
transitions is similar with the basic structure. However, we add

107107

additional guards in all states that can be part of a lookahead
transition as follows:

Consider each path starting in a ﬁnal state qsrc and ending
in a ﬁnal state qdst through a path of non ﬁnal states, while
consuming an input string r, |r| = k and generating an output
o. In other words this path is a lookahead transition which
consumes the input string r and produces the string o. Then
we perform the following:

1)

2)

3)

For each preﬁx of r, ri for all i < k compute the set
of states Si which are accesible from state qsrc with
the string ri. Since the transducer is single-valued
this set contains exactly one ﬁnal state. The set Si
of accesible states can be easily computed using a
BFS search. Moreover, let oi be the output of the
transducer on string ri from state qsrc. We save for
each preﬁx i the triple (ri, oi, Si).
Let si be the non ﬁnal state reached by ri if the sufﬁx
following ri is the remaining symbols of r. Then,
for every state s ∈ Si add inside the case statement
containing the guards of si the guards of each s ∈ S
ordered in a way such that the unique ﬁnal state in
Si is checked last.
In the end part of the iterator, add for each preﬁx i
a case guard asserting that if the computation ended
in state si then the program must yield the string oi.
These statements handle the case where the input is
ﬁnished while processing a lookahead transition.

As soon as we add these additional guards for every lookahead
transition the BEK program is completed.

D. Decision trees as SFA

Although are main focus in developing a learning algorithm
for SFAs lies in the inference of regular expression ﬁlters,
SFAs is a very general computation model which allow us to
represent various data structures. In ﬁgure 10 we show the
representation of a decision tree over the real numbers, as a
SFA. The predicate family here is the set of linear inequalities
of one variable over the real numbers. If we restrict
the
alphabet Σ to an, inﬁnite, subset of the real numbers such
that maxw∈Σ |w| = R and moreover, there is a margin γ for
every predicate guard 3, then, predicate guards of size k will be
O(kR2/γ2)-learnable [49] and thus the overall decision tree
can be efﬁciently inferred using our algorithm.

E. Bug in BEK HTML Decoder Example

While developing and debugging our implementation we
found a bug in an example implementation of a simpliﬁed
HTML decoder in the online BEK tutorial. The program in
question is the program named decode from the second part
of the BEK tutorial [48]. We won’t present the whole program
here due to space constraints, but the problem occurs in the
following case:

case (s == 1) :

//memorized &

if (c == ’&’) { yield (’&’); }
else if (c == ’l’) { s := 2; }

| (cid:2)

3A margin γ for a linear inequality
i aiχi + θ| > γ

(cid:2)

i aiχi ≥ θ means that, for all (cid:7)χ ∈ Σ

x < λ1

q2

q0

x ≥ λ1

q1

x < λ2

true

q3

true

x ≥ λ2

q4

true

Fig. 10. SFA model for a decision tree over the reals.

else if (c == ’g’) { s := 3; }
else { yield (’&’,c); s := 0; }

Here, as the comments suggests, the transducer has already
processed the letter “&” and checks if any of the letter “l”
or “t” follows which would complete the html entities “&lt;”
or “&gt;”. In the opposite case that no match with these two
characters is found, the memorized symbol is being added to
the output along with the current symbol. Unfortunately, if the
new character is also part of an HTML entity, for example “&”,
then the program will fail to start scanning for the next symbols
of the entity, rather it will just output the same character
and return to initial state. Therefore, the program will fail to
correctly decode sequences such as “&&lt;”.

We detected this bug during the development of our
lookahead learning algorithm and our conversion algorithm to
BEK programs. Speciﬁcally, we coded an HTML decoder like
the decode BEK program and used the equivalence checking
function of BEK in order to check whether the inferred BEK
programs we were producing were correct. At some point,
we detected the bug we described as a counterexample to the
equivalence of the two implementations.

We believe that this bug demonstrates the complexity of
writing sanitizers that make heavy use of lookahead transitions
in BEK. One should implement a large number of nested
if-then-else statements, like we describe in our conversion
algorithm in section VII-E. We believe that the BEK language
could become much simpler with the introduction of a string
compare function to allow the programmers to easily handle
lookaheads. This may require extra work on the backend of
the BEK compiler, however we believe that this is a feasible
task, that will greatly simplify the language.

F. Proofs of Theorems and Lemmas

Proof: (of Theorem 1) We need to show that the algorithm
does progress towards the discovery of a correct hypothesis.
Recall that the algorithm starts with an SOT that is closed and
reduced. Each time the algorithm has an SOT that satisﬁes
these properties an equivalence query is issued resulting either
in termination or in a counterexample. Processing the coun-
terexample will require O(log m + n) membership queries.
The counterexample will either make the SOT not closed
(in which case a new state is introduced) or it will lead to
b in Λ. A pair of access
the introduction of an element si0

108108

addition of certain lookahead transitions in the list L with the
respective columns in the observation table. Now it is easy to
notice that the SG counterexample processing method will add
a distinguishing sufﬁx if the counterexample is due to a hidden
state while the preﬁx-closed queries will detect and process
any undiscovered lookahead transition, thus the algorithm will
eventually terminate with a correct hypothesis.

Regarding the complexity of the algorithm, notice that the
algorithm will issue a preﬁx-closed query only in order to ﬁll
certain entries in the observation table. Therefore, it sufﬁces to
bound the size of the rows and columns of the table. The rows
of the table remain the same as in the Shabaz-Groz algorithm
and therefore, we have at most (|Σ| + 1)n rows. The table
is initialized with |Σ| columns corresponding to each symbol
of the alphabet. A column is added either when we process
a counterexample due to a hidden state or an undiscovered
lookahead transition. We distinguish between the two cases:

–

–

In case the counterexample is due to a hidden state,
then at most m columns are added. Since there are at
most n counterexamples due to hidden states the total
number of columns added can be at most mn.
In case the counterexample is due to an undiscovered
lookahead transition, we notice that the length of the
path can be at most n, since we have a bounded
lookahead, and therefore at most n columns will be
added. Thus, since there is a total of k lookahead
transitions at most kn columns will be added.

We notice that each preﬁx-closed membership query can be
implemented with at most n+max{n, m} membership queries,
since the longest column is of length max{n, m} and the
longest row is of length n. Finally, since a counterexample will
be either due to a hidden state or an undiscovered lookahead
transition it follows that we can have at most n+k equivalence
queries.

b ≡ s(cid:5)

b ≡ s(cid:5)

b ≡ s(cid:5)

strings (s, s(cid:5)
) will be called completed if it holds that the
guard predicate φ in the transition (s, φ, s(cid:5)
) of the hypothesis
is logically equivalent to the predicate φ that is in the transition
between states qs and qs(cid:2) in the target SFA. We will show that
for the new element si0 b that is added in Λ it holds that it
corresponds to an s(cid:5) for which (si0 , s(cid:5)
) is not yet completed.
For the sake of contradiction suppose the opposite is true, i.e.,
mod W ∪ {d} for some s(cid:5) for which (s, s(cid:5)
that si0
)
, φ, qs(cid:2) )
is completed. It follows that the the transition (qsi0
found in the Hypothesis SFA is correct and it will hold that
mod W ∪{d}. In turn this means that
φ(b) and also si0
mod W and as a result si0+1 ≡ s(cid:5)
mod W . Because
si0
the hypothesis SFA is reduced we obtain s(cid:5)
= si0+1 which is
a contradiction since si0 b (cid:11)≡ si0+1 mod W ∪ {d}. It follows
that si0 b ≡ sj mod W ∪ {d} for some j, j (cid:11)= i0 + 1 and the
pair (si0 , sj) is not yet completed. We conclude that (b, sj) is
a counterexample w.r.t. (R, φ, s) where R was the input to the
guardgen() algorithm for the construction of the guard of state
si0 in the hypothesis and φ is the predicate guard of the state
qsi0 in the target automaton. Indeed, (φ, si0+1) is in the output
of guardgen() and it holds that φ(b) = 1, while φi0+1(b) = 0
as j (cid:11)= i0 + 1 and φj(b) = 1. Using the above, the equivalence
queries that result in closed SOT tables cannot exceed nt(k).
On the other hand, if an equivalence query results in an SOT
that is not closed this results in the introduction of a new
state; no membership queries will be needed in this case as
the row si0 b is already determined with respect to W ∪ {d}.
The statement of the theorem follows.
Proof: (of Theorem 2) First of all observe that there is at
least one index j∗ ∈ {0, . . . ,|z(cid:5)| − 1} with the property that
γj∗ (cid:11)= γj∗+1. Indeed if the negation of this statement holds it
will contradict with the statement that γ0 (cid:11)= γ|z(cid:2)|. Let J ∗ be the
set of all such indices. The proof of the theorem is by induction
using the previous observation as basis. Suppose that the given
range [jleft, jright] satisﬁes the property that it intersects with
J ∗. We will prove that the next range selected by the binary
search process as described above preserves the property and it
also intersects with J ∗. Suppose that j is the middle point of
[jleft, jright] and γj = γ0. The search process selects [j, jright]
as the next range. Suppose for the sake of contradiction that
[j, jright] has no intersection with J ∗; this implies γjright = γ0.
In case jright = |z(cid:5)| this leads immediately to a contradiction.
On the other hand, if jright < |z(cid:5)| this means that at a previous
stage jright + 1 was a middle point and the binary search
process decided to choose the left sub-range. By deﬁnition
this implies that γjright+1 (cid:11)= γ0. As a result, since γjright = γ0
we obtain that jright ∈ J ∗ which is again a contradiction. For
the second case, suppose that γj (cid:11)= γ0 and thus the search
process selects [jleft, j − 1] as the next range. Suppose, for the
sake of contradiction that [jleft, j − 1] has no intersection with
J ∗. In case jleft = 0 then γj−1 = γ0 and since γj (cid:11)= γ0 we
have that j−1 ∈ J ∗ hence a contradiction. On the other hand,
if jleft > 0 this means that at a previous stage of the binary
search process, jleft was a middle point and a decision to go
right was made. In turn this implies that γjleft = γ0. However
by assumption γj (cid:11)= γ0 and thus there must be an index in
[jleft, j − 1] that belongs to J ∗, a contradiction.

Proof: (Sketch) (of Theorem 3) The algorithm starts with
the empty string as the sole access string and attempts to
close the observation table by issuing transduction queries.
Eventually the table will become closed, possibly with the

109109

