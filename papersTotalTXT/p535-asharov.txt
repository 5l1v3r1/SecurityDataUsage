More Efﬁcient Oblivious Transfer and Extensions for

Faster Secure Computation

Gilad Asharov, Yehuda Lindell

Cryptography Research Group

Bar-Ilan University, Israel

asharog@cs.biu.ac.il, lindell@biu.ac.il

Thomas Schneider, Michael Zohner
Engineering Cryptographic Protocols Group

TU Darmstadt, Germany

thomas.schneider@ec-spride.de,

michael.zohner@ec-spride.de

ABSTRACT
Protocols for secure computation enable parties to compute
a joint function on their private inputs without revealing
anything but the result. A foundation for secure computa-
tion is oblivious transfer (OT), which traditionally requires
expensive public key cryptography. A more eﬃcient way to
perform many OTs is to extend a small number of base OTs
using OT extensions based on symmetric cryptography.
In this work we present optimizations and eﬃcient imple-
mentations of OT and OT extensions in the semi-honest
model. We propose a novel OT protocol with security in
the standard model and improve OT extensions with re-
spect to communication complexity, computation complex-
ity, and scalability. We also provide speciﬁc optimizations
of OT extensions that are tailored to the secure computa-
tion protocols of Yao and Goldreich-Micali-Wigderson and
reduce the communication complexity even further. We ex-
perimentally verify the eﬃciency gains of our protocols and
optimizations. By applying our implementation to current
secure computation frameworks, we can securely compute a
Levenshtein distance circuit with 1.29 billion AND gates at
a rate of 1.2 million AND gates per second. Moreover, we
demonstrate the importance of correctly implementing OT
within secure computation protocols by presenting an attack
on the FastGC framework.

Categories and Subject Descriptors
F.1.2 [Modes of computation]: Interactive and reactive
computation—cryptographic protocols

Keywords
Secure computation; oblivious transfer extensions; semi-honest
adversaries

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright 2013 ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516738.

1.

INTRODUCTION

1.1 Background

In the setting of secure two-party computation, two par-
ties P0 and P1 with respective inputs x and y wish to com-
pute a joint function f on their inputs without revealing any-
thing but the output f (x, y). This captures a large variety of
tasks, including privacy-preserving data mining, anonymous
transactions, private database search, and many more. In
this paper, we consider semi-honest adversaries who follow
the protocol, but may attempt to learn more than allowed
via the protocol communication. We focus on semi-honest
security as this allows construction of highly eﬃcient proto-
cols for many application scenarios. This model is justiﬁed
e.g., for computations between hospitals or companies that
trust each other but need to run a secure protocol because
of legal restrictions and/or in order to prevent inadvertent
leakage (since only the output is revealed from the communi-
cation). Semi-honest security also protects against potential
misuse by some insiders and future break-ins, and can be en-
forced with software attestation. Moreover, understanding
the cost of semi-honest security is an important stepping
stone to eﬃcient malicious security. We remark that also in
a large IARPA funded project on secure computation on big
data, IARPA stated that the semi-honest adversary model
is suitable for their applications [27].

Practical secure computation. Secure computation
has been studied since the mid 1980s, when powerful fea-
sibility results demonstrated that any eﬃcient function can
be computed securely [15, 51]. However, until recently, the
bulk of research on secure computation was theoretical in
nature. Indeed, many held the opinion that secure computa-
tion will never be practical since carrying out cryptographic
operations for every gate in a circuit computing the func-
tion (which is the way many protocols work) will never be
fast enough to be of use. Due to many works that pushed
secure computation further towards practical applications,
e.g., [4, 5, 8, 11, 13, 21, 24, 30, 35–37, 44, 50], this conjecture
has proven to be wrong and it is possible to carry out se-
cure computation of complex functions at speeds that ﬁve
years ago would have been unconceivable. For example, in
FastGC [24] it was shown that AES can be securely com-
puted with 0.2 seconds of preprocessing time and just 0.008
seconds of online computation. This has applications to pri-
vate database search and also to mitigating server breaches
in the cloud by sharing the decryption key for sensitive data
between two servers and never revealing it (thereby forcing
an attacker to compromise the security of two servers in-

535stead of one). In addition, [24] carried out a secure compu-
tation of a circuit of size 1.29 billion AND gates, which until
recently would have been thought impossible. Their compu-
tation took 223 minutes, which is arguably too long for most
applications. However, it demonstrated that large-scale se-
cure computation can be achieved. The FastGC framework
was a breakthrough result regarding the practicality of se-
cure computation and has been used in many subsequent
works, e.g., [22, 23, 25, 26, 44]. However, it is possible to
still do much better. The secure computation framework
of [49] improved the results of FastGC [24] by a factor of
6-80, depending on the network latency. Jumping ahead,
we obtain additional speedups for both secure computation
frameworks [24] and [49]. Most notably, when applying our
improved OT implementation to the framework of [49], we
are able to evaluate the 1.29 billion AND gate circuit in just
18 minutes. We conclude that signiﬁcant eﬃciency improve-
ments can still be made, considerably broadening the tasks
that can be solved using secure computation in practice.

Oblivious transfer and extensions.

In an oblivious
transfer (OT) [48], a sender with a pair of input strings
(x0, x1) interacts with a receiver who inputs a choice bit
σ. The result is that the receiver learns xσ without learn-
ing anything about x1−σ, while the sender learns nothing
about σ. Oblivious transfer is an extremely powerful tool
and the foundation for almost all eﬃcient protocols for se-
cure computation. Notably, Yao’s garbled-circuit protocol
[51] (e.g., implemented in FastGC [24]) requires OT for ev-
ery input bit of one party, and the GMW protocol [15] (e.g.,
implemented in [8, 49]) requires OT for every AND gate of
the circuit. Accordingly, the eﬃcient instantiation of OT
is of crucial importance as is evident in many recent works
that focus on eﬃciency, e.g., [8,16,19,22–24,26,34,37,43,49].
In the semi-honest case, the best known OT protocol is that
of [40], which has a cost of approximately 3 exponentiations
per 1-out-of-2 OT. However, if thousands, millions or even
billions of oblivious transfers need to be carried out, this will
become prohibitively expensive. In order to solve this prob-
lem, OT extensions [2, 28] can be used. An OT extension
protocol works by running a small number of OTs (say, 80 or
128) that are used as a base for obtaining many OTs via the
use of cheap symmetric cryptographic operations only. This
is conceptually similar to public-key encryption where in-
stead of encrypting a large message using RSA, which would
be too expensive, a hybrid encryption scheme is used such
that only a single RSA computation is carried out to encrypt
a symmetric key and then the long message is encrypted us-
ing symmetric operations only. Such an OT extension can
actually be achieved with extraordinary eﬃciency; speciﬁ-
cally, the protocol of [28] requires only three hash function
computations on a single block per oblivious transfer (be-
yond the initial base OTs).

Related Work. There is independent work on the eﬃ-
ciency of OT extension with security against stronger mali-
cious adversaries [17, 42, 43]. In the semi-honest model, [20]
improved the implementation of the OT extension protocol
of [28] in FastGC [24]. They reduce the memory footprint by
splitting the OT extension protocol sequentially into multi-
ple rounds and obtain speedups by instantiating the pseudo-
random generator with AES instead of SHA-1. Their imple-
mentation evaluates 400,000 OTs (of 80-bit strings without
precomputations) per second over WiFi; we propose addi-
tional optimizations and our fastest implementation eval-

uates more than 700,000 OTs per second over WiFi, cf.
Tab. 4.
1.2 Our Contributions and Outline

In this paper, we present more eﬃcient protocols for OT
extensions. This is somewhat surprising since the protocol
of [28] sounds optimal given that only three hash function
computations are needed per transfer. Interestingly, our pro-
tocols do not lower the number of hash function operations.
However, we observe that signiﬁcant cost is incurred due to
other factors than the hash function operations. We propose
several algorithmic (§4) and protocol (§5) optimizations and
obtain an OT extension protocol (General OT, G-OT §5.3)
that has lower communication, faster computation, and can
be parallelized. Additionally, we propose two OT exten-
sion protocols that are speciﬁcally designed to be used in
secure computation protocols and which reduce the commu-
nication and computation even further. The ﬁrst of these
protocols (Correlated OT, C-OT §5.4) is suitable for secure
computation protocols that require correlated inputs, such
as Yao’s garbled circuits protocol with the free-XOR tech-
nique [32, 51]. The second protocol (Random OT, R-OT
§5.4) can be used in secure computation protocols where
the inputs can be random, such as GMW with multiplica-
tion triples [1, 15] (cf. §5.1). We apply our optimizations
to the OT extension implementation of [49] (which is based
on [8]) and demonstrate the improvements by extensive ex-
periments (§6).1 A summary of the time complexity for
1-out-of-2 OTs on 80-bit strings is given in Fig. 1. While
the original protocol of [28] as implemented in [49] evalu-
ates 223 OTs in 18.0 s with one thread and in 14.5 s with
two threads, our improved R-OT protocol requires only 8.4 s
with one thread and 4.2 s with two threads, which demon-
strates the scalability of our approach.

Figure 1: Runtime for 1-out-of-2 OT extension opti-
mizations on 80-bit strings. The reference and num-
ber of threads is given in (); the time for 223 OTs is
given in {}.

Secure random number generation. In §3 we empha-
size that when OT protocols are used as building block in a
secure computation protocol, it is very important that ran-
dom values are generated with a cryptographically strong
1Our
encrypto.de/code/OTExtension.

implementation is available online at http://

536random number generator. In fact, we show an attack on
the latest version of the FastGC [24] implementation (ver-
sion v0.1.1) of Yao’s protocol which uses a weak random
number generator. Our attack allows the full recovery of
the inputs of both parties. To protect against our attack,
a cryptographically strong random number generator needs
to be used (which results in an increased runtime).

Faster semi-honest base OT without random ora-
cle. In the semi-honest model, the OT of [40] is the fastest
known with 2 + n exponentiations for the sender and 2n
ﬁxed-base exponentiations for the receiver, for n OTs. How-
ever, it is proven secure only in the random oracle model,
which is why the authors of [40] also provide a slower semi-
honest OT that relies on the DDH assumption, which has
complexity 4n ﬁxed-base + 2n double exponentiations for
the sender and 1 + 3n ﬁxed-base + n exponentiations for
the receiver. In §5.2 we construct a protocol secure under
the Decisional Diﬃe-Hellmann (DDH) assumption that is
much faster when many transfers are run (as in the case of
OT extensions where 80 base OTs are needed) and is only
slightly slower than the fastest OT in the random oracle
model (§6.1).
Faster OT extensions. In §5.3 we present an improved
version of the original OT extension protocol of [28] with
reduced communication and computation complexity. Fur-
thermore, we demonstrate how the OT extension protocol
can be processed in independent blocks, allowing OT exten-
sion to be parallelized and yielding a much faster runtime
(§4.1). In addition, we show how to implement the matrix
transpose operation using a cache-eﬃcient algorithm that
operates on multiple entries at once (§4.2); this has a sig-
niﬁcant eﬀect on the runtime of the protocol. Finally, we
show how to reduce the communication by approximately
one quarter (depending on the bit-length of the inputs).
This is of great importance since local computations of the
OT extension protocol are so fast that the communication is
often the bottleneck, especially when running the protocol
over the Internet or even wireless networks.

Extended OT functionality. Our improved protocol
can be used in any setting that regular OT can be used.
However, with a mind on the application of secure computa-
tion, we further optimize the protocol by taking into account
its use in the protocols of Yao [51] and GMW [15] in §5.4.
For Yao’s garbled circuits protocol, we observe that the OT
extension protocol can choose the ﬁrst value randomly and
output it to the sender while the second value is computed
as a function of the ﬁrst value. For the GMW protocol. we
observe that the OT extension protocol can choose both val-
ues randomly and output them to the sender. In both cases,
the communication is reduced to a half (or even less) of the
original protocol of [28].
Experimental evaluation and applications. In §6 we
experimentally verify the performance improvements of our
proposed optimizations for OT and OT extension. In §7 we
demonstrate their eﬃciency gains for faster secure compu-
tation, by giving performance benchmarks for various appli-
cation scenarios. For the Yao’s garbled circuits framework
FastGC [24], we achieve an improvement up to factor 9 for
circuits with many inputs for the receiver, whereas we im-
prove the runtime of the GMW implementation of [49] by
factor 2, e.g., a Levenshtein distance circuit with 1.29 bil-
lion AND gates can now be evaluated at a rate of 1.2 million
AND gates per second.

2. PRELIMINARIES
In the following, we summarize the security parameters
used in our paper (§2.1) and describe the OT extension pro-
tocol of [28] (§2.2), Yao’s garbled circuits protocol (§2.3),
and the GMW protocol (§2.4) in more detail. Standard def-
initions of security are given in Appendix A.
2.1 Security Parameters

Throughout the paper, we denote the symmetric secu-
rity parameter by κ. Tab. 1 lists usage times (time frames)
for diﬀerent values of the symmetric security parameter κ
(SYM ) and corresponding ﬁeld sizes for ﬁnite ﬁeld cryp-
tography (FFC) and elliptic curve cryptography (ECC) as
recommended by NIST [45]. For FCC we use a subgroup of
order q = 2κ. For ECC we use Koblitz curves which had
the best performance in our experiments.

Security (Time Frames) SYM FFC ECC
1024 K-163
Short (legacy)
2048 K-243
Medium (< 2030)
Long (> 2030)
3072 K-283

80
112
128

Table 1: Security parameters and recommended key
sizes.

i , x1

2.2 Oblivious Transfer and OT Extension
The m-times 1-out-of-2 OT functionality for (cid:96)-bit strings,
denoted m×OT(cid:96), is deﬁned as follows: The sender S inputs
i ∈ {0, 1}(cid:96) (1 ≤ i ≤ m), the re-
m pairs of strings x0
ceiver R inputs a string r = (r1, . . . , rm) of length m, and
(1 ≤ j ≤ m) as output. OT ensures that S
R obtains xrj
j
learns nothing about r and R learns nothing about x1−rj
.
implements the m× OT(cid:96) func-
An OT extension protocol
tionality using a small number of actual OTs, referred to as
base OTs, and cheap symmetric cryptographic operations.
In [28] it is shown how to implement the m×OT(cid:96) functionality
using a single call to κ×OTm, and 3m hash function compu-
tations. Note that κ×OTm can be implemented via a single
call to κ× OTκ in order to obliviously transfer symmetric
keys, and then using a pseudo-random generator G to obliv-
iously transfer the actual inputs of length m (cf. [26,28]). In
the ﬁrst step of [28], S chooses a random string s ∈R {0, 1}κ,
and R chooses a random m× κ bit matrix T = [t1 | . . . | tκ],
where ti ∈ {0, 1}m denotes the i-th column of T . The par-
ties then invoke the κ× OTm functionality, where R plays
the sender with inputs (ti, ti ⊕ r) and S plays the receiver
with input s. Let Q = [q1 | . . . | qκ] denote the m × κ
matrix received by S. Note that qi = (si · r) ⊕ ti and
qj = (rj · s) ⊕ tj (where tj, qj are the j-th rows of T and
j ⊕ H(qj)
Q, respectively). S sends (y0
j ⊕ H(qj ⊕ s), for 1 ≤ j ≤ m. R ﬁnally out-
and y1
j = x1
j ⊕ H(tj) for every j. The protocol is secure
puts zj = yrj
assuming that H : {0, 1}m (cid:55)→ {0, 1}(cid:96) is a random oracle, or
a correlation robust function as in Deﬁnition A.2; see [28]
for more details.
2.3 Yao’s Garbled Circuits Protocol

j ) where y0

j

j , y1

j = x0

Yao’s garbled circuits protocol [51] allows two parties to
securely compute an arbitrary function that is represented
as Boolean circuit. The sender S encrypts the Boolean gates
of the circuit using symmetric keys and sends the encrypted

537function together with the keys that correspond to his input
bits to the receiver R. R then uses a 1-out-of-2 OT to oblivi-
ously obtain the keys that correspond to his inputs and eval-
uates the encrypted function by decrypting it gate by gate.
To obtain the output, R sends the resulting keys to S or S
provides a mapping from keys to output bits. We emphasize
that Yao’s garbled circuits protocol requires a 1-out-of-2 OT
on κ-bit strings for each input bit of R. For our experiments
we use the Yao’s garbled circuits framework FastGC [24].
2.4 The GMW Protocol

The protocol of Goldreich, Micali, and Wigderson (GMW)
[15] also represents the function to be computed as a Boolean
circuit. Both parties secret-share their inputs using the XOR
operation and evaluate the Boolean circuit as follows. An
XOR gate is computed by locally XORing the shares while
an AND gate is evaluated interactively with the help of a
multiplication triple [1,49] which can be precomputed by two
random 1-out-of-2 OTs on bits (cf. §5.1). To reconstruct
the outputs, the parties exchange their output shares. The
performance of GMW depends on the number of OTs and
on the depth of the evaluated circuit, since the evaluation
of AND gates requires interaction. For our experiments we
use the GMW framework of [49], which is an optimization
of the framework of [8] for the two party case.

3. RANDOM NUMBER GENERATION

The correct instantiation of primitives in implementations
of cryptographic protocols is a challenging task, since various
security properties have to be met. For instance, an impor-
tant security property of a pseudo-random generator (PRG)
is its unpredictability, i.e., given a sequence of pseudo-random
bits x1...xn, the next bit xn+1 should not be predictable. If
the security property of the primitive is not met, the secu-
rity of the overall scheme can be compromised. We found
that this was the case for the FastGC framework in version
0.1.1 [24] that uses the standard Java Random class in order
to generate random values used in the base OTs, the random
choices of vector s and matrix T in the OT extension, and
the input keys of the garbled circuit. Overall, this enables
an attack that allows each party to recover the inputs of the
respective other party, as we will describe now.
3.1 The Java Random Class
The Java Random class implements a so-called truncated
linear congruential generator (T-LCG) with secret seed ψ ∈
{0, 1}48. Random numbers can be generated by invoking the
next method of an object of the Java Random class which
takes as input the requested number of random bits b (for
1 ≤ b ≤ 32), updates the seed ψ(cid:48) = (αψ + β) mod m, and
returns the topmost b bits of ψ, where α = 0x5DEECE66D,
β = 0xB, and m = 248 are public constants. If more than
32 random bits are needed, next is called repeatedly until a
suﬃcient number of bits has been generated.
The security of T-LCGs was widely studied and they were
shown to be predictable [18], even if the generated sequence
is not directly output [3]. In case of the Java Random class,
each iteration reveals b bits of the seed, leaving a remaining
entropy of 48 − b bits. Furthermore, consecutive values can
be used to build linear equations.
For our analysis, we assume that the generated random value
has at least length 64 bits, i.e., it was generated by two con-
secutive calls to the next method with b = 32. This holds

for the FastGC framework [24] which uses a Java Random
object to generate symmetric keys and the columns of the
T matrix (we use the ﬁrst 64 bits only). To predict the
output of the Java Random object, we recover its secret
seed ψ = ψ1...ψ48 using the 64 bit output d = d1...d64.
Since the topmost 32 bits are directly used as output, we
have ψ17...ψ48 = d1...d32. In addition, we have ψ(cid:48)
48 =
d33...d64. Now, the remaining lower 16 bits ψ1...ψ16 can be
recovered using the linear equation ψ(cid:48) = (αψ + β) mod m.
Speciﬁcally, for each of the 216 possible values of ψ we com-
pute (αψ +β) mod m−(ψ(cid:48)
48)·216. Now, for the correct
value of ψ the result will be zero in the 32 most-signiﬁcant
bits and so will be smaller than 216, whereas for all other
values it will be larger (with high probability). In practice,
this suﬃces for ﬁnding the entire seed ψ in 216 steps, which
takes under a second. The recovered secret seed ψ can then
be used to predict the output of the Java Random object.

17...ψ(cid:48)

17...ψ(cid:48)

3.2 Exploiting the Weak PRG in FastGC [24]
We demonstrate how the usage of the Java Random class
in version v0.1.1 of the FastGC [24] framework can be ex-
ploited such that the sender can recover the input bits of the
receiver using the T matrix generated in the OT extension
protocol (cf. §2.2), and the receiver can recover the input
bits of the sender using the sender’s input keys to the gar-
bled circuit. We implemented and veriﬁed both attacks on
FastGC, which both run in less than a second. Note that
both attacks are carried out on the honestly generated tran-
script, as required for the setting of semi-honest adversaries.
Recovering the Receiver’s Inputs. The sender can
recover the receiver’s input bits using the T matrix, which
is chosen randomly by the receiver in the OT extension
(cf. §2.2). Upon receiving the matrix Q = [q1 | . . . | qκ],
the sender knows that qi = ti, if si = 0, and qi = ti⊕ r, if
si = 1. Hence, whenever the receiver has si = 0, the sender
obtains qi = ti and can recover an intermediate seed ψ of the
Java Random object that was used to generate this column
of T . Afterwards, the sender computes for j > i consecutive
random outputs tj until he obtains a column qj (cid:54)= tj where
sj = 1 which occurs with overwhelming probability 1− κ+1
2κ .
Now, the sender can recover the receiver’s input bits r by
computing qj ⊕ tj = tj⊕ r ⊕tj = r.

Recovering the Sender’s Inputs. The receiver can re-
cover the sender’s input bits using the sender’s input keys
to the garbled circuit. In FastGC, the sender generates ran-
dom symmetric keys ki ∈ {0, 1}κ for each of his (cid:96) input
bits bi ∈ {0, 1} using the same Random object. If bi = 0, he
sends Ki = ki to the receiver, else he sends Ki = ki⊕(∆||0),
where ∆ ∈ {0, 1}κ−1 is a constant global value [32]. In or-
der to recover the sender’s input bits, the receiver iteratively
computes a candidate for the seed with which Ki was gener-
ated, computes the next (cid:96)− i keys k(cid:48)
j (i < j ≤ (cid:96)) and checks
whether the candidate seed generates a consistent view for
the observed values K(cid:48)
j. If bi = 0, then Ki = ki and the re-
ceiver knows that he has recovered the correct seed by ﬁnd-
i+2 = Ki+1⊕Ki+2 if there are at least two
ing either k(cid:48)
more input bits bi+1 = bi+2 = 1 or k(cid:48)
j = Kj if another input
bit is bj = 0. Once the receiver has found such a bi = 0, he
can recover all subsequent input bits by checking whether
j = Kj (⇒ bj = 0) or not (⇒ bj = 1). If bi = 1, then
k(cid:48)
Ki = ki ⊕ (∆||0) and the receiver recovers the wrong seed
i+2 = Ki+1 ⊕ Ki+2
such that neither K(cid:48)
hold with very high probability. Thus, the receiver knows

j = Kj nor K(cid:48)

i+1 ⊕ K(cid:48)

i+1⊕k(cid:48)

538that bi = 1 and repeats the attack for i + 1. Note that this
attack fails if the sender has less than three input bits or all
except the last two input bits of the sender are set to 1. In
this case, however, the receiver can recover the input bits
with high probability by using the remaining κ − 64 bits of
the key to check if the candidate seed is correct.

Securing FastGC [24]. Securing the FastGC framework
is relatively easy, since Java also provides a cryptographi-
cally strong random number generator, called SecureRan-
dom, which by default is implemented based on SHA-1.2
Replacing all usage of the Random class by SecureRandom
increased the runtime of our experiments in §7 by around
0.5 − 4%, depending on the application. A complementary
method to reduce the overhead in runtime is to use our cor-
related input OT extension of §5.4 which eliminates the need
of generating a random T matrix s.t. our attack for recon-
structing the receiver’s inputs no longer works. Neverthe-
less, all randomness that is needed (even for our method)
must be generated using SecureRandom.

4. ALGORITHMIC OPTIMIZATIONS

In the following we describe algorithmic optimizations that
improve the scalability and computational complexity of OT
extension protocols. We identiﬁed computational bottle-
necks in OT extension by micro-benchmarking the 1-out-of-2
OT extension implementation of [49].3 We found that the
combined computation time of S and R was mostly spent
on three operations: the matrix transposition (43%), the
evaluation of H, implemented with SHA-1 (33%), and the
evaluation of G, implemented with AES (14%). To speed
up OT extension, we propose to use parallelization (§4.1)
and an eﬃcient algorithm for bit-matrix transposition (§4.2).
Note that these implementation optimizations are of gen-
eral nature and can be applied to our, but also to other
OT extension protocols with security against stronger ac-
tive/malicious adversaries, e.g., [28, 43]. As we will show
later in our experiments in §6.2, both algorithmic improve-
ments result in substantially faster runtimes, but only in
settings where the computation is the bottleneck, i.e., over
a fast network such as a LAN.
4.1 Blockwise Parallelized OT Extension

Previous OT extension implementations [8, 49] improved
the performance of OT extension by using a vertical pipelin-
ing approach, i.e., one thread is associated to each step of
the protocol: the ﬁrst thread evaluates the pseudorandom
generator G and the second thread evaluates the correlation
robust function H (cf. §2.2). However, as evaluation of G
is faster than evaluation of H, the workload between the
two threads is distributed unequally, causing idle time for
the ﬁrst thread. Additionally, this method for pipelining is
designed to run exactly two threads and thus cannot easily
be scaled to a larger number of threads.
As observed in [20], a large number of OT extensions can be
performed by sequentially running the OT extension proto-
col on blocks of ﬁxed size. This reduces the total memory
consumption at the expense of more communication rounds.

2In response to our ﬁndings, the usage of Random has been
replaced with SecureRandom in version 0.1.2 of FastGC.
3Note that the implementation in [49] performs 1-out-of-4
OT, but we adapted their implementation since our protocol
optimizations in §5 target 1-out-of-2 OT extension.

We propose to use a horizontal pipelining approach that
splits the matrices processed in the OT extension protocol
into independent blocks that can be processed in parallel us-
ing multiple threads with equal workload, i.e., each of the N
threads evaluates the OT extension protocol for m
N inputs
in parallel. Each thread uses a separate socket to commu-
nicate with its counterpart on the other party, s.t. network
scheduling is done by the operating system.
4.2 Efﬁcient Bit-Matrix Transposition

The computational complexity of cryptographic protocols
is often measured by counting the number of invocations of
cryptographic primitives, since their evaluation often domi-
nates the runtime. However, non-cryptographic operations
can also have a high impact on the overall run time of execu-
tions although they might seem insigniﬁcant in the protocol
description. Matrix transposition is an example for such an
operation. It is required during the OT extension protocol to
transpose the m× κ bit-matrix T (cf. §2.2), which is created
column-wise but hashed row-wise. Although transposition
is a trivial operation, it has to be performed individually for
each entry in T , making it a very costly operation.
We propose to eﬃciently implement the matrix transposi-
tion using Eklundh’s algorithm [10], which uses a divide-
and-conquer approach to recursively swap elements of adja-
cent rows (cf. Fig. 2). This decreases the number of swap
operations for transposing a n × n matrix from O(n2) to
O(n log2 n). Additionally, since we process a bit-matrix, we
can perform multiple swap operations in parallel by load-
ing multiple bits into one register. Thereby, we again re-
duce the number of swap operations from O(n log2 n) to
r (cid:101) log2 n), where r is the register size of the CPU (r = 64
O((cid:100) n
for the machines used in our experiments). Jumping ahead
to the evaluation in §6, this reduced the total time for the
matrix transposition by approximately a factor of 9 from
7.1 s to 0.76 s per party.

Figure 2: Eﬃcient matrix transposition of a 4 × 4
matrix using Eklundh’s algorithm.

5. PROTOCOL OPTIMIZATIONS
In this section, we show how to eﬃciently base the GMW
protocol on random 1-out-of-2 OTs (§5.1), introduce a new
OT protocol (§5.2), outline an optimized OT extension pro-
tocol (§5.3), and optimize OT extension for usage in secure
computation protocols (§5.4).
5.1 GMW with Random 1-out-of-2 OTs

An AND gate in the GMW protocol can be computed
eﬃciently using the multiplication triple functionality [1]:
the parties hold no input, and the functionality chooses
random bits a0, a1, b0, b1, c0, c1 under the constraint that
c0 ⊕ c1 = (a0 ⊕ a1)(b0 ⊕ b1). Each Pi receives the shares
labeled with i. To precompute the multiplication triples,
previous works suggest to use 1-out-of-4 bit OT [8, 49].

101112914151613678523411311159141216106482537171115381216461014259131539In the following, we present a diﬀerent approach for gen-
erating multiplication triples using two random 1-out-of-2
OTs on bits (R-OT). The R-OT functionality is exactly the
same as OT, except that the sender gets two random mes-
sages as outputs. Later in §5.4, we will show that R-OT can
be instantiated more eﬃciently than OT. In comparison to
1-out-of-4 bit OTs, using two R-OTs only slightly increases
the computation complexity (one additional evaluation of G
and H and two additional matrix transpositions), but im-
proves the communication complexity by a factor of 2.
In order to generate a multiplication triple, we ﬁrst introduce
the f ab functionality that is implemented in Algorithm 1 us-
ing R-OT. In the f ab functionality, the parties hold no input
and receive random bits ((a, u), (b, v)), under the constraint
that ab = u ⊕ v. Now, note that for a multiplication triple
c0 ⊕ c1 = (a0 ⊕ a1)(b0 ⊕ b1) = a0b0 ⊕ a0b1 ⊕ a1b0 ⊕ a1b1.
The parties can generate a multiplication triple by invoking
the f ab functionality twice:
in the ﬁrst invocation P0 acts
as R to obtain (a0, u0) and P1 acts as S to obtain (b1, v1)
with a0b1 = u0 ⊕ v1; in the second invocation P1 acts as R
to obtain (a1, u1) and P0 acts as S to obtain (b0, v0) with
a1b0 = u1 ⊕ v0. Finally, each Pi sets ci = aibi ⊕ ui ⊕ vi.
For correctness, observe that c0 ⊕ c1 = (a0b0 ⊕ u0 ⊕ v0) ⊕
(a1b1 ⊕ u1 ⊕ v1) = a0b0 ⊕ (u0 ⊕ v1) ⊕ (u1 ⊕ v0) ⊕ a1b1 =
a0b0 ⊕ a0b1 ⊕ a1b0 ⊕ a1b1 = (a0 ⊕ a1)(b0 ⊕ b1), as required.
A proof sketch for security is given in Appendix B.

Algorithm 1 Random (a, u), (b, v) with ab = u ⊕ v
1: R chooses a ∈R {0, 1}.
2: S and R perform a R-OT with a as input of R.
3: R sets u = xa; S sets b = x0 ⊕ x1 and v = x0.

S obtains bits x0, x1 and R obtains bit xa as output.
[Note that ab = u⊕ v as ab = a(x0 ⊕ x1) = (a(x0 ⊕ x1)⊕
x0) ⊕ x0 = xa ⊕ x0 = u ⊕ v.]

4: R outputs (a, u) and S outputs (b, v).

5.2 Optimized Oblivious Transfer

The best known protocols for oblivious transfer with se-
curity in the presence of semi-honest adversaries are those
of Naor-Pinkas [40]. They present two protocols; a more
eﬃcient protocol that is secure in the random oracle model
and a less eﬃcient protocol that is secure in the standard
model and under standard assumptions. In this section, we
describe a new semi-honest OT protocol that is secure in the
standard model and is essentially an optimized instantiation
of the OT protocol of [12]. When implemented over ellip-
tic curves, our protocol is about three times faster than the
standard model OT of [40] and only two times slower than
the random oracle OT of [40] (see §6.1 for a comparison of
the protocol runtimes). Hence, our protocol is a good alter-
native for those preferring to not rely on random oracles.
Our n×OT(cid:96) protocol is based on the DDH assumption and
uses a key derivation function (KDF); see Deﬁnition A.1.
We also assume that it is possible to sample a random el-
ement of the group, and the DDH assumption will remain
hard even when the coins used to sample the element are
given to the distinguisher (i.e., (g, h, ga, ha) is indistinguish-
able from (g, h, ga, gb) for random a, b, even given the coins
used to sample h). This holds for all known groups in which
the DDH problem is assumed to be hard and can be imple-
mented as described next. For ﬁnite ﬁelds, one can sample

a random element h ∈ Zp of order q by choosing a ran-
dom x ∈R Zp and computing h = x(p−1)/q until h (cid:54)= 1.
For elliptic curves, one chooses a random x-coordinate, ob-
tains a quadratic equation for the y-coordinate and ran-
domly chooses one of the solutions as h (if no solution exists,
start from the beginning).
The computational complexity of our protocol for n×OT(cid:96) is
2n exponentiations for the sender Sand 2n ﬁxed-base expo-
nentiations for the receiver R (in ﬁxed-base exponentiations,
the same “base” g is raised to the power of many diﬀerent
exponents; more eﬃcient exponentiation algorithms exist for
this case [38, Sec. 14.6.3]). In addition, S computes the KDF
function 2n times, and R computes it n times. R samples
n random group elements according to the above deﬁnition.
See Protocol 5.1 for a detailed description of the protocol.

PROTOCOL 5.1

(Optimized n×OT(cid:96) Protocol).

i , x1

Inputs: S holds n pairs (x0
i ) of (cid:96)-bit strings, for every
1 ≤ i ≤ n. R holds the selection bits σ = (σ1, . . . , σn).
The parties agree on a group (cid:104)G, q, g(cid:105) for which the DDH
is hard, and a key derivation function KDF.
First Round (Receiver): Choose random exponents
αi∈RZq and random group elements hi∈RG for every
1 ≤ i ≤ n. Then, for every i, set (h0

(cid:26) (gαi , hi)

(hi, gαi )

i , h1

i ) as follows:
if σi = 0
if σi = 1

(h0

i , h1
i )

def
=

Send the pairs (h0

i , h1

i ) to S.

Second Round (Sender): Choose a random element
r∈RZq and compute u = gr. Then, for each pair (h0
i , h1
i )
compute the keys: (k0
the pair of ciphertexts:
i ⊕ KDF(k0
i )

i )r(cid:1) and compute

i ) =(cid:0)(h0

v0
i = x0

i )r, (h1

and v1

i , k1

Send u together with the n pairs (v0

Output Computation (Receiver):
1 ≤ i ≤ n, set kσi
i = vσi
R outputs (xσ1
n ); S has no output.

i = uαi and xσi

1 , . . . , xσn

i = x1
i , v1

i ⊕ KDF(k1
i ).
i ) to R.
every
i ⊕ KDF(kσi
i ).

For

1

n

i , h1

i )}n

1 , . . . , xσn

1 , . . . , xσn

, . . . , x1−σn
and using x1−σi

The protocol is secure in the presence of a semi-honest
adversary (see Deﬁnition A.3). The view of a corrupted
sender consists of the pairs {(h0
i=1 which are com-
pletely independent of the receiver’s inputs, and therefore
can be simulated perfectly. For the corrupted receiver, we
need to show the existence of a simulator S1 that produces
a computationally-indistinguishable view, given the inputs
and outputs of the receiver, i.e., σ and (xσ1
n ), with-
). S1
out knowing the other sender values (x1−σ1
n
works by running an execution of the protocol playing an
honest S using inputs xσ1
= 0
for all 1 ≤ i ≤ n. The only diﬀerence between the view
of the receiver generated by the simulator and in a real
execution is regarding the values {v1−σi
}n
i=1, which equal
) in a real execution and just KDF(k1−σi
x1−σi
)
in the simulation. From the security of the KDF with re-
spect to DDH (see Deﬁnition A.1), and using a standard hy-
brid argument, the values (KDF(k1−σ1
)) =
(KDF(hr
n)) are indistinguishable from n uni-
form strings z1, . . . , zn each of size (cid:96) (even when the distin-
guisher sees (cid:104)G, q, g, u = gr(cid:105)). This implies that the values
}n
{v1−σi
i=1 in the real execution are computationally indis-
tinguishable from those in the simulation.
An additional optimization for random OT. When
constructing OT extensions (see §2.2) the parties ﬁrst run
κ × OTκ on random inputs (this holds for our optimized

), . . . , KDF(k1−σn

⊕KDF(k1−σi

1), . . . , KDF(hr

n

1

i

i

i

i

i

i

540i = KDF((h0

i )r), and R by computing xσi

OT extension protocol, and also for the original protocol
of [28] if κ×OTm is implemented via κ×OTκ as described
in §2.2). Observe that in this case, the sender only needs to
send u = gr to the receiver R; the parties can then derive
the values locally (S by computing x0
i )r) and
x1
i = KDF((h1
i = KDF(uαi )).
This reduces the communication since the elements v0
i and
v1
i do not have to be sent.
In addition, this means that
the messages sent by S and R are actually independent of
each other, and so the protocol consists of a single round of
communication. (As pointed out in [43], this optimization
can also be carried out on the protocols of Naor-Pinkas [40].
However, those protocols still require two rounds of commu-
nication which can be a drawback in high latency networks.)
The timings that appear in §7 are for an implementation
that uses this additional optimization.4
5.3 Optimized General OT Extension
In the following, we optimize the m×OT(cid:96) extension pro-
tocol of [28], described in §2.2. Recall, that in the ﬁrst
step of the protocol in [28], R chooses a huge m × κ matrix
T = [t1| . . .|tκ] while S waits idly. The parties then engage
in a κ×OTm protocol, where the inputs of the receiver are
(ti, ti ⊕ r) where r is its input in the outer m×OT(cid:96) protocol
(m selection bits). After the OT, S holds ti⊕(si·r) for every
1 ≤ i ≤ κ. As described in the appendices of [26,28], the pro-
tocol can be modiﬁed such that R only needs to choose two
small κ× κ matrices K0 = [k0
1| . . .|k1
κ]
of seeds. These seeds are used as input to κ×OTκ; speciﬁcally
R’s input as sender in the i-th OT is (k0
i ) and, as in [28],
the input of S is si. To transfer the m-bit tuple (ti, ti⊕r) in
i and k1
the i-th OT, R expands k0
i using a pseudo-random
i ) ⊕ ti ⊕ r),
i ) ⊕ ti, G(k1
i ) = (G(k0
i , v1
generator G, sends (v0
i ) ⊕ vsi
and S recovers G(ksi
i .
Our main observation is that, instead of choosing ti ran-
domly, we can set ti = G(k0
i ). Now, R needs to send only
i ) ⊕ r to S (whereas
i ) ⊕ G(k1
one m-bit element ui = G(k0
in previous protocols of [26, 28] two m-bit elements were
sent). Observe that if S had input si = 0 in the i-th OT,
i ) = G(ksi
then it can just deﬁne its output qi to be G(k0
i ).
In contrast, if S had input si = 1 in the i-th OT, then it
i ) ⊕ ui.
can deﬁne its output qi to be G(k1
i ) ⊕ ui =
Since ui = G(k0
i ) ⊕ r = ti ⊕ r, as required. The full description of our
G(k0
protocol is given in Protocol 5.2. This optimization is sig-
niﬁcant in applications of m×OT(cid:96) extension where m is very
large and (cid:96) is short, such as in GMW. In typical use-cases
for GMW (cf. §7), m is in the size of several millions to a
billion, while (cid:96) is one. Thereby, the communication com-
plexity of GMW is almost reduced by half.
In addition, as in [26], observe that unlike [28] the initial
OT phase in Protocol 5.2 is completely independent of the
actual inputs of the parties. Thus, the parties can perform

i ) ⊕ ui = G(ksi
i ) ⊕ r, we have that G(k1

κ] and K1 = [k1

i ) ⊕ G(k1

1| . . .|k0

i , k1

i , x0

4We remark that, in order to prove the security of this op-
timization in the standard model (without a random ora-
cle), we need to change the ideal functionality for the ran-
dom OT such that for every i, the output of the sender
is (β0
i )) and (β1
i )), and the
σi
output of the receiver is (σi, βσi
i )). That is, in
i
addition to receiving their input and output from the ran-
dom OT functionality, the parties receive the “discrete log”
of the pertinent values. This additional information is of no
consequence in our applications of random OT.

i = KDF(gβ1
, KDF(gβ

i = KDF(gβ0

i , x1

the initial OT phase before their inputs are determined.
Finally, another problem that arises in the original protocol
of [28] is that the entire m × κ matrix is transmitted to-
gether and processed. This means that the number of OTs
to be obtained must be predetermined and, if m is very
large, this results in considerable latency as well as memory
management issues. As in [20], our optimization enables us
to process small blocks of the matrix at a time, reducing
latency, computation time, and memory management prob-
lems. In addition, it is possible to continually extend OTs,
with no a priori bound on m. This is very useful in a secure
computation setting, where parties may interact many times
together with no a priori bound.

PROTOCOL 5.2

(General OT extension protocol).

j , x1

j ) of (cid:96)-bit strings, for every

Inputs: S holds m pairs (x0
1 ≤ j ≤ m. R holds m selection bits r = (r1, . . . , rm).
Initial OT Phase (base OTs):
1. S choose a random string s = (s1, . . . , sκ) and R
2. The parties invoke the κ×OTκ-functionality, where S
plays the receiver with input s and R plays the sender
with inputs (k0

chooses κ pairs of κ-bits seeds {(k0

i )}κ

i , k1

i=1.

i , k1

i ) for every 1 ≤ i ≤ κ.
let ti = G(k0

3. For every 1 ≤ i ≤ κ,

i ). Let T =
[t1| . . . |tk] denote the m × κ bit matrix where the i-th
column is ti, and let tj denote the j-th row of T , for
1 ≤ j ≤ m.

i ) and ui = ti ⊕ G(k1

sends ui to S for every 1 ≤ i ≤ κ.
(Note that qi = (si · r) ⊕ ti.)

OT extension Phasea:
i ) ⊕ r, and
1. R computes ti = G(k0
2. For every 1 ≤ i ≤ κ, S deﬁnes qi = (si · ui) ⊕ G(ksi
i ).
3. Let Q = [q1| . . . |qκ] denote the m× κ bit matrix where
the i-th column is qi. Let qj denote the j-th row of
the matrix Q. (Note that qj = (rj · s) ⊕ tj .)
j ) for every 1 ≤ j ≤ m, where:

4. S sends (y0

j , y1
j ⊕ H(j, qj )

y0
j = x0

5. For 1 ≤ j ≤ m, R computes x
Output: R outputs (xr1

1 , . . . , xrn

j ⊕ H(j, qj ⊕ s)
and y1
j = x1
j ⊕ H(j, tj ).
rj
rj
j = y
n ); S has no output.

aThis phase can be iterated. Speciﬁcally, R can com-
pute the next κ bits of ti and ui (by applying G to
get the next κ bits from the PRG for each of the seeds
and using the next κ bits of its input in r) and send the
block of κ×κ bits to S (κ bits from each of u1, . . . , uκ).

Theorem 5.3. Assuming that G is a pseudorandom gen-
erator and H is a correlation-robust function (as in Deﬁ-
nition A.2), Protocol 5.2 privately-computes the m× OT(cid:96)-
functionality in the presence of semi-honest adversaries, in
the κ×OTκ-hybrid model.
Proof: We ﬁrst show that the protocol indeed implements
the m×OT(cid:96)-functionality. Then, we prove that the protocol
is secure where the sender is corrupted, and ﬁnally that it is
secure when the receiver is corrupted.

Correctness. We show that the output of the receiver is
(xr1
1 , . . . , xrm
m ) in an execution of the protocol where the in-
puts of the sender are ((x0
m)) and the input
of the receiver is r = (r1, . . . , rm). Let 1 ≤ j ≤ m, we show
that zj = xrj
1. rj = 0: Recall that qj = (rj · s) ⊕ tj, and so qj = tj.

j . We have two cases:

1), . . . , (x0

m, x1

1, x1

541Thus:

zj = y0
= x0

j ⊕ H(tj) = x0
j ⊕ H(tj) ⊕ H(tj) = x0
2. rj = 1: In this case qj = s ⊕ tj, and so:

j

j ⊕ H(qj) ⊕ H(tj)

zj = y1
= x1

j ⊕ H(tj) = x1
j ⊕ H(tj) ⊕ H(tj) = x1

j

j ⊕ H(qj ⊕ s) ⊕ H(tj)

1 , . . . , ksκ

Corrupted Sender. The view of the sender during the
protocol contains the output from the κ×OTκ invocation and
the messages u1, . . . , uκ. The simulator S0 simply outputs
a uniform string s ∈ {0, 1}κ (which is the only randomness
that S chooses in the protocol, and therefore w.l.o.g. can
be interpreted as the random tape of the adversary), κ ran-
dom seeds ks1
κ , which are chosen uniformly from
{0, 1}κ, and κ random strings u1, . . . , uκ, chosen uniformly
from {0, 1}m. In the real execution, (s, ks1
κ ) are cho-
sen in exactly the same way. Each value ui for 1 ≤ i ≤ κ is
i ) ⊕ r. Since k1−si
deﬁned as G(k0
is unknown to S
(by the security of the κ×OTκ functionality), we have that
G(k1−si
) is indistinguishable from uniform, and so each ui
is indistinguishable from uniform. Therefore, the view of the
corrupted sender in the simulation is indistinguishable from
its view in a real execution.

i ) ⊕ G(k1

1 , . . . , ksκ

i

i

j

m, y1

m, y1

1 , . . . , xrm

m)) as the view of the corrupted receiver.

Corrupted Receiver. The view of the corrupted re-
1, y1
ceiver consists of its random tape and the messages ((y0
1)
m)) only. The simulator S1 is invoked with the
, . . . , (y0
inputs and outputs of the receiver, i.e., r = (r1, . . . , rm) and
m ). S1 then chooses a random tape ρ for the
(xr1
adversary (which determines the k0
i , k1
i values), deﬁnes the
j ⊕ H(tj) for 1 ≤ j ≤ m.
matrix T , and computes yrj
j = xrj
Then, it chooses each y1−rj
uniformly and independently
at random from {0, 1}(cid:96). Finally, it outputs (ρ, (y0
1), . . . ,
(y0
We now show that the output of the simulator is indistin-
guishable from the view of the receiver in a real execu-
j ⊕
If rj = 0, then qj = tj and thus (y0
tion.
j ⊕ H(tj ⊕ s)). If rj = 1, qj = tj ⊕ s and therefore
H(tj), x1
j ⊕ H(tj)). In the simulation,
(y0
j ) = (x0
j ⊕ H(tj) and therefore
the values yrj
are identical to the real execution. It therefore remains to
show that the values (y1−r1
) as computed in the
real execution are indistinguishable from random strings as
output in the simulation. As we have seen, in the real exe-
cution each y1−rj
⊕ H(tj ⊕ s). Since
H is a correlation robust function, it holds that:

j ⊕ H(tj ⊕ s), x1
j are computed as xrj

is computed as x1−rj

, . . . , y1−rm

j ) = (x0

j , y1

j , y1

1, y1

m

1

j

j

{t1, . . . , tm, H(t1 ⊕ s), . . . , H(tm ⊕ s)} c≡ {Um·κ+m·(cid:96)}

for random s, t1, . . . , tm ∈ {0, 1}κ, where Ua deﬁnes the uni-
form distribution over {0, 1}a (see Deﬁnition A.2). In the
protocol we derive the values t1, . . . , tm by applying a pseu-
dorandom generator G to the seeds k0
κ and transpos-
ing the resulting matrix. We need to show that the values
H(t1⊕ s), . . . , H(tm⊕ s) are still indistinguishable from uni-
form in this case. However, this follows from a straightfor-
ward hybrid argument (namely, that replacing truly random
ti values in the input to H with pseudorandom values pre-
serves the correlation robustness of H). We conclude that
the ideal and real distributions are computationally indis-
tinguishable.

1, . . . , k0

w = k0

j = x1
w and x1

w ⊕ ∆. Since k0

j ⊕H(qj) and y1
j = k0

5.4 Optimized OT Extension in Yao & GMW
The protocol described in §5.3 implements the m× OT(cid:96)
functionality. In the following, we present further optimiza-
tions that are speciﬁcally tailored to the use of OT exten-
sions in the secure computation protocols of Yao and GMW.
Correlated OT (C-OT) for Yao. Before proceeding to
the optimization, let us focus for a moment on Yao’s protocol
[51] with the free-XOR [32] and point-and-permute [37] tech-
niques.5 Using this techniques, the sender does not choose
all keys for all wires independently. Rather, it chooses a
global random value δ ∈R {0, 1}κ−1, sets ∆ = δ||1, and for
w ∈R {0, 1}κ and sets
every wire w it chooses a random key k0
w ⊕ ∆. Later in the protocol, the parties invoke OT
k1
w = k0
extension to let the receiver obliviously obtain the keys asso-
ciated with its inputs. This eﬀectively means that, instead
of having to obliviously transfer two ﬁxed independent bit
strings, the sender needs to transfer two random bit strings
with a ﬁxed correlation. We can utilize this constraint on
the inputs in order to save additional bandwidth in the OT
extension protocol. Recall that in the last step of Proto-
col 5.2 for OT extension, S computes and sends the messages
j ⊕H(qj⊕s). In the case of Yao,
y0
j = x0
we have that x0
j = k1
w is
just a random value, S can set k0
w = H(qj) and can send the
single value yj = ∆⊕H(qj)⊕H(qj⊕s). R deﬁnes its output
as H(tj) if rj = 0 or as yj ⊕ H(tj) if rj = 1. Observe that
if rj = 0, then tj = qj and R outputs H(qj) = x0
w, as
required. In contrast, when rj = 1, it holds that tj = qj ⊕ s
and thus yj ⊕ H(qj ⊕ s) = ∆ ⊕ H(qj) = ∆ ⊕ k0
w = k1
w,
as required. Thus, in the setting of Yao’s protocol when
using the free-XOR technique, it is possible to save band-
width. As the keys k0
w used in Yao are also of length
κ, the bandwidth is reduced from 3κ bits that are trans-
mitted in every iteration of the extension phase to 2κ bits,
eﬀectively reducing the bandwidth by one third. Proving
the security of this optimization requires assuming that H
is a random oracle, in order to “program” the output to be
as derived from the OT extension. In addition, we deﬁne
a diﬀerent OT functionality, called correlated OT (C-OT),
that receives ∆ and chooses the sender’s inputs uniformly
under the constraint that their XOR equals ∆. Since Yao’s
protocol uses random keys under the same constraint, the se-
curity of Yao’s protocol remains unchanged when using this
optimized OT extension. Note that by using the correlated
input OT extension protocol, the server needs to garble the
circuit after performing the OT extension; this order is also
needed for the pipelining approach used in many implemen-
tations, e.g., [24, 34, 36]. We remark that this optimization
can be used in the more general case where in each pair one
of the inputs is chosen uniformly at random and the other
input is computed as a function of the ﬁrst. Speciﬁcally,
the sender has diﬀerent functions fj for every 1 ≤ j ≤ m,
and receives random values x0
j as output from the extension
protocol, which deﬁnes x1
j ). E.g., for Yao’s garbled
circuits protocol, we have x1

j ) = ∆ ⊕ x0
j .

j = fj(x0

j = fj(x0

j = k0

w, k1

Random-OT (R-OT) for GMW. When using OT ex-
tensions for implementing the GMW protocol, the eﬃciency
can be improved even further. In this case, the inputs for
S in every OT are independent random bits b0 and b1 (see
§5.1 for how to evaluate AND gates using two random OTs).

5Our optimization is also compatible with the garbled row
reduction technique of [47].

542Thus, the sender can allow the random OT extension pro-
tocol (functionality) R-OT to determine both of its inputs
randomly. This is achieved in the OT extension protocol by
having S deﬁne b0 = H(qj) and b1 = H(qj ⊕ s). Then, R
computes brj just as H(tj). The receiver’s output is correct
because qj = (rj · s) ⊕ tj, and thus H(tj) = H(qj) when
rj = 0, and H(tj) = H(qj ⊕ s) when rj = 1. With this op-
timization, we obtain that the entire communication in the
OT extension protocol consists only of the initial base OTs,
together with the messages u1, . . . , uκ, and there are no yj
messages. This is a dramatic improvement of bandwidth.
As above, proving the security of this optimization requires
assuming that H is a random oracle, in order to “program”
the output to be as derived from the OT extension. In ad-
dition, the OT functionality is changed such that the sender
receives both of its inputs from the functionality, and the
receiver just inputs r (see [43, Fig. 26]).
Summary. The original OT extension protocol of [28]
and our proposed improvements for m× OT(cid:96) are summa-
rized in Tab. 2. We compare the communication complexity
of R and S for m parallel 1-out-of-2 OT extensions of (cid:96)-
bit strings, with security parameter κ (we omit the cost of
the initial κ× OTκ). We also compare the assumption on
the function H needed in each protocol, where CR denotes
Correlation-Robustness and RO denotes Random Oracle.
S → R H
CR
2m(cid:96)
CR
2m(cid:96)
RO
m(cid:96)
0
RO

Protocol
Original [28] All applications
G-OT §5.3
All applications
C-OT §5.4
only x0
j random
R-OT §5.4
x0
j , x1
j random

Applicability R → S
2mκ
mκ
mκ
mκ

Table 2: Sent bits for sender S and receiver R for m
1-out-of-2 OT extensions of (cid:96)-bit strings and security
parameter κ.

6. EXPERIMENTAL EVALUATION
In the following, we evaluate the performance of our pro-
posed optimizations. In §6.1 we compare our base OT pro-
tocol (§5.2) to the protocols of [40] and in §6.2 we evalute
the performance of our algorithmic (§4) and protocol opti-
mizations (§5.3 and §5.4) for OT extension.

Benchmarking Environment. We build upon the C++
OT extension implementation of [49] which implements the
OT extension protocol of [28] and is based on the imple-
mentation of [8]. We use SHA-1 to instantiate the random
oracle and the correlation robust function and AES-128 in
counter mode to instantiate the pseudo-random generator
and the key derivation function. Our benchmarking environ-
ment consists of two 2.5 GHz Intel Core2Quad CPU (Q8300)
Desktop PCs with 4 GB RAM, running Ubuntu 10.10 and
OpenJDK 6, connected by a Gigabit LAN.
6.1 Base OTs

In the following, we compare the performance of the OT
protocols of Naor and Pinkas [40] in the random oracle (RO)
and standard (STD) model to our STD model OT protocol
of §5.2 for diﬀerent libraries. We either use ﬁnite ﬁeld cryp-
tography (FFC) (based on the GNU-Multiprecision library
v.5.0.5) or elliptic curve cryptography (ECC) (based on the
Miracl library v.5.6.1). We measure the time for perform-
ing κ 1-out-of-2 base OTs on κ-bit strings, for symmetric

security parameter κ, using the key sizes from Tab. 1. The
runtimes are shown in Tab. 3.
For the short term security parameter, FFC using GMP out-
performs ECC using Miracl by factor 2 for all protocols.
However, starting from a medium term security parameter,
ECC becomes increasingly more eﬃcient and outperforms
FCC by more than factor 2 for the long term security pa-
rameter. For ECC, we can observe that [40]-RO is about
5-6 times faster than [40]-STD but only 2 times faster than
our §5.2-STD protocol. For FFC, our §5.2-STD protocol
becomes more ineﬃcient with increasing security parame-
ter, since the random sampling requires nearly full-range
exponentiations as opposed to the subgroup exponentiations
in [40]-RO and [40]-STD.

Security
GMP (FFC)
Short [ms]
Medium [ms]
Long [ms]
Miracl (ECC)
Short [ms]
Medium [ms]
Long [ms]

[40]-RO

[40]-STD

§5.2-STD

18 (±0.9)
107 (±3.4)
288 (±7.9)

39 (±1.6)
82 (±2.9)
138 (±5.0)

99 (±0.6)
629 (±3.3)
1,681 (±4.7)

41 (±3.3)
352 (±18)
1,217 (±47)

178 (±0.3)
418 (±0.6)
763 (±0.8)

61 (±2.5)
137 (±5.0)
239 (±7.5)

Table 3: Performance results and standard devia-
tions for base OTs.

6.2 OT Extension

To evaluate the performance of OT extension, we measure
the time for generating the random inputs for the OT exten-
sion protocol and the overall OT extension protocol execu-
tion on 10,000,000 1-out-of-2 OTs on 80-bit strings for the
short-term security setting, excluding the times for the base
OTs. Tab. 4 summarizes the resulting runtimes for the orig-
inal version without (Orig [49] (1 T)) and with pipelining
(Orig [49] (2 T)), the eﬃcient matrix transposition (EMT
§4.2), the general protocol optimization (G-OT §5.3), the
correlated OT extension protocol (C-OT §5.4), the random
OT extension protocol (R-OT §5.4), as well as a two and
four threaded version of R-OT (2 T and 4 T, cf. §4.1). The
line (x T) denotes the number of threads, running on each
party. Since our optimizations target both, the runtime as
well as the amount of data that is transferred, we assume
two diﬀerent bandwidth scenarios: LAN (Gigabit Ethernet
with 1 GBit bandwidth) and WiFi (simulated by limiting the
available bandwidth to 54 MBit and the latency to 2 ms).
As our experiments in Tab. 4 show, the LAN setting bene-
ﬁts from computation optimizations (as computation is the
bottleneck), whereas the WiFi setting beneﬁts from commu-
nication optimizations (as the network is the bottleneck).
All timings are the average of 100 executions with one party
acting as sender and the other as receiver. Note that each
version includes all prior listed optimizations.

LAN setting. The original OT extension implemen-
tation of [49] has a runtime of 20.61 s without pipelining,
which is reduced to only 80% (16.57 s) when using pipelin-
ing. Implementing the eﬃcient matrix transposition of §4.2
decreases the runtime to 70% of the one-threaded original
version (14.43 s) and already outperforms the pipelined ver-
sion even though only one thread is used. The general im-
proved OT extension protocol of §5.3 removes the need to

543Network Orig [49] Orig [49] EMT §4.2 G-OT §5.3 C-OT §5.4 R-OT §5.4 R-OT §5.4 R-OT §5.4
(4 T, §4.1)

(2 T, §4.1)

(1 T)
10.60
(±0.03)
14.39
(±0.14)

(1 T)
10.00
(±0.02)
14.22
(±0.12)

5.03
(±0.08)
14.23
(±0.18)

2.62
(±0.05)
14.23
(±0.22)

LAN [s]

WiFi [s]

(1 T)
20.61
(±0.07)
30.69
(±0.18)

(2 T)
16.57
(±0.33)
30.42
(±0.20)

(1 T)
14.43
(±0.05)
30.45
(±0.24)

(1 T)
13.92
(±0.07)
29.36
(±0.26)

Table 4: Performance results and standard deviations for 10,000,000 1-out-of-2 OTs on 80-bit strings using
our optimizations in §4 and §5.

generate the random matrix T , which reduces the runtime
to 13.92 s. The C-OT extension of §5.4 decreases the run-
time to 10.60 s, since the protocol generates the random
input values for the sender. The R-OT extension of §5.4
further decreases the runtime to 10.00 s, since the last com-
munication step is eliminated. Finally, the parallelized OT
extension of §4.1 results in a nearly linear decrease in run-
time to 50% (5.03 s) for two threads and to 26% (2.62 s) for
four threads. Overall, using two threads, we decreased the
runtime in the LAN setting by a factor of 3 compared to the
two-threaded original implementation.

WiFi setting. In the WiFi setting, we observe that the
one and two threaded original implementation is already
slower compared to the LAN setting. Moreover, all opti-
mizations that purely target the runtime have little eﬀect,
since the network has become the bottleneck. We therefore
focus on the optimizations for the communication complex-
ity. The G-OT optimization of §5.3 only slightly decreases
the runtime since both parties have the same up and down-
load bandwidth and the channel from sender to receiver be-
comes the bottleneck (cf. Tab. 2).6 The C-OT extension of
§5.4 reduces the runtime by a factor of 2, corresponding to
the reduced communication from sender to receiver which
is now equal to the communication in the opposite direc-
tion. The R-OT extension of §5.4 only slightly decreases the
runtime, since now the channel from receiver to sender has
become the bottleneck. Finally, the multi-threading opti-
mization of §4.1 does not reduce the runtime as the network
is the bottleneck.

7. APPLICATION SCENARIOS

OT extension is the foundation for eﬃcient implementa-
tions of many secure computation protocols, including Yao’s
garbled circuits implemented in the FastGC framework [24]
and GMW implemented in the framework of [8, 49]. To
demonstrate how both protocols beneﬁt from our improved
OT extensions, we apply our implementations to both frame-
works and consider the following secure computation use-
cases: Hamming distance (§7.1), set-intersection (§7.2), min-
imum (§7.3), and Levenshtein distance (§7.4). The overall
performance results are summarized in Tab. 5 and discussed
in §7.5. All experiments were performed under the same
conditions as in §6 (LAN setting) using the random-oracle
protocol of [40] as base OT. We extended the FastGC frame-
work [24] to call our C++ OT implementation using the Java
Native Interface (JNI). We stress that the goal of our perfor-
mance measurements is to highlight the eﬃciency gains of
our improved OT protocols, but not to provide a comparison
between Yao’s garbled circuits and the GMW protocol.

6For shorter strings or if the channel would have a higher
bandwidth from sender to receiver (e.g., a DSL link), the
runtime would decrease already for the G-OT optimization.

7.1 Hamming Distance

The Hamming distance between two (cid:96)-bit strings is the
number of positions that both strings diﬀer in. Applications
of secure Hamming distance computation include privacy-
preserving face recognition [46] and private matching for car-
dinality threshold [29]. As shown in [24, 49], using a circuit-
based approach is a very eﬃcient way to securely compute
the face recognition algorithm of [46] which uses (cid:96) = 900.
We use the compact Hamming distance circuit of [6] with
size (cid:96) − HW ((cid:96)) AND gates and (cid:96) input bits for the client,
where HW ((cid:96)) is the Hamming weight of (cid:96).
7.2 Set-Intersection

Privacy-preserving set-intersection allows two parties, each
holding a set of σ-bit elements, to learn the elements they
have in common. Applications include governmental law
enforcement [9], sharing location data [41], and botnet de-
tection [39]. Several Boolean circuits for computing the set-
intersection were described and evaluated in [23]. The au-
thors of [23] state that for small σ (up to σ = 20 in their
experiments), the bitwise AND (BWA) circuit achieves the
best performance. This circuit treats each element e ∈ {0, 1}σ
as an index to a bit-sequence {0, 1}2σ
and denotes the pres-
ence of e by setting the respective bit to 1. The parties then
compute the set-intersection as the bitwise AND of their
bit-sequences. We build the BWA circuit for σ = 20, result-
ing in a circuit with 2σ = 1,048,576 AND gates and input
bits for the client. To reduce the memory footprint of the
FastGC framework [24], we split the overall circuit and the
OTs on the input bits into blocks of size 216 = 65,536.
7.3 Secure Minimum

Securely computing the minimum of a set of values is
a common building block in privacy-preserving protocols
and is used to ﬁnd best matches, e.g., for face recogni-
tion [11] or online marketplaces [8]. We use the scenario
considered in [36] that securely computes the minimum of
N = 1,000,000 (cid:96) = 20-bit values, where each party holds
500,000 values. Using the minimum circuit construction
of [31], our circuit has 2(cid:96)N − 2(cid:96) ≈ 40,000,000 AND gates
and the client has N
2 (cid:96) = 10,000,000 input bits. We note
that the performance of the garbled circuit implementation
of [36] is about the same as that of FastGC [24] – their
circuit has twice the size and takes about twice as long to
evaluate. For the FastGC framework we again evaluate the
overall circuit by iteratively computing the minimum of at
most 2,048 values.
7.4 Levenshtein Distance

The Levenshtein distance denotes the number of oper-
ations that are needed to transform a string a into an-
other string b using an alphabet of bit-size σ.
It can be

544Implementation
FastGC [24]
FastGC [24] ﬁxed with CPRG
FastGC [24] with C-OT (4 T)
GMW [49]
GMW [49] with R-OT (4 T)
AND gates
Client input bits

Base-OTs

470 ms
482 ms
69 ms
142 ms
28 ms

-
-

896
900

1,048,576
1,048,576

Hamming §7.1
149 ms (86.8 ms)
155 ms (87.6 ms)

85 ms (4.4 ms)
79 ms (46.5 ms)
30 ms (11.3 ms)

Set-Intersect. §7.2 Minimum §7.3
1094 s (552 s)
1106 s (554 s)

249 s (227 s)
253 s (227 s)
27 s (0.96 s)
1.91 s (1.34 s)
0.93 s (0.51 s)

Levenshtein §7.4
265 min (148 ms)
266 min (157 ms)
266 min (15 ms)

—

18 min (11 min)

1,290,653,042

2,000

593 s (15 s)
44 s (41 s)
21 s (19 s)
39,999,960
10,000,000

Table 5: Performance results for the frameworks of [24] and [49] with and without our optimized OT imple-
mentation. The time spent in the OT extensions is given in ().

used for privacy-preserving matching of DNA and protein-
sequences [24]. We use the same circuit and setting as [24]
with σ = 2 to compare strings a and b of size |a| = 2,000
and |b| = 10,000. The resulting circuit has 1.29 billion AND
gates and σ|a| = 4,000 input bits for the client. The GMW
framework of [49] was not able to evaluate the Levenshtein
circuit since their OT extension implementation tries to pro-
cess all OTs at once and their framework tries to store
the whole circuit in memory, thereby exceeding the avail-
able memory of our benchmarking environment. Hence, we
changed their underlying circuit structure to support large-
scale circuits by deleting gates that were used and building
the circuit iteratively.
7.5 Discussion

We discuss the results of our experiments in Tab. 5 next.
For the FastGC framework [24], our improved OT extension
implementation written in C++ and using 4 threads is more
than one order of magnitude faster than the corresponding
single-threaded Java routine of the original implementation.
The improvements on total time depend on the ratio be-
tween the number of client inputs and the circuit size: for
circuits with many client inputs (§7.1, §7.2, §7.3), we obtain
a speedup by factor 2 to 9, whereas for large circuits with
few inputs (§7.4) the improvement for OTs has a negligible
eﬀect on the total runtime. To further improve the runtime
of large circuits, a faster engine for circuit garbling, e.g., [4],
could be combined with our improved OT implementation.
For the GMW framework [49], the total runtime is domi-
nated by the time for performing OT extension, which we
reduce by factor 2.

Acknowledgements. We thank David Evans and the anony-
mous reviewers of ACM CCS for their helpful comments on
our paper. The ﬁrst two authors were funded by the Eu-
ropean Research Council under the European Union’s Sev-
enth Framework Programme (FP/2007-2013) / ERC Grant
Agreement n. 239868. The third and fourth author were
supported by the German Federal Ministry of Education and
Research (BMBF) within EC SPRIDE and by the Hessian
LOEWE excellence initiative within CASED.

8. REFERENCES
[1] D. Beaver. Eﬃcient multiparty protocols using circuit

randomization. In Advances in Cryptology –
CRYPTO’91, volume 576 of LNCS, pages 420–432.
Springer, 1991.

[2] D. Beaver. Correlated pseudorandomness and the

complexity of private computations. In Symposium on

Theory of Computing (STOC’96), pages 479–488.
ACM, 1996.

[3] M. Bellare, S. Goldwasser, and D. Micciancio.

“pseudo-random” number generation within
cryptographic algorithms: The DDS case. In Advances
in Cryptology – CRYPTO’97, volume 1294 of LNCS,
pages 277–291. Springer, 1997.

[4] M. Bellare, V. Hoang, S. Keelveedhi, and P. Rogaway.

Eﬃcient garbling from a ﬁxed-key blockcipher. In
Symposium on Security and Privacy, pages 478–492.
IEEE, 2013.

[5] A. Ben-David, N. Nisan, and B. Pinkas. FairplayMP:

a system for secure multi-party computation. In
Computer and Communications Security (CCS’08),
pages 257–266. ACM, 2008.

[6] J. Boyar and R. Peralta. The exact multiplicative

complexity of the Hamming weight function.
Electronic Colloquium on Computational Complexity
(ECCC’05), (049), 2005.

[7] R. Canetti. Security and composition of multiparty

cryptographic protocols. J. Cryptology, 13(1):143–202,
2000.

[8] S. G. Choi, K.-W. Hwang, J. Katz, T. Malkin, and
D. Rubenstein. Secure multi-party computation of
Boolean circuits with applications to privacy in on-line
marketplaces. In Cryptographers’ Track at the RSA
Conference (CT-RSA’12), volume 7178 of LNCS,
pages 416–432. Springer, 2012.

[9] E. De Cristofaro and G. Tsudik. Practical private set

intersection protocols with linear complexity. In
Financial Cryptography and Data Security (FC’10),
volume 6052 of LNCS, pages 143–159. Springer, 2010.

[10] J. O. Eklundh. A fast computer method for matrix

transposing. IEEE Transactions on Computers,
C-21(7):801–803, 1972.

[11] Z. Erkin, M. Franz, J. Guajardo, S. Katzenbeisser,
I. Lagendijk, and T. Toft. Privacy-preserving face
recognition. In Privacy Enhancing Technologies
Symposium (PETS’09), volume 5672 of LNCS, pages
235–253. Springer, 2009.

[12] S. Even, O. Goldreich, and A. Lempel. A randomized
protocol for signing contracts. Communmunications of
the ACM, 28(6):637–647, 1985.

[13] K. Frikken, M. Atallah, and C. Zhang.

Privacy-preserving credit checking. In Electronic
Commerce (EC’05), pages 147–154. ACM, 2005.

[14] O. Goldreich. Foundations of Cryptography, volume 2:
Basic Applications. Cambridge University Press, 2004.

545[15] O. Goldreich, S. Micali, and A. Wigderson. How to

play any mental game or a completeness theorem for
protocols with honest majority. In Symposium on
Theory of Computing (STOC’87), pages 218–229.
ACM, 1987.

[16] S. D. Gordon, J. Katz, V. Kolesnikov, F. Krell,
T. Malkin, M. Raykova, and Y. Vahlis. Secure
two-party computation in sublinear (amortized) time.
In Computer and Communications Security (CCS’12),
pages 513–524. ACM, 2012.

[17] D. Harnik, Y. Ishai, E. Kushilevitz, and J. B. Nielsen.

OT-combiners via secure computation. In Theory of
Cryptography (TCC’08), volume 4948 of LNCS, pages
393–411. Springer, 2008.

[18] J. H˚astad and A. Shamir. The cryptographic security
of truncated linearly related variables. In Symposium
on Theory of Computing (STOC’85), pages 356–362.
ACM, 1985.

[19] W. Henecka, S. K¨ogl, A.-R. Sadeghi, T. Schneider,
and I. Wehrenberg. TASTY: Tool for Automating
Secure Two-partY computations. In Computer and
Communications Security (CCS’10), pages 451–462.
ACM, 2010.

[20] W. Henecka and T. Schneider. Faster secure two-party

computation with less memory. In ACM Symposium
on Information, Computer and Communications
Security (ASIACCS’13), pages 437–446. ACM, 2013.
[21] A. Holzer, M. Franz, S. Katzenbeisser, and H. Veith.

Secure two-party computations in ANSI C. In
Computer and Communications Security (CCS’12),
pages 772–783. ACM, 2012.

[22] Y. Huang, P. Chapman, and D. Evans.

Privacy-preserving applications on smartphones. In
Hot topics in security (HotSec’11). USENIX, 2011.

[23] Y. Huang, D. Evans, and J. Katz. Private set

intersection: Are garbled circuits better than custom
protocols? In Network and Distributed Security
Symposium (NDSS’12). The Internet Society, 2012.
[24] Y. Huang, D. Evans, J. Katz, and L. Malka. Faster

secure two-party computation using garbled circuits.
In Security Symposium. USENIX, 2011.

[25] Y. Huang, J. Katz, and D. Evans.

Quid-pro-quo-tocols: Strengthening semi-honest
protocols with dual execution. In Symposium on
Security and Privacy, pages 272–284. IEEE, 2012.

computation. In Computer and Communications
Security (CCS’11), pages 703–714. ACM, 2011.
[31] V. Kolesnikov, A.-R. Sadeghi, and T. Schneider.

Improved garbled circuit building blocks and
applications to auctions and computing minima. In
Cryptology And Network Security (CANS’09), volume
5888 of LNCS, pages 1–20. Springer, 2009.

[32] V. Kolesnikov and T. Schneider. Improved garbled

circuit: Free XOR gates and applications. In
International Colloquium on Automata, Languages
and Programming (ICALP’08), volume 5126 of LNCS,
pages 486–498. Springer, 2008.

[33] H. Krawczyk. Cryptographic extraction and key
derivation: The HKDF scheme. In Advances in
Cryptology – CRYPTO’10, volume 6223 of LNCS,
pages 631–648. Springer, 2010.

[34] B. Kreuter, A. Shelat, and C.-H. Shen. Billion-gate

secure computation with malicious adversaries. In
Security Symposium. USENIX, 2012.

[35] P. MacKenzie, A. Oprea, and M. K. Reiter. Automatic

generation of two-party computations. In Computer
and Communications Security (CCS’03), pages
210–219. ACM, 2003.

[36] L. Malka. VMCrypt - modular software architecture

for scalable secure computation. In Computer and
Communications Security (CCS’11), pages 715–724.
ACM, 2011.

[37] D. Malkhi, N. Nisan, B. Pinkas, and Y. Sella. Fairplay
— a secure two-party computation system. In Security
Symposium, pages 287–302. USENIX, 2004.

[38] A. Menezes, P. C. van Oorschot, and S. A. Vanstone.
Handbook of Applied Cryptography. CRC Press, 1996.

[39] S. Nagaraja, P. Mittal, C.-Y. Hong, M. Caesar, and

N. Borisov. Botgrep: Finding P2P bots with
structured graph analysis. In Security Symposium,
pages 95–110. USENIX, 2010.

[40] M. Naor and B. Pinkas. Eﬃcient oblivious transfer
protocols. In ACM-SIAM Symposium On Discrete
Algorithms, SODA ’01, pages 448–457. Society for
Industrial and Applied Mathematics, 2001.

[41] A. Narayanan, N. Thiagarajan, M. Lakhani,

M. Hamburg, and D. Boneh. Location privacy via
private proximity testing. In Network and Distributed
Security Symposium (NDSS’11). The Internet Society,
2011.

[26] Y. Huang, L. Malka, D. Evans, and J. Katz. Eﬃcient

[42] J. B. Nielsen. Extending oblivious transfers eﬃciently

privacy-preserving biometric identiﬁcation. In Network
and Distributed Security Symposium (NDSS’11). The
Internet Society, 2011.

[27] Intelligence Advanced Research Projects Activity

(IARPA). Security and Privacy Assurance Research
(SPAR) Program, 2010.

[28] Y. Ishai, J. Kilian, K. Nissim, and E. Petrank.

Extending oblivious transfers eﬃciently. In Advances
in Cryptology – CRYPTO’03, volume 2729 of LNCS,
pages 145–161. Springer, 2003.

[29] A. Jarrous and B. Pinkas. Secure hamming distance

based computation and its applications. In Applied
Cryptography and Network Security (ACNS’09),
volume 5536 of LNCS, pages 107–124. Springer, 2009.

[30] F. Kerschbaum. Automatically optimizing secure

- how to get robustness almost for free. Cryptology
ePrint Archive, Report 2007/215, 2007.

[43] J. B. Nielsen, P. S. Nordholt, C. Orlandi, and S. S.

Burra. A new approach to practical active-secure
two-party computation. In Advances in Cryptology –
CRYPTO’12, volume 7417 of LNCS, pages 681–700.
Springer, 2012.

[44] V. Nikolaenko, U. Weinsberg, S. Ioannidis, M. Joye,

D. Boneh, and N. Taft. Privacy-preserving ridge
regression on hundreds of millions of records. In
Symposium on Security and Privacy, pages 334–348.
IEEE, 2013.

[45] NIST. NIST Special Publication 800-57,

Recommendation for Key Management Part 1:
General (Rev. 3). Technical report, 2012.

546[46] M. Osadchy, B. Pinkas, A. Jarrous, and B. Moskovich.

SCiFI - a system for secure face identiﬁcation. In
Symposium on Security and Privacy, pages 239–254.
IEEE, 2010.

[47] B. Pinkas, T. Schneider, N. P. Smart, and S. C.

Williams. Secure two-party computation is practical.
In Advances in Cryptology – ASIACRYPT’09, volume
5912 of LNCS, pages 250–267. Springer, 2009.

[48] M. O. Rabin. How to exchange secrets with oblivious

transfer, TR-81 edition, 1981. Aiken Computation
Lab, Harvard University.

[49] T. Schneider and M. Zohner. GMW vs. Yao? Eﬃcient
secure two-party computation with low depth circuits.
In Financial Cryptography and Data Security (FC’13),
LNCS. Springer, 2013.

[50] A. Schr¨opfer and F. Kerschbaum. Demo: secure

computation in JavaScript. In Computer and
Communications Security (CCS’11), pages 849–852.
ACM, 2011.

[51] A. C. Yao. How to generate and exchange secrets. In
Foundations of Computer Science (FOCS’86), pages
162–167. IEEE, 1986.

APPENDIX
A. DEFINITIONS
We let κ denote the security parameter. A function µ(·)
is negligible if for every positive polynomial p(·) and all suf-
ﬁciently large n it holds that µ(n) < 1/p(n). A distribution
ensemble X = {X(a, n)}a∈Dn,n∈N is an inﬁnite sequence of
random variables indexed by a ∈ Dn and n ∈ N. Two dis-
tribution ensembles X, Y are computationally indistinguish-
c≡ Y if for every non-uniform polynomial
able, denoted X
time algorithm D there exists a negligible function µ(·) such
that for every n, and every a ∈ Dn:

|Pr [D(X(a, n), a, n) = 1] − Pr [D(Y (a, n), a, n]| ≤ µ(n).
Key Derivation Function. The following deﬁnition is
an adaptation of the general deﬁnition of [33] for the case
of the DDH problem. Intuitively, the adversary should not
be able to distinguish between an output of the KDF func-
tion and a uniform string. Let Gen(1κ) be a function that
produces a group (G, q, g) for which the DDH problem is
believed to be hard. We deﬁne:

Definition A.1

(Key-Derivation Function). A key
derivation function KDF with (cid:96)-bit output is said to be secure
with respect to DDH if for any ppt attacker A there exists
a negligible function µ(·) such that:

|Pr [A(G, q, g, gr, h, KDF(hr)) = 1]

− Pr [A(G, q, g, gr, h, z) = 1]| ≤ µ(κ)

where (G, q, g) = Gen(1κ), r is distributed uniformly in Zq
and z is distributed uniformly in {0, 1}(cid:96).

Correlation Robust Function. We present a deﬁnition
for correlation robust function. The deﬁnition is based on
the deﬁnition in [28].

Definition A.2. [Correlation Robustness] An eﬃciently
computable function H : {0, 1}κ → {0, 1}(cid:96) is said to be cor-
relation robust if it holds that:

{t1, . . . , tm, H(t1 ⊕ s), . . . , H(tm ⊕ s)} c≡ {Um·κ+m·(cid:96)}

where t1, . . . , tm, s are chosen uniformly and independently
at random from {0, 1}κ, and Um·κ+m·(cid:96) is the uniform distri-
bution over {0, 1}m·κ+m·(cid:96).

Secure Two-Party Computation. We give a formal
deﬁnition for security of a two party protocol in the presence
of a semi-honest adversary. The deﬁnition is the standard
deﬁnition, see [7,14].The view of the party P0 during an exe-
cution of a protocol π on inputs (x, y), denoted viewπ
i (x, y),
is deﬁned to be (x, r; (cid:126)m) where x is P0’s private input, r its
internal coin tosses, and (cid:126)m are the messages it has received
in the execution. The view of P1 is deﬁned analogously. Let
outputπ(x, y) denote the output pair of both parties in a
real execution of the protocol. We are now ready to security
deﬁnition:

Definition A.3. Let f : ({0, 1}∗)2 → ({0, 1}∗)2 be a
(possible randomized) two–party functionality, and let fi(x, y)
denotes the ith element of f (x, y). Let π be a protocol.
We say that π privately–computes f if for every (x, y) ∈
({0, 1}∗)2: outputπ(x, y) = f (x, y) and there exists a pair
of probabilistic polynomial-time ppt algorithms S0,S1:
{S0(x, f0(x, y)), f (x, y)}z
{S1(y, f1(x, y)), f (x, y)}z
where z = (x, y) ∈ ({0, 1}∗)2.

0 (x, y), outputπ(x, y)}z
1 (x, y), outputπ(x, y)}z

c≡ {viewΠ
c≡ {viewΠ

In case the function f is deterministic (like in the OT func-
tionality), there is no need to consider the joint distribution
of the outputs and the view, and it is enough to show that
the output of the simulator Si is indistinguishable from the
view of the party Pi.

B. MULTIPLICATION TRIPLE PROTOCOL
In this section, we show that the protocol presented in
§5.1 privately computes the multiplication triple functional-
ity.
First, we consider the f ab functionality. The protocol im-
plements the functionality since any random (b, v), (a, u), for
which ab = u⊕v, can be written as (b, v) = (x0⊕x1, x0) and
(a, u) = (a, ab ⊕ v) = (a, xa), since it holds that: ab ⊕ v =
ab ⊕ x0 = a(x0 ⊕ x1) ⊕ x0 = xa. The inputs and outputs of
each party fully determine its view, and therefore simulators
are trivial and just re–arrange their inputs. Consistency of
the generated view with the output of the parties holds triv-
ially.
We turn to the multiplication triple functionality. It is easy
to verify that the protocol implements the functionality.
Regarding simulation, a simulator S0 is given (a0, b0, c0),
chooses random u0 and deﬁnes: v0 = c0 ⊕ a0b0 ⊕ u0. Since
u0, v0 are random and hidden from the distinguisher, the
view is consistent with (a1, b1, c1). A simulator for S1 works
the same, and security holds from the same reasoning (i.e.,
v1 = a0b1 ⊕ u0 is random since u0 is hidden from the distin-
guisher, and v1 is fully determined from c1, a1, b1, u1).

547