Dialing Back Abuse on Phone Veriﬁed Accounts

(cid:2)

Kurt Thomas
Tadek Pietraszek

Dmytro Iatskiv
(cid:2)
Chris Grier

(cid:2)
†∗

(cid:2)

Elie Bursztein
Damon McCoy

‡

(cid:2)

†

Google, Inc

University of California, Berkeley

‡

∗

International Computer Science Institute

George Mason University

{kurtthomas, diatskiv, elieb, tadek}@google.com

grier@cs.berkeley.edu

mccoy@cs.gmu.edu

ABSTRACT
In the past decade the increase of for-proﬁt cybercrime has
given rise to an entire underground ecosystem supporting
large-scale abuse, a facet of which encompasses the bulk reg-
istration of fraudulent accounts. In this paper, we present a
10 month longitudinal study of the underlying technical and
ﬁnancial capabilities of criminals who register phone veriﬁed
accounts (PVA). To carry out our study, we purchase 4,695
Google PVA as well as pull a random sample of 300,000
Google PVA that Google disabled for abuse. We ﬁnd that
miscreants rampantly abuse free VOIP services to circum-
vent the intended cost of acquiring phone numbers, in eﬀect
undermining phone veriﬁcation. Combined with short lived
phone numbers from India and Indonesia that we suspect
are tied to human veriﬁcation farms, this conﬂuence of fac-
tors correlates with a market-wide price drop of 30–40% for
Google PVA until Google penalized veriﬁcations from fre-
quently abused carriers. We distill our ﬁndings into a set of
recommendations for any services performing phone veriﬁ-
cation as well as highlight open challenges related to PVA
abuse moving forward.

Categories and Subject Descriptors
K.4.1 [Public Policy Issues]: Abuse and crime involving
computers

Keywords
Account abuse; phone veriﬁcation; underground economies

1.

INTRODUCTION

In the past decade the increase of for-proﬁt cybercrime
has given rise to an entire underground ecosystem support-
ing large-scale abuse, a facet of which encompasses the bulk
registration of fraudulent accounts. Miscreants leverage this
market to obtain cheap email addresses and social network

credentials for as little as 0.50¢ an account [26], in turn fu-

eling spam and abuse at the expense of millions of users.

third-party components of this work must be

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage, and that copies bear this notice and the full ci-
tation on the ﬁrst page.Copyrights for components of this work owned by others
than ACM must be honored. Abstracting with credit is permitted.  To copy
otherwise, or republish, to post on servers or to redistribute to lists, requires 
prior specific permission and/or a fee. Request permissions from 
Permissions@acm.org.  Copyrights
Copyright is held by the owner/author(s). Publication rights licensed to ACM
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
ACM 978-1-4503-2957-6/14/11.
http://dx.doi.org/10.1145/2660267.2660321.

For all other uses,

the owner/author(s).

honored.

.author/owner(s).

contact

Copyright

is held by the

The deluge of messages that follow seek to monetize victims
in a variety of manners:
from spamvertised products [14]
to phishing and malware attacks that perpetrate software
scams [22], clickfraud [7], banking theft [23], or convert in-
fected victims into assets for the pay-per-install market [5].
Web services attempt to rate limit this torrent of auto-
matically generated accounts through CAPTCHAs, email
veriﬁcation, and most recently phone veriﬁcation. While
CAPTCHAs and email accounts are trivially available from
the underground for relatively low prices [15, 26], ideally
phone numbers represent a scarce resource for criminals that
are otherwise globally accessible to legitimate users [16, 17].
Consequently, when Google deployed phone veriﬁcation as
a signup protection, prices on the underground surged from
$30 per 1K to over $500. Yet there are signs that criminals
have streamlined the circumvention of phone veriﬁcation.
Prices for Google accounts have declined to as low as $85
per 1K at the time of this study.

In this paper, we present a longitudinal study of the un-
derlying technical and ﬁnancial factors inﬂuencing the di-
minishing eﬀectiveness of phone veriﬁcation. To conduct
our study, we track phone veriﬁed account (PVA) abuse on
Google over a 10 month period from July, 2013–April, 2014.
Our perspective includes 4,695 accounts purchased from a
cross-section of 14 account merchants selling Google PVA
on blackmarket forums and storefronts as well as a sample
of 300,000 PVA disabled by Google for abuse. We rely on
these dual datasets to monitor the pricing and organization
of the market for phone veriﬁed accounts; evaluate how mis-
creants circumvent the intended cost of phone veriﬁcation;
and identify a set of recommendations for preserving the
long term viability of phone veriﬁcation.

We ﬁnd that merchants are capable of registering a steady
stream of thousands of PVA that subsequently sell for $85–
$500 per 1K to the underground. This wildly diﬀerent price
range reﬂects both the ﬁnancial barrier imposed by phone
veriﬁcation (where some merchants advertise real SIM cards
from a variety of regions and prices) as well as the inﬂuence
of account resellers operating in a similar fashion to spam
aﬃliate programs [14]. Merchants fulﬁll orders for fully func-
tioning, phone veriﬁed accounts within 24–48 hours, though
the lifetime of accounts is dubious; 68% of the PVA we pur-
chase are disabled within a month of their changing hands
despite laying dormant, likely due to re-used infrastructure.
We analyze the registration process tied to abusive PVA to
understand the root source of phone numbers and the most
frequently abused carriers. We ﬁnd that 24% of PVA dis-

abled by Google are veriﬁed with free VOIP numbers from
Bandwidth.com (which services Google Voice, Pinger, and
other providers [3]), eﬀectively allowing miscreants to cir-
cumvent the cost of acquiring SIM cards. The remaining
accounts in our dataset are veriﬁed with phone numbers
tied to a variety of mobile carriers, the most popular of
which originate from India and Indonesia. We ﬁnd evidence
these regions are traditionally related to CAPTCHA farms
and underground hired labor, suggesting that abusive phone
veriﬁcation may be a manual endeavor. Combined with reg-
ular re-use of short lived phone numbers, this conﬂuence of
factors correlates with a market-wide price drop of 30–40%
for Google PVA from November, 2013–February, 2014 until
Google penalized veriﬁcations from frequently abused carri-
ers.

Based on our ﬁndings, we produce a set of recommen-
dations and best practices for services that rely on phone
veriﬁcation.
In particular, we propose a carrier reputa-
tion system that automatically penalizes SMS and VOIP
providers consistently associated with abusive accounts. Al-
ternative approaches—such as blacklisting phone numbers
upon abuse detection to prevent re-use—are too slow com-
pared to the velocity that phone numbers appear and disap-
pear. Ultimately, we argue that a global phone number rep-
utation similar to IP and domain reputation systems [1, 12]
is required to prevent miscreants from amortizing the cost
of abusive SIMs and VOIP numbers across multiple ser-
vices, as well as to prepare for the potential of compromised
phones—already a challenge for banking two-factor authen-
tication [27]—serving as a platform for verifying accounts in
the future.

In summary, we frame our contributions as follows:
• We conduct a 10-month longitudinal study of the ﬁ-
nancial and technical challenges related to phone ver-
iﬁed abuse.
• We ﬁnd an increased reliance on VOIP numbers and in-
expensive SIMs from India and Indonesia—likely tied
to manual veriﬁcation farms—correlate with a price
drop of 30–40% for Google PVA.
• We evaluate a number of underground practices in-
cluding phone re-use, phone access durations, and pre-
ferred carriers.
• We distill our ﬁndings into a set of recommendations
and best practices for services that rely on phone ver-
iﬁcation.

2. BACKGROUND

Phone veriﬁcation is a single iteration in a long evolution
of abuse safeguards that aim to prevent the bulk registration
of accounts. We provide an overview of the process behind
phone veriﬁcation, how the underground market has under-
mined prior protections, and privacy and ethical standards
we obied by when studying phone veriﬁed abuse.
2.1 Phone Veriﬁcation Process

Phone veriﬁcation serves as both an initial signup protec-
tion as well as an abuse escalation where services prevent
suspicious account from conducting further actions until af-
ter veriﬁcation. To start the veriﬁcation process, a client
provides a number they wish to associate with their account.
The server then sends a challenge PIN via SMS or voice to

that number which the client must correctly enter into a web
form to prove receipt and complete the process. Phone ver-
iﬁcation is currently employed by Google, Facebook, Twit-
ter, LinkedIn, and Craigslist among other services to combat
abuse as well as for security and account recovery purposes.
Phone veriﬁcation imposes a cost on both criminals and
services. For criminals, a single number typically has a hard
limit on the quantity of accounts it can be associated with.
Re-use also exposes bulk accounts to clustering where one
abuse violation can trigger a cascade of deactivations across
correlated accounts. Consequently, miscreants require a con-
stant stream of fresh numbers to seed registrations. Con-
versely, services employing phone veriﬁcation as a defense
incur a fee for each SMS or voice challenge. This exposes
services to typical operational costs as well as resource ex-
haustion attacks where miscreants request SMS veriﬁcation
for a deluge of numbers tied to expensive carriers to incur
exorbitant SMS fees, a threat we discuss further in Section 6.
2.2 Evolution of Abuse Safeguards

Phone veriﬁcation builds on a history of defenses that in-
cludes IP reputation, CAPTCHAs, and email veriﬁcation.
Ideally, these are scarce resources for criminals to acquire
that otherwise exert little friction on legitimate users.
In
practice, many of these components are readily available
from the underground.

IP Addresses: Services can leverage IP addresses as a weak
identity tied to newly registered accounts. When thousands
of accounts are registered from a single IP, there is a strong
likelihood of abuse. To circumvent detection, criminals rely
on compromised hosts and proxy services to acquire access
to tens of thousands of IPs [26]. Anecdotally, we see adver-
tisements for proxies as low as $250/mo for 15,000–30,000
IPs on blackmarket forums.

CAPTCHAs: CAPTCHAs—intended as human-solvable
tasks that prevent automation—have become a staple of
the underground economy [15]. Services such as http://
spamvilla.com advertise automated CAPTCHA solvers with
50% accuracy for $30/mo, while human CAPTCHA farms
such as http:// antigate.com outsource CAPTCHA solving
to an array of laborers operating out of India, Pakistan,
Ukraine, Russia, Vietnam, and Indonesia for $0.70 per 1K
solutions. The availability of manual solvers undermines
the feasibility of CAPTCHAs (though such services are not
free).

Email Veriﬁcation: Email veriﬁcation serves to tie the
rate miscreants can create accounts to the rate they can
acquire email addresses. This eﬀectively outsources abuse
prevention to email providers who in turn must rely on al-
ternative signals. In response, email addresses have become
a fundamental resource of the underground. Hotmail.com
and Yahoo.com accounts are available from merchants for
as low as $5 per 1K [26].

Each of these scenarios highlight how the underground
evolves over time to respond to new defenses. While bleak
from a defenders perspective, each successive protection in-
creases the cost of accounts, cutting into the bottom line of
spam and abuse.
2.3 Privacy and Ethical Considerations

Part of our study requires interacting with underground
merchants selling Google phone veriﬁed accounts as well as

466

analyzing registration data tied to abusive signups. We build
on the guidelines originally discussed by Thomas et al. [26]
for interacting with the account underground. Prior to our
study, we worked with the authors respective institutions as
well as Google to set down a policy for purchasing accounts.
We conduct all purchases (which would otherwise violate
Google’s Terms of Service) with Google’s express permis-
sion. Furthermore, even though merchants provide us with
passwords, we never access accounts. Finally, we restrict our
analysis to merchants who publicly advertise Google phone
veriﬁed accounts; we do not purchase accounts beyond this
scope nor attempt to deceive or coerce the merchants in-
volved.

3. CAPTURING ABUSIVE ACCOUNTS

To conduct our study, we rely on two sources of phone
veriﬁed accounts (PVA): purchased accounts acquired from
a cross section of the underground economy and a sample
of abusive accounts disabled by Google for Terms of Service
violations related to spam and abuse. We combine these two
datasets to provide insights into the pricing of phone veriﬁed
accounts as well as to understand the scope of Google phone
veriﬁed abuse.
3.1 Purchased Accounts

Our purchased account dataset consists of 2,217 PVA that
we buy in July 2013 at the onset of our study and a sec-
ond set of 2,478 we purchase at the conclusion of our study
in April 2014. We rely on purchasing to validate the au-
thenticity of merchants as well as to understand the market
organization for phone veriﬁed accounts. We provide an
overview of how we identify account merchants, the prices
they charge, and the duration merchants stockpile accounts.
We ﬁnd that 68% of the accounts we purchase in July are dis-
abled by Google’s infrastructure within one month. Given
this high coverage, we elected not to conduct regular repur-
chases and instead concentrate our analysis on PVA disabled
by Google throughout our study. We believe this minimizes
our ﬁnancing of underground merchants without sacriﬁcing
access to a representative sample of PVA abuse. We rely
on our second purchase in April 2014 to understand how
the market has adapted, providing a detailed comparison in
Section 5. We restrict the remainder of our discussion in
this section to our ﬁrst purchase set.

3.1.1 Merchants
We identify a cross section of 14 merchants advertising ac-
cess to Google accounts (among other services) on web store-
fronts, blackhat forums, and freelance labor pages. For oper-
ational concerns we refrain from documenting the identities
of the merchants we solicit. Advertisements range in so-
phistication from automatically generated accounts with no
proﬁle information to “manually generated” accounts with
“real SIM cards” from Eastern Europe which cost substan-
tially more. From this bazaar, we elect to purchase 2,217
PVA split across 3 merchants on blackhat forums and 4 mer-
chants operating their own storefronts in July, 2013. Mer-
chants fulﬁlled all orders in 24-48 hours with working, phone
veriﬁed accounts. We provide a summary of these purchases
in Table 1 which we reference throughout this section.

As an extension of purchasing, we also track the pricing
of Google PVA (and non-PVA) based on public listings ad-

Asset
Google PVA
Google PVA
Google PVA
Google PVA
Google PVA
Google+ PVA
YouTube PVA
YouTube PVA
YouTube PVA
YouTube PVA
YouTube PVA

Price/1K Volume Disabled
77%
89%
100%
0%
11%
100%
100%
5%
0%
28%
0%

105
1,000
168
100
103
81
220
98
192
100
50

$85
$100
$172
$200
$300
$135
$95
$153
$276
$300
$500

Table 1: List of assets we purchase, the associated price
per 1K, the volume we purchase, and whether the accounts
are eventually disabled.

$160

d
n
a
s
u
o
h
T
 
r
e
p

$140

$120

$100

● ● ● ● ●

● ●

● ●

● ● ● ● ● ● ● ●

● ● ● ● ● ● ● ● ●

 

e
c
i
r

P

$80

$60

Jul

Oct

Jan

Apr

● ● ● ● ● ● ● ●

Figure 1: Historical pricing data for Google PVA mer-
chants from July, 2013–April, 2014. A market wide price
decrease of 30–40% is visible from November until February
for PVA.

1

We poll this
vertised by 6 of the 14 merchants we identify.
data on a weekly basis from July, 2013 until the conclusion
of our study in April, 2014. We rely on this historical pric-
ing data to understand the stability of the PVA marketplace
and to understand how price correlates with adaptations in
phone veriﬁcation techniques. When available, we also track
the prices of Facebook and Twitter PVA accounts which we
use to understand the burden imposed by phone veriﬁcation
as a general technique.
3.1.2 Account Pricing
Prices for the accounts we purchase in July, 2013 range
from $85 per 1K at the lowest and $500 at the highest, as
detailed in Table 1. We provide a breakdown of the his-
torical prices these and other merchants charge throughout
our study in Figure 1, with prices over $250 omitted for
clarity. Prices in this upper bracket were $250, $300, $350,
$500, and $600 per 1K accounts. These prices never changed
throughout our monitoring.

Despite a large pool of competing storefronts, we ﬁnd no
evidence of merchants attempting to undercut one another
by lowering prices. Instead, the cost of Google PVA remain
ﬁxed throughout our study, with the exception of a single
1

Other merchants rely on email or Skype conversations to
determine up-to-date pricing which precludes passive moni-
toring.

467

Service
Google
Youtube
Youtube
Google
Google
Facebook
Facebook
Facebook
Twitter

Reg. Cost PVA Cost
$100
$349
$150
$230
$500
$600
$350
$1800
$500

$80
$270
$80
$120
$80
$300
$70
$400
$20

Increase
1.25x
1.29x
1.875x
1.9x
6.25x
2x
5x
4.5x
25x

Table 2: Price diﬀerence between phone veriﬁed and reg-
ular accounts for Google, Facebook, and Twitter based on
advertisements from 3 merchants. Despite a wide range of
prices, phone veriﬁcation tends to impose a 1.25x–6.25x in-
crease, with the exception of Twitter at 25x.

market-wide drop lasting November, 2013–February, 2014.
During this period, almost all of the merchants we tracked
(with the exception of those in the upper bracket) lowered
their pricing by 30–40% before returning to their previous
rate. The correlated behavior of merchants leads us to be-
lieve that many storefronts are merely resellers for the same
miscreant in a similar fashion to spam aﬃliate programs [14].
3.1.3 Cost of Phone Veriﬁcation
The primary goal of phone veriﬁcation is to throttle the
rate miscreants can register fraudulent accounts, and as a
byproduct, increase the cost of credentials. While we can-
not determine the fees that merchants pay to acquire fresh
phone numbers, we can measure how merchants pass these
costs on to blackmarket consumers. Of the merchants we
track, three simultaneously advertised non-PVA and PVA
equivalents for Google as well as Facebook, while one mer-
chant advertised access to Twitter non-PVA and PVA. (We
were unable to ﬁnd merchants advertising both LinkedIn or
Craigslist PVA and non-PVA.) We use these merchants to
measure the price increase imposed by phone veriﬁcation.
Assuming that merchants rely on the same infrastructure
to register PVA and non-PVA, this allows us to isolate the
impact of phone veriﬁcation from variable merchant sophis-
tication and registration safeguards across services.

Table 2 shows the relative price increase underground mer-
chants charge for phone veriﬁcation. While the base price
of accounts are wildly diﬀerent between merchants, this in-
crease is relatively ﬁxed: 1.25x–6.25x for Google and 2–5x
for Facebook. The 25x increase for Twitter is likely a re-
sult of merchants not yet adapting to phone veriﬁcation on
the service, with PVA accounts emerging only at the end
of March, 2014 (a month before our study concluded). We
observed a similar drastic price diﬀerence with the initial
release of Google PVA in 2012, where prices were 17x their
non-PVA equivalent. We note that a direct comparison be-
tween PVA multipliers is diﬃcult due to varying service-level
policies on the number of accounts that can be associated
with a single phone or whether certain phone numbers are
prohibited as veriﬁcation endpoints.

We caution there is no indication whether blackmarket
consumers are willing to bare the fees charged by account
merchants. Equally opaque is whether the price diﬀeren-
tial between non-PVA and PVA accounts is grounded in the
scarcity of phone numbers, demand, or consumer naivety.
Consequently, we explore the relation between phone veriﬁ-

cation techniques and market price, particularly during the
market-wide price reduction, further in Section 4.

Stockpiling

3.1.4
The freshness of accounts is an important metric for
whether merchants conduct real-time bulk registrations or
instead rely on outdated stockpiles. We measure the age
of the 2,217 accounts we purchase as the delta between the
time we order accounts versus the time merchants registered
the accounts. Accounts range in age from 1–164 days, with
an average age of roughly 27 days. Our results indicate
that merchants are not reliant on old stockpiles, but in-
stead have access to recently registered accounts. Paired
with stable pricing throughout our analysis, this suggests
that merchants have a regular supply of phone numbers at
their disposal.

3.1.5 Disable Rate
Inactive accounts that merchants stockpile are not im-
mune to abuse detection. We measure the volume of ac-
counts per merchant that Google disables (independent of
our purchasing and analysis), shown in Table 1. Overall,
Google disables roughly 68% of the accounts we acquire
within one month of their purchase. We ﬁnd that cheaper
accounts are more frequently correlated with being caught
and deactivated by Google, indicating that price may have
some bearing on the eﬀort account merchants put into bulk
registering accounts (e.g. limiting the reuse of infrastructure
to avoid clustering). For the purposes of our study, the high
recall rate allows us to rely on sampling abusive accounts
disabled by Google without risk of omitting a large mar-
ket segment of PVA abuse. We note however that without
regular repurchases, we cannot guarantee the detection rate
remains stable throughout our analysis.
3.2 Abusive Accounts

The bulk of our analysis relies on a retroactive random
sample of 300,000 Google PVA created and disabled for
spam and abuse between July, 2013–April, 2014. No ac-
count information ever leaves Google datacenters or is ac-
cessed in non-aggregate form by external researchers. For
each of these accounts (as well as our purchased account
dataset), we have access to the registration IP, registration
phone number, and other signals tied to the registration
process. We note that due to potential delays in abuse de-
tection, we may underestimate the volume of abuse towards
the tail end of our collection period. We consider this lim-
itation whenever we discuss trends in the volume of abuse
over time or changes in registration behaviors.

4. ANALYZING ABUSIVE ACCOUNTS

A fundamental question of our investigation is the sus-
tainability of phone veriﬁcation as a defense against bulk
account creation. We ﬁnd evidence that phone veriﬁed abuse
is a persistent threat. To dissect this problem, we analyze
the origin of abusive number and techniques miscreants use
to maximize the value they garner from a single phone num-
ber. We relate these technical measurements that capture
the complexity of creating phone veriﬁed accounts to the
prices merchants charge. Finally, we analyze the eﬀective-
ness of other registration safeguards including IP reputation,
CAPTCHAs, and secondary email addresses.

468

4.1 Origin of Abusive Phone Numbers

We examine multiple facets tied to the origin of phone
numbers including the country of origin, the carrier provid-
ing service, and whether fraudulent accounts are registered
with collocated IPs and phone numbers. We acquire these
database used by Google
phone signals from an MSISDN
to map phone numbers to carrier data (including whether
the number is VOIP). We note that similar databases are
publicly available, though typically for some fee.

2

4.1.1 Breakdown by Country
We examine the country code of each phone number as-
sociated with our abusive and purchased accounts to cap-
ture which regions serve as the most popular veriﬁcation
endpoints. We ﬁnd that the United States is the single
largest origin of phone numbers, accounting for 27% of abu-
sive PVA in our dataset. This is followed in popularity by
India (22%), Indonesia (12%), Nigeria (4%), South Africa
(4%), and Bangladesh (4%), with other regions accounting
for 28% of abuse. We note that receiving an SMS in all of
these top countries other than the United States is free.

Bulk access to phone numbers in these regions appears to
be a variable process. Figure 2 shows a weekly breakdown
of the top six countries serving as veriﬁcation endpoints
throughout our study. Phones from India, while prevalent
at the onset of our measurement (contributing nearly 40% of
new PVA), has fallen oﬀ in favor of Indonesia. In contrast,
phones from the United States dominate 60% of new PVA
registrations from October–February. This period overlaps
with the drastic price reduction we observe from November–
February, a phenomenon we explore further in the next sec-
tion.

For the accounts we purchased at the onset of our study,
97% were veriﬁed with phone numbers from the United
States while 3% were associated with numbers from Ukraine.
We ﬁnd that only one of the 7 merchants we solicit rely on
non-US numbers.
If we examine pricing based on the re-
gion that phones numbers originate from, merchants appear
to charge arbitrarily for accounts veriﬁed with US numbers.
Such accounts range $85–300 per 1K accounts, while the sole
merchant verifying accounts from Ukraine charged $500 per
1K. Our ﬁndings indicate that the origin of phone numbers
alone cannot explain the cost of an account or why certain
merchants are more likely to have their stockpiles disabled.

4.1.2 Breakdown by Carrier
We further subdivide countries based on the abused car-
riers operating in each region, the results of which we show
in Table 3. Bandwidth.com—a VOIP provider in the US
tied to multiple free telephony services including Pinger and
Google Voice [3]—represents the single largest gateway for
abuse. This is followed in popularity by a multitude of mo-
bile carriers predominantly operating out of India and In-
donesia. We evaluate each of these veriﬁcation approaches
separately.

VOIP Abuse: VOIP in particular poses a signiﬁcant threat
to the intended cost of phone veriﬁcation. Services such as
Pinger [18] and TextPlus [24] allow new customers to regis-
ter for a free, SMS-receivable number in exchange for solving
a CAPTCHA or email veriﬁcation challenge. Such resources

2

An MSISDN is the unique international representation of

a phone number which is associated with a SIM card.

A
V
P
 
e
v
s
u
b
A

i

 
f
o
 
.
c
r
e
P
 
y
k
e
e
W

l

60%

40%

20%

0%

●●

●●●●●●●●●●

●●

●●●●●●●●●●●●●●●●●

●●●●●●●●●

Jul

Oct
Registration Date

Jan

Apr

country ● BD

ID

IN

NG

US

ZA

Figure 2: Weekly breakdown of the top 6 country codes
associated with abused phone numbers. The most popu-
lar origins of numbers are the United States (US), India
(IN), Indonesia (ID), Nigeria (NG), South Africa (ZA), and
Bangladesh (BD).

are cheaply available from the underground as we previously
discussed in Section 2. Similarly, services such as Google
Voice allow miscreants to convert an existing phone num-
ber (including US VOIP numbers) into multiple new phone
numbers. This creates an abuse multiplier that allows mis-
creants to amortize the cost of the original phone number
seed as well as mask the original carrier. All of these services
are available online, opening up the possibility for miscre-
ants to scrape page content to automate SMS veriﬁcation
challenges. In total, 24% of all abusive PVA in our dataset
were veriﬁed with VOIP numbers.

The merchants we solicit readily exploit cheap VOIP num-
bers to circumvent the intended cost of phone veriﬁcation.
Of the accounts we purchased, 97% were veriﬁed via num-
bers tied to a mixture of VOIP providers including Band-
width.com, Level 3, and Telengy. This trend is also repre-
sented in Figure 2 where 94% of all US numbers used to
verify accounts between October–January were VOIP. The
decrease in US phone numbers after January is the result
of Google penalizing new registrations tied to frequently
abused US VOIP providers. This conﬂuence of events cor-
relates with the 30–40% price drop in accounts that we ob-
serve from November–February after which prices returned
to their normal levels. While we cannot provide deﬁnitive
proof, our results suggest that market prices can serve as an
indicator of the underlying performance of abuse safeguards.

Mobile carriers: VOIP numbers alone do not explain the
entire phone veriﬁed abuse ecosystem; a second substantial
component is fueled by mobile carriers tied to India and
Indonesia including PT, Bharti, and Vodafone. Our un-
derstanding of how miscreants acquire phone numbers from
these regions and subsequently respond to SMS challenges is
less clear than VOIP. Anecdotally, when we conducted our
search to identify merchants selling PVA, we also encoun-
tered an underground market segment surrounding veriﬁca-
tion as a service. Sites such as http://sms-area.org adver-
tise automated APIs for phone verifying Vkontakte, Google,
and Facebook accounts. Prices for these services are as low

469

Rank Carrier
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
-

Bandwidth.Com
Pt
Bharti
Vodafone
Mtn
Idea
Telekomunikasi
Aircel
Tata
Viettel
Reliance
Mtn
Gramenphone
Vodacom
Bsnl
Excelcom
Hutchison
Level 3
Cell
Telengy
Other

Country Popularity
19.91%
7.29%
5.31%
4.04%
2.99%
2.79%
2.23%
2.11%
1.87%
1.71%
1.71%
1.52%
1.51%
1.29%
1.28%
1.16%
0.95%
0.86%
0.84%
0.81%
37.80%

US
ID
IN
IN
NG
IN
ID
IN
IN
VN
IN
ZA
BD
ZA
IN
ID
ID
US
ZA
US
-

Table 3: Top 20 carriers used by abusive phone veriﬁed ac-
counts. Veriﬁcation challenges are predominantly sent over
VOIP or to a concentrated set of carriers in India and In-
donesia.

as $140 per 1K veriﬁcation codes for mobile (non-VOIP)
numbers originating from Russia, Kazakhstan, and Belarus.
Similarly, miscreants can acquire SIM cards in bulk. We see
resellers advertising prices of $140–420 per 1K SIM cards
for Russian carriers such as Beeline, MTS, and MegaFon.
While we can only speculate, discussions we observe on un-
derground forums suggest that workers manually respond to
veriﬁcation challenges using modiﬁed cell phones to simplify
cycling through SIM cards. This reﬂects related strategies
for CAPTCHA solving that rely on manual laborers oper-
ating out of India and Indonesia as discussed in Section 2.

4.1.3 Collocation of Phones and IP Addresses
One potential measurement of the validity of a newly reg-
istered PVA is the collocation of a phone’s country of origin
and the geolocation of the IP address a miscreant uses to
register the account. Figure 3 shows a weekly breakdown
of the six most popular IP geolocations tied to signups at a
country granularity. We ﬁnd that trends in IP geolocation
nearly mirror that of phone origins (previously presented in
Figure 2). The exception to this trend is the decreased popu-
larity of US IP addresses, which may be a direct consequence
of the diﬃculty of purchasing hosts in the US from the pay-
per-install market [5] or the respective cost of freelance labor
in the US compared to other regions. Quantitatively, 60%
of abusive accounts in our dataset share the same IP and
phone origin, while the same is true for only 33% of pur-
chased accounts. This deviation for purchased accounts is a
consequence of the majority of phone numbers coming from
the United States while IPs originate in India, a trend that
is also reﬂected in Figure 3 for abusive accounts back in
July. Our results indicate that miscreants bulk registering
PVA take care to mimic the expected behavior of legitimate
registrations beyond avoiding clustering.

A
V
P
 
e
v
s
u
b
A

i

 
f
o
 
.
c
r
e
P
 
y
k
e
e
W

l

60%

40%

20%

0%

●●

●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●

Jul

Oct

Jan

Apr

country ● BR

ID

IN

US

VN

ZA

Figure 3: Geolocation of IPs related to abusive signups.
The most frequent source of abusive IPs mirrors that of abu-
sive sources of phone numbers.

4.2 Lifecycle of a Phone Number

Miscreants have a multitude of strategies for how they
leverage SMS access once acquired. We measure the number
of accounts that miscreants associate with the same phone
number, estimate the duration miscreants control phone
numbers, and identify whether miscreants opt for SMS or
voice challenges.

4.2.1 Phone Reuse
Miscreants can reuse a phone number multiple times to
amortize the cost of acquiring access to a VOIP number
or SIM card. For each phone numbers in our abusive ac-
count sample we calculate the total number of all registered
accounts that share the same number, regardless if Google
disabled those accounts for abuse. We repeat this process
again for phone numbers tied to purchased accounts. To
serve as a comparison, we also obtain re-use statistics tied
to a random sample of 300,000 benign phone numbers (pro-
vided by Google). Figure 4 shows a summary of our results.
We ﬁnd that 36% of numbers associated with abusive ac-
counts are unique. This results in a skewed distribution,
where the top 10% of phone numbers (ranked by popular-
ity) are used to register 23% of accounts. A similar result
appears for numbers tied to purchased accounts where only
13% of numbers are unique and the top 10% of numbers
are used to create 25% of accounts. In total, phone clusters
of size 5 or greater contain 58% of abusive accounts. As
a result, a safeguard that restricts the number of accounts
miscreants can associate with a single phone number can
have a substantial impact on the volume of phone numbers
required to sustain PVA abuse while having little impact on
legitimate users.

4.2.2 Phone Access Lifetime
During our investigation of the underground we found that
blackmarket merchants oﬀering SMS as a service frequently
advertised a limited window of availability—clients would
receive access to a number for 30-90 days, after which that
number would no longer be accessible. We estimate the life-

470

100%

75%

50%

25%

s
r
e
b
m
u
n
 
f
o
 
e
g
a
t
n
e
c
r
e
P

●

1

●

●

●

●

●

●

●

●

●

Number of accounts sharing phone number

5

7

3

9

label

● abusive

benign

purchased

Figure 4: CDF of the size of account clusters all veriﬁed
with the same phone number.

●
●

●

●

●

●

●

●

●

●

●

●

●

100%

75%

50%

25%

0%

●

s
r
e
b
m
u
n

 
f

o

 

t

e
g
a
n
e
c
r
e
P

●

●

●

●

●
●
●
●
●
●
●
●
●
●
●
●
●
●

●

1

40320
Lifetime of phone number (minutes)

1440

60

label

● abusive

benign

purchased

Figure 5: CDF of time between successive account regis-
trations sharing the same phone number.

time that miscreants control a number as the time between
its ﬁrst use to its last use within our measurement window,
restricting our analysis to numbers used at least ﬁve times.
This timestamp is determined based on the creation time of
an account. Our results are shown in Figure 5.

We ﬁnd that 62% of phone numbers tied to abusive PVA
have a lifetime of only 1 hour. Similarly, 55% of phones tied
to purchased accounts have a lifetime of only 1 hour and
76% less than a day. This indicates that once miscreants
acquire a phone number, there is a high velocity period of
abuse, after which the phone number is never used again.
Consequently, blacklisting an individual phone number upon
an abuse report is ineﬀective at preventing future abuse if
the delay between an account’s creation and deactivation is
greater than a day.

Defenders can leverage this short lifetime to their advan-
tage. Miscreants that purchase accounts from the under-
ground have no means to re-verify access to a phone number
once the account transfers hands. Similarly, merchants that
bulk generate thousands of accounts would need to catalog
and retain the VOIP number or SIM card used to verify each
account, something that may be impossible. We explore how
services can perform re-veriﬁcation without increasing fric-
tion on legitimate users further in Section 6.

471

4.2.3 Veriﬁcation Challenge Type
When miscreants verify fraudulent PVA they can opt to
receive challenge codes via SMS or voice. We ﬁnd that 90%
of abusive accounts rely on SMS codes, while the same is
true for 85% of purchased accounts. This holds for benign
accounts as well where users verify their phone 94% via SMS.
We ﬁnd that the veriﬁcation method miscreants use is inde-
pendent of whether they rely on VOIP or mobile numbers.
The exception to this rule is PT in Indonesia; 31% of ver-
iﬁcation codes served through this carrier were conducted
over voice. This further suggests that human veriﬁers may
respond to challenges from this region, though we note that
voice transcription software is an alternative explanation.
We cannot draw any conclusion as to how SMS codes from
mobile phones are recovered, though we note that VOIP
services such as Google Voice digitize text messages that
miscreants can scrape.
4.3 Alternative Account Challenges

Phone veriﬁcation is one layer in a set of successive
challenges miscreants must pass in order to register a
new account. These other challenges include IP signals,
CAPTCHA solving, and providing a secondary email. We
brieﬂy examine how miscreants circumvent each of these
measures. When possible, we compare our results to those of
the Twitter account market examined by Thomas et al. [26]
to determine whether merchant techniques for bulk registra-
tion generalize across services.
4.3.1
Miscreants rely on IP addresses from India (32%), the
United States (19%), Indonesia (11%), Vietnam (2%), and
a range of other countries to register abusive PVA. Our pur-
chased accounts were registered via IPs exclusively from In-
dia (70%) and the United States (30%). In contrast, miscre-
ants targeting Twitter relied on a much more diverse range
of countries; India, the most popular region, accounted for
only 8% of abuse [26]. We believe this diﬀerence stems di-
rectly from miscreants relying on IP addresses collocated
with phones, as previously discussed in Section 4.1.

IP Diversity

Once miscreants have access to an IP they register tens
to hundreds of accounts from that portal. Figure 6 shows
a breakdown of IP reuse amongst abusive, purchased, and
a random sample of benign accounts. The merchants we
purchase from clearly restrict the number of accounts they
register from a single IP. Other miscreants bulk registering
accounts are not so cautious. Nevertheless, IP reuse is not
a foolproof signal; benign accounts are frequently registered
via the same IP due to NATing and mobile traﬃc.
4.3.2 CAPTCHA Solving
We ﬁnd that CAPTCHAs are a minor roadblock in the
account creation process. In total, 56% of abusive accounts
solved a CAPTCHA. Miscreants solved these CAPTCHAs
correctly 96% of the time. This accuracy is a strong indi-
cation of human solvers based on the results of Motoyama
et al. [15], though it may be possible that OCR CAPTCHA
solving has vastly improved since then. Our ﬁndings diﬀer
from Thomas et al. [26] where the majority of Twitter ac-
count merchants relied on what appeared to be automated
solvers with roughly 7% accuracy. We cannot directly mea-
sure the time it takes miscreants to solve a CAPTCHA.
However, we can estimate the overall time it takes miscre-

100%

s
P

I
 
f
o
 
e
g
a
t
n
e
c
r
e
P

75%

50%

25%

0%

●
●
●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

Number of accounts registered with same IP address

10

1000

label

● abusive

benign

purchased

Figure 6: Reuse of IP addresses for registering accounts.

Secondary Email Address

ants to register a new account. We ﬁnd it takes a median of
1.86 minutes from the time Google displays a signup form to
the time miscreants submit a response. In contrast, benign
registrations take a median of 3.36 minutes. This overall
timing yields little signal into the abusiveness of a newly
minted account.
It is likely miscreants purposefully delay
their automation speeds to avoid rudimentary timing detec-
tion.
4.3.3
Google allows new accounts to associate a secondary email
for recovery purposes. While not required, we ﬁnd that 83%
of purchased accounts and 34% of abusive accounts provide
a secondary email. A breakdown of the most popular email
providers tied to abusive accounts is shown in Table 4. We
observe that 52% of abusive PVA list a second Gmail address
as a recovery email. For purchased accounts (not shown in
the Table), 57% use a secondary Gmail address. The remain-
ing 43% of accounts use Hotmail.com, one of the cheapest
emails on the underground that we observe merchants sell-
ing for $5 per 1K. Apart from an increased prevalence of
Gmail addresses, the most popular email providers are iden-
tical to those abused by Twitter account merchants with the
exception of rediﬀmail.com [26].

The frequency of Gmail recovery addresses amongst bulk
generated accounts is a result of email chaining where mis-
creants specify a recovery address tied to a previously gen-
erated account they control. We build a graph of all email-
secondary email pairs and ﬁnd that 95% of accounts we
purchased share a link with another purchased accounts.
Miscreants form chains that are 2–4 accounts long before
forming a cycle with the start of the chain. We note that
forming a cycle is possible because secondary addresses are
not validated on signup. This practice removes any cost as-
sociated with merchants purchasing secondary emails while
providing a credible veneer in the event recovery emails are
factored into spam analysis.
5. REVISITING THE UNDERGROUND

Following the conclusion of our market and abuse mon-
itoring in April, 2014, we revisit the underground mer-
chants we originally solicited to procure a fresh set of 2,478
Google PVA. We use these accounts to independently verify
the long-term impact of Google’s penalization of frequently
abused carriers in January, 2014 (discussed in Section 4.1).

472

Rank Email provider
1
2
3
4
5
-

gmail.com
rediﬀmail.com
yahoo.com
hotmail.com
mail.com
Other

Popularity
52%
10%
10%
6%
2%
19%

Table 4: Top 5 email providers used as recovery addresses
for abusive PVA.

Of the accounts we purchase, 29% are stale accounts regis-
tered back in mid-October, 2013 while the remaining 71%
are fresh accounts created in mid-April, 2014. We discuss
the implications each set has on our understanding of the
account blackmarket and abusive phone veriﬁcation.

Stale Accounts: Merchants providing stale PVA are still
liquidating stockpiles they generated during the period of
rampant VOIP abuse. All of the accounts in this set were
phone veriﬁed via Bandwidth.com, re-aﬃrming our ﬁndings
presented in Section 4.1. Even though old stockpiles are reg-
ularly disabled (discussed in Section 3), we ﬁnd that mer-
chants are still able to retain some operational credentials.
The presence of such accounts also suggests a lack of liquid-
ity in the market; merchants have held on to accounts for 6
months without sale. One potential explanation is consumer
skepticism on the merchant’s credibility or the exorbitant
fees they charge.

Fresh Accounts: Merchants providing fresh PVA have
adapted to the new phone veriﬁcation requirements imposed
by Google. Of fresh accounts, only 12% were veriﬁed via
Bandwidth.com—an evolution we see mirrored at the end
of our analysis in April. Instead, merchants verify 74% of
PVA with a previously unobserved US carrier that is likely a
VOIP provider and 9% from a carrier related to TextMe (an
Android and iOS VOIP app) which we previously observed.
Our results highlight the resilience of the underground to
intervention. Nevertheless, we believe that if services force
merchants away from VOIP it will in turn raise the opera-
tional costs of miscreants and ultimately cut into the prof-
itability of spam and abuse.

Noticeably absent in our fresh account sample are any
phones tied to carriers in India or Indonesia as we see in our
abusive dataset. This may reﬂect a limitation in our cover-
age of the underground market or alternatively indicate that
some spammers are vertically integrated and beyond our ac-
cess. As such, while we believe that underground inﬁltration
provides an invaluable oracle into the performance of abuse
safeguards, it should be supplemented with service-side data
to provide a dual perspective on abuse.

6. ADAPTING PHONE VERIFICATION

We distill our underground market analysis of PVA abuse
into a set of recommendations and best practices for services
reliant on phone veriﬁcation. While our perspective of PVA
abuse is limited to Google, we believe the threats we iden-
tify are fundamental to phone veriﬁcation and thus apply
outside its conﬁnes. We also take a moment to discuss open
challenges for phone veriﬁcation services moving forward in-
cluding resource exhaustion attacks and the potential for
compromised phones.

6.1 Restricting Phone Numbers

The long term validity of phone veriﬁcation hinges on ser-
vices enforcing the scarcity of phone numbers as an under-
ground resource. To satisfy this requirement, we propose
two solutions: a carrier reputation system which tracks the
most frequently abused telephony providers at a coarse level
and phone reputation that provides ﬁne-grained abuse in-
formation related to phone numbers, similar to existing IP,
domain, and social reputation systems [1, 12, 13, 28].

6.1.1 Carrier Reputation
As our analysis shows, account merchants gravitate to-
wards free or inexpensive regional telephony carriers for the
bulk of their phone numbers. If we examine the aggregate
contributions of carriers ranked by popularity–shown in Fig-
ure 7–we ﬁnd miscreants verify 20% of all abusive PVA from
a single carrier and 50% of PVA from the top 10 carriers.
Blacklisting carriers outright (with the exception of VOIP)
is not an option. Table 5 shows a breakdown of the top 10
carriers tied to PVA abuse and the fraction of all accounts
veriﬁed via those carriers that are considered legitimate by
Google (e.g. not disabled). Only Bandwidth.com, the VOIP
provider we saw aﬃliated with rampant abuse, has a low rep-
utation. All other carriers are popular amongst legitimate
users.

An alternative to blacklisting is to adaptively throttle
the number of accounts that can be tied to a single phone
number on a per-carrier basis. While there are legitimate
users who rely on re-using phone numbers (discussed in Sec-
tion 4.2), phone veriﬁcation services can strike a balance
between user friction and abuse prevention. In particular,
services can restrict phones tied to frequently abused carriers
to a one-to-one mapping between accounts and phone num-
bers, forcing miscreants to acquire more numbers. Other
carriers would default to a many-to-one allowance. Carrier
reputation scores can also be considered as a factor into ma-
chine learning risk evaluations tied to new registrations.

This same system can outright block mobile and VOIP
services (if appropriate) when the threshold of abusive ac-
counts drops below an acceptable level. While miscreants
may spread their veriﬁcation endpoints over multiple carri-
ers, this forces criminals to pay higher fees. Craigslist has
taken a similar policy to the extreme, blacklisting all VOIP
and non-US numbers as veriﬁcation endpoints [6]. This
strategy has kept Craigslist PVA at a price of $3.50–$5 per
account (as advertised by account merchants), though it pre-
cludes a global user bases. Carrier reputation services cur-
rently exist from Telesign and Pindrop, though the method-
ology or accuracy of these systems is not public.

6.1.2 Phone Reputation
Where carrier reputation can help throttle the creation
rate of PVA, phone reputation can outright block abusive
registrations. The primary challenge of phone reputation is
the velocity of abuse. As we discussed in Section 4.2, 62% of
phones used to verify abusive accounts have a lifetime un-
der one hour. Consequently, if abuse reports cannot ﬂag a
phone number in time, the window for a reputation system
to impact abuse will have passed. One option is for services
to restrict the velocity of new registrations tied to the same
phone number (e.g.
forcing users to wait a period before
a phone number is re-usable), but this oﬀers no protection
if numbers are single-use. This beneﬁt could be expanded

A
V
P
 
e
v
s
u
b
A

i

 
f
o
 
e
g
a
t
n
e
c
r
e
P

100%

80%

60%

40%

20%

10
Number of Carriers

1000

Figure 7: Aggregate contribution of fraudulent PVA of
carriers ranked by popularity. Miscreants use the top carrier
to verify 20% of all abusive PVA and the top 10 to verify
50% of PVA.

Rank
1
2
3
4
5
6
7
8
9
10

Carrier Country % Good
41%
91%
98%
98%
97%
98%
99%
98%
98%
99%

Bandwidth.com
Pt
Bharti
Vodafone
Mtn
Idea
Telekomunikasi
Aircel
Tata
Viettel

US
ID
IN
IN
NG
IN
ID
IN
IN
VN

Table 5: Top 10 carriers used by abusive phone veriﬁed
accounts and their respective reputations. Blacklisting car-
riers outright would impact a disproportionate number of
legitimate users.

by services sharing abuse information which would prevent
veriﬁcation as a service merchants (discussed in Section 4.1)
from registering multiple accounts cross-service with a sin-
gle phone number. We also believe that phone reputation
can become a predictive score that assesses the risk of a
previously unseen phones tied to newly registered account.
Potential features include the sequentiality of phone num-
bers and whether the phone number has appeared in other
contexts before. We leave such a system for future work.

6.1.3 Phone Reveriﬁcation
The relatively short lifetime of phone numbers—a median
of less than 1 hour in our analysis—raises the potential for
defenders to re-verify phone numbers as an eﬀective abuse
escalation. By limiting re-veriﬁcation as a response to sus-
picious activity (e.g. sending an abnormal number of email;
rapidly subscribing to hundreds of YouTube channels), le-
gitimate users will avoid the friction imposed by phone ver-
iﬁcation. Conversely, miscreants who purchased accounts
will not have access to the original phone number tied to an
account after it changes hands. Similarly, spammers that
are vertically integrated and register their own credentials
must retain access to thousands of SIM cards, something
that may not be possible if miscreants rely on veriﬁcation
as a service merchants. This adds yet another dimension to
the complexity of circumventing phone veriﬁcation, where

473

duration of access becomes just as important as the quan-
tity of phone numbers miscreants can draw from. We note
that Facebook may already rely on this practice based on
chatter from underground forums, but cannot conﬁrm.
6.2 Open Challenges

6.2.1 Phone Chaining
When miscreants abuse free call forwarding services such
as Google Voice, they must register a phone number to serve
as the forwarding endpoint. While this initial number is
intended as a safeguard—similar to email veriﬁcation or a
CAPTCHA—the existence of other free (virtual) numbers
overcomes this protection. This is exacerbated by the po-
tential many-to-one relationship between seed numbers and
numbers handed out by forwarding telephony services. This
leads to a vulnerability we call phone chaining. In particular,
miscreants can use a single free mobile number or free VOIP
number that fans out to multiple free forwarding numbers.
These in turn can serve as forwarding endpoints at other
services, with miscreants repeating the process ad nauseam
to create an arbitrarily sized tree of phone numbers for veri-
ﬁcation purposes. Even if virtual number providers prevent
chaining between their own phone number pool, miscreants
can obfuscate the original identity of a number by cycling
through multiple forwarding services for each level of the
tree. Absent a comprehensive forwarding blacklist—which
is diﬃcult to acquire due to phone ranges constantly chang-
ing hands and limited opacity into phone ownership—there
is nothing to prevent this practice. An alternative is to have
telephony services charge for forwarding numbers, but global
adoption is required to prevent miscreants from constantly
shifting their operations to free providers.

6.2.2 Resource Exhaustion Attacks
Phone veriﬁcation is not free. Services must pay a fee
for each attempted SMS or phone challenge. The cost of
phone veriﬁcation exposes services to resource exhaustion
attacks. Miscreants can request thousands of spurious ver-
iﬁcation codes for non-existent numbers or phones tied to
legitimate victims (who may in turn be charged a delivery
fee). Assuming a ﬁxed daily budget, a fail-open system will
allow miscreants to bypass phone veriﬁcation all together;
a fail-closed system will block legitimate users from regis-
tering new accounts. This challenge also exists for email
veriﬁcation—services that generate excessive bounce notiﬁ-
cations expose themselves to throttling on the receiving end
that can degrade the delivery rate of important messages.
While services can perform a risk analysis for each new reg-
istration attempt and block suspicious registrations before a
SMS challenge is sent, we view resource exhaustion attacks
as an open challenge.

6.2.3 Compromised Phones
The widespread adoption of Android and iOS devices car-
ries with it an emerging risk of mobile malware [8].
In-
stances already exist of the Zeus banking trojan intercepting
two-factor authentication PINs for liquidating a victim’s as-
sets [27]. Other threats include mobile drive-by-downloads
installing the NotCompatible malware family that converts
a victim’s phone into a mobile proxy [19]. While we ﬁnd no
evidence of miscreants using compromised phones as ver-
iﬁcation endpoints, there is no reason that compromised

phones will not become a commodity market like compro-
mised hosts [5]. This possibility undermines the longterm
sustainability of phone veriﬁcation and any protection pro-
vided by carrier-level reputation. Similarly, it forces phone
reputation systems into a reactive position, eﬀectively be-
coming phone blacklists much like existing IP and DNS
blacklists [21].

7. RELATED WORK
Monetizing Account Access. Miscreants leverage bulk
registered accounts to expose legitimate users to spam,
phishing, and malware [9, 11]. At its heart, a substantial
amount of spam serves to advertise products and lure people
to purchase pharmaceuticals, replica goods, and counterfeit
software, often with the aid of complex infrastructure man-
aged by aﬃliates and aﬃliate programs [14]. Recent alter-
natives in monetization include ad syndication services and
ad-based URL shortening [25]. These examples highlight
the range of strategies that miscreants employ to generate a
proﬁt once they gain access to account credentials.

Reputation Systems. Reputation is commonly used to
prevent or limit abuse of web services. One technique, with
roots in email spam ﬁltering, is the use of IP addresses for
reputation [13]. Using IP reputation enables a web service
to quickly score actions and label them as abusive or benign.
IP reputation can become error prone and new techniques
have been developed for evaluating IP address ranges that
are populated with a mix of benign and abusive actions [13].
Approaches to reputation have also evaluated automated
scoring using network-level features [12]. In addition to IP
addresses, other forms of reputation are used to label do-
mains [4], and accounts on web services by leveraging the
observed actions of existing users to vet new accounts [28].
Phone reputation over voice has also been explored based on
audio features introduced by telephony networks [2], though
such features do not extend to numbers used purely for SMS.

Applications of Phone Veriﬁcation. In addition to pre-
venting fraudulent account registration, SMS and phone ver-
iﬁcation is used broadly to prevent account hijacking. One
widely deployed use is two-factor authentication for online
banking. With SMS two-factor, a one-time code is sent via
SMS and used along with the username and password to
login [20]. Even two-factor authentication is not without
vulnerabilities, and criminals have used malware to inter-
cept SMS messages on the target phone [10, 20]. Similar to
two-factor authentication, other uses for phone veriﬁcation
include account recovery, and as an informational channel
to alert users of changes to their account.

8. CONCLUSION

In this paper, we presented a longitudinal study of the
underlying technical and ﬁnancial factors inﬂuencing the di-
minishing eﬀectiveness of phone veriﬁcation. To conduct our
study, we combined underground intelligence gleaned from
4,695 phone veriﬁed accounts purchased from 14 blackmar-
ket merchants as well as 300,000 phone veriﬁed accounts
disabled by Google for spam and abuse. We found that
merchants were capable of registering a steady stream of
thousands of PVA that subsequently sold for $85–$500 per
1K to the underground. Many of these merchants appeared
to operate in a fashion similar to spam aﬃliate programs,

474

reiterating that specialization with the underground ecosys-
tem is the norm. We found that merchants used inexpensive
VOIP numbers to circumvent the intended cost of acquiring
SIM cards, eﬀectively invalidating the defense provided by
phone veriﬁcation. As this practice became a widespread,
we observed a simultaneous market-wide price drop of 30–
40% for Google PVA until Google penalized veriﬁcations
from frequently abused phone carriers. Our results high-
light how blackmarket monitoring can provide an invaluable
oracle into the performance of abuse safeguards. This infor-
mation vastly simpliﬁes the task of defenders keeping pace
with evolutions of the underground, in turn better protect-
ing users against spam and abuse.

9. ACKNOWLEDGMENTS

This work was supported in part by the National Science
Foundation under grant 1237265 and 1237076, by the Of-
ﬁce of Naval Research under MURI grant N000140911081,
and by a gift from Google. Any opinions, ﬁndings, and con-
clusions or recommendations expressed in this material are
those of the authors and do not necessarily reﬂect the views
of the sponsors.

10. REFERENCES
[1] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and
N. Feamster. Building a dynamic reputation system
for dns. In Proceedings of the USENIX Security
Symposium, pages 273–290, 2010.

[11] C. Grier, K. Thomas, V. Paxson, and M. Zhang.

@spam: The Underground on 140 Characters or Less.
In Proceedings of the ACM Conference on Computer
and Communications Security (CCS), 2010.

[12] S. Hao, N. A. Syed, N. Feamster, A. G. Gray, and

S. Krasser. Detecting Spammers with SNARE:
Spatio-temporal Network-level Automatic Reputation
Engine. In USENIX Security Symposium, volume 9,
2009.

[13] C.-Y. Hong, F. Yu, and Y. Xie. Populated IP
Addresses: Classiﬁcation and Applications. In
Proceedings of the 2012 ACM Conference on
Computer and Communications Security, 2012.

[14] K. Levchenko, A. Pitsillidis, N. Chachra, B. Enright,

M. F´elegyh´azi, C. Grier, T. Halvorson, C. Kanich,
C. Kreibich, H. Liu, et al. Click trajectories:
End-to-end analysis of the spam value chain. In
Proceedings of IEEE Security and Privacy, 2011.

[15] M. Motoyama, K. Levchenko, C. Kanich, D. McCoy,

G. M. Voelker, and S. Savage. Re:
Captchas-understanding captcha-solving services in an
economic context. In Proceedings of the USENIX
Security Symposium, 2010.

[16] Pew Research. Emerging nations embrace internet,

mobile technology.
http:// www.pewglobal.org/ 2014/ 02/ 13/
emerging-nations-embrace-internet-mobile-technology/ ,
2014.

[2] V. A. Balasubramaniyan, A. Poonawalla, M. Ahamad,

[17] Pew Research. Mobile technology fact sheet.

M. T. Hunter, and P. Traynor. Pindr0p: using
single-ended audio features to determine call
provenance. In Proceedings of the 17th ACM
conference on Computer and communications security,
pages 109–120. ACM, 2010.

[3] Bandwidth.com. Who we are.

http:// bandwidth.com/ about-us, 2014.

[4] L. Bilge, E. Kirda, C. Kruegel, and M. Balduzzi.
EXPOSURE: Finding Malicious Domains Using
Passive DNS Analysis. In NDSS, 2011.

[5] J. Caballero, C. Grier, C. Kreibich, and V. Paxson.
Measuring Pay-per-Install: The Commoditization of
Malware Distribution. In Proceedings of the USENIX
Security Symposium, 2011.

[6] Craigslist. How does phone veriﬁcation work? http:

// www.craigslist.org/ about/ help/ phone veriﬁcation,
2014.

[7] V. Dave, S. Guha, and Y. Zhang. Measuring and

Fingerprinting Click-Spam in Ad Networks. In
Proceedings of the ACM SIGCOMM. ACM, 2012.

[8] A. P. Felt, M. Finifter, E. Chin, S. Hanna, and

D. Wagner. A Survey of Mobile Malware in the Wild.
In Proceedings of ACM Workshop on Security and
Privacy in Smartphones and Mobile Devices, 2011.

[9] H. Gao, J. Hu, C. Wilson, Z. Li, Y. Chen, and B. Y.

Zhao. Detecting and Characterizing Social Spam
Campaigns. In Proceedings of the 10th ACM
SIGCOMM conference on Internet measurement, 2010.

[10] L. Goddard. Researchers discover ﬁve new samples of

zitmo malware for android and blackberry.
http:// www.theverge.com/ 2012/ 8/ 8/ 3227638/
zitmo-malware-android-blackberry-samples, August
2012.

http:// www.pewglobal.org/ 2014/ 02/ 13/
emerging-nations-embrace-internet-mobile-technology/ ,
2014.

[18] Pinger. Free unlimited texting to 35 countries from
your computer. https:// www.pinger.com/ content/
text-from-your-computer/ , 2014.

[19] F. Ruiz. Android notcompatible looks like piece of pc

botnet. http:// blogs.mcafee.com/ mcafee-labs/
androidnotcompatible-looks-like-piece-of-pc-botnet,
2012.

[20] B. Schneier. Two-Factor Authentication: Too Little,

Too Late. 2005.

[21] S. Sinha, M. Bailey, and F. Jahanian. Shades of grey:

On the eﬀectiveness of reputation-based “blacklists”.
In Malicious and Unwanted Software, 2008.

[22] B. Stone-Gross, R. Abman, R. A. Kemmerer,

C. Kruegel, D. G. Steigerwald, and G. Vigna. The
Underground Economy of Fake Antivirus Software. In
Economics of Information Security and Privacy, 2013.

[23] B. Stone-Gross, M. Cova, L. Cavallaro, B. Gilbert,

M. Szydlowski, R. Kemmerer, C. Kruegel, and
G. Vigna. Your Botnet is My Botnet: Analysis of a
Botnet Takeover. In Proceedings of the ACM CCS,
pages 635–647. ACM, 2009.

[24] Text+. Free text to anyone in the us or canada.

http:// www.textplus.com/ , 2014.

[25] K. Thomas, C. Grier, V. Paxson, and D. Song.

Suspended Accounts In Retrospect: An Analysis of
Twitter Spam. In Proceedings of the Internet
Measurement Conference, November 2011.

[26] K. Thomas, D. McCoy, C. Grier, A. Kolcz, and

V. Paxson. Traﬃcking Fraudulent Accounts: The Role
of the Underground Market in Twitter Spam and

475

Abuse. In Proceedings of the USENIX Security
Symposium, 2013.

[27] TrendMicro. Zeus now bypasses two-factor

authentication. http:// blog.trendmicro.com/
trendlabs-security-intelligence/
zeus-now-bypasses-two-factor-authentication/ , 2013.

[28] Y. Xie, F. Yu, Q. Ke, M. Abadi, E. Gillum,

K. Vitaldevaria, J. Walter, J. Huang, and Z. M. Mao.
Innocent by Association: Early Recognition of
Legitimate Users. In Proceedings of the 2012 ACM
conference on Computer and communications security,
2012.

476

