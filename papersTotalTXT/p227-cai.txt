A Systematic Approach to Developing and Evaluating

Website Fingerprinting Defenses

Xiang Cai 1

Rishab Nithyanand 1

Tao Wang 2

Rob Johnson 1

Ian Goldberg 2

1Stony Brook University

{xcai, rnithyanand, rob}@cs.stonybrook.edu

2University of Waterloo

{t55wang, iang}@cs.uwaterloo.ca

ABSTRACT
Fingerprinting attacks have emerged as a serious threat against pri-
vacy mechanisms, such as SSL, Tor, and encrypting tunnels. Re-
searchers have proposed numerous attacks and defenses, and the
Tor project now includes both network- and browser-level defenses
against these attacks, but published defenses have high overhead,
poor security, or both.

This paper (1) systematically analyzes existing attacks and de-
fenses to understand which trafﬁc features convey the most infor-
mation (and therefore are most important for defenses to hide),
(2) proves lower bounds on the bandwidth costs of any defense
that achieves a given level of security, (3) presents a mathematical
framework for evaluating performance of ﬁngerprinting attacks and
defenses in the open-world, given their closed-world performance,
and (4) presents a new defense, Tamaraw, that achieves a better se-
curity/bandwidth trade-off than any previously proposed defense.
Our feature-based analysis provides clear directions to defense
designers on which features need to be hidden. Our lower bounds
on bandwidth costs help us understand the limits of ﬁngerprint-
ing defenses and to determine how close we are to “success”. Our
open-world/close-world connection enables researchers to perform
simpler closed-world experiments and predict open-world perfor-
mance. Tamaraw provides an “existence proof” for efﬁcient, secure
defenses.

Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: General–Security
and protection
; K.4.1 [Computing Milieux]: Computers and Society–Privacy

Keywords
Anonymity; Website ﬁngerprinting attacks and defenses

1.

INTRODUCTION

Website ﬁngerprinting attacks enable an adversary to infer which
website a victim is visiting, even if the victim uses an encrypting
proxy, such as Tor. These privacy mechanisms encrypt the content
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2957-6/14/11 ...$15.00.
http://dx.doi.org/10.1145/2660267.2660362.

transferred between the web server and client, but they do not ef-
fectively hide the size, timing, and direction of packets. A website
ﬁngerprinting attack uses these features to infer the web page being
loaded by a client.

Website ﬁngerprinting attacks have emerged as a serious threat
against web browsing privacy mechanisms, such as SSL, Tor, and
encrypting tunnels. At the 2012 Oakland conference, Dyer, et al.
[5] showed that an attacker could infer, with a success rate over
80%, which of 128 pages a victim was visiting, even if the victim
used network-level countermeasures. At CCS 2012, Cai et al. [3]
described an attack that could achieve a greater than 75% success
rate (out of 100 sites) against numerous network and application-
level defenses.

Published and deployed defenses have high overhead, poor se-
curity, or both. The Tor project has incorporated network- and
browser-level defenses against ﬁngerprinting attacks into its Tor
Browser Bundle [13], but Cai found that they provide no secu-
rity beneﬁt. Luo, et al. proposed HTTPOS [11], a collection of
network- and HTTP-level defenses, but Cai’s attack showed that it
offered little security beneﬁt. Wright, et al. proposed trafﬁc morph-
ing [19], but both Dyer and Cai showed that it provides little protec-
tion against ﬁngerprinting attacks. In fact, Dyer and Cai surveyed
numerous defenses and found them all ineffective. Dyer proposed
BuFLO, which offers good security, but at a high bandwidth cost.
This paper addresses several challenges in designing, evaluating
and comparing the performance of website ﬁngerprinting attacks
and defenses.

Most attack evaluations have used the artiﬁcial “closed-world”
model, in which the victim selects one of n websites uniformly
randomly and the attacker attempts to guess the chosen website
based on the observed network trafﬁc. This model has been crit-
icized for being unrealistic because, in a real attack, the victim
may visit any website in the world [14], potentially making the at-
tacker’s task much more difﬁcult. Consequently, some researchers
have suggested that website ﬁngerprinting attacks are in fact a pa-
per tiger [14].

In this paper we show how to compute the open-world perfor-
mance of an attack based on its performance in a closed-world ex-
periment. Thus, researchers can evaluate attacks and defenses in
the simpler closed-world model and, using our method, compute
open-world performance results. We use this method to compute
open-world performance of our new defense, Tamaraw.

We also investigate the danger that ﬁngerprinting attacks pose in
the real world. We ﬁnd that, without any defense whatsoever, ﬁn-
gerprinting attacks can pose a signiﬁcant threat to visitors to pop-
ular web pages. For example, an ideal attacker against defenseless
victims could recognize visits to the 100 most popular websites
with a false discovery rate of less than 50%.

227Defense
Tamaraw
Tamaraw
BuFLO
Tor

Security () BW Overhead Overhead Ratio
31.3
6.9
1965
495.2

3.4%
0.4%
41.5%
77.5%

199%
687%
199%
25%

Table 1: Security and bandwidth overhead of defenses in a
closed-world experiment with 800 websites. A defense is -
secure if no attacker can guess the victim’s website with prob-
ability more than . Note that this security evaluation is attack
independent. An overhead ratio of r indicates that the defense
incurred an overhead r times larger than the lower bound on
overhead derived in Section 5.1.

Most defense evaluations have attempted to estimate the efﬁcacy
of the proposed defense by using the state-of-the-art attacks avail-
able at that time. This provides only a lower bound on the security
of a defense — future attacks may demonstrate that it is insecure.
This approach also makes it difﬁcult to compare defenses that were
evaluated using different attacks.

We solve both problems by evaluating defenses against an ideal
attacker. In our ideal attack, two websites are distinguishable unless
they generate the exact same sequence of network trafﬁc observa-
tions. Thus evaluating a defense against an ideal attacker gives the
lower bound on the security provided by the defense and the eval-
uation results are attack-independent — i.e., future researchers can
compare different defenses using the same ideal attack.

Even when two defenses have been evaluated against the same
attack, it can be difﬁcult to compare them, since every defense of-
fers a different trade-off between security and overhead. And even
if one defense strictly dominates all other defenses in terms of secu-
rity and efﬁciency, it is still not clear whether the attack is optimal.
How efﬁcient can a defense be while offering a given level of secu-
rity?

To answer these questions, we develop an abstract model of web-
site ﬁngerprinting attacks and defenses and prove lower bounds on
the bandwidth overhead of any defense that offers a given level of
security. This enables us to compare defenses with different over-
head/security trade-offs by comparing how close they are to the
optimal trade-off curve. We can also bound how far defenses are
from optimal. Our bounds suggest that, although defenses are get-
ting better, there may still be signiﬁcant room for improvement.

In order to design efﬁcient and effective defenses, we need to
know which trafﬁc features leak the most information about the
website being visited. Without this information, we may make the
mistake of designing a defense that incurs high cost to hide a low-
information feature. For example, most early defenses focused ex-
clusively on packet sizes, but Cai, et al. showed that packet or-
dering contains at least as much information as packet sizes [3].
Therefore, we systematically analyze existing attacks and defenses
to understand which trafﬁc features convey the most information
and therefore are most important for defenses to hide. Our anal-
ysis goes beyond the “black-box” approach of previous work that
published overall attack success rates but did not investigate the
reasons attacks and defenses succeed or fail.

Finally, we propose and evaluate a new, provably secure ﬁn-
gerprinting defense. Tamaraw extends and tunes BuFLO to hide
the most signiﬁcant trafﬁc features uncovered by our feature-based
analysis. In particular, we ﬁnd that BuFLO unnecessarily wastes
bandwidth hiding the number of upstream packets and does not ad-
equately hide the total number of downstream packets.

We then use the new evaluation techniques described above to
evaluate Tamaraw. We show that Tamaraw offers signiﬁcantly bet-
ter security than BuFLO in a closed-world setting. Our closed-
world evaluation uses an ideal attacker and therefore bounds the
success rate that any attacker can achieve against Tamaraw. Table 1
summarizes the evaluation results. We evaluated Tamaraw under
two different conﬁgurations. One of them offers over 12× bet-
ter security than BuFLO for the same bandwidth overhead. Table 1
also shows that all the defenses have a signiﬁcant gap between their
performance and the trade-off lower-bound curve, although Tama-
raw comes closest by far.

Then, we show how to compute the open-world performance of
an attack based on experimental results derived in the closed-world
setting. Further, we show that even the optimal attacker, against de-
fenseless victims, suffers from high false discovery rates. Finally,
we evaluate Tamaraw in our open-world model and show that it
performs signiﬁcantly better than BuFLO, against the optimal at-
tacker.

The rest of this paper is organized as follows. Section 2 reviews
website ﬁngerprinting attacks. Section 3 describes our feature-
based defense comparison methodology. In section 4, we survey
a set of six previously proposed defenses and four attack features.
We then present the results of applying our feature-based compar-
ative methodology to each of these defenses. Section 5 presents
our model of ﬁngerprinting attacks, the security/overhead trade-off
lower-bound theorems, and the closed-world/open-world connec-
tion. Section 6 describes Tamaraw and presents our evaluation re-
sults. Section 8 discusses implications of our research.

2. WEBSITE FINGERPRINTING

ATTACKS

In general, website ﬁngerprinting (WF) attacks are a subset of
trafﬁc analysis attacks. A WF attacker is able to monitor the com-
munications between a client’s computer and a private web brows-
ing proxy. The private browsing proxy may be an SSH proxy, VPN
server, Tor, or other privacy service. The trafﬁc between the user
and proxy is encrypted, so the attacker can only see the timing, di-
rection, and size of packets exchanged between the user and the
proxy. Based on this information, the attacker attempts to infer
the website(s) that the client is visiting via the proxy by examining
various features of the observed trafﬁc. Cai et al. [3] and Chen et
al. [4] describe variants wherein an attacker aims to identify a web
site instead of a web page. For consistency across the literature,
however, we focus on the identiﬁcation of single web pages. A WF
defense is a set of countermeasures that protect the client against a
WF attack by obfuscating, or covering features of the web trafﬁc,
making them less distinguishable across different web pages, thus
reducing the accuracy of the attack.

A WF attacker is assumed to be local and passive: the attacker
taps and observes from only one location, and he is not allowed
to add, drop, or change packets. This means that the attacker is
weak, but is also resource-light and essentially undetectable. The
attacker can prepare for the attack by collecting information about
websites in advance. For example, he can visit websites using the
same privacy service as the client, collecting a set of website “ﬁn-
gerprints” as a training set, which he later uses to recognize the
client site. These ’ﬁngerprints’ usually consist of packet sizes, di-
rections, etc. observed between the client and the proxy. Although
the packets themselves are encrypted, the packet sequence still car-
ries information about the sizes of the objects in a web page and
the order they are being requested, which is induced by the struc-
ture of the web page (the list of resources, their lengths, and which

228resources each resource requests). The interaction of multiple con-
nections between a client and a web server may cause randomiza-
tion in packet ordering but, as we will see later, a successful WF
attack will tolerate these randomized differences while learning to
distinguish different web pages.

We retain two assumptions that all previous works on WF have
made of the attacker. First, the attacker is able to notice exactly
when a new page is requested. In other words, the attacker knows
which sequence of packets corresponds to a single page. This as-
sumption is sometimes made in a stronger form — that the client’s
think time always dominates page load time — which implies that a
distinct pause exists between any two packet sequences of different
page loads. Second, any background activity the client may have
will not interfere with the client’s trafﬁc. For example, a client will
not download a ﬁle while visiting a web page; alternatively, these
ﬁle download packets can be easily discarded by the attacker. These
assumptions are used by all previous works on WF as they simplify
the problem, though it should be noted that these assumptions are
advantageous for the attacker.

3. FEATURES AND METHODOLOGY

A classiﬁer succeeds at distinguishing between two classes when
it is able to discover a consistent difference between them. This
can be viewed as a difference between their features, which char-
acterize a class. Implicitly or explicitly, classiﬁcation techniques
such as WF attacks extract features to classify. Conversely, a suc-
cessful defense effectively hides these features. In this section, we
describe our methodology and use it to evaluate the strengths and
weaknesses of different WF defenses.
3.1 Packet Sequences and their Features

In general, packet sequences have four major features: unique
packet lengths, packet length frequency, packet ordering, and in-
terpacket timing. Therefore, a packet sequence P can be written
as:

P = (cid:104)(t1, (cid:96)1), (t2, (cid:96)2), ..., (tn, (cid:96)n)(cid:105)

In the above, ti is the difference in time observed between packets
i and i − 1 (interpacket timing), with t1 = 0; (cid:96)i is the byte length
of packet i. The sequence length, |P|, is equal to n. We write
Pt and P(cid:96) as the sequences of only the interpacket times and only
the packet lengths, respectively. We indicate the packet length as a
positive value if the packet is outgoing and as a negative value if it
is incoming.

Unique Packet Lengths: Packet lengths are a simple and strong
feature of a web page. GET request lengths are partly determined
by the length of the resource name. Incoming packets are almost
always sent at the Maximum Transmission Unit (MTU), with the
length of the last packet indicating the size of the resource (modulo
the MTU).

Most packet lengths of a page are unlikely to change unless re-
source lengths change. WF attacks almost always consider packet
lengths unless they are designed for the Tor scenario, in which case
packet lengths are covered. When unspeciﬁed, we assume that
packet lengths are not hidden from the attacker.
Mathematically, sequences P and P (cid:48) are said to have different
unique packet lengths iff their sets of packet lengths are different –
i.e.,

(∃L ∈ P(cid:96)|L /∈ P

(cid:96)) ∨ (∃L ∈ P
(cid:48)

(cid:96)|L /∈ P(cid:96))
(cid:48)

Packet Length Frequency: Packet length frequency is the num-
ber of times each unique packet length occurs. The number of
incoming packets at MTU size is a rough estimation of the total

size of the page, which changes due to random advertisements and
updated content. We will subsequently show that all current WF
defenses fail to cover the total trafﬁc size, as doing so is difﬁcult
and would necessarily incur a large trafﬁc overhead. Therefore,
the poor performance of most early WF attacks [6, 9, 10] may be
attributed to the fact that they explicitly discard packet length fre-
quencies.
Suppose nL(P(cid:96)) is the number of times packet length L appears
in P(cid:96). P and P (cid:48) are said be have different packet length frequencies
iff their packet lengths occur at different frequencies while exclud-
ing packet lengths that are unique to either P or P (cid:48) – i.e.,

∃L|nL(P(cid:96)) (cid:54)= nL(P

(cid:96)) ∧ nL(P(cid:96)) > 0 ∧ nL(P
(cid:48)

(cid:48)
(cid:96)) > 0

Packet Ordering: The structure of a page induces a logical or-
der in its packet sequence. As an example, a GET packet for a
resource can only be sent once the reference to that resource is
received by the client. An attacker may be able to infer informa-
tion about the content of each packet from observing packet order-
ing. Further, packet ordering depends on network conditions: it
may vary due to bandwidth and latency, and it may be affected by
changing the parameters for persistent HTTP connections, pipelin-
ing, and so on. Tor developers have implemented a prototype de-
fense based on packet ordering by randomizing request order (see
Section 4.1).
We denote M(cid:96) as the multiset of packet lengths in P(cid:96), without or-
dering. We say that two sequences P and P (cid:48) have different packet
ordering iff:

M(cid:96) = M

(cid:96) ∧ P(cid:96) (cid:54)= P
(cid:48)

(cid:48)
(cid:96)

Interpacket Timing: Interpacket times often reveal the logi-
cal relationship between packets. For example, viewing from the
client’s end, the outgoing server connection SYN and the incoming
SYN-ACK will differ by a round-trip time; so will the GET request
and the ﬁrst packet of that resource. If the attacker’s tap is near the
client, then the attacker can infer that an outgoing packet and an
incoming packet cannot be logically dependent if their interpacket
time is less than one RTT.
Suppose P and P (cid:48) have sequence lengths |P| and |P (cid:48)|. P and
P (cid:48) are said to have different interpacket timings iff their timings
are different – i.e.,

∃i, 1 ≤ i ≤ min(|P|,|P

(cid:48)|) : (Pt)i (cid:54)=(cid:0)P

(cid:48)
t

(cid:1)

i

FACT 1. If P (cid:54)= P (cid:48), then they must differ in at least one of the

four features above.

This fact demonstrates that our choice of features is, in some
sense, complete, in that it represents any difference between two
packet sequences. We can therefore claim that successful attacks
should expose at least one of those four features between packet
sequences, while defenses are perfectly effective if they can hide
all four features.

FACT 2. Given any packet sequence P and any subset of the
above features, there exists a packet sequence P (cid:48) such that P and
P (cid:48) only differ in this subset of features, with the exception that
different packet ordering implies that unique packet lengths and
packet length frequencies do not differ.

This fact implies that our features are somewhat independent of
each other (except packet ordering). It should therefore be possible
to ﬁnd generators that change one feature without affecting the oth-
ers, allowing us to pinpoint which features various defenses attempt
to cover. It also shows that the features considered in this paper are
exhaustive, even for data-dependent features (For example, if the
size of a response depends on the content of a cookie).

2293.2 Comparative Methodology

To determine if a defense is able to hide a feature, we apply the
defense to two classes, C and C(cid:48), which differ only by that feature.
Then, we say that a defense is successful in hiding the feature if af-
ter applying the defense, there is no discernible difference between
C and C(cid:48).
We use a generator G to transform C into C(cid:48) by causing a change
in some feature of each packet sequence P ∈ C and inserting the
output into C(cid:48). We parameterize G(v) by v, a non-negative in-
teger such that the greater the value, the more “different” P and
P (cid:48) = G(v)(P ) will be; we require G(0)(P ) = P . We design each
generator to modify only one speciﬁc feature. G(v) operates from
the start of the packet sequence. Informally, G(v) is equivalent to
G(1) repeated v times, possibly from different starting points in the
packet sequence. For all of our generators, this interpretation en-
sures that v functions as a magnitude. The designed generators are
not randomized and each generator may accept values of v up to
180 or |P|/5, whichever is lower. None of the generators produce
a packet length greater than the MTU. We give a textual description
of each generator below and mathematically deﬁne each generator
G(v)
in Table 2. More details of the generators can be found in our
tech report. [17]

Small Packet-Length Changes (G1): All packet lengths are in-

i

creased by v, up to MTU.

Large Packet-Length Changes (G2): v packet lengths are in-

creased by 1000, up to MTU.

Packet-Length Diffusion (G3): The lengths of v packet are in-

creased by their position divided by 5, up to MTU.

Appended Incoming Packets (G4): v incoming MTU packets

are appended to the end.

Appended Outgoing Packets (G5): v outgoing packets are ap-
pended to the end, their lengths being the lengths of the ﬁrst outgo-
ing packets of P .

Inserted Incoming Packets (G6): v incoming MTU packets are

added, one per 5 packets.

the previous packet.

Adjacent Transpositions (G7): v packets are transposed with

Short-Distance Transpositions (G8): v packets are transposed

with the packet 4 elements ago.

Long-Distance Transpositions (G9): v packets are transposed

with the packet 19 elements ago.

Delays (G10): Each packet is delayed by a linearly increasing

amount of time, multiplied by v.

3.3 Classiﬁcation and Experimental Setup

In order to understand the signiﬁcance of these trafﬁc features
for ﬁngerprinting attacks, we focus on distinguishing between two
classes:

C = {P1, P2, ..., P400}
(cid:48)
C

= {G(v)(P1), G(v)(P2), ..., G(v)(P400)}

These are the original class (C) and the generator-modiﬁed class
(C(cid:48)) with one feature changed. Since our generators operate on
packet sequences, the elements of C and C(cid:48) are packet sequences.
We construct C by connecting to bbc.co.uk 400 times with
caching disabled. The reason we do so is that C should contain
packet sequences of the same page rather than different pages, be-
cause WF attack classiﬁers are designed to tolerate the randomness
within the same page while exposing the differences between dif-
ferent pages. A successful classiﬁer should therefore be able to dis-
tinguish C and C(cid:48) despite the randomness in C (and therefore C(cid:48)).
On the other hand, the elements of C need to differ from each other;
this will allow us to measure how sensitive each defense is to the

train and C(cid:48)

generators’ operations. The page we chose has a suitable amount
of randomness and has therefore been difﬁcult to classify [18]. We
use the ﬁrst 200 elements of classes C and C(cid:48) for training and the
last 200 elements for testing our feature classiﬁers described below.
The training and testing sets are denoted Ctrain and Ctest, with the
generator-modiﬁed sets being C(cid:48)
test. We use four dif-
ferent feature classiﬁers, each one specializing on differentiating
one speciﬁc feature.
Unique Packet-Lengths (F1): Given a unique packet length in
Ptest, if it is in any packet sequence P ∈ C and not in any P (cid:48) ∈ C(cid:48),
add 1 to the score of class C and vice versa. This is a modiﬁed
version of the early Jaccard co-efﬁcient classiﬁer introduced in [9].
Packet-Length Frequencies (F2): For training, we count the
total number of bytes contained in incoming and outgoing packets,
as well as the total number of incoming and outgoing packets, and
take the mean and standard deviation over the packet sequences in
each class. Each testing packet sequence is then scored using the
normal distribution kernel against those four values for each class,
with the incoming and outgoing packets scored separately and then
multiplied. This classiﬁer is a simpliﬁed version of the Naïve Bayes
classiﬁer also described in [9].

Packet Ordering (F3): For testing, each packet length in the se-
quence (discarding direction) is compared to the mean of all train-
ing packet lengths at that position. This classiﬁer is derived from
the Cross Correlation classiﬁer described in [2].

Interpacket Timing (F4): Classiﬁcation here is based only on
total elapsed time. We use this classiﬁer because G10 is a delay.
This reveals whether or not the total load time of a page would still
be a useful feature after the defense is applied.

The defense D is applied to each element of Ctrain and C(cid:48)

Since the objective is simply to ﬁnd the difference between the
two classes that differ only by a single feature, the above four single
feature classiﬁers are sufﬁcient.
train
to produce D(Ctrain) and D(C(cid:48)
train); the feature classiﬁer is then
trained to distinguish between them. Finally, D is applied to Ctest
and C(cid:48)
test and its effectiveness is measured by the feature classi-
ﬁers. The effectiveness of the defense D is measured by the value
of v before the classiﬁer is able to distinguish between the two
classes with reasonable levels of accuracy (.55 and .75) – i.e., the
magnitude of differences induced between C and C(cid:48) before the
classiﬁer can distinguish between them.

Our experimental setup is as follows. We load pages over a
100 Mbps Ethernet connection with MTU set at 1500. For auto-
mated page loading, we used iMacros 9.00 on Firefox 23.0. We
collected data with tcpdump and parsed the data into packet se-
quences with our code. We implemented all of the classiﬁers and
simulated defenses in this paper in a combination of Python, C++,
and C, and all of them are available upon request.

4. COMPARISON OF DEFENSES

In this section, we survey the current state-of-the-art of WF de-
fenses and present the results of our comparative evaluation based
on the methodology described in Section 3. We then analyze our
ﬁndings and try to shed light on previously unexplained results.
Our simulations of each of the listed defenses operate on packet
sequences (packet lengths and timings, but no content) rather than
raw packets; they do not directly modify packets during page load-
ing. This allows us to observe if a defense is able to cover a feature
modiﬁed by a generator.
4.1 Simulated Defenses

We simulate and compare the following network level ﬁnger-

printing defenses:

230Feature type

Unique packet sizes

Packet size frequencies

Packet ordering

Interpacket timing

Generator name
Small packet size changes
Large packet size changes
Diffusing packet sizes
Append inbound MTU packets
Append outbound packets
Insert inbound MTU packets
Adjacent transpositions
Short distance transpositions
Long distance transpositions
Delays

#
1
2
3
4
5
6
7
8
9
10

Transformation for G(v)
For 0 < i ≤ |P|: (cid:96)i ← di min(|(cid:96)i| + v, 1500)
#
For 0 < i ≤ v: (cid:96)5i ← d5i min(|(cid:96)5i| + 1000, 1500)
For 0 < i ≤ v: (cid:96)5i ← d5i min(|(cid:96)5i| + i, 1500)
Repeat v times: P ← A(P, N, (tN ,−1500))
For 0 < i ≤ v: P ← A(P, N, (tN , Pouti ))
For 0 < i ≤ v: P ← A(P, 5i, (t5i,−1500))
For 0 < i ≤ v: T (P, 5i, 5i − 1)
For 0 < i ≤ v: T (P, 5i, 5i − 4)
For 0 < i ≤ (cid:98)v/5(cid:99), 0 < j ≤ 5: T (P, 25i− j, 25i−
19 − j)
∀pi ∈ P, ti ← ti + v · i · 0.020 ms

Table 2: Generators. Packet sequence P = {p1, p2, ..., pN} where pi = (ti, (cid:96)i), t1 = 0. Pout is the sequence of outgoing packets in
P , and Pouti is its ith element (wrapping back to the beginning if i > |Pout|). di is the direction (1=outgoing, -1=incoming) of pi.
A(P, i, p) appends packet p after pi. T (P, i, j) transposes the packet lengths of pi and pj.

Defense

Unique packet lengths

Packet length counts

Packet ordering

Timing

G1
*

PadM *
*
PadE F2 28 91 F3

*

G2
*
1

G3

*

*
3 F3 59 * F3

Wr-Morph F2 13 74 F2 29 180 *
HTTPOS F3 29 30 F3 23
Pa-Decoy F1

6
68 F1 48 178 F1 34 * F3 93

50 F3 45 * F3

1

BuFLO F2 147 *

*
Tamaraw F2 177 * F2 180

*

*
*

*
*

2

G8

G6

G4

G7
*

G5
9 F2 16 57
* * F2 16 57 F2 3
9 F3 1
27 F2 2
11 F2 32 68
* * F2 43 72 F2 2
18 F2 3
9 F3 1
* F2 38 151 F3 1

G10
* * F4 23
1 F3 29 * F3 2 3 F3 4 4 F4 23
* * F4 23
3 F3 179 * F3 2 * F3 4 4 F4 23
*
* * F2 23 85 F2 78
* F2 20 94
* * F2 122 * F2 68 168 F2 82 *

47
47
47
47
* * * * F3 14 * F4 111 146
*
* * * * *
* * * * *
*

* * * * *

* * * * *

* *
* *

*
*
*

*
*
*

G9

*

*

*
*

*
*

*

Table 3: Upper bounds on the quality of the defenses. Results are given in three columns: the ﬁrst column is the feature classiﬁer
that was able to achieve the highest mean accuracy, the second is the value of v for which the feature classiﬁer in column 1 had an
accuracy greater than 0.55 for all greater values of v, and the third is similar, but for 0.75; asterisks indicate when these accuracies
were not reached for v ≤ 180. Asterisks and higher v values indicate that the corresponding defense is more successful in covering
the speciﬁc feature. Tamaraw is our BuFLO-based defense presented in Section 6.

Maximum Packet Padding (PadM): Padding adds garbage data
to the end of packets in order to obscure their true length. Packet
padding schemes have been known in the literature; a large number
of different padding schemes were analyzed by Dyer et al. [5] and
shown to be ineffective against the attack classiﬁers described in [9]
and [12]. Packet padding schemes are meant to obscure the unique
packet length feature. In the PadM defense, all packet lengths are
padded to the MTU. The effect of using Tor is similar to PadM, as
Tor trafﬁc is delivered in ﬁxed-size cells.

Exponential Packet Padding (PadE): Here, packet lengths are
padded upwards to the closest power of 2, but not exceeding the
MTU. No extra packets are added in either of the two schemes.
PadE is meant to be a bandwidth-cheaper version of PadM.

Trafﬁc Morphing (Wr-Morph): Wright et al. [19] published a
WF defense that is meant to obscure packet lengths, known as traf-
ﬁc morphing. Unique among the defenses, Wr-Morph is designed
to allow the client to set a target page CT and mimic the page’s
packet size distribution by modifying packet lengths.

In our implementation, we use google.com as CT , our target
morph page since it is reasonable for the client to attempt to hide
her trafﬁc features by using the most commonly accessed page as a
decoy.

HTTP Obfuscation (HTTPOS): HTTPOS was presented by
Luo et al. [11] as a platform for website ﬁngerprinting defenses.
Unlike many other defenses, HTTPOS is implemented entirely on
the client-side, with no need for support from any proxy or the end
server. It does so by using TCP advertised windows, HTTP pipelin-

ing, and HTTP ranges in order to control the sizes of both outgoing
and incoming packets.

Our simulation is not done at the application layer; rather, we
simply go through the packet sequence and split up each incom-
ing packet of size less than the MTU. In the implementation of
HTTPOS, this requires a new outgoing packet between the two
splits which signals the end server that the client is ready to receive
the second split, which costs one round-trip time. In our simulated
defense, we assume this can be done without the signal and round-
trip time, which is possible with the cooperation of a proxy or the
end server.1 We complete this defense by also padding all outgoing
packets to a ﬁxed size of 1500; the authors describe how outgoing
packet padding can be done, but they are not clear as to what they
implemented. Our choice gives maximum protection for unique
packet lengths, at the cost of extra overhead.

Background Noise (Pa-Decoy): Background noise can be used
to add randomness to each page load in order to make them less
distinguishable. Tor has some background activity that makes ﬁn-
gerprinting more difﬁcult, such as circuit construction, circuit mea-
surement, and stream SENDMEs.

Panchenko et al. [12] proposed a simple defense using back-
ground noise to defeat their own attack. Whenever a page is loaded,
a decoy page is loaded in the background, using its own connec-
tions and connection limit so as not to interfere with the connec-
tions of the intended page. This defense has a high overhead. We

1This assumption is reasonable for us as many of the other defenses
also require the cooperation of a proxy or the end server.

231used a different page from Alexa’s top 800 sites as background
noise for each of the training and testing elements in order to simu-
late the intended effect that the attacker cannot predict which page
the client picked. Our simulated defense assumes that the decoy
page does not interfere at all with the page load of the true page.

Buffered Fixed Length Obfuscator (BuFLO): After Dyer et
al. analyzed a large number of trafﬁc analysis countermeasures and
found that efﬁcient defenses failed, they presented their own de-
fense, BuFLO — a Buffered Fixed-Length Obfuscator, and demon-
strated its relative success against the attacks of the day [5]. The
BuFLO defense is an obfuscator with large bandwidth and time
overhead that is applied to both the incoming and outgoing traf-
ﬁc. Packets are sent at ﬁxed intervals with ﬁxed length, and if no
data needs to be sent, dummy packets are sent instead. The trafﬁc
must continue for a minimum amount of time, after which it may
terminate if no more data needs to be sent.

BuFLO is parameterized by three values: d the ﬁxed size of
packets (set to 1500), ρ the interpacket timing (set to one packet/20
milliseconds), and τ the ﬁxed minimum amount of time for which
data must be sent (set to 10 seconds). These parameter settings
were the strong (and more bandwidth-intensive) choice presented
by Dyer et al., which was able to sharply decrease the accuracy of
the Panchenko classiﬁer [12].

4.2 Comparative Results

In this section we highlight the conclusions of our comparative
evaluation. The full results are given in Table 3. For each defense,
we only present the most successful feature classiﬁer. We only use
the interpacket timing classiﬁer on G10. We vary v from 1 to 180
and present the minimum value of v for which the feature classi-
ﬁer had a higher accuracy than 0.55 and 0.75 for all greater v. A
lower v indicates that the defense was less successful in covering
the feature against our classiﬁers, whereas an asterisk indicates that
our feature classiﬁers could not distinguish the classes with the tar-
get accuracy (0.55 or 0.75) for any value of v that we tested. This
table also includes our new proposed defense, Tamaraw (presented
in Section 6).

Our evaluation shows that PadM covers unique packet length as
well as packet orderings.
In PadE, changing packet length can
cause the lengths to be padded to different powers of 2, which
could affect the set of unique packet lengths. However, the number
of distinct lengths with PadE is small, so this is unlikely. Con-
sequently, the unique packet length classiﬁer did not detect a dif-
ference. Our packet ordering classiﬁer, however, considered the
changes in packet lengths to be re-ordering, and therefore managed
to defeat PadE. PadM and PadE are ineffective against attacks that
use packet length frequencies.

HTTPOS has been shown to be effective against attack classi-
ﬁers that are strongly dependent on unique packet lengths [9, 11].
However, Cai, et al.’s attack succeeds against HTTPOS [3] . This
is because HTTPOS attempts to remove unique packet lengths as a
feature, but Cai’s attack primarily uses packet ordering.

Pa-Decoy and BuFLO are effective against the Panchenko clas-
siﬁer and attacks that are dependent on packet length frequencies
[5,12] – i.e., these defenses partly cover packet length frequencies.
The table exposes several ﬂaws. PadM, PadE, Wr-Morph and
HTTPOS are not designed to cover total transmission size (packet
length frequencies), so they would be ineffective against the attacks
that leverage them. Pa-Decoy fails to completely cover interpacket
timing because it only covers the total transmission time roughly
half the time (i.e., when the decoy page takes longer to load than
the desired page), which may leak the total page size, a powerful
feature. Similarly, BuFLO does not cover total transmission time if

it is over 10 seconds at ρ = 0.020 s/packet, which happened quite
often. Trying to cover packet length frequency on G(v)
4 becomes a
race between v and the overhead of BuFLO; a larger v requires a
larger setting of minimum time τ to cover it.

Our results are upper bounds on the quality of the defense, as
more complicated classiﬁers could reveal more information. For
instance, HTTPOS performs well against F1, but if C(cid:48) has larger
unique packet lengths than C, then D(C(cid:48)) will also have larger
unique packet lengths than D(C) under HTTPOS. We wrote a clas-
siﬁer speciﬁcally to ﬁnd this difference and achieved an accuracy
of 0.99 with G(100)

compared to 0.5 for F1.

Tor developers want to understand what WF defenses work with
Tor [15]. As Tor already covers unique packet length, PadM, PadE,
Wr-Morph, and HTTPOS are not meaningful on Tor, as all of these
defenses are focused on covering unique packet lengths (although
only PadM truly does so). We note in particular that HTTPOS is a
platform valuable for its client-only implementation (requiring no
cooperation from a proxy or the end server), but Tor bridges can be
made to cooperate by implementing a WF defense as a pluggable
transport. Pa-Decoy and Dy-BuFLO achieve only limited success
at covering packet length frequencies. In short, none of these de-
fenses can be considered a perfect ﬁt for Tor.

1

5. THEORETICAL FOUNDATIONS

In this section we develop a model of website ﬁngerprinting at-
tacks and defenses, derive lower bounds on the bandwidth overhead
of any defense that achieves a given level of security, and show how
to derive open-world performance from closed-world experimental
results.
5.1 Security vs. Overhead Trade-Off

We focus on understanding the relationship between bandwidth
overhead and security guarantees. The overhead required by a ﬁn-
gerprinting defense depends on the set of web sites to be protected
– a set of similar websites can be protected with little overhead, a
set of dissimilar websites requires more overhead. To derive lower
bounds of bandwidth costs, we consider an ofﬂine version of the
website ﬁngerprinting defense problem, i.e.
the defense system
knows, in advance, the set of websites that the user may visit and
the packet traces that each website may generate. We develop an
efﬁcient dynamic program to compute a lower bound on the band-
width overhead of any ﬁngerprinting defense scheme in the closed-
world setting. We will use this algorithm to compute lower bounds
on overhead for the websites used in our evaluation (in Section 6.2).

5.1.1 Deﬁnitions
In a website ﬁngerprinting attack, the defender selects a website,
w, and uses the defense mechanism to load the website, producing
a packet trace, t, that is observed by the attacker. The attacker then
attempts to guess w.

Let W be a random variable representing the URL of the web-
site selected by the defender. The probability distribution of W
reﬂects the probability that the defender visits each website. For
each website, w, let T D
w and Tw be the random variables repre-
senting the packet trace generated by loading w with and without
defense system D, respectively. Packet traces include the time, di-
rection, and content of each packet. Since cryptographic attacks
are out of scope for this paper, we assume any encryption functions
used by the defense scheme are information-theoretically secure.
The probability distribution of T D
w captures variations in network
conditions, changes in dynamically-generated web pages, random-
ness in the browser, and randomness in the defense system. We

232assume the attacker knows the distribution of W and T D
w.

w for every

In a closed world setting, the attacker’s goal is to infer W from
W . The optimal closed-world attacker, A, upon observing trace t,
T D
outputs

(cid:104)

(cid:105)

A(t) = argmax

Pr[W = w] Pr

T D
w = t

w

If more than one w attains the maximum, then the attacker chooses
randomly among them.

Some privacy applications require good worst-case performance,
and some only require good average-case performance. This leads
to two security deﬁnitions for website ﬁngerprinting defenses:

DEFINITION 1. A ﬁngerprinting defense D is non-uniformly

-secure for W iff Pr(cid:2)A(T D
-secure for W if maxw Pr(cid:2)A(T D

W ) = W(cid:3) ≤ . Defense D is uniformly

w ) = w(cid:3) ≤ .

These are information-theoretic security deﬁnitions – A is the op-
timal attacker described above. The ﬁrst deﬁnition says that A’s
average success rate is less than , but it does not require that every
website be difﬁcult to recognize. The second deﬁnition requires all
websites to be at least  difﬁcult to recognize. All previous papers
on website ﬁngerprinting attacks and defenses have reported aver-
age attack success rates in the closed-world model, i.e. they have
reported non-uniform security measurements. We will do the same.
To deﬁne the bandwidth overhead of a defense system, let B(t)
be the total number of bytes transmitted in trace t. We deﬁne the
bandwidth ratio of defense D as

E(cid:2)B(cid:0)T D

W

(cid:1)(cid:3)

E [B (TW )]

BWRatioD(W ) =

(cid:104)

This deﬁnition captures the overall bandwidth ratio between a user
surﬁng the web while using defense D and a user visiting the same
websites with no defense.
5.1.2 Bandwidth Lower Bounds
In this section we derive an algorithm to compute, given web-
sites w1, . . . , wn, a lower bound for the bandwidth that any non-
uniformly -secure ﬁngerprinting defense can use in a closed-world
experiment using w1, . . . , wn.

To compute a lower bound on bandwidth, we consider an adver-
sary that looks only at the total number of bytes in a packet trace,
i.e. an attacker AS that always guesses

AS(t) = argmax

Pr

B(T D

w ) = B(t)

w

Any defense that is -secure against an arbitrary attacker must also
be at least -secure against AS. If we can derive a lower bound on
defenses that are -secure against AS, that lower bound will apply
to any -secure defense.

We make two simplifying assumptions in order to obtain an ef-
ﬁcient algorithm for computing lower bounds. First, we assume
that each website has a unique ﬁxed size, si. In our closed world
experiments, we found that, for just over half the web pages in our
dataset, their size had a normalized standard deviation of less than
0.11 across 20 loads, so we do not believe this assumption will
signiﬁcantly impact the results of our analysis. Second, we assume
that the defense mechanism does not compress or truncate the web-
site.

We prove the following theorem in Appendix A:

(cid:105)

THEOREM 1. Suppose n is an integer. Let W be a random
variable uniformly distributed over w1, . . . , wn, i.e. W represents
a closed-world experiment. Suppose D is a defense that is -non-
uniformly-secure against AS on distribution W . Then there exists
a monotonically increasing function f from S = {s1, . . . , sn} to
itself such that

• |f (S)| ≤ n.

i=1 f (si)/(cid:80)n
• (cid:80)n

i=1 si ≤ BWRatioD(W ).

i=1 f (si).

Intuitively, f represents a mapping from each website’s original
size (si) to the number of bytes that D transmits when loading web-
site wi.

This theorem enables us to efﬁciently compute a lower bound on
the overhead of any defense that is  uniformly or non-uniformly
secure in a closed world experiment on w1, . . . , wn. To get a lower
bound for non-uniformly -secure defenses, we just need to ﬁnd
a monotonically increasing function f : S → S that satisﬁes

|f (S)| ≤ n and minimizes(cid:80)n
ing k ≤ n and minimizing (cid:80)k

titions satisfy a recurrence relation.
non-uniformly k
non-uniformly k−1
fore the cost, C( k

Such an f is equivalent to a partition S1, . . . , Sk of S satisfy-
i=1 |Si| maxs∈Si s. These par-
If S1, . . . , Sk is an optimal
n -secure partition, then S1, . . . , Sk−1 is an optimal
n−|Sk| -secure partition of S1 ∪ ··· ∪ Sk−1. There-
n , n), of the optimal f satisﬁes the recurrence
if k = 1
otherwise.

, n − j) + jsn

 nsn

, n) =

k − 1
n − j

1≤j≤n−1

We can obtain a similar bound for uniformly -secure determin-
istic defenses. We say a defense is deterministic if, on each load of
website wi, it always transmits bi bytes. The following theorem is
proven in Appendix A.

min

k
n

C(

C(

THEOREM 2. Let W be uniformly distributed over w1, . . . , wn,
i.e. W represents a closed-world experiment. Suppose D is a de-
terministic defense that is uniformly -secure against AS on distri-
bution W . Then there exists a monotonically increasing function f
from S = {s1, . . . , sn} to itself such that

i=1 si ≤ BWRatioD(W ).

• mini |f−1(si)| ≥ 1/.

• (cid:80)n
i=1 f (si)/(cid:80)n
|Si| ≥ 1/ and minimizing (cid:80)k

As with the lower bound on non-uniformly secure defenses, such
an f corresponds to a partition S1, . . . , Sk of S satisfying mini
i=1 |Si| maxs∈Si s. These parti-
tions satisfy a slightly different recurrence. If S1, . . . , Sk is is an
optimal uniformly -secure partition of S, then S1, . . . , Sk−1 is an
optimal uniformly -secure partition on S1 ∪ ··· ∪ Sk−1. Thus the
cost, C(, n) of the optimal uniformly -secure partition satisﬁes
the recurrence relation:

if n ∈(cid:2) 1

if n < 1/
 , 2
otherwise.



(cid:1)



∞
nsn
1≤j≤ n−1

min



(cid:48)

C

(, n) =

(cid:48)

(, n − j) + jsn

C

Algorithm 1 shows a dynamic program for computing a lower
bound on the bandwidth of any defense that can achieve  non-
uniform security in a closed-world experiment on static websites
with sizes s1, . . . , sn in time O(n2). We use this algorithm to
compute the lower bounds reported in Section 6.2. The dynamic
program for computing uniform security lower bounds is similar.
5.2 From Closed to Open World

In this section, we show how to use closed-world experimental
results to compute open-world security of defenses and open-world
performance of attacks. This makes attack and defense evaluation
simpler: researchers need only perform closed-world experiments
to predict open-world performance.

In an open-world attack, the defender selects a website, W , ac-
cording to some probability distribution and generates a trace, T D
W ,
corresponding to a visit to that website using some defense, D.

233The attacker’s goal is to determine whether W = w∗, where w∗ is
a particular website of interest. (It is easy to generalize this deﬁni-
tion to situations with multiple websites of interest).

In the open-world setting, the distribution of the random variable
W corresponds to the popularity of different websites among the
population of users being monitored in the attack. So, for example,
if the ﬁngerprinting attacker is a government monitoring citizens
Tor usage, then W would be distributed according to the popularity
of websites among that nation’s Tor users.

Any closed-world attack can be used to construct an open-world
attack by selecting websites w2, . . . , wn and building a closed-
world classiﬁer, A, on w∗, w2, . . . , wn. The open-world classiﬁer
is deﬁned as C(t) = 1 iff A(t) = w∗.
We can compute the false positive rate of this open-world attack
as follows. Let p∗ = Pr[W = w∗] and pi = Pr[W = wi] for i =
2, . . . , n. We can obtain estimates for p∗, p2, . . . , pn from public
sources, such as the Alexa Page-Views per Million database [1].
Let Rn be the average success rate of A in the closed world, i.e.

Pr[A(T D

w∗ ) = w∗] +

Pr[A(T D

wi ) = wi]

Rn =

Note that Rn is the standard performance metric used in closed-
world evaluations. For simplicity, we assume that Pr[A(T D
w∗ ) =
w∗] = Rn. We also assume that, whenever A misclassiﬁes a trace,
there is a 1/n chance that it misclassiﬁes the trace as w∗, i.e. that
W ) (cid:54)= W ] = 1/n. Essen-
Pr[A(T D
tially, these two assumptions are equivalent to assuming that w∗
is not particularly difﬁcult or easy for A to recognize. With these
assumptions, we can compute C’s false-positive rate:

W ) = w∗|W (cid:54)= w∗ ∧ A(T D

FPR(C) = Pr[C(T D

W ) = 1|W (cid:54)= w
Pr[W = w] Pr[C(T D

∗

]

w ) = 1]

n(cid:80)

i=2
n

Pr[W = w] Pr[A(T D

w ) = w∗]

Pr[W = wi] Pr[A(T D

wi ) = w∗]

1 − p∗

1 − p∗

1 − p∗

(cid:33)

w(cid:54)=w∗

(cid:88)
(cid:88)
n(cid:88)
(cid:32)
1 − n(cid:88)

w(cid:54)=w∗

i=2

i=2

1 − Rn
n(1 − p∗)

=

=

=

+

=

i=2
With the same assumptions, the true positive rate of C is

i=2

TPR(C) = Pr[C(T D

] = Rn

pi +

n(1 − p∗)
W ) = 1|W = w

∗

i=2

n(cid:80)

The choice of the websites w2, . . . , wn used to build A will af-
fect the performance of C in the open world. The choice of web-
sites affects the false-positive rate in two ways: (1) choosing less
popular websites tends to increase the false-positive rate since it
decreases
pi, and (2) choosing more similar websites increases
the false-positive rate by reducing Rn. The choice of websites af-
fects the true-positive rate only through Rn. Cai, et al., showed that
the Alexa top 100 websites were about as similar as 100 randomly
chosen websites [3], i.e. that the most popular websites are not par-
ticularly similar to eachother. Thus it is generally a good strategy
to choose w2, . . . , wn to be the most popular websites other than
w∗.

Similarly, the number, n, of websites used to build A affects the
false-positive rate in two ways: (1) increasing n tends to increase
the false positive rate by lowering Rn, and (2) increasing n tends to

Pr[W = wi]

n(cid:88)

1

n(1 − p∗)

(cid:32)

1

1 − n(cid:88)

(cid:33)

pi

end for

end for
return C[n, n]

end function

C[j, i] = min1≤(cid:96)≤i−1 [(i − (cid:96))si + C[j − 1, (cid:96)]]

n(cid:80)

i=2

pi. Increasing

decrease the false-positive rate since it increases
n can only decrease the true-positive rate.

Thus we can tune the false-positive and true-positive rates of C
by varying n. Small n will have large true- and false-positive rates.
Increasing n will reduce both the false- and true-positive rates. By
varying n, we can generate the receiver operating curve (ROC) of
C.
In the real world, visits to w∗ may be rare. In this case, false-
positive rate can be a misleading metric. A classiﬁer with a low
false-positive rate may still be useless if true positives are so rare
that they are overwhelmed by false positives. Therefore, we also
report true-discovery rates for the open-world attack and defense
evaluations in this paper. Given an open-world classiﬁer, C, its
true-discovery rate is deﬁned as

TDR(C) = Pr[W = w

∗|C(T D

W ) = 1].

Intuitively, the true-discovery rate is the fraction of alarms that are
true alarms. The true-discovery rate can be computed from the
false-positive and true-positive rates as follows:

Pr[W = w∗] TPR(C)

TDR(C) =

Pr[W = w∗] TPR(C) + Pr[W (cid:54)= w∗] FPR(C)

=

p∗Rn + 1−Rn

n

n(cid:80)

p∗Rn

pi + (1 −(cid:80)n

i=2

i=2 pi) 1

n

Algorithm 1 Algorithm to compute a lower bound on the band-
width of any ofﬂine non-uniformly  secure ﬁngerprinting defense
against AS attackers.

function AS-MIN-COST(n, , {s1, . . . , sn})

Array C[0 . . . n, 0 . . . n]
for i = 0, . . . , n do

C[i, 0] ← 0

end for
for i = 0, . . . , n do

C[0, i] ← ∞
end for
for i = 1 → n do

for j = 1 → n do

6. TAMARAW: A NEW DEFENSE

In this section we present a prototype of a new defense, Tama-
raw2, that can be considered a theoretically provable version of Bu-
FLO.
6.1 Design

Based on the results of our comparative and theoretical study of
website ﬁngerprinting defenses, Tamaraw is designed with three
guiding principles in mind:

1. Strong Theoretical Foundations: The security of the Tama-
raw defense is based on an extension of the concept of op-
timal partitioning and feature hiding demonstrated in Sec-
tion 5.1 (against AS attackers). The relation is seen in section
Section 6.2.1.

2A Tamaraw is a lightweight cousin of the Buffalo.

2342. Feature coverage: While Section 5.1 aims to hide only the
total transmission size, Tamaraw attempts to hide all fea-
tures. In fact, Table 3 shows that Tamaraw effectively hides
all the features studied in Section 3, with the exception of to-
tal downstream transmission size. As in Section 5.1, optimal
partitioning requires different sites to be padded to different
transmission sizes.

3. Reducing Overhead Costs: BuFLO faces the dilemma that
increasing τ will increase its defensive coverage, but also in-
crease its overhead. We address this dilemma and we are able
to ﬁnd ways to signiﬁcantly reduce the overhead of BuFLO
in both bandwidth and time.

Tamaraw works as follows. As in BuFLO, trafﬁc is still sent in
ﬁxed size packets and at ﬁxed intervals; however, the packet size
is set at 750 bytes rather than the MTU. This is done since most
outgoing packets are covered by this size (see Appendix: Figure
3) while not incurring unwanted overhead. Further, incoming and
outgoing trafﬁc are treated differently. Outgoing trafﬁc is ﬁxed at a
higher packet interval, which saves overhead as outgoing trafﬁc is
much less frequent. We denote the packet intervals as ρout and ρin
(measured in s/packet). We use experimentation to choose these
values of ρ in Section 6.2.

Additionally, BuFLO only attempts to cover total transmission
size if the total amount of time for one page is less than τ. This
makes the choice of τ especially awkward: increasing τ increases
the number of web pages covered by BuFLO, but it also increases
the overhead. In Tamaraw, however, the number of packets sent in
both directions are always padded to multiples of a padding param-
eter, L.3 This means that if L is large enough, then it is likely that
for each web page there exists some other web page that is mapped
to the same multiple of L. Suppose the total number of incoming
packets is I, where AL < I ≤ (A + 1)L, then we pad to (A + 1)L
at the rate ρin. We do this separately for outgoing packets as well.
Compared to the optimal defense in Section 5.1, the partitions pro-
duced are ﬁxed, independent of the dataset.

Even though the differences between BuFLO and Tamaraw are
not very large, the impact on security is tremendous: Tamaraw of-
fers a maximum attack-accuracy guarantee, BuFLO does not.
6.2 Experimental Results

In BuFLO, ρout and ρin were both 0.02, but it is expected that
ρout should not have to be as large as ρin. As the distinguishability
of two different web pages is controlled by the padding parame-
ter L, our objective in the choice of ρin and ρout is to minimize
overhead. We test the bandwidth and time overhead of Tamaraw
on Alexa’s top 100 pages, loaded 70 times each. We vary ρout and
ρin from 0.005 to 0.16 seconds/packet while using Tamaraw with
MTU packet sizes. We present a pareto curve showing all values
for which no other choice of parameters had both a lower time and
bandwidth overhead in the Appendix: Figure 4.

Generally, as ρin and ρout increased, size overhead decreased
while time overhead increased. Here we set L to 100, for reasons
discussed below. With MTU packets, ρout = 0.04 and ρin =
0.012, we achieve a 17% decrease of total transmission size over-
head from BuFLO’s 149 ± 6% to 123 ± 10%, with the time over-
head roughly the same, changing from 330 ± 80% to 320 ± 70%.
3It is non-trivial for the proxy to know when to pad, as it does not
know when the data stream has ended. One way for the proxy to
know this is to set a parameter K, such that if the last K packets
were dummy packets, then the trafﬁc is determined to have ended.
In our analysis we assume that the client and proxy know when to
pad.

In order to achieve these same beneﬁts when we use Tamaraw with
750 byte packet sizes, we maintain the same transmission rate. This
is achieved by halving ρin and ρout – i.e., we set ρout = 0.02 and
ρin = 0.006.

In our implementations of BuFLO and Tamaraw, we pessimisti-
cally required that the original logical ordering of the real packets
must be maintained. For example, if the defense allowed an outgo-
ing packet to be sent, but the next real packet to be sent is an incom-
ing packet, then a dummy outgoing packet is sent, even if there are
other outgoing packets waiting after the incoming packet. This is
to guarantee that the causal order is preserved: it could be that the
subsequent outgoing packets depend on the incoming packet. This
rule has a large effect on the bandwidth. A practical implementa-
tion could achieve a lower size and time overhead as re-ordering is
possible for both defenses when subsequence is not consequence;
our simulations are therefore pessimistic on the overhead but nec-
essary to guarantee correctness.

We apply the same defense methodology in Section 4.2, and
give the results in Table 3, presented earlier. We can see that at
ρout = 0.02, ρin = 0.006, and L = 100, Tamaraw is much more
successful at protecting all features than other defenses, despite that
it cannot achieve a perfect cover of total packet length or frequency
either. Looking more closely at the table, we see that Tamaraw is
not perfectly successful against generators that signiﬁcantly change
the total transmission size (including the unique packet length gen-
erators G1 and G2). As BuFLO sends more dummy outgoing pack-
ets than Tamaraw, BuFLO is more able to cover changes in outgo-
ing transmission size (G2, G5), but it is less able to cover changes
in incoming transmission size (G1, G4, G6). We next show why
Tamaraw is a more effective defense than BuFLO.
6.2.1 An Ideal Attacker
In order to produce an upper bound on the attack accuracy of
any classiﬁer on Tamaraw, we evaluate the partitions produced by
Tamaraw (partitions were introduced in Section 5.1). The number
of partitions is directly linked to the maximum classiﬁcation accu-
racy. For a partition of size |S|, the attacker can at best achieve an
accuracy of 1/|S| on each site in the partition.

For Tamaraw, the partition is calculated as follows. Let D be
Tamaraw where L is set to 0 (no dummy packets appended to the
end). Suppose the number of incoming packets for defended packet
sequence D(P ) is |D(P )inc| and the number of outgoing packets
is |D(P )out|. Two packet sequences D(P ) and D(P (cid:48)) are the
same under Tamaraw if they satisfy:

(cid:106) |D(P (cid:48))inc|

(cid:107)

(cid:106) |D(P )out|

(cid:107)

(cid:106) |D(P (cid:48))out|

(cid:107)

(cid:106) |D(P )inc|

(cid:107)

L

L

.

=

L

L

,

=

This is the case even if the attacker is able to observe those packet
sequences multiple times with the knowledge that they belong to
two pages. We experiment on Alexa’s top 800 sites. We only load
one instance of each web page and reset the browser state between
each page load. By doing this, we eliminate the network variability
and make the defense system deterministic, which, as shown in the
Appendix, does not reduce the security of the defense. Thus we
can soundly use this technique to obtain an upper bound on the
success rate of an ideal attacker against this defense. For BuFLO,
we consider two packet sequences to belong to the same partition
if the total transmission size is the same, as total transmission size
is the only observable difference.
6.2.2 Closed-world Performance
Figure 1 shows the non-uniform security provided by Tamaraw
and BuFLO against their corresponding bandwidth overheads. The
BuFLO points correspond to the BuFLO conﬁgurations evaluated
by Dyer, et al. [5]. For reference, Figure 1 also includes a point

235TDR of the corresponding open-world classiﬁer where the the web-
site of interest is wi, for i = 1, . . . , 100. Note that, even though
the open-world is the entire internet, our experiment only consid-
ers open-world attacks that attempt to recognize visits to one of
the 100 most popular websites. The reason is because the TDR of
an open-world attack on an unpopular website will be lower than
that of an attack on a more popular website. By showing that the
TDR becomes extremely low when attacking Tamaraw, even for the
ﬁrst 100 websites, we show that it’s extremely low for all websites.
The popularity of each website was taken from the Alexa estimated
page views per million database [1]. We only need popularity in-
formation for the sites used to construct the closed-world classiﬁer;
the rest of the sites on the internet are treated as being randomly
classiﬁed and have, in aggregate, 106− (p1 + p2 + ... + p800) page-
views per million, where pi is the page-views-per-million of the ith
most popular site. For comparison, for the 100th most popular site,
in the open world, Tamaraw (with 200% overhead) has a TDR ap-
th the TDR of BuFLO and Tamaraw (with overhead
proximately 1
13
th the TDR of BuFLO. These
687%) has a TDR approximately 1
110
results show that Tamaraw is a signiﬁcant improvement over Bu-
FLO in the open- and closed-world settings.

7. CODE AND DATA RELEASE

To ensure reproducibility and correctness, all code and data used
in this paper are publicly available4. This includes: traces of web-
sites loaded, code for all generators, code for all feature based at-
tackers, and code for all defenses tested (including Tamaraw).

8. CONCLUSIONS

In this paper, we developed and tested a new feature-based com-
parative methodology that classiﬁes and qualiﬁes WF defenses.
This methodology allows us to understand which defenses are able
to successfully hide which features – thereby upper-bounding their
success rates in defending against attackers that rely heavily on that
feature. This methodology also exposes some ﬂaws of previous de-
fenses.

Our theoretical model clariﬁes the limits of website ﬁngerprint-
ing defenses. It establishes efﬁciency bounds that no defense can
cross, giving an absolute benchmark for evaluating the efﬁciency
of defenses. The lower bounds of bandwidth costs are surprisingly
low, suggesting that it may be possible to build very efﬁcient de-
fenses. We also show that, in some contexts, randomized defenses
offer no security or overhead advantage compared to deterministic
defenses. This theoretical foundation also provides a framework
for comparing schemes which offer different overhead and security
trade-offs. Further, it allows conclusions to be drawn about open-
world performance of attacks and defenses, based on their closed-
world results. This greatly simpliﬁes the experimental setup re-
quired to estimate open-world performance of attacks and defenses.
While previous work has shown that current WF defenses are
either ineffective or inefﬁcient, and while our work has explained
these results using a systematic methodology, we argue that the
situation is not hopeless for web browsing clients who desire pri-
vacy. We propose a new defense, Tamaraw, that is able to reduce
the overhead of BuFLO signiﬁcantly. Using our methodology, we
show that Tamaraw provides better protection against website ﬁn-
gerprinting attacks than all previous defenses, in both, the open and
closed-world models.

4https://crysp.uwaterloo.ca/software/
webfingerprint/

Figure 1: Non-uniform security () against transmission size
overhead for BuFLO, Tamaraw with L = 100, and Tor.

Figure 2: TDR for the Alexa top 100 sites in the open-world
when using various defenses against the ideal attacker.

for Tor, for which we use overhead and security measurements
reported by Cai, et al. against their Ca-DLevenshtein attack [3].
The results show that Tamaraw offers a signiﬁcantly better secu-
rity/efﬁciency trade-off than BuFLO. For reference, at a size over-
head of 130%, there are 553 partitions (non-uniform security of
69%) in BuFLO (τ = 9) and 18 partitions (non-uniform security
of 2.25%) in Tamaraw. This shows that a design that adheres to the
principles of provable lower bounds in Section 5.1 is more suitable
for clients.

Table 1 shows how close different defenses are to the optimal
lower bound curve derived in Section 5.1. The Overhead Ratio of
a defense is the ratio between the defense’s bandwidth overhead
and the lower bound on overhead. Table 1 shows the best over-
head ratios that Tamaraw and BuFLO achieved in our experiments.
For reference, we also give the overhead ratios for Tor. Tamaraw
achieves its best overhead ratio in a high-security/high-overhead
conﬁguration that may not be practical for most users. Therefore,
we also report Tamaraw’s performance in a more feasible conﬁgu-
ration with overhead comparable to the best BuFLO conﬁguration
in our experiments. Even with this restriction, Tamaraw has an
overhead ratio less than a sixtieth of BuFLO.

6.2.3 Open-world Performance
Figure 2 shows the TDR in the open-world for the Alexa top
100 sites when they face the ideal adversary and are defended by
BuFLO, Tamaraw (at 200% and 687% overhead), or no defense,
respectively. To compute these curves, we build an ideal closed-
world classiﬁer on the Alexa top 800 sites. The ideal attacker is
based on the ambiguity sets described above. We then compute the

 0 0.5 1 1.5 2 2.5 3 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8Bandwidth Overhead (x100%)Adversarial Accuracy (ε)Non-Uniform BoundTamarawBuFLOTor 0 0.2 0.4 0.6 0.8 1 10 20 30 40 50 60 70 80 90 100True Discovery RateSite IndexNo DefenseBuFLO vs. Optimal AttackTamaraw (OH: 200%) vs. Optimal AttackTamaraw (OH:687%) vs. Optimal Attack2369. ACKNOWLEDGMENTS

We would like to thank Scott E. Coull, Andriy Panchenko, and
Kevin P. Dyer for their correspondence with us, which helped us
improve the paper. We thank NSERC, ORF, and The Tor Project for
funding this project. This work was made possible by the facilities
of the Shared Hierarchical Academic Research Computing Net-
work (SHARCNET: www.sharcnet.ca) and Compute/Calcul
Canada.

10. REFERENCES
[1] Alexa — The Web Information Company. www.alexa.com.
[2] G. D. Bissias, M. Liberatore, D. Jensen, and B. N. Levine.

Privacy Vulnerabilities in Encrypted HTTP Streams. In
Privacy Enhancing Technologies, pages 1–11. Springer,
2006.

[3] X. Cai, X. Zhang, B. Joshi, and R. Johnson. Touching from a

Distance: Website Fingerprinting Attacks and Defenses. In
Proceedings of the 2012 ACM Conference on Computer and
Communications Security, pages 605–616, 2012.

[4] S. Chen, R. Wang, X. Wang, and K. Zhang. Side-Channel
Leaks in Web Applications: A Reality Today, a Challenge
Tomorrow. In Security and Privacy (SP), 2010 IEEE
Symposium on, pages 191–206. IEEE, 2010.

[5] K. Dyer, S. Coull, T. Ristenpart, and T. Shrimpton.

Peek-a-Boo, I Still See You: Why Efﬁcient Trafﬁc Analysis
Countermeasures Fail. In Proceedings of the 2012 IEEE
Symposium on Security and Privacy, pages 332–346, 2012.

[6] D. Herrmann, R. Wendolsky, and H. Federrath. Website

Fingerprinting: Attacking Popular Privacy Enhancing
Technologies with the Multinomial Naïve-Bayes Classiﬁer.
In Proceedings of the 2009 ACM workshop on Cloud
computing security, pages 31–42, 2009.

[7] A. J. Hoffman and J. B. Kruskal. Integral boundary points of
convex polyhedra. In M. JÃijnger, T. M. Liebling, D. Naddef,
G. L. Nemhauser, W. R. Pulleyblank, G. Reinelt, G. Rinaldi,
and L. A. Wolsey, editors, 50 Years of Integer Programming
1958-2008, pages 49–76. Springer Berlin Heidelberg, 2010.

[8] I. Keller and C. Tompkins. An Extension of a Theorem of

Dantzig’s. Linear Inequalities and Related Systems, Annals
of Mathematics Studies, 38:247–254, 1956.

[9] M. Liberatore and B. Levine. Inferring the Source of

Encrypted HTTP Connections. In Proceedings of the 13th
ACM Conference on Computer and Communications
Security, pages 255–263, 2006.

[10] L. Lu, E.-C. Chang, and M. C. Chan. Website Fingerprinting

and Identiﬁcation Using Ordered Feature Sequences. In
Computer Security–ESORICS 2010, pages 199–214.
Springer, 2010.

[11] X. Luo, P. Zhou, E. W. Chan, W. Lee, R. K. Chang, and
R. Perdisci. HTTPOS: Sealing Information Leaks with
Browser-side Obfuscation of Encrypted Flows. In NDSS,
2011.

[12] A. Panchenko, L. Niessen, A. Zinnen, and T. Engel. Website

Fingerprinting in Onion Routing Based Anonymization
Networks. In Proceedings of the 10th ACM Workshop on
Privacy in the Electronic Society, pages 103–114, 2011.

[13] M. Perry. Experimental Defense for Website Trafﬁc

Fingerprinting. https:
//blog.torproject.org/blog/experimental-
defense-website-traffic-fingerprinting,
September 2011. Accessed Feb. 2013.

Figure 3: Packet lengths observed when loading one instance
of each of Alexa’s top 800 sites. Packets sized 1500 bytes are
discarded.

Figure 4: The lower-left boundary of the two-dimensional feasi-
bility region of size and time overhead for Tamaraw when vary-
ing ρout and ρin. Our chosen parameters and the overhead of
BuFLO on the same data set are marked. The overhead in-
cludes the padding mandated by L = 100.

[14] M. Perry. A critique of website ﬁngerprinting attacks.

https:
//blog.torproject.org/blog/critique-
website-traffic-fingerprinting-attacks,
November 2013.

[15] M. Perry, E. Clark, and S. Murdoch. The Design and

Implementation of the Tor Browser [DRAFT].
https://www.torproject.org/projects/
torbrowser/design/. Accessed Oct. 2013.

[16] P. Seymour. Decomposition of regular matroids. Journal of

Combinatorial Theory, Series B, 28:305–359, 1980.

[17] T. Wang and I. Goldberg. Comparing website ﬁngerprinting

attacks and defenses. Technical Report 2013-30, CACR,
2013. http://cacr.uwaterloo.ca/
techreports/2013/cacr2013-30.pdf.

[18] T. Wang and I. Goldberg. Improved Website Fingerprinting

on Tor. In Proceedings of the 12th ACM Workshop on
Privacy in the Electronic Society, 2013.

[19] C. Wright, S. Coull, and F. Monrose. Trafﬁc Morphing: An

Efﬁcient Defense against Statistical Trafﬁc Analysis. In
Proceedings of the 16th Network and Distributed Security
Symposium, pages 237–250, 2009.

APPENDIX
A. LOWER BOUND PROOFS
Suppose websites w1, . . . , wn have sizes s1 < s2 < . . . <
sn. Let S = {s1, . . . , sn}. For any defense, D, let pij be the
probability that D transmits j bytes during a load of website wi.

Since, in a closed-world experiment, each website occurs with

probability 1/n, the bandwidth cost of D is

∞(cid:88)

n(cid:88)

1
n

jpij

j=1

i=1

 0 0.2 0.4 0.6 0.8 1 0 200 400 600 800 1000 1200 1400CDFPacket length (bytes)OutgoingIncoming 0 100 200 300 400 0 50 100 150 200 250Time overhead (%)Size overhead (%) Dy-BuFLOρout = 0.04,ρin = 0.012Tamaraw237and the non-uniform success probability of AS is

(cid:80)

∞(cid:88)

j=1

maxi pij(cid:80)

i pij

·

∞(cid:88)

j=1

i pij
n

=

maxi pij

n

We derive lower bounds on the bandwidth cost of D by comput-
ing the matrix of pij values that minimize the above bandwidth cost
function while still satisfying the above security constraint. Recall
that, since D is assumed not to compress or truncate web pages,
pij = 0 for j < si.

The overall structure of the proof for non-uniform security is
• Constrain the structure of the optimal pij so that we can for-
(see

mulate the optimization problem as a linear program.
Lemma 1).

• Prove that the linear program has an integral solution, so that
the optimal solution is equivalent to a function f : S → S
satisfying certain constraints (see Lemma 2).

• Prove that f is monotonically increasing (see Lemma 3).

The lower bound for uniform security is similar. We ﬁrst prove that
there exists a similar function f for any deterministic uniformly
secure defense, and then apply Lemma 3.

LEMMA 1. Let pij be the probabilities that minimize the band-

width cost while meeting the security requirement.

1. pij = 0 unless j ∈ {s1, . . . , sn}.
2. If pij < maxk pkj, then for all j(cid:48) > j, pij(cid:48) = 0.
3. For all j, pkj ≤ pk+1,j for k ∈ [1, i], where si ≤ j < si+1.
1. Suppose p(cid:96)j (cid:54)= 0 where sk < j < sk+1. Then
PROOF.
we can make a more efﬁcient and no less secure by replacing
pisk with pisk +pij for all i and setting pij = 0 for all i. This
will have lower bandwidth cost because sk < j. This will not
violate the constraint that, for all i and j(cid:48) < si, pij(cid:48) = 0,
because, if pij (cid:54)= 0 before the change, then si ≤ j, so si ≤
sk. This will not worsen security because maxi(pisk +pij) ≤
maxi pisk + maxi pij.
2. Suppose otherwise. Let t = min(maxk pkj−pij, pij(cid:48) ). Note
t (cid:54)= 0. Thus we can construct a more efﬁcient and no less
secure defense by replacing pij with pij + t and pij(cid:48) with
pij(cid:48) − t.
3. Suppose pkj > pk+1,j for some k ∈ [1, i], where si ≤
j < si+1. This implies that pk+1,j < maxi pij. By Item 2,
pk+1,j(cid:48) = 0 for all j(cid:48) > j.

j(cid:48)=sk+1

pk+1,j(cid:48) = 1.

Thus we must have that:(cid:80)j
(cid:80)j

pkj(cid:48) >(cid:80)j

j(cid:48)=sk+1

j(cid:48)=sk

This also implies that pkj (cid:54)= 0. Thus, by Item 2, pkj(cid:48) =
maxi pij(cid:48) for all j(cid:48) ∈ {sk, . . . , j − 1}. This implies that

pk+1,j(cid:48) = 1, a contradicition.

Since pij is non-zero only if j ∈ {s1, . . . , sn}, we can relabel
the pij to be the probability that the defense transmits sj bytes
during a load of website wi.

Lemma 1, Item 3 implies that maxi pij = pii, so the security

constraint can be re-written as(cid:80)n

i=1 pii ≤ n.

Now that the security constraint is a linear function of the pij
variables, we can formulate a linear program for computing the
optimal pij values:

n(cid:88)

n(cid:88)

j=i
subject to the constraints

i=1

minimize

(a) (cid:80)n
(b) (cid:80)n

(c)

i=1 pii ≤ n
j=i pij = 1
0 ≤ pij ≤ 1

pijsj

(the bandwidth cost)

( non-uniform security)
(pij are probabilities)

LEMMA 2. The above linear program has an integral solution.
PROOF. Linear programs with Totally Unimodular (TU) con-
straint matrices and integral objective functions have integral so-
lutions [7]. We prove that the constraint matrix, A (derived by
the constraints (a), (b), and (c) of the above LP), is TU. To prove
TU-ness of A, it is sufﬁcient to prove the following [8]: (i) Every
column contains at-most 2 non-zero entries, (ii) Every entry is 0,
1, or -1, (iii) If two non-zero entries in any column of A have the
same sign, then the row of each belongs in two disjoint partitions
of A.

Since the set of TU matrices is closed under the operation of
adding a row or column with at-most one non-zero entry [16], we
may delete the 2n rows of A corresponding to constraint (c) and
prove that the remaining constraint matrix A(cid:48) satisﬁes the TU con-
ditions (i) - (iii).

Observe the following properties of A(cid:48):
• There are n rows (WLOG, rows 1 to n) induced by the con-
straint (a). These are such that: Ai,(i−1)n, . . . , Ai,in−1 = 1,
∀i ∈ {1, . . . , n} and 0 for all other entries. Therefore, each
column of the partition B composed of these n rows contains
only a single non-zero entry (i.e., +1).

• There is only 1 row (WLOG, row n + 1) induced by the
constraint (b). This row has the form: An+1,j = 1, ∀j ∈
{12, . . . , n2} and 0 for all other entries. Each column of the
partition C composed of this single vector may contain only
a single non-zero entry (i.e., +1).

From the above properties, it is clear that matrix A(cid:48) is TU since:
Each column contains at-most 2 non-zero entries (+1) and it may
be partitioned into matrices B and C such that condition (iii) is
satisﬁed. Therefore, the matrices A(cid:48) and A are TU and the LP
describing A has only integral optima.
In an integral solution of the linear program, all the probabilities
are 0 or 1, so the solution is equivalent to a function f : S → S
satisfying

• |f (S)| ≤ n.

• (cid:80)n
i=1 f (si)/(cid:80)n

i=1 si ≤ BWRatioD(W ).

We now show there is a similar function for any deterministic
uniformly secure defense D. Set f (si) = bi where bi is the num-
ber of bytes transmitted when the defense D loads website wi.
Since D does not compress or truncate websites, we must have
bi ≥ maxs∈f−1(bi) s for all i. Observe that we can assume bi =
maxs∈f−1(bi) s without harming security or efﬁciency, so that f :
S → S. Thus f satisﬁes the security constraint mini |f−1(si)| ≥

1/, and(cid:80)n

i=1 f (si)/(cid:80)n

i=1 si ≤ BWRatioD(W ).

LEMMA 3. The mapping function f corresponding to an opti-
mal non-uniformly -secure defense, or a deterministic uniformly
-secure defense, is monotonic.

PROOF. Consider any partition of {s1, . . . , sn} into sets S1,
. . . , Sk. Let mi = maxs∈Si Si. Without loss of generality, as-
sume m1 ≤ m2 ≤ ··· ≤ mk. Now consider the monotonic
i | = |Si|. Let
allocation of traces into sets S∗
i ≤ mi for all i, i.e. the new
m∗
allocation has lower bandwidth.

s. Observe that m∗

k where |S∗

i = maxs∈S∗

1 , . . . , S∗

Since the number of sets in the partition and the sizes of those
sets are unchanged, this new allocation has the same uniform and
non-uniform security as the original, but lower bandwidth. Hence
the optimal f must be monotonic.

i

238