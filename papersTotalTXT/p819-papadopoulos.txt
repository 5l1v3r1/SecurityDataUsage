Taking Authenticated Range Queries to

Arbitrary Dimensions

Dimitrios Papadopoulos

Boston University
Boston MA, USA

dipapado@bu.edu

Stavros Papadopoulos

Intel Labs & MIT

Cambridge MA, USA

stavrosp@csail.mit.edu

Nikos Triandopoulos

RSA Laboratories &
Boston University

Cambridge MA, USA

nikolaos.triandopoulos@rsa.com

ABSTRACT
We study the problem of authenticated multi-dimensional range
queries over outsourced databases, where an owner outsources its
database to an untrusted server, which maintains it and answers
queries to clients. Previous schemes either scale exponentially in
the number of query dimensions, or rely on heuristic data structures
without provable bounds. Most importantly, existing work requires
an exponential, in the database attributes, number of structures to
support queries on every possible combination of dimensions in the
database. In this paper, we propose the ﬁrst schemes that (i) scale
linearly with the number of dimensions, and (ii) support queries on
any set of dimensions with linear in the number of attributes setup
cost and storage. We achieve this through an elaborate fusion of
novel and existing set-operation sub-protocols. We prove the secu-
rity of our solutions relying on the q-Strong Bilinear Difﬁe-Hellman
assumption, and experimentally conﬁrm their feasibility.

Categories and Subject Descriptors
H.2.7 [Database Management]: Database Administration—secu-
rity, integrity and protection; C.2.4 [Communication Networks]:
Distributed Systems—client/server, distributed databases

General Terms
Algorithms, Security, Veriﬁcation

Keywords
authenticated range queries; authenticated data structures; delega-
tion of computation; database outsourcing

1.

INTRODUCTION

Database outsourcing [16] has lately emerged as a common prac-
tice for companies and institutions. It allows a data owner to del-
egate the maintenance and administration of its database to a pow-
erful third-party server. Clients access the database by contacting
the server instead of the owner. This paradigm reduces the owner’s

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
Copyright 2014 ACM 978-1-4503-2957-6/14/11 ...$15.00.
http://dx.doi.org/10.1145/2660267.2660373 .

needs for building a sophisticated and potentially costly infrastruc-
ture, since storage and computationally intensive tasks are ofﬂoaded
to the server. On the other hand, the server proﬁts from accommo-
dating a large number of owners. Despite its merits, database out-
sourcing poses the challenge that the server may be untrusted and,
thus, tamper with the results (e.g., to bias the competition among
rival serviced companies). Hence, it is vital that the server provides
the client with proofs certifying the result integrity, i.e., that the
query was executed correctly on the owner’s data.

In this work we target the case where the client issues a multi-
dimensional range query. We model the owner’s database as a ta-
ble T that contains n tuples with m attribute values. A range query
is deﬁned over d out of the m attributes, which we refer to as di-
mensions. It is expressed as d pairs of values li, ui, each along a
certain dimension ai. Its result includes all the tuples whose value
on ai is in range [li, ui] for all dimensions ai speciﬁed in the query.
This query is fundamental in a vast variety of applications. For
instance, it is a typical select...where query in conventional rela-
tional databases. Moreover, it is a frequent query in the emerging
scientiﬁc databases (e.g., it is called subarray in SciDB [7]). Re-
lational and scientiﬁc database systems manage numerous types of
data, such as corporate, stock, astronomical, medical, etc. With the
advent of “big data,” such systems are commonly deployed by third
party servers in massively parallel architectures, in order to address
the issue of scalability. Integrity assurance is a desirable property
that serves both as a guarantee against a possibly malicious server,
but also as a tool for error detection.
Prior work. The most basic authentication problem is set member-
ship, i.e., whether an element belongs in a data collection. Well-
known example schemes include Merkle trees [19] and accumu-
lation trees [22]. At the opposite extreme, there exist generic ap-
proaches (e.g., [11, 25]) that aim at authenticating any possible
query on outsourced data. Although such protocols can address our
problem, they incur an excessive proof construction overhead at the
server, due to their generality. Therefore, there is a large variety of
specialized constructions that have been proposed in the literature
for the problem of authenticated multi-dimensional range queries.
Martel et al. [18] provide a generalization of Merkle trees, which
captures the case of multi-dimensional range queries. Chen et al. [9]
proposes a solution that is similar to [18], based on attribute do-
main partition and access control. For the restricted case of 1-
dimensional and 2-dimensional queries, Goodrich et al. [14, 15]
construct schemes based on cryptographic extensions of Merkle
trees. Li et al. [17] propose a variant of the B+-tree that incor-
porates hash values similarly to the Merkle tree, for processing 1-
dimensional queries in external storage. Yang et al. [28] extend this
idea to multiple dimensions, by transforming the R∗-tree [4] into a

819Scheme
Martel et al. [18]
Chen et al. [9]
Our basic scheme (using [19])
Our basic scheme (using [22])
Our update-efﬁcient scheme (using [19])
Our update-efﬁcient scheme (using [22])

O(|T|)
O(|T|)
√
√
n)
O(m
n)
O(m
m: # attributes, n: # tuples, |T|(= mn): database size, d: # dimensions, Ri: partial result at dimension ai, R: query result, N: maximum domain size,  ∈ (0, 1]

˜O(|R|) + O(d log n)

˜O(|R|) + O(d log n)

˜O(|R|) + O(d)

˜O(|R|) + O(d)

Table 1: Comparison of asymptotic complexities of authenticated multi-dimensional range query schemes

Veriﬁcation
O(logd−1 |T|)
O(logd N )

Update

O(logm−1 |T|)
O(logm N )

Setup

Proof size

O(|T| logm−1 |T|) O(logd−1 |T|)
O(|T| logm N )
O(logd N )
O(|T| log n)
O(d log n)
O(|T| log n)
O(|T| log n)
O(|T| log n)

O(d log n)

O(d)

O(d)

Proof construction

˜O((cid:80)d
˜O((cid:80)d
˜O((cid:80)d
˜O((cid:80)d

O(logd−1 |T|)
O(logd N )
i=1 |Ri|) + O(d log n)
i=1 |Ri|) + O(dn log n)
i=1 |Ri|) + O(d log n)
i=1 |Ri|) + O(dn log n)

Merkle R∗-tree. There are also other cryptographically augmented
data structures (e.g., [20, 10] based on signatures instead of hashes).
The existing literature suffers from the following critical prob-
lems. On the one hand, the schemes of [18, 9] that provide guar-
anteed (non-trivial) complexity bounds, scale exponentially with
the number of dimensions d. On the other hand, the rest of the
approaches rely on the heuristic R∗-tree and fail to accommodate
more than a limit of dimensions in practice (e.g., more than 8), as
the performance and effectiveness of the index deteriorates with
dimensionality. Most importantly, all methods require an exponen-
tial in m number of structures to support queries on every possible
combination of dimensions in the database. This is because each
structure is built on a speciﬁc set of dimensions, and different sets
require separate structures.

Finally, there is a work by Xu [27] that, contrary to [18, 9], scales
quadratically with d. However, this scheme falls within a different
model, as it necessitates multi-round interaction between server and
client (as opposed to our non-interactive setting).
Its security is
based on non-falsiﬁable “knowledge-type” assumptions. Moreover,
this scheme makes use of functional encryption [6], considerably
reducing its potential for implementation.
Our contributions. We introduce two schemes for authenticated
multi-dimensional range query processing; a basic, and a update-
efﬁcient. Our solutions feature two novel and powerful properties:
• They are the ﬁrst schemes where all costs (i.e., setup, stor-
age, update, proof construction, veriﬁcation, and proof size)
grow only linearly with the number of dimensions, a huge
improvement over the current literature. Table 1 provides
a comparison of our asymptotic complexities against known
schemes (with non-trivial bounds).

• They are the ﬁrst to support an exponential in m number of

range queries with linear in m setup cost and storage.

In that sense, the main result of this work is that it takes authenti-
cated range query processing to arbitrary dimensions, both in terms
of number and choice.

The central idea of our solutions is the reduction of the multi-
dimensional range query to set-operations over appropriately de-
ﬁned sets in the database. In particular, in a one-time setup stage,
the owner builds a novel authenticated structure over every database
attribute separately, and then binds all structures using an existing
set-membership structure (e.g., [19, 22]). Given a query involv-
ing any set of dimensions, the server decomposes it into its d 1-
dimensional ranges, and processes them individually on the struc-
ture of each dimension, producing d proofs for the partial results
R1, . . . , Rd. The main challenge is for these d proofs to (i) be
combinable such that they verify the intersection of Ri, which is
the ﬁnal result R, and (ii) be veriﬁable without the partial results,
so that the total proof size and veriﬁcation cost are independent of
their (potentially large) sizes. We address this challenge through

an elaborate fusion of existing and novel intersection, union, and
set-difference protocols, based on bilinear accumulators.

This particular treatment of the problem, i.e., the efﬁcient au-
thentication of a d-dimensional range query via the combination of
d separate 1-dimensional proofs, would not be feasible without the
recent advances in set-operation authentication (e.g., [24, 8]). We
anticipate that future research will substantially improve the efﬁ-
ciency of the set-operation sub-protocols. Motivated by this, as an
additional important contribution, we identify and abstract the set-
operation sub-protocols needed as building blocks in our schemes,
and formulate a general framework that can integrate any future
improved machinery for set-operation authentication.

We formally prove our constructions secure under the q-Strong
Bilinear Difﬁe-Hellman [5] assumption and the security of the un-
derlying set-membership schemes. We also provide an experimen-
tal evaluation, demonstrating the feasibility of our schemes.
Roadmap. Section 2 contains the necessary cryptographic back-
ground. Section 3 formulates our problem. Section 4 presents our
basic scheme for authenticated multi-dimensional range query pro-
cessing, whereas Section 5 introduces an alternative construction
with optimized updates. Section 6 provides a thorough experimen-
tal evaluation of our solutions. Finally, Section 7 concludes our
paper with directions to future work.
2. CRYPTOGRAPHIC BACKGROUND

In the following, λ denotes the security parameter, ν(λ) a negli-
gible function, and PPT a probabilistic polynomial time algorithm.
In complexity analysis, we also use ˜O notation that hides a poly-
logarithmic multiplicative factor. Moreover, for proof sizes, we
omit the factor imposed by the bit representation of group elements.
Bilinear pairings. Let G1, G2 be cyclic multiplicative groups of
prime order p, generated by g1, g2 respectively. Let also GT be a
cyclic multiplicative group with the same order p and e : G1 ×
G2 → GT be a bilinear pairing with the following properties: (1)
Bilinearity: e(P a, Qb) = e(P, Q)ab for all P, Q ∈ G1 × G2 and
a, b ∈ Zp. (2) Non-degeneracy: e(g1, g2) (cid:54)= 1. (3) Computability:
There is an efﬁcient algorithm to compute e(P, Q) for all P, Q ∈
G1 × G2. In the sequel, for ease of presentation, we will assume a
symmetric (Type I) pairing, where G1 = G2 = G. We denote with
pub = (p, G, GT , e, g) the bilinear pairings parameters, output by
a PPT algorithm BilGen on input 1λ. We will make use of the
following assumption over bilinear groups:
ASSUMPTION (q-Strong Bilinear Difﬁe-Hellman (q-SBDH) [5]).
Let λ be a security parameter and let pub ← BilGen(1λ). Given
(pub, gs, . . . , gsq
) where q is poly(λ), for some s chosen at ran-
dom from Z∗
p, there is no PPT algorithm that can output a pair
(c, e(g, g)1/(c+s)) ∈ Z∗
Collision-resistant hash functions. A collision-resistant hash func-
tion (CRHF) H is a function randomly sampled from a function

p × GT except with probability ν(λ).

820family, such that no non-uniform PPT algorithm can output x, x(cid:48),
such that H(x) = H(x(cid:48)) and x (cid:54)= x(cid:48), except with probability ν(λ).
Set-membership authentication. Consider a data owner outsourc-
ing a set X to an untrusted third-party server. Clients issue queries
about a single element x ∈ X. A set-membership authentication
protocol (SMA) allows the server to prove to a client that x is
indeed a member of X. An SMA is a collection of algorithms
KeyGen, Setup, Prove, Verify and Update. The owner executes
Keygen and Setup prior to outsourcing X. The former gener-
ates a secret and public key pair sk, pk, whereas the latter pro-
duces a digest δ that is a succinct cryptographic representation of
X. The owner keeps sk and publishes pk and δ. Given a client
query about x ∈ X, the server runs Prove to produce a proof
of membership π. Given pk, δ, π and x, the client runs Verify to
check the membership of x in X. In case the owner modiﬁes X
by inserting/deleting elements, it executes Update to produce a
new digest δ reﬂecting the updates in X, and notiﬁes the server
about the changes. An SMA is secure, if the probability that
(accept ← Verify ∧ y /∈ X) is negligible.
The most well-known SMA is the Merkle tree [19], which is a
binary tree where (i) each leaf node contains an element x ∈ X, and
(ii) each non-leaf node stores the hash of the values of its children,
using a CRHF H. During Setup, the owner builds a Merkle tree on
X, signs the hash value in the root, publishes it as the digest δ, and
sends the tree to the server. During Prove, the server accesses the
tree to ﬁnd x, and includes in proof π all sibling hash values along
the path from the root to the leaf storing x. In Verify, the client re-
cursively performs the hash operations to reconstruct the root hash
value, and checks it against δ. Producing an element y (cid:54)∈ X and a
convincing proof is known to be as hard as ﬁnding a collision for
H. For n elements, the proof construction and size, veriﬁcation,
and update time are all O(log n), whereas the setup is O(n). An
alternative SMA is the accumulation tree [22], which features two
main differences to the Merkle tree: (i) the fanout of each non-leaf
node is n1/, where  ∈ (0, 1] is a user-deﬁned parameter, and
(ii) each non-leaf node stores an accumulation value (discussed be-
low) produced over the values of its children. The following lemma
(originally from [23]; slightly informal here) describes the security
of the bilinear-pairing based accumulation tree.
LEMMA 1. Let λ be a security parameter. Under q-SBDH, no PPT
adversary on input pk output by Keygen and with oracle access
to algorithms Setup, Update, Prove and Verify can produce set
X, element x (cid:54)∈ X and proof π, such that Verify outputs accept,
except with probability ν(λ).

We refer the interested reader to [22] and [24] for a more detailed
description of the accumulation tree. This SMA offers O(1) proof
size, veriﬁcation, and update time, and O(n) setup cost. The down-
side is the proof construction overhead, which is now O(n log n),
and the costly operations as opposed to the Merkle tree (exponenti-
ations vs. hashings).
Set operation authentication. Consider now an owner of a collec-
tion of sorted sets X = {X1, . . . , Xm}, who outsources them to
an untrusted server. Clients issue queries describing set operations
over X , consisting of unions, intersections, and set-differences. Ex-
ample queries include X1 ∩ X5, (X2 ∪ X3)∩ X1, and X1 \ X2. A
set operation authentication protocol (SOA) enables the server to
prove the integrity of the result. Similarly to SMA, it is comprised
of algorithms KeyGen, Setup, Prove, Verify Update, and its secu-
rity is deﬁned as the inability of the server to present a false answer
with an accepting proof.

|X|), the proof is generated in time ˜O((cid:80)

Existing SOA constructions appear in [24] and [8]. The former
can support queries expressed as a single set operation (for instance
Xi ∩ . . . ∩ Xj, i.e., one intersection over an arbitrary number of
sets). On the other hand, the latter accommodates any circuit of set
operations, e.g., (Xi ∩ Xj) ∪ Xl. Both schemes offer the same
asymptotic overhead. Speciﬁcally, for a single operation on collec-
tion XQ ⊆ X of d sets that produces result R, computable in time
|X|)
and has size O(d). Note that proof construction incurs only a poly-
logarithmic overhead compared to result computation, and this is
generalized naturally for circuits of multiple operations in [8]. The
veriﬁcation overhead is ˜O(|R|) + O(d), whereas the setup cost is
X∈X |X|). Although [8] subsumes [24] in terms of function-
ality, its security relies on non-standard “knowledge-type” assump-
tions.

Ω((cid:80)
O((cid:80)

X∈XQ

X∈XQ

We next describe the intersection scheme of [24], as we utilize
it in our constructions. This scheme employs the bilinear accumu-
lator primitive [21]. Let X be a set with elements from Zp, and
s ←R Z∗

p a secret. The accumulation value of X is deﬁned as:

(cid:81)
x∈X (x+s) .

acc(X) = g

x∈X (x+S) = PX (S) =(cid:80)|X|

ular, we can write(cid:81)
compute acc(X) = gPX (s) =(cid:81)|X|

This value is a succinct, collision-resistant cryptographic represen-
tation of X under q-SBDH. It is also computable (from scratch)
even without s, by having access to the public pairing parameters
pub, as well as a public key (gs, . . . , gsq
), where q is a user-deﬁned
parameter that is an upper bound on the cardinality of X. In partic-
i=0 ciSi, where S
is an undeﬁned variable. The coefﬁcients c0, . . . , c|X| can be com-
puted in time O(|X| log |X|) using FFT interpolation. One can
)ci using only the public
information. Note that, with access to s, the bilinear accumulator
can accommodate an insertion/deletion in X with O(1) operations
[21]. However, without s, the updated accumulation value must be
computed from scratch.
In order to prove to a client with access to acc(X1), acc(X2)
that a set I is the intersection X1 ∩ X2, it sufﬁces to prove that
(i) I ⊆ X1 and I ⊆ X2, and (ii) (X1 \ I) ∩ (X2 \ I) = ∅.
Towards (i), the server must send subset witnesses W1, W2 to the
client, where Wi = acc(Xi \ I) for i = 1, 2. To verify (i), the
client ﬁrst computes acc(I), and checks the following for i = 1, 2:

i=0(gsi

e(acc(I), Wi) ?= e(acc(Xi), g) .

follows. Since (X1\I)∩(X2\I) = ∅, PX1\I (S) =(cid:81)
S) and PX2\I (S) =(cid:81)

For (ii), the server computes two disjointness witnesses F1, F2 as
x∈X1\I (x+
x∈X2\I (x + S) have greatest common divi-
sor of degree zero. Hence, there exist polynomials Q1(S), Q2(S)
such that Q1(S)· PX1\I (S) + Q2(S)· PX2\I (S) = 1. These poly-
nomials (also known as Bézout coefﬁcients) are efﬁciently com-
putable by the Extended Euclidean algorithm. The server calculates
the disjointness witnesses as F1 = gQ1(s), F2 = gQ2(s). To verify
(ii), the client simply checks

e(W1, F1) · e(W2, F2) ?= e(g, g) .

This approach naturally generalizes for d > 2 sets Xi, with cor-
i=1. In our security

responding intersection proof π∩ = {Wi, Fi}d
proofs, we use the following lemma from [24]:
LEMMA 2. Let λ be a security parameter, and pub ← BilGen(1λ).
) ∈ G for some s chosen
Under q-SBDH, on input (pub, gs, . . . , gsq
at random from Z∗
p, no PPT adversary can output sets X1, . . . , Xd, I

821with elements in Zp, where d = poly(λ), and π∩ = {Wi, Fi}d

such that e(acc(I), Wi) = e(acc(Xi), g),(cid:81)
and I (cid:54)=(cid:84)

i Xi, for i = 1, . . . , d, except with probability ν(λ).

i=1,
i e(Wi, Fi) = e(g, g),

3. PROBLEM FORMULATION

In this section we describe our targeted setting, formulate our

authentication protocol, and model its security.
Setting and query. Our setting involves three types of parties; an
owner, a server, and a number of clients. The owner outsources to
the server a dataset T that consists of n tuples, each having a set
A = {a1, . . . , am} of attributes. This dataset can be perceived as
a table in traditional relational databases. It could also be a multi-
dimensional array in scientiﬁc databases (e.g., SciDB [7]), where
a subset of the attributes are the array dimensions (i.e., the array
indices), and the rest are the array attributes (i.e., the array cell
values). In addition, the server is responsible for maintaining the
dataset, upon receiving tuple updates (modeled as insertion/deletion
requests) from the owner.

Clients issue multi-dimensional range queries on T to the server,
which return the tuples from T that satisfy certain range conditions
over a set of attributes. More formally, a query Q is speciﬁed over
any subset of d attributes AQ ⊆ A, where |AQ| = d ≤ m, and
encoded by the set of triplets {(i, li, ui)}ai∈AQ. The result of Q is
a set R ⊆ T that contains exactly those tuples t ∈ T that satisfy
li ≤ t.ai ≤ ui for all ai ∈ AQ. This query corresponds to a
select. . .where query in relational databases, and a subarray
query in scientiﬁc databases. In our terminology, each ai ∈ AQ
represents a dimension in the multi-dimensional range query.

In our setting, we consider that the server is untrusted, and may
present to the client a tampered result. Our goal is to construct a
protocol for authenticated multi-dimensional range queries, which
allows the client to verify the integrity of the received result.
Authentication protocol. Let Tj denote the version of dataset
T after j rounds of updates. An authenticated multi-dimensional
range query protocol (AMR) consists of the following algorithms:

1. KeyGen(1λ): It outputs secret and public keys sk, pk.

2. Setup(T0, sk, pk): It computes some authentication infor-
mation auth(T0) and digest δ0, given dataset T0, sk and pk.

3. Update(upd, auth(Tj), δj, sk, pk): On input update infor-
mation upd on Tj, auth(Tj), δj and sk, it outputs an up-
dated dataset Tj+1, along with new auth(Tj+1), and δj+1.

4. Prove(Q, R, Tj, auth(Tj), pk): On input query Q on Tj

with result R, and auth(Tj), it returns R and proof π.

5. Verify(Q, R, π, δj, pk): On input query Q, result R, proof

π, digest δj and pk, it outputs either accept or reject.

In a pre-processing stage, the owner runs KeyGen and Setup. It
publishes public key pk and digest δ0, which is a succinct cryp-
tographic representation of initial dataset T0. Moreover, it sends
T0, auth(T0) to the server, where auth(T0) is some authentica-
tion information on T0 that will be used by the server to construct
proofs. The owners maintains its dataset by issuing Update when
changes occur at the dataset. Speciﬁcally, an update is a tuple in-
sertion or deletion, encoded by upd. An update on Tj produces
a new version Tj+1, as well as new digest δj+1 and auth(Tj+1).
The owner sends to the server only the modiﬁed parts necessary
for computing Tj+1, auth(Tj+1), δj+1. The server responds to a

query Q from the client by ﬁrst computing the result R, and ex-
ecutes Prove that constructs the corresponding proof π. Finally,
the client validates the integrity and freshness of R being a correct
answer to Q on current Tj, by running Verify.

An AMR must satisfy the following two properties:

CORRECTNESS. A AMR is correct if, for all λ ∈ N, (sk, pk) ←
KeyGen(1λ), all (T0, auth(T0), δ0) output by one invocation of
Setup followed by j(cid:48) calls to Update on updates upd, where j(cid:48) is
poly(λ), any Q with correct result R, and π output by Prove(Q, Tj,
auth(Tj), pk), Verify(Q, R, π, δj, pk) returns accept with prob-
ability 1, for all j ≤ j(cid:48).
SECURITY. Let λ ∈ N be a security parameter, key pair (sk, pk) ←
KeyGen(1λ), and A be a PPT adversary that possesses pk and has
oracle access to all algorithms of AMR. The adversary picks an
initial state of the dataset T0 and receives T0, auth(T0), δ0 through
oracle access to Setup. Then, for i = 0, ..., j(cid:48) − 1 = poly(λ), A
issues an update updi for Ti and receives Ti+1, auth(Ti+1) and
δi+1 through oracle access to Update. At any point during these
update queries, A can make polynomially many oracle calls to al-
gorithms Prove and Verify. Finally, A picks an index 0 ≤ j ≤ j(cid:48),
a query Q, a result R∗ and a proof π∗. We say that a AMR is
secure if for all large enough λ ∈ N and all PPT adversaries A, it
holds that:

 ≤ ν(λ) ,

, π

, δj, pk)



∗

(Q, R

, π

∗

, j) ← A s.t
∗

∗

Pr

accept ←Verify(Q, R
∗ (cid:54)= R

∧ R

where R is the correct result of Q on Tj, and the probability is
taken over the randomness of the algorithms and the coins of A.

As an additional remark, note that the above protocol falls within
the framework of authenticated data structures, introduced in [26],
but is tailored for the speciﬁc problem of range queries.

4. BASIC SCHEME
Section 4.1 presents a generalized methodology for construct-
ing AMRs, Section 4.2 introduces a concrete instantiation of this
methodology, and Section 4.3 includes a set-difference sub-protocol
that is used as part of our construction.
4.1 A General Framework

We present our proposed framework, outline its beneﬁts, and
highlight the challenges behind a secure and efﬁcient instantiation.
Framework. Recall that the query result is a set of tuples, each
consisting of m attribute values, and satisfying certain range con-
ditions. For the sake of simplicity, we henceforth deﬁne result R
of query Q on dataset T as a set containing exactly the hash value
hi = H(ti) of the binary representation of each tuple ti ∈ T that
satisﬁes the query conditions, under a CRHF H : {0, 1}∗ → Zp.
Our AMR constructions will focus on proving that R is the cor-
rect set of hash values corresponding to the tuples satisfying the
query. Then, given these hash values along with the full result tu-
ples, the client can validate the integrity of each result tuple ti by
testing H(ti) ?= hi. Due to collision-resistance of H, the server
cannot return a falsiﬁed t∗
i ) = hi, instead of the
correct pre-image ti of hi. In the following, when clear from the
context, we use term “tuple” for a table tuple ti ∈ T and its hash
value hi = H(ti) interchangeably.

i such that H(t∗

822We illustrate the main idea of our framework using Figure 1. Let
h1, . . . , hn correspond to the hash values of the tuples t1, . . . , tn of
T , respectively. We maintain a copy of the values for every attribute
ai, and sort the copy of ai according to the attribute values of the
tuples on ai. For instance, in Figure 1, h3 = H(t3) appears ﬁrst in
the ordering of a1 because t3 has the smallest value on attribute a1
among the tuples in T .

Figure 1: Illustrating the different tuple orders per attribute

A multi-dimensional range query Q is deﬁned over an arbitrary
set of dimensions (where, recall, each dimension is an attribute).
Our framework “decomposes” a d-dimensional range query into d
separate 1-dimensional queries. More speciﬁcally, our framework
boils down to two steps:

• Step 1: (1-D proofs) For each dimension ai involved in Q,
compute the set Ri of all hash values of tuples that satisfy
the condition on ai. Formally, Ri = {hj = H(tj) | li ≤
tj.ai ≤ ui}. Also compute proof πRi for the integrity of Ri.
i Ri and
proof π for its integrity, given pairs (Ri, πRi ) for every ai
involved in Q.

• Step 2: (Combination) Compute the result R

= (cid:84)

def

For example, suppose in Figure 1 that a 2-dimensional query Q
is deﬁned over ai and aj. Our two-step framework ﬁrst dictates
the computation of Ri = {h1, h3, h7} that corresponds to the 1-
dimensional result along dimension ai, and Rj = {h1, h7} along
dimension aj, as well as proofs πRi , πRj . It next requires the com-
putation of result R = {h1, h7} and a proof π.
Beneﬁts. Our view of multi-dimensional range queries as a collec-
tion of 1-dimensional range queries offers multiple advantages over
existing approaches: (i) We aim to support range queries over any
combination of attributes. Thus, there are O(2m) possible differ-
ent attribute combinations that can be involved in a query, where
m is the total number of attributes in T . In order to support all of
them, existing solutions must build O(2m) separate authenticated
structures. On the contrary, our framework requires m such struc-
tures (one per attribute) constructed once, which sufﬁce to capture
all O(2m) possible subsets of attributes. (ii) As discussed in Sec-
tion 1, the performance of all existing constructions deteriorates
drastically with d.
In contrast, the separate handling of each di-
mension allows our framework to scale with d gracefully. (iii) To
address scalability issues that arise from the advent of “big data,”
data management systems typically employ multi-core CPU hard-
ware, as well as cloud infrastructures involving multiple nodes. In
our framework, the 1-dimensional sub-queries can be distributed

across multiple cores/nodes, and run in parallel. The combination
step can then take place using well-known in-network aggregation
techniques (e.g., in a MapReduce fashion [12]).
The challenge. There are several efﬁcient solutions for the prob-
lem of 1-dimensional range queries (e.g., [18, 17, 14, 15]), each
of which can be used to instantiate Step 1 in our framework. The
problem lies in Step 2, i.e., how to efﬁciently combine the separate
proofs. In particular, for all known 1-dimensional solutions, Step 2
entails creating the proof π as the concatenation of all proofs πRi
and the partial results Ri. This makes the proof size as large as the
sum of the partial result cardinalities, which can be substantially
larger than the ﬁnal result R. In turn, this may lead to a prohibitive
communication and veriﬁcation cost for the client.

π in Step 2, whose size is independent of(cid:80)
is efﬁcient, if it outputs proofs π of size o((cid:80)

A fundamental requirement of our framework is the partial proofs
πRi produced in Step 1 to be efﬁciently combinable to a short proof
i |Ri|. More formally:
EFFICIENCY REQUIREMENT. A AMR following our framework
i |Ri|).

Based on our observation above, any existing 1-dimensional so-
lution trivially conforms to our framework. However, no such solu-
tion satisﬁes the efﬁciency requirement. Essentially, the efﬁciency
requirement motivates the design of AMRs with non-trivial proof
combination techniques. What has prevented the research commu-
nity from devising such AMRs is the combination of the lack of
appropriate cryptographic tools, and the reduced need for range
queries over arbitrarily many dimensions, and large quantities of
data. However, the emergence of big data practices renders the
problem timely and important, whereas the recent introduction of
SOA techniques opens new directions towards efﬁcient solutions.
4.2 Construction

We ﬁrst outline the main idea of our scheme, and elaborate on
some important implementation decisions. Subsequently, we present
the instantiation of our algorithms.
Main idea. Recall that Step 2 of our framework dictates that the
result R is expressed as the intersection of sets Ri. We stress
that SOA techniques appear to solve our targeted problem trivially
as follows: The owner pre-computes a proof component πRi =
acc(Ri) for each Ri, where acc(Ri) is the accumulation value of
set Ri, and signs each πRi. According to our discussion in Sec-
tion 2, given all Ri, πRi, the server computes and sends to the client
a combined intersection proof π∩ for the integrity of R, along with
all πRi and their corresponding signatures. Observe that this ap-
proach satisﬁes our efﬁciency requirement. However, there exist
O(n2) possible Ri sets per dimension that can be involved in a
query, which makes the pre-processing cost for the owner and the
storage overhead for the server prohibitive. The main idea behind
our scheme is to express any possible Ri as the result of an oper-
ation over a ﬁxed number of “primitive sets,” given the constraint
that there are O(n) such “primitive sets.”

One possible way to derive Ri from “primitive sets” is illus-
trated in Figure 2(a). Let us focus on ai and the ordering of the
hash values hj (of tuples tj) according to the tj.ai values. We de-
ﬁne the preﬁx set Pi,j to consist of all hash values appearing in
positions 1, . . . , j in the ordering. In the ﬁgure, Pi,1 = {h3} and
Pi,2 = {h3, h1}. Similarly, we deﬁne sufﬁx set Si,j to consist of all
hash values appearing in positions n− j + 1, . . . , n in the ordering.
In our example, Si,1 = {h6} and Si,2 = {h5, h6}. Now assume
that k(cid:48)
i + 1, ki are the two positions in this ordering correspond-
ing to the ﬁrst and last tuple satisfying the query on ai. Observe

h1h3h4h7.....................h1h7h4h3h1h7h4h3.................................h7h3h1h4RiRja1amaiaj823i Ri =(cid:84)

= acc(Pi,ki ) and πS
i(Pi,ki ∩ Si,k(cid:48)i

that, in this case, Ri = Pi,ki ∩ Si,k(cid:48)i
+1, and, thus, there exist 2n
R =(cid:84)
“primitive sets” per dimension, i.e., all preﬁx and sufﬁx sets. Let
+1). Then, since
πPi,ki
+1) can be computed with a single
set intersection, we can utilize the SOA of [24] to create a proof
) for
π (consisting of π∩ and signatures on every πPi,ki
the integrity of R, while satisfying both efﬁciency and O(n) pre-
processing/storage.

= acc(Si,k(cid:48)i

, πS

i,k(cid:48)i

+1

i,k(cid:48)i

+1

(a)

(b)

Figure 2: Set representation of Ri

+1| ∈ Ω(n), along each attribute.

Unfortunately, from the complexity analysis of [24] in Section 2,
it follows that π∩ requires ˜O(d·n) time for each query at the server,
which makes this approach impractical. The reason is that the π∩
construction overhead is dictated by the cardinality of the input sets,
which is |Pi,ki| + |Si,k(cid:48)i
Motivated by the above, we propose an alternative solution which
we demonstrate using Figure 2(b). We deﬁne sets Ri through set-
the “primitive sets” are only the n preﬁx sets. Now R =(cid:84)
difference. In particular, using the notation of the previous para-
graph, it holds that Ri = Pi,ki \ Pi,k(cid:48)i
(cid:84)
. Consequently, in this case
i Ri =
i(Pi,ki \ Pi,k(cid:48)i
) is no longer expressed as a single set operation.
The only known SOA that can accommodate a circuit of set oper-
˜O(|Ri|), and π∩ with ˜O((cid:80)
ations is [8]. Brieﬂy stated, [8] allows the construction of πRi with
i |Ri|), exponentiations. The downside
is that its security relies on non-standard cryptographic assump-
tions. In Section 4.3, we construct our own sub-protocol for produc-
ing combinable proofs of set-difference, customized for the special
case where the ﬁrst participating set is a strict superset of the sec-
ond. This particular constraint enables our sub-protocol to prove
with ˜O(|Ri|) exponentiations,
the validity of Ri = Pi,ki \ Pi,k(cid:48)i
while being secure under a standard cryptographic assumption.
Our algorithms are comprised of a collection of set operation
sub-protocols, bundled with a set membership scheme. For clar-
ity of presentation, we will abstract the internal mechanics of these
sub-protocols, and instead use the following conventions:

• By SMA we refer to either a Merkle tree [19] or an accu-

mulation tree [22], along with all its algorithms.

• By ProveIntersection, VerifyIntersection, we refer to the
corresponding algorithms of the SOA of [24]. The former

computes an intersection proof on its input sets, and the lat-
ter veriﬁes this operation.

• By ProveSetDiﬀ, VerifySetDiﬀ, we refer to the correspond-
ing algorithms of our construction presented in Section 4.3.
The former generates a set-difference proof, and the latter
veriﬁes this operation.

This presentation choice also highlights that our algorithms use
elementary cryptographic tools as building blocks. Therefore, the
overall performance of our scheme is highly dependent on that of
the underlying tools, leaving potential for great improvement as
novel tool instantiations are introduced in the literature.
Key generation. It outputs key pair pk, sk, which are simply the
public and secret keys of the underlying SMA and SOA schemes,
generated by their corresponding key generation routines.
Setup. Figure 3 visualizes the detailed authentication structure pro-
duced by the setup algorithm, whose pseudo code is shown in the
next page. The owner computes the hash value h = H(t) for every
t ∈ T (Line 1). It then produces the sorted orderings of the hash
values along every attribute (Lines 2-3), and computes the preﬁx
sets Pi,j as explained in Figure 2(b). Next, it calculates preﬁx proof
πPi,j for each Pi,j (Lines 4-5). For each Pi,j, it computes a triplet
τPi,j = (vi,j, vv,j+1, πPi,j ) in Lines 6-7. Values vi,j, vi,j+1 indi-
cate the jth and (j + 1)th largest values on attribute ai appearing
in T . These values are necessary for guaranteeing the complete-
ness of the result, and their purpose will become clear soon. We
make the assumption that all triplets τ are distinct across attributes,
i.e., there does not exist τ that appears in more than one attributes.
This can be easily achieved in practice by including the attribute
index i in each τ, however for simplicity of presentation we avoid
it. Subsequently, it computes an SMAi over the triples τPi,j of
every attribute ai, producing digests δ1, . . . , δm (Line 8). It then
constructs a SMA over the (i, δi) pairs, and generates digest δ
(Line 9). Finally, it sends the m + 1 SMA structures to the server
along with T (Line 10), and publishes pk, δ (Line 11).

Figure 3: Our authentication structure

Proof construction. For ease of presentation and without loss of
generality, we assume that the requested query is upon the d ﬁrst
attributes of T and, hence, encode it as Q = {i, li, ui) for i =
1, ..., d. We provide the pseudo code of this algorithm below.

Given R, the server ﬁrst computes πR (Line 1), and calculates set
such that

Ri for each attribute ai. It identiﬁes preﬁxes Pi,ki , Pi,k(cid:48)i

h1h3h7h2h5h6Pi,1Pi,2Pi,kiSi,nSi,k′i+1Si,n−1...Ri...∩Pi,kiSi,k′i+1......Rk′i+1ki...Pi,k′iPi,kiRiPi,k′iPi,ki......R∩\h1h3h7h2h5h6Pi,1Pi,2......k′i+1ki...t1T...tnh1h1a1amPreﬁxh1=H(t1)P1,1P1,nPm,nPm,1......τP1,1τP1,nτPm,nτPm,1.........τPm,1=(vm,1,vm,2,πPm,1)πPm,1=acc(Pm,1)SMA1SMAmproofs(1,δ1)(m,δm)SMAδDigestsPublisheddigest...824Algorithm Setup(T, pk, sk)

Sort hj in ascending order along tj .ai
For j = 1, ..., n

1. For j = 1, ..., n, compute hj = H(tj )
2. For i = 1, ..., m
3.
4.
5.
Compute πPi,j = acc(Pi,j )
Let vi,j be the jth largest value on attribute ai in T
6.
7.
Construct triplet τPi,j = (vi,j , vi,j+1, πPi,j )
Build SMAi with digest δi over τPi,1 , ..., τPi,n
8.
9. Build SMA with digest δ over (1, δ1), ..., (m, δm)
10. Send T, auth(T ) = (SMA, SMA1, ..., SMAm) to the server
11. Publish pk, δ

Algorithm Prove(Q, R, pk, auth(T ))

1. Compute πR = acc(R)
2. For i = 1, ..., d
Compute Ri
3.
Identify Pi,k and locate τPi,k = (vi,ki , vi,ki+1, πPi,ki
4.
5.
Identify Pi,k(cid:48) and locate τPi,k(cid:48)
+1, πP
= (vi,k(cid:48)i
i,k(cid:48)i
Compute SMAi proofs for τPi,k , τPi,k(cid:48)
6.
Compute SMA proof for (i, δi)
7.
8.
πRi = ProveSetDiﬀ(Ri, pk)
9. π∩ = ProveIntersection(R, R1, ..., Rd, πR, πR1 , ..., πRd , pk)
i=1, all SMA proofs)
10. Set π = (πR, π∩, (πRi , τPi,k , τPi,k(cid:48)
11. Send π, R to the client

, vi,k(cid:48)i

, δi)d

)

)

i,k(cid:48)i

i,k(cid:48)i

, τP

, τP

Ri = Pi,ki \ Pi,k(cid:48)i
(as in Figure 2(b)), and locates the correspond-
(Lines 4-5). Subsequently, it constructs
ing triplets τPi,ki
(Line 6) and SMA proofs
the SMAi proofs for τPi,ki
for (i, δi), for i = 1, . . . , d (Line 7). It then invokes subroutines
ProveSetDiﬀ and ProveIntersection as deﬁned in our main idea
paragraph, and produces proofs πR1 , . . . , πRd and π∩ (Lines 8-9),
respectively. Finally, it puts together all proof components into a
single proof π (Line 10), and sends it to the client along with re-
sult R (Line 11). We thoroughly describe the functionality of every
proof component in π in the next paragraph.
Veriﬁcation. We visualize the intuition in Figure 4, where we de-
pict the authentication ﬂow among the various proof components of
the ﬁnal proof π sent to the client. Speciﬁcally, if a component au-
thenticates another, we draw an arrow from the former to the latter.
The corresponding arrow labels represent information serving as
“glue” between the components. The goal is to verify result R (top
of the ﬁgure), but the only trusted information (in addition to pk)
is δ (bottom of the ﬁgure). Veriﬁcation proceeds bottom-up from
level 0 to 5, maintaining the invariant that, at level (cid:96), the server
must have computed the components therein truthfully with respect
to T and Q.
At level 0, δ is signed/published by the owner and, thus, it is
trusted. At level 1, given the d SMA proofs and δ, we verify
the integrity of components (i, δi). Likewise, at level 2, given the
2d SMAi proofs along with (i, δ), we verify the integrity of 2d
triplets (τPi,ki
). Here, we reach a critical point in the veriﬁ-
cation process. We must prove that these particular (τPi,ki
)
i,k(cid:48)i
, such that Pi,ki \
correspond to the triplets for sets Pi,ki , Pi,k(cid:48)i
= Ri, where Ri is the truthful result of Q on dimension
Pi,k(cid:48)i
< li ≤
i=1 and check vi,k(cid:48)i
ai. To do this, we parse Q as (i, li, ui)d
+1 and vi,ki ≤ ui < vi,ki+1, where vi,ki , vi,ki+1, vi,k(cid:48)i
vi,k(cid:48)i
, vi,k(cid:48)i
. This guarantees that Pi,ki is the
are included in τPi,ki

, τP

, τP

, τP

i,k(cid:48)i

i,k(cid:48)i

+1

Figure 4: Authentication ﬂow

i,k(cid:48)i

i,k(cid:48)i

, τP

, τP

, πP

from (τPi,ki

) indeed correspond to the correct Pi,ki , Pi,k(cid:48)i

that πR is the accumulation value of(cid:84)

smallest preﬁx set that contains the entire Ri, and Pi,k(cid:48)i
is the largest
preﬁx set that does not intersect Ri. Therefore, we verify that
. Next,
(τPi,ki
), respectively, and
we retrieve πPi,ki
run routine VerifySetDiﬀ to validate the truthfulness of πRi as the
accumulation value of set Ri at level 3. Next, at level 4 we verify
i Ri with VerifyIntersection,
using πR, all πRi, and π∩. Observe that, at this point we know that
πR corresponds to the accumulation of the correct result of Q on T .
At the last level 5, we verify that R is indeed this correct result by
checking if acc(R) = πR. We summarize this veriﬁcation process
in the pseudocode below.

i,k(cid:48)i

Algorithm Verify(Q, R, π, pk, δ)

i=1

Verify δi with respect to δ with SMA proof
Verify τPi,k , τPi,k(cid:48)
Verify vi,k(cid:48)i
Run VerifySetDiﬀ(πPi,k , πPi,k(cid:48)

1. Parse Q as (i, li, ui)d
2. For i = 1, ..., d
3.
4.
5.
6.
7. Run VerifyIntersection(πR, πR1 , ..., πRd , π∩, pk)
8. Compute acc(R) and verify acc(R) = πR
9. If veriﬁcation in Lines 3-8 fails, return reject, else return accept

with respect to δi with SMAi proofs
+1 and vi,ki ≤ ui < vi,ki+1

< li ≤ vi,k(cid:48)i

, πRi , pk)

Updates. We focus on an insertion of a single tuple t (the case of
deletions is similar). The process is easier to follow by revisiting
Figure 3. The owner ﬁrst computes h = H(t). It then inserts h
in the appropriate position in the ordering of each attribute ai, and
properly updates all the preﬁx sets it affects. Note that, if h is placed
in position j for attribute ai, the owner must change sets Pi,j(cid:48) for
all j(cid:48) ≥ j, and modify their corresponding proofs πPi,j(cid:48)
in τPi,j(cid:48)
.
Furthermore, it must create a new τPi,j , and alter vi,j in τPi,j−1
(where it appears as the second element). Finally, it must propagate
the changes of all τ triplets in all SMAi and SMA. Admittedly,
the update process in this basic scheme can be quite expensive; in
fact, it can be as costly as re-running the setup stage. In the Sec-
tion 5, we introduce a solution that supports efﬁcient updates, while
maintaining all other asymptotic costs.
Complexity analysis. Table 1 in Section 1 summarizes our com-
plexities. We will analyze our schemes considering SMAs [19,
22]. The setup cost is O(|T| log n) regardless of the underlying
SMA, as it is dominated by m sorts of n hashes, and O(mn) pre-
ﬁx proof computations. The proof size is O(d log n) if Merkle-trees
are used as SMAs, and O(d) in the case of accumulation trees;

(τP1,k1,τP1,k′1)(1,δ1)(d,δd)δSMAdproof...SMA1proof(τPd,kd,τPd,k′d)(1,l1,u1)(d,ld,ud)πR1πRdπ∩RπR......Level0Level1Level2Level3Level4Level5SMAproof1π∩SMAproofd825tively. Proof construction entails ˜O((cid:80)d

the proof is comprised of O(d) preﬁx proofs, and d SMA proofs
each with size O(log n) and O(1) for the two alternatives, respec-
i=1 |Ri|) cost for computing
Wi, Fi encompassed in proof π∩, and O(d log n) / O(dn log n)
SMA overhead for [19] / [22], respectively. Veriﬁcation involves
˜O(|R|) time for verifying π∩, and O(d log n) / O(d) for validat-
ing the SMA proofs. Finally, update is dominated by the re-
computation of the O(mn) preﬁx proofs and, thus, it can be done
in time O(|T|).
Correctness, efﬁciency, security. The correctness of our scheme
results from the semantics of the proof generation and veriﬁcation
as thoroughly explained above. Moreover, since the proof size is
either O(d) or O(d log n), our construction satisﬁes the efﬁciency
requirement. Finally, the next theorem states the security of the
basic scheme. The proof is included in the Appendix.

THEOREM 1. Our basic scheme is secure under q-SBDH and the
security of the employed SMA.
4.3 A Set-Difference Sub-protocol

We present a sub-protocol for proving the correctness of a set-
difference operation between two sets X1, X2, under the constraint
that the ﬁrst is a proper superset of the second. This constraint
renders our sub-protocol conceptually simple and very efﬁcient. It
consists of two routines ProveSetDiﬀ and VerifySetDiﬀ. The for-
mer takes as input set X1 \ X2 and outputs a proof for its validity
as the set-difference of X1, X2. The latter receives succinct rep-
resentations πX1 , πX2 , πX1\X2 of X1, X2, X1 \ X2, respectively,
and returns accept if X1 \ X2 is the set-difference of X1, X2, and
reject otherwise. Below is the pseudo codes of the two routines.

Algorithm ProveSetDiﬀ(X1 \ X2, pk)
1. Return π\ = acc(X1 \ X2)
Algorithm VerifySetDiﬀ(πX1 , πX2 , π\, pk)
1. If e(πX2 , π\) = e(πX1 , g), return accept, else return reject

Note that these routines are meaningful only as part of a more
elaborate SOA scheme (e.g., [24, 8]), which utilizes bilinear ac-
cumulators as well, and relies on the same public key pk. More
speciﬁcally, the caller SOA is enforced with the computation of
input X1 \ X2 to ProveSetDiﬀ. Therefore, this routine simply re-
turns π\ as the accumulation value of X1\X2 in time ˜O(|X1\X2|).
In addition, the SOA must ﬁrst check that inputs πX1 , πX2 of
VerifySetDiﬀ are the accumulation values of X1, X2, such that X1
is a proper superset of X2, prior to calling the routine. In this case,
the cost of VerifySetDiﬀ is O(1) pairings.

For example, in our scheme in Section 4.2, ProveSetDiﬀ is called
in algorithm Prove for each set Ri, after Ri has been computed.
Moreover, VerifySetDiﬀ is invoked in Verify using as inputs the
already veriﬁed accumulation values of preﬁx sets Pi,ki , Pi,k(cid:48)i
that,
by deﬁnition, satisfy the constraint Pi,ki ⊃ Pi,k(cid:48)i
. The following
lemma is useful in our proofs included in the Appendix.
LEMMA 3. Let λ be a security parameter, pub ← BilGen(1λ),
) ∈ G, computed for some s chosen at
and elements (g, gs, ..., gsq
random from Z∗
p. Let X1, X2 be sets with elements in Zp, such that
X1 ⊃ X2. For an element y ∈ G, it holds that y = acc(X1 \ X2),
iff e(acc(X2), y) = e(acc(X1), g).

5. UPDATE-EFFICIENT SCHEME

Section 5.1 presents an update-efﬁcient construction that builds
upon the basic scheme of the previous section. Section 5.2 includes
a set union sub-protocol that is used as part of our construction.
5.1 Construction

Similar to our basic solution, the update-efﬁcient scheme views
the query result as a combination of “primitive set” operations. It
then allows the server to compute a small set of proof elements,
which can be aggregated by the client in a bottom-up fashion (sim-
ilar to Figure 4). It adopts the same idea of computing proofs for
the partial Ri results along each dimension ai, and then combin-
ing them through a set intersection protocol into a single proof that
veriﬁes the ﬁnal result R.
It also adopts the idea of performing
set-difference operations over preﬁx sets. The primary difference
with the basic scheme is that we now organize the hash values in
the ordering of each dimension into buckets, and compute preﬁx
sets over both the buckets, as well as the hashes in each bucket.
As we shall see, this twist isolates the effect of an update, thus, re-
ducing the update cost complexity. However, it also mandates the
modiﬁcation of the overall authentication structure, proof genera-
tion and veriﬁcation processes, and creates the need for a new set
union sub-protocol (presented in Section 5.2). In the following, we
only describe the main ideas behind the construction, omitting the
tedious algorithmic details.

Figure 5 depicts the authentication structure created by the owner
during the setup stage, focusing on attribute ai. As before, the
owner sorts the hash values of the n tuples of T in ascending or-
der of the ai values of the tuples. It then creates b buckets, enu-
merated as Bi,1, . . . , Bi,b (bottom left in the ﬁgure). For clarity of
presentation, we assume that the partitioning of hashes into buckets
is publicly known (e.g., each bucket may correspond to a speciﬁc
range of the domain of ai), and that each bucket has n/b hashes.

Figure 5: Authentication structure for efﬁcient updates
We deﬁne as Pi,j the preﬁx set over buckets Bi,1, . . . , Bi,j, i.e.,
the set of hashes included in Bi,1, . . . , Bi,j (we use calligraphic P
for bucket preﬁxes to distinguish them from hash preﬁxes denoted
by P ). The owner computes a proof πPi,j = acc(Pi,j) for every
Pi,j. In addition, for every bucket Bi,j, it computes preﬁxes Pi,j,l
for the hashes therein (bottom right in the ﬁgure), as well as proofs
πPi,j,l = acc(Pi,j,l). Subsequently, the owner creates a triplet
(i, j, πPi,j ) for every Pi,j, as well as tuple τPi,j,l for every Pi,j,l.
Note that τPi,j,l is similar to the case of the basic scheme (i.e., it

h1h1Bi,1Pi,1,1Pi,1,n/b...h2SMA′iδ′iSMAδ...Bi,bPi,1Pi,b(i,1,πPi,1)(i,b,πPi,b)...Pi,b,1Pi,b,n/bh2τPi,1,1τPi,1,n/bτPi,b,n/bτPi,b,1SMAi,1SMAi,bδi,1δi,bSMAiδi...............ai...BucketBi,1BucketBi,b826encompasses πPi,j,l along with two ai values), but now also in-
corporates the index j of the bucket. The owner feeds (i, j, πPi,j )
to the leaf level of SMA(cid:48)
i with digest δ(cid:48)
i. It also feeds τPi,j,l to
SMAi,j with digest δi,j.
It then superimposes another SMAi
over digests δi,j which has digest δi. Finally, it builds SMA over
i, δi with ﬁnal digest δ that is published. The various SMAs
all δ(cid:48)
will later allow the server to construct proofs validating that πPi,j ,
πPi,j,l were indeed computed by the owner speciﬁcally for bucket
Bi,j; this is conceptually similar to their usage in the basic scheme.
We explain the proof construction and veriﬁcation process using
Figure 6, focusing on Ri. In our example, Ri fully covers buckets
Bi,κ(cid:48)+1, . . . , Bi,κ, and partially covers buckets Bi,κ(cid:48) and Bi,k+1.
Observe that we can decompose Ri into three sets, let 1(cid:13), 2(cid:13), 3(cid:13)
(so that we alleviate our notation and allow an easy reference to the
ﬁgure), such that Ri = 1(cid:13) ∪ 2(cid:13) ∪ 3(cid:13) and 1(cid:13), 2(cid:13), 3(cid:13) are pairwise
disjoint (the importance of the latter property will become clear
in Section 5.2). Observe also that 1(cid:13) = Pi,κ(cid:48),k \ Pi,κ(cid:48),k(cid:48), 2(cid:13) =
Pi,κ \ Pi,κ(cid:48), and 3(cid:13) = Pi,κ(cid:48)+1,k. Therefore, the server builds the
, πPi,κ,
proof π by including proof components πPi,κ(cid:48),k, πPi,κ(cid:48),k(cid:48)
, πPi,κ(cid:48)+1,k. Moreover, it includes (i, j, πPi,j ), τPi,j,l, their
πPi,κ(cid:48)
proper proofs from SMA(cid:48)
i,SMAi,j,SMAi,SMA, as well as
π 1(cid:13) = acc( 1(cid:13)), π 2(cid:13) = acc( 2(cid:13)), π 3(cid:13)=acc( 3(cid:13)). With all the above,
the client can verify that π 1(cid:13), π 2(cid:13), π 3(cid:13) are the truthful proofs for
sets 1(cid:13), 2(cid:13), 3(cid:13).
The client next needs to combine π 1(cid:13), π 2(cid:13), π 3(cid:13) in order to ver-
ify that proof πRi = acc(Ri), also included in the ﬁnal π by the
server, indeed corresponds to the Ri that is the union of 1(cid:13), 2(cid:13),
3(cid:13). After that point, the client can proceed to prove the ﬁnal re-
sult R in an identical way to the basic scheme. For this particular
task, we utilize our own customized set union sub-protocol, which
is included in Section 5.2. This sub-protocol is motivated by sim-
ilar reasons that motivated our set-difference sub-protocol in Sec-
tion 4.3; we need it to be executed in time ˜O(|Ri|), and be secure
under standard cryptographic assumptions. What enables us to do
this is the extra constraint that the participant sets must be a priori
proven pairwise disjoint. At a high level, its ProveUnion routine
outputs a proof π∪ on input sets 1(cid:13), 2(cid:13), 3(cid:13), which later facilitates
the VerifyUnion routine invoked on π 1(cid:13), π 2(cid:13), π 3(cid:13), πRi.

Figure 6: Representation of Ri through sets

√

Consider that tuple t is inserted in bucket Bi,j (deletions are han-
dled similarly). This insertion affects all b bucket preﬁxes in the
worst case, and all n/b hash preﬁxes in Bi,j. It is important to ob-
serve that t does not affect any hash preﬁx of any other bucket; in
√
that sense, the buckets isolate the effect of the update within their
n · m)
boundaries. Setting b =
preﬁxes in overall, each with a single exponentiation. Moreover,
it should propagate the changes of the corresponding proofs inside
the SMA structures, whose cost is asymptotically the same as in
√
the case of the basic scheme. Therefore, the total update time in this
construction reduces from O(n·m) to O(
n·m). Interestingly, the
asymptotic complexities of all other algorithms and the proof size
remain unaffected. However, the absolute costs slightly increase

n, the owner must update O(

due to the extra bucket preﬁxes, as conﬁrmed by our experiments
in Section 6. Due to space limitations, we delegate the security and
correctness proofs, as well as the detailed algorithm descriptions
and complexity analysis to the long version of our work.
5.2 A Set Union Sub-protocol

We present a sub-protocol for proving the correctness of a union
operation among a number of sets Xi under the constraint that they
are pairwise disjoint. We focus on the case of three input sets, as
this is the way it is utilized in Section 5. The sub-protocol consists
of two routines, ProveUnion and VerifyUnion. The former receives
sets X1, X2, X3, and outputs a proof π∪ for the integrity of the
union operation X = X1 ∪ X2 ∪ X3. The latter receives succinct
descriptions πX1 , πX2 , πX3 , πX of X1, X2, X3, X, respectively,
as well as a proof π∪, and returns accept if X is the union of the
three sets, and reject otherwise. We provide the pseudo codes of
the two routines below.

Algorithm ProveUnion(X1, X2, X3, pk)
1. Output π∪ = acc(X1 ∪ X2)
Algorithm VerifyUnion(πX1 , πX2 , πX3 , πX , π∪, pk)
1. Verify e(πX1 , πX2 ) = e(π∪, g)
2. Verify e(π∪, πX3 ) = e(πX , g)
3. If veriﬁcation in Lines 1-2 fails, return reject, else return accept

Similar to the set-difference sub-protocol, these routines are mean-
ingful only as part of a SOA scheme based on bilinear accumu-
lators. ProveUnion runs in time ˜O(|X1| + |X2| + |X3|). For
VerifyUnion, it is the responsibility of the caller to check that πX1,
πX2, πX3 are the accumulation values of pairwise disjoint X1, X2,
and X3, prior to calling the routine. Its cost is O(1) pairings.
6. EXPERIMENTS

We performed our experiments on a 64-bit machine with Intel
Core i5 CPU 2.5GHz, running Linux. We measured the perfor-
mance of all schemes implementing the necessary cryptographic
primitives in C++, using the following libraries: DCLXVI [2] for
fast bilinear pairing computations, Flint [3] for modular arithmetic,
and Crypto++ [1] for SHA-256 hash operations. DCLXVI employs
a 256-bit BN elliptic curve and an asymmetric optimal ate pairing,
offering bit-level security of 128 bits. We represent elements of G1
with 768 bits using Jacobi coefﬁcients, which yield faster opera-
tions. Elements in G2 are roughly twice as large as those of G1.
We chose an asymmetric pairing for efﬁciency reasons, but we note
that this choice does not introduce any redundancy to our schemes
as presented with symmetric pairings. We instantiate all SMAs
with Merkle trees [19] and bilinear accumulator trees [22]. Table 2
summarizes all primitive costs involved in our schemes.

Operation
Exp. in G1 / G2
Mult. in Zp / GT
SHA-256 / Bilinear pairing
Quicksort in Zp
Acc. in G1
Acc. in G2
Polynom. Mult in Zp[r]
XGCD in Zp[r]

Cost

0.55 / 0.94 ms
7 µs / 0.09 ms
5 µs / 1.41 ms
0.1 / 0.9 / 4.6 ms

25.3 / 236 / 2, 628 ms
32.6 / 338 / 3, 471 ms

0.4 / 7.3 / 92.9 ms

8.4 / 599 / 108, 093 ms

(100/1000/10000 elems.)

(100/1000/10000 coeffs.)

–(cid:113)–
–(cid:113)–
–(cid:113)–

Table 2: Costs of primitive operations

We test four possible conﬁgurations: (i) our basic scheme with
Merkle trees (Basic-Mer), (ii) our basic scheme with accumula-
tor trees (Basic-Acc), (iii) our update-efﬁcient scheme with Merkle

h3Bi,κ′Bi,κ+1...Bi,κ′+1Pi,κ′Pi,κ......h4h5h6......Bi,κPi,κ′,k′Pi,κ′,kPi,κ′+1,kRi1!2!3!827trees (UpdEﬀ-Mer), and (iv) our update-efﬁcient scheme with ac-
cumulator trees (UpdEﬀ-Acc). For each conﬁguration, we assess
the performance at the client, owner and server, varying several pa-
rameters. We run each experiment 10 times and report the average
costs. Note that the performance of all schemes does not depend on
the data distribution, but rather on the table schema and the result
selectivities, hence we chose to use synthetic data in our evalua-
tion. We stress that our goal here is not to construct an optimized
prototype, but rather to demonstrate the feasibility of our schemes.
As such, we have left numerous optimizations regarding database
storage and query handling as future work.

Client. Figure 7 depicts the veriﬁcation cost at the client. This
overhead is mainly affected by the result size |R| and the number
of query dimensions d. Figure 7(a) shows the CPU time (in ms)
as a function of |R|, ﬁxing d = 32, n = 106 and m = 64. The
veriﬁcation cost increases with |R| in all schemes. Basic-Mer is
the fastest for |R| ≤ 1, 000. This is because the Merkle-based
schemes are faster than the accumulator-based ones, as they entail
hash operations for the SMA proofs, which are much cheaper than
the pairings needed in accumulation trees. Moreover, the overhead
in the update-efﬁcient schemes is slightly larger than that in their
basic counterparts, due to the extra proof veriﬁcations of the bucket
preﬁxes and the taller SMA hierarchy. Nevertheless, observe that,
for |R| = 10, 000 the performance of all schemes converges. The
reason is that the computation of πR = acc(R) that is common to
all techniques becomes the dominant factor, which effectively hides
the costs of the SMA proofs and all set-operation veriﬁcations.
Figure 7(b) illustrates the CPU time versus d, when |R| = 1, 000,
n = 106 and m = 64. The performance of the schemes is qual-
itatively similar to Figure 7(a) for the same reasons. Once again,
all costs increase linearly with d because the veriﬁcation overhead
of the set-differences and intersections is also linear in d. However,
the effect of d on the total CPU time is not as signiﬁcant as that
of |R|, since the common accumulation cost for R emerges as the
dominant cost when |R| = 1, 000. In both ﬁgures, the veriﬁcation
time for all constructions is between 20 ms and 3.36 seconds.

(a) Time vs. |R|

(b) Time vs. d

Figure 7: Veriﬁcation overhead at client

Table 3 includes the proof sizes for the four schemes when vary-
ing d. We make three observations. First, all sizes increase with d,
since the proof includes components for every dimension. Second,
the basic schemes have smaller proofs than their counterparts, again
because of the extra bucket preﬁx proofs and taller SMA hierar-
chy. Third, although Basic-Acc outperforms Basic-Mer , this is not
true for UpdEﬀ-Acc and UpdEﬀ-Mer. This is because, although
accumulators provide asymptotically smaller proofs than Merkle
trees, this does not hold in practice for the database sizes we tested.
Overall, the proofs for all schemes are quite succinct, ranging from
4.5 to 153.5 KBs, which are independent of the result size that
could easily be in the order of MBs.

d

Basic-Mer
Basic-Acc
UpdEﬀ-Mer
UpdEﬀ-Acc

2
4.5
3.6
9.2
9.6

4
9.1
7.2
18.4
19.2

8
18.1
14.3
36.9
38.4

16
36.3
28.8
73.8
76.8

32
72.5
57.5
147.5
153.5

Table 3: Proof size in KB (n = 106, m = 64)

Owner. Figure 8 assesses the performance of the owner for the
setup stage (which includes the key generation), and updates. In this
set of experiments, we focus only on the Merkle-based schemes that
have a clear performance advantage over the accumulator-based, as
evident also from our evaluation for the client above. Figure 8(a)
plots the pre-processing cost when varying n and ﬁxing m = 64.
Naturally, the overhead increases linearly with n in both schemes.
This overhead is dominated by the computation of πPi,j for all i, j,
which completely hides the sorting and hashing costs (see also Ta-
ble 2). As expected, UpdEﬀ-Mer is more than twice as slow as
Basic-Mer. Although the pre-processing time can reach up to three
hours for n = 106, recall that this is a one-time cost for the owner.

(a) Setup time vs. n

(b) Update time vs. # updates

Figure 8: Setup and update overhead at owner

is (cid:80)d

Figure 8(b) evaluates the update time as a function of the number
of updates performed in a single batch operation, where n = 105
and m = 64. Note that we report the respective worst case in both
schemes. For Basic-Mer, the CPU time is practically unaltered and,
in fact, is as bad as the setup overhead. On the contrary, UpdEﬀ-
Mer is greatly beneﬁted by the bucket isolation and becomes up to
more than two orders of magnitude more efﬁcient than Basic-Mer.
As the number of updates in the batch increase, the performance
gap between the two schemes closes, since the updates in the batch
are likely to affect more buckets. For the tested settings, the update
time ranges between 30 seconds and one hour.
Server. Figure 9 reports the proof generation time at the server.
As explained in our complexity analysis, the dominant factor here
i=1 |Ri|. Therefore, due to the lack of real-world data and
query workloads, it sufﬁces to vary |Ri| and ﬁx it across all dimen-
sions, rather than varying d and setting an arbitrary partial result
size per dimension. Figure 9 depicts the CPU time at the server,
when varying |Ri| and setting n = 105, m = 64, d = 32 and
|R| = 0.1·|Ri| (i.e., 10% of a 1-dimensional result). At every point
of the curve, we also provide the percentages of the three dominant
computational costs, namely the construction of Wi, Fi (for the in-
tersection proof) and πRi. The performances of two schemes differ
marginally. This is because the generation of the extra set union
proof of UpdEﬀ-Mer incurs negligible cost compared to the large
burden of computing the three types of elements mentioned above.
The most interesting observation is that, for |Ri| = 10, the cost
for Wi is 51% and for Fi is 15%, whereas for |Ri| = 10, 000,
the two costs become 7% and 87%, respectively. This is because
computing Fi requires running the Extended Euclidean (XGCD)

102103104101102103104Time (ms)|R|Basic-MerBasic-AccUpdEff-MerUpdEff-Acc1021032481632Time (ms)dBasic-MerBasic-AccUpdEff-MerUpdEff-Acc100101102103104105102103104105106Time (sec)nBasic-MerUpdEff-Mer1011021031041255075100Time (sec)# updatesBasic-MerUpdEff-Mer828algorithm, whose time increases drastically with the degree of the
polynomials (as shown in Table 2), dictated by |Ri|. The server’s
total overhead ranges between 650 ms and 25 minutes.

[4] N. Beckmann, H.-P. Kriegel, R. Schneider, and B. Seeger.

The R*-tree: An efﬁcient and robust access method for
points and rectangles. In SIGMOD, 1990.

[5] D. Boneh and X. Boyen. Short signatures without random

oracles and the SDH assumption in bilinear groups. J.
Cryptology, 21(2):149–177, 2008.

[6] D. Boneh, A. Sahai, and B. Waters. Functional encryption:

Deﬁnitions and challenges. In TCC, 2011.

[7] P. G. Brown. Overview of SciDB: Large scale array storage,

processing and analysis. In SIGMOD, 2010.
[8] R. Canetti, O. Paneth, D. Papadopoulos, and

N. Triandopoulos. Veriﬁable set operations over outsourced
databases. In PKC, 2014.

Figure 9: Proof construction cost at server

Summary and future improvements. Our experimental evalua-
tion conﬁrms the feasibility of our schemes. Speciﬁcally, it demon-
strates that the veriﬁcation cost at the client in all schemes is in
the order of a few seconds in the worst case, even for moderate re-
sult sizes, whereas the proof size is up to a few hundred of KBs. At
the owner, we illustrated the beneﬁts of our update-efﬁcient scheme
over the basic one in terms of updates, which come at the cost of
a more expensive setup and client veriﬁcation. Finally, the server
is the most impacted party in our constructions. The proof gener-
ation cost takes from several ms to several minutes, for small and
moderate partial result sizes and dimensionality.

Nevertheless, it is important to stress that the deﬁning costs at the
server account for exponentiations and modular polynomial arith-
metic. These operations are at the core of numerous applications
and, thus, there is huge potential for improvement in the near fu-
ture. In addition, there are works (e.g., [13]) that have substantially
boosted such operations with modern hardware, which we did not
possess in our experimentation. Being instantiations of a general
framework, our schemes feature the attractive property that are eas-
ily upgradeable with future advances in such cryptographic tools.

7. CONCLUSION

We proposed schemes for authenticated multi-dimensional range
queries over outsourced databases. Contrary to existing literature,
our solutions scale linearly with the number of dimensions, and can
support queries on any set of dimensions with linear in the number
of database attributes setup cost and storage. The central idea of
our methods is the reduction of the multi-dimensional range query
to set-operations over appropriately deﬁned sets in the database. We
provided a detailed asymptotic and empirical performance evalua-
tion, which conﬁrms the feasibility of our schemes in practice.

Acknowledgments
We thank all the anonymous reviewers for their detailed comments
and suggestions. Research supported in part by NSF grants CNS-
1012798 and CNS-1012910.

8. REFERENCES
[1] The Crypto++ Library. http://www.cryptopp.com/.
[2] The DCLXVI Library.

http://cryptojedi.org/crypto/.

[3] The Flint Library. http://www.flintlib.org/.

[9] H. Chen, X. Ma, W. Hsu, N. Li, and Q. Wang. Access control
friendly query veriﬁcation for outsourced data publishing. In
ESORICS, 2008.

[10] W. Cheng and K.-L. Tan. Query assurance veriﬁcation for

outsourced multi-dimensional databases. J. Computer
Security, 17(1):101–126, 2009.

[11] K.-M. Chung, Y. T. Kalai, F.-H. Liu, and R. Raz. Memory

Delegation. In CRYPTO, 2011.

[12] J. Dean and S. Ghemawat. MapReduce: Simpliﬁed data

processing on large clusters. Commun. ACM, 51(1):107–113,
Jan. 2008.

[13] P. Emeliyanenko. High-performance polynomial GCD
computations on graphics processors. In HPCS, 2011.
[14] M. T. Goodrich, R. Tamassia, and N. Triandopoulos.

Super-efﬁcient veriﬁcation of dynamic outsourced databases.
In CT-RSA, 2008.

[15] M. T. Goodrich, R. Tamassia, and N. Triandopoulos.

Efﬁcient authenticated data structures for graph connectivity
and geometric search problems. Algorithmica,
60(3):505–552, 2011.

[16] H. Hacigümüs, S. Mehrotra, and B. R. Iyer. Providing

database as a service. In ICDE, 2002.

[17] F. Li, M. Hadjieleftheriou, G. Kollios, and L. Reyzin.
Dynamic authenticated index structures for outsourced
databases. In SIGMOD, 2006.

[18] C. Martel, G. Nuckolls, P. Devanbu, M. Gertz, A. Kwong,
and S. G. Stubblebine. A general model for authenticated
data structures. Algorithmica, 39(1):21–41, Jan. 2004.

[19] R. C. Merkle. A certiﬁed digital signature. In CRYPTO, 1989.
[20] E. Mykletun, M. Narasimha, and G. Tsudik. Authentication
and integrity in outsourced databases. TOS, 2(2):107–138,
2006.

[21] L. Nguyen. Accumulators from bilinear pairings and

applications. In CT-RSA, 2005.

[22] C. Papamanthou, R. Tamassia, and N. Triandopoulos.

Authenticated hash tables. In CCS, 2008.

[23] C. Papamanthou, R. Tamassia, and N. Triandopoulos.

Cryptographic accumulators for authenticated hash tables.
IACR Cryptology ePrint Archive, 2009:625, 2009.

[24] C. Papamanthou, R. Tamassia, and N. Triandopoulos.
Optimal veriﬁcation of operations on dynamic sets. In
CRYPTO, 2011.

[25] B. Parno, J. Howell, C. Gentry, and M. Raykova. Pinocchio:
Nearly Practical Veriﬁable Computation. In IEEE Symposium
on Security and Privacy, 2013.

[26] R. Tamassia. Authenticated data structures. In ESA, 2003.

10-1100101102103101102103104Time (sec)|Ri|Wi = 51%Fi = 15%πRi = 34%Wi = 34%Fi = 40%πRi = 26%Wi = 31%Fi = 44%πRi = 25%Wi = 7%Fi = 87%πRi = 6%Basic-MerUpdEff-Mer829[27] J. Xu. Authenticating aggregate range queries over dynamic
multidimensional dataset. IACR Cryptology ePrint Archive,
2010:244, 2010.

[28] Y. Yang, S. Papadopoulos, D. Papadias, and G. Kollios.
Authenticated indexing for outsourced spatial databases.
VLDB J., 18(3):631–648, 2009.

APPENDIX
Proof of Lemma 3
(⇒) Let X1 = {x1, ..., xl(cid:48)} and X2 = {x1, ..., xl} for l, l(cid:48) ∈ N
with l < l(cid:48).
(cid:81)l(cid:48)
If e(acc(X2), y) = e(acc(X1), g), then we have
i=1(xi+s), g). Hence, it holds e(y, g) =
e(g
= e(acc(X1 \ X2), g) and it follows that y =

i=1(xi+s), y) = e(g
i=l+1(xi+s), g)

(cid:81)l
(cid:81)l(cid:48)

def

e(g
acc(X1 \ X2).
(⇐) If y = acc(X1 \ X2) = g
e(g

i=1(xi+s), y) = e(g
i=1(xi+s), g) = e(acc(X1), g).

(cid:81)l
(cid:81)l(cid:48)

(cid:81)l

(cid:81)l(cid:48)

e(g

i=1(xi+s), g

i=l+1(xi+s), then it holds that

(cid:81)l(cid:48)

i=l+1(xi+s)) =

(cid:4)

Proof of Theorem 1
Let us assume there exists PPT adversary A that wins the AMR
security game with non-negligible probability. Also, let Q, R∗, π∗, j
be the cheating tuple output by A and let T denote the data struc-
ture’s state at index j, and auth(T ), δ the corresponding authenti-
cation information and digest . In the following, we annotate by ∗
any element of π∗. Moreover, if an event is denoted by E, then its
complement is denoted by E(cid:48). Consider the following events:
E1: A wins the AMR game.
E2: π∗ contains a tuple τ∗ or (i, δi)∗ /∈ auth(T ).
Recall that auth(T ) consists of m + 1 SMA structures; each of
the m ﬁrst is built over n tuples τ containing sequential values and
preﬁx accumulations for attribute ai, and the last is built over m
pairs of the form (i, δi), i.e., containing the attribute index and
corresponding digest. Note that, in the AMR game the values
auth(T ), d are computed correctly by the challenger for T .

By the law of total probability, we have:

Pr[E1] = Pr[E2] Pr[E1|E2] + Pr[E(cid:48)
2] .

≤ Pr[E1|E2]] + Pr[E1|E(cid:48)

2] Pr[E1|E(cid:48)
2]

Intuitively, the ﬁrst term in the right hand of the above relation cor-
responds to an adversary that wins by breaking the security of the
underlying SMA and the second term with breaking the q-SBDH.
CLAIM 1. Pr[E1|E2] is negligible in λ.
Proof. Let us assume it is non-negligible in λ. Without loss of
generality, we will assume that the non-existing tuple is of the form
τ∗, i.e., it should fall under some of the ﬁrst m SMA structures,
e.g., SMAi. Since A wins, it follows that the AMR veriﬁcation
succeeds however τ∗ (cid:54)∈ SMAi. We now distinguish between the
chosen SMA instantiation:

• Merkle tree. We will construct adversary A(cid:48) that ﬁnds a col-
lision in the CRHF H used to implement the Merkle tree as
follows. A(cid:48) runs BilGen(1λ) to compute bilinear parameters
pub, chooses s ←R Z∗
p and q ∈ poly(λ) and computes values
gs, . . . , gsq . Finally, he runs A on input (pub, gs, . . . , gsq
).

He then proceeds to provide oracle access for all the AMR
algorithms. For the necessary computations of H (as part of
the Merkle tree construction and veriﬁcation) he queries his
CRHF challenger. After the setup and each update call from
A, database Tη for η = 0, . . . , j is produced and A(cid:48) stores
all triplets (Tη, auth(Tη), δη). When A outputs his chal-
lenge tuple for index j, A(cid:48) parses π∗, checking for each tuple
whether it appears in auth(Tj). If any of them does not ap-
pear in auth(Tj), there must exist triplet τ in the correspond-
ing SMA ∈ auth(Tj) such that τ (cid:54)= τ∗ and H(τ ) = H(τ∗)
(for the challenge sample key of H). This holds since the ver-
iﬁcation process for τ∗ under a Merkle tree in auth(Tj) suc-
ceeds, yet τ∗ is not in the tree. By assumption this will happen
with non-negligible probability, hence A(cid:48) breaks the collision
resistance of H, and the claim follows.

• Accumulation tree. The reduction proceeds in the same man-
ner is in the previous case. The difference is that A(cid:48) is now
playing against an accumulation tree challenger, he receives
as input a public key that coincides perfectly with the AMR
game and he does not need to issue any queries to his chal-
lenger before he sees the challenge tuple by A, since every-
thing can be computed with access to the public key only (this
follows from the properties of the bilinear accumulator used
to build the tree). After A issues his challenge, A(cid:48) constructs
the tree SMAi by issuing consecutive update queries to his
challenger. Finally, he outputs τ∗ and the part of π∗ that cor-
responds to proving (the false statement) that τ∗ ∈ SMAi.
By Lemma 1 this can only happen with negligible probabil-
ity, which contradicts our original assumption, and the claim
follows.

i,l, v∗

Now we prove that the second term of the inequality, namely
Pr[E1|E(cid:48)
2], is negligible, by contradiction. Assume that Pr[E1|E(cid:48)
2]
is non-negligible. Since E2 does not happen, all triplets τ∗ and pairs
(1, δ1), . . . , (m, δm) in π∗ appear in auth(T ).

This immediately implies that the two values v∗

i,l+1 in each
triplet are consecutive along their dimension and each digest matches
its corresponding dimension. By construction, along each dimen-
sion there exist exactly two distinct τ∗, τ(cid:48)∗ for which veriﬁcation of
Q succeeds; one corresponds to the lower bound of the 1-dimensional
range of the query (li) and one for the upper (ui). Furthermore, if
a triplet correctly formed for SMA∗
i of attribute ai, is used as part
of the proof of an SMA∗
j corresponding to aj (cid:54)= ai, then it can be
used to break the SMA security as shown in the proof of Claim 1,
which can only happen with negligible probability.
i,i(cid:48) ∈ π∗
in dimension ai contains the accumulation value of the correctly
computed preﬁx set Pi,i(cid:48) with all but negligible probability. As-
suming this holds, by Lemma 3 and because veriﬁcation succeeds,
∈ π∗ is the accumulation value of the cor-
it follows that π∗
rectly computed set Ri for query Q on T . Therefore, the values
∩, along with sets Ri and cheating answer R∗ (cid:54)= R
W ∗
(where R is the correct result of Q) as output by A, contradict
Lemma 2, breaking the q-SBDH assumption. Therefore, the prob-
ability Pr[E1|E(cid:48)

From the above, it follows that, for all i, i(cid:48), the triplet τ∗

2] must be negligible.

i ∈ π∗

Since Pr[E1|E2] + Pr[E1|E(cid:48)

2] is negligible, Pr[E1] must be negli-
gible as well, contradicting our original assumption that there exists
PPT adversary A that breaks our scheme with non-negligible prob-
ability.
(cid:4)

i , F ∗

Ri

830