TreeDroid: A Tree Automaton Based Approach to

Enforcing Data Processing Policies∗

Mads Dam

KTH Royal Institute of

Stockholm, Sweden

Technology
mfd@kth.se

Gurvan Le Guernic
KTH Royal Institute of

Technology

Stockholm, Sweden
gurvan@kth.se

Andreas Lundblad
KTH Royal Institute of

Technology

Stockholm, Sweden
landreas@kth.se

ABSTRACT
Current approaches to security policy monitoring are based
on linear control ﬂow constraints such as runQuery may be
evaluated only after sanitize. However, realistic security
policies must be able to conveniently capture data ﬂow con-
straints as well. An example is a policy stating that argu-
ments to the function runQuery must be either constants,
outputs of a function sanitize, or concatenations of any
such values.

We present a novel approach to security policy monitor-
ing that uses tree automata to capture constraints on the
way data is processed along an execution. We present a
λ-calculus based model of the framework, investigate some
of the models meta-properties, and show how it can be im-
plemented using labels corresponding to automaton states
to reﬂect the computational histories of each data item. We
show how a standard denotational semantics induces the ex-
pected monitoring regime on a simple ”while” language. Fi-
nally we implement the framework for the Dalvik VM using
TaintDroid as the underlying data ﬂow tracking mechanism,
and evaluate its functionality and performance on ﬁve case
studies.

Categories and Subject Descriptors
D.2.5 [Software Engineering]: Testing and debugging—
Monitors; D.4.6 [Operating Systems]: Security and Pro-
tection—Information ﬂow controls

Keywords
Runtime monitoring, policy enforcement, tree automata

1.

INTRODUCTION

Today 95% of all mobile devices run Android, Symbian,
iOS or RIM [15]. All those OS share the same security model

∗Work partially supported by the EU FP7 project HATS, by

the Swedish Strategic Research Foundation project PROS-
PER, and by the ACCESS Linnaeus Centre at KTH.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’12, October 16–18, 2012, Raleigh, North Carolina, USA.
Copyright 2012 ACM 978-1-4503-1651-4/12/10 ...$15.00.

for third party applications. When a new application is in-
stalled (or launched for the ﬁrst time) the operating system
asks the user if he or she grants the application a set of per-
missions. Such permissions typically allow the application
to access internet, the GPS hardware, address book data,
camera, etc. Unfortunately the model is quite crude. Most
useful and innocent tasks require a combination of permis-
sions which could just as well be used maliciously [12, 35].
Many applications request the Internet access permission,
for example in order to display ads, together with permis-
sions for other phone resources, which can then potentially
be remotely accessed and controlled. For this reason it is of
high importance to study techniques, such as the one pro-
posed in this paper, which allow policies to be expressed at
a ﬁner level of granularity.

Our proposal is to use bottom-up tree automata to track
how an application processes data at runtime. The approach
monitors how each data item in an execution has been com-
puted and prevents certain function calls from being made
based on this information. This data-centric approach to
runtime monitoring allows for a wide range of policies to
be expressed, including API usage policies restricting which
methods may be applied to what arguments and data ﬂow
policies stating how data must have been processed before
being passed to certain functions.

The policies in this framework are diﬀerent from the ones
handled by existing techniques. For example, as opposed to
existing runtime monitoring techniques which handle poli-
cies expressing temporal properties such as “f may be in-
voked after g has been invoked but not vice versa” our ap-
proach handles policies such as “f may be applied to the
result of g but not vice versa”. A more concrete example of
a policy which is naturally expressed in our framework (but
diﬃcult or impossible to express in others) could for instance
state that sanitize accepts any string as argument, while
the function runQuery only accepts string constants, strings
returned by sanitize or concatenations of such strings.

The approach described in this paper diﬀers from tra-
ditional runtime monitoring on three key points. The ap-
proach is (a) data centric, (b) based on tree shaped traces
and (c) relies on richer observable actions.
(a) Standard
techniques [11, 20, 13, 36] are control ﬂow oriented: They
monitor the linear ﬂow of events as they occur at system/
thread/object level. By contrast, our technique is data ori-
ented, allowing diﬀerent ﬂows of data to be monitored in
isolation, even if they are arbitrarily interleaved in the ap-
plication. (b) Existing runtime monitoring frameworks are
typically based on deterministic ﬁnite automata (DFA) [8,

89411, 20], edit automata [22], LTL [27, 30], context free gram-
mars [25], or a variation thereof [23, 16], all of which rely
on a model of linear traces. Since our approach focuses
on how data is processed, i.e. how functions are combined
rather than in what order actions are performed, traces ma-
nipulated in our framework are tree shaped. (c) Similarly
to work by others [2, 20, 19, 25, 22], we let the function
calls be the actions observable by the monitor. However,
the fact that monitoring is performed at the data level al-
lows the observable actions to depend on the computational
history of each arguments in a manner which is impossible
or inconvenient using the existing frameworks.

The ﬁrst contribution of the paper is a theoretical formal-
ization of the framework using λ-calculus. It includes a pro-
gram model which records computational histories of data,
and a policy model which accepts or rejects certain compu-
tations. As our second contribution we identify three policy
classes and establish their relationships. As a third contri-
bution, the paper describes a solution allowing an eﬃcient
implementation of the approach by using so called labels
which are to be seen as abstractions of computational histo-
ries. We show how policies, which are semantically deﬁned
in terms of bottom-up tree automata, can be enforced using
data labels corresponding to the automaton states. As a val-
idation of our framework we then show how a standard deno-
tational semantics induces the expected monitoring regime
on a simple imperative language. The ﬁnal contribution is
an implementation of the framework for Java programs run
on top of the Android platform. The implementation re-
lies on taint tracking for its underlying data ﬂow mechanism
and on monitor inlining for policy enforcement. The practi-
cality of the approach is demonstrated in ﬁve diﬀerent case
studies.

The theoretical part of the paper is related to the work on
labeled λ-calculus which was initially proposed by L´evy [21].
A labeled λ-calculus associates labels with subterms in order
to track how they aﬀect the reduction. Gandhe, Venkatesh
and Amitabha [14] use this as a theoretical basis for anal-
ysis of certain aspects of functional programs. Speciﬁcally,
they deﬁne a notion of need and show how to use the cal-
culus to identify to what extent an argument is needed to
reduce a function application to its head normal form. This
involves tracking computations and origins of subterms just
as required by our framework. However, the existing la-
beled λ-calculi do not reﬂect the exact semantics of practi-
cal data ﬂow tracking techniques such as the taint tracking
mechanism on which our framework relies, which is why the
calculus presented in this paper diﬀers from existing ones.

Taint analysis is a well known technique for tracking di-
rect data ﬂows and has been studied extensively over the
years. Our framework is built upon the TaintDroid taint
analysis framework [10]. TaintDroid targets Android appli-
cations and is based on an extension of the Dalvik VM. The
extension allows for simultaneous real-time tracking of data
coming from multiple diﬀerent sources with the relatively
small runtime overhead of 14%.

The inlining algorithm presented in the paper builds upon
the algorithm described by Dam et al [8, 7] with important
diﬀerences regarding the representation and manipulation of
automaton states.

Several papers describe static approaches for checking and

enforcing policies related to the ones handled in our frame-
work. These approaches usually rely on some form of type
system and typically focuses on checking API protocols. The
programming language concept of typestates is one example
of such an approach. Typestate is a reﬁnement of the con-
cept of a type: whereas the type of an object determines the
set of operations ever permitted on the object, a typestate
determines the subset of these operations which is permitted
in a particular context. The idea was introduced by Strom
and Yemini [31] and has recently been developed further by
DeLine and F¨andrich [9] and by Bierhoﬀ and Aldrich [2, 3].
When compared to our approach, a typestate could be seen
as the compile-time counterpart of a label. However, just
as the runtime type of an object is more precise than its
static type, our dynamic labels are more precise than type-
states. The higher precision available at runtime allows us
to avoid many of the problems that static program analysis
faces due to, for instance, aliasing and concurrency. Fur-
thermore, even if typestates were tracked and inspected in
runtime, our notion of label is more general than typestates,
since labels are not bound to a speciﬁc type and since labels
can propagate from one object to another.
2. A CALCULUS WITH API FUNCTIONS
This section presents the calculus used as theoretical foun-
dation. The calculus is an untyped λ-calculus extended with
constants, ranged over by c ∈ C, n:ary function symbols,
ranged over by f n ∈ F and choice, written (t = t) t t. Ap-
plying f n on c1 , . . . , cn yields a value in C atomically and
without side-eﬀects. The semantics of functions is externally

deﬁned and written simply as(cid:74)f n (c1 , . . . , cn )(cid:75). The calculus

grammar follows:

t ::= v | t t | (t = t) t t
v ::= x | c | λx . t | f n c1 . . . cm

where m < n

The standard transition relation (cid:42) is identical to the ex-
tended transition relation −→ of Figure 1 with the ˆτ -related
annotations removed.

We regard terms as programs, and ﬁnite (resp.

inﬁnite)
sequences of reductions, written t0 (cid:42) t1 (cid:42) . . . (cid:42) tn (resp.
t0 (cid:42) t1 (cid:42) . . .), as runs or executions. For brevity, we write
t0 (cid:42) t1 (cid:42) . . . ((cid:42) tn) when our reasoning applies to both
ﬁnite and inﬁnite executions.

Example 1. Provided (cid:74)userInput()(cid:75) yields some string
s, (cid:74)flipCoin()(cid:75) yields either hd or tl, (cid:74)sanitize(s)(cid:75) yields
s(cid:48), and(cid:74)exec(c)(cid:75) yields r c, the following program:
executes as follows whenever(cid:74)flipCoin()(cid:75) yields hd:

exec (λx . ((flipCoin = hd) (sanitize x ) x ) userInput)

(cid:42) exec (λx .((flipCoin = hd) (sanitize x ) x ) s)
(cid:42) exec ((flipCoin = hd) (sanitize s) s)
(cid:42) exec ((hd = hd) (sanitize s) s)
(cid:42) exec (sanitize s)
(cid:42) exec s(cid:48)
(cid:42) r s(cid:48)

This execution is safe as the user input is sanitized before

being executed. If (cid:74)flipCoin()(cid:75) yields tl, the execution pro-

ceeds as follows:

. . .

(cid:42) exec ((tl = hd) (sanitize s) s)
(cid:42) exec s
(cid:42) r s

895This execution is unsafe. As the user input is not sanitized,
the user can execute any “bad” command.

Example 1 emphasizes a ﬁrst distinction between static
veriﬁcation and our dynamic approach. Static techniques
reject the whole program as it contains at least one bad exe-

cution. Our approach rejects executions where(cid:74)flipCoin()(cid:75)

yielded tl, but accepts the others.
2.1 Observable Actions

An observable action is an action performed by the pro-
gram, and observed by the execution monitor (and possibly
rejected). As in similar work [7, 8, 20, 19, 11], the observ-
able actions are the calls to external functions. However,
the novelty is the fact that not only function identiﬁer and
argument values are taken into account, but also the history
of how the arguments were computed.

To keep track of the history of the computations the re-
sulting constants are annotated with a function application
tree (FAT), ˆτ ::= f (τ1, . . . , τn) where τ ::= ˆτ | c. A FAT is
intended to capture the full history of function applications
producing a constant. For example, f(g()) : 1 means that 1
is the result of applying f(·) to g(). Each time a function f n
is called with some arguments, τ1 : c1 , . . . , τn : cn , a new tree
is constructed: f (τ1, . . . , τn). This newly created tree serves
both as the annotation of the resulting constant, and as the
descriptor of the observable action that took place. The
reduction of t to t(cid:48) is written t ˆτ−→ t(cid:48) if it generates the ob-
servation ˆτ , and t −→ t(cid:48) otherwise. The extended semantics
with annotations is described in Figure 1. An unannotated
reduction sequence can always be annotated to form a cor-
responding annotated reduction sequence, and vice versa.
In other words, (cid:42) and −→ are bisimilar. Depending on the
context, [ˆτ ] denotes ˆτ or . If the generated observation is
not relevant, the reduction is written t −→ t(cid:48).

Definition 1

(Observable Trace: ω◦T ). Given an
execution e = t0 (cid:42) . . . ((cid:42) tn), T (e) is the annotated reduc-
tion sequence t(cid:48)
i equals ti with
every constant annotated; in particular, every constant of t(cid:48)
is annotated c :c. Furthermore ω(T (e)) denotes the observ-
0
able trace of e, which is the sequence of observable actions
[ˆτ1], . . . (, [ˆτn]) with the silent actions  ﬁltered out.

n) where t(cid:48)

[ˆτ1]−−→ . . . (

[ˆτn]−−→ t(cid:48)

0

Example 2. Let the ﬁrst execution in Example 1 be de-

noted by e. The annotated execution T (e) looks as follows:

exec (λx .((flipCoin = hd:hd)

(sanitize x ) x ) userInput)

userInput()

−−−−−−−−−−−−→ exec (λx .((flipCoin = hd:hd)
−−−−−−−−−−−−→ exec ((flipCoin = hd:hd)



(sanitize x ) x ) userInput():s)

(sanitize userInput():s) userInput():s)



ﬂipCoin()

sanitize(userInput())

(sanitize userInput():s) userInput():s)

−−−−−−−−−−−−→ exec ((ﬂipCoin():hd = hd:hd)
−−−−−−−−−−−−→ exec (sanitize (userInput():s))
−−−−−−−−−−−−→ exec (sanitize(userInput()):s(cid:48))
−−−−−−−−−−−−→ exec (sanitize(userInput())):r s(cid:48)
The observable trace of e, ω(T (e)), is: userInput(), ﬂipCoin(),
sanitize(userInput()), exec(sanitize(userInput())).

exec(sanitize(userInput()))

The calculus ensures that the annotation of any constant
fully captures how that value was computed, and ﬁlters out
unrelated processing. In fact, if each constant c in a term t
is annotated with c itself and t −→∗ ˆτ : c(cid:48) then ˆτ alone can
be used to recover the computation resulting in the constant
c(cid:48). This property is formalized in Theorem 1.

Theorem 1. Given a term t in which all constants have
the shape c : c, if t −→∗ τ : c(cid:48) then term(τ ) −→∗ τ : c(cid:48)
where term(f (τ1, . . . , τn)) = f n term(τ1) . . . term(τn) and
term(c) = c :c.

Proof. We start by showing that if, for all annotated
constants τ : c in a term t, term(τ ) −→∗ τ : c holds
and t −→ t(cid:48) then, for all annotated constants τ(cid:48) : c(cid:48) in t(cid:48),
term(τ(cid:48)) −→ τ(cid:48) :c(cid:48) holds . This is shown by induction on the
derivation tree of t −→ t(cid:48). All cases except T-AppFun are
trivial as no other rule introduces a new constant. For the T-
AppFun case we need to show that term(f (τ1, . . . , τn)) −→∗

term(f (τ1, . . . , τn)) : (cid:74)f n (c1 , . . . , cn )(cid:75). We ﬁrst note that
f (τ1, . . . , τn):(cid:74)f n (c1 , . . . , cn )(cid:75).

term(f (τ1, . . . , τn)) = f n term(τ1) . . . term(τn). Since we
know that term(τi) −→∗ τi : ci for all annotated constants in
t, we have f n term(τ1) . . . term(τn) −→∗ f n τ1 :c1 . . . τn :cn −→

The result now follows from the fact that all constants in

t are on the form c :c and term(c) −→∗ c :c.

Note, however, that the trace of a reduction t −→∗ τ :c may
not be equal to the trace of term(τ ) −→∗ τ :c since some com-
putations may be discarded in the former reduction. In Ex-
ample 2 for instance, exec (sanitize (userInput())) is suf-
ﬁcient to retrieve the core processing resulting in r s(cid:48) (from
which the flipCoin related code has been ﬁltered out).

The choice of tracking direct function applications and not
decisions regarding branching (i.e. tracking direct data ﬂows
and not indirect ones) is deliberate but not a fundamental
requirement of the approach. The calculus could in princi-
ple be adapted to take branching decisions (explicit indirect
ﬂows) into account simply by (1) annotating terms with a
context describing which computations the current compu-
tations depends upon and (2) update this context based on
τ1 and τ2 in the T-CondT and T-CondF rules. However,
from a theoretical point of view, the policies we currently
have in mind are strongly related to data processing (i.e.
what is actually computed rather than under what condi-
tions something is computed) and can be conveniently en-
forced using existing taint tracking mechanisms (i.e. mecha-
nisms tracking only direct ﬂows). Moreover, from a practical
point of view, the absence of eﬃcient dynamic data tracking
mechanisms for a commercial-level system handling indirect
ﬂows, on top of which to implement our approach, reinforces
this choice.

3. POLICIES

In our setting, a policy P speciﬁes which computations
(nesting of function applications) are allowed to be per-
formed. Since each new function application is recorded
in the form of an observable action, policies can be conve-
niently expressed as a predicate over traces, i.e. sequences of
observable actions. This nomenclature is standard in mon-
itoring, [23, 1, 20]. A reduction sequence, e, is said to be
accepted by P if and only if P(ω(T (e))) holds and rejected

896t1

t1 t2

t2

v1 t2

1 t2

1

ˆτ−→ t(cid:48)
ˆτ−→ t(cid:48)
ˆτ−→ t(cid:48)
ˆτ−→ v1 t(cid:48)

2

2

−

T-AppL

T-AppR

c1 = c2

(τ1 :c1 = τ2 :c2 ) t1 t2

T-CondT

−→ t1

c1 (cid:54)= c2

(τ1 :c1 = τ2 :c2 ) t1 t2

T-CondF

−→ t2

(λx . t) v −→ t[v/x]

T-AppAbs

f n τ1 :c1 . . . τn :cn

t1

ˆτ−→ t(cid:48)
ˆτ−→ (t(cid:48)

1

T-CondL

T-CondR

(t1 = t2) t3 t4
ˆτ−→ t(cid:48)
ˆτ−→ (τ1 :c1 = t(cid:48)

t2

2

(τ1 :c1 = t2) t3 t4

1 = t2) t3 t4

2) t3 t4

−

f (τ1,...,τn)

−−−−−−−→ f (τ1, . . . , τn):(cid:74)f n (c1 , . . . , cn )(cid:75) T-AppFun

Figure 1: Reduction rules with history annotations and observable actions.

otherwise. In this paper, we do not consider arbitrary poli-
cies. Some policies can not even be enforced in practice.
The class of policies considered include only the ones that
are local and subtree closed.

Definition 2

(Local Policy). A policy, P, is said to
be local if a predicate P exists such that P (c) holds for all
c ∈ C and P(ˆτ1, . . . (, ˆτn)) holds iﬀ ∀0≤i (<n) P (ˆτi) holds.
This property allows us to focus on stateless policies stating
which computations may be performed rather than when
they may be performed and alleviates the need of a global
monitor state. This constraint is however not fundamental
and can be relaxed by instead stating that the set of accepted
traces should be preﬁx-closed (i.e. that if a trace is accepted
then so should all its preﬁxes). This would allow policies to
express temporal properties of the observable traces, such
as “f may not be evaluated until g has been evaluated” and
would arguably be more suitable when, for instance, dealing
with functions with side-eﬀects. Such class of policies has
however been studied in depth already, [7, 8, 1] and we see
no incompatibility with those studies and the results in this
paper.

Definition 3

(Subtree Closed Policy). A local po-
licy is subtree closed if the set of observable actions for
which P (Deﬁnition 2) holds is subtree closed.

This property rules out policies that for instance accept the
evaluation of g(f ()) but rejects the evaluation of f (). As dis-
cussed below such policies are not meaningful in languages
with call-by-value semantics like Java, since f () indeed needs
to be evaluated in order to evaluate g(f ()) (in a call-by-name
setting however, f () does not necessarily need to be evalu-
ated).

Example 3. A typical example of a policy which is local
and subtree closed could for instance express that sanitize
accepts any string, while exec only accepts results from the
sanitize function (i.e. all strings must be sanitized before
they are passed to exec). With such a policy, the evaluation
of the term of Example 1 is accepted if flipCoin returns hd
and rejected otherwise.

The hierarchy between preﬁx-closed, local and subtree-
closed policies, both in general and under the assumption of
a call-by-value semantics (CBV), can be summarized as fol-
lows: subtree-closed policies are by deﬁnition also local; local
policies are not necessarily subtree closed except for CBV
semantics; local policies are preﬁx-closed but preﬁx-closed
policies are not necessarily local, not even when assuming a
CBV semantics. The distinction between call-by-value and
call-by-name semantics come from the fact that, in CBV,

any parameter of an executed function call has been evalu-
ated previously.

Lemma 1. In CBV semantics, if ˆτ1, . . . , ˆτn, f i (τj, . . . , τk)
is a preﬁx of a trace of an execution ω(T (t0 (cid:42) . . . ((cid:42) tm))),
then ({τj, . . . , τk} \ C ) ⊆ {ˆτ1, . . . , ˆτn}.

Proof. Any argument of f i must have the form τl : c. Ei-
ther c comes from the original term, in which case τj ∈ C or
c is the result of a function application prior to f i (τj, . . . , τk)
in which case τj ∈ {ˆτ1, . . . , ˆτn}.
4. LABELS

Manipulating FATs at runtime for enforcement is not ef-
ﬁcient in practice. For instance, if a policy requires an ar-
gument to be the result of an even number of applications
of toggle, the FATs could grow indeﬁnitely, despite the fact
that a boolean value would suﬃce to maintain and describe
the relevant computational history. To circumvent this prob-
lem, labels are introduced to replace FATs. A label can be
seen as an abstraction of a FAT.
Labels (denoted by α, β, ...) range over a set L of ground
labels closed under ⊕. A special label L0 ∈ L denotes the
default label and is used for constants present in the initial
term. By convention, Lf denotes the label associated to f n
(Lf can be the same as Lg ). The deterministic ⊕ opera-
tor is used to compute the label of the result of a function
application. ⊕ can be seen as an abstraction of the FAT con-
structor. The pair (cid:104)L,⊕(cid:105) is referred to as a labeling scheme.
It has the nice property to be instantiable to reﬂect the taint
tracking policy of TaintDroid, on which our implementation
is based. For enforcement purposes, programs are evaluated
using a new semantics −→⊕ manipulating labels similar to
the one of Figure 1 where observable actions are removed
and tree-annotated constants τi : ci are replaced by label-
annotated constants αi : ci . The only diﬀerence is the rule
T-AppFun which is replaced by the rule L-AppFun which
follows:

γ = Lf ⊕ α1 ⊕ ··· ⊕ αn

f n α1 : c1 . . . αn : cn →⊕ γ :(cid:74)f n(c1, . . . , cn)(cid:75)

Just as in the case with FATs, the labels do not aﬀect the
resulting terms and every annotated reduction sequence has
a corresponding unannotated reduction sequence. strip(t)
is t with the label of every constant removed and init(t) is
the term t in which each unlabeled constant c is replaced by
L0 :c.

Proposition 1. If t −→n⊕ t(cid:48) then strip(t) (cid:42)n strip(t(cid:48)).
The reverse is true for every term only if ⊕ is a total

function. It is a potential property of an execution.

897Definition 4

tn has a valid (cid:104)L,⊕(cid:105)-labeling iﬀ there exists t(cid:48)
that init(t0) −→n⊕ t(cid:48)

(Valid Labeling). An execution t0 (cid:42)n
n such
n where ti = strip(t(cid:48)

1, . . . , t(cid:48)
i) for i ∈ [1, n].

By allowing ⊕ to be a partially deﬁned function certain
sequences of reductions are ruled out due to the premise of
the L-AppFun rule. This can be (and is) exploited as an
enforcement mechanism as shown in the following deﬁnition.
((cid:104)L,⊕(cid:105) Enforcement). (cid:104)L,⊕(cid:105) enforces
a policy P if all executions with valid (cid:104)L,⊕(cid:105)-labelings are
accepted by P. If the reverse also holds, i.e. all executions
accepted by P have a valid (cid:104)L,⊕(cid:105)-labeling, (cid:104)L,⊕(cid:105) is said to
precisely enforce P.

Definition 5

An example of how a labeling scheme enforces a sanitize be-
fore executing-policy is presented in Example 5 in Section 6.
When reasoning about the correctness of the labeling sche-
me we need a way to tell which label a certain FAT corre-
sponds to. For this purpose we deﬁne the RL,⊕-function as
follows:

Definition 6

(RL,⊕). RL,⊕(τ ) is deﬁned as follows:

RL,⊕(c) = L0

RL,⊕(f (τ1, . . . , τn)) = Lf ⊕ RL,⊕(τ1) ⊕ . . . ⊕ RL,⊕(τn)
Lemma 2
(Labels abstract FATs). For any t0:
to −→n τ :c ∧ RL,⊕(τ ) ∈ L ⇔ init(t0) −→n
Proof. By induction on the length of the derivation. The
only interesting case, T-AppFun, follows directly from the
semantics deﬁnitions and Deﬁnition 6.

⊕ RL,⊕(τ ):c

An execution is accepted iﬀ, for any observable action ˆτ

generated, RL,⊕(ˆτ ) is deﬁned.

Theorem 2

t0 (cid:42)n tn has a valid (cid:104)L,⊕(cid:105)-labeling (init(t0) −→n⊕ t(cid:48)
for any ˆτ in ω(T (e)), RL,⊕(ˆτ ) is deﬁned (RL,⊕(ˆτ ) ∈ L).

(Accepted execution). Execution e =
n) iﬀ,

Proof. Assuming −→ goes through, −→⊕ can only fail on
L-AppFun, whose corresponding rule T-AppFun is the only
one generating observable FATs. Hence, if RL,⊕(ˆτ ) is de-
ﬁned for any ˆτ in ω(T (e)) then Lemma 2 helps conclude
that init(t0) −→n⊕ t(cid:48)
n. The other direction is proved by in-
duction on the length of init(t0) −→n⊕ t(cid:48)
n and by observing
that, by Lemma 1 and induction hypothesis, for any subtree
τ of the potentially newly generated FAT ˆτn+1, RL,⊕(τ ) is
deﬁned and, by Lemma 2, equal to the corresponding label in
t(cid:48)
n. Hence, RL,⊕(ˆτn+1) is deﬁned.
5. DEFINING AND ENFORCING POLICIES
As suggested previously, security policies in this work are
deﬁned by a bottom-up deterministic ﬁnite tree automaton
(DFTA) [5] that characterizes a set of FATs.

Definition 7

(DFTA [5]). A (bottom-up) determinis-
tic ﬁnite tree automaton over a ranked alphabet A is a tu-
ple A = (Q, A, Qf , ∆) where Q is a set of (unary) states,
Qf ⊆ Q is a set of accepting states and ∆ is a partial
function deﬁned by a set of transition rules of the form
An, q1 , . . . , qn ∈ Q and t1, . . . , tn are terms over A.

a(q1 (t1), . . . , qn (tn)) (cid:95) q(a(t1, . . . , tn)) where n ≥ 0, a ∈
L(A)) if t(cid:95)∗ q(t) for some q ∈ Qf .

A ground term t of A is accepted by an automata A (t ∈

Intuitively, an automaton accepts a term t iﬀ every node
in the tree t can be annotated with a state such that the root
node is annotated with a ﬁnal state, and the annotations are
compatible with the transition rules ∆.
A policy is deﬁned in terms of a DFTA over F ∪ C, from

now on referred to as a security tree automaton (STA).

Definition 8

(STA). A security tree automaton is a
DFTA A = (Q, F ∪ C, Q, ∆) such that there exists q0 in Q

and for all c in C: c(cid:95) q0 (c) ∈ ∆.

PA denotes the policy deﬁned by the STA A whose set of

accepted traces is {[ˆτ0, . . . (, ˆτn)] | ∀i ∈ [0, n]. ˆτi ∈ L(A)}.
Lemma 3. A policy deﬁned in terms of a STA is local.
Proof. The predicate P (τ ) def= τ ∈ (C ∪ L(A)) is a valid
candidate showing that the policy PA is local according to
Deﬁnition 2.

Additionally, as for ordinary security automata [29], all sta-
tes of a STA are required to be accepting (this does not
imply that all trees are accepted, since ∆ is partial). This
requirement is suﬃcient to ensure that STA policies are sub-
tree closed.

Lemma 4. The language of a STA is subtree closed.

Proof. If f (τ1, . . . , τn) is accepted, then there exist q,

q1 , . . . , qn such that f (τ1, . . . , τn)(cid:95)∗ f (q1 (τ1), . . . , qn (τn))(cid:95)
τi(cid:95)∗ qi (τi) and since Qf = Q, τi is also accepted.

q(f (τ1, . . . , τn)). This means that, for all τi in τ1, . . . , τn,

If there exists an injective function from the states of an
STA A to the labels of a labeling scheme (cid:104)L,⊕(cid:105) and ⊕ simu-
lates the transitions in ∆ then (cid:104)L,⊕(cid:105) precisely enforces PA.
(Equivalent (cid:104)L,⊕(cid:105)). (cid:104)L,⊕(cid:105) precisely en-
forces the policy described by the STA A = (Q, F ∪ C, Q, ∆)
if there exists an injective function L : Q → L such that,
with Lc = L0 for all c in C:

Theorem 3

L(q) = La ⊕ L(q1 ) ⊕ . . . ⊕ L(qn ) ⇐⇒

a(q1 (τ1), . . . , qn (τn))(cid:95) q(a(τ1, . . . , τn)) ∈ ∆ (1)

Proof. Following Deﬁnition 5, it is suﬃcient that for a
given L the following holds for any execution e = t0 (cid:42)n tn:
e has a valid (cid:104)L,⊕(cid:105)-labeling ⇐⇒ e is accepted by PA

Since the policy is local and since all states in the policy
automaton are accepting, by Lemma 2 and Deﬁnition 8, it
is suﬃcient to show the following for each ˆτ ∈ ω(T (e)):

which follows from the following holding for all τ :

RL,⊕(ˆτ ) ∈ L ⇐⇒ ∃q. ˆτ (cid:95)∗ q(ˆτ )
τ (cid:95)∗
RL,⊕(τ ) = α ⇒ τ (cid:95)∗

q(τ ) ⇒ RL,⊕(τ ) = L(q)
−1(α)(τ )

L

(2)

(3)

(2) and (3) follow by induction on τ by assuming (1).

We now turn to the syntax of the language for describ-
ing security tree automata. We ﬁrst give a concrete self
explanatory example and then generalize this into a proper
deﬁnition.

898Example 4. A policy stating that the function exec only
accepts strings returned by another function sanitize, or
concatenations of any such strings is written as:

{unsanitized, sanitized},
{sanitize(α) :
concat(α1 , α2 ) : α1 = α2 = sanitized → sanitized

true → sanitized

exec(α) :

true → unsanitized
α = sanitized → sanitized}

Where the default label L0 equals unsanitized.

The general syntax of a policy is deﬁned as follows.

Definition 9

(Policy Syntax). Syntactically, a pol-

icy is expressed as follows
{L0, L1, . . . , LnL},
1 (α11 , . . . , α1n1 ) : guard 11 → expr 11
{f n1
→ expr 1g1
k (αk1 , . . . , αknk ) : guard k1 → expr k1
f nk
→ expr kgk

···
guard kgk

···
guard 1g1

...

,

}

where each guard is a boolean expression and each expr is
a label expression, both of which are composed from the de-
clared label constants, the argument labels and simple tests
such as equality.

i

Intuitively, when f ni

is invoked the formal parameters,
αi1, . . . , αini , are bound to the labels associated with the ar-
guments. The return label is computed from the expression
expr ij corresponding to the ﬁrst guard guard ij that holds
among guard i1, . . . , guard igi
If no guard holds, the invo-
cation is to be seen as a violation of the policy. A formal
translation into a security tree automata follows.

.

Definition 10

(Policy Semantics). Given a policy P
in the syntax of Deﬁnition 9, the corresponding security tree
automaton, AP = (Q, F ∪ C, Q, ∆), is deﬁned as follows:

Q = {q0 , q1 , . . . , qnL} and ∆ = {c(cid:95) q0 (c) | c ∈ C} ∪(cid:83) δij,

where each δij represents the set of automaton transitions
corresponding to guard j in clause i:
(cid:48)

(cid:48)

{ fi (q
| q
(cid:48)
1 . . . q

(cid:48)
1 (x1), . . . , q

ni (xni ))(cid:95) q
=(cid:74)expr ij[qk /Lk ][q
ni ∈ Q ∧ q
(cid:48)
∧ (cid:74)guard ij[qk /Lk ][q
k /αik ](cid:75)
∧ ¬ (cid:95)
1≤g<j(cid:74)guard ig[qk /Lk ][q
k /αik ](cid:75) }

(cid:48)

(cid:48)

(cid:48)

(fi (x1, . . . , xni ))

(cid:48)

k /αik ](cid:75)

As mentioned in Section 4, the enforcement mechanism
does not, for practical reasons, work directly on FATs but on
labels. To enforce a policy, an equivalent labeling scheme is
needed. For policies expressed in the syntax of Deﬁnition 9,
such labeling scheme can be deﬁned as follows.

Definition 11. Given a policy P in the syntax of Deﬁni-
tion 9, the labeling scheme LS (P) is deﬁned as (cid:104){L0, L1, . . . ,
LnL} ∪ {Lfi},⊕(cid:105) where Lfi ⊕ α1 ⊕ ··· ⊕ αni is:
[αk /αik ](cid:75) then(cid:74)expr igi

if(cid:74)guard i1[αk /αik ](cid:75) then(cid:74)expr i1[αk /αik ](cid:75)
[αk /αik ](cid:75)

else if(cid:74)guard igi

else if . . .

then . . .

We now show that LS (P) indeed precisely enforces P ac-

cording the semantics deﬁned in Deﬁnition 10.

Theorem 4

(Correctness of LS ). Given a policy P
in the syntax of Deﬁnition 9, LS (P) enforces P precisely.
Proof. Follows directly from Theorem 3 with L(qi ) =

Li

6. LABELED IMPERATIVE LANGUAGE

A λ-calculus is a natural candidate for the core language
since central concepts such as function applications are eas-
ily represented. Furthermore, the structure and potential
data ﬂow in a program is arguably clearer if written in
the form of a λ-term than in a language with side eﬀects.
Nonetheless it is important to make sure that the calculus is
general enough to serve as a foundation for other languages
as well, such as Java which is the language of applications
monitored by TreeDroid. This section introduces a While-
language whose semantics track labels in a natural way. A
straightforward encoding of the language in our calculus is
then provided and shown to agree with the labeling seman-
tics.

The language presented in this section is a simple impera-
tive language with loops and the addition of labels, external
function applications and return statement. The small-step
operational semantics of the language is given in Figure 2. A
conﬁguration is represented as (cid:104)S, σ(cid:105) where S is the state-
ment to be executed and σ the current store. The store
maps variables to labeled values and the initial store, σ0,
maps each variable to L0 :0.

Example 5. The program in this exmaple is similar to

the one of Example 1.

x1 := userInput();
if flipCoin() = 1 then x1 := sanitize(x1) else x1 := x1;
return exec(x1)
With the labeling scheme, (cid:104){L0, input, sanitized, result, Lexec,
LﬂipCoin , Lsanitize , LuserInput}, ⊕(cid:105) where

α1 ⊕ α2 ⊕ . . . ⊕ αm =



L0
input
sanitized if α1 = Lsanitize

if α1 = LﬂipCoin
if α1 = LuserInput

(cid:26) α1 = Lexec

result

if

α2 = sanitized

an execution in which flipCoin yields 1 terminates:

(cid:104)x1 := userInput(); if flipCoin() = 1 then . . . , σ0(cid:105)

(cid:16)⊕ (cid:104)if flipCoin() = 1 then . . . , σ0[x1 (cid:55)→ input:7](cid:105)
(cid:16)⊕ (cid:104)x1 := sanitize(x1); . . . , σ0[x1 (cid:55)→ input:7](cid:105)
(cid:16)⊕ (cid:104)return exec(x1), σ0[x1 (cid:55)→ sanitized:7(cid:48)](cid:105)
(cid:16)⊕ result:7(cid:48)(cid:48)

and an execution in which flipCoin yields 0 would get stuck:

(cid:104)x1 := userInput(); if flipCoin() = 1 then . . . , σ0(cid:105)

(cid:16)⊕ (cid:104)if flipCoin() = 1 then . . . , σ0[x1 (cid:55)→ input:7](cid:105)
(cid:16)⊕ (cid:104)x1 := x1; . . . , σ0[x1 (cid:55)→ input:7](cid:105)
(cid:16)⊕ (cid:104)return exec(x1), σ0[x1 (cid:55)→ input:7](cid:105)
since Lexec ⊕ input is undeﬁned.

Figure 3 gives an encoding of While in the style of state

transformers with C = N and F = {f1, . . . , fk}.

899−

(cid:104)n, σ(cid:105) (cid:16)⊕ L0 : n

−

(cid:104)xk, σ(cid:105) (cid:16)⊕ σ(xk)

(cid:104)E, σ(cid:105) (cid:16)⊕ α : n

(cid:104)xk := E, σ(cid:105) (cid:16)⊕ σ[xk (cid:55)→ α : n]

(cid:104)S1, σ(cid:105) (cid:16)⊕ (cid:104)S(cid:48)
(cid:104)S1; S2, σ(cid:105) (cid:16)⊕ (cid:104)S(cid:48)

1, σ(cid:48)(cid:105)
1; S2, σ(cid:48)(cid:105)

(cid:104)E1, σ(cid:105) (cid:16)⊕ α1 : n (cid:104)E2, σ(cid:105) (cid:16)⊕ α2 : n

(cid:104)if E1 = E2 then S1 else S2, σ(cid:105) (cid:16)⊕ (cid:104)S1, σ(cid:105)

(cid:104)E1, σ(cid:105) (cid:16)⊕ α1 : n (cid:104)E2, σ(cid:105) (cid:16)⊕ α2 : n

(cid:104)while E1 = E2 do S, σ(cid:105) (cid:16)⊕ (cid:104)S; while E1 = E2 do S, σ(cid:105)

(cid:104)E1, σ(cid:105) (cid:16)⊕ α1 : n1

(cid:104)f (E1, . . . , Em), σ(cid:105) (cid:16)⊕ Lf ⊕ α1 ⊕ ··· ⊕ αm :(cid:74)f (n1, . . . , nm)(cid:75)

(cid:104)Em, σ(cid:105) (cid:16)⊕ αm : nm

. . .

(cid:104)S1, σ(cid:105) (cid:16)⊕ σ(cid:48)

(cid:104)E, σ(cid:105) (cid:16)⊕ α : n

(cid:104)S1; S2, σ(cid:105) (cid:16)⊕ (cid:104)S2, σ(cid:48)(cid:105)
(cid:104)E1, σ(cid:105) (cid:16)⊕ α1 : n1

(cid:104)return E, σ(cid:105) (cid:16)⊕ α : n
(cid:104)E2, σ(cid:105) (cid:16)⊕ α2 : n2 n1 (cid:54)= n2

(cid:104)if E1 = E2 then S1 else S2, σ(cid:105) (cid:16)⊕ (cid:104)S2, σ(cid:105)

(cid:104)E1, σ(cid:105) (cid:16)⊕ α1 : n1

(cid:104)E2, σ(cid:105) (cid:16)⊕ α2 : n2 n1 (cid:54)= n2

(cid:104)while E1 = E2 do S, σ(cid:105) (cid:16)⊕ σ

Figure 2: Semantics of the While-language with Function Application Monitoring.

Auxiliary deﬁnitions:

get = λs. λx. s x
set = λs. λx. λv. λk. (k = x) v (s k)
ﬁx = λg. (λx. g (λy. x x y)) (λx. g (λy. x x y))

Expressions:

(cid:74)n(cid:75) = λs. L0 : n
(cid:74)xk(cid:75) = λs. get s k

Statements:

(cid:74)f (E1, . . . , Em)(cid:75) = λs. f ((cid:74)E1(cid:75) s) . . . ((cid:74)Em(cid:75) s)
(cid:74)S1; S2(cid:75) = λs.(cid:74)S2(cid:75) ((cid:74)S1(cid:75) s)
(cid:74)xk := E(cid:75) = λs. set s k ((cid:74)E(cid:75) s)
(cid:74)if E1 = E2 then S1 else S2(cid:75) = λs. ((cid:74)E1(cid:75) s =(cid:74)E2(cid:75) s)
(cid:74)return E(cid:75) = λs.(cid:74)E(cid:75) s

((cid:74)S1(cid:75) s) ((cid:74)S2(cid:75) s)
(cid:74)while E1 = E2 do S(cid:75) = ﬁx (λw. λs. ((cid:74)E1(cid:75) s =(cid:74)E2(cid:75) s)
(w ((cid:74)S(cid:75) s)) s)

Figure 3: Encoding of While in our λ-calculus

Definition 12. A state is a term λk. t which reduces to a
labeled constant when applied to a number: (λk. t) n →∗ α:c.
A state s and a store σ agree, s ∼ σ, iﬀ s k →∗ σ(xk) for
all k.

⊕ α:n.

Lemma 5

(Expression equivalence). If s ∼ σ then

Proof. By structural induction on E. For E ≡ n, we

Initial state for evaluation is s0 = λk. L0 : 0. The follow-
ing lemmas show that (cid:16)⊕ evaluating P accepts the same

executions as −→⊕ evaluating(cid:74)P(cid:75).
(cid:104)E, σ(cid:105) (cid:16)⊕ α:n ⇔(cid:74)E(cid:75) s −→∗
have (cid:104)n, σ(cid:105) (cid:16)⊕ L0 : n and (cid:74)n(cid:75) s −→⊕ L0 : n. For E ≡ xk, we
have (cid:104)xk, σ(cid:105) (cid:16)⊕ σ(xk) and (cid:74)xk(cid:75) s −→⊕ (λs.get s k) s −→⊕
. . . ⊕ αm :(cid:74)f (n1, . . . , nm)(cid:75), assuming (cid:104)Ei, σ(cid:105) (cid:16)⊕ αi :ni . By
induction, (cid:74)f (E1, . . . , Em(cid:75) s = λs.f ((cid:74)E1(cid:75)s) . . . ((cid:74)Em(cid:75) s)
(cid:74)f (n1, . . . , nm)(cid:75).
(cid:104)S, σ(cid:105) (cid:16)⊕ (cid:104)S(cid:48), σ(cid:48)(cid:105) (resp. α : n) iﬀ (cid:74)S(cid:75) s −→∗
⊕ (cid:74)S(cid:48)(cid:75) s(cid:48) (resp.

get s k −→⊕ s k where s k reduces to σ(xk) by Deﬁnition 12.
For E ≡ f (E1, . . . , Em), (cid:104)f (E1, . . . , Em), σ(cid:105) (cid:16)⊕ Lf ⊕ α1 ⊕

reduces to f α1 :n1 . . . αm :nm and then Lf ⊕ α1 ⊕ . . .⊕ αm :

(Statement equivalence). If s ∼ σ then

α:n) and σ(cid:48) ∼ s(cid:48) (assuming reductions proceed).

Lemma 6

Proof Sketch. For brevity, full details and sublemmas
are left out. In full details, the proof proceeds by deﬁning
−→+⊕⊆−→∗
⊕ step-wise equivalent to (cid:16)⊕. Brieﬂy, the direction
from (cid:16)⊕ to −→∗
⊕ proceeds by cases on the semantics rules,
and by observing that P evaluates to a value only if it eval-

uates a return and then(cid:74)P(cid:75) also evaluates to a value. The

most complex cases are for the ﬁrst while-rule:

−→∗

(cid:74)while E1 = E2 do S(cid:75) s
= (ﬁx (λw.λs.((cid:74)E1(cid:75) s =(cid:74)E2(cid:75) s) (w ((cid:74)S(cid:75) s)) s)) s
−→⊕ (λs.((cid:74)E1(cid:75) s =(cid:74)E2(cid:75) s) ((ﬁx (λw.λs.((cid:74)E1(cid:75) s =(cid:74)E2(cid:75) s)
(w ((cid:74)S(cid:75) s)) s)) ((cid:74)S(cid:75) s)) s) s
−→⊕ ((cid:74)E1(cid:75) s =(cid:74)E2(cid:75) s) ((ﬁx (λw.λs.((cid:74)E1(cid:75) s =(cid:74)E2(cid:75) s)
(w ((cid:74)S(cid:75) s)) s)) ((cid:74)S(cid:75) s)) s
⊕ (α1 : n = α2 : n) ((ﬁx (λw.λs.((cid:74)E1(cid:75) s =(cid:74)E2(cid:75) s)
(w ((cid:74)S(cid:75) s)) s)) ((cid:74)S(cid:75) s)) s
−→⊕ (ﬁx (λw.λs.((cid:74)E1(cid:75) s =(cid:74)E2(cid:75) s) (w ((cid:74)S(cid:75) s)) s)) ((cid:74)S(cid:75) s)
= (cid:74)S; while E1 = E2 do S(cid:75) s
duces to σ[xk (cid:55)→ α:n] iﬀ(cid:74)xk := E(cid:75) s = (λs.set s k ((cid:74)E(cid:75) s)) s

and for assignments where, by Lemma 5, (cid:104)xk := E, σ(cid:105) re-
reduces to λl.(l = k) α : n (s k) and, since σ ∼ s, σ[xk (cid:55)→
α : n] ∼ λl.(l = k) α : n (s k). The other direction proceeds
similarly by cases on −→+⊕.

7.

IMPLEMENTATION

From a formal point of view, there is a large gap between
the While-language and a real world language such as Java.
Conceptually however, the semantics presented in the previ-
ous section outlines how the implementation of the labeling
semantics works for Java. This section describes an imple-
mentation targeting Java (bytecode) and the Android plat-
form which follows this outline.
Implementing the frame-
work involves solving two main tasks: tracking data ﬂows
and intercepting policy relevant function calls. In our im-
plementation we solve the ﬁrst task using taint analysis and
the second task using monitor inlining.
7.1 Tracking Data Flows using Taint Analysis
Taint analysis (also known as taint tracking) is a com-
mon technique for tracking data ﬂows at runtime. The tech-
nique relies on (1) having points at which data is originally
tainted (taint sources), (2) making sure that taints propa-
gate along with every data ﬂow (taint propagation) and (3)
having points at which taints of output data is intercepted
(taint sinks). In our work we rely on taint propagation for
tracking data ﬂows by letting taints represent labels. The
notion of taint sources and sinks however are factored out
and handled by the inlined monitor.

Taint analysis implementations targeting the JVM has
been described by several authors [18, 34, 4, 10]. Our imple-
mentation uses the TaintDroid framework by Enck et al [10]
which targets the Android Platform. TaintDroid is based on
a modiﬁed version of the Dalvik VM which taints data com-
ing from various privacy related sources such as the GPS,

900camera, microphone etc. and monitors the taints of data
being sent on the network.
7.1.1 Limitations due to Taint Analysis
In TaintDroid a taint is represented by a 32-bit word
where each bit corresponds to one of the privacy related
sources. If for instance the taint of a value v has bit 25 and
bit 32 is set, then v contains data which potentially comes
from the camera and GPS respectively. When data is copied
from one location to another, the taint is copied along with
it. If two values v1 and v2 are combined (added or concate-
nated for instance) the taint of the result is determined by
the bitwise or of the taint of v1 and the taint of v2. While
this approach makes sense when working with the type of
privacy related policies which TaintDroid is intended for, it
poses a limitation on what policies we are able to enforce in
our framework. For a policy to be enforceable, when using
TaintDroid as the underlying taint tracking mechanism, it
must have the two properties described below.

Property 1. If L is the set of labels in a policy P, there
need to exist an injective function F of type L → 2{1,...,32}
such that the range of F is closed under ∪.

This property ensures that for any two labels L1 and L2
there exists a label L3 such that F (L1) ∪ F (L2) = F (L3)
or, put diﬀerently, the bitwise or-operation performed by
TaintDroid always yields a taint representing a valid label.
The other property is regarding arithmetic operations.
Such operations are encoded as external functions in the
theory, but in practice do not correspond to observable ac-
tions.

Property 2. Whenever an arithmetic operation is ap-
plied to two labeled constants L1 : c1 and L2 : c2 the policy
must deﬁne the resulting label as F −1(F (L1)∪ F (L2)) where
F is the function described in Property 1.

In terms of abstract algebra, Property 1 and 2 hold for a
policy P iﬀ there exists a monomorphism between the two
algebras (L,(cid:12)) and (2{1,...,32},∪) where (cid:12) is the label op-
erator for arithmetic operations induced by P. Our imple-
mentation assumes that these properties hold for all policies
given to the inliner, and does not have syntactical support
for deﬁning custom behavior for arithmetic operations.
7.1.2 Taint Propagation: Or vs And
Using bitwise or as taint propagation mechanism is suit-
able when handling conﬁdentiality properties. When for ex-
ample enforcing a policy such as “do not send address book
data on the network”, a phone number should maintain its
taint, even if it is manipulated. Conceptually however, our
framework works just as well for integrity related proper-
ties, such as “send text messages only to numbers from my
address book”. Enforcing such policies call for a bitwise and
propagation mechanism since if a phone number is manipu-
lated, it should lose its taint.

To support both types of policies, we split the taint words
in two parts: bits 0-15 which are or :ed together when com-
bined (referred to as or -ﬂags), and bits 16-31 which are
and :ed together when combined (referred to as and -ﬂags).
Rather than changing the actual propagation code in Taint-
Droid however, we simply changed the default taint from
32 zeros to 16 zeros followed by 16 ones and inverted the
interpretation of the and -ﬂags.

7.2 Intercepting Calls using Monitor Inlining
Whenever a program is about to call a function the moni-
tor needs to check if the call is allowed by the policy or not.
If it is not allowed the call should be prevented (for instance
by terminating the execution) and if it is allowed the label of
the result of the function call should be set according to the
policy. This task could be handled by the VM. However, our
implementation delegates the task to the program itself by
inlining the monitor code into the program. This approach
is known as monitor inlining [11] and has the advantage of
not requiring extra support from the execution environment.

Inlining a monitor into P involves the following steps:
1. Parse a policy P given in Deﬁnition 9 syntax.
2. Traverse P’s code and replace each call to a policy rel-

evant function fi with code that does the following

(a) Copy the arguments from the operand stack to lo-
cal variables (as they may be needed after the call
when evaluating the label expression in step 2e)
(b) Until a guard guardij holds, evaluate the guards
successively starting with guardi1 . If guardij holds
store j in a temporary variable x and go to 2d.

(c) Terminate the execution due to policy violation.
(d) Perform the original function call.
(e) Evaluate expr1x and assign the resulting label to

the value returned by the function.

Steps 2b and 2e rely on code for accessing the labels of
certain values. Since the labels are not accessible directly
through bytecode instructions this requires interaction with
TaintDroid. As TaintDroid was not originally designed to
interact with client programs, a few minor modiﬁcations to
TaintDroid were required (exposing some internal methods).
The inlining step is fully automatic and can conveniently
be added to the compile chain, as it has been done by editing
the build settings in the Eclipse IDE for example.
7.2.1 Limitations due to Client-Side Inlining
The general client side inlining limitations has been ex-
plored previously [8, 7]. The main drawback in our setting
is the lack of complete mediation [28] (function calls made
internally by the runtime library are not observable).

The solution is to let the policy prevent internal com-
putations from violating the policy, by restricting the calls
performed by the client. For example, if exec is a policy rele-
vant function, the policy must also restrict calls to functions
that call exec internally, such as wrapper functions. This
may require an over approximation of the intended policy.

Provided all internal policy violations are avoided by the
above technique, as the resulting label would be overridden
by the monitor when control returns to the client code re-
gardless of the internal computations, the lack of complete
mediation is irrelevant when calling functions which are ex-
plicitly mentioned in the policy. However, one can not ex-
pect that a policy has a clause for each function in the Java
API. To relate the behavior of our implementation to the
theory of the framework, the semantics of calling a method
not mentioned in the policy is considered to be the same as
if the body of that method was recursively unfolded into the
client code. In other words, the labels of values returned by
internal function calls are determined solely by the rules for
arithmetic operations (as described in Section 7.1.1).

9017.3 Handling Impure Functions

For simplicity, the theoretical presentation of the frame-
work is restricted to pure functions. As shown in Theorem 1,
the value of an argument in such setting is fully determined
by its FAT. For this reason the observable actions do not en-
tail information regarding actual values of arguments. How-
ever, a language like Java depends heavily on impure func-
tions. The case studies highlight the importance of being
able to reason about argument values.

The modiﬁcations needed for proper handling of impure
functions are however straightforward and do not aﬀect the
theorems presented in the paper. FATs (and thus observable
actions) need to take argument values into account which is
done by the following T-AppFun reduction:

f n τ1 : c1 . . . τn : cn

f (τ1:c1,...,τn:cn)

−−−−−−−−−−−→

f (τ1 : c1, . . . , τn : cn) :(cid:74)f n(c1, . . . , cn)(cid:75)

Similarly ⊕ needs to operate on labeled constants instead

of just labels and the L-AppFun needs to be written as

γ = Lf ⊕ α1 : c1 ⊕ ··· ⊕ αn : cn

f n α1 : c1 . . . αn : cn → γ :(cid:74)f n(c1, . . . , cn)(cid:75)

These modiﬁcations allows the policy guards and expres-
sions to refer to the argument values in addition to the argu-
ment labels. Modiﬁcations to the deﬁnitions of the derived
policy automaton and labeling scheme are straightforward.

8. CASE STUDIES

This section evaluates the approach and the implemen-
tation in ﬁve case studies with varying characteristics. The
webpage [24] contains full details including concrete policies.
8.1 Case Study 1: DroidLocator

Just as the popular application Find My Phone for iPhone,
the DroidLocator application allows the user to locate a lost
or stolen Android device through a web service. As op-
posed to Find My Phone and other similar services how-
ever, DroidLocator prevents server administrators and third
parties from using the location data maliciously. It does so
by encrypting the location data, based on a user-provided
key, before uploading it to the server. When the user later
retrieves the encrypted location data, he or she can decrypt
it without revealing the location to anyone else.

Application DroidLocator is a small application written
by one of the paper’s authors. It retrieves the location data
from the GPS hardware, uses the javax.crypto package to
encrypt it with a key retrieved through EditText.getText,
and submits it to the server using the standard socket API.

Policy The desired policy states that (A) the location may
not be sent over the network unless it is encrypted and that
(B) the encryption key needs to be provided by the user
(retrieved through EditText.getText on an object with no
prior calls to EditText.setText). Figure 5 shows the policy
expressed in terms of the syntax in Deﬁnition 9. The for-
mal semantics of this policy is provided by the STA, ADL,
obtained from Figure 5 by Deﬁnition 10. Examples of FATs
accepted and rejected by ADL are found in Figure 6.

The labeling scheme used at runtime is obtained by follow-
ing Deﬁnition 11 and adapting it to TreeDroid as described
in Section 7. The resulting set of labels L is: {016116 (L0),

{L0, sock, conf, userinp, userenc, nonuser},
{LocationManager.

getLastKnownLocation(α) :

Location.toString(αloc) :
EditText.setText(αet , αtext ) :
EditText.getText(αet ) :

Editable.toString(α) :
SimpleCrypto.getRawKey(α) :
SimpleCrypto.encrypt(αk , αm ) : αk = user → userenc
Socket.getOutputStream(α) :
OutputStream.write(αout , αval ) : αval = L0 → L0

true → conf
true → αloc
true → nonuser
αet (cid:54)= nonuser → userinp
true → L0
true → α
true → α
true → sock
αval = userenc → L0
αout (cid:54)= sock → L0}

Figure 5: Policy for DroidLocator case study.

LocationManager

.getLastKnownLocation

EditText.getText

Editable.toString

Location.toString

SimpleCrypto.getRawKey

SimpleCrypto.encrypt

Socket.getOutputStream

OutputStream.write

LocationManager

.getLastKnownLocation

“”

Location.toString

SimpleCrypto.getRawKey

SimpleCrypto.encrypt

Socket.getOutputStream

OutputStream.write

Figure 6: Accepted and rejected FATs

1015116 (sock), 01014116 (conf), 001013116 (nonuser), 017115
(userenc), 01610114 (userinp)}, and the bitwise-or operator is
used for ⊕.

The label specifying that data contains location informa-
tion is encoded using an or -ﬂag and the label specifying that
data is encrypted is encoded using an and -ﬂag.

Results The behavior was unaﬀected by monitor inlining
since the original application adhered to the policy. When
the code was changed to use as encryption key a predeﬁned
string literal (such as, in Figure 6, the empty string), the
execution was terminated before the location was uploaded.
8.2 Case Study 2: Sms2Group

An application, Sms2Group, requiring the send sms per-
mission, allowing users to send SMS-messages to groups of
contacts, is studied. The policy in this study restricts which
numbers messages may be sent to.

Application Sms2Group has been developed for the pur-
pose of this study. The application allows the user to auto-
mate the task of sending text messages to a group of con-
tacts. It relies on the group attribute in the contact book,
fetched using the content provider API and uses the ordinary
SmsManager.sendTextMessage method to send SMSes.

Policy Messages are prevented from being sent to arbitrary
numbers by ensuring that destination numbers (ﬁrst argu-
ment of sendTextMessage) originate from the local address

902Case study:
Lines of Java source code:
Size bytecode before inlining:
Size increase due to inlining:
Inlining duration:
Policy relevant method calls:
Number of policy clauses:
Average total execution time:
Overhead due to TaintDroid:
Overhead due to inlined code:
Downloads on Google Play:

DroidLocator
330
16.8 kB
24.9 %
178 ms
11
9
142 ms
38.9 %
45.4 %
N/A

Sms2Group Bankdroid+HttpClient Auto Birthday SMS
N/A
193.9 kB
43.2 %
870 ms
359
5
N/A
N/A
N/A
>10,000

101079
2.6 MB
0.395 %
2740 ms
213
14
9780 ms
28.0 %
19.5 %
>100,000

240
17.0 kB
35.2 %
190 ms
15
4
884 ms
53.3 %
16.9 %
N/A

Lovetrap
N/A
55.0 kB
5.30 %
210 ms
1
4
N/A
N/A
N/A
N/A

Figure 4: Statistics from the case studies.

book. The label specifying that a value is a valid destination
number is encoded using an and -ﬂag which prevents attack-
ers from using a modiﬁed address book number. This gen-
eral policy naturally separates legitimate executions from
malicious ones. Using traditional inlining techniques this
type of policy would be expressed using a guard that scans
the address book and checks that the destination number is
present. There are two conceptual diﬀerences between these
approaches. As opposed to a policy that relies on scanning
the address book, our policy expresses that an SMS may not
be sent to numbers with arbitrary origin even if the num-
ber is present in the address book. In this sense our policy
is stricter. Another diﬀerence is that a scan of the address
book is typically a linear operation, whereas checking the
taint of a value is a constant time operation.

Results The inlining did not aﬀect the functionality of the
original program as it adheres to the policy. When changing
the code so that the program attempts to send an SMS to
a hard-coded number or a number from the address book
concatenated with an arbitrary string the policy is violated
and the program is terminated as expected.
8.3 Case Study 3: Bankdroid

This case study examines an internet banking application,
Bankdroid, which allows users to review account informa-
tion from several diﬀerent banks. The application has many
security concerns as the information it handles (balances,
recent transactions, etc) is usually considered conﬁdential.
The main objective of the case study is to demonstrate how
standard security policies can be applied transparently on
real world honest applications, while still blocking dishonest
variants of the same applications.

Application Bankdroid (40k lines of code) is distributed
through Google Play and is currently installed on 100.000+
devices [17]. It uses the Apache HttpClient library to com-
municate with the banks. To allow the policy to be ex-
pressed at the level of sockets (instead of at the level of the
Apache HttpClient API), the library has been included in
the client code base which adds another 60k lines of code.

Policy The policy is a Chinese-Wall policy which states
that data received from host A may be sent back to host A
but not to some other host B. As mentioned in the above
paragraph, the policy is expressed at the level of sockets
which makes it general and applicable to many other appli-
cations requiring Internet access.

Results The application was modiﬁed to leak the current
balance of each bank account to a host controlled by a po-
tential attacker. The policy was then inlined in the modiﬁed

application. When the leak was about to take place, the in-
lined code successfully terminated the execution.
8.4 Case Study 4: Auto Birthday SMS

Auto Birthday SMS is a popular application distributed
on Google Play which allows the user to automatically send
SMS-messages to friends on their birthdays.
It is free of
charge but displays ads which are retrieved over the net-
work. It requires the internet and send sms permissions.
Applications requiring this combination of permissions are
interesting to study since trojans sending premium-rate SMS
messages are relatively common [12] and could potentially
transform the phone into an SMS spamming bot. As demon-
strated in this case study, TreeDroid is useful even for hon-
est coders in order to harden their applications by inlining
generic security policies.

Application Application data, including numbers to send
messages to, are stored in a SQLite database. The code
turns out to be vulnerable to SQL-injection attacks which
can be exploited by any application with permission to mod-
ify the address book data. The code calls SQLiteDatabase.
execSQL, which updates the database, with an unsanitized
query containing the name of a contact. The contact name
should be sanitized by DatabaseUtil.sqlEscapeString be-
fore running the query.

Policy The policy applied is a general sanitize-before-query
policy stating that a query passed to execSQL must be a
string literal, a result of sqlEscapeString or a concatena-
tion of such strings. The label used for sanitized values is
encoded using an and -ﬂag to ensure that the concatenation
of sanitized and unsanitized strings are considered sanitized.
An example of an accepted FAT is found in Figure 7. Omit-
ting the call to sqlEscapeString would result in a tree which
would be rejected by the policy.

"SELECT * . . . WHERE name="

contactName

new StringBuilder

DatabaseUtil.sqlEscapeString

StringBuilder.append

StringBuilder.toString

SQLiteDatabase.execSQL

Figure 7: Accepted FAT for the SQL-policy.

Results The inlined code prevents the application from
performing queries containing unsanitized arguments, such

903as raw contact names, in the SQL statements. The original
application violates the policy upon certain user actions, in
such cases execution is successfully terminated by the mon-
itor.
8.5 Case Study 5: Lovetrap

Lovetrap is a real world SMS-trojan detected by Symantec
in July 2011 [32]. Among other bad behaviors, it sends pre-
mium rate SMS messages (which is the focus of this study).
This case study demonstrates the eﬃciency of TreeDroid on
real world attacks.

Application Lovetrap, which looks like a regular game,
starts a service which downloads a list of numbers and mes-
sages which it repeatedly tries to send by SMS.

Policy The policy from case study 1 is reused without mod-
iﬁcation, which is an indication of the policy genericness.

Results By locally redirecting requests going to the host of
the attacker to our own server, we managed to supervise the
actions of the trojan. The monitor inlining at the bytecode
level proceeds as expected without special tweaking. After
inlining, the trojan’s service is terminated immediately and
therefore no longer able to send SMS messages as intended.
8.6 Statistics

Case studies statistics have been collected in Table 4. For
applications where we have access to the source code, busi-
ness logic execution time has been measured. In Bankdroid
we measured the time it takes to update the accounts, for
DroidLocator we measured the time it takes to encrypt and
upload the location, and for Sms2Group we measured the
time it takes to collect the group information and send the
SMS. Taint tracking runtime overhead has been estimated
by TaintDroid’s authors to about 14 % on a Google Nexus
One [10]. Our measurements (signiﬁcantly higher, as ex-
pected since they are performed using Dalvik in debug mode
on an Android emulator) are included for comparison with
the runtime overhead due to the inlined code. The bytecode
size overhead in the Auto Birthday SMS study is due to the
fact that the relatively common operation of concatenating
strings is considered policy relevant.

9. CONCLUSIONS AND FUTURE WORK
The paper presents a new monitoring technique using tree
automata to track and enforce data processing constraints
in a novel way. Many security properties, which were either
diﬃcult or impossible to express using existing techniques,
can be treated. The approach is theoretically well-founded
and practical as demonstrated by the various case studies.
Usability could be further increased by using techniques
that give a formal semantics to textual policies [26, 33]. It
would allow application authors to provide usage description
of required permissions (which is a recommended good prac-
tice) that are both user-readable and from which enforceable
formal policies could be extracted.

Focus on direct ﬂows that can be tracked by taint analysis
is not a fundamental limitation of the approach. A possible
direction for future work would be to extend the program
model, notion of observable actions and policy semantics to
support indirect ﬂows (decisions inﬂuencing data process-
ing).
It should be noted, however, that no practical ap-
proaches currently exists that can provide a comprehensive

protection against covert ﬂows anyway, and so it is far from
clear that the added quality of protection oﬀered by such
an extension really motivates the additional complexity and
runtime overhead.

Concurrency poses no problems if the order of policy rel-
evant actions does not matter (as for local policies) since
each thread can be monitored in isolation. For non-local
policies, however, where the order of the actions does mat-
ter, the monitor has to synchronize the threads to exclude
schedulings that yield illegal executions. This requires in-
lined code to be executed atomically together with policy
relevant actions. This is problematic for a client-side inliner
due to the fact that there is no way to acquire a lock before
calling a method, and releasing it immediately when control
has passed into the API method. The solution is either to
release the lock after the policy relevant method has com-
pleted, i.e. use a blocking inliner [8] or restrict attention to
so-called race free policies [6].

Leveraging tree automata theory allows for reuse of ex-
isting algorithms such as automata containment and mini-
mization. Exploring these techniques further is left as future
work.

Finally, our approach could very well be used in con-
junction with existing control-ﬂow bound techniques which
would allow policies to express properties such as “if the au-
thenticate method returned true for credentials that has been
provided by the user, queries do not have to be sanitized ”.
Some techniques for linear monitoring can also naturally be
applied directly to tree based monitoring. Translating the
idea of using edit automata instead of ordinary word au-
tomata into the context of tree automata would for instance
allow us to express policies such as “whenever an unsanitized
query is about to be evaluated, sanitize it ﬁrst”.

Acknowledgments We would like to express our appreci-
ation to Tomas Andr´easson for his work on the inliner tool
and assistance in carrying out the case studies.
10. REFERENCES
[1] I. Aktug, M. Dam, and D. Gurov. Provably correct

runtime monitoring. In Proc. symp. Formal Methods,
FM’08, pages 262–277, Berlin, Heidelberg, 2008.
Springer-Verlag.

[2] K. Bierhoﬀ and J. Aldrich. Plural: checking protocol
compliance under aliasing. In Companion of the intl.
Conf. on Software engineering, ICSE Companion ’08,
pages 971–972, New York, NY, USA, 2008. ACM.
[3] K. Bierhoﬀ, N. Beckman, and J. Aldrich. Practical
API protocol checking with access permissions. In
ECOOP 2009 - Object-Oriented Programming, volume
5653 of LNCS, pages 195–219. Springer Berlin /
Heidelberg, 2009.

[4] E. Chin and D. Wagner. Eﬃcient character-level taint
tracking for Java. In Proc. work. Secure web services,
SWS ’09, pages 3–12, New York, NY, USA, 2009.
ACM.

[5] H. Comon, M. Dauchet, R. Gilleron, C. L¨oding,

F. Jacquemard, D. Lugiez, S. Tison, and M. Tommasi.
Tree automata techniques and applications. Available
on: http://www.grappa.univ-lille3.fr/tata, 2007.
release October, 12th 2007.

[6] M. Dam, B. Jacobs, A. Lundblad, and F. Piessens.

Security monitor inlining and certiﬁcation for

904multithreaded Java. To appear in Mathematical
Structures in Computer Science.

[7] M. Dam, B. Jacobs, A. Lundblad, and F. Piessens.
Security monitor inlining for multithreaded Java. In
European Conf. of Object-Oriented Computing, pages
546–569. Springer-Verlag, July 2009.

[21] J.-J. L´evy. R´eductions correctes et optimales dans le

lambda calcul. PhD thesis, Paris 7, 1978.

[22] J. Ligatti, L. Bauer, and D. Walker. Edit automata:

Enforcement mechanisms for run-time security
policies. International Journal of Information
Security, 4(1–2):2–16, Feb. 2005.

[8] M. Dam, B. Jacobs, A. Lundblad, and F. Piessens.

[23] J. Ligatti and S. Reddy. A theory of runtime

Provably Correct Inline Monitoring for Multithreaded
Java-like Programs. Journal of Computer Security,
18(1):37–59, 2010.

enforcement, with results. In Proc. of the European
Symposium on Research in Computer Security, Sept.
2010.

[9] R. Deline and M. Fahndrich. Typestates for objects.

[24] A. Lundblad and T. Andr´easson. TreeDroid: Tree

In European Conf. of Object-Oriented Computing,
volume 3086 of LNCS, 2004.

[10] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung,

P. McDaniel, and A. N. Sheth. Taintdroid: an
information-ﬂow tracking system for realtime privacy
monitoring on smartphones. In Proc. conf. Operating
systems design and implementation, OSDI’10, pages
1–6, Berkeley, CA, USA, 2010. USENIX Association.
[11] U. Erlingsson. The inlined reference monitor approach

to security policy enforcement. PhD thesis, School of
Computer Science, Reykjav´ık University, Ithaca, NY,
USA, 2004. AAI3114521.

[12] A. P. Felt, M. Finifter, E. Chin, S. Hanna, and

D. Wagner. A survey of mobile malware in the wild.
In Proc. work. Security and privacy in smartphones
and mobile devices, SPSM ’11, pages 3–14, New York,
NY, USA, 2011. ACM.

Automaton Based Policy Inlining. https:
//sites.google.com/site/treedroidcasestudies.
Accessed May 4, 2012.

[25] P. Meredith, D. Jin, F. Chen, and G. Ro¸su. Eﬃcient

monitoring of parametric context-free patterns.
Journal of Automated Software Engineering,
17(2):149–180, June 2010.

[26] S. M. Montazeri, N. Roy, and G. Schneider. From

Contracts in Structured English to CL Speciﬁcations.
In Proc. Work. Formal Languages and Analysis of
Contract-Oriented Software, volume 68 of EPTCS,
pages 55–69, M´alaga, Spain, Sept 2011.

[27] G. Ro¸su and S. Bensalem. Allen linear (interval)
temporal logic –translation to LTL and monitor
synthesis–. In Proc. intl. conf. Computer Aided
Veriﬁcation, volume 4144 of LNCS, pages 263–277.
Springer, 2006.

[13] C. Fournet and A. D. Gordon. Stack inspection:

[28] J. Saltzer and M. Schroeder. The protection of

Theory and variants. In Transactions on Programming
Languages and Systems, pages 307–318. ACM Press,
2001.

information in computer systems. Proc. of the IEEE,
63(9):1278 – 1308, sept. 1975.

[29] F. B. Schneider. Enforceable security policies. ACM

[14] M. Gandhe, G. Venkatesh, and A. Sanyal. Labeled

Trans. Inf. Syst. Secur., 3(1):30–50, Feb. 2000.

lambda-calculus and a generalized notion of strictness
(an extended abstract). In Proc., Concurrency and
Knowledge, ACSC ’95, pages 103–110, London, UK,
1995. Springer-Verlag.

[30] K. Sen, G. Rosu, and G. Agha. Generating optimal

linear temporal logic monitors by coinduction. In
Proc. Asian Computing Science Conference, pages
260–275. Springer-Verlag, 2004.

[15] I. Gartner. Gartner says sales of mobile devices in

[31] R. E. Strom and S. Yemini. Typestate: A

second quarter of 2011 grew 16.5 percent year-on-year;
smartphone sales grew 74 percent.
http://www.gartner.com/it/page.jsp?id=1764714.
Accessed February 17, 2012.

[16] S. Ghoshal, S. Manimaran, G. Ro¸su, T. F. ¸Serb˘anu¸t˘a,
and G. ¸Stef˘anescu. Monitoring IVHM systems using a
monitor-oriented programming framework. In The
Sixth NASA Langley Formal Methods Workshop (LFM
2008), 2008.

[17] Google, Inc. Google play: Bankdroid.

https://play.google.com/store/apps/details?id=
com.liato.bankdroid. Accessed April 23, 2012.

programming language concept for enhancing software
reliability. IEEE Trans. Softw. Eng., 12(1):157–171,
Jan. 1986.

[32] Symantec Corporation. Android.lovetrap.

http://www.symantec.com/security_response/
writeup.jsp?docid=2011-072806-2905-99. Accessed
May 3, 2012.

[33] R. Thion and D. Le M´etayer. FLAVOR: A formal

language for a posteriori veriﬁcation of legal rules. In
Proc. Symp. Policies for Distributed Systems and
Networks, pages 1–8. IEEE Computer Society, June
2011.

[18] V. Haldar, D. Chandra, and M. Franz. Dynamic taint

[34] O. Tripp, M. Pistoia, S. J. Fink, M. Sridharan, and

propagation for Java. In Proc. Annual Computer
Security Applications Conf., pages 303–311, 2005.

[19] K. W. Hamlen and M. Jones. Aspect-oriented in-lined

reference monitors. In Proc. work. Programming
Languages and Analysis for Security, pages 11–20,
Tucson, Arizona, June 2008.

[20] K. W. Hamlen, G. Morrisett, and F. B. Schneider.
Certiﬁed in-lined reference monitoring on .NET. In
Proc. work. Programming languages and analysis for
security, PLAS ’06, pages 7–16, New York, NY, USA,
2006. ACM.

O. Weisman. TAJ: Eﬀective taint analysis of web
applications. In Proc. Programming language design
and implementation, PLDI ’09, pages 87–97, New
York, NY, USA, 2009. ACM.

[35] T. Vidas, D. Votipka, and N. Christin. All your droid
are belong to us: A survey of current android attacks.
In WOOT, pages 81–90, 2011.

[36] D. S. Wallach, A. W. Appel, and E. W. Felten.

SAFKASI: a security mechanism for language-based
systems. ACM Trans. Softw. Eng. Methodol.,
9(4):341–378, Oct. 2000.

905