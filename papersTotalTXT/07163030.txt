2015 IEEE Symposium on Security and Privacy
2015 IEEE Symposium on Security and Privacy

Geppetto: Versatile Veriﬁable Computation

Craig Costello C´edric Fournet
Benjamin Kreuter† Michael Naehrig Bryan Parno
† University of Virginia

Jon Howell Markulf Kohlweiss
Samee Zahur†

Microsoft Research

Abstract

Cloud computing sparked interest in Veriﬁable Computation
protocols, which allow a weak client to securely outsource com-
putations to remote parties. Recent work has dramatically re-
duced the client’s cost to verify the correctness of their results,
but the overhead to produce proofs remains largely impractical.
Geppetto introduces complementary techniques for reducing
prover overhead and increasing prover ﬂexibility. With Multi-
QAPs, Geppetto reduces the cost of sharing state between com-
putations (e.g., for MapReduce) or within a single computation
by up to two orders of magnitude. Via a careful choice of cryp-
tographic primitives, Geppetto’s instantiation of bounded proof
bootstrapping improves on prior bootstrapped systems by up
to ﬁve orders of magnitude, albeit at some cost in universality.
Geppetto also efﬁciently veriﬁes the correct execution of propri-
etary (i.e., secret) algorithms. Finally, Geppetto’s use of energy-
saving circuits brings the prover’s costs more in line with the
program’s actual (rather than worst-case) execution time.

Geppetto is implemented in a full-ﬂedged, scalable compiler
and runtime that consume LLVM code generated from a variety
of source C programs and cryptographic libraries.

1 Introduction

The recent growth of mobile and cloud computing makes out-
sourcing computations from a weak client to a computationally
powerful worker increasingly attractive economically. Verify-
ing the correctness of such outsourced computations, however,
remains challenging, as does maintaining the privacy of sen-
sitive data used in such computations, or even the privacy of
the computation itself. Prior work on verifying computation
focused on narrow classes of computation [32, 51], relied on
physical-security assumptions [41, 47], assumed uncorrelated
failures [19, 20], or achieved good asymptotics [2, 28, 30, 31,
33, 38, 44] but impractical concrete performance [46, 50].

Recently, several lines of work [9, 46, 49, 52] on veriﬁable
computation [28] have combined theoretical and engineering in-
novations to build systems that can verify the results of general-
purpose outsourced computations while making at most cryp-
tographic assumptions. Two of the best performing, general-
purpose protocols for veriﬁable computation [46, 49] are based
on Quadratic Arithmetic Programs (QAPs) [29]. To provide
non-interactive, publicly veriﬁable computation, as well as
zero-knowledge proofs (i.e., proofs of computations in which

© 2015, Craig Costello. Under license to IEEE.
© 2015, Craig Costello. Under license to IEEE.
DOI 10.1109/SP.2015.23
DOI 10.1109/SP.2015.23

253
253

some or all of the worker’s inputs are private), many recent sys-
tems [3, 7, 9, 10, 16, 25, 39, 54] have converged on the Pinoc-
chio protocol [46] as a cryptographic back end. Pinocchio, in
turn, depends on QAPs.

While these protocols have made veriﬁcation nearly practical
for clients, the cost to generate a proof remains a signiﬁcant
barrier to practicality for workers.
Indeed, most applications
are constrained to small instances, since proof generation costs
3–6 orders of magnitude more than the original computation.

With Geppetto1, we combine a series of interlocked tech-
niques that support more ﬂexible, and hence more efﬁcient,
provers. These techniques include the new notion of Multi-
QAPs for sharing state between or within computations,
bounded bootstrapping for succinct proof aggregation, a QAP-
friendly C library for verifying cryptographic computations,
and a new technique for energy-saving circuits, which ensures
the prover’s costs grow with actual execution time, rather than
worst-case execution time.

In more detail, we ﬁrst generalize QAPs to create MultiQAPs,
which allow the veriﬁer (or prover) to commit to data once and
then use that data in multiple related proofs. For example, the
prover can commit to a data set and then use it in many differ-
ent MapReduce jobs. At a ﬁner granularity, we show how to use
MultiQAPs to break an arithmetic circuit up into many smaller,
simpler veriﬁable circuits that efﬁciently share state. Today,
compiling code from C to a QAP typically requires unrolling
all loops and inlining all functions, leading to a huge circuit
full of replicated subcircuit structures. Since key size, and key
and proof generation time all depend linearly (or quasilinearly)
on the circuit size, this blowup severely degrades performance.
With MultiQAPs, instead of unrolling a loop, we can create a
single circuit for the loop body, use a proof for each iteration
of the loop, and connect the state at the end of each iteration
to the input of the next iteration. This allows us to shrink key
size and key generation time, and, more importantly, to save
the prover time and memory. Prior work suggested achieving
similar properties via Merkle hash trees [8, 12, 27, 29, 43], but
implementations show that this approach increases the degree
of the QAP by tens or hundreds per state element [9, 16, 54],
whereas with MultiQAPs, the degree increases only by 1.

With MultiQAPs, the prover generates multiple proofs about
related data. This improves ﬂexibility and performance for the
prover, but it degrades attractive features of Pinocchio, namely
that the proof consists of a (tiny) constant-sized proof, and the
veriﬁer’s work scales only with the IO.

1A skilled craftsman who can create and coordinate many Pinocchios.

As a second contribution, we explore the use of bounded
proof bootstrapping to obtain MultiQAPs with constant-sized
proofs. In theory, with proof bootstrapping [11, 53], the prover
can combine any series of proofs into one by veriﬁably com-
puting the veriﬁcation of all of those proofs. Very recent work
elegantly instantiates unbounded proof bootstrapping [9], but
this generality comes at a cost (§5,§7.3.1). Our instantiation and
implementation of bounded proof bootstrapping shows that, as
with semi-homomorphic vs. fully homomorphic encryption, if
we pragmatically set a bound on the number of proofs we intend
to combine, we can achieve more practical performance.

To support bounded proof bootstrapping, Geppetto includes a
QAP-friendly C library for general-purpose cryptographic com-
putations. Such computations arise in many outsourcing appli-
cations. For instance, a MapReduce job may need to compute
over signed data, or a customer with a smart meter may wish to
privately compute a bill over signed readings [48]. As another
example, recent work [7, 25] shows how to anonymize Bitcoin
transactions using Pinocchio [46] and would beneﬁt from the
ability to verify signatures within transactions. In existing QAP
systems, computations take place over a relatively small (e.g.,
254-bit) ﬁeld, so computing cryptographic operations (e.g., a
signature veriﬁcation) requires an awkward embedding of the
cryptographic machinery via either a BigInteger library built
out of ﬁeld elements or via large extension ﬁelds [25]. With
our techniques, all of these examples can be naturally and efﬁ-
ciently embedded into a proof of an outsourced computation.

By considering (bounded or unbounded) bootstrapping in the
context of our QAP-friendly crypto library, we show how to ef-
ﬁciently compile and outsource computations so that the com-
putation itself is hidden from the veriﬁer. For example, a patient
might verify that a trusted authority (say the US FDA) signed
the code for a medical-data analysis, and that the analysis was
correctly applied to the patient’s data, without the patient ever
learning anything about the proprietary analysis algorithm. Pre-
vious systems could potentially support this scenario via univer-
sal circuits [46, 49] or circuits executing CPU instructions [9],
but the extra level of interpretation potentially slows the com-
putation down by orders of magnitude (see §7.3.1).

Lastly,

just as MultiQAPs eliminate the redundancy that
comes from code repetition (e.g., in the form of loops or func-
tion invocations), we introduce the notion of energy-saving cir-
cuits to eliminate the redundant work that arises from code
branching. With energy saving, the prover only exerts crypto-
graphic effort for the actual path taken (e.g., only the ‘if’ branch
when the condition is true). While energy-saving circuits are
generally useful, they are particularly beneﬁcial when using
bounded proof bootstrapping to combine many proofs from a
MultiQAP. Such proof compaction requires the key generator
to commit, in advance, to the maximal number of proofs to
be combined. With energy saving circuits, the key generator
can choose a large number, and if a particular computation re-
quires fewer proofs, the prover only performs cryptographic op-
erations proportional to the number of proofs used, rather than
the maximum chosen by the key generator.

We have implemented Geppetto as a complete toolchain for
verifying the execution of C programs. Geppetto’s code is avail-

F

F0

(1)
F1

(8)
F1

...

F0

F1

F2

(a)

F2

(b)

F

s
e
s
u
b

F1

F0

F2

(c)

Figure 1: MultiQAPs (a) Most existing veriﬁable computation sys-
tems compile programs to a single large circuit-like representation,
leading to internal redundancy. (b) By extracting common substruc-
tures, we can represent a program as an assembly of smaller circuits,
but the veriﬁer must now also check all connections between circuits.
(c) MultiQAPs connect circuits using bus structures that support suc-
cinct and efﬁcient commitments to the bus values.

able at https://vc.codeplex.com.
It includes a compiler
in F#, a cryptographic runtime in C++, QAP-friendly libraries
in C, and various programming examples. Our compiler takes
as input LLVM code produced by clang, a mainstream state-of-
the-art optimizing C compiler; this enables us to focus on QAP-
speciﬁc compilation. Our libraries support explicit, low-level
control for programming MultiQAPs, allowing the C program-
mer to dictate how state ﬂows from one QAP to another and
hence control the resulting cryptographic costs. Geppetto also
provides higher-level C libraries for common programming pat-
terns, such as MapReduce or loops.

2 Geppetto Overview

In this section, we give an overview of Geppetto’s main con-
structions: MultiQAPs (§2.1), proofs for cryptographic op-
erations and bootstrapping (§2.2), and energy-saving circuits
(§2.3). We defer cryptographic deﬁnitions to §3 and our pro-
tocol to §4.

2.1 MultiQAPs
2.1.1 MultiQAP Intuition

At a high level, prior veriﬁable computation systems like Pinoc-
chio [46] allow a prover to convince a skeptical veriﬁer that
F(u) = y, where u is a veriﬁer-supplied vector of inputs. The
prover accomplishes this with a constant-sized proof π, and the
veriﬁer’s work scales linearly in |u| +|y|, regardless of the com-
plexity of F. However, as F grows to encompass larger and
more complex functionality (see Figure 1), the CPU and mem-
ory costs for the prover (as well as its key size) increase su-
perlinearly. As §7.2 shows, this limits prior systems to modest
application parameters.

254254

To scale to larger problems, we can naturally decompose the
proof of F into a conjunction of proofs of m simpler functions
F0, . . . , Fm−1. For example, if F(u) = F1(F0(u)), then na¨ıvely
the prover could use Pinocchio twice to prove:

z = F0(u)
y = F1(z)

(0)
(1)

The veriﬁer would check a proof for each equation separately
and check that the output from F0 was correctly used as input
to F1. Unfortunately, this means that the prover must send the
intermediate state z to the veriﬁer, and the veriﬁer must perform
work linear in |z|. If z is large, then handling so much interme-
diate state would make it difﬁcult or impossible for the veriﬁer
to beneﬁt from outsourcing.

Instead, with Geppetto, we have the prover return a constant-
sized digest, Dz, representing the intermediate state z. The ver-
iﬁer uses this digest when checking the proof for Equation (0)
and when checking the proof for Equation (1), ensuring that
the prover consistently used the same intermediate state in both
proofs, but without requiring the veriﬁer to explicitly handle z.
Prior work achieved a similar reduction in veriﬁer effort by
extending F0 to hash its output and F1 to hash its input, so the
veriﬁer need only handle the constant-sized hash value [8, 12,
29, 43]. However, those hash computations make both functions
more expensive [9, 16]. In contrast, with Geppetto, we observe
that Pinocchio already computes a digest-like structure and that,
with a careful reﬁnement of its encoding, we can have the prover
compute digests almost for free.2

In more detail, we divide all of the variables used to com-
pute F into disjoint sets we call banks. Each bank falls into one
of three categories: a bank may represent F’s (the overall com-
putation’s) input and output (u and y in our earlier example); it
may represent a set of ‘local’ variables used within a single Fi;
or it may be a bus, i.e., a set of variables shared between multi-
ple Fi (e.g., z).

Each bank is associated with its own cryptographic key ma-
terial, used to compute a succinct digest of the values assigned
to the bank’s variables: the prover produces a digest for each
local bank and for each bus, while the veriﬁer produces a digest
for the IO banks as part of the veriﬁcation process. The latter
ensures that the proof veriﬁcation is with respect to the input the
veriﬁer supplied, and the alleged output the prover produced.

To verify a proof that a given Fi was computed correctly, the
veriﬁcation algorithm will need a digest for Fi’s local bank, and
digests for any buses or IO banks that Fi reads or writes. Con-
tinuing our earlier example, the veriﬁer computes IO digests Du
and Dy. The prover computes and returns digests DF0 and DF1
summarizing the intermediate variables used by F0 and F1 re-
spectively, and a single digest Dz representing the values on the
bus between them. He also returns proofs π0 and π1 to demon-
strate that F0 and F1 were computed correctly. The veriﬁer runs
the veriﬁcation algorithm twice:
Verify((Du,DF0
Verify((Dz,DF1

,Dz),π0)
,Dy),π1)

(2)
(3)

2We use ‘digest’ rather than ‘commitment’, since only some of the digests

need to be binding—see §3.1.

255255

F;F0, . . . ,Fm−1 Function F is decomposed into m functions Fi
= |B|

Formal variables used when computing F
A partition of χχχ into banks Bb ∈ B with (cid:2)
An instance tb of bank Bb;
Commit-and-prove message for bank Bb (Defn. 2)
= |σ|
(cid:3)
A proof schedule (Defn. 1) with length n
The MultiQAP Q(cid:3), combining sub-QAPs Qi
A QAP has size ρ and degree d

χχχ
B, (cid:2)
B(tb)
b
χb
σ, n
Q(cid:3), Qi
ρ,d

(cid:3)

Figure 2: Notation summary for §2.

and accepts y as F(u) if both checks succeed.3 Note that Dz oc-
curs in both veriﬁcation checks. Formally, a system that allows
a prover to commit to state in this fashion and use the result-
ing commitments in multiple proofs is known as a commit-and-
prove (CP) scheme (see §3.1).

As shown in Figure 1, proofs of complex functions F may in-
volve multiple instances of a simpler function Fi. For example,
Fi may represent the execution of a single function call, or a sin-
gle loop iteration in F. Each instance of Fi requires the prover
to generate (and the veriﬁer to check) a fresh proof, along with
digests for the banks involved. In §2.1.2, we formalize these
relationships with a proof schedule (Defn 1); each step in the
schedule indicates which Fi is “active”, which banks it depends
on, and which set of bank values this particular instance of Fi
depends on.

To efﬁciently build a commit-and-prove system supporting
such schedules, we use Pinocchio’s techniques to express each
function Fi as a Quadratic Arithmetic Program (QAP) Qi, a for-
mat suitable for succinct cryptographic proofs. To share state
between individual Qi, we combine them into a single Multi-
QAP Q(cid:3) that also efﬁciently incorporates the buses connecting
them. Using a MultiQAP also simpliﬁes our deﬁnitions, con-
structions, and security proofs.
In particular, we can repeat-
edly use a commit-and-prove scheme for a single relation for all
proof schedules composed of different Qi steps, with the abil-
ity to share compact, private digests between the proof steps.
MultiQAPs support this functionality without signiﬁcantly in-
creasing the prover’s costs beyond what is required to handle
each sub-QAP of the schedule individually.

2.1.2 Scheduling Proofs With Shared State
As described in §2.1.1, we decompose the proof of a complex
function F into a conjunction of proofs of m simpler functions
F0,. . . ,Fm−1.4 Let χχχ represent all of the formal variables used
when computing F; this includes F’s input and output variables,
variables “local” to the computation of each Fi, and the variables
shared across the Fi. Based on these different roles, we partition
χχχ into banks Bb ∈ B.
A given execution of F may involve several instances of the
same bank (e.g., if Fi represents a loop body, then the banks
,π0) the proof for

3This approach generalize’s Pinocchio’s, which calls (DF0

F0 and has the veriﬁer compute Du and Dz inside the veriﬁcation algorithm.

4Cryptographers think of F as a language, and F’s IO as a language instance.
Programmers may see this proof as a trace-property, e.g., interpreting u,y as a
valid input-output sequence obtained by running a program whose speciﬁcation
is captured by F.

(cid:3)

(cid:3)

corresponding to its IO and local variables may take on differ-
ent concrete values on each loop iteration). We refer to these
distinct instances of bank Bb as B(tb)
for tb = 1,2, . . . reserving
b
tb = 0 for the instance that assigns the constant 0 to every vari-
able in Bb. With these notations (summarized in Figure 2), we
can deﬁne proof schedules.
Deﬁnition 1 (Multi-proof schedule) A schedule σ is a se-
quence of steps of the form (i,t) where i ∈ [m] and t is a vector
with an index tb ≥ 0 for each bank Bb ∈ B. We deﬁne n
= |σ| to
= |B| the number of banks.
be the length of the schedule, and (cid:2)
Each step (i,t) of the schedule selects a function Fi and the
instances B(tb)
of the banks it uses, with tb = 0 whenever Fi does
b
not use Bb. We require that Fi use only its local bank BFi, that
is, tFj
A proof for σ consists of (1) a proof πi for each of its steps,
and (2) a digest D(t)
b

for each of its bank instances B(t)
b .

= 0 whenever i (cid:5)= j.

Intuitively, the schedule indicates a sequence of calls to Fis
for which the prover must generate (or the veriﬁer must check)
a proof, and the indexes t of the banks digests that the prover
(or the veriﬁer) should use with that proof. The variables in any
banks not used in a given step are implicitly set to 0 and hence
can be represented with a trivial digest.
Returning to our example from §2.1.1, we have B = (Bu,By,
,Bz) and the schedule for Equations (0) and (1) would
,BF1
BF0
be σ = [(0, (1,0,1,0,1)), (1, (0,1,0,1,1))].

2.1.3 An Efﬁcient CP System from MultiQAPs

To understand Geppetto’s MultiQAPs, it helps to review how
Pinocchio encodes computations as QAPs. This encoding en-
ables Pinocchio’s efﬁcient cryptographic protocol.

Quadratic Arithmetic Programs (QAPs)
[29, 46] Ab-
stractly, Pinocchio compiles a function F into a conjunction of
d equations of the form
(cid:2)

(4)

Q(χχχ)

(cid:3)
=

(vr ·χχχ)(wr ·χχχ) = (yr ·χχχ)

r∈[d]

where χχχ is the vector of F’s variables, which range over some
large, ﬁxed prime ﬁeld Fp, and the vectors vr, wr, yr each de-
ﬁne linear combinations over the variables χχχ. Each equation
(indexed by r) can be thought of as encoding a two-input mul-
tiplication gate in the arithmetic circuit computing F, with vr
indicating each variable’s contribution (if any) to the gate’s left
input, wr indicating each variable’s contribution to the gate’s
right input, and yr indicating the variable’s relation to the gate’s
output. We say that Q has size ρ (cid:3)

= |χχχ| and degree d.

Crucially, Pinocchio’s evaluation key (used by the prover to
create his proof) contains cryptographic key material for each
variable χ ∈ χχχ, and the structure of that key material depends
directly on which (and how) χ participates in each of the d equa-
tions in Equation (4), i.e., on the value of χ’s entry in each of
the vectors vr, wr, yr.

From QAPs to MultiQAPs
If we decompose F into sim-
pler functions Fi, then we can create a corresponding QAP Qi

for each Fi. Suppose we wish to connect Q0, which has some
variables z0 representing F0’s output, with Q1, which has some
variables z1 representing F1’s input, with |z0| = |z1|. Since F0
and F1 are different functions, z0 and z1 undoubtedly participate
in different equations in Q0 and Q1, and hence, as explained
above, will have different key material representing z0 and z1.
As a result, a digest for z0 will be completely different from a
digest for z1, even if z0 = z1! We could ﬁx this by combining Q0
and Q1 into a single QAP and adding equations requiring that
z0 = z1, but then we lose the beneﬁts we hoped to gain from
decomposing F.

Instead, we combine all of the (Qi)i∈[m] into a single Multi-
QAP Q(cid:3). Q(cid:3) has the same equations and variables χχχ used in
the Qi. In addition, for each variable s that we wish to share
between some subset ˆQ of the Qi, we add a new variable ˆs to a
new bus bank associated with ˆQ, and we add an equation relat-
ing ˆs to the local copy of s in each of the Qi in ˆQ. Continuing
our earlier example, we will introduce a new bus for variables
ˆz with | ˆz| = |z0| = |z1|, and for each ˆz in ˆz, we will add an
equation:

z0 + z1 = ˆz

(5)
relating it to the corresponding variables in Q0 and Q1. By
adding the ˆz bus as a layer of indirection, it no longer matters if
z0 is used differently in Q0 than z1 is in Q1; the prover can cre-
ate a single digest Dˆz representing the values on the bus, and the
veriﬁer can use this digest when checking the correct execution
of Q0, as well as that of Q1, just as in the example in §2.1.1,
when computing Equations (2) and (3). Because the veriﬁer
only accepts proof schedules with trivial digests for all other
local banks (Deﬁnition 1), when she veriﬁes a proof of Q0, all
of the variables in Q1 are set to 0, and hence Equation (5) says
that z0 = ˆz, whereas when she veriﬁes a proof of Q1, all of the
variables in Q0 are set to 0, and hence (5) says that z1 = ˆz.
If we follow these steps to combine m sub-QAPs (Qi)i∈[m],
each of size ρi and degree at most d, along with the buses
connecting them, into a single MultiQAP Q(cid:3), then Q(cid:3) has size
ρ(cid:3) = |s| + ∑i∈[m] ρi and degree d(cid:3) = d +|s|, where s includes
all intermediate variables shared between the Qi. By choosing
a decomposition from F to (Fi)i∈[m] that exploits the structure
of F, Geppetto’s compiler can ensure that most variables are lo-
cal to one Fi, so we typically achieve |s| << d. Since each step
in a proof schedule considers only one Qi at a time, the size and
degree of the “active” QAP within Q(cid:3) is only slightly larger
than the original Qi. Thus, MultiQAPs enable state sharing
across sub-QAPs without signiﬁcantly increasing the prover’s
costs beyond what is required to handle the sub-QAPs of the
schedule individually.

2.1.4 Other Techniques for Stateful Computations

Prior work explores other, largely complementary mechanisms
for handling veriﬁable computations over state. As discussed in
§2.1.1, a classic way to condense state is to commit to it via a
hash [8, 12, 29, 43]. When specifying the IO to a function F,
the veriﬁer only gives the hash value h = H(u). The prover
supplies the full data values and, as part of the veriﬁable com-
putation, hashes the data and proves that the hash matches the

256256

one supplied by the veriﬁer. A recent system, Pantry [16], im-
plements such collision-resistant hashing on top of the existing
QAP-based Pinocchio [46] and Zaatar protocols [49].
As shown in §7.2, using MultiQAPs is much cheaper than
hashing when all (or most) of the state will be used in a given
computation. Thus, MultiQAPs will typically be advantageous
when passing state between computations, such as between
mappers and reducers in a MapReduce job or within a decom-
posed program such as the one shown in Figure 1, since a good
compiler will ensure that state is passed between computations
only if both computations actually need it. MultiQAPs are also
advantageous for IO when the veriﬁer’s inputs can be split in
two pieces, a (mostly) static and a dynamic portion, that inter-
act in each computation. For example, we might see this pattern
if the computation takes in a large dataset and a small query, and
the query needs to veriﬁably compute on most of the dataset.

In contrast, hashing is advantageous when the inputs are
large, but the veriﬁable computation only accesses a small por-
tion of the input at a time. For example, if the computation is
over a large database but any given computation only selects a
handful of records, then hashing makes sense. Hashing is also
suitable for transferring state between veriﬁable computations
performed with keys created by mutually distrusting parties.

As an orthogonal contribution, Pantry uses hashes to build
a RAM abstraction based on Merkle trees [43], though subse-
quent work [10, 54] suggests that handling RAM via memory
routing networks [8] performs better for most memory sizes.
Regardless, these techniques are orthogonal to Geppetto in the
sense that they focus on dynamic RAM access within a com-
putation/QAP, rather than on transferring state between com-
putations. Indeed, routing networks would likely be the most
efﬁcient way to allow a given Geppetto sub-QAP to incorpo-
rate a RAM abstraction. Recent work demonstrates [54] that
such abstractions can be naturally integrated with Geppetto’s
compilation-based approach.

Finally, in concurrent work, Backes et al. modify the Pinoc-
chio protocol to incorporate a linearly homomorphic MAC in
order to optimize computing on authenticated data [3]. Using
signed Geppetto commitments offers an alternate approach; we
defer evaluating the tradeoffs to future work.

2.2 Veriﬁable Crypto and Bootstrapping Proofs
In theory, we should be able to verify cryptographic compu-
tations (e.g., a signature veriﬁcation) just like any other com-
In practice, as discussed in §1, a naive embedding
putation.
of cryptographic computations into the ﬁeld Fp that our Mul-
tiQAPs operate over leads to signiﬁcant overhead. In §5, we
use a careful choice of cryptographic primitives and parameters
to build a large class of crypto operations (e.g., signing, ver-
iﬁcation, encryption) using elliptic curves built “natively” on
Fp. For example, this makes it cheap to verify computations on
signed data, since the data and the signature both “live” in Fp.
Prior work used such tailoring for unbounded bootstrapping [9]
and hashing [9, 16].

Our most complex application of this technology is a form
of proof bootstrapping [11, 53], which we use to address the

main drawback of CP schemes. With CP schemes, includ-
ing our MultiQAP-based scheme, the size of the cryptographic
evidence—and the veriﬁer costs—grow linearly with the num-
ber of digests and proofs. While often acceptable in practice,
these costs can be reduced to a constant by using another in-
stance of our CP scheme to outsource the veriﬁcation of all of
the cryptographic evidence according to a target proof schedule.
More formally, let Verifyσ(cid:3)(D,Π) be the function checking
that a scheduled CP proof cryptographically veriﬁes, where D
and Π are the collections of digests and proofs used in the
schedule σ(cid:3). We recursively apply Geppetto to generate a
quadratic program Qσ(cid:3) for Verifyσ(cid:3). This yields another, more
◦
σ(cid:3) (D◦,π◦) with a single, constant-sized
efﬁcient veriﬁer Verify
digest D◦ of D, Π, and all intermediate variables used to verify
them according to σ(cid:3), and with a single constant-sized proof π◦
to verify, now in constant time.

◦
σ(cid:3) need not be limited to just
verifying the execution of Verifyσ(cid:3). For example, suppose an
authority the client trusts (e.g., the US FDA) cryptographically
◦
signs the veriﬁcation keys for Verifyσ(cid:3), and we deﬁne Verify
σ(cid:3)
to ﬁrst verify the signature on the keys before using them to
run Verifyσ(cid:3). If we use Geppetto’s option to make digests and
proofs perfectly hiding, then the veriﬁer checks a constant-sized
proof and learns that a trusted algorithm (for example, a medical
diagnosis) ran correctly over her data, but she learns nothing
about the algorithm. Thus, a client can efﬁciently and veriﬁably
outsource computations with proprietary algorithms.

We further observe that Verify

Although the general

idea of bootstrapping is well-
known [11, 53], its practicality relies on careful cryptographic
choices to support an efﬁcient embedding. Recent work [9] in-
stantiated and implemented an embedding that supports boot-
strapping an unbounded number of proofs but this generality
comes at a cost (§5).
In §5, we explore a pragmatic alternative that supports only
bounded-length schedules but can achieve better performance.
Intuitively, the construction is based on the observation that the
◦
algorithm Verify
σ(cid:3) described above, can itself be scheduled and
bootstrapped. In other words, given an initial CP scheme P ,
we deﬁne a second CP scheme P (cid:7) that veriﬁes a schedule for
P of length at most L. If our application requires a schedule
longer than L, we can deﬁne a third CP scheme P (cid:7)(cid:7) that con-
denses digests and proofs from P (cid:7). With enough levels, we can
ensure that the veriﬁer only receives a constant-sized digest and
proof, and hence only performs work linear in the overall com-
putation’s IO, regardless of how the prover decomposes F into
smaller functions. The overall protocol can be thought of as
a tree of proof schedules, where the arity of each node is L,
and as we move towards the root of the tree, each level con-
denses the digests and proofs from the nodes above it. Our full
paper [23] formalizes this process, adapting the usual proof-of-
a-proof bootstrapping techniques [11, 53].

Using multiple levels reduces both the key sizes and the
prover’s work. For example, suppose the application produces
N proofs for P . The na¨ıve approach of using a single recursive
level P (cid:7) would require a key capable of consuming all N proofs.
√
Instead, with multiple levels, we can design P (cid:7) to consume
N
proofs from P and design P (cid:7)(cid:7) to consume
N proofs from P (cid:7).

√

257257

cond

inputs

1-cond

cond

inputs

1-cond

if

circuit
×

else
circuit
×

+
++
+
outputs

×
if

circuit

×
else
circuit

+
++
+
outputs

Figure 3: Energy-Saving Circuits. Moving the multiplex step can
nullify expensive crypto operations, since at runtime, in one of the two
circuit blocks, every wire inside takes on the value zero.

√
N), instead of size N for a single
The resulting keys will be O(
recursive layer.
Our CP deﬁnitions and theorems (§3), as well as our compiler
(§6.4), support multiple-levels of bootstrapping through such
recursion. For example, our compiler (§6.4) rewrites source
programs to replace outsourced function calls by proof veriﬁ-
cation and can be called on its own output.

2.3 Energy-Saving Circuits
Existing veriﬁable computation systems represent a computa-
tion as a quadratic program (informally, a circuit), which results
in a program whose size reﬂects the worst-case computational
resources necessary over all possible inputs. For instance, when
branching on a runtime-value, Pinocchio’s prover interprets and
proves both branches and only then joins their results. Con-
cretely, the command if(b) {x = y} else {x=2*z} is ef-
fectively compiled as x = 2z + b*(y-2z), as shown generi-
cally in the left side of Figure 3. Similarly, if a loop has a static
bound of N iterations, the prover must perform work for all N,
even if the loop typically exits early.

Ideally, we would like to “turn off” parts of the circuit that
are not needed for a given input, much the same way hardware
circuits can power down parts not currently in use. Geppetto
achieves this by observing that in our cryptographic protocol,
there is no cryptographic cost for QAP variables that evalu-
ate to zero (however these variables still increase the degree of
the QAP, and hence the cost of the polynomial operations the
prover performs). Thus, if at compile-time we ensure that all
intermediate variables for the branch evaluate to 0 in branches
that are not taken, then at run-time there is no need to evalu-
ate those branches at all. The right side of Figure 3 shows an
example of how we achieve this for branches by applying the
condition variable to the inputs of each subcircuit, rather than
to the outputs. Thus, in contrast with Pinocchio, the prover only
does cryptographic work proportional to the path actually taken
through the program.

Prior compilers [49] use a related technique that applies the
condition variable to the equations in each branch, rather than to
the inputs. This avoids the need to interpret untaken branches,
but produces more constraints than Geppetto in the common

258258

case when the branch contains more equations than inputs.
§6.5 explains how our compiler produces energy-saving cir-
cuits, while §7.4 quantiﬁes the signiﬁcant savings we recoup via
this technique.

3 Deﬁning Proof Composition
We now give formal cryptographic deﬁnitions for the concepts
introduced in §2, deferring our concrete protocol to §4.

3.1 Commit-and-Prove Schemes
As discussed in §2.1.1, Geppetto employs three types of digest,
one for F’s IO, one for the local variables for each Fi, and one
for each bus. Each digest, D, may hide the values it represents
via randomness o. Without hiding, we use a trivial opening
o = 0 (and may omit it). We require that all digests of bus values
be binding, as otherwise the prover could, say, use one set of
values for the bus when proving that F0 correctly wrote to the
bus, while using a different set of values when proving that F1
correctly read from the bus. In contrast, digests used only in a
single proof, e.g., for intermediate local variables, need not be
binding, since the veriﬁer only needs to know that there exists
an assignment of values to those variables corresponding to a
single correct execution. Finally, digests of IO naturally need
not be binding since the veriﬁer computes them herself.

As a side note, while Geppetto uses commit-and-prove
schemes to prove function executions, such schemes also en-
able interactive protocols where values are committed, used in
proofs, and opened dynamically. For instance, they easily inte-
grate with existing Σ-protocols as employed in anonymous cre-
dential systems [5, 17].

Since we are interested in succinct proofs, we modify earlier
deﬁnitions of commit-and-prove schemes [18, 26, 37] to only
consider computationally bounded adversaries. As a succinct
digest implies that more than one plaintext maps to a given di-
gest value, an unbounded adversary can always “escape” the
digest’s binding property.

Each MultiQAP Q(cid:3) in our construction deﬁnes a relation R
from the family R of all MultiQAPs over a ﬁxed ﬁeld F. As
our security deﬁnition has a security parameter λ ∈ N (which
intuitively determines the size of the ﬁeld F), we actually talk
about a sequence of families of polynomial-time veriﬁable rela-
tions {R λ}λ∈N.
Deﬁnition 2 (Succinct Commit-and-Prove) Consider (cid:2)-ary
polynomial-time veriﬁable relations {R λ}λ∈N on tuples χχχ of
a ﬁxed length (cid:2).
A succinct commit-and-prove scheme P = (KeyGen =
(KeyGen1, KeyGen2), Digest, Prove, Verify) for {R λ}λ∈N con-
sists of ﬁve polynomial-time algorithms as follows:
• Key generation is split into two probabilistic algorithms:
τ ← KeyGen1(1λ) takes the security parameter λ as input
and produces a trapdoor τ = (τS ,τE ) (independent of R
and consisting of a simulation and extraction component).
(EK,VK) ← KeyGen2(τ,R) takes the trapdoor and a rela-
tion R ∈ R λ as input and produces a public evaluation key

b

,o(t)
b

← Digest(EKb,χ(t)

EK and a public veriﬁcation key VK. To simplify notation,
we assume that EK includes a copy of VK, and that EK
and VK include digest keys EKb and VKb for b ∈ [(cid:2)].
• D(t)

): Given an evaluation key for
b
b, message instance t for b (χ(t)
b ), and corresponding ran-
domness o(t)
b , the deterministic digest algorithm produces
b of χ(t)
a digest D(t)
b .
• π ← Prove(EK,χχχ,o): Given an evaluation key, messages
χχχ ∈ R, and openings o, the deterministic prove algorithm
returns a succinct proof π; i.e., |π| is poly(λ).
• {0,1} ← Verify(VKb,D(t)
): Given a veriﬁcation key for b,
the deterministic digest-veriﬁcation algorithm either re-
jects (0) or accepts (1) the digest D(t)
b .
• {0,1} ← Verify(VK,D,π): Given a veriﬁcation key and (cid:2)
digests D, the deterministic veriﬁcation algorithm either
rejects (0) or accepts (1) the proof π.

b

Proof-veriﬁcation guarantees apply only when each digest D(t)
b
in D either passes the digest-veriﬁcation algorithm or was com-
puted directly by the veriﬁer.

We deﬁne two security requirements below. Standard deﬁ-
nitions for correctness and zero-knowledge are in the full pa-
per [23]. First, we require that digests shared across multiple
proofs (i.e., those representing bus values) be binding, meaning
the prover cannot claim the digest represents one set of values in
the ﬁrst proof and a different set of values in the second proof.
We collect the indexes of their keys in what we call the binding
digest subset S ⊂ [(cid:2)].

Deﬁnition 3 (Binding) The commit-and-prove scheme P is
binding for (cid:2)-ary relations {R λ}λ∈N and binding digest sub-
set S ⊂ [(cid:2)], if for all efﬁcient A and any R ∈ R λ,

Pr[

τ ← KeyGen1(1λ);τ = (τS ,τE );
(EK,VK) ← KeyGen2(τ,R);
(cid:7)(cid:3) ← A(EK,R,τE ) :
(cid:2)
b,χ,o,χ(cid:7),o
χ (cid:5)= χ(cid:7) ∧ b ∈ S ∧
Digest(EKb,χ,o) = Digest(EKb,χ(cid:7),o

(cid:7))

] = negl(λ).

Second, we require that if an adversary creates a set of digests
and a proof that Verify accepts, then the adversary must “know”
a valid witness, in the sense that this witness can be successfully
extracted by “watching” the adversary’s execution. Note that
the trapdoor the extractor receives from KeyGen1 is generated
independently of relation R and hence cannot make it easier for
the extractor to produce its own witnesses.

Pr[

τ ← KeyGen1(1λ);τ = (τS ,τE );
(EK,VK) ← KeyGen2(τ,R);
(D,π;χχχ,o) ← (A(EK,R) (cid:12) E(EK,R,τE )) :
(cid:2)∃b ∈ [(cid:2)]. Verify(VKb,D(t)
(cid:2)∀b ∈ [(cid:2)]. Verify(VKb,D(t)
] = negl(λ).

b

b

(cid:5)= Digest(EKb,χ(t)
)∧ D(t)
,o(t)
(cid:3)
b
)∧ Verify(VK,D,π)∧ χχχ /∈ R

b

b

))∨

3.2 Composition by Scheduling
As discussed in §2, intuitively, we can verify the correct execu-
tion of a complex F by verifying simpler functions and using
digests to share state between them. We now formalize this in-
tuition by extending knowledge soundness to multiple related
proofs that share digests according to a proof schedule.
Deﬁnition 5 (Scheduled Knowledge Soundness) The commit
and-prove scheme P is scheduled knowledge sound for (cid:2)-ary
relations {R λ}λ∈N and binding digest subset S ⊂ [(cid:2)], if for all
efﬁcient A there is an efﬁcient extractor E taking the random
tape of A such that, for any R ∈ R λ,
Pr[ τ ← KeyGen1(1λ);
(EK,VK) ← KeyGen2(τ,R);
(σ,D,Π;χχχ,o) ← (A(EK,R) (cid:12) E(EK,R,τ)) :
∀D(t)
) ⇒ D(t)
(cid:2)∀D(t)
) ∧
(cid:3)
∀(i,t) ∈ σ. Verify(VK,D(t),πi)
⇒ ∀(i,t) ∈ σ. χχχ(t) ∈ R
] = 1− negl(λ),
where D(t) indicates a digest instance t for each bank b used in
a given proof (and default digests of 0 values for any bank not
used), and χχχ(t) represents the digested values.
Theorem 1 (Scheduled Knowledge Soundness) If a CP P is
knowledge sound and binding for (cid:2)-ary relations and binding
digest subset, then it is scheduled knowledge sound for the same
relations and subset.

∈ D. (Verify(VKb,D(t)
∈ D. Verify(VKb,D(t)

= Digest(EKb,χ(t)
b

,o(t)
b

b

b

b

b

b

))∧

The proof of Theorem 1 can be found in the full paper [23].
Intuitively, it follows from extracting valid digest openings from
all subproofs, and leveraging the binding property of the bus
digests to guarantee consistency across subproofs.

4 Geppetto’s CP Protocol

We now construct an efﬁcient commit-and-prove protocol for
}λ∈N (see §3.1) deﬁned by a MultiQAP Q(cid:3)
(cid:2)-ary relations {RQ(cid:3)
derived from multiple QAPs Qi, as described in §2.1.3.

λ

Deﬁnition 4 (Knowledge Soundness) The commit-and-prove
scheme P is knowledge sound for (cid:2)-ary relations {R λ}λ∈N, if
for all efﬁcient A there is an efﬁcient extractor E taking the
random tape of A such that, for any R ∈ R λ,

4.1 MultiQAPs as Polynomials
We use Pinocchio’s technique (which originated with Gennaro
et al. [29]) to lift quadratic programs to polynomials.

259259

Given MultiQAP Q(cid:3), of size ρ(cid:3) and degree d(cid:3), we ﬁrst de-
ﬁne a set D of d(cid:3) “root values” of the form r ∈ {2i}d(cid:3)
i=1,5 and
we deﬁne the polynomial δ(x) as the polynomial with all r ∈ D
as roots. Recalling §2.1.3, we then deﬁne a set V of ρ(cid:3) poly-
nomials vk(x) by interpolation over the roots in D such that for
k ∈ [ρ(cid:3)],r ∈ D: vk(r) = vr,k. Each of the k polynomials es-
sentially summarizes the effect one of χχχ’s variables has on the
computation. We deﬁne similar sets W and Y using the vectors
wr and yr.

We say that the polynomial MultiQAP is satisﬁed by χ if δ(x)
(cid:3)

divides p(x), where:

(cid:2)
∑ρ
k=0

χk · vk(x)

(cid:3)·(cid:2)
∑ρ
k=0

p(x) =

χk · wk(x)

(cid:3)−(cid:2)
∑ρ
k=0

χk · yk(x)

.

We use MultiQAPs to prove statements about shared state.
To achieve this, the polynomials corresponding to bus values
need to fulﬁll an additional condition. We say that a bus bank
Bb is commitment compatible if (i) the polynomials in each set
{yk(x)}k∈Bb are linearly independent, meaning that no linear
combination of them cancels all coefﬁcients, and (ii) all poly-
nomials in the set {vk(x),wk(x)}k∈Bb are 0. The ﬁrst property
is crucial for commitments to be binding, while the second im-
proves performance and facilitates zero-knowledge when using
externally generated commitments.
By inspection of Equation (5), the buses in our MultiQAP
construction in §2.1.3 are commitment compatible. Concretely,
continuing our example from that section, Equation (5) will be
encoded as the QAP equation:

(0 +··· + 0)(0 +··· + 0) = (1· z0 + 1· z1 + (−1)· ˆz).

4.2 Commit-and-Prove Scheme for MultiQAPs
Geppetto’s protocol inherits techniques from Pinocchio [46];
the key differences are starting with MultiQAPs instead of
QAPs, and splitting the prover’s efforts into separate digest and
proof computations.

1 or gx

We present our protocol in terms of a generic quadratic en-
coding E [29].
In our implementation, we use an encoding
based on bilinear groups. Speciﬁcally, let e be a non-trivial bi-
linear map [13] e : G1 × G2 → GT and let g1, g2 be generators
of G1 and G2 respectively. To simplify notation, we deﬁne the
encoding E(x) to be either gx
2 depending on whether it
appears on the left or the right side of a product ∗.
Below, each Bb ∈ B represents a subset of [ρ(cid:3)], and we use
the commit-and-prove message χ(t)
to represent the values of
b
bank instance B(t)
b .
Protocol 1 (Geppetto)
• τ ← KeyGen1(1λ):
Choose s,{αv,b,αw,b,αy,b}b∈[(cid:2)],rv,rw
(τS ,τE ) = (s,{αv,b,αw,b,αy,b}b∈[(cid:2)],rv,rw), (rv,rw).
• (EK,VK) ← KeyGen2(τ,RQ(cid:3)):
Choose {γb,βb}b∈[(cid:2)]
R← F. Set ry = rv·rw. To simplify nota-
tion, deﬁne Ev(x) = E(rvx) (and similarly for Ew and Ey).

R← F. Construct τ as

5Choosing roots of this form enables our C++ library to implement an efﬁ-

cient d(cid:3) logd(cid:3) algorithm [15] for the prover’s polynomial division.

260260

For the MultiQAP Q(cid:3) = (ρ(cid:3),d(cid:3),B,V ,W ,Y ,δ(x)), con-
struct the public evaluation key EK as:
(EKb)b∈[(cid:2)],
(cid:2)
where each bank’s digest key EKb is deﬁned as:
Ey(yk(s))

(E(si))i∈[d] , Ev(δ(s)),Ew(δ(s)),Ey(δ(s))

Ev(vk(s)),
Ev(αv,bvk(s)), Ew(αw,bwk(s)), Ey(αy,byk(s)),

Ew(wk(s)),

E(βb(rvvk(s) + rwwk(s) + ryyk(s))),

(cid:3)
k∈Bb

Ev(αv,bδ(s)),
Ev(βbδ(s)),

Ew(αw,bδ(s))
Ew(βbδ(s)),

Ey(αy,bδ(s)),
Ey(βbδ(s)).

Construct the public veriﬁcation key VK as:
(VKb)b∈[(cid:2)], E(1), Ey(δ(s)) ,

where each bank’s digest veriﬁcation key VKb is:

VKb = E(αv,b),E(αw,b),E(αy,b),E(γb),E(βbγb) .
Additionally VK includes digest keys EKb for digests that
the veriﬁer computes (e.g., for IO banks). Since EK and
VK are public, the split into prover and veriﬁer keys is pri-
marily designed to reduce the veriﬁer’s storage overhead.

• D(t)

← Digest(EKb,χ(t)
b
b as (ov,ow,oy).

b
Parse o(t)
If Bb is an IO bank, simply return:

,o(t)
b

):

Ev(v(b)(s)), Ew(w(b)(s)), Ey(y(b)(s)),

χkvk(s) + ovδ(s) (and similarly for
where v(b)(s) = ∑k∈Bb
w(b)(s) and y(b)(s)). Since the veriﬁer typically computes
these digests, ov is typically 0. Note that all of these terms
can be computed using the values in VKb, thanks to the
linear homomorphism of the encoding E.
For any other bank, compute:

Ey(y(b)(s)),

Ew(w(b)(s)),

Ev(v(b)(s)),
Ev(αv,bv(b)(s)), Ew(αw,bw(b)(s)), Ey(αy,by(b)(s)),
E(βb(rvv(b)(s) + rww(b)(s) + ryy(b)(s)))

.
Note that all of these terms can be computed using the
values in EKb. The values above constitute an extractable
digest of the χ(t)
b . For
b
commitment-compatible buses, this digest is also binding.
Furthermore,
for all commitment-compatible buses,
v(b)(s),w(b)(s),ov,ow are all 0, so the digest above
simpliﬁes to:

values, perfectly hidden via o(t)

Ey(y(b)(s)),Ey(αy,by(b)(s)),E(βb(ryy(b)(s))) ;

• π ← Prove(EK,χ,o): Parse each ob ∈ o as (ob,v,ob,w,ob,y)
and use the coefﬁcients χ to calculate:
χkvk(x) + ∑
b∈[(cid:2)]

v(x) = ∑
k∈[ρ(cid:3)]

ob,vδ(x),

and similarly for w(x), and y(x).
Just as in a standard QAP proof [29], calculate h(x) such
that h(x)δ(x) = v(x)w(x) − y(x), that is, the polynomial
that proves that δ(x) divides v(x)w(x)− y(x). Compute the
proof as π ← E(h(s)) using the E(si) terms in EK.

• {0,1} ← Verify(VKb,D(t)

b

): Verify digest D(t)

b by checking
Ev(v(b)(s))∗ E(αv,b) = Ev(αv,bv(b)(s))∗ E(1) (6)
Ew(w(b)(s))∗ E(αw,b) = Ew(αw,bw(b)(s))∗ E(1) (7)
Ey(y(b)(s))∗ E(αy,b) = Ey(αy,by(b)(s))∗ E(1) (8)

and the β check:
(cid:4)
βb(rvv(b)(s) + rww(b)(s) + ryy(b)(s))

(cid:5)

E
(cid:4)
Ev(v(b)(s))+Ey(y(b)(s))

(cid:5)

(9)
∗E(βbγb)+E(βbγb)∗ Ew(w(b)(s)).

∗ E(γb) =

(For buses, we do not require the checks in Equations (6)
and (7), and we can simplify the β check (Eqn (9)).)
• {0,1} ← Verify(VK,D0, . . . ,D(cid:2)−1,π): Combine the di-
gests and perform the divisibility check on the proof term
E(h(s)) in π:

(cid:4)
∑b∈[(cid:2)] Ev(v(b)(s))
(cid:4)
∑b∈[(cid:2)] Ey(y(b)(s))

(cid:5)
(cid:5)

(cid:5)

(cid:4)
∑b∈[(cid:2)] Ew(w(b)(s))

∗
∗ E(1) = E(h(s))∗ Ey(δ(s)) .

−

(10)

As described,
the protocol supports non-interactive zero-
knowledge proofs, in addition to veriﬁable computation. For
applications that only desire the latter, the multiples of δ(s) in
the EK and the use of digest randomizations o may be omitted.
Theorem 2 Protocol 1 has binding digests, as deﬁned by Deﬁ-
nition 3 under the d-SDH assumption.
Theorem 3 Protocol 1 is a knowledge-sound commit-and-
prove scheme, as deﬁned by Deﬁnition 4.
Theorem 4 Protocol 1 is a perfectly zero-knowledge commit-
and-prove scheme.

We refer to the full paper [23] for the proofs of these theorems
and the deﬁnition of their assumptions. Like the protocol, the
proofs inherit their techniques from Pinocchio.

5 Veriﬁable Crypto Computations
Background Pinocchio, along with the systems built atop it,
instantiates its cryptographic protocol using pairing-friendly el-
liptic curves. Such curves ensure good performance and com-
pact keys and proofs. An elliptic curve E deﬁnes a group of
prime order p(cid:7) where each element in the group is an (x,y)
point, with x and y drawn from a second ﬁeld Fp of large prime
characteristic p. When Pinocchio is instantiated with such a
curve, the QAPs (and hence all veriﬁable computations) are de-
ﬁned over Fp(cid:7), and hence code that compiles naturally to oper-
ations on Fp(cid:7) is cheap.

Approach At a high-level, we choose the curve E we use to
instantiate Geppetto such that the group order “naturally sup-
ports” operations on a second curve ˜E, which we can use for any
cryptographic scheme built on ˜E, e.g., anything from signing
with ECDSA to the latest attribute-based encryption scheme.

261261

In more detail, suppose we want to verify ECDSA signatures
over an elliptic curve ˜E built from points chosen from Fq. If
we instantiate Geppetto using a pairing-friendly elliptic curve
E with a group of prime order p(cid:7) = q, then operations on points
from ˜E embed naturally into our QAPs, meaning that basic op-
erations like adding two points cost only a handful of crypto-
graphic operations, rather than hundreds or thousands required
if p(cid:7) did not align with q.
Bootstrapping As described in §2.2, proof bootstrapping is
a particularly compelling example of verifying cryptographic
operations, since it allows us to condense a long series of proofs
and digests into a single proof and digest.

Remarkably, Karabina and Teske [35] show that it is possi-
ble to generate two MNT curves [45] E and ˜E that are pairing
friendly and, more importantly, ˜E can be embedded in E, and E
can be embedded in ˜E.

Ben-Sasson et al. [9] recently instantiated and implemented
such curves to bootstrap the veriﬁcation of individual CPU in-
structions. Geppetto can use a similar approach to achieve un-
bounded bootstrapping of entire QAPs. Speciﬁcally, we could
instantiate two versions of Geppetto, one built on E that con-
denses proofs consisting of points from ˜E and another built on ˜E
that condenses proofs consisting of points from E.

Unfortunately, there are drawbacks to using the curves Ben-
Sasson et al. found. First, they were only able to ﬁnd a pair of
curves that provide 80 bits of security. Finding cycles of perfor-
mant curves for the more standard 128-bit setting appears non-
trivial, since just ﬁnding 80-bit curves required over 610,000
core-hours of computation. Second, the MNT curve family
is not the most efﬁcient family at higher security levels, and
achieving a cycle requires larger-than-usual ﬁelds, creating ad-
ditional inefﬁciency [9].

To estimate the costs of using MNT curves at the 128-bit se-
curity level used by Pinocchio, we coded up all of the relevant
curve operations in Magma [14] and counted the group opera-
tions required. We made very optimistic assumptions about the
optimal implementation of the curves, e.g., by assuming that
the operations employ all available EC tricks within the pairing
computation, even though the actual curves may not allow for
them. Even under these assumptions, our measurements indi-
cate that key and proof generation, as well as IO veriﬁcation, for
Geppetto’s ﬁrst batch of proofs would be 34-77× slower than
a standard Pinocchio-style proof, while the constant pairing-
based portion of proof veriﬁcation would be 11× slower; sub-
sequent batches would cost more, due to technical challenges in
the way the curves ﬁt together [9].

As a pragmatic alternative, we use a sequence of nested
curves (an option suggested previously [9, Footnote 10]) to in-
stantiate and implement bounded bootstrapping, Speciﬁcally,
we instantiate one version of Geppetto with the same highly
efﬁcient BN curve [6] employed by Pinocchio. We use the
BN curve to generate a collection of digests and proofs for
our MultiQAP-based CP scheme. We then construct a sec-
ond curve capable of efﬁciently embedding the BN curve op-
erations. When instantiated with the second curve, Geppetto
can efﬁciently verify crypto operations on the BN curve. Thus,

a veriﬁer can, for example, check signatures on the veriﬁcation
key built on the BN curve and then use that key to verify the
BN digests and proofs. To gain greater scalability, this process
can be repeated with a bounded number of additional carefully
constructed curves, each used to verify the digests and proofs
from the previous curve. Unfortunately, none of the curves can
efﬁciently embed later curves, and hence when generating keys,
the client must ultimately commit to the maximum number of
BN proofs that will be veriﬁed. Fortunately, our use of energy-
saving circuits saves the prover effort if it ends up using fewer
proofs.

Details We construct bilinear systems, GIN and GOUT . To
achieve this at the 128-bit security level, we instantiate GIN us-
ing a Barreto-Naehrig (BN) elliptic curve [6], and then construct
GOUT accordingly with the Cocks-Pinch method [21]. Roughly,
the latter constructs a pairing-friendly curve by outputting a ﬁ-
nite ﬁeld corresponding to a given, prescribed group order. We
ﬁx the prime p from the BN parameterization as the group order,
so that the output of the Cocks-Pinch algorithm is the prime ˜p
(as well as the other parameters required in the description of
GOUT ). The following lemma makes this explicit in a special
case that is of most interest in the current work.
Lemma 1 Let x ∈ Z be such that p = 36x4 +36x3 +24x2 +6x+
1 and p(cid:7) = 36x4 + 36x3 + 18x2 + 6x + 1 are prime. If

˜p = 5184x8+10368x7 + 12204x6 + 8856x5 + 4536x4

+1548x3 + 363x2 + 48x + 4

(11)
is also prime, then there exists both an elliptic curve E/Fp of
order #E(Fp) = p(cid:7) with embedding degree k = 12 (with respect
to p(cid:7)), and an elliptic curve ˜E/F ˜p, such that its order # ˜E(F ˜p) is
a multiple of p and ˜E has embedding degree ˜k = 6 (w.r.t. p).
Our full paper contains proofs and construction details [23].

To construct additional nesting curves, given a group order,
we once again apply the Cocks-Pinch approach to produce a
sequence of curves E(i), deﬁned over prime ﬁelds Fpi, respec-
tively, such that pi divides #E(i+1)(Fpi+1
). Each hop creates a
larger curve, and hence will eventually produce curves equal to
or larger than the MNT curves that support unbounded boot-
strapping. For example, for the ﬁrst Cocks-Pinch curve, ˜p is
509 bits (with embedding degree 6), and the next two levels are
1023 bits and 2055 bits with embedding degrees 3 and 1.

Even when we reach these larger sizes, the inner layers (es-
pecially the BN curve where most of the “real” computation
happens) are still more efﬁcient than the MNT curves, and even
at comparable sizes, exponentiations on the Cocks-Pinch curves
are faster due to a CM endomorphism (not available for MNT
curves) and a G2 cubic twist. Of course, for sufﬁciently large
problems, the unbounded approach eventually offers better per-
formance.

Implementation

6
The Geppetto system includes a library for guiding the compila-
tion of banks and buses, a cryptographic compiler that operates

262262

on C programs via LLVM, and libraries that support common
programming patterns and bootstrapped computation.

Although it has been applied to over 10,000 lines of C and
supports many LLVM instructions, Geppetto imposes semantic
restrictions on source programs, thereby reﬂecting limitations
of compilation to QAP encodings. For instance, it offers almost
no support for computations on pointers. Recent work shows
how to remove many of Geppetto’s restrictions [54].

We ﬁrst explain our programming model by example, then
describe the design and selected features of our compiler, and
ﬁnally discuss C libraries and programming patterns.

6.1 Programming Model
A Geppetto programmer deﬁnes the structure of outsourced
computations, their compound proofs, and the shared buses that
connect them, thereby explicitly controlling cost and amortiza-
tion of proof and digest generation. This structure is embed-
ded in source C programs via library invocations. (The design
of higher-level syntactic sugar and programming abstractions is
left as future work.)

From the veriﬁer’s viewpoint, Geppetto’s C programming
model is reminiscent of remote procedure calls (RPCs). The
programmer marks some function calls as outsourced, indicat-
ing that the veriﬁer should remote the calls to an untrusted ma-
chine, then verify their results using the accompanying crypto-
graphic evidence. This approach provides a clear operational
speciﬁcation of the veriﬁed computation, even for complex
proof schedules: when the main program of the veriﬁer com-
pletes, its outputs and return values must be the same as those
that would be obtained by executing the entire program on a
single trusted machine.

We illustrate the deﬁnition of outsourced functions on the
Geppetto program sample.c, outlined in Figure 4.
The
program deﬁnes some application code (elided), notably
compute() that operates on a matrix and a vector of integers.
The programmer intends to ﬁx the matrix across instances
of compute, and vary the input vector.
To this end,
sample.c declares three banks for veriﬁable outsourced com-
putation. For instance, relying on the Geppetto header ﬁle,
BANK(QUERY, vector) deﬁnes a QUERY bank datatype that
carries values of type vector, and functions like save_QUERY
and load_QUERY, analogous to RPC marshalling and unmar-
shalling functions. By convention, each bank instance can be
assigned only once, and must be assigned before being loaded.
The program then deﬁnes two functions: job, the outsourced
function, and main, that repeatedly calls job and processes its
arguments. Note that the call to job is marked as OUTSOURCE,
and that the digest db to the largest input M is computed just
once, outside the loop.
• When compiling sample.c natively outside Geppetto,
geppetto.h provides trivial deﬁnitions that implement
DATA, QUERY, and RESULT as in-memory buffers and
OUTSOURCE as a local call: OUTSOURCE(job, db, q) is
replaced with job(db, q).
• During compilation, Geppetto interprets the outsourced
function of sample.c, using symbolic values for the pay-

#include "geppetto.h"

// Geppetto banks and proofs

RESULT verify_job(DATA b0, QUERY b1) {

// application code
typedef struct { int M[SIZE][SIZE]; ...} bigdata;
typedef struct { int x[SIZE];
void compute(bigdata *db, vector *in, vector *out);

...} vector;

BANK(DATA, bigdata)
BANK(QUERY, vector)
BANK(RESULT, vector)

// we define 3 IO banks

RESULT job(DATA db, QUERY in) {

bigdata M;
vector query, result;
load_DATA(db,&M);
load_QUERY(in,&query);
compute(&M, &query, &result);
return (save_RESULT(&result));

}
int main() {
bigdata M;
vector query[N], result[N];
... // prepare the data & queries
DATA db = save_DATA(&M); // digest M once into db
for (i=0; i<N; i++) {

QUERY q = save_QUERY(&query[i]);
RESULT r = OUTSOURCE(job, db, q);
load_RESULT(r,&result[i]);

}
... // do something with the results

}

Figure 4: Example Geppetto Program (sample.c).

load of its input banks, and generates a public key pair
(EK,V K).
• In prove mode, using EK, Geppetto interprets sample.c
with concrete values to produce cryptographic digests (D)
for each bank; it intercepts OUTSOURCE to accumulate in-
termediate values during the execution of job and to pro-
duce a proof (π) for each outsourced call.
• In verify mode, using V K, Geppetto produces a version of
the program that replaces bank loads and outsource calls
with cryptographic veriﬁcations; this version can then be
natively compiled with clang -DVERIFY sample.c.

In both modes, the execution ﬂow of main determines the
schedule (σ) of calls to outsourced functions.

In more details, in verify mode, veriﬁcation keys are initially
loaded from ﬁles, banks are supplemented with cryptographic
functions for verifying digests, and OUTSOURCE(job, db, q)
is replaced with the function call verify_job(db, q). In Fig-
ure 5, we show the implementation of verify_job, generated
by Geppetto during the Geppetto compilation of sample.c and
included during its native compilation with the -DVERIFY ﬂag.
Just like job, verify_job takes two banks and returns a bank.
The input banks propagate previously computed (or veriﬁed) di-
gests from the caller; in particular, the bigdata digest is shared
across all calls. The function loads and digests the prover’s pro-
posed value for the output bank, veriﬁes the local bank’s digest

digest D[4];
D[0] = b0->d; // use digest produced by save_DATA
D[1] = b1->d; // use digest produced by save_QUERY
RESULT b2 = load_redigest_RESULT();
D[2] = b2->d;
load_verify_digest(&STATE.vk, &D[3], LOCALS);
proof pi;
load_proof("job", &pi);
verify_proof(&STATE.vk, &pi, 4, D);
return b2;

}

Figure 5: Simpliﬁed Veriﬁcation Example. Geppetto replaces the
original outsourced function job with a version that loads the function
result and cryptographic evidence and then veriﬁes that the function
was computed correctly.

evidence, and veriﬁes the computation’s proof.
If any veri-
ﬁcation fails, the program exits with an error. Otherwise, the
resulting bank b2 carries the correct response to the outsourced
computation.

6.2 MultiQAP Programming Patterns
Geppetto provides additional support for common commit-and-
prove patterns, coded as generic C libraries.

Sequential Loops Many large computations consist of a main
loop with a code body that updates loop variables at every iter-
ation, and also reads (but does not modify) outer variables.

Geppetto provides a generic template for outsourcing each
loop iteration (or, more generally, for outsourcing ﬁxed num-
bers of iterations that ﬁt within a single QAP), with a bank for
the outer variables; hence the cost to digest and verify the outer
bank is amortized across all loop iterations.

What about the loop variables? Recall that our commit-and-
prove scheme requires that each bank be assigned at most once
in every proof. Thus, we use two buses for the loop variables,
alternating between odd and even iterations of the loop, and we
compile the loop body twice, once reading the even loop vari-
ables and writing the odd loop variables, and once the other way
round. Hence, our generic template deﬁnes three banks, two
outsourced functions, and a reﬁned loop that alternates calls be-
tween the two. The veriﬁer then checks two digests and one
proof for each iteration, except for the ﬁrst iteration (where it
computes a digest of the initial values of the loop variables) and
the last (where it recomputes a digest of the ﬁnal values returned
by the prover).

MapReduce Geppetto also provides a few generic templates
for parallel loops (like sample.c above) and MapReduce com-
putations. As with sequential loops, for MapReduce computa-
tions, we use a series of buses to succinctly share potentially
many variables between mappers and reducers. Speciﬁcally, we
adopt Pantry’s model [16] in which M mappers feed R reduc-
ers. Geppetto compiles a MapReduce job into a MultiQAP with
two sub-QAPs (Qm for the mapper computation and Qr for the

263263

reducer computation) with max(M,R) shared buses in between
them. Each reducer reads from M buses and computes its out-
put. Each mapper computation takes an ID as input, telling it
which R buses to write its outputs to. For example, suppose
M = 10 and R = 2, and hence we have 10 shared buses. The
ﬁrst mapper writes its output for reducer 1 to bus 1 and for re-
ducer 2 to bus 2 (and implicitly writes zeros to the other buses).
The second mapper writes its output for reducer 1 to bus 2 and
for reducer 2 to bus 3. This continues until the tenth mapper
writes its output for reducer 1 to bus 10 and its output for re-
ducer 2 to bus 1. The prover sends the digests for all of the
computations and buses, along with the proofs binding them
together, back to the veriﬁer, who ensures (via the digests fed
into each Verify call) that the data was routed correctly between
mappers and reducers. If desired, all of the proofs and digests
can be made zero knowledge, and since the dataﬂow between
mappers and reducers is data independent, the computation as a
whole is zero knowledge as well.

Automated QAP Partitioning As explained above, Gep-
petto’s libraries enable programmer-directed QAP partitioning.
We also experimented with automated partitioning of large
monolithic QAPs, expressed as ﬁnding hyper-graph cuts. We
had some success efﬁciently ﬁnding approximate cuts in graphs
of up to 200,000 equations with the METIS tool [36]. However,
the programmer-directed approach is more ﬂexible and better
exploits regular structure such as loops.

6.3 Symbolic Interpretation via LLVM
Next, we provide details on the construction of the Geppetto
compiler. We elide QAP techniques described elsewhere [46].

General-Purpose LLVM Front-End As a front-end com-
piler, we use clang [40], a fast full-ﬂedged C compiler with rich
syntax, standard semantics, and optimizations. Hence, Gep-
petto compilation to quadratic equations starts from a low-level,
typed, integer-centric representation of the program, obtained
by running (for instance) clang -O2 -S -DQAP -emit-llvm
sample.c -o sample.s, where -DQAP declares but does not
deﬁne Geppetto primitive types and functions.

Compiling to QAPs beneﬁts from clang’s aggressive inlining
and partial evaluation. We disable other, unhelpful clang opti-
mizations, such as its replacement of multiplication by a con-
stant x∗ 8 (free in QAPs) with a bit shift x << 3 (which incurs
bit splitting). Using clang should also facilitate extension to
other LLVM-supported languages, but this may require adding
support for more of LLVM’s instruction set.

Interpreting LLVM Bitcode
Instead of emitting an arith-
metic circuit, Geppetto ﬁrst compiles, then evaluates programs
(in prove mode) by symbolic interpretation of LLVM code.
Keeping the circuit implicit facilitates the generation of proofs
for large computations, inasmuch as the unfolded circuits can
be much larger than the LLVM code that generates them.

Our interpreter relies on a shallow embedding into F#, re-
lying on the F# control stack and heap; i.e., function calls are

implemented by calls to an F# call function, and mallocs are
F# array creations.

Some values are known at compile time, and used to special-
ize the QAP equations (Eqn. (4)) we produce. Others are known
only at run time; these values are treated symbolically, using an
abstract domain for integers; their operations generally involve
adding QAP equations.

Interpretation is cheap relative to cryptography, so, in prove
mode, we simply re-interpret the LLVM code to produce con-
crete witnesses for all run-time intermediate variables (the
‘wires’ of the implicit circuit), and we accumulate them into
digests and proofs. Thus, Geppetto uses two related interpreters
(described below) that differ in their interpretation of integers.

Symbolic Interpretation (1): Compilation Geppetto sepa-
rately interprets each outsourced function. As a side-effect of
their operations, variables and equations are added to the func-
tion’s QAP. For instance, multiplying two unknown integers
adds a variable (for the result) and an equation. Global caches
identify and eliminate common subexpressions.

For this interpretation, we represent unknown integers as a
triple of (i) a linear combination of QAP variables; (ii) a source
semantics: either some LLVM intn integer (e.g., int, short,
char) or a ﬁeld element (for embedded cryptography); and (iii) a
range: an interval in Z that covers any value this integer may
have at run time. Keeping track of ranges enables us to opti-
mize precomputations for fast exponentiations, to minimize bi-
nary decompositions (which cost one equation per potentially
active bit), to detect ﬁeld overﬂows, and to defer integer trunca-
tion (which require binary decompositions) for almost all op-
erations. For instance, our compiler may represent the (un-
known) value of an LLVM local variable as ‘an int32, obtained
by adding the 5th and 6th QAP variables, with range 1..100’.

At this stage of the compilation, the MultiQAP consists of
one QAP per function, plus ‘linking’ information on the shared
buses. This sufﬁces to generate keys, as the compiler traverses
each function’s QAP in turn, while keeping the buses virtual.

Symbolic Interpretation (2): Evaluation in ‘prove’ mode
We use another, faster instance of our interpreter, and we now
interpret the whole program, not just its outsourced code. De-
pending on the program’s control ﬂow, one outsourced function
may be interpreted many times with different ‘run-time’ val-
ues. The evaluator still distinguishes between ‘compile-time’
and ‘run-time’ values, although it has values for both, because it
needs to accumulate QAP witnesses for any operation on ‘run-
time’ values, in strict correspondence with the QAP variables
and equations produced by the compiler. Hence, values for all
QAP variables introduced at compile time are stored as inputs
for the cryptographic digests.

Because some compiler optimizations depend on data not
available at run time (such as integer ranges and caches), the
evaluation of some operations depends on auxiliary ‘interpreta-
tion hints’ passed along by the compiler. For example, before
XORing a variable with a constant, a hint tells the evaluator
whether a new binary decomposition is required (as we try to
re-use existing decompositions) and, when required, how many

264264

bits it uses (as the evaluator must record a witness for every bit
of the decomposition provisioned by the compiler).

The evaluator also intercepts calls to load or save banks, as
well as OUTSOURCE calls, and computes digests and proofs re-
spectively. When evaluation completes, the prover will have
produced exactly the evidence expected by the veriﬁer.

Cryptography (FFLib) All cryptographic operations are im-
plemented in a separate high-performance C++ library, with ef-
ﬁcient support for many base ﬁelds and elliptic curves. FFLib
is optimized for native x64 execution, unlike our QAP-friendly
crypto libraries (§6.4). In addition to default curves that achieve
128-bit security, it also supports toy curves for testing and de-
bugging. Since as much as 75% of the total run time (for key,
digest, and proof generation) is spent multiplying and exponen-
tiating elliptic curve points, we optimize these operations using
standard pre-computation and batching techniques [46].

Primitive Libraries Whenever possible, we reﬂect (and even
implement) primitive features of the interpreter using C types
and functions. Pragmatically, this keeps our code base small,
and lets us rely on standard (non-cryptographic) tools for testing
and debugging purposes—for instance by comparing printfs
between native clang runs and interpreted runs of the same code.
We provide a basic IO library. When loading from a ﬁle,
a ﬂag indicates whether this is a ‘compile-time’ or a ‘run-time’
ﬁle. Values from compile-time ﬁles are baked into the compiled
QAP. For run-time ﬁles, the compile-time interpreter allocates
fresh local QAP variables, and the evaluation-time interpreter
loads the ﬁle’s contents as run-time values. Thus, the ﬁle repre-
sents private, untrusted inputs provided by the prover.

As another example, for many programs, QAP size intri-
cately depends on compile-time values; the interpreter provides
a primitive function int nRoot() that returns the degree of
the QAP being generated (or proved), thereby letting C pro-
grammers debug the cryptographic performance of their code
and even control the partitioning of their code between several
QAPs of comparable degrees—for instance by unrolling a loop
until four million QAP equations have been generated.

6.4 Cryptographic Libraries and Bootstrapping
Geppetto has speciﬁc support for the compilation of programs
that evaluate cryptographic operations, to enable bootstrapping
and other ﬂexible applications of nested evaluation.

Field arithmetic and cryptography To support bootstrap-
ping, we provide custom C libraries that implement primitive
ﬁeld operations including addition, multiplication, division, and
binary decomposition. These enable fast, ﬁeld-based embed-
ding of cryptography, intuitively taking advantage of 254-bit
words. The ﬁeld type is also implemented natively. Thus, ﬁeld
operations can be compiled both with clang and for bootstrap-
ping by Geppetto.

Accordingly, our IO library supports loading C structs that
mix machine integers and ﬁeld elements. As shown in the code

of verify_job, we use it to load cryptographic evidence as
‘run-time’ data, and similarly for all other pieces of evidence.
By choosing to load the veriﬁcation keys at ‘compile time’ or
‘run time’, we select a different trade-off between performance
and ﬂexibility (see §7.3).

QAP-Friendly Elliptic Curves Cryptography We devel-
oped a plain, QAP-friendly C implementation of the elliptic-
curve algorithms for §5, including optimal Ate pairings. We
brieﬂy discuss two speciﬁc optimizations.

As in prior work [9], we use afﬁne coordinates (2 ﬁeld el-
ements) instead of projective ones (3 ﬁeld elements). Native
implementations use projective coordinates to avoid a ﬁeld divi-
sion when adding two points; since we verify the computation,
however, a ﬁeld division is just as fast as a ﬁeld multiplication.
For fast multiplication, the native algorithm has four cases at
each iteration of the loop, due to the special treatment of inﬁnite
points in addition. To prevent these conditional branches, which
are costly when compiling to QAPs, we add an initial summand
and remove it at the end.

Bounded Bootstrapping Our compiler implements multiple
levels of bootstrapping, as described in §2.2. Continuing with
our example in §6.1, assume we wish to compress the N proofs
by writing a bootstrapped function that aggregates the values
in the result[N] array. Geppetto’s libraries will ensure that
all N proofs (and corresponding digests) are veriﬁably veriﬁed,
in addition to verifying the aggregation of the result array.
To this end, we include another, similar but distinct copy of
our Geppetto library that lets the C programmer deﬁne ‘level
2’ or ‘outer’ banks and outsourced functions. We can then pro-
gram with two nested levels of veriﬁable computations, with the
outer top-level calling ‘level 2’ outsourced functions, which in
turn call inner ‘level 1’ outsourced functions according to their
own schedules. Hence, we also support proof schedules, digest
re-use, and MultiQAP programming at ‘level 2’. As before,
we obtain our veriﬁcation speciﬁcation by using a trivial im-
plementation of banks as local buffers and ignoring OUTSOURCE
annotations.

When compiling, we ﬁrst run the Geppetto compiler with
the trivial deﬁnition of ‘level 2’ banks and OUTSOURCE, and the
primitive Geppetto deﬁnitions for ‘level 1’. This generates keys
and code for outsourcing all ‘level 1’ functions. We then run the
Geppetto compiler with the primitive Geppetto deﬁnitions for
‘level 2’, and with the -DVERIFY ﬂag for ‘level 1’, thereby in-
cluding, e.g., the code of verify_job instead of job, as well as
our supporting cryptographic libraries for all ‘level 1’ elliptic-
curve veriﬁcation steps.

When proving, we run the Geppetto prover ﬁrst at level 1
(producing evidence for its outsourced calls) then at level 2
(loading that evidence from untrusted, ‘run-time’ ﬁles). When
verifying, we simply compile the source program with the
-DVERIFY ﬂag for level 2.

The approach above applies for further bootstrapping levels.

265265

6.5 Branching and Energy-Saving
When evaluating a program, there is no proof cost involved for
QAP variables that evaluate to zero: formally, we add a poly-
nomial contribution multiplied by 0 (§4.1), and we multiply di-
gests by 1 (a key element exponentiated by 0). Thus, if at com-
pile time we ensure that all intermediate variables for a branch
evaluate to 0 when the branch is not taken, then at run time there
is no need to evaluate that branch at all.

For example, consider the code fragment if(b) t = f(x).
At compile time, if b is known, we just interpret the test, and
compile the call to f only if b is true. If b is unknown, we in-
terpret this fragment as t = f(b*x) + (1 - b)*t and, cru-
cially, we compile the call to f conditionally on the guard b,
with the following invariant: if b is 0 and f’s inputs are all 0,
then its result must be zero, and zero must be a correct assign-
ment for all its intermediate variables. Additionally, any store
in f is conditionally handled, using similar multiplications by b.
Note that the addition of (1 - b)*t is generally required to
ensure that, if the branch is not taken, then the value of t is
unchanged.

More generally, we extend our ‘compile-time’ interpreter so
that its main evaluation function takes an additional parame-
ter: its guard, g, with range 0..1. The guard is initially 1, but
it can also be unknown (typically one of the QAP variables).
Except for branches, the guard is left unchanged by the in-
terpreter. Whenever the interpreter accesses a register with a
less restrictive guard, it multiplies it by g before using it. (We
cache these multiplications.) When branching on an unknown
boolean, say b, both branches are evaluated with guards g ∗ b
and g∗ (1− b), respectively. When joining, we sum the results
of the corresponding branches, as explained next.

The single-static-assignment discipline of LLVM and its ex-
plicit handling of joins help us implement this feature. In our
example, the code actually passed from clang to Geppetto is

entry:

%tobool = icmp eq i32 %b, 0
br i1 %tobool, label %if.end, label %if.then

if.then:

%result = ...
br label %if.end

if.end:

%t = phi i32 [ %result, %if.then ], [ %t, %entry ]
...

where the compile-time function phi selects which register to
use for the resulting value of t after the join. At compile time,
as we symbolically execute all branches, we simply interpret
the phi function as a weighted sum instead of a selector.

At run time, our representation of b tells us whether it was
known at compile time or not; we use that information to (im-
plicitly) provide 0 values for any branch not actually taken.

7 Evaluation

Below, we evaluate the effect of Geppetto’s optimizations on
the performance of the prover. We run our experiments on an

Op
Fixed Base Exp.
Multi Exp. (254 bit)
Pairing
Field Addition
Field Multiplication

Barreto-Naehrig
Twist
Base
87.2μs
21.2μs
55.6μs
241.5μs

0.6ms
44.2ns
288.2ns

Cocks-Pinch

Level 1
161.3μs
454.5μs
5.0ms
43.3ns
288.0ns

Level 2
1027.5μs
2008.2μs
31.9ms
65.2ns
726.0ns

Figure 6: Microbenchmarks for Cryptography. Breakdown of the
main sources of performance overhead in Geppetto’s larger protocol.
Each value is the average of 100 trials. Standard deviations are all
less than 4%.

HP Z420 desktop, using a single core of a 3.6 GHz Intel Xeon
E5-1620 with 16 GB of RAM.

7.1 Microbenchmarks
To calibrate our results, we summarize the cost of our cryp-
tographic primitives in Figure 6. We generally use a Barreto-
Naehrig (BN) curve for generating digests and proofs, and we
use the Cocks-Pinch (CP) curves to handle embedded crypto-
graphic computations like bootstrapping. We show measure-
ments from two CP curves to illustrate how the costs grow for
each progressive level. The BN curve is asymmetric, meaning
that one source group (base) is cheaper than the other (twist).
Geppetto’s protocol and compiler are designed to keep most of
the work on the base group.

The CP curves are slower than the BN for two reasons. First,
the CP curves are chosen to support bounded bootstrapping, so
they use larger ﬁeld elements than the BN curve (see §5). Sec-
ond, the BN code has been extensively optimized, including
hand-tuned assembly code, while the CP code is newly writ-
ten C. Based on operation counts from Magma [14], the ﬁrst
CP curve should be within 2-4× of the BN curve, and indeed
comparing the CP curve’s performance with a similar C version
of the BN curve conﬁrms this.

7.2 MultiQAPs
We compare the use of MultiQAPs for shared state with the
use of hashing in prior work such as Pantry [16]. At a mi-
cro level, Pantry’s results suggest that hashing an element of
state increases the degree of the QAP by ∼11.25/byte. In con-
trast, with MultiQAPs, a full ﬁeld element only increases the
degree by one, so with Geppetto, the degree only increases by
∼0.03/byte, a savings of 375×. Even if we want to operate on
32-bit values, instead of full ﬁeld elements, Geppetto only costs
0.25/byte, a savings of 45×.

At a macro level, for MapReduce, Pantry and Geppetto share
the same costs for proving that the core mapper and reducer
computations were performed correctly; on top of that, to han-
dle state transferred between mappers and reducers, Pantry
proves the correctness of 2M· R hashes (since both the mappers
and the reducers must prove they hashed the state correctly),
while Geppetto proves the correctness of M · R bus digests. As
a result, Geppetto’s keys end up being a bit smaller; Geppetto’s

266266

Geppetto
Pantry
Geppetto
Pantry
Geppetto
Pantry
Geppetto
Pantry

MR: Dot product
(m = 10K)
MR: Dot product
(m = 160K)
MR: Nucleotide substring
(m = 6K,d = 10)
MR: Nucleotide substring
(m = 60K,d = 32)
Loop: Matrix exponentiation Geppetto
(n = 10,e = 40)
Loop: Matrix exponentiation Geppetto
(n = 20,e = 40)

Pantry

Pantry

QAP Degree
10K
1.1M (103×)
161K
16.8M (104×)
1K
98K (84×)
26K
327K (13×)
8K
32K (4.0×)
37K
131K (3.5×)

KeyGen

5s
(114×)
643s
49s
14130s† (283×)
0.7s
(55×)
39s
21s
(7×)
155s
5s
(3.1×)
15s
15s
(3.5×)
54s

Prover

Veriﬁer

Baseline

3s
(1169×)
3696s
53s
22187s† (412×)
1s
(72×)
126s
43s
(21×)
909s
51s
(8×)
405s
253s
(6×)
1463s

10ms
58ms
10ms
58ms†
36ms
58ms
35ms
58ms
411ms
211ms
421ms
211ms

(5.8×)
(5.8×)
(1.6×)
(1.7×)
(0.5×)
(0.5×)

0.5ms

6.3ms

0.2ms

0.3ms

0.9ms

1.1ms

Figure 7: Apps with Shared State. For MapReduce (MR) apps, we give per-mapper statistics. For Loop, we consider the entire computation.
These apps do not use bootstrapping. Parenthetical values show Pantry’s relative overhead. Entries with † indicate simulated Pantry values.

keys save further relative to Pantry, as Pantry needs key mate-
rial for R hashes for each mapper and M hashes for each reducer,
while Geppetto only needs max(M,R) shared buses (§6.2).

A na¨ıve alternative to MultiQAPs and hashing is to build one
gigantic Pinocchio QAP, so that the shared state becomes sim-
ply internal circuit wires. However, our experiments quickly
showed the futility of this approach; even for the relatively
modest applications shown in Figure 7 and assuming only 10
mappers, this approach would require a QAP with a degree of
10M+, while the Pinocchio prover keels over (i.e., begins swap-
ping) before it can reach 3M on a 16 GB machine.

7.2.1 Applications

To measure the end-to-end effect of MultiQAPs, we evaluate
Geppetto on the following applications. We compare Gep-
petto’s results against Pantry’s implementation running on the
same hardware, except when Pantry runs out of memory, in
which case we use Pantry’s validated cost model [16]. We bor-
row the ﬁrst two examples from Pantry [16] to give a direct com-
parison with their work. We adopt Pantry’s ratio of 10 mappers
to 1 reducer, and we use their extension of Pinocchio to ensure
an apples-to-apples comparison.

MapReduce: Dot Product [16] The veriﬁer speciﬁes (in
Pantry via hash, in Geppetto via a digest) two vectors of in-
tegers; each mapper receives m integers and computes a partial
dot product, and the reducer sums the mapper outputs.

MapReduce: Nucleotide Substring Search [16] The veri-
ﬁer speciﬁes a DNA string that is divided amongst the mappers,
each receiving m nucleotides. The mapper then searches for
dynamically supplied length-d substrings reporting a match (if
any) to the reducer which combines the matches.

Loop: Matrix Exponentiation The veriﬁer supplies a dy-
namically chosen n × n matrix M and an exponent e, and the
prover returns Me. Matrix exponentiation is useful for many

applications, e.g., to compute the width of a graph represented
as an adjacency matrix [52].

This example shows the beneﬁts of intertwined MultiQAPs.
With Pinocchio, the QAP would scale with e, limiting the size of
the problem, whereas, with MultiQAPs, we only need to com-
pile the loop body (after some loop unfolding), which can then
be used for arbitrary values of e. With Pantry, the loop body
needs to hash a matrix on the way in and again on the way out,
whereas MultiQAPs incur a handful of crypto operations per
intermediate state generated.

7.2.2 MultiQAP Results

Figure 7 summarizes the impact of using MultiQAPs for shared
state. The results only show CPU costs and do not include net-
work latency or bandwidth, though the latter is unlikely to be
a problem for either Pantry or Geppetto, given that proofs and
digests are only a few hundred bytes each.

For MapReduce, we see the largest discrepancy between
Geppetto and Pantry on the dot-product app. For this app, the
QAP for the computation itself is quite simple, so for Pantry,
the cost of hashing dwarfs the cost of the computation. For the
nucleotide app, the shared state is still a dominant portion of the
calculation for Pantry (though not as dominant as in dot prod-
uct), and hence Geppetto maintains a wide margin.

For the Loop application, the QAP for the computation itself
is non-trivial and grows faster than the IO between loop itera-
tions; thus, the cost of state sharing relative to the computation
is lower than for dot product, and the ratio drops further for
larger matrices. Since Geppetto and Pantry generate essentially
the same QAP for the computation itself, Geppetto’s relative
advantage drops accordingly.

7.3 Verifying Cryptography and Bootstrapping
In §5, we claimed that embedding cryptographic operations
without matching ﬁeld sizes was exorbitantly expensive. To
validate this claim, we combined data from a basic ECC pairing
operation coded in Magma with cost models from Pinocchio

267267

for various operations such as bit splitting. Our calculations es-
timate that the pairing alone would require a QAP with degree
of 44 million.
Fortunately, our choice of matching curves in §5 brings this
cost down signiﬁcantly. For example, a pairing only requires a
QAP of degree 14K, an improvement of 3100× vs. the na¨ıve
approach, while an exponentiation, i.e., gx, increases the degree
by ∼60 per bit in x.
Furthermore, as discussed in §5, for a comparable security
level, our initial curves for bounded bootstrapping provide ap-
proximately 34-77× better performance than curves supporting
unbounded bootstrapping [9]. As §7.1 shows, however, perfor-
mance degrades with each level added, and hence will eventu-
ally reach a point where they fall short of the unbounded curves’
performance.

7.3.1 Bootstrapping

From the veriﬁer’s perspective, one level of bootstrapping is at-
tractive, since she only receives (and only veriﬁes) one constant-
sized, 512-bit proof, and one constant-sized, 448-byte digest.

Without bootstrapping, the only way for the prover to gen-
erate such concise proofs would be via one massive Pinocchio-
style QAP, which our results above (§7.2) show is infeasible.
Nonetheless, bootstrapping does come at a cost. While boot-
strapping, the “outer” QAP’s degree grows with each digest or
proof that it must verify. We summarize these costs below as-
suming that the veriﬁcation keys are known at compile-time.
• For each recomputed digest, we increase the degree by 2K
• For each full digest veriﬁcation, we pay 79.6K (including
the pairings needed for the checks from Equations (6)-(9)).
• For each bus digest veriﬁcation, we pay 33.8K (since, as
noted in §4.2, buses require fewer checks).
• For each proof veriﬁcation (Eqn (10)), we pay 28.2K.

for each 32-bit integer value committed.

With keys unknown at compile-time, we pay instead 89.8K and
30.6K for full digest and proof veriﬁcation, respectively.

We also observe that the prover’s cryptographic cost for
“outer” proofs and digests is typically higher than for work on
the “inner” instance, even for QAPs of the same size. One rea-
son is that the outer CP curve is less efﬁcient than the inner BN
curve (§7.1). A second reason is that many of the values the
prover commits to for the inner instance arise from the program
being veriﬁed, and hence they are often 1, 32, or 64 bits. In con-
trast, the outer curve veriﬁes elliptic curve operations and hence
many values are full-ﬂedged 254-bit values.

While these costs are substantial, they are low enough that
we can employ bootstrapping to scale the prover to much larger
computations. For example, with our existing implementation,
we could bootstrap up to 14 “inner” proofs sharing 16 buses; ap-
plying this to, say, the matrix exponentiation example allows us
to produce a single, constant-size proof for a computation with
a useful (i.e., not counting bootstrapping costs) QAP degree of
over 50 M. When evaluating the computation, the prover exe-
cutes 24M LLVM instructions and generates a proof in 152 min-
utes. While slow, this is ﬁve orders of magnitude faster than the

 

e
t
u
p
m
o
c
 
o
t
 
e
m

i
t
 
d
e
z
i
l

a
m
r
o
N

s
f
o
o
r
p
d
n
a

 

 
s
t
n
e
m

t
i

m
m
o
c

5.00

4.00

3.00

2.00

1.00

0.00

Energy-saving runtime conditions

5.01

5.06

1.00

1.68

static

runtime

1 multiplication

5 multiplications

Figure 8: Energy-Saving Circuits. The energy-saving multiplexer
allows us to include an optional circuit that has low cost when unused.

unbounded bootstrapping in previous work (BCTV) [9], which,
with a reported clock rate of 26 milliHz (and a lower 80-bit se-
curity level), would take approximately 29 years.

No source code was available for BCTV, so analyzing the
causes of this large performance gap requires some guesswork.
First, we estimate that one order of magnitude comes from the
different choices of curves.

Second, BCTV use a circuit that checks a general-purpose
CPU transition function for each program instruction. Thus, for
straight-line code like matrix multiplication, they use hundreds
of equations for each operation, whereas Geppetto generally
uses one. BCTV’s interpreter, however, supports RAM access
and data-dependent control ﬂow, while Geppetto’s compilation-
based implementation currently does not, and thus, one might
expect a smaller performance gap on applications making use
of those features. However, recent work [54] indicates that the
compilation-based approach can incorporate these features and
still outperform interpretation by 2-4 orders of magnitude on
straight line code, and 1-3 orders of magnitude on RAM and
data-dependent benchmarks.

Finally, BCTV apply bootstrapping at a very ﬁne granular-
ity. At every step of their CPU, they produce a proof with one
curve, and then they use their second curve to verify that proof
and translate it back into a proof on the ﬁrst curve. Thus, each
CPU instruction requires two bootstrapped proof veriﬁcations,
whereas in this application, each Geppetto proof veriﬁcation
covers 1.7M LLVM instructions.

7.4 Energy-Saving Circuits

As a targeted microbenchmark to evaluate the beneﬁts of
energy-saving circuits (§2.3), in Figure 8, we compare a static
compile-time condition to a runtime condition. The left group
shows a static computation with a single matrix multiplication
and a static computation containing ﬁve multiplications that
takes proportionally longer. On the right, a single computa-
tion supports up to ﬁve multiplications, but is organized using
energy-saving circuits to make the one-multiplication case inex-
pensive. Using this circuit to compute one matrix multiply costs
68% more than the static version (rather than 5×), and costs a
negligible 1% in the ﬁve-multiply case.

268268

7.5 Compiler

Some previous veriﬁable computations systems do not include a
compiler [22, 52], while those that do [10, 16, 46] have typically
compiled small examples with less than 100 lines of C code. In
contrast, Geppetto’s compiler handles non-trivial cryptographic
libraries, with the largest clocking in at 4,159 SLOC [55] of
complex cryptographic code supporting elliptic curve opera-
tions, including pairing.

8 Related Work
Veriﬁable Computation As discussed in §1, many previous
systems for verifying outsourced computation make undesirable
assumptions about the computation or the prover(s). Recently
however, several lines of work have reﬁned and implemented
protocols for veriﬁable computation that make at most crypto-
graphic assumptions [9, 46, 49, 52]. These systems offer dif-
ferent tradeoffs between generality, efﬁciency, interactivity, and
zero-knowledge, but they share a common goal of achieving
strong guarantees with practical efﬁciency.

However, these systems typically verify a single program at
a time, leading to performance issues for state shared across
computations (see §2.1.1). We compare and contrast alternate
techniques for handling state in §2.1.4.
As discussed in §5 and §7.3.1, Ben-Sasson et al. [9] instanti-
ate and implement suitable elliptic curves for unbounded boot-
strapping. Geppetto can leverage unbounded bootstrapping, but
it also supports bounded bootstrapping for better performance.
Ben-Sasson et al. bootstrap the veriﬁcation of individual CPU
instructions using handwritten circuits, whereas Geppetto uses
compiled cryptographic libraries to bootstrap high-level opera-
tions (e.g., procedure calls) following our belief that C should
be compiled, not interpreted. Compilation plus bounded boot-
strapping can provide up to ﬁve orders of magnitude faster per-
formance, though both techniques sacriﬁce generality compared
with unbounded interpretation.

Interpreting CPU instructions means that Ben-Sasson et al.
natively avoid the redundancy of executing both branches of
an if-else branch in the source program, but the interpretation
circuit itself is repeated for every instruction and contains cir-
cuit elements that are not active for every instruction, and hence
could beneﬁt from Geppetto’s energy-saving circuit’s ability to
power down unused portions of the CPU veriﬁer. Similarly, pro-
grams interpreted in this framework can beneﬁt from Geppetto’s
MultiQAP-based approach to state.

Commit-and-Prove To our knowledge, commit-and-prove
(CP) schemes are ﬁrst mentioned by Kilian [37]. Canetti et
al. [18] deﬁne CP schemes in the UC model and realize such
schemes in the FZK-hybrid model. Escala and Groth [26] de-
sign CP schemes from Groth-Sahai proofs [34].

Zero Knowledge Several systems compile high-level func-
tions to zero-knowledge (ZK) proofs [1, 4, 42]. Compilers

from Almeida et al. [1] and Meiklejohn et al. [42] build on Σ-
protocols [24], while the work of Backes et al. [4] uses Groth-
Sahai ZK proofs [34]. For the subset of functionality these sys-
tems support, they are likely to outperform Geppetto at least for
the prover, but none offer the degree of efﬁcient generality and
concise proofs that Geppetto provides.

9 Conclusions

Geppetto employs four independent but carefully intertwined
techniques: MultiQAPs, QAP-friendly cryptography, bounded
bootstrapping, and energy-saving circuits. We increase the ef-
ﬁciency of the prover by orders of magnitude, and we improve
the versatility of its proofs, e.g., by enabling the efﬁcient veri-
ﬁcation of hidden computations. Geppetto’s scalable compiler
exposes this power and ﬂexibility to developers, bringing veri-
ﬁable computation one step closer to practicality.

10 Acknowledgements

The authors gratefully thank Joppe Bos, Olga Ohrimenko, Sri-
nath Setty, Michael Walﬁsh, and the anonymous reviewers.

References
[1] J. B. Almeida, E. Bangerter, M. Barbosa, S. Krenn, A.-R.
Sadeghi, and T. Schneider. A certifying compiler for zero-
knowledge proofs of knowledge based on σ-protocols. In Proc.
of ESORICS, 2010.

[2] S. Arora and S. Safra. Probabilistic checking of proofs: A new

characterization of NP. J. ACM, 45(1):70–122, 1998.

[3] M. Backes, D. Fiore, and R. M. Reischuk. Nearly practical and
privacy-preserving proofs on authenticated data. In Proc. of IEEE
Symposium on Security and Privacy, 2015.

[4] M. Backes, M. Maffe, and K. Pecina. Automated synthesis of
In Proc. of ISOC

privacy-preserving distributed applications.
NDSS, 2012.

[5] F. Baldimtsi and A. Lysyanskaya. Anonymous credentials light.

In Proceedings of ACM CCS, 2013.

[6] P. S. L. M. Barreto and M. Naehrig. Pairing-friendly elliptic
curves of prime order. In Selected Areas in Cryptography (SAC),
2006.

[7] E. Ben-Sasson, A. Chiesa, C. Garman, M. Green, I. Miers,
E. Tromer, and M. Virza. Zerocash: Decentralized anonymous
payments from Bitcoin. In Proc. of the IEEE Symposium on Se-
curity and Privacy, 2014.

[8] E. Ben-Sasson, A. Chiesa, D. Genkin, and E. Tromer. Fast re-
ductions from RAMs to delegatable succinct constraint satisfac-
tion problems. In Innovations in Theoretical Computer Science
(ITCS), Jan. 2013.

[9] E. Ben-Sasson, A. Chiesa, E. Tromer, and M. Virza. Scalable
zero knowledge via cycles of elliptic curves. In Proc. of CRYPTO,
2014.

[10] E. Ben-Sasson, A. Chiesa, E. Tromer, and M. Virza. Succinct
non-interactive zero knowledge for a von Neumann architecture.
In Proc. of USENIX Security, 2014.

269269

[11] N. Bitansky, R. Canetti, A. Chiesa, and E. Tromer. Recursive
composition and bootstrapping for SNARKS and proof-carrying
data. In STOC, 2013.

[12] M. Blum, W. Evans, P. Gemmell, S. Kannan, and M. Naor.
Checking the correctness of memories. In IEEE Symposium on
Foundations of Computer Science (FOCS), 1991.

[13] D. Boneh and M. Franklin. Identity-based encryption from the

Weil pairing. Proceedings of IACR CRYPTO, 2001.

[14] W. Bosma, J. Cannon, and C. Playoust. The Magma algebra sys-

tem. I. The user language. J. Symbolic Comput., 24(3-4), 1997.

[15] A. Bostan and E. Schost. Polynomial evaluation and interpolation

on special sets of points. Journal of Complexity, 21(4), 2005.

[16] B. Braun, A. J. Feldman, Z. Ren, S. Setty, A. J. Blumberg, and
M. Walﬁsh. Verifying computations with state. In Proc. of the
ACM SOSP, 2013.

[17] J. Camenisch and A. Lysyanskaya.

Efﬁcient non-trans-
ferable anonymous multi-show credential system with optional
anonymity revocation. In EUROCRYPT, 2001.

[18] R. Canetti, Y. Lindell, R. Ostrovsky, and A. Sahai. Universally
In

composable two-party and multi-party secure computation.
Proceedings of ACM STOC, 2002.

[19] B. Carbunar and R. Sion. Uncheatable reputation for distributed

computation markets. In FC, 2006.

[20] M. Castro and B. Liskov. Practical Byzantine fault tolerance and

proactive recovery. ACM Trans. on Comp. Sys., 20(4), 2002.

[21] C. Cocks and R. Pinch. Identity-based cryptosystems based on

the Weil pairing. Manuscript, 2001.

[22] G. Cormode, M. Mitzenmacher, and J. Thaler. Practical veriﬁed
computation with streaming interactive proofs. In Innovations in
Theoretical Computer Science, 2012.

[23] C. Costello, C. Fournet, J. Howell, M. Kohlweiss, B. Kreuter,
M. Naehrig, B. Parno, and S. Zahur. Geppetto: Versatile veriﬁ-
able computation. Cryptology ePrint Archive, Report 2014/976,
Nov. 2014.

[24] R. Cramer, I. Damg˚ard, and B. Schoenmakers. Proofs of partial
knowledge and simpliﬁed design of witness hiding protocols. In
Proc. of CRYPTO, 1994.

[25] G. Danezis, C. Fournet, M. Kohlweiss, and B. Parno. Pinocchio
coin: Building Zerocoin from a succinct pairing-based proof sys-
tem. In ACM PETShop, 2013.

[26] A. Escala and J. Groth. Fine-tuning Groth-Sahai proofs. Cryp-

tology ePrint Archive, Report 2004/155, Oct. 2013.

[27] K. Fu, M. F. Kaashoek, and D. Mazi`eres. Fast and secure dis-
tributed read-only ﬁle system. ACM Trans. on Comp. Sys., 20(1),
Feb. 2002.

[28] R. Gennaro, C. Gentry, and B. Parno. Non-interactive veriﬁable
In

computing: Outsourcing computation to untrusted workers.
Proceedings of IACR CRYPTO, 2010.

[29] R. Gennaro, C. Gentry, B. Parno, and M. Raykova. Quadratic
In Proc. of

span programs and succinct NIZKs without PCPs.
EUROCRYPT, 2013.

[30] S. Goldwasser, Y. T. Kalai, and G. N. Rothblum. Delegating com-
putation: Interactive proofs for muggles. In Proc. of the Sympo-
sium on Theory of Computing (STOC), 2008.

[31] S. Goldwasser, S. Micali, and C. Rackoff. The knowledge com-
plexity of interactive proof systems. SIAM J. Comput., 18(1),
1989.

[32] P. Golle and I. Mironov. Uncheatable distributed computations.

In Proc. of CT-RSA, 2001.

[33] J. Groth. Short pairing-based non-interactive zero-knowledge ar-

270270

guments. In IACR ASIACRYPT, 2010.

[34] J. Groth and A. Sahai. Efﬁcient non-interactive proof systems for

bilinear groups. In Proc. of EUROCRYPT, 2008.

[35] K. Karabina and E. Teske. On prime-order elliptic curves with
embedding degrees k = 3, 4, and 6. In Proc. of the Conference on
Algorithmic Number Theory (ANTS), 2008.

[36] G. Karypis. METIS 5.1.0: A software package for partition-
ing unstructured graphs, partitioning meshes, and computing ﬁll-
reducing orderings of sparse matrices. Technical report, Depart-
ment of Computer Science, University of Minnesota, Mar. 2013.
[37] J. Kilian. Uses of Randomness in Algorithms and Protocols. PhD

thesis, MIT, Apr. 1989.

[38] J. Kilian. A note on efﬁcient zero-knowledge proofs and argu-

ments (extended abstract). In STOC, 1992.

[39] A. E. Kosba, D. Papadopoulos, C. Papamanthou, M. F. Sayed,
E. Shi, and N. Triandopoulos. TrueSet: Nearly practical veriﬁ-
able set computations. In Proc. of USENIX Security, 2014.

[40] C. Lattner and V. Adve. LLVM: A compilation framework for
lifelong program analysis and transformation. In Symposium on
Code Generation and Optimization, Mar 2004.

[41] R. B. Lee, P. Kwan, J. P. McGregor, J. Dwoskin, and Z. Wang.
Architecture for protecting critical secrets in microprocessors. In
ISCA, 2005.

[42] S. Meiklejohn, C. C. Erway, A. K¨upc¸ ¨u, T. Hinkle, and A. Lysyan-
skaya. ZKPDL: A language-based system for efﬁcient zero-
knowledge proofs and electronic cash. In Proc. of USENIX, 2010.
[43] R. C. Merkle. A certiﬁed digital signature. In Proc. of CRYPTO,

1989.

[44] S. Micali. Computationally sound proofs. SIAM J. Comput.,

30(4):1253–1298, 2000.

[45] A. Miyaji, M. Nakabayashi, and S. Takano. New explicit condi-
tions of elliptic curve traces for FR-reduction. IEICE Trans. on
Fundamentals, 84(5), 2001.

[46] B. Parno, C. Gentry, J. Howell, and M. Raykova. Pinocchio:
In Proc. of the IEEE

Nearly practical veriﬁable computation.
Symposium on Security and Privacy, May 2013.

[47] B. Parno, J. M. McCune, and A. Perrig. Bootstrapping Trust in

Modern Computers. Springer, 2011.

[48] A. Rial and G. Danezis. Privacy-preserving smart metering. In

Proc. of the ACM WPES, 2011.

[49] S. Setty, B. Braun, V. Vu, A. J. Blumberg, B. Parno, and M. Wal-
ﬁsh. Resolving the conﬂict between generality and plausibility in
veriﬁed computation. In EuroSys, 2013.

[50] S. Setty, R. McPherson, A. J. Blumberg, and M. Walﬁsh. Making
argument systems for outsourced computation practical (some-
times). In Proc. ISOC NDSS, 2012.

[51] R. Sion. Query execution assurance for outsourced databases. In

Proc. of VLDB, 2005.

[52] J. Thaler. Time-optimal interactive proofs for circuit evaluation.

In Proc. of IACR CRYPTO, 2013.

[53] P. Valiant.

Incrementally veriﬁable computation or proofs of

knowledge imply time/space efﬁciency. In TCC, 2008.

[54] R. S. Wahby, S. Setty, Z. Ren, A. J. Blumberg, and M. Walﬁsh.
Efﬁcient RAM and control ﬂow in veriﬁable outsourced compu-
tation. In Proceedings of the ISOC NDSS, Feb. 2015.

[55] D. A. Wheeler. SLOCCount. http://www.dwheeler.com/

sloccount/.

