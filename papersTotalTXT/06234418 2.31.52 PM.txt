2012 IEEE Symposium on Security and Privacy

Quid-Pro-Quo-tocols: Strengthening Semi-Honest Protocols with Dual Execution

Yan Huang

University of Virginia
yhuang@virginia.edu

Jonathan Katz

University of Maryland

jkatz@cs.umd.edu

David Evans

University of Virginia
evans@virginia.edu

Abstract—Known protocols for secure two-party computa-
tion that are designed to provide full security against malicious
behavior are signiﬁcantly less efﬁcient than protocols intended
only to thwart semi-honest adversaries. We present a concrete
design and implementation of protocols achieving security
guarantees that are much stronger than are possible with
semi-honest protocols, at minimal extra cost. Speciﬁcally, we
consider protocols in which a malicious adversary may learn a
single (arbitrary) bit of additional information about the honest
party’s input. Correctness of the honest party’s output is still
guaranteed. Adapting prior work of Mohassel and Franklin,
the basic idea in our protocols is to conduct two separate
runs of a (speciﬁc) semi-honest, garbled-circuit protocol, with
the parties swapping roles, followed by an inexpensive secure
equality test. We provide a rigorous deﬁnition and prove that
this protocol leaks no more than one additional bit against a
malicious adversary. In addition, we propose some heuristic
enhancements to reduce the overall
information a cheating
adversary learns. Our experiments show that protocols meeting
this security level can be implemented at cost very close to
that of protocols that only achieve semi-honest security. Our
results indicate that this model enables the large-scale, practical
applications possible within the semi-honest security model,
while providing stronger security guarantees.

Keywords-secure two-party computation, privacy-preserving

protocols.

I. INTRODUCTION

Protocols for secure two-party computation allow two
mutually distrusting parties to compute a function that
depends on both their inputs while ensuring correctness,
privacy, and more, without relying on a trusted third party.
Recent results [29, 28, 34, 14, 16] have shown that it is
feasible to implement generic protocols for secure two-party
computation (where by “generic” we mean protocols that can
compute arbitrary functions speciﬁed as a boolean or arith-
metic circuit) based on Yao’s garbled-circuit approach [36],
in some cases quite efﬁciently [17, 15]. To obtain reasonable
performance, however, many of these works [29, 14, 16]
and others that rely on them [17, 15] assume the semi-
honest (or honest-but-curious) model in which the adversary
is assumed to always follow the protocol but may try to
learn information from the protocol transcript beyond what
is allowed.

Several generic approaches are known for achieving secu-
rity against malicious adversaries (i.e., adversaries who may
arbitrarily deviate from the protocol speciﬁcation). Some
approaches rely on zero-knowledge proofs of correct be-
havior [11, 22]. Others rely on “cut-and-choose” techniques
to detect dishonesty [25, 33, 35, 27, 24]. Another recent

approach uses message-authentication techniques to ensure
that parties use correct values throughout
the computa-
tion [32]. Protocols produced by any of these approaches
exhibit a slowdown of several orders of magnitude compared
to protocols with semi-honest security. The slowdown is
not only due to increased computation and communication;
a (potentially) more signiﬁcant issue is the memory usage
required by some of the known protocols. As an example,
the Lindell-Pinkas protocol [25] requires hundreds of copies
of the garbled circuits to be transmitted before veriﬁcation
and evaluation, and so does not appear to be compatible
with pipelined circuit execution (a technique that makes
secure computation memory efﬁcient [16]), at
least not
without introducing additional overhead. As one data point
supporting this claim, a recent implementation of secure
two-party computation of AES [35] (with security against
malicious adversaries) required one of the parties to use
about 190 MB of storage. This suggests that the resources
required in order to achieve (full) security against malicious
adversaries can be prohibitive, even for many small-scale
computations.

Mohassel and Franklin [30] proposed a relaxed deﬁnition
of security in which,
informally, a malicious adversary
may be able to learn a small number of additional bits of
information about the honest party’s input, beyond what is
implied by the output (a formal deﬁnition is in Section V).
This deﬁnition may sufﬁce for many realistic scenarios in
which secure computation would be used. Note that even
fully secure protocols leak information about the honest
party’s input
in the function output. Depending on the
speciﬁc function and the control the adversary has over its
own input this information leakage may be substantial and
hard to characterize.

In addition to proposing the new security notion discussed
above, Mohassel and Franklin also present a general ap-
proach to realizing that notion. At a high level, the idea
is to run two independent executions of a (speciﬁc) semi-
honest protocol, with the parties swapping roles in the two
executions. This is followed by an equality test on particular
values held by the two parties. See Section III for details.

Additional related work is discussed in Section II-C.

A. Contributions

In this work we ﬂesh out and implement an optimized
version of the Mohassel-Franklin protocol. We describe a
speciﬁc, highly efﬁcient mechanism for carrying out the
equality test (Section III-B) in their approach, and implement

© 2012, Yan Huang. Under license to IEEE.
DOI 10.1109/SP.2012.43

272

their protocol, incorporating pipelined execution and other
efﬁciency optimizations (Section VI). We provide a precise
deﬁnition of their security notion (specialized for the case of
1-bit leakage), formally specify the details of the Mohassel-
Franklin protocol, and give a rigorous proof that
their
“dual-execution” approach satisﬁes the given deﬁnition (Sec-
tion V). Our experimental results (Section VI-C) show that
it is possible to obtain performance competitive with state-
of-the-art semi-honest protocols, while achieving meaningful
(though not complete) protection against malicious behavior.
In Section VII we present two heuristic strategies for
further limiting what an adversary can learn. In our ﬁrst
approach, the actual function output is revealed only after
the equality test is completed successfully. This means the
adversary may learn an unallowed bit of information, but
only at the expense of failing to learn the actual output some
of the time. The second approach ensures that the attacker
learns at most one more bit of the output than the honest
party. Both these enhancements are inexpensive, and their
complexity depends only on the length of the output.

II. BACKGROUND

The main cryptographic tools we use are garbled circuits
and oblivious transfer, which we brieﬂy introduce next.
Section II-C summarizes previous work towards secure
computation against stronger classes of adversaries.

A. Garbled Circuits

Garbled circuits [36] allow two semi-honest parties to
compute an arbitrary function f (x0, x1) that depends on
their respective private inputs, x0 and x1, without leaking
any information about their inputs beyond what is revealed
by the function output itself. One party, acting as the circuit
generator, produces a garbled circuit that is evaluated by the
other party, known as the circuit evaluator. The result is an
“encrypted” output, which can then be mapped to its actual
value and revealed to either or both parties. We provide an
overview here; for technical details and a proof of security,
see Lindell and Pinkas [26].

The basic idea is to transform a boolean circuit into a
garbled circuit that operates on labels (i.e., cryptographic
keys) instead of bits. Any binary gate, g, which has two
input wires W0, W1 and output wire W2, can be converted
into a garbled gate. First, generate random labels w0
i and
i to represent 0 and 1 on each wire Wi. Then, generate a
w1
truth table containing the four entries

Encws0

(wg(s0,s1)

2

)

0 ,ws1

1

for each s0, s1 ∈ {0, 1} (where s0, s1 denote the 1-bit
signals on wires W0, W1, respectively), and randomly per-
mute the table. This truth table is called a garbled gate.
Observe that given the garbled gate and labels ws0
0 and ws1
1 ,
it is possible to recover wg(s0,s1)
. Thus, given the labels
that correspond to some set of input values for the entire
circuit, it is possible for the circuit evaluator to recover labels
corresponding to the output of the circuit on those inputs. If

2

the circuit generator provides a way to map those labels back
to bits, the circuit evaluator can recover the actual output.
The only thing that remains is to provide a mechanism that
allows the circuit evaluator to obtain input-wire labels for
the bits corresponding to the inputs of the two parties. The
circuit generator can simply send the appropriate labels for
its own input to the circuit evaluator since these labels reveal
nothing about the circuit generator’s input but are merely
randomly chosen labels. The circuit evaluator obtains the
input-wire labels for its own input using oblivious transfer,
described in Section II-B.

In summary, a garbled-circuit protocol involves parties
agreeing to a circuit that computes the desired function, and
then following these steps: (1) the circuit generator garbles
each gate in the circuit; (2) the circuit generator sends the
garbled gates, along with the wire labels corresponding to
its own inputs; (3) the circuit evaluator obtains the wire
labels corresponding to its inputs from the generator using an
oblivious transfer protocol; (4) the circuit evaluator evaluates
the circuit by successively decrypting entries of each garbled
gate until reaching the output wires; and (5) the generator
provides a way to map output-wire labels to bits,
thus
allowing the evaluator to compute the actual output.

The main bottleneck in garbled-circuit protocols is gen-
erating and evaluating each gate, since this requires four
encryptions for the circuit generator and (as described) four
decryptions for the circuit evaluator. Many techniques have
been developed to reduce the costs of executing garbled
circuits, including the point-and-permute technique that al-
lows the circuit evaluator to decrypt only a single entry
the free-
(rather than all four) in a garbled gate [29];
XOR technique [23] that allows XOR gates to be executed
without any encryption operations; Garbled Row Reduction
(GRR) [34] that reduces the size of a garbled gate to
three ciphertexts (thus saving 25% of network bandwidth);
and pipelined execution that parallelizes circuit generation
and evaluation [16]. Our implementation uses all of these
techniques.

B. Oblivious Transfer

An oblivious-transfer (OT) protocol allows a sender to
send one of a possible set of values to a receiver. The
receiver selects and learns only one of the values, and the
sender cannot learn which value the receiver selected. In
particular, a 1-out-of-2 OT protocol [8] allows the sender,
who has two strings b0 and b1, to transfer bσ to the receiver,
who holds a private bit σ. Oblivious-transfer extension [19]
allows the realization of an unbounded number of oblivious
transfers with minimal marginal cost per OT, starting from
a small number of (expensive) “base” OTs.

In our implementation we use the OT-extension protocol
of Ishai et al. [19] with security against malicious adver-
saries, that uses O(k2) “base” OTs for k a statistical security
parameter. More efﬁcient approaches, requiring only O(k)
base OTs, are known [12, 32], but are not used in our
implementation. For the “base” OTs we use the Naor-Pinkas
protocol [31], whose security is based on the computational

273

Difﬁe-Hellman assumption in the random-oracle model. This
protocol achieves privacy against malicious adversaries, but
not full (simulation-based) security against malicious adver-
saries (as required by our proof of security in Section V).
Nevertheless, because we use oblivious-transfer extension,
OT is a small fraction of the overall execution time, and
changing the OT protocol used would not substantially
impact our experimental results. The Naor-Pinkas protocol
could easily be adapted to provide (simulation-based) se-
curity against malicious adversaries in the random-oracle
model, with relatively little additional cost.

C. Threat Models

Most previous work in secure computation has assumed
either a semi-honest or malicious threat model [10]. In the
semi-honest (also known as honest-but-curious) model, the
adversary is assumed to follow the protocol as speciﬁed, but
may attempt to learn extra information from the protocol
transcript. In contrast, a malicious adversary may arbitrarily
deviate from the speciﬁed protocol as it attempts to compro-
mise the privacy of the other party’s inputs or correctness
of the obtained result.

Most implementations of generic secure two-party com-
putation have targeted the semi-honest threat model [29, 14,
16], and have used protocols based on Yao’s garbled-circuit
approach. The scalability and efﬁciency of garbled-circuit
protocols have been improved by a series of optimizations
including point-and-permute [29], free-XOR [23], garbled-
row reduction [34], pipelining [16], and library-based mod-
ular circuit construction [16].

Several approaches have been proposed for achieving
security against malicious adversaries [11, 22, 25, 33, 35,
27, 24, 32], some of which have been implemented [28, 34,
35, 32]. However, even the best known protocols are orders-
of-magnitude slower than the best semi-honest protocols.

Aumann and Lindell et al. introduced the covert threat
model [1]. In this model, a cheating adversary is “caught”
with some constant probability, but with the remaining
probability can (potentially) learn the honest party’s entire
input and arbitrarily bias the honest party’s output. If an
adversary is unwilling to take the risk of being caught, then
such protocols will deter cheating altogether. Aumann and
Lindell also show a two-party protocol with covert security
that is only a small constant factor less efﬁcient than the
basic (semi-honest) garbled-circuit protocol.

The single-bit leakage model we consider here is incom-
parable to the covert model. On the one hand, the single-
bit leakage model allows the adversary to always learn one
additional bit about the honest user’s input, without any risk
of being caught. (See Sections IV-A and VII, however, for
some discussion about mitigating what the adversary learns.)
On the other hand, the covert model allows the adversary
to learn the entire input of the honest party with constant
probability. The covert model also allows the adversary to
affect the correctness of the honest party’s output (with
constant probability), something prevented in the single-bit
leakage model.

III. DUAL-EXECUTION PROTOCOLS

Informally, a secure-computation protocol needs to satisfy
two properties: privacy, which ensures private inputs are
not revealed improperly, and correctness, which guaran-
tees the integrity of the ﬁnal output. Yao’s (semi-honest)
garbled-circuit protocol is easily seen to provide one-sided
privacy against a malicious circuit generator as long as an
OT protocol secure against malicious adversaries is used,
and the evaluator does not reveal the ﬁnal output to the
circuit generator. It thus only remains to provide correctness
guarantees for an honest circuit evaluator against a possibly
malicious generator, and to provide a way for both parties
to receive the output while continuing to provide privacy
guarantees against a malicious generator.

The dual-execution (DualEx) protocol proposed by Mo-
hassel and Franklin [30] provides a mechanism to achieve
these guarantees. The protocol involves two independent ex-
ecutions of the semi-honest garbled-circuit protocol, where
each participant plays the role of circuit generator in one of
the executions. The outputs obtained from the two execu-
tions are then compared to verify they are identical; if so,
each party simply outputs the value it received. Intuitively,
this may leak an extra bit of information to an adversary
who runs the comparison protocol using an incorrect input.
We describe the protocol and method for comparing
outputs in more detail next. Note that Mohassel and Franklin
left some details of the protocol unspeciﬁed, and did not
give a proof of security. They also did not provide any
implementation of their approach.

A. Notation

We write a set of wire-label pairs as a matrix:

(cid:32)

W =

w0
w1

1 w0
2
1 w1
2

··· w0
··· w1

(cid:96)

(cid:96)

(cid:33)

.

A vector of wire labels is denoted as

w = (w1, w2, . . . , w(cid:96)) .

If v ∈ {0, 1}(cid:96) is a string and W is a matrix as above, then
we let

Wv = (wv1

1 , . . . , wv(cid:96)
(cid:96) )

be the corresponding vector of wire labels.

B. Protocol

Assume the parties wish to compute some function f, and
(for simplicity) that each party holds an n-bit input and that
f produces an (cid:96)-bit output.

Figure 1 depicts an overview of the basic DualEx protocol.
This is essentially the protocol described in Section 4.1 of
Mohassel and Franklin’s paper [30]. The protocol consists of
two separate runs of a particular semi-honest protocol plus a
ﬁnal stage for verifying that certain values computed during
the course of the two semi-honest executions are identical.
A more detailed description of the DualEx protocol is
shown in Figure 2. The protocol is conceptually divided
into three stages: the ﬁrst run, the second run, and the

274

Figure 1. DualEx protocol overview (informal).

secure validation. For the sake of performance, however, our
implementation executes the ﬁrst two stages concurrently,
using pipelining to overlap the circuit-generation and circuit-
evaluation work for each party (see Section VI). (As long
as the oblivious transfers are done sequentially, our security
proof is unaffected by performing the two garbled-circuit
executions in parallel. The reason is that our security proof
holds even against a “worst-case” adversary who waits to
receive the entire garbled circuit from the honest party before
sending any of its own garbled gates.) We stress that the
parties run each of the ﬁrst two stages to completion — even
if an error is encountered — so that no information is leaked
about the presence or absence of errors in an execution. If an
error is detected that prevents normal progress, the execution
continues using random values.

The DualEx protocol uses a speciﬁc garbled-circuit pro-
tocol with an oblivious-transfer sub-protocol secure against
malicious adversaries (see Figure 3). After an execution of
this protocol, only P2 learns the output (but is uncertain
about
its correctness), while P1 learns nothing. In this
version, the result f (x, y) is revealed to P2 (Bob in the
ﬁrst execution as deﬁned in Figure 2) even if cheating by
P2 is detected during the equality-checking protocol. This
does not violate our deﬁnition of security, however for many
scenarios this property would be undesirable. Section VII
presents some heuristic enhancements to the basic protocol
that address this issue by limiting the amount of information
either party can obtain during the protocol execution.

C. Secure Output Validation

The goal of the secure validation protocol is to verify
the correctness of the outputs Alice and Bob obtained in
the previous stages. The validation protocol consists of an
equality test between certain output-wire labels held by
each of the parties. Since half the output-wire labels chosen
by the garbled-circuit generator are never learned by the
circuit evaluator (and since output-wire labels are chosen at
random) this has the effect of preventing an adversary from
(usefully) changing their input to the equality test. In an
honest execution, on the other hand, since both executions

275

of the garbled-circuit sub-protocol are computing the same
function on the same inputs, the inputs to the equality test
will be equal.

The equality test will be done by ﬁrst (a) computing a
hash of the inputs at both sides, and then (b) comparing the
hashes using an equality test that is secure against malicious
adversaries. (See Figure 4.) If the hash used in the ﬁrst
step is modeled as a random oracle (with sufﬁciently large
output length), then it is possible to show that this results in
an equality test for the original inputs with security against
malicious adversaries.

Input to Alice: the private input x.
Input to Bob: the private input y.
Output to both Alice and Bob: f (x, y), or ⊥ if
cheating is detected.
Execution:

1) Alice and Bob run the semi-honest garbled-circuit
protocol (Figure 3) where Alice plays the role of
circuit generator (P1), and Bob plays the role of
circuit evaluator (P2). Alice knows the 2(cid:96)
output-wire labels she generated, WA, while Bob
learns (cid:96) output-wire labels wB and an output
vB ∈ {0, 1}(cid:96). (If both parties are honest,
wB = WvB
A .)

2) Alice and Bob invoke the semi-honest garbled

circuit protocol again, swapping roles. Alice
learns the output vA along with labels wA, while
Bob knows the label pairs WB. (If both parties
are honest, then wA = WvA
B , and also vA = vB.)

3) Alice and Bob run a “validation protocol” (i.e.,

an equality test), secure against malicious
adversaries. (See Figures 4 and 5 for one possible
A (cid:107)wA and Bob
instantiation.) Alice uses input WvA
uses input wB(cid:107)WvB
B . If the protocol outputs true,
then Alice outputs vA and Bob outputs vB.
Otherwise, the honest party has detected
malicious behavior and outputs ⊥.
Figure 2. DualEx protocol

Simply exchanging the hashes and doing local comparison
is problematic, because this may reveal information on the
outputs of the circuit evaluation which is supposed to be
hidden from the generator unless the validation check passes.
For example, already knowing all the output-wire label pairs,
the generator who learns the evaluator’s hash can test for
candidate output values. Therefore, it is of vital importance
to keep the hashes secret throughout the comparison protocol
if the equality test fails.

A (cid:107)wA) and h2 = H(wB(cid:107)WvB

The most straightforward realization of the equality test
is to use a generic garbled-circuit protocol (with malicious
security). The inputs to the circuit are the hashes h1 =
H(WvA
B ), while the circuit
is simply a bunch of bitwise XORs (to compute h1 ⊕ h2)
followed by a many-to-1 OR circuit that tests if all bits of
h1 ⊕ h2 are zero. This still requires running a full garbled-
circuit protocol with malicious security, however, which can
be expensive.

An alternative is to view an equality test as computing
the intersection of two singleton sets. Private set intersection
has been widely studied in many contexts, including in the
presence of malicious adversaries [9, 13, 5, 20, 21, 7]. We
derive our secure equality-test protocol (Figure 5) by spe-
cializing the ideas of Freedman et al. [9] based on additively
homomorphic encryption. The basic protocol enables P2 to
prove to P1 that he holds an hB that is equal to hA in

(cid:33)

.

(cid:32)

w0
w1

Input from P1: private input x.
Input from P2: private input y.
Output to P1: the output wire key pairs
WA =
Output to P2: vB ∈ {0, 1}(cid:96) representing the value of
f (x, y), and output-wire labels
A2 ,··· , wvB(cid:96)
wB = (wvB1
A(cid:96) ).
Execution:

··· w0
··· w1

A1 w0
A2
A1 w1
A2

A1 , wvB2

A(cid:96)

A(cid:96)

1) P1 and P2 run a garbled-circuit protocol where
P1 plays the circuit generator’s role and P2 the
circuit evaluator’s role.

2) P1 and P2 execute a malicious OT protocol (with

P1 the sender and P2 the receiver) to enable P2
to learn the wire labels corresponding to P2’s
input y. Then P2 evaluates the garbled circuit to
learn output-wire labels wB.

3) P1 computes(cid:32)

(cid:33)

H(w0
H(w1

A1)··· H(w0
A(cid:96))
A1)··· H(w1
A(cid:96))

for H a random oracle, and sends it to P2 so that
it can use wA to learn vB.

4) If P2 detects cheating at any point during the
protocol, he does not complain but instead just
outputs completely random vB and wB.
Figure 3. Semi-honest garbled-circuit sub-protocol

276

a privacy-preserving fashion. This basic protocol will be
invoked twice with the parties swapping roles. We remark
that the protocol that results does not appear to achieve
the standard notion of (simulation-based) security against
malicious adversaries. Nevertheless, under the assumption
that h1, h2 are independent, random values (of sufﬁcient
length), it does, informally, satisfy the following properties
even against a malicious adversary: (1) no information about
the honest party’s input is leaked to the malicious party,
and (2) the malicious party can cause the honest party to
output 1 with only negligible probability. We conjecture
that our proof of security in Section V can be adapted for
equality-testing protocols having these properties.

First of all, P1 sends to P2 α0 = (cid:74)−h1(cid:75). Then, P2
computes e =(cid:74)r × (h2 − h1) + s(cid:75), using the homomorphic

properties of the encryption scheme, as follows

r ∗(cid:0)(h2 ∗ α1) + α0

(cid:1) + s ∗ α1

where ∗ and + here denote homomorphic addition and
constant multiplication, respectively. In addition, P2 sends
h = H(s, h2). P1 decrypts the result
to recover ˆs =
r × (h2 − h1) + s, which is equal to s in case h2 = h1
but a random value otherwise. Finally, P1 checks whether
H(ˆs, h1) = h.

In contrast to the “malicious-client” protocol by Freed-
man et al. [9], it is unnecessary for P1 to verify that P2
followed the protocol (even though it could). The reason is
a consequence of several facts:
(a) P2 doesn’t gain anything from seeing (α0, α1, s1);
(b) it is of P2’s own interest to convince P1 that h1 = h2;
(c) the test only passes with negligible probability if P2

cheats.

This three-round protocol satisﬁes the properties claimed
earlier even when both Alice and Bob are malicious. The in-
formal arguments are as follows. To see that Alice’s privacy

is guaranteed, note that (cid:74)−hA(cid:75) hides −hA thanks to the

semantic security offered by the homomorphic encryption
scheme. Bob’s privacy is also guaranteed by the semantic se-
curity of both the homomorphic encryption scheme and the
cryptographic hash function (in the random-oracle model).

Input to Alice: WvA
A , wA.
Input to Bob: wB, WvB
B .
Output to both Alice and Bob:

(cid:40)

true,

if WvA

A = wB and wA = WvB
B ;

false, otherwise.

Execution:
A (cid:107)wA);
1) Alice computes h1 = H(WvA
2) Bob computes h2 = H(wB(cid:107)WvB
B );
3) Alice and Bob uses an equality test (secure

against malicious adversaries) to compare h1 and
h2. If they are equal, Alice and Bob both output
true; otherwise they output false.

Figure 4. An instantiation of the secure-validation protocol.

IV. SECURITY ANALYSIS

This section clariﬁes what it means to leak a single bit on
average, and informally discusses possible attack strategies.
In Section V, we provide a proof that the deﬁned protocol
satisﬁes the desired property of not leaking more than one
bit on average beyond what can already be inferred from the
outputs.

A. Leakage and Detection Probability

As argued at the beginning of Section III, there is no
privacy loss for the evaluator when a semi-honest garbled
circuit protocol is executed if the result is not disclosed
to the circuit generator. This works in both directions for
our DualEx protocol, so the only concern is how much
information is leaked by the equality test. The output of
the equality test is just a single bit.

In an information theoretic sense, the maximum average
leakage is achieved when the adversary can partition the
victim’s possible private inputs into two subsets which are
equally likely. This assumes the attacker know the a priori
distribution of the victim’s private inputs, and can design the
malicious circuit to produce incorrect results on an arbitrary
subset of inputs. Since the other party learns when the
equality test fails, a malicious adversary can achieve the
maximum expected information gain by designing a circuit
that behaves correctly on the victim’s private inputs half the
time, and incorrectly (that is, it produces an output that will
fail the equality test) on the other inputs.

This extra information does not come free to the adver-
sary, however. If the equality test fails, the victim learns that
the other party misbehaved. So, for the maximum average
leakage circuit which divides the private inputs into two
equally likely subsets the attacker learns one extra bit on
every protocol execution but has a 1/2 probably of getting
caught.

An attacker who does not want to get caught, can (possi-
bly) design a circuit that divides the other parties private
inputs into two subsets where the ﬁrst subset for which
the equality test passes contains 0 < e ≤ 1/2 of the
input distribution. (It makes no sense for e > 1/2 since
then the equality test fails on more than half of the inputs,

Input to P1: h1; decryption key skP1.
Input to P2: h2.
Public inputs: Public key pkP1.
Output to P1: true if h1 = h2; false otherwise.
Output to P2: ⊥.
Execution:

1) P1 sends to P2 α0 =(cid:74)−h1(cid:75).
(e, h) = ((cid:74)r × (h2 − h1) + s(cid:75) , H2(s, h2)), and

2) P2 picks random r, s, computes

sends (e, h) to P1.

3) P1 computes ˆs = Dec(e). If H(ˆs, h1) = h, P1

outputs true; otherwise, it outputs false.

Figure 5. A one-sided equality-testing protocol. For a discussion of the
security guarantees provided, see the text.

277

and the attacker is more likely to get caught than if the
subsets are swapped.) In the extreme, an attacker who only
cares about one particular private input, x∗ could create a
circuit that behaves correctly on all inputs except for x∗.
The attacker would have no chance of getting caught except
when the target input is matched, but would gain very little
information otherwise. This suggests, unsurprisingly, that it
is unwise to execute a secure computation many times since
each execution leaks some information. This is true even for
a maliciously secure protocol since the output itself leaks
information, and, even with a maliciously secure protocol,
an attacker can alter its own inputs to probe the victim’s
private inputs.

The implications of the single-bit leakage depend on the
application, and in some scenarios leaking even a single
bit may be unacceptable. On the other hand, for many
applications this is much less information that an adversary
can infer from the outputs, even if a maliciously secure
protocol is used. Further, our analysis assumes the worst case
where the adversary may implement an arbitrary partitioning
function. It may be possible to take advantage of constraints
in the circuit design to limit the possible partitioning func-
tions that can be implemented, and to combine this with
delayed revelation protocols (see Section VII) to further limit
the actual information an adversary can obtain, although we
have no yet found a principled way to provide meaningful
constraints on the possible partitioning functions.
B. Attacker Strategies

There are several possible strategies a malicious attacker
may use against a DualEx protocol. The attacks may be
grouped into three main types1: selective failure, in which
the attacker constructs a circuit that fails along some exe-
cution paths and attempts to learn about the other party’s
private inputs from the occurrence of failure, false function,
in which the attacker constructs a circuit that implements
function that is different from the agreed upon function, and
inconsistent inputs, in which the attacker provides different
inputs to the two executions. Note that the formal security
proof presented in Section V is independent of any speciﬁc
attack strategy.
Selective failure. In a selective failure attack, a malicious
party engages in the protocol in a way that causes it to
fail for a subset of the other party’s possible inputs. This
could be done by either putting bad entries into a garbled
truth table, or by providing bad input wire labels in the OT
for some values. If the protocol succeeds, in addition to
knowing the secure computation outcome, the attacker also
eliminates some possibilities of the peer’s private inputs. If
the protocol fails, the attacker still learns something about
the peer’s inputs, but the misbehavior will be detected by
the peer.

One characteristic of our garbled circuit implementation is
that the circuit evaluator can always proceed to the normal

1We do not consider side-channel attacks, which are possible if the
protocol implementation is not done carefully, but only focus on protocol-
level attacks here.

termination even when some intermediate wire labels are
broken (possibly due to the selective failure attack) since
the evaluator never checks the validity of those wire labels
except for the ﬁnal wires. This is desirable because it
conceals the positions where the fault occurs, constraining
the amount of leakage to merely a single bit on average.
False function. A malicious participant can generate a
circuit that computes some function, g, that is different from
the function f which the other party agreed to compute. The
malicious circuit function g has the same output format as
f, enabling the attacker to learn if g(x, y) = f (x, y), in
addition to knowing the desired output f (x, y). However,
the adversary has to risk being caught if g(x, y) (cid:54)= f (x, y).
This attack is intrinsic to the design of dual execution
protocols. However, the space of g can be limited by the
structure of the circuit, which is already known to the
evlauator. Although the other party cannot determine if
the individual garbled tables perform the correct logical
function, it can verify that (a) the circuit uses a prede-
ﬁned number of gates, (b) the gates are interconnected as
presumed, (c) all XOR gates show up as presumed (since
these are implemented using the free-XOR optimization),
and (d) all non-free gates are positioned correctly. Limiting
the set of functions g that could be implemented by the
adversary, depends on understanding the possible functions
that can be computed with a given circuit structure by
changing the binary operations of non-free gates in the
circuit. Analyzing a given circuit structure for more precise
quantiﬁcation of the leakage can be an interesting future
work.
Inconsistent inputs. The adversary can also provide differ-
ent inputs to the two protocol executions so that the equality
test reveals if f (x, y) = f (x(cid:48), y) (where x (cid:54)= x and are
selected by the adversary) in the secure validation stage. For
example, for any input wire corresponding to Alice’s private
input, Alice as a circuit generator could send to Bob a label
representing 1, whereas as a circuit evaluator uses 0 as her
input to the OT protocol to obtain a wire label representing
0 for evaluation.

These attacks appear to give the malicious adversary a
great deal of power. However, as we prove in the next
section, regardless of the adversary’s strategy, the essential
property of dual execution protocols is that the leakage is
limited to the single bit leaked by the equality test.

V. PROOF OF SECURITY

We give a rigorous proof of security for the DualEx
protocol following the classic paradigm of comparing the
real-world execution of the protocol to an ideal-world exe-
cution where a trusted third party evaluates the function on
behalf of the parties [10]. The key difference is that here we
consider a non-standard ideal world where the adversary is
allowed to learn an additional bit of information about the
honest party’s input.

We remark that, for reasons described throughout

the
text, the proof here does not apply to our implementation

instead refers to the DualEx protocol from
per se, but
in Figure 2, instantiated using the garbled-circuit protocol
from Figure 3, where the equality test in Figure 2 and the
oblivious transfers in Figure 3 are done using protocols that
achieve the standard (simulation-based) notion of security
against malicious adversaries, and the oblivious-transfer sub-
protocols are run sequentially.

A. Deﬁnitions

Preliminaries. We use n to denote the security parameter.
A function µ(·) is negligible if for every positive polynomial
p(·) and all sufﬁciently large n it holds that µ(n) < 1/p(n).
A distribution ensemble X = {X(a, n)}a∈Dn, n∈N is an
inﬁnite sequence of random variables indexed by a ∈ Dn
and n ∈ N, where Dn may depend on n.
Distribution ensembles X = {X(a, n)}a∈Dn, n∈N and
Y = {Y (a, n)}a∈Dn, n∈N are computationally indistinguish-
c≡ Y , if for every non-uniform polynomial-
able, denoted X
time algorithm D there exists a negligible function µ(·) such
that for every n and every a ∈ Dn

(cid:12)(cid:12)(cid:12) Pr[D(X(a, n)) = 1] − Pr[D(Y (a, n)) = 1]

(cid:12)(cid:12)(cid:12) ≤ µ(n).

We consider secure computation of single-output, deter-
ministic functions where the two parties wish to compute
some (deterministic) function f with Alice providing in-
put x, Bob providing input y, and both parties learning the
result f (x, y). We assume f maps two n-bit inputs to an
(cid:96)-bit output.

A two-party protocol for computing a function f is a
protocol running in polynomial time and satisfying the fol-
lowing correctness requirement: if Alice begins by holding
1n and input x, Bob holds 1n and input y, and the parties run
the protocol honestly, then with all but negligible probability
each party outputs f (x, y).
Security of protocols. We consider static corruptions by
malicious adversaries, who may deviate from the protocol
in an arbitrary manner. We deﬁne security via the standard
real/ideal paradigm, with the difference being that we use
a weaker version of the usual
ideal world. Speciﬁcally,
in the standard formulation of the ideal world there is a
trusted entity who receives inputs x and y from the two
parties, respectively, and returns f (x, y) to both parties.
(We ignore for now the issue of fairness.) In contrast, here
we consider an ideal world where a malicious party sends
its input along with an arbitrary boolean function g, and
learns g(x, y) in addition to f (x, y). (The honest party
still learns only f (x, y).) Note that in this weaker ideal
model, correctness and input independence still hold: that
is, the honest party’s output still corresponds to f (x, y) for
some legitimate inputs x and y, and the adversary’s input
is independent of the honest party’s input. Privacy of the
honest party’s input also holds, modulo a single additional
bit that the adversary is allowed to learn.
Execution in the real model. We ﬁrst consider the real
model in which a two-party protocol Π is executed by Alice

278

and Bob (and there is no trusted party). In this case, the
adversary A gets the inputs of the corrupted party and
arbitrary auxiliary input aux and then starts running the
protocol, sending all messages on behalf of the corrupted
party using an arbitrary polynomial-time strategy. The honest
party follows the instructions of Π.
Let Π be a two-party protocol computing f. Let A be
a non-uniform probabilistic polynomial-time machine with
auxiliary input aux. We let VIEWΠ,A(aux)(x, y, n) be the
random variable denoting the entire view of the adversary
following an execution of Π, where Alice holds input x and
1n, and Bob holds input y and 1n. Let OUTΠ,A(aux)(x, y, n)
be the random variable denoting the output of the honest
party after this execution of the protocol. Set
REALΠ,A(aux)(x, y, n) def=

(cid:0)VIEWΠ,A(aux)(x, y, n), OUTΠ,A(aux)(x, y, n)(cid:1) .

Execution in our ideal model. Here we describe the ideal
model where the adversary may obtain one additional bit
of information about the honest party’s input. The parties
are Alice and Bob, and there is an adversary A who
has corrupted one of them. An ideal execution for the
computation of f proceeds as follows:
Inputs: Alice and Bob hold 1n and inputs x and y, respec-
tively; the adversary A receives an auxiliary input aux.
Send inputs to trusted party: The honest party sends its
input to the trusted party. The corrupted party controlled
by A may send any value of its choice. Denote the
pair of inputs sent to the trusted party as (x(cid:48), y(cid:48)). (We
assume that if x(cid:48) or y(cid:48) are invalid then the trusted
party substitutes some default input.) In addition, the
adversary sends an arbitrary boolean function g to the
trusted party.
Trusted party sends output: The trusted party computes
f (x(cid:48), y(cid:48)) and g(x(cid:48), y(cid:48)), and gives both these values to
the adversary. The adversary may at this point tell the
trusted party to stop, in which case the honest party is
given ⊥. Otherwise, the adversary may tell the trusted
party to continue, in which case the honest party is
given f (x(cid:48), y(cid:48)). (As usual for two-party computation
with malicious adversaries, it is impossible to guarantee
complete fairness and we follow the usual convention
of giving up on fairness altogether in the ideal world.)
Outputs: The honest party outputs whatever it was sent by
the trusted party; A outputs an arbitrary function of its
view.

f,A(aux)(x, y, n) (resp., OUThon

We let OUTA
f,A(aux)(x, y, n)) be
the random variable denoting the output of A (resp., the
honest party) following an execution in the ideal model as
described above. Set
IDEALf,A(aux)(x, y, n) def=

(cid:16)

(cid:17)

.

OUTA

f,A(aux)(x, y, n), OUThon

f,A(aux)(x, y, n)

Deﬁnition 1 Let f, Π be as above. Protocol Π is said to
securely compute f with 1-bit leakage if for every non-uni-
form probabilistic polynomial-time adversary A in the real
model, there exists a non-uniform probabilistic polynomial-

279

time adversary S in the ideal model such that

(cid:8)IDEALf,S(aux)(x, y, n)(cid:9)

(cid:8)REALΠ,A(aux)(x, y, n)(cid:9)

x,y,aux∈{0,1}∗

c≡

x,y,aux∈{0,1}∗

Remark. In the proof of security for our protocol, we
consider a slight modiﬁcation of the ideal model described
above: namely, the adversary is allowed to adaptively choose
g after learning f (x(cid:48), y(cid:48)). Although this may appear to be
weaker than the ideal model described above (in that the
adversary is stronger), in fact the models are identical. To
see this, ﬁx some adversary A = (A1,A2) in the “adaptive”
ideal world, where A1 denotes the initial phase of the
adversary (where the adversary decides what input to send
to the trusted party) and A2 denotes the second phase of the
adversary (where, after observing f (x(cid:48), y(cid:48)), the adversary
speciﬁes g). We can construct an adversary A(cid:48) in the “non-
adaptive” ideal world who learns the same information: A(cid:48)
runs A1 to determine what input to send, and also submits
a boolean function g(cid:48) deﬁned as follows: g(cid:48)(x(cid:48), y(cid:48)) runs
A2(f (x(cid:48), y(cid:48))) to obtain a boolean function g; the output
is g(x(cid:48), y(cid:48)).

B. Proof of Security

We assume the DualEx protocol runs in a hybrid world
where the parties are given access to trusted entities com-
puting two functions: oblivious transfer and equality testing.
(These trusted entities operate according to the usual ideal-
world model where there is no additional one-bit leakage.)
We show that the DualEx protocol securely computes f
with one-bit leakage in this hybrid model. It follows from
standard composition theorems [4] that the DualEx protocol
securely computes f with one-bit leakage if the trusted
entities are replaced by secure protocols (achieving the
standard security deﬁnition against malicious adversaries).
Theorem 1. If the garbled-circuit construction is secure
against semi-honest adversaries and H is modeled as a
random oracle, then the DualEx protocol securely computes
f with one-bit leakage in the hybrid world described above.
Proof: Let A denote an adversary attacking the protocol
in a hybrid world where the parties have access to trusted
entities computing oblivious transfer and equality testing.
We assume that A corrupts Bob, though the proof is sym-
metric in the other case. We show that we can construct an
adversary S, running in our ideal world where the parties
have access to a trusted entity computing f, that has the
same effect as A in the hybrid world.

Construct S as follows:
1) S, given inputs y and aux, runs A on the same inputs.
It then simulates the ﬁrst-stage oblivious transfers as
follows: for the ith oblivious transfer, S receives A’s
input bit y(cid:48)
i and returns a random “input-wire label” wi
to A.
n and sends y(cid:48) to the trusted entity

2) S sets y(cid:48) = y(cid:48)

1 ··· y(cid:48)

computing f. It receives in return an output vB.

3) S chooses random output-wire labels
A1 ,··· , wvB(cid:96)
A(cid:96) ) .

def= (wvB1

WvB
A

Then, in the usual way (e.g., [26]), S gives to A a
simulated garbled circuit constructed in such a way
that the output-wire labels learned by A (given the
input-wire labels chosen by S in the ﬁrst step) will
A . Additionally, S chooses random
be precisely WvB
A1 , . . . , w¯vB(cid:96)
w¯vB1

A(cid:96) , deﬁnes
WA =

(cid:18) w0
and gives (cid:18) H(w0

w1

A1

A1

··· w0
··· w1

A(cid:96)

A(cid:96)

(cid:19)
(cid:19)

,

A1)
A1)

H(w1

··· H(w0
··· H(w1

A(cid:96))
A(cid:96))

i , w1

5) Finally, A submits some input wB(cid:107)w(cid:48)

to A. (The notation H(·) just means that S simulates a
random function on the given inputs.) This completes
the simulation of the ﬁrst stage of the protocol.
4) Next, S simulates the second-stage oblivious transfers
by simply recording, for all i, the “input-wire labels”
i ) used by A in the ith oblivious transfer. A
(w0
then sends its second-phase message (which contains
a garbled circuit, input-wire labels corresponding to its
own input, and hashes of the output-wire labels).
B for the equality
test. S then deﬁnes the following boolean function g
(that depends on several values deﬁned above):
a) On input x, y ∈ {0, 1}n, use the bits of x as selec-
tor bits to deﬁne “input-wire labels” wx1
n .
1 , . . . , wxn
Then, run stage 2 of the protocol exactly as an honest
Alice would to obtain vA ∈ {0, 1}(cid:96) and wA. (In
particular,
if some error is detected then random
values are used for vA and wA. These random values
can be chosen by S in advance and “hard coded”
into g.)

A (cid:107)wA is equal to wB(cid:107)w(cid:48)

b) Return 1 if WvA
B; other-
wise, return 0.
S sends g to the trusted party, receives a bit z in return,
and gives z to A.
6) If z = 0 or A aborts, then S sends stop to the trusted
entity. Otherwise, S sends continue. In either case, S
then outputs the entire view of A and halts.
To complete the proof, we need to show that

(cid:8)IDEALf,S(aux)(x, y, n)(cid:9)

(cid:8)REALΠ,A(aux)(x, y, n)(cid:9)

x,y,aux∈{0,1}∗

c≡

x,y,aux∈{0,1}∗
(where, above, the second distribution refers to the execution
of DualEx in the hybrid world where the parties have
access to trusted entities computing oblivious transfer and
equality). This is fairly straightforward since there are only
two differences between the distribution ensembles:
1) In the real world the garbled circuit sent by Alice to A
is constructed correctly based on Alice’s input x, while
in the ideal world the garbled circuit is simulated based
on the input-wire values given to A and the output vB
obtained from the trusted entity computing f.

2) In the real world the output of the honest Alice when
the equality test succeeds is vA, whereas in the ideal
world it is vB (since vB is the value sent to Alice by
the trusted entity computing f).

Computational indistinguishability of the ﬁrst change fol-
lows from standard security proofs for Yao’s garbled-circuit
construction [26]. For the second difference, the probability
(in the ideal world) that
the equality test succeeds and
vB (cid:54)= vA is negligible. The only way this could occur
is if A is able to guess at least one value w¯vBi
Ai ; but, the
only information A has about any such value is H(w¯vBi
Ai ).
Thus, A cannot guess any such value except with negligible
probability.

VI. EVALUATION

A. Implementation

Since there is no need for any party to keep the circuit
locally as is required for cut-and-choose, the execution of
the garbled circuit sub-protocol (Figure 3) can be pipelined
as for ordinary semi-honest secure computing protocols. We
implement this protocol using the framework of Huang et
al. [16]. This framework provides the most efﬁcient known
implementation of semi-honest garbled circuit protocols by
incorporating circuit-level optimizations (including bit width
minimization and extensive use of the free-XOR technique)
and scalability by using a pipelined execution process where
garbled gates are transmitted to the evaluator and evaluated
as they are ready, thereby reducing latency and avoiding the
need for either the generator or evaluator to ever keep the
entire garbled circuit in memory.

In adapting this framework to support dual execution
protocols, we observe that Stage 1 and Stage 2 of the dual
execution protocol are actually two independent executions
of the same semi-honest protocol. Their executions can be
overlapped, with both parties simultaneously running the
execution where they are the generator and the one where
they are the evaluator as two separate threads executing
in parallel. Since the workload for the different roles is
different, this has additional beneﬁts. Because the generator
must perform four encryptions to generate each garbled
table, while the evaluator only has to perform a single
decryption, the workload for the party acting as the generator
is approximately four times that of the evaluator. During
normal pipelined execution, this means the circuit evaluator
is idle most of the time. With simultaneous dual execution,
however, both parties have the same total amount of work
to do, and nearly all the previously idle time can be used
usefully.

B. Experimental Setup

Hardware & Software. The experiments are done on two
standard Dell boxes, each equipped with an Intel R(cid:13) CoreTM 2
Duo E8400 3GHz processor, 8 GB memory. They are
connected with a 100 Mbps LAN. Both boxes are running
Linux 3.0.0-12 (64 bit). The JVM version we used is

280

Sun R(cid:13)JavaTM1.6 SE. Our implementation is available under
an open source license from http://www.MightBeEvil.com.
Security Parameters. We use 80-bit nonces to represent
wire labels. In our implementation of the Naor-Pinkas OT
protocol, we use an order-q cyclic subgroup of Z∗
p where
|p| = 1024 and |q| = 160. For the implementation of OT
extension, we used k = 80 and 80-bit symmetric keys. Our
security parameters conform to the ultra-short security level
recommended by NIST [2].
Applications. We demonstrate the effectiveness of
the
DualEx protocol with several secure two-party computation
applications including private set intersection (PSI), which
enables computing the intersection of two secret sets without
revealing them, secure edit distance (ED), which computes
the edit distance between two secret strings, and private
AES encryption, where the key and message are supplied by
different entities and kept secret throughout the ciphering.
These applications are representative of commonly studied
privacy-preserving applications in the literature and were
selected for easy performance comparison. Our implemen-
tations are based on the framework of Huang et al. [16, 15].

C. Results

Figure 6 summarizes the running time for the three appli-
cations running under different settings. The PSI instance is
computed over two sets each containing 4096 32-bit num-
bers using the Sort-Compare-Shufﬂe with Waksman Network
(SCS-WN) protocol [15]. The edit distance is calculated
from two strings each having 200 8-bit characters. The
AES instance is executed in 128-bit key size mode, with
100 iterations. The measurements are the average time over
20 runs of each protocol with randomly generated private
inputs (of course, in a secure computation protocol, the
running time cannot depend on the actual input values since
all operations must be data-independent). We compare our
results for DualEx protocols with the results for the best
known semi-honest protocols [16, 15], which uses a single
garbled circuit execution using the same framework upon
which our DualEx protocols are built.

The measurements include time spent on direct transfer
of wire labels, the online phase of oblivious transfer, circuit
generation and evaluation, and secure validity test. The time
used to initialize the circuit structure and oblivious transfer
is not included since these are one-time costs that can be
performed off-line.

For symmetric input applications (PSI and ED), we ob-
serve the bandwidth cost of dual execution protocols is
exactly twice of that for semi-honest protocols. The running
time of DualEx protocols running on a dual-core hardware
is only slightly higher than that for the corresponding semi-
honest protocol. All of the work required for the second
execution is essentially done simultaneously with the ﬁrst
execution using the otherwise idle core. The only additional
overhead is the very inexpensive equality test at the end of
the protocol.

On the other hand, for asymmetric input applications like

Figure 6. Time costs comparing to semi-honest protocols.

AES, the dual execution protocol appears to be slower. The
reason is that in the semi-honest settings the party holding
the message is always designated the circuit generator such
that the more expensive oblivious transfers need only to
be used for the encryption key (which is shorter than the
message). In the DualEx protocol every input bit needs to
be obliviously transferred once. Thus, it runs slower than its
semi-honest version deployed in favor of using less OTs.

We do not include the time required to compute the 80
“base” OTs (about 12 seconds) in the timing measurements,
since this is a one-time, ﬁxed cost that can be pre-computed
independent of the actual function to be computed.

Although our implementation is programmed explicitly
in two Java threads, we have also run it using a single
core for fair comparisons. We used the same software and
hardware setup but the processes are conﬁned to be run
on a single core using the taskset utility command.
The corresponding results are shown as the third column
in Figure 6. Note that the added overhead is only 42%–
47% than a semi-honest run even if two semi-honest runs
are included in the dual execution protocol. Recall
that
in the semi-honest garbled circuit protocol, the point-and-
permute [29] technique sets the workload ratio between the
generator and the evaluator to four to one, because the
evaluator needs to decrypt only one of the four entries in
a garbled truth table. Moreover, garbled-row-reduction [34]
optimization brings this ratio down to about 3, since only
3 out of 4 entries in a garbled truth table needs to be
transmitted. Therefore, should the overhead of thread-level
context switch and interferences are ignored, the slowdown
factor of dual execution will be about of 33%. (We assume
the network bandwidth is not the bottleneck, which is true on
a wired LAN.) Our experimental results actually show that
about another 15% of time is lost due to the interferences
between the two threads.

The scale of the circuits used in our experiments above is
already well beyond what has been achieved by state-of-art
maliciously-secure secure two-party computation prototypes.
However, to fully demonstrate the memory efﬁciency of

281

0 10 20 30 40 50 60 70 80 90 PSI (4096) ED (200x200) AES (100) Time (seconds) Semi-honest DualEx (dual-core) DualEx (single-core) map).

The delayed revelation modiﬁcation prevents the semantic
values from being learned at the end of each semi-honest
protocol execution, and supports the two protocol variations
discussed next for revealing the semantic values in a way
that ensures a limited notion of fairness.

A. DualEx-based Equality Test

if it

Our goal is to prevent an adversary from learning the
output
is caught cheating by the equality test. To
achieve this, we introduce a pre-emptive secure equality-test
protocol that is done before output-wire label interpretation.
In addition, compared to the secure equality test used in the
basic DualEx protocol (Section III), the test here has to start
from output-wire labels (as opposed to be able to use the
previously-revealed outputs).

The goal of the pre-emptive equality test

is to com-
pute in a privacy-preserving way the predicate Equal =
AND(Equal 1, Equal 2, . . . , Equal (cid:96)) in which Equali is de-
ﬁned as follows,

if ∃σ, s.t. wAi = wσ

Ai and wBi = wσ

Bi;

(cid:26) 1,

Equal i =

0, otherwise.

where wAi (respectively wBi) is the ith output-wire label
Bob (respectively Alice) obtained from circuit evaluation.

The basic idea is to implement Equal with a garbled
circuit, which ANDs all (cid:96) wires from (cid:96) Equali circuits. The
circuit Equali can be implemented as shown in Figure 8.
The cost of Equali is 2σ non-free gates (where σ is the
length of a wire label), while the Equal circuit requires 2(cid:96)σ
non-free gates. Thus, its cost does not grow with the length
of f’s inputs nor the f’s circuit size (which can be very
large).

We could execute the Equal circuit with any generic
protocol secure against malicious adversaries. Alternatively,
the basic DualEx protocol can be employed to keep the
overhead low. Note that on average one-bit could be leaked
using the DualEx protocol here, but it is a bit about the
random nonces used as wire labels, hence does not expose
the original private inputs.

Figure 7. Time costs for large scale problems.

the dual execution approach, we also report results from
running the PSI and edit distance applications on larger
problem sizes. The timing results are shown in Figure 7 for
performing private set intersection on two sets of one million
32-bit values each, and for an edit-distance computation
with input DNA sequences (2-bit character) of 2000 and
10000. The performance of DualEx protocols remains very
competitive with semi-honest secure computation protocols
even for large inputs.

VII. ENHANCEMENTS

One problem with the basic DualEx protocol is that it
allows the attacker to learn the output of f (x, y) even when
cheating since the output is revealed before the equality test.
Consequently, this advantage for adversaries could actually
encourage participants to cheat and would be unacceptable
in many scenarios.

In this section, we present two heuristic enhancements
that aim at mitigating the problem. (We leave formal def-
initions and proofs of security for future work.) The ﬁrst
enhancement, called progressive revelation,
is the most
straightforward and guarantees that the adversary has can
only learn one more bit of the output than the honest party.
The second enhancement, we call DualEx-based equality
test, ensures the outputs are revealed only after the equality
check passes. Note that since the two enhancements are
orthogonal, they can be combined to construct a improved
DualEx protocol that beneﬁts from both.

In both enhancements,

to prevent early revelation of
outputs we change the output revelation process in the basic
DualEx protocol by replacing the ﬁnal step in the garbled
circuit sub-protocol (execution step 3 from Figure 3) with a
step that just outputs the wire labels without decoding their
semantic values:
3) P1 outputs W1 that it produced when generating the
1 that it obtains from circuit

circuit, while P2 outputs wv2
evaluation.

This changes the output P2 receives to only include the
output-wire labels (and not the underlying bits to which they

Figure 8. Circuit realization of Equali.

282

0 1 2 3 4 5 6 7 PSI (2M) ED (2000x10000) Time (Hours) Semi-honest DualEx (dual-core) B. Progressive Revelation

The goal of this variation is to reveal the output wires to
both parties in a bitwise fashion, until cheating (if there is
any) is detected on one output wire. Hence, if the outputs
match exactly, both parties will receive the full output at
the end of the protocol. If the outputs do not match, both
parties will receive the same matching output bits until the
ﬁrst mismatch and the adversary receives at most a single
additional mismatched output bit.

The idea resembles that of the gradual release protocols
used for exchanging secret keys [3, 6], signing contracts [8],
and secure computation [18]. In our scenario, to reveal the ith
bit of the output, the parties can securely evaluate a circuit
EqualRevi (Figure 9), which tests equality (indicated by
vi) and reveals the output bit (denoted by oi) at the same
time. This circuit looks exactly the same as Equali except
it has an extra oi bit which set to 0 if and only if wAi =
Bi. The vi = 1 bit implies the oi bit is
w0
indeed valid.

Ai and wBi = w0

ACKNOWLEDGMENTS

The authors thank Peter Chapman, Greg Morrisett, Abhi
Shelat, David Wagner, and Samee Zahur for useful com-
ments on this work. This work was supported by grants
from the National Science Foundation, Air Force Ofﬁce
of Scientiﬁc Research, and DARPA. The contents of this
paper, however, do not necessarily reﬂect the views of the
US Government.

REFERENCES

[1] Y. Aumann and Y. Lindell. Security against covert
adversaries: Efﬁcient protocols for realistic adversaries.
Journal of Cryptology, 23(2):281–343, 2010.

[2] E. Barker, W. Barker, W. Burr, W. Polk, and M. Smid.
NIST special publication 800-57: Recommendation for
key management — part 1, March 2007.

[3] M. Blum. How to exchange (secret) keys. ACM Trans-

actions on Computer Systems, 1(2):175–193, 1983.

[4] R. Canetti.

Security and composition of multi-
party cryptographic protocols. Journal of Cryptology,
13(1):143–202, 2000.

[5] D. Dachman-Soled, T. Malkin, M. Raykova, and
M. Yung. Efﬁcient robust private set intersection. In 7th
Intl. Conference on Applied Cryptography and Network
Security (ACNS), volume 5536 of LNCS, pages 125–
142. Springer, 2009.

[6] I. Damg˚ard.

Practical and provably secure release
Journal of

of a secret and exchange of signatures.
Cryptology, 8(4):201–222, 1995.

Figure 9. Circuit realization of EqualRevi.

To further limit an adversary’s advantage, we can require
the output-wire labels interpretation process to be done in
an order that is collectively determined by both parties. For
example, let pa and pb denote two random permutations
solely determined by Alice and Bob, respectively. The two
parties will reveal the output bits in the order determined
by the permutation p = pa ⊕ pb. Note that to make sure
each party samples its random permutation independent of
the other’s permutation, pa and pb need to be committed
before they are revealed.

VIII. CONCLUSION

Previous work in secure computation has left an enormous
efﬁciency gap between protocols in the semi-honest and
malicious models. This work demonstrates the potential
of an alternate approach for security against a malicious
adversary, which relaxes the security properties by allowing
a single bit of extra information to leak. This relaxation
allows us to implement privacy-preserving applications with
much stronger security guarantees than semi-honest proto-
cols, but with minimal extra cost. The applications scale
to large inputs on commodity machines, including million-
input private set intersection.

[7] E. De Cristofaro, J. Kim, and G. Tsudik. Linear-
intersection protocols secure
complexity private set
In Advances in Cryptology —
in malicious model.
Asiacrypt 2010, volume 6477 of LNCS, pages 213–
231. Springer, 2010.

[8] S. Even, O. Goldreich, and A. Lempel. A randomized
protocol for signing contracts. Communications of the
ACM, 28(6):637–647, 1985.

[9] M. J. Freedman, K. Nissim, and B. Pinkas. Efﬁcient
private matching and set intersection. In Advances in
Cryptology — Eurocrypt 2004, volume 3027 of LNCS,
pages 1–19. Springer, 2004.

[10] O. Goldreich. Foundations of Cryptography, vol. 2:
Basic Applications. Cambridge University Press, Cam-
bridge, UK, 2004.

[11] O. Goldreich, S. Micali, and A. Wigderson. How to
play any mental game, or a completeness theorem for
protocols with honest majority. In 19th Annual ACM
Symposium on Theory of Computing (STOC), pages
218–229. ACM Press, 1987.

[12] D. Harnik, Y. Ishai, E. Kushilevitz, and J. B. Nielsen.
OT-combiners via secure computation. In 5th Theory of

283

Cryptography Conference — TCC 2008, volume 4948
of LNCS, pages 393–411. Springer, 2008.

[13] C. Hazay and Y. Lindell. Efﬁcient protocols for set
intersection and pattern matching with security against
In 5th Theory of
malicious and covert adversaries.
Cryptography Conference — TCC 2008, volume 4948
of LNCS, pages 155–175. Springer, 2008.

[14] W. Henecka, S. K¨ogl, A.-R. Sadeghi, T. Schneider,
and I. Wehrenberg.
tool for automating
secure two-party computations. In 17th ACM Conf. on
Computer and Communications Security (CCS), pages
451–462. ACM Press, 2010.

TASTY:

[15] Y. Huang, D. Evans, and J. Katz.

in-
tersection: Are garbled circuits better than custom
protocols? In Network and Distributed System Security
Symposium (NDSS). The Internet Society, 2012.

Private set

[16] Y. Huang, D. Evans, J. Katz, and L. Malka. Faster
secure two-party computation using garbled circuits.
In 20th USENIX Security Symposium, 2011.

[17] Y. Huang, L. Malka, D. Evans, and J. Katz. Efﬁcient
privacy-preserving biometric identiﬁcation. In Network
and Distributed System Security Symposium (NDSS),
pages 421–434. The Internet Society, 2011.

[18] R. Impagliazzo and M. Yung. Direct minimum-
knowledge computations. In Advances in Cryptology
— Crypto ’87, volume 293 of LNCS, pages 40–51.
Springer, 1988.

[19] Y. Ishai, J. Kilian, K. Nissim, and E. Petrank. Ex-
tending oblivious transfers efﬁciently. In Advances in
Cryptology — Crypto 2003, volume 2729 of LNCS,
pages 145–161. Springer, 2003.

[20] S. Jarecki and X. Liu. Efﬁcient oblivious pseudoran-
dom function with applications to adaptive OT and
secure computation of set intersection. In 6th Theory of
Cryptography Conference — TCC 2009, volume 5444
of LNCS, pages 577–594. Springer, 2009.

[21] S. Jarecki and X. Liu. Fast secure computation of
In 7th Intl. Conf. on Security and
set intersection.
Cryptography for Networks, volume 6280 of LNCS,
pages 418–435. Springer, 2010.

[22] S. Jarecki and V. Shmatikov. Efﬁcient two-party secure
In Advances in
computation on committed inputs.
Cryptology — Eurocrypt 2007, volume 4515 of LNCS,
pages 97–114. Springer, 2007.

[23] V. Kolesnikov and T. Schneider.

Improved garbled
circuit: Free XOR gates and applications. In 35th Intl.
Colloquium on Automata, Languages, and Program-
ming (ICALP), Part II, volume 5126 of LNCS, pages
486–498. Springer, 2008.

[24] Y. Lindell, E. Oxman, and B. Pinkas. The IPS com-

piler: Optimizations, variants and concrete efﬁciency.
In Advances in Cryptology — Crypto 2011, volume
6841 of LNCS, pages 259–276. Springer, 2011.

[25] Y. Lindell and B. Pinkas. An efﬁcient protocol for
secure two-party computation in the presence of ma-
In Advances in Cryptology —
licious adversaries.
Eurocrypt 2007, volume 4515 of LNCS, pages 52–78.
Springer, 2007.

[26] Y. Lindell and B. Pinkas. A proof of security of
Yao’s protocol for two-party computation. Journal of
Cryptology, 22(2):161–188, 2009.

[27] Y. Lindell and B. Pinkas. Secure two-party compu-
In 8th
tation via cut-and-choose oblivious transfer.
Theory of Cryptography Conference — TCC 2011,
volume 6597 of LNCS, pages 329–346. Springer, 2011.

[28] Y. Lindell, B. Pinkas, and N. Smart.

Implementing
two-party computation efﬁciently with security against
malicious adversaries. In 6th Intl. Conf. on Security and
Cryptography for Networks (SCN ’08), volume 5229 of
LNCS, pages 2–20. Springer, 2008.

[29] D. Malkhi, N. Nisan, B. Pinkas, and Y. Sella. Fairplay
In Proc.

— a secure two-party computation system.
13th USENIX Security Symposium, 2004.

[30] P. Mohassel and M. Franklin. Efﬁciency tradeoffs for
malicious two-party computation. In 9th Intl. Confer-
ence on Theory and Practice of Public Key Cryptog-
raphy(PKC 2006), volume 3958 of LNCS, pages 458–
473. Springer, 2006.

[31] M. Naor and B. Pinkas. Efﬁcient oblivious transfer
In ACM-SIAM Symposium on Discrete

protocols.
Algorithms (SODA), 2001.

[32] J. Nielsen,

P. Nordholt,

and
A new approach to practical active-
at

S. Burra.
secure
http://eprint.iacr.org/2011/091.

C. Orlandi,

two-party

computation.

Available

[33] J. B. Nielsen and C. Orlandi. LEGO for two-party
In 6th Theory of Cryptography
secure computation.
Conference — TCC 2009, volume 5444 of LNCS, pages
368–386. Springer, 2009.

[34] B. Pinkas, T. Schneider, N. Smart, and S. Williams.
Secure two-party computation is practical. In Advances
in Cryptology — Asiacrypt 2009, volume 5912 of
LNCS, pages 250–267. Springer, 2009.

[35] A. Shelat and C.-H. Shen. Two-output secure com-
In Advances in
putation with malicious adversaries.
Cryptology — Eurocrypt 2011, volume 6632 of LNCS,
pages 386–405. Springer, 2011.

[36] A. C.-C. Yao. How to generate and exchange secrets. In
27th Annual Symposium on Foundations of Computer
Science (FOCS), pages 162–167. IEEE, 1986.

284

