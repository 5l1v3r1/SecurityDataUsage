An Information Theoretic Framework for Web Inference

Detection

Hoi Le Thi and Reihaneh Safavi-Naini

Department of Computer Science

University of Calgary, Canada

{leh, rei}@ucalgary.ca

ABSTRACT
Document redaction is widely used to protect sensitive infor-
mation in published documents. In a basic redaction system,
sensitive and identifying terms are removed from the docu-
ment. Web-based inference is an attack on redaction sys-
tems whereby the redacted document is linked with other
publicly available documents to infer the removed parts.
Web-based inference also provides an approach for detect-
ing unwanted inferences and so constructing secure redac-
tion systems. Previous works on web-based inference used
general keyword extraction methods for document represen-
tation. We propose a systematic approach, based on infor-
mation theoretic concepts and measures, to rank the words
in a document for purpose of inference detection. We extend
our results to the case of multiple sensitive words and pro-
pose a metric that takes into account possible relationship
of the sensitive words and results in an eﬀective and eﬃcient
inference detection system.

Using a number of experiments we show that our ap-
proach, when used for document redaction, substantially re-
duce the number of inferences that are left in a document.
We describe our approach, present the experiment results,
and outline future work.

Categories and Subject Descriptors
H.1.1 [Systems and Information Theory ]: Information
theory; H.4 [Information Systems Applications]: Mis-
cellaneous

Keywords
inference detection,
tion, web-based inference detection

information theory, document redac-

1.

INTRODUCTION

The knowledge encapsulated in the Web combined with
the power of search engines, makes it easy to look for un-
knowns and make unexpected ﬁndings. Search queries on

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
AISec’12, October 19, 2012, Raleigh, North Carolina, USA.
Copyright 2012 ACM 978-1-4503-1664-4/12/10 ...$15.00.

multiple words and phrases that are relevant to a search
target, can narrow down the search results and in many
cases identify a single target. On the other hand this power
of Web search makes it very hard to “hide” information or
remain anonymous.
Inferring individuals’ details by com-
bining anonymized Netﬂix databases and other public data
made headline news a few years ago [22].

An important security mechanism that is severely chal-
lenged by the public knowledge on the Web and the power of
search engines, is document redaction. Document redaction
systems protect sensitive contents of documents by remov-
ing a subset of words. Document redaction is widely used in
practice and is the main protection mechanism that is used
for privacy protection when complying with Freedom of In-
formation Legislations. For example in the U.S., redaction
is used to protect patients’ privacy when their information
needs to be shared with other parties.

The information that is left in a redacted document how-
ever, can be combined with the public knowledge encap-
sulated in the Web to make inferences about the sensitive
parts. Staddon et al.
[24] showed a Web-based inference
attack that recovers the removed words of a document using
the public information on the Web. They noted that their
approach can also be used for detecting unwanted inferences;
that is inferences that could later leak information about the
removed parts of the document. They also developed a set
of tools to semi-automatically (with the aid of human) de-
tect such inferences. In the rest of this paper we consider
this latter application of their approach.

Web-inference system.
In a Web-inference system, a document that includes sen-
sitive information, and a collection of documents (corpus)
related to the sensitive topic, are at hand. The aim is to
publish the document “safely”: that is publish it such that
the publication does not leak information about the sensitive
content. The redacted document has to stay readable and so
the number of removed words must be kept at a minimum.
A Web-inference system uses the following steps: (i) use a
Natural Language Processing (NPL) tool to extract a set of
keywords from the document, (ii) query on subsets of these
keywords to a Web search engine (e.g. Bing in our case), and
(iii) analyze the returned documents to detect unwanted in-
ferences. (Figure 1 shows the main steps of Web-inference
detection approach for detecting unwanted inferences). An
inference is modeled as co-occurrence of a set of words:
if
w1 and w2 both occur in many documents that include the
sensitive word s, they are considered as precedent of an in-
ference w1 ∧ w2 ⇒ s, where s is the sensitive word.

25Figure 1: Main steps in inference detection.

The above framework can be instantiated using diﬀerent
algorithms for keyword extraction in Step (i) and inference
detection in Step (iii), above. The eﬀectiveness of each step
in an instantiation can be measured by the number of in-
ferences that can be detected, assuming other parts of the
systems are kept ﬁxed. For example, by keeping Steps (ii)
and (iii) ﬁxed, one can evaluate eﬀectiveness of a particular
keyword extraction algorithm (See 2.4).

To extract document keywords, Staddon et al. used a
well-known metric, called TF.IDF (Term Frequency-Inverse
Document Frequency) [19] that requires a set of documents
that was related to the sensitive word. The TF.IDF value of
a word w with respect to a document D and a corpus C, is
deﬁned as T Fw × log(IDFw), where T Fw is the number of
with |C| is the num-
times w occurs in D and IDFw =
ber of documents in C, and DFw is the number of documents
that contain the word w. TF.IDF tends to extract keywords
that are frequent and speciﬁc to the document (IDF is in-
versely proportional to frequency of the occurrence of the
word in the corpus). In this paper we focus on Step (i) and
provide an information theoretic approach to keyword ex-
traction, that naturally matches the inference model (word
co-occurrence). For our future work we will use information
theoretic measure for more accurate detection of inferences
in Step (iii).

|C|
DFw

Our work
We propose an information theoretic approach to document
keyword extraction for the purpose of inference detection,
when inferences are modeled as word co-occurrence.

Keyword extraction. The goal is to select a set of keywords
from the document that “best” capture the document with
respect to the sensitive word(s). The set of keywords, (i)
must be eﬃciently computable, and (ii) when used in the
Web-inference system (Figure 1) should result in the least
amount of undetected inferences in the ﬁnal document, as-
suming other parts of the system are ﬁxed.

Our key observation is that if keywords are extracted
based on the strength of their relationship with the sensitive
word that is calculated using the corpus documents, then in
the Web search phase they would exhibit the similar rela-
tionship in the search results. Unlike the TF.IDF measure
that focuses on the uniqueness of a document in a collection,
our approach focuses on the relationship of words with the
sensitive word(s) and considers those that are “more related”

as more important. We use information theoretic measures
to quantify the strength of the relationship.
Single sensitive word. Let the sensitive keyword be denoted
by s0. We rank the words in the document with respect to
the strength of their relationship with s0, and use the top
(cid:96) ranked words to form the keyword list. The strength of
the relationship of a word wi with s0, denoted by I(wi; s0),
is measured by the mutual information between two binary
random variables Xwi and Xs0 whose distributions corre-
spond to the relative frequencies of the occurrences of the
two words in the documents in the corpus C, respectively.
Note that Xwi does not represent the frequency (number)
of occurrences of wi in C. Rather, it captures presence of
the word wi in the corpus. Similarly, Xwi,s0 represents co-
occurrence of the word wi and the sensitive word s0 in C.
The list of values I(wi; s0) are sorted, and the top l ranked
words will be used as keywords.
Multiple sensitive words. In many cases more than one sen-
sitive words must be protected. We consider multiple sensi-
tive keywords {s1 ··· su}, and the aim is to detect unwanted
inferences with respect to any of the words. Although this
problem was not considered in [24], as we will explain in
section 2.3, there are direct solutions that are based on sin-
gle sensitive word algorithms. However these solutions are
ineﬃcient and require the single sensitive word algorithm to
be repeated once for each sensitive word. We propose an
information theoretic measure Iw,s1,··· ,su that takes into ac-
count the strength of the relationship of w with respect to
the whole set of sensitive words. When the sensitive words
can be considered as “unrelated” (or independent), we will
have:

Iwi,s1,··· ,su = I(wi; s1) + I(wi; s2) + ... + I(wi; su)

For the general case, the expression will be more complex

and is given in Section 2.3.
Tool set and experiments.
We compare our proposed approach to [24] using the same
framework and examples of Staddon et al. For this we devel-
oped a set of tools that allowed us to implement the frame-
work and the two instantiations of keyword extraction algo-
rithm.

We compare performance of the systems, and show the
eﬀectiveness of our keyword extraction approach through a
number experiments. The results of our experiments (Sec-
tion 3) show that our inference detection algorithm performs
consistently better than [24] (almost double the percentage
of inferences found) and [8].

26We note that the result of the experiment in general, will
depend on the choice of corpus. We show however that our
algorithm is not very sensitive to this change, by repeating
the experiments for 3 corpora with diﬀerent qualities, where
quality of a corpus is measured in terms of the relevance of
the corpus to the sensitive word(s).

Signiﬁcance and extensions. Modeling inference as co-occurrence
has been considered in [24, 27] Our proposed information
theoretic measure corresponds to the strength of co-occurrence
of words in documents. The inference detection algorithm
in Step (iii) also uses co-occurrence of words and so the two
steps of the Web-inference system are aligned. (A simple
inference detection procedure for Step (iii) in Figure 1, is to
deﬁne a threshold γ and consider the word set used for the
query as precedent of an unwanted inference, if the sensitive
word(s) occurs in one of the top γ returned documents.)

Our approach can be used to model more complex in-
ferences. As noted in [24] one may consider inferences in
which the precedent and consequent are combinations of
disjunctive and conjunctive forms, such as A ⇒ B where
A is of the form A1 ∧ A2... ∧ An, and B is of the form
B1 ∨ B2...∨ Bm. Deﬁning appropriate information theoretic
quantities to rank words for capturing such inferences is an
interesting open question.

1.1 Related work

Inference detection has been considered by many researchers.

Unwanted inferences in databases has been studied in [23,
28, 6, 7].
In these works, it is shown that the knowledge
about the database such as data schema, data dependen-
cies, domain semantic and even actual data, can be used
to derive inferences about other sensitive information stored
in the database. To protect against such inferences, each
user’s query is analyzed in the context of the past queries to
ﬁnd possible inferences. Based on this analysis, the query is
denied or accepted. These works do not take into account
other public information. In [6] and [7] authors considered
the web access history of the user as an input to detect un-
wanted inferences. However, this information was not taken
into account in their algorithm.

Inferences have also been used to de-identify individuals
([26], [25] and [27]).
In [26] and [25], authors developed
methods to make inferences about the identity of an indi-
vidual or other sensitive data, when data is structured. Ex-
amples of structured data are data from banks and hospitals.
This is diﬀerent from our work (and Staddon et al.) where
no structure is assumed for the data. In [27], a tool is devel-
oped that can be used to infer an identity from a document
using other public documents. The tool takes speciﬁc infor-
mation, that is, SSN numbers, to make inferences about the
birth year and status of an employee.

Other works related to redaction are [14] which presents
a signature scheme that tolerates document changes due to
redaction, and [17] and [18], where attacks on redacted doc-
uments using natural language processing or image and font
analysis are presented.

The works in ([24] and [8]) have the same goal as ours:
inference detection using the Web as public knowledge with
the aim of providing better document redaction. Our work
builds on these works and proposes a keyword selection meth-
ods that best matches the underlying model of inference
(word co-occurrence).

1.1.1 Web-based inference detection
Web-based inference is ﬁrst proposed in [24] as a semi-
automated way for detecting unwanted inferences in a doc-
ument when public knowledge encapsulated in the Web is
taken into account.
Let D be the document that must be redacted. Authors
use TF.IDF (see Section 1) to construct a set K(D) including
the words that have the highest TF.IDF values in D. The
keywords in K(D) are then used to detect inferences by issu-
ing queries on subsets of keywords to a search engine. If the
top γ returned documents contain the sensitive keyword(s),
the set of keywords are considered to be inference enabling.
Extracting keywords using TF.IDF results in words with
high frequency in D that almost do not appear in other doc-
uments in C to be included in K(D). This includes some
high frequency words that are not related to the sensitive
keywords. For example in Section 4, in the case of the docu-
ment with the name Bin Laden redacted, general words such
as “resource” and “support” are more frequent than speciﬁc
words such as “US” and “September”, although, the latter
words are more important.

1.1.2 Detecting Privacy Leaks Using Corpus-based

Association Rules

[8] only focuses on the inference detection technique but
the results can be applied to the redaction problem we are
considering here.
(Authors also develop a redaction tool
based on this algorithm [9]). Authors consider a collection
(corpus) of documents C that is related to a set of sensi-
tive keywords, and search for sets of words (consisting of
a number of words), that co-occur frequently in the collec-
tion C. An editor then selects item sets of interest which
are frequently occurring word sets, and closely related to a
speciﬁc privacy application. The selected sets are then rep-
resented as a list of candidate inferences, each inference is
of the form A ⇒ B, where A and B are Boolean formulas of
items, which means A is of the form A1 ∧ A2... ∧ An, and B
is of the form B1 ∨ B2... ∨ Bm with Ai is from an item set
and Bj is from a set of sensitive keywords. They calculate a
conﬁdence level for each inference and when the conﬁdence
is above a threshold, the inference will become part of the
ﬁnal output.

Our experimental results show that the set of inferences
produced by this approach is incomplete. Also it would be
more eﬀective if words in the private documents are used
directly in the search for these predicted inferences (cur-
rently only the words in the corpus are considered). The
algorithm needs to produce a set of all unwanted inferences
based on the corpus, so the “knowledge” about the sensitive
topic represented in the corpus should be suﬃcient. Gener-
ating a “good corpus” that results in all unwanted inferences
presents major challenges.

2. PROBLEM STATEMENT

We ﬁrst state the inference detection problem in an ab-

stract way, and proceed to give concrete values.
A document is a set of words over an alphabet. We consider
unstructured documents such as those that can be found on
the Web, which can include other symbols including num-
bers and punctuation marks. In deﬁning inference, we use
an intuitive deﬁnition of knowledge and knowledge combi-
nation that has been used in [24]. The aim is to capture the

27notion of inference in its most general form, without limit-
ing oneself to a particular model or notion inference. Let D
denote a private document that contains some sensitive in-
formation. Informally, let K(D) denote the “knowledge” (or
facts, or axioms) that can be extracted from D and assume
that there are knowledge composition rules, which specify
how to derive new knowledge from the combination of exist-
ing pieces of knowledge. (Here we use the term knowledge
that is represented as K(D) without a formal deﬁnition and
only to represent intuition about this concept.)
Denote by ¯K(D) the closure of K(D) under the knowl-
edge composition rules. The rules are abstract rules that
are assumed to be applied repeatedly to the knowledge to
generate/derive new knowledge. The closure of K(D) is the
closed set of all knowledge that can be obtained from K(D)
by repeated application of the composition rules. Before
deﬁning the redaction problem, we deﬁne the inference de-
tection problem.
Inferences detection. Let R denote a collection of ref-
erence documents (such as public Web) that are related to
a topic. The “knowledge” that can be computed from the

union of the private and the reference collection, ¯K(D(cid:83)R),
is in general larger than ¯K(D)(cid:83) ¯K(R), which is the union

of what can be extracted separately from D and R. In the
most general formulation, the inference detection problem is
to ﬁnd and understand the diﬀerence:

δ(D,R) = ¯K(D(cid:83)R) − ( ¯K(D)(cid:83) ¯K(R))

S(cid:84) δ(Dsub,R) = ∅. While Dsub = ∅ trivially satisﬁes this

Document redaction. We are given a set S of sen-
sitive keywords that the publication of D should not ex-
Ideally, redaction of a document D with respect to
pose.
the sensitive keyword set S and a reference document set
R, is ﬁnding a subset Dsub of D such that the intersection
condition, the goal is to have a subset Dsub of a “good” size
in the sense that it preserves the usefulness of the original
document while protecting S.
2.1 Redaction system

We consider a redaction system that detects and removes
unwanted inferences. The system consists of two major
steps: (i) Inference detection and (ii) Breaking inferences by
removing words. We focus on (i) and in particular keyword
extraction. For completeness we also include an overview of
the other part.
2.1.1 Inference detection algorithm
Input: Document D, a sensitive keyword s0, public Web

documents.

Output: A list L of inferences, of the form:

(w1, ..., wk) ⇒ s0

where w1, ..., wk are keywords extracted from document D.
Here we only consider a single sensitive word.

Step 1. Preprocessing. Use a NLP (Natural Lan-
guage Processing) tool to “clean”D and remove “stop” words.
These are common words in the language that are unlikely
to be related to the sensitive keyword. For example, in En-
glish “the”, “an”, “a”, “do”, are considered stop words. Our
tool takes a list of previously deﬁned stop words and removes
them together with s0 from D to form Dp.

Step 2. Extract keywords from the document Dp
with respect to s0. K(D) consists of all the words in Dp
whose mutual information with s0 is greater than a threshold
α.
The algorithm requires a corpus C of related documents to
s0. We construct a corpus C of documents related to s0 by
using a search engine to search for documents that contain
s0 on the public Web and then choose a subset of documents
that appear more related.
For each word w ∈ Dp, we calculate the mutual infor-
mation between w and s0 (I(w, s0)) for each document in
C, and average the result over all documents in the corpus.
Details are below.

We consider each paragraph in a document as a subdoc-
ument. Let Xw and Xs0 denote two binary variables that
takes the value 1, if w and s0 appear in a subdocument,
respectively. We estimate the probability Pr(Xw = 1) by
ﬁnding the number of paragraphs that contain w, divided
by the total number of paragraphs in the document. A sim-
ilar approach will be used to ﬁnd distribution of Pr(Xs0 )
and also the joint distribution Pr(Xw, Xs0 ). The mutual
information between Xw and Xs0 based on the corpus C is
calculated, and the the top (cid:96) words with the highest mutual
information are outputted.
SelectKeywords (Dp, s0)
– For each document Dj in C
– Calculate Ij(Xwi ; Xs0 ) = H(Xwi )+H(Xs0 )−H(Xwi , Xs0 )
for each wi ∈ Dp
– Take Iwi = 1
n
– Select the top l words that have highest Iw
Here n is the number of documents in the corpus C, H(X)
is the entropy of the random variable X, and H(X1, X2) is
the joint entropy of two random variables X1 and X2 :

j=1 Ij(wi; s0)

(cid:80)n

H(X) = −(cid:88)
H(X1, X2) = − (cid:88)

x∈X

x1∈X1,x2∈X2

p(x)log2p(x)

p(x1, x2)log2p(x1, x2)

The probabilities of the random variables Xw and Xs0 can
be estimated as relative frequencies in C as follows:

Pr(Xwi = 1, Xs0 = 1) =
nwi
Pr(Xwi = 1) =
nj
Pr(Xs0 = 1) = ns0
nj

nwi∧s0

nj

where nj is the number of subdocuments in the docu-
ment Dj, nwi∧s0 is the number of subdocuments in Dj that
contain both wi and s0, and nwi , ns0 are the numbers of
subdocuments in Dj contain wi, s0 respectively.
Step 3. Inference analysis. The list L of inferences is
initially empty. We consider every subset K(cid:48) ⊆ K(D) of size
|K(cid:48)| = β, K(cid:48) = (w1, ..., wβ), and do the following:

1. Issue queries on (w1, ..., wβ) to a search engine and
use the top γ documents based on the search engine’s
rankings (γ is an integer > 0).

2. Find s0 in the top γ documents, if s0 appears, we add

to L the inference K(cid:48) ⇒ s0.

28Breaking inferences by removing words.

2.1.2
A simple approach to secure redaction is to remove all
words in the precedents of unwanted inferences in L from D
to obtain Dsub. However to increase the readability, one can
use more reﬁned methods to minimize the number of words
that need to be removed to eliminate unwanted inferences.
This is our future research.
2.2 Parameters of inference detection
Performance of the inference detection step depends on a
number of parameters, (i) (cid:96): the size of K(D), (ii) β which
is the size of subsets that are used in queries, and (iii) γ
that controls the search depth for documents in the public
Web. These parameters can be tuned to achieve the required
trade-oﬀs between the computation cost of the inference de-
tection and the strength of inferences (i.e., weak inferences
are not considered in lieu of more eﬃcient algorithms). Al-
lowing larger (cid:96), β and γ results in more costly algorithms
but allows ﬁner inferences (and probably weaker ones) to be
detected.

Figure 5 shows that subsets of words (subsets of 2 words-
in this experiment) are more likely to result in inferences
than single words; however, the number of queries increases
from O(l) to O(l2) (l is the size of the keyword set)(Figure
6).

The depth of the search also aﬀects the eﬃciency and
eﬀectiveness of the scheme. Our experiments in Section 3
shows with increasing depth, extra weaker inferences can
be found with reasonable amount of extra computation (see
Figure 7, Figure 8) .
2.3 Multiple Sensitive Keywords

We ﬁrst give three algorithms that are direct applications
of single word algorithm to multi sensitive word case. Our
proposed algorithm as well as TF.IDF based algorithm of
Staddon et al. both can be used for single sensitive word
case. We next extend our information theoretic approach to
deﬁne a combined metric for ranking of words in the doc-
ument that takes into account the relationship among the
sensitive words.

Suppose we are to redact a document with respect to a given
list of sensitive keywords s1, s2, ...su.

Let Π denote the algorithm that is used for keyword ex-
traction with respect to a single sensitive keyword. Π takes
three inputs, a document D, a sensitive keyword s0, and the
length (cid:96) of the keyword list that it needs to construct.

The trivial algorithm below follows this approach.

A direct solution when there are multiple sensitive key-
words, is to repeat the above procedure for each sensitive
keyword and take the union of the unwanted inferences ob-
tained in each case.
TrivMultiWrdInfr (D, s1 ··· su; (cid:96))
– For i = 1,··· u,
– Call Π(D, si, (cid:96)) → Ki(D)
– Find Infri, the set of inferences on D using Ki(D)
– Find Infr = ∪u
ences.

i=1Infri where Infr is the set of all infer-

The algorithm will have u complete passes over the docu-
ment and the Web-query phase for ﬁnding inferences. The
redacted document will have many words (and some un-
necessarily) removed which will reduce the quality of the
output.

Merging lists. To reduce the number of Web searches, the
keyword lists corresponding to sensitive words are ﬁrst merged
and then used for Web search. The two algorithms are the
same, except MergListMultiWrdInfr 2 considers the top
(cid:96) elements of the merged list.
MergListMultiWrdInfr 1 (D, s1 ··· su; (cid:96))
– For i = 1,··· u,
– Call Π(D, si, (cid:96)/u) → Ki(D)
– Form Kmerg(D) = ∪u
i=1Ki(D)
– Find Infr, the set of inferences on Kmerg(D)
MergListMultiWrdInfr 2 (D, s1 ··· su; (cid:96))
– For i = 1,··· u,
– Call Π(D, si, (cid:96)) = Ki(D)
– Select the top (cid:96) words in ∪u
– Find Infr, the set of inferences on Kmerg(D)

i=1Ki(D) to form Kmerg(D).

In all above algorithms, relationship of a word w in the
document is considered separately with each sensitive word,
and so if a word w has strong relationship with combina-
tion of two or more sensitive words, it may not be included
in the ﬁnal keyword list. This shortcoming is addressed by
extending our information theoretic measure. The advan-
tage of these two latter algorithms compared to TrivMul-
tiWrdInfr is eﬃciency, that is, they use Web query phase
only once. We will show the eﬃciency and eﬀectiveness of
each algorithm in the experiments in Section 3.
Information theoretic approach. We generalize the keyword
extraction to cater for multiple sensitive words. We consider
two cases:
s1,··· , su are independent.
For each word wi ∈ D and each sensitive keyword sj, we
ﬁnd I(wi; sj), and use the top (cid:96) words that have the highest
sum of mutual information with the sensitive words as the
keywords. In other words, we rank words in D based on the
following quantity:

Iw,s1,··· ,su = I(wi; s1) + I(wi; s2) + ... + I(wi; su)

This quantity eﬀectively captures the strength of the rela-
tionship (in terms of co-occurrence) between w and the set
of sensitive keywords:
if there is one sensitive keyword in
the set that has high value of I(w; si), the sum will be high.
Similarly, if mutual information is moderate with respect to
a number of sensitive words, the total may be suﬃcient to
move the word into the keyword list. Only if the mutual
information with respect to all sensitive words is very small,
the sum will be small and the word will not be included.
s1,··· , su are not independent.
We assume s1,··· , su are not independent if I(si; sj) ≥ t
for at least one pair: i, j ∈ {1,··· , u} and i (cid:54)= j, where t is a
threshold that needs to be determined for each application.
Users can also explicitly specify si and sj as related words.

Let u = 2. That is, there are two sensitive words that are
related to each other and so I(si; sj) ≥ t. We use the fol-
lowing metric to quantify the strength of the relationship
between w and (s1, s2):

Iw,s1,s2 = I(w; s1) + I(w; s2) − I(w; s1, s2)

For the general case, suppose that every two words in u
sensitive words are related to each other and I(si; sj) ≥ t
for all i, j ∈ {1,··· , u} and i (cid:54)= j. We then have:

29u(cid:88)

i=1

Iw,s1,··· ,su =

I(w; si) −

u(cid:88)

i,j=1,i(cid:54)=j

I(w; si, sj)

+

−

I(w; si, sj, sm)

i,j,m=1,i(cid:54)=j(cid:54)=m

I(w; si, sj, sm, sn) + ···

i,j,m,n=1,i(cid:54)=j(cid:54)=m(cid:54)=n

u(cid:88)
u(cid:88)

n(cid:88)

To calculate mutual information of more than two random
variables, one can use the chain rule for mutual information
as described in [11]:

I(X1,··· , Xn; Y ) =

I(Xi; Y |Xi−1, Xi−2,··· , X1)

i=1

The algorithm to extract (cid:96) keywords from the document fol-
lowing this approach will be as follows.
CumulMultiWrdInfr (D, s1,··· su; (cid:96))
– For each word wi in D,
– Calculate Iw,s1,··· ,su
– To form the keyword list K(D), ﬁnd the top (cid:96) words in D
with the highest Iw,s1,··· ,su .
– Find Infr, the set of inferences on D using K(D).

The algorithm is one pass and so uses Web query phase

only once. For detailed comparisons, see Section 3.2.3.
2.4 Evaluating Web-based inference detection

systems

Web-based inference detection systems extract a keyword
list K(D) from a document and result in a list Lpre that
contain precedents of the found unwanted inferences.
We ﬁrst deﬁne the set of all inferences of a document D
as follows:
Deﬁnition 1: The set of all inferences A of a document D
with a parameter β and γ (as described in Section 2.1) con-
sists of the inferences that are found by querying all subsets
of β words in Dp. For each search result, the returned docu-
ments are analyzed (as in the Inference analysis phase) and
the queried subset is detected as precedent of an inference,
if the test is passed.

Important aspects of a Web-inference detection algorithm

for the purpose of redaction are:

1. Eﬀectiveness of inference detection: this is measured
by the parameter ρ deﬁned as the percentage of all
inferences detected by using a speciﬁc algorithm. For
a ﬁxed document, ρ is a function of, (i) K(D), (ii) query
algorithm parameters: β, γ, the ranking algorithm of
the search engine, and the inference analysis stage.

2. Eﬃciency: This consists of:

(i) Computational complexity of ﬁnding K(D);
(ii) Query eﬃciency of the algorithm: is the number of

queries and is measured as(cid:0)|K(D)|

(cid:1);

β

(iii) Computational complexity of inference analysis
stage: that depends on the number of returned pages
(in all queries) and the speciﬁc algorithm that is used
to analyze these pages to detect inferences.

Both our algorithm and [24] require the same computa-
tion cost for extracting keywords, that is O(m) where m is
the number of words in the private document, and for the

inference analysis phase that is O(γ(cid:0)|K(D)|

(cid:1)).

β

3. EXPERIMENTS

We developed a tool set written in Java, and performed
the experiments reported in [24] and also new experiments
required when employing our proposed keyword extraction
algorithm.

We did two sets of experiments: a single sensitive key-
word and multiple sensitive keywords. The ﬁrst experiment
is for redacting a record about “Bin Laden” and the aim is
to prevent inference of “Bin Laden” when the redacted doc-
ument is combined with the documents on the public Web.
The second experiment is about redacting all sensitive infor-
mation related to a patient’s diseases before the document
is released. We limited our search to inferences with prece-
dents consisting of two words (pairs of words used for issuing
queries).
3.1 Experimental challenges and tools

Ideally, the approach needs to be tested on real docu-
ments and related corpus. For example, for protecting a
document against inferences made for “Bin Laden”, we need
a corpus of FBI documents that are related to “Bin Laden”,
so that a correct estimate of probabilities can be calculated.
However, such a corpus is hard to obtain. We used instead
publicly available information about the sensitive keywords
under consideration (“Bin Laden” in our ﬁrst experiment,
“anxiety”, “depression” in our second experiment). We built
3 diﬀerent corpora for algorithm’s stability test. Each cor-
pus consists of 30 documents and are mostly from Wikipedia
pages. These documents are in html or text format. For
html documents, the text is extracted from html. All the
stop words and sensitive words are then removed from those
documents and a list of keywords are identiﬁed.

All of our experiments use the tool set to remove stop
words and extract the keyword list. Our code for extracting
text from html uses standard techniques for removing html
tags. We used Bing Search API [5] to make queries using
keywords. Bing Search API is an API that allows us to issue
queries automatically to the search engine of Bing.
3.2 Experiment description
3.2.1 Redaction of a Military document: one sensi-

tive keyword

The experiment takes as input the document that must
be redacted, in this case, a page about Bin Laden [4]. The
page is then anonymized and the name and aliases of the
person are removed. To identify words that might allow
“Bin Laden” to be inferred, we issued queries on subsets of
words and examined top 5 returned pages, and detected an
inference if at least one document included the word “Bin
Laden”.

The following describes our experiment in more details.
Input: A plaintext ﬁle of the article about Bin Laden [4].

1. Remove the subject “Osama Bin Laden” and aliases

from the text.

2. Extract the top (cid:96) words ((cid:96) varies from 20 to 100) from
the text following the algorithm SelectKeywords.
This forms the set SB.

3. Issue queries on pairs of keywords from the set SB.
Select the top 5 pages returned by Bing Search. We
considered only the hits consist of html or text.

304. We add that pair of keywords to a set of precedents of
if it passes the test in the Inference

inferences Infrpre
analysis stage.

1

Output: Set of precedents of inferences Infrpre

1

.

We compared this algorithm with the results obtained
from the algorithms in [24] and [8]. For the algorithm [24],
we used exactly the above steps, except in step 2 used TF.IDF
technique as described in [24]. This results in a diﬀerent set
of precedents of inferences Infrpre
. The table 1 presents the
keyword lists extracted using two keyword extraction algo-
rithms.

2

The experiments showed that keyword pairs from our al-
gorithm generated more inferences for “Bin Laden”, with the
same eﬃciency (both algorithms used the same number of
queries, and required the same computation cost for extract-
ing keywords and inference analysis phase). This is expected
as our algorithm extracts in the document a list of keywords
related to “Bin Laden” and not general high frequency words
(see Figure 2- our algorithm constantly gives better results
with diﬀerent sizes of the keyword set). As the result, the
redacted document produced by our algorithm contains less
inferences about “Bin Laden” than the redacted one pro-
duced by the previous work.

As described in Section 1.1.2, the algorithm [8] outputs
a set of candidate inferences based on a corpus. In the ex-
periment, we followed the algorithm and outputted a set of
candidate inferences CandInfrpre.

The experiment showed that approximately 95% of sen-
sitive inferences in the private document were not detected
by the set CandInfrpre. The corpus should contain suﬃ-
cient “knowledge” related to the sensitive topic so that the
algorithm can perform eﬀectively (outputs a set CandInfrpre
that captures more sensitive inferences) (see Section 1.1.2).
We changed the range of the parameters to examine the
aﬀect on the performance of the system. Our results show
that, as expected, the number of inferences increases as the
number of extracted words increases (see Figure 3). This
increase however will plateau when the number of extracted
words gets close to the number of words in the document.
3.2.2 Different corpora experiment.
The quality of the corpus (how much the corpus is related
to the sensitive words) aﬀects the eﬀectiveness of the scheme.
We built up three corpora with diﬀerent relevance to the
sensitive words. The ﬁrst corpus was selected to make sure
that the contents of the documents were not duplicated and
they were related to the sensitive words. This corpus could
be referred as a quality corpus with the aid of human. To
create two other corpora, we used the sensitive words to
query a search engine. The second and the third corpus were
the documents 1-30 and 31-60, respectively, returned by that
search. No further processing was used on these two corpora.
We expected the second corpus to have lower quality. The
eﬀect of corpus is shown in the Figure 4. Our proposed
keyword selection scheme behaved fairly stably when the
quality of corpus varied. The second corpus which consisted
of the top 30 pages returned by the search engine, still can
be considered as a good one: the documents in this corpus
were all about the sensitive topic. The result of using this
corpus was slightly diﬀerent from the ﬁrst one. The third
corpus contained some irrelevant documents thus resulted in
lower eﬀectiveness on average.

Staddon et al.’s
Our algorithm

)

%

(

s
e
c
n
e
r
e
f
n
I

20

15

10

5

0

20

40

60

80

100

Size of keyword list

Figure 2: Comparisons between our algorithm and
[24] when (cid:96) changes.

3.2.3 Medical record redaction experiment: multiple

sensitive keywords

In this experiment, the goal is to redact a medical record
that is about a patient who suﬀers a mental illness [16]. Sup-
pose he has to publish his medical record to a third party
but does not want to reveal his health status. In this exper-
iment, the sensitive keywords that need to be protected are
“anxiety”, “depression” (which are marked as related to each
other). The detailed procedure is below.

For each algorithm TrivMultiWrdInfr, MergMultiWrdInfr 1,
MergMultiWrdInfr 2 and CumulMultiWrdInfr :
Input: A plaintext ﬁle of the medical record [16].

1. Remove “anxiety”, “depression” from the article.

2. Extract words from the document as described in the
algorithm with (cid:96) = 50. A keyword set SB(cid:48) is produced.
3. We issued queries on every two words of the set SB(cid:48)
to the Bing Search engine. Select the top 5 pages re-
turned by that search. We considered only the hits
consist of html or text.

4. We add that pair of keywords to a set of precedents of
(cid:48)pre if it passes the test in the Inference

inferences Infr
analysis stage.

Output: set of precedents of inferences Infr

(cid:48)pre.

Table 2 compares the results of the 4 algorithms. The
algorithm TrivMultiWrdInfr detects more inferences, and
has higher query cost (also requires more computational
cost for inference analysis stage). This is due to TrivMul-
tiWrdInfr operates on two keyword lists separately, one for
each sensitive word. With the same number of queries Cu-
mulMultiWrdInfr could result in more than 60% inferences
found. The remaining 3 algorithms have the same query
cost. Among these, CumulMultiWrdInfr results in the most
sensitive inferences found. We note that ﬁnding K(D) in
CumulMultiWrdInfr is more complex than the other algo-
rithms, but the extra cost is negligible.

31Input: The article Osama Bin Laden and the Al Qaeda group [4]
Keywords extracted using our algorithm: saudi, world, US, arabia, afghanistan, soviet, terrorist, government,
group, September, children, states, born, ﬁrst, family, construction, 1957, network, time, islamic, muslim, joined,
bombing, afghan, country, international, 2001, troops, pakistan, middle, 10, father, resistance, union, university, king,
alqaeda, holy, iraq, mohammed, organization,...

Keywords extracted using algorithm [24]: groups, mohammad, mak, alqaeda, azzam, vast, alias, campaign,
ideology, kashmir, channeled, islamic, cells, reach, islami, abu, resources, support, rulers, algeria, leader, membership,
principal, hamas, organizations, le, jane, domestic, broad, turki, closely, banks, dr, phil, drawn, gunaratna, expertise,
indonesia, kosovo, morocco, tan, mentor, hirschkorn, combat, ﬁghting, inline, lebanon, ﬁght,...

Table 1: Example of keywords extracted using our algorithm and [24]. In the smaller box, the left column
is examples of pairs of words that we used to issue queries, and the right column is the resulted pages from
the queries that contain sensitive content.

)

%

(

s
e
c
n
e
r
e
f
n
I

20

15

10

5

0

0

0.2

0.4

0.6

0.8

Computational cost (number of queries)

1
·104

Corpus 1
Corpus 2
Corpus 3

)

%

(

s
e
c
n
e
r
e
f
n
I

20

15

10

5

0

20

40

60

80

100

Size of keyword list

Figure 3: Eﬀectiveness vs. eﬃciency of the scheme
while increasing (cid:96)

Figure 4: Eﬀectiveness of the scheme with diﬀerent
corpora

3.3 Performance analysis

The running time of the system mainly depends on the
number of queries that need to be issued and the stability of
the network. Concretely, if we extract from the input doc-
ument 100 keywords, the query step using Bing Search for
each experiment requires around 8 hours to complete. This
is due the total number of keyword pairs in each experiment
is 4950, and also in most of the running time, Bing Search
has network response delays which are sometimes some min-
utes for one query. Interestingly, the other modules of the
system take only 30 seconds to ﬁnish all the tasks.

4. CONCLUSION AND FUTURE WORK

We proposed an information theoretic approach to docu-
ment keyword extraction with respect to a single sensitive
word and extended it to the case of multiple sensitive words.
Our approach is a natural way of extracting keywords when
inferences are modeled as co-occurrences. We showed su-

perior performance of the proposed approach in detecting
unwanted inferences compared to [24]. The novelty and sig-
niﬁcance of our work is in deﬁning appropriate information
theoretic measures for ranking document words with respect
to a corpus, that captures their potentials to result in un-
wanted inferences. The keyword list can be seen as a list of
words in the target document that give strong direct (sin-
gle word) inference of the form w ⇒ s0 about the sensitive
keyword(s), and the follow on stage of Web search is to ﬁnd
subsets of more than one keywords that give new unwanted
inferences.

Using inferences in the context of redaction has other chal-
lenges related to the overall performance of the system. It
is always easy to remove many words from the document
to reduce unwanted inferences. However this will reduce
readability and usefulness of the redacted document. One
may also use complex NPL analysis and human experts to
remove inferences. The result will be a costly process that
cannot scale to the large volume of documents that must

32be released, for example by states and in response to the
Freedom of Information Legislations. Our theoretical ap-
proach opens possible directions for developing automated
redaction systems that do not leak unwanted inferences and
maintain high readability of the redacted document.

5. REFERENCES
[1] E. Bier, L. Good, K. Popat, and A. Newberger. A
document corpus browser for in-depth reading. In
Proceedings of the 4th ACM/IEEE-CS joint conference
on Digital libraries, JCDL ’04, pages 87–96, New
York, NY, USA, 2004. ACM.

[2] E. A. Bier and E. W. Ishak. Entity quick click: rapid
text copying based on automatic entity extraction. In
Abstracts of the Conference on Human Factors in
Computing Systems (CHI, pages 562–567. ACM Press,
2006.

[3] E. A. Bier and E. W. Ishak. Entity workspace: an

evidence ﬁle that aids memory, inference, and reading.
In Proceedings of Intelligence and Security Informatics
(ISI 2006, pages 466–472. Springer-Verlag, 2006.

[4] R. o. Bin Laden.

http://www.webspawner.com/users/islamicjihad15,
Aug. 2001.

[5] Bing-API. www.bing.com/toolbox/bingdeveloper,

2012.

[6] Y. Chen and W. W. Chu. Database security

protection via inference detection. In IEEE
International Conference on Intelligence and Security
Informatics, 2006.

[7] Y. Chen and W. W. Chu. Protection of database

security via collaborative inference detection. IEEE
Trans. on Knowl. and Data Eng., 20:1013–1027,
August 2008.

[8] R. Chow, P. Golle, and J. Staddon. Detecting privacy

leaks using corpus-based association rules. In
Proceeding of the 14th ACM SIGKDD international
conference on Knowledge discovery and data mining,
KDD ’08, pages 893–901, New York, NY, USA, 2008.
ACM.

[9] R. Chow, I. Oberst, and J. Staddon. Sanitization’s

slippery slope: the design and study of a text revision
assistant. In Proceedings of the 5th Symposium on
Usable Privacy and Security, SOUPS ’09, pages
13:1–13:11, New York, NY, USA, 2009. ACM.

[10] P. Cimiano and S. Staab. Learning by googling.

SIGKDD Explor. Newsl., 6:24–33, December 2004.

[11] T. M. Cover and J. A. Thomas. Elements of

information theory. Wiley-Interscience, New York,
NY, USA, 1991.

pseudonymization, and data deidentiﬁcation. In
Proceedings of the 2008 ACM symposium on
Information, computer and communications security,
ASIACCS ’08, pages 353–362, New York, NY, USA,
2008. ACM.

[15] M. Koppel, J. Schler, S. Argamon, and E. Messeri.

Authorship attribution with thousands of candidate
authors. In Proceedings of the 29th annual
international ACM SIGIR conference on Research and
development in information retrieval, SIGIR ’06, pages
659–660, New York, NY, USA, 2006. ACM.

[16] linden method.com.

http://www.linden-method.com/medical-records/,
1993.

[17] D. Lopresti and A. L. Spitz. Quantifying information
leakage in document redaction. In Proceedings of the
1st ACM workshop on Hardcopy document processing,
HDP ’04, pages 63–69, New York, NY, USA, 2004.
ACM.

[18] D. Lopresti, A. L. Spitz, D. Lopresti, and A. L. Spitz.

Information leakage through document redaction:
Attacks and countermeasures. In In DRR, pages
183–190, 2004.

[19] C. D. Manning and H. Sch¨utze. Foundations of

statistical natural language processing. MIT Press,
Cambridge, MA, USA, 1999.

[20] T. M. Mitchell. Machine learning. McGraw Hill, New

York, 1997.

[21] C. E. Shannon and W. Weaver. A Mathematical

Theory of Communication. University of Illinois Press,
Champaign, IL, USA, 1963.

[22] Slashdot.org. Anonymity of netﬂix prize dataset

broken, 2007.

[23] D. L. Spooner, S. A. Demurjian, and J. E. Dobson,
editors. Proceedings of the ninth annual IFIP TC11
WG11.3 working conference on Database security IX :
status and prospects: status and prospects, London,
UK, UK, 1996. Chapman & Hall, Ltd.

[24] J. Staddon, P. Golle, and B. Zimny. Web-based

inference detection. In Proceedings of 16th USENIX
Security Symposium on USENIX Security Symposium,
pages 6:1–6:16, Berkeley, CA, USA, 2007. USENIX
Association.

[25] L. Sweeney. Achieving k-anonymity privacy protection

using generalization and suppression. Int. J.
Uncertain. Fuzziness Knowl.-Based Syst., 10:571–588,
October 2002.

[26] L. Sweeney. k-anonymity: a model for protecting

privacy. Int. J. Uncertain. Fuzziness Knowl.-Based
Syst., 10:557–570, October 2002.

[12] M. Dowman, V. Tablan, H. Cunningham, and

[27] L. Sweeney. Ai technologies to defeat identity theft

B. Popov. Web-assisted annotation, semantic indexing
and search of television and radio news. In Proceedings
of the 14th international conference on World Wide
Web, WWW ’05, pages 225–234, New York, NY, USA,
2005. ACM.

[13] C. Farkas and S. Jajodia. The inference problem: a
survey. SIGKDD Explor. Newsl., 4:6–11, December
2002.

[14] S. Haber, Y. Hatano, Y. Honda, W. Horne,

K. Miyazaki, T. Sander, S. Tezoku, and D. Yao.
Eﬃcient signature schemes supporting redaction,

vulnerabilities. AAAI Spring Symposium, AI
Technologies for Homeland Security, 2005.

[28] R. Yi and K. Levitt. Data level inference detection in

database systems. In Proceedings of the 11th IEEE
workshop on Computer Security Foundations, pages
179–, Washington, DC, USA, 1998. IEEE Computer
Society.

331 word queries
2 word queries

s
e
c
n
e
r
e
f
n

i

f
o

r
e
b
m
u
N

800

600

400

200

0

·104

1 word queries
2 word queries

s
e
i
r
e
u
q

f
o

r
e
b
m
u
N

1

0.8

0.6

0.4

0.2

0

20

40

60

80

100

Size of keyword list

20

40

60

80

100

Size of keyword list

Figure 5: Eﬀectiveness of the scheme with diﬀerent
values of β

Figure 6: Eﬃciency of the scheme with diﬀerent values
of β (in number of queries)

4 pages returned
5 pages returned

)

%

(

s
e
c
n
e
r
e
f
n
I

20

15

10

5

0

20

40

60

80

100

Size of keyword list

o
t

d
e
e
n

s
e
g
a
p

f
o

r
e
b
m
u
n
(

t
s
o
c

l
a
n
o
i
t
a
t
u
p
m
o
C

)
s
e
c
n
e
r
e
f
n

i

d
n
ﬁ

o
t

d
e
z
y
l
a
n
a

e
b

500

400

300

200

100

4 pages returned
5 pages returned

20

40

60

80

100

Size of keyword list

Figure 7: Eﬀectiveness of the scheme with diﬀerent
values of γ

Figure 8: Eﬃciency of the scheme with diﬀerent values
of γ

TrivMultiWrdInfr

MergMultiWrdInfr 1

MergMultiWrdInfr 2

CumulMultiWrdInfr

45.46%

18.77%

18.89%

19.89%

O(u|D|)
O(u|D|)
O(u|D|)
O(u2|D|)

11175

1225

1225

1225

Eﬀectiveness Finding K(D) Query eﬃciency

Inference analysis

O(γ(cid:0)|K(D)|
(cid:1))
(cid:1))
O(γ(cid:0)|K(D)|
O(γ(cid:0)|K(D)|
(cid:1))
O(γ(cid:0)|K(D)|
(cid:1))

β

β

β

β

Table 2: Comparison results of 4 multiword algorithms

34APPENDIX
The redacted document generated by our algorithm is shown in the ﬁgure below.

Figure 9: The left hand side shows the document [4] before being redacted. The right hand side shows an
example of a redacted document of [4] using our algorithm where the back rectangles represent redacted
words recommended by our algorithm.

35