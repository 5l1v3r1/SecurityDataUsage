Track Me If You Can: On the Eﬀectiveness of Context-based Identiﬁer Changes

in Deployed Mobile Networks

Laurent Bindschaedler1,∗

Murtuza Jadliwala2,∗

Igor Bilogrevic1

Imad Aad3

Philip Ginzboorg3

Valtteri Niemi3

Jean-Pierre Hubaux1

1EPFL, Switzerland. 2Wichita State University, USA. 3Nokia Research Center.
E-mail: firstname.lastname@{1epfl.ch, 2wichita.edu, 3nokia.com}

Abstract

Location privacy is a major concern in an increasingly
connected and highly pervasive network of mobile users.
Novel
location-based applications and device-to-device
services (on these mobile devices) are gaining popularity,
but at the same time, these services allow curious service
providers and eavesdroppers to track users and their move-
ments. Earlier research eﬀorts on location-privacy preser-
vation, which were mostly based on identiﬁer-change mech-
anisms in spatio-temporal de-correlation regions called
mix-zones, show that coordinated identiﬁer-change tech-
niques are reasonably eﬀective in a simulation setting, al-
though some smart attacks are still possible. However,
a thorough analysis of these mechanisms that takes into
consideration communication patterns and mobility from
a real-life deployment is missing from these results.
In
this paper, we evaluate in a real-life setting the eﬀective-
ness of standard mix-zone-based privacy protection mech-
anisms against probabilistic tracking attacks. Our exper-
iments involved 80 volunteers carrying smartphones for 4
months and being constantly eavesdropped on an adversar-
ial mesh network of standard wireless Access Points (APs).
To the best of our knowledge, this is the ﬁrst study that
provides empirical evidence about the eﬀectiveness of mix-
zone-based privacy-preserving mechanisms against practi-
cal adversaries in upcoming wireless and mobile systems.

1. Introduction

Over the last few years, smartphones and mobile devices
have replaced traditional personal computers as the main
means to access web and other context-based services. A
wide variety of applications are available on these devices,
∗Equally contributing authors; ordered alphabetically. Murtuza was

with EPFL when this work was accomplished.

including applications for friend-ﬁnding [1], dating [2, 3],
micro-blogging [27], localized advertisement [16], gaming,
entertainment [49] and localized social networking [4, 7];
they take advantage of both infrastructure-based and device-
to-device communications. Novel data-sharing applications
have also emerged in societies that enforce strict censorship
and data-regulation. For example, device-to-device messag-
ing applications are being used in Iran to exchange sexually-
explicit messages [39] and by anti-governmental insurgents
in order to coordinate their actions [22]. New infrastructure-
less systems for wireless device-to-device communica-
tions have been recently announced by Nokia [43], Qual-
comm [17], Peep Wireless [30], and NEC [46].

In such pervasive communication systems, privacy,
speciﬁcally location privacy,
is always a critical issue.
Eavesdroppers can constantly track users based on device
identiﬁers in the broadcasted wireless messages. This in-
formation can be used by curious service providers in order
to de-anonymize users and their availabilities [29], to track
their preferences [26], to identify their social networks [23],
or it can be used by malicious parties for nefarious activi-
ties [5, 20]. Infrastructure owners and third-party service
providers who track user communications and location in-
formation in order to improve the oﬀered service can inad-
vertently harm users’ privacy if the collected data is leaked
to unauthorized parties or improperly shared with corporate
partners.

The location privacy problem in pervasive and mobile
communication networks has recently received much atten-
tion. Inspired by Chaum’s seminal work on mix networks
[14, 15], Beresford and Stajano [9, 10] propose the con-
cept of mix-zones, which are spatio-temporally deﬁned re-
gions where users can mix [41] or change [34, 13] their
device identiﬁers, such as IP and MAC addresses. Appli-
cation layer identities are generally encrypted by using ses-
sion keys and are not visible. While in the mix-zone, users
remain silent after this identiﬁer change operation. They re-

sume communication with a new identiﬁer (or pseudonym)
after exiting the mix-zone. By providing de-correlation be-
tween users and their device identiﬁers, mix-zones make it
diﬃcult for an adversary to continuously track users sim-
ply by linking messages containing the same identiﬁer. In
cellular networks, location privacy is supported by chang-
ing a subscriber’s Temporary Mobile Subscriber Identity, or
TMSI [21], upon moving to a new geographical area.

The eﬀectiveness of mix-zone-based identiﬁer-change
mechanisms has been studied in some of the recent research
eﬀorts [12, 28, 48], where authors proposed new location-
privacy attacks in such systems. Butty´an et al. [13] and
Freudiger et al. [24] focus on mix-zone schemes that con-
sider speciﬁc network characteristics, whereas, Palanisamy
et al. [42] propose schemes that guarantee a lower-bound on
the level of achieved anonymity. Freudiger et al. [25] and
Jadliwala et al. [36] address the problem of optimal mix-
zone deployment by minimizing the probabilistic advantage
of the adversary in tracking users. More recently, the mix-
zone placement problem was also addressed from a game-
theoretic perspective [35, 8] by deriving optimal attack and
defense strategies for both eavesdroppers and users. How-
ever, a majority of these eﬀorts consider only vehicular net-
working scenarios, which have signiﬁcantly diﬀerent net-
work characteristics and mobility patterns compared to net-
working scenarios involving mobile humans. Moreover,
due to the diﬃculty in conducting large-scale ﬁeld trials,
these results are based solely on simulations with rather re-
strictive parameters. Additionally, most of these studies as-
sume a global passive adversary, which is a highly unrealis-
tic assumption. Before this contribution, there did not exist
a single ﬁeld-study that evaluated context-based identiﬁer-
change mechanisms under a practical adversary model both
on real mobile devices and in real communication scenar-
ios. In our opinion, such a study is crucial in order to real-
istically evaluate the eﬀectiveness of coordinated identiﬁer-
change mechanisms.

In this paper, we evaluate mix-zones and context-
based identiﬁer-change mechanisms by means of a real
on-campus mobile network deployment consisting of 80
state-of-the-art Nokia N900 smartphones. These smart-
phones, carried and used by EPFL students and staﬀ for
a period of four months, were enabled with both standard
infrastructure-based communications, such as cellular and
WiFi, as well as a novel WiFi-based wireless peer-to-peer
technology by Nokia, called Nokia Instant Community or
NIC. We deployed an adversarial wireless mesh network of
Access Points (APs) over a target region of the campus in
order to eavesdrop on user communications in that region.
In addition to developing a variety of custom applications
to stimulate usage and participation, we implemented and
deployed a context-based identiﬁer-change service on all
the deployed smartphones. This service performs a device

identiﬁer change operation based on the device context such
as the number of neighborhood devices obtained from the
wireless peer-to-peer channel. Setting up a real deployment
is a challenging exercise with several non-trivial tasks such
as volunteer recruitment, providing usage incentives, device
conﬁgurations, application development and deploying reg-
ular updates. More details can be found in [6].

Given the data collected, during four month, from the ad-
versarial mesh network, we ﬁrst reconstruct the groundtruth
of user movements and device identiﬁers. We then outline
a Markov chain-based tracking framework for user tracking
and propose two straightforward tracking strategies. By us-
ing well-established privacy metrics, we evaluate the eﬀec-
tiveness and cost of the deployed context-based identiﬁer-
change mechanism against the proposed tracking strategies
for various adversarial strengths and parameters.

2. System Model

In this section, we outline the setup of our experimen-
tal mobile network and the deployed adversarial mesh net-
work. We also describe the context-based identiﬁer-change
mechanism deployed on the mobile devices.

2.1. Mobile Network Model and Deployment

In order to conduct our experiments, we deployed a real
mobile network testbed on the EPFL campus in Lausanne,
Switzerland. The network model corresponding to the de-
ployment is depicted in Fig. 1 (leftmost). We recruited 80
volunteers (mostly students and a few instructors) to par-
ticipate in our four month-long experiments from March to
June 2011. Each participant was equipped with, and was
expected to use, a Nokia N900 smartphone for the dura-
tion of the experiment. In addition to accessing web ser-
vices using the standard WLAN and cellular interfaces, par-
ticipants also exchanged information with other co-located
users by using an experimental wireless peer-to-peer mes-
saging platform from Nokia called Nokia Instant Commu-
nity or NIC [43]. NIC uses WiFi-based ad-hoc connec-
tions to seamlessly carry small-sized data between devices
without any infrastructure requirement. The NIC wireless
peer-to-peer interface not only provides a novel and inex-
pensive means for participants to seamlessly communicate
with each other, but it is also useful in determining con-
text such as device neighborhood. We stress that any other
non-WiFi-based short-range wireless peer-to-peer commu-
nication interface, such as Bluetooth, could also be used for
the purpose of context determination.

As mentioned earlier, participants used the NIC inter-
face to exchange information with other colocated partic-
ipants based on relationship, interests, aﬃliations and con-
text. NIC communications are either non-interactive, where

Figure 1. Left: System and network model with communities shown as shaded regions. Nokia N900
smart phone shown at bottom used in actual deployment. Middle: Mix-zone showing silent period
and identiﬁer changes. Right: Adversarial wireless mesh network of Asus routers.

users broadcast information without any speciﬁc request
from others, or interactive, where users multi-cast relevant
information only in response to speciﬁc queries. In order to
stimulate information exchange, participants were recruited
from closely-knitted groups, such as people in the same
course or study group. To support both forms of commu-
nications, we developed seven custom NIC-based applica-
tions including a “Classforum” application for students to
interact with the lecturer, a simple chat application, a restau-
rant application and a friend-ﬁnding application. These
applications were either pre-loaded on the devices or re-
motely installed after deployment. Users could also dy-
namically create and organize themselves into communi-
ties using NIC. All users belonged to one large public com-
munity. Private communities could also be formed locally
by users based on interest, preferences and aﬃliations. In
adddition to this, participants also accessed Internet-based
services, such as email, web browsing, etc., using these
smartphones by connecting to the campus WiFi network.
We note that, unlike Bluetooth, NIC-enabled smartphones
seamlessly switch to the wireless peer-to-peer mode when
NIC applications are running or other NIC devices appear
in the neighborhood.

NIC messages are multi-hop and valid up to a certain
maximum hop count. NIC messages carry limited data (≈
100 bytes) for eﬃciency and timing purposes (considering
the short encounter period between devices). NIC imple-
ments an adaptive beaconing mechanism for neighborhood

discovery. In order to prevent trivial linking of user mes-
sages from beacons, provisions are made in the beaconing
mechanism, which allows a group of devices in the vicinity
of each other to eﬃciently distribute the beaconing task uni-
formly within the group. Thus, the probability of the same
device sending a beacon message regularly is low.

All NIC messages, similar to UDP/TCP segments, con-
sist of (1) an unencrypted identiﬁer or pseudonym (such as
MAC and IP address) that belongs to the message origina-
tor and (2) the message itself in either encrypted or unen-
crypted form, depending on whether the message is private
or public, respectively. If the message is not public, iden-
tifying information of the target user(s) or community is
also included. Link-layer encryption [38, 50] could be used
to encrypt MAC addresses, but the performance degrada-
tion due to the additional message size and cryptographic
operations makes it infeasible for use in NIC. Each de-
vice runs (in the background) an identiﬁer-change service,
called Pseudonym-Change Algorithm (PCA), which condi-
tionally changes the device MAC address.
In this work,
we assume that only the MAC address is changed, but the
PCA can be easily extended to change application and net-
work layer identiﬁers as well. For notational purposes, we
denote an actual message sent by a user u as a ﬁve-tuple
m = (t, p, u, π, c), where t, p and π are the device time (in
seconds), location (as a 2-D coordinate) and device iden-
tiﬁer, respectively, when m was sent and c is the message
content. Note that u is shown here only to associate a mes-

66 m•LBSs•Social Networkstpucπm =Mix zonePCA-triggeredID change•Time-dependent•Context(neighborhood) dependentMix ?186 msage to a particular user and may not actually be sent with
the message on the network. M is the set of all actual mes-
sages (sent by all users) and t(m), p(m), π(m) refer to the
time, position and identiﬁer associated with m. A symbol
table can be found in the Appendix.

2.2. Adversary Model and Deployment

In this work, we assume a passive adversary that eaves-
drops on the messages sent by the devices and that is local-
ized in a certain part of the network. We implement such
an adversary by means of a mesh network of IEEE 802.11
wireless routers or APs (Asus WL-500gP APs running
OpenWRT Linux), as shown in Fig. 1 (rightmost). This
wireless mesh network of 37 APs is located on the same
ﬂoor-level of six interconnected buildings, where there is
high student activity because of the presence of various
classrooms, study-areas and a cafeteria. Beyond this area,
the adversary has no information on sent messages. The ad-
versary has no direct access to any device, and all devices
are assumed to be honest (i.e., non-colluding with the ad-
versary).

Within the coverage area, the adversary is not be able to
capture all possible messages due to hardware-related limi-
tations, such as radio interference and hidden terminals, and
AP software failures. The amount of data that the adversary
can sniﬀ or collect, i.e., adversary’s strength, depends on
the total number of APs used by her for sniﬃng. Each of
these APs run a “tcpdump” background process to capture
all communications on the speciﬁed channel and periodi-
cally upload the sniﬀed messages to a central server. The
adversary is limited by the constraints of the cryptographic
methods, i.e., she is not able to obtain/break the required
cryptographic keys to decrypt private messages between de-
vices. The adversary is not able to replay old messages
or to inject or synthesize false messages into the network.
Our adversary is weaker compared to the standard Dolev-
Yao [19] model where the adversary is global, is able to
overhear and intercept all messages, and is able to synthe-
size fake messages in the network. Our weaker, local eaves-
dropper adversary model is practical, given the current state
of the art in monitoring technology, and it is suﬃcient for
launching localized user-tracking attacks.

Let us represent a message observed by the adversary as
a ﬁve-tuple ˆm = (ˆt, ˆπ, ˆc, ˆo, ˆs), where ˆo is the adversary AP
observing the message, and ˆt, ˆπ, ˆc are the reception time (at
the AP), device identiﬁer or pseudonym and message con-
tent, respectively, and ˆs is the received signal strength (in
dB) measured by ˆo. Note that an observed message, obvi-
ously, does not contain the identity of the user u who sent
the message, but only the device pseudonym ˆπ = π. Let
ˆM be the set of all the messages observed by the adversary.
The adversary attempts to link all pseudonyms (hence, the

messages) belonging to a given user from the set of all ob-
served pseudonymous messages, and thus to reconstruct the
path taken by him (over the area observed by the adver-
sary). We refer to this as a reconstruction attack, deﬁned as
follows:
Deﬁnition 1. A reconstruction attack attempts to con-
struct a temporal sequence or trace ˜r = ( ˆπ0, ˆπ1, . . . , ˆπk) of
pseudonyms belonging to the same user, where Π is the set
of all user pseudonyms and ˆπi ∈ Π,∀i. The corresponding
true sequence, also called ground-truth, is denoted by r.

The adversary’s goal is to maximize the success of her
reconstruction attack. We measure the success of the ad-
versary by using well-established metrics, as described in
Section 5.1. After all the traces belonging to a given
user have been reconstructed, the adversary can attempt
to deanonymize the actual identity of the user. Such re-
identiﬁcation attacks are beyond the scope of this paper;
they could be carried out using several existing strategies
in the literature [29, 26].

2.3. Pseudonym Change Algorithm (PCA)

In this work, our main aim is to evaluate context-based
location-privacy protection mechanisms against passive ad-
versaries as outlined in the earlier section. For this pur-
pose, we implement a standard context-based identiﬁer-
change mechanism, referred to as Pseudonym Change Al-
gorithm or PCA, which uses the concept of mix-zones
[9, 10]. Mix-zones, as shown in Fig. 1 (middle), are dynam-
ically formed regions (in our case, device neighborhoods)
where users’ devices stop transmitting and synchronously
change their identiﬁers to achieve communication unlinka-
bility. After exiting the mix-zone, the devices resume com-
munication with new identiﬁers.
It has been shown [10]
that such coordinated identiﬁer-changes provide suﬃcient
spatio-temporal de-correlation between devices and their
communications. But in order to be eﬀective, identiﬁer-
changes should be reﬂected across all communication lay-
ers, including link, network and application layers. As
application-layer identiﬁers can be encrypted and network
addresses are dynamically assigned (at least in NIC), we
focus on changing only the link layer or MAC address in
our PCA.

We now brieﬂy describe our PCA implementation (see
Algorithm 1). Using a context-check timer tc, the PCA pe-
riodically checks whether its current neighborhood is favor-
able (enough devices in the neighborhood) for an identiﬁer-
change operation. If there are enough devices in the neigh-
borhood and if the total number (num context changes) of
context-based identiﬁer changes on the device, so far, is be-
low some system-deﬁned threshold Qc, then the PCA ini-
tiates the MAC address change operation on the host de-
vice by calling the CHANGE PSEUDONYM() function. It

Algorithm 1 Pseudonym Change Algorithm (PCA)

Deﬁne Qc → context quota, Q f → forced quota,
radio o f f time → min.
radio silence after identi-
ﬁer change, change time threshold → required min.
time threshold and neighbor threshold → required min.
neighbor threshold for identiﬁer change.

on t f expired do

(cid:46) Forced timer expiration

if num f orced changes < Q f then

broadcast(mix request)
change pseudonym( )
radio silence(radio oﬀ time)
num f orced changes + +

end if

end on

on tc expired do

(cid:46) Context timer expiration
if current neighborhood > neighbor threshold and

num context changes < Qc then

broadcast(mix request)
change pseudonym( )
radio silence(radio oﬀ time)
num context changes + +

end if

end on

Let

dt

current timestamp
>

if

dt

on mix request received do

←

(cid:46) Incoming mixing request
last change timestamp −

change time threshold

and

num context changes < Qc then

change pseudonym( )
radio silence(radio oﬀ time)
num context changes + +

end if

end on

also initiates a mix attempt by sending a mix-request to the
neighboring devices. After the identiﬁer-change operation,
PCA switches oﬀ the wireless interface for a random time
period and increments the counter for context-based iden-
tiﬁer changes. Random timers are used to prevent trivial
timing-based linking attacks.

Upon receiving a mix-request,

the neighboring de-
vices follow a similar procedure for changing their MAC
addresses;
they perform an additional check before the
identiﬁer-change operation in order to prevent frequent
changes that are ineﬀective and expensive. If the identiﬁer-
changes were solely based on device context,
it would
be possible that devices do not have a favorable context
or neighborhood for a long period of time, thus making
them trivially trackable.
In order to overcome this issue,

PCA makes use of another timer, called the forced-change
timer or t f . When t f expires, the device, independently
of its neighborhood, changes its MAC and enters a radio
silence period if the number of forced identiﬁer changes
(num f orced changes) is below the system-deﬁned forced-
change threshold Q f . In order to prevent trivial timing at-
tacks, both t f and tc are not ﬁxed values but are chosen
from a normal distribution (with appropriately chosen mean
and variation) independently by each device. Note that the
thresholds Qc and Q f are maximum daily thresholds and the
counters num context changes and num f orced changes
are reset daily at 00:00 on each device.

In order to evaluate PCA under diﬀerent privacy set-
tings, we select three sets of parameter values, as shown
in Table 1. The ﬁrst set focuses on cost-eﬀectiveness by re-
quiring a comparatively lower number of overall identiﬁer-
changes and a larger time-gap between changes, which
leads to fewer mixing attempts. Due to relaxed neighbor-
hood requirements per change, the probability that the mix-
ing attempt will be successful for this set of parameters
is high. The third set of parameters has provisions for a
large number of identiﬁer-changes and a smaller time-gap
requirement between changes, thus representing a privacy-
sensitive behavior. The higher neighborhood requirement
per change, in this case, is aimed at improving the unlinka-
bility per change, i.e., each change is more eﬀective than in
the earlier case. Finally, the second parameter set represents
an intermediate behavior.

Before the actual deployment, we divide the devices into
three groups, each running PCA with a diﬀerent parame-
ter setting.
In order to achieve a uniform distribution of
parameters across all devices, the device parameters were
shuﬄed across the groups remotely, once a month. In or-
der to determine an appropriate value for the neighborhood
threshold, we refer to the analysis by Kiukkonen et al. [40]
who studied real user mobility based on mobile phone data
(GPS locations and Bluetooth encounters) of 200 users col-
lected over a period of 2 years. The authors observed that
the average probability of any device having a Bluetooth
encounter with more than 3 other devices was less than
0.2. WiFi-based peer-to-peer and Bluetooth communica-
tions diﬀer in many aspects, but as WiFi-based peer-to-peer
networks, such as NIC, are not commonplace, we rely on
the above results to select initial values for the neighbor-
hood thresholds. As NIC devices, unlike Bluetooth, are
context-sensitive and may be switched-on all the time, the
selected threshold values are a bit pessimistic, but they serve
as a good starting point. Due to the limited duration of our
deployment, we could not test a large variety of parameter
conﬁgurations in real experiments. Later, as discussed in
Section 5.6, we will perform simulation experiments with
other PCA parameters and conﬁgurations by using the mo-
bility patterns and data ﬂows from the real deployment.

Table 1. PCA parameter values used in the real deployment.

Q = Qc + Q f

change time threshold

neighbor threshold

Parameter

Cost-eﬀective
Intermediate

Privacy-sensitive

Mean t f
14400 sec
7200 sec
3600 sec

Mean tc
3600 sec
1200 sec
300 sec

5
20
60

7200 sec
1800 sec
600 sec

1
2
3

3. Data Collection and Processing

In order to accurately measure the adversary’s success,
it is important to compare the results of her tracking at-
tacks to the groundtruth (or actual user traces); the ground-
truth acts as a reference for evaluating the success of the
tracking attacks. The adversary wants to be as close to the
groundtruth as possible. In this work, our ﬁrst task is to re-
construct the groundtruth by adding extra information in the
observed data. We assume that this extra information will
not be available to the adversary, and as a result she will not
be able to reconstruct the groundtruth as outlined in Section
3.1. Nevertheless, the adversary has to perform some basic
processing on the observed data, as outlined in Section 3.2,
before using it in her tracking attacks.

3.1. Groundtruth Reconstruction

The groundtruth reconstruction step provides the true
mapping between each observed message and the device
that sent it. This mapping will be used later to verify the
correctness of the mapping created by the adversary’s track-
ing algorithm. The source MAC address in the messages
cannot be used for groundtruth reconstruction because it is
regularly updated by the PCA. Thus, in order to obtain the
groundtruth, we need to include some ﬁxed device identiﬁer
in the observed messages. We achieve this by embedding
the device International Mobile Equipment Identity (IMEI)
number in the messages generated by a few user applica-
tions. The IMEI contained in the messages from these ap-
plications can be used to match diﬀerent MAC addresses to
the same device. For instance, two sets of messages, each
with a diﬀerent MAC address, can be linked to the same
device (or user) if there is at least one message containing
the IMEI for each MAC used. Even messages that do not
contain the IMEI, such as system messages, can be linked
together if there is at least one IMEI containing message
with the same MAC address. In this way, we are able to
reconstruct approximately 99% of the groundtruth from the
observed messages.

3.2. Adversary Post-Processing

The adversary faces two main challenges while process-
ing the observed or sniﬀed data: First, for any message

m there may exist multiple copies of observed messages
ˆm (from diﬀerent APs or sniﬃng stations), possibly with
diﬀerent values of ˆt, ˆo and ˆs (but obviously, with identical
ˆπ and ˆc). Second, the position of the original message m
is not directly available from the observed messages ˆm; it
must be derived from the position of the sniﬃng stations
(ˆo) and the Received Signal Strength Indicator (RSSI) ( ˆs).
For any message m, let ˜m be the re-construction of m by the
adversary from the observed messages ˆm. The objective of
the adversary is to reconstruct ˜m as close to m as possible.
In order to do this, she has to ﬁrst gather all observed mes-
sages ˆm corresponding to the same sent message m. We re-
fer to such a collection of identical observed messages as an
event that can be represented as a ﬁve-tuple e = (ˆπ, ˆc, ˆT , ˆO),
where ˆπ is the pseudonym the device used while sending
the message with content ˆc, ˆT is the set of time-stamps cor-
responding to the times observed in each of the ˆm forming
e and ˆO is the set of sniﬃng-station identiﬁers and corre-
sponding RSSIs associated with each ˆm forming e. The set
of all events is denoted by E. The construction of E, re-
ferred to as event identiﬁcation, can be accomplished by the
adversary by matching the pseudonyms (ˆπ) and contents (ˆc)
of observed messages. After E is constructed, the adversary
can use each event e in E to reconstruct the corresponding
˜m by aggregating all the information in that event. In other
words, given an event e, the reconstructed message ˜m can be
represented as ˜m(e) = (u, ˜t, ˜p, ˜π, ˜c), where u is the user that
sent the message m, ˜π = ˆπ(e), ˜c = ˆc(e) and ˜t, ˜p are aggre-
gated values of time and position from ˆT and ˆO in e. The
user u is not known to the adversary after the aggregation
phase and it can be determined by using re-identiﬁcation
techniques [29, 26] after executing the tracking algorithms.
We now outline the post-processing that the adversary does
to construct ˜m (except user information) for each message
m from a set of observed messages ˆm.

3.2.1 Time-stamp Synchronization

In order to accurately aggregate and order time-stamps dur-
ing event identiﬁcation, the adversarial sniﬃng stations or
APs should be synchronized with each other. In our deploy-
ment, the APs suﬀer from synchronization problems due to
large clock drifts (sometimes in several minutes) and ran-
dom clock resets (in some rare cases) to the Unix Epoch,
i.e., 1970-1-1 00:00:00. Due to the unavailability of NTP-
based solutions on these APs, we employ a best-eﬀort syn-

chronization technique. We ﬁrst divide time into discrete
intervals of two hours. For each interval, we construct a
graph where the (observed) APs represent the vertices of the
graph and there is an edge between two vertices if a clock
skew is detected between them. The clock skew gives the
edge weight. Then, by means of a standard all-pairs short-
est path algorithm such as Floyd-Warshall algorithm, we
build a set of least cost paths between all pairs of sniﬃng
stations. By starting from the node with the smallest cost
path to all other nodes, we correct the clock skews step-by-
step, until all clocks are resynchronized. The Nokia N900s
are time-synchronized by using the NTP implementation on
the devices.

3.2.2 Event Identiﬁcation

Event identiﬁcation consists of aggregating identical mes-
sages observed by diﬀerent sniﬃng stations at (or approxi-
mately) the same time. A naive approach that searches the
entire message space is infeasible. We use the following
two heuristics, which signiﬁcantly reduce the search space,
and thus the event identiﬁcation time.

• Temporal proximity-based search: Typically, any mes-
sage broadcast by a device arrives at the neighboring
sniﬃng stations within a delay of a few milliseconds of
each other. Thus, we deﬁne an appropriate time thresh-
old for each observed message and limit our search for
identical messages to only those messages that have
reception times within this threshold.

• Spatial proximity-based search: Assuming that all
sniﬃng stations have the same range, any message sent
by a device can be seen by sniﬃng stations only within
a certain distance from the device. As deﬁning dis-
tance thresholds is not practical, we deﬁne a neigh-
borhood for each sniﬃng station and limit our search
to messages observed by the station and its neighbor-
hood.

We further reduce the processing time for message com-
parison by comparing the message content hashes (obtained
using a cryptographic hash function such as SHA-2) rather
than the actual content. This improves the comparison
speed because of the reduced length and absence of long
common preﬁxes in the compared strings.

3.2.3 Time-stamp Aggregation

After the event identiﬁcation step, the adversary needs to
reconstruct individual messages ˜m from their corresponding
events. For each such message, she needs to ﬁrst estimate
the time at which it may have been sent by the source de-
vice. For a reconstructed message ˜m of the original message
m, we assume that the adversary chooses the time-stamp ˜t

as min( ˆT), where ˆT is the set of time-stamps of the corre-
sponding event. In other words, she chooses the lowest ob-
served time-stamp for each event because it will be closest
to the time instant at which the message was actually sent.
The goal of aggregating time-stamps in such a fashion is to
obtain an accurate ordering for reconstructed messages.

3.2.4 Coordinate Mapping

After assigning time-stamps to each reconstructed message
˜m, the adversary needs to estimate its position, i.e., the posi-
tion of the device when the corresponding m was sent. The
adversary does this by aggregating the sniﬃng station and
RSSI information present in each observed message of the
event. The location of devices (hence, the messages) and
sniﬃng stations can be represented as two-dimensional co-
ordinates (x, y), where 0 ≤ x ∈ R ≤ 200, 0 ≤ y ∈ R ≤ 100.
Note that the message (or device) positions can be slightly
beyond the 186m × 66m sniﬃng station deployment area.
As the adversarial sniﬃng network is deployed on the same
ﬂoor level, we do not consider the third dimension. For
each reconstructed message ˜m, the adversary ﬁrst computes
its distance to each sniﬃng station (observing that message)
from the corresponding RSSI value in the event by using a
standard radio propagation model [47] (Eqn. 1).

(cid:18) λ

(cid:19)

4π

(cid:33)

(cid:32) 1

d

Pr = Pt + 20 log

+ 10n log

(1)

In (1), Pt and Pr are the transmitted and received power
[dBm], λ is the wavelength of the radio signal [m], n is
the path-loss exponent and d is the distance between the
transmitter and receiver [m]. In our deployment, we have
Pt = 20dBm, λ = 0.125m and n = 4.8 (considered suitable
for indoor environments).

In Algorithm 2, we outline the procedure for comput-
ing the message position once the distances have been esti-
mated. There can be four cases, depending on the distinct
number of RSSIs available for the event, which in turn de-
pends on the number of distinct observations (by sniﬃng
stations) per message. In case only one observation is avail-
able, the position of the reconstructed message is chosen as
the location of the sniﬃng station observing the message.
If two observations are available, then a position weighted
on the distance to each sniﬃng station is chosen.
In the
case three or more distinct distances to non-collinear sniﬀ-
ing stations are available, a straightforward trilateration pro-
cedure [37] is used by choosing an appropriate bound on the
distance-error .

4. Tracking Framework and Algorithms

We now outline our probabilistic tracking framework

and two tracking algorithms within this framework.

Algorithm 2 Position Estimation

Input: P[] is the list of positions of sniﬃng stations
observing the message. P[i] = (Px[i], Py[i]) are the x
and y coordinates of the ith sniﬃng station observing
the message
Input: ˜D[] is the list of distances (computed from sig-
nal strength indicator) from each sniﬃng station ob-
serving the message
Output: ˜p, the estimated position of the message

1: n = |P|, the number of sniﬃng stations
2: m = | ˜D|, the number of distances
3: if not (n = m) OR n = 0 then
4:
5: else if n = 1 then (cid:46) Only sniﬃng station i observes the

return error

message

return P[i]

6:
7: else if n = 2 then

observe the message

8:

return

(Px[i]
Py[ j] − Py[i]

Py[i] +

( ˜D[i] + ˜D[ j])/ ˜D[i]

9: else if n = 3 then

observe the message

(cid:46) Only sniﬃng stations i and j

Px[ j] − Px[i]

( ˜D[i] + ˜D[ j])/ ˜D[i]

,

+

)

(cid:46) Only sniﬃng stations i, j and k

return trilateration(P[i],

˜D[i], P[ j],

˜D[ j], P[k],

Let l, m, n be the three sniﬃng stations in P[] with

the smallest distances

return trilateration(P[l], ˜D[l], P[m], ˜D[m], P[n],

10:

˜D[k])
11: else
12:

13:

˜D[n])
14: end if

4.1. Probabilistic Tracking Framework

We model the daily observations by the adversarial AP
mesh network by using a Markov chain, where a state of
the system is deﬁned as the set of ordered observations with
the same pseudonym and the transition probability gives
the probability of going from one set of observations to
the next. As the total number of observations is ﬁnite and
the transitions probabilities are time-invariant (as discussed
below) with a ﬁxed probability distribution on the initial
states, the proposed model can be characterized as a ﬁnite
state ﬁrst order Markov chain.
Let S be the state space and each state s ∈ S be rep-
resented as a triple of the form s = (π, estart, eend), where
π ∈ Π is a pseudonym and estart, eend are temporally1 the
ﬁrst and last event respectively using the pseudonym π.
Here, tstart(s) = ˜t(estart(s)) and tend(s) = ˜t(eend(s)) are the
corresponding start and end times of the state s, respec-

1An implicit assumption here is that no pseudonym is reused.

ity: (cid:80)

tively. A similar notation is used for the observers and re-
ceived signal strengths of the state. The transition probabil-
ity matrix is deﬁned by a transition function P : S × S →
[0, 1] that satisﬁes the following two constraints: 1) Valid-
s j∈S P(si, s j) = 1 ∀si ∈ S and 2) Time monotonic-
ity: P(si, s j) = 0 ∀si, s j ∈ S such that tend(si) > tstart(s j).
Each entry in the transition probability matrix P[i, j] rep-
resents how likely the adversary considers state s j to fol-
low si; it gives the likelihood of the adversary to observe
events in s j immediately after observing events in si for any
user. The transition probability matrix is user-invariant, i.e.,
the adversary’s transition function is the same for all users.
The tracking success of the adversary depends on how well
the transition function is deﬁned and how close it is to the
actual transitions. In this work, we estimate the transition
function by using two heuristics that intuitively capture the
likelihood of observing a set of events from some previous
events.

1. Common sniﬃng stations: The probability that a state
s(cid:48) is the next state of state s is proportional to the num-
ber of common sniﬃng stations in the events observed
in s and in s(cid:48). The higher the number of common sniﬀ-
ing stations between s and s(cid:48), the higher the probability
of transitioning from s to s(cid:48).

2. Speed matching: As each event has position and time
information, a notion of speed between two events can
be deﬁned as the Euclidean distance between the (po-
sition of) two events divided by the time diﬀerence
between the events. Then, according to our speed-
matching heuristic, the probability that a state s(cid:48) fol-
lows state s is 1 − |v(s) − v(s(cid:48))|/vmax, where v(s) is the
speed of state s and vmax is the maximum speed (5m/s
in our case).

The tracking framework and the transition probabilities
described above are for a single user, given his initial state
(or some probability distribution on it). In this case, the at-
tacker wants to determine a single (most probable) path in
the state space corresponding to the user in the initial state.
It is also possible to track multiple users simultaneously us-
ing the above model, i.e., the attacker will attempt to ﬁnd
several non-overlapping paths in the state space, given the
initial states of multiple users. As the transitions in this
case are between sets of states or multi-states (one state for
each user being tracked), the transition probability function
needs to be accordingly modiﬁed. The transition probability
of one multi-state to the next can be estimated by normaliz-
ing the sum of the individual transition probabilities in the
multi-set. Speciﬁc details of the single user and multi-user
transition probability matrix computations can be found in
[11].

4.2. Tracking Strategies

We propose two straightforward adversarial tracking

strategies based on the above tracking framework.

4.2.1 Locally Optimal Walk (L-WALK)

The L-WALK algorithm (Alg. 3) reconstructs the user trace
by performing a locally-optimal walk in the state space. In
other words, at each state (of the walk), starting from the ini-
tial state, the next state candidate with the highest probabil-
ity is selected, until there are no further candidates. L-WALK
produces an ordered sequence of states T = (s0, s1, ..., sk)
(k > 0) such that P(si, si+1) > P(si, s(cid:48)) ∀ s(cid:48) ∈ S \ si+1 ∀ i =
0, 1, ..., k.

Algorithm 3 Locally optimal walk (L-WALK)
Input: Initial state s0, heuristic function P
Output: Trace T = (s0, ..., sk)
1: T ← (s0), continue ← True
2: repeat
3:

Let c be the next state candidate with the highest

probability

Append c to T

4:
5: until no more candidates
6: return T

From Alg. 3, we can see that L-WALK iteratively builds a
walk by selecting the probabilistically best next state at each
iteration and stops when no more states are available. It is
possible to improve L-WALK by using additional reference
points along the walk. For instance, if the adversary is able
to ascertain that some state s j is associated to a given user,
she can use s j to better direct her search in cases where mul-
tiple next states are equally probable at a given state. Due
to this additional knowledge, paths that do not pass through
s j can also be discarded by the adversary. More than one
such reference point will further improve the accuracy of
the adversary’s walk.

4.2.2 Globally Optimal Walk (G-WALK)

The G-WALK algorithm (Alg. 4) reconstructs the user trace
by performing a walk in the state space such that the prob-
ability over the entire walk is maximized over all walks.
In other words, G-WALK produces an ordered sequence of
states T = (s0, s1, ..., sk) (k > 0) such that Πk−1
i=0 P(si, si+1) >
l) with T(cid:48) (cid:44) T and
j, s(cid:48)
Πl−1
j=0P(s(cid:48)
s0 = s(cid:48)
0. Unlike L-WALK, G-WALK does not rely on locally
optimal choices but makes a globally optimal choice.

j+1) : ∀T(cid:48) = (s(cid:48)

1, ..., s(cid:48)

0, s(cid:48)

An exhaustive search for a globally optimal path is in-
feasible due to the large number of paths in the state space.
In order to obtain a fairly good approximation of the global

Algorithm 4 Globally optimal walk (G-WALK)

Input: Initial state s0, transition function P, maximum
evaluation count cmax, initial temperature tinitial and tem-
perature decrease factor k ∈ [0, 1]
Output: Trace T = (s0, ..., sk)
T ← L-WALK(s0), v ← Πk−1
and likelihood
Tbest ← T , vbest ← v
c ← 0
while c < cmax do

(cid:46) Best solution and likelihood
(cid:46) Initial evaluation count

i=0 P(si, si+1) (cid:46) Initial solution

Tnew ← mutate(T), vnew ← Πk−1
t ← temperature(c), c ← c + 1
if random( ) < accept probability(v, vnew, t) then (cid:46)

i=0 P(snew,i, snew,i+1)

Randomly move to a new state

T ← Tnew, v ← vnew

end if
if vnew > vbest then

Tbest ← Tnew, vbest ← vnew

end if
end while
return Tbest

function mutate(T)

Let T(cid:48) be a random mutation of T.
return T(cid:48)
end function

function temperature(c)

return tinitial · (k)c

end function

function accept probability(v, vnew, t)

return min(1, e(vnew−v)/t)

end function

optimum, we use a randomized search heuristic called Sim-
ulated Annealing (SA) [33]. In G-WALK, the current solution
in each iteration is replaced by a random “nearby” solution
chosen with a probability that depends both on the diﬀer-
ence between the values of those solutions and a global
parameter t, called the temperature, which is gradually de-
creased in each iteration. The “nearby” solution or path is
chosen by the MUTATE function, which replaces one of the
state transitions in the current solution by an alternate one.
The temperature parameter enables the algorithm to escape
local optima throughout the simulation, while slowly con-
verging to a near-optimal solution.

5. Empirical Results and Evaluation

pseudonym changes:

· l−1(cid:88)

1
l

H(Y(πi))

uavg(˜r) =
umax(˜r) = max{H(Y(πi)) | πi ∈ ˜r \ ˜πl}
umin(˜r) = min{H(Y(πi)) | πi ∈ ˜r \ ˜πl}

i=0

We evaluate the success of the L-WALK and G-WALK al-
gorithms in tracking users by using well-known metrics for
location privacy.

5.1. Privacy Metrics

We use four metrics in our evaluation; each uniquely

captures the extent to which users can be tracked.

5.1.1 Traceability Metrics (τ-metrics)

Traceability metrics, originally proposed by Hoh et al. [32],
capture the extent to which the user can be tracked in time or
distance. In our setting, we deﬁne two traceability metrics:
the percentage of time τt and the percentage of space τd
during which tracking is successful. Formally, these metrics
are deﬁned as follows:

Deﬁnition 2 (Traceability metrics). Let ˜r = ( ˜π0, ˜π1, ..., ˜πl)
denote the reconstruction of user pseudonyms as obtained
by a reconstruction attack and r = (π0, π1, ..., πk) be the
real sequence (groundtruth) of pseudonyms. The time- and
distance-traceability metrics are:

i=0

(cid:80)min(k,l)
(cid:80)k
(cid:80)min(k,l)
(cid:80)k

i=0

tmatch(πi, ˜πi)

i=0 tused(πi)

dmatch(πi, ˜πi)

i=0 dused(πi)

τt(r, ˜r) =

τd(r, ˜r) =

where tused(π) and dused(π) are the actual time and distance
that pseudonym π was used by the user being tracked, and
tmatch(π, ˜π) and dmatch(π, ˜π) are the time and distance during
which pseudonym ˜π is correctly matched to π in the recon-
structed trace by the adversary for that user.

5.1.2 Uncertainty Metrics (u-metrics)

Uncertainty metrics, originally proposed by Diaz et al. [18],
capture the uncertainty of the adversary to correctly predict
the next pseudonym used by the user. We deﬁne three un-
certainty metrics as follows.

Deﬁnition 3 (Uncertainty metrics). Let ˜r = ( ˜π0, ˜π1, ..., ˜πl)
denote the reconstruction of user pseudonyms obtained by
a reconstruction attack. Let Y(π) be the random variable
denoting the next possible pseudonym (selected by the ad-
versary) of pseudonym π and H denote the entropy oper-
ator. Then, we have the following uncertainty metrics that
give the average, maximum and minimum entropy for all

5.1.3 Traceability-Uncertainty Metrics (µ-metrics)

Traceability-Uncertainty metrics combine the advantages of
the traceability and uncertainty metrics by capturing both
the extent to which the user can be tracked, as well as the
diﬃculty (or uncertainty) in tracking. They can be deﬁned
as follows.
Deﬁnition 4 (Traceability-uncertainty metric). Let ˜r =
( ˜π0, ˜π1, ..., ˜πl), r = (π0, π1, ..., πk), Y(π) be deﬁned as above.
Let Hmax(Y(π)) = log2 |Y(π)| denote the maximum achiev-
able entropy for pseudonym π. Then, the corresponding
time- (µt) and distance-traceability-uncertainty (µd) metrics
are:

(cid:80)min(k,l)
(cid:80)min(k,l)

i=1

i=1

H(Y(πi−1))
(cid:80)min(k,l)
Hmax(Y(πi−1))
H(Y(πi−1))
(cid:80)min(k,l)
Hmax(Y(πi−1))

i=1

i=1

tused(πi)

dused(πi)

· tmatch(πi, ˜πi)

· dmatch(πi, ˜πi)

µt(r, ˜r) =

µd(r, ˜r) =

5.1.4 Clustering Metrics (c-metrics)

Clustering c-metrics, as proposed by Hoh et al. [31], capture
the extent to which one user was confused with another in
the context of multiple user tracking. We deﬁne the cluster-
ing error metric as a measure of the average distance-error
between the reconstructed and real sequence of pseudonym
over all users. We ﬁrst deﬁne the clustering error for a single
user as follows:
Deﬁnition 5 (Clustering error for single user). For any user
u, let ˜r = ( ˜π0, ..., ˜πl) and r = (π0, ..., πk) be deﬁned as above
and pstart(π) be the position of the start event of the sub-
trace with pseudonym π. Then, the clustering error cu for
user u is the average distance between the start events in
the reconstruction and in the groundtruth:

cu(r, ˜r) =

1

min(k, l) − 1

||pstart( ˜πi) − pstart(πi)||

Then, the multi-user clustering error metric can be de-

ﬁned as follows.
Deﬁnition 6 (Clustering error metric). Let ˜R be the set of
reconstructed sequences of user pseudonyms as obtained

· min(k,l)(cid:88)

i=0

(a)

(c)

(b)

(d)

Figure 2. Traceability success: 2(a) single user tracking results; 2(b) multiple user tracking results.
Adversary strengths using L-WALK and G-WALK: 2(c) single user; 2(d) multiple users.

by a multi-user reconstruction attack, R be the set of real
sequences (groundtruth) of pseudonyms for the same users
and U be the set of all users. Then, the the clustering error
metric C is deﬁned as the average clustering error over all
users:

cu(r, ˜r)

u∈U,r∈R,˜r∈ ˜R

|U| · (cid:88)

1

C(R, ˜R) =

The evaluation of the proposed tracking algorithms with
more sophisticated privacy metrics, such as the one by
Shokri et al. [45, 44], is left as part of future work.

5.2. Results Overview

Fig. 2(a) shows the results for the single-user tracking
using time and distance traceability metrics, which are av-
eraged across all users and all tracking attempts over the en-
tire 4-month duration. We can observe that the success ratio
of L-WALK is around 60% with the time traceability met-
ric and roughly 50% with the distance traceability metric.

Also, both the speed and common station heuristics fared
more or less equally well. The high success ratio of the
simple L-WALK algorithm shows that the current PCA pa-
rameters (Table 1), althought realistic, do not perform very
well in networking scenarios with slow or limited mobil-
ity, such as a network of smartphone users. In our setting,
it is indeed rare to observe users move signiﬁcantly during
a mixing attempt. Consequently, even simple algorithms,
such as L-WALK, are very eﬀective in providing a correct or-
dering on candidates for the next state, despite the fact that
transition probability estimates are not extremely precise.

In order to have an equivalent performance compari-
son of the G-WALK with L-WALK for the single user case,
we need to slightly adapt G-WALK’s maximization crite-
rion. In the single-user case, simply maximizing the prod-
uct of probabilities for each complete walk is inherently
prone to selecting shorter walks (as their products tend to
be larger than those of longer walks). In our implementa-
tion, rather than simply maximizing the product of proba-

62%47%61%50%46%31%43%28%   0   10   20   30   40   50   60   70   80   90   100time trackingdistance trackingTraceability [%]L-WALK with common sniffing stations heuristicL-WALK with speed matching heuristicG-WALK with common sniffing stations heuristicG-WALK with speed matching heuristic84%65%88%70%83%67%81%64%   0   10   20   30   40   50   60   70   80   90   100time trackingdistance trackingTraceability [%]L-WALK with common sniffing stations heuristicL-WALK with speed matching heuristicG-WALK with common sniffing stations heuristicG-WALK with speed matching heuristic   0   10   20   30   40   50   60   70   80   90   10071319253137Traceability [%]Number of sniffing stationsL-WALK time trackingL-WALK distance trackingG-WALK time trackingG-WALK distance tracking   0   10   20   30   40   50   60   70   80   90   10071319253137Traceability [%]Number of sniffing stationsL-WALK time trackingL-WALK distance trackingG-WALK time trackingG-WALK distance tracking(cid:113)
l) with T(cid:48) (cid:44) T, s(cid:48)

k

bilities, G-WALK selects the walk that maximizes the geo-
(cid:113)
Πk−1
i=0 P(si, si+1) >
metric average of its probabilities, i.e.,
i ∈
1, ..., s(cid:48)
Πl−1
i=0P(s(cid:48)
S ∀ i = 0, 1, ..., k. Thus, by taking into account the length
of each walk, we avoid the previous bias towards selecting
shorter walks.

i+1) ∀T(cid:48) = (s(cid:48)

0, s(cid:48)

l

i , s(cid:48)

Experimental results show that

the success rate of
G-WALK in tracking individual users is just over 43% with
the time traceability metric and around 30% with the dis-
tance traceability metric, which is obviously lower than that
of L-WALK. This fact can be explained based on the proba-
bility assignment done by the common sniﬃng stations and
speed-matching heuristics. Both these heuristics are static
and memoryless, i.e., they do not consider the probability
of reaching a particular state (from the initial state) in or-
der to estimate transition probabilities from that state. As a
result, the transition probabilities assigned by these heuris-
tics would suggest a good ordering rather than an accurate
overall probability estimate, which explains why L-WALK
performs better as it attempts to determine the most likely
order of states by making locally optimal decisions. Fig-
ure 3 shows a (partial) snapshot of the single-user tracking
algorithm execution on the data collected from our experi-
ments. In this ﬁgure, the blue color shows the groundtruth,

Figure 3. L-WALK versus G-WALK.

the green color indicates the path chosen by the L-WALK al-
gorithm and the red color indicates the path chosen by the
G-WALK algorithm. We can clearly see that G-WALK attempts
to choose a globally optimal path, which is not the correct
one, and thus results in a lower traceability. Moreover, a
manual examination of a few tens of sample paths also re-
veals that the percentage of situations, where the overall

most likely path in the graph was truly the correct path,
was less than 20%, thus explaining the discrepancy between
L-WALK and G-WALK. Further improvements of the likeli-
hood heuristics and G-WALK are left as future work. L-WALK
could be further improved by using reference points in or-
der to guide the state search. Only one extra reference point
suﬃces to increase L-WALK’s average traceability by 20%.
With two more reference points, the traceability nears 95%.
Fig. 2(b) presents multiple user time- and distance-
traceability results. Both L-WALK and G-WALK methods
yield approximately the same results: over 80% time trace-
ability and over 60% distance traceability. The main advan-
tage of multiple user tracking over single user tracking is
that the former leads to no collisions: as all users are be-
ing tracked simultaneously, no two users can have the same
next state. Another advantage is that multiple user track-
ing algorithms can handle the users’ leaving the experiment
area, and their coming back, because they have a global pic-
ture of all users. These advantages lead to a higher tracking
success.

Table 2 summarizes all tracking results for the previously
deﬁned metrics. In particular, we observe that the uncer-
tainty (uavg) depends both on the data and the heuristic used
and that the µ-metrics (traceability-uncertainty combined)
roughly follow the τ-metrics (traceability only). Finally,
the c-metric, which is deﬁned only in the multiple user sce-
nario, indicates a clustering error of about 8 meters. Al-
though this is not enough to precisely track a single user, in
most cases it is enough to identify the room in which the
user is.

5.3. Adversary Strength

Hereafter, we evaluate the success of the proposed track-
ing algorithms under varying adversarial strengths. We vary
adversarial strengths by systematically reducing the adver-
sary’s sniﬃng capabilities (see Table 3) at each step of the
evaluation. At each step, we reduce the number of sniﬃng
stations (speciﬁcally, by six additional stations), and thus
the corresponding sniﬀed data, available for tracking. These
sniﬃng stations are selected based on the coverage provided
by each of them such that the overal coverage after their re-
moval is maximized.

Fig. 2(c) shows the success rate of single user tracking
under varying adversarial strengths. We can observe that
the traceability success increases with the number of adver-
sarial sniﬃng stations, which is intuitive. Interestingly, the
traceability success stabilizes after a given point (31 sniﬃng
stations), where the adversary’s coverage can be considered
as optimal and additional stations are not very useful.

Similarly, Fig. 2(d) shows the success rate of multi-
ple user tracking for varying values of adversary strength.
The traceability success trends for the multiple user track-

0.10.40.50.60.40.30.31.00.4s0s1s2s3s4s5s6s7s8s9Table 2. Complete tracking results using the time, distance and clustering privacy metrics.

Users

Single User

Multiple Users

Heuristic

Method
L-WALK common stations
speed matching
G-WALK common stations
speed matching
L-WALK common stations
speed matching
G-WALK common stations
speed matching

τd

uavg
τt
62% 47% 0.69
61% 51% 1.21
46% 31% 0.33
43% 28% 0.80
84% 65% 0.47
88% 70% 0.63
83% 67% 0.52
81% 64% 0.56

µt
µd
40% 37%
59% 41%
23% 17%
36% 25%

cavg
-
-
-
-

-
-
-
-

-
-
-
-

8.32
7.86
8.78
8.10

ing case are very similar to those in single user tracking, ex-
cept that in multiple user tracking, the success rate is around
20% higher compared to single user tracking over all the
adversary strengths. In fact, by processing multiple users at
the same time, we observe that the algorithms perform bet-
ter even with signiﬁcant inaccuracies in the user positions.

Table 3. Adversary strengths.

# stations Density [/1000m2]

37
31
25
19
13
7

1.9
1.6
1.3
1.0
0.7
0.4

Strength
100%
84%
68%
51%
35%
19%

There might be other adversary models for tracking that
are signiﬁcantly weaker than (even the passive version of)
the omni-potent Dolev-Yao model but relevant from the
practical point of view. To be more widely useful, such an
adversary model should, of course, be applicable to many
diﬀerent kinds of scenarios. Finding such a model is an in-
teresting research challenge.

5.4. Impact on Network Efﬁciency

While providing privacy protection, one major concern
for pseudonym change mechanisms is the eﬀect it can have
on the network performance. We analyze the eﬀect of our
pseudonym change mechanism on the network performance
by computing the average time spent by devices in a mix-
zone and the resulting packet loss rate. We estimate the
average time of a device in a mix-zone by computing the
ratio of the average mixing time to the average time between
two mixings for that device. We estimate the packet loss
between two mix attempts by computing the ratio of the
average number of packets that would be sent during a mix
attempt to the average number of packets sent between two
mix attempts. In our experiments, we observe that between

two mixing attempts, devices spend an average of 1.5% of
their network time in mix-zones, resulting in a packet loss
rate of approximately 2.4%. These results show that PCA
with the current parameters does not have a major eﬀect
on the network performance. However, these values do not
consider the costs involved in re-establishing connections
or the eﬀect on transport protocols with congestion control
mechanisms.

5.5. Traceability in Large User Clusters

Intuitively, when users organize themselves in large clus-
ters (each cluster consisting of many mix-zones close to
each other), user density within individual mix-zones also
increases, thus leading to larger anonymity sets. Techni-
cally, this should result in better protection against trace re-
construction or tracking attacks. To verify this intuition,
we measure the traceability of users on some selected days
when the user-density is comparatively higher, for example,
around the time when participants have lectures. Specif-
ically, we deﬁne two tracking intervals, each of approxi-
mately 10 minutes, one at the beginning and the other at the
end of the monitored lecture.

We plot (Fig. 4) the average time traceability, as deﬁned
in Section 5.1, and the picked-up ratio during these two
tracking intervals. The picked-up ratio is the ratio of the
number of users for which the subtraces in the ﬁrst and the
second tracking interval match the ground truth to the total
number of users in both the intervals. The horizontal axis
in the plot denotes the number of users, during a particular
lecture, that can be followed by our multiple target tracking
algorithm. This number is also indicative of the size of the
user cluster on that particular day, although it does not di-
rectly represent the size of each mix-zone within that clus-
ter. We plot tracking results for 9 diﬀerent lectures of the
same course. We can see from the results that an increase in
the number of users present in the cluster decreases both the
traceability and the picked-up ratio. In other words, large
clusters enable users to hide from the adversary. Note that
these results include users (not necessarily in equal num-

identiﬁer-changes or mixing on the devices at the appropri-
ate times and locations.

Fig. 5(a) and 5(b) show the traceability results of the
L-WALK and G-WALK algorithms on the simulation-based
traces. These plots show that, although aggressive param-
eters result in better location privacy for users in general,
multiple-user tracking still performs suﬃciently well and is
a concern to location privacy. Furthermore, both the new
sets of parameters result in a signiﬁcant network perfor-
mance degradation, which makes it harder to implement
them in practice. Network performance will only worsen
for more aggressive parameter values.

Overall, the traceability results indicate that the current
PCA speciﬁcation, regardless of the chosen parameter val-
ues, is not very successful in preventing tracking attacks
against users in mobile and pervasive networking systems.
As a result, we propose three improvements to our original
PCA speciﬁcation, as outlined below, and evaluate each of
them in a simulation setting.

1. PCA with radio silence randomized over a larger time
interval: each device implements a radio silence delay
(tsilent) that is randomly selected between 0 and 30 sec-
onds, as opposed to the original speciﬁcation, where it
was randomly selected between 10 and 20 seconds.

2. PCA with longer radio silence: radio silence (tsilent) is

observed for a longer time period (30-90 seconds).

3. PCA with radio silence until movement detected: radio
silence is observed until the user has traveled a distance
of at least d (randomly selected in the interval [0, 20])
meters since the mixing decision.

As before, we simulate these PCA improvements over
the original experimental traces and the groundtruth ob-
tained from the real experiments. Tracking is performed
on the resulting simulated traces and the traceability results
are outlined in Fig. 5(c) and 5(d). We can see that all the
PCA improvements discussed above are successful against
the speed matching heuristic. However, solely randomiz-
ing the radio silence, as proposed in the ﬁrst two cases, is
not enough to defeat the common sniﬃng stations heuristic
due to the lower mobility and speed of users. Determin-
ing the length of the radio silence period by making use
of the user’s mobility (third improvement) provides protec-
tion against this heuristic. In this case, radio silence periods
can sometimes be extremely long, e.g., 30 minutes or more,
which could result in poor network performance and QoS.

6. Conclusion

In this paper, we have evaluated the eﬀectiveness of
mix-zone-based identiﬁer-change mechanisms in upcoming

Figure 4. Traceability and picked-up ratio ver-
sus the number of users in large clusters.

bers) from all the three parameter values outlined in Table 1
and that non-deterministic factors, such as user movements,
speed etc., can have an inﬂuence on the traceability, as visi-
ble from the slight irregularities in the plots.

5.6. PCA Improvements

The experimental results with the current set of PCA pa-
rameters (Table 1) show that even mobile users deploying
identiﬁer-changes are highly traceable and are prone to lo-
cation privacy-related attacks. The question remains: Is it
possible to choose better values (from the privacy perspec-
tive) for PCA parameters or to improve the PCA in general?
In this section, we attempt to answer these questions by se-
lecting two new sets of PCA parameters, which we consider
to be signiﬁcantly more aggressive with respect to privacy
preservation. These parameters are outlined in Table 4. We
performed simulations to verify the eﬀectiveness of these
aggressive parameter values in preventing user traceability.

Table 4. Aggressive PCA parameters.
Parameter
Mean t f
Mean tc

Aggressive V. aggressive
1200 sec
120 sec

Q = Qc + Q f

200

600 sec
60 sec
500

change time threshold

neighbor threshold

300 sec

3

120 sec

3

We simulated PCA with these new parameters, while re-
taining all original user communication and mobility pat-
terns. These simulations build a new set of traces from the
original traces and from the groundtruth (obtained during
the real experiments) by correctly simulating coordinated

0%10%20%30%40%50%60%70%80%90%100%152125263040465867Traceability [%]Ratio of users picked up [%]Number of userstime traceabilitypicked up ratio0%10%20%30%40%50%60%70%80%90%100%(a)

(c)

(b)

(d)

Figure 5. Results for aggressive parameters: 5(a) single user; 5(b) multiple users. Results with
modiﬁed PCA in multiple user tracking: 5(c) common snifﬁng stations; 5(d) speed matching.

wireless and mobile systems by means of a real deploy-
ment of 80 Nokia N900 smartphones on the EPFL cam-
pus. The local passive adversary, in our case, is comprised
of a wireless mesh network of 37 access points covering
a 200mx100m rectangular area of the campus. Our adver-
sary’s goal was to reconstruct an accurate ordering of identi-
ﬁers that belong to the same device in order to learn the path
taken by users. For this purpose, the adversary constructed
a probabilisitc tracking (Markov) model by employing in-
tuitive heuristics on the observations from the adversarial
access points. Two strategies were used to determine the
most likely path taken by the users, (1) a local greedy strat-
egy (L-WALK) and (2) a globally optimal strategy (G-WALK).
Our results have shown that, in real settings, even sim-
ple tracking strategies achieve high traceability success. By
changing identiﬁers in an aggressive fashion, we have ob-
served that the tracking success of the adversary reduces
considerably, albeit with a signiﬁcant decrease in the net-
work performance. We have observed that a decrease in

the number of adversary sniﬃng stations results in lower
traceability. There is still a need to ﬁnd a generic adversary
model that is weaker than the standard Dolev-Yao model
but stronger than our localized and stationary eavesdropper.
Finally, we have also shown that randomizing silence peri-
ods within a mix-zone, based on time-of-change or distance
travelled post-change, can vastly imrove the eﬀectiveness of
mixing in real systems.

Acknowledgments

We would like to thank Adel Aziz, Julien Herzen and
Patrick Thiran for their support and guidance during the
setup of the adversarial wireless mesh network. Special
thanks to Andreea Anghel for implementing the PCA and
to all the EPFL students who participated in the trial. Fi-
nally, we are grateful to Nokia Research Center for funding
this project.

42%28%35%22%23%14%20%12%0%10%20%30%40%50%60%70%80%90%100%time trackingdistance trackingTraceability [%]Aggressive L-WALKAggressive, G-WALKVery aggressive, L-WALKVery aggressive, G-WALK53%43%51%39%35%29%29%25%0%10%20%30%40%50%60%70%80%90%100%time trackingdistance trackingTraceability [%]Aggressive, L-WALKAggressive, G-WALKVery aggressive, L-WALKVery aggressive, G-WALK84%65%72%55%60%52%14%10%   0   10   20   30   40   50   60   70   80   90   100time trackingdistance trackingTraceability [%]Original dataRandomized radio silenceIncreased radio silenceRadio silence until movement88%70%13%7%12%7%10%7%   0   10   20   30   40   50   60   70   80   90   100time trackingdistance trackingTraceability [%]Original dataRandomized radio silenceIncreased radio silenceRadio silence until movementReferences

[1] https://foursquare.com/.
[2] http://en.wikipedia.org/wiki/Lovegetty.
[3] http://en.wikipedia.org/wiki/Bluedating.
[4] https://facebook.com/.
[5] http://pleaserobme.com/.
[6] I. Aad, M. Jadliwala, I. Bilogrevic, V. Niemi, L. Bind-
schaedler, J.-P. Hubaux, P. Ginzboorg, and K. Lepp¨anen.
Nokia Instant Community at EPFL: a Real-world Large-
scale Wireless Peer-to-Peer Trial. Technical Report EPFL-
REPORT-170421, EPFL, Lausanne, Switzerland, 2011.

[7] A. Ahtiainen, K. Kalliojarvi, M. Kasslin, K. Leppanen,
A. Richter, P. Ruuska, and C. Wijting. Awareness network-
ing in wireless environments: Means of exchanging infor-
mation. IEEE Vehicular Technology Magazine, September
2009.

[8] T. Alpcan and S. Buchegger. Security games for vehicular
networks. IEEE Transactions on Mobile Computing, 2011.
[9] A. R. Beresford and F. Stajano. Location privacy in perva-

sive computing. Pervasive Computing, 2003.

[10] A. R. Beresford and F. Stajano. Mix zones: User privacy in

location-aware services. In PerCom Workshop, 2004.

[11] L. Bindschaedler. Track me if you can. Master’s thesis,
School of Computer and Communication Sciences, EPFL,
2011.

[12] L. Butty´an, T. Holczer, and I. Vajda. On the eﬀective-
ness of changing pseudonyms to provide location privacy
in VANETs. In ESAS, 2007.

[13] L. Butty´an, T. Holczer, A. Weimerskirch, and W. Whyte.
Slow: A practical pseudonym changing scheme for location
privacy in VANETs. In IEEE VNC, 2009.

[14] D. Chaum. Untraceable electronic mail, return addresses

and digital pseudonyms. Comm. ACM, 1981.

[15] D. Chaum. The dining cryptographers problem: Uncon-
ditional sender and recipient untraceability. J. Cryptology,
1988.

[16] Z. Chen, H. Shen, Q. Xu, and X. Zhou. Instant Advertising

in Mobile Peer-to-Peer Networks. In ICDE, 2009.

[17] M. Corson, R. Laroia, J. Li, V. Park, T. Richardson, and
G. Tsirtsis. Toward Proximity-aware Internetworking. Wire-
less Communications, 2010.

[18] C. Diaz, S. Seys, J. Claessens, and B. Preneel. Towards

measuring anonymity. In PETS, 2002.

[19] D. Dolev and A. C. Yao. On the security of public key pro-

tocols. IEEE trans. on Information Theory, 1983.

Iranian opposition activists hanged for
http://www.bbc.co.uk/news/world-middle-

[20] B. M. East.

protest footage.
east-12272067, 2011.

[21] J. Ebersp¨acher, H.-J. V¨ogel, C. Bettstetter, and C. Hartmann.

GSM - Architecture, Protocols and Services. Wiley, 2008.

[22] M. Follman. “Bluetoothing” Iran’s revolution. Markfoll-

man.com, 2010.

[23] J. Freudiger, M. Jadliwala, J.-P. Hubaux, V. Niemi, P. Ginz-
boorg, and I. Aad. Privacy of community pseudonyms in
wireless peer-to-peer networks. Technical Report EPFL-
REPORT-170392, EPFL, Lausanne, Switzerland, 2011.

[24] J. Freudiger, M. Raya, M. Felegyhazi, P. Papadimitratos, and
J.-P. Hubaux. Mix zones for location privacy in vehicular
networks. In Win-ITS, 2007.

[25] J. Freudiger, R. Shokri, and J.-P. Hubaux. On the optimal

placement of mix zones. In PETS, 2009.

[26] J. Freudiger, R. Shokri, and J.-P. Hubaux. Evaluating the
privacy risk of location-based services. In Financial Cryp-
tography, 2011.

[27] S. Gaonkar, J. Li, R. R. Choudhury, L. P. Cox, and
A. Schmidt. Micro-blog: sharing and querying content
through mobile phones and social participation. In MobiSys,
2008.

[28] M. Gerlach and F. Guttler. Privacy in VANETs using chang-
ing pseudonyms - ideal and real. In IEEE VTC-Spring, 2007.
[29] P. Golle and K. Partridge. On the anonymity of home/work

location pairs. In Pervasive, 2009.

[30] M. Hachman. Peep Proposes Wireless P2P System. PC

Magazine, 2011.

[31] B. Hoh and M. Gruteser. Protecting location privacy through

path confusion. In SecureComm, 2005.

[32] B. Hoh, M. Gruteser, H. Xiong, and A. Alrabady. Preserving
privacy in GPS traces via uncertainty-aware path cloaking.
In ACM CCS, 2007.

[33] J. Hromkoviˇc. Algorithms for Hard Problems. Springer-

Verlag, 2004.

[34] L. Huang, K. Matsuura, H. Yamane, and K. Sezaki. Enhanc-
In IEEE

ing wireless location privacy using silent period.
WCNC, 2005.

[35] M. Humbert, M. H. Manshaei, J. Freudiger, and J.-P.
Hubaux. Tracking games in mobile networks. In GameSec,
2010.

[36] M. Jadliwala, I. Bilogrevic, and J.-P. Hubaux. Optimizing
mixing in pervasive networks: A graph-theoretic perspec-
tive. In ESORICS, 2011.

[37] M. Jadliwala, S. Zhong, S. Upadhyaya, C. Qiao, and J.-P.
Hubaux. Secure distance-based localization in the presence
IEEE Transactions on Mobile
of cheating beacon nodes.
Computing, 2010.

[38] C. Karlof, N. Sastry, and D. Wagner. Tinysec: a link layer
security architecture for wireless sensor networks. In Sen-
Sys, 2004.

[39] M. Khiabani. Metro-sexual. http://bit.ly/theranMetroSexual,

2009.

[40] N. Kiukkonen, J. Blom, O. Dousse, D. Gatica-Perez, and
J. Laurila. Towards rich mobile phone datasets: Lausanne
data collection campaign. In ICPS, 2010.

[41] M. Li, K. Sampigethaya, L. Huang, and R. Poovendran.
Swing & swap: user-centric approaches towards maximiz-
ing location privacy. In WPES, 2006.

[42] B. Palanisamy and L. Liu. Mobimix: Protecting location
privacy with mix zones over road networks. In ICDE, 2011.
Nokia instant community gets you social.
2010/05/25/nokia-instant-

[43] Rhiain.

http://conversations.nokia.com/
community-gets-you-social/.

[44] R. Shokri, G. Theodorakopoulos, G. Danezis, J.-P. Hubaux,
and J.-Y. Le Boudec. Quantifying location privacy: The case
of sporadic location exposure. In PETS, 2011.

[45] R. Shokri, G. Theodorakopoulos, J.-Y. Le Boudec, and J.-P.
Hubaux. Quantifying location privacy. In IEEE Security &
Privacy Symposium, 2011.

[46] M. Stiemerling and S. Kiesel. A system for peer-to-peer
video streaming in resource constrained mobile environ-
ments. In U-NET, 2009.

[47] Theodore S. Rappaport. Wireless Communications: Princi-
ples and Practice, 2nd Edition, chapter Mobile Radio Prop-
agation: Large-Scale Path Loss. Pearson Education, Inc.,
2003.

[48] B. Wiedersheim, Z. Ma, F. Kargl, and P. Papadimitratos. Pri-
vacy in Inter-Vehicular Networks: Why simple pseudonym
change is not enough. In IEEE/IFIP WONS, 2010.

[49] H. Yoon, J. Kim, F. Tan, and R. Hsieh. On-demand video
streaming in mobile opportunistic networks. In PERCOM,
2008.

[50] X. Zhang, H. Heys, and C. Li. An analysis of link layer
In ICC,

encryption schemes in wireless sensor networks.
2010.

Appendix

Table 5. Symbol Table.

Symbol Deﬁnition
m
t(m)
p(m)
π(m)
c
M
Q f
t f
Qc
tc
tsilent
Q
ˆm
ˆo( ˆm)
ˆs( ˆm)
r
˜e
ˆT
ˆO
˜r
˜m
S
P
v(s)
τ
u
µ
C

User’s actual message
Device time when the message m is sent
Device position when message m is sent
Device identiﬁer when message m is sent
Message content
Set of all actual messages (sent by all users)
Quota for forced identiﬁer changes
Forced timer
Quota for context-based identiﬁer changes
Context check timer
Radio silence period
Total identiﬁer-change quota
Copy of the m observed by the adversary
Adversary AP observing ˆm
Received signal strength of ˆm
Actual sequence of pseudonyms
Event constructed from observed messages
Set of time-stamps in the event
Set of observing APs in the event
Reconstructed sequence of pseudonyms
Message reconstructed from an event ˜e
State space
State transition function
Speed associated with the state s
Traceability metric
Uncertainty metric
Traceability-uncertainty metric
Clustering metric

