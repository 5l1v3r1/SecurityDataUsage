CARONTE: Detecting Location Leaks for
Deanonymizing Tor Hidden Services

Srdjan Matic

Universita degli Studi di Milano

Milan, Italy

srdjan.matic@unimi.it

platon.kotzias@imdea.org

juan.caballero@imdea.org

Platon Kotzias

IMDEA Software Institute

Madrid, Spain

Juan Caballero

IMDEA Software Institute

Madrid, Spain

ABSTRACT

Anonymity networks such as Tor are a critical privacy-enabling
technology. Tor’s hidden services provide both client and server
anonymity. They protect the location of the server hosting the ser-
vice and provide encryption at every hop from a client to the hid-
den service. This paper presents CARONTE, a tool to automatically
identify location leaks in hidden services, i.e., sensitive information
in the content served by the hidden service or its conﬁguration that
discloses the server’s IP address. Compared to prior techniques
that deanonymize hidden services CARONTE implements a novel
approach that does not rely on ﬂaws on the Tor protocol and as-
sumes an open-world, i.e., it does not require a short list of can-
didate servers known in advance. CARONTE visits the hidden ser-
vice, extracts Internet endpoints and looks up unique strings from
the hidden service’s content, and examines the hidden service’s cer-
tiﬁcate chain to extract candidate Internet endpoints where the hid-
den service could be hosted. Then, it validates those candidates by
connecting to them. We apply CARONTE to 1,974 hidden services,
fully recovering the IP address of 101 (5%) of them.

Categories and Subject Descriptors
C.2.0 [Computer-communication networks]: Security and pro-
tection; H.3.5 [Online Information Services]: Web-based services

General Terms
Security

Keywords
Tor hidden services; location leaks; deanonymization

1.

INTRODUCTION

The increasing surveillance of communications have made
anonymity networks a critical privacy-enabling technology.
Tor [21] is arguably the most popular anonymity network. It pro-
vides both sender anonymity and recipient anonymity for hidden
services. Hidden services protect the location (i.e., IP address) of
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-3832-5/15/10˙..$15.00
DOI: http://dx.doi.org/10.1145/2810103.2813667.

the server hosting the hidden service. In addition, they further pro-
tect against network-level eavesdropping by providing encryption
all the way from the client to the hidden service. This includes the
communication between the last Tor relay and the hidden service,
even when the application trafﬁc is not encrypted.

Deanonymizing the location of a hidden service, i.e., recover-
ing the IP address of the server hosting the hidden service, en-
ables taking down the hidden service, seizing its content, and pos-
sibly identifying the owners. Prior work has proposed attacks to
deanonymize Tor hidden services through ﬂaws on the Tor pro-
tocol [17, 40] and clock-skew ﬁngerprinting [36, 47]. Attacks on
the Tor protocol are promptly ﬁxed by the Tor project. For ex-
ample, the attack by Øverlier and Syverson [40] was ﬁxed by in-
troducing guard nodes and the more recent attack by Biryukov et
al. [17] has also been ﬁxed [16]. Attacks leveraging clock-skew
ﬁngerprinting assume a closed-world where a short list of possible
candidate servers is known and the ﬁngerprinting validates which
candidate is the hidden server. Deanonymization attacks have also
been proposed for the equivalent of hidden services in I2P (called
eepSites) [20]. These attacks also assume a closed-world, where
the IP addresses of I2P peers are candidate servers for eepSites.

This paper studies the problem of location leaks, i.e., informa-
tion in the content or conﬁguration of a hidden service that gives
away its location. Location leaks are introduced by the hidden ser-
vice administrators and cannot be centrally ﬁxed by the Tor project.
Deanonymizing hidden services through location leaks does not re-
quire the attacker to be part of the anonymity network, but only to
access the hidden services.

Such content and conﬁguration leaks are a well-known problem
for hidden services, but their extent is currently unknown. In fact,
some notorious takedowns of hidden services by law enforcement
have been linked to such leaks. For example, in July 2013, law
enforcement identiﬁed the location of the Silk Road marketplace,
where products such as cocaine, heroin, LSD, and counterfeit cur-
rencies were traded [19]. The FBI claimed in court that they lo-
cated the server of the original Silk Road through a leak of its IP
address when visiting the site [27]. The FBI story has been dis-
puted [27, 34], but researchers still believe it is likely that the take-
down was due to a leak in the server’s conﬁguration [27]. After the
Silk Road takedown other similar hidden services took its place.
In November 2014, an international law-enforcement operation co-
denamed Onymous, took down over 400 hidden services including
the Silk Road 2.0, Cloud 9, and Hydra drug markets [28]. The
deanonymization method used by law enforcement in Onymous re-
mains unknown [42]. Unfortunately, the same location leaks that
law enforcement may be using to deanonymize abusive hidden ser-
vices can also be used by oppressive governments to deanonymize
and censor hidden services of political activists.

1455In this paper we propose a novel approach to deanonymize hid-
den services using a subset of location leaks in an open-world,
i.e., without previous knowledge of a set of candidate servers.
Our approach includes two steps. First, we propose techniques
to extract candidate Internet endpoints (i.e., domains and IP ad-
dresses that may correspond to the hidden server) from the con-
tent and conﬁguration of a hidden service. Our techniques ex-
amine endpoints and unique identiﬁers in the content and the
HTTPS certiﬁcates. This step allows moving from an open-
world to a closed-world. Then we validate each candidate pair
(cid:104)hidden_service, Internet_endpoint(cid:105), checking if the Internet
endpoint corresponds to the Web server hosting the hidden service.
Previous work that leverages leaks on a server’s clock skew [36,47]
or software version [20] assume a closed-world and use the leaks
only for validation.
In contrast, our approach leverages location
leaks to obtain also the candidate servers.

We implement our approach in a tool called CARONTE, which
takes as input the URL of a hidden service and tries to deanonymize
it through location leaks. CARONTE could be used by law en-
forcement agencies to automate the currently manual process of
deanonymizing abusive hidden services, and also by political ac-
tivists running hidden services that risk being censored. CARONTE
checks a hidden service for a subset of content and conﬁguration
errors that can lead to deanonymization. CARONTE has no false
positives. If it recovers the hidden service’s IP address, it proves
the need to improve operational security. However, it only tests
for a subset of location leaks whose detection can be automated
and may fail to validate some leaks. Thus, it cannot guarantee the
hidden service is free of location leaks.

To test CARONTE’s effectiveness we have applied it to 1,974 live
HTTP and HTTPS hidden services, of which CARONTE recovers
the IP address of 101 (5%). Our results can be considered the ﬁrst
measurement study of location leaks in Tor hidden services. Since
CARONTE only tests for some types of location leaks and may fail
to validate some leaks its results are conservative, i.e., some ser-
vices not deanonymized could still be vulnerable.

Our results also show that 21% of the deanonymized services
are hosted on Tor relays. Hidden services on Tor relays can easily
be deanonymized, even in the absence of location leaks, assuming
a closed-world where relays’ IP addresses are candidate locations
for a hidden service. This result also highlights the importance
of assuming an open-world, as 79% of hidden services CARONTE
deanonymizes cannot be deanonymized under the closed-world as-
sumption. CARONTE also identiﬁes 9 hidden services that redirect
their users to Internet sites through HTTP, negating the beneﬁt of
encryption in the last hop.

This work makes the following contributions:
• We propose a novel approach to deanonymize hidden ser-
vices through location leaks. Our approach assumes an open-
world, i.e., no prior knowledge on candidate servers. To
move from an open-world to a closed-world we propose tech-
niques to identify candidate servers from the content and
conﬁguration of a hidden service.

• We implement our approach into CARONTE, a tool that
attempts to deanonymize the location of hidden services
through location leaks.

• Using CARONTE we perform the ﬁrst measurement study
on the prevalence of location leaks in hidden services.
CARONTE analyzes 1,974 input hidden services, recovering
the IP address of 101 (5%). It also uncovers that 21% of the
deanonymized hidden services are running on Tor relays.

The rest of this paper is structured as follows. Section 2 intro-
duces hidden services, location leaks, and our approach. Section 3
details the approach and CARONTE’s implementation. Section 4
presents the measurements. Section 5 discusses defenses against
location leaks and Section 6 ethical considerations. Section 7 de-
scribes related work and Section 8 concludes.

2. OVERVIEW & PROBLEM DEFINITION
In this Section we ﬁrst brieﬂy describe hidden services (Sec-
tion 2.1), then we detail the type of leaks that CARONTE looks for
(Section 2.2), and ﬁnally we provide an overview of our approach
(Section 2.3).
2.1 Hidden Services

The Tor network provides hidden services as a mechanism for
users to anonymously offer services accessible by other users
through Tor. Hidden services provide recipient anonymity, i.e., they
hide the IP address of the server hosting the hidden service. Hid-
den services can offer different functionality, e.g., Web services and
Bitcoin mining. This paper focuses on hidden Web services.

The creation of a hidden service picks a public key and a se-
cret key and creates an onion identiﬁer by doing a SHA1 hash
of the public key truncated to 80 bits. The onion identiﬁer is
encoded in base32 producing a 16 character string, which is ap-
pended the sufﬁx “.onion” to produce an onion address, e.g.,
niazgxevgzlrbpvq.onion1. Some hidden services gener-
ate large numbers of onion addresses until they ﬁnd one contain-
ing a desired substring. For example, Facebook’s ofﬁcial hidden
service has onion address facebookcorewwwi.onion. For
Web services, hidden services are advertised as onion URLs, where
the DNS domain is replaced by an onion address, e.g., http:
//niazgxevgzlrbpvq.onion/content.html. The dis-
tribution of onion URLs happens out-of-band: there is no a central
repository that lists all the hidden Web services available in a given
moment and thus users can access only those for which they know
an onion URL.
Rendezvous protocol. The hidden service chooses a set of 3 Tor
relays as introduction points and creates circuits (i.e., encrypted
tunnels) to each of them. The hidden service then produces a signed
descriptor that lists the service’s public key and its introduction
points. The descriptor is published in a distributed hash table on
the Tor relays using as index the onion identiﬁer and time period.
To use a hidden service a Tor client establishes a circuit to a
Tor relay randomly chosen as rendezvous point. Then, it retrieves
the hidden service’s descriptor using the onion identiﬁer and cur-
rent time. Next, it creates another circuit to one of the introduc-
tion points, and communicates the rendezvous point to the hidden
service through it. The hidden service creates a circuit to the ren-
dezvous point and communication between client and hidden ser-
vice happens over their respective circuits to the rendezvous point.
With hidden services all hops between client and hidden service
are encrypted, compared to visiting an Internet domain through
Tor where communication between last Tor relay and the service is
not encrypted, unless the application layer is encrypted (e.g., with
HTTPS).
2.2 Location Leaks

Hidden services hide the location of the server hosting them, but
they do not protect against administrators unintentionally leaking
information in the content or conﬁguration of their hidden services

1Fake onion address for illustration.

1456Using a leak in the content or conﬁguration of a hidden ser-
vice to deanonymize their administrators or its location involves
two steps. First, ﬁnd some candidate identity (e.g., the owner of
a phone number embedded in the hidden services content) or can-
didate Internet endpoint (e.g., an IP address or DNS domain in an
error page). Then, validate that the candidate identity truly cor-
responds to the administrators or the candidate Internet endpoint
to the IP address. In this work we focus exclusively on location
leaks that provide candidate Internet endpoints for the IP address of
the hidden service, by simply visiting the hidden service, without
adding any nodes to the Tor network or compromising the hidden
service. Identity leaks as well as leaks that an attacker can induce
by exploiting the hidden service’s code (e.g., SQL injections) are
considered out of scope.

We do not focus on location leaks because they are more impor-
tant, but rather because we know a way to automatically validate
candidate Internet endpoints to conﬁrm that they are hosting the
hidden service. Validation of identity leaks is better suited for man-
ual police work than for an automated tool. Of course, deanonymiz-
ing the location of a hidden service may be a ﬁrst step towards
deanonymizing its owner’s identity, e.g., by checking server reg-
istration records or monitoring accesses to the server. Note that
location leaks are a problem for any type of anonymous services.
While we focus on Tor hidden services, our approach is indepen-
dent of Tor and can be applied to deanonymize the equivalent of
hidden services in other anonymity networks, e.g., I2P eepSites [9].
There exist many different types of location leaks that can lead
to deanonymizing the hidden server’s location. CARONTE auto-
matically identiﬁes 3 types of location leaks due to endpoints (i.e.,
IP addresses, domains) and unique strings (i.e., Google Analytics
ID, Google AdSense ID, Bitcoin wallets, page titles) embedded in
the content of the hidden service, and the HTTPS certiﬁcate of the
hidden service. Obviously, many other types of location leaks may
exist and thus CARONTE may not ﬁnd all location leaks.
Validating location leaks. Our candidate selection techniques out-
put candidate pairs (cid:104) onion_address, Internet_endpoint (cid:105), where the
Internet endpoint is a DNS domain or IP address that may host the
hidden server of the onion address. If the candidate pair contains
an IP address, validation connects to the IP address through the In-
ternet but requests the content of the hidden service, i.e., sets the
HTTP Host header to the onion address. If the Web server delivers
the hidden service’s content, it conﬁrms that the hidden service is
hosted on the candidate IP address. Note that the Tor network is an
overlay of the Internet. Thus, hidden Web services are hosted on a
Web server with a public IP address. The (hidden) Web server will
reply to a request from the Internet to its public IP address unless
a ﬁrewall allows only connections from certain IP addresses. Even
when a ﬁrewall is used, the ﬁrewall will often be conﬁgured to al-
low connections through Tor (i.e., from Tor relays), in which case
we can run validation through Tor (or from a Tor relay).

that may lead to deanonymizing them (identity leaks) or the IP ad-
dress of the hidden server (location leaks). The Tor project de-
scribes the risks of content and conﬁguration leaks [11] but it is
not clear to what extent hidden services administrators are taking
precautions against them and how prevalent they are.

When the candidate pair contains a DNS domain, validation
works the same by ﬁrst resolving the domain to an IP address. The
main reason why an Internet domain may resolve to the public IP
address of the hidden Web server is when the domain identiﬁes
an Internet service hosted on the same Web server as the hidden
service. Thus, if the hidden service runs on its own Web server
CARONTE will probably fail to validate a candidate domain, even
if the candidate domain belongs to the hidden service owners. For

example, CARONTE could identify from the content of the hidden
service an Internet site owned by the hidden service’s owners, but
hosted on a separate Web server. While CARONTE cannot validate
that location leak, network-level attackers could monitor connec-
tions to the Internet site in hopes that the hidden service owners
relax protections when accessing it. For that reason, CARONTE
still outputs the candidate domains it found even if they are not
validated, so that the hidden service administrator can check them.
In summary, CARONTE produces no false positives. If it outputs
a leak, the deanonymization has been validated. On the other hand,
CARONTE may have false negatives due to unsupported classes of
leaks and leaks it cannot validate. We discuss how to safely conﬁg-
ure hidden services in Section 5.
Unintentional leaks. Hidden services often contain sensitive con-
tent and need to protect their location to avoid censorship or legal
prosecution. However, not all hidden services are like that. Some
hidden services advertise an Internet clone, i.e., an Internet site that
provides the same content, and explicitly link to it, e.g., Facebook.
Similarly, an Internet site may explicitly link to its hidden service
clone, indicating its availability to privacy-concerned users. In Sec-
tion 4 we describe 3 automatic checks that CARONTE performs
to classify location leaks leading to deanonymizations as uninten-
tional or not.
2.3 Approach Overview

Figure 1 summarizes our approach.

It comprises three main
steps: exploration, candidate selection, and validation. Explo-
ration takes as input a set of initial onion URLs (Section 3.1), cre-
ates an extended set of onion URLs and visits them through HTTP
and HTTPS to collect the content of the hidden service and its cer-
tiﬁcate chain (Section 3.2). All the information of the exploration
is stored in a central database.
Candidate selection takes as input the information in the database
and outputs a list of candidate pairs (cid:104) onion_address,
Inter-
net_endpoint (cid:105), where the Internet endpoint is a DNS domain or
IP address considered a candidate to be hosting the hidden server
of the onion address (Section 3.3). To select candidates, it exam-
ines the endpoints (i.e., URLs, email domains, IP addresses) and
unique strings (i.e., Google Analytics ID, Google AdSense ID, Bit-
coin wallets, page titles) in the onion pages collected from the
hidden service, as well as its HTTPS certiﬁcate.
It searches the
unique strings on Internet search engines to ﬁnd if they are em-
bedded in the content of Internet sites and queries certiﬁcate stores
(i.e., Sonar [6]) to ﬁnd Internet sites using the same certiﬁcates as
the hidden service.

Validation takes as input the candidate pairs and veriﬁes if a
candidate Internet endpoint indeed hosts the hidden service (Sec-
tion 3.4). It visits the Internet endpoints to collect their content and
certiﬁcates. Then, it compares pairs of HTTP responses: one from
the candidate Internet endpoint and the other from the hidden ser-
vice. If it ﬁnds a pair with similar content and served from a similar
Web server it outputs a location leak.
3. APPROACH
3.1 Collecting Onion URLs

CARONTE takes as input a list of onion URLs corresponding to
a hidden service to deanonymize. These may be provided by an
administrator that wants to check its hidden service or come from
external means. However, for evaluating CARONTE we need to
collect onion URLs for a large number of hidden services.

Obtaining onion URLs is a challenging process because there is
no centralized repository and valid onion addresses are difﬁcult to

1457Figure 1: Approach overview.

predict being a SHA1 hash of the hidden service’s key truncated to
80-bit. Owners of hidden services obtain their onion address dur-
ing installation and are in charge of advertising their onion URLs.
Given the nature of some hidden services, their onion URLs may
not be publicly advertised, but only disclosed in private forums. In
addition, many hidden services do not link to other hidden services,
which limits crawling. Furthermore, onion addresses exhibit high
churn, as the same hidden service may change onion addresses over
time. In 2013, Biryukov et al. [17] presented a technique to list all
onion addresses leveraging a ﬂaw in Tor. However, that ﬂaw was
ﬁxed after version 0.2.4.10-alpha [16].

As a consequence of these challenges, many sites exist that list
onion URLs of hidden services with a description of their content
such as “Deepweb links” [2] and “The Hidden Wiki” [4]. There
are also specialized search engines for hidden services, typically
accessible both from the Internet and through a hidden service [3,
10]. In addition, many onion addresses can be found by querying
Web search engines such as Google and Bing.

We have developed scripts that periodically visit the above re-
sources, scrape their links, perform searches on common terms,
and feed the identiﬁed onion URLs to CARONTE.
In addition,
as CARONTE explores the hidden services, it adds any new onion
URLs found in their content to the list, so that they are visited in the
next round of exploration. Overall, CARONTE explores 15 K onion
URLs on 6 K onion addresses. On February 2013, Biryukov et al.
obtained a complete listing of hidden services and scanned them for
open ports [16]. They found 3,741 HTTP hidden services listening
on 80/tcp, while CARONTE ﬁnds 1,965. Assuming the number of
HTTP hidden services has remained relatively constant since then,
our sample would cover 52% of them, with popular hidden services
being better represented.

3.2 Exploring Hidden Services

Given the initial list of onion URLs, CARONTE ﬁrst creates an
extended set of onion URLs that includes for each onion address:
the root page, all resources for that onion address in the initial set,
and one random resource. The random resource is added to trigger
a not found error page, which may leak conﬁguration information
speciﬁc to the hidden server.

The exploration visits each onion URL in the extended set
through Tor eight times: using HTTP and HTTPS, two Host header
values (i.e., the onion address and a random onion address), and re-
questing the resource identiﬁed during the collection and a random
one. The intuition behind using a random onion address is that the
hidden service’s Web server may also host other sites. If the hidden
service is not the default site, the Web server may return the de-

Method
Endpoints

Identiﬁers

Titles

Certiﬁcates

Description
Extract IP addresses, Internet domains in email
addresses, and Internet domains in URLs embed-
ded in onion pages.
Use search engines to locate Internet domains
embedding Google Analytics, Google AdSense,
and Bitcoin wallet identiﬁers found in onion
pages.
Use search engines to locate Internet domains
with similar title as onion page.
(1) Extract DNS domains and IP addresses from
leaf certiﬁcate of hidden service. (2) Search leaf
certiﬁcate of hidden service in Sonar [6] to obtain
IP addresses where observed.
(3) Search pub-
lic key of hidden service certiﬁcate in Sonar to
obtain IP addresses where observed. (4) Search
Sonar for certiﬁcates on the Internet with onion
addresses and the IP addresses where observed.

Table 1: Description of candidate endpoints.

fault site to the random onion address, and that site may leak some
candidate Internet endpoints.

For each request, the exploration collects the response, pre-
processes it, and stores both request and response in a database.
We limit CARONTE to download only textual and HTML responses
(i.e., onion pages) to avoid storing copyrighted software and offen-
sive multimedia content (e.g., explicit videos and pictures). This
restriction means that CARONTE cannot identify leaks in other con-
tent types, e.g., EXIF data in images, although we do not expect
they contain many candidate endpoints. For HTTPS, it also stores
the certiﬁcate chain provided by the hidden server. The exploration
is multi-process and runs from a single host; furthermore this step
is rerun over time as new onion URLs are collected.
3.3 Identifying Candidate Endpoints

After the exploration ﬁnishes one round, the next step is to ex-
tract for each onion address a list of candidate Internet endpoints,
i.e., DNS domains and IP addresses, which may point to the hidden
server. For this, CARONTE examines the endpoints (Section 3.3.1)
and unique strings (Section 3.3.2) contained in the onion pages col-
lected through Tor, as well as the HTTPS certiﬁcate of the hidden
server (Section 3.3.3). Table 1 summarizes the methods used to
obtain candidate endpoints that are detailed in this section.

The input to this step is the information from the exploration
stored in the database. This step does not require interacting with

Onion URLsDBCandidate PairsLocationLeaksSonar DataSearch EnginesINTERNET2. Candidate SelectionCertiﬁcatesIdentiﬁersPage TitlesEndpoints1. Tor ExplorationOnion UrlexpansionFetch OnionPage3. ValidationInternetExplorationResponseSimilarity1458the hidden service, but it interacts with some public Internet Web
services. The output is a list of candidate pairs (cid:104)onion_address,
Internet_endpoint(cid:105) where each pair indicates that the hidden ser-
vice at the onion address could be hosted at the Internet endpoint.
The same onion address may appear in multiple candidate pairs
with different Internet endpoints.
3.3.1 Internet Endpoints in Onion Pages
Internet endpoints contained in the onion pages of a hidden ser-
vice are good candidates for the hidden server. While we expect
hidden service administrators to be careful about Internet URLs
they link to, there exist several cases in which such leaks can hap-
pen, e.g., links or email addresses pointing to other sites of unre-
lated content but hosted on the same Web server, IP addresses and
domains leaked in error pages, and endpoints in comments not vis-
ible and possibly forgotten.

For each onion page in the database, CARONTE applies regular
expressions to extract URLs, email addresses, and IP addresses in
the page. If an extracted URL contains an onion address, it is dis-
carded since we are interested in Internet endpoints, but the onion
URL is added to the database if previously unknown. If the URL
contains a DNS domain, the domain is checked against the Alexa
list of one million most popular domains. Alexa domains are dis-
carded since very popular domains do not typically have a hidden
service or publicly advertise it when they do (e.g., Facebook). Non-
Alexa domains are added to the list of candidate Internet endpoints
for the onion address of the page examined. For email addresses,
if the email domain is in a list of popular email providers, it is dis-
carded, otherwise it is a candidate.

IP addresses in the onion page are added as candidates, except
when the onion page contains more than 5 IP addresses. In that
case, all IP addresses in the page are discarded to prevent large
directories of IP addresses unrelated to the hidden server (e.g., lists
of Tor relay nodes) to be added as candidates.
3.3.2 Unique Strings in Onion Pages
A general technique to identify candidate Internet endpoints is
to ﬁrst extract some distinctive string from the content of the onion
pages of the hidden service and then look up those strings in Inter-
net search engines. Search engines will return Internet sites where
they have observed those strings, and their DNS domains can be
used as candidate Internet endpoints. This technique can be ap-
plied to any unique string that appears in the content of a hidden
service. The more unique the string is, i.e., the less it appears in
unrelated hidden and Internet services, the better the candidates
produced. In any case, candidate pairs from non-unique strings are
removed during validation. So far, we have added support for two
classes of such unique strings: identiﬁers and page titles. We de-
tail them below and leave as future work applying this technique to
other classes of unique strings in the onion pages.
Identiﬁers. Onion pages may contain identiﬁers unique to the own-
ers of the hidden service. CARONTE queries dedicated search en-
gines to ﬁnd Internet sites that also contain those identiﬁers. Such
Internet sites likely belong to the owners of the hidden service and
are good candidates for being hosted on the same Web server as the
hidden server. Even when they are not, such leaks are dangerous, as
those other Internet sites can be monitored by an adversary. If the
owners of the hidden service connect to those other Internet sites
they own (e.g., to conﬁgure them or change their content) without
precautions (e.g., without a VPN) their identity could be revealed.
For each onion page, CARONTE applies regular expressions to
extract Google Analytics and Google AdSense identiﬁers, as well
as Bitcoin wallets. Google Analytics identiﬁers are unique to a

Google Analytics account and are often embedded in pages to col-
lect statistics. Google AdSense identiﬁers are less frequently in-
cluded in pages but are unique for a publisher’s account. Bitcoin
wallets are often added to ask for donations. An onion page could
add the Bitcoin wallet of some other user to encourage donations
to that user’s site and could even spoof the Google Analytics iden-
tiﬁer of an unrelated account. This is not an issue, as unrelated
candidates will be discarded during validation.

For each unique identiﬁer extracted from at least one onion
page, CARONTE queries dedicated identiﬁer search engines that
index Internet pages where identiﬁers have been observed (e.g.,
SameID [7]). DNS domains where the identiﬁer has been observed
are added as candidates for the onion addresses of the onion pages
from where the identiﬁer was extracted.
Titles. Page titles are often speciﬁc to the content of a page. Thus,
they can also be used as distinctive strings to be looked up in In-
ternet search engines. To reduce the number of queries to search
engines, CARONTE ﬁrst removes any title served by more than 10
hidden services, which removes generic titles such as those of de-
fault error pages. Each unique title is then queried on a search
engine. DNS domains of the top 10 Internet sites where the title
has been observed are added as candidates for the onion address of
the onion page with that title.

3.3.3 HTTPS Certiﬁcates
CARONTE uses four methods to select candidate pairs from the
collected leaf certiﬁcate of each HTTPS hidden service. The ﬁrst
method is to extract from the hidden service’s certiﬁcate the Sub-
ject’s Common Name (CN) and the Subject Alternative Name
(SAN) extension. DNS domains and IP addresses in those ﬁelds
are added as candidates for any onion address that provided that
certiﬁcate. The intuition is that Web servers hosting multiple sites
oftentimes reuse the same leaf certiﬁcate for all sites. While it is
possible to conﬁgure separate certiﬁcate chains for each site this
relies on the client sending the SNI header. Thus, hidden services’
certiﬁcates may contain the domains or IP addresses of other Inter-
net sites hosted on the same Web server.

Even if the certiﬁcate of a hidden service does not contain any In-
ternet endpoints, a leak may happen if that certiﬁcate (or its public
key) is also used by an Internet site on the same Web server. The
other 3 methods leverage recently created certiﬁcate repositories
that store information about certiﬁcates that have been observed in
Internet trafﬁc (passively, by crawling, or by scanning the Inter-
net). These include Rapid7’s Sonar project [6], ICSI’s Certiﬁcate
Notary [8], and Google’s Certiﬁcate Transparency [1]. ICSI’s no-
tary does not provide the IP addresses that served a certiﬁcate and
Certiﬁcate Transparency only allows querying for extended valida-
tion (EV) certiﬁcates. CARONTE uses Sonar, which contains 35 M
unique certiﬁcates obtained by periodically scanning the Internet.
The second method computes the SHA1 hash of the DER for-
mat of the hidden service’s certiﬁcate. Then, it uses the hash to
search in Sonar whether this certiﬁcate has been served by any In-
ternet site. If so, the IP addresses from where the certiﬁcate was
served are added as candidates for the onion addresses from where
CARONTE collected the certiﬁcate. Interestingly, some researchers
have recently hypothesized that the Silk Road takedown could have
been done by correlating the Silk Road’s HTTPS certiﬁcate with an
Internet HTTPS scan as we do [27].

The third method extracts the public key of the hidden service’s
certiﬁcate and searches in Sonar for certiﬁcates served by Internet
sites that use the same public key. Public keys are left unchanged
in many certiﬁcate replacements [39]. Thus, it could happen that

1459Sonar observed an older certiﬁcate with the same public key in the
same IP address still hosting the hidden service.

The fourth method searches in Sonar for any certiﬁcate whose
Subject’s CN or SAN extension contains an onion address. Intu-
itively, a certiﬁcate that contains an onion address but is observed
on the Internet likely corresponds to a Web server that hosts both
hidden services and Internet sites. This is a wide search for any cer-
tiﬁcate with an onion address, even if the certiﬁcate was not seen
during exploration. This method is unlikely to deanonymize a spe-
ciﬁc target hidden service, but is included for completeness of the
measurement study. The onion address and each IP address that
served the certiﬁcate form a candidate pair. If the onion address
was previously unknown, it is queued for exploration.
3.4 Validation
(cid:104)onion_address,
list
Internet_endpoint(cid:105) validation ﬁrst resolves the candidate do-
main endpoints to candidate IP addresses. For each candidate pair,
it sends eight HTTP requests to the candidate IP address through
the Internet. It fetches both the root page and a random resource
using HTTP and HTTPS. In addition, it uses two different values
of the Host header: the Internet endpoint (domain or IP) and the
onion address. The responses and certiﬁcate chains are stored in
the database. Then, CARONTE computes the distance between
pairs of responses, where one response comes from the Internet
endpoint and the other was received through Tor from the hidden
service. We detail this distance in Section 3.4.1. If it ﬁnds a pair of
similar, non-generic, responses the leak is conﬁrmed.

candidate

Given

pairs

the

of

If the candidate endpoint corresponds to a site on the same Web
server as the hidden service, that site can serve similar content as
the hidden service or a completely unrelated site. If the candidate
site is similar, when providing the candidate endpoint in the Host
header, the similarity with the hidden service content will mani-
fest. If the sites are different, when provided with the onion ad-
dress in the Host header the Web server will serve back the hidden
service content through the Internet, and the similarity will mani-
fest. The Web server may be conﬁgured to serve the hidden service
only through Tor, which prevents validation through the Internet.
However, validation can also contact the Internet candidate end-
point through Tor, which would bypass this protection. Validation
could also be performed using the clock-skew ﬁngerprinting tech-
nique from Murdoch [36]. We leave these as future work.

The rest of this section describes the HTTP response similarity
metric (Section 3.4.1), classifying leaks as intentional or uninten-
tional (Section 3.4.2), and clustering conﬁrmed leaks on the same
servers (Section 3.4.3).

3.4.1 HTTP Response Similarity
Our HTTP response similarity metric takes as input two HTTP
responses (one from the hidden service, the other from the candi-
date Internet endpoint) and outputs one if both responses have sim-
ilar content and come from a similar server, zero otherwise. When
the output is one, the candidate pair is ﬂagged as a location leak.

One challenge is that the similarity should ignore generic pages,
e.g., “It works” pages and default error pages, which do not indicate
a leak even if observed in both responses. Another challenge is that
the similarity needs to handle dynamic content, which may make
two equivalent responses be different.

CARONTE uses a simple, yet effective, blacklisting mechanism
to identify generic pages. To populate the blacklist, it hashes the
body of every page in the database. Hashes that were retrieved from
at least 5 different DNS domains or were associated to at least 5
status codes are added to the blacklist. When computing similarity,

Figure 2: HTTP response similarity algorithm

if any of the two responses has a body whose hash is in the blacklist,
the similarity is considered zero and no leak is ﬂagged.

The similarity metric uses 7 features. For each response, it com-
putes the hash of the body and extracts the values of the E-Tag,
Last-Modiﬁed, Content-Length, Server, and X-Powered-By head-
ers. In addition, it computes the similarity of the two HTML doc-
uments using an off-the-shelf package [30], which compares the
HTML tag structure of the documents, but not the tag contents.
The HTML similarity is high even if both documents contain dif-
ferent dynamic content, as long as the structure of the HTML has
not changed signiﬁcantly.

The similarity metric computation is summarized in Figure 2.
First, it determines if the content is served from similar servers.
For this, it checks whether the Server and X-Powered-By header
values are identical. If either the Server or X-Powered-By head-
ers are missing in both responses it considers them identical.
If
those headers are not identical, it considers the responses different
(i.e., outputs zero). Then, it determines that the body of both pages
are similar if: they have the same hash and the hash is not in the
blacklist, or if they have the same E-Tag value, or the same Last-
Modiﬁed value, or if both pages are larger than 1 KB and their
HTML similarity is greater than 0.75. This threshold allows for
small changes in the HTML structure of the pages because the two
pages may have been collected at different points in time.

3.4.2 Determining Leak Intention
Next, our approach determines if the leaks are unintentional or
not. Clearly we cannot know for sure whether the leak was uninten-
tional, but there exist some indications that the hidden service own-

HTTP RESPONSESSame Body HashPage_Size >1KBandHTML Sim. >0.75Same E-TagValue Same Last-ModiﬁedValue SameServer HeadersSameX-Powered-ByHeadersYesNoBody SimilarityServer SimilarityNoNoYesNoNoYesYes00No01GenericBodyHashYesNo1Yes1Yes1460Onion URLs
Onion addr.

All
31,849
6,426

Live HTTP HTTPS
177
4,794
1,974
79

4,617
1,965

Table 2: Onion URLs and addresses in our collection (all), those
returning content (live), and their split by protocol.

Type
URLs
Domains
IPs
TOTAL

Endpoints

6,207
182
73

(11,207)
(231)
(22,182)

Onion Addr. Cand.
4,372
916
172
249
102
75
4,704

(2,301)
(269)
(89)

Table 3: Endpoints extracted from onion pages.

ers may not be trying to protect their service’s location. CARONTE
uses 3 automatic checks to classify a leak as intentional.

First, it compares the onion address and the Internet endpoint.
If their longest common substring is larger or equal to 4 charac-
ters, they are considered similar. Since the onion address comes
from a truncated hash, an onion address with a common substring
with an Internet domain indicates brute-forcing on the onion ad-
dress generation (e.g. facebookcorewwwi.onion and www.
facebook.com).

Second,

if the Internet site contains the onion address of
the hidden service, the leak is also intentional. For example,
the Internet site could advertise: “Hidden service available at
niazgxevgzlrbpvq.onion”. This check is only applied to
connections where we do not spoof the Host header to prevent er-
rors from servers that echo back the domain provided.

Third, it compares the Internet endpoint with the title of the
onion page where the leak was validated. If the title of the page
retrieved from the hidden service is embedding the Internet end-
point, likely the owner of the service is intentionally reminding
users that the hidden service is also reachable through the Internet.
This check is not applied to connections where CARONTE spoofs
the Host header.

If none of these 3 conditions is satisﬁed, CARONTE considers the

leak unintentional.
3.4.3 Clustering Leaks
A leak comprises of an onion address and an Internet endpoint
(DNS domain or IP address). Multiple leaks may correspond to
the same hidden service, e.g., a hidden service may change onion
address over time or multiple DNS domains may match an onion
address. To simplify the analysis of leaks, CARONTE clusters them
based on their onion address, endpoint, and IP addresses.
First, for each leak with a domain endpoint, CARONTE resolves
the domain and outputs a tuple (cid:104)onion_addr, endpoint, IP(cid:105) for each
IP address the domain resolves to. A similar tuple is created for IP
endpoints. The clustering uses a distance function that given two
tuples returns zero if the onion address, the IP address or the effec-
tive second-level domain (ESLD) are the same, otherwise it returns
one. The ESLD of a domain is the SLD unless the SLD enables
third parties to obtain a subdomain, in which case it is the 3LD. For
example, for www.google.com the ESLD is google.com, and
for books.amazon.co.uk it is amazon.co.uk. To obtain a
domain’s ESLD CARONTE uses Mozilla’s Public Sufﬁx List [5].

The clustering starts with zero clusters and iterates on the list of
tuples. For each tuple, if the distance is zero to any tuple already
in a cluster it adds the tuple to the cluster. If the distance is zero
to tuples in different clusters, it merges those clusters and adds the
tuple to the merged cluster. Otherwise, it creates a new cluster for
the tuple.

4. EVALUATION

This section details the evaluation of CARONTE:

the datasets
used (Section 4.1), the selection of candidate pairs (Section 4.2)
and the validation of the candidate pairs (Section 4.3).

4.1 Datasets

Table 2 summarizes the collection and exploration of onion
URLs. It shows the number of onion URLs and addresses initially
collected from search engines and indices (All), the total number of
onion URLs that returned some content (Live), and the split by pro-
tocol. Overall, CARONTE explored 31,849 onion URLs from 6,426
onion address. Only 31% of the onion addresses were alive, which
may be due to non-HTTP(S) services, short-lived hidden services,
and hidden services that change onion address over time. Only
4% of the live onion addresses offered HTTPS, which may be due
to the communication with hidden services being encrypted in all
hops and the difﬁculty of having a CA sign a certiﬁcate for an onion
address. The exploration took place in 4 rounds, each round lasting
three days on average.
Sonar data. The Sonar project [6] offers data from 68 Internet-
wide scans performed between October 2013 and February 2015.
Each scan has 3 ﬁles. The certs ﬁle (average size of 448MB per
scan) has one row for each certiﬁcate with its SHA1 hash in DER
format and the certiﬁcate in base64 encoding. Each row in the
names ﬁle (30 MB) contains the certiﬁcate hash and the Subject’s
CN. The hosts ﬁle (2 GB) contains in each row the certiﬁcate hash
and an IP address from where the certiﬁcate was collected. Over-
all, the Sonar data comprises 205 GB and contains 35 M distinct
certiﬁcates.
4.2 Candidate Pairs

This section describes the candidate pairs extracted from the end-

points, identiﬁers, and certiﬁcates.
Endpoints. Table 3 summarizes the endpoints extracted from the
onion pages collected during exploration. For each type of end-
point, it shows the number of distinct endpoints after ﬁltering (be-
fore ﬁltering in brackets), the number of onion addresses with at
least one endpoint after ﬁltering (before ﬁltering in brackets), and
the number of candidate pairs obtained from that type of endpoint.
The numbers show that the ﬁltering of non-Alexa domains and
pages with more than 5 IP addresses removes 81% of the endpoints,
most of those being IP addresses from Tor relay status pages. After
ﬁltering, the median contribution of each onion address is: 2 URLs,
1 domain from email addresses and 1 IP address. CARONTE pro-
duces 4,704 candidate pairs from endpoints: 93% from URLs, 5%
from email domains, and 2% from IP addresses.
Identiﬁers. Table 4 summarizes the identiﬁers extracted from the
onion pages collected during exploration. For each type of iden-
tiﬁer, it shows the number of distinct IDs, the number of onion
addresses and URLs containing at least one identiﬁer of that type,
and the number of candidate pairs obtained from these identiﬁers
by searching on Internet search engines. CARONTE extracted 58
unique identiﬁers: 24 Google Analytics IDs, 3 Google AdSense
IDs, and 31 Bitcoin wallets. Only 66 hidden services (3.3%) con-
tained an identiﬁer, indicating that most administrators are careful
to avoid them. After querying the 58 identiﬁers on search engines,
CARONTE found candidate Internet endpoints for 32 (64%), for a
total of 192 candidate pairs.

1461Identiﬁer
Google Analytics
Google AdSense
Bitcoin
TOTAL

Onion

IDs Addr. URLs
24
52
3
3
36
31
58
90

33
3
31
66

Cand.
Pairs
146
24
22
192

Table 4: Identiﬁers extracted from the onion pages.

Method
Method 1
Method 2
Method 3
Method 4
TOTAL

Candidates

Pairs Onion Addr.
29
30
9
30
63

81
188
20
97
366

IPs Dom.
81
0
0
60
141

0
188
20
37
225

Table 5: Candidates pairs from certiﬁcates.

Titles. After ﬁltering titles in onion pages that appear in more than
10 hidden services CARONTE identiﬁes 583 distinct titles. Looking
up these titles on a search engine returns hits for 183 titles. From
those hits, CARONTE produces 200 candidate pairs.
Certiﬁcates. Of the 79 onion addresses with port 443/tcp open, 50
provided a certiﬁcate chain. CARONTE uses 4 methods to obtain
candidate pairs from HTTPS certiﬁcates, which are summarized
in Table 5. The table shows the number of candidate pairs, and
the number of distinct onion addresses, IP addresses, and DNS do-
mains in those pairs. CARONTE produces a total of 366 candidate
pairs from certiﬁcates. Next, we detail the results for each method.
First, CARONTE extracts DNS domains and IP addresses from
the Subject’s CN and SAN extension from each leaf certiﬁcate col-
lected during exploration. Of the 50 leaf certiﬁcates, 11 (22%) con-
tain only onion addresses, 3 (6%) contain both Internet endpoints
and onion addresses, 26 (52%) contain only Internet endpoints, and
10 (20%) contain no Internet endpoint or onion address. The 3
certiﬁcates with both onion and Internet endpoints are likely do-
ing this on purpose. However, 52% of the HTTPS hidden services
are leaking endpoints in their certiﬁcate. This method produces 81
candidate pairs for 29 onion addresses (2.8 candidate endpoints per
onion address).

Second, CARONTE searches the hash of the 50 leaf certiﬁcates
in Sonar. It ﬁnds 30 of them, so at least 60% of the HTTPS hidden
services are using the same certiﬁcate that an Internet Web server
does. Of those 30, 26 were identiﬁed by the previous method. This
method identiﬁes 4 certiﬁcates that were not leaking an Internet
endpoint but can still be found on Internet Web servers. Of those
4, 3 contain no Internet endpoints or onion addresses and the other
one an onion address only. For each of the 30 certiﬁcates, Sonar
provides one or more IP addresses from where the certiﬁcates were
collected for a total of 188 candidate pairs.

Third, CARONTE searches the public keys of the 50 leaf cer-
tiﬁcates in Sonar. This method ﬁnds 9 new certiﬁcates that share
their public key with one of the 50 leaf certiﬁcates. Those 9 cer-
tiﬁcates are observed being distributed from 20 IPs, of which 5 are
not known from the previous methods.

Fourth, CARONTE searches Sonar for certiﬁcates that contain an
onion address in their Subject CN or SAN extension. It ﬁnds 30
previously unknown certiﬁcates (i.e., not observed during explo-
ration), each with one onion address. Some of those are additional
Facebook certiﬁcates, which are excluded because they generate
many useless candidate pairs. The IP addresses from where the
remaining certiﬁcates were observed produce 97 candidate pairs.
Total. The left side of Table 6 summarizes the candidate pairs per
method. In summary, CARONTE produced 5,462 candidate pairs:
86% from endpoints, 3% from identiﬁers, 4% from titles, and 7%
from certiﬁcates.
4.3 Validation

Of the 5,462 candidate pairs, 303 (5.8%) successfully validated.
Of those 303 pairs, 88 had an IP address as Internet endpoint and
215 a domain name. Those 303 pairs contained 100 unique onion

addresses, 87 IP addresses, and 163 domains. One of the onion
addresses offered two different hidden services, one through HTTP
and the other through HTTPS. Thus, 101 hidden services were suc-
cessfully deanonymized by CARONTE. Next, we classify leaks as
intentional or not.
Intentional leaks. CARONTE automatically labels as intentional
those leaks that match any of the 3 rules described in Section 3.4.2.
Overall, 49% deanonymized hidden services are considered to be
leaking their location intentionally. For these, the hidden service
has an Internet site counterpart that serves similar content and runs
on the same Web server, and there are references from the onion
site to the Internet site and/or viceversa, e.g., the onion address ap-
pearing in the Internet site or the title of the onion site being similar
to the domain of the Internet site. This result indicates that almost
half of the hidden services CARONTE deanonymized may not be
trying to protect the hidden server’s location. This may be due to a
selection bias in our collection towards the most advertised hidden
services. One beneﬁt to these Internet sites of having a hidden ser-
vice is that users of the hidden service have their communication
encrypted at all hops from the client to the hidden service. Fur-
thermore, since the onion address is derived from the public key
through a hash, the public key is self-authenticating, which helps
preventing man-in-the-middle attacks.
Unintentional leaks. We manually analyze 15 of the unintentional
leaks. They correspond to 4 cases. First, 5 hidden services run on
a Web server with multiple virtual hosts, where the hidden service
is not the default virtual host. When connecting to the hidden ser-
vice providing a random domain in the Host header the Web server
provides the default site, different from the hidden service, which
contains the candidate Internet endpoints.

Second, 8 hidden services are deanonymized through certiﬁcate
leaks, which provide a candidate Internet endpoint, even if the con-
tent of the hidden service did not provide any candidate. Of these, 4
are certiﬁcates that include the domain or IP address of the hidden
server; the other 4 are certiﬁcates with an onion address observed
by Sonar but not in our exploration.

Another hidden service is deanonymized because it contains an
email address to a DNS domain with an Internet site also hosted in
the same Web server. While the Internet site serves content unre-
lated to the hidden server, when querying the Internet site with the
Host header being the onion address, the hidden service content is
returned through the Internet.

The last deanonymization happens with two hidden services run-
ning on the same onion address through HTTP and HTTPS, respec-
tively. One has an intentional leak to an Internet site offering the
same content through both HTTP and HTTPS. When requesting
the Internet site with the Host header being the onion address the
two hidden services are observed, one on each port.
Location leak types. Table 6 summarizes the candidate pairs and
deanonymizations per method. For the candidates it shows the total
number of pairs and the distinct onion addresses in those pairs. The

1462Method
Endpoints
Identiﬁers
Titles
Certiﬁcates
TOTAL

Candidates

Pairs Onions
4,704
793
66
192
157
200
63
366
5,462
841

Deanonymizations
All Unintentional
67
32
2
12
20
44
18
30
101
51

Table 6: Summary of location leaks.

deanonymizations show the total onion addresses deanonymized
by each method and how many of those are classiﬁed as uninten-
tional. When considering all 101 deanonymized hidden services,
URL endpoints are the most effective content leak being present in
67 deanonymizations, followed by titles (44), certiﬁcates (30), and
identiﬁers (12). The identiﬁers correspond to Google Analytics (8)
and Bitcoin wallets (4). Note that some deanonymizations con-
tain several types of leaks. When considering only unintentional
leaks, the most effective location leaks are endpoints (32), titles
(20), and certiﬁcates (18). These numbers indicate that certiﬁcate
leaks are best to identify unintentional leaks (60%) and identiﬁers
worst (17%), which may indicate that administrators are already
careful about them.
Clustering. Grouping the 101 hidden services by shared domains
and IP addresses leaves 80 clusters. Of those, 12 contain multiple
onion addresses. Three of those 12 correspond to hidden services
that offer the same content through different onion addresses. The
other 9 clusters with multiple onion addresses correspond to servers
that are being used for hosting multiple hidden services.
Tor relay hosting. Of the 101 hidden services deanonymized, 21
are hosted on 13 Tor relays. Of those, 18 are considered intentional
leaks and 3 unintentional, a smaller fraction of unintentional leaks
compared with non-relay servers. This matches reports by the Tor
project that several Tor relays were taken down during operation
Onymous [42]. In some cases multiple hidden services are hosted
at the same Tor relay, indicating that those hidden services belong
to the owner of the Tor relay or that the Tor relay provides hid-
den service hosting services. Note that the Tor project discourages
hosting hidden services on Tor relays as Tor relay runtime is known
and can be correlated with the uptime of a hidden service [11].
Furthermore, CARONTE could be conﬁgured to consider the IP ad-
dresses of all Tor relays as candidates for all hidden services. We
leave this as future work as our goal is to demonstrate open-world
deanonymization and also to avoid impacting Tor relays.
Redirections. Fourteen hidden services redirect to an Internet site
counterpart at some point of the study. Surprisingly, 9 of these
hidden services redirect to the HTTP version of the Internet site.
This is problematic for their users as they expect all hops of the
communication to be encrypted when accessing a hidden service,
but the last hop will not be. For these sites, the beneﬁt of having a
hidden service is not clear.

4.4 Performance

CARONTE currently runs from one off-the-shelf workstation.
Once preprocessing ﬁnishes (e.g., parsing/indexing Sonar records)
analyzing a hidden service takes close to one minute. Most
time is spent in network connections. To scale CARONTE we
could use multiple backend servers. Once a hidden service to be
deanonymized is submitted a link could be generated where results
would be available after the analysis completed.

5. DEFENSES

This section summarizes best practices that administrators of
hidden services should take to eliminate location leaks. Some of
these best practices are mentioned at the Tor project’s how-to con-
ﬁgure a hidden service [11].
Use a dedicated Web server. CARONTE can validate candidate
domains when the same Web server is used to host both a hidden
server and an Internet site. The Tor project recommends installing
the hidden service in a separate Web server, but we believe this is a
must and we recommend changing the wording to emphasize this.
Administrators should speciﬁcally avoid reusing an existing Web
server that already hosts an Internet site by simply creating a new
virtual host. It is also a good idea to host the hidden service on a
dedicated machine.
Bind the web server to localhost. Another best practice is binding
the hidden service’s Web server only to localhost, so that HTTP re-
quests from Tor (running as a SOCKS proxy on localhost) are suc-
cessfully answered, but HTTP requests from the Internet receive an
HTTP Forbidden error response. We emphasize that this protection
is required in addition to running the hidden server on a dedicated
Web server. More speciﬁcally, if the hidden server is hosted on the
same Web server as another Internet site, even if the Web server is
bound to localhost, it is still possible to perform validation by con-
tacting the Internet site over Tor, rather than through the Internet.
To prevent conﬁguration errors we recommend the Tor project to
add detailed instructions on how to conﬁgure a Web server in this
manner, at least for the most common open source Web servers.

A ﬁrewall can also block non-Tor connections to the hidden
server. Network ﬁrewalls can block connections that do not come
from a Tor relay. However, the list of Tor relays needs to be con-
tinuously updated. Host ﬁrewalls can only allow connections from
localhost. Similar to binding the Web server to localhost, the hid-
den service should still be run on a dedicated Web server. The ad-
vantage is that Internet connections fail without generating an error
message.

Another principle could be that if the server does not know its
IP address it cannot leak it. Thus, the hidden service could be run
in a NATed VM without a public IP address. However, other leaks
(e.g., domain names in the content) could still happen.
Site auditing. Administrators should carefully audit their site’s
contents for leaks before making the site available as a hidden ser-
vice. A general rule is that given the many possible sources of
location leaks, the smaller the site, the easier the auditing and the
smaller the probability of location leaks. During the audit, admin-
istrators could use CARONTE to identify validated location leaks,
as well as to examine the candidate pairs CARONTE could not val-
idate. Also, all external links should be made to point to onion
addresses rather than Internet domains or IP addresses. Since not
all Internet sites have a corresponding onion address, they should
also audit all remaining IP addresses and Internet domains so that
they do not point to the public IP address of the hidden server. They
should also remove links to Internet domains or IP addresses owned
by them, even when hosted in other servers, as tracking accesses to
those other servers may reveal the identity of the administrators.
Furthermore, identiﬁers such as email addresses, Google Analyt-
ics, Google AdSense, and Bitcoin addresses should be removed or
at least not be reused in any other sites.
Certiﬁcates. Certiﬁcates with onion addresses in the CN or SAN
ﬁelds should not include DNS domains or IP addresses, and should
exclusively be used on Web servers that only run a hidden service
bound to localhost. In addition, a hidden service should never reuse
the certiﬁcate chain of another Internet site from the owner. Nowa-

1463days, the vast majority of hidden services use self-signed certiﬁ-
cates since few CAs will issue a certiﬁcate for an onion address
(only Facebook’s hidden service seems to have a valid certiﬁcate
chain [12]). Thus, certiﬁcate chains do not validate and will gener-
ate warnings, but man-in-the-middle attacks are limited by the fact
that public keys of hidden services are self-authenticating.
Avoid Tor relays. Hidden services that want to hide their loca-
tion should not be hosted on Tor relays, as this enables attackers to
perform closed-world validation using the IP addresses of all Tor
relays as candidates for any hidden service to be deanonymized.
Also, Tor relay uptime is public and can be correlated with hidden
service uptime. Similarly, running a hidden service on a machine
that is not always on enables uptime correlation attacks.

6. ETHICAL CONSIDERATIONS

While there exist tools like Shadow [31] to simulate attacks
against Tor, the application layer leaks studied in this paper cannot
be easily simulated because they are caused by erroneous conﬁgu-
rations by administrators of hidden services. Similar to Biryukov et
al. [17] we deem experiments on the live Tor network worthwhile
and necessary to enhance the scientiﬁc understanding of hidden ser-
vices, as long as they do not cause degradation of the network and
hidden services.

Our approach does not add any malicious Tor relay and gives
us no access to the plaintext of trafﬁc of any user. We purpose-
fully avoid deanonymization techniques based on exploiting soft-
ware vulnerabilities. However, our data is sensitive because it con-
tains location information on some hidden services that may want
to protect their location. This work has been approved by our in-
stitution’s ethics review board, which has mandated that due to its
sensitive nature the data must be protected with diligence, must not
be disclosed to third parties, and must be deleted when the paper is
accepted for publication. Furthermore, in this paper we do not dis-
close any deanonymized hidden service but only provide aggregate
data or fake examples to illustrate important steps and ﬁndings.

During the exploration of hidden services, to prevent download-
ing copyrighted material and offensive content (e.g., pornography),
we limit CARONTE to collecting textual and HTML content, ignor-
ing other content such as images, videos, or documents.

We have sent a copy of this draft to the Tor project to give them

a heads up on the work.

7. RELATED WORK

The ﬁrst generation of Tor’s hidden services is described in the
original design paper [21], but has since been revised [13]. Øverlier
and Syverson [40] ﬁrst demonstrated techniques to deanonymize
hidden services. They show how an adversary could lie about the
available bandwidth of a relay it controls to increase the probability
of that relay being selected for a hidden service circuit. This adver-
sary can repeatedly connect to a hidden server until trafﬁc corre-
lation indicates that the hidden server built a circuit to one of the
adversary’s relays. Bauer et al. [15] extended the attack to general
purpose circuits. As the result of these attacks, entry guard nodes
were added to the Tor hidden services speciﬁcation [13, 46]. Elahi
et al. [23] propose improvements to reduce the guard compromise
rate. Biryukov et al. [17] deanonymize hidden services in the pres-
ence of guard nodes by combining the bandwidth inﬂation attack
with a technique to phase their relays in and out of the consensus
at will without them losing their ﬂags.

These attacks target a speciﬁc hidden service, while we show that
large-scale deanonymization of many hidden services is possible
through content leaks. Also, these attacks rely on vulnerabilities

in the Tor speciﬁcation that can be centrally addressed by the Tor
project, while content leaks need to be ﬁxed by each hidden service.
Furthermore, our attacks do not require adding a malicious relay to
the Tor network.

Most similar to our approach is the work by Crenshaw on
deanonymizing I2P eepSites [20]. Crenshaw sets up an I2P router
and uses the IP addresses of the peers known to his router as can-
didates for hosting the eepSites. In Tor, which is not peer-to-peer
based, his approach is similar to considering the list of all Tor relays
as candidates for hosting any hidden service. This closed-world ap-
proach would enable deanonymizing only 21% of hidden services
that are hosted on Tor relays. Our approach in contrast shows how
to move from an open-world to a closed-world by extracting can-
didates from the identiﬁers and endpoints in the content of hidden
services, as well as their HTTPS certiﬁcates. In addition, his valida-
tion step relies solely on similar Server headers, which can produce
a high number of false positives.

A different deanonymization approach uses clock-skew mea-
surements when repeatedly connecting to a hidden service [36,47].
This attack also assumes a closed-world. We propose techniques to
move from a closed-world to an open-world and could also use this
technique in our validation.
DoS attacks. Selective denial-of-service attacks on relays can
force circuits to be re-built, increasing the probability of end-
to-end compromise [18]. Øverlier and Syverson [41] introduce
Valet Service nodes to improve the resilience of introduction points
against DoS attacks. Jansen et al. [32] deanonymize hidden ser-
vices through selective denial-of-service of relays’ memory that
forces the hidden service to choose guard nodes in control of the
adversary. The attack requires hours or days to deanonymize a sin-
gle hidden service and requires the adversary to identify the target’s
guards.
Forensics. A separate line of work considers the forensics prob-
lem of proving that a conﬁscated machine hosted a hidden ser-
vice [24, 43]. Those works assume the hidden service logs the re-
quests and place identiﬁable ﬁngerprints in the log ﬁles through
crafted queries.
AS-level adversaries. An attacker that is able to observe encrypted
trafﬁc from a client to the ﬁrst relay and from the ﬁnal relay to
the destination can link the client and destination by correlating
trafﬁc patterns [44]. Prior work has studied Tor’s vulnerability to
adversaries that can establish themselves in that position both at the
Internet exchange [38] and the AS [14, 22, 26, 33, 45] levels. Our
attacks instead deanonymize hidden services.
Trafﬁc analysis. Prior work proposes trafﬁc analysis attacks on
Tor that make probabilistic inferences about relays and clients that
are part of a speciﬁc circuit. One approach is to congest a re-
lay [25, 37]. Another approach leverages network-level character-
istics such as circuit throughput and latency [29,35]. These attacks
target clients and may not fully deanonymize them, while our at-
tacks fully deanonymize the location of hidden servers.
8. CONCLUSION

a tool

In this paper we have presented CARONTE,

to
deanonymize hidden services through location leaks in their con-
tent and conﬁguration. CARONTE implements a novel approach
to deanonymize hidden services that does not rely on ﬂaws on the
Tor protocol and assumes an open-world, i.e., it does not assume
a short list of candidate servers is known in advance. Instead, it
implements novel techniques to identify candidate servers from the
content and conﬁguration of a hidden service, which enable moving
from an open-world to a closed-world.

1464Using CARONTE we perform the ﬁrst measurement study on
the prevalence of location leaks in hidden services. Out of 1,974
live HTTP hidden services, CARONTE successfully deanonymizes
the location of 5% of them. Of the deanonymized hidden services
21% are running on Tor relays. The remaining 79% could not be
deanonymized in a close-world.

9. ACKNOWLEDGMENTS

The authors would like to thank the anonymous reviewers for
their feedback. This work was performed while Srdjan Matic was
a visiting Ph.D. student at the IMDEA Software Institute.

This research was partially supported by the Regional Govern-

ment of Madrid through the N-GREENS Software-CM project
S2013/ICE-2731 and by the Spanish Government through the
StrongSoft Grant TIN2012-39391-C04-01. All opinions, ﬁndings
and conclusions, or recommendations expressed herein are those of
the authors and do not necessarily reﬂect the views of the sponsors.

10. REFERENCES
[1] Certiﬁcate Transparency.

http://www.certificate-transparency.org/.

[2] Deep web links: .onion hidden service urls list.

http://deepweblinks.org/.

[3] Duckduckgo. http://3g2upl4pq6kufc4m.onion.
[4] Hidden wiki: Tor .onion urls directories.

http://thehiddenwiki.org/.

[5] Public Sufﬁx List. http://publicsuffix.org/.
[6] Rapid 7: Sonar Project.

https://scans.io/study/sonar.ssl.

[7] Sameid. http://sameid.net/.
[8] The ICSI Certiﬁcate Notary.

http://notary.icsi.berkeley.edu/.

[9] The Invisible Internet Project. https://geti2p.net/.
[10] Tor hidden service (.onion) search.

https://ahmia.fi/search/.

[11] Tor project: Conﬁguring hidden services for tor.

https://www.torproject.org/docs/tor-
hidden-service.html.en.

[12] Tor project: Facebook, hidden services, and https certs.

https:
//blog.torproject.org/blog/facebook-
hidden-services-and-https-certs.

[13] Tor project: Tor rendezvous speciﬁcation.

https://gitweb.torproject.org/torspec.
git/tree/rend-spec.txt.

[14] M. Akhoondi, C. Yu, and H. V. Madhyastha. LASTor: A
Low-Latency AS-Aware Tor Client. In Proceedings of the
IEEE Symposium on Security and Privacy, 2012.

[15] K. Bauer, D. McCoy, D. Grunwald, T. Kohno, and D. Sicker.
Low-resource Routing Attacks Against Tor. In Proceedings
of the ACM Workshop on Privacy in Electronic Society,
2007.

[16] A. Biryukov, I. Pustogarov, F. Thill, and R.-P. Weinmann.

Content and Popularity Analysis of Tor Hidden Services. In
Proceedings of the First International Workshop on Big Data
Analytics for Security, June 2014.

[17] A. Biryukov, I. Pustogarov, and R.-P. Weinmann. Trawling

for Tor Hidden Services: Detection, Measurement,
Deanonymization. In Proceedings of the IEEE Symposium
on Security and Privacy, 2013.

[18] N. Borisov, G. Danezis, P. Mittal, and P. Tabriz. Denial of
Service or Denial of Security? In Proceedings of the 14th
ACM Conference on Computer and Communications
Security, 2007.

[19] N. Christin. Traveling the silk road: A measurement analysis
of a large anonymous online marketplace. In Proceedings of
the 22nd international conference on World Wide Web, pages
213–224. International World Wide Web Conferences
Steering Committee, 2013.

[20] A. Crenshaw. Darknets and hidden servers: Identifying the
true IP/network identity of I2P service hosts, 2011. Black
Hat DC.

[21] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The

Second-generation Onion Router. In Proceedings of the 13th
USENIX Security Symposium, 2004.

[22] M. Edman and P. Syverson. AS-awareness in Tor Path

Selection. In Proceedings of the 16th ACM Conference on
Computer and Communications Security, 2009.

[23] T. Elahi, K. Bauer, M. AlSabah, R. Dingledine, and

I. Goldberg. Changing of the Guards: A Framework for
Understanding and Improving Entry Guard Selection in Tor.
In Proceedings of the ACM Workshop on Privacy in the
Electronic Society, 2012.

[24] J. A. Elices, F. Perez-Gonzalez, and C. Troncoso.

Fingerprinting Tor’s Hidden Service Log Files Using a
Timing Channel. In Proceedings of the IEEE International
Workshop on Information Forensics and Security, 2011.
[25] N. S. Evans, R. Dingledine, and C. Grothoff. A Practical

Congestion Attack on Tor Using Long Paths. In Proceedings
of the 18th USENIX Security Symposium, 2009.

[26] N. Feamster and R. Dingledine. Location Diversity in

Anonymity Networks. In Proceedings of the ACM Workshop
on Privacy in the Electronic Society, 2004.

[27] R. Graham. Reading the Silk Road conﬁguration, October
2014. http://blog.erratasec.com/2014/10/
reading-silk-road-configuration.html.

[28] A. Greenberg. Wired: Global Web Crackdown Arrests 17,
Seizes Hundreds Of Dark Net Domains, November 2014.
http://www.wired.com/2014/11/operation-
onymous-dark-web-arrests/.

[29] N. Hopper, E. Y. Vasserman, and E. Chan-TIN. How Much

Anonymity Does Network Latency Leak? ACM Transactions
on Information Systems Security, 13(2):1–28, Feb. 2010.

[30] Html::Similarity.

http://search.cpan.org/~xern/HTML-
Similarity-0.2.0/lib/HTML/Similarity.pm/.
[31] R. Jansen and N. Hopper. Shadow: Running Tor in a Box for

Accurate and Efﬁcient Experimentation. In Proceedings of
the 19th Annual Network and Distributed System Security
Symposium, February 2012.

[32] R. Jansen, F. Tschorsch, A. Johnson, and B. Scheuermann.

The Sniper Attack: Anonymously Deanonymizing and
Disabling the Tor Network. In Proceedings of the 21st
Annual Network and Distributed System Security
Symposium, 2014.

[33] A. Johnson, C. Wacek, R. Jansen, M. Sherr, and P. Syverson.

Users Get Routed: Trafﬁc Correlation on Tor by Realistic
Adversaries. In Proceedings of the ACM Conference on
Computer and Communications Security, 2013.

[34] B. Krebs. Silk Road Lawyers Poke Holes in FBIâ ˘A ´Zs Story,

October 2014.

1465http://krebsonsecurity.com/2014/10/silk-
road-lawyers-poke-holes-in-fbis-story/.
[35] P. Mittal, A. Khurshid, J. Juen, M. Caesar, and N. Borisov.

Stealthy Trafﬁc Analysis of Low-latency Anonymous
Communication Using Throughput Fingerprinting. In
Proceedings of the 18th ACM Conference on Computer and
Communications Security, 2011.

[36] S. J. Murdoch. Hot or Not: Revealing Hidden Services by

Their Clock Skew. In Proceedings of the 13th ACM
Conference on Computer and Communications Security,
2006.

[37] S. J. Murdoch and G. Danezis. Low-Cost Trafﬁc Analysis of
Tor. In Proceedings of the IEEE Symposium on Security and
Privacy, 2005.

[38] S. J. Murdoch and P. Zieli´nski. Sampled Trafﬁc Analysis by
Internet-exchange-level Adversaries. In Proceedings of the
7th International Conference on Privacy Enhancing
Technologies, 2007.

[39] Netcraft. Keys left unchanged in many Heartbleed

replacement certiﬁcates!, April 2014.
http://news.netcraft.com/archives/2014/
05/09/keys-left-unchanged-in-many-
heartbleed-replacement-certificates.html.

[40] L. Øverlier and P. Syverson. Locating Hidden Servers. In

Proceedings of the IEEE Symposium on Security and
Privacy, 2006.

[41] L. Øverlier and P. Syverson. Valet Services: Improving

Hidden Servers with a Personal Touch. In Proceedings of the
6th International Conference on Privacy Enhancing
Technologies, 2006.

[42] T. Project. Thoughts and concerns about operation onymous,

November 2014. https:
//blog.torproject.org/blog/thoughts-and-
concerns-about-operation-onymous.

[43] B. Shebaro, F. Perez-Gonzalez, and J. R. Crandall. Leaving
Timing-channel Fingerprints in Hidden Service Log Files.
Digital Investigations, 7:104–113, Aug. 2010.

[44] P. Syverson, G. Tsudik, M. Reed, and C. Landwehr. Towards

an Analysis of Onion Routing Security. In Designing
Privacy Enhancing Technologies: Workshop on Design Issue
in Anonymity and Unobservability, July 2000.

[45] L. Vanbever, O. Li, J. Rexford, and P. Mittal. Anonymity on
QuickSand: Using BGP to Compromise Tor. In Proceedings
of the 13th ACM Workshop on Hot Topics in Networks, 2014.

[46] M. Wright, M. Adler, B. N. Levine, and C. Shields.

Defending Anonymous Communications Against Passive
Logging Attacks. In Proceedings of the IEEE Symposium on
Security and Privacy, 2003.

[47] S. Zander and S. J. Murdoch. An Improved Clock-skew

Measurement Technique for Revealing Hidden Services. In

Proceedings of the 17th USENIX Security Symposium, 2008.

1466