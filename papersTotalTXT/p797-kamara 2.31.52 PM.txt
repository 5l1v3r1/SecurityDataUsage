Salus: A System for Server-Aided

Secure Function Evaluation

Seny Kamara

Microsoft Research

senyk@microsoft.com

Payman Mohassel
University of Calgary

∗
Ben Riva

Tel Aviv University

pmohassel@cspc.ucalgary.ca

benriva@tau.ac.il

ABSTRACT

Secure function evaluation (SFE) allows a set of mutually
distrustful parties to evaluate a function of their joint inputs
without revealing their inputs to each other. SFE has been
the focus of active research and recent work suggests that it
can be made practical. Unfortunately, current protocols and
implementations have inherent limitations that are hard to
overcome using standard and practical techniques. Among
them are: (1) requiring participants to do work linear in
the size of the circuit representation of the function; (2)
requiring all parties to do the same amount of work; and (3)
not being able to provide complete fairness.

A promising approach for overcoming these limitations is
to augment the SFE setting with a small set of untrusted
servers that have no input to the computation and that
receive no output, but that make their computational re-
sources available to the parties. In this model, referred to as
server-aided SFE, the goal is to tradeoﬀ the parties’ work
at the expense of the servers. Motivated by the emergence
of public cloud services such as Amazon EC2 and Microsoft
Azure, recent work has explored the extent to which server-
aided SFE can be achieved with a single server.

In this work, we revisit the sever-aided setting from a prac-
tical perspective and design single-server-aided SFE proto-
cols that are considerably more eﬃcient than all previously-
known protocols. We achieve this in part by introducing
several new techniques for garbled-circuit-based protocols,
including a new and eﬃcient input-checking mechanism for
cut-and-choose and a new pipelining technique that works
in the presence of malicious adversaries. Furthermore, we
extend the server-aided model to guarantee fairness which
is an important property to achieve in practice.

Finally, we implement and evaluate our constructions ex-
perimentally and show that our protocols (regardless of the
number of parties involved) yield implementations that are
4 and 6 times faster than the most optimized two-party SFE

∗Work done at Microsoft Research.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’12, October 16–18, 2012, Raleigh, North Carolina, USA.
Copyright 2012 ACM 978-1-4503-1651-4/12/10 ...$15.00.

implementation when the server is assumed to be malicious
and covert, respectively.

Categories and Subject Descriptors

K.6.5 [Management of Computing and Information
Systems]: Security and Protection

Keywords

Secure Computation, Server-Aided Computation, Multi-Party
Computation, Cloud Computing

1

Introduction

Secure function evaluation (SFE) allows a set of n parties,
each with a private input, to securely and jointly evaluate
an n-ary function f over their inputs. Roughly speaking,
a SFE protocol guarantees (at least) that: (1) the parties
will not learn any information from the interaction other
than their output and what is inherently leaked from it; and
(2) that the functionality was computed correctly. SFE is
useful in any setting where mutually distrustful parties need
to cooperate but do not wish to reveal their inputs to each
other. This often occurs in practice, for example, during
negotiations, auctions, data mining, and voting.

Towards practical SFE. Early work on SFE—and the
more general notion of multi-party computation (MPC)—
focused on feasibility results; that is, demonstrating that ev-
ery function can be computed securely [57, 58, 24, 10]. Mo-
tivated by these results, much of the work in SFE focused on
improving the security deﬁnitions [44, 9], on strengthening
the adversarial models, on decreasing the round and commu-
nication complexity and on improving eﬃciency [43, 45, 7,
38, 41, 4, 6, 52]. The special case of two-party SFE (2SFE)
in particular has been improved extensively with more ef-
ﬁcient semi-honest-to-malicious compilation techniques [43,
45, 56, 38, 41, 35, 40, 55], garbled circuit constructions and
implementations [49, 35, 52, 29, 42], and oblivious transfer
protocols [48, 30, 50]. In fact, recent work on practical SFE
has even led to the design and implementation of several
SFE/MPC frameworks such as Fairplay [43, 4], VIFF [15],
Sharemind [5], Tasty [28], HEKM [29] and VMCrypt [42].

Limitations of standard SFE. While these advances have
resulted in great improvements in eﬃciency and have eﬀec-
tively taken SFE from a purely theoretical idea to a poten-
tially practical technology, there are inherent limitations to

797these optimizations. Indeed, in all current implementations—
even with the state-of-the-art protocols and optimizations—
the parties’ running time is linear in the size of the circuit
representation of the function they wish to evaluate.

Unfortunately, the circuit representation of most functions
of practical interest can be quite large. For example, note
that the circuit for evaluating the AES function requires
roughly 30, 000 gates, while a circuit that evaluates the edit
distance between two 50 character strings requires about
250, 000 gates (see Section 4.2). It is easy to think of inter-
esting functionalities with circuits that go up to billions of
gates.

An additional limitation of standard SFE is that the work-
load is symmetric in the sense that each party has to do the
same amount of computation. In many real-world applica-
tions, however, some parties are weaker than others. Con-
sider, e.g., a mobile device that retrieves location-based in-
formation from a server; or a PC that searches a distributed
database hosted by a large-scale cluster of machines.
In
each case, SFE would allow the parties involved to per-
form the computation while keeping their inputs (i.e., the
location and the search term) private. Unfortunately, stan-
dard protocols— all of which require a symmetric amount of
work—are ill-suited for these settings since the size of both
parties’ inputs is bounded by the resources available to the
weakest device.
In other words, the mobile device would
only be able to search through a small amount of location
data, and the PC could only search through a small fraction
of the database.

Finally, achieving fairness is not always possible with stan-
dard SFE. Roughly speaking, fairness ensures that either all
the parties learn the output of the function being evaluated
or none will. This is crucial in many real-world applications
such as auctions, electronic voting, or collective ﬁnancial
analysis, where a dishonest participant should not be able
to disrupt the protocol if it is not satisﬁed with the outcome
of the computation. In 1986, Cleve showed that complete
fairness is impossible in general, unless the majority of the
players are honest [12]. A number of constructions try to
achieve fairness for a speciﬁc class of functionalities [27], or
consider limited (partial) notions of fairness instead [51, 19,
26].

Server-aided SFE. Several approaches to SFE have been
proposed to address the inherent limitations outlined above
and to achieve a sub-linear amount of work (in the size of the
circuit representation of the function). Of course, one pos-
sibility is to design special-purpose protocols, i.e., protocols
that work for a single functionality or a class of function-
alities (see, e.g., [46, 25]). Another approach, referred to
as server-aided or cloud-assisted SFE, augments the stan-
dard setting with a small set of servers that have no inputs
to the computation and receive no output but that make
their computational resources available to the parties.
In
this paradigm, the goal is to tradeoﬀ the parties’ work at
the expense of the servers. Server-aided SFE with two or
more servers has been considered in the past [16, 17] and
even deployed in practice [6].

Currently, there are two approaches to designing single-

server-aided SFE protocols: (1) combining fully-homomorphic
encryption (FHE) [21] with a proof system [3, 1]; or (2)
using Yao’s garbled circuit technique [57, 58]. The lat-
ter was proposed by Feige, Killian and Naor [18] in the

semi-honest model and recently formalized and extended to
stronger models by Kamara, Mohassel and Raykova [32].
The FHE-based approach is asymptotically optimal, but
currently only of theoretical interest. The garbled circuit
approach is slightly less eﬃcient asymptotically but yields
protocols that are eﬃcient in practice. In addition, it can
beneﬁt from almost all the optimizations discussed above so
it is complementary to previous work on practical SFE.

While the garbled-circuit approach yields practical proto-
cols, we note that it is in a weaker adversarial model than
the FHE-based solutions.
In standard SFE it is assumed
that if two or more parties are dishonest, they will collude.
The protocols of [18] and [32], however, are only secure in
settings where some of the dishonest parties do not collude.
There are many settings in practice where collusion does
not occur, e.g., due to physical restrictions, legal constraints
and/or economic incentives. In a server-aided setting where
the server is a large cloud provider (e.g., Amazon, Google or
Microsoft), it is reasonable—given the consequences of legal
action and bad publicity—to assume that the server will not
collude with the parties.

Another limitation of the garbled circuit approach is that
it yields protocols where at least one of the parties (other
than the server) has to do linear work (throughout we will as-
sume this party to be the ﬁrst party P1). It is shown in [32]
that any non-interactive single-server-aided protocol with-
out this limitation would imply a secure non-interactive del-
egated computation scheme which, currently, we only know
how to construct based on FHE.

Deploying server-aided SFE. Even with the limitations
outlined above, we believe that the garbled-circuit approach
to single-server-aided SFE could be useful in many real-
world scenarios. Consider, for example, the case of an en-
terprise (e.g., a small-to-medium-sized one) that may want
to use SFE to provide better privacy for itself and its cus-
tomers. The limitations of standard SFE outlined above
would make this completely impractical—especially if the
enterprise’s clients are resource-constrained devices such as
smartphones or tablets.

A better approach would be to use server-aided SFE where
the server is instantiated by a public cloud (e.g., Amazon
EC2, Windows Azure or Google Compute Engine), the en-
terprise plays the role of P1 and its clients play the roles of
the remaining parties. Note that such a setup is very natu-
ral in the setting of cloud computing since many business’s
already make use of public clouds to deliver services to their
own clients (e.g., Netﬂix, Instagram) and since they have
signiﬁcantly more resources than their clients.

1.1 Background on Garbled Circuits

We make use of several cryptographic building blocks in
our protocols, including garbled circuits, oblivious transfer
(OT) [53] and secret sharing [54]. We omit formal descrip-
tions of these building blocks due to lack of space and refer
the reader to [22]. However, we brieﬂy review garbled cir-
cuits before describing our contributions.

Yao’s garbled circuit technique [57, 58] transforms circuits
in such a way that they can be evaluated on encrypted in-
puts. We refer the reader to [39] for details on Yao’s garbled
circuit construction. At a very high level, a garbling scheme
consists of: (1) a circuit garbling procedure that transforms
a circuit into a garbled circuit consisting of garbled gates;

798(2) an input garbling procedure that generates a set of input
labels; (3) an evaluation procedure that evaluates a garbled
circuit over a set of input labels, resulting in a set of out-
put labels; and (4) a decoding procedure that recovers the
output from the output labels.

The main security property provided by garbled circuits is
input privacy, which guarantees that no information about
the inputs is revealed by the evaluation and decoding pro-
cedures beyond what can be inferred from the output. Our
protocols will rely on a slightly diﬀerent property called in-
put/output privacy which guarantees that no information
about the inputs or outputs are revealed by the evaluation
procedure (these properties are implied by the security proof
of [39]). Another useful property of garbled circuits is un-
forgeability which, informally, guarantees that an incorrect
evaluation can be detected with all but negligible probabil-
ity. This property has also been noted and used in works as
early as [49], but pointed out more explicitly in [20].

Cut-and-choose and input-consistency. A diﬃculty that
often comes up when designing protocols based on garbled
circuits is verifying whether a circuit was garbled correctly
(this occurs when adversaries can be malicious). Several
mechanisms exist to address this but the most eﬃcient is cut-
and-choose [47, 43, 45, 34, 56, 38]. With cut-and-choose, the
garbler starts by constructing many garbled circuits. The
evaluator chooses a random subset of these circuits and ver-
iﬁes their correctness by asking the garbler to reveal the se-
crets it used. If the veriﬁcation goes through, the evaluator
is left with several unopened garbled circuits and, with high
probability, most of them are properly constructed (other-
wise at least one malconstructed garbled circuit would have
been detected during veriﬁcation). The evaluator then eval-
uates the remaining garbled circuits and outputs the major-
ity value.

This last step, however, introduces new problems and to
avoid subtle attacks the evaluator has to check that the gar-
bler used the same inputs for all the remaining circuits. This
input checking step can be handled using several techniques.
Mohassel and Franklin [45] and Lindell and Pinkas [38] ex-
tend the cut-and-choose technique to cover the input labels
as well. Unfortunately, this requires a quadratic (in the secu-
rity parameter) number of commitments. Another approach
is to use specially-designed zero-knowledge proofs [40, 55]
which, under speciﬁc number-theoretic assumptions, require
only a linear number of exponentiations.

The techniques of [45] and [38] are extended to the server-
aided setting in [32], where an input checking mechanism is
described that requires a quadratic number of commitments.

Pipelined execution. Finally, since circuits can grow very
large, garbling and evaluating them in memory can be ex-
pensive. Several implementations, therefore, pipeline the
generation and evaluation of garbled circuits [31, 28, 29,
42] by having the garbler send (or stream) the garbled gates
immediately after generating them and having the evaluator
evaluate (or verify) them on the ﬂy. Using this approach, the
parties store in memory only the intermediate wires needed
for the rest of the evaluation. This leads to very eﬃcient
implementations since the parties only need to store inter-
mediate values and garbled gates on disk. Moreover, it im-
proves the latency of the protocol since the garbler and the
evaluator can operate simultaneously. Previous work, how-

ever, has only shown how to pipeline garbled circuits in the
presence of semi-honest adversaries.

1.2 Our Contributions
Secure function evaluation is an important and powerful
cryptographic primitive and many of its underlying tech-
niques, such as garbled circuits, oblivious transfer and secret
sharing, are important in their own right. As such, SFE and
the underlying primitives that enable it have a wide array of
applications and if made practical could have a large impact
on the design of secure and privacy-preserving technologies.
Today, the server-aided approach seems to be one of the
most promising directions for scaling SFE and overcoming
the inherent limitations of the optimization techniques dis-
covered in previous work. In addition, given the recent emer-
gence of public clouds, such as Amazon EC2 and Microsoft
Azure, server-aided SFE can be implemented broadly and
at low-cost.

In this work, we revisit the server-aided setting from a
more practical point of view and explore the extent to which
we can take advantage of this model and design protocols
that are more eﬃcient and practical than what was previ-
ously known [18, 32]. Our ﬁndings are quite positive as we
make the following contributions.

Fairness. We extend the server-aided model to provide fair-
ness, which guarantees that either all parties will receive
their outputs or none will. Fairness is an important prop-
erty to achieve in the context of practical SFE as it provides
an incentive for parties not to abort the protocol after re-
ceiving their outputs.

A generic transformation. In the full version of the pa-
per we give a black-box transformation from any two-party
SFE protocol secure against malicious adversaries to a multi-
party server-aided SFE protocol. This yields a generic com-
piler for designing eﬃcient server-aided SFE protocols and
provides a point of comparison for custom-designed con-
structions.

Efficient server-aided protocols. We design two new
single-server-aided multi-party SFE protocols. Both are based
on garbled circuits, achieve fairness and are more eﬃcient
than any of the previously-known protocols [18, 32], or the
generic construction mentioned above. In addition, the eﬃ-
ciency of the ﬁrst protocol can be increased if it is used in
the presence of a covert server (i.e., a server that wants to
cheat but does not want to be caught) [2].

One of the reasons behind the improved eﬃciency is a
new input checking mechanism for the cut-and-choose step
that only requires a linear number of commitments (in the
total length of the inputs), as opposed to previously-known
alternatives that either require a quadratic number of com-
mitments (in the security parameter) or a linear number of
exponentiations.

In settings where the total input length is relatively small
compared to the square of the security parameter (which is
roughly 17, 000) our approach is signiﬁcantly more eﬃcient.
For example, for the AES circuit our construction reduces
the total size of the commitments from more than 100MB
(in the quadratic case) to around 1MB.

Pipelining with malicious adversaries. We introduce
a new pipelining technique that works in the presence of a
malicious adversary. As discussed above, previous solutions

799were only applicable to the semi-honest setting and did not
work when considering malicious adversaries. We note that
in independent and concurrent work, Kreuter, shelat and
Shen [36] describe an approach similar to ours.

Experimental evaluation. We implement our protocols
and evaluate their eﬃciency empirically over two large cir-
cuits: (1) the AES circuit which has roughly 30, 000 gates;
and (2) the edit distance circuit for 50 character strings of
8 bits each which has roughly 250, 000 gates. Naturally,
all parties but P1 have to do very little work. Interestingly,
however, our experiments show a signiﬁcant reduction in the
total running times—even for the server and P1. For AES,
our ﬁrst protocol (which is secure against a covert server)
is roughly 6× faster than the covert protocol of [52]. Our
second protocol (which secure against a malicious server), is
roughly 4× faster than the most optimized 2SFE implemen-
tation [55]. Moreover, a nice property that our experiments
illustrate is that the running time of our second protocol is
almost independent of the number of the parties involved.

2 Model and Deﬁnitions

Practical server-aided SFE with a single server has only been
achieved in certain speciﬁc adversarial models. In particu-
lar, as shown in [32], the garbled-circuit-based protocol of
Feige, Killian and Naor from [18] is a secure sever-aided SFE
protocol against a set of non-colluding semi-honest adver-
saries, that is, adversaries that follow the protocol and are
independent in the sense that they do not share any infor-
mation before or after the protocol execution. [32] also gives
protocols that are secure in the presence of non-cooperating
adversaries which, roughly speaking, are adversaries that de-
viate from the protocol but do not send information other
than what prescribed by the protocol (note that a non-
cooperating adversary is stronger than a semi-honest ad-
versary).

A natural question, therefore, is whether these relaxations
of the adversarial model are necessary in order to achieve
practical server-aided SFE and all the advantages it pro-
vides, such as asymmetric eﬃciency (i.e., diﬀerent parties
needing diﬀerent amounts of resources) and sub-linear work.

Asymmetric efficiency in the standard model? Con-
sider a solution that does not make use of the relaxations de-
scribed above. In particular, one might attempt to design an
eﬃcient server-aided protocol between parties (P1 . . . , Pn)
and a server S, such that: (1) a subset of the parties do sub-
linear work; and (2) the server and the remaining parties
do work that is polynomial in the size of the circuit. Such
a protocol with security in the standard adversarial model,
however, would yield a 2SFE protocol with low communica-
tion and computation for one party 1 which, currently, can
only be constructed based on FHE [14].

Server-aided SFE from any two-party SFE. A sec-
ond promising attempt (and a successful one) is to take
advantage of the fact that the server and P1 are never si-
multaneously malicious. With this assumption in place, one
can indeed design practical protocols wherein all the parties

1Given such a server-aided SFE protocol one can construct
a standard two-party protocol by having the ﬁrst party sim-
ulate the subset of the parties who perform sub-linear work
and having the second party simulate the server S and the
remaining parties.

but P1 perform very little work (only proportional to their
own input). The idea is as follows: the players (P2, . . . , Pn)
share their inputs between S and P1, and let them run a
general-purpose 2SFE protocol (with security against mali-
cious adversaries) for computing the desired function on the
players’ inputs. This approach is promising but for it to
work one needs to enhance the 2SFE protocol with mecha-
nisms to convince the players that: (1) their real inputs were
used (note that the security of 2SFE does not imply this);
and (2) the output of the 2SFE is delivered back to them
(2SFE guarantees output correctness but not honest delivery
of the output to P2 through Pn). In the full version of the
paper we describe an eﬃcient solution that addresses both
issues, and works with any general-purpose 2SFE protocol
with security against malicious adversaries.

Better efficiency than 2SFE? An important question
is whether the server-aided setting can lead to more eﬃcient
protocols than the standard setting or whether the best we
can hope for is to achieve the complexity of existing 2SFE
protocols. Unfortunately, the latter is indeed the case in
general, i.e., if we insist on security with respect to all pos-
sible adversarial settings. Suppose, for example, that we
require the server-aided protocol to be secure in the pres-
ence of either: (1) a malicious server and a single malicious
party (say Pt); or (2) an honest server and all but one ma-
licious parties. The overall complexity of such a protocol
(even if carefully optimized) will always be greater than the
complexity of the most eﬃcient 2SFE protocol with security
against malicious adversaries.

To see why, we sketch how one can use such a protocol to
construct a 2SFE protocol secure against malicious adver-
saries. Let A and B be the two parties who want to engage
in a 2SFE protocol. A runs the server-aided protocol sim-
ulating the server and Pt with A’s input, and B runs the
protocol simulating the rest of the parties (and sharing his
input between them). If A is malicious, the security of the
server-aided protocol against a malicious server and a mali-
cious Pt guarantees security. If B is malicious, the security
of the server-aided protocol against an honest server and a
colluding set of all but one malicious parties (Pt in this case)
implies security for the 2SFE protocol.

On a positive note, we show that if we restrict ourselves
to certain adversarial settings then we can indeed do better
than 2SFE. More precisely, we show that by only requiring
security in the presence of a non-cooperative server, we can
do much better.

2.1 Formal Model

We recall the ideal/real-model security deﬁnition for MPC
in the presence of non-cooperative adversaries presented in
[32]. At a high level, the deﬁnition compares the real-model
execution of a protocol for computing an n-party function f
to the ideal-model evaluation of f by a trusted party in the
presence of m independent adversaries (A1, . . . , Am) that
are assumed not to collude.

Non-collusion in MPC. The standard adversarial models
for MPC include: (1) semi-honest adversaries which follow
the protocol but attempt to learn extra information from
their view of the execution; and (2) malicious adversaries
which can deviate arbitrarily from the protocol. The re-
cently proposed notion of non-cooperative adversaries [32]
captures adversaries that may deviate from the protocol but

800that do not share any information that is not prescribed by
the protocol.

Definition 2.1

(Non-cooperative adversary [32]).
An adversary Ai is non-cooperative with respect to adversary
Aj if the messages Ai sends to Aj reveal no information
about Ai’s private values (i.e., its coins and input) to Aj
beyond what can be inferred from Aj ’s output fj (x).

Note that the notion of non-cooperation only restricts the
information revealed by Ai’s messages and does not imply
that Ai is semi-honest. Indeed, Ai could deviate from the
protocol without revealing any information to Aj about its
private values, e.g., by garbling a function f ′
6= f when
required to garble f .

2.2 Security Deﬁnition
Our security deﬁnition is similar to the one presented in [32]
with the exception that it guarantees fairness and handles
the case when the server is covert. (See [22] for more details
about the idea-model/real-model security for MPC.) At a
high level, fairness is guaranteed by modifying the behavior
of the trusted party in the ideal-model execution so that it
sends ⊥ to all parties if any party chooses to abort (note
that the fairness guarantee does not extend to the server).
We capture covertness using the explicit cheat formulation of
[2] which augments the ideal-model execution by allowing a
covert adversary A to send a cheat instruction to the trusted
party. Upon receiving this instruction, the trusted party
sends A all the inputs and takes one of two possible actions:
with probability ǫ it discloses to all parties that A cheated
and with probability 1 − ǫ it does not.

Real-model execution. The real-model execution of pro-
tocol Π takes place between parties (P1, . . . , Pn), server Pn+1
and adversaries (A1, . . . , Am+1), where m ≤ n.

At the beginning of the execution, each party (P1, . . . , Pn)
receives its input xi, a set of random coins ri, and an aux-
iliary input zi while the server Pn+1 receives only a set of
random coins rn+1 and an auxiliary input zn+1. Each ad-
versary (A1, . . . , Am) receives an index i ∈ I that indicates
the party it corrupts, while adversary Am+1 receives a set of
indices that indicate the parties it will corrupt (this captures
the fact that these parties collude).

For all honest parties Pi, let outi denote its output and
for all corrupted parties Pi, let outi denote its view during
the execution of Π. The ith partial output of a real-model
execution of Π between parties (P1, . . . , Pn+1) in the pres-
ence of adversaries A = (A1, . . . , Am+1) is deﬁned as

real(i)(k, x; r)

def

= (cid:8)outj : j ∈ H(cid:9) ∪ outi.

where H denotes the set of honest parties and r = (r1, . . . ,
rn+1).

Ideal-model execution. In the ideal-model execution, all
the parties interact with a trusted party that evaluates f .
As in the real-model execution, the ideal execution begins
with each party (P1, . . . , Pn) receiving its input xi, its coins
ri and an auxiliary input zi, while the server Pn+1 receives
only its coins rn+1 and an auxiliary input zn+1. Each party
(P1, . . . , Pn) sends x′
i = xi
if Pi is semi-honest and x′ is an arbitrary value if Pi is ei-
ther malicious or non-cooperating. If any x′
i = ⊥ or if the
server sends an abort message, the trusted party returns ⊥

i to the trusted party, where x′

to all parties.
If the server Pn+1 is covert, it can send a
cheat instruction to the trusted party. Upon receiving this
instruction, the trusted party tosses some coins and with
probability 1 − ǫ discloses the server’s cheating (and the
other parties output ⊥) and with probability ǫ does not.
In the latter case, the trusted party sends (x′
n) to
the server, receives (y1, . . . , yn) in response, and returns yi
to Pi.
If the server did not send cheat, the trusted party
returns fi(x′

n) to party Pi.

1, . . . , x′

1, . . . , x′

For all honest parties Pi, let outi denote the output re-
turned to Pi by the trusted party, and for all corrupted par-
ties let outi be some value output by Pi. The ith partial
output of an ideal-model execution between parties (P1, . . . ,
Pn+1) in the presence of independent simulators S = (S1, . . . ,
Sm+1) is deﬁned as

ideal(i)(k, x; r)

def

= (cid:8)outj : j ∈ H(cid:9) ∪ outi.

where H denotes the set of honest parties and r = (r1, . . . ,
rn+1).

We now present our formal deﬁnition of security which,
intuitively, guarantees that executing a protocol Π in the
real model is equivalent to executing Π in an ideal model
with a trusted party.

Definition 2.2

(Security). A n-party protocol Π se-
curely computes f if there exists a set {Simi}i∈[m+1] of
polynomial-size transformations such that for all polynomial-
size adversaries A = (A1, . . . , Am+1), for all x and z, and
for all i ∈ [m + 1],

(cid:26)real(i)(k, x; r)(cid:27)k∈N

c

≈(cid:26)ideal(i)(k, x; r)(cid:27)k∈N

where S = (S1, . . . , Sm+1) and Si = Simi(Ai) and where r
is chosen uniformly at random.

We now present a Lemma from [32] that we will use to
prove security. Informally, it asserts that to prove a protocol
Π secure in the presence of a non-cooperative adversary Ai it
suﬃces to show that the protocol is secure in the semi-honest
model (i.e., where all the adversaries follow the protocol)
and that it is secure when Ai is malicious and all the other
parties are honest.

Lemma 2.3

([32]). If a multi-party protocol Π between
n parties (P1, . . . , Pn) securely computes f in the presence
of (1) independent and semi-honest adversaries and (2) a
malicious Ai and honest {Aj }j6=i; then Π is also secure in
the presence of an adversary Ai that is non-cooperative with
respect to all other semi-honest adversaries.

3 Our Protocols

We describe our server-aided SFE protocols which are secure
in the presence of a covert and malicious server, respectively.
For simplicity of the description, we assume the output of
the computation is a single bit. Extending it to more than
one output bit is straightforward.

Notations and primitives. Denote by inp(Pi) the set of
input wires for Pi’s input bits and let m be the total number

of input bits, i.e., m = P |inp(i)|. Here we assume the

output of the computation is a single bit, but both protocols
can be easily adapted to handle multiple bit outputs.

801Let C be a circuit that computes the function f . Let
GC(C; r) be an algorithm that, given a boolean circuit C and

random coins r, outputs a garbled circuit eC. Let GI(m; r)

be an algorithm that, given an input length m and coins r,
returns 2m input labels:

W =(cid:18) w0

1
w1
1

. . . w0
m
. . . w1

m (cid:19) ,

i and w1

such that w0
i are the labels of 0 and 1, respectively,
for the ith input wire. If x is an m-bit string, we denote by
W|x the label vector (wx1
m ). Let GO(r) be an algo-
rithm that, given coins r, returns two output labels (ω0, ω1)
and let Dec(ω; r) be a decoding algorithm that, given an
output label ω and coins r, returns a bit b. Finally, let

1 , . . . , wxm

Eval(eC, W|x) be an evaluation algorithm that, given a gar-
bled circuit eC and a set of input labels W|x, returns an

output label ω. We require that for all circuits C and all
coins r,

Eval(cid:18)GC(cid:0)C; r(cid:1), W|x(cid:19) = ωf (x),

and (ω0, ω1) := GO(r). For security, we also require in-

and that for b ∈ {0, 1}, Dec(cid:0)ωb; r(cid:1) = b, where W := GI(m; r)
put/output privacy which guarantees that a pair (eC, W|x)

reveal no partial information about x and f (x); and unforge-
ability which guarantees that an incorrect evaluation can be
detected.

Our protocols make use of several standard cryptographic

primitives, including pseudo-random functions, commitments,
secret sharing and symmetric key encryption (see [23] and
references therein for thorough discussion of their security
property and pointers to instantiations). We will denote by
FK (·) a pseudo-random function with key K. Let H(·) be
a one-way function (we use SHA, but we only need its one-
wayness property); Com(m) be a commitment to message m;
and Enc(k, m) be a (deterministic) symmetric encryption of
a message m under a key K. Any standard instantiation of
the above primitives works for us but following previous im-
plementations [52], we use SHA-1 and SHA-256 as pseudo-
random functions and use them to implement all other prim-
itives (see Section 4.1). Share will denote the sharing algo-
rithm of a n-out-of-n secret sharing scheme, i.e., Share(n, x)
outputs n shares (σ1, . . . , σn) of x such that no partial infor-
mation about x can be recovered unless all shares are held.
Throughout, we will assume that sharing is instantiated with
the simple XOR secret sharing scheme which, given an input
i=1 ri ⊕ x), where each
ri is a |x|-bit string chosen uniformly at random. Last, we
denote by [n] the set {1, . . . , n}.

x, returns n shares (r1, . . . , rn−1,Ln−1

3.1 Security Against a Covert Server
Our ﬁrst protocol is fair and secure in the presence of a
covert server which, roughly speaking, means that the server
is dishonest but does not want to get caught. The covert ad-
versarial model was introduced by Aumann and Lindell [2]
and allows for more eﬃcient protocols than the standard
malicious model. Assuming that the server is covert (as op-
posed to fully malicious) seems natural in settings where
there are strong incentives not to cheat. If the server is a
large cloud provider (e.g., Amazon or Microsoft), this as-
sumption is quite reasonable since the provider’s reputation
is at stake. We note that for our protocol, if the communi-

cation between all parties and the server is digitally signed,
the parties can use the transcript as a proof that the server
cheated.

As for fairness, we observe that although it is unachievable
in the standard SFE setting (with a dishonest majority), it
is achievable in the server-aided setting, hence providing a
stronger security guarantee than standard SFE in this re-
spect.

Recall the server-aided setting where a set of parties (P1, . . . ,

Pn) each with a private input and a server S with no input
or output, want to collectively compute a function f over
their private inputs. Let C be a Boolean circuit of size |C|
that evaluates f and let x = (x1, . . . , xm) be a binary string
that represents the joint input of all the parties. Our con-
struction makes use of garbled circuits and a distributed OT
protocol. Next, we provide a high level overview of the pro-
tocol. A detailed description can be found in Figure 1.

Overview. S garbles a small number s1 (e.g., 16) of circuits
and sends them to P1. It then shares the input labels for
all the wires between all the parties (i.e., each party receives
a share of each label of each wire) and sends them some
secret information. Each party Pi communicates with all
the other parties once and uses the secret information it
received from S and the messages exchanged to generate
the label corresponding to his input. This mechanism can
be viewed as a special distributed OT protocol (where the
server plays the role of the sender) that allows each party
Pi to learn the label for its input xi, without the server or
the other parties {Pj }j6=i learning anything about it.

P1 then picks a circuit at random and asks the server to
reveal the randomness it used to construct all the other cir-
cuits. This randomness also includes the coins used for the
secret sharing of the labels. P1 checks that this randomness
is indeed correct and all the parties verify that their shares
are derived from it. Finally, all the parties send their labels
to P1 who evaluates the remaining circuit and returns the
result to all the parties.

Distributed OT. As discussed above, the distributed OT
protocol allows the parties to privately retrieve their labels
from the server, i.e., without the server or the other parties
learning anything about them. We construct such a protocol
based on black-box access to a PRF and without invoking a
standard OT protocol.

The server holds two inputs a0 and a1, and one of the
parties Pj holds a bit b. The distributed OT should let Pj
learn ab without revealing any additional information. The
intuition behind the construction is as follows: the server
secret shares a0 and a1 between all the parties, permuting
each pair of shares randomly. The server sends to Pj the per-
mutations that he used for all the parties. Pj asks for one
share from each party according to the bit b and the random
permutations he receives from the server. Note that the par-
ties do not learn any information about b since they do not
know the random permutations and Pj only learns one of a0
and a1 (assuming that at least one party does not cooperate
with Pj). This solution, however, is not enough since if one
of the shares is wrong, there is no way to determine if it
is the server’s fault or one of the parties. Thus, the server
commits to all the shares and sends those commitments to
the parties. Before requesting a share, Pj checks with the
other parties that they received the same commitments, and
only then proceeds with choosing the share.

802Achieving fairness. Unfortunately, the protocol as de-
scribed above does not provide fairness since P1 can abort
after seeing the output. We ﬁx this by hiding the output
from P1 until all the parties receive the same output label.
Consider a single output wire wi. The output of the garbled
circuit on this wire is a label and its translation to the real
output bit is only known to S. After P1 sends this label to
all the parties, the server sends hashes of the two possible
labels (one for the wire bit 0 and one for wire bit 1) in ran-
dom order. The parties check that the hash of the label they
have is equal to one of those hashes, and if so, they return
an ACK message to S. After all the parties return an ACK,
S sends the two labels to all the parties along with their
mappings to the output value. Now each party can map its
label to a corresponding output bit. One problem that arises
in this protocol is that the server can change the output to
whatever he wants by sending an incorrect mapping. We
solve this by simply asking S to commit to the mappings in
advance and having the parties check those commitments as
part of the randomness revealing stage.

Asymptotic efficiency. Let s be a statistical security pa-
rameters, n the number of parties, and m be the combined
length of all parties’ inputs. With our protocol, S and P1
work in time O(s · |C| + smn) while the other parties work
in time O(sm), where for the speciﬁc values s = 16 (as sug-
gested in [52]) we obtain a complexity of O(16 · |C| + 16mn)
and O(16m), respectively. We emphasize that we only use
inexpensive cryptographic primitives such as hash functions
and commitments.

In the full version of the paper we prove the following

theorem.

Theorem 3.1. The protocol fairly and securely computes
the circuit C in the following two corruption scenarios: (1)
The server is covert (but non-cooperative with respect to
the parties), while all other parties are semi-honest, (2) the
server is semi-honest, while all but one of the parties is ma-
licious (but non-cooperative with respect to the server).

3.2 Security Against a Malicious Server

Our second protocol is secure against a malicious server
and is described in detail in Figure 2. We now provide an
overview.

Overview. In this protocol we assume the parties share
randomness in the beginning. This can be achieved by sim-
ply running a simulatable coin tossing protocol [37, 33].
Such a protocol emulates the usual coin-ﬂipping function-
ality in the presence of arbitrary malicious adversaries and
allows a simulator who controls a single player to control the
outcome of the coin ﬂip.

Here, P1 is the garbler and S is the evaluator. P1 uses
the shared randomness to generate s garbled circuits which
it sends to the server S. To verify the correctness of the
garbling step, S and P1 execute a cut-and-choose protocol.
At the end of the cut-and-choose, S is left with λ circuits,
the majority of which are properly garbled (with high prob-
ability). Then, all the parties send the labels for their input
wires to S (they can compute these labels using the shared
randomness). Since this is done for multiple circuits, we
have to ensure that each party uses the same input in all
the circuits.

1,i| · · · |w0

λ,i(cid:1) and

1,i| · · · |w1

λ,i(cid:1), where wb

Input checking. There are several mechanisms to check
and enforce input consistency [45, 38, 40, 55, 32] but we de-
viate from previous approaches and introduce a new mecha-
nism that is more eﬃcient. In particular, we require that
for each wire i ∈ [m], each party send to S the follow-

ing two hashes permuted at random: H(cid:0)w0
H(cid:0)w1

j,i is the input label for bit b of
the ith wire of the jth circuit (for j ∈ [λ]). The server ver-
iﬁes that the hashes it received from diﬀerent parties are
the same. Assuming that at least one party is honest, this
implies the hash was honestly computed. Then, given the
labels for the ith input wire, S can compute their hash and
verify that the result indeed matches one of the two previ-
ously accepted hashes for the same wire. If the check passes
for all input wires, the server proceeds to the evaluation of
the remaining λ circuits. At the end of the evaluation, S is
left with λ output labels (the results of the λ evaluations).
If the server directly sends these labels to the parties, how-
ever, it will leak additional information to them (as already
pointed out in [32]).

We use a new technique for resolving this issue, that al-
lows the server to output a single value that represents the
majority output without revealing any additional informa-
tion. This new technique is more eﬃcient than the oblivious
cut-and-choose technique of [32].

Asymptotic efficiency. The complexity of the protocol
is as follows: let s be the security parameter (the number of
garbled circuits), λ < s be the number of circuits used for
evaluation, n be the number of parties, and m be the total
length of all the parties’ inputs combined. S and P1 work
in time O(s · |C| + sm) and the other parties work in time
O(λm), where for the speciﬁc values s = 132 and λ = 2s/5
(as suggested in [55]) we get a complexity of O(132 · |C| +
132m) and O(52m), respectively. Again, we stress that we
only use inexpensive cryptographic primitives.

Comparison to oblivious cut-and-choose. The obliv-
ious cut-and-choose technique of [32] (executed between S
and P1) works in time O(s · |C| + s2m) and each party Pi
(for i > 1) works in time O(λ2mi) where mi is the length
of his own input. Hence, the price of checking input consis-
tency is quadratic in the security parameter (alternatively,
using the techniques of [40, 55] this can be done at the cost
of a linear number of exponentiations). In many settings,
the size of the input is not too large, and as such, it is more
eﬃcient to have the parties work in time that is proportional
to the total input size than in time that is quadratic in the
security parameter. Furthermore, our approach can be com-
posed with the oblivious cut-and-choose technique so that
a party Pi can either work in time that is quadratic in the
security parameter (but only linear in his own input length),
or add to the work of all other parties, by having them do
additional work linear to Pi’s input length. We defer the
details of this composition to the full version of the paper.
In the full version of the paper we prove the following

theorem.

Theorem 3.2. The protocol fairly and securely computes
the circuit C in the following two corruption scenarios: (1)
The server is malicious (but non-cooperative with respect to
the parties), while all other parties are semi-honest, (2) the
server is semi-honest, while all but one of the parties is ma-
licious (but non-cooperative with respect to the server).

803Setup and inputs: Each party Pi has an mi-bit input while the server has no input. Let m =Pi∈[n] mi. The server S holds a

secret key K for a pseudo-random function F . s is a statistical security parameter. C is the circuit that computes f .

Distributed OT :

For all ℓ ∈ [s1]:

1. S computes rℓ := FK (ℓ). All the coins used by S for the ℓth circuit will be derived from rℓ,
2. S computes Wℓ := GI(m; rℓ) and for all i ∈ [m], (σ0

n,i) ← Share(n, w0

i ) and (σ1

1,i, . . . , σ0

1,i, . . . , σ1

n,i) ← Share(n, w1

i ),

3. S then samples a n × m binary matrix Pℓ uniformly at random and generates the n × m matrix Sℓ deﬁned as:

Sℓ =



ij(cid:19),

Pℓ
ij , v1−Pℓ

where Pℓ

ij(cid:2)v0, v1(cid:3) def

= (cid:18)v

Pℓ

11(cid:20)σ0
n1(cid:20)σ0

1,1, σ1
.
..
n,1, σ1

1,1(cid:21)
n,1(cid:21)

Pℓ

. . .

. . .

Pℓ

1m(cid:20)σ0
nm(cid:20)σ0

Pℓ

.
..

1,m(cid:21)
n,m(cid:21)




,

1,m, σ1

n,m, σ1

4. S then constructs the n × m matrix Cℓ such that Cℓ

the ath element of the pair stored at location ij of Sℓ,

ij =(cid:18)Com(cid:0)Sℓ

ij [1](cid:1), Com(cid:0)Sℓ

ij[2](cid:1)(cid:19), where Sℓ

ij[a] for a ∈ {1, 2} denotes

5. for all i ∈ [n],

(a) S sends the ith rows of Sℓ and Cℓ and the associated decommitments to Pi,
(b) if the decommitments are invalid Pi accuses S and aborts,
(c) for all j ∈ inp(Pi), S sends the jth column of Pℓ to Pi,

6. S sends to all parties Qℓ

0 := Com(ω0

ℓ ) and Qℓ

1 := Com(ω1

ℓ ), and, H(ω0

ℓ ) and H(ω1

ℓ ) permuted in a random order, where

(ω0

ℓ , ω1
Cut-and-choose :

ℓ ) := GO(rℓ).

1. For all ℓ ∈ [s1], S sends eCℓ := GC(C; rℓ) to P1.

$
← [s1] to S.

2. P1 sends e
3. S sends {ri}i∈[s1]−e to P1 who in turn sends it to all the parties.
4. All parties verify that all the values received from S in the previous steps were constructed properly from the appropriate

randomness. If not, they accuse S and abort.

Input label reconstruction for Pi :

For all j ∈ inp(Pi)

1. for all i′ 6= i:

(a) Pi sends bi′ j := xj ⊕ Pe
i′j [bi′j ] (recall that Pi′ received the i′th row from S in step 5(a) of th distributed OT phase).
(b) Pi′ returns Se
xj
j using the n shares obtained in the previous steps.

i′ j to P ′

2. Pi reconstructs w

i

Commitment consistency check :

For all i ∈ [n], j ∈ inp(Pi) and i′ 6= i:

1. S sends Ce

i′j to Pi,

2. Pi and Pi′ check that they have the same commitments (simply by sending them to each other). If not, they accuse S

and abort. More precisely:
(a) for all j ∈ inp(Pi) ∪ inp(Pi′ ) they check that they both received the same commitments Ce

ij or Ce

i′ j (depending on

who owns wire j),

(b) they check that they received the same Qe

0 and Qe
1,

3. Pi′ sends to Pi decommitments to Ce

i′j [bi′j ]. If any decommitment is invalid, Pi accuses Pi′ and aborts.

Garbled circuit evaluation :

1. All the parties send their input labels for eCe to P1.
2. P1 evalautes eCe and returns the garbled output z to all the parties.

Revealing the output :

1. Each party Pi computes a hash of z and veriﬁes that it matches one of the two hashes H(ω0

e ) and H(ω1

e ) the server

sent earlier. If so, it sends an ACK message to the server.

2. After receiving an ACK messages from all players, S sends the decommitments to Qe

0 and Qe

1 to all parties.

3. Using the decommitments and z, each party can determine the output bit.

Figure 1: Protocol 1 - Covert Server

804Setup and inputs: Each party Pi has an mi-bit input while the server has no input. Let m = Pi |mi|. All the parties share a

secret key K. s and λ are statistical security parameters.

Setup shared randomness :

1. For all ℓ ∈ [s], the players compute rℓ = FK (ℓ) (these will be used to garble s circuits).
2. The players compute γ0 := FK (s + 1) and γ1 := FK (s + 2) (these will be used to decode the ﬁnal output).

Circuit Garbling :

For all ℓ ∈ [s], P1 sends eCℓ := GC(C; rℓ) to S.

Garbled Circuit Veriﬁcation :

1. S picks a set T ⊂ [s] of size s − λ at random, and sends T to P1.
2. P1 sends to rℓ for all ℓ ∈ T , to S.

3. For all ℓ ∈ T , S checks that eCℓ was created using rℓ. If so, it sends rℓ to all the parties who verify that it is equal to

the randomness they computed earlier.

Input label transfer :

Let E = [n] − T be the set of indices of non-veriﬁed circuits. Each party Pi computes Wℓ := GI(m; rℓ) for all ℓ ∈ E. It then
sends all its input labels to S. Denote by wℓ,j the label S receives for the jth input wire of the ℓth circuit.

Input label consistency check :

For j ∈ [m]:

1. All the players send the hash values hw,b = H(wb

ℓ1 ,j| · · · |wb

ℓλ,j) for b ∈ {0, 1} in a random order, where ℓ1, . . . , ℓλ ∈ E.

2. S checks that it receives the same hash values from all the players.
3. S checks that one of the hashes equals H(wℓ1,j | · · · |wℓλ,j ).

Garbled circuit evaluation :

S evaluates the circuits eCℓ for all ℓ ∈ E. Denote the output of eCℓ by zℓ.

Majority output :

For all ℓ ∈ E:

1. each party sends the two ciphertexts Enc(ω0

GO(rℓ),

ℓ , γ0) and Enc(ω1

ℓ , γ1) to S permuted in a random order, where (ω0

ℓ , ω1

ℓ ) :=

2. S checks that the pairs of encryptions it receives from all the players are identical and aborts otherwise,
3. S decrypts the two ciphertexts using zℓ and recovers γℓ and γ′
ℓ.

S sends to all parties the value W that appears the most among the set {γℓ, γ′

ℓ}ℓ∈E.

Output recovery :

Players output the bit b such that γb = W .

Figure 2: Protocol 2 - Malicious Server

3.3 Pipelining with Malicious Garblers

As demonstrated in [29, 42], pipelining the execution of gar-
bled circuits (i.e., garbling and evaluation) can lead to better
running times and less memory consumption. In a pipelined
execution, each gate is garbled and evaluated “on the ﬂy”and
the result of the evaluation is only stored while still needed
for future gates. This results in better running times since
the evaluator can start the evaluation while the garbler is
still garbling the circuit. Furthermore, there is no need to
store the entire garbled circuit (which can be several Giga-
bytes large) at any point during the execution, which leads
to better memory usage.

Unfortunately, the pipelining technique is not applicable
in the malicious setting and particularly when one applies
cut-and-choose techniques. The diﬃculty with pipelning
when one uses cut-and-choose is that for the evaluator to
verify/evaluate a garbled gate he needs to know from the be-
ginning of the execution either the circuit’s randomness (for
veriﬁcation) or the garbler’ s label (for evaluation). How-
ever, if the garbler can determine which circuits will be ver-
iﬁed and which will be evaluated while the execution is oc-
curring then he can easily cheat, e.g., by sending an invalid

garbled circuit for those being evaluated and valid circuits
for those being veriﬁed.

Our solution to this problem is to let the evaluator learn
the required information obliviously in the beginning of the
protocol, without giving it any information. This is done by
executing an OT protocol for each circuit, where the garbler
plays the sender in the OT and has two inputs: (1) the ran-
domness used to garble the circuit; and (2) its input labels
for the circuit. The evaluator plays the receiver in the OT
and decides whether it wants to either learn the randomness
and verify the garbled circuit, or learn the garbler’s labels
and evaluate the circuit. Transforming our protocols to use
this technique is straightforward. For example, for our sec-
ond protocol, we replace the Garbled Circuit Veriﬁcation
and Input Label Transfer stages with the following: for each
ℓ ∈ [s], all players share an input key Kℓ. Before the Circuit
Garbling stage, all players send their inputs to all circuits,
encrypted under the input keys. Then, the above OT is
executed, where P1’s inputs are the pairs (rℓ, Kℓ), and S’s
inputs are its choices in the cut-and-choose. Now, P1 sends
the garbled circuits and S can either evaluate or verify them

805on-the-ﬂy. Last, S reveals its choices and they continue the
rest of the protocol.

While we use this new pipelining technique in the server-
aided setting, the same approach can be used in the standard
SFE setting against malicious adversaries.

4 Evaluation

To evaluate the performance of our protocols we designed
and built a framework on top of which we can implement
any server-aided (and even standard 2SFE) protocol.

4.1 Our Framework

Our framework consists of the following modules:

Circuit generator - Generates a textual representation of
a boolean circuit. The circuit can be speciﬁed using the
FairPlay format [43], or using object-oriented python
code similarly to [29, 42].

Crypto library - Provides implementations of hash func-

tions, pseudo-random functions, commitments and sym-
metric encryption. These are all based on the JAVA
SHA-1 and SHA-256 implementations as suggested in
[52]. It also includes our implementation of the Peik-
ert, Vaikuntanathan and Waters OT protocol [50] built
on top of the JAVA BigInteger package.

Garbled circuit - Given a circuit representation and a PRF
key, it garbles the circuit using randomness generated
by the PRF. Given input labels and a garbled circuit,
it evaluates the circuit and returns the result. Given
a garbled circuit and a key to a PRF, it veriﬁes that
the given circuit was generated properly using that
key. All these functionalities are designed to work in
a pipelined fashion (more details below).

Communication library - Handles communication between

a set of parties, either peer-to-peer or broadcast.

Since the focus of our work is on eﬃciency, we do not
consider the cost of generating circuit representations. Our
design allows us to use any circuit generator, even ones that
generate circuits “on-the-ﬂy” such as [29, 42].

Circuit representation. The particular circuit represen-
tation we use is similar to FairPlay’s format [43] where each
gate has a unique identiﬁer and the circuit is represented by
specifying the identiﬁers of the inputs for each gate. As an
example, the string "354 120 380 AND" represents an AND
gate with identiﬁer 354 that uses inputs from gates 120 and
380. We slightly augment the FairPlay format with infor-
mation that is needed for pipelining the circuits. This is
because during pipelining we have to determine in realtime
whether a gate is needed to evaluate future gates or not
(in which case we can free the memory used for storing its
value).

Pipelining. We now discuss how pipelining is implemented.
Note that the work of garbler is fairly simple and space-
eﬃcient. It goes over the circuit speciﬁcation and, for each
gate, uses the PRF to generate the labels for the input and
output wires of the gate. Similar work is done by the eval-
uator when verifying a circuit.

If, on the other hand, the evaluator evaluates the circuit,
pipelining becomes more diﬃcult since it needs to store in-
termediate values. We can view the pipelining process as a
topological ordering of the gates that minimizes the number
of live gates (i.e., gates that are still needed) in each part of
the ordering. Obviously, the optimal ordering can be pre-
computed during a pre-processing phase so we assume that
the circuit representation is already ordered optimally. Dur-
ing the protocol execution, the evaluator maintains a list of
all live gates. When a gate is not needed anymore, the gar-
bler notiﬁes the evaluator that it can free that gate. As a
result, the evaluator maintains only the required intermedi-
ate values for the rest of the process.

Free XOR. Finally, we mention that we also use the free
XOR technique of Kolesnikov and Schneider [35] that is now
standard in any garbled circuit implementation. This tech-
nique allows us to construct a circuit in such a way that XOR
operations are “free” in the sense that they do not require
any cryptographic operations.

4.2 Experimental Results

We use two circuits in our experiments: (1) a circuit that
given a 128-bit message and a 1408-bit (expanded) key, com-
putes the AES encryption of the message under the key 2;
and (2) a circuit that computes the edit distance of two 50
character strings of 8 bit characters. The size of the AES
circuit is 31512 gates of which 13904 are non-XOR gates.
We generated the edit distance circuit according to the sug-
gestions of [29]. The size of that circuit is 254930 gates,
94472 of which are non-XOR gates.

For our experiments we used two Intel Core 2 Duo 3GHz
machines with 4GB RAM connected through a switched
LAN. The ﬁrst was used for executing the protocol of S,
and the second one for P1 and the rest of the parties. As
suggested in [52] we use a security level of 2−40 for the ma-
licious case and of 2−4 for the covert case.

In Tables 1 we present a summery of our experiments.
These results are with SHA-1 as the underlying hash func-
tion. The use of SHA-256 increases the total time by 5% −
10% and the communication of P2 (and the other weak par-
ties) by 30% on average in the ﬁrst protocol (since the size
of the commitments is aﬀected). We do not include the run-
ning time of the weaker parties since they were signiﬁcantly
smaller than S and P 1 (e.g., 2 seconds for protocol 2 with
AES).

We conclude from the above numbers that: (1) our ﬁrst
protocol requires more communication from the weak parties
which makes it suitable mainly for weak devices that have
high bandwidth; (2) the complexity of our second protocol
is almost independent in the number of parties. The com-
munication and running time of our ﬁrst protocol, however,
increases as the number of parties grows. The main over-
head in both protocols is the communication of the garbled
circuits.

Comparison to previous implementations. There are
many factors that aﬀect performance in practice. For exam-

2AES encryption is currently the standard benchmark for
2SFE implementations. Speciﬁcally, we use the circuit of
[52] in order to correctly compare it with the results of both
[52] and [55]. We remark that any optimization of the AES
circuit itself, e.g. as done in [8], could improve performance
in a similar way.

806ple, size and structure of the circuit, communication latency,
the security parameters, etc. However, the important and
most objective parameters for evaluating any system are the
total running time and the communication time. Thus, we
try to compare our results with previous ones with respect
to these parameters as much as possible 3

As we show in the full version, any secure 2SFE can be
used to achieve the security we require. The question, how-
ever, is whether current 2SFE constructions give us better
performance. The most eﬃcient 2SFE implementation for
semi-honest adversaries is the one of [29], which can securely
compute AES in 0.2s. For the case of a covert adversary, the
best result is 60 seconds [52] (in the random oracle model),
whereas our ﬁrst protocol takes around 9 seconds for 2 par-
ties.

As for the more interesting case of 2SFE secure in the
malicious model, the implementation of [52] runs in 1114
seconds, whereas the best known result is 192 seconds [55].
We note that the latter excludes communication and that
our second protocol is more than four times faster including
communication (which is of similar size to that of [55]).

A diﬀerent but relevant class of protocols is, of course, that
of secure multi -party SFE. In this case, the performance of
current implementations is a step behind that of 2SFE im-
plementations. For example, in the work of [13], one 32-bit
multiplication takes roughly 9ms. Since it is based on arith-
metic circuits, however, it is not clear how to best compare
it to our work. If we multiply its running time by the num-
ber of non-XOR gates of the AES circuit, we get around
125s—which is almost three times slower than our second
protocol. This performance, however, is for four parties with
at most one malicious party, whereas our protocol with four
parties allows up to three malicious parties. Moreover, it is
shown in [13] that as the number of parties grows, the per-
formance per multiplication gate gets worse (e.g., for seven
parties with at most two malicious, it takes 28ms) whereas
the performance of our protocol is almost independent of the
number of parties.

The work of [11] considers secure multi-party computa-
tion with boolean circuits, but only for semi-honest parties.
They do not use the AES benchmark but they show that it
takes roughly 3 − 8 seconds for three parties to evaluate a
circuit with 5500 AND gates. This means that in order to be
faster than our second protocol, a semi-honest-to-malicious
transformation would need to have an multiplicative over-
head smaller than 6. Recall that in the two-party case, the
eﬃciency ratio between semi-honest and malicious security
is more than several hundreds.

Side-channels in pipelined execution. We note that dur-
ing our experiments, we experienced diﬀerent timings for the
processing of the circuits that were evaluated and those that
were veriﬁed. This seems inevitable since the receiver works
harder in case he checks a garbled circuit. Indeed, simple so-
lutions like restricting the receiver to work in constant time
could work, at the cost of eﬃciency. However, clever tech-
niques that parallelize the work on several circuits could be
more eﬃcient. We leave this direction for future work.

3We note that some works try to compare the diﬀerent steps
of the protocols, but we ﬁnd such comparisons to be of little
value.

5 Acknowledgments
We would like to thank Benny Pinkas and Nigel P. Smart
for providing us the AES circuit from [52], and Peeter Laud
for his valuable comments.

6 References

[1] G. Asharov, A. Jain, A. Lopez-Alt, E. Tromer,

V. Vaikuntanathan, and D. Wichs. Multiparty computation
with low communication, computation and interaction via
threshold FHE. In EUROCRYPT, 2012.

[2] Y. Aumann and Y. Lindell. Security against covert

adversaries: Eﬃcient protocols for realistic adversaries. In
TCC, 2007.

[3] B. Barak and O. Goldreich. Universal arguments and their

applications. In CCC, 2002.

[4] A. Ben-David, N. Nisan, and B. Pinkas. Fairplaymp: a

system for secure multi-party computation. In CCS, 2008.

[5] D. Bogdanov, S. Laur, and J. Willemson. Sharemind: A
framework for fast privacy-preserving computations. In
ESORICS, 2008.

[6] P. Bogetoft, D. Christensen, I. Damgard, M. Geisler,
T. Jakobsen, M. Krøigaard, J. Nielsen, J. B. Nielsen,
K. Nielsen, J. Pagter, M. Schwartzbach, and T. Toft.
Secure multiparty computation goes live. In FC, 2009.

[7] P. Bogetoft, I. Damgard, T. P. Jakobsen, K. Nielsen,
J. Pagter, and T. Toft. A practical implementation of
secure auctions based on multiparty integer computation.
In FC, 2006.

[8] J. Boyar and R. Peralta. A small depth-16 circuit for the
aes s-box. In Information Security and Privacy Research,
2012.

[9] R. Canetti. Security and composition of multi-party

cryptographic protocols. Journal of Cryptology, 2000.
[10] D. Chaum, C. Cr´epeau, and I. Damgard. Multiparty

unconditionally secure protocols. In STOC, 1988.

[11] S. G. Choi, K. Hwang, J. Katz, T. Malkin, and

D. Rubenstein. Secure multi-party computation of boolean
circuits with applications to privacy in on-line
marketplaces. In CT-RSA, 2012.

[12] R. Cleve. Limits on the security of coin ﬂips when half the

processors are faulty. In STOC, 1986.

[13] Ivan Damgaard, Martin Geisler, Mikkel Kroigaard, and

Jesper Buus Nielsen. Asynchronous multiparty
computation: Theory and implementation. In PKC, 2009.

[14] I. Damgard, S. Faust, and C. Hazay. Secure two-party
computation with low communication. In TCC, 2012.

[15] I. Damgard, M. Geisler, M. Krøigaard, and J.-B. Nielsen.

Asynchronous multiparty computation: Theory and
implementation. In PKC, 2009.

[16] I. Damgard and Y. Ishai. Constant-round multiparty

computation using a black-box pseudorandom generator. In
CRYPTO, 2005.

[17] I. Damgard, Y. Ishai, M. Krøigaard, J.-B. Nielsen, and
A. Smith. Scalable multiparty computation with nearly
optimal work and resilience. In CRYPTO, 2008.

[18] U. Feige, J. Killian, and M. Naor. A minimal model for

secure computation (extended abstract). In STOC, 1994.
[19] J. Garay, P. MacKenzie, M. Prabhakaran, and K. Yang.

Resource fairness and composability of cryptographic
protocols. TCC, 2006.

[20] R. Gennaro, C. Gentry, and B. Parno. Non-interactive

veriﬁable computing: outsourcing computation to
untrusted workers. In Advances in Cryptology - CRYPTO
’10, volume 6223 of Lecture Notes in Computer Science,
pages 465–482. Springer-Verlag, 2010.

[21] C. Gentry. Fully homomorphic encryption using ideal

lattices. In STOC, 2009.

[22] O. Goldreich. Foundations of Cryptography – Volume 2.

Cambridge University Press, 2004.

807Total Time

Communication Time
P1 / S Communication

P2 Communication

AES

Edit distance

Protocol 1 Protocol 1 Protocol 2 Protocol 2 Protocol 1
2 parties
2 parties

4 parties

4 parties

2 parties

9.12
6.5

14.8
9.5

45
32

46
32

33.5
26

Protocol 2
2 parties

240
185

27777KB
2443KB

27777KB
5539KB

216749KB 216749KB 165918KB 1296319KB

33KB

33KB

862KB

2KB

Table 1: Experimental results. Total time is the sum of communication time and computation time (in
seconds). P1 / S communication is the communication size of the party who communicates the most (either
P1 or S). P2 communication is the communication size of any one of the weaker players.

[23] O. Goldreich. Foundations of Cryptography – Volume 1.

[39] Y. Lindell and B. Pinkas. A proof of security of Yao’s

Cambridge University Press, 2006.

[24] O. Goldreich, S. Micali, and A. Wigderson. How to play

ANY mental game. In STOC, 1987.

[25] D. Gordon, J. Katz, V. Kolesnikov, T. Malkin, M. Raykova,

and Y. Vahlis. Secure computation with sublinear
amortized work. Technical Report 2011/482, IACR ePrint
Cryptography Archive, 2011.

protocol for two-party computation. Journal of Cryptology,
2009.

[40] Y. Lindell and B. Pinkas. Secure two-party computation

via cut-and-choose oblivious transfer. In TCC, 2011.

[41] Y. Lindell, B. Pinkas, and N. Smart. Implementing

two-party computation eﬃciently with security against
malicious adversaries. In SCN, 2008.

[26] S. Gordon and J. Katz. Partial fairness in secure two-party

[42] L. Malka. Vmcrypt: modular software architecture for

computation. EUROCRYPT, 2010.

scalable secure computation. In CCS, 2011.

[27] S. D. Gordon, C. Hazay, J. Katz, and Y. Lindell. Complete

[43] D. Malkhi, N. Nisan, B. Pinkas, and Y. Sella. Fairplay—a

fairness in secure two-party computation. Journal of the
ACM (JACM), 58(6):24, 2011.

secure two-party computation system. In USENIX
Security, 2004.

[28] W. Henecka, S. Kogl, A.-R. Sadeghi, T. Schneider, and

[44] S. Micali and P. Rogaway. Secure computation (abstract).

I. Wehrenberg. TASTY: tool for automating secure
two-party computations. In CCS, 2010.

[29] Y. Huang, D. Evans, J. Katz, and L. Malka. Faster secure
two-party computation using garbled circuits. In USENIX
Security, 2011.

[30] Y. Ishai, J. Kilian, K. Nissim, and E. Petrank. Extending

oblivious transfers eﬃciently. In CRYPTO, 2003.

[31] K. J¨arvinen, V. Kolesnikov, A.-R. Sadeghi, and

T. Schneider. Garbled circuits for leakage-resilience:
hardware implementation and evaluation of one-time
programs. In CHES, 2010.

[32] S. Kamara, P. Mohassel, and M. Raykova. Outsourcing

multi-party comptuation. Technical Report 2011/272,
IACR ePrint Cryptography Archive, 2011.

[33] J. Katz, R. Ostrovsky, and A. Smith. Round eﬃciency of

multi-party computation with a dishonest majority. In
EUROCRYPT, 2003.

[34] M. S. Kiraz and B. Schoenmakers. An eﬃcient protocol for

fair secure two-party computation. In CT-RSA, 2008.

[35] V. Kolesnikov and T. Schneider. Improved garbled circuit:

Free xor gates and applications. In ICALP, 2008.

[36] B. Kreuter, a. shelat, and C.-H. Shen. Towards billion-gate

secure computation with malicious adversaries. Technical
Report 2012/179, IACR ePrint Cryptography Archive,
2012.

[37] Y. Lindell. Parallel coin-tossing and constant-round secure

two-party computation. In CRYPTO, 2001.

[38] Y. Lindell and B. Pinkas. An eﬃcient protocol for secure

two-party computation in the presence of malicious
adversaries. In EUROCRYPT, 2007.

In CRYPTO, 1992.

[45] P. Mohassel and M. Franklin. Eﬃciency tradeoﬀs for

malicious two-party computation. In PKC, 2006.

[46] M. Naor and K. Nissim. Communication preserving

protocols for secure function evaluation. In STOC, 2001.

[47] M. Naor and B. Pinkas. Oblivious transfer and polynomial

evaluation. In STOC, 1999.

[48] M. Naor and B. Pinkas. Eﬃcient oblivious transfer

protocols. In SODA, 2001.

[49] M. Naor, B. Pinkas, and R. Sumner. Privacy preserving

auctions and mechanism design. In EC, 1999.

[50] C. Peikert, V. Vaikuntanathan, and B. Waters. A

framework for eﬃcient and composable oblivious transfer.
In CRYPTO, Berlin, Heidelberg, 2008.

[51] B. Pinkas. Fair secure two-party computation.

EUROCRYPT, 2003.

[52] B. Pinkas, T. Schneider, N. Smart, and S. Williams. Secure
two-party computation is practical. In ASIACRYPT, 2009.

[53] M. Rabin. How to exchange secrets by oblivious transfer.

Technical Report TR-81, Aiken Computation Lab, Harvard
University, 1981.

[54] A. Shamir. How to share a secret. Commun. ACM,

November 1979.

[55] A. Shelat and C. H. Shen. Two-output secure computation

with malicious adversaries. In EUROCRYPT, 2011.

[56] D. Woodruﬀ. Revisiting the eﬃciency of malicious

two-party computation. In EUROCRYPT, 2007.

[57] A. Yao. Protocols for secure computations. In FOCS, 1982.
[58] A. Yao. How to generate and exchange secrets. In FOCS,

1986.

808