Raccoon: Closing Digital Side-Channels through 

Obfuscated Execution

Ashay Rane, Calvin Lin, and Mohit Tiwari, The University of Texas at Austin
https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/rane

This paper is included in the Proceedings of the 24th USENIX Security SymposiumAugust 12–14, 2015 • Washington, D.C.ISBN 978-1-931971-232Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXRaccoon: Closing Digital Side-Channels through Obfuscated Execution

Ashay Rane, Calvin Lin

Department of Computer Science,
The University of Texas at Austin

{ashay,lin} @cs.utexas.edu

Mohit Tiwari

Dept. of Electrical and Computer Engineering

The University of Texas at Austin

tiwari@austin.utexas.edu

Abstract
Side-channel attacks monitor some aspect of a com-
puter system’s behavior to infer the values of secret data.
Numerous side-channels have been exploited, including
those that monitor caches, the branch predictor, and the
memory address bus. This paper presents a method of
defending against a broad class of side-channel attacks,
which we refer to as digital side-channel attacks. The
key idea is to obfuscate the program at the source code
level to provide the illusion that many extraneous pro-
gram paths are executed. This paper describes the techni-
cal issues involved in using this idea to provide conﬁden-
tiality while minimizing execution overhead. We argue
about the correctness and security of our compiler trans-
formations and demonstrate that our transformations are
safe in the context of a modern processor. Our empiri-
cal evaluation shows that our solution is 8.9× faster than
prior work (GhostRider [20]) that speciﬁcally defends
against memory trace-based side-channel attacks.

1

Introduction

It is difﬁcult to keep secrets during program execu-
tion. Even with powerful encryption, the values of secret
variables can be inferred through various side-channels,
which are mechanisms for observing the program’s exe-
cution at the level of the operating system, the instruction
set architecture, or the physical hardware. Side-channel
attacks have been used to break AES [26] and RSA [27]
encryption schemes, to break the Difﬁe-Hellman key ex-
change [15], to ﬁngerprint software libraries [46], and to
reverse-engineer commercial processors [18].

To understand side-channel attacks, consider the pseu-
docode in Figure 1, which is found in old implementa-
tions of both the encryption and decryption steps of RSA,
DSA, and other cryptographic systems.
In this func-
tion, s is the secret key, but because the Taken branch
is computationally more expensive than the Not Taken

if b = 1 then

z ← 1
for bit b in s from left to right do

1: function SQUARE AND MULTIPLY(m,s,n)
2:
3:
4:
5:
6:
7:
8:
9:
10: return z
11: end function

z ← m· z2 mod n
z ← z2 mod n

end if

end for

else

Figure 1: Source code to compute ms mod n.

branch, an adversary who can measure the time it takes
to execute an iteration of the loop can infer whether the
branch was Taken or Not Taken, thereby inferring the
value of s one bit at a time [31, 5]. This particular block
of code has also been attacked using side-channels in-
volving the cache [44], power [16], fault injection [3, 41],
branch predictor [1], electromagnetic radiation [11], and
sound [32].

Over the past ﬁve decades, numerous solutions [20,
30, 21, 42, 35, 22, 40, 14, 43, 37, 39, 38, 23, 45, 25, 34,
9, 33, 10] have been proposed for defending against side-
channel attacks. Unfortunately, these defenses provide
point solutions that leave the program open to other side-
channel attacks. Given the vast number of possible side-
channels, and given the high overhead that comes from
composing multiple solutions, we ideally would ﬁnd a
single solution that simultaneously closes a broad class
of side-channels.

In this paper, we introduce a technique that does just
this, as we focus on the class of digital side-channels,
which we deﬁne as side-channels that carry information
over discrete bits. These side-channels are visible to the
adversary at the level of both the program state and the
instruction set architecture (ISA). Thus, address traces,
cache usage, and data size are examples of digital side-

USENIX Association  

24th USENIX Security Symposium  431

channels, while power draw, electromagnetic radiation,
and heat are not.

Our key insight is that all digital side-channels emerge
from variations in program execution, so while other so-
lutions attempt to hide the symptoms—for example, by
normalizing the number of instructions along two paths
of a branch—we instead attack the root cause by execut-
ing extraneous program paths, which we refer to as de-
coy paths. Intuitively, after obfuscation, the adversary’s
view through any digital side-channel appears the same
as if the program were run many times with different in-
puts. Of course, we must ensure that our system records
the output of only the real path and not the decoy paths,
so our solution uses a transaction-like system to update
memory. On the real paths, each store operation ﬁrst
reads the old value of a memory location before writing
the new value, while the decoy paths read the old value
and write the same old value.

The only distinction between real and decoy paths lies
in the values written to memory: Decoy and real paths
will write different values, but unless an adversary can
break the data encryption, she cannot distinguish decoy
from real paths by monitoring digital side-channels. Our
solution does not defend against non-digital side-channel
attacks, because analog side-channels might reveal the
difference between the encrypted values that are stored.
For example, a decoy path might “increment” some vari-
able x multiple times, and an adversary who can precisely
monitor some non-digital side-channel, such as power-
draw, might be able to detect that the “increments” to x
all write the same value, thereby revealing that the code
belongs to a decoy path.

Nevertheless, our new approach offers several advan-
tages. First, it defends against almost all digital side-
channel attacks.1 Second, it does not require that the
programs themselves be secret, just the data. Third, it
obviates the need for special-purpose hardware. Thus,
standard processor features such as caches, branch pre-
dictors and prefetchers do not need to be disabled. Fi-
nally, in contrast with previous solutions for hiding spe-
ciﬁc side channels, it places few fundamental restrictions
on the set of supported language features.

This paper makes the following contributions:

1. We design a set of mechanisms, embodied in a
system that we call Raccoon,2 that closes digital
side-channels for programs executing on commod-
ity hardware. Raccoon works for both single- and
multi-threaded programs.

1Section 3 (Threat Model) clariﬁes the speciﬁc side-channels closed

by our approach.

2Raccoons are known for their clever ability to break their scent
trails to elude predators. Raccoons introduce spurious paths as they
climb and descend trees, jump into water, and create loops.

2. We evaluate the security aspects of these mecha-
nisms in several ways. First, we argue that the ob-
fuscated data- and control-ﬂows are correct and are
always kept secret. Second, we use information
ﬂows over inference rules to argue that Raccoon’s
own code does not leak information. Third, as an
example of Raccoon’s defense, we show that Rac-
coon protects against a simple but powerful side-
channel attack through the OS interface.

3. We evaluate the performance overhead of Raccoon
and ﬁnd that its overhead is 8.9× smaller than
that of GhostRider, which is the most similar prior
work [20].3 Unlike GhostRider, Raccoon defends
against a broad range of side-channel attacks and
places many fewer restrictions on the programming
language, on the set of applicable compiler opti-
mizations, and on the underlying hardware.

This paper is organized as follows. Section 2 describes
background and related work, and Section 3 describes
our assumed threat model. We then describe our solu-
tion in detail in Section 4 before presenting our security
evaluation and our performance evaluation in Sections 5
and 6, respectively. We discuss the implications of Rac-
coon’s design in Section 7, and we conclude in Section 8.

2 Background and Related Work

Side-channel attacks through the OS, the underlying
hardware, or the processor’s output pins have been a sub-
ject of vigorous research. Formulated as the “conﬁne-
ment problem” by Lampson in 1973 [19], such attacks
have become relevant for cloud infrastructures where the
adversary and victim VMs can be co-resident [29] and
also for settings where adversaries have physical access
to the processor-DRAM interface [46, 22].

Side-Channels through OS and Microarchitecture.
Some application-level information leaks are beyond the
application’s control, for example, an adversary reading
a victim’s secrets through the /proc ﬁlesystem [13], or a
victim’s ﬂoating point registers that are not cleared on a
context switch [2]. In addition to such explicit informa-
tion leaks, implicit ﬂows rely on contention for shared
resources, as observed by Wang and Lee [39] for cache
channels and extended by Hunger et al. [37] to all mi-
croarchitectural channels.

Defenses against such attacks either partition re-
sources [40, 14, 43, 37], add noise [39, 38, 23, 45], or

3GhostRider [20] was evaluated with non-optimized programs exe-
cuting on embedded CPUs, which results in an unrealistically low over-
head (∼10×). Our measurements instead use a modern CPU with an
aggressively optimized binary as the baseline.

432  24th USENIX Security Symposium 

USENIX Association

2

normalize the channel [17, 20] to curb side-channel ca-
pacity. Raccoon’s defenses complement prior work that
modiﬁes the hardware and/or OS. Molnar et al. [25] de-
scribe a transformation that prevents control-ﬂow side-
channel attacks, but their approach does not apply to pro-
grams that contain function calls and it does not protect
against data-ﬂow-based side-channel attacks.

Physical Access Attacks and Secure Processors.
Execute-only Memory (XOM) [36] encrypts portions of
memory to prevent the adversary from reading secret
data or instructions from memory. The AEGIS [35] se-
cure processor provides the notion of tamper-evident ex-
ecution (recognizing integrity violations using a merkle
tree) and tamper-resistant computing (preventing an ad-
versary from learning secret data using memory encryp-
tion). Intel’s Software Guard Extensions (SGX) [24] cre-
ate “enclaves” in memory and limit accesses to these en-
claves. Both XOM and SGX are only partially successful
in prevent the adversary from accessing code because an
adversary can still disassemble the program binary that is
stored on the disk. In contrast, Raccoon permits release
of the transformed code to the adversary. Hence Raccoon
never needs to encrypt code memory.

Oblivious RAM. AEGIS, XOM, and Intel SGX do not
prevent information leakage via memory address traces.
Memory address traces can be protected using Oblivious
RAM, which re-encrypts and re-shufﬂes data after each
memory access. The Path ORAM algorithm [34] is a
tree-based ORAM scheme that adds two secret on-chip
data structures, the stash and position map, to piggyback
multiple writes to the in-memory data structure. While
Raccoon uses a modiﬁed version of the Path ORAM al-
gorithm, the speciﬁc ORAM implementation is orthogo-
nal to the Raccoon design.

The Ascend [9] secure processor encrypts memory
contents and uses the ORAM construct to hide mem-
ory access traces. Similarly, Phantom [22] implements
ORAM to hide memory access traces. Phantom’s mem-
ory controller leverages parallelism in DRAM banks to
reduce overhead of ORAM accesses. However, both
Phantom and Ascend assume that the adversary can only
access code by reading the contents of memory. By con-
trast, Raccoon hides memory access traces via control
ﬂow obfuscation and software ORAM while still permit-
ting the adversary to read the code. Ascend and Phan-
tom rely on custom memory controllers whereas Mem-
ory Trace Oblivious systems that build on Phantom [20]
rely on a new, deterministic processor pipeline. In con-
trast, Raccoon protects off-chip data on commodity hard-
ware.

Memory Trace Obliviousness. GhostRider [20, 21] is
a set of compiler and hardware modiﬁcations that trans-
forms programs to satisfy Memory Trace Obliviousness
(MTO). MTO hides control ﬂow by transforming pro-
grams to ensure that the memory access traces are the
same no matter which control ﬂow path is taken by the
program. GhostRider’s transformation uses a type sys-
tem to check whether the program is ﬁt for transforma-
tion and to identify security-sensitive program values. It
also pads execution paths along both sides of a branch so
that the length of the execution does not reveal the branch
predicate value.

However, unlike Raccoon, GhostRider cannot exe-
cute on generally-available processors and software envi-
ronments because GhostRider makes strict assumptions
about the underlying hardware and the user’s program.
Speciﬁcally, GhostRider (1) requires the use of new in-
structions to load and store data blocks, (2) requires sub-
stantial on-chip storage, (3) disallows the use of dynamic
branch prediction, (4) assumes in-order execution, and
(5) does not permit use of the hardware cache (it instead
uses a scratchpad memory controlled by the compiler).
GhostRider also does not permit the user code to contain
pointers or to contain function calls that use or return
secret information. By contrast, Raccoon runs on SGX-
enabled Intel processors (SGX is required to encrypt val-
ues on the data bus) and permits user programs to contain
pointers, permits the use of possibly unsafe arithmetic
statements, and allows the use of function calls that use
or return secret information.

3 Threat Model and System Guarantees

This section describes our assumptions about the under-
lying hardware and software, along with Raccoon’s ob-
fuscation guarantees.

Hardware Assumptions. We assume that the adver-
sary can monitor and tamper with any digital signals on
the processor’s I/O pins. We also assume that the pro-
cessor is a sealed chip [35], that all off-chip resources
(including DRAM, disks, and network devices) are un-
trusted, that all read and written values are encrypted,
and that the integrity of all reads and writes is checked.

Software Assumptions. We assume that the adversary
can run malicious applications on the same operating
system and/or hardware as the victim’s application. We
allow malicious applications to probe the victim applica-
tion’s run-time statistics exposed by the operating system
(e.g. the stack pointer in /proc/pid/stat). However,
we assume that the operating system is trusted, so Iago
attacks [7] are out of scope.

USENIX Association  

24th USENIX Security Symposium  433

3

The Raccoon design assumes that the input program
is free of errors, i.e. (1) the program does not contain
bugs that will induce application crashes, (2) the pro-
gram does not exhibit undeﬁned behavior, and (3) if
multi-threaded, then the program is data-race free. Un-
der these assumptions, Raccoon does not introduce new
termination-channel leaks, and Raccoon correctly obfus-
cates multi-threaded programs.

Raccoon statically transforms the user code into an ob-
fuscated binary; we assume that the adversary has access
to this transformed binary code and to any symbol table
and debug information that may be present.

In its current implementation, Raccoon does not sup-
port all features of the C99 standard. Speciﬁcally, Rac-
coon cannot obfuscate I/O statements4 and non-local
goto statements. While break and continue statements
do not present a fundamental challenge to Raccoon, our
current implementation does not obfuscate these state-
ments. Raccoon cannot analyze libraries since their
source code is not available when compiling the end-
user’s application.

As with related solutions [30, 20, 21], Raccoon does
not protect information leaks from loop trip counts, since
na¨ıvely obfuscating loop back-edges would create inﬁ-
nite loops. For the same reason, Raccoon does not ob-
fuscate branches that represent terminal cases of recur-
sive function calls. However, to address these issues, it is
possible to adapt complementary techniques designed to
close timing channels [42], which can limit information
leaks from loop trip counts and recursive function calls.
Raccoon includes static analyses that check if the in-
put program contains these unsupported language con-
structs. If such constructs are found in the input program,
the program is rejected.

System Guarantees. Within the constraints listed
above, Raccoon protects against all digital side-channel
attacks. Raccoon guarantees that an adversary monitor-
ing the digital signals of the processor chip cannot dif-
ferentiate between the real path execution and the de-
coy path executions. Even after executing multiple de-
coy program paths, Raccoon guarantees the same ﬁnal
program output as the original program.

Raccoon guarantees that its obfuscation steps will not
introduce new program bugs or crashes, so Raccoon does
not introduce new information leaks over the termination
channel.

Assuming that the original program is race-free, Rac-
coon’s code transformations respect the original pro-
gram’s control and data dependences. Moreover, Rac-
coon’s obfuscation code uses thread-local storage. Thus,

4Various solutions have been proposed that allow limited use of
“transactional” I/O statements through runtime systems [6], operating
systems [28], or the underlying hardware [4].

4

...

1: p ← &a;
2: if secret = true then
3:
4: else
5:
6:
7:
8: end if

...
p ← &b;
∗p ← 10;

(cid:30) Real path.

(cid:30) Decoy path.
(cid:30) Dummy instructions do not update p.
(cid:30) Accesses variable a instead of b!

Figure 2: Illustrating the importance of Property 2. This
code fragment shows how solutions that do not update
memory along decoy paths may leak information. If the
decoy path is not allowed to update memory, then the
dereferenced pointer in line 7 will access a instead of
accessing b, which reveals that the statement was part of
a decoy path.

Raccoon’s obfuscation technique works seamlessly with
multi-threaded applications because it does not introduce
new data dependences.

4 Raccoon Design

This section describes the design and implementation of
Raccoon from the bottom-up. We start by describing the
two critical properties of Raccoon that distinguish it from
other obfuscation techniques. Then, after describing the
key building block upon which higher-level oblivious op-
erations are built, we describe each of Raccoon’s individ-
ual components: (1) a taint analysis that identiﬁes pro-
gram statements that require obfuscation (Section 4.3),
(2) a runtime transaction-like memory mechanism for
buffering intermediate results along decoy paths (Sec-
tion 4.4), (3) a program transformation that obfuscates
control-ﬂow statements (Section 4.5), and (4) a code
transformation that uses software Path ORAM to hide
array accesses that depend on secrets (Section 4.6). We
then describe Raccoon’s program transformations that
ensure crash-free execution (Section 4.7). Finally, we
illustrate with a simple example the synergy among Rac-
coon’s various obfuscation steps (Section 4.8).

4.1 Key Properties of Our Solution
Two key properties of Raccoon distinguish it from other
branch-obfuscating solutions [20, 21, 25, 8]:

• Property 1: Both real and decoy paths execute ac-

tual program instructions.

• Property 2: Both real and decoy paths are allowed

to update memory.

Property 1 produces decoy paths that—from the per-
spective of an adversary monitoring a digital side-
channel—are indistinguishable from from real paths.

434  24th USENIX Security Symposium 

USENIX Association

Without this property, previous solutions can close one
side-channel while leaving other side-channels open. To
understand this point, we refer back to Figure 1 and con-
sider a solution that normalizes execution time along the
two branch paths in the Figure by adding NOP instructions
to the Not Taken path. This solution closes the timing
channel but introduces different instruction counts along
the two branch paths. On the other hand, the addition
of dummy instructions to normalize instruction counts
will likely result in different execution time along the two
branch paths, since (on commodity hardware) the NOP in-
structions will have a different execution latency than the
multiply instruction.

Property 2 is a special case of Property 1, but we in-
clude it because the ability to update memory is critical to
Raccoon’s ability to obfuscate execution. For example,
Figure 2 shows that if the decoy path does not update the
pointer p, then the subsequent decoy statement will up-
date a instead of b, revealing that the assignment to *p
was part of a decoy path.

4.2 Oblivious Store Operation

Raccoon’s key building block is the oblivious store op-
eration, which we implement using the CMOV x86 in-
struction. This instruction accepts a condition code, a
source operand, and a destination operand; if the condi-
tion is true, it moves the source operand to the destina-
tion. When both the source and the destination operands
are in registers, the execution of this instruction does
not reveal information about the branch predicate (hence
the name oblivious store operation).5 As we describe
shortly, many components in Raccoon leverage the obliv-
ious store operation. Figure 3 shows the x86 assembly
code for the CMOV wrapper function.

4.3 Taint Analysis

attribute

Raccoon requires the user to annotate secret variables
construct. With these secret
using the
variables identiﬁed, Raccoon performs inter-procedural
taint analysis to identify branches and data access state-
ments that require obfuscation. Raccoon propagates taint
across both implicit and explicit ﬂow edges. The result of
the taint analysis is a list of memory accesses and branch
statements that must be obfuscated to protect privacy.

5Contrary to the pseudocode describing the CMOV instruction in the
Intel 64 Architecture Software Developer’s Manual, our assembly code
tests reveal that in 64-bit operating mode when the operand size is
16-bit or 32-bit, the instruction resets the upper 32 bits regardless of
whether the predicate is true. Thus the instruction does not leak the
value of the predicate via the upper 32 bits, as one might assume based
on the manual.

01: cmov(uint8_t pred, uint32_t t_val, uint32_t f_val) {
02:
03:
04:
05:
06:
07:
08:
09:
10:
11:
12:
13: }

%2, %0;"
"mov
%1, %1;"
"test
%3, %0;"
"cmovz
%2, %2;"
"test
: "=r" (result)
: "r" (pred), "r" (t_val), "r" (f_val)
: "cc"

uint32_t result;
__asm__ volatile (

);
return result;

Figure 3: CMOV wrapper

4.4 Transaction Management
To support Properties 1 and 2, Raccoon executes each
branch of an obfuscated if-statement in a transaction. In
particular, Raccoon buffers load and store operations
along each path of an if-statement, and Raccoon writes
values along the real path to DRAM using the oblivi-
ous store operation.
If a decoy path tries to write a
value to the DRAM, Raccoon uses the oblivious store
operation to read the existing value and write it back.
At compile time, Raccoon transforms load and store
operations so that they will be serviced from the transac-
tion buffers. Figure 4 shows pseudocode that implements
transactional loads and stores. Loads and stores that ap-
pear in non-obfuscated code do not use the transaction
buffers.

4.5 Control-Flow Obfuscation
To obfuscate control ﬂow, Raccoon forces control ﬂow
along both paths of an obfuscated branch, which re-
quires three key facilities: (1) a method of perturbing
the branch outcome, (2) a method of bringing execu-
tion control back from the end of the if-statement to
the start of the if-statement so that execution can fol-
low along the unexplored path, and (3) a method of en-
suring that memory updates along decoy path(s) do not
alter non-transactional memory. The ﬁrst facility is im-
plemented by the obfuscate() function (which forces
sequential execution of both paths arising out of a con-
ditional branch instruction). Although Raccoon executes
both branch paths, it evaluates the (secret) branch pred-
icate only once. This ensures that the execution of the
ﬁrst path does not unexpectedly change the value of the
branch predicate. The second facility is implemented
by the epilog() function (which transfers control-ﬂow
from the post-dominator of the if-statement to the be-
ginning of the if-statement). Finally the third facility
is implemented using the oblivious store operation de-
scribed earlier. The control-ﬂow obfuscation functions

USENIX Association  

24th USENIX Security Symposium  435

5

// Writes a value to the transaction buffer.
tx_write(address, value) {
if (threaded program)

lock();

// Write to both the transaction buffer
// and to the non-transactional storage.
tls->gl_buffer[address] = value;
*address = cmov(real_idx == instance,

value, *address);

if (threaded program)

unlock();

}

// Fetches a value from the transaction buffer.
tx_read(address) {

if (threaded program)

lock();

value = *address;
if (address in tls->gl_buffer)

value = tls->gl_buffer[address];

value = cmov(real_idx == instance,

*address, value);

if (threaded program)

unlock();

return value;

}

Figure 4: Pseudocode for transaction buffer accesses.
Equality checks are implemented using XOR operation to
prevent the compiler from introducing an explicit branch
instruction.

(obfuscate() and epilog()) use the libc setjmp() and
longjmp() functions to transfer control between pro-
gram points.

Safety of setjmp() and longjmp() Operations. The
use of setjmp() and longjmp() is safe as long as the
runtime system does not destroy the activation record of
the caller of setjmp() prior to calling longjmp(). Thus,
the function that invokes setjmp() should not return un-
til longjmp() is invoked. To work around this limitation,
Raccoon copies the stack contents along with the register
state (identiﬁed by the jmp buff structure) and restores
the stack before calling longjmp(). To avoid perturbing
the stack while manipulating the stack, Raccoon manip-
ulates the stack using C macros and global variables.

As an additional safety requirement, the runtime sys-
tem must not remove the code segment containing the
call to setjmp() from instruction memory before the call
to longjmp(). Because both obfuscate()—which calls
setjmp()—and epilog()—which calls longjmp()—
are present in the same program module, we know that

that the code segment will not vanish before calling
longjmp().

Obfuscating Nested Branches. Nested branches are
obfuscated in Raccoon by maintaining a stack of transac-
tion buffers that mimics the nesting of transactions. Un-
like traditional transactions, transactions in Raccoon are
easier to nest because Raccoon can determine whether
to commit the results or to store them temporarily in
the transaction buffer at the beginning of the transaction
(based on the secret value of the branch predicate).

4.6 Software Path ORAM
Raccoon’s implementation of the Path ORAM algorithm
builds on the oblivious store operation. Since proces-
sors such as the Intel x86 do not have a trusted mem-
ory (other than a handful of registers) for implementing
the stash, we modify the Path ORAM algorithm from
its original form [34]. Raccoon’s Path ORAM imple-
mentation cannot directly index into arrays that represent
the position map or the stash, so Raccoon’s implementa-
tion streams over the position map and stash arrays and
uses the oblivious store operation to selectively read or
update array elements. Raccoon implements both re-
cursive [33] as well as non-recursive versions of Path
ORAM. Our software implementation of Path ORAM
permits ﬂexible sizes for both the stash memory and the
position map.

Section 6.3 compares recursive and non-recursive
ORAM implementations with an implementation that
streams over the entire data array. Raccoon uses AVX
vector intrinsic operations for streaming over data ar-
rays. We ﬁnd that even with large data sizes, it is faster
to stream over the array than perform a single ORAM
access.

4.7 Limiting Termination Channel Leaks
By executing instructions along decoy paths, Raccoon
might operate on incorrect values. For example, consider
the statement if (y != 0) { z = x / y; }. If y = 0 for
a particular execution and if Raccoon executes the decoy
path with y = 0, then the program will crash due to a
division-by-zero error, and the occurrence of this crash
in an otherwise bug-free program would reveal that the
program was executing a decoy path (and, consequently,
that y = 0).

To avoid such situations, Raccoon prevents the pro-
gram from terminating abnormally due to exceptions.
For each integer division that appears in a transaction
(along both real and decoy paths), Raccoon instruments
the operation so that it obliviously (using cmov) replaces

436  24th USENIX Security Symposium 

USENIX Association

6

/* Sample user code. */
01: int array[512] __attribute__((annotate ("secret")));
02: if (array[mid] <= x) {
03:
04: } else {
05:
06: }

l = mid;

r = mid;

/* Transformed pseudocode. */
07: r1 = stream_load(array, mid);
08: r2 = r1 <= x;
09: key = obfuscate(r2, r3);

10: if (r3) {
11:
12: } else {
13:
14: }

tx_write(l, mid);

tx_write(r, mid);

15: epilog(key);

Figure 5: Sample code and transformed pseudocode.

the divisor with a non-zero value. To prevent integer di-
vision overﬂow, Raccoon checks whether the dividend is
equal to INT MIN and whether the divisor is equal to -1;
if so, Raccoon obliviously substitutes the divisor to pre-
vent a division overﬂow. Raccoon also disables ﬂoating
point exceptions using fedisableexcept(). Similarly,
array load and store operations appearing on the de-
coy path are checked (again, obliviously, using cmov) for
out-of-bounds accesses. Thus, to ensure that the execu-
tion of decoy paths does not crash the program, Raccoon
patches unsafe operations. Section 5.3 demonstrates that
this process of patching unsafe operations does not leak
secret information to the adversary.

4.8 Putting It All Together
We now explain how Raccoon transforms the code
shown in Figure 5. Here, the secret annotation informs
Raccoon that the contents of array are secret.

Static taint analysis then reveals that the branch predi-
cate (line 2) depends on the secret value, so Raccoon ob-
fuscates this branch. Similarly, implicit ﬂow edges from
the branch predicate to the two assignment statements (at
lines 3 and 5) indicate that Raccoon should use the obliv-
ious store operation for both assignment statements.

Accordingly, Raccoon replaces direct memory stores
for l and r with function calls that write into trans-
action buffers in lines 11 and 13 of the transformed
pseudocode. The access to array in line 1 is replaced
by an oblivious streaming operation in line 7.
Fi-
nally, the branch in line 2 is obfuscated by inserting
the obfuscate() and epilog() function calls. The
epilog() and obfuscate() function calls are coordi-
nated over the key variable. To prevent the compiler

from deleting or optimizing security-sensitive code sec-
tions, Raccoon marks security-sensitive functions, vari-
ables, and memory access operations as volatile (not
shown in the transformed IR).6

At runtime, the transformed code executes the follow-

ing steps:

1. Line 7 streams over the array and uses ORAM to
load a single element (identiﬁed by mid) of the ar-
ray.

2. Line 8 calculates the actual value of the branch

predicate.

3. The key to this obfuscation lies in the epilog()
function on line 15, which forces the transformed
code to execute twice. The ﬁrst time this function is
called, it transfers control back to line 9. The sec-
ond time this function is called, it simply returns,
and program execution proceeds to other statements
in the user’s code.

4. Line 9 obfuscates the branch outcome. The ﬁrst
time the obfuscate() function returns, it stores 0
in r3, and control is transferred to the statement at
line 13, where the tx write() function call updates
the transaction buffer. Non-transactional memory
is updated only if this path corresponds to the real
path.
The second time the obfuscate() function returns,
it stores 1 in r3, and control is transferred to the
statement at line 11, again calling the tx write()
function to update the transaction buffer. Again,
non-transactional memory is updated only if this
path corresponds to the real path.

5 Security Evaluation

In this section, we ﬁrst demonstrate that the control-ﬂows
and data-ﬂows in obfuscated programs are correct and
that they are independent of the secret value. Then, us-
ing type-rules that track information ﬂows, we argue that
Raccoon’s own code does not leak secret information.
We then illustrate Raccoon’s defenses against termina-
tion channels by reasoning about exceptions in x86 pro-
cessors. Finally, we evaluate Raccoon’s ability to prevent
side-channel attacks via the /proc ﬁlesystem.

5.1 Security of Obfuscated Code
In this section, we argue that the obfuscated control-
ﬂows and data-ﬂows (1) preserve the original program’s
6The C99 standard states that any “any expression referring to [a
volatile object] shall be evaluated strictly according to the rules of the
abstract machine”, and the abstract machine is deﬁned in a manner that
considers that “issues of optimization are irrelevant”.

USENIX Association  

24th USENIX Security Symposium  437

7

dependences and (2) do not reveal any secret informa-
tion. We only describe scalar loads and stores, since
all array-loads and array-stores are obfuscated by simply
streaming over the array. To simplify the explanation,
the following arguments describe a top-level (i.e. a non-
nested) branch. The same arguments can be extended
to nested branches by maintaining a stack of transaction
buffers.

Correctness of Obfuscated Data-Flow. To ensure
correct data-ﬂow, Raccoon uses a combination of trans-
action buffers and non-transactional storage (i.e. main
memory). Raccoon sets up a fresh transaction buffer for
each thread that executes a new path. Figure 4 shows the
implementation of buffered load and store operations
for use with transactions. The store operations along
real paths write to both transaction buffers and non-
transactional storage (since threads cannot share data that
is stored in thread-local transaction buffers).

Consider a non-obfuscated program that stores a value
to a memory location m in line 10 and loads a value from
the same location in line 20. We now consider four pos-
sible arrangements of these two load and store oper-
ations in the obfuscated program, where each operation
may reside either inside or outside a transaction. Our
goal is to ensure that the load operation always reads
the correct value, whether the correct value resides in a
transactional buffer or in non-transactional storage.

• store outside transaction, load inside transac-
tion: This implies that there is no store operation
on m within the transaction. Thus, the transaction
buffer does not contain an entry for m, and the load
operation reads the value from the non-transactional
storage.

• store inside transaction, load inside transac-
tion: Since the transaction has previously written
to m, the transaction buffer contains an entry for m,
and the load operation fetches the value from the
transaction buffer.

• store inside transaction, load outside transac-
tion: This implies that the store operation must
lie along the real path. Real-path execution up-
dates non-transactional storage. Since load opera-
tions outside of transactions always fetch from non-
transactional storage, the load operation reads the
correct value of m.

• store outside transaction, load outside transac-
tion: Raccoon does not change load or store op-
erations that are located outside of the transactions.
Hence the non-obfuscated reaching deﬁnition re-
mains unperturbed.

Raccoon correctly obfuscates multi-threaded code as
well. In programs obfuscated by Raccoon, decoy paths
only update transactional buffers. Thus, only the store
operations on real path affect reaching deﬁnitions of the
obfuscated program. Furthermore, store (or load) op-
erations along real path immediately update (or fetch)
non-transactional storage and do not wait until the trans-
action execution ends. Thus, memory updates from
execution of real paths are immediately visible to all
threads, ensuring that inter-thread dependences are not
masked by transactional execution. Finally, all transac-
tional load and store operations use locks to ensure
that these accesses are atomic. Put together, load and
store operations on real paths are atomic and globally-
visible, whereas store operations on decoy paths are
only locally-visible and get discarded upon transaction
termination. We thus conclude that the obfuscated code
maintains correct data-ﬂows for both single- and multi-
threaded programs.

Concealing Obfuscated Data-Flow. Raccoon always
performs two store operations for every transactional
write operation, regardless of whether the write opera-
tion belongs to a real path or a decoy path. Moreover, by
leveraging the oblivious store operation, Raccoon hides
the speciﬁc value written to the transactional buffer or to
the non-transactional storage. Although the tx read()
function uses an if-statement, the predicate of the if-
statement is not secret, since an adversary can simply
inspect the code and differentiate between repeated and
ﬁrst-time memory accesses. Thus, we conclude that the
data-ﬂows exposed to the adversary do not leak secret
information.

Concealing Obfuscated Control-Flow. Raccoon con-
verts control ﬂow that depends on secret values into static
(i.e. deterministically repeatable) control-ﬂow that does
not depend on secret values. Given a conditional branch
instruction and two branch targets in the LLVM Inter-
mediate Representation (IR), Raccoon always forces ex-
ecution along the ﬁrst target and then the second target.
Thus, the sequence of executed branch targets depends
on the (static) encoding of the branch instruction and not
on the secret predicate.

5.2 Security of Obfuscation Code
Raccoon’s own code should never leak secret informa-
tion, so in this section, we demonstrate the security of the
secret information maintained by Raccoon. Because the
Raccoon code exposes only a handful of APIs (Table 1)
to user applications, we can perform a detailed analysis
of the code’s entry- and exit-points to ensure that these

438  24th USENIX Security Symposium 

USENIX Association

8

T-LOAD

lr(p) =L, A = pts(p),m = max
la(a)
a∈A
(cid:30)x = loadp;c,la,lr(cid:29) → (cid:30)c,la,lr[x (cid:27)→ m](cid:29)

T-STORE

T-BINOP (cid:30)v = binary-op(x,y);c,la,lr(cid:29) → (cid:30)c,la,lr[v (cid:27)→ max(lr(x),lr(y))](cid:29)

T-BRANCH

lr(p) =L, (cid:30)ct;c,la,lr(cid:29) → (cid:30)c,la(cid:26),lr(cid:26)(cid:29),(cid:30)c f ;c,la,lr(cid:29) → (cid:30)c,la(cid:26)(cid:26),lr(cid:26)(cid:26)(cid:29)

(cid:30)branch(p,ct ,c f );c,la,lr(cid:29) → (cid:30)c,M(la(cid:26),la(cid:26)(cid:26)),M(lr(cid:26),lr(cid:26)(cid:26))(cid:29)

T-SKIP (cid:30)v = skip;c,la,lr(cid:29) → (cid:30)c,la,lr(cid:29)

M(l(cid:26),l(cid:26)(cid:26)) =∀ x ∈ {K(l(cid:26)) ∪ K(l(cid:26)(cid:26))} (x, max(l(cid:26)(x),l(cid:26)(cid:26)(x)))

K(l) ={x | (x,s) ∈ l}

lr(p) = L,A = pts(p)

(cid:30)store(x, p);c,la,lr(cid:29) → (cid:30)c,(cid:31)a∈A
T-UNOP (cid:30)v = unary-op(x);c,la,lr(cid:29) → (cid:30)c,la,lr[v (cid:27)→ lr(x)](cid:29)

la[a (cid:27)→ max(la(a),lr(x)),lr](cid:29)

T-CMOV (cid:30)v = cmov(p,t, f );c,la,lr(cid:29) → (cid:30)c,la,lr[v (cid:27)→ L](cid:29)

T-SEQUENCE

(cid:30)c0,la,lr(cid:29) → (cid:30)c0(cid:26),la(cid:26),lr(cid:26)(cid:29)

(cid:30)c0;c1,la,lr(cid:29) → (cid:30)c0(cid:26);c1,la(cid:26),lr(cid:26)(cid:29)

Figure 6: Typing rules and supporting functions that check security of Raccoon’s code.

Category

Control-ﬂow
obfuscation.

Wrapper functions
for unsafe operations.

Registering stack and
array information.
Initialization and
clean-up functions.

Functions
obfuscate(),
epilog().
stream load(),
stream store(),
div wrapper().
reg memory(),
reg stack base().
init handler(),
exit handler().

-

-

Secret info.

Predicate value

Array index,

division operands.

coon passes the secret information through the declassi-
ﬁer (cmov) before executing a load, store, or branch
operation with a secret value. Due to its oblivious na-
ture, the cmov operation resets the security label of its
destination to L.

Table 1: Entry-points of Raccoon’s library.

interfaces never spill secret information outside of Rac-
coon’s own code.

Type System for Tracking Information Flows. Fig-
ure 6 shows a subset of the typing rules used for check-
ing the IR of Raccoon’s own code. These rules express
small-step semantics that track security labels. We as-
sume the existence of a functions lr : ν → γ and la : ∆ → γ
that map LLVM’s virtual registers (ν) and addresses (∆)
to security labels (γ), respectively. Security labels can be
of two types: L represents low-context (or public) infor-
mation, while H represents high-context (or secret) infor-
mation. Secret information listed in Table 1 is assigned
the H security label, while all other information is as-
signed the L security label. We also assume the existence
of a function pts : r → {∆} that returns the points-to set
for a given virtual register r.
Our goal is to ensure that Raccoon does not leak secret
information either through control-ﬂow (branch instruc-
tions) or data-ﬂow (load and store instructions). The
typing rules in Figure 6 verify that information labeled
as secret never appears as an address in a load or store
instruction and never appears as a predicate in a branch
instruction. Otherwise, the typing rules would result in
a stuck transition. To prevent information leaks, Rac-

Security Evaluation of the cmov Operation. The tiny
code size of the cmov operation (Figure 3) permits us to
thoroughly inspect each instruction for possible informa-
tion leaks. We use the Intel 64 Architecture Software De-
veloper’s Manual to understand the side-effects of each
instruction.

Since the code operates on the processor registers
only and never accesses memory, it operates within the
(trusted) boundary of the sealed processor chip. The se-
cret predicate is loaded into the %1 register. The mov in-
struction in line 4 initializes the destination register with
t val. The test instruction at line 5 checks if pred is
zero and updates the Zero ﬂag (ZF), Sign ﬂag (SF), and
the Parity ﬂag (PF) to reﬂect the comparison. The subse-
quent cmovz instruction copies f val into the destination
register only if pred is zero. At this point, ZF, SF, and PF
still contain the results of the comparison. The test in-
struction at line 7 overwrites these ﬂags by comparing
known non-secret values.

Since none of the instructions ever accesses mem-
ory, these instructions can never raise a General Pro-
tection Fault, Page Fault, Stack Exception Fault, Seg-
ment Not Present exception, or Alignment Check excep-
tion. None of these instructions uses the LOCK preﬁx, so
they will never generate an Invalid Opcode (#UD) excep-
tion. As per the Intel Software Developer’s Manual, the
above instructions cannot raise any other exception be-
sides the ones listed above. Through a manual analysis
of the descriptions of 253 performance events7 supported

7Intel 64 and IA-32 Architectures Software Developers Manual,

Section 19.5.

9

USENIX Association  

24th USENIX Security Symposium  439

by our target platform, we discovered that only two
performance events are directly relevant to the code in
Figure 3: PARTIAL RAT STALLS.FLAGS MERGE UOP and
UOPS RETIRED.ALL. The ﬁrst event (FLAGS MERGE UOP),
which counts the number of performance-sensitive ﬂags-
merging micro-operations, produces the same value for
our code, no matter whether the predicate is true or false.
The second event (UOPS RETIRED.ALL) counts the num-
ber of retired micro-operations. Since details of micro-
operation counts for x86 instructions are not publicly
available, we used an unofﬁcial source of instruction ta-
bles8 to verify that the micro-operation count for a cmov
instruction is independent of the instruction’s predicate.
We thus conclude that the code in Figure 3 does not leak
the secret predicate value.

Category
Arithmetic errors

Memory access
interrupts
Debugging interrupts
Privileged operations
Coprocessor (legacy)
interrupts

Other

Interrupt list
Division by zero, invalid operands,
overﬂow, underﬂow, inexact results.
Stack exception fault,
general protection fault, page fault.
Single-step, breakpoint.
Invalid TSS, segment not present.
No coprocessor, coprocessor overrun,
coprocessor error.
Non-maskable interrupt,
invalid opcode, double-fault abort.

Table 2: Categorized list of x86 hardware exceptions.

5.3 Termination Leaks
In Section 4.7, we explained how Raccoon patches divi-
sion operations and memory access instructions to pre-
vent the program from crashing along decoy paths. We
now explain why these patches are sufﬁcient in prevent-
ing the introduction of new termination leaks. Table 2
shows a categorized list of exception conditions arising
in Intel x86 processors9 that may terminate programs.
Among these interrupts, Raccoon transparently handles
arithmetic and memory access interrupts.

Debugging interrupts are irrelevant for the program
safety discussion because they do not cause the program
to terminate. Our threat model does not apply obfus-
cation to OS or kernel code. Since we do not expect
user programs to contain privileged instructions, Rac-
coon does not need to mask interrupts from privileged
operations. Coprocessor interrupts are relevant to Nu-
meric Processor eXtensions (NPX), which are no longer
used today. Non-maskable interrupts are not caused by
software events and thus need not be hidden by Rac-
coon. Branches in Raccoon always jump to the start of
valid basic blocks, so invalid opcodes can never occur in

an obfuscated version of a correct program. A double-
fault exception occurs when the processor encounters an
exception while invoking the handler for a previous ex-
ception. Aborts due to double-fault need not be hidden
by Raccoon because none of the primary exceptions in
an obfuscated program will leak secret information. In
conclusion, Raccoon prevents abnormal program termi-
nation, thus guaranteeing that Raccoon’s execution of de-
coy paths will never cause information leaks over the ter-
mination channel.

5.4 Defense Against Side-Channel Attacks
We have argued in Sections 5.1 and 5.2 that Raccoon
closes digital side-channels. We now show a concrete ex-
ample of a simple but powerful side-channel attack, and
we use basic machine-learning techniques to visually il-
lustrate Raccoon’s defense against this attack. We model
the adversary as a process that observes the instruction
pointer (IP) values of the victim process. Both the vic-
tim process and the adversary process run on the same
machine. The driver process starts the victim process
and immediately pauses the victim process by sending
a SIGSTOP signal. The driver process then starts the
adversary process and sends it the process ID of the
paused victim process. This adversary process polls
for the instruction pointer of the victim process every
5ms via the kstkeip ﬁeld in /proc/pid/stat. When
the victim process ﬁnishes execution, the driver pro-
cess sends a SIGINT signal to the adversary process,
signalling it to save its collection of instruction pointers
to a ﬁle. We run the victim programs with various se-
cret inputs and each run produces a (sampled) trace of
instruction pointers. Each such trace is labelled with the
name of the program and an identiﬁer for the secret in-
put. We collect 300 traces for each label. For the sake
of brevity, we show results for only three programs from
our benchmark suite.

The labelled traces are then passed through a Support
Vector Machine for k-fold cross-validation (we choose
k = 10) using LIBSVM v3.18. Using the prediction data,
we construct a confusion matrix for each program, which
conveys the accuracy of a classiﬁcation system by count-
ing the number of correctly-predicted and mis-predicted
values (see Figure 7). The confusion matrices show that
for the non-secure executions, the classiﬁer is able to la-
bel instruction pointer traces with high accuracy. By con-
trast, when using traces from obfuscated execution, the
classiﬁer’s accuracy is signiﬁcantly lower.

6 Performance Evaluation

8http://www.agner.org/optimize/instruction tables.pdf
9http://www.x86-64.org/documentation/abi.pdf

Methodology. Raccoon is implemented in the LLVM
compiler framework v3.6. In our test setup, the host op-

440  24th USENIX Security Symposium 

USENIX Association

10

Name
Classiﬁer
IP resolver
Medical risk analysis
CRC32
Genetic algorithm
Tax calculator
Radix sort
Binary search
Dijkstra
Find max
Heap add
Heap pop
Histogram
Map
Matrix multiplication

Lines

86
247
92
76
446
350
675
35
50
27
24
42
40
29
28

Data size

5 features, 5 records

3,500 records
3,200 records

10 KB

pop. size = 1 KB

-

256K elements
10K elements

1K edges

1K elements
1K elements
10K elements
1K elements
1K elements

500 x 500 values

Table 3: Benchmark programs used for performance
evaluation of Raccoon. The bottom eight programs are
also used to evaluate GhostRider. The remaining seven
programs cannot be transformed by GhostRider because
these programs use pointers and invoke functions in the
secret context.

stash size is selected at ORAM initialization time and is
set to ORAM block count
or 64 entries, whichever is higher.

100

6.1 Obfuscation Overhead
There are two main sources of Raccoon overhead: (1) the
cost of the ORAM operations (or streaming) and (2) the
cost of control-ﬂow obfuscation (including the cost of
buffering transactional memory accesses,
the cost of
copying program stack and CPU registers, and the cost
of obliviously patching arithmetic and memory access in-
structions). We account for ORAM/streaming overhead
over both real and decoy paths. Of course, the overhead
varies with program characteristics, such as size of the
input data, number of obfuscated statements, and number
of memory access statements. Figure 8 shows the obfus-
cation overhead for the benchmark programs when com-
pared with an aggressively optimized (compiled with
-O3) non-obfuscated binary executable. The geometric
mean of the overhead is ∼16.1×. Applications closer
to the left end of the spectrum had low overheads due
to Raccoon’s ability to leverage existing compiler opti-
mizations (if-conversion, automatic loop unrolling, and
memory to register promotion).
In most applications
with high obfuscation overhead, a majority of the over-
head arises from transactional execution in control-ﬂow
obfuscation.

6.2 Comparison with GhostRider
To place our work in the context of similar solutions
to side-channel defenses, we compare Raccoon with the

Figure 7: Confusion matrices for ip-resolv, find-max
and tax. The top matrices describe original execution.
The bottom matrices describe obfuscated execution.

erating system is CentOS 6.3. To evaluate performance,
we use 15 programs (eight small kernels and seven small
applications). Table 3 summarizes their characteristics
and the associated input data sizes. The bottom eight
programs in the table are the same programs used to eval-
uate GhostRider [20, 21], and we use these to compare
Raccoon’s overhead against that of GhostRider. To sim-
plify the comparison between Raccoon and GhostRider,
we use data sizes that are similar to those used to evaluate
GhostRider [20]. Raccoon uses the
con-
struct to mark secret variables—which mandates that the
input programs are written in C/C++. However the rest of
Raccoon operates entirely on the LLVM IR and does not
use any source-language features. Thus, Raccoon can
easily be ported to work with any language that can be
compiled to the LLVM IR. All tests use the LLVM/Clang
compiler toolchain.

attribute

We run all experiments on a machine with two Intel
Xeon (Sandy Bridge) processors and with 32 GB (8 ×
4 GB) DDR3 memory. Each processor has eight cores
with 256 KB private L2 caches. The eight cores on a
processor chip share a 20 MB L3 cache. Streaming en-
cryption/decryption hardware makes the cost of access-
ing memory from encrypted RAM banks almost the same
as the cost of accessing a DRAM bank. The underlying
hardware does not support encrypted RAM banks, but we
do not separately add any encryption-related overhead to
our measurements because the streaming access cost is
almost the same with or without encryption.
our

simulated
ORAM use the native hardware performance event—
UNHALTED CORE CYCLES. We measure overhead using
clock gettime(). Our software Path ORAM imple-
mentation is conﬁgured with a block size of 64 bytes.
Each node in the Path ORAM tree stores 10 blocks. The

Performance measurements

of

USENIX Association  

24th USENIX Security Symposium  441

11

#1#2#3#4#5#1#2#3#4#5ActualPredictedip−resolv.ascdscrndascdscrndActualPredictedfindmax2k100k500k2k100k500kActualPredictedtax#1#2#3#4#5#1#2#3#4#5ActualPredictedobfs. ip−resolv.ascdscrndascdscrndActualPredictedobfs. findmax2k100k500k2k100k500kActualPredictedobfs. taxORAM/Streaming Obfuscation
Control−Flow Obfuscation

2000

1500

)

X

1000

(
 
d
a
e
h
r
e
v
O

500

GhostRider
Raccoon

1987

1294

1,000

500

]

l

e
a
c
s
−
g
o

l
[
 
)

X

(
 
d
a
e
h
r
e
v
O

100

50

10

5

1

genetic−algo
matrix−mul
heap−add
med−risks
radix−sort
findmax
ip−tree

bin−search
heap−pop
histogram
classifier
dijkstra
crc−32
map

tax

Figure 8: Sources of obfuscation overhead.

GhostRider hardware/software framework [20, 21] that
implements Memory Trace Obliviousness. This section
focuses on the performance aspects of the two systems,
but as mentioned in Section 2, Raccoon provides sig-
niﬁcant beneﬁts over GhostRider beyond performance.
First, Raccoon provides a broad coverage against many
different side-channel attacks. Second, the dynamic ob-
fuscation scheme used in Raccoon strengthens the threat
model, since it allows the transformed code to be re-
leased to the adversary. Third, Raccoon does not require
special-purpose hardware. Finally, since GhostRider
adds instructions to mimic address traces in both branch
paths, it requires that address traces from obfuscated
code be known at compile-time, which signiﬁcantly lim-
its the programs that GhostRider can obfuscate. Rac-
coon relaxes this requirement by executing actual code,
so Raccoon can transform more complex programs than
GhostRider.

Methodology. We now describe our methodology for
simulating the GhostRider solution. As with our Rac-
coon setup, we compare GhostRider’s obfuscated pro-
gram with an aggressively optimized (compiled with
-O3) non-obfuscated version of the same program. Var-
ious compiler optimizations (dead code elimination,
vectorization, constant merging, constant propagation,
global value optimizations, instruction combining, loop-
invariant code motion, and promotion of memory to reg-
isters) interfere with GhostRider’s security guarantees,
so we disable optimizations for the obfuscated program.
We manually apply the transformations implemented in

495

320

152

127

432

46 81 115
heap−pop

histogram

0

map

find−max

dijkstra

112

20

0

26

0

0

matrixmul

heap−add

bin−search

Figure 9: Overhead comparison on GhostRider’s bench-
marks.
Even when we generously underestimate
GhostRider’s overhead, GhostRider sees an average
overhead of 195×, while Raccoon’s overhead is 21.8×.

the GhostRider compiler. We simulate a processor that
is modelled after the GhostRider processor, so we use
a single-issue in-order processor that does not allow
prefetching into the cache.

There are four reasons why our methodology signiﬁ-
cantly underestimates GhostRider’s overhead. The ﬁrst
three reasons stem from our inability to faithfully sim-
ulate all features of the GhostRider processor: (1) We
simulate variable-latency instructions, (2) we simulate
the use of a dynamic branch predictor, and (3) we sim-
ulate a perfect cache for non-ORAM memory accesses.
All three of these discrepancies give GhostRider an un-
realistically fast hardware platform. The fourth reason
arises because our simulator does not support AVX vec-
tor instructions, so we are unable to compare GhostRider
against a machine that can execute AVX vector instruc-
tions.

The non-obfuscated execution uses a 4-issue, out-of-
order core with support for Access Map Pattern Match-
ing prefetching scheme [12] for the L1, L2 and L3 data
caches. In all other respects, the two processor conﬁg-
urations are identical. Both processors are clocked at 1
GHz. The processor conﬁguration closely matches the
conﬁguration described by Fletcher et al. [10], and based
on their measurements, we assume that the latency to all
ORAM banks is 1,488 cycles per cache line. We run
GhostRider’s benchmarks on this modiﬁed Marss86 sim-
ulator and manually add the cost of each ORAM access

442  24th USENIX Security Symposium 

USENIX Association

12

to the total program execution latency.

can be further reduced by using such special purpose
hardware [22].

Performance Comparison. Figure 9 compares the
overhead of GhostRider on the simulated processor and
the overhead of Raccoon. Only those benchmark pro-
grams that meet GhostRider’s assumptions are used in
this comparison. The remaining seven applications can-
not be transformed by the GhostRider solution because
they use pointers or because they invoke functions in the
secret context. We see that Raccoon’s overhead (geo-
metric mean of 16.1× over all 15 benchmarks, geomet-
ric mean of 21.8× over GhostRider-only benchmarks)
is signiﬁcantly lower than GhostRider’s overhead (geo-
metric mean of 195×), even when giving GhostRider’s
processor substantial beneﬁts (perfect caching, lack of
AVX-vector support in the baseline processor, and dy-
namic branch prediction).

6.3 Software Path ORAM
This section considers choices for Raccoon’s ORAM im-
plementation.
In particular, to run on typical general-
purpose processors, we need to modify the Path ORAM
algorithm to assume just a tiny amount of trusted mem-
ory, which forces us to stream the position map and stash
multiple times to obliviously copy or update elements.

We thus consider three possible implementations. The
ﬁrst, recursive ORAM [33], places the position map in
a smaller ORAM until the position map of the smallest
ORAM ﬁts in the CPU registers. The second is a non-
recursive solution that streams over a single large posi-
tion map. The third uses AVX intrinsic operations and
streams over the entire array to access a single element.
Figure 10(a) compares the cost of ORAM initial-
ization for different ORAM sizes in our recursive and
non-recursive ORAM implementations. On this log-log
scale, we see that the non-recursive ORAM is signiﬁ-
cantly faster than the recursive ORAM for all sizes. Fig-
ure 10(b) compares our non-recursive ORAM implemen-
tation against the streaming approach.
In particular, it
measures the cost of accessing a single element and the
cost of 64 single-element random accesses using ORAM
and streaming. We see that the streaming implementa-
tion is orders of magnitude faster than our non-recursive
ORAM.

In summary, our software implementation of Path
ORAM requires non-trivial changes to the original Path
ORAM algorithm. Unfortunately, these changes im-
pose a prohibitively large memory bandwidth require-
ment, making the modiﬁed software Path ORAM far
costlier than streaming over arrays. Raccoon’s obfusca-
tion technique is compatible with the use of dedicated
ORAM memory controllers, and Raccoon’s overhead

7 Discussion

Closing Other Side-Channels. The existing Raccoon
implementation does not defend against kernel-space
side-channel attacks. However, many of Raccoon’s ob-
fuscation principles can be applied to OS kernels as well.
Memory updates in systems such as TxOS [28] can be
made oblivious using Raccoon’s cmov operation. By
contrast, non-digital side-channels appear to be funda-
mentally beyond Raccoon’s scope since physical charac-
teristics (power, temperature, EM radiation) of hardware
devices make it possible to differentiate between real val-
ues and decoy values.

Multi-threaded Programs. Raccoon’s data structures
are stored in thread-local storage (TLS), so Rac-
coon can access internal data structures without us-
ing locks. Raccoon initializes these data-structures at
thread entry-points (identiﬁed by pthread create())
and frees them at thread destruction-points (identiﬁed by
pthread exit()). Raccoon prevents race conditions on
the user program’s memory by using locks where neces-
sary. Most importantly, as long as the user program is
race-free, Raccoon maintains the correct data-ﬂow de-
pendences in both single-threaded and multi-threaded
programs, as described in Section 5.1.

Taint Analysis. Raccoon’s taint analysis is sound but
not complete, so it over-approximates the amount of code
that must be obfuscated. For large programs, this over-
approximation is a signiﬁcant source of overhead. Rac-
coon’s taint analysis is ﬂow-insensitive, path-insensitive,
and context-insensitive, and Raccoon uses a rudimen-
tary alias analysis technique that assumes two pointers
alias if they have the same type. We believe that more
precise static analysis techniques can be used to greatly
shrink Raccoon’s taint graph, thus reducing the obfusca-
tion overhead.

Limitations Imposed by Hardware. Various x86 in-
consume different cycles
structions (DIV, SQRT, etc.)
depending on their operand values.
Such operand-
dependent instruction execution latency introduces the
biggest hurdle in ensuring the security of Raccoon-
obfuscated programs. We also believe that the perfor-
mance overhead of obfuscated programs would be sub-
stantially smaller than the current overhead if processors
came equipped with (small) scratchpad memory. Based
on these conjectures, we plan to explore the impact of
modiﬁed hardware designs in the near future.

USENIX Association  

24th USENIX Security Symposium  443

13

)
s
u
(
 
e
m
T

i

6
0
+
e
1

4
0
+
e
1

2
0
+
e
1

0
0
+
e
1

Recursive ORAM
Non−recursive ORAM

G

G

G

G

0
0
0
0
1

0
0
1

)
s
n
o

i
l
l
i

m

l

(
 
s
e
c
y
c
 
U
P
C

Non−recursive ORAM − 64
Non−recursive ORAM − 1
Stream − 64
Stream − 1

G

G

G

G

G

G

1e+01

G

G

G

1

G

G

G

G

G

1e+03

1e+05

1e+07

1e+01

1e+03

1e+05

1e+07

1e+09

ORAM size (KB)

Data size (elements)

(a) Initialization cost of recursive and non-recursive ORAM implemen-
tation (median of 10 measurements for each sample).

(b) Performance comparison of software Path ORAM and streaming
over the entire array.

Figure 10: Software ORAM performance.

8 Conclusions

In this paper, we have introduced the notion of digital
side-channel attacks, and we have presented a system
named Raccoon to defend against such attacks. We have
evaluated Raccoon’s performance against 15 programs
to show that its overhead is signiﬁcantly less than that
of the best prior work and that it has several additional
beneﬁts: it expands the threat model, it removes special-
purpose hardware, it permits the release of the trans-
formed code to the adversary, and it also expands the set
of supported language features. In comparing Raccoon
against GhostRider, we ﬁnd that Raccoon’s overhead is
8.9× lower.

Raccoon’s obfuscation technique can be enhanced in
several ways. First, while the performance overhead
of Raccoon-obfuscated programs is high enough to pre-
clude immediate practical deployment, we believe that
this overhead can be substantially reduced by employing
deterministic or special-purpose hardware. Second, Rac-
coon’s technique of transactional execution and oblivious
memory update can be applied to the operating system
(OS) kernel, thus paving the way for protection against
OS-based digital side-channel attacks. Finally, in addi-
tion to defending against side-channel attacks, we be-
lieve that Raccoon can be strengthened to defend against
covert-channel communication.

Acknowledgments. We thank our shepherd, David
Evans, and the anonymous reviewers for their helpful
feedback. We also thank Casen Hunger and Akanksha
Jain for their help in using machine learning techniques
and microarchitectural simulators. This work was funded
in part by NSF Grants DRL-1441009 and CNS-1314709
and a gift from Qualcomm.

References
[1] ACIIC¸ MEZ, O., KOC¸ , C. K., AND SEIFERT, J.-P. On the power
of simple branch prediction analysis. In Symposium on Informa-
tion, Computer and Communications Security (2007), pp. 312–
320.

[2] ACIICMEZ, O., AND SEIFERT, J.-P. Cheap Hardware Paral-
lelism Implies Cheap Security. In Workshop on Fault Diagnosis
and Tolerance in Cryptography (2007), pp. 80–91.

[3] BAO, F., DENG, R. H., HAN, Y., A.JENG, NARASIMHALU,
A. D., AND NGAIR, T. Breaking public key cryptosystems on
tamper resistant devices in the presence of transient faults.
In
Workshop on Security Protocols (1998), pp. 115–124.

[4] BLUNDELL, C., LEWIS, E. C., AND MARTIN, M. Unrestricted
transactional memory: Supporting I/O and system calls within
transactions. Tech. rep., University of Pennsylvania, 2006.

[5] BRUMLEY, D., AND BONEH, D. Remote timing attacks are prac-

tical. In USENIX Security Symposium (2005).

[6] CARLSTROM, B. D., MCDONALD, A., CHAFI, H., CHUNG, J.,
MINH, C. C., KOZYRAKIS, C., AND OLUKOTUN, K. The Ato-
mos transactional programming language. In Conference on Pro-
gramming Language Design and Implementation (2006), pp. 1–
13.

[7] CHECKOWAY, S., AND SHACHAM, H. Iago Attacks: Why the
System Call API is a Bad Untrusted RPC Interface. In Architec-

444  24th USENIX Security Symposium 

USENIX Association

14

tural Support for Programming Languages and Operating Sys-
tems (2013), pp. 253–264.

[8] CRANE, S., HOMESCU, A., BRUNTHALER, S., LARSEN, P.,
AND FRANZ, M. Thwarting cache side-channel attacks through
dynamic software diversity. In Network and Distributed System
Security Symposium (2015).

[9] FLETCHER, C. W., DIJK, M. V., AND DEVADAS, S. A Secure
Processor Architecture for Encrypted Computation on Untrusted
Programs.
In ACM Workshop on Scalable Trusted Computing
(2012), pp. 3–8.

[10] FLETCHER, C. W., LING, R., XIANGYAO, Y., VAN DIJK, M.,
KHAN, O., AND DEVADAS, S. Suppressing the oblivious RAM
timing channel while making information leakage and program
efﬁciency trade-offs. In International Symposium on High Per-
formance Computer Architecture (2014), pp. 213–224.

[11] GANDOLFI, K., MOURTEL, C., AND OLIVIER, F. Electromag-
netic analysis: Concrete results. In Cryptographic Hardware and
Embedded Systems (2001), pp. 251–261.

[12] ISHII, Y., INABA, M., AND HIRAKI, K. Access map pattern
matching for high performance data cache prefetch. Journal of
Instruction-Level Parallelism (2011), 499–500.

[13] JANA, S., AND SHMATIKOV, V. Memento: Learning secrets
In IEEE Symposium on Security and

from process footprints.
Privacy (2012), pp. 143–157.

[14] KIM, T., PEINADO, M., AND MAINAR-RUIZ, G. STEALTH-
MEM: system-level protection against cache-based side channel
attacks in the cloud. In USENIX Conference on Security Sympo-
sium (2012), pp. 11–11.

[15] KOCHER, P. C. Timing attacks on implementations of Difﬁe-
Hellman, RSA, DSS, and other systems. In Advances in Cryptol-
ogy (1996), pp. 104–113.

[16] KOCHER, P. C., JAFFE, J., AND JUN, B. Differential Power
Analysis. In Advances in Cryptology. Springer Berlin Heidelberg,
1999, pp. 388–397.

[17] KONG, J., ACIICMEZ, O., SEIFERT, J.-P., AND ZHOU, H.
Hardware-software integrated approaches to defend against soft-
ware cache-based side channel attacks.
In High Performance
Computer Architecture (2009).

[18] KUHN, M. G. Cipher Instruction Search Attack on the Bus-
Encryption Security Microcontroller DS5002FP. IEEE Transac-
tions on Computers 47, 10 (1998), 1153–1157.

[19] LAMPSON, B. W. A note on the conﬁnement problem. Commu-

nications of the ACM (1973), 613–615.

[20] LIU, C., HARRIS, A., MAAS, M., HICKS, M., TIWARI, M.,
AND SHI, E. GhostRider: A Hardware-Software System for
Memory Trace Oblivious Computation.
In Architectural Sup-
port for Programming Languages and Operating Systems (2015),
pp. 87–101.

[21] LIU, C., HICKS, M., AND SHI, E. Memory Trace Oblivious Pro-
gram Execution. In Computer Security Foundations Symposium
(2013), pp. 51–65.

[22] MAAS, M., LOVE, E., STEFANOV, E., TIWARI, M., SHI, E.,
ASANOVIC, K., KUBIATOWICZ, J., AND SONG, D. PHAN-
TOM: Practical Oblivious Computation in a Secure Processor. In
Conference on Computer and Communications Security (2013),
pp. 311–324.

[23] MARTIN, R., DEMME, J., AND SETHUMADHAVAN, S. Time-
rethinking timekeeping and performance monitoring
In International

Warp:
mechanisms to mitigate side-channel attacks.
Symposium on Computer Architecture (2012), pp. 118–129.

[24] MCKEEN, F., ALEXANDROVICH, I., BERENZON, A., ROZAS,
C. V., SHAFI, H., SHANBHOGUE, V., AND SAVAGAONKAR,
U. R. Innovative instructions and software models for isolated
execution. In International Workshop on Hardware and Archi-
tectural Support for Security and Privacy (2013).

[25] MOLNAR, D., PIOTROWSKI, M., SCHULTZ, D., AND WAG-
NER, D. The program counter security model: Automatic de-
tection and removal of control-ﬂow side channel attacks. In In-
formation Security and Cryptology (2006), pp. 156–168.

[26] OSVIK, D. A., SHAMIR, A., AND TROMER, E. Cache attacks
In RSA conference on

and countermeasures: the case of AES.
Topics in Cryptology (2006), pp. 1–20.

[27] PERCIVAL, C. Cache missing for fun and proﬁt.

(2005).

In BSDCan

[28] PORTER, D. E., HOFMANN, O. S., ROSSBACH, C. J., BENN,
A., AND WITCHEL, E. Operating system transactions. In Sym-
posium on Operating Systems Principles (2009), pp. 161–176.

[29] RISTENPART, T., TROMER, E., SHACHAM, H., AND SAVAGE,
S. Hey, You, Get Off of My Cloud: Exploring Information Leak-
age in Third-party Compute Clouds. In Computer and Commu-
nications Security (2009), pp. 199–212.

[30] SABELFELD, A., AND MYERS, A. C.

Language-Based

Information-Flow Security. IEEE JSAC (2003), 5–19.

[31] SCHINDLER, W. A timing attack against RSA with the chinese
remainder theorem. In Cryptographic Hardware and Embedded
Systems (2000), pp. 109–124.

[32] SHAMIR, A., AND TROMER, E. Acoustic cryptanalysis. Online

at http://www.wisdom.weizmann.ac.il/∼tromer.

[33] SHI, E., CHAN, T.-H. H., STEFANOV, E., AND LI, M. Obliv-
ious RAM with O((log n)3) Worst-case Cost.
In International
Conference on The Theory and Application of Cryptology and
Information Security (2011), pp. 197–214.

[34] STEFANOV, E., VAN DIJK, M., SHI, E., FLETCHER, C., REN,
L., YU, X., AND DEVADAS, S. Path ORAM: An Extremely
Simple Oblivious RAM Protocol.
In Conference on Computer
and Communications Security (2013), pp. 299–310.

[35] SUH, G. E., FLETCHER, C., CLARKE, D., GASSEND, B., VAN
DIJK, M., AND DEVADAS, S. Author Retrospective AEGIS: Ar-
chitecture for Tamper-evident and Tamper-resistant Processing.
In International Conference on Supercomputing (2014), pp. 68–
70.

[36] THEKKATH, C., LIE, D., MITCHELL, M., LINCOLN, P.,
BONEH, D., MITCHELL, J., AND HOROWITZ, M. Architec-
tural Support for Copy and Tamper Resistant Software. In Inter-
national Conference on Architectural Support for Programming
Languages and Operating Systems (2000), pp. 168–177.

[37] TIWARI, M., HUNGER, C., AND KAZDAGLI, M. Understand-
ing Microarchitectural Channels and Using Them for Defense. In
International Symposium on High Performance Computer Archi-
tecture (2015), pp. 639–650.

[38] VATTIKONDA, B. C., DAS, S., AND SHACHAM, H. Eliminat-
ing Fine Grained Timers in Xen. In Cloud Computing Security
Workshop (2011), pp. 41–46.

[39] WANG, Z., AND LEE, R. B. New Cache Designs for Thwarting
In International

Software Cache-based Side Channel Attacks.
Symposium on Computer Architecture (2007), pp. 494–505.

[40] WANG, Z., AND LEE, R. B. A novel cache architecture with
enhanced performance and security. In IEEE/ACM International
Symposium on Microarchitecture (2008), pp. 83–93.

[41] YEN, S.-M., AND JOYE, M. Checking before output may not be
enough against fault-based cryptanalysis. IEEE Transactions on
Computers (2000), 967–970.

USENIX Association  

24th USENIX Security Symposium  445

15

[42] ZHANG, D., ASKAROV, A., AND MYERS, A. C. Predictive mit-
igation of timing channels in interactive systems. In Conference
on Computer and Communications Security (2011), pp. 563–574.
[43] ZHANG, Y., JUELS, A., OPREA, A., AND REITER, M. K.
HomeAlone: Co-residency Detection in the Cloud via Side-
Channel Analysis. In IEEE Symposium on Security and Privacy
(2011), pp. 313–328.

[44] ZHANG, Y., JUELS, A., REITER, M. K., AND RISTENPART, T.
Cross-VM side channels and their use to extract private keys. In
Conference on Computer and Communications Security (2012),
pp. 305–316.

[45] ZHANG, Y., AND REITER, M. K. Duppel: Retroﬁtting Com-
modity Operating Systems to Mitigate Cache Side Channels in
the Cloud. In Conference on Computer and Communications Se-
curity (2013), pp. 827–838.

[46] ZHUANG, X., ZHANG, T., AND PANDE, S. HIDE: An Infras-
tructure for Efﬁciently Protecting Information Leakage on the
Address Bus.
In Architectural Support for Programming Lan-
guages and Operating Systems (2004), pp. 72–84.

446  24th USENIX Security Symposium 

USENIX Association

16

