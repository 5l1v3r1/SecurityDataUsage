Losing Control: On the Effectiveness of Control-Flow

Integrity under Stack Attacks

Mauro Conti∗, Stephen Crane‡, Lucas Davi†, Michael Franz‡, Per Larsen‡,

Christopher Liebchen†, Marco Negro†, Mohaned Qunaibit‡, Ahmad-Reza Sadeghi†

†CASED, Technische Universität Darmstadt, Germany

‡University of California, Irvine

∗University of Padua, Italy

Abstract
Adversaries exploit memory corruption vulnerabilities to hi-
jack a program’s control ﬂow and gain arbitrary code ex-
ecution. One promising mitigation, control-ﬂow integrity
(CFI), has been the subject of extensive research in the past
decade. One of the core ﬁndings is that adversaries can con-
struct Turing-complete code-reuse attacks against coarse-
grained CFI policies because they admit control ﬂows that
are not part of the original program. This insight led the
research community to focus on ﬁne-grained CFI implemen-
tations.

In this paper we show how to exploit heap-based vul-
nerabilities to control the stack contents including security-
critical values used to validate control-ﬂow transfers. Our
investigation shows that although program analysis and
compiler-based mitigations reduce stack-based vulnerabili-
ties, stack-based memory corruption remains an open prob-
lem. Using the Chromium web browser we demonstrate
real-world attacks against various CFI implementations:
1) against CFI implementations under Windows 32-bit by
exploiting unprotected context switches, and 2) against
state-of-the-art ﬁne-grained CFI implementations (IFCC
and VTV) in the two premier open-source compilers un-
der Unix-like operating systems. Both 32 and 64-bit x86
CFI checks are vulnerable to stack manipulation. Finally,
we provide an exploit technique against the latest shadow
stack implementation.

Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection

Keywords
stack corruption; control-ﬂow integrity; code-reuse attacks

1. MOTIVATION

Computer systems still run vast amounts of legacy soft-
ware written in unsafe languages such as C and C++. In the

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
c(cid:13) 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813671.

pursuit of eﬃciency and ﬂexibility, languages in the C fam-
ily eschew safety features such as automatic memory man-
agement, strong typing, and overﬂow detection. As a re-
sult, programming errors can lead to memory corruption
and memory disclosure vulnerabilities that are exploited by
attackers—often with severe consequences.

Although defenses such as stack canaries, data execution
prevention (DEP), and address space layout randomization
(ASLR) have raised the bar for attackers, they do not stop
sophisticated exploits against complex software.

Since DEP prevents code injection, code reuse has be-
come a key technique in modern exploits that bypass all
current mitigations. Code-reuse attacks repurpose legiti-
mate instruction sequences (called gadgets) that are present
in program memory to avoid the need for code injection.

Control-ﬂow integrity (CFI) [1, 3], code-pointer integrity
(CPI) [32], and code randomization [33] have emerged as
the most promising improvements over the exploit mitiga-
tions used today. CFI ensures that a program’s control ﬂow
follows a predeﬁned control-ﬂow graph, CPI protects code
pointers from being overwritten, and randomization hides
the code layout.

On one hand, all these approaches improve resilience
against code-reuse attacks. On the other hand, practical
implementations of these techniques must provide an ap-
propriate balance between eﬃciency, security, and compati-
bility with legacy software like browsers, document readers,
and web servers. The need to meet these constraints often
leads to compromises that enable attacks on implementa-
tions of CFI [12, 38, 55, 57, 58], ﬁne-grained code random-
ization [17, 43, 45], and CPI [21].

We focus on CFI implementations because CFI has been
the subject of intensive research in the past decade. More-
over, Microsoft and Google recently added CFI support to
the most popular C/C++ compilers [36, 50].

Goal and contributions. Our main objective concerns
the pitfalls that must be taken into account when imple-
menting ﬁne-grained CFI defenses. We show that failing to
do so leads to vulnerabilities that can be exploited to un-
dermine the formal security properties of CFI [2]. In partic-
ular, we discovered that CFI implementations in two major
compilers—indirect function call checks (IFCC) in LLVM,
and virtual table veriﬁcation (VTV) in GCC [50]—can be
bypassed in a realistic adversary model. In principle, both
CFI schemes provide strong protection, and even resist the
latest code-reuse attack techniques such as COOP (counter-
feit object-oriented programming) [40]. However, the im-

952plemented CFI checks contain weaknesses due to unantici-
pated interactions with optimizations applied by the com-
piler. Since both compilers are the foundation for many
open-source projects, our ﬁndings aﬀect a wide range of ap-
plications.

We also demonstrate a new attack that exploits unpro-
tected context switches (i.e., user-mode return addresses)
between user and kernel mode to bypass any CFI imple-
mentation for Windows on x86 32-bit that does not protect
these context switches. In general, return addresses can be
protected through a shadow stack [16], however, this applies
only to return addresses that are used by the application
and not to those which are used by kernel. By obtaining
control over multiple program threads we can create race
conditions to undermine control-ﬂow checks.

Our exploits contradict the widely held belief that stack
corruption is a solved problem. For instance, both IFCC
and VTV focus on heap-based attacks, like virtual-function
table manipulation, assuming that the program stack and
the return addresses it contains cannot be manipulated due
to randomization and stack canaries [50]. However, this as-
sumption is only valid for most stack-related vulnerabilities
such as the classic stack-based buﬀer overﬂow [4]. We re-
visit this assumption and demonstrate new attacks against
the stack using memory-corruption vulnerabilities that are
unrelated to the stack. We call our combined attacks Stack-
Deﬁler, which not only pose a severe threat to CFI imple-
mentations but also question the security of stack protec-
tions such as StackGuard [13] and StackArmor [11, 13] (see
Section 6.2.1).

In summary, our contributions are as follows:
• Attack on stack-spilled registers. We found that
compiler optimizations spill critical CFI pointers on
the stack. To conﬁrm that the weaknesses we identi-
ﬁed are exploitable in practice, we created a proof-of-
concept implementation to exploit this ﬂaw and bypass
Google’s ﬁne-grained forward-edge CFI implementa-
tion [50]. Both IFCC and VTV suﬀer from this weak-
ness on x86 (32 and 64-bit) systems. To mitigate our
attack, we also developed a patch for IFCC and eval-
uated its eﬃciency.

• Attack on user-mode return addresses on the
stack. We show how to bypass CFI by overwriting
the user-mode return address that is used by the ker-
nel to return from a system call. Our attack requires
no kernel privileges, and is within the threat model of
all CFI schemes, i.e., arbitrary read and write of data
memory in user mode. We present a proof-of-concept
implementation of our attack that uses multi-threading
to bypass CFI implementations on Windows not pro-
tecting the user-mode return address. This attack ap-
plies to operating systems where user-mode return ad-
dresses are pushed on the stack during a system call
(Windows 32-bit).

• Attack on shadow stacks. Shadow stacks are used
in CFI to protect return instructions. However, pro-
tecting shadow stacks is expensive [16, 39] unless they
are protected by hardware, which is not always avail-
able. We show that shadow stacks not protected
by hardware are vulnerable to memory disclosure,
and provide a proof-of-concept implementation of an

exploit against the latest shadow stack implementa-
tion [16].

• Attack the stack from the heap. We present
a new technique to leak the address of the program
stack allowing us to reliably alter stack content. While
there has been some eﬀort to protect the stack (Stack-
Guard [13] and StackArmor [11]), these defenses are
based on the implicit assumption that attacks on the
stack use stack-based vulnerabilities. We demonstrate
stack attacks that are based on heap vulnerabilities,
and hence, undermine this assumption. This has di-
rect impact on defenses that rely on the stack integrity.

2. CODE-REUSE ATTACKS AND CFI

Code-reuse attacks require the target program to contain
memory corruption vulnerabilities such as buﬀer overﬂows
that the adversary can exploit to hijack the control ﬂow and
redirect execution to existing code fragments already avail-
able in an application’s memory space. A prominent attack
technique is return-oriented programming (ROP), which is
based on maliciously combining and executing a chain of
short code sequences of an application [44]. The key ele-
ment is the return instruction which serves as connecting
link for the various code sequences.

One of the most promising defense technique to thwart
code-reuse attacks is control-ﬂow integrity [1, 3]. The main
idea of CFI is to compute an application’s control-ﬂow graph
(CFG) prior to execution, and then monitor its run-time be-
havior to ensure that the control ﬂow follows a legitimate
path in the CFG. The destinations of forward edges of the
CFG (indirect call and jump instructions) are computed dur-
ing a static analysis phase and enforced at runtime, e.g.,
through label checking. The same is possible for backward
edges (return instructions), however, static enforcement can
lead to an exploitable imprecision [9], because one function
can be called by a large number of functions. Therefore, CFI
utilizes a shadow stack [3, 16] which stores the benign return
targets securely on a separate stack and enforces that returns
must target the calling function1. Any deviation from the
CFG leads to the termination of the application. Validating
all indirect control-ﬂow transfers can have a substantial per-
formance impact that prevents widespread deployment. For
instance, when validating forward and backward edges, the
average run time overhead is 21% for the initially proposed
CFI [1] and 13.7% for state-of-the-art solutions (4.0% for
forward [50] and 9.7% for backward edges [16]).

Several CFI frameworks aim at reducing the run-time
overhead by enforcing coarse-grained policies. There is no
clear deﬁnition in the literature with respect to the terms
ﬁne and coarse-grained CFI policy. However, the general
understanding of a ﬁne-grained CFI policy is that only
branches intended by the programmer are allowed. In con-
trast, a coarse-grained CFI policy is more relaxed and might
allow indirect branches to target the start address of any
function. For instance ROPecker [12] and kBouncer [38]
leverage the branch history table of modern x86 proces-
sors to perform a CFI check on a short history of executed
branches. Zhang and Sekar [58] and Zhang et al. [57] ap-
plied coarse-grained CFI policies using binary rewriting to

1In practice this policy is relaxed by allowing the program to
return to any of the active call-sites for compatibility with
exception handling.

953protect COTS binaries. Relaxing the CFI policies (or in-
troducing imprecision to the CFG) has the downside of en-
abling the adversary to launch code-reuse attacks within the
enforced CFG. Consequently, coarse-grained variants of CFI
have been repeatedly bypassed [10, 18, 25, 26]. This impor-
tant insight has recently turned the research focus towards
ﬁne-grained CFI implementations [1, 16, 50]. Particularly,
we consider the implementations of CFI for the LLVM and
GCC compiler by Tice et al. [50], called indirect function call
check (IFCC) and virtual table veriﬁcation (VTV). IFCC
veriﬁes indirect calls by ensuring that the call destination is
within a so-called jump table which contains jump instruc-
tions to valid targets for the indirect call. The set of valid
call-targets is determined at compile time. VTV only pro-
tects virtual function calls. At compile time the compiler
derives the set of valid vTables and inserts checks at every
virtual call site. These checks verify that the virtual table
used for the function call is valid for the current object.

3. THREAT MODEL AND ASSUMPTIONS
Our threat model captures the capabilities of real-world
attacks, and is in line with the common threat model of
CFI [3], as well as with the prior oﬀensive work [20, 40, 43,
45].

Adversarial Capabilities.

• Memory read-write: The target program contains
a memory-corruption vulnerability that allows the ad-
versary to launch a run-time exploit.
In particular,
we focus on vulnerabilities that allow the adversary
to read (information disclosure) and write arbitrary
memory. Such vulnerabilities are highly likely as new
vulnerabilities are being constantly reported. Com-
mon examples are use-after-free errors [49].

• Adversarial Computation: The adversary can per-
form computations at run time. Many modern tar-
gets such as browsers, Flash, Silverlight, and document
viewers, as well as server-side applications and kernels
allow the adversary to perform run-time computations.
Real-world attacks on client-side applications typically
utilize a scripting environment to instantiate and per-
form a run-time exploit. Additionally, the adversary
can use the scripting engine to generate multiple exe-
cution threads.

Defensive Assumptions.

• Non-Executable Memory: The target system en-
forces data execution prevention (DEP) [35]. Oth-
erwise the adversary could directly manipulate code
(e.g., overwriting CFI checks), or inject new malicious
code into the data section of a program. The adversary
is therefore limited to code-reuse attacks.

• Randomization: The target system applies address

space layout randomization (ASLR).

• Shadow Stack: We do not have access to the im-
plementation of shadow stacks [1, 16]. Therefore, we
assume the presence of an adequate shadow stack im-
plementation.

4. STACKDEFILER

Our attacks are based on modifying data on the stack.
Hence, as a ﬁrst step, in the presence of ASLR, we must
disclose the address of the stack. We stress that we do not
rely on stack-based vulnerabilities to attack the stack. In-
stead, we used heap-based vulnerabilities in our exploits. We
observe that an adversary with the ability to disclose arbi-
trary memory can get a stack address by recursively disclos-
ing data pointers (see Section 5.2). Attacking values on the
stack is challenging, because (i) only certain functions will
write critical data to the stack, and (ii) the lifetime of values
on the stack is comparatively short, i.e., generally during the
execution of a function. Nevertheless, we are able to manip-
ulate targeted values on the stack.

In the following we give a high-level description of our
attacks. For this we discuss three diﬀerent stack-corruption
techniques that allow us to bypass the CFI implementations
we examined.
4.1 Corrupting Callee-Saved Registers

To maximize the eﬃciency of a program, the compiler
tries to maximize the use of CPU registers, instead of using
the (slower) main memory. The compiler performs register
allocation to keep track which registers are currently in use
and to which it can assign new values. If all registers are
in use, but a register is required to perform a computation,
the compiler temporarily saves the content of the register
to the stack. When a function (the caller) calls another
function (the callee), the callee cannot determine which of
the caller’s registers are used at the moment of the call.
Therefore, the callee saves all registers it needs to use during
its execution temporarily on the stack. These saved registers
are called callee-saved registers. Before the callee returns to
the caller it restores all callee-saved registers. While the
registers are saved, the adversary can change the values on
the stack and therefore corrupt the callee-saved registers.
This becomes a severe problem if the caller uses the restored
(and potentially corrupted) registers for CFI checks and can
aﬀect all architectures where the application binary interface
(ABI) speciﬁes the concept of callee-saved registers.

We found that two CFI implementations, IFCC and
VTV [50], are vulnerable to this kind of attack. As we will
argue in the following, this threat becomes even more crucial
for applications that are compiled with position-independent
code (PIC) for architectures that do not support program-
counter relative (PC-relative) addressing, such as x86 32-bit.
Position-Independent Code
On Unix-like systems,
including Mac OS X and Linux,
ASLR compatible binaries contain position-independent
code (PIC). Position independence means that all code refer-
ences are relative to the program counter (PC). This allows
the dynamic loader to load the binary at an arbitrary base
address without relocating it.

However, Intel x86 processors running 32-bit code do not
directly support PC-relative addressing. As a workaround,
PIC on x86 requires the program to obtain the current value
(i.e., the absolute address) of the program counter dynami-
cally at run time. Once this address is known, the program
can perform PC-relative references. At assembly level this is
implemented by executing a call to the subsequent instruc-
tion. The call automatically loads the return address onto
the stack, where the return address is simply the absolute

954are enforced through label checking. A shadow stack is used
to verify the backward edges of the CFG. We noticed that
user-mode CFI only instruments user-mode applications and
not the kernel. In general, this makes sense because the ker-
nel isolates itself from user-mode applications, and hence,
is considered trusted. However, we discovered a way to by-
pass CFI without compromising the kernel. In particular,
we exploit the fact that the kernel reads the return address
used to return from a system call to the user mode from the
user-mode stack.

On x86 32-bit a special instruction—sysenter—was in-
troduced to speed up the transition between user and kernel
mode [30]. The sysenter instruction does not save any state
information. Therefore Windows saves the return address to
the user-mode stack before executing sysenter. After ex-
ecuting the system call, the kernel uses the saved return
address to switch back to user mode. This opens a small
window of time between the return address being pushed on
the stack and the kernel reading it to switch back to user
mode. We use a second, concurrent thread that exploits this
window to overwrite the saved return address. Hence, when
returning from a system call the kernel uses the overwrit-
ten address. This allows the adversary to set the instruc-
tion pointer to an arbitrary address and bypass CFI policy
checks.

Note that this attack works within the adversary model
of CFI because we never modify existing code, nor corrupt
the kernel, or tamper with the shadow stack, but we exploit
a missing check of a code pointer that can be controlled by
the adversary.

The 64-bit x86 architecture uses a diﬀerent instruction,
called syscall, to switch from user to kernel mode. This
instruction saves the user-mode return address into a regis-
ter, thus preventing the adversary from changing it. How-
ever, even 64-bit operating systems provide an interface for
sysenter to be compatible with 32-bit applications. Hence,
32-bit applications that are executed in 64-bit operating sys-
tems remain vulnerable. Another pitfall of 64-bit x86 is
that it partially deprecates memory segmentation, hence,
the shadow stack can no longer be completely protected via
hardware.

Hence, the shadow stack can no longer be completely pro-
tected via hardware. As a consequence the protection of the
shadow stack relies on information hiding or less eﬃcient
software-fault isolation techniques.

4.3 Disclosing the Shadow Stack Address

Dang et al. [16] survey the diﬀerent implementations of
shadow stacks and their performance costs. One observation
is that a parallel shadow stack, i.e., a shadow stack located
at a constant oﬀset to the normal stack, provides the best
performance. However, as we demonstrate in Section 5.2
the adversary can leak the address of the normal stack and
therefore compute the address of the shadow stack.

Another shadow stack technique utilizes the thread-local
storage (TLS), a per-thread memory buﬀer usually used to
store thread-speciﬁc variables. In the following we discuss
potential implementation pitfalls of this approach. However,
we have not implemented this attack due to the unavailabil-
ity of implementations in public domain. TLS is addressed
through a segment register. Although segmentation is no
longer available under x86 64-bit, segment registers are still
present and can be used to address memory.
In general,

Figure 1: Application compiled with position-
independent code. To get the absolute address of
str the compiler emits instructions that ﬁrst receive
the absolute address of Function at run time. The
absolute address of str is then calculated by adding
the relative oﬀset between Function and str, calcu-
lated by the compiler, to the absolute address of
Function.

address of the subsequent instruction. Hence, the program
can obtain its current program counter by simply popping
the return address oﬀ the stack in the subsequent instruc-
tion. Once the program counter is loaded into a register, an
oﬀset is added to form the position-independent reference.
Figure 1 illustrates how position-independent code ref-
erences the global string variable str in the data section
(Line 12). At function entry, the function calls get_eip()
(Line 2). This function (Line 9) only reads the return ad-
dress from the stack (Line 10), which is the address of the
instruction following the call of get_eip() (Line 3). Next,
the result is moved into the ebx register (Line 3). We noticed
that both LLVM and GCC primarily use the ebx register to
compute position-independent references (Line 5).

Subsequently, the program can perform PC-relative ad-
dressing to access the global string variable: the add instruc-
tion adds the relative oﬀset between the data section and the
current function to ebx which now holds a pointer to the
data section (Line 4). Finally, the oﬀset of the string within
the data section is added to ebx and the result (address of
the string variable) is saved in the eax register (Line 5).

On x86 32-bit platforms PIC becomes a vulnerability for
CFI, because the global CFI policies are addressed through
the ebx register. Since ebx is a callee-saved register it is
spilled on the stack by all functions that perform CFI checks.
4.2 Corrupting System Call Return Address
Fine-grained CFI as proposed by Abadi et al. [1] validates
the target address of every indirect branch. Valid forward
edges of the CFG are determined using static analysis and

Application1   Function:2     call get_eip3     mov  ebx, eax4     add  ebx, rel_offset_to_data5     lea  eax, [ebx+str_offset]6     [..]7     ret89   get_eip:10    mov eax, [esp] ; read return                      address from                      stack11    retPosition Independent Code12  str:      "this is a String"Datarelativeoﬀsetto data955a TLS-based shadow stack implementation ﬁrst loads the
shadow-stack pointer into a general purpose register. Next,
this register is used to save the return address on the shadow
stack [1, 16]. However, we did not ﬁnd any evidence that the
registers used during this operation are cleared afterwards.
Hence, the address of the shadow stack may be leaked when
a function pushes the used register on the stack. Further,
an application might hold a reference in one of its memory
objects that can be leaked to disclose the memory address
of TLS and the shadow stack.

5. STACKDEFILER IMPLEMENTATION

We now turn our attention to the practical implemen-
tation of the previously described attacks. To prove the
eﬀectiveness of these attacks we start from real-world vul-
nerabilities. For our proof-of-concept implementation of the
attacks we chose the Chromium web browser because it is
available for all common operating systems, and implements
state-of-the-art heap and stack software defenses. We stress
that our attacks also apply to other applications that pro-
vide the adversarial capabilities we outlined in Section 3.
This includes document viewers, Flash, Silverlight, server-
side applications and kernels. We re-introduced an older
software vulnerability (CVE-2014-3176) in the most recent
version of Chromium (v44.0.2396.0)—we did not make any
further changes to the source code.

To prove that stack spilled registers pose a severe threat to
modern, ﬁne-grained forward-edge CFI implementation we
compiled Chromium with IFCC for 32 and 64-bit on Ubuntu
14.04 LTS. We disassembled IFCC and VTV protected ap-
plications to verify that they are vulnerable to stack-spilling
attacks on other operating systems (Unix and Mac OS X)
as well. We implemented our attack against the initial pro-
posed CFI [1] on a fully patched Windows 7 32-bit system.
Since the implementation of the originally proposed CFI [1]
is not available, we assume that ﬁne-grained CFI with a se-
cure shadow stack and construct our attack under the con-
strains given by the paper.

After giving a short introduction to browser exploitation,
we give a detailed description of our proof-of-concept ex-
ploits that bypass existing CFI implementations.
5.1 Attacking a Web Browser

While adversary-controlled JavaScript in browsers is gen-
erally sandboxed by enforcing type and memory safety, the
runtime used to interface the browser and web contents is
not. Performance critical parts of the JavaScript runtime li-
brary are written in lower level, unsafe languages, e.g., C++.
The usage of C++ opens the door for memory-related secu-
rity vulnerabilities. Memory corruption is then used to ma-
nipulate the native representation of website objects, which
cannot be done directly from JavaScript code. Next, we ex-
plain how this can be exploited to read arbitrary memory
and hijack the program control ﬂow.
5.1.1 Information Disclosure
Websites create a variety of objects using the browser’s
scripting engine. These objects are stored consecutively in
memory. For instance, the native representation of an ar-
ray object is usually a C++ object with two ﬁelds:
the
length of the array followed by its starting address, as shown
in Figure 2. A JavaScript program can read the contents of
the array by using the runtime interface provided by the

native C++ object. To ensure memory safety, the native
read function uses the saved array length to ensure that the
JavaScript program does not access memory outside the ar-
rays bounds. By using a memory corruption vulnerability,
the adversary can overwrite the array length in the native
representation of the array object with a larger value, as
shown in Step . This allows the adversary to read the
memory beyond the original array boundaries using normal
JavaScript code (Step ) and disclose the contents of a sub-
sequent C++ object.

Figure 2: The adversary can overwrite the length
ﬁeld of an array object. He uses the native read
function to disclose memory content beyond the ar-
ray buﬀer, e.g., the vTable pointer of a consecutive
object.

vTable Hijacking

5.1.2
To hijack the program’s control ﬂow, the adversary must
overwrite a code pointer holding the destination of an indi-
rect branch instruction. C++ virtual function tables (vTa-
bles) are commonly used for this purpose. The vTable is
used to resolve virtual functions call targets at run time
and contains an array of pointers to virtual functions, along
with other meta-data. The entries of a vTable cannot be
overwritten because they reside in read-only memory. How-
ever, each C++ object that uses virtual functions maintains
a pointer to its corresponding vTable. Since this pointer is
a ﬁeld of the object, it is stored in writable memory. The
adversary can exploit a memory corruption vulnerability to
overwrite the vTable pointer of a C++ object with a pointer
to a fake vTable which he created and injected beforehand.
Instead of the original table of function pointers, all function
pointers in the fake vTable will point to the code the adver-
sary aims to leverage for a code-reuse attack. Lastly, after
overwriting the vTable pointer of an object, the adversary
uses JavaScript interfaces to the native object to invoke a
virtual function from the fake vTable.

Heap   AdversaryArray Object DataLength = 13Buﬀer PointerData Buﬀer of Arrayoverwritewith 37Array Object Coderead(int position)write(int position)callsread(20)if 0 ≤ position < Length:   return buﬀer[position]else:   return errorC++ ObjectvTable Pointerread129565.2 Proof-of-Concept Exploit

Our exploit performs the following steps: (i) Gain arbi-
trary read and write capabilities, (ii) locate the stack and
disclosing its contents, and (iii) bypass the CFI check and
hijack the control ﬂow.

The re-introduced vulnerability (CVE-2014-3176) allows
us to manipulate the data ﬁelds of JavaScript objects on
the heap, such as  in Figure 2. Once an array-like object
has been corrupted, we can access adjacent memory location
without failing a bounds check (see  in Figure 2). In our
exploit, we use the corrupted object to manipulate the buﬀer
pointer ﬁeld of a JavaScript ArrayBuffer instance. By set-
ting the buﬀer pointer to the address we want to access, we
can then read and write arbitrary memory by accessing the
ﬁrst element of the ArrayBuffer via the JavaScript inter-
face. There are many ways to corrupt array-like objects,
hence, our exploit does not depend on a speciﬁc type of vul-
nerability.

Disclosing Data Structures.

Chromium places diﬀerent memory objects in diﬀerent
heaps. For instance, the array instance in Figure 2 is stored
in the object heap while the data buﬀer it contains is in the
buﬀer heap. The use of separate heaps prevents exploit tech-
niques such as heap feng shui [46] which the adversary has
used to co-locate vulnerable buﬀers and C++ objects [51].

However, during the analysis of Chromium’s heap alloca-
tor, we found a way to force the allocator to place the vul-
nerable buﬀer at a constant oﬀset to metadata that is used
by the allocator to manage the diﬀerent heaps. Chromium’s
heap allocator, PartitionAlloc, pre-allocates memory for a
range of diﬀerent buﬀer sizes. However, when memory for a
buﬀer is requested that was not pre-allocated, PartitionAlloc
will request memory from the operating system. Since Parti-
tionAlloc needs to manage the dynamically allocated mem-
ory buﬀers, it requests two additional, consecutive mem-
ory pages from the operating system. The newly requested
memory is organized as follows:

(i) Meta information of allocated memory. This includes a
pointer to the main structures of PartitionAlloc, which
contains all information to manage existing and future
allocations.

(ii) Guard page. This page is mapped as inaccessible,
hence, continuous memory reads/writes will be pre-
vented. However, it does not prevent non-continuous
reads/writes.

(iii) Memory to fulﬁll allocation request. This is the mem-
ory that is used by PartitionAlloc to allocate buﬀers.

By allocating a large buﬀer (e.g., 1MB) which is very un-
likely to happen during normal execution, we ensure that
PartitionAlloc will allocate a new structure as previously
described. We further know that the requested buﬀer will
be placed at the start of (3), because it is the ﬁrst buﬀer of
this size. Since the oﬀset between (i) and (iii) is constant,
we can disclose the pointer to the main meta-data structure
of PartitionAlloc. This allows us to identify all memory ad-
dresses used by the heap allocator, as well as predict which
memory addresses will be used for future allocations.

This is a very powerful technique as we can predict the
memory address of every C++ object that is created. Fur-
ther we can control which objects are created at run time

via the JavaScript interface. Hence, it becomes very hard to
hide information (e.g., a shadow stack address) because as
long as any object contains a pointer to the hidden informa-
tion, we can disclose the information by creating the object
and disclosing its memory.

Finally, in our attack, we choose to allocate an object
that contains a vTable pointer, i.e.
the XMLHttpRequest
object. By overwriting the vTable pointer of this object
with a pointer to a fake vTable, we can hijack the control
ﬂow (see Section 5.1.2).

Disclosing the Stack Address.

To disclose and corrupt values on the stack to bypass CFI
checks, we must ﬁrst locate the stack in memory. In con-
trast to the heap, objects on the stack are only live until the
function that created them returns. Hence, it is challenging
to ﬁnd a pointer to a valid stack address within the heap
area. However, we noticed that Chromium’s JavaScript en-
gine V8 saves a stack pointer to its main structure when a
JavaScript runtime library function is called. Since the Ar-
rayBuffer.read() function, which we use for information
disclosure, is part of the runtime library, we can reliably
read a pointer that points to a predictable location on the
stack. The remaining challenge is to ﬁnd a reference to a V8
object, because V8 objects are placed on a diﬀerent heap
than Chromium’s objects. Hence, we need to ﬁnd a ref-
erence from an object whose address we already disclosed
to the V8 object that stores the stack address. We chose
XMLHttpRequest, because it contains a pointer to a chain of
other objects which eventually contain a pointer to the V8
object. Once we disclose the address of this object, we can
disclose the saved stack pointer.

At this point we have arbitrary read and write access
to the memory and have disclosed all necessary addresses.
Hence, we now focus on implementing the attacks described
in Section 4.

5.2.1 Bypassing IFCC
IFCC implements ﬁne-grained forward-edge CFI and is
vulnerable to attacks that overwrite registers which are
spilled on the stack. For brevity, we omit the bypass of
VTV. However, from a conceptual point of view there is no
diﬀerence between the IFCC bypass and the one for VTV.
Tice et al. [50] assume that the stack is protected by Stack-
Guard [13] which implements a canary for the stack to pre-
vent any stack attacks. In practice, this does not prevent
the adversary from overwriting the return address. Since
IFCC focuses on the protection of CFG forward edges, we
assume an ideal shadow stack to be in place that cannot
be bypassed, though this might be hard to implement in
practice.

IFCC protects indirect function calls by creating, at com-
pile time, a list of functions that can be reached through
indirect calls.
It then creates a trampoline, i.e., a simple
jump instruction to the function, for every function in this
list. The array of all trampolines is called jump table. Fi-
nally, every indirect call is instrumented so it can only target
a valid entry in the jump table.

Listing 1 contains the disassembly of an instrumented call.
In the Line 8 and 9, the target address of the indirect call
and the address of the jump table are loaded into registers.
Subtracting the base address of the target pointer and then
using a logical and is an eﬃcient way of ensuring that an

957;

l o a d a b s . a d d r e s s o f F1

c a l l K i F a s t S y s t e m C a l l

;

;

[ eax+4]
[ ebx−149C8h ]

l o a d a d d r e s s F t a r g e t
l o a d jump−t a b l e

edi ,
eax ,
ecx , edi
ecx , eax ; g e t o f f s e t
ecx , 1FFFF8h ;
ecx , eax ; add b a s e addr jump t a b l e
ecx , edi
c f i
edi

; compare t a r g e t a d d r e s s

; e x e c u t e i n d i r e c t

e n f o r c e bounds

i n jump t a b l e

f a i l u r e

c a l l

; o v e r w r i t e o f ebx happends h e r e

F0 next

F s p i l l

ebx

c a l l

[ . . . ]
c a l l
[ . . . ]

1 F0 :
2
3 F 0 next :
4 pop
5
6
7
8 mov
9 mov
10 mov
sub
11
and
12
add
13
cmp
14
15
jnz
16
c a l l
17
18
19 push ebx
20
21 pop
ret
22

F s p i l l :

[ . . . ]

ebx

Listing 1: Disassembly of an indirect call that is
instrumented by IFCC.

oﬀset within the jump table is used. Finally, this oﬀset is
added again to the base address of the jump table. This en-
sures that every indirect call uses the jump table, unless the
adversary can manipulate the ebx register. As we explained
in Section 4.1 ebx is a callee-saved register and therefore
spilled on the stack during function calls.

For our exploit we target a protected, virtual function
call Ftarget that is invoked (Line 16) after another function
Fspill is called (Line 6), see Listing 1. During the execution
of Fspill the ebx register is spilled on the stack (Line 19):
we overwrite the target address of Ftarget through vTable
injection (see Section 5.1.2) and the saved ebx register. We
overwrite the saved ebx register such that Line 9 will load
the address of our gadget. After Fspill ﬁnishes execution,
the overwritten register is restored and used to verify the
subsequent call in Ftarget. The check will pass and Line 16
will call our ﬁrst gadget. After the initial bypass of CFI, we
use unintended instructions to avoid further CFI checks.

Although 64-bit x86 oﬀers more general purpose registers,
our analysis of a 64-bit, IFCC-protected Chromium version
exposed that around 120, 000 out of 460, 000 indirect calls
CFI checks (around 26%) are vulnerable to our attacks. We
did not manually verify if all of these CFI checks are vul-
nerable. However, for a successful attack it is suﬃcient that
only one of these CFI checks is vulnerable to our attack. We
exploited one vulnerable CFI check to implement a similar
attack and bypass IFCC for the 64-bit version of Chromium.

5.2.2 Bypassing ﬁne-grained CFI
It seems that overwriting a user-mode return address used
by a system call is straightforward. However, we encoun-
tered some challenges during the implementation. The ﬁrst
challenge is being able to correctly time the system call and
the overwrite of the return address. We found the most re-
liable way is to spawn two threads: one thread constantly
makes the system call and the other constantly overwrites
the return address. The attack succeeded in 100% of our
tests without any noticeable time delay.

We can utilize the Web Worker HTML5 API [54] to cre-

; System c a l l number

[ edx ]

c a l l
ret Ch

n t d l l ! ZwWaitForSingleObject :

1
2 mov eax , 1 8 7 h
3 mov edx , o f f s e t Sys te mC al lS tu b
4
5
6
7
8
9

n t d l l ! K i F a s t S y s t e m C a l l :

[ . . . ]

;

10 mov edx , esp
11

s y s e n t e r

Listing 2: ZwWaitForSingleObject System Call on
Windows 7 32-bit.

ate a dedicated victim thread. During our analysis to ﬁnd
a suitable function that eventually invokes a system call, we
noticed that an idle thread is constantly calling the ZwWait-
ForSingleObject system call which is shown in Listing 2.
Line 4 shows the call that pushes the return address on the
stack that is later used by the kernel to return to user mode.
Another challenge is that the constant invocation of the
system call might corrupt any ROP gadget chain we write on
the stack. Hence, we overwrite the user-mode return address
with the address of a gadget which sets the stack pointer to a
stack address that is not constantly overwritten. From there
on we use gadgets that are composed of unintended instruc-
tions [44] to bypass the instrumented calls and returns.

This exploitation technique can bypass any ﬁne-grained
CFI solution that aims to protect 32-bit applications on
Windows.

6. MITIGATIONS

We consider possible mitigation techniques against our at-
tacks. First, we describe our compiler patch for the IFCC/-
VTV implementation vulnerability and measure its perfor-
mance impact on the SPEC CPU2006 benchmarks. Subse-
quently, we discuss the broader problem of protecting the
stack against memory disclosure and corruption attacks.
6.1 Patching IFCC

Recall that IFCC uses the base register containing the
address of the GOT to reference the jump table validating
the target of an indirect call (see Section 4.1). To prevent our
attack presented in Section 5.2.1, we developed a compiler
patch that safely reloads the GOT register before loading
the CFI jump table. Our patch adds new instrumentation
before the CFI check so this register is always re-calculated
instead of being restored from the stack. With our proposed
ﬁx, IFCC uses three more instructions to validate each target
which brings the total number of added instructions up to
15 per indirect call. Listing 3 shows an example of the IFCC
instrumentation without our patch, and Listing 4 shows the
reload we add on lines 12-17.

We measured the performance impact of this change using
the SPEC CPU 2006 benchmark suite on a dual channel
Intel Xeon E5-2660 server running Ubuntu 14.04 with Linux
kernel 3.13.0. We selected only the benchmarks that have
indirect calls since IFCC will not aﬀect code that only uses
direct calls. The benchmark results we report are medians
over three runs using the reference inputs.

We report overheads relative to a baseline without IFCC
enabled. Since IFCC uses link-time optimization, we also
compile the baseline with link-time optimization turned on.

9581
2
3
4
5
6
7

8
9
10
11
12
13
14

1
2
3
4
5
6
7

8
9
10
11
12

13
14
15
16
17
18
19
20
21
22

s t o r e c u r r e n t e i p i n ebx

;
c a l l

. n e x t

. n e x t :

pop ebx
add ebx , GLOBAL OFFSET TABLE
. . .
;

c a l l

f u n c t i o n which s t o r e s ebx t o t h e

s t a c k

. . .
; Load d e s t i n a t i o n f u n c t i o n a d d r e s s
l e a ecx , v t a b l e+i n d e x
; Load jump t a b l e e n t r y r e l a t i v e t o ebx
mov eax ,
<p e r f o r m CFI−check>
c a l l ecx

[ ebx + jump table @GOT ]

Listing 3: Example IFCC assembly before ﬁx

s t o r e c u r r e n t e i p i n ebx

;
c a l l

. n e x t

. n e x t :

pop ebx
add ebx , GLOBAL OFFSET TABLE
. . .
;

c a l l

f u n c t i o n which s t o r e s ebx t o t h e

s t a c k

. . .
; Load d e s t i n a t i o n f u n c t i o n a d d r e s s
l e a ecx , v t a b l e+i n d e x

; PATCH: Reload ebx with c u r r e n t e i p ,

i n s t e a d o f
u n t r u s t e d ,

. n e x t 2

;
c a l l

. n e x t 2 :

c o r r u p t i b l e v a l u e

pop ebx
add ebx , GLOBAL OFFSET TABLE

; Load jump t a b l e e n t r y r e l a t i v e t o ebx
mov eax ,
<p e r f o r m CFI−check>
c a l l ecx

[ ebx + jump table @GOT ]

Listing 4: Example IFCC assembly after ﬁx

Figure 3 shows that our patched version of IFCC performs
between 0.12% and 1.19% slower (0.46% on average) than
unpatched IFCC. Tice et al. [50] also found cases where
IFCC outperforms the baseline, and we did not analyze these
cases further. The patch for the 64-bit version is similar and
was omitted for brevity.

We reported the weaknesses in IFCC and VTV and our
mitigation for IFCC to the original developers of these mit-
igations.

6.2 Securing Stack

It is highly challenging to secure the machine stack against
all types of attacks, since it must be readable and writable by
the program. Similar to other exploit mitigation schemes,
stack protection schemes can be categorized into schemes
that rely on applying randomization to the stack or ensur-
ing the integrity of the stack through isolation. We found
that current stack randomization schemes introduce a lower
performance overhead but remain vulnerable to our attack
as the randomization secret can be disclosed, as we will dis-
cuss in the next section. On the other hand, isolating the
stack can potentially mitigate our attacks. However, current

Figure 3: SPEC CPU2006 performance of IFCC-
protected programs before and after we applied our
ﬁx relative to an unprotected baseline.

stack mitigation techniques are either not eﬀective or suﬀer
from non-negligible performance overheads.

Next, we shortly discuss the eﬀectiveness of these mitiga-

tion schemes under our threat model.
6.2.1 Randomization-based Defenses
StackGuard [13] attempts to prevent stack-based buﬀer
overﬂows by inserting a random stack cookie between po-
tentially vulnerable buﬀers and the return address. How-
ever, this defense is insuﬃcient against current attackers.
An attacker with the capability to read the stack, as we
have demonstrated with our attacks, can read and forge this
cookie, even without an arbitrary memory write vulnerabil-
ity.

The recently proposed StackArmor [11] further protects
the stack not only against buﬀer overﬂows, but also stack
buﬀer over/under reads and stack-based temporal vulnera-
bilities. However, StackArmor’s protections are conﬁned to
the stack itself. Without any heap protection, an attacker
can use heap-memory corruption to read and write arbi-
trary memory locations and can disclose metadata used by
the StackArmor allocator to ﬁnd and modify the stack.
6.2.2
One possible mitigation strategy against our attacks is to

Isolation-based Defenses

isolate the stack from the regular data memory.

Lockdown [39] is a DBI-based (dynamic binary instrumen-
tation) CFI implementation with a shadow stack. DBI re-
writes the binary code of the application at run time, hence,
it can control application memory accesses. This allows it
to prevent access and leakage of the shadow stack address.
However, these security guarantees come with an average
run time overhead of 19% which is considered impractical.
Recently LLVM integrated a component of CPI, called
SafeStack [32, 48].
It aims to isolate critical stack data,
like return addresses or spilled registers from buﬀers that
potentially can be overﬂown. During a static analysis phase

-­‐2%	  0%	  2%	  4%	  6%	  8%	  10%	  12%	  14%	  16%	  astar	  dealII	  namd	  omnetpp	  perlbench	  povray	  soplex	  xalancbmk	  Mean	  IFCC	  IFCC+Fix	  959the compiler identiﬁes buﬀers that are located on the stack
and relocates them to a separate stack, called the unsafe
stack. The regular stack is then assumed to be the safe
stack. The separation of buﬀers and critical values is likely
to prevent most stack-based memory vulnerabilities from
being exploitable. However, if we can leak the stack pointer
register (see Section 5.2), i.e., the pointer to the safe stack,
we can overwrite the protected values.

Full CPI [32] provides more comprehensive protection of
code pointers by isolating them from other memory objects.
On 32-bit x86 the isolation is enforced through segmenta-
tion. In principle this can prevent our attacks, however, on
64-bit x86 or other architectures, e.g., ARM, this feature is
not available. The authors suggest alternative implemen-
tations to the segmentation-based isolation. All come with
their own pros and cons: While the randomization approach
provides good performance, it was shown to be prone to in-
formation leakage attacks [20]. A more secure implementa-
tion is based on software fault isolation (SFI) [52], however,
this adds an additional 7% [42] to the 8% average run-time
overhead induced by CPI itself [32]. In general the overhead
depends on the number of objects that must be protected,
e.g., the authors report of CPI an overhead of 138% for a web
server that serves dynamic webpages, which is impractical.
6.3 Securing CFI Implementations

Zeng et al. [56] compiled a list of requirements to imple-
ment a secure inline-reference monitor, in which they also
mention the danger of stack-spilled variables. However, the
threat of stack-spilled registers was not considered in two
major compiler implementations. Our work proves that reg-
ister spills are a severe threat to CFI, which should be ad-
dress by future implementations.

Ultimately, while stack-oriented defenses help to mitigate
stack vulnerabilities, they do not oﬀer suﬃcient protection
to complex software such as web browsers, where dynamic
code generation, heap vulnerabilities and attacker-controlled
scripting provide many alternative attack vectors to the ad-
versary. Defenders must combine these types of defenses
with other protection against heap-based memory corrup-
tion to be secure.

7. RELATED WORK

Memory disclosure poses a crucial threat to application se-
curity. Previous research on memory disclosure focused on
leaking information about the code layout to bypass code
randomization whereas we focus on data structures to iden-
tify memory locations that contain values that are critical
for the enforcement of CFI.

Many exploit mitigations introduce randomness into the
in-memory representation of applications. Such mitigations
rely on the assumption that the adversary cannot read the
memory. However, in the presence of memory disclosure
vulnerabilities, assuming memory secrecy is neither justiﬁed
nor realistic. We ﬁrst discuss related oﬀensive work on va-
riety of memory disclosure vulnerabilities and bypasses of
ﬁne-grained CFI, and then devote our attention to defensive
works that aim at resisting memory leakage.
7.1 Memory Disclosure Attacks

Bhatkar et al. [7] note that contemporary schemes (ASLR,
StackGuard, PointGuard) are vulnerable if an adversary can
read arbitrary values in memory. Strackx et al. [47] later

demonstrated that memory disclosure through buﬀer over-
read errors allows attackers to bypass ASLR and stack ca-
naries. Roglia et al. [22] then used return-oriented program-
ming to disclose the randomized location of libc.

Observing that ASLR was highly vulnerable to memory
disclosure, researchers argued that ﬁne-grained code ran-
domization solutions would provide suﬃcient resilience [19,
24, 27, 28, 33, 37, 53].

Snow et al. [45] introduced a novel type of memory dis-
closure attacks called just-in-time return-oriented program-
ming (JIT-ROP) that is able to bypass not only ASLR but
ﬁne-grained code randomization as well. JIT-ROP exploits
the design of memory paging in modern systems: it (i) iden-
tiﬁes the page start and end of a leaked function pointer,
(ii) disassembles the code page, and (iii) identiﬁes code ref-
erences on the disassembled page to repeat this process on
other memory pages. Since JIT-ROP attacks must disas-
semble and analyze the disclosed code, it must be launched
against scripting-capable victim applications such as web
browsers or document viewers.

Bittau et al. [8] developed another memory disclosure at-
tack against services that automatically restart after crashes.
This attack exploits the fact that some servers (created us-
ing fork without execve) do not re-randomize after a crash.
By sending such servers a malformed series of requests and
by analyzing whether the requests cause the server to crash,
hang, or respond, the adversary can guess the locations of
the gadgets required to launch a simple ROP attack that
sends the program binary to the remote adversary. Like
JIT-ROP, this attack undermines ﬁne-grained code random-
ization.

Siebert et al. [43] presented a memory disclosure attack
against servers that uses a timing side-channel. By sending a
malformed request to a web server, the adversary can control
a byte pointer that controls the iteration count of a loop.
This creates a correlation between the target of the pointer
and the response time of the request that the adversary can
use to (slowly) scan and disclose the memory layout of the
victim process. In a similar vein, Hund et al. [29] exploit
a timing side-channel to infer the memory of the privileged
ASLR-randomized kernel address space.

Lastly, Evans et al. [20] were able to use memory disclo-
sure to bypass an implementation of the code pointer in-
tegrity (CPI) defense by Kuznetsov et al. [32]. CPI works
by storing control ﬂow and bounds information in a “safe
region” which is separate from non-sensitive data. This pre-
vents control-ﬂow hijacking and spatial memory corruption.
Whereas the 32-bit x86 implementation uses memory seg-
mentation to isolate the safe region, the fastest 64-bit x86
implementation uses information hiding. However, it turns
out that the hidden safe region was suﬃciently large to be
located and parsed using a modiﬁed version of the memory
disclosure attack by Siebert et al. [43]. Kuznetsov et al. also
provide a 64-bit CPI implementation where the safe region
is protected by SFI which has not been bypassed.

7.2 Attacks against ﬁne-grained CFI

Carlini et al [9] provide evidence that static ﬁne-grained
CFI provides insuﬃcient protection, and that a shadow stack
is required to provide precise enforcement of the CFG. Fur-
thermore, they demonstrate that CFI cannot defend against
non-control-data attacks, where the control ﬂow stays within
the boundaries of the enforced CFG but the attacker mod-

960iﬁes variables or function arguments such that the targeted
application behaves maliciously.

CFI is only as eﬀective as the CFG that is derived for the
application.
In Control Jujutsu Evans et al. [21], explore
the limits of the state-of-the-art algorithm [34] that is used
to derive forward edges in the CFG. They found that the
derived CFG contains imprecisions that can be exploited
and allow arbitrary code execution.
7.3 Preventing Memory Disclosure

Backes and N¨urnberger [6] proposed Oxymoron, the ﬁrst
defense that aims at preventing JIT-ROP. Oxymoron pre-
vents the step of the JIT-ROP attack in which it identiﬁes
references to other code pages. Oxymoron does so by mak-
ing all references between code pages opaque using legacy
x86 segmentation features. Davi et al. [17] show that Oxy-
moron can be bypassed in practice since JIT-ROP can be
modiﬁed not to rely on following references between code
pages by harvesting code pointers from C++ virtual tables
instead.

Backes et al. [5] proposed an alternative defense against
JIT-ROP called eXecute-no-Read (XnR). The goal of XnR
is to improve upon DEP under which execute permissions
imply read permissions. To emulate execute permissions
without read permissions, XnR marks all but a small num-
ber of code pages as “not present”. A modiﬁed page fault
handler marks pages as executable (and readable) and si-
multaneously marks the last recently used executable page
as “not present”. As our experiments in Section 8 indicate,
XnR in combination with function permutation does not
provide protection against code-pointer leakage.

The HideM approach by Gionta et al. [23] implements
execute-only memory via “TLB-desynchonization”. This ap-
proach, which relies on pre-2008 hardware, directs read ac-
cesses to a diﬀerent memory page than instruction fetches
by the CPU. This avoids the small window of executable
and readable pages. Nevertheless, HideM does not protect
against code pointer leaks.

The Readactor approach by Crane et al. [14] implements
execute-only memory using the second level address trans-
lation feature in modern processors with support for hard-
ware accelerated virtualization. Redactor introduces code-
pointer hiding, a technique which decouples all code point-
ers in attacker observable memory from the code layout.
For instance, a return pointer does not point into a func-
tion, instead it points to a “return trampoline” which jumps
to the original return address. Because the return tram-
poline is mapped with execute-only permissions, the adver-
sary cannot read the original return address.
In general,
Readactor resists our attacks as it is resilient to code-pointer
leakage. On the other hand, the trampoline addresses are
still allocated on the stack and subject to StackDeﬁler. The
adversary can collect trampoline addresses to identify call-
preceded gadgets. However, it is not yet shown that the col-
lected call-preceded gadgets are suﬃcient to mount a gadget-
stitching attack [10, 18, 25, 26, 41].

8. DISCUSSION

Memory disclosure was previously used to attack code-
randomization schemes [45]. Although attacking code ran-
domization is not the main focus of this paper, it suggests
itself to use stack disclosure against code randomization. In
particular, we investigated the impact of stack disclosure

against mitigation schemes that aim to prevent direct mem-
ory disclosure by marking the code segment as execute-only:
XnR [5] and HideM [23]. We performed some preliminary
experiments in which we used our capabilities to read the
stack of a parallel thread to disclose a large number of return
addresses. Considering that we can control which functions
are executed in the parallel thread, we were able to leak the
addresses of speciﬁc gadgets. The results of our experiments
are that indirect code disclosure via return addresses can be
used to bypass ﬁne-grained code-randomization. In particu-
lar, we can bypass function permutation [31] or basic-block
permutation [53] even when XnR or HideM are in place to
protect against memory disclosure. Readactor by Crane et
al. [14] performs code-pointer hiding and is not vulnerable to
return address leakage. Further, the authors extended their
work to protect function tables [15] which prevents vTable
hijacking as described in Section 5.1.2.

9. CONCLUSION

We present StackDeﬁler a set of stack corruption attacks
that we use to bypass CFI implementations. Our novel at-
tack techniques corrupt the stack without the need for stack-
based vulnerabilities. This contradicts the widely held belief
that stack corruption is a solved problem. To the best of our
knowledge, this paper presents the ﬁrst comprehensive study
of stack-based memory disclosure and possible mitigations.
Surprisingly, we ﬁnd that ﬁne-grained CFI implementa-
tions for the two premier open-source compilers (used to
protect browsers), LLVM and GCC, are not safe from at-
tacks against our stack attacks. IFCC spills critical pointers
to the stack which we can exploit to bypass CFI checks.
We veriﬁed that a similar vulnerability exists in VTV—a
completely separate implementation of ﬁne-grained CFI in a
separate compiler. Next, we demonstrated that unprotected
context switches between the user and kernel mode can lead
to a bypass of CFI. Further, we show the challenges of im-
plementing a secure and eﬃcient shadow stack and provide
evidence that information disclosure poses a severe threat
to shadow stacks that are not protected through memory
isolation. Finally, we analyzed several stack-based defenses
and conclude they cannot counter our StackDeﬁler attack.
Based on our ﬁndings, we recommend that new defenses
should (i) consider the threat of arbitrary memory reads and
writes to properly secure a web browser and other attacker-
scriptable programs, (ii) never trust values from writable
memory, and (iii) recommend complementary approaches to
protect the stack and heap to mitigate the threat of memory
disclosure.

10. ACKNOWLEDGMENTS

The authors thank Andrei Homescu for providing insight
into the V8 JavaScript engine. We thank Ferdinand Brasser
and the anonymous reviewers for their suggestions and con-
structive feedback.

This work has been co-funded by the German Science
Foundation as part of project S2 within the CRC 1119
CROSSING, the European Union’s Seventh Framework Pro-
gramme under grant agreement No. 609611, PRACTICE
project and the Intel Collaborative Research Institute for
Secure Computing (ICRI-SC)

This material is based upon work partially supported by
the Defense Advanced Research Projects Agency (DARPA)

961under contracts D11PC20024, N660001-1-2-4014, FA8750-
15-C-0124, and FA8750-15-C-0085 as well as gifts from
Google, Mozilla, Oracle, and Qualcomm.

Any opinions, ﬁndings, and conclusions or recommenda-
tions expressed in this material are those of the authors
and do not necessarily reﬂect the views of the Defense Ad-
vanced Research Projects Agency (DARPA), its Contract-
ing Agents, the National Science Foundation, or any other
agency of the U.S. Government.

Mauro Conti is supported by a European Marie Curie
Fellowship (N. PCIG11-GA-2012-321980). This work is
also partially supported by the Italian MIUR PRIN Project
TENACE (N. 20103P34XC), and the University of Padua
PRAT 2014 Project on Mobile Malware.

References
[1] M. Abadi, M. Budiu, ´U. Erlingsson, and J. Ligatti. Control-
ﬂow integrity: Principles,
implementations, and applica-
tions. In ACM SIGSAC Conference on Computer and Com-
munications Security, CCS, 2005.

[2] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti. A theory
of secure control ﬂow. In Proceedings of the 7th International
Conference on Formal Methods and Software Engineering,
ICFEM’05, 2005.

[3] M. Abadi, M. Budiu, ´U. Erlingsson, and J. Ligatti. Control-
ﬂow integrity principles, implementations, and applications.
ACM Transactions on Information System Security, 13,
2009.

[4] Aleph One. Smashing the stack for fun and proﬁt. Phrack

Magazine, 49(14), 2000.

[5] M. Backes, T. Holz, B. Kollenda, P. Koppe, S. N¨urnberger,
and J. Pewny. You can run but you can’t read: Pre-
venting disclosure exploits in executable code.
In ACM
SIGSAC Conference on Computer and Communications Se-
curity, CCS, 2014.

[6] M. Backes and S. N¨urnberger. Oxymoron: Making ﬁne-
grained memory randomization practical by allowing code
sharing.
In 23rd USENIX Security Symposium, USENIX
Sec, 2014.

[7] S. Bhatkar, D. DuVarney, and R. Sekar. Address obfuscation:
An eﬃcient approach to combat a broad range of memory er-
ror exploits. In 12th USENIX Security Symposium, USENIX
Sec, 2003.

[8] A. Bittau, A. Belay, A. J. Mashtizadeh, D. Mazi`eres, and
In 35th IEEE Symposium on

D. Boneh. Hacking blind.
Security and Privacy, S&P, 2014.

[9] N. Carlini, A. Barresi, M. Payer, D. Wagner, and T. R.
Gross.
Control-ﬂow bending: On the eﬀectiveness of
control-ﬂow integrity. In 24th USENIX Security Symposium,
USENIX Sec, 2015.

[10] N. Carlini and D. Wagner. ROP is still dangerous: Break-
ing modern defenses. In 23rd USENIX Security Symposium,
USENIX Sec, 2014.

[11] X. Chen, A. Slowinska, D. Andriesse, H. Bos, and C. Giuf-
frida. Stackarmor: Comprehensive protection from stack-
based memory error vulnerabilities for binaries. In Sympo-
sium on Network and Distributed System Security (NDSS),
NDSS, 2015.

[12] Y. Cheng, Z. Zhou, M. Yu, X. Ding, and R. H. Deng.
ROPecker: A generic and practical approach for defending
against ROP attacks.
In 21st Annual Network and Dis-
tributed System Security Symposium, NDSS, 2014.

[13] C. Cowan, C. Pu, D. Maier, H. Hintony, J. Walpole,
P. Bakke, S. Beattie, A. Grier, P. Wagle, and Q. Zhang.
StackGuard: Automatic adaptive detection and prevention

of buﬀer-overﬂow attacks. In 8st USENIX Security Sympo-
sium, USENIX Sec, 1998.

[14] S. Crane, C. Liebchen, A. Homescu, L. Davi, P. Larsen, A.-R.
Sadeghi, S. Brunthaler, and M. Franz. Readactor: Practical
code randomization resilient to memory disclosure. In 36th
IEEE Symposium on Security and Privacy, S&P, 2015.

[15] S. Crane, S. Volckaert, F. Schuster, C. Liebchen, P. Larsen,
L. Davi, A.-R. Sadeghi, T. Holz, B. D. Sutter, and M. Franz.
It’s a TRAP: Table randomization and protection against
function reuse attacks.
In ACM SIGSAC Conference on
Computer and Communications Security, CCS, 2015.

[16] T. H. Dang, P. Maniatis, and D. Wagner. The performance
cost of shadow stacks and stack canaries. In 10th ACM Sym-
posium on Information, Computer and Communications Se-
curity, ASIACCS, 2015.

[17] L. Davi, C. Liebchen, A.-R. Sadeghi, K. Z. Snow, and
F. Monrose. Isomeron: Code randomization resilient to (just-
in-time) return-oriented programming. In 22nd Annual Net-
work and Distributed System Security Symposium, NDSS,
2015.

[18] L. Davi, A. Sadeghi, D. Lehmann, and F. Monrose. Stitching
the gadgets: On the ineﬀectiveness of coarse-grained control-
ﬂow integrity protection. In 23rd USENIX Security Sympo-
sium, USENIX Sec, 2014.

[19] L. V. Davi, A. Dmitrienko, S. N¨urnberger, and A. Sadeghi.
Gadge me if you can: secure and eﬃcient ad-hoc instruction-
level randomization for x86 and ARM. In 8th ACM Sym-
posium on Information, Computer and Communications
Smiecurity, ASIACCS, 2013.

[20] I. Evans, S. Fingeret, J. Gonzalez, U. Otgonbaatar,
T. Tang, H. Shrobe, S. Sidiroglou-Douskos, M. Rinard, and
H. Okhravi. Missing the point: On the eﬀectiveness of code
pointer integrity. In 36th IEEE Symposium on Security and
Privacy, S&P, 2015.

[21] I. Evans, F. Long, U. Otgonbaatar, H. Shrobe, M. Rinard,
H. Okhravi, and S. Sidiroglou-Douskos. Control jujutsu: On
the weaknesses of ﬁne-grained control ﬂow integrity. In ACM
SIGSAC Conference on Computer and Communications Se-
curity, CCS, 2015.

[22] G. Fresi Roglia, L. Martignoni, R. Paleari, and D. Bruschi.
Surgically returning to randomized lib(c). In 25th Annual
Computer Security Applications Conference, ACSAC, 2009.

[23] J. Gionta, W. Enck, and P. Ning. HideM: Protecting the con-
tents of userspace memory in the face of disclosure vulner-
abilities. In 5th ACM Conference on Data and Application
Security and Privacy, CODASPY, 2015.

[24] C. Giuﬀrida, A. Kuijsten, and A. S. Tanenbaum. Enhanced
operating system security through eﬃcient and ﬁne-grained
address space randomization.
In 21st USENIX Security
Symposium, USENIX Sec, 2012.

[25] E. G¨oktas, E. Athanasopoulos, H. Bos, and G. Portokalidis.
Out of control: Overcoming control-ﬂow integrity. In 35th
IEEE Symposium on Security and Privacy, S&P, 2014.

[26] E. G¨oktas, E. Athanasopoulos, M. Polychronakis, H. Bos,
and G. Portokalidis. Size does matter: Why using gadget-
chain length to prevent code-reuse attacks is hard. In 23rd
USENIX Security Symposium, USENIX Sec, 2014.

[27] J. Hiser, A. Nguyen-Tuong, M. Co, M. Hall, and J. W. David-
son. ILR: where’d my gadgets go? In 33rd IEEE Symposium
on Security and Privacy, S&P, 2012.

[28] A. Homescu, S. Neisius, P. Larsen, S. Brunthaler, and
M. Franz. Proﬁle-guided automatic software diversity.
In
IEEE/ACM International Symposium on Code Generation
and Optimization, CGO, 2013.

[29] R. Hund, C. Willems, and T. Holz. Practical timing side
channel attacks against kernel space aslr. In 34th IEEE Sym-
posium on Security and Privacy, S&P, 2013.

[30] Intel.

Intel 64 and IA-32 architectures software de-

962veloper’s manual, combined volumes 3A, 3B, and 3C:
System programming guide.
http://www.intel.com/
content/dam/www/public/us/en/documents/manuals/64-
ia-32-architectures-software-developer-system-
programming-manual-325384.pdf, 2013.

[31] C. Kil, J. Jun, C. Bookholt, J. Xu, and P. Ning. Address
space layout permutation (ASLP): towards ﬁne-grained ran-
domization of commodity software. In 22nd Annual Com-
puter Security Applications Conference, ACSAC, 2006.

[32] V. Kuznetsov, L. Szekeres, M. Payer, G. Candea, R. Sekar,
and D. Song. Code-pointer integrity. In 11th USENIX Sym-
posium on Operating Systems Design and Implementation,
OSDI, 2014.

[33] P. Larsen, A. Homescu, S. Brunthaler, and M. Franz. SoK:
Automated software diversity. In 35th IEEE Symposium on
Security and Privacy, S&P, 2014.

[34] C. Lattner, A. Lenharth, and V. Adve. Making context-
sensitive points-to analysis with heap cloning practical for
the real world. In Proceedings of the ACM SIGPLAN Con-
ference on Programming Language Design and Implementa-
tion, PLDI, 2007.

[35] Microsoft. Data Execution Prevention (DEP).
support.microsoft.com/kb/875352/EN-US/, 2006.

http://

[36] Microsoft.

guard.
https://msdn.microsoft.com/en-us/library/Dn919635.aspx,
2015.

Control

ﬂow

[37] V. Pappas, M. Polychronakis, and A. D. Keromytis. Smash-
ing the gadgets: Hindering return-oriented programming us-
ing in-place code randomization. In 33rd IEEE Symposium
on Security and Privacy, S&P, 2012.

[38] V. Pappas, M. Polychronakis, and A. D. Keromytis. Trans-
parent ROP exploit mitigation using indirect branch tracing.
In 22nd USENIX Security Symposium, USENIX Sec, 2013.

[39] M. Payer, A. Barresi, and T. R. Gross. Fine-grained control-
ﬂow integrity through binary hardening. In 12th Conference
on Detection of Intrusions and Malware and Vulnerability
Assessment, DIMVA, 2015.

[40] F. Schuster, T. Tendyck, C. Liebchen, L. Davi, A.-R.
Sadeghi, and T. Holz. Counterfeit object-oriented program-
ming: On the diﬃculty of preventing code reuse attacks in
C++ applications.
In 36th IEEE Symposium on Security
and Privacy, S&P, 2015.

[41] F. Schuster, T. Tendyck, J. Pewny, A. Maaß, M. Steegmanns,
M. Contag, and T. Holz. Evaluating the eﬀectiveness of cur-
rent anti-ROP defenses. In 17th International Symposium on
Research in Attacks, Intrusions and Defenses, RAID, 2014.

[42] D. Sehr, R. Muth, C. Biﬄe, V. Khimenko, E. Pasko,
K. Schimpf, B. Yee, and B. Chen. Adapting software
fault isolation to contemporary cpu architectures.
In 19th
USENIX Conference on Security, USENIX Sec, 2010.

[43] J. Seibert, H. Okhravi, and E. S¨oderstr¨om. Information leaks
without memory disclosures: Remote side channel attacks on

diversiﬁed code. In ACM SIGSAC Conference on Computer
and Communications Security, CCS, 2014.

[44] H. Shacham. The geometry of innocent ﬂesh on the bone:
return-into-libc without function calls (on the x86). In ACM
SIGSAC Conference on Computer and Communications Se-
curity, CCS, 2007.

[45] K. Z. Snow, F. Monrose, L. Davi, A. Dmitrienko,
C. Liebchen, and A. Sadeghi. Just-in-time code reuse: On
the eﬀectiveness of ﬁne-grained address space layout random-
ization. In 34th IEEE Symposium on Security and Privacy,
S&P, 2013.

[46] A. Sotirov. Heap Feng Shui in JavaScript.

In Black Hat

Europe, BH US, 2007.

[47] R. Strackx, Y. Younan, P. Philippaerts, F. Piessens, S. Lach-
mund, and T. Walter. Breaking the memory secrecy assump-
tion. In 2nd European Workshop on System Security, EU-
ROSEC, 2009.

[48] The Clang Team. Clang 3.8 documentation SafeStack. http:

//clang.llvm.org/docs/SafeStack.html, 2015.

[49] C. Tice.

Improving function pointer security for virtual
In GNU Tools Cauldron Workshop,

method dispatches.
2012.

[50] C. Tice, T. Roeder, P. Collingbourne, S. Checkoway, ´U. Er-
lingsson, L. Lozano, and G. Pike. Enforcing forward-edge
control-ﬂow integrity in GCC & LLVM. In 23rd USENIX
Security Symposium, USENIX Sec, 2014.

[51] VUPEN Security.

internet
Advanced exploitation of
explorer heap overﬂow (pwn2own 2012 exploit).
http:
//www.vupen.com/blog/20120710.Advanced_Exploitation_
of_Internet_Explorer_HeapOv_CVE-2012-1876.php, 2012.

[52] R. Wahbe, S. Lucco, T. E. Anderson, and S. L. Graham.
Eﬃcient software-based fault isolation. In 14th ACM Sym-
posium on Operating Systems Principles, SOSP, 1993.

[53] R. Wartell, V. Mohan, K. W. Hamlen, and Z. Lin. Binary
stirring: self-randomizing instruction addresses of legacy x86
binary code. In ACM SIGSAC Conference on Computer and
Communications Security, CCS, 2012.

[54] Web Hypertext Application Technology Working Group

(WHATWG). Chapter 10 - Web workers, 2015.

[55] Z. Yunhai. Bypass control ﬂow guard comprehensively. In

Black Hat, BH US, 2015.

[56] B. Zeng, G. Tan, and U. Erlingsson. Strato: A retargetable
framework for low-level inlined-reference monitors. In 22nd
USENIX Security Symposium, USENIX Sec, 2013.

[57] C. Zhang, T. Wei, Z. Chen, L. Duan, L. Szekeres, S. McCa-
mant, D. Song, and W. Zou. Practical control ﬂow integrity
and randomization for binary executables.
In 34th IEEE
Symposium on Security and Privacy, S&P, 2013.

[58] M. Zhang and R. Sekar. Control ﬂow integrity for COTS
In 22nd USENIX Security Symposium, USENIX

binaries.
Sec, 2013.

963