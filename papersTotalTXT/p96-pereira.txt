Leakage-Resilient Authentication and Encryption

from Symmetric Cryptographic Primitives

Olivier Pereira

Université catholique de

Louvain

ICTEAM – Crypto Group

B-1348, Belgium

olivier.pereira@uclouvain.be

François-Xavier

Standaert

Université catholique de

Louvain

ICTEAM – Crypto Group

B-1348, Belgium

fstandae@uclouvain.be

Srinivas Vivek

University of Luxembourg

University of Bristol

sv.venkatesh@bristol.ac.uk

ABSTRACT
Leakage-resilient cryptosystems aim to maintain security in
situations where their implementation leaks physical infor-
mation about their internal secrets. Because of their eﬃ-
ciency and usability on a wide range of platforms, solutions
based on symmetric primitives (such as block ciphers) are
particularly attractive in this context. So far, the literature
has mostly focused on the design of leakage-resilient pseu-
dorandom objects (e.g. PRGs, PRFs, PRPs). In this paper,
we consider the complementary and practically important
problem of designing secure authentication and encryption
schemes. For this purpose, we follow a pragmatic approach
based on the advantages and limitations of existing leakage-
resilient pseudorandom objects, and rely on the (arguably
necessary, yet minimal) use of a leak-free component. The
latter can typically be instantiated with a block cipher im-
plementation protected by traditional countermeasures, and
we investigate how to combine it with the more intensive
use of a much more eﬃcient (less protected) block cipher
implementation. Based on these premises, we propose and
analyse new constructions of leakage-resilient MAC and en-
cryption schemes, which allow ﬁxing security and eﬃciency
drawbacks of previous proposals in this direction. For en-
cryption, we additionally provide a detailed discussion of
why previously proposed (indistinguishability based) secu-
rity deﬁnitions cannot capture actual side-channel attacks,
and suggest a relaxed and more realistic way to quantify
leakage-resilience in this case, by reducing the security of
many iterations of the primitive to the security of a single
iteration, independent of the security notion guaranteed by
this single iteration (that remains hard to deﬁne).

INTRODUCTION

1.
Motivation. Attacks based on the exploitation of side-
channels [21] or faults [17], are an important issue for the se-
curity of cryptographic hardware. Motivated by their prac-

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813626.

tical relevance for small embedded devices such as smart
cards, a large body of research has investigated solutions
to mitigate them, analyzed in more or less abstract mod-
els, and leading to more or less eﬃcient implementations.
In this context, symmetric cryptographic primitives such as
block ciphers are of utmost importance. In general, they are
considered as the workhorses of modern cryptography [19].
Because of their low cost and eﬃciency on a wide range
of platforms, they are also a target of choice for physical
attacks. Unfortunately, their lack of mathematical struc-
ture makes them particularly challenging to protect. Tak-
ing the example of side-channel attacks (that will be our
main concern), probably the most investigated countermea-
sure is masking [5] (aka secret sharing [16]). But it implies
overheads that are (at least) quadratic in the number of
shares used (see e.g. [14] for a comparison of a couple of
schemes), and its secure implementation is far from trivial
(i.e., hardware engineers have to ensure that the leakage of
each share is independent of each other, which is frequently
contradicted in practice [22], or need to take this constraint
into account by design, which implies additional costs [28]).
Following, an alternative approach (and, as we will see, com-
plementary as well ), next denoted as leakage-resilience, has
started to look for new primitives of which the design is
inherently (more) secure against such physical attacks. So
far, leakage-resilient symmetric cryptography has mostly fo-
cused on PRGs (aka stream ciphers) [7, 9, 30, 31, 36, 37, 38,
39], PRFs and PRPs [6, 9, 37, 38]. By contrast, much less
work has been carried out on the exploitation of these prim-
itives in the context of standard cryptographic tasks such
as authentication and encryption. Our goal in this paper is
therefore to clarify how and when to use leakage-resilience
in these cases (and for which formal security guarantees).

Preliminaries. Our starting point for dealing with this
problem is a recent work of Belaid et al. [3] which shows that
concretely, the security improvements brought by leakage-
resilience highly depend on whether the underlying primitive
is stateful (like PRGs, typically) or stateless (like PRFs and
PRPs, typically).1 That is, despite proofs for both types
of primitives being essentially based on the same assump-
tions (namely the leakage per iteration has to be limited
in some sense), ensuring this condition in practice is sig-

1 By stateful, we mean that the implementation of the prim-
itive has to maintain a state (typically a key) between its
consecutive iterations, which implies that diﬀerent parties
involved in the use of this primitive have to be synchronized.

96niﬁcantly more diﬃcult in the case of stateless primitives
than in the case of stateful ones. In the case of PRGs and
stream ciphers, leakage-resilient designs limit the number
of measurements that an adversary can obtain per itera-
tion. By contrast, for PRFs and PRPs, they only limit
the number of plaintexts for which measurements can be
obtained (which still allows the adversary to measure the
same plaintext an arbitrary number of times, hence to reduce
the noise). Therefore, implementations of leakage-resilient
PRGs and stream ciphers (mostly) lead to concrete secu-
rity against side-channel key recovery attacks at a lower cost
than countermeasures like masking. By contrast, implemen-
tations of leakage-resilient PRFs and PRPs (mostly) lead to
lower concrete security levels than standard PRFs and PRPs
protected with such countermeasures. As a result, if we want
to stick with constructions based on standard block ciphers
for eﬃciency and usability reasons, there seems to be little
hope to have a secure MAC or encryption scheme without
further assumption. Indeed, stateless primitives are usually
important ingredients of such schemes, and without prop-
erties such as a homomorphic structure, block cipher re-use
will eventually leak the key in full, as just explained.

In this respect, a natural direction to investigate is to as-
sume that we will need a well protected component (i.e., a
block cipher in our case), that we will denote as “leak-free”
for convenience. Admittedly, this leak-free component will
be much (a dozen to hundred times) slower than an unpro-
tected block cipher implementation, as it could be based on
a combination of masking and other countermeasures – in
fact, it could also be based on an asymmetric cryptographic
primitive enjoying some exploitable homomorphic structure.
Concretely, it will probably be imperfect to some extent as
well (and we will detail how to capture these imperfections
in our analysis). So our goal will be to make minimal use
of this component (one call per message, independently of
the message, typically), and to combine it with a faster im-
plementation of block cipher in order to get a scheme that
would still provide good protection against side-channel at-
tacks (or at least, as good as we can hope), but would also
be much more eﬃcient than if we had to use the leak-free
component only (or solutions that only exploit the math-
ematical structure of asymmetric cryptographic primitives
such as [18] for encryption and [12, 23] for authentication).

Our contribution. First, we follow this goal of minimizing
the need of leak-freeness for two important symmetric cryp-
tographic functionalities, namely authentication and encryp-
tion. Second, we clarify and ﬁx two important shortcomings
in previously published approaches to these functionalities.
For leakage-resilient MACs, the only existing work based
on symmetric primitives is the one by Schipper [35]. The
basic idea is simple: take a leakage-resilient PRG and use it
to generate keys for a one-time MAC. While this is indeed a
stateful primitive, the main problem in this scheme is that
the use of the key is limited per message, not per message
block. This means that for long messages, and depending
on the one-time MAC that is used (CBC-MAC would be
problematic, for instance), the adversary can observe a large
number of leaking operations exploiting the same key. One
partial solution considered in Schipper’s thesis is to use a
MAC based on a leakage-resilient PRF. But this has a higher
implementation cost (as noticed in [23]) and faces the pre-
viously discussed problem of stateless primitives. In order

to improve this situation, we ﬁrst propose a new (stateful)
leakage-resilient MAC that limits the use of leak-free compo-
nent to a single IV block (which can be pre-computed), and
is eﬃcient for large messages (i.e., requires a single block
cipher execution per message block). We then propose a
variant of this scheme based on a hash and MAC paradigm.
Along these lines, we also put forward that certain standard
MACs are better suited for leakage-resilience than others
(e.g. HMAC is better than CBC-MAC in this respect).

For encryption, the literature based on symmetric primi-
tives is also sparse. To the best of our knowledge, the work
by Abdalla et al. [2] is the only one to address this question.
Here, the problem is more general and deﬁnitional. That is,
a central issue in all the leakage-resilient encryption notions
proposed so far is that they exclude the leakage during the
challenge queries, or focus on a restricted setting where an
encryption is assumed to not leak any single bit of the plain-
text that is encrypted (e.g. consider only key leakage). In
fact, this is also true for public-key encryption schemes: see,
e.g., [27] for an early proposal in this direction and [15] for a
more recent one. On the one hand, this seems unavoidable:
indeed a single bit of leakage on the plaintext trivially breaks
the semantic security game. On the other hand, we argue
that excluding challenge leakages is artiﬁcial and does not
capture the actual adversarial scenario of leaking devices, at
least in the context of side-channel attacks based on power
consumption and electromagnetic radiation that we consider
in this paper (but, we believe, in general as well). And, as
a side eﬀect, such deﬁnitions do not make a diﬀerence be-
tween an encryption implementation that would leak the full
plaintexts from an implementation that would not leak any
information about the plaintexts – a diﬀerence that seems to
be of crucial importance in the context of encryption. Hence,
we propose an alternative way to model the security in front
of leakages where we do not try to enforce traditional se-
curity notions with a negligible advantage. We rather show
that the security of multiple iterations reduces to the secu-
rity of a single iteration. That is, we show that whatever the
adversary is able to do against multiple iterations of our en-
cryption scheme is also possible against a single iteration of
this scheme. We believe this approach is more realistic since
it does not give users the (illusory) feeling that semantic (or
any indistinguishability-based) security can be obtained for
encryption schemes with leakage. By contrast, we provide
an eﬃcient solution for which the designer is guaranteed that
the security of the full construction reduces to the security
of a single block (whatever security he is able to achieve).

Remarks. The combination of these results is in fact well in
line with the early investigations of Micali and Reyzin, where
it was shown that unpredictability-based security is eas-
ier to obtain than indistinguishability-based security in the
presence of leakage [25]. Concretely, and based on present
knowledge, it also means that if semantic (or equivalent) se-
curity is required for an application, the best option is to
use leakage-resilient authentication to access a leak-free en-
vironment ﬁrst, and to perform encryption only afterwards.
In other words, the security guarantees of leakage-resilient
encryption, despite practically meaningful (e.g. in order to
prevent key recoveries), are indeed much harder to formal-
ize in terms of message conﬁdentiality. Note ﬁnally that our
following constructions only consider the leakage-resilience
of tag generation and encryption. This is a relevant ﬁrst
step, since it is a frequent scenario that only one (cost-

97constrained) party in authentication and encryption has to
be protected against side-channel analysis, while the other
party (e.g., a reader) is much easier to shield through phys-
ical countermeasures [24]. Yet, we also admit that securing
the tag veriﬁcation and decryption parts will most likely be
more challenging (since these algorithms are not randomized
in most existing MAC and encryption schemes), and leave
their investigation as an intersting research problem.

Leakage model. We consider the continuous leakage model
since it is the only one capturing actual side-channel attacks.
Indeed, if a system is used for a suﬃciently long period of
time, the amount of leakage observed by an attacker may ex-
ceed any apriori determined leakage bound. In this context,
we capture the limited informativeness of actual leakages
with the recently introduced “simulatable leakage” frame-
work [36]. We are aware of the ongoing discussion about
how to implement block ciphers ensuring this empirically
veriﬁable assumption [11]. Yet, and as argued in this ref-
erence, it remains the most realistic assumption to reason
about leakage we currently have (and in particular, the only
one that can be challenged by hardware engineers). Besides,
the recent discussion in [29] suggests that the main issue
with the leakage simulators of [36] is due to the diﬃculty
to capture the noise distribution in actual leakage traces
(i.e., does not relate to exploitable key-dependent signal),
and describes ways to design new instances of simulators to
overcome this problem (of which the analysis is beyond the
scope of this paper). Eventually, and more importantly, we
believe our core contribution is the general investigation of
leakage-resilient MAC and encryption, as well as the pro-
posal of eﬃcient constructions minimizing the need of leak-
freeness. This contribution is quite independent of the quest
for a perfectly realistic model of leakage-resilience, which in-
deed remains a great conceptual challenge. That is, we use
a leakage model (here, the simulatability framework) to rea-
son formally about our constructions and make sure they are
theoretically founded. But in the ﬁrst place, we hope that
they will be helpful in practice, for cryptographic engineers.

2. LEAKAGE-RESILIENT MESSAGE

AUTHENTICATION CODES

2.1 Security deﬁnition
Let us recollect the standard deﬁnition of a Message Authen-
tication Code. A MAC is a tuple of three polynomial time
algorithms MAC = (KeyGen, Mac, Vrfy) deﬁned as follows:
• the key generation algorithm KeyGen(1n) takes as
input the security parameter n and generates a shared
(master) secret key k to be used by both the tag gen-
erator and the veriﬁer,

• the MAC generation algorithm Mac(m, k; r) takes
as input the message m, the secret key k, and possibly
some randomness r, and then outputs a tag τ .
(In
the following, we omit mentioning the randomness in
contexts where it is not relevant.)

• the tag veriﬁcation algorithm Vrfy(m, τ, k) takes as
input a message m, the corresponding tag τ and the
secret key k. The algorithm outputs 1 (accept) if the
tag is valid for the message, else it outputs 0 (reject).

We require the usual correctness property to be satisﬁed
by the MAC, i.e., Vrfy(m, Mac(m, k; r), k) → 1 for every
message m and key k in the range of KeyGen. Informally, the
MAC is said to be existentially unforgeable in the presence
of leakage during tag generation (in short, LR-MAC) if the
adversary is unsuccessful in the following security game. As
usual, a key is selected as part of the experiment. We do not
consider leakages at this step, as the actual way of loading
the key into a device can vary quite a lot from one situation
to another, and will usually happen at manufacturing time,
out of reach of the adversary. Next, the adversary can ask for
tags on messages of its choice, computed with that key. This
time, a leakage corresponding to the each tag computation is
provided to the adversary together with the tag, this leakage
being computed through the leakage function L. We will of
course place some restrictions on this leakage function later
in the paper. Eventually the adversary will also have access
to the tag veriﬁcation oracle, but it will not get leakages
during veriﬁcation (which corresponds to the fact that we
only secure the tag generation against side-channel attacks,
not the tag veriﬁcation).2 The goal of the adversary is to
output a valid forgery on a message for which it has not
previously obtained a corresponding tag.
Formally, we consider the experiment Forgeeuf−cma

AL,MAC(n):

Forgeeuf−cma

AL,MAC(n):

k ← KeyGen(1n)
F ← ∅
(m, τ ) ← AL,OML(·),OV(·,·)(1n)
If m ∈ F, then Return b := 0
b ← Vrfy(m, τ, k)
Return b

Oracle OML(m):
r ← {0, 1}n
F ← F ∪ m
Return (Mac(m, k; r),
Oracle OV(m, τ ):
Return Vrfy(m, τ, k)

L(m, k; r))

Conceptually, we do not want to place unnecessary re-
strictions on the leakage function L. In particular, it is an
open problem to determine the complexity of such a func-
tion, and whether it can be computed eﬃciently. So, in
order to abstract the complexity of the leakage function, we
separate the process of obtaining a leakage, which is going
through a physical measurement, from the internal compu-
tation of the adversary. The possibility for an adversary A
to obtain leakages from a circuit is then expressed as an or-
acle access: AL. Furthermore, we talk about (s, t)-bounded
adversaries for adversaries who are able to perform s leak-
age queries and perform a computation bounded by running
time t. Note that those s leakage queries are quite diﬀer-
ent from the OML queries in the Forgeeuf−cma
AL,MAC(n) game: when
querying L, A must select the inputs (m, k) of the circuit
by himself, while the OML oracle provides A with leakages
about a key k that A is not expected to know. Those s
2 As mentioned in the introduction, preventing side-channel
attacks during the tag veriﬁcation will most likely be quite
challenging. Indeed, if the adversary can observe the leak-
age during veriﬁcation, it should be able to fully recover the
key by re-using it many times in the veriﬁcation phase. Be-
sides, this problem is not speciﬁc to symmetric primitives.
A similar (yet relaxed) restriction is also made in [23] for a
construction of a leakage-resilient MAC based on pairings.
In this case, the adversary gets the leakage during veriﬁca-
tion, but only once, for a given message and randomness
pair. Otherwise, the adversary will be able to leak a correct
tag bit-by-bit by repeatedly accessing the veriﬁcation oracle
with incorrect tags against the same message.

98queries actually correspond to a training phase that A can
perform as part of his attack of the circuit, a practice that
is common in (proﬁled) side-channel analyses.

Deﬁnition 1. [LR-MAC] MAC is said to be a (q, s, t, )
secure LR-MAC in the presence of leakage L, if  is a bound
on the the advantage of any (s, t)-bounded adversary AL
playing the experiment Forgeeuf−cma
AL,MAC(n) and making at most
q queries to the OML oracle, that is,

Pr[Forgeeuf−cma

AL,MAC(n) = 1] ≤ .

Remark 1. The notion of Strongly-Unforgeable LR-MAC
is a stronger security notion than that in Deﬁnition 1. This
distinction is analogous to the diﬀerence between strong un-
forgeability and basic unforgeability notions for MAC in the
traditional setting (without leakage). In the case of strongly-
unforgeable LR-MAC, it suﬃces for the adversary to output
a valid message-tag pair distinct from those pairs it received
in its interaction. Hence, it is not necessarily required to
output forgery on a distinct message. Otherwise, the secu-
rity game remains the same as that for LR-MAC.
2.2 Why CBC-MAC is not leakage-resilient
To motivate our following investigations, we start with a
brief explanation of why standard MAC constructions such
as CBC-MAC, are not leakage-resilient by default. For this
purpose, just look at the informal description of CBC-MAC
in Figure 1. Here, the master key k is used in every iteration
of the MAC (and kept constant among messages). So we are
exactly in the scenario where a standard side-channel key re-
covery attack is the most devastating. As a result, a natural
suggestion for improving the situation would be to combine
CBC-MAC with a leakage-resilient stream cipher so that ev-
ery message block would be processed with a diﬀerent key.
Yet, this would typically imply three block cipher executions
per message block. In the following section, we show that a
three times more eﬃcient solution can be obtained.

Figure 1: CBC-MAC.

2.3 Leakage-resilient tag generation
We next present a plausible construction of LR-MAC that is
a variant of the standard CBC-MAC. The scheme MAC1 =
(KeyGen1, Mac1, Vrfy1), depicted in Figure 2 and described
below, is a ﬁxed length MAC that takes as input (cid:96) blocks
of messages ((cid:96) ≥ 1), each block being n-bit long.3 The
construction requires two pseudorandom functions F and F∗
that we will typically instantiate with a block cipher. The
same block cipher could be used twice, but we distinguish
between the two functions because their implementations

3 For clarity, we stick to a ﬁxed-length MAC construction,
just as CBC-MAC. The adaptations of CBC-MAC to a vari-
able length MAC would apply here as well – see, e.g., [4].

Figure 2: Re-keying MAC.

will be quite diﬀerent: we demand F∗ for being essentially
leak-free (or strongly protected) and expect its implementa-
tion to be fairly ineﬃcient, while F is expected to be more
eﬃcient and require much less protection against leakages.
How to realize the leak-free function F∗ and to capture its
possible imperfections will be discussed in Section 4.

Description of MAC1:

• KeyGen1(1n): Choose a shared master secret key

k $← {0, 1}n.

• Mac1 (m, k): Parse m = (cid:104)m1, m2, . . . , m(cid:96)(cid:105). Choose
IV $← {0, 1}n. Compute the session key k(cid:48) := k1 =
F∗

k(IV ).
– for j = 2, . . . (cid:96)+1: compute kj = Fkj−1 (mj−1).

Return τ = (IV, k(cid:96)+1).

• Vrfy1 (m, τ, k): Parse τ = (IV, tg). Compute τ(cid:48) ←

Mac1 (m, k, IV ).

– If τ(cid:48) ?= τ , then return 1 (correct), else return

0 (incorrect).

Compared to CBC-MAC, one can directly see that this
scheme brings improved leakage-resilience, since a new ses-
sion key is used for every new message. Compared to the LR-
MAC of Schipper in [35], we have the additional advantage
that the key evolves for every message block, which allows
us to state our requirements on the leakage for a single iter-
ation of the scheme. We also exploit the block cipher quite
eﬃciently since this new stateful construction essentially re-
quires an execution of F per message block. Eventually, we
require a very minimum use of the leak-free component F∗
(depicted in dark grey on the ﬁgure):
it is only needed to
encrypt a single random IV under the master key k.

Remark 2. In the MAC1 construction above, a random
IV is chosen to compute every new tag on a message m.
Nevertheless, the security of the construction will not be
aﬀected even if we choose the IVs arbitrarily, as long as they
are distinct (cf. proof of Theorem 1). Hence, for instance,
we could use a counter mode (i.e., start with IV = 0, and
then successively increment it). This would only require the
MAC implementation to maintain a public state.

We now prove the LR-MAC security of our MAC1 con-
struction based on the pseudorandomness and the simulat-
able leakage assumption of the block cipher F, assuming that
the implementation of F∗ used to compute the session key
k(cid:48) from IV is leak-free. We ﬁrst recall these properties.

Deﬁnition 2. [Pseudorandom Function (PRF) [36, Deﬁ-
nition 2]] A block cipher F : {0, 1}n × {0, 1}n → {0, 1}n is a

99(s, t, prf ) PRF in the presence of leakage function L if, for
every (s, t)-bounded adversary AL(.,.), we have:

| Pr[AL(.,.),FK (·) = 1] − Pr[AL(.,.),R(·) = 1]| ≤ prf ,

where K $← {0, 1}n and R is a random function.

As discussed in [36], this deﬁnition would be exactly equiv-
alent to the standard notion of PRF if the leakage function
was polynomial time: indeed, in that case, A could emulate
L internally. However, as discussed above, we do not want
to make any such restriction, since it remains an open prob-
lem to determine the exact complexity of physical functions,
and since leakages generally result from a physical process
rather than a traditional computational process. This obser-
vation motivates the next q-simulatable leakage assumption
that is deﬁned via the following game and can be directly
challenged by hardware engineers, as detailed in [36].

Game q-sim(A, F, L,S, b) [36, Section 2.1].
The challenger selects two random keys k, k∗ $← {0, 1}n.
The output of the game is a bit b(cid:48) computed by AL based
on the challenger responses to a total of at most q adver-
sarial queries of the following type:

Query
Enc(x)

Response if b = 0 Response if b = 1
Fk(x), L(k, x)

Fk(x), S L(k∗, x, Fk(x))

and one query of the following type:
Query
Gen(z, x) S L(z, x, k)

S L(z, x, k∗)

Response if b = 0 Response if b = 1

It directly leads to the following deﬁnition of a block cipher
implementation with q-simulatable leakages.

Deﬁnition 3. [q-simulatable leakages [36, Defn. 1]] Let
F be a block cipher having leakage function L. Then F is
said to have (sS , tS , sA, tA, q-sim) q-simulatable leakages if
there is an (sS , tS )-bounded simulator S L such that, for ev-
ery (sS , tS )-bounded adversary AL, we have:

| Pr[q-sim(A, F, L,S L, 1) = 1]−

Pr[q-sim(A, F, L,S L, 0) = 1]| ≤ q-sim.

(cid:104)DL(cid:16)

(cid:12)(cid:12)(cid:12)Pr
(cid:104)DL(cid:16)

(cid:17)

(cid:105) −
(cid:105)(cid:12)(cid:12)(cid:12)

Eventually, the following lemma is a consequence of Deﬁni-
tion 2 and Deﬁnition 3 (for 2− simulatable leakages) [36].
Lemma 1. [2-simulatable ideal execution [36, Lemma 1]]
Let F : {0, 1}n × {0, 1}n → {0, 1}n be a (s, t, prf ) PRF in
the presence of leakage function L having (sS , tS , s, t, 2-sim)
2-simulatable leakages, and let S L be an appropriate (sS , tS )-
bounded leakage simulator. Then, for every k−, p0, p1, z ∈
{0, 1}n and every (s − 3sS , t − max(tprf , tsim))-bounded dis-
tinguisher DL, the following holds:

= 1

(cid:17)

y+, k+, L(k(cid:48), p0), L(k(cid:48), p1), SL(k−, z, k(cid:48))
y∗, k∗, SL(k(cid:48), p0, y∗), SL(k(cid:48), p1, k∗), SL(k−, z, k(cid:48))

Pr

= 1
≤ prf + 2-sim,
where k(cid:48), y∗, k∗ $← {0, 1}n, y+ = F(k(cid:48), p0), k+ = F(k(cid:48), p1).
Furthermore, tprf is equal to 3 · tS augmented with the time
needed to make 2 oracle queries to the PRF challenger and
select a uniformly random key in {0, 1}n, and tsim is the
time needed to relay the content of two Enc and one Gen
queries from and to a q-sim challenger.

Remark 3. We note that the output of the two Enc and
the Gen queries in Lemma 1 can be obtained adaptively.
More precisely, let (cid:104)d1, d2, d3, d4, d5(cid:105) denote the input re-
ceived by DL. The above indistinguishability result holds
even if DL adaptively obtains the input as (cid:104)d1, d3(cid:105), (cid:104)d2, d4(cid:105),
and d5, in any order of its choice. This observation will be
useful in the following security analysis of MAC1.

Remark 4. Note that besides the previously mentioned
simulatability, we need to assume that the blocks leak in-
dependently of each other. This actually corresponds to the
“only computation leaks” assumption (or “independent leak-
age” assumption) that is anyway required for any proof of
leakage-resilience to hold.
In the present case, we believe
that it is reasonable to have it satisﬁed in practice, since we
need it at the macroscopic level of fairly large blocks. That
is, as for [7] and follow up works, it seems unlikely that
our construction will be broken because of small deviations
from this assumption (which can possibly be reduced at the
hardware level, e.g. by shielding blocks with ground lines).

Security of MAC1.

2.3.1
We now establish the LR-security of our MAC1 construction.
Theorem 1. Let F : {0, 1}n × {0, 1}n → {0, 1}n be an
(s, t, prf ) PRF having (sS , tS , s, t, 2-sim) 2-simulatable leak-
ages. Then, the instantiation of MAC1 with F is an (q, s(cid:48), t(cid:48),
(cid:48))-strongly-unforgeable LR-MAC on messages of length (cid:96)
with n-bit blocks, where:

(cid:48) ≤ prf + (q + 1)(cid:96)(prf + 2-sim) + negl(n),



with s(cid:48) ≈ s−q·(cid:96)·sS and t(cid:48) ≈ t−˜t, where ˜t is the time required
by the challenger to simulate the experiment Forgeeuf−cma
AL,MAC(n)
for the construction MAC1, which essentially consists of (q +
1)· ((cid:96) + 1) evaluations of F and q· (cid:96) calls to the simulator S L.
Here, negl(n) refers to a negligible function of n assuming
that q and (cid:96) are polynomially bounded in n.

Proof. The proof of strongly-unforgeable LR-MAC se-
curity for our MAC1 construction is available in Appendix
A. It proceeds by a sequence of hybrid games, which essen-
tially follows the strategy introduced in [36, Theorem 1].

Remark 5. A glance at Figure 2 might suggest that only
the 1-simulatability leakage assumption would suﬃce for the
security of the MAC1 construction, but this does not seem
to be the case. Indeed, for most parts of the security reduc-
tion, the 1-simulatability leakage assumption is enough. But
because we allow the adversary to possibly output a forgery
on a previously used IV, we need the second output pair of
the leakage simulator to enable us to verify the attempted
forgery by the adversary (on this particular IV). Note that
this issue only relates to the reduction and has nothing to
do with the MAC construction itself (for which we anyway
exclude the leakage during veriﬁcation).

Remark 6. From a performance point-of-view, the con-
struction is essentially as fast as one can hope since it has
an amortized cost of one (weakly protected) block cipher
execution per message block – see the table in [23] for an
overview. However, strict comparisons with these previous
works is not possible due to their diﬀerent leakage models.
In particular, as recently discussed in [10], simulatable leak-
age and bounded leakage are not implied by each other.

1002.4 Variation: the hash then MAC paradigm
To conclude this section, we note that in view of how the
message in Figure 2 is processed, an alternative (and in fact
even simpler) solution to build a leakage-resilient MAC is
to rely on the hash then MAC paradigm. Such a proposal
is intuitively depicted in Figure 3, where we can see that
the leakage-resilience of the scheme now really boils down
to the execution of the leak-free block cipher on a random
IV, which comes at the cost of an additional building block
(namely a collision-resistant hash function). This essentially
results from the fact that the hash function is only executed
on public inputs. Interestingly, this construction also sug-
gests that a standard solution like HMAC could be slightly
tweaked in order to become leakage-resilient (which is in
contrast with the previously mentioned CBC-MAC).

Figure 3: Hash then MAC.

More precisely, our construction MAC2 = (KeyGen2, Mac2,
Vrfy2), can be viewed as a special instantiation of MAC1
where the messages of arbitrary length are ﬁrst hashed to
a single n-bit block using the hash function H : {0, 1}∗ →
{0, 1}n. Then a tag is generated for this hashed block using
MAC1, which makes its analysis straightforward.

Description of MAC2:

• KeyGen2(1n): Choose a hash function H : {0, 1}∗ →
{0, 1}n, and a shared symmetric-key k $← {0, 1}n.
• Mac2 (m, k): Choose IV $← {0, 1}n. Compute k(cid:48) =
k(IV ), h = H (m), and r = Fk(cid:48) (h). Return
• Vrfy2 (m, τ, k): Parse τ = (IV, tg). Compute τ(cid:48) ←
– If τ(cid:48) ?= τ , then return 1 (correct), else return

F∗
τ = (IV, r).

Mac2 (m, k, IV ).

0 (incorrect).

Our proof requires the deﬁnition of a collision resistant hash
function (sampled from a family) which only operates on
public values. Hence, we do not consider any leakage here.

Deﬁnition 4. [Collision Resistance]. A hash function H :
{0, 1}∗ → {0, 1}n sampled from a family of functions H is
(t, cr) collision-resistant if for any adversary A running for
time at most t, its advantage in outputting m, m(cid:48) ∈ {0, 1}∗
such that m (cid:54)= m(cid:48) and H(m) = H(m(cid:48)), is at most cr.

Based on this deﬁnition, the following theorem establishes
the leakage-resilience of our MAC2 construction.

Theorem 2. Let F : {0, 1}n × {0, 1}n → {0, 1}n be an
(s, t, prf ) PRF having (sS , tS , s, t, 2-sim) 2-simulatable leak-
ages, and let H : {0, 1}∗ → {0, 1}n be a (t, cr) collision-
resistant hash function. Then, the instantiation of MAC2
with F and H is an (q, s(cid:48), t(cid:48), (cid:48))-strongly-unforgeable LR-MAC
on messages of arbitrary length, where:

(cid:48) ≤ cr + prf + (q + 1)(prf + 2-sim) + negl(n),


with s(cid:48) ≈ s− q· sS and t(cid:48) ≈ t− ˜t, where ˜t is the time required
by the challenger to simulate the experiment Forgeeuf−cma
AL,MAC(n)
for the construction MAC2, which essentially consists of 2 ·
(q+1) evaluations of F and q calls to the simulator S L. Here,
negl(n) again refers to a negligible function of n assuming
that q and (cid:96) are polynomially bounded in n.

Proof sketch. We just observe that if the adversary is un-
able to break the collision resistance of H, then it has to
output a valid forgery on a new hash output (correspond-
ing to some message) for a previously queried IV, or on an
old hash output but for a new IV. By treating the n-bit
hash outputs as the message space of MAC1, we obtain the
above bound on the advantage of A from Theorem 1 (with
(cid:96) = 1). Note that the adversary’s advantage in breaking the
collision-resistance of H is cr.

Remark 7. For a 128-bit block cipher such as the AES-
128, we will have cr = 2−64 (because the hash function
outputs n bits) and prf = 2−64 (because of the PRP to PRF
conversion that we use for simplicity in our proof). However,
beyond birthday security could potentially be obtained by
hashing on 2n-bit values and replacing the block cipher by
a tweakable block cipher, e.g. as done in the context of
authenticated encryption [20], which we leave as an open
problem. Besides, note that this variant allows gaining a
factor (cid:96) compared to the bound of Theorem 1, which comes
at the cost of an additional primitive to implement.

3. LEAKAGE-RESILIENT ENCRYPTION
3.1 Security deﬁnition
We now turn to the construction of a leakage-resilient sym-
metric encryption scheme ENC with key generation algo-
rithm Gen, encryption algorithm Enc and decryption algo-
rithm Dec. The Enc algorithm proceeds on messages made
of a variable number of blocks, i.e., messages from the set
({0, 1}n)∗ where n is the block size. For this scheme, we
deﬁne a PrivKlmcpa,b
AL,ENC game, analogue to the traditional IND-
CPA security game, but in a physical setting where all en-
cryption operations, including the test query, return to the
adversary a leakage together with a ciphertext.

PrivKlmcpa,b

AL,ENC is the output of the following experiment:

1. A key k is generated by running Gen.
2. ALgets access to a leaking encryption oracle that,
on messages of arbitrary block length, returns an
encryption of these messages together with the leak-
age resulting from the encryption process.
3. AL submits two messages m0 and m1 of identical
4. A ciphertext c ← Enck(mb) is computed, resulting
5. AL can keep accessing the leaking encryption oracle.
6. AL outputs a bit b(cid:48).

block length
in a leakage l. Both c and l are given to AL.

101Naturally, we will be interested in the diﬀerence

AL,ENC − PrivKlmcpa,1

AL,ENC|, which we would like to be min-

|PrivKlmcpa,0
imal. However, and as discussed in the introduction, since
we consider leakages even during the test query, we cannot
expect this diﬀerence to be negligible. For that reason, we
rather focus on establishing bounds that are derived from
the security of a considerably simpler encryption scheme,
that encrypts only one message made of a single block per
key. That is, we want to show that any security guarantee
that can be ensured for this simple (single-block, one-time)
encryption scheme (next denoted by ENCs) extends to our
full construction ENC. This is eventually what we achieve
in Theorems 3 and 4, which relate the CPA security of the
multi-block ENC scheme to the eavesdropper security of the
single-block ENCs scheme. We believe that such a result
concretely helps the task of secure implementation and se-
curity evaluation in two ways:

1. The eavesdropper security game gives a unique leak-
age for a single-block message to the adversary, which
is a most limited input to run a side-channel attack
(in practice such attacks usually rely on a few hun-
dred leakages). This means that a cheap and relatively
weakly protected implementation could be used even
in a setting where long messages are encrypted [3].

2. Security evaluations can also focus on the (compara-
tively) simpler task of assessing the security of a single
encryption round, without needing to care about the
combination of leakages from the encryption of multi-
ple blocks of message. (For instance, leaking one bit of
a key per encryption block is probably not a problem
when encrypting a single block, but could become a
problem if the encryption of each block leaks a new
bit. Our proof guarantees that there is no such risk.)

The rest of this section is organized as follows. We start
in Section 3.2 by deﬁning our leakage-resilient encryption
scheme ENC and its leakage model. Next, in Section 3.3, we
deﬁne our one-time and one-block encryption scheme ENCs,
together with its leakage model. Based on these deﬁnitions,
we build our security analysis as follows. In Section 3.4, we
deﬁne an idealized version ENCsI of ENCs that has perfectly
random outputs and simulated leakages for the PRFs. We
also deﬁne a one-time (but multiple block) version of the
ENC scheme, which we call ENC(cid:96) (the (cid:96) referring to the (cid:96)
blocks), as well as an ideal version ENC(cid:96)I of it. We conclude
this section by bounding the probability that an adversary
distinguishes between real and ideal versions of the schemes.
In Section 3.5, we push our analysis one step further, bound-
ing the probability that an adversary breaks eavesdropper
security for the ENC(cid:96)I scheme as a function of the proba-
bility of breaking that same property on the ENCsI scheme.
The result from Section 3.4 can then be used to move back
to the real encryption schemes. Eventually, in Section 3.6,
we conclude by relating the CPA security of the ENC scheme
to the eavesdropper security of the ENC(cid:96) scheme.
3.2 Leakage-resilient encryption scheme

The ENC scheme. Our starting point is the leakage-resilient
stream cipher from [36], which we transform into an encryp-
tion scheme by XORing its output with the message to be
encrypted. CPA security is obtained by adding an initial-
ization round, which generates the stream-cipher seed by

Figure 4: Leakage-resilient encryption scheme.

applying a leak-free PRF, keyed with the encryption key, to
an initialization vector IV, as represented in Figure 4. As
for the previous MAC constructions, we require the initial-
ization step be leak-free in order to make sure that, despite
the fact that it will be executed many times with the same
key, that key will remain safe. And here as well, this use of
leak-free component is minimal (a single execution per mes-
sage) and independent of the message size (so that the fresh
key k(cid:48) can possibly be pre-computed.) The ENC encryption
scheme is deﬁned more formally in Table 1.
• Gen picks a random key k ← {0, 1}n.
• Enc picks a random IV ← {0, 1}n, then computes
k0 = F∗
k(IV ) using the leak-free PRF. The encryp-
tion of the (cid:96)-block message m = (cid:104)m1, . . . , m(cid:96)(cid:105) is
then computed as IV, c1, . . . , c(cid:96), where ci = yi⊕mi,
yi = Fki−1 (pB) and ki = Fki−1 (pA) (pA and pB are
public constants, where pA (cid:54)= pB).
• Dec proceeds in the natural way.

Table 1: The ENC encryption scheme

Leakage model and assumptions. We capture the leak-
ages of an implementation of this encryption scheme through
two leakage functions: LF(p, k) that deﬁnes the leakage of
each PRF running on plaintext p with key k, and L⊕(m, y)
that deﬁnes the leakage of computing the XOR of m and
(When the adversary AL has the single L superscript,
y.
we mean that it can query both these leakage functions.)
So, the encryption of each message block mi causes the fol-
lowing leakages: LF(pA, ki−1), LF(pB, ki−1) and L⊕(mi, yi).
Here and later, we precede an algorithm with the L letter
(e.g. LEnck(m)) to refer to both the output of an encryp-
tion and the resulting leakage. As in the previous section
about MACs, we require the leakages of the PRF F to be
2-simulatable, but no more. As a consequence, leakage func-
tions do not need to be eﬃcient, and can possibly leak sev-
eral bits of information on their inputs. In particular, they
can provide several bits of information on yi and mi, which
makes traditional security notions based on indistinguisha-
bility impossible to achieve. We believe that, without addi-
tional leak-free component, this is just unavoidable: at some
point, messages need to be used during the encryption pro-
cess, and this use must be expected to leak information that
is suﬃcient to win any indistinguishability game.
3.3 Single-block one-time encryption scheme
We deﬁne, in the left part of Table 2, the ENCs single-block
one-time encryption scheme, from the security of which we
will infer the PrivKlmcpa,
AL,ENC security of our ENC multi-block

102Description of ENCs:

• Gen picks k0 ← {0, 1}n.
• Encsk0 (m) returns (k1, c1), where c1 =
y1 ⊕ m, y1 = Fk0 (pB) and k1 =
Fk0 (pA).

• Dec proceeds in the natural way.

resulting

leakage
deﬁned

The
LEncs(k0, m)
is
(LF(pA, k0), LF(pB, k0), L⊕(m, y1),
SL(k−, pA, k0), k−) with k− ← {0, 1}n.

from Encsk0 (m)
:=

as

Description of ENCsI:

• EncsI

returns

k0 (m)

(k1, c1), where
c1 = y1 ⊕ m, y1 ← {0, 1}n and k1 ←
{0, 1}n.
leakage

deﬁned

resulting from EncsI
The
LENCsI (k0, k1, y1, m)
is
(SL(k0, pA, k1), SL(k0, pB, y1), L⊕(m, y1),
SL(k−, pA, k0), k−) with k− ← {0, 1}n.

k0 (m)
:=

as

Table 2: The ENCs and ENCsI schemes.

scheme. The ENCs scheme, while being similar to the single
block version of ENC, bears important diﬀerences with it:

1. It has no leak-free initialization process. This is not

necessary for a one-time version of the scheme.

2. Its ciphertext contains k1. While being harmless from
a black-box point of view, including k1 in the cipher-
text will show to be useful in bounding the amount of
information that leakages can transfer between rounds.
We will provide constructive evidence that this addi-
tion is necessary after the proof of Lemma 3.

3. Its leakages contain S L(k−, pA, k0), k− with a random
k−. This leakage has a similar purpose as adding k1 in
the ciphertext. Namely, it will be used to bound the
information that can leak, in the multi-block setting,
from the encryption of previous blocks.

3.4 One-time ideal versions of our schemes
We now idealize the Encs encryption process by replacing
the use of F for computing k1 and y1 by the selection of
random values. Furthermore, we adapt the corresponding
leakages using S L. The resulting algorithms are deﬁned in
the right part of Table 2. The following lemma expresses
that leaking encryptions produced with these two schemes
are hard to distinguish, by relying on the 2-simulatability
assumption and the properties of the PRF.

Lemma 2. Ideal single block encryption. Let F :
{0, 1}n × {0, 1}n → {0, 1}n be a (s, t, prf )-PRF, whose im-
plementation has a leakage function LF having (sS , tS , s, t,
2-sim) 2-simulatable leakages, and let S L be an appropriate
(sS , tS )-bounded leakage simulator. Then, for every m, pA,
pB, p ∈ {0, 1}n, pA (cid:54)= pB, and every (s − sr, t − tr)-bounded
distinguisher DL, the following holds:

(cid:104)DL (m, LEncs(k0, m)) = 1
(cid:105) −

(cid:12)(cid:12)(cid:12)Pr

(cid:17)

= 1

(cid:105)(cid:12)(cid:12)(cid:12) ≤ prf + 2-sim,

Pr

m, LEncsI(k0, m)

(cid:104)DL(cid:16)

with sr := 3· sS + 1, tr = max(tprf , tsim), tprf being equal to
3·tS augmented with the time needed to make 2 oracle queries
to the PRF challenger and select a uniformly random key in
{0, 1}n, and tsim the time needed to relay the content of two
Enc and one Gen queries from and to a q-sim challenger.

Proof. We follow the same approach as used for proving
Lemma 1: ﬁrst replace the leakages of LEncs with simulated
leakages, relying on the simulatability assumption, then re-
place the outputs of the PRF of LEncs with random values,
relying on the assumption that F is a PRF.

We now transpose the deﬁnitions of ENCs and ENCsI to
the multi-block setting, but still focusing on the one-time en-
cryption case. The resulting schemes, ENC(cid:96) and ENC(cid:96)I are
described in Table 3. These ideal versions are closer to the
ENC scheme deﬁnition: while we still ignore the leak-free ini-
tialization process, the ciphertexts do not contain the extra
key block any more, and the leakages follow the natural def-
inition. Just as before, we express that leaking encryptions
produced with these two schemes are hard to distinguish.

Lemma 3. Ideal multiple block encryption. Let F
and S L be deﬁned as in Lemma 2. Then, for every (cid:96)-block
message m, every pA, pB and every (s − sr, t − tr)-bounded
distinguisher DL, the following holds:

(cid:12)(cid:12)(cid:12)Pr

(cid:104)DL (m, LEnc(cid:96)(k0, m))) = 1

(cid:105)(cid:12)(cid:12)(cid:12) ≤ (cid:96)(prf + 2-sim).

(cid:105) −
(cid:17)

(cid:104)DL(cid:16)

Pr

m, LEnc(cid:96)I(k0, m)

= 1

Here, sr = (cid:96)(2sS + 3) and tr is equal to 2(cid:96)tS augmented with
the time needed to pick 2(cid:96) random values in {0, 1}n, evaluate
F 2(cid:96) times and compute (cid:96) ⊕ operations.

Proof. We deﬁne the hybrid distributions H0, . . . , H(cid:96) in
which Hi(m) is deﬁned as the concatenation of an ideal exe-
cution LEnc(cid:96)I
k0 (m[1,i]) and a real execution LEnc(cid:96)ki (m[i+1,(cid:96)])
with k0 chosen uniformly at random and ki resulting from
the evaluation of Enc(cid:96)I. It is clear that H0 is distributed just
as the inputs of DL in the ﬁrst probability distribution from
the lemma’s statement, while H(cid:96) is distributed as the inputs
of DL in the second probability distribution. We now show
that the probability with which DL can distinguish Hi−1
from Hi is bounded by prf + 2-sim, which will in turn im-
ply the expected result. For this purpose, we build, from
DL, a (s, t)-bounded distinguisher DL(cid:48) between the two dis-
tributions d1 and d2 that are the input of the distinguisher
of Lemma 2. DL(cid:48) receives its inputs mi, ci, ki, and leakages
lA, lB, l⊕, ls, ki−2 sampled from d1 or d2. It then: (1) Sam-
ples the encryption of the i− 1 ﬁrst blocks of m from LEnc(cid:96)I,
except that it uses ki−2 as key for the round i − 1 and ls
as leakage for computing ki−1; (2) Extends it with ci and
the leakages lA, lB and l⊕ for the i-th round; (3) Extends it
with LEnc(cid:96)ki (m[i+1,(cid:96)]) for the last (cid:96)− i− 1 rounds. It can be
easily veriﬁed that, if the inputs of DL(cid:48) are sampled from d1
(resp d2), then DL(cid:48) produced something sampled according
to Hi−1 (resp. Hi). If fed to DL, the result will enable DL(cid:48) to
distinguish Hi−1 from Hi with the same probability DL(cid:48) dis-
tinguishes d1 from d2. Furthermore, by inspection, we can
verify that DL(cid:48) is (s, t)-bounded. Applying Lemma 2, this
probability is then bounded by prf + 2-sim, as desired.

103Description of ENC(cid:96):

• Gen picks k0 ← {0, 1}n.
• Enc(cid:96)k0 (m1, . . . , m(cid:96)) returns c1, . . . , c(cid:96),
where ci = yi ⊕ mi, yi = Fki−1 (pB)
and ki = Fki−1 (pA).

• Dec proceeds in the natural way.

The leakage LEnc(cid:96)(k0, m) resulting from com-
puting Enc(cid:96)k0 (m) is deﬁned by the sequence
of (LF(pA, ki−1), LF(pB, ki−1), L⊕(mi, yi)) for
i ∈ {1, . . . , (cid:96)}.

Description of ENC(cid:96)I:

• Enc(cid:96)I

k0 (m1, . . . , m(cid:96)) returns (c1, . . . , c(cid:96)),
where ci = yi ⊕ mi, y1, . . . , y(cid:96) ← {0, 1}n
and k1, . . . , k(cid:96) ← {0, 1}n.

The leakage LEnc(cid:96)I (k, y, m) resulting from com-
puting Enc(cid:96)I
k0 (m) with the random vectors
k and y is deﬁned by the
sequence of
(SL(ki−1, pA, ki), SL(ki−1, pB, yi), L⊕(mi, yi))
for i ∈ {1, . . . , (cid:96)}.

Table 3: The ENC(cid:96) and ENC(cid:96)I schemes.

Further remarks on the deﬁnition of Encs. The proof
above heavily relies on the use of the extra leakages pro-
vided when running Encs, for the linking of the hybrids.
This is however not just an artifact that we use to simplify
our proof. Consider for instance a situation in which Encs
would not leak k1 and a simple leakage function LF(p, k)
would leak just the ﬁrst bit of k ⊕ Fk(p). In such a setting,
if k1 is not leaked, the leakage does not provide any useful
information on the encrypted message (we just loose one bit
of security for the key). So, if we encrypt the messages m1
and m2 with Encs using two independent keys, the leakages
do not provide us with any useful information. However,
if we encrypt the message (m1, m2) using Enc(cid:96), we will ob-
tain c1, c2 and leakages containing the ﬁrst bit of k0 ⊕ y1,
k0 ⊕ k1 and k1 ⊕ y2, from which we can derive the ﬁrst bit
of y1 ⊕ y2, and eventually the ﬁrst bit of m1 ⊕ m2, which
was not available before. This observation is a constructive
evidence that encrypting two message blocks with Enc(cid:96) can
be far more damaging on the privacy than encrypting these
blocks independently with a version of Encs from which k1
would not be leaked. The leakage of k1 in Encs prevents
the shortcoming we just described, as k1 would provoke the
leakage of the ﬁrst bit of each message block.
3.5 From 1-block to (cid:96)-block security
The above section demonstrated how one-time versions of
our encryption scheme can be idealized with controlled secu-
rity loss, in the case of single and multiple block encryption.
We now use these idealized encryption processes to evaluate
the (eavesdropper) security of an (cid:96)-block encryption with
Enc(cid:96)I by comparison with the security of (cid:96) encryptions with
EncsI performed with independent keys, block by block.

Lemma 4. For every pair of (cid:96)-block messages m0 and m1
and (s, t)-bounded adversary AL, there is an (s − sr, t − tr)-
bounded adversary AL(cid:48) such that the following holds:

(cid:12)(cid:12)(cid:12)Pr
(cid:104)AL(cid:16)
(cid:12)(cid:12)(cid:12)Pr
(cid:96)(cid:88)

i=1

= 1

(cid:105)
(cid:17)
(cid:104)AL(cid:16)
(cid:17)

ki (m0
i )

LEnc(cid:96)I

(cid:104)AL(cid:48)(cid:16)

k0 (m0)
−Pr

LEncsI

(cid:17)

LEnc(cid:96)I

k0 (m1)

= 1

(cid:105)−
(cid:104)AL(cid:48)(cid:16)

= 1

Pr

LEncsI

ki (m1
i )

(cid:105)(cid:12)(cid:12)(cid:12) ≤
(cid:17)

(cid:105)(cid:12)(cid:12)(cid:12) ,

= 1

with all k’s chosen uniformly at random, sr = (cid:96)(2sS +1) and
tr equal to 2(cid:96)tS to which we add the time needed to sample
2(cid:96) random values and compute (cid:96) times the ⊕ operations.

Proof. We proceed in two steps. We start by building
a sequence of (cid:96) + 1 messages mh,0, . . . , mh,(cid:96) starting from
m0 and modifying its blocks one by one until obtaining m1.
That is, mh,i := m1
[i+1,(cid:96)]. From the triangle inequal-
ity, it holds that:

[1,i], m0

(cid:104)AL(cid:16)
(cid:12)(cid:12)(cid:12)Pr
(cid:104)AL(cid:16)

(cid:12)(cid:12)(cid:12)Pr
(cid:96)(cid:88)

i=1

(cid:17)

(cid:105)
(cid:104)AL(cid:16)

= 1

LEnc(cid:96)I

k0 (m0)
− Pr

LEnc(cid:96)I

ki (mh,i−1)

(cid:17)

k0 (m1)

= 1

LEnc(cid:96)I

(cid:17)
(cid:105)−
(cid:104)AL(cid:16)

= 1

(cid:105)(cid:12)(cid:12)(cid:12) ≤
(cid:17)

(cid:105)(cid:12)(cid:12)(cid:12) .

= 1

Pr

LEnc(cid:96)I

ki (mh,i)

The (cid:96) diﬀerences in the sum above can now be related to
the probability of distinguishing the encryptions of single
from an EncsI encryption of m0,i or m1,i
block messages:
with the associated leakage LEncsI , it is immediate to sample
an Enc(cid:96)I encryption of mh,i−1 or mh,i with the associated
leakage LEnc(cid:96)I . The cost of this sampling is bounded by sr
leakage queries and running time tr.

Injecting Lemmas 2 and 3, which relate real and ideal
encryptions, into Lemma 4, we obtain Theorem 3 which is
our main result for eavesdropper security.

Theorem 3. Let F be a (s, t, prf )-PRF, with a leakage
simulator S L as in Lemma 2, and let (sr, tr) be the bounds
deﬁned in Lemma 3. For every pair of (cid:96)-block messages m0
and m1 and (s − sr, t − tr)-bounded adversary AL, there is
an (s − 2sr, t − 2tr)-bounded adversary AL(cid:48) such that the
following holds:

(cid:105)
(cid:104)AL(cid:0)LEnc(cid:96)k0 (m0)(cid:1) = 1
(cid:105)(cid:12)(cid:12)(cid:12) ≤
(cid:104)AL(cid:0)LEnc(cid:96)k0 (m1)(cid:1) = 1
(cid:12)(cid:12)(cid:12)Pr
(cid:105)−
(cid:104)AL(cid:48)(cid:0)LEncski (m0
i )(cid:1) = 1
(cid:104)AL(cid:48)(cid:0)LEncski (m1
i )(cid:1) = 1

(cid:105)(cid:12)(cid:12)(cid:12) + 4(cid:96)(prf + 2-sim).

(cid:12)(cid:12)(cid:12)Pr
(cid:96)(cid:88)

− Pr

Pr

i=1

It indicates that, if we want to bound the probability that
an attacker distinguishes the encryptions of two (cid:96)-block mes-
sages, we can focus on bounding the probabilities that an at-
tacker distinguishes independent encryptions of the (cid:96) pairs
of blocks, which is arguably easier, and derive the desired
bound from it. Furthermore, the security degradation is
moderate, being proportional to the number of blocks.

1043.6 From eavesdropper to CPA security
The ENC(cid:96) scheme is obviously insecure under chosen plain-
text attack. However, the PrivKlmcpa,b
AL,ENC security of the ENC
scheme can now be derived from Theorem 3.

Theorem 4. Let AL be an (s − sr, t − tr)-bounded
AL,ENC adversary against the ENC scheme based on a

PrivKlmcpa,b
(s, t, prf )-secure PRF. Then:

AL,ENC = 1] − Pr[PrivKlmcpa,1
(LEnc(cid:96)k(m0)) = 1] − Pr[AL(cid:48)

AL,ENC = 1]

(LEnc(cid:96)k(m1)) = 1]

(cid:12)(cid:12)(cid:12)Pr[PrivKlmcpa,0
(cid:12)(cid:12)(cid:12)Pr[AL(cid:48)

(cid:12)(cid:12)(cid:12) ≤

(cid:12)(cid:12)(cid:12) +

2prf + q/2n,
where AL(cid:48) is (s − 2sr, t − 2tr)-bounded, m0 and m1 are the
messages chosen by AL for the test query, sr := 3q where q
is the number of encryption queries made by AL, and tr is
the time needed to evaluate LEnc(cid:96) on q messages of at most
(cid:96) blocks and sample 2(cid:96) random values.

Proof. We proceed in two steps. First, we modify the
PrivKlmcpa,b
AL,ENC game by replacing the leak-free PRF with a ran-
dom function. Since the cost of the reduction of this change
to the PRF security is less than the (sr, tr) bounds, the
probability that AL detects the change is bounded by prf .
Next, we rely on the perfectly random distribution of the
ephemeral keys (k(cid:48)) used by Enc to emulate the leak-free
PRF and (consistently) answer all encryption queries with
random IV ’s and random ephemeral key k0’s. For the test
query, we generate a random IV , but use the LEnc(cid:96) oracle to
produce the ciphertext. This strategy will only fail when the
random IV selected here is equal to one of the IV’s gener-
ated during one of the at most q previous encryption queries,
bounding the probability of this event by q/2n. Again, the
cost of answering these queries is bounded by (sr, tr).

4. LEAK-FREE COMPONENT INSTANTI-

ATION AND IMPERFECTIONS

Our constructions make use of a component modeled as leak-
free used as part of the initialization of every MAC and en-
cryption computation. Of course, it is unlikely that such a
thing exists in reality. A simple work-around to this situa-
tion would be to require this component to be polynomially
simulatable instead, i.e., require that it would satisfy the
simulatability deﬁnition (Def. 3) for a number of observa-
tions q that would be high enough to not be reached within
the life-time of the circuit. This would add a degradation
factor corresponding to the one of the q-sim bound into all
our reductions (which we did not do for clarity).

This requirement is of course much more demanding than
the bound q = 2 that appears in the rest of our proofs,
and would then require a highly protected implementation
of this speciﬁc primitive, which might be considerably slower
and demanding in energy. Concretely, we expect it to be a
dozen to a few hundred times less eﬃcient than the weakly
protected one used in the leakage-resilient parts of our con-
structions (i.e. all the light grey blocks in Figures 2, 3 and 4).
This is the typical gap between a standard implementation
of the AES and a heavily protected implementation using
masking and other countermeasures. For illustration, Ta-
ble 4 reports some performance ﬁgures for unprotected and
masked AES in software and hardware that are in these

ranges.4 We believe that this gap amply motivates our min-
imal use of the strongly protected component:
it makes it
possible to amortize its cost as soon as messages contain a
few kilobits (the longer the better, of course), resulting in
an eﬃciency gain of a factor comparable to the gap between
the two implementations when comparing with a situation
where a strongly-protected implementation would be used
everywhere. Besides, and as previously mentioned, the ran-
dom inputs of the highly protected component are indepen-
dent of the messages that are manipulated, which makes it
possible to run these (pre)computations in advance, there-
fore avoiding any delay when the messages are available.

As for the practical security of the proposed schemes, we
anticipate that it will also follow the analyses in [3]. That
is, the leakage-resilient parts of our constructions are ex-
pected to lower-bound the time complexity of the best side-
channel attacks independently of the number of adversarial
measurements (e.g. up to >80 bits depending of the im-
plementations). As for the strongly protected (intialization)
component, and as previously mentioned, the side-channel
attacks’ complexity cannot be bounded independently of the
number of adversarial measurements. So the security level
highly depends on the choice of q in this case. For example,
Table 5 (for software implementations) and 18 (for hardware
implementations) in [3] estimate the cost to maintain secu-
rity levels of > 80 bits with up to q measurements. In gen-
eral, masking increases security exponentially in the number
of masks for a quadratic performance overheads. So we can
theoretically have q arbitrarily large in the leak-free com-
ponent, but for much larger overheads than in the leakage-
resilient parts of our constructions – which again motivates
our approach. Of course and as usual, further evaluations
(on various devices) by third-parties remain welcome to im-
prove the understanding of the concrete implementation se-
curity of our encryption and authentication schemes.

5. ACKNOWLEDGEMENTS
Olivier Pereira’s work has been partly supported by the
GreenTIC TrueDev Walloon region project 1317971.
Fran¸cois-Xavier Standaert is a research associate of the Bel-
gian Fund for Scientiﬁc Research (F.R.S.-FNRS). His work
has been funded in part by the European Commission
through the ERC project 280141 (acronym CRASH).
Srinivas Vivek has been supported in part by the European
Union’s H2020 programme under grant agreement number
ICT-644209.

6. REFERENCES
[1] CHES 2013, volume 8086 of Lecture Notes in

Computer Science. Springer, 2013.

[2] M. Abdalla, S. Bela¨ıd, and P. Fouque.

Leakage-resilient symmetric encryption via re-keying.
In CHES 2013 [1], pages 471–488.

[3] S. Bela¨ıd, V. Grosso, and F. Standaert. Masking and

leakage-resilient primitives: One, the other(s) or both?
Cryptography and Communications, 7(1):163–184,
2015.

4 The cost functions are code size × cycle count for software
implementations, and area / throughput for hardware ones.
The physical assumptions are additional properties that jus-
tify the higher implementation cost of certain solutions (e.g.
regarding the independent leakage assumption).

105Software (8-bit)
Implementations
Unprotected [8]
1-mask Boolean [34]
1-mask polynomial [13, 32]
2-mask Boolean [34]
FPGA (Virtex-5)
Implementations

Unprotected (128-bit) [33]
1-mask Boolean (128-bit) [33]
Threshold (8-bit) [26]

code size
(bytes)

1659
3153
20 682
3845
area

(slices)

478
1462
958

cycle
count
4557
129 · 103
1064 · 103
271 · 103
throughput
(enc/sec)

11

245·106
100·106
170·106

11

266

cost

function

physical

assumptions

7.560
406.7
22 000
1042
cost

-

glitch-sensitive
glitch-resistant
glitch-sensitive

physical

function

assumptions

21.46
160.8
1499

-

glitch-sensitive
glitch-resistant

Table 4: Performance of some illustrative AES implementations (borrowed from [3]).

[4] M. Bellare, J. Kilian, and P. Rogaway. The security of

[14] V. Grosso, F. Standaert, and S. Faust. Masking vs.

the cipher block chaining message authentication
code. J. Comput. Syst. Sci., 61(3):362–399, 2000.
[5] S. Chari, C. S. Jutla, J. R. Rao, and P. Rohatgi.

Towards sound approaches to counteract
power-analysis attacks. In CRYPTO ’99, volume 1666
of Lecture Notes in Computer Science, pages 398–412.
Springer, 1999.

multiparty computation: how large is the gap for
AES? J. Cryptographic Engineering, 4(1):47–57, 2014.

[15] C. Hazay, A. L´opez-Alt, H. Wee, and D. Wichs.

Leakage-resilient cryptography from minimal
assumptions. In EUROCRYPT 2013, volume 7881 of
Lecture Notes in Computer Science, pages 160–176.
Springer, 2013.

[6] Y. Dodis and K. Pietrzak. Leakage-resilient

[16] Y. Ishai, A. Sahai, and D. Wagner. Private circuits:

pseudorandom functions and side-channel attacks on
feistel networks. In CRYPTO 2010, volume 6223 of
Lecture Notes in Computer Science, pages 21–40.
Springer, 2010.

[7] S. Dziembowski and K. Pietrzak. Leakage-resilient
cryptography. In FOCS 2008, pages 293–302. IEEE
Computer Society, 2008.

[8] T. Eisenbarth, Z. Gong, T. G¨uneysu, S. Heyse,
S. Indesteege, S. Kerckhof, F. Koeune, T. Nad,
T. Plos, F. Regazzoni, F. Standaert, and L. van
Oldeneel tot Oldenzeel. Compact implementation and
performance evaluation of block ciphers in attiny
devices. In A. Mitrokotsa and S. Vaudenay, editors,
AFRICACRYPT 2012, volume 7374 of Lecture Notes
in Computer Science, pages 172–187. Springer, 2012.

[9] S. Faust, K. Pietrzak, and J. Schipper. Practical

leakage-resilient symmetric cryptography. In CHES
2012, volume 7428 of Lecture Notes in Computer
Science, pages 213–232. Springer, 2012.

[10] B. Fuller and A. Hamlin. Unifying leakage classes:
Simulatable leakage and pseudoentropy. In ICITS
2015, volume 9063 of Lecture Notes in Computer
Science, pages 69–86. Springer, 2015.

[11] J. L. Galea, D. P. Martin, E. Oswald, D. Page,
M. Stam, and M. Tunstall. Simulatable leakage:
Analysis, pitfalls, and new constructions. In
ASIACRYPT 2014, volume 8873 of Lecture Notes in
Computer Science, pages 223–242. Springer, 2014.

[12] D. Galindo and S. Vivek. A leakage-resilient

pairing-based variant of the Schnorr signature scheme.
In IMA International Conference, IMACC 2013,
volume 8308 of Lecture Notes in Computer Science,
pages 173–192. Springer, 2013.

[13] V. Grosso, F. Standaert, and S. Faust. Masking vs.

multiparty computation: How large is the gap for aes?
In CHES 2013 [1], pages 400–416.

Securing hardware against probing attacks. In
CRYPTO 2003, volume 2729 of Lecture Notes in
Computer Science, pages 463–481. Springer, 2003.

[17] M. Joye and M. Tunstall, editors. Fault Analysis in

Cryptography. Information Security and Cryptography.
Springer, 2012.

[18] E. Kiltz and K. Pietrzak. Leakage resilient ElGamal

encryption. In ASIACRYPT 2010, volume 6477 of
Lecture Notes in Computer Science, pages 595–612.
Springer, 2010.

[19] L. R. Knudsen and M. Robshaw. The Block Cipher

Companion. Information Security and Cryptography.
Springer, 2011.

[20] M. Liskov, R. L. Rivest, and D. Wagner. Tweakable

block ciphers. In CRYPTO 2002, volume 2442 of
Lecture Notes in Computer Science, pages 31–46.
Springer, 2002.

[21] S. Mangard, E. Oswald, and T. Popp. Power analysis
attacks - revealing the secrets of smart cards. Springer,
2007.

[22] S. Mangard, T. Popp, and B. M. Gammel.

Side-channel leakage of masked CMOS gates. In
CT-RSA 2005, volume 3376 of Lecture Notes in
Computer Science, pages 351–365. Springer, 2005.
[23] D. P. Martin, E. Oswald, and M. Stam. A leakage

resilient MAC. IACR Cryptology ePrint Archive,
2013:292, 2013.

[24] M. Medwed, F. Standaert, J. Großsch¨adl, and

F. Regazzoni. Fresh re-keying: Security against
side-channel and fault attacks for low-cost devices. In
AFRICACRYPT 2010, volume 6055 of Lecture Notes
in Computer Science, pages 279–296. Springer, 2010.

[25] S. Micali and L. Reyzin. Physically observable

cryptography (extended abstract). In TCC 2004,
volume 2951 of Lecture Notes in Computer Science,
pages 278–296. Springer, 2004.

106[26] A. Moradi, A. Poschmann, S. Ling, C. Paar, and

H. Wang. Pushing the limits: A very compact and a
threshold implementation of AES. In K. G. Paterson,
editor, EUROCRYPT, volume 6632 of Lecture Notes
in Computer Science, pages 69–88. Springer, 2011.

[27] M. Naor and G. Segev. Public-key cryptosystems

resilient to key leakage. In CRYPTO 2009, volume
5677 of Lecture Notes in Computer Science, pages
18–35. Springer, 2009.

[28] S. Nikova, V. Rijmen, and M. Schl¨aﬀer. Secure

hardware implementation of nonlinear functions in the
presence of glitches. J. Cryptology, 24(2):292–321,
2011.

[29] P. Pessl, F. Standaert, S. Mangard, and F. Durvaux.

Towards leakage simulators that withstand the
correlation distinguisher. ASIACRYPT 2014 rump
session talk, 2014.

[30] C. Petit, F. Standaert, O. Pereira, T. Malkin, and

M. Yung. A block cipher based pseudo random
number generator secure against side-channel key
recovery. In ASIACCS 2008, pages 56–65. ACM, 2008.
[31] K. Pietrzak. A leakage-resilient mode of operation. In
EUROCRYPT 2009, volume 5479 of Lecture Notes in
Computer Science, pages 462–482. Springer, 2009.
[32] E. Prouﬀ and T. Roche. Higher-order glitches free

implementation of the AES using secure multi-party
computation protocols. In B. Preneel and T. Takagi,
editors, CHES 2011, volume 6917 of Lecture Notes in
Computer Science, pages 63–78. Springer, 2011.

[33] F. Regazzoni, W. Yi, and F.-X. Standaert. FPGA
implementations of the AES masked against power
analysis attacks. In COSADE 2011, pp 56-66,
Darmstadt, Germany, February 2011.

[34] M. Rivain and E. Prouﬀ. Provably secure higher-order

masking of AES. In S. Mangard and F. Standaert,
editors, CHES 2010, volume 6225 of Lecture Notes in
Computer Science, pages 413–427. Springer, 2010.
[35] J. Schipper. Leakage-resilient authentication. Msc

thesis, Centrum Wiskunde and Informatica, The
Netherlands, 2010.

[36] F. Standaert, O. Pereira, and Y. Yu. Leakage-resilient

symmetric cryptography under empirically veriﬁable
assumptions. In CRYPTO 2013, volume 8042 of
Lecture Notes in Computer Science, pages 335–352.
Springer, 2013.

[37] F. Standaert, O. Pereira, Y. Yu, J. Quisquater,

M. Yung, and E. Oswald. Leakage resilient
cryptography in practice. In Towards
Hardware-Intrinsic Security - Foundations and
Practice, Information Security and Cryptography,
pages 99–134. Springer, 2010.

[38] Y. Yu and F. Standaert. Practical leakage-resilient

pseudorandom objects with minimum public
randomness. In CT-RSA 2013, volume 7779 of Lecture
Notes in Computer Science, pages 223–238. Springer,
2013.

[39] Y. Yu, F. Standaert, O. Pereira, and M. Yung.

Practical leakage-resilient pseudorandom generators.
In CCS 2010, pages 141–151. ACM, 2010.

APPENDIX
A. PROOF OF THEOREM 1
Consider the following hybrid games:

Hybrid H +. This is the original security game executed as
deﬁned in the experiment Forgeeuf−cma
AL,MAC(n) (Deﬁnition 1, Re-
mark 1). In particular, the q session keys k(i)
(i = 1, 2, . . . , q)
1
are the output of F on random IV s. Let the queried mes-
sages (each containing (cid:96) blocks) be denoted as mi = (cid:104)m(i)
1 ,
(cid:96) (cid:105) (i = 1, 2, . . . , q). The advantage of a q-query ad-
. . . , m(i)
versary AL in Forgeeuf−cma

AL,MAC(n) is (cid:48).

Hybrid H ++. This is the same as hybrid H + except that
the q IV s randomly chosen are distinct. Let ++ denote the
advantage of AL in this hybrid. Using the birthday bound,
we have that:

(cid:12)(cid:12)

(cid:48) − ++(cid:12)(cid:12) ≤ q2

2n+1 .

(1)
Hybrid H∗. This is the same as hybrid H ++ except that
$← {0, 1}n are chosen uniform ran-
the q session keys k(i)
domly and independently. Let ∗ denote the advantage of
1
AL in this hybrid. It is easy to see that:

(cid:12)(cid:12)++ − 

∗(cid:12)(cid:12) ≤ prf .

(2)
This is because using the adversary AL of MAC1, we can
construct a (s, t(cid:48), prf ) against F.
Hybrids H∗
i,j. Next, we successively transform the hybrid
i,j (1 ≤ i ≤ q +1, 0 ≤ j ≤ (cid:96)) by transform-
H∗ into hybrids H∗
ing the normal execution of the block cipher F into an ideal
execution one message block at a time. More precisely, the
hybrids H∗ and H∗
1,1, the out-
1 , m(1)
put of F(k(1)
1 ) while processing the ﬁrst message block
during the ﬁrst tag-generation query is a uniform random
element in {0, 1}n and leakages are simulated (cf. Lemma
1). The processing of the remaining message blocks in the
ﬁrst as well as the later queries is carried out “normally.”
By “normal” we mean that the actual values of F are used
for all except the ﬁrst block of the ﬁrst message and all the
session keys, unless for consistency we are forced to use the
random sampled value in case the inputs (k(1)
1 ) to F
appear again elsewhere later.

1,0 are identical. In hybrid H∗

1 , m(1)

More generally, in the hybrid H∗

i,(cid:96) and H∗

i,j, all the evaluations of
F are treated as ideal until (and including) the jth message
block of the ith tag query. All the remaining evaluations of
F are normal upto the consistency requirement mentioned
i+1,0 are identical for 1 ≤ i ≤
above. The hybrids H∗
q, and the veriﬁcation of the plausible forgery output by AL
is considered as q + 1-st tag query except that the leakages
and the tag are not output. This means that the hybrids
H∗
q+1,j correspond to idealizing the execution of F during the
veriﬁcation stage. Note that the goal of the adversary AL
is to break the strong-unforgeability of MAC1. This means
that either it outputs a forgery on a distinct IV for a possibly
previously queried message, or it outputs a forgery on a
previously queried IV but on a distinct message. We assume
without loss of generality that the forgery output by AL
satisﬁes either of the above two conditions and it makes
exactly q tag request queries. Hence the hybrids H∗
q+1,j will
be present. Note that this last sequence of hybrids may be

107avoided if we try to follow the standard approach of ﬁrst
showing that the construction is a PRF and hence it is a
MAC. But it turns out this way we need more hybrid games
than the current approach.
Next, we show that in the successive hybrids H∗
i,j and
i,j+1 (1 ≤ i ≤ q + 1, 0 ≤ j ≤ (cid:96) − 1), the views of AL
H∗
are computationally identical upto the 2-simulatable leakage
assumption. Let i,j and i,j+1 denote the advantages of AL
in the hybrids H∗

i,j+1, respectively.

i,j and H∗

.

2n

i,j or hybrid H∗

Lemma 5. |i,j − i,j+1| ≤ prf + 2-sim + (q+1)2((cid:96)+1)2
Proof. Using AL as a subroutine, we construct a (s(cid:48), t(cid:48))-
bounded distinguisher DL for the distributions of Lemma 1
that has advantage as indicated on the R.H.S. of Lemma
5. DL simulates hybrid H∗
i,j+1 depending on
whether its input distribution is actual or ideal, respectively.
DL chooses a uniform random shared secret key k, random
session keys ki,1 (1 ≤ i ≤ q), and possibly a random session
key kq+1,1 for veriﬁcation if the target forgery is on a diﬀer-
ent IV. Whenever DL samples a random output value, say
γ, on “key-message” input (α, β) it records the input/output
pair ((α, β), γ) in a table T , in addition to the simulated
leakage S L(˜k∗, β, γ) (˜k∗ $← {0, 1}n). This table is used to
consistently return the same (random) output on the same
input pair. Also, all the block cipher evaluations while the
processing the tag requests return random outputs and sim-
ulated leakages until (including) the jth message block of the
ith tag request. Recall the notation that the j(cid:48)th block of the
i(cid:48)th message is denoted by mi(cid:48),j(cid:48) , and the corresponding key
and the output for the evaluation of F is denoted by ki(cid:48),j(cid:48)
and ki(cid:48),j(cid:48)+1, respectively. A ‘*’ in the superscript of a pa-
rameter, for example, as in k∗
i(cid:48),j(cid:48) , explicitly denotes that the
parameter was chosen uniform randomly and independently
(and was not computed normally).
At this point, DL ﬁrst receives its input d5 upon querying
$← {0, 1}n (cf.
its challenger with Gen(˜k∗
Remark 3). It then uses d5 instead of the simulated leakage
S L(˜k∗
i,j). Note that the output of this round is im-
plicitly set to k(cid:48) (if j = 0, then the session key k∗
i,1 is implic-
itly set to k(cid:48)). It then builds the view for the (i, j + 1)th ex-
ecution of F by querying its challenger for (d1, d3) by query-
ing Enc(mi,j+1) (p0 := mi,j+1). DL then provides AL with
(d1, d3). The remaining steps are executed normally by eval-
uating F with the (known) inputs. In case any inconsistency
arises when F is evaluated with the inputs present in the ta-
ble T , then the corresponding output value recorded in the
table is used. Such a situation does arise when the adver-
sary outputs a possible forgery on a message m(cid:48) w.r.t. the
IV IVi, such that m(cid:48) (cid:54)= mi share a common preﬁx. Also,
note that to evaluate F w.r.t. the (implicit) key k(cid:48), DL has
to use its input distribution to determine the output. This
means that if there are more than two queries to F w.r.t. the
(implicit) key k(cid:48), then DL will abort the simulation. Denote
this abort event by Abort.

i,j, mi,j) with ˜k∗

i,j, mi,j, k∗

i,j

In order for this simulation by DL to AL to be consistent

with the working of MAC1, two events must not occur.

• All the random values sampled (and listed in table T )

must be distinct.

• The abort event Abort mentioned above must not occur.
Let us denote both the events by Collision. The reason for the
ﬁrst of the above conditions is that if the intermediate values
repeat, then a possible pattern could arise in the successive
intermediate values and there by implicitly setting the out-
put of the (i, j)th step to k(cid:48) may lead to inconsistency. Next,
to ensure that the Abort event does not arise, and hence 2-
simulatable assumption suﬃces, we need to make sure that
k(cid:48) is never used as key more than once later. This means
that F is not queried with the input (k∗
i,j, mi,j) more than
once later. Note that if the ﬁrst condition above does not
occur, then the outputs of the later steps are function of pa-
rameters independent of the value k∗
i,j, except possibly once
during the veriﬁcation stage. It is easy to see that:

Pr[Collision] ≤ (q + 1)2((cid:96) + 1)2

2n

.

(3)

Hence the lemma follows from Lemma 1 and (3).

Note that there are at most (q + 1)(cid:96) distinct hybrids H∗
(1 ≤ i ≤ q + 1, 0 ≤ j ≤ (cid:96)) since the hybrids H∗
are identical for 1 ≤ i ≤ q. Also note that the hybrids H∗
and H∗
|
∗ − q+1,(cid:96)| ≤ (q + 1)(cid:96)(prf + 2−sim) +

1,0 are identical as well. Hence we obtain:

(q + 1)3(cid:96)((cid:96) + 1)2

i,(cid:96) and H∗

i+1,0

i,j

.

2n

(4)

1

2n+1

2n−((q+1)((cid:96)+1))2 + (q+1)2((cid:96)+1)2

Lemma 6. q+1,(cid:96) ≤
Proof. In this hybrid, all the evaluations of F are ideal,
that means that distinct “key-message” input pairs produce
random output values, and all the leakages are simulated.
To break the strong-unforgeability property of MAC1, AL
must either output a forgery on a distinct IV for a possibly
previously queried message, or it outputs a forgery on a pre-
viously queried IV but on a distinct message. This implies
that during the veriﬁcation step, conditioned on the event
of no collision of randomly chosen output values, there will
be distinct “key-message” pairs with which F will be queried
and, as a consequence, a random output will be produced.
Further, no collision would imply that the same would hap-
pen with the later message blocks during the veriﬁcation
step, including the ﬁnal block. Note that the probability
of collision is at most (q+1)2((cid:96)+1)2
. Again, conditioned on
the event of no collision, the probability that the tag τ out-
put by AL is a valid forgery for the message m is at most
2n−((q+1)((cid:96)+1))2 . Hence the lemma follows.

2n+1

1

Theorem 1 follows from (1), (2), (4) and Lemma 6.

108