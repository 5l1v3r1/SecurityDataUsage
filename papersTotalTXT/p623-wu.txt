The Impact of Vendor Customizations on Android Security

Lei Wu, Michael Grace, Yajin Zhou, Chiachih Wu, Xuxian Jiang

Department of Computer Science

North Carolina State University

{lwu4, mcgrace, yajin_zhou, cwu10}@ncsu.edu, jiang@cs.ncsu.edu

ABSTRACT

The smartphone market has grown explosively in recent years, as
more and more consumers are attracted to the sensor-studded mul-
tipurpose devices. Android is particularly ascendant; as an open
platform, smartphone manufacturers are free to extend and modify
it, allowing them to differentiate themselves from their competitors.
However, vendor customizations will inherently impact overall An-
droid security and such impact is still largely unknown.

In this paper, we analyze ten representative stock Android im-
ages from ﬁve popular smartphone vendors (with two models from
each vendor). Our goal is to assess the extent of security issues
that may be introduced from vendor customizations and further de-
termine how the situation is evolving over time. In particular, we
take a three-stage process: First, given a smartphone’s stock im-
age, we perform provenance analysis to classify each app in the
image into three categories: apps originating from the AOSP, apps
customized or written by the vendor, and third-party apps that are
simply bundled into the stock image. Such provenance analysis
allows for proper attribution of detected security issues in the ex-
amined Android images. Second, we analyze permission usages of
pre-loaded apps to identify overprivileged ones that unnecessarily
request more Android permissions than they actually use. Finally,
in vulnerability analysis, we detect buggy pre-loaded apps that can
be exploited to mount permission re-delegation attacks or leak pri-
vate information.

Our evaluation results are worrisome: vendor customizations are
signiﬁcant on stock Android devices and on the whole responsible
for the bulk of the security problems we detected in each device.
Speciﬁcally, our results show that on average 85.78% of all pre-
loaded apps in examined stock images are overprivileged with a
majority of them directly from vendor customizations. In addition,
64.71% to 85.00% of vulnerabilities we detected in examined im-
ages from every vendor (except for Sony) arose from vendor cus-
tomizations. In general, this pattern held over time – newer smart-
phones, we found, are not necessarily more secure than older ones.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516728.

Categories and Subject Descriptors

D.4.6 [Security and Protection]: Information ﬂow controls; D.2.5
[Software Engineering]: Testing and Debugging—Code inspec-
tions and walk-throughs

Keywords

Android; Provenance; Customization; Static Analysis

1.

INTRODUCTION

The smartphone market has grown explosively in recent years,
as more and more consumers are attracted to the sensor-studded
multipurpose devices. According to IDC [30], smartphone ven-
dors shipped a total of 482.5 million mobile phones in the fourth
quarter of 2012 – levels nearly equal to those of feature phones.
Meanwhile, among smartphones, Google’s Android captured al-
most 70% of the global smartphone market share last year [31],
compared to about 50% the year before [20].

Android’s popularity is due in part to it being an open platform.
Google produces a baseline version of Android, then makes it freely
available in the form of the Android Open Source Project (AOSP).
Manufacturers and carriers are free to build upon this baseline,
adding custom features in a bid to differentiate their products from
their competitors. These customizations have grown increasingly
sophisticated over time, as the hardware has grown more capable
and the vendors more adept at working with the Android frame-
work. Flagship devices today often offer a substantially different
look and feel, along with a plethora of pre-loaded third-party apps.
From another perspective, vendor customizations will inherently
impact overall Android security. Past work [24] has anecdotally
shown that Android devices had security ﬂaws shipped in their pre-
loaded apps. Note that stock images include code from potentially
many sources:
the AOSP itself, the vendor, and any third-party
apps that are bundled by the vendor or carrier. It is therefore im-
portant to attribute each particular security issue back to its source
for possible bug-ﬁxes or improvements.

In this paper, we aim to study vendor customizations on stock
Android devices and assess the impact on overall Android secu-
rity. Especially, we intend to determine the source of the security
issues that trouble Android smartphone images, then further deter-
mine how the situation is evolving over time. To that end, we de-
velop a three-stage process to evaluate a given smartphone’s stock
ﬁrmware image. First, we perform provenance analysis, aiming
to classify each pre-loaded app into three categories: apps origi-
nating from the AOSP, apps customized or written by the vendor,
and third-party apps that are simply bundled into the stock image.
We then analyze, in two different ways, the security implications of
each app: (1) Permission usage analysis compares the permissions

623requested by the app with those that it actually uses, looking for
apps that request more permissions than they use. This situation
is known as permission overprivilege, and it indicates a poor un-
derstanding of the Android security model; (2) Vulnerability anal-
ysis, in comparison, looks for two general types of actual security
vulnerabilities: permission re-delegation attacks and content leaks.
Permission re-delegation attacks allow unprivileged apps to act as
though they have certain sensitive permissions, while content leaks
allow such apps to gain (unauthorized) access to private data.

To facilitate our analysis, we implement a Security Evaluation
Framework for Android called SEFA to evaluate stock smartphone
images. Given a particular phone ﬁrmware image, SEFA ﬁrst pre-
processes it and imports into a local database a variety of informa-
tion about the image, including the number of apps and numerous
information about each app, such as the list of requested permis-
sions, declared components, and the set of used Android APIs.
Then SEFA compares each pre-loaded app with various ones in
the original AOSP to determine its source and further performs a
system-wide data-ﬂow analysis to detect possible vulnerabilities.
In our study, we have applied SEFA to ten ﬂagship phone models
from ﬁve popular vendors: Google, Samsung, HTC, LG, and Sony.
For each vendor, we selected two phones: one from the current
crop of Android 4.x phones, and one from the previous generation
of 2.x devices. This slate of devices allows us to do two compara-
tive analyses: horizontal differential analysis compares the various
manufacturers’ offerings for a given generation, while vertical dif-
ferential analysis studies the evolution of any given vendor’s secu-
rity practices chronologically.

Our evaluation results show that more than 81.78% of pre-loaded
apps (or 76.34% of LOC) on stock Android devices are due to
vendor customizations. It is worrisome to notice that vendor cus-
tomizations were, on the whole, responsible for the bulk of the se-
curity problems suffered by each device. On average, 85.78% of all
pre-loaded apps in examined stock images are overprivileged with
a majority of them directly from vendor customizations. And ven-
dor apps consistently exhibited permission overprivilege, regard-
less of generation. Our results also show that vendor customiza-
tions are responsible for a large proportion of the vulnerabilities
in each phone. For the Samsung, HTC, and LG phones, between
64.71% and 85.00% of the vulnerabilities were due to vendor cus-
tomizations. This pattern was largely stable over time, with the no-
table exception of HTC, whose current offering is markedly more
secure than the last-generation model we evaluated.

The rest of this paper is organized as follows. We present our
methodology and system framework in Section 2, and describe im-
plementation and evaluation results with case studies in Section 3.
We then discuss for possible improvements in Section 4. Finally,
we compare with related work and conclude this paper in Section 5
and Section 6 respectively.

2. DESIGN

The goal of this work is to study vendor customizations on stock
Android devices and assess corresponding security impact. Note
that the software stack running in these devices are complex, and
their ﬁrmware is essentially a collaborative effort, rather than the
work of a single vendor. Therefore, we need to categorize the code
contained in a stock image based on its authorship and audit it for
possible security issues. After that, we can attribute the ﬁndings of
the security analyses to the responsible party, allowing us to better
understand the state of smartphone security practices in the industry
and spot any evident trends over time.

In Figure 1, we summarize the overall architecture of the pro-
posed SEFA system. Our system takes a stock phone image as

Preprocessing

Database

Provenance Analysis

Permission Usage Analysis

Vulnerability Analysis

Figure 1: The overall architecture of SEFA

its input, preprocessing each app and importing the results into a
database. This database, initially populated with a rich set of in-
formation about pre-loaded apps (including information from their
manifest ﬁles, signing certiﬁcates, as well as their code, etc.), is
then used by a set of subsequent analyses. Each analysis reads
from the database, performs its analysis, and stores its ﬁndings in
the database.

To study the impact of vendor customizations on the security of
stock Android smartphones, we have developed three such analy-
ses. First, to classify each app based on its presumed authorship,
we perform provenance analysis (Section 2.1). This analysis is
helpful to measure how much of the baseline AOSP is still retained
and how much customizations have been made to include vendor-
speciﬁc features or third-party apps. To further get a sense of the
security and privacy problems posed by each app, we use two dif-
ferent analyses: permission usage analysis (Section 2.2) assesses
whether an app requests more permissions than it uses, while vul-
nerability analysis (Section 2.3) scans the entire image for concrete
security vulnerabilities that could compromise the device and cause
damage to the user. Ultimately, by correlating the results of the se-
curity analyses with the provenance information we collected, we
can effectively measure the impact of vendor customizations.

2.1 Provenance Analysis

The main purpose of provenance analysis is to study the distri-
bution of pre-loaded apps and better understand the customization
level by vendors on stock devices. Speciﬁcally, we classify pre-
loaded apps into three categories:

• AOSP app: the ﬁrst category contains apps that exist in the

AOSP and may (or may not) be customized by the vendor.

• vendor app: the second category contains apps that do not

exist in the AOSP and were developed by the vendor.

• third-party app: the last category contains apps that do not

exist in the AOSP and were not developed by the vendor.

The idea to classify pre-loaded apps into the above three cat-
egories is as follows. First we collect AOSP app candidates by
searching the AOSP, then we exclude these AOSP apps from the
pre-loaded ones. After that, we can classify the remaining apps
by examining their signatures (i.e., information in their certiﬁcate
ﬁles) based on a basic assumption: third-party apps shall be private
and will not be modiﬁed by vendors. Therefore, they will not share
the same signing certiﬁcates with vendor apps.

In practice, this process is however not trivial. Since AOSP apps
may well be customized by vendors, their signatures are likely to
be changed as well. Although in many cases, the app names, pack-
age names or component names are unchanged, there do exist ex-
ceptions. For example, Sony’s Conversations app, with package
name com.sonyericsson.conversations, is actually a customized
version of the AOSP Mms app named com.android.mms. In order
to solve this problem, we perform a call graph similarity analysis,

624which has been demonstrated to be an effective technique even to
assist malware clustering and provenance identiﬁcation [29].

To generate the call graph required by any such analysis, we add
all method calls that can be reached starting from any entrypoint
method accessible to other apps or the framework itself. However,
we are hesitant to use graph isomorphism techniques to compare
these call graphs, as they are complex and have undesirable perfor-
mance characteristics. Instead, we notice that later analysis (Sec-
tion 2.3) will use paths, sequences of methods that start at an en-
trypoint and ﬂow into a sink (i.e., API or ﬁeld which may require
sensitive permissions, lead to dangerous operations or meet other
special needs). Therefore, we choose to preprocess each app, ex-
tract and compare the resulting paths, a much more straightforward
process that still compare the parts of each app that we are most
concerned with.

From our prototype, we observe that such a path-based similarity
analysis is implementation-friendly and effective. Particularly, we
use the return type and parameters (number, position and type) of
each node (method) in the path as its signature. If the similarity be-
tween two paths exceeds a certain threshold, we consider these two
paths are matching. And the similarity between two apps is largely
measured based on the number of matched paths. In our prototype,
to determine which apps belong to the AOSP, we accordingly take
the approach: (1) by matching app names and package names; (2)
by matching component names in the manifest ﬁle; (3) and then
by calculating the similarity between paths and apps. We point out
that a ﬁnal manual veriﬁcation is always performed to guarantee
the correctness of the classiﬁcation, which can also conﬁrm the ef-
fectiveness of our heuristics.

During this stage, we also collect one more piece of informa-
tion: the code size of pre-loaded apps measured by their lines of
code (LOC). Although it is impossible for us to get all the source
code of the pre-loaded apps, we can still roughly estimate their size
based on their decompiled .smali code.1 Therefore, we can draw a
rough estimate of vendor customization from provenance analysis
because the number and code size of apps are important indicators.
In addition, we also collect ﬁrmware release dates and update cy-
cles as supplementary information for our later evaluation (Section
3.1).

2.2 Permission Usage Analysis

Our next analysis stage is designed to detect instances of permis-
sion overprivilege, where an app requests more permissions than it
uses. SEFA applies permission usage analysis to measure the adop-
tion of the principle of least privilege in app development. Note that
here it is only possible to get the usage of permissions deﬁned in the
standard AOSP framework. The usage of vendor-speciﬁc permis-
sions cannot be counted because of the lack of related information.
There are four types of permissions in Android: normal, dan-
gerous, system and systemOrSignature. The latter three are sensi-
tive, because normal permissions are not supposed to be privileged
enough to cause damage to the user. Speciﬁcally, we deﬁne per-
missions declared by element uses-permission in the manifest ﬁle
as requested permissions, and permissions which are actually used
(e.g., by using related APIs) as used permissions respectively. An
overdeclared permission is a permission which is requested but not
used. Overprivileged apps contain at least one overdeclared per-
mission.

Algorithm 1 outlines our process for permission usage analysis.
From the database, we have the initial requested permission set of
apps (as it is in the manifest information), and our goal is to ﬁnd the

1We use the baksmali [42] tool to translate the Android app’s

.dex code into the .smali format.

Algorithm 1: Permission Usage Analysis

Input: initial info. in our database about pre-loaded apps
Output: overdeclared permission set of apps

apps = all apps in one image;
mappings = all permission mappings;
A = API invocation set;
I = intent usage set;
C = content provider usage set;
S = shared user id set;
R = requested-permission set;
U = ∅; // used permission set
O = ∅; // overdeclared permission set

foreach s ∈ S do

tmp = ∅;
foreach app ∈ s do

tmp = tmp ∪ R[app];

foreach app ∈ s do
R[app] = tmp;

foreach app ∈ apps do

foreach a ∈ A[app] do

U [app].add(mappings[a]);

foreach i ∈ I[app] do

U [app].add(mappings[i]);

foreach c ∈ C[app] do

U [app].add(mappings[c]);

foreach app ∈ apps do

O[app] = R[app] − U [app];

return O

overdeclared permission set. Despite the initial requested permis-
sion set, we ﬁnd it still needs to be augmented. Especially, there is
a special manifest ﬁle attribute, sharedUserId, which causes mul-
tiple apps signed by the same developer certiﬁcate to share a user
identiﬁer, thus sharing their requested permission sets.
(As per-
missions are technically assigned to a user identiﬁer, not an app, all
such apps will be granted the union of all the permissions requested
by each app. Accordingly, apps with the same sharedUserId re-
quire extra handling to get the complete requested permission set.)
Next, we leverage the known permission mapping built by earlier
work [2] to determine which permissions are actually used.2 Hav-
ing built both the requested permission set and the used permission
set, we can then calculate the overdeclared permission set.

Our approach to calculate the overdeclared permission set is con-
servative. Notice that some permissions declared in the manifest
ﬁle may be deprecated in the corresponding standard Android frame-
3 that was
work. An example is the permission READ_OWNER_DATA
removed after API level 8 (i.e., Android version 2.2), but still de-
clared by one app in the Nexus 4 (API level 17, or Android 4.2).
We do not consider them as overdeclared permissions, because the
vendor may retain deprecated permissions in the customized frame-
work for its own usage.

2Early studies including PScout [2] concern themselves only
with those permissions that are available to third-party apps. In our
study, we need to cover additional permissions deﬁned at system
and systemOrSignature levels, which may not be well documented.
3Without speciﬁcation, the preﬁx of standard Android permis-

sion name android.permission. is omitted in this paper.

625After obtaining the overdeclared permission set, we then analyze
the overall permission usage of each device, and classify results
by provenance. The distributions of overprivileged apps as well as
overdeclared permissions can then both be studied. Further, we also
perform horizontal and vertical analysis, i.e., cross-vendor, same-
generation, vs. cross-generation, same-vendor comparisons.

2.3 Vulnerability Analysis

While our permission usage analysis aims to measure the soft-
ware development practices used in the creation of each pre-loaded
app, vulnerability analysis is concerned with ﬁnding real, action-
able exploits within those apps. Speciﬁcally, we look for two rep-
resentative types of vulnerabilities in the Android platform which
stem from misunderstanding or misusing Android’s permission sys-
tem. First, we identify permission re-delegation attacks [18], which
are a form of the classic confused deputy attack [27]. Such an
attack exists if an app can gain access to an Android permission
without actually requesting it. A typical example is an app which
is able to send Short Message Service (SMS) messages without ac-
quiring the (supposedly required) SEND_SMS permission. For the
second kind of vulnerability, we consider content leaks, which es-
sentially combines the two types of content provider vulnerabili-
ties reported by Zhou and Jiang [52]: passive content leaks and
content pollution. An unprotected content provider (i.e., one that
takes no sensitive permission to protect its access) is considered
to have a passive content leak if it is world-readable, and to have
content pollution if it is world-writable. We extend this deﬁnition
to cover both open and protected content providers. The protected
ones are also interesting as there may also exist unauthorized ac-
cesses to them through the other three types of components which
could serve as springboards for exploitation. For ease of presenta-
tion, we call these vulnerabilities content leaks.

As our main goal is to accurately locate possible vulnerabilities,
we in this study consider the following adversary model: a mali-
cious app, which is compatible with the phone, may be installed
on the phone by the user. We do not expect the malicious app will
request any sensitive permissions during installation, which means
it will only rely on vulnerable apps to accomplish its goals: either
steal money from the user, gather conﬁdential data, or maliciously
destroy data. In other words, we limit the attacker to only unprivi-
leged third-party apps to launch their attacks.

Keeping this adversary model in mind, we focus our analysis
on security-critical permissions – the ones that protect the func-
tions that our adversary would most like to gain access to. Specif-
ically, for permission re-delegation attacks, we focus on permis-
sions that are able to perform dangerous actions, such as SEND_SMS
and MASTER_CLEAR, because they may lead to serious damage to the
user, either ﬁnancially or in terms of data loss. As for content leaks,
we ignore those whose exposures are likely to be intentional4. Note
that some apps may be vulnerable to low-severity content leaks;
for example, publicly-available information about a network TV
schedule is not as sensitive as the user’s banking credentials. In
other words, we primarily consider serious content leaks whose ex-
posures are likely to cause critical damages to the user.

To actually ﬁnd these vulnerabilities, we rely on a few key tech-
niques. An essential one is reachability analysis, which is used to
determine all feasible paths from the entrypoint set of all Android
components, regardless of whether we consider them to be pro-
tected by a sensitive permission (Section 2.3.1). To better facilitate
vulnerability analysis, we deﬁne two varieties of sinks:

4Some content providers are exported explicitly, such as

TelephonyProvider in the app of the same name.

• sensitive-sinks: sensitive Android APIs which are related to

sensitive permissions (e.g., MASTER_CLEAR) of our concern

• bridge-sinks: invocations that are able to indirectly trigger

another (vulnerable) component, e.g., sendBroadcast

Note that any path reachable from an open entrypoint or com-
ponent can be examined directly to see if it has a sensitive-sink.
Meanwhile, we also determine whether it could reach any bridge-
link that will trigger other protected components (or paths). The
remaining paths, whose entrypoints are protected, are correlated
with paths that contain bridge-sinks to form the complete vulner-
able path, which is likely cross-component or even cross different
apps. This is essentially a reﬂection-based attack and we will de-
scribe it in Section 2.3.2 in greater detail. All calculated (vulnera-
ble) paths will subject to manual veriﬁcation.

We stress that unlike some previous works (e.g., [24]) which
mainly focus on discovery of vulnerabilities, this analysis stage
primarily involves a more contextual evaluation of vulnerabilities,
including distribution, evolution and the impact of customization.
Especially, we use the distribution of vulnerable apps as a metric to
assess possible security impact from vendor customizations. Note
the detected vulnerabilities are classiﬁed into different categories
by their provenance and leveraged to understand the corresponding
impact of customization. As mentioned earlier, both horizontal and
vertical impact analyses are performed.

2.3.1 Reachability Analysis

Our reachability analysis is performed in two steps. The ﬁrst step
is intra-procedural reachability analysis, which involves building
related call graphs and resolving it by conventional def-use analy-
sis [11]. The resolution starts from the initial state (pre-computed
when the database is initially populated) and then gradually seeks
a ﬁxed point of state changes with iteration (due to various transfer
functions). However, as the state space might be huge (due to com-
binatorial explosion), the convergence progress could be slow or
even unavailable. In practice, we have to impose additional condi-
tional constraints to control the state-changing iteration procedure.
We call the result of intra-procedural analysis, i.e., the states of
variables and ﬁelds, a summary.

The second step is inter-procedural reachability analysis that is
used to propagate states between different methods. After each
propagation, method summaries might be changed. In such cases,
intra-procedural reachability analysis is performed again on each
affected method to generate a new summary. Inter-procedural reach-
ability analysis is also an iterative process, but takes longer and
requires more space to converge; therefore, we use some heuris-
tics to reduce the computational and space overhead. For instance,
if a variable or ﬁeld we are concerned with has already reached a
sink, there is no need to wait for convergence. A more formal de-
scription of our reachability analysis is listed in Algorithm 3 (see
Appendix A).

Paths of apps from different vendors but with similar functional-
ity may share something in common, especially for those apps in-
herited from the standard AOSP framework. Here “common” does
not mean that their source code is exactly the same, but is similar
from the perspective of structure and functionality. Many devices
reuse the code from the AOSP directly, without many modiﬁca-
tions. If we have already performed reachability analysis on such
a common path, there is no need to do it on its similar counter-
parts. We believe this improves system performance since reacha-
bility analysis is time consuming (especially when the state space
is huge). Therefore, we also perform a similarity analysis as a part
of the reachability analysis to avoid repetitive efforts.

6262.3.2 Reﬂection Analysis

To facilitate our analysis, we classify vulnerable paths into the

following three types:

• in-component: a vulnerable path that starts from an unpro-
tected component to a sink that is located in the same com-
ponent.

• cross-component: a vulnerable path that starts from an un-
protected component, goes through into other components
within the same app, and then reaches a sink.

• cross-app: a vulnerable path that starts from an unprotected
component of one app, goes through into another app’s com-
ponents, and eventually reaches a sink.

The in-component vulnerable paths are relatively common and
have been the subject of recent studies [24, 34]. However, the latter
two, especially the cross-app ones, have not been well studied yet,
which is thus the main focus of our reﬂection analysis. Note that
a reﬂection-based attack typically involves with multiple compo-
nents that may not reside in the same app. A concrete example that
is detected by our tool will be shown in Figure 6 (Section 3.3.1).

Traditional reachability analysis has been effective in detecting
in-component vulnerable paths. However, it is rather limited for
other cross-component or cross-app vulnerable paths. (A cross-app
execution path will pass through a chain of related apps to ulti-
mately launch an attack.) In order to identify them, a comprehen-
sive analysis of possible “connection” between apps is necessary.
To achieve that, our approach identiﬁes not only possible reachable
paths within each component, but also the invocation relationship
for all components. The invocation relationship is essentially in-
dicated by sending an intent [21] from one component to another,
explicitly or implicitly. An explicit intent speciﬁes the target com-
ponent to receive it and is straightforward to handle. An implicit
intent, on the other hand, may be sent anonymously without spec-
ifying the receiving component, thus requiring extra handling (i.e.,
intent resolution in Android) to determine the best one from the
available components. In our system, SEFA essentially mimics the
Android intent resolution mechanism by matching an intent against
all possible <intent-filter> manifest declarations in the installed
apps. However, due to the ofﬂine nature of our system, we have
limited available information about how the framework behaves at
run-time. Therefore, we develop the following two heuristics:

• A component from the same app is preferable to components

from other apps.

• A component from a different app which shares the same

sharedUserId is preferable to components from other apps.

If multiple component candidates still exist for a particular in-
tent, we simply iterate each one to report possible vulnerable path
and then manually verify it in a real phone setting. In Algorithm 2,
we summarize the overall procedure. The basic idea here is to
maintain a visited component list. For a particular component, the
algorithm returns ∅ if it has been visited; otherwise we add it into
the list, and check all possible components that are able to start up
that component recursively.

3.

IMPLEMENTATION AND EVALUATION
We have implemented a SEFA prototype as a mix of Java code
and Python scripts with 11, 447 and 4, 876 lines of code (LOC)

5This category contains apps that exist in the AOSP and may (or
may not) be customized by the vendor – Section 2.1. This deﬁnition
also applies to Tables 3, 4 and 5.

Algorithm 2: Reﬂection Analysis

Input: current component, visited component list
Output: vulnerable path set
/* find vulnerable paths recursively from

backward for current component

c = current component;
V C = visited component list;
CC = components which are able to start up c;
V = ∅; // vulnerable path set

*/

if c ∈ V C then

return V

else

V C.append(c);

foreach cc ∈ CC do

tmp = V C.clone();
V .add(Reﬂection Analysis(cc, tmp));

return V

respectively.
In our evaluation, we examined ten representative
phones (Table 1) released between the end of 2010 and the end
of 2012 by ﬁve popular vendors: Google, Samsung, HTC, LG, and
Sony. The selected phone model either has great impact and is
representative, or has huge market share. For example, Google’s
phones are designed to be reference models for their whole genera-
tion; Samsung is the market leader which occupies 39.6% of smart-
phone market share in 2012 [30]. To analyze these phone images,
our system requires on average 70 minutes to process each image
(i.e., around 30 seconds per app) and reports about 300 vulnerable
paths for us to manually verify. Considering the off-line nature of
our tool, we consider this acceptable, even though our tool could
be optimized further to speed up our analysis.

3.1 Provenance Analysis

As mentioned earlier, the provenance analysis collects a wide
variety of information about each device and classiﬁes pre-loaded
apps into three different categories. In Table 1, we summarize our
results. Overall, these ten devices had 1,548 pre-loaded apps, to-
talling 114,427,232 lines of code (in terms of decompiled .smali
code). A further break-down of these apps show that, among these
devices, there are on average 28.2 (18.22%), 99.7 (64.41%), and
26.9 (17.38%) apps from the categories of AOSP, vendor and third-
party, respectively. Note that the apps in the AOSP category may
also be customized or extended by vendors (Section 2.1). As a
result, the ﬁgures in the AOSP column of Table 1 should be con-
sidered an upper bound for the proportion of code drawn from the
AOSP. Accordingly, on average, vendor customizations account for
more than 81.78% of apps (or 76.34% of LOC) on these devices.

In our study, we selected two phone models for each vendor, one
from the current crop of Android 4.x phones, and one from the pre-
vious generation of 2.x devices. Table 2 shows the initial release
date of each phone model, as reported by GSM Arena [26]. As it
turns out, these devices can be readily classiﬁed by their release
dates: the past generation of devices all were initially released be-
fore 2012, while the current generation’s products were released in
2012 or later. Therefore, we break them down into pre-2012 and
post-2012 devices. Such classiﬁcation is helpful to lead to certain
conclusions. For example, as one might expect, the complexity of
these devices is clearly increasing over time. In all cases, the post-
2012 products from any given manufacturer contain more apps and
LOC than their pre-2012 counterparts. Speciﬁcally, the HTC Wild-
ﬁre S has 147 apps with 9,643,448 LOC, and the HTC One X has

627Table 1: Provenance analysis of representative devices

Vendor
Samsung
Samsung

HTC
HTC
LG
LG
Sony
Sony
Google
Google

Device

Galaxy S2
Galaxy S3
Wildﬁre S

One X

Optimus P350
Optimus P880
Xperia Arc S

Xperia SL
Nexus S
Nexus 4

Total

Version & Build #
2.3.4; I9100XWKI4
4.0.4; I9300UBALF5

2.3.5; CL362953
4.0.4; CL100532

2.2; FRG83

4.0.3; IML74K

2.3.4; 4.0.2.A.0.62
4.0.4; 6.1.A.2.45
2.3.6; GRK39F

4.2; JOP40C

Total

# Apps

# LOC

172
185
147
280
100
115
176
209
73
91

1548

10,052,891
17,339,442
9,643,448
19,623,805
6,160,168
12,129,841
7,689,131
10,704,797
5,234,802
15,848,907
114,427,232

AOSP app 5

vendor app

# Apps (%)
26 (15.12%)
30 (16.22%)
24 (16.33%)
29 (10.36%)
27 (27.00%)
28 (24.35%)
28 (15.91%)
28 (13.40%)
31 (42.47%)
31 (34.07%)
282 (18.22%)

# LOC (%)

# Apps

2,419,155 (24.06%)
6,344,721 (36.59%)
2,759,415 (28.61%)
4,718,633 (24.05%)
1,152,885 (18.72%)
3,170,950 (26.14%)
1,164,691 (15.15%)
1,800,690 (16.82%)
1,036,858 (19.81%)
2,506,778 (15.82%)
27,074,776 (23.66%)

114
119
94
190
40
63
123
156
41
57
997

# LOC
3,519,955
5,660,569
3,514,921
7,354,468
604,197
3,269,936
2,666,397
4,127,343
2,821,874
12,156,673
45,696,333

# Apps

third-party app
# LOC
4,113,781
5,334,152
3,369,112
7,550,704
4,403,086
5,688,955
3,858,043
4,776,764
1,376,070
1,185,456
41,656,123

32
36
29
61
33
24
25
25
1
3

269

Release Date1

Table 2: Release dates of examined Android devices
Device
Nexus S
Nexus 4
Wildﬁre S

Update Date 2 & Version
4.0.4, Mar 2012; 4.1.2, Oct 2012
N/A
N/A
4.1.1, Nov 2012; 4.1.2, Mar 2013
N/A
4.1.2, Mar 2013
2.3.6, Dec 2011; 4.0.3 Jul 2012; 4.1.1,
Jan 2013; 4.1.2, Apr 2013
4.1.1, Nov 2012; 4.1.2, Mar 2013
4.0.4, Aug 2012
4.1.2, May 2013

Dec 2010
Nov 2012
May 2011
May 2012
Feb 2011
Jun 2012
Apr 2011

One X

Optimus P350
Optimus P880

Galaxy S2

Galaxy S3

Xperia Arc S

Xperia SL

May 2012
Sep 2011
Sep 2012

1

The release dates may vary by area and carrier, but the difference is not that

signiﬁcant (e.g., around one month).

2

The update dates collected here are mainly for markets in United States.

280 apps with 19,623,805 LOC. The number of apps and LOC in-
crease 90.47% and 103.49%, respectively.

Our analysis also shows that, though the baseline AOSP is in-
deed getting more complicated over time – but vendor customiza-
tions are at least keeping pace with the AOSP. This trend is not dif-
ﬁcult to understand, as vendors have every incentive to add more
functionality to their newer products, especially in light of their
competitors doing the same.

The Google-branded phones are particularly interesting. Both
have relatively few apps, as they are designed to be reference de-
signs with only minor alterations to the core AOSP. However, the
Nexus 4 has over three times as many lines of code as were in-
cluded in the Nexus S, despite adding only 18 apps. The Nexus S
was the simplest phone we studied, while the Nexus 4 is the third
most complex – only the HTC One X and Samsung Galaxy S3,
which are well known for their extensive customization, have more
LOC. We attribute this to the fact that the Nexus 4 includes newer
versions of vendor-speciﬁc apps (e.g., Gmail) that have more func-
tionality with larger code size.

Meanwhile, we also observe these devices experience slow up-
date cycles: the average interval between two updates for a phone
model is about half a year! Also, it is interesting to note that the
updates in the United States tend to lag behind some other areas.
For instance, users of the Samsung Galaxy S3 in the United King-
dom received updates to Android 4.1.1 (which was released in July
2012) in September 2012, while the updates were not available for
users in the United States until January 2013. If we compare the
update dates in Table 1 with the corresponding dates of Android
releases [22], it often takes half a year for vendors to provide an of-
ﬁcial update (excepting Google’s reference phones) for users in the
United States, though in many cases carriers may share the blame.
Overall, ofﬁcial updates can hardly be called timely, which thereby
seriously affects the security of these devices.

3.2 Permission Usage Analysis

After determining the provenance of each pre-loaded app, our
next analysis captures the instances of permission overprivilege,
where an app requests more permissions than it uses. The results
are summarized in Table 3. On average, there is an alarming fact
that across the ten devices, 85.78% of apps are overprivileged.
Even Google’s reference devices do not necessarily perform bet-
ter than the others; the Nexus S has the second most overprivileged
apps of all the pre-2012 devices. Note that the situation appears
to be getting slightly better as time goes on. The average percent-
age of overprivileged apps in the post-2012 devices has decreased
to 83.61%, compared to 87.96% of all apps on pre-2012 devices.
But this situation is still hardly reassuring. Interestingly, our re-
sults show that the proportion of overprivileged pre-loaded apps
are more than the corresponding result of third-party apps (reported
by [2, 17]). We believe there are two main reasons: 1) pre-loaded
apps are more privileged than third-party apps, as they can request
certain permissions not available to third-party ones; 2) pre-loaded
apps are more frequent in specifying the sharedUserId property,
thereby gaining many (possibly unnecessary) permissions.

Speciﬁcally, if we take into account the provenance of each app,
a different story emerges. Looking over the breakdowns in Table 3,
the modest gains over time appear to be primarily attributable to a
reduction in app overprivilege among AOSP apps; vendors appear
to be responsible for roughly the same amount of overprivileged
apps in each image (51.29% of all pre-2012 apps, vs. 52.71%
of post-2012 apps). In this sense the vendors themselves do not
appear to care signiﬁcantly more about the least privilege principle
than third-party app developers do, despite being, on average, much
larger corporate entities.

In Figure 2, we summarize the distributions of overprivileged
apps among pre-2012 devices and post-2012 devices respectively.
The majority of overprivileged apps have no more than 10 overde-
clared permissions. Note that pre-loaded apps have access to cer-
tain permissions that are not available to third-party apps. There-
fore, these overdeclared permissions, if exploited, can lead to greater
damage. For example, our results demonstrate that both REBOOT and
MASTER_CLEAR are among overdeclared permissions that can allow
for changing (important) device status or destroying user data with-
out notiﬁcation.

3.3 Vulnerability Analysis

Our vulnerability analysis led to several interesting results, espe-
cially once combined with our efforts to determine the provenance
of each app. In particular, if we consider the distribution of vul-
nerable apps across each phone image (Table 4), the percentage
of vulnerable apps of these devices varies from 1.79% to 14.97%.
Applying our horizontal analysis to each generation of devices, it
appears that the HTC Wildﬁre S and LG Optimus P880 have the

628Table 3: Permission usage analysis of representative devices

Pre-2012 devices

% of overprivileged apps among all pre-loaded apps

AOSP app 5

vendor app

third-party app

Device

Nexus S
Wildﬁre S

Optimus P350

Galaxy S2

Xperia Arc S

Average

Total

90.41%

92.52%

85.00%

88.37%

83.52%

38.36%

15.65%

23.00%

13.95%

14.20%

50.68%

57.82%

33.00%

58.14%

56.82%

87.96%

21.03%

51.29%

1.37%

19.05%

29.00%

Device

Nexus 4
One X

Optimus P880

16.28%

12.50%

Galaxy S3
Xperia SL
Average
Overall Average: 85.78%

15.64%

Post-2012 devices

% of overprivileged apps among all pre-loaded apps

Total

79.12%

78.21%

91.30%

87.57%

81.82%

AOSP app 5

vendor app

third-party app

30.77%

10.00%

20.87%

15.14%

11.96%

48.35%

50.71%

50.43%

55.68%

58.37%

0.00%

17.50%

20.00%

16.76%

11.48%

83.61%

17.75%

52.71%

13.15%

Table 4: Vulnerability analysis of representative devices (I)

Pre-2012 devices

Post-2012 devices

% of vulnerable apps among all apps
AOSP app 5

vendor app

third-party app

% of vulnerable apps among all apps
AOSP app 5

vendor app

third-party app

Device

Nexus S
Wildﬁre S

Optimus P350

Galaxy S2

Xperia Arc S

Average

Total
5.48%

14.97%

11.00%

12.21%

2.27%

8.99%

2.74%

4.76%

4.00%

3.49%

1.14%

2.74%

8.84%

1.00%

6.98%

0.00%

3.23%

3.91%

by no more than 5 permissions
by 6 to 10 permissions
by more than 10 permissions

0.00%

1.36%

6.00%

Device

Nexus 4
One X

Total
2.20%

1.79%

Optimus P880

10.43%

1.74%

1.14%

Galaxy S3
Xperia SL
Average
Overall Average: 6.77%

1.85%

n
o
i
t
a
z
i
m
o
t
s
u
c
 

o
t
 
e
u
d

 
s
e
i
t
i
l
i
b
a
r
e
n
l
u
v

 
f
o
%

 

  90%

  80%

  70%

  60%

  50%

  40%

  30%

  20%

  10%

  0%

6.49%

1.91%

4.56%

Wildfire S

O

ne X

1.10%

0.71%

5.22%

2.70%

0.96%

1.10%

0.71%

5.22%

3.24%

0.48%

2.14%

2.15%

0.00%

0.36%

0.00%

0.54%

0.48%

0.28%

O

ptim

O

ptim

us P350

us P880

G

alaxy S2

G

alaxy S3

X

X

peria Arc S

peria S

L

p
p
a
 

d
e
g
e
l
i
v
i
r
p
r
e
v
o

 
f
o
%

 

p
p
a
 

d
e
g
e
l
i
v
i
r
p
r
e
v
o

 
f
o
%

 

  70%

  60%

  50%

  40%

  30%

  20%

  10%

  0%

  70%

  60%

  50%

  40%

  30%

  20%

  10%

  0%

Nexus S

Wildfire S

Optimus P350

Galaxy S2

Xperia Arc S

(a) Pre-2012 devices

by no more than 5 permissions
by 6 to 10 permissions
by more than 10 permissions

Nexus 4

One X

Optimus P880

Galaxy S3

Xperia SL

(b) Post-2012 devices

Figure 2: Distributions of overprivileged apps

most vulnerable apps in each generation. Inversely, the Sony Xpe-
ria Arc S and – interestingly – the HTC One X have the least vul-
nerable apps by proportion. As one may expect, Google’s reference
phones (especially the Nexus 4) both perform well compared to
their contemporaries, as their images are designed to be a reference
baseline. Our vertical analysis has an even more impressive result
– the percentage of vulnerable apps across each generation dropped
from an average of 8.99% last generation to 4.56% this generation.
Even incorporating provenance information in the vertical analysis,
there is a dramatic improvement for all three categories of app.

However, the percentage of vulnerable apps is not necessarily
a good metric to measure the security of such devices. The com-
plexity metrics we collected as part of our provenance analysis (see
Table 1) show that the devices contain ever-increasing amounts of
code. Therefore, while fewer vulnerabilities – as a percentage –
may be introduced in newer phones, the sheer scale of their stock

Figure 3: Vulnerabilities due to vendor customizations

images works to counteract any gains. Furthermore, some vulnera-
ble apps may contain more vulnerabilities than others. As a result,
there is value in counting the absolute number of critical vulnera-
bilities as well as the proportion of vulnerable apps.

To this end, we summarize our results in that format in Table 5.
When we use this table for vertical differential analysis, it tells quite
a different story. While, indeed, the number of vulnerabilities in
each generation of devices generally decreased, the reduction is
nowhere near so dramatic. Furthermore, when considered in hor-
izontal differential analysis, different devices take the crown for
most and least secure devices in each generation. The HTC Wild-
ﬁre S is still the least secure pre-2012 device, but only by a hair
– the Samsung Galaxy S2 has only one fewer vulnerability. The
Sony Xperia Arc S is tied with the Google Nexus S for the most
secure pre-2012 device. Meanwhile, there is a complete shake-up
among the post-2012 devices: the Samsung Galaxy S3 has 40 vul-
nerabilities to the LG Optimus P880’s 26, while the HTC One X
(at 15 vulnerabilities) falls to mid-pack, behind the Nexus 4 (at 3)
and the Sony Xperia SL (at 8).

Table 5 still does not tell the complete story. Looking at the ta-
ble’s provenance analysis results, it appears that most of the vulner-
abilities stem from the AOSP. However, recall that our provenance
analysis concerns the original provenance of each app, not each
vulnerability. To gather information about the provenance of each
vulnerability, we manually examine each of the reported vulnerable
paths. Our results are shown in Figure 3 (note that Google’s phones
are not included here because the AOSP is led by Google, making
the distinction difﬁcult). For the Samsung, HTC, and LG phones,
the majority of vulnerabilities – between 64.71% and 85.00% – did
not originate from the AOSP. However, for both of Sony’s products,

629Table 5: Vulnerability analysis of representative devices (II)

Device

Nexus S
Wildﬁre S

Optimus P350

Galaxy S2

Xperia Arc S

Total

8

40

17

39

8

Pre-2012 devices

AOSP app 1

# of vulnerabilities
vendor app

third-party app

6

23

11

18

6

2

15

1

18

0

0

2

5

3

2

Device

Nexus 4
One X

Optimus P880

Galaxy S3
Xperia SL

Total

3

15

26

40

8

Post-2012 devices

AOSP app 1

# of vulnerabilities
vendor app

third-party app

2

12

17

20

6

1

2

9

12

1

0

1

0

8

1

This category contains apps that exist in the AOSP and may (or may not) be customized by the vendor – Section 2.1.

1

n
o
i
t
u
l
o
v
e
 
s
e
i
t
i
l
i
b
a
r
e
n
l
u
v

 
f
o
%

 

Inherited
Introduced

  70%

  60%

  50%

  40%

  30%

  20%

  10%

  0%

 

s
e
i
t
i
l
i
b
a
r
e
n
l
u
v
p
p
a
−
s
s
o
r
c
 
f
o
%

 

  14%

  12%

  10%

  8%

  6%

  4%

  2%

  0%

N

exus S

N

exus 4

Wildfire S

O

ne X

O

ptim

O

ptim

us P350

us P880

G

G

alaxy S2

alaxy S3

X

X

peria Arc S

peria S

L

Figure 5: Distribution of cross-app vulnerabilities

conﬁrmed, other vendors have still not spoken with us even after
several months. Among the detected vulnerabilities, we believe
cross-app ones are the most challenging to detect. Figure 5 gives
the percentage of cross-app vulnerabilities. On average, 8.90% vul-
nerabilities are of this type. In the following, we describe some
speciﬁc vulnerabilities introduced due to vendor customizations.

3.3.1 Case Study: Samsung Galaxy S3

In the Samsung Galaxy S3, there is a pre-loaded app named
Keystring_misc. This particular app has a protected component
PhoneUtilReceiver that leads to a dangerous path for performing
a factory reset, thus erasing all user data on the device. This path
ends in the phoneReset method, which will broadcast an intent
android.intent.action.MASTER_CLEAR to perform the operation.
At ﬁrst sight, this path seems to be safe because this component is
protected by the com.sec.android.app.phoneutil.permission.-
KEYSTRING permission, which is deﬁned with the restrictive syste-
mOrSignature protection level (i.e., only other ﬁrmware apps, or
apps from Samsung, can invoke it).

Unfortunately, there exists another app named FactoryTest that
contains a feasible path which is able to start up this very com-
ponent in the Keystring_misc app. This arrangement is an exam-
ple of a cross-app vulnerable path, which can be used to launch
a reﬂection attack (Figure 6). Speciﬁcally, this app exports a ser-
vice called FtClient without any protection. After being launched,
the service will start a thread and then try to build connections
with two hard-coded local socket addresses: FactoryClientRecv
and FactoryClientSend. The established connections can be ex-
ploited to send commands through the ﬁrst socket. Our manual
investigation shows that there are many dangerous operations that
can be triggered by this exploit, including MASTER_CLEAR, REBOOT,
SHUTDOWN and SEND_SMS.

In our study, we also discover a number of other vulnerabilities.
For example, there are four content providers in the sCloudBackup-
Provider app (with the package name of com.sec.android.sCloud
BackupProvider). They expose access interfaces to speciﬁc databases,
including calllogs.db, sms.db, mms.db and settings.db. Each
of them is protected by two permissions, but with normal (non-
sensitive) protection levels. Apparently, they are accessible to any

One X

Optimus P880

Galaxy S3

Xperia SL

Figure 4: Vendor-speciﬁc vulnerability evolution

only 37.50% of vulnerabilities were caused by vendor customiza-
tions. In fact, one of Sony’s modiﬁcations to the AOSP actually
mitigated a pre-existing bug in it.

We can also apply vertical differential analysis to this data, and
therefore look at the evolution of vulnerabilities over time. The
post-2012 devices may have inherited some vulnerabilities that were
never caught during the lifetime of the pre-2012 devices, as they
often have code in common with earlier devices by the same man-
ufacturer6; alternatively, they may have introduced new vulnerabil-
ities in their new and altered features. Figure 4 depicts this evo-
lutionary information, which varies wildly in proportion between
different vendors. For example, for the HTC One X, about 60.00%
of its vulnerabilities were inherited from the previous device, while
the Samsung Galaxy S3 has more introduced vulnerabilities than
inherited ones (47.50% vs. 35.00%).

Table 6: Classiﬁcation of detected vulnerabilities

Name
CALL_PRIVILEGED

Description
Initiate a phone call (including emergency
number) without requiring conﬁrmation

MASTER_CLEAR Wipe out user data and factory reset

REBOOT
RECORD_AUDIO
SEND_SMS
SHUTDOWN
WRITE_SMS
OTHER

Reboot the device
Allows an application to record audio.
Allows an application to send SMS messages.
Power off the device
Allows an application to write SMS messages
All the other dangerous/critical operations

No treatment of this topic would be complete without discussing
the distribution of vulnerabilities that we found. Table 6 lists the
vulnerabilities we focus on. We use the names of permission to
represent the most common (i.e., shared by devices of different
vendors) vulnerabilities for permission re-delegation attacks with
explicit permission names, and use OTHER to represent all other vul-
nerabilities (including both types of studied vulnerabilities). Note
that vulnerabilities belong to OTHER do not mean they are not crit-
ical, and the only reason is that they are more vendor- and model-
speciﬁc. Table 7 lists the distribution of these vulnerabilities.

With these detected vulnerabilities, we have attempted to contact
the corresponding vendors. While some of them have already been
6The relationship between each pair of devices may be not di-
rect (i.e., predecessor and successor), but we can still regard these
vulnerabilities as an inheritance because they are vendor-speciﬁc.

630Name

CALL_PRIVILEGED

MASTER_CLEAR

REBOOT

RECORD_AUDIO

SEND_SMS
SHUTDOWN
WRITE_SMS

OTHER
Total

Table 7: Distribution of vulnerabilities among examined devices

# of vulnerabilities

Google

HTC

LG

Samsung

Sony

Nexus S

Nexus 4 Wildﬁre S

One X

P350

P880

Galaxy S2

Galaxy S3

Xperia Arc S

Xperia SL

1

0

0

0

3

0

2

2

8

0

0

0

0

2

0

0

1

3

2

1

0

1

6

0

5

25

40

1

0

0

0

3

0

6

5

1

0

0

0

4

0

3

9

15

17

3

0

1

1

4

0

3

14

26

2

3

4

1

7

0

4

18

39

4

2

4

1

7

1

4

17

40

1

0

0

0

3

0

2

2

8

1

0

0

0

3

0

2

2

8

FactoryTest

com.sec.factory.aporiented.FtClient

void onCreate()

ConnectionThread
void run()

com.sec.factory.aporiented.AtParser

void process(String,ResponseWriter)

com.sec.factory.aporiented.athandler.AtFactorst

java.lang.String handleCommand(java.lang.String[])

void DoFactoryReset()

Keystring_misc

com.sec.android.app.phoneutil.PhoneUtilReceiver

void onReceive(android.content.Context,android.content.Intent)

void DoFactoryReset(android.content.Context)

com.sec.android.app.sysdump.FactoryReset

void onCreate(Bundle)

void startFactoryReset()

void phoneReset()

Figure 6: An example path of reﬂection attack

third-party app. Also, notice that this app exports four receivers
without any protection, and it is able to craft speciﬁc intents that
trigger corresponding backup actions to save various private infor-
mation into these databases (e.g., standard SMS messages stored in
mmssms.db will be copied into sms.db). After that, any app can
simply retrieve these sensitive information (e.g., SMS messages
and contacts information) through the corresponding four content
providers without acquiring any sensitive permission.

3.3.2 Case Study: LG Optimus P880

The LG Optimus P880 has a number of vulnerabilities; here, we
will detail two of them, leading to a permission re-delegation at-
tack and a content leak respectively. However, unlike the Samsung
vulnerabilities, neither of the ones we will describe are reﬂection
attacks, making them easier to detect, describe, and exploit.

The ﬁrst one is related to REBOOT, a permission reserved for sys-
tem or pre-loaded apps. In the LG Optimus P880, there is an app
named LGSettings, which is a customized version of the AOSP Set-
tings app. This particular app exports an activity com.android.-
settings.Reboot (completely without permission protection). This
activity will be triggered if an android.intent.action.MAIN intent
is received, and its invocation will simply reboot the device directly.
Note that the AOSP does not have the corresponding vulnerable
component.

The second one is a rather direct content leak vulnerability. The
com.lge.providers.lgemail content provider in the LGEmail app
is not protected, and therefore exposes access to the EMAIL.db, a

database that contains three tables named EAccount, EMessageBox
and EMessage. These tables are very sensitive, as through them, all
account and message related information (including message con-
tents) can be exposed. Note that this app is customized from the
AOSP Email app; however, in the AOSP, the corresponding con-
tent provider is protected by a permission named com.android.-
email.permission.ACCESS_PROVIDER with the systemOrSignature
protection level. Therefore, LG’s customization here adds a vulner-
ability to an otherwise-secure AOSP app.

4. DISCUSSION

While collecting the data for our evaluation, we saw some indi-
rect evidence of software development policies in place at the var-
ious vendors. This evidence may be anecdotal, but we feel it is in-
teresting enough to warrant mention. For example, Sony’s standout
performance does not appear to be accidental; in both their devices
that we studied, the eventstream content provider (which was im-
plemented as an SQLite database, as many are) actually had explicit
checks for SQL injection attacks. Furthermore, Sony’s customized
version of the AOSP Mms app actually mitigated problems found
in the unaltered problem. Similarly, as we remarked in Section 2.3,
HTC made considerable progress between the release of the HTC
Wildﬁre S and the One X, possibly due to early exposure of a large
proportion of security vulnerabilities in earlier HTC’s devices [39]
and the efforts made by the corporation to take security to heart
ever since. The One X makes extensive use of custom permissions
to prevent further vulnerabilities from creeping into its ﬁrmware –
a relatively straightforward approach to take, yet an effective one,
as shown by our vulnerability analysis.

We also note that there are not very strong correlations between
a number of superﬁcial metrics and the number of vulnerabilities
present in a stock ﬁrmware image. Code size does not strongly
correlate: the Nexus 4 has the third-largest number of LOC, but the
lowest number of vulnerabilities in the whole study. The number
of apps does not correlate: both Sony devices perform very well,
despite having a very large number of apps, while the LG devices
do poorly on security even though they have the fewest apps of any
non-reference device. Finally, even popularity does not appear to
correlate with security: Samsung’s Galaxy S3 was the most popular
smartphone of 2012, having shipped in excess of 50 million units
as of March 2013 [45], and yet it had the most vulnerabilities of
any phone in its generation studied in this paper.

Lastly, we would like to acknowledge some of the limitations of
our work. We do not cover the customization of system level code,
which can be an interesting topic for future research. Our current
prototype also has several constraints. First of all, our static anal-
ysis produces a relatively high false positive rate. On average, our
analysis produces less than 300 paths per device. While it does not
make too much effort to manually verify each path, it would be bet-
ter if we could use a light-weight dynamic analyzer to reduce the

631manual workload. Secondly, we generate the call graph recursively.
In order to avoid very deep (potentially inﬁnite) recursion, we con-
strain our analysis in two ways: only acyclic graphs are allowed,
and/or the maximum length of a path (or the maximum exploration
time) is set as an upper boundary for safety. These constraints may
prevent us from discovering certain vulnerabilities if there exists
heavy code obfuscation that either extends the length of vulnerable
path or modiﬁes the sinks we use to deﬁne such paths. Fortunately,
it is our experience that most pre-loaded apps (other than bundled
third-party apps) are not extensively obfuscated. As a result, these
constraints were primarily triggered by inﬁnite recursion, not by
overly long, yet valid, call chains.

5. RELATED WORK

Provenance Analysis

In our system, provenance provides im-
portant context which we use when evaluating the results of our
other analyses. However, determining the provenance of an app or
a piece of code is a difﬁcult problem, which has attracted much re-
search. For example, traditional similarity measurement has been
widely used in malware (e.g., virus and worm) clustering and inves-
tigation. Kruegel et al. [32] propose an approach to detect polymor-
phic worms by identifying structural similarities between control
ﬂow graphs. SMIT [29], a malware database management system
based on malware’s function-call graphs, is able to perform large
scale malware indexing and queries. Note these approaches are
mainly developed for PC malware and have considerably more so-
phistication – and complexity – than our own. In the same spirit, we
use chains of method signatures to determine whether a pre-loaded
app is, in fact, an altered version of a core AOSP app. Previous
insights however should be able to further guide us in improving
accuracy and completeness of our approach.

In the Android platform, one line of inquiry concerns detecting
repackaged apps – apps that have been altered and re-uploaded
by some party other than the original author. DroidMOSS [50],
DNADroid [9] and PiggyApp [49] all focus on detecting repack-
aged apps in Android app markets, while AppInk [46] pays at-
tention to deterring repackaging behavior with watermarking tech-
niques. These efforts all must establish the ancestry of any given
app, which mirrors our efforts to understand, longitudinally, the
evolution of ﬁrmware images using vertical differential analysis.
However, we are not as concerned with the arrow of time – it
is obvious the relationship between the original AOSP image and
the vendor’s customizations, for legal reasons more than technical
ones.

Lastly, mobile advertisement libraries have attracted a lot of at-
tention, as they live within other apps and share their permissions.
They have been demonstrated to be another important source of
privacy leaks [23]; furthermore, Book et al.’s longitudinal study [5]
shows that negative behaviors may be growing more common in
such libraries over time. As a result, several mitigation measures
have been proposed. Some add new APIs and permissions [36] to
attempt to isolate such alien code; AdSplit [41], in contrast, moves
advertisement code into another process to allow the core Android
framework to issue it different permissions, and thus enforce a dif-
ferent policy. Our work has a strange kinship with these works, in
that we similarly are interested in poorly-tagged vendor customiza-
tions mixed in with code from other sources. While we operate on
a different scale to evaluate whole phone images instead of indi-
vidual third-party apps, many of the same concepts apply. Further-
more, there similarly exists a disconnection between the trust a user
may afford the open-source, heavily vetted AOSP and the vendor’s
customizations of it – attempting to mitigate the ﬂaws introduced
by the vendor would be an interesting topic for future work.

Permission Usage Analysis Our permission usage analysis
is built upon the accumulated insight of a number of other works
in this area. For example, Stowaway [17], Vidas et al. [44] and
PScout [2] all study the problem of overprivileged third party apps
and provide permission mappings in different ways. Barrera et
al. [3] study the permission usage patterns of third party apps by
applying self-organizing maps. None of these works analyze the
problem of permission overprivilege in pre-loaded ﬁrmware apps,
which is one key focus of our work.

Others have attempted to infer certain security-related properties
about apps based solely on their requested permissions. Kirin [16],
for example, looks for hard-coded dangerous combinations of per-
missions to warn the user about potential malware. Sarma et al. [40],
Peng et al. [37] and Chakradeo et al. [7], on the other hand, use ma-
chine learning techniques to automatically classify apps as poten-
tially malicious based on the permissions they seek. In this initial
study, we do not attempt to look for such emergent effects in the
permissions requested by a pre-loaded app as the examined stock
images are released by reputable and trustworthy entities.

Vulnerability Analysis Several works have attempted to survey
the landscape of malware on Android (e.g., MalGenome [51]) as
well as general apps [15, 38]. Other works, like DroidRanger [53],
RiskRanker [25], Peng et al. [37] and MAST [7] all have been con-
cerned with ﬁnding malicious apps in app markets that contain a
large number of benign apps. DroidScope [48] uses virtualization
to perform semantic view reconstruction, much like a number of
desktop systems, to analyze Android malware. The insights de-
veloped in these works are useful in informing our own about the
potential dangers of third-party malicious apps.

Permission re-delegation vulnerabilities, a form of the classic
confused-deputy attack [27], have been known to be a problem
on the Android platform for some time. ComDroid [8], Wood-
pecker [24], and CHEX [34] all apply static analysis techniques to
ﬁnd vulnerabilities in either third party or pre-loaded apps. SEFA is
most similar to the latter two systems. But our system also performs
provenance analysis, allowing us to determine the impact of ven-
dor customizations on security. While ComDroid and Woodpecker
only could detect in-component vulnerabilities, CHEX could addi-
tionally detect cross-component ones. Our work is the most com-
prehensive yet, as it can ﬁnd in-component, cross-component, and
cross-app vulnerabilities. Speciﬁcally, cross-app vulnerabilities ac-
count for 8.90% of the vulnerabilities that we found, a signiﬁcant
proportion that also leads to similar, if not greater, security risks.

Several systems [6, 12, 18] aim to mitigate the permission re-
delegation problem by either checking IPC call chains or by mon-
itoring the run-time communication between apps. Other works
try to protect security in a different manner. For example, virtual-
ization techniques are leveraged by Cells [1] and L4Android [33].
MoCFI [10] implements a control-ﬂow integrity enforcement frame-
work for apps on iOS platform. These works are all complementary
to our own, as similar techniques may be able to be applied to mit-
igate the impact of the ﬂaws that we have detected.

Several systems, including TaintDroid [14], PiOS [13], Apex [35],
MockDroid [4], TISSA [54], AppFence [28], Aurasium [47], SOR-
BET [19] and CleanOS [43] aim to study privacy leak issues. They
all try to protect (or mitigate) the privacy leak problem by modi-
fying the underlying framework. There has been considerably less
work related to content leaks. ContentScope [52] tries to identify
vulnerabilities related to third-party, unprotected content providers.
Our own work uses a similar concept, but is concerned with content
providers in ﬁrmware. Note these content providers are only ever
found in that context and we have to additionally cover protected
content providers (that have not been addressed by earlier work).

6326. CONCLUSION

In this paper, we evaluate the security impact of vendor cus-
tomizations on Android devices by designing and implementing the
SEFA analysis framework. This tool performs several analyses to
study the provenance, permission usage and vulnerability distribu-
tion of the pre-loaded apps that make up a device’s ﬁrmware image.
We evaluated ten devices from ﬁve different vendors: two models
from each vendor, representing two different generations. We then
compare the various vendors’ offerings for a given generation, as
well as the evolution of any given vendor’s security practices over
time. Our results show that due to heavy vendor customizations,
on average, over half of the apps in each image are overprivileged
vendor apps, and more than 60% of the vulnerabilities we identiﬁed
stemmed from the vendors’ modiﬁcations to the ﬁrmware. Further-
more, for most of the manufacturers in our study, these patterns
were stable over time, highlighting the need for heightened focus
on security by the smartphone industry.

7. ACKNOWLEDGEMENTS

We would like to thank the anonymous reviewers for their com-
ments that greatly helped improve the presentation of this paper.
We also want to thank Kunal Patel, Wu Zhou and Minh Q. Tran
for the helpful discussion. This work was supported in part by
the US National Science Foundation (NSF) under Grants 0855297,
0855036, 0910767, and 0952640. Any opinions, ﬁndings, and con-
clusions or recommendations expressed in this material are those
of the authors and do not necessarily reﬂect the views of the NSF.

8. REFERENCES
[1] J. Andrus, C. Dall, A. Van’t Hof, O. Laadan, and J. Nieh. Cells: A

Virtual Mobile Smartphone Architecture. In Proceedings of the 23rd
ACM Symposium on Operating Systems Principles, SOSP ’11, 2011.

[2] K. W. Y. Au, Y. F. Zhou, Z. Huang, and D. Lie. PScout: Analyzing

the Android Permission Speciﬁcation. In Proceedings of the 19th
ACM Conference on Computer and Communications Security, CCS
’12, 2012.

[3] D. Barrera, H. G. Kayacik, P. C. van Oorschot, and A. Somayaji. A
Methodology for Empirical Analysis of Permission-Based Security
Models and its Application to Android. In Proceedings of the 17th
ACM Conference on Computer and Communications Security, CCS
’10, 2010.

[4] A. R. Beresford, A. Rice, N. Skehin, and R. Sohan. MockDroid:

Trading Privacy for Application Functionality on Smartphones. In
Proceedings of the 12th International Workshop on Mobile
Computing Systems and Applications, HotMobile ’11, 2011.

[5] T. Book, A. Pridgen, and D. S. Wallach. Longitudinal Analysis of

Android Ad Library Permissions. In IEEE Mobile Security
Technologies, MoST ’13, 2013.

[6] S. Bugiel, L. Davi, A. Dmitrienko, T. Fischer, A.-R. Sadeghi, and

B. Shastry. Towards Taming Privilege-Escalation Attacks on
Android. In Proceedings of the 19th Annual Symposium on Network
and Distributed System Security, NDSS ’12, 2012.

[7] S. Chakradeo, B. Reaves, P. Traynor, and W. Enck. MAST: Triage for

Market-scale Mobile Malware Analysis. In Proceedings of the 6th
ACM Conference on Security and Privacy in Wireless and Mobile
Networks, WiSec ’13, 2013.

[8] E. Chin, A. P. Felt, K. Greenwood, and D. Wagner. Analyzing

Inter-Application Communication in Android. In Proceedings of the
9th Annual International Conference on Mobile Systems,
Applications, and Services, MobiSys ’11, 2011.

[9] J. Crussell, C. Gibler, and H. Chen. Attack of the Clones: Detecting

Cloned Applications on Android Markets. In Proceedings of 17th
European Symposium on Research in Computer Security, ESORICS
’12, 2012.

[10] L. Davi, A. Dmitrienko, M. Egele, T. Fischer, T. Holz, R. Hund,

S. Nurnberger, and A.-R. Sadeghi. MoCFI: A Framework to Mitigate
Control-Flow Attacks on Smartphones. In Proceedings of the 19th

Annual Symposium on Network and Distributed System Security,
NDSS ’12, 2012.

[11] Defuse. Use-deﬁne chain. http://en.wikipedia.org/

wiki/Use-define_chain.

[12] M. Dietz, S. Shekhar, Y. Pisetsky, A. Shu, and D. S. Wallach.
QUIRE: Lightweight Provenance for Smart Phone Operating
Systems. In Proceedings of the 20th USENIX Security Symposium,
USENIX Security ’11, 2011.

[13] M. Egele, C. Kruegel, E. Kirda, and G. Vigna. PiOS: Detecting
Privacy Leaks in iOS Applications. In Proceedings of the 18th
Annual Symposium on Network and Distributed System Security,
NDSS ’11, 2011.

[14] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung, P. McDaniel, and

A. N. Sheth. TaintDroid: An Information-Flow Tracking System for
Realtime Privacy Monitoring on Smartphones. In Proceedings of the
9th USENIX Symposium on Operating Systems Design and
Implementation, USENIX OSDI ’10, 2010.

[15] W. Enck, D. Octeau, P. McDaniel, and S. Chaudhuri. A Study of

Android Application Security. In Proceedings of the 20th USENIX
Security Symposium, USENIX Security ’11, 2011.

[16] W. Enck, M. Ongtang, and P. McDaniel. On lightweight mobile
phone application certiﬁcation. In Proceedings of the 16th ACM
Conference on Computer and Communications Security, CCS ’09,
2009.

[17] A. P. Felt, E. Chin, S. Hanna, D. Song, and D. Wagner. Android

Permissions Demystiﬁed. In Proceedings of the 18th ACM
Conference on Computer and Communications Security, CCS ’11,
2011.

[18] A. P. Felt, H. Wang, A. Moshchuk, S. Hanna, and E. Chin.

Permission Re-Delegation: Attacks and Defenses. In Proceedings of
the 20th USENIX Security Symposium, USENIX Security ’11, 2011.

[19] E. Fragkaki, L. Bauer, L. Jia, and D. Swasey. Modeling and

Enhancing Android’s Permission System. In Proceedings of 17th
European Symposium on Research in Computer Security, ESORICS
’12, 2012.

[20] Gartner. Gartner Says Worldwide Smartphone Sales Soared in Fourth

Quarter of 2011 With 47 Percent Growth. http://www.
gartner.com/it/page.jsp?id=1924314.

[21] Google. Intent. http://developer.android.com/

reference/android/content/Intent.html.

[22] Google. Platform Versions. http://developer.android.

com/about/dashboards/index.html.

[23] M. Grace, W. Zhou, X. Jiang, and A.-R. Sadeghi. Unsafe Exposure
Analysis of Mobile In-App Advertisements. In Proceedings of the
5th ACM Conference on Security and Privacy in Wireless and Mobile
Networks, WiSec ’12, 2012.

[24] M. Grace, Y. Zhou, Z. Wang, and X. Jiang. Systematic Detection of
Capability Leaks in Stock Android Smartphones. In Proceedings of
the 19th Annual Symposium on Network and Distributed System
Security, NDSS ’12, 2012.

[25] M. Grace, Y. Zhou, Q. Zhang, S. Zou, and X. Jiang. RiskRanker:
Scalable and Accurate Zero-day Android Malware Detection. In
Proceedings of the 10th International Conference on Mobile Systems,
Applications and Services, MobiSys ’12, 2012.
[26] Gsmarena. http://www.gsmarena.com/.
[27] N. Hardy. The Confused Deputy: (or why capabilities might have

been invented). ACM SIGOPS Operating Systems Review, 22,
October 1988.

[28] P. Hornyack, S. Han, J. Jung, S. Schechter, and D. Wetherall. These

Aren’t the Droids You’re Looking For: Retroﬁtting Android to
Protect Data from Imperious Applications. In Proceedings of the
18th ACM Conference on Computer and Communications Security,
CCS ’11, 2011.

[29] X. Hu, T.-c. Chiueh, and K. G. Shin. Large-Scale Malware Indexing

Using Function-Call Graphs. In Proceedings of the 16th ACM
Conference on Computer and Communications Security, CCS ’09,
2009.

[30] IDC. Strong Demand for Smartphones and Heated Vendor

Competition Characterize the Worldwide Mobile Phone Market at
the End of 2012, IDC Says. https://www.idc.com/getdoc.
jsp?containerId=prUS23916413#.UQIPbh0qaSp.

633[31] J. Koetsier. Android captured almost 70% global smartphone market

[49] W. Zhou, Y. Zhou, M. Grace, X. Jiang, and S. Zou. Fast, Scalable

share in 2012, Apple just under 20%. http://venturebeat.
com/2013/01/28/android-captured-almost-70-
global-smartphone-market-share-in-2012-apple-
just-under-20/.

[32] C. Kruegel, E. Kirda, D. Mutz, W. Robertson, and G. Vigna.
Polymorphic worm detection using structural information of
executables. In Proceedings of 8th International Symposium on
Recent Advances in Intrusion Detection, RAID ’05, 2005.

[33] M. Lange, S. Liebergeld, A. Lackorzynski, A. Warg, and M. Peter.

L4Android: A Generic Operating System Framework for Secure
Smartphones. In Proceedings of the 1st Workshop on Security and
Privacy in Smartphones and Mobile Devices, CCS-SPSM ’11, 2011.

[34] L. Lu, Z. Li, Z. Wu, W. Lee, and G. Jiang. Chex: Statically vetting

android apps for component hijacking vulnerabilities. In Proceedings
of the 19th ACM Conference on Computer and Communications
Security, CCS ’12, 2012.

[35] M. Nauman, S. Khan, and X. Zhang. Apex: Extending Android
Permission Model and Enforcement with User-Deﬁned Runtime
Constraints. In Proceedings of the 5th ACM Symposium on
Information, Computer and Communications Security, ASIACCS
’10, 2010.

[36] P. Pearce, A. P. Felt, G. Nunez, and D. Wagner. AdDroid: Privilege

Separation for Applications and Advertisers in Android. In
Proceedings of the 7th ACM Symposium on Information, Computer
and Communications Security, ASIACCS ’12, 2012.

[37] H. Peng, C. Gates, B. Sarma, N. Li, Y. Qi, R. Potharaju,

C. Nita-Rotaru, and I. Molloy. Using probabilistic generative models
for ranking risks of android apps. In Proceedings of the 19th ACM
Conference on Computer and Communications Security, CCS ’12,
2012.

[38] S. Rosen, Z. Qian, and Z. M. Mao. AppProïˇn ˛Aler: A Flexible Method

of Exposing Privacy-Related Behavior in Android Applications to
End Users. In Proceedings of the 3nd ACM Conference on Data and
Application Security and Privacy, CODASPY ’13, 2013.

[39] A. Russakovskii. http://www.androidpolice.com/2011/

10/01/massive-security-vulnerability-in-htc-
android-devices-evo-3d-4g-thunderbolt-others-
exposes-phone-numbers-gps-sms-emails-
addresses-much-more/.

[40] B. Sarma, C. Gates, N. Li, R. Potharaju, C. Nita-Rotaru, and

I. Molloy. Android Permissions: A Perspective Combining Risks and
Beneﬁts. In Proceedings of the 17th ACM Symposium on Access
Control Models and Technologies, SACMAT ’12, 2012.

[41] S. Shekhar, M. Dietz, and D. S. Wallach. AdSplit: Separating

smartphone advertising from applications. In Proceedings of the 21th
USENIX Security Symposium, USENIX Security ’12, 2012.
[42] Smali. An assembler/disassembler for Android’s dex format.

http://code.google.com/p/smali/.

[43] Y. Tang, P. Ames, S. Bhamidipati, A. Bijlani, R. Geambasu, and

N. Sarda. CleanOS: Limiting Mobile Data Exposure With Idle
Eviction. In Proceedings of the 11th USENIX Symposium on
Operating Systems Design and Implementation, USENIX OSDI ’12,
2012.

[44] T. Vidas, N. Christin, and L. F. Cranor. Curbing Android permission

creep. In Proceedings of the 2011 Web 2.0 Security and Privacy
Workshop, W2SP ’11, 2011.

[45] Wiki. Samsung Galaxy S3. http://en.wikipedia.org/

wiki/Samsung_Galaxy_S_III.

[46] Z. Wu, X. Zhang, and X. Jiang. AppInk: Watermarking Android

Apps for Repackaging Deterrence. In Proceedings of the 8th ACM
Symposium on Information, Computer and Communications
Security, ASIACCS ’13, 2013.

[47] R. Xu, H. Saidi, and R. Anderson. Aurasium: Practical Policy

Enforcement for Android Applications. In Proceedings of the 21th
USENIX Security Symposium, USENIX Security ’12, 2012.

[48] L. K. Yan and H. Yin. DroidScope: Seamlessly Reconstructing the

OS and Dalvik Semantic Views for Dynamic Android Malware
Analysis. In Proceedings of the 21th USENIX Security Symposium,
USENIX Security ’12, 2012.

Detection of ‘Piggybacked’ Mobile Applications. In Proceedings of
the 3nd ACM Conference on Data and Application Security and
Privacy, CODASPY ’13, 2013.

[50] W. Zhou, Y. Zhou, X. Jiang, and P. Ning. DroidMOSS: Detecting

Repackaged Smartphone Applications in Third-Party Android
Marketplaces. In Proceedings of the 2nd ACM Conference on Data
and Application Security and Privacy, CODASPY ’12, 2012.

[51] Y. Zhou and X. Jiang. Dissecting Android Malware: Characterization

and Evolution. In Proceedings of the 33rd IEEE Symposium on
Security and Privacy, IEEE Oakland ’12, 2012.

[52] Y. Zhou and X. Jiang. Detecting Passive Content Leaks and Pollution

in Android Applications. In Proceedings of the 20th Annual
Symposium on Network and Distributed System Security, NDSS ’13,
2013.

[53] Y. Zhou, Z. Wang, W. Zhou, and X. Jiang. Hey, You, Get off of My

Market: Detecting Malicious Apps in Ofﬁcial and Alternative
Android Markets. In Proceedings of the 19th Annual Symposium on
Network and Distributed System Security, NDSS ’12, 2012.

[54] Y. Zhou, X. Zhang, X. Jiang, and V. W. Freeh. Taming

Information-Stealing Smartphone Applications (on Android). In
Proceedings of the 4th International Conference on Trust and
Trustworthy Computing, TRUST ’11, 2011.

APPENDIX

A. REACHABILITY ANALYSIS

Algorithm 3: Reachability Analysis

Input: path from entrypoint to sink
Output: path is reachable or not

ret = f alse;
intra_analysis(all nodes in path) ;
nodes = nodes in the path;
edges = edges in the path;

while constraint does not meet do

f lag = f alse;
foreach n ∈ nodes do

callee = callee set of n;
if callee = ∅ then

break;

foreach c ∈ callee do

if (n, c) ∈ edges then

f lag = f lag ∪ c.summarize(n);

if f lag then

inter_analysis(c);
if constraint meets then

break;

else

break;

ret = reachability_check(path with summary information);
return ret

634