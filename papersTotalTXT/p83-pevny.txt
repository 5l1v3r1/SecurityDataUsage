Discriminative Models for Multi-instance Problems with

Tree Structure

Tomáš Pevný
CTU in Prague

Cisco R&D Center in Prague

Prague, Czech Republic
pevnak@gmail.com

Petr Somol

Cisco R&D Center in Prague

UTIA, Czech Academy of Sciences

Prague, Czech Republic
psomol@cisco.com

ABSTRACT
Modelling network traﬃc is gaining importance to counter
modern security threats of ever increasing sophistication. It
is though surprisingly diﬃcult and costly to construct reli-
able classiﬁers on top of telemetry data due to the variety
and complexity of signals that no human can manage to
interpret in full. Obtaining training data with suﬃciently
large and variable body of labels can thus be seen as a pro-
hibitive problem. The goal of this work is to detect infected
computers by observing their HTTP(S) traﬃc collected from
network sensors, which are typically proxy servers or net-
work ﬁrewalls, while relying on only minimal human input
in the model training phase. We propose a discriminative
model that makes decisions based on a computer’s all traf-
ﬁc observed during a predeﬁned time window (5 minutes in
our case). The model is trained on traﬃc samples collected
over equally-sized time windows for a large number of com-
puters, where the only labels needed are (human) verdicts
about the computer as a whole (presumed infected vs. pre-
sumed clean). As part of training, the model itself learns dis-
criminative patterns in traﬃc targeted to individual servers
and constructs the ﬁnal high-level classiﬁer on top of them.
We show the classiﬁer to perform with very high precision,
and demonstrate that the learned traﬃc patterns can be in-
terpreted as Indicators of Compromise. We implement the
discriminative model as a neural network with special struc-
ture reﬂecting two stacked multi-instance problems. The
main advantages of the proposed conﬁguration include not
only improved accuracy and ability to learn from gross la-
bels, but also automatic learning of server types (together
with their detectors) that are typically visited by infected
computers.

Keywords
Neural network; user modeling; malware detection; big data;
learning indicators of compromise

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
AISec’16, October 28 2016, Vienna, Austria
c(cid:13) 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ISBN 978-1-4503-4573-6/16/10. . . $15.00
DOI: http://dx.doi.org/10.1145/2996758.2996761

1. MOTIVATION

In network security it is increasingly more diﬃcult to re-
act to the inﬂux of new malicious programs such as trojans,
viruses and others (further called malware). Traditional
defense solutions rely on identifying pre-speciﬁed patterns
(called signatures) known to distinguish malware in incom-
ing network connections, e-mails, locally stored programs,
etc. But signature-matching now runs out of breath with
the rapid increase in malware sophistication. Contemporary
malware deploys many evasion techniques such as polymor-
phism, encryption, obfuscation, randomization, etc., which
critically decrease recall of signature-based methods. One
of possible perpendicular approaches is identifying infected
computers on the basis of their behavior, i.e., usually by
monitoring and evaluating network activity or system calls.
The advantage of such an approach is higher recall, because
it is much harder to evade behavior-based detection. For
example, computers infected by spamming malware almost
inevitably display an increase in the number of sent e-mails.
Click-fraud, where infected computers earn money to the
originator of the infection by showing or accessing advertise-
ments, is another example where the increased volume of cer-
tain traﬃc is a good indicator of compromise. On the other
hand, behavior-based malware detection frequently suﬀers
from higher false positive rates compared to signature based
solutions.

Machine learning methods have recently attracted atten-
tion due to their promise to improve false-positive rates of
behavioral malware detection[2]. However, the use of oﬀ-
the-shelf machine learning methods to detect malware is
typically hindered by the diﬃculty of obtaining accurate la-
bels, especially if classiﬁcation is to be done at the level of
individual network connections (TCP ﬂow, HTTP request,
etc.)[11, 13]. Even for an experienced security analyst it
is almost impossible to determine which network connec-
tions are initiated by malware and which by a benign user
or application,1 since malware often mimics the behavior
of benign connections. We have observed malware connect-
ing to google.com for seemingly benign connection checks,
displaying advertisements, or sending e-mail as mentioned
above. Labeling individual network connections is thus pro-

1Even though one has access to the machine infected by
malware and can obtain hashes of processes issuing connec-
tions, malicious browser plugins will have the hash of the
browser, which is a legitimate application, which renders
this technique useless. Also, the database of hashes used to
identify malware processes might not be complete, resulting
in incomplete labeling.

83Figure 1: Sketch of the traﬃc of a single computer.

hibitive not only due to their huge numbers but also due
to ambiguity in individual connections’ classiﬁcation. Auto-
matic and large-scale training of accurate classiﬁers is thus
very diﬃcult.

In this work we sidestep this problem by moving the ob-
ject of classiﬁcation one level up, i.e., instead of classifying
individual connections we classify the computer (represented
by a collection of all its traﬃc) as a whole. The immediate
beneﬁt is twofold. First, the labeling is much simpler, as it
is suﬃcient to say “this computer is infected / clean” rather
than “this connection has been caused by malware”. Second,
a grouping of connections provides less ambiguous evidence
than a single connection (see cases described above where a
single access to an ad server does not tell much, but a mul-
titude of such accesses does). This latter property is in fact
the main motivation behind our present work.

The biggest obstacle in implementing a classiﬁer on ba-
sis of all observed traﬃc is the variability in the number of
network connections (hereafter called ﬂows). This property
eﬀectively rules out the majority of machine learning algo-
rithms requiring each sample to be described by a ﬁxed di-
mensional vector, because the number of observed ﬂows sup-
posed to characterize one computer can range from dozens to
millions while information content of the ﬂows may vary sig-
niﬁcantly. Our problem thus belongs to the family of multi-
instance learning (MIL) problems [3, 7] where one sample
is commonly called a bag (in our case representing a com-
puter) and consists of a variable number of instances (in
our case one instance is one ﬂow), each described by a ﬁxed
dimensional vector.

The solution proposed below diﬀers from the current MIL
paradigm by taking a step further and representing data not
as a collection of bags, but as a hierarchy of bags. We show
that such approach is highly advantageous as it eﬀectively
utilizes the natural hierarchy inherent in our data. Flows
emitted or observed by one computer can be easily grouped
according to servers they connect to (these groups are called
sub-bags), so that the bag representing the particular com-
puter becomes a collection of sub-bags. This hierarchy can
be viewed as a tree with leafs representing ﬂows (instances),
inner nodes representing servers (sub-bags), and ﬁnally the
root representing the computer (bag). The structure of the
problem is shown in Figure 1. Note that trees represent-

ing diﬀerent computers will have diﬀerent number of inner
nodes and leafs. The proposed classiﬁer exploits this struc-
ture by ﬁrst modeling servers (sub-bags) on the basis of ﬂows
targeted to them and then modeling the computer on top
of the server models. This approach can be viewed as two
MIL problems stacked one on top of the other. In Section 3
we show how the hierarchical MIL problem can be mapped
into a neural-network architecture, enabling direct use of
standard back-propagation as well as many recent develop-
ments in the ﬁeld of deep learning. Once trained, the ar-
chitecture can be used for classiﬁcation but it can also be
decomposed to identify types of traﬃc signiﬁcant for distin-
guishing benign from infected computers, i.e., it allows to
extract learned indicators of compromise (IOCs). Finally,
using an approach similar to URCA [17], it is possible to
identify particular connections which made the neural net-
work decide that the computer is infected; hence eﬀectively
providing an explanation of the learned IOC.

Section 4 demonstrates the proposed approach on a large
scale real-world problem of detecting infected computers
from proxy logs. It is shown that the neural network can
learn to identify infected computers in computer networks,
as well as provide sound explanations of its verdicts to the
consumer. Neurons in lower layers are shown to have learned
weak indicators of compromise typical for malware.

The proposed neural network architecture is shown to
have multiple advantageous properties. Its hierarchal MIL
nature dramatically reduces the cost of label acquisition. By
using labels on high-level entities such as computers or other
network devices the creation of training data is much sim-
pler. The ability to decompose the encoded structure is no
less important as it provides a deﬁnition of learned indica-
tors of compromise. Finally, it allows for human-intelligible
explanations of classiﬁer verdicts as security incidents, which
simpliﬁes the job of the network administrator.

This paper is organized as follows. The next section for-
mulates the problem of multiple instance learning and re-
views important work we build upon. The proposed ap-
proach is presented in Section 3. Experimental evaluation is
provided in Section 4.

google.comgoogle.com/search .gmail.com/check .gmail.com/check . .100.100.100.100 .cnn.comcnn.com/newscnn.com/images .addelivery.com . . .skype.com .skype.com/chat . .bing.combing.com/search . . .dropbox.com/check .dropbox.comdbox.com/upload . .user_j_smithuser_s_dawnhttp(s) traffic of John Smithhttp(s) traffic of John Smithextracted per-flowfeature vectorsextracted per-flowfeature vectorsindividual flow layer(k neurons)„flow active as connection check“Remark: interpretation of learned neuron is possible in after-learning phase through subsequent analysis of flows on which learned neurons excite the most.Remark: aggregation per bag is the key advantage here over standard Neural Networks„user often reads mail and news“„communication to this domain has high number of connection checks“„communication to this domain   is mostly API based“„communication to this domain  contained empty path“„flow representing search request“„user accesses search engines through API“domain connection type layer(d neurons)user type layer(u neurons)binary classification layer (infected/benign)per-destination-domainaggregated vectorper-destination-domainaggregated vectorper-useraggregated vectorper-useraggregated vectorto be classifiedin last Neural Netlayerto be classifiedin last Neural Netlayerfor google.comfor skype.comfor user_s_dawnfor user_j_smithfor gmail.comfor bing.comfor cnn.comfor addelivery.comfor dropbox.comfor 100.100.100.100timetime∈Rkf1, f2, .....∈Rkf1, f2, .....∈Rdf1, f2, .....∈Rdf1, f2, .....∈Rdf1, f2, .....∈Ruf1, f2, .....∈Ruf1, f2, .....∈Rdf1, f2, .....∈Rdf1, f2, .....∈Rdf1, f2, .....∈Rdf1, f2, .....∈Rdf1, f2, .....∈Rkf1, f2, .....∈Rkf1, f2, .....∈Rkf1, f2, .....∈Rkf1, f2, .....∈Rkf1, f2, .....∈Rkf1, f2, .....∈Rkf1, f2, .....∈Rkf1, f2, .....∈Rkf1, f2, .....∈Rkf1, f2, .....∈Rkf1, f2, .....∈Rkf1, f2, .....∈Rkf1, f2, .....∈Rkf1, f2, .....}}}}}}}}Multiple-Instance Neural Network in Computer Network SecurityTraffic SampleTraffic SampleNeural Network ModelExamples of Learned IOCspooling function aggregates over flows per bag (flows per domain)pooling function aggregates over connections per bag (connection type vectors per user)842. RELATED WORK

Here we review the evolution of paradigms leading to the

solution proposed in the next section.
2.1 Multi instance learning problem

The pioneering work [6] coined multiple-instance or multi-
instance learning as a problem, where each sample b (to be
referred to as bag in the following) consists of a set of in-
stances x, i.e., b = {xi ∈ X|i ∈ {1, . . . ,|b|}}. Each instance x
can be attributed a label yx ∈ {−1, +1}, but these instance-
level labels are not assumed to be known even in the training
set. The sample b is deemed positive if at least one of its
instances has a positive label, i.e., label of a sample b is
y = maxx∈b yx. For this scenario the prevalent approach is
the so-called instance-space paradigm, i.e., to train a classi-
ﬁer on the level of individual instances f : X (cid:55)→ {−1, +1}
and then infer the label of the bag b as maxx∈b f (x).
2.1.1 Embedded-Space Paradigm
Later works (see reviews [3, 7]) have introduced diﬀerent
assumptions on relationships between the labels on the in-
stance level and labels of bags or even dropped the notion of
instance-level labels and considered only labels at the level
of bags, i.e., it is assumed that each bag b has a correspond-
ing label y ∈ Y, which for simplicity we will assume to be
binary, i.e., Y = {−1, +1} in the following. The common
approach of the latter type is either to follow a bag-space
paradigm and deﬁne a measure of distance (or kernel) be-
tween bags, or to follow an embedded-space paradigm and
deﬁne a transformation of the bag to a ﬁxed-size vector.

Since the solution presented in Section 3 belongs to the
embedded-space paradigm, we describe this class of methods
in necessary detail and adopt the formalism of [16], which is
suitable for presenting our solution. The formalism of [16] is
intended for a general formulation of MIL problems, where
labels are assumed only at the level of bags without any
labels at the level of instances. Each bag b consists of a
set of instances, which are viewed as a realization of some
probability distribution pb deﬁned over the instance space X .
To allow more ﬂexibility between bags even within the same
class, the formalism assumes that probability distributions
pb of diﬀerent bags are diﬀerent, which is captured as pb
being realization of a probability P (pb, y), where y ∈ Y is
the bag label.

During the learning process each concrete bag b is thus
viewed as a realization of an unknown probability distribu-
tion pb that can be inferred only from groups of instances
{x ∈ b|x ∼ pb} observed in data. The goal is to learn a
discrimination function f : B (cid:55)→ Y, where B is the set of
all possible realizations of all distributions p ∈ PX , i.e.,

B =(cid:8)xi|p ∈ PX , xi ∼ p, i ∈ {1, . . . l}, l ∈ N(cid:9). Note that this

deﬁnition also subsumes the one used in [6].2

Methods from embedded space-paradigm [3, 7] ﬁrst repre-
sent each bag b as a ﬁxed-dimensional vector and then use
any machine learning algorithm with samples of ﬁxed di-
mension. Therefore the most important component in which

2Ref. [6] assumed labels on instances and a bag was classiﬁed
as positive if it contained at least one positive instance. In
the used general formulation this corresponds to the case,
where in each positive bag exist instances that never occur in
negative bags, which means that the diﬀerence of support of
positive and negative probability distributions is non-empty,
i.e., p+\p− (cid:54)= Ø, where p+ ∼ P (p|+) and p− ∼ P (p|−).

Figure 2:
embedding-space paradigm.

Neural network optimizing embedding in

most methods diﬀer is the embedding. An embedding of bag
b can be generally written as

(φ1(b), φ2(b), . . . , φm(b)) ∈ Rm
with individual projection φi : B (cid:55)→ R being

φi = g(cid:0){k(x, θi)}x∈b

(cid:1) ,

(1)

(2)

where k : X ×Θ (cid:55)→ R+
0 is a suitably chosen distance function
parametrized by parameters θ (also called dictionary items)
and g : ∪∞
n=1Rk (cid:55)→ R is the pooling function (e.g. minimum,
mean or maximum). Most methods diﬀer in the choice of
aggregation function g, distance function k, and ﬁnally in
the selection of dictionary items θ ∈ Θ.
2.2 Simultaneous Optimization of Embedding

and Classiﬁer

The important novelty introduced in [16] is that embed-
ding functions {φi}m
i=1 are optimized simultaneously with
the classiﬁer that uses them, as opposed to prior art where
the two optimization problems are treated indepedently. Si-
multaneous optimization is achieved by using the formalism
of neural network, where one (or more) lower layers followed
by a pooling layer implement the embedding function φ, and
subsequent layers implement the classiﬁer that is thus built
on top of bag representations in the form of feature vectors
of ﬁxed length. The model is sketched in Figure 2 with a
single output neuron implementing a linear classiﬁer once
the embedding to a ﬁxed-length feature representation is re-
alized. The neural network formalism enables to optimize
individual components of the embedding function as follows.

• Lower layers (denoted in Figure 2 as {ki}m

i=1) before
pooling identiﬁes parts of the instance-space X where
the probability distributions generating instances in
positive and negative bags diﬀer the most with respect
to the chosen pooling operator.

• The pooling function g can be either ﬁxed, such as
mean or maximum, or any other pooling function for
which it is possible to calculate gradient with respect
to its inputs. The pooling function itself can have pa-
rameters that can be optimized during learning, as was

k1(·)k2(·)km(·)····g(·)g(·)g(·)····f(·)multiplevectorsperbagsinglevectorperbag85form q(cid:113) 1|b|

shown e.g.

mized.

(cid:80)
in [9], where the pooling function has the
i∈b |xi|q with the parameter q being opti-

• Layers after the pooling (denoted in Figure 2 as f (·))
correspond to the classiﬁer that already uses the rep-
resentation of bags as vectors of ﬁxed dimension.

The above model is very general and allows for automatic op-
timization of all its parameters by means of back-propagation,
though the user still needs to select the number of layers,
number of neurons in each layer, transfer functions, and pos-
sibly also the pooling function.

3. THE PROPOSED SOLUTION

In the light of the previous section, the problem of iden-
tifying infected computers can be viewed as two MIL prob-
lems, one stacked on top of the other, where the traﬃc of a
computer b is generated by a two-level generative model.
3.1 Generative Model
Let us denote S the set of all servers accessible by any com-
puter. Let Sc ⊆ S denote the subset of all servers accessed
from computer c in a given time frame. The communication
of computer c with each server s ∈ Sc consists of a group of
ﬂows x ∈ X that are viewed as instances forming a ﬁrst-level
bag bs. The bag of ﬂows bs is thus viewed as a realization of
some probability distribution pbs ∈ PX .

We imagine that every server s is associated with a type
t(s), which inﬂuences the probability distribution of the ﬂows
pbs . Accordingly, each ﬁrst-level bag bs is realized according
to pbs , which itself is a realization of a probability distribu-
tion P (pbs , t(s)). This captures the real-world phenomenon
of a user’s interaction with some server (e.g., e-mail server)
being diﬀerent from that of a diﬀerent user communicating
with the same server, as well as the fact that diﬀerent types
of servers impose diﬀerent communication patterns.

In view of the above we can now consider computer c to be
a second-level bag consisting of a group of ﬁrst-level bags bs.
Similarly as above, we assume c to be a realization of proba-
bility distribution pc ∈ PB, where B is the set of all possible
realizations of all distributions p ∈ PX . The probability dis-
tribution pc is expected to be diﬀerent for each computer, in
particular we assume this to be true between infected and
clean computers labeled by y ∈ {−1, +1}. The probability
distribution pc is thus viewed as a realization of a probability
distribution P (pc, y). This captures the real-world observa-
tion that infected computers exhibit diﬀerences in communi-
cation patterns to servers, both in what servers they access
and within individual connections to a server.

The model imposes a generative process as illustrated in

Algorithm 1.

The proposed multi-level generative model opens up pos-
sibilities to model patterns at the level of individual con-
nections to server as well as at the level of multiple servers’
usage. In the following we discuss the implementation and
show the practical advantages on large-scale experiments.
3.2 Discriminative model

The rationale behind the discriminative model closely fol-
lows the above generative model by breaking the problem
into two parts: classifying the computer based on the types

clear or infected

input : y ∈ {−1, +1} label marking computer c as
output: Set of ﬂows F of one computer
1. sample a distribution pc of servers from P (pc, y);
2. sample a set of servers Sc from pc;
3. F = Ø;
foreach s ∈ Sc do %iterate over selected

4. sample distribution pbs of ﬂows from P (pbs , t(s));
5. sample ﬂows x from pbs ;
6. add sampled ﬂows to all ﬂows, F = F ∪ {xi};

end

Algorithm 1: Generative model of the ﬂows of one com-
puter.

of contacted servers and classifying the type of a server based
on ﬂows exchanged between the server and the client.

Let’s assume that each contacted server is described by a
feature vector of a ﬁxed dimension, which can be as simple
as one-hot encoding of its type t(s). Then the problem of
classifying the computer becomes a MIL problem with the
bag being the computer and instances being the servers. The
problem is of course that types of servers t(s) are generally
unknown and we cannot imagine to manually create a map-
ping between a server IP or domain name and a server type.
To make the problem even more diﬃcult, the same server
can be used diﬀerently by diﬀerent computers, and there-
fore it can be of diﬀerent type for each of them. One can
indeed learn a classiﬁer that would predict the server type
from ﬂows between the computer and the server, which again
corresponds to a MIL classiﬁer with the bag being the server
and instances being the ﬂows, but the problem of obtaining
labeled samples for training the classiﬁer is non-trivial and
it is unlikely that we will have known all types of servers.
Moreover, since we are learning a discriminative model, we
are interested in types of servers occurring with diﬀerent
probabilities in clean and infected computers.

To side step this problem we propose to stack a MIL clas-
siﬁer at the level of computers on top of a MIL classiﬁer at
the level of servers. Since both MIL classiﬁers are realized
by a neural network described in the previous chapter, we
obtain one (larger) neural network with all parameters op-
timizable using standard back-propagation and importantly
using labels only at the level of bags (computers). This ef-
fectively removes the need to know types of servers t(s) or
learn classiﬁer for them, because the network learns that au-
tomatically from the labels on the level of computers. The
caveat is that the network learns only types of servers that
occur with diﬀerent probabilities in clean and infected com-
puters.

Figure 3illustrates the idea in its simplest incarnation.
The distinctive feature is the presence of two pooling lay-
ers reﬂecting two MIL problems dividing the network into
three parts. The ﬁrst part part up to the ﬁrst pooling in-
cluded implements the embedding of sub-bags into a ﬁnite-
dimensional vector (modeling servers based on ﬂows). After
the ﬁrst pooling each sub-bag (server) is represented by one
ﬁnite-dimensional vector. Similarly the second part start-
ing after the ﬁrst pooling up to the second pooling included
embeds sub-bags into a ﬁnite dimensional vector character-
izing each bag (computer). Finally, the third part after the
second pooling implements the ﬁnal classiﬁer.

86Figure 3: Hierarchical MIL

The right choice of the pooling function is not straightfor-
ward as there are many aspects to be taken into the consid-
eration.

• Mean function should be theoretically better than max [12],

since it is more general. The advantage of mean pool-
ing function has been experimental demonstrated in [16].
• If malware performs only a few distinct types of con-
nections (e.g. connection checks) to well known servers,
max functions can identify them whereas mean func-
tion might suppress them among the clutter caused
by many connections of legitimate applications. This
problem has been recently studied in [4] in the context
of natural images.

• The number of contacted servers and ﬂows to servers
varies between computers and max pooling is more
stable then mean.

• The training with max pooling is approximately six
times faster, since the back-propagated gradient is non-
zero only for one element entering the pooling opera-
tion (one ﬂow per server and neuron, one server per
computer and neuron).

3.3 Extracting indicators of compromise

The presented model is based on the assumption that
there exist types of servers contacted with diﬀerent prob-
ability by infected and clean computers, though one gener-
ally does not know much about them.
If these types did
not exist, then the probability distributions pc of infected
and clean computers would be the same and it would be
impossible to create a reliable detector for them. But if the
neural network has learned to recognize them, vector repre-
sentations of servers (output of the network’s ﬁrst part from
the input to the ﬁrst pooling included in Figure 3) have to
have diﬀerent probability distributions for clean and infected
computers.

Since the above line of reasoning can be extended to the
output of the layer just before the ﬁrst pooling function, out-
put of each neuron of this layer can be viewed as an indicator

of compromise, since it has to contribute to the identiﬁca-
tion of infected computers. From a close inspection of ﬂows
on which these neurons provide the highest output a skilled
network analyst can ﬁgure out what kind of traﬃc it is (con-
crete examples are shown in Section 4.2). Admittedly, these
learned IOCs would deliver poor performance if used alone.
But in the neural network they are used together with IOCs
from diﬀerent servers, which provide context contributing
to good accuracy. Also, once a network administrator anno-
tates these neurons, this annotation can be used to provide
more detailed information about the decisions.
3.4 Explaining the decision

Neural networks have a reputation being a black-box in
the sense that they do not provide any details about their
decisions. In intrusion detection this behavior is undesirable,
since the investigation of a possible security incident would
have to start from the very beginning. Therefore providing
the analyst with an explanation why the classiﬁer viewed
the computer as infected is of great help.

The explanation method relies on the assumption that
ﬂows caused by the infection are additive, i.e. the malware
does not block user’s ﬂows but only adds its own. This
means that if the computer was deemed infected, by remov-
ing the right ﬂows (instances) the network should ﬂip its de-
cision. Although ﬁnding the smallest number of such ﬂows
is likely an NP complete problem, a greedy approximation
inspired by [17] performs surprisingly well.

The greedy approximation ﬁnds in each iteration a set of
ﬂows going to same server (subbag), that causes the biggest
decrease of the classiﬁer’s output when removed from a com-
puter’s traﬃc (in our implementation positive means in-
fected). The algorithm stops when the classiﬁer’s output
becomes negative (clean). The set of all removed subbags
is returned as the explanation in the form: “This computer
was found infected because it has communicated with these
domains”. If decired, examples of ﬂows to these domains can
be obviously supplied.
3.5 Computational complexity

The computational complexity is important not only for

individual flow layerdomain connection type layeruser type layerbinary classification layer (infected/benign)pooling function aggregates over flows per bag (flows per domain)pooling function aggregates over connections per bag (connection type vectors per user)87the training, but also for the deployment as the amount
of network traﬃc that needs to be processed can be high.
For example Cisco’s Cognitive Threat Analytics [5] processes
1010 proxy logs per day. The hierarchical aggregation inside
the network decreases substantially the computational com-
plexity, since after the ﬁrst pooling, the network produces a
single vector per server instead of one vector per ﬂow yield-
ing up to six fold decrease of the data to be processed. Simi-
larly, after the second pooling the computer is described just
by a single vector instead of a set of vectors, which again
decreases the complexity. Compare this to the prior art on
solving MIL with neural networks [18], where the pooling is
done after the last linear layer just before the output, which
means that all layers of the network have to process all ﬂows.
The eﬀect on the computational complexity is tremendous.
Whereas our approach takes approximately ﬁve seconds per
100 iterations of the training, the prior art of [18] takes 1100
seconds, which is 220 times slower.

4. EXPERIMENTAL EVALUATION

Albeit the proposed solution is general and can be used
for any kind of network traﬃc, it has been evaluated in the
context of detecting infected computers from logs of web
proxies due to the availability of large data to us. Besides,
proxy logs are nicer for human investigation than for exam-
ple netﬂow data. The proxy logs were collected by Cisco’s
Cognitive Threat Analytics [5] from 500 large networks dur-
ing eight days. The days were picked randomly from the
period from November 2015 till February 2016 with the test-
ing day being 7th March 2016. Since the total number of
infected computers in the dataset from seven training days
was small, we have added data of infected computers from
additional 25 days from the period spanning the training
data.

Since the data were collected in ﬁve-minute time windows,
one bag consists of all web requests of one computer during
that window. Computers were identiﬁed either by source
IP address or by the user name provided in the proxy logs.
Subbags contain requests with the same part in the HTTP
request.

Computers (bags) were labeled using Cisco’s Cognitive
Threat Analytics [5] so that if one computer had at least
one request known to be caused by malware, the computer
was considered to be infected in that ﬁve-minute window. If
the same computer in some diﬀerent time window did not
have any malware ﬂows, the bag from that time window was
considered as clean.

The training set contained data from approximately 20
million unique computers out of which 172 013 were infected
and approximately 850 000 000 ﬂows, out of which 50 000
000 belonged to infected computers. The testing set con-
tained data of approximately 3 000 000 computers out of
which 3 000 were infected and approximately 120 000 000
ﬂows with 500 000 ﬂows belonging to the infecting comput-
ers.

We are certain that the labeling we have used in this ex-
periment is far from being perfect. While there will be a rel-
atively small number of infected computers labeled as clean,
there will be quite a lot of computers labeled as clean that
were in fact infected. Despite these issues, we consider this
labeling as ground truth, because the aim of the experiments
is to demonstrate that the proposed solution can learn from
high-level labels and identify weak indicators of compromise.

The experiments were implemented in author’s own li-
brary, since popular libraries for neural networks are not
designed for MIL problems. They do not allow to have sam-
ples (bags and sub-bags) of diﬀerent sizes (number of in-
stances) which makes the encoding of the hierarchical struc-
ture impossible. Therefore evaluated architectures used sim-
ple building blocks: rectiﬁed linear units [8, 12], mean and
maximum pooling functions, and ADAM optimization al-
gorithm [10]. Unless said otherwise, ADAM was used with
default parameters with the gradient estimated in each it-
eration from 1000 legitimate and 1000 infected computers
(bags) sampled randomly. This size of the minibatch is
higher than is used in most prior art about deep learn-
ing, however we have found it beneﬁcial most probably be-
cause the signal to be detected is weaker. Contrary to most
state of the art, we have used weighted Hinge loss function
max{0, 1 − y · wy · f (x)} with w+ being the cost of (false
negative) missed detection and w− being the cost of false
positive (false alarms). The rationale behind Hinge loss is
that it produces zero gradients if sample (bag) is classiﬁed
correctly with suﬃcient margin. This means that gradient
with respect to all network parameters is zero, therefore
the back-propagation does not need to be performed, which
leads to a considerable speed-up. The learning was stopped
after ADAM has performed 3 · 105 iterations.

The performance was measured using precision-recall curve
(PR curve) [14] popular in document classiﬁcation and infor-
mation retrieval as it is better suited for highly imbalanced
problems, into which intrusion detection belongs (in the test-
ing data there is approximately one infected computer per
one thousand clean ones).
4.1 Network architecture

All evaluated neural networks used simple feature vec-
tors (instances) with 34 cheap to compute statistics, such as
length of the url, query and path parts, frequency of vowels
and consonants, HTTP status, port of the client and the
server, etc, but not a single feature was extracted from the
hostname. Evaluated neural networks followed the archi-
tecture in Figure 3 with layer of 40 ReLu neurons before
the ﬁrst pooling, but then diﬀering in: using either mean or
max pooling functions; having either one layer with 40 ReLu
neurons or two layers each with 20 ReLu neurons between
ﬁrst and second pooling; and ﬁnally having additional layer
of 20 ReLu neurons after the second pooling and ﬁnal linear
output neuron.

Precision-recall curves of all six evaluated neural networks
each trained with three diﬀerent costs of errors on false pos-
itives (0.5, 0.9, 0.99) and false negative (0.5, 0.1, 0.01) are
shown in Figure 4. Based on these experiments, we have
made the following conclusions.

• Simpler networks with max pooling function tend to
overﬁt, as the error on the training set of all three eval-
uated architectures is very good (dashed lines) but the
error on the testing set is considerably worse (solid
lines). We believe this to be caused by the network
to act more like a complicated signature detector by
learning speciﬁc patterns in ﬂows prevalent in the in-
fected computers in the training set, but missing in
infected computers in testing set. This hypothesis is
supported by (i) the fact that when we have been creat-
ing ground truth, we have labeled computer as infected
if it had at least one connection known to be caused by

88malware and (ii) testing data being one month older
then training ones.

• Simple networks with mean pooling with costs of error
w+ = 0.01 and w− = 0.99 are amongst the best ones.
Their discrepancy between training and testing error
is much lower than in the case of max pooling, ex-
cept the most complicated architecture 4f. We believe
this to be caused by the network learning how infected
computers behave (contacting too many advertisement
servers) rather than patterns speciﬁc for some type of
malware (like those with max pooling). This conclu-
sion is supported by the fact that max pooling function
can be approximated from the mean if layers preceding
the aggregation are suﬃciently complex [15].

An interesting feature is the sharp drop in precision for cer-
tain architectures, which we attribute to the fact that some
infections cannot be detected based on the simple 34 fea-
tures.
4.2 Indicators of compromise

Since one of the main features of the proposed architecture
is the ability to learn indicators of compromise IOCs, we
show examples of traﬃc to which some neurons in the layer
just before the ﬁrst pooling are sensitive. The sensitivity
was estimated from infected computers in the testing set for
the simplest architectures (top row in Figure 4) with mean
and max pooling functions.

We have not observed much diﬀerence between IOCs learned

by networks with mean and max pooling functions. Learned
IOCs included:

• tunneling through url (example shown in appendix due

to its length);

• sinkholed domains such as hxxp://malware.vastglow
s.com, hxxp://malware.9f6qmf0hs.ru/a.htm?u=3969
23, hxxp://malware.ywaauuackqmskc.org/.

• domains with repetitive characters such as hxxp://ww
wwwwwwwwwwvwwwwwwwwwwwwwwwwwwvwwwwwwwwwwwwwwww
wwwwwwwwwwwwvww.com/favicon.ico or hxxp://ibuyi
tttttttttttttttttttttttttttttttttttibuyit.com/
xxx.zip;

• https traﬃc to raw domains such as hxxps://209.12

6.109.113/;

• subdomain generated by an algorithm on a hosting do-
main, for example d2ebu295n9axq5.webhst.com, d2e2
4t2jgcnor2.webhostoid.com, or dvywjyamdd5wo.web
hosteo.com;

• Download of infected seven-zip: d.7-zip.org/a/7z93

8.exe3.

4.3 Example explanation

Table 1 shows an explanation of the simplest evaluated
neural network with maximum pooling functions. The ex-
planation consists of a list of domains with examples of re-
quests to them as they have been identiﬁed by the greedy

refer

3We
to hxxps://www.herdprotect.com/domain-d.
7-zip.org.aspx for conﬁrmation that this is indeed malware-
related.

(a) relu-max-relu-max-lin

(b) relu-mean-relu-mean-lin

(c) relu-max-relu-max-relu-lin (d) relu-mean-relu-mean-relu

(e)
relu-lin

relu-max-relu-relu-max-

relu-mean-relu-relu-mean-

(f)
relu-lin

Figure 4: Precision-recall curves of six neural network ar-
chitectures utilizing simple 34 features. Dashed lines show
the curves estimated on the training set and solid lines show
the curves estimated from the testing set. Networks with PR
curves in the left column used max pooling function, whereas
those with PR curves in the right column used mean pooling
function. Captions w = 0.5, w = 0.1, and w = 0.01 corre-
spond to diﬀerent costs in weighted hinge loss with cost on
false positives (false alarms) being w− = 1 − w while that
on the false negatives (missed detections) being w+ = w.

00.20.40.60.8100.20.40.60.81recallprecisionw=0.5w=0.1w=0.0100.20.40.60.8100.20.40.60.81recallprecisionw=0.5w=0.1w=0.0100.20.40.60.8100.20.40.60.81recallprecisionw=0.5w=0.1w=0.0100.20.40.60.8100.20.40.60.81recallprecisionw=0.5w=0.1w=0.0100.20.40.60.8100.20.40.60.81recallprecisionw=0.5w=0.1w=0.0100.20.40.60.8100.20.40.60.81recallprecisionw=0.5w=0.1w=0.0189NN

output

4.84
2.07
0.21
0.18

url
hxxp://www.inkstuds.org/?feed=podcast
hxxp://feeds.podtrac.com/YxRFN5Smhddj
hxxps://www.youtube-nocookie.com/
hxxps://upload.wikimedia.org/

Table 1: Example output of the explanation of an incident.

algorithm described in Section 3.4. The column “NN out-
put” shows how the output of the neural net decreases as
ﬂows to individual domains are iteratively removed.

At the time of writing this paper, the last three domains
were all involved in the communication with some malware
samples according to Virus Total [1]. Searching further on
the web we have found this article4 stating that www.inkstuds.org
was hacked and used to serve malware.

5. CONCLUSION

We have introduced a stacked Multiple Instance Learning
(MIL) architecture, where data is viewed not as a collection
of bags but as a hierarchy of bags. This extension of the
MIL paradigm is shown to bring many advantages particu-
larly for our target application of intrusion detection. The
hierarchical model is straightforward to implement, requir-
ing just a slight modiﬁcation in a standard neural network
architecture. This enables the exploitation of the vast neural
network knowledgebase including deep learning paradigms.
The proposed architecture posseses key advantages espe-
cially important in network security. First, it requires labels
(clean / infected) only at the high level of computers instead
of at single ﬂows, which dramatically saves time of human
analysts constructing the ground truth and also makes it
more precise (it might be sometimes nearly impossible to
determine if a ﬂow is related to infection or not). Second,
the learned mapping of traﬃc patterns to neurons can be ex-
tracted to obtain human-understandable Indicators of Com-
promise (IOC). Third, it is possible to identify ﬂows that
have caused the computer to be classiﬁed as infected, which
decreases the time needed to investigate a security incident.
The advantages of the proposed architecture were demon-
strated in the context of detecting infected computers from
their network traﬃc collected on the proxy server.
It has
been shown that the neural network can detect infected com-
puters, learn indicators of compromise in lower layers of the
network from high-level labels, and provide sound explana-
tions of output classiﬁcations.
Acknowledgements
This work has been partially supported by Czech Science
Foundation project 15-08916S.

6. REFERENCES
[1] Virus total. https://www.virustotal.com, 2016.
[2] Tansu Alpcan and Tamer Ba¸sar. Network security: A

decision and game-theoretic approach. Cambridge
University Press, 2010.

4http://inkstuds.tumblr.com/post/139553865057/
started-my-day-with-the-inkstuds-site-getting

[3] Jaume Amores. Multiple instance classiﬁcation:

Review, taxonomy and comparative study. Artiﬁcial
Intelligence, 201:81–105, 2013.

[4] Y-Lan Boureau, Jean Ponce, and Yann LeCun. A

theoretical analysis of feature pooling in visual
recognition. In Proceedings of the 27th international
conference on machine learning (ICML-10), pages
111–118, 2010.

[5] Cisco Systems Inc. Cisco Cognitive Threat Analytics.

https://cognitive.cisco.com.

[6] Thomas G Dietterich, Richard H Lathrop, and Tom´as

Lozano-P´erez. Solving the multiple instance problem
with axis-parallel rectangles. Artiﬁcial intelligence,
89(1):31–71, 1997.

[7] James Foulds and Eibe Frank. A review of

multi-instance learning assumptions. The Knowledge
Engineering Review, 25(01):1–25, 2010.

[8] Xavier Glorot, Antoine Bordes, and Yoshua Bengio.

Deep sparse rectiﬁer neural networks. In Aistats,
volume 15, page 275, 2011.

[9] Caglar Gulcehre, Kyunghyun Cho, Razvan Pascanu,
and Yoshua Bengio. Learned-norm pooling for deep
feedforward and recurrent neural networks. In
Machine Learning and Knowledge Discovery in
Databases, pages 530–546. Springer, 2014.

[10] Diederik Kingma and Jimmy Ba. Adam: A method

for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.

[11] Matthew V. Mahoney and Philip K. Chan. Learning

nonstationary models of normal network traﬃc for
detecting novel attacks. In Proceedings of the Eighth
ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, KDD ’02,
pages 376–385, New York, NY, USA, 2002. ACM.

[12] Krikamol Muandet, Kenji Fukumizu, Francesco

Dinuzzo, and Bernhard Sch¨olkopf. Learning from
distributions via support measure machines. In
Advances in neural information processing systems,
pages 10–18, 2012.

[13] T. T. T. Nguyen and G. Armitage. A survey of
techniques for internet traﬃc classiﬁcation using
machine learning. IEEE Communications Surveys
Tutorials, 10(4):56–76, Fourth 2008.

[14] James W. Perry, Allen Kent, and Madeline M. Berry.

Machine literature searching x. machine language;
factors underlying its design and development.
American Documentation, 6(4):242–254, 1955.

[15] T. Pevn´y and I. Nikolaev. Optimizing pooling function

for pooled steganalysis. In Information Forensics and
Security (WIFS), 2015 IEEE International Workshop
on, pages 1–6, Nov 2015.

[16] Tom´aˇs Pevn´y and Petr Somol. Using neural network

formalism to solve multiple-instance problems. In
submission to ECML 2016.

[17] F. Silveira and C. Diot. Urca: Pulling out anomalies

by their root causes. In INFOCOM, 2010 Proceedings
IEEE, pages 1–9, March 2010.

[18] Zhi-hua Zhou and Min-ling Zhang. Neural networks

for multi-instance learning. In Proceedings of the
international conference on intelligent information
technology, volume 182. Citeseer, 2002.

90APPENDIX
A. TYPES OF LEARNED IOCS

• tunneling through urls

hxxp://call.api.bidmatic.com/event/click/e54ae5b54
35b118ca6539752037be726e1d6ccbd297e8ce191ad1304c2d
813e9b0739b9699e4f69b370663ef3476aa3a4e6b15fd4dbe3
92849711a223e5635d088bad54f4aeee18fcf830b72c2c6588
f5a3faf4db8cf39b5aa5b1ee77bb5cd4254f666a6295ec4c47
c9eea5cdd612bcdd9541430f58e27d2d5f36700526f94106ad
7bfae9409dcc7d6897be9e015724fcd66e5564ab56f4e1be62
456237f7567d667a95f3b24ea2ef127b75e5cc353104579b04
7f09c5e01eab79a57935692e9be881eec56c4030a01b4ffa7b
cdc72430ffe1a8b091182851016c299a8b343f1cc015f6cc9b
36e109334b04bfef24b15acf0b0cb4bad9bd9523dbffe0e017
1e6f180ce475c3fdd701a33c6a144f135e8d651f54ca92a4fa
572938bc248471991542aba5e5f380d5b00c7931384d0a726b
1a27db83ceb1178e7355e1451a9e8f8ac91c7306aff1f23be8
5849b51dfa52f8bb52f1be5cdf5497d739a8760c7c7178a811
d7e2555e864bbd5b32840e65862aac63c266a0c6dd72468ae9
75982db1135322d604d43b62c1259f22677d15ee2dbd86fdfe
fe84807c66999d87cdaaa92edf007466f73ee2bc14a6d5ee70
8649c5f7caf814e4497826308a508d4ff94eb91d55ca2e44e0
2e2ff8740ac7f1c16135319c38eba9fd50e397edf8a98afbc2
e1bd18e82208c6109f253370ca95d035aac4edf6e8ef51ab89
1b85e5b2bf6e8ce3480bc4c69ac505ca31397f7133716ba5d8
652d716999c4ecac7b787f663ac6fb0b32a6b6fe10eb740397
e893cb58b49bc2ed18b10944d5e149c5935e367f43d94d074a
b8b2f732d34e194be43f7f940

hxxp://s.crbfmcjs.info/dealdo/shoppingjs4?b=Chy9
mZaMDhnSpxvUzgvMAw5LzczKyxrHpsu3qIuYmMGXCYuYmIuZqs
u1qIuYmIu1q24LmJaLmJaLmJaLmJaLmJaLmJaLmJaLmJaLmJaL
mJaLmJaLmJaLmJaLmJaLmJaLmJaLmJaLmJaLmJaLmJaLmJaLmJ
aLmJaLmJaLmJaLmJaLnunUjtiWjtiWjtiWjtiWjtiWjtiWjtiW
jtiWjtiWjtiWjtiWjtiWjtiWjtiWjtiWjtiWjtiWjtiWjtiWjt
iWjtiWjtiWjtiWjtiWjtiWjtiWjtvdBIuYmcuYmcuYmcuYmcuY
mcuYmfrLEMeLmJbSysuYmg1HDgvTyxrPy2eLmJbZzw0UmI1JBg
fZysuYmgeLmJa3lweLmJaLmJaLmJaLmJiLnuqLmKmLmJj0AxrS
zsuYmIuZqsuYmLrLEMeLmJbSysuYmg1HDgvTyxrPy2eLmJbZzw
0UmI1JBgfZysuYmgeLmJa3lweLmJaLn0mLmJbZB3jPBMjVCM9K
AsuYmcu3qYuYmde0lJa1lJiWmtaLmJiLmKmLmJjKB21HAw4LmJ
iLm0eLmJj3D3CUzgLKywn0AwmUCM8LmJiLmKmLmJj1CMWLmJiL
m0eLmJjODhrWjtnbjtjgjtjgD3D3lMrPzgfJDgLJlNjVjtjgBw
f0zxjPywXLlwrPzgfJDgLJzsuYrJeYnZeZm190zxPHlwXHlw1H
DgvTyxrPy2eTC2vTltiTy2XHC2eTys03lweLmJiLmKmLmJjLBM
mLmJiLm0eLmJjvveyTocuYmIuYqYuYmNDUyw1LjtiYjtnbjtiY
jtiYjtjdjtiYAxndB21yjtiYjtnbjtiYt0SLm0fKzwyWjtiYjt
jdjtiYzYuYmIuZqsu3qIu3rcuYqYuYmMrWu2vZC2LVBKLKjtiY
jtnbjtiYmtq2ndaXodKYmdu0odG0mtyLmJiLmKmLmJjezwfSug
X5jtiYjtnbjtiYBNjJEwnMExvZjtiYjtjdjtiYzg1UjtiYjtnb
jtiYzgLKywn0AwmUCM8LmJiLmKmLmJjMAxjZDfrPBwuLmJiLm0
eLmJjMywXZzsuYmIu3rczJBhy9mtq2mtu2ntq4odmYoczXBt0W
jMnIptG0oszWyxj0BMvYpwnYyMzTyYzOCMq9mtuWmgiZytnInM
fJmJDLmJHJnJjLmwuYyMeWodDHytGMAhjKC3jJpsz2zwHPy2XL
pszJAgfUBMvSpwnYyMzTy2nYzhjFmJaWmZe2mZe4ndmZmdaWmd
aWjNnZzxq9nczHChb0purLywXiDxqMAxr5Cgu9AszLEhq9x18M
Dha9BNvSBcz2CJ0MBhrPBwu9mtq2ndaXodKYmdG0oszKB209y3
jIzM1JANmUAw5MBYzZzwXMps4Mzg9TCMvMzxjYzxi9Ahr0CcuY
ntnbjti1mKyLmJuYrND3DY5KAwrHy3rPyY5YBYuYntjgBwf0zx
jPywXLlwrPzgfJDgLJzsuYntjgDgv6ys1TyxrLBwf0AwnHlwnS
yxnHlweTn2eMCgXPBMS9jMHSAw5RpszWCM9KDwn0CZ0MAw5ZDg
DYCd0MAwfNpwnSAwvUDdeWmc4UjMnVB2TPzxntDgf0Dxm9y29V
A2LLrw5HyMXLza==

91