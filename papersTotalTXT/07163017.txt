2015 IEEE Symposium on Security and Privacy
2015 IEEE Symposium on Security and Privacy

VC3: Trustworthy Data Analytics in the Cloud using SGX

Felix Schuster∗, Manuel Costa, C´edric Fournet, Christos Gkantsidis

Marcus Peinado, Gloria Mainar-Ruiz, Mark Russinovich

Microsoft Research

Abstract—We present VC3, the ﬁrst system that allows users
to run distributed MapReduce computations in the cloud while
keeping their code and data secret, and ensuring the correctness
and completeness of their results. VC3 runs on unmodiﬁed
Hadoop, but crucially keeps Hadoop, the operating system and
the hypervisor out of the TCB; thus, conﬁdentiality and integrity
are preserved even if these large components are compromised.
VC3 relies on SGX processors to isolate memory regions on
individual computers, and to deploy new protocols that secure
distributed MapReduce computations. VC3 optionally enforces
region self-integrity invariants for all MapReduce code running
within isolated regions, to prevent attacks due to unsafe memory
reads and writes. Experimental results on common bench-
marks show that VC3 performs well compared with unprotected
Hadoop: VC3’s average runtime overhead is negligible for its
base security guarantees, 4.5% with write integrity and 8% with
read/write integrity.

I. INTRODUCTION

Cloud providers provision thousands of computers into data
centers and make them available on demand. Users rent this
computing capacity to run large-scale distributed computations
based on frameworks such as MapReduce [4], [20]. This is a
cost-effective and ﬂexible arrangement, but it requires users to
trust the cloud provider with their code and data: while data
at rest can easily be protected using bulk encryption [35],
at some point, cloud computers typically need access to
the users’ code and data in plaintext
in order to process
them effectively. Of special concern is the fact that a single
malicious insider with administrator privileges in the cloud
provider’s organization may leak or manipulate sensitive user
data. In addition, external attackers may attempt to access this
data, e. g., by exploiting vulnerabilities in an operating system
or even a hypervisor deployed in the cloud infrastructure.
Finally, attackers may also tamper with users’ computations
to make them produce incorrect results. Typically, cloud users
hope for the following security guarantees:

I Conﬁdentiality and integrity for both code and data; i. e.,
the guarantee that they are not changed by attackers and
that they remain secret.

II Veriﬁability of execution of the code over the data; i. e.,
the guarantee that their distributed computation globally
ran to completion and was not tampered with.

In theory, multiparty computation techniques may address
these demands. For
instance, data conﬁdentiality can be
achieved using fully homomorphic encryption (FHE), which
enables cloud processing to be carried out on encrypted

*Work done while at Microsoft Research; afﬁliated with Horst G¨ortz Institut

(HGI) at Ruhr-Universit¨at Bochum, Germany.

© 2015, Felix Schuster. Under license to IEEE.
© 2015, Felix Schuster. Under license to IEEE.
DOI 10.1109/SP.2015.10
DOI 10.1109/SP.2015.10

38
38

[22]. However, FHE is not efﬁcient for most com-
data
putations [23], [65]. The computation can also be shared
between independent parties while guaranteeing conﬁdential-
ity for individual inputs (using e. g., garbled circuits [29])
and providing protection against corrupted parties (see e. g.,
SPDZ [19]). In some cases, one of the parties may have
access to the data in the clear, while the others only have
to verify the result, using zero-knowledge proofs (see e. g.,
Pinocchio [48], Pantry [13], and ZQL [21]). Still, our goals
cannot currently be achieved for distributed general-purpose
computations using these techniques without losing (orders
of magnitude of) performance. Other systems use speciﬁc
types of computation and provide practical guarantees, but do
not protect all code and data (see e. g., CryptDB [50] and
Cipherbase [6]).

We present Veriﬁable Conﬁdential Cloud Computing (VC3),
a MapReduce framework that achieves the security guarantees
(I and II) formulated above, with good performance. Our threat
model accounts for powerful adversaries that may control
the whole cloud provider’s software and hardware infrastruc-
ture, except for the certiﬁed physical processors involved in
the computation. Denial-of-service, side-channels, and trafﬁc-
analysis attacks are outside the scope of this work.

Our main contribution is the design, implementation, and
evaluation of a practical system that integrates hardware prim-
itives, cryptographic protocols, and compilation techniques.
We use trusted SGX processors [3], [27], [41] as a building
block, but we need to solve several challenges not directly
addressed by the hardware. The ﬁrst is to partition the system
into trusted and untrusted parts, to minimize its TCB. VC3
runs on unmodiﬁed Hadoop, but our design crucially keeps
Hadoop, the operating system and the hypervisor out of the
TCB. Thus, our conﬁdentiality and integrity guarantees hold
even if these large software components are compromised. To
keep the TCB small in our design, users simply write the usual
map and reduce functions in C++, encrypt them, bind them
to a small amount of code that implements our cryptographic
protocols, and ﬁnally upload the code to the cloud. On each
worker node, the cloud operating system loads the code into
a secure region within the address space of a process and
makes use of the security mechanisms of SGX processors to
make the region inaccessible to the operating system and the
hypervisor. Subsequently, the code inside the region runs our
key exchange protocol, decrypts the map and reduce functions,
and runs the distributed computation that processes the data.
By comparison, recent work [9] proposes loading a library
variant of Windows 8 together with an application into an
SGX-isolated region; this allows running unmodiﬁed Windows

binaries, but results in a TCB that is larger than VC3’s by
several orders of magnitude.

The second challenge is to guarantee integrity for the whole
distributed computation, since the processors guarantee only
integrity of memory regions on individual computers. We thus
propose an efﬁcient job execution protocol that guarantees the
correct and conﬁdential execution of distributed MapReduce
jobs: the computing nodes produce secure summaries of the
work they perform, and they aggregate the summaries they
receive from their peers. By verifying the ﬁnal summaries
included in the results, the user can check that the cloud
provider did not interfere with the computation. At the same
time,
the cloud provider can freely schedule and balance
the computation between the nodes, as long as all data is
eventually processed correctly.

The ﬁnal challenge is to protect the code running in the
isolated memory regions from attacks due to unsafe memory
accesses. SGX processors allow this code to access the en-
tire address space of its host process, thus unsafe memory
accesses can easily leak data or enable other attacks. Since
implementing full memory safety for C/C++ [43], [44], [60]
is expensive, we instead provide a compiler that efﬁciently
enforces two region self-integrity invariants for code in an
isolated region: region-write-integrity which guarantees that
writes through pointers write only to address-taken variables
or heap allocations in the isolated region, and that indirect call
instructions target only address-taken functions in the region;
and region-read-write-integrity, which further guarantees that
reads through pointers read only from addresses inside the
region. Users who want these additional security assurances
may use our compiler.

We implemented VC3 for the popular Hadoop distribution
HDInsight on the Windows operating system. Our implemen-
tation is based on the new hardware security mechanisms
of Intel SGX, but it could in principle target other secure
computing technologies [46]. Experimental results on com-
mon benchmarks show that VC3 performs well compared
with unprotected Hadoop; VC3’s average runtime overhead
is negligible for its base security guarantees, 4.5% with write
integrity and 8% with read/write integrity.

In summary we make the following contributions:
• We describe the design and implementation of VC3, the
ﬁrst system executing MapReduce jobs with good performance
while guaranteeing conﬁdentiality and integrity of code and
data, as well as the correctness and completeness of the
results. We propose a partitioning of the system that achieves
a small TCB: we keep Hadoop, the operating system and the
hypervisor out of the TCB. Our design runs on unmodiﬁed
Hadoop and works well with Hadoop’s scheduling and fault-
tolerance services.
• We design and implement two new security protocols,
for each MapReduce job, ﬁrst for cloud attestation and key
exchange, then for running the job and gathering evidence of
its correct execution. We establish their security by reduction
to standard cryptographic assumptions. The security proofs
appear in the extended version of this paper [55].

Input 
Splits

Intermediate
Key-Value Pairs

Output

Key-Value Pairs

M

M

M
Step 2

(mapping)

R

R

Step 3

(reducing)

Output

Input

Step 1

(splitting)

Fig. 1: The steps of a MapReduce job as discussed in this work with mappers
(M) and reducers (R).

• We design and implement efﬁcient, compiler-based,
region-write-integrity and region-read-write-integrity invari-
ants for all user code running within isolated regions.
• We report on the performance of a practical

imple-
mentation of VC3 under realistic conditions by running 7
applications on a Hadoop cluster.

We proceed as follows: we provide background (§II), in-
troduce our adversary model (§III), present an overview of
our design (§IV), present our cryptographic protocols (§V and
§VI), describe our region self-integrity invariants and how to
enforce them (§VII), discuss limitations (§VIII), present our
implementation (§IX), evaluate our approach (§X), discuss
related work (§XI), and conclude (§XII).
II. BACKGROUND

A. MapReduce

MapReduce [20] is a popular programming model for process-
ing large data sets: users write map and reduce functions, and
the execution of both functions is automatically parallelized
and distributed.

The abstract data-ﬂow of a parallel MapReduce job is de-
picted in Figure 1. Each job is a series of three steps: splitting,
mapping, and reducing. In the splitting step, the framework
breaks raw input data into so called input splits. Input splits are
then distributed between mappers. Each mapper node parses
its splits into input key-value pairs, and calls the map function
on each of them to produce intermediate key-value pairs. The
framework groups these pairs by key and distributes them
between reducers (partitioning and shufﬂing). Each reducer
node calls the reduce function on sets of all the values with
the same key to produce output key-value pairs.

Probably the most popular framework for the execution and
deployment of MapReduce jobs is Hadoop [4]. Hence, we
chose it as our default execution environment.

B. Intel SGX

SGX [3], [32], [41] is a set of x86-64 ISA extensions that
makes it possible to set up protected execution environments
(called enclaves) without requiring trust in anything but the
processor and the code users place inside their enclaves.
Enclaves are protected by the processor: the processor controls
access to enclave memory. Instructions that attempt to read
or write the memory of a running enclave from outside
the enclave will fail. Enclave cache lines are encrypted and

3939

integrity protected before being written out to RAM. This
removes a broad class of hardware attacks and limits the
hardware TCB to only the processor. The software TCB is
only the code that users decide to run inside their enclave.

Enclave code can be called from untrusted code by means
of a callgate-like mechanism that transfers control to a user-
deﬁned entry point inside the enclave. Enclave execution may
be interrupted due to interrupts or traps. In such cases, the
processor will save the register context to enclave memory and
scrub the processor state before resuming execution outside the
enclave. Enclaves reside within regular user mode processes.
Enclave code can access the entire address space of its host
process. This feature allows for efﬁcient interaction between
enclave code and the outside world.

SGX supports sealed storage and attestation [3]. While
different in many details, these features have the same basic
purpose as sealed storage and attestation in other trusted com-
puting hardware. During enclave construction (by untrusted
software), the processor computes a digest of the enclave
which represents the whole enclave layout and memory con-
tents. This digest is roughly comparable to the PCR values of
the TPM [62]. Untrusted software, like the operating system
(OS) or the hypervisor, can freely interfere with enclave
creation, but such interference will cause the processor to
register a different digest for the enclave. The sealing facilities
provide each enclave with keys that are unique to the processor
and the enclave digest. Local attestation allows an enclave to
prove to another enclave that it has a particular digest and
is running on the same processor. This privileged mechanism
can be used to establish authenticated shared keys between
local enclaves. It also enables the deployment of enclaves that
support remote attestation. To this end, each SGX processor is
provisioned with a unique asymmetric private key that can be
accessed only by a special quoting enclave (QE) [3]. We refer
to this special QE as SGX QE. The SGX QE signs digests of
local enclaves together with digests of data produced by them,
creating so called quotes. A quote proves to a remote veriﬁer
that certain information came from a speciﬁc enclave running
on a genuine SGX processor.

C. Cryptographic Assumptions

We now introduce standard notations and security assumptions
for the cryptography we use.
We write m | n for the tagged concatenation of two
messages m and n. (That is, m0 | n0 = m1 | n1 implies
both m0 = m1 and n0 = n1.)

Cryptographic Hash, PRF, and Enclave Digest

We rely on a keyed pseudo-random function, written
PRFk(text) and a collision-resistant cryptographic hash func-
tion, written H(text). Our implementation uses HMAC and
SHA-256.

We write EDigest(C) for the SGX digest of an enclave’s
initial content C. We refer to C as the code identity of an
enclave. Intuitively, EDigest provides collision resistance; the
SGX speciﬁcation [32] details its construction.

Public-key Cryptography

We use both public-key encryption and remote attestation

for key establishment.
A public-key pair pk, sk is generated using an algorithm
PKGen(). We write PKEncpk{text} for the encryption of
text under pk. In every session, the user is identiﬁed and
authenticated by a public-key pku. We assume the public-
key encryption scheme to be at least IND-CPA [10]: without
the decryption key, and given the ciphertexts for any chosen
plaintexts, it is computationally hard to extract any information
from those ciphertexts. Our implementation uses an IND-
CCA2 [10] RSA encryption scheme.
We write ESigP [C]{text} for a quote from a QE with
identity P that jointly signs H(text) and the EDigest(C)
on behalf of an enclave with code identity C. We assume
that this quoting scheme is unforgeable under chosen message
attacks (UF-CMA). This assumption follows from collision-
resistance for H and EDigest and UF-CMA for the EPID
group signature scheme [15]. Furthermore, we assume that
Intel’s quoting protocol implemented by QEs is secure [3]:
only an enclave with code identity C may request a quote of
the form ESigP [C]{text}.

Authenticated Encryption

For bulk encryption, we rely on a scheme that provides
authenticated encryption with associated data (AEAD). We
write Enck(text, ad) for the encryption of text with associated
data ad, and Deck(cipher, ad) for the decryption of cipher
with associated data ad. The associated data is authenticated,
but not included in the ciphertext. When this data is commu-
nicated with the ciphertext, we use an abbreviation, writing
Enck[ad]{text} for ad | Enck(text, ad). (Conversely, any IV
or authentication tag used to implement AEAD is implicitly
included in the ciphertext.) We assume that our scheme is
both IND-CPA [11] (explained above) and INT-CTXT [11]:
without
the secret key, and given the ciphertexts for any
chosen plaintexts and associated data, it is hard to forge any
other pair of ciphertext and associated data accepted by Deck.
Our implementation uses AES-GCM [40], a high-performance
AEAD scheme.

III. ADVERSARY MODEL

We consider a powerful adversary who may control the entire
software stack in a cloud provider’s infrastructure, including
hypervisor and OS. The adversary may also record, replay,
and modify network packets. The adversary may also read or
modify data after it left the processor using probing, DMA, or
similar techniques. Our adversary may in particular access any
number of other jobs running on the cloud, thereby accounting
for coalitions of users and data center nodes. This captures
typical attacks on cloud data centers, e. g., an administrator
logging into a machine trying to read user data, or an attacker
exploiting a vulnerability in the kernel and trying to access
user data in memory, in the network, or on disk.

We assume that the adversary is unable to physically open
and manipulate at least those SGX-enabled processor pack-
ages that reside in the cloud provider’s data centers. Denial-

4040

Stack

e
v
a

l
c
n
E

Public Code E+

Private Code E-

Heap

Shared Memory

Framework F

...

Private Code E-

Public Code E+

readKV()/writeKV()

Framework F

CPU

M

Enclave 
Code
RAM

R

R

Input

M

M

Operating System

Fig. 3: High-level concept of a VC3 enhanced MapReduce job: code and data
are always kept encrypted when outside the processor chip.

Process Memory Layout

Dependencies

Fig. 2: Left: Memory layout of process containing SGX enclave and
framework code. Right: Dependencies between the involved components.

of-service, network trafﬁc-analysis, side-channels, and fault
injections are also outside the scope of this paper.

We consider the user’s implementation of the map and
reduce functions to be benign but not necessarily perfect: the
user’s code will never intentionally try to leak secrets from
enclaves or compromise the security of VC3 in any other way,
but it may contain unintended low-level defects.

IV. DESIGN OVERVIEW

Our goal is to maintain the conﬁdentiality and integrity of
distributed computations running on a network of hosts poten-
tially under the control of an adversary. This section outlines
our design to achieve this with good performance and keeping
large software components out of the TCB.

In VC3, users implement MapReduce jobs in the usual way:
they write, test, and debug map and reduce functions using
normal C++ development tools. Users may also statically link
libraries for particular data analytics domains (e. g., machine
learning) with their code; these libraries should contain pure
data-processing functions that do not depend on the operating
system (we provide mathematical and string libraries in our
prototype).

When their map and reduce functions are ready for produc-
tion, users compile and encrypt them, obtaining the private
enclave code E−. Then they bind the encrypted code together
with a small amount of generic public code E+ that imple-
ments our key exchange and job execution protocols (see §V).
Users then upload a binary containing the code to the cloud;
they also upload ﬁles containing encrypted data. In the cloud,
enclaves containing E− and E+ are initialized and launched
by public and untrusted framework code F on worker nodes.
Figure 2 depicts the memory layout of a process containing
the described components; it also shows their dependencies.
In VC3, a MapReduce job starts with a key exchange between
the user and the public code E+ running in the secure enclave
on each node. After a successful key exchange, E+ is ready
to decrypt the private code E− and to process encrypted data
following the distributed job execution protocol.

To keep the operating system out of VC3’s TCB, we kept
the interface between E+ and the outside world narrow.
Conceptually,
it has only two functions: readKV() and
writeKV(), for reading and writing key-value pairs from
and to Hadoop (akin to receiving and sending messages). Since
F and enclave share the virtual address space of a process,
data is passed from E+ inside the enclave to F outside the
enclave over a shared memory region outside the enclave.
Other than relying on this narrow interface, the code in the
enclave is self-sufﬁcient: it has no further dependencies on
the operating system. The enclave has its own stack which we
reserve on start-up (it includes a guard page to detect stack
out-of-memory conditions); it has its own heap, carved out
of the enclave memory region; and we guarantee that only
one thread at a time executes the user code (the enclave is
created with a single thread control structure, to ensure that
all execution of enclave code is single threaded); parallelism
is achieved in MapReduce jobs by running many instances of
the map and reduce functions in parallel in separate enclaves.
With this design, the operating system and the hypervisor can
still mount attacks such as not scheduling processes, dropping
or duplicating network packets, not performing disk I/O, and
corrupting data when it is out of the enclaves. While we cannot
guarantee progress if the operating system mounts denial of
service attacks, our job execution protocol guarantees that the
results are correct and complete if the distributed computation
terminates successfully.
Note that while in the cloud, both E− and the user’s data
are always kept encrypted, except when physically inside the
trusted processor chip on a mapper or reducer node, as shown
in Figure 3. Inside the processor chip, the user’s map and
reduce functions run on plaintext data at native speed. At
the same time, we allow Hadoop to manage the execution of
VC3 jobs. The framework code (F ) implements the Hadoop
streaming interface [5] to bind to unmodiﬁed Hadoop de-
ployments; VC3’s map and reduce nodes look like regular
worker nodes to Hadoop. Thus, Hadoop can use its normal
scheduling and fault-tolerance mechanisms to manage all data-
ﬂows, including performance mechanisms for load balancing
and straggler mitigation. But
the
operating system, and the hypervisor are kept out of the TCB.

the Hadoop framework,

4141

Some of these properties could also be achieved using
trusted hypervisors [17], [28], [36], [38], [58], but trusted
hypervisors are problematic in a cloud environment. They
force a potentially large privileged software component that is
under the control of the (possibly adversarial) cloud provider
into the TCB of every user. While users can use attestation to
authenticate a digest of such software, it is unclear how they
can establish trust in it, especially in light of periodic software
upgrades. While the software TCB of a VC3 application
may have as many or more lines of code as small special-
purpose hypervisors [38], [58], the former code is entirely
chosen and compiled by the user, whereas the latter are not.
It is also unclear how these special-purpose hypervisors could
be extended to coexist with the more functional hypervisors
used in cloud systems [8]. Finally, note that VC3’s hardware
TCB is only the SGX processor package; this is smaller than
traditional systems based on TXT [31] or a TPM (large parts
of the motherboard); this is important in a cloud setting where
the hardware is under the control of the cloud provider.

The ﬁnal aspect of the VC3 design is that users may enforce
region self-integrity invariants using our compiler. The region
integrity invariants act as an additional layer of protection that
allows the trusted code inside the enclave to continuously
monitor its internal state to prevent memory corruption and
disclosure of information due to low-level defects. Users who
want the additional security assurances may use our compiler,
but we emphasize that this optional; users may use other
mechanisms, including manual inspection, testing, and formal
veriﬁcation, to check that their code does not have defects.

V. JOB DEPLOYMENT

After preparing their code, users deploy it in the cloud. The
code is then loaded into enclaves in worker nodes, and it runs
our key exchange protocol to get cryptographic keys to decrypt
the map and reduce functions. After this, the worker nodes run
our job execution and veriﬁcation protocol. This section and
the next present our cryptographic protocols for the exchange
of keys and the actual MapReduce job execution, respectively.
Before describing these protocols in detail, we ﬁrst discuss the
concept of cloud attestation used in VC3.

A. Cloud Attestation

it does not guarantee that

As described above, in SGX, remote attestation for enclaves
is achieved via quotes issued by QEs. The default SGX QE
only certiﬁes that the code is running on some genuine SGX
processor, but
the processor is
actually located in the cloud provider’s data centers. This may
be exploited via a type of cuckoo attack [47]: an attacker could,
for example, buy any SGX processor and conduct a long term
physical attack on it to extract the processor’s master secret.
If no countermeasures were taken, she would then be in a
position to impersonate any processor in the provider’s data
centers. Note that our threat model excludes physical attacks
only on the processors inside the data centers.

To defend against such attacks, we use an additional Cloud

QE, created by the cloud provider whenever a new SGX-
enabled system is provisioned. The purpose of the Cloud QE
is to complement quotes by the SGX QE with quotes stating
that the enclave runs on hardware owned and certiﬁed by the
cloud provider, in a certain data center. At the same time, to
defend against possibly corrupted cloud providers, we only use
the Cloud QE in conjunction with the SGX QE. (Note that the
cloud provider cannot fake quotes from the SGX QE, since
our threat model excludes physical attacks on the processors
inside the data centers.) The procedure to provision Cloud
QEs is simple. Before a new machine enters operation in a
data center, a Cloud QE is created in it. This Cloud QE then
generates a public/private key pair, outputs the public key and
seals the private key which never leaves the Cloud QE.

two ﬁxed

the

assume
for

following, we
for SGX and

In
the
signing
identities
cloud, we write
ESigSGX [C]{text} and ESigCloud[C]{text} for quotes
by the main SGX QE and the Cloud QE, respectively,
and write ESigSGX,Cloud[C]{text} for their concatenation
ESigSGX [C]{text} | ESigCloud[C]{text}.
We foresee that cloud providers will create groups of proces-
sors based on geographical, jurisdictional, or other boundaries
that are of interest to the user, and will publish the appropriate
public keys to access these groups of processors.

B. Key Exchange

To execute the MapReduce job, enclaves ﬁrst need to get keys
to decrypt the code and the data, and to encrypt the results.
In this section we describe our protocol for this. Our key
exchange protocol is carefully designed such that it can be
implemented using a conventional MapReduce job that works
well with existing Hadoop installations. We ﬁrst describe
the protocol using generic messages, and then show how to
integrate it with Hadoop. We present a multi-user variant in
Appendix A and a lightweight variant in Appendix B.

Recall that the user is identiﬁed and authenticated by her key
pku for public-key encryption and each SGX processor runs
a pair of SGX and Cloud QEs. Before running the protocol
itself, the user negotiates with the cloud provider an allocation
of worker nodes for running a series of jobs.

Setting up a new job involves three messages between the

user and each node:

1) The user chooses a fresh job identiﬁer j and generates a
fresh symmetric key kcode to encrypt E−, then sends to
any node involved the code for its job enclave (Cj,u):

Cj,u = E+ | Enckcode

[]{E−} | j | pku.

2) Each node w starts an enclave with code identity Cj,u.
1 and

Within the enclave E+ derives a symmetric key kw
encrypts it under the user’s public key:
{kw}.

mw = PKEncpku

1This can be the enclave’s sealing key or a key generated using the random

output of the x86-64 instruction RDRAND.

4242

The enclave then requests quotes from the SGX and
Cloud QEs with text mw, thereby linking mw to its code
identity Cj,u (and thus also to the job-speciﬁc j and pku).
The message mw and the quotes are sent back to the user:

pw = mw | ESigSGX,Cloud[Cj,u]{mw}.

3) The user processes a message pw from each node w, as
follows: the user veriﬁes that both quotes sign the mes-
sage payload mw with the code identity Cj,u sent in the
initial message; then, the user decrypts mw and responds
with job credentials encrypted under the resulting node
key kw:

JCw = Enckw

[]{kcode | k}

where kcode is the key that protects the code E− and

k = kjob | kin | kinter | kout | kprf

is the set of authenticated-encryption keys used in the
actual job execution protocol (see §VI). Speciﬁcally, kjob
is used to protect veriﬁcation messages while kin, kinter,
and kout are used to protect input splits, intermediate key-
value pairs, and output key-value pairs respectively; kprf
is used for keying the pseudo-random function PRF.

4) Each node resumes E+ within the job enclave, which
decrypts the job credentials JCw using kw, decrypts its
private code segment E− using kcode, and runs E−.

On completion of the protocol, the user knows that any enclave
that contributes to the job runs the correct code, and that she
shares the keys for the job with (at most) those enclaves.

Our protocol provides a coarse form of forward secrecy,
inasmuch as neither the user nor the nodes need to maintain
long-term private keys. (The user may generate a fresh pku
in every session.) The protocol can also easily be adapted to
implement a Difﬁe-Hellmann key agreement, but this would
complicate the integration with Hadoop described in §V-C.
An outline of the security theorem for the key exchange
is given below; the formal theorem statement, auxiliary def-
initions, and proof appear in the extended version of this
paper [55].
Theorem 1. Enclave and Job Attestation (Informally)

1) If a node completes the exchange with user public key pku
and job identiﬁer j, then the user completed the protocol
with those parameters; and
the same job code E+, E− and job keys in k; and

2) all parties that complete the protocol with (pku, j) share
3) the adversary learns only the encrypted size of E−, and

nothing about the job keys in k.

C. Integrating Key Exchange with Hadoop

Hadoop does not foresee online connections between nodes
and the user, hence we need another mechanism to implement
the key exchange in practice. We now describe the in-band
variant of key exchange that is compatible with unmodiﬁed
Hadoop installations and is implemented in our VC3 prototype.

4343

The in-band variant of key exchange is designed as a
lightweight key exchange job that is executed before the actual
job. The online communication channels between nodes and
user are replaced by the existing communication channels in
a MapReduce job: user → mapper → reducer → user.
By design, our in-band key exchange also does not require
nodes to locally maintain state between invocations. (Per
default, Hadoop does not foresee applications to store ﬁles
permanently on nodes.) This is achieved by diverting the
enclaves’ unique and secret sealing keys from their common
use. The exact procedure is described in the following.

The user creates Cj,u and the accompanying parameters for
the actual job as described. The user then deploys this exact
Cj,u ﬁrst for the special key exchange job. It is important that
the same Cj,u is executed on the same nodes for both jobs.
When launched on a mapper or reducer node, E+ obtains
the enclave’s unique sealing key (unique to the processor
and digest of Cj,u, see §II-B) and uses it as its node key
kw. Each node outputs the corresponding pw in the form
of a MapReduce key-value pair. Mapper nodes immediately
terminate themselves subsequently, while reducer nodes re-
main active until having forwarded all intermediate key-value
pairs containing the mappers’ pw. E− is not (and cannot be)
decrypted during the key exchange job. The user obtains all
pw from the ﬁnal outputs of the key exchange job. The user
creates the job credentials JCw for each node as described.
Finally, the user writes JCw for all nodes to a ﬁle and deploys
it together with Cj,u for the actual job.

During the actual job, E+ derives the unique sealing key
(equivalent to kw) on each node again and uses it to decrypt the
corresponding entry in D, obtaining kcode and k. Afterward,
E− is decrypted and the execution of the job proceeds as
normal. Note how it is essential to use the exact same Cj,u in
both jobs. Otherwise, the sealing keys used in the key exchange
job could not be re-obtained during the execution of the actual
job. Thus, E+ needs to implement the required functionality
for both jobs.

VI. JOB EXECUTION AND VERIFICATION

After obtaining keys to decrypt the secret code and data,
worker nodes need to run the distributed MapReduce com-
putation. A na¨ıve approach for protecting the computation
would be to simply encrypt and authenticate all
the key-
value pairs exchanged between the nodes. A hostile cloud
environment would though still be in the position to arbitrarily
drop or duplicate data. This would allow for the manipulation
of outputs. A dishonest cloud provider might also simply be
tempted to drop data in order to reduce the complexity of
jobs and thus to save on resources. Furthermore, care has to
be taken when encrypting data in a MapReduce job in order
not to negatively impact the load-balancing and scheduling
capabilities of Hadoop or the correctness of results. In this
section we present our protocol that tackles these problems and
guarantees the overall integrity of a job and the conﬁdentiality
of data. As before, we ﬁrst describe the protocol using generic
messages, and then show how to integrate it with Hadoop.

Setup

Execution

Sjob

V

I
II
I
Input‘

MMMM

KVC
KVC
KVC
KVC
KV‘inter
out
out
out
out

KVC
KVC
KVC
KVclose

R
RR

KVC
KVC
KVC
KVC
KV‘out
out
out
out
out

Verification

V

Soutput

MMMM

KVCKVCKVC
FM

RRR

IIFR

Fig. 4: Schematic overview of our job execution protocol. The veriﬁer (V), mappers (M), and reducers (R) are depicted as squares. A light-gray circle displays
a message/key-value pair that is sent once by an entity; a dark-gray circle one that is sent multiple times. The user is depicted at both far ends.

For now, we rely on a not further speciﬁed veriﬁer that
can communicate securely with the user and is trusted by the
user. In practice, the veriﬁer can run on a user’s local machine
or in an enclave. We show later how the veriﬁer can also
be implemented “in-band” as a distinct MapReduce job. Our
implementation uses a distinct tag for each type of message;
these tags are omitted below for simplicity. The entire protocol
is implemented in E+. Figure 4 gives a schematic overview
of the message ﬂows in the protocol.

Step 1: Setup
As a preliminary step, the user uploads chunks of AEAD-
encrypted data as input splits to the cloud provider. Each
encrypted input split Input is cryptographically bound to a
fresh, unique identiﬁer (ID) (cid:2)in:
(cid:2) = Enckin

[(cid:2)in]{Input}

Input

(In practice, we use the 128-bit MAC of the AES-GCM
encryption as ID. Book keeping can though be simpler
(cid:2)
are
for incremental IDs.) All encrypted input splits Input
stored by the cloud provider. The user decides on a subset
of all available input splits as input for the job: Bin =
{(cid:2)in,0, (cid:2)in,1, . . . , (cid:2)in,n−1}; chooses a number of logical reduc-
ers for the job: R; and passes the job speciﬁcation Sjob =
j | kjob | R | Bin securely to the veriﬁer. The number of
mapper instances is not ﬁxed a priori as Hadoop dynamically
creates and terminates mappers while executing a job. We
write m ∈ m for the mapper indexes used for the job. (This
set of indexes is a priori untrusted; one goal of the protocol
is to ensure that all reducers agree on it.)

Step 2: Mapping
Hadoop distributes input splits to running mapper instances.
As input splits are encrypted, Hadoop cannot parse them
for key-value pairs. Hence,
the parsing of input splits is
undertaken by E+. Mappers keep track of the IDs of the input
splits they process, and they refuse to process any input split
more than once.

Intermediate Key-Value Pairs

Mappers produce intermediate key-value pairs KVinter =
(cid:4)Kinter : Vinter(cid:5) from the input splits they receive. Hadoop
assigns these to reducers for ﬁnal processing according to each
pair’s key (the shufﬂing step). For the functional correctness
of a job, it is essential that key-value pairs with identical
keys are processed by the same reducer; otherwise the job’s
ﬁnal output could be fragmented. However, the user typically
has a strong interest in keeping not only the value Vinter
but also the key Kinter of an intermediate key-value pair

secret. Thus, our mappers wrap plaintext intermediate key-
value pairs in encrypted intermediate key-value pairs KV (cid:2)
inter
of the following form:

inter : V (cid:2)

(Kinter) mod R

inter = r ≡ PRFkprf
K(cid:2)
inter = Enckinter [j | (cid:2)m | r | im,r]{(cid:4)Kinter : Vinter(cid:5)}
V (cid:2)
inter = (cid:4)K(cid:2)
KV (cid:2)

inter(cid:5)
inter ∈ 0..R − 1, and all interme-
By construction, we have K(cid:2)
diate key-value pairs KV with the same key are assigned to
the same logical reducer. The derivation of K(cid:2)
inter is similar
to the standard partitioning step performed by Hadoop [4].
In the associated authenticated data above, (cid:2)m is a secure
unique job-speciﬁc ID randomly chosen by the mapper m ∈ m
for itself (in our implementation we use the x86-64 instruction
RDRAND inside the enclave); r is the reducer index for the
key; and im,r is the number of key-value pairs sent from
this mapper to this reducer so far. Thus, ((cid:2)m, r, im,r) uniquely
identiﬁes each intermediate key-value pair within a job. Note
that, in practice, many plaintext KVinter from one mapper to
one reducer may be batched into a single KV (cid:2)

inter.

Mapper Veriﬁcation

For veriﬁcation purposes, after having processed all their in-
puts, our mappers also produce a special closing intermediate
key-value pair for each r ∈ R:
KVclose = (cid:4)r : Enckinter

[j | (cid:2)m | r | im,r]{}(cid:5)

This authenticated message ensures that each reducer knows
the total number im,r of intermediate key-value pairs (zero
or more) to expect from each mapper. In case a reducer
does not receive exactly this number of key-value pairs, or
receives duplicate key-value pairs, it terminates itself without
outputting its ﬁnal veriﬁcation message (see next step).

Furthermore, each mapper sends the following ﬁnal veriﬁ-

cation message to the veriﬁer:
FM = Enckjob

[j | (cid:2)m | Bin,m]{}

where Bin,m is the set of IDs of all input splits the mapper
m ∈ m processed. This authenticated message lets the veriﬁer
aggregate information about the distribution of input splits.

Step 3: Reducing
Assuming for now that Hadoop correctly distributes all
intermediate key-value pairs KV (cid:2)
inter and KVclose, reducers
produce and encrypt the ﬁnal output key-value pairs for the
job:

KV (cid:2)

out = (cid:4)(cid:2)out : Enckout

[(cid:2)out]{KVout}(cid:5)

4444

where KVout is a split of ﬁnal output key-value pairs, with
secure unique ID (cid:2)out. (Again, we may use the MAC of the
AES-GCM encryption as unique ID.) By design, the format of
V (cid:2)
out is compatible with the format of encrypted input splits,
allowing the outputs of a job to be immediate inputs to a
subsequent one.

Reducer Veriﬁcation

After having successfully processed and veriﬁed all key-
inter and KVclose received from mappers, each

value pairs KV (cid:2)
reducer sends a ﬁnal veriﬁcation message to the veriﬁer:
FR = j | r | Bout,r | Enck(j | r | Bout,r | Pr,{})
Pr ⊆ ((cid:2)m)m∈m

The authenticated message FR carries the set Bout,r of IDs
(cid:2)out for all outputs produced by the reducer with index r ∈ R.
It also authenticates a sorted list Pr of mapper IDs, one for
each closing intermediate key-value paper it has received. (To
save bandwidth, Pr is authenticated in FR but not transmitted.)

Step 4: Veriﬁcation
The veriﬁer receives a set of FM messages from mappers
and a set of FR messages from reducers. To verify the global
integrity of the job, the veriﬁer ﬁrst checks that it received
exactly one FR for every r ∈ 0..R − 1.
The veriﬁer collects and sorts the mapper IDs Pverif ier ⊆
((cid:2)m)m∈m from all received FM messages, and it checks that
Pverif ier = Pr for all received FR messages, thereby ensuring
that all reducers agree with Pverif ier.

The veriﬁer checks that the sets Bin,m received from the
mappers form a partition of the input split IDs of the job
speciﬁcation, thereby guaranteeing that every input split has
been processed once.

(cid:2)

Finally, the veriﬁer accepts the union of the sets received
from the reducers, Bout =
r∈0..R−1 Bout,r, as the IDs of the
encrypted job output. The user may download and decrypt this
output, and may also use Bout in turn as the input speciﬁcation
for another job (setting the new kin to the previous kout).

A. Security Discussion

We outline below our security theorem for the job execution
and subsequently discuss the protocol informally; the formal
theorem statement, auxiliary deﬁnitions, and proof appear in
the extended version of this paper [55].
Theorem 2. Job Execution (Informally)

1) If the veriﬁer completes with a set of output IDs, then
the decryptions of key-value pairs with these IDs (if they
succeed) yield the correct and complete job output.

2) Code and data remains secret up to trafﬁc analysis: The
adversary learns at most (i) encrypted sizes for code,
input splits, intermediate key-value pairs, and output key-
value pairs; and (ii) key-repetition patterns in intermedi-
ate key-value pairs.

We observe that, if the veriﬁer completes with a set of output
IDs, then the decryptions of key-value pairs with these IDs
(if they succeed) yield the correct and complete job output.

For each cryptographic data key, AEAD encryption guarantees
the integrity of all messages exchanged by the job execution
protocol; it also guarantees that any tampering or truncation
of input splits will be detected.
Each message between mappers, reducers, and veriﬁer
(KV (cid:2)
inter, KVclose, FM, and FR) includes the job-speciﬁc
ID j, so any message replay between different jobs is also
excluded. Thus, the adversary may at most attempt to duplicate
or drop some messages within the same job. Any such attempt
is eventually detected as well: if the veriﬁer does not receive
the complete set of messages it expects, veriﬁcation fails;
otherwise, given the FM messages from the set m(cid:2) of mappers,
it can verify that the mappers with distinct IDs ((cid:2)m)m∈m(cid:2)
together processed the correct input splits. Otherwise, if any
inputs splits are missing, veriﬁcation fails. Furthermore, given
one FR message for each r ∈ 0..R − 1, the veriﬁer can verify
that every reducer communicated with every mapper. Given
R, the veriﬁer can also trivially verify that it communicated
with all reducers that contributed to the output.

Reducers do not know which mappers are supposed to
send them key-pairs. Reducers though know from the KVclose
messages how many key-value pairs to expect from mappers
they know of. Accordingly, every reducer is able to locally
verify the integrity of all its communication with every mapper.
Although the adversary can remove or replicate entire streams
of mapper/reducer communications without being detected by
the reducer, this would lead to an incomplete set Pr of mapper
IDs at the reducer, eventually detected by the veriﬁer.

B. Analysis of Veriﬁcation Cost

We now analyze the cost for the veriﬁcation of a job with
M mappers and R reducers. VC3’s full runtime cost
is
experimentally assessed in §X.

There are M + R veriﬁcation messages that mappers and
reducers send to the veriﬁer. These messages most signiﬁcantly
contain for each mapper the set Bin,m of processed input split
IDs and for each reducers the set Bout,r of IDs of produced
outputs. Each ID has a size of 128 bits. Typically, input splits
have a size of 64 MB or larger in practice. Hence, mappers
need to securely transport only 16 bytes to the veriﬁer per 64+
MB of input. As reducers should batch many output key-value
pairs into one KV (cid:2)
out, a similarly small overhead is possible for
reducer/veriﬁer communication. There are M × R veriﬁcation
messages sent from mappers to reducers. These messages are
small: they contain only four integers. The computational cost
of veriﬁcation amounts to the creation and veriﬁcation of
the MACs for all M + R + M × R veriﬁcation messages.
Additionally, book keeping has to be done (by all entities).
We consider the cost for veriﬁcation to be small.

C. Integrating the Veriﬁer with Hadoop

For the job execution protocol it is again desirable to avoid
online connections between the involved entities. We now
describe a variant of the protocol
implements an in-
band veriﬁer as a simple MapReduce job. Our VC3 prototype
implements this variant of the job execution protocol.

that

4545

Mappers send FM messages in the form of key-value pairs
to reducers. Reducers output all FM key-value pairs received
from mappers and also output their own FR messages in the
form of key-value pairs. The veriﬁcation job is given Sjob
of the actual job and is invoked on the entire corresponding
outputs. The mappers of the veriﬁcation job parse input splits
for FM and FR messages and forward them to exactly one
veriﬁcation reducer by wrapping them into key-value pairs
with a predeﬁned key K(cid:2)
inter. On success, the veriﬁcation
reducer outputs exactly one key-value pair certifying Bout as
valid output for Sjob. This key-value pair can ﬁnally easily
be veriﬁed by the user. In practice, the veriﬁcation job can be
bundled with a regular job that already processes the outputs
to be veriﬁed while parsing for veriﬁcation messages. In such
a case, one of the regular reducers also acts as veriﬁcation
reducer (we use the reducer with r = 0). The bundled job in
turn creates its own veriﬁcation messages FM and FR. This
way, it is possible to chain an arbitrary number of secure
MapReduce jobs, each verifying the integrity of its immediate
successor with low overhead.

VII. REGION SELF-INTEGRITY

The ﬁnal aspect of our design is the enforcement of region
self-integrity invariants for user code loaded into enclaves. By
design, code within an enclave can access the entire address
space of its host process. This enables the implementation of
efﬁcient communication channels with the outside world but
also broadens the attack surface of enclaves: if enclave code,
due to a programming error, ever dereferences a corrupted
pointer to untrusted memory outside the enclave, compromise
of different forms becomes possible. For example, the enclave
code may write through an uninitialized pointer or a null
pointer; if the pointer happens to contain an address that is
outside of the enclave, data immediately leaks out. Conversely,
reads through such pointers may cause the user code to read
data from arbitrary addresses outside the enclave;
in this
case, the untrusted environment is in the position to inject
arbitrary data into the enclave. Such a data injection may in
the simplest case affect the correctness of computations but
may also, depending on the context of the corrupted pointer
dereference, pave the way for a control-ﬂow hijacking attack
eventually allowing the adversary to capture all the enclave’s
secrets. We stress that we assume the code inside the enclave is
not malicious, but it may have low-level defects; applications
written in languages like C and C++ have a long history of
problems induced by unsafe memory accesses.

Since memory safety implementations for C/C++ have high
overhead [43], [44], [60], we instead address this problem
with a compiler that efﬁciently enforces two security invariants
for code running inside the enclave. Before presenting the
invariants, we introduce some terminology. An address-taken
variable is a variable whose address is taken in the code,
e. g. &v, or an array (the address of arrays is implicitly taken).
By write through a pointer we mean writing to the memory
targeted by the pointer (this includes array accesses, which use

4646

a pointer and an offset). Likewise for read through a pointer.
We deﬁne two invariants:

indirect call

Region-write-integrity guarantees that writes through point-
ers write only to address-taken variables in the enclave or to
allocations from the enclave heap. Additionally, it guarantees
that
instructions can target only the start of
address-taken functions in the enclave.
includes

region-write-
integrity guarantee, plus the guarantee that reads through
pointers read only from addresses inside the enclave.

Region-read-write-integrity

the

Region-write-integrity prevents memory corruption: it pre-
vents corruption of all non-address-taken variables in the
program (typically a large fraction of the stack frames contain
only non-address-taken variables [34]) and it prevents corrup-
tion of all compiler-generated data such as return addresses on
the stack. It also prevents information leaks caused by writes to
outside of the enclave. Region-read-write-integrity additionally
prevents use of un-authenticated data from outside the enclave,
which may be injected by an attacker.

The integrity invariants are enforced with dynamic checks
on memory reads, writes and control-ﬂow transitions. The
compiler inserts dynamic checks when it cannot verify the
safety of memory operations or control-ﬂow transitions at
compile time. Note that direct writes/reads to local or global
variables access memory at ﬁxed offsets in the stack-frame
or from the enclave base address are guaranteed to neither
corrupt memory, nor access memory outside the enclave (we
reserve space for global variables when creating the enclave;
and we stop the program if we exhaust stack space). Hence,
we only need to check memory accesses through pointers.
Checking memory reads adds runtime overhead. We therefore
let users choose between no integrity, region-write-integrity,
and full region-read-write-integrity, depending on the runtime
cost they are willing to pay.

The checks on indirect calls together with the integrity
of return addresses enforce a form of control-ﬂow integrity
(CFI) [1], but our invariants are stronger than CFI. Attacks on
CFI [24] typically require an initial step to corrupt memory
(e. g., through a buffer overﬂow) and/or leak information. CFI
solutions do not try to prevent memory corruption; they aim
only to mitigate the malicious effects of such corruption by
restricting the sets of possible targets for indirect control-ﬂow
transitions. On the other hand, our read and write checks are
mainly designed to prevent memory corruptions and informa-
tion leaks; the main purpose of our control-ﬂow checks is
to guarantee that the checks on writes and reads cannot be
bypassed: control never ﬂows to unaligned code potentially
containing unexpected and unchecked memory reads or writes.
Our invariants share some properties with recent proposals
for efﬁcient execution integrity, such as CPI [34] and WIT [2],
but our invariants and enforcement mechanisms are adapted to
the enclave environment. For example, on x64 (VC3’s target
environment), CPI relies on hiding enforcement information
at a random address (with leak-proof information hiding);
while that is effective in large address-spaces, it would be
less effective inside VC3’s small (512MB) memory regions.

Our enforcement data structures are also a factor of 8 smaller
than WIT’s, and unlike CPI and WIT we do not require
sophisticated compiler analysis (e. g., points-to analysis).

The instrumentation for memory accesses is applied for all
enclave code except for the functions that implement commu-
nication with the outside world through the shared memory
area, but these functions encrypt/decrypt and authenticate the
data being written/read. Next, we describe how we enforce the
integrity invariants.

A. Enforcing region-write-integrity

To enforce that writes through pointers go to address-taken
variables in the enclave or memory allocated from the enclave
heap, we maintain a bitmap to record which memory areas
inside the enclave are writable. The bitmap maps every 8-
byte slot of enclave memory to one bit. When the bit is set,
the memory is writable. The bitmap is updated at runtime,
when stack frames with address-taken variables are created and
destroyed and when heap memory is allocated and freed. When
the compiler determines that a stack frame contains address-
taken variables, it generates code to set the corresponding
bits on the bitmap on function entry, and to reset them on
function exit. The compiler also ensures that address-taken
variables have free 8-byte slots around them (and similarly
for heap allocations),
to detect sequential overﬂows. The
compiler also records the addresses and sizes of address-taken
global variables in a data structure that our runtime uses to
set the corresponding bits in the bitmap at enclave startup.
Our heap implementation sets/resets the bits in the bitmap
on heap allocations/deallocations. When the compiler cannot
prove statically that a write conforms to region-write-integrity,
it inserts a check of the form (VC3 works on x64 processors):

mov
and
xor
je
int
$L1:mov
mov
shr
mov
shr
mov
bt
jb
int
$L2:mov

rax,r8
rax,0xFFFFFFFFE0000000
rax,0x20000000
$L1
3
rdx,_writeBitmap
rcx,r8
rcx,9
rax,r8
rax,3
rcx,[rdx+rcx*8]
rcx,rax
$L2
3
[r8],4 #unsafe write

The ﬁrst part of the check, up to the L1 label, checks that the
address being written to is within the enclave address range. If
the check fails, the program stops with an exception; we chose
this exception because it uses an efﬁcient encoding: a single
byte. If the check succeeds, we then check that the address is
marked as writable in the bitmap. The initial range check on
the address allows us to allocate the bitmap to cover only a
small portion of the address space. If the bitmap check also
succeeds, the write is allowed to proceed (label L2).

This design is efﬁcient: the bitmap is a compact repre-
sentation of which addresses are writable: one bit per 8

bytes of enclave address space and, as shown above, we can
access it with fast code sequences. The compiler also includes
optimizations to make write checks more efﬁcient (§IX).

To implement the checks on indirect control-ﬂow transi-
tions, we maintain a separate bitmap that records where the
entry points of address-taken functions are. This bitmap maps
each 16-byte slot of enclave memory to a bit. The bit is set
if an address-taken function starts at the beginning of the
slot. The compiler aligns address-taken functions on 16-byte
boundaries, and records the addresses of these function in a
data structure that our runtime uses to set the corresponding
bits in the bitmap at enclave startup. Using a 16-byte slot keeps
the bitmap small and wastes little space due to alignment; we
use smaller slots for the write bitmap to reduce the amount of
free space around address-taken variables and heap allocations.
When generating code for an indirect control-ﬂow transfer, the
compiler emits code to check that the target is 16-byte aligned
and that the corresponding bit is set in the bitmap (the code
sequence is similar to the write checks).

Note that code outside the enclave cannot corrupt

the
bitmaps used for the integrity checks, since the bitmaps are
allocated inside the enclave. Even writes inside the enclave
cannot corrupt the bitmaps, because they are always instru-
mented and the write bitmap disallows writes to the bitmaps.

B. Enforcing region-read-write-integrity

To enforce region-read-write-integrity,
emits checks of the form:

the compiler further

mov
and
xor
je
int
$L1:mov

rax,r8
rax,0xFFFFFFFFE0000000
rax,0x20000000
$L1
3
rdx,[r8] #unsafe read

These checks guarantee that

the memory being read is
within the enclave region. If it is not, the program stops.
An alternative design would be to simply mask the bits
in the address to make sure they are within the enclave,
without stopping if they are not [66]. While that is more
efﬁcient, it is safer to stop the program when the error is
detected. Again, when memory accesses are guaranteed to not
violate region-read-write-integrity, for example direct accesses
to scalar variables on the enclave stack, the compiler elides the
read checks at compile time.

VIII. DISCUSSION

We now discuss several attack scenarios on VC3 which are
partly outside the adversary model from §III.
A. Information Leakage

One basic principle of MapReduce is that all key-value pairs
with the same key be processed by the same reducer. Thus,
inasmuch as a network attacker can count the number of
pairs delivered to each reducer, we should not expect semantic
security for the intermediate keys (as in “key-value pair”) as
soon as there is more than one reducer. Next, we discuss this

4747

information leakage in more detail: For the whole job, each
key Kinter is mapped to a ﬁxed, uniformly-sampled value
inter ∈ 0..R − 1. where R is the number of reducers for
K(cid:2)
the job chosen by the user (§VI). For each intermediate key-
value pair, the adversary may observe the mapper, the reducer,
and K(cid:2)
inter. Intuitively, the smaller the overall number of
unique intermediate keys Kinter in relation to R, the more
the adversary may learn on the actual distribution of keys.
For example, in the case of a presidential election vote count,
there are only two possible intermediate keys (the names of
both candidates). If R > 1, then the adversary easily learns
the distribution of the votes but not necessarily the name of
the successful candidate. Conversely, if there are many keys
(each with a small number of key-value pairs) relative to R,
then leaking the total number of pairs dispatched to each
reducer leaks relatively little information. In particular, when
all intermediate keys are unique, no information is leaked.
Attackers may also use more advanced trafﬁc analyses against
VC3 [16], [56], [68]. For example, by observing trafﬁc, an
attacker may correlate intermediate key-value pairs and output
key-value pairs to input splits; over many runs of different jobs
this may reveal substantial information about the input splits.
We plan to address these attacks with padding, clustering, and
distributed shufﬂe techniques [45].

B. Replay Attacks

The adversary could try to proﬁt in various ways from fully or
partially replaying a past MapReduce job. Such replay attacks
are generally prevented in case the online key exchange (§V-B)
is employed, as the user can simply refuse to give JCw a
second time to any enclave. This is different for the in-band
version of our approach (§V-C): an enclave is not able to tell
if it ran on a set of input data before as it cannot securely
keep state between two invocations. (The adversary can always
revert a sealed ﬁle and reset the system clock.) Given Cj,u and
JCw corresponding to a certain processor under their control,
the adversary is in the position to arbitrarily replay parts of
a job that the processor participated in before or even invoke
a new job on any input splits encrypted under kin contained
in JCw. This allows the adversary to repeatedly examine the
runtime behavior of E− from outside the enclave and thus
to amplify other side-channel attacks against conﬁdentiality.
The resilience of VC3 against such attacks can be enhanced
by hardcoding a job’s speciﬁcation into mappers to restrict the
input splits they should accept to process. Finally, Strackx et
al. recently proposed an extension to SGX that provides state
continuity for enclaves [57] and, if adopted, could be used in
VC3 to largely prevent replay attacks.

IX. IMPLEMENTATION

We implemented VC3 in C++ for Windows 64-bit and the
HDInsight distribution of Hadoop. Jobs are deployed as 64-
bit native code in the form of an executable (fw.exe) which
contains the framework code F , and a dynamic link library
(mapred.dll) that contains the enclave code E+ and E−.

A. SGX Emulation

We successfully tested our implementation in an SGX em-
ulator provided by Intel. However since that emulator is not
performance accurate, we have implemented our own software
emulator for SGX. Our goal was to use SGX as speciﬁed
in [32] as a concrete basis for our VC3 implementation and
to obtain realistic estimates for how SGX would impact the
performance of VC3. Our software emulator does not attempt
to provide security guarantees.

invoke our emulator via a call

The emulator is implemented as a Windows driver. It hooks
the KiDebugRoutine function pointer in the Windows
kernel that is invoked on every exception received by the
kernel. Execution of an SGX opcode from [32] will generate
an illegal instruction exception on existing processors, upon
which the kernel will
to
KiDebugRoutine. The emulator contains handler functions
for all SGX instructions used by VC3, including EENTER,
EEXIT, EGETKEY, EREPORT, ECREATE, EADD, EEX-
TEND, and EINIT. We use the same mechanism to handle
accesses to model speciﬁc registers (MSR) and control regis-
ters as speciﬁed in [32]. We also modiﬁed the SwapContext
function in the Windows kernel to ensure that the full register
context is loaded correctly during enclave execution.

The code in each handler function is modeled after the
corresponding pseudo code in [32]. We emulate the en-
clave page cache (EPC) by allocating a contiguous range
of physical memory (using the memory manager function
MmAllocateContiguousMemorySpecifyCache) and
using a data structure along the lines of the Enclave Page
Cache Map of [32] to keep track of it.

B. Performance Model

We are interested in estimating the performance of VC3
on a hypothetical SGX-enabled processor. We assume that
the performance of the existing processor instructions and
mechanisms would be unaffected by the extensions of [32].
Furthermore, the execution of most SGX instructions does
not appear to be relevant to VC3 performance. As the enclave
setup instructions ECREATE, EADD, EEXTEND and EINIT
constitute only a one-time cost at initialization of VC3, we
exclude them from the performance model. Other instruc-
tions (EGETKEY, EREPORT) are called only once during a
VC3 run and seem unlikely to have a noticeable impact on
performance. In all cases, we believe that the cost on our
emulator overestimates the cost on a hypothetical hardware
implementation.

These simpliﬁcations allow us to focus our performance
model on the cost of entering and exiting enclaves, which
we conservatively model as roughly the cost of an address
space switch. In particular, upon each transition, we perform
a kernel transition, do a TLB ﬂush, and execute a number
of delay cycles. We perform these actions in the handlers
for EENTER (enter enclave), ERESUME (enter enclave) and
EEXIT (exit enclave). As interrupts during enclave execution
also cause transitions, we also add the performance penalty

4848

at the beginning and end of each interrupt that occurs during
enclave execution. In particular, we patch the low-level in-
terrupt handling code in the Windows kernel to add the TLB
ﬂush and the delay cycles. We performed a sensitivity analysis
by running sample applications repeatedly while varying the
number of delay cycles, but we found that our optimizations to
control enclave transitions (batching of key-value pairs) allow
us to reduce the performance impact of transitions to negligible
levels even for large numbers of delay cycles. Therefore, for
the experiments described in the evaluation, we used 1,000
delay cycles, which is similar to the cost of crossing other
security boundaries such as performing system calls.

The SGX facility for encrypting and integrity protecting
data before they are written from CPU caches to platform
memory [41] could also affect performance. It is impossible
for us to model this effect accurately since the additional cost
of cache misses depends strongly on how the crypto pro-
tections for memory are implemented in hardware. However,
we can estimate the cache miss rate of typical VC3 appli-
cations. We have used the processor’s performance counter
for Last Level Cache Misses (LLC Misses) to measure the
memory bandwidth required by the enclave code of each
of the applications described in §X. In particular, we bound
the execution to one core and started that core’s counter
upon enclave entry and stopped it upon enclave exit. We
ran one application at a time. Several of the applications,
in particular the reducers, used hundreds of MB of memory,
which is signiﬁcantly larger than the processor’s L3 cache
size (6 MB). The measured memory bandwidths were well
below the bandwidths of modern memory encryption engines,
which indicates that SGX memory encryption should not have
a noticeable performance impact on VC3.

C. Enclave Creation

We implemented a driver (fw.sys) to provide functionality for
enclave creation. The driver obtains the physical addresses
of EPC memory from the emulator, maps pages into user
mode and calls SGX instructions involved in enclave creation.
Fw.sys is expected to be installed on all nodes; it would
typically be distributed with the operating system.

D. Enclave and Protocols

Fw.exe acts as the host process of the enclave. It performs un-
trusted I/O interaction with Hadoop via the streaming protocol
[5] over stdin/stdout. E+ implements the in-band variants of
both the key exchange and the job execution protocols, which
work on top of the Hadoop protocol. Our implementation uses
two optimizations: (i) We batch read/writes of key-value pairs
from within the enclave. This is important because transitions
in and out of the enclave come at a cost; we want to avoid
them when possible. Our implementation processes key-value
pairs in batches of 1000. (ii) We use the AES-NI instructions
[30] to accelerate our implementation of AES-GCM, including
the PCLMULQDQ instruction [25]. Our implementation of
E+ consists of roughly 5500 logical lines of code (LLOC)

of C, C++ and Assembly. About 2500 LLOC of these imple-
ment standard cryptographic algorithms. The user can inspect,
change and recompile the code of E+, or even use our protocol
speciﬁcation to completely re-implement it.

E. In-enclave Library

As a convenience for application development, we have cre-
ated an enclave-compatible C++ runtime library. Existing
C/C++ libraries which have operating system dependencies
cannot be used in an enclave environment because system
calls are conceptually not available [32]. Accordingly, we
could neither use common implementations of the Standard
C Library nor of the C++ Standard Template Library. Our
library contains functions which we found useful when writing
our sample applications: a set of mathematical functions, string
classes, containers, and a heap allocator which manages an in-
enclave heap and is the default backend for new. This library
is relatively small (3702 LLOC) and we stress that users may
choose to change it, use other libraries instead, or write their
own libraries.

F. Compiler

We implemented the compiler that supports our enclave self-
integrity invariants as a modiﬁcation to the Microsoft C++
compiler version 18.00.30501. The implementation consists
of two main parts: changes to code generation to emit our
runtime checks when needed, and changes to generate data
that our runtime library needs to initialize our enforcement
bitmaps in the enclave. We now describe each of the parts.

We inserted our new code generation module immediately
before the compiler phase that generates machine dependent
code. Although our implementation of VC3 is only for Intel
x64 processors at the moment, this will allow us to target
other architectures in the future. Our code generation module
is intra-function only, i. e., it does not perform global static
analysis. We do a pass over the instructions in a function to
ﬁnd any address-taken local variables; if we ﬁnd any such
variables, we emit code in the function’s prolog and epilog
to update the corresponding bits in our write bitmap. In the
prolog we set the bits in the bitmap, in the epilog we clear
them. Our implementation does this efﬁciently by generating
the appropriate bit masks and setting/resetting up to 64 bits
at a time. We also change the locations of these variables in
the function’s stack frame to make sure they do not share 8-
byte memory slots with other variables (recall that we keep
our bitmap information as 1 bit per every 8-bytes of enclave
memory). When iterating over the instructions in a function,
we insert a write check if we ﬁnd a store instruction that is not
a direct write to a local or a global variable. Direct writes to
local or globals are stores to ﬁxed offsets in the stack-frame or
the enclave base address and are guaranteed to be inside the
enclave. We also insert indirect call checks for every indirect
call instructions that we ﬁnd in the function. Note that we do
not insert checks on function returns, because the integrity of
the return addresses in the enclave stack is guaranteed by our

4949

write checks. We also perform a simple intra-function analysis
to simplify write checks when possible: when the write’s target
is a local or global variable, but the write is to a computed
offset in the variable, for example an array access, we replace
the full write check with a check of the form offset <
size. Finally, when generating code to enforce region-read-
write-integrity we also generate our read checks when we ﬁnd
load instructions whose target is not a local or global variable.
Our compiler also needs to generate data that our runtime
library uses to initialize our enforcement bitmaps when starting
the enclave. We generate two kinds of data: a list of addresses
of address-taken functions, and a list of the addresses and
sizes of address-taken global variables. These lists are simply
generated by emitting the addresses in special sections of the
object ﬁles whenever the compiler ﬁnds an instruction that
takes the address of a function or a global variable. We perform
this operation while iterating over all the code to generate the
runtime checks, i. e., we do not require an extra pass over
the code. We also iterate over all the initializers in global
data, to ﬁnd address-taken functions or address-taken global
variables there. The linker merges and removes duplicates
from this information when generating the binary to load into
the enclave. When we create the enclave, our runtime library
iterates over the addresses in these lists and sets the appropriate
bits in our enforcement bitmaps.

G. Other tools

We also created several other tools to support VC3, including
tools to generate symmetric and asymmetric keys, and tools to
encrypt and decrypt data. We created a tool called packer.exe
that encrypts E− and merges it with E+ to create the
self-contained and signed mapred.dll. E− and E+ are ﬁrst
compiled into distinct DLLs. The packer statically resolves
dependencies between the two DLLs and relocates both to a
ﬁxed virtual base address. It also makes sure that the DLLs’
sections (e. g., .text and .data) are page-aligned, as they
would be when loaded into a user mode process by the stan-
dard Windows image loader [53]. This is necessary to make
sure that the enclave code can be loaded into memory and
run unaltered without the help of the standard image loader.
Users need to be able to reliably compute the enclave digest in
advance. Otherwise, they could not verify statements by QEs.
Our tools are incorporated into the Microsoft Visual Studio
environment. They automatically create mapred.dll from a
user’s C++ MapReduce code.

X. EVALUATION

We used the applications listed in Table I to evaluate VC3.
We chose a mix of real-world applications and well-known
benchmarks, including IO-intensive and CPU-intensive appli-
cations. We measured the performance of the applications on
Hadoop, and also in isolation to remove the overhead-masking
effects of disk I/O, network transfers, and spawning of Hadoop
tasks. Before discussing our results, we brieﬂy describe each
application.

Application

LLOC

Size input

UserUsage
IoVolumes
Options
WordCount
Pi
Revenue
KeySearch

224
241
6098
103
88
96
125

41 GB
94 GB
1.4 MB
10 GB
8.8 MB
70 GB
1.4 MB

TABLE I: Applications used to evaluate VC3.

Size E−
(vc3)
18 KB
16 KB
42 KB
18 KB
15 KB
16 KB
12 KB

map tasks

665
1530
96
162
16
256
96

UserUsage and IoVolumes: Real applications that process
resource usage information from a large compute/storage
platform consisting of tens of thousands of servers. UserUsage
counts the total process execution time per user. IoVolumes
is a join. It ﬁlters out failed tasks and computes storage I/O
statistics for the successful tasks.
Options: Simulates the price of European call options using
Monte Carlo methods [42]. The large size of the application
in terms of LLOC (see Table I) stems from the inclusion of a
set of optimized mathematical functions.
WordCount: Counts the occurrences of words in the input.2
Pi: Benchmark that statistically estimates the value of Pi.3
Revenue: Reads a synthetic log ﬁle of users visiting websites
and accumulates the total ad revenue per IP (from [49]).
KeySearch: Conducts a known plaintext attack on a 16-byte
message encrypted with RC4 [63].

All experiments ran under Microsoft Windows Server 2012
R2 64-Bit on workstations with a 2.9 GHz Intel Core i5-4570
(Haswell) processor, 8 GB of RAM, and a 250 GB Samsung
840 Evo SSD. We used a cluster of 8 workstations connected
with a Netgear GS108 1Gbps switch. All code was compiled
with the Microsoft C++ compiler version 18.00.30501 for x64,
optimizing for speed. We compiled our 7 applications in four
conﬁgurations:

baseline runs the applications on plaintext data and with-
out following the job execution protocol. Also, no performance
penalty for enclave transitions (TLB ﬂush, delay cycles, and
swapping of the stack) is applied and unnecessary copying of
data across (non-existent) enclave boundaries is avoided.
vc3 runs the same application on VC3 with encrypted
mapper and reducer inputs and outputs. Sizes of the E− DLL
range from 12 KB for KeySearch to 42 KB for Options (see
Table I); the generic E+ DLL has a size of 210 KB. The
enclave memory size was set to be 512 MB and the cost of
an enclave transition (including interrupts) to one TLB ﬂush
and 1,000 delay cycles. This version provides the base security
guarantees of VC3.

vc3-w uses the same conﬁguration as vc3, but applications

were compiled to further guarantee region-write-integrity.

2http://wiki.apache.org/hadoop/WordCount
3http://hadoop.sourcearchive.com/documentation/0.20.2plus-pdfsg1-1/

PiEstimator 8java-source.html

5050

Fig. 5: Execution time of running MapReduce jobs in a Hadoop cluster
over typical input data-sets. Running times are normalized to the perfor-
mance of running the same job in normal mode and with unencrypted data
(baseline). Note: vc3-w and vc3-wr correspond to vc3 with extra
region-write-integrity checks and region-read-write-integrity checks respec-
tively.

Fig. 6: Execution time of running the map phase of MapReduce jobs in
isolation over typical input data-sets. Running times are normalized to the
performance of running the same computation in the baseline conﬁgura-
tion.

vc3-wr uses the same conﬁguration as vc3, but applica-
tions were compiled to further guarantee region-read-write-
integrity.

A. Performance on Hadoop

We measured the execution times of baseline and vc3 in
an unmodiﬁed Hadoop environment. We used the Hortonworks
distribution of Hadoop 2 (HDP 2.1) for Windows with 8
worker nodes (one per workstation). We used the default con-
ﬁguration options for resource management, and conﬁgured
our jobs to use 8 reduce tasks; except for Pi, Options, and
KeySearch that conceptually use 1. We ran each job and each
conﬁguration at least 10 times and measured the execution
time. To facilitate comparisons, we normalized the running
times with the average running time for each job using the
baseline conﬁguration. Figure 5 plots the average ratios
for each job and conﬁguration, and the values of two standard
deviations below and above each average.

Figure 5 shows that vc3’s performance is similar

to
baseline; the differences in performance are well below
the experimental variability for all jobs. vc3’s overhead is
negligible with its base security guarantees. When introducing
the write and read-write integrity checks, the performance
overhead increases on average by 4.5% and 8% respectively.
The increased overhead is a small price for the extra security
guarantees. We believe these results show that VC3 can be
used in practice to provide general-purpose secure cloud
computation with good performance.

B. Performance in Isolation

When running applications, Hadoop performs many activities,
such as spawning mappers and reducers, waiting for disk I/O,
network transfers, and others, that may mask the overheads of
VC3. To better understand the performance impact of VC3 on
the execution times of individual map and reduce tasks, we ran

5151

the mappers and reducers in isolation, i.e., on a single machine
without Hadoop. We repeated each experiment 10 times, and,
as in Section X-A, we normalize using the average of the
baseline run. Figure 6 plots the average ratios for the map
tasks, as well as the values of two standard deviations below
and above the average. (The results for reduce tasks are similar
— we omit them for brevity.)

On average, vc3’s overhead was 4.3% compared to
baseline, vc3-w’s was 15.3%, and vc3-wr’s was 24.5%.
The overheads were negligible for the three compute intensive
jobs (Key Search, Options, and Pi); these jobs spend little
time in copying and encryption/decryption operations, and
most of the time they compute using plain-text data off of the
processor’s caches; in addition, for these jobs the compiler was
effective at eliding checks on safe memory accesses, and hence
the overheads of vc3-w and vc3-wr are also negligible.

The IoVolumes and UserUsage jobs were slower than
baseline in all conﬁgurations. The IoVolumes(UserUsage)
job was 23.1%(6.1%), 41.4%(23.6%) and 63.4%(55.3%)
slower in the vc3, vc3-w, and vc3-wr conﬁgurations
respectively. The overheads are higher in these cases, because
these applications are IO-intensive. Since they perform little
computation, the relative cost of encryption is higher. Revenue
and WordCount are also IO-intensive, but these applications
implement a combine operation which increases the compu-
tation performed at the mapper, hence reducing the relative
cost of encryption. The combine operation performs a group-
by of the key-value pairs generated by the map function, and
calls a combine function that performs a partial reduction
at
the mapper. This is a common optimization to reduce
network trafﬁc (IoVolumes does not implement combining,
which contributes to its larger overhead). We thus observe little
performance difference between baseline and vc3 for Rev-
enue and WordCount. The write(read-write) integrity checks
increased their running times by 18%(26%) and 22%(27%)
respectively. The performance differences between vc3 and
vc3-w/vc3-wr are due to the region self-integrity checks

and they vary according to the ability of the compiler to check
if memory accesses are safe at compile-time.

We now turn our attention to the performance difference
between baseline and vc3. This difference is due to:
(i) copying data to and from the enclave, (ii) encryption
and decryption operations, and (iii) enclave transitions (either
due to normal operations or due to system interrupts). We
measure the copy operations and the total encryption and
decryption times and use that to explain the difference in the
execution times of vc3 versus baseline. We ﬁnd that the
crypto(copying) operations contributed 13.3(4.8) percentage
points for IoVolumes; the crypto operations dominated the
overhead for UserUsage. Despite the use of hardware accelera-
tion to speed up encryption and decryption (with the AES-NI
instructions, see section IX), there is a performance penalty
for using encrypted data; this is unavoidable in our setting.

We believe that in all cases the overheads are reasonable for
the provided security guarantees. Moreover, when run as part
of Hadoop jobs, these overheads have small (if any) impact
on the total run time (Figure 5).

C. Effectiveness of region self-integrity

We also conducted fault-injection experiments to verify the
effectiveness of the region self-integrity invariants. We wrote
a tool that injects three types of faults in the source code
of applications: writes to a random address outside of the
enclave, reads from a random address outside the enclave, and
pointer dereferences that corrupt a return address inside the
enclave. For each type of fault, we conducted 10 experiments
per application. In all cases the region self-integrity checks
caught the invalid access and stopped the application.

XI. RELATED WORK

Applications of SGX were ﬁrst discussed in [27]. Haven [9] is
a recently proposed SGX-based system for executing Windows
applications in the cloud. Haven loads a given application
together with a library OS variant of Windows 8 into an
enclave. Haven makes a different trade-off between security
and compatibility: it can run unmodiﬁed Windows binaries, but
its TCB is larger than VC3’s by several orders of magnitude.
Unlike VC3, Haven neither guarantees integrity for distributed
computations, nor does it provide our region self-integrity
properties. Brenner et al. presented an approach to run Apache
ZooKeeper in enclaves [14].

Several systems protect conﬁdentiality of data in the cloud.
Fully homomorphic encryption and multiparty computation
[21], [22] can achieve data conﬁdentiality, but they are not ef-
ﬁcient enough for general-purpose computation. CryptDB [50]
and MrCrypt [61] use partial homomorphic encryption to
run some computations on encrypted data; they neither pro-
tect conﬁdentiality of code, nor guarantee data integrity or
completeness of results. On the other hand,
they do not
require trusted hardware. TrustedDB [7], Cipherbase [6], and
Monomi [64] use different forms of trusted hardware to
process database queries over encrypted data, but they do not
protect the conﬁdentiality and integrity of all code and data.

5252

Monomi splits the computation between a trusted client and an
untrusted server, and it uses partial homomorphic encryption
at
the server. Mylar [51] is a platform for building Web
applications that supports searches over encrypted data.

Several systems combine hardware-based isolation [37],
[46], [59] with trusted system software [17], [28], [36], [38],
[54], [58], [69], which is typically a trusted hypervisor. The
Flicker [39] approach uses TXT [31] and avoids using a trusted
hypervisor by time-partitioning the host machine between
trusted and untrusted operation. Virtual Ghost [18] avoids
using a trusted hypervisor and specialized hardware-based
isolation mechanisms by instrumenting the kernel.

Some systems allow the user to verify the result of a
computation without protecting the conﬁdentiality of the data
or the code [48]. Pantry [13] can be used to verify the integrity
of MapReduce jobs which are implemented in a subset of C.
Pantry incurs a high overhead. Hawblitzel et al. presented the
concept of formally veriﬁed Ironclad Apps [26] running on
partially trusted hardware. They report runtime overheads of
up to two orders of magnitude.

Several security-enhanced MapReduce systems have been
proposed. Airavat [52] defends against possibly malicious
map function implementations using differential privacy. Se-
cureMR [67] is an integrity enhancement for MapReduce that
relies on redundant computations. Ko et al. published a hybrid
security model for MapReduce where sensitive data is handled
in a private cloud while non-sensitive processing is outsourced
to a public cloud provider [33]. PRISM [12] is a privacy-
preserving word search scheme for MapReduce that utilizes
private information retrieval methods.

XII. CONCLUSIONS

We presented VC3, a novel approach for the veriﬁable and con-
ﬁdential execution of MapReduce jobs in untrusted cloud en-
vironments. Our approach provides strong security guarantees,
while relying on a small TCB rooted in hardware. We show
that our approach is practical with an implementation that
works transparently with Hadoop on Windows, and achieves
good performance. We believe that VC3 shows that we can
achieve practical general-purpose secure cloud computation.

REFERENCES

[1] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti. Control-Flow
In ACM

Integrity: Principles, Implementations, and Applications.
Conference on Computer and Communications Security (CCS), 2005.

[2] P. Akritidis, C. Cadar, C. Raiciu, M. Costa, and M. Castro. Preventing
memory error exploits with WIT. In IEEE Symposium on Security and
Privacy, 2008.

[3] I. Anati, S. Gueron, S. Johnson, and V. Scarlata. Innovative technology
for CPU based attestation and sealing. In Workshop on Hardware and
Architectural Support for Security and Privacy (HASP), 2013.

[4] Apache Software Foundation. Hadoop. http://wiki.apache.org/hadoop/,

Accessed: 11/05/2014.

[5] Apache Software Foundation. HadoopStreaming. http://hadoop.apache.

org/docs/r1.2.1/streaming.html, Accessed: 11/05/2014.

[6] A. Arasu, S. Blanas, K. Eguro, R. Kaushik, D. Kossmann, R. Rama-
In

murthy, and R. Venkatesan. Orthogonal security with Cipherbase.
Conference on Innovative Data Systems Research (CIDR), 2013.

[7] S. Bajaj and R. Sion. TrustedDB: A trusted hardware-based database

with privacy and data conﬁdentiality. In IEEE Transactions on Knowl-
edge and Data Engineering, volume 26, 2014.

[8] P. Barham, B. Dragovic, K. Fraser, S. Hand, T. Harris, A. Ho, R. Neuge-
bauer, I. Pratt, and A. Warﬁeld. Xen and the art of virtualization. In
ACM Symposium on Operating Systems Principles (SOSP), 2003.

[9] A. Baumann, M. Peinado, and G. Hunt. Shielding applications from
In USENIX Symposium on Operating

an untrusted cloud with haven.
Systems Design and Implementation (OSDI), 2014.

[10] M. Bellare, A. Desai, D. Pointcheval, and P. Rogaway. Relations among
notions of security for public-key encryption schemes. In Advances in
Cryptology—CRYPTO, 1998.

[11] M. Bellare and C. Namprempre. Authenticated encryption: Relations
In

among notions and analysis of the generic composition paradigm.
Advances in Cryptology—ASIACRYPT, 2000.

[12] E.-O. Blass, R. Di Pietro, R. Molva, and M. ¨Onen. Prism—privacy-
preserving search in MapReduce. In S. Fischer-H¨ubner and M. Wright,
editors, Privacy Enhancing Technologies, volume 7384 of Lecture Notes
in Computer Science. Springer Berlin Heidelberg, 2012.

[13] B. Braun, A. J. Feldman, Z. Ren, S. Setty, A. J. Blumberg, and
In ACM Symposium

M. Walﬁsh. Verifying computations with state.
on Operating Systems Principles (SOSP), 2013.

[14] S. Brenner, C. Wulf, and R. Kapitza. Running ZooKeeper coordination
In USENIX Workshop on Hot Topics in

services in untrusted clouds.
Systems Dependability (HotDep), 2014.

[15] E. Brickell and J. Li. Enhanced privacy ID from bilinear pairing
In IEEE International

for hardware authentication and attestation.
Conference on Social Computing (SocialCom), 2010.

[16] S. Chen, R. Wang, X. Wang, and K. Zhang. Side-channel leaks in web
applications: A reality today, a challenge tomorrow. In IEEE Symposium
on Security and Privacy, 2010.

[17] X. Chen, T. Garﬁnkel, E. C. Lewis, P. Subrahmanyam, C. A. Wald-
spurger, D. Boneh, J. Dwoskin, and D. R. Ports. Overshadow: A
virtualization-based approach to retroﬁtting protection in commodity
operating systems. In International Conference on Architectural Support
for Programming Languages and Operating Systems (ASPLOS), 2008.
[18] J. Criswell, N. Dautenhahn, and V. Adve. Virtual Ghost: Protecting
applications from hostile operating systems. In International Conference
on Architectural Support for Programming Languages and Operating
Systems (ASPLOS), 2014.

[19] I. Damg˚ard, V. Pastro, N. Smart, and S. Zakarias. Multiparty com-
In Advances in

putation from somewhat homomorphic encryption.
Cryptology—CRYPTO, 2012.

[20] J. Dean and S. Ghemawat. MapReduce: simpliﬁed data processing on

large clusters. Commun. ACM, 51(1), 2008.

[21] C. Fournet, M. Kohlweiss, G. Danezis, and Z. Luo. ZQL: A compiler
for privacy-preserving data processing. In USENIX Security Symposium,
2013.

[22] C. Gentry. Fully homomorphic encryption using ideal lattices. In ACM

Symposium on Theory of Computing (STOC), 2009.

[23] C. Gentry and S. Halevi.

Implementing Gentry’s fully-homomorphic
encryption scheme. In Advances in Cryptology—EUROCRYPT, 2011.
[24] E. G¨oktas¸, E. Athanasopoulos, H. Bos, and G. Portokalidis. Out of
In IEEE Symposium on

control: Overcoming control-ﬂow integrity.
Security and Privacy, 2014.

[25] S. Gueron and M. E. Kounavis. Intel carry-less multiplication instruction

and its usage for computing the GCM mode, 2010. No. 323640-001.

[26] C. Hawblitzel, J. Howell, J. R. Lorch, A. Narayan, B. Parno, D. Zhang,
Ironclad Apps: End-to-end security via automated full-
In USENIX Symposium on Operating Systems

and B. Zill.
system veriﬁcation.
Design and Implementation (OSDI), 2014.

[27] M. Hoekstra, R. Lal, P. Pappachan, C. Rozas, V. Phegade, and J. del
Cuvillo. Using innovative instructions to create trustworthy software
solutions.
In Workshop on Hardware and Architectural Support for
Security and Privacy (HASP), 2013.

[28] O. S. Hofmann, S. Kim, A. M. Dunn, M. Z. Lee, and E. Witchel. Inktag:
Secure applications on an untrusted operating system. In International
Conference on Architectural Support for Programming Languages and
Operating Systems (ASPLOS), 2013.

[29] Y. Huang, D. Evans, J. Katz, and L. Malka. Faster secure two-party
In USENIX Security Symposium,

computation using garbled circuits.
2011.

[30] Intel Corp.

Intel 64 and IA-32 architectures software developer’s
manual—combined volumes: 1, 2a, 2b, 2c, 3a, 3b and 3c, 2013. No.
325462-048.

5353

[31] Intel Corp.

Intel trusted execution technology. software development

[32] Intel Corp. Software guard extensions programming reference, 2013.

guide, 2013. No. 315168-009.

No. 329298-001.

[33] S. Y. Ko, K. Jeon, and R. Morales. The Hybrex model for conﬁdentiality
and privacy in cloud computing. In USENIX Workshop on Hot Topics
in Cloud Computing (HotCloud), 2011.

[34] V. Kuznetsov, L. Szekeres, M. Payer, G. Candea, R. Sekar, and D. Song.
In USENIX Symposium on Operating Systems

Code-pointer integrity.
Design and Implementation (OSDI), 2014.

[35] J. Li, M. Krohn, D. Mazieres, and D. Shasha. Secure untrusted data
In USENIX Symposium on Operating Systems

repository (SUNDR).
Design and Implementation (OSDI), 2004.

[36] Y. Li, J. McCune, J. Newsome, A. Perrig, B. Baker, and W. Drewry.
In Usenix ATC,

MiniBox: A two-way sandbox for x86 native code.
2014.

[37] D. Lie, M. Thekkath, M. Mitchell, P. Lincoln, D. Boneh, J. Mitchell,
and M. Horowitz. Architectural support for copy and tamper resistant
software.
In International Conference on Architectural Support for
Programming Languages and Operating Systems (ASPLOS), 2000.

[38] J. M. McCune, Y. Li, N. Qu, Z. Zhou, A. Datta, V. D. Gligor, and
A. Perrig. Trustvisor: Efﬁcient TCB reduction and attestation. In IEEE
Symposium on Security and Privacy, 2010.

[39] J. M. McCune, B. J. Parno, A. Perrig, M. K. Reiter, and H. Isozaki.
Flicker: an execution infrastructure for TCB minimization. In European
Conference on Computer Systems (EuroSys), 2008.

[40] D. McGrew and J. Viega. The Galois/counter mode of operation (GCM).

Submission to NIST Modes of Operation Process, 2004.

[41] F. Mckeen,

I. Alexandrovich, A. Berenzon, C. Rozas, H. Shaﬁ,
V. Shanbhogue, and U. Savagaonkar.
Innovative instructions and
software model for isolated execution. In Workshop on Hardware and
Architectural Support for Security and Privacy (HASP), 2013.

[42] G. Morris and M. Aubury. Design space exploration of the European
option benchmark using hyperstreams. In IEEE Symposium on Field-
Programmable Custom Computing Machines (FCCM), 2007.

[43] S. Nagarakatte, J. Zhao, M. M. Martin, and S. Zdancewic. SoftBound:
Highly compatible and complete spatial memory safety for C.
In
ACM SIGPLAN Conference on Programming Language Design and
Implementation (PLDI), 2009.

[44] S. Nagarakatte, J. Zhao, M. M. Martin, and S. Zdancewic. CETS:
compiler enforced temporal safety for C. In International Symposium
on Memory Management, 2010.

[45] O. Ohrimenko, M. T. Goodrich, R. Tamassia, and E. Upfal. The
Melbourne shufﬂe: Improving oblivious storage in the cloud.
In
International Colloquium on Automata, Languages and Programming
(ICALP), 2014.

[46] E. Owusu, J. Guajardo, J. McCune, J. Newsome, A. Perrig, and
A. Vasudevan. Oasis: On achieving a sanctuary for integrity and
secrecy on untrusted platforms. In ACM Conference on Computer and
Communications Security (CCS), 2013.

[47] B. Parno. Bootsrapping trust in a ”trusted” platform.

In USENIX

Workshop on Hot Topics in Security (HotSec), 2008.

[48] B. Parno, C. Gentry, J. Howell, and M. Raykova. Pinocchio: Nearly
practical veriﬁable computation. In IEEE Symposium on Security and
Privacy, 2013.

[49] A. Pavlo, E. Paulson, A. Rasin, D. J. Abadi, D. J. DeWitt, S. Madden,
and M. Stonebraker. A comparison of approaches to large-scale data
analysis. In ACM SIGMOD International Conference on Management
of Data, 2009.

[50] R. A. Popa, C. M. S. Redﬁeld, N. Zeldovich, and H. Balakrishnan.
CryptDB: Protecting conﬁdentiality with encrypted query processing.
In ACM Symposium on Operating Systems Principles (SOSP), 2011.

[51] R. A. Popa, E. Stark, J. Helfer, S. Valdez, N. Zeldovich, M. F. Kaashoek,
and H. Balakrishnan. Building web applications on top of encrypted data
using Mylar. In USENIX Symposium on Networked Systems Design and
Implementation (NSDI), 2014.

[52] I. Roy, S. T. Setty, A. Kilzer, V. Shmatikov, and E. Witchel. Airavat:
In USENIX Symposium on

Security and privacy for MapReduce.
Networked Systems Design and Implementation (NSDI), 2010.

[53] M. Russinovich and D. Solomon. Windows Internals, Part 1. Microsoft

Press Corp., 6th edition, 2012.

[54] N. Santos, R. Rodrigues, K. P. Gummadi, and S. Saroiu. Policy-sealed
data: A new abstraction for building trusted cloud services. In USENIX
Security Symposium, 2012.

[55] F. Schuster, M. Costa, C. Fournet, C. Gkantsidis, M. Peinado, G. Mainar-
Ruiz, and M. Russinovich. V C3: Trustworthy data analytics in the
cloud. Technical Report MSR-TR-2014-39, Microsoft Research, 2014.
[56] D. Song, D. Wagner, and X. Tian. Timing analysis of keystrokes and

SSH timing attacks. In USENIX Security Symposium, 2001.

[57] R. Strackx, B. Jacobs, and F. Piessens. ICE: A passive, high-speed, state-
continuity scheme. In Anual Computer Security Applications Conference
(ACSAC), 2014.

[58] R. Strackx and F. Piessens.

Fides: Selectively hardening software
application components against kernel-level or process-level malware.
In ACM Conference on Computer and Communications Security (CCS),
2012.

[59] G. Suh, D. Clarke, B. Gassend, M. van Dijk, and S. Devadas. AEGIS:
In

Architecture for tamper-evident and tamper-resistant processing.
International Conference on Supercomputing (ICS), 2003.

[60] L. Szekeres, M. Payer, T. Weiz, and D. Song. Sok: Eternal war in

memory. In IEEE Symposium on Security and Privacy, 2013.

[61] S. D. Tetali, M. Lesani, R. Majumdar, and T. Millstein. MrCrypt:
In Conference on
Static analysis for secure cloud computations.
Object-Oriented Programming, Systems, Languages, and Applications
(OOPSLA), 2013.

[62] Trusted Computing Group. Trusted platform module main speciﬁcation.

version 1.2, revision 103, 2007.

[63] K. H. Tsoi, K.-H. Lee, and P. H. W. Leong. A massively parallel RC4
key search engine. In IEEE Symposium on Field-Programmable Custom
Computing Machines (FCCM), 2002.

[64] S. Tu, M. F. Kaashoek, S. Madden, and N. Zeldovich. Processing

analytical queries over encrypted data. In VLDB, 2013.

[65] M. Van Dijk and A. Juels. On the impossibility of cryptography alone
for privacy-preserving cloud computing. In USENIX Workshop on Hot
Topics in Security (HotSec), 2010.

[66] R. Wahbe, S. Lucco, T. E. Anderson, and S. L. Graham. Efﬁcient
software-based fault isolation. In ACM Symposium on Operating Systems
Principles (SOSP), 1993.

[67] W. Wei, J. Du, T. Yu, and X. Gu. Securemr: A service integrity assurance
In Anual Computer Security Applications

framework for mapreduce.
Conference (ACSAC), 2009.

[68] C. Wright, L. Ballard, S. Coull, F. Monrose, and G. Masson. Spot me if
you can: Uncovering spoken phrases in encrypted VoIP conversations.
In IEEE Symposium on Security and Privacy, 2008.

[69] F. Zhang, J. Chen, H. Chen, and B. Zang. CloudVisor: Retroﬁtting
protection of virtual machines in multi-tenant cloud with nested virtual-
ization. In ACM Symposium on Operating Systems Principles (SOSP),
2011.

APPENDIX

A. Multi-User Key Exchange

We describe a variant of our basic key exchange protocol in
case there are several users u ∈ U, each contributing their
own set of input splits (using separate keys), and all getting
access to the output. For simplicity, it is assumed that online
communication channels between the involved parties exist.
It is though possible to implement the multi-user protocol as
regular MapReduce job without such channels the same way
it is described in §V-C for the single-user protocol.
1) Each user is still identiﬁed by its public encryption key

pku.

2) The users agree on the code to run; they exchange fresh
random shares ju, kcode,u, kjob,u, kout,u and compute
j = ⊕u∈U ju, kcode = ⊕u∈U kcode,u, kjob = ⊕u∈U kjob,u,
kout = ⊕u∈U kout,u. They then prepare the enclave
code Cj,u as above (using the same randomness for the
encryption), except that all their public keys (pku)u∈U
are included in the Cj,u package.

3) Each enclave prepares and sends the message of the base
protocol pw to every user, each encapsulating a distinct,

fresh, symmetric key kw,u. (The collection of messages
may be jointly quoted once by each effective QE.)

4) Each user independently receives, veriﬁes, and decrypts
then sends the encrypted job credentials
its message,
Encki,u []{kcode | kjob | kin,u | kinter ,u | kout | kprf ,u},
where kin,u, kout are the authenticated-encryption keys
for their input and the output ﬁle, and where kinter ,u and
kprf ,u are their fresh shares of the keys for the intermedi-
ate key-value pairs and the pseudo-random function PRF
respectively.

5) Each enclave decrypts all job credentials, checks that they
all provide the same keys kcode, kjob, kout, and computes
kinter = ⊕u∈U kinter ,u and kprf = ⊕u∈U kprf ,u.

At this stage, kcode, kjob, and kout are known to every user
and every enclave in the job; kin,u is known to every enclave
and to user u; kinter and kprf are known to every enclave
in the job, but not to any strict subset of users. VC3 does
currently not implement a multi-user key exchange but we
plan to support it in the future.

B. Lightweight Key Exchange
The in-band key exchange protocol (§V-C) implemented in our
VC3 prototype works well with existing Hadoop installations,
but requires executing a full (though lightweight) MapReduce
job just for exchanging keys.

In case the user is willing to put extended trust into a
special Support Enclave (SE), the necessity for a separate key
exchange job can be avoided while maintaining compatibility
with existing Hadoop installations. We brieﬂy describe a
corresponding protocol in the following.
As described in §V-A, we generally foresee the cloud
provider to deploy a Cloud QE to each of its SGX-enabled
nodes that is functionally equivalent to the standard SGX
QE. Here, a special Support Enclave (SE) with extended
functionality is deployed instead of such a Cloud QE. Instead
of an EPID private key, each SE creates and manages a node-
speciﬁc long-term RSA key pair that is permanently sealed to
local storage. Each SE acquires a quote from the regular local
SGX QE for its RSA public key. The cloud provider makes
the quoted public keys for all SEs available to the user. For
each SE, the user veriﬁes the quotes and sends
[Cj,u]{kcode | k} | PKEncpkSE

{ke}

Encke

where ke is a fresh job-speciﬁc ephemeral symmetric key.
Each SE decrypts ke and then veriﬁes Cj,u and decrypts
kcode | k. Subsequently, on each node, a new enclave con-
taining Cj,u is started. A mutually authenticated secure local
channel between E+ (running in the newly created enclave)
and SE is created using local attestation (see §II-B). The SE
passes kcode | k over this channel to E+. Finally, E+ decrypts
E− and the enclave is able to process job data afterwards.

In this protocol variant, the user needs to trust the SE
deployed by the cloud provider as it handles kcode and k in
the clear. In order to facilitate the establishment of this trust,
the cloud provider should make the source code of the SE
publicly available.

5454

