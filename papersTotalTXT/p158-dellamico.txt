Monte Carlo Strength Evaluation:

Fast and Reliable Password Checking

Matteo Dell’Amico

Symantec Research Labs, France

matteo_dellamico@symantec.com

∗

Maurizio Filippone
University of Glasgow, UK

maurizio.ﬁlippone@eurecom.fr

ABSTRACT
Modern password guessing attacks adopt sophisticated prob-
abilistic techniques that allow for orders of magnitude less
guesses to succeed compared to brute force. Unfortunately,
best practices and password strength evaluators failed to
keep up: they are generally based on heuristic rules designed
to defend against obsolete brute force attacks.

Many passwords can only be guessed with signiﬁcant ef-
fort, and motivated attackers may be willing to invest re-
sources to obtain valuable passwords. However, it is em-
inently impractical for the defender to simulate expensive
attacks against each user to accurately characterize their
password strength. This paper proposes a novel method to
estimate the number of guesses needed to ﬁnd a password
using modern attacks. The proposed method requires little
resources, applies to a wide set of probabilistic models, and
is characterised by highly desirable convergence properties.
The experiments demonstrate the scalability and general-
ity of the proposal. In particular, the experimental analysis
reports evaluations on a wide range of password strengths,
and of state-of-the-art attacks on very large datasets, includ-
ing attacks that would have been prohibitively expensive to
handle with existing simulation-based approaches.

Categories and Subject Descriptors
K.6.5 [Management of Computing and Information
Systems]: Security and Protection—Authentication; G.3
[Mathematics of Computing]: Probability and Statis-
tics—Probabilistic algorithms (including Monte Carlo)

General Terms
Algorithms, Security, Theory

Keywords
Passwords, strength, Monte Carlo

∗M. Filippone is now with EURECOM, France.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
c(cid:13) 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org//10.1145/2810103.2813631 .

1.

INTRODUCTION

After years spent on unsuccessful attempts to overcome
password-based authentication, researchers have come to ac-
cept that, in the foreseeable future, passwords will still be
used in a large class of scenarios [12]. The recent pub-
lic leaks of very large password datasets (the latest one
in February 2015 involved ten million passwords along with
usernames [3]) can only exacerbate the well-known security
problems of password authentication.

Often, attackers can perform guessing attacks, i.e., at-
tempt to guess a password by trying a large number of can-
didates. Examples include cases where an attacker wants
to ﬁnd the password that protects a wireless network or the
master password that unlocks a password manager, or cases
where the attacker has access to a list of hashed passwords
or to a laptop where data is password-encrypted. Advanced
probabilistic guessing schemes [18, 19, 21, 28, 30] use leaked
password lists as training sets, improving their capability to
guess even passwords that have not been leaked.

While passwords remain a key part of security infrastruc-
tures and attacks become more and more eﬃcient, solutions
designed to help users choose better passwords are still un-
satisfactory. “Best practices,” such as mixing uppercase and
lowercase letters with digits, were conceived to defend users
from brute-force attacks that have progressively become ob-
solete. Against current attacks, these practices strike bad
trade-oﬀs between usability and security [10, 11, 29].

A promising direction that motivates this work is repre-
sented by password meters. Evidence shows that users are
inﬂuenced in their password choice when informed about
their “strength” [9, 27]. Although password meters encour-
age users to choose better passwords, their output is often
questionable as it is not a reliable assessment of the eﬀort
that attackers need to break a password [6].

These considerations suggest what the objective of pass-
word meters should actually be, and yield the following
widely accepted deﬁnition of password strength [1, 7, 15, 18,
19,28,29]: password strength is deﬁned as the number of at-
tempts that an attacker would need in order to guess it. The
deﬁnition underlies a guessing strategy, and indicates that
it is possible to compute password strength by emulating it;
however, such an approach is very expensive and – even after
considerable computational eﬀorts – the strength of a sub-
stantial fraction of unguessed passwords remains unknown.
For this reason, as we discuss in Section 2, existing litera-
ture does not provide a satisfactory solution to the problem
of eﬃciently evaluating password strength.

The best known guessing attacks adopt probabilistic ap-

158proaches [18, 19, 21, 28, 30], which model ways users choose
passwords, resulting in an assignment of a probability to any
password. These probabilities are then used by guessing at-
tacks to determine in what sequence passwords should be
tried. Based on the above deﬁnition of password strength,
this paper proposes a novel way to eﬃciently and accurately
evaluate the strength of any password against a given prob-
abilistic attack. Our method, described in Section 3, esti-
mates password strength by sampling from the model, i.e.,
generating random passwords according to the probabilities
assigned by the model. The appealing properties of our pro-
posal are computational eﬃciency and accuracy. Computa-
tional eﬃciency stems from the fact that the sampling step is
cheap and can be precomputed; once this is done, computing
password strength is as cheap as an array lookup through bi-
nary search. Accuracy can be rigorously characterized using
the theory of Monte Carlo sampling, and a key result of the
√
paper is that our estimate of password strength converges
n), n
to the correct value with a convergence rate of O (1/
being the number of passwords in the sample.

We evaluate our method by considering very large datasets
of leaked passwords, and state-of-the-art attacks such as the
n-grams proposed by Narayanan and Shmatikov [21], the
probabilistic context free grammars by Weir et al. [30], and
the “backoﬀ” model proposed by Ma et al. [19] (for which
we propose an improvement). Details on the evaluation are
available in Section 4.

In Section 5, we use our method in an extensive empirical
evaluation. In its ﬁrst part, we empirically analyze the pre-
cision of our method: we ﬁnd that sample sizes as small as
100-1,000 are suﬃcient to obtain strength estimates in the
right order of magnitude, which is suitable for the imple-
mentation of a strength meter. More accurate results can
simply be obtained by increasing the sample size, yielding a
relative error around 1% when the sample size is 100,000.

In the second part of Section 5, we use our method to
compare the performance of attack models, overcoming the
limitations of existing studies, as discussed in Section 2.2.
We study passwords that are extremely diﬃcult to guess (re-
quiring up to 280 attempts), and we ﬁnd that no approach is
a clear winner. Depending on the number of guesses that an
attacker can aﬀord, diﬀerent approaches become preferable.
In the third part of Section 5, we analyze the importance
of training sets with respect to attack eﬀectiveness; we show
that larger training sets improve attacks against “average”
passwords, whereas not much is gained for passwords that
are either particularly easy or hard to guess.

We conclude Section 5 by assesssing the impact of tra-
ditional restrictions (i.e., limitations on length or classes of
character composing the password) by evaluating the im-
provements in password strength that such restrictions can
obtain:
the results suggest that length requirements are
more advisable than those about character composition.

Contributions. Our main contributions are:

1. A sound method to compute password strength, ac-
cording to the consensus deﬁnition of robustness against
guessing attacks. The method is lightweight and easy
to implement, and we provide theorems to prove its
correctness and approximation level.

2. An empirical evaluation of the accuracy of our method,
including the trade-oﬀ between computation cost and

precision. We show that accurate estimations can be
obtained at a low computational cost.

3. An extensive empirical evaluation comparing state-of-
the-art attack models, impact of training set and of
restrictions in password choice. Our method allows
performing this analysis while overcoming the limita-
tions of previous research discussed in Section 2.2.

2. RELATED WORK

We ﬁrst outline the state of the art in terms of password
guessing in general (Section 2.1); we then focus on studies
that gauge password strength, highlighting the limitations
this work improves on (Section 2.2).
2.1 Password Guessing

The ﬁrst studies on password guessing attacks date back
to 1979, when Morris and Thompson [20] reported that it
was already possible for computers to guess “a substantial
fraction” of the passwords that were used in Unix systems
through brute force and dictionary attacks; similar stud-
ies after more than two decades show that not much has
changed in the meanwhile [16, 26].

Rainbow chains [22] are a technique that allows to eﬃ-
ciently memorize a very large set of pre-computed password
hashes and ﬁnd passwords that appear in them. They are
defeated by the technique of salting, i.e. appending a ran-
dom string of bits to passwords before computing their hash.
More recently, probabilistic attacks have been proposed to
drastically reduce the number of guesses for passwords that
are long and/or do not appear in dictionaries: notable exam-
ples are attacks based on n-gram models [21] and probabilis-
tic context-free grammars (PCFGs) [30]. These approaches
build a model through a training set of passwords in clear-
text; password creation is then seen as a stochastic process
where each password has a given probability of being cho-
sen. To minimize the number of needed guesses, probabilis-
tic attacks enumerate the guesses by descending probability.
Recent improvements to these attacks include the proposal
of a backoﬀ technique to improve n-gram models [19] and
amending PCFGs to include semantic patterns [28] and to
better suit Chinese passwords [18]. In this work, we imple-
mented the n-grams, PCFGs and backoﬀ models; they are
described in detail in Section 4. In Section 5.2, we provide
extensive experimental results to compare them.

A key defense technique against guessing attacks is pass-
word strengthening, or stretching, which amounts to hash-
ing passwords using computationally expensive functions,
resulting in a slowing down of guessing attacks. The de-
sign of strengthening techniques that are resilient to at-
tacks that use parallelization is an active topic of research
[23, 25]. Strengthening is a tool that essentially multiplies
the strength of a password by a constant factor, and this
beneﬁt is counterbalanced by the inconvenience of addi-
tional computation whenever a legitimate user’s password
is checked: better knowledge of password strength allows to
better choose a desirable point in this trade-oﬀ.
2.2 Password Strength Evaluation

The ubiquity of password authentication makes it obvi-
ously important to evaluate password strength,
i.e., how
diﬃcult it is to guess them. Traditionally, simple strate-
gies based on the number of characters and the presence

159of special characters such as uppercase characters, digits
and symbols have been used [4]; however, these approaches
have been found to be inadequate to quantify the resistence
against modern attacks [29]. Indeed, recent studies evalu-
ate password strength as the number of attempts an attack
would need to guess it. With this metric, a password of
strength 2x can be considered as strong as a symmetric en-
cryption key of x bits, since an attacker can guess either
with the same eﬀort.

Dell’Amico et al. [7] adopted an approximation technique
to evaluate the number of attempts needed to guess pass-
words when using n-gram models. Besides being limited to
n-grams, this technique has scalability issues with the large
state space produced by state-of-the art attacks with n ≥ 3
and datasets having millions of passwords. Our proposal re-
quires a fraction of the resources and is applicable in general
to any probabilistic password model.

Bonneau [1] considered the ideal case of probabilistic at-
tacks based on inﬁnitely large training sets, which model
perfectly the probability with which users choose passwords.
An analysis based on 80 million passwords allowed charac-
terizing the strength of passwords appearing multiple times
in the dataset, but the complete probability distribution re-
mains unknown: Kolmogorov-Smirnov tests rejected the in-
terpolation to a power-law distribution with high conﬁdence.
Unfortunately, this implies that the behavior of ideal prob-
abilistic models is still uncertain for the less frequent (and
hence stronger) passwords that most users choose.

Kelley et al. [15] measured the strength of passwords against

Brute Force Markov (BFM) and PCFGs. BFM is a hybrid
between brute force cracking and n-gram models for which
computing exactly the number of guesses needed is easy;
unfortunately, BFM performs deﬁnitely worse than n-gram
models that are actually used by attackers, ﬁnding very few
passwords within the ﬁrst 240 − 245 attempts. For PCFGs,
Kelley et al. employed a 64-node Hadoop cluster for several
days to emulate an attack of around 245 guesses; our ap-
proximated approach, instead, returns an accurate account
of password strength in a fraction of a second even for pass-
words that require around 280 attempts to be found.

Ma et al. [19] studied probabilistic password models such
as n-grams and PCFGs, and proposed a new “backoﬀ” model
that we consider in the evaluation section of this paper.
Rather than attempting to simulate very expensive attacks,
Ma et al. resorted to analyzing the distribution of prob-
abilities that existing models associate to large password
datasets. As the authors themselves acknowledge, this tech-
nique is useful in “type-1” research where passwords in dif-
ferent datasets are compared against the same attack model,
but it can give misleading results in “type-2” research where
diﬀerent attack models are compared against the same pass-
word dataset, because two passwords that are assigned the
same probability by two diﬀerent attack models may be
guessed after a diﬀerent number of attempts in the two at-
tacks: for example, a password with probability 2−15 could
be the very ﬁrst guess in a model and the thousandth one in a
diﬀerent one. Ma et al. still performed “type-2” comparisons,
based on the conjecture of a roughly linear relationship be-
tween probability and password strength. In Section 5.1, we
show that this conjecture does not hold true for a variety of
datasets and attack models; this motivates the importance
of our proposal that aims at computing password strength
in terms of number of guesses rather than probabilities.

Password strength is typically presented to users through
“strength meters”. Studies show that users put in practice
the suggestions given by strength meters in order to generate
stronger passwords [9,27]; unfortunately, strength meters are
generally based on heuristic methods that do not necessarily
reﬂect the resistance of passwords to guessing attacks [6].
Castelluccia et al. [5] show the design of a strength me-
ter that outputs strength as the probability that a Markov
model would assign to a password; as argued above, prob-
ability does not give a clear information about the number
of guesses needed to break a password: our mechanism can
be integrated in this framework to transform the password
checker’s output from a probability to the number of guesses.
Telepathwords [17] is a system that highlights easy-to-
guess patterns as users type their passwords: we think this
approach is ideally complementary to a good password me-
ter, helping users understand the reason why a password is
assigned a given strength.

3. EVALUATING PASSWORD STRENGTH
State-of-the-art password research is based on probabilis-
tic password models. Such models attempt to characterize
the way humans choose their passwords by constructing a
mapping between strings and the frequency with which hu-
mans are assumed to choose them as passwords. Let us
denote the (possibly inﬁnite) set of all allowed passwords as
Γ; a probabilistic password model is a function p such that
α∈Γ p (α) = 1. We call p (α) the probability of α under p.
Attack models enumerate passwords by descending order
of probability: hence, the strength (or rank ) Sp (α) of a pass-
word α under model p is the number of passwords that have
probability higher than α:

(cid:80)

Sp (α) = |{β ∈ Γ : p (β) > p (α)}| .

(1)

We are interested in approximating Sp (α) eﬃciently and
accurately. In addition to being able to compute p (α), our
only requirement is to be able to generate a sample (with re-
placement) of passwords such that, at any draw, the proba-
bility of choosing password α is exactly p (α). Implementing
this is not diﬃcult for any of the models that we consider in
this work (n-grams, PCFGs and backoﬀ).

In order to use p for a guessing attack, the attacker needs
to enumerate passwords by descending probability; doing
this eﬃciently is an open problem [8, 21]. Our method, in-
stead, relies only on sampling and does not require imple-
menting this enumeration.
3.1 The Method
Evaluating password strength as deﬁned in Equation 1
entails computing the cardinality of the set ∆ ⊂ Γ of all
passwords weaker than α, i.e., ∆ = {β ∈ Γ : p (β) > p (α)}.
Computing Sp (α) exactly would require generating all ele-
ments of ∆, which is obviously impractical if ∆ is large. Our
method approximates Sp (α) eﬃciently based on a subset of
n passwords; we prove its convergence to the true value of
Sp (α) for n going to inﬁnity. In Section 3.2, we show how
this method can be implemented eﬃciently, yielding a pre-
computed probability vs. rank curve.

We generate a sample Θ of n passwords. Passwords are
sampled with replacement and each password β is sampled
with probability p (β). Then, our estimation C∆ for the

160cardinality of ∆ is

C∆ =

(cid:40) 1

p(β)·n
0

(cid:88)

β∈Θ

if p(β) > p(α),
otherwise.

(2)

Note that the values of p (β) can be very low, and these
calculations may overﬂow or underﬂow. In our experiments,
we observed these phenomena with 32-bit ﬂoating point val-
ues, and we avoided them by using 64-bits arithmetic. To
avoid such problems altogether, one may want to resort to
arbitrary-precision numeric implementations.
In the following, we prove two theorems: ﬁrst, the ex-
pected value of C∆ under the attack model p is |∆|, mean-
ing that the expected value of our estimation is indeed the
desired quantity in Equation 1; second, the variance de-
√
creases as the sample size grows, with a convergence rate
n) – the standard for Monte Carlo estimators.
of O (1/
Theorem 1. The expected value of C∆ is |∆| = Sp(α).

Proof. Let us ﬁrst consider the n = 1 case. Here,

control on how to sample from Γ, and we assume the sam-
pling probabilities as given. Moreover, since Γ is extremely
large and possibly inﬁnite, even assuming that uniform sam-
pling was possible, elements from ∆ in the sample would be
very rare or non existent; on the other hand, since ∆ includes
elements with higher probabilities, they are deﬁnitely more
likely to appear in our non-uniform sample.
3.2 Optimized Implementation

The method described so far would require to create a
sample Θ of size n from the model p every time we want to
evaluate the strength of a password α. This is not necessary:
in the following, we show how to precompute the probability-
rank curve, and compute the strength of a new password
simply by performing an O(log n) lookup.

The key idea here is that the sampling step can be per-
formed just once, and it is only necessary to store the prob-
abilities p (βi) for each password βi in Θ. We store the
probabilities in an array A = [p (β1) , . . . , p (βn)] sorted by
descending probability, and we create an array C such that
C’s i-th element is

(cid:40) 1

(cid:88)

β∈Γ

E [C∆] =

p (β)

p(β)
0

if β ∈ ∆
otherwise

=

(cid:88)

β∈∆

1 = |∆| .

C [i] =

1
n

= C [i − 1] +

1

A[j]

1

n · A[i]

.

i(cid:88)

j=1

Theorem 2. The standard deviation of C∆ is O (1/

For n > 1, it is suﬃcient to note that our estimation is the
mean of n estimates done with n = 1. Since all estimates
are i.i.d., the expected value of the average is again |∆|.
√
n).

Proof. The variance of a random variable X is E(cid:2)X 2(cid:3) −
Var (C∆) = E(cid:2)C 2

(E [X])2. For the n = 1 case, we compute the variance as

(cid:3) − E [C∆]2 =

(cid:88)

∆

β∈∆

=

p (β)

p (β)2 − |∆|2
(cid:88)

1

p (β)

β∈∆

− |∆|2 .

We notice that the above value is ﬁnite because, by hypoth-
esis, |∆| is always ﬁnite; let us call this value V1. Since the
variance of an average of n i.i.d. variables is the variance of
those variables divided by n [2, Section 2.11.1], the generic
expression for the variance will be

Var (C∆) =

V1
n

=

β∈∆

p(β) − |∆|2

1

n

.

(3)

(cid:80)

Since V1 does not depend on n we obtain that, when n grows,
the variance converges in probability to 0 and C∆ converges
in probability to |∆|. With a variance in O (1/n), the stan-
dard deviation is O (1/
n), which is what typically happens
with Monte Carlo estimators [24].

√

In Equation 2, we are performing an inverse probability
weighting: we multiply the contribution of each element in
the sample by the inverse of the probability that such ele-
ment has to appear in the sample. This procedure is not new
in Statistics: it has been proposed in 1952 by Horvitz and
Thompson [13] for stratiﬁed sampling – a technique where
the analyst has control over sampling, and chooses diﬀerent
sampling probabilities for diﬀerent subpopulations (strata).
In our case, the diﬀerence lies in the fact that we do not have

A probability A[i] indeed corresponds to a rank C[i]. To
compute the strength of a password α, we ﬁrst lookup the
index j of the rightmost A[j] value in A such that A[j] >
p (α) through binary search; the output for C∆ is simply
C[j]. The procedure has O (log n) cost due to binary search.
In Section 5.4, to evaluate mandatory restrictions on pass-
words, we evaluate the cardinality of a diﬀerent set of pass-
words, a ∆(cid:48) set of passwords that is deﬁned via a boolean
ﬁlter function f that identiﬁes allowed passwords, such that
∆f = {β ∈ Γ : p (β) > p (α) ∧ f (β)}. In this case, it is point-
less to store information about passwords for which f (β)
is false, as they will never be taken in consideration when
evaluating C∆f ; therefore, our array A will only contain the
probabilities under model p of passwords that satisfy f (β).

4. EXPERIMENTAL SETUP

Here, we describe the setup we employ to evaluate our pro-
posal. We describe the datasets used in our evaluation and
the state-of-the-art guessing techniques that we consider.
4.1 Datasets

Several very large password datasets have been made pub-
licly available through leaks: the de facto standard in pass-
word research – allowing to compare results between diﬀer-
ent works – is the Rockyou dataset, which contains a set
of 32 million passwords that was released to the public in
2009. On this dataset we measure password strength as fol-
lows. Whenever a password training set is needed, we use
a dataset of 10 million passwords that was recently released
(February 2015) on the Xato.net website [3] – in the follow-
ing, we will label this as the Xato dataset. Most passwords
in the Xato dataset appear to come from Western users,
with the most common language being English. The Xato
dataset does not include passwords from the Rockyou leak.
We performed additional experiments – not reported here
due to space limitations – where we switched the role of
datasets, using Xato as test set and Rockyou as a training
set. Results are largely analogous to those reported here,

161reinforcing our conﬁdence on the generality of our results,
conﬁrming that there are no discernible defects in either
dataset, and showing that very large password datasets from
users speaking the same languages exhibit similar properties.
We have chosen Xato and Rockyou because of dataset
quality, uniformity and size. Other large datasets of Web
passwords include the Chinese datasets studied by Li et
al. [18]: the authors commented that “the raw ﬁles contain
duplication and blank passwords that can aﬀect the analy-
sis”. To avoid the risk of misleading results due to improper
data cleaning, we left those datasets out of our analysis.

Other large datasets of more than one million passwords
have been leaked from Gawker, eHarmony, LinkedIn, Ever-
note and Adobe. These datasets, however, contain hashed
or encrypted passwords: therefore, they are not suitable for
our analysis which needs passwords in clear-text to train the
attack models and to evaluate strength.
4.2 Attack Models

We now describe the attack models we consider in the

eﬀort of covering the most representative approaches.
4.2.1 N-Grams
Password guessing attacks using n-grams (i.e., substrings
of length n appearing in a training set) have been originally
proposed by Narayanan and Shmatikov [21].

In the following, we denote the number of occurrences of a
string of characters ca . . . cb in the training set as o(ca . . . cb).
We further denote the frequency with which character cb
follows the string ca . . . cb−1 as
P (cb|ca . . . cb−1) =

(4)
In an n-gram model (equivalently known as order n − 1
Markov model ), the probability of a password c1 . . . cl is

o (ca . . . cb)
o (ca . . . cb−1)

l+1(cid:89)

pn-gram (c1 . . . cl) =

P (ci|ci−n+1 . . . ci−1) ,

(5)

i=1

where all values ci when i ≤ 0 or i > l are considered to be a
special symbol ⊥ that does not appear in passwords, which
is used to denote the start or the end of the password.

Higher values of n make it possible to exploit a longer
history when predicting the next character; however, as n
grows, the issue of data sparsity appears: some n-grams may
not be represented in the training set, and the model would
incorrectly label their probabilities as 0. A solution to this
problem is the backoﬀ model described in Section 4.2.3.

Implementation Details.

For each n-gram ci−n+1 . . . ci, we simplify the notation by
calling ci−n+1 . . . ci−1 as its state s and ci as its transition
t. We precompute all values of P (t|s) by grouping all the
n-grams by state: in this way, the number of occurrences of
the state s needed for Equation 4 is computed by summing
the occurrences of all the n-grams in the group.

The probabilities that we compute can be very small and
may underﬂow: to avoid such problems, we store and com-
pute the base-2 logarithms of probabilities rather than prob-
abilities themselves. When computing probabilities, we per-
form similar substitutions also for PCFG and backoﬀ meth-
ods described later in the text.

Algorithm 1 Password generation for n-grams.

def starting_state():

return “⊥ . . .⊥” with length n − 1

def update_state(s, t):

drop the ﬁrst character from s
return s + t # concatenation
s ←starting_state()
g ←“” # accumulator for the result
while True:

r ←random number in [0, 1]
# ﬁnd i through binary search
i ←rightmost index s.t. Cs [i] > r
if ts,i = ⊥: return g
append ts,i to g

s ←update_state(s, ts,i)

such that each element Cs[i] =(cid:80)i

password enumeration: for each state s, we sort all transi-
tions ts,i in descending order of number of occurrences; we
then precompute an array Cs of cumulative probabilities
j=1 P (ts,j|s) = C[i − 1] +
P (ts,i|s). The creation of a password for the sample needed
in Section 3.1 is then carried out according to the procedure
shown in Algorithm 1: using binary search on Cs speeds up
password generation.

We also implemented a method to generate explicitly the
passwords with highest probability, in order to evaluate em-
pirically the accuracy of our approach as done in Section 5.1.
To keep memory usage under control we use a depth-ﬁrst
exploration of the state space rather than using a priority
queue, exploring all states that have probability higher than
a chosen threshold [19]; we sort passwords by decreasing
probability after having generated them.
4.2.2 PCFGs
Probabilistic Context-Free Grammars (PCFGs) have been
proposed by Weir et al. in 2009 [30]: they are based on the
realization that passwords often follow similar structures,
such as for example a word followed by a number.

In the PCFG approach, passwords are grouped by tem-
plates, which are the way sequences of letters, digits and
symbols are concatenated to form the password. For exam-
ple, the “abc123” password has the L3D3 template, meaning
that it is composed of three letters followed by three digits.
The probability of the password is calculated by multiplying
the frequency of the template P (L3D3) by the frequency of
each pattern in the template, i.e.,
pPCFG (“abc123”) = P (L3D3) P (“abc”|L3) P (“123”|D3) ,
where P (“abc”|L3) and P (“123”|D3) are the frequency of
“abc” and “123” within the set of three-characters groups of,
respectively, letters and digits.

Weir et al. proposed to obtain the frequencies of tem-
plates, digits and symbols from a training set of passwords
and to get the frequencies of letter groups from a dictio-
nary; however, when the training set is large, PCFGs per-
form better by calculating also letter group frequencies from
the training set [19]. In Section 5.2, we conﬁrm this result.

Implementation Details.

We implemented PCFGs following the speciﬁcations by

We also precompute data to facilitate sample creation and

Weir et al.; implementing the sampling step is trivial.

162Instead of storing the frequencies of templates and groups
of characters, we store their number of occurrences. This
allows us to perform evaluations where the test set and
the training set are the same with “leave-one-out” cross-
validation: when computing the probability for a given pass-
word, we subtract the one occurrence which is due to the
password under evaluation.
4.2.3 Backoff
The backoﬀ model has been proposed by Katz in the ﬁeld
of natural language processing [14], and it has been pro-
posed for password cracking by Ma et al. [19]. This model
addresses sparsity by considering n-grams of all lengths, and
discarding those with less occurrences than a threshold τ .
Intuitively the idea is that, for each choice of a new charac-
ter, the model considers the longest sequence of past char-
acters appearing at least τ times in the training set.

Given a threshold τ , the probability of a password c1 . . . cl
under the backoﬀ model can be deﬁned by induction, start-
ing from the single character case. The probability of a single
character ˆc is that character’s frequency in the training set:

o (ˆc)(cid:80)

c o (c)

pbo (ˆc) =

,

where – as in Section 4.2.1 – o (c1 . . . cn) is the number of
occurrences of the c1 . . . cn string in the training set. The
probability of a string of more than one character is

pbo (c1 . . . cn+1) = pbo (c1 . . . cn) · P (cn+1|c1 . . . cn) ,

r (c1 . . . cn) =

o (c1 . . . cnc)
o (c1 . . . cn)

.

c:o(c1...cnc)≥τ

As for the n-grams case, each password is considered to

end with a ⊥ symbol.

We noticed that, by construction, this model often gener-
ates passwords that are suﬃxes of common ones (e.g., “ss-
word”). To avoid this problem, we propose to prepend – sim-
ilarly to what happens for n-grams – a start symbol co = ⊥
to each password. We will see in Section 5.2 that this mod-
iﬁcation improves the quality of the guesses for this model.

Implementation Details.

The output of this method only depends on the number
of occurrences of n-grams with at least τ occurrences. A
na¨ıve way of implementing this model would process the
training set once, count the number of occurrences of all n-
grams for any value of n and, at the end of the process, drop
information for all n-grams with less than τ occurrences.
This approach requires very large amounts of memory, most
of which is devoted to temporarily memorizing the (in most
cases low) number of occurrences for n-grams with large n.
It is therefore problematic for our very large datasets.

In our implementation, we proceed by scanning the train-
ing set multiple times, and at the i-th iteration we compute
the number of occurrences of i-grams, discarding those that
have less than τ occurrences. We know for sure that the

where
P (c|c1 . . . cn) =

and

o(c1...cn)

(cid:40) o(c1...cnc)
(cid:88)

if o (c1 . . . cnc) ≥ τ,

P (c|c2 . . . cn) r (c1 . . . cn) otherwise

def starting_state():

Algorithm 2 Sample creation for the backoﬀ model.
if using the start symbol: return “⊥”
else: return “”

def update_state(s, t):

append t to s
while o (s) < τ :

drop the ﬁrst character in s

Run Algorithm 1 using these functions.

number of occurrences of an i-gram will not be higher than
the number of occurrences of both its preﬁx and suﬃx of
length i− 1: therefore, we can avoid storing any information
about i-grams whose preﬁx or suﬃx is not included in the
previous iteration. As an additional optimization, at the i-
th iteration we avoid considering passwords that – thanks
to this optimization – had no impact on the calculation in
the previous round.

We store the number of occurrences of each n-gram to
facilitate leave-one-out cross validation, for the reasons de-
scribed in Section 4.2.2. However, to make it eﬃcient to
create a sample and to generate passwords, we also precom-
pute the values of each P (c|c1 . . . cn) when o (c1 . . . cn) ≥ τ .
We consider c1 . . . cn as a state and c as a transition, and
we apply the same treatment described in Section 4.2.1 to
generate the CS auxiliary data structures. The sample cre-
ation algorithm then follows the procedure introduced for
n-grams (Algorithm 1), overriding the starting_state and
update_state functions as described in Algorithm 2.

5. EXPERIMENTAL RESULTS

We now proceed with our experimental evaluation, in which
we provide the following contributions: we evaluate the pre-
cision – and the limitations – of our method (Section 5.1).
We then provide a detailed comparison of the eﬃcacy in
cracking passwords of the attack models we consider (Sec-
tion 5.2); we discuss the impact of training set size on the
performance of guessing algorithms (Section 5.3); ﬁnally,
we evaluate the strength of passwords that satisfy typical
mandatory restrictions (Section 5.4).
Unless otherwise stated, in the experiments the sample
size n = |Θ| used by our method is 10,000; results are ob-
tained by evaluating a random subset of 10,000 passwords in
the test (Rockyou) database; the value of τ for the backoﬀ
model is 10 in line with Ma et al. [19]. Models are always
trained on the full training datasets.
5.1 Method Precision

In Figure 1, we show the relationship between the proba-
bility that models attribute to passwords and their rank (i.e.,
the Sp (α) value introduced in Equation 1). We evaluate the
models that behave best for password guessing (more infor-
mation about them is provided in Section 5.2). For each of
these models, we generated all the passwords having proba-
bility higher than 2−20; for each of them, we plot their rank
against their probability. The shaded areas are the ones be-
tween the minimum and maximum estimation provided by
our model, re-generating a sample Θ for 5 diﬀerent runs.

In the ﬁrst plot, estimates are so close to the correct val-
ues that it is impossible to discern the shaded areas; in the
second plot, we show a closeup of a particular area. We ex-

163sample standard deviation.1 We plot the results obtained on
evaluations based on 30 diﬀerent samples, using the 3-gram
model. This plot helps us in quantifying the precision in
estimating password strength and shows that, as predicted
by Theorem 2, estimates do converge as the sample size
grows. These results can be used as a guideline to choose
the sample size n: if the user is only interested in a rough
order-of-magnitude estimation of password strength, even a
sample that is as small as 100 elements can be suﬃcient.

In Figure 4, we investigate the limitations of our approach.
When we start evaluating very strong passwords, our esti-
mation of their strength becomes deﬁnitely more uncertain:
the reason is that, if p (α) is low, a password with proba-
bility close to p (α) is unlikely to appear in our sample, and
its presence or absence has a strong impact on our strength
estimation since it would add a (large) value 1/p (α) to the
estimation. The PCFG and backoﬀ models are less likely
to generate passwords with very low probability (see Figure
2), and this results in higher uncertainty on their strength.
Strength estimation is less precise for stronger passwords:
when these estimates are used to inform users, we deem this
uncertainty acceptable, as these passwords can generally still
be considered strong enough for most evaluation purposes.
In Figure 5, we compare the rank–probability pairs for
ranges that are expensive or prohibitive to evaluate by gen-
erating explicitly the passwords (in this case, to limit the
uncertainty of our estimation for very small probabilities, we
raised the sample size to 100,000). The probability values
diverge between models as the rank grows: the probabili-
ties for passwords having the same rank can diﬀer between
models by orders of magnitude. This result suggests that
it is dangerous to compare probability attributed to pass-
words by diﬀerent models when what we are interested in is
password strength; our method, instead, provides a sound
solution to this problem.

In Figure 6, we highlight the diﬀerence between the mod-
els by plotting the value of probability multiplied by rank.
If models had similar rank values associated with the same
probability, this value should be similar between attack mod-
els; when discussing the opportunity of comparing probabil-
ities between diﬀerent attack models, Ma et al. [19] conjec-
tured that this value should remain between 2−3 and 2−8;
this would have implied a roughly linear relationship be-
tween probability and rank, and justiﬁed comparing proba-
bilities output by diﬀerent models when ranks are expensive
to compute. Our results show that this is not the case:
again, this comes as evidence that comparing the number
of guesses is unavoidable if one wants to compare diﬀerent
probabilistic password models.
5.2 Comparing Attack Models

With the results of the previous section, we have estab-
lished that our method yields precise estimates of password
strength and that simply comparing probabilities – as done
in other works – is not suﬃcient to reliably compare attacks.
We now show a comparison in terms of guess-number graphs,
plotting the probability that an attacker would guess a sin-
gle password against the number of guesses; to the best of
our knowledge, this study is the ﬁrst to report guess-number
graphs comparing several state-of-the-art attacks up to an

1Relative sample standard deviation is the square root of
sample variance (i.e., variance computed using Bessel’s cor-
rection) divided by the mean of the values.

Figure 1: Password probability vs. rank. We show the cor-
rect values obtained by enumerating passwords by descend-
ing probabilities and, in the shaded areas, the area between
the minimum and maximum of 5 diﬀerent estimates.

perimentally conﬁrm the result we have proven in Theorem
1: our estimates converge to the correct values. An inter-
esting insight that we gain by looking at the leftmost area
of the password enumeration space, is that the probability-
rank relations can clearly diﬀer between models.

The diﬀerence in the probability vs. rank plot is due to
the fact that each model generates passwords with a dif-
ferent probability distribution.
In Figure 2, we show the
histograms resulting from binning the generated passwords

in each(cid:2)2−n, 2−n−1(cid:1) probability interval. From these plots,

it is clear that models have a very diﬀerent signature in
terms of probabilities attributed to passwords: in particular,
the probability distribution of passwords generated through
PCFGs and the backoﬀ model are clustered on probabilities
between 2−20 and 2−25; n-gram models, instead, are more
likely to generate passwords that have very low probabilities.
It is interesting to note that the training set contains
around 223 unique passwords; as we shall see in the following
results, this means that passwords labeled with a probabil-
ity lower than around 2−27 − 2−29 are unlikely to be present
in the original datasets. Models such as 3- and 4-grams are
deﬁnitely more likely to generate, when sampled, passwords
that do not appear in the original training set.

Theorem 1 proves that our estimates are correct on av-
erage, but the expression of the variance in Equation 3 is
diﬃcult to interpret, because it depends on an unknown
probability distribution. In Figure 3, we plot the level of un-
certainty we have in our estimation, in the form of relative

2−202−172−142−112−8Probability2327211215Rank3-grams4-gramsPCFGbackoff2−182−17Probability213214Rank3-grams4-gramsPCFGbackoff164(a) 3-grams.

(b) 4-grams.

bilities in the(cid:2)2−n, 2−n−1(cid:1) interval. The probability distribution varies widely depending on the model used.

Figure 2: Probability distribution for passwords generated by diﬀerent models. Each bin contains passwords having proba-

(c) PCFG.

(d) Backoﬀ.

Figure 3: Estimation uncertainty while varying sample size.
Estimates converge as the sample size grows.

Figure 4: Estimation uncertainty for very small probabilies.
When probabilities reach values for which elements in the
sample are rare (see Figure 2), estimations lose precision.

extremely large (280) number of attempts. Here and in the
following, results are obtained by evaluating the passwords
in the Rockyou dataset, using Xato as a training set.
Figure 7 shows an overview of the attacks that – as we will
see in the following – perform best. For the ﬁrst 216 − 220
guesses, backoﬀ and PCFG perform almost equivalently:
this is because both models are essentially guessing the most
frequent passwords in the training dataset. When the num-
ber of occurrences of a passwords falls below the backoﬀ
models’ threshold, the PCFG model continues by guessing
words that are in the training set, while the backoﬀ model
starts attempting “generalizations”, attempting words that
are not in the training set. At ﬁrst, this favors PCFGs,
but they eventually lose eﬃcacy because many existing pass-
words are not represented by the patterns they model.

From Figure 7, we conclude that the optimal attack strat-
egy varies depending on the number of guesses that the at-

tacker can aﬀord: PCFGs perform best at ﬁrst but they are
not capable of ﬁnding a substantial percentage of passwords,
while 4-grams and then 3-grams become preferrable to at-
tack stronger passwords. While never being optimal, the
backoﬀ strategy performs well across the whole spectrum of
passwords, proving that it indeed “self-tunes” to avoid the
dead-ends that models such as PCFGs reach.

In Figure 8, we analyze whether diﬀerent attacks would
require similar eﬀort to guess the same password.
In the
scatter-plots, we compare the number of attempts needed
to guess a password between the backoﬀ strategy and the
other ones considered in Figure 7. The correlation between
the approaches is obvious, suggesting that the strength of
a password against an attack is indicative of its strength
against other attacks. In addition, we notice that the backoﬀ
and PCFG strategies are very highly correlated for the pass-

202−162−322−482−642−802−962−1122−128Probabilitybin0%2%4%6%8%10%12%14%202−162−322−482−642−802−962−1122−128Probabilitybin0%2%4%6%8%10%12%14%202−162−322−482−642−802−962−1122−128Probabilitybin0%2%4%6%8%10%12%14%202−162−322−482−642−802−962−1122−128Probabilitybin0%2%4%6%8%10%12%14%2−602−492−382−272−16Probability0.1%1%10%100%1000%Relativestandarddeviation1001,00010,000100,0002−1002−812−622−432−24Probability1%10%100%1000%Relativestandarddeviation3-grams4-gramsPCFGbackoff165Figure 5: Probability vs. rank. Between n-grams and the
backoﬀ and PCFG models, the probabilities of passwords
having the same rank can diﬀer by orders of magnitude.

Figure 7: Overview of the best-performing attacks. Depend-
ing on the diﬃculty of the passwords, diﬀerent attack strate-
gies perform better. The “backoﬀ” strategy perform not far
from optimally for each probability.

obsolete: guessing passwords as they appear in the Xato
dataset appears always preferable than using dictionaries.
Using PCFGs is essentially equivalent to guessing passwords
as they appear in the training dataset – however, passwords
present in the Xato dataset are useful to ﬁnd around 40%
of the passwords of the Rockyou dataset; an additional 20%
are found via the mangling made through PCFGs.
5.2.2 N-Grams
In Figure 10, we compare attack models based on n-grams.
Compared to results based on much smaller training sets [7],
the sheer size of the training dataset makes it possible to
ﬁnd a large majority of the passwords even with higher-
order models (n = 3 and n = 4). Attack models based
on 2-grams and 1-grams (i.e., simply considering character
frequencies) are unlikely to be helpful for conceivably-sized
guessing attacks.
5.2.3 PCFGs
We analyze the performance of PCFG-based attacks in
Figure 11. As described in Section 4.2.2, our implementa-
tion of the model allows us to perform “leave-one-out” cross-
validation.
In this case, we evaluate the beneﬁts that an
attacker might have with a very well tuned training set: the
extreme case is, of course, to perform training on the full
Rockyou database. As per the original description by Weir
et al., we also train the alphabetic patterns of PCFGs from
an external dictionary, rather than from the training set: we
choose Openwall, since it performs best in Figure 9.

A better training set (Rockyou rather than Xato) boosts
performance noticeably, raising the percentage of found pass-
words by around 13%. Two factors are in play here: ﬁrst,
the Rockyou training set is larger than Xato; second, it is –
of course – more representative of passwords for the Rock-
you website (e.g., the “rockyou” string is very common in
the former and relatively rare in the latter). Again, we ﬁnd
that the size of training sets available today makes ad-hoc
dictionaries obsolete, conﬁrming previous ﬁndings [19].
5.2.4 Backoff
Figure 12 shows the results of evaluating diﬀerent vari-
ants of the backoﬀ model. Again, we evaluate the Rockyou
dataset as a training set using the “leave-one-out” method.

Figure 6: Probability multiplied by rank. Ma et al. [19] con-
jectured that the product between these two values remains
between 2−3 and 2−8. Our results show that this trend does
not hold for small probabilities.

words that are easier to guess (up to around 216 attempts),
which are in general the ones that appear multiple times in
the training dataset. When a password can ultimately be
guessed by PCFGs, they do this with less eﬀorts than the
backoﬀ attack; however, we stress that roughly a third of
the passwords are never guessed by PCFGs and hence they
do not appear in the graph.

The results of Figure 8 highlight that the strength of a
given password against diﬀerent attacks is obviously corre-
lated; nevertheless we consider that user passwords should
still be checked against several attacks. A resonable con-
servative strategy would be to output to the user the result
yielding the lowest strength value.

In the following, we provide more details about attacks by

examining each class more in detail.

5.2.1 Dictionary Attacks
We take into account dictionary attacks. We consider the
Openwall and dic-0294 dictionaries, two ad-hoc dictionaries
for password guessing that have been evaluated in related
work [7,19,30], and we compare them to using the password
in the Xato dataset as a dictionary, sorted by decreasing
number of occurrences: the results are shown in Figure 9.
It appears that large password datasets make dictionaries

2−252−502−752−100Probability20210220230240250260270280290Rank3-grams4-gramsPCFGBackoff2−252−502−752−100Probability2−122−102−82−62−42−2Rank×probability3-grams4-gramsPCFGBackoff20216232248264280Attempts0%20%40%60%80%100%Guessingprobability3-grams4-gramsPCFGBackoff166Figure 9: Dictionary attacks. A large sets of leaked pass-
words performs better in cracking passwords than ad-hoc
crafted dictionaries.
PCFGs are eﬃcient to generalize
guesses when dictionaries are exhausted.

Figure 8: Comparing diﬀerent attacks on the same pass-
words. Dots on the diagonal represents passwords that are
found after the same number of attempts by two attacks.

As before, we observe that using the matching dataset as a
training set improves the attack. In addition, our modiﬁca-
tion to include a start symbol improves the quality of initial
guesses, matching at the beginning the one of PCFGs (see
Figure 7).
5.3 Impact of Training

In Figure 13, we consider the eﬀect of training set size
on our results: we consider the backoﬀ model, because it
obtains a good guessing probability for any number of at-
tempts. We vary the training set size between 0.1% and
100% of the training dataset.

It is interesting to point out that a larger training set
has little eﬀect in guessing either the easiest passwords (the
most common passwords are likely to be in smaller subsets
of the original training set) or the hardest ones (they are

Figure 10: n-grams. When trained on very large datasets,
attacks based on 3-grams cover almost all passwords. 4-
grams are slightly more eﬃcient to guess weaker passwords.

most likely unique, and little information about them can be
gleaned even from large training sets). Raising the training
set size, instead, appears useful for the “average” passwords,
i.e., those for which either the given password or a similar
one can be found in a larger dataset.
5.4 Evaluating Mandatory Requirements

We now turn our attention to evaluating mandatory re-
quirements such as the ones that are often included in pass-
words: minimum length and/or including uppercase, nu-
meric and/or symbolic characters. From our datasets, we
only consider the passwords that satisfy such requirements;
we evaluate the number of attempts an attacker would need
in order to guess a password. We assume that the attacker
is aware of the restriction and therefore that passwords that
do not satisfy the requirements will not be guessed.

We think that these results should be regarded as opti-
mistic evaluations of the strength improvements that can be
obtained by imposing such restrictions:
indeed, users who
choose weaker passwords might see such restrictions as a
hurdle to bypass with minimum eﬀort, choosing the sim-
plest modiﬁcation that would satisfy the requirement (e.g.,
appending “1” to satisfy the requirement of including digits).
In this case, given a boolean function f (α) that tells us

20216232248264280Attemptswithbackoff20216232248264280Attemptswith3-grams20216232248264280Attemptswithbackoff20216232248264280Attemptswith4-grams20216232248264280Attemptswithbackoff20216232248264280AttemptswithPCFG20216232248264280Attempts0%10%20%30%40%50%60%70%GuessingprobabilityPCFGXatoopenwalldic-029420216232248264280Attempts0%20%40%60%80%100%Guessingprobability1-grams2-grams3-grams4-grams167Figure 11: PCFGs. The legend indicates the training set
and whether an additional dictionary has been used to train
the alphabetic groups of PCFGs.

Figure 13: Training set. The legend refers to the percentage
of the full Xato set used for training.

and this is easy to guess for attackers. Symbols appear to
be less predictable and placed in diﬀerent locations of the
password, and that noticeably increases password strength:
in our case, passwords that include symbols are roughly as
strong as those of length at least 12.

6. CONCLUSIONS

Passwords are an ubiquitous way of handling access con-
trol, and hence properly evaluating their solidity against
state-of-the-art attacks is obviously important. To the best
of our knowledge, this is the ﬁrst study that provides a reli-
able estimation – backed by proofs of correctness and conver-
gence – for the success rate of very expensive attacks to pass-
words using state-of-the-art guessing techniques. By evalu-
ating the password strength in terms of number of guesses
needed by an attacker, we make it possible to gain better
insights into the actual cost that an attacker should pay to
guess a password, and therefore better understand the us-
ability vs. security trade-oﬀ that password strength implies.
Our study shows that the number of attempts needed
to guess a password is correlated between diﬀerent attacks;
nevertheless, we believe that user passwords should be checked
against several attack models, and that a reasonable strat-
egy would be to conservatively output the result yielding the
lowest strength value.

Our method is generic and extremely lightweight, with the
possibility to increase the level of accuracy in the assessment
of password strength by a quantity that can be directly re-
lated to the number of computations that one is willing to
invest. Our proposal is applicable to any generative prob-
abilistic model; we consider this approach to be reasonably
future-proof, as we believe that new developments in pass-
word guessing will most likely continue to use models that
are (or can be expressed as) generative probabilistic models.

7. REFERENCES
[1] J. Bonneau. The science of guessing: analyzing an

anonymized corpus of 70 million passwords. In S&P.
IEEE, 2012.

[2] G. Bontempi and S. Ben Taieb. Statistical foundations

of machine learning. 2009.

[3] M. Burnett. Today I am releasing ten million

passwords. https://xato.net/passwords/ten-
million-passwords/, February 2015.

Figure 12: Backoﬀ. The legend indicates the training set
and whether our proposed use of a start symbol is adopted.

whether a given password is accepted according to the re-
quirements, our new strength measure should only count the
passwords that have probability higher than p (β) > p (α)
and for which f (β) is true; the procedure to do this is
described in Section 3.2. Passwords that satisfy the most
stringent requirements are rare in our datasets, so to limit
precision problems, we increase the size of our sample set
Θ and the test set from the Rockyou dataset, in order to
obtain 10,000 passwords that satisfy f in both sets.

In Figure 14 we plot the distribution of password strength
for passwords with restrictions, according to the procedure
outlined above (policies are described in the caption). Again,
we consider the backoﬀ model as the attack method.

Length requirements increase password strength rather
homogeneously for all passwords – with the exception of the
weakest ones for the length limitation at 8: this is because
several very common passwords have length 8.

We notice that requiring passwords with both letters and
numbers does little to increase security; this may be due to
the fact that passwords including letters and numbers often
have very predictable patterns (e.g., numbers at the end)
which are easily discovered by guessing techniques. Requir-
ing a mix of uppercase and lowercase characters does better,
but the strength improvement on the weakest passwords is
limited: this is because, for weak passwords, uppercase char-
acters are generally placed at the beginning of the password,

20216232248264280Attempts0%10%20%30%40%50%60%70%80%GuessingprobabilityXatoRockyouXato+OpenwallRockyou+Openwall20216232248264280Attempts0%20%40%60%80%100%GuessingprobabilityRockyou,startsymbolXato,startsymbolRockyou,nostartsymbolXato,nostartsymbol20216232248264280Attempts0%20%40%60%80%100%Guessingprobability100%10%1%0.1%168Sustainably managing large numbers of accounts. In
USENIX Security, 2014.

[12] C. Herley and P. Van Oorschot. A research agenda

acknowledging the persistence of passwords. In S&P.
IEEE, 2012.

[13] D. G. Horvitz and D. J. Thompson. A generalization

of sampling without replacement from a ﬁnite
universe. J. Am. Stat. Assoc., 47(260):663–685, 1952.
[14] S. Katz. Estimation of probabilities from sparse data

for the language model component of a speech
recognizer. IEEE TASSP, 35(3):400–401, 1987.

[15] P. G. Kelley, S. Komanduri, M. L. Mazurek, R. Shay,

T. Vidas, L. Bauer, N. Christin, L. F. Cranor, and
J. Lopez. Guess again (and again and again):
Measuring password strength by simulating
password-cracking algorithms. In S&P. IEEE, 2012.

[16] D. V. Klein. Foiling the cracker: A survey of, and

improvements to, password security. In USENIX
Security, 1990.

[17] S. Komanduri, R. Shay, L. F. Cranor, C. Herley, and

S. Schechter. Telepathwords: Preventing weak
passwords by reading users’ minds. In USENIX
Security, 2014.

[18] Z. Li, W. Han, and W. Xu. A large-scale empirical

analysis of chinese web passwords. In USENIX
Security, 2014.

[19] J. Ma, W. Yang, M. Luo, and N. Li. A study of

probabilistic password models. In S&P. IEEE, 2014.
[20] R. Morris and K. Thompson. Password security: A

case history. CACM, 22(11):594–597, 1979.

[21] A. Narayanan and V. Shmatikov. Fast dictionary
attacks on passwords using time-space tradeoﬀ. In
CCS. ACM, 2005.

[22] P. Oechslin. Making a faster cryptanalytic

time-memory trade-oﬀ. In CRYPTO. Springer, 2003.

[23] C. Percival and S. Josefsson. The scrypt

password-based key derivation function. 2012.

[24] W. H. Press, S. A. Teukolsky, W. T. Vetterling, and

B. P. Flannery. Numerical Recipes: The Art of
Scientiﬁc Computing. Cambridge University Press, 3rd
edition, 2007.

[25] Solar Designer and S. Marechal. Password security:

past, present, future. Passwordˆ12 workshop,
December 2012.

[26] E. H. Spaﬀord. Observing reusable password choices.

In USENIX Security, 1992.

[27] B. Ur, P. G. Kelley, S. Komanduri, J. Lee, M. Maass,

M. L. Mazurek, T. Passaro, R. Shay, T. Vidas,
L. Bauer, et al. How does your password measure up?
the eﬀect of strength meters on password creation. In
USENIX Security, 2012.

[28] R. Veras, C. Collins, and J. Thorpe. On the semantic

patterns of passwords and their security impact. In
NDSS. Internet Society, 2014.

[29] M. Weir, S. Aggarwal, M. Collins, and H. Stern.
Testing metrics for password creation policies by
attacking large sets of revealed passwords. In CCS.
ACM, 2010.

[30] M. Weir, S. Aggarwal, B. De Medeiros, and

B. Glodek. Password cracking using probabilistic
context-free grammars. In S&P. IEEE, 2009.

Figure 14: Restrictions. We show the number of attempts an
attacker would need to guess passwords that satisfy certain
restrictions, if knowing that the restrictions exist. Meaning
of the labels: “policy 1” refers to passwords that have alpha-
betic and numeric characters; “policy 2” requires lowercase,
uppercase and digits; “policy 3” requires alphabetic and nu-
meric characters in addition to non-alphanumeric symbols.

[4] W. Burr, D. Dodson, R. Perlner, W. Polk, and

S. Gupta. NIST special publication 800-63-1 electronic
authentication guideline, 2006.

[5] C. Castelluccia, M. D¨urmuth, and D. Perito. Adaptive

password-strength meters from markov models. In
NDSS. Internet Society, 2012.

[6] X. de Carn´e de Carnavalet and M. Mannan. From very

weak to very strong: Analyzing password-strength
meters. In NDSS. Internet Society, 2014.

[7] M. Dell’Amico, P. Michiardi, and Y. Roudier.
Password strength: An empirical analysis. In
INFOCOM. IEEE, 2010.

[8] M. Duermuth, F. Angelstorf, C. Castelluccia,

D. Perito, and A. Chaabane. OMEN: Faster password
guessing using an ordered Markov enumerator. In
ESSoS. IEEE, 2015.

[9] S. Egelman, A. Sotirakopoulos, I. Muslukhov,

K. Beznosov, and C. Herley. Does my password go up
to eleven?: the impact of password meters on
password selection. In SIGCHI. ACM, 2013.

[10] D. Florˆencio, C. Herley, and P. C. Van Oorschot. An

administrator’s guide to internet password research. In
LISA. USENIX, 2014.

[11] D. Florˆencio, C. Herley, and P. C. Van Oorschot.

Password portfolios and the ﬁnite-eﬀort user:

20216232248264280Attempts0%20%40%60%80%100%Guessingprobabilityallpasswordslength≥8length≥10length≥1220216232248264280Attempts0%20%40%60%80%100%Guessingprobabilitynorestrictionpolicy1policy2policy3169