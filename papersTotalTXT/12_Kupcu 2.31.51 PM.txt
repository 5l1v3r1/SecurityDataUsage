Fast Optimistically Fair Cut-and-Choose 2PC

Alptekin K¨up¸c¨u1∗ and Payman Mohassel2

1 Ko¸c University, TURKEY

2 Yahoo Labs, USA

Abstract. Secure two party computation (2PC) is a well-studied prob-
lem with many real world applications. Due to Cleve’s result on general
impossibility of fairness, however, the state-of-the-art solutions only pro-
vide security with abort. We investigate fairness for 2PC in presence of
a trusted Arbiter, in an optimistic setting where the Arbiter is not in-
volved if the parties act fairly. Existing fair solutions in this setting are
by far less eﬃcient than the fastest unfair 2PC.
We close this eﬃciency gap by designing protocols for fair 2PC with
covert and malicious security that have competitive performance with
the state-of-the-art unfair constructions. In particular, our protocols only
requires the exchange of a few extra messages with sizes that only depend
on the output length; the Arbiter’s load is independent of the compu-
tation size; and a malicious Arbiter can only break fairness, but not
covert/malicious security even if he colludes with a party. Finally, our
solutions are designed to work with the state-of-the-art optimizations ap-
plicable to garbled circuits and cut-and-choose 2PC such as free-XOR,
half-gates, and the cheating-recovery paradigm.

Keywords: secure two-party computation, covert adversaries, cut-and-choose,
garbled circuits, fair secure computation, optimistic fair exchange.

Introduction

1
In electronic commerce, privacy and fairness are two sought-after properties as
depicted in work related to contract signing and fair exchange [5,14,49,9,6,8,21].
Fair exchange is used in electronic payments to buy or barter items [12,43] and
contract signing is often used to ensure fairness: either all parties sign and agree
on the contract, or the contract is invalid.

Fair secure two-party computation (2PC), a fundamental problem in cryp-
tography, can be used to address both the privacy and fairness concerns, si-
multaneously. Alice and Bob would like to jointly compute a function of their
private inputs, such that nothing other than the output leaks, and either both
parties learn the output or either do (e.g. two banks trying to calculate a joint
credit score for a customer, without giving away critical private information).
Unfortunately, however, there is a signiﬁcant eﬃciency gap between secure 2PC
that achieve fairness and their unfair counterparts that have been the subject of
many recent implementations and optimizations.

∗We thank T ¨UB˙ITAK, the Scientiﬁc and Technological Research Council of Turkey,

project 111E019, and European Union COST Action IC1306.

2PC Without Fairness: Yao [61] introduced the ﬁrst 2PC with security
against honest-but-curious adversaries [46] and a large body of recent work has
focused on making 2PC practical in presence of stronger (covert and malicious)
adversaries [50,47,7,54,45,23].

The cut-and-choose paradigm is a popular method for enhancing the security
of Yao’s garbled circuit protocol to the case of malicious (or covert) adversaries
where the players can deviate arbitrarily. In a nutshell, in this paradigm, one
player (Alice) garbles many circuits while the other player (Bob) checks a ran-
domly chosen subset (to ensure that the garbling was done correctly) and eval-
uates the rest. Until recently, many existing solutions (e.g. [51,47,48,59,52,60])
required garbling at least 3s circuits to detect cheating with probability 1− 2−s.
The high number of garbled circuits is due to the fact that all these constructions
ask that the evaluator computes a “majority output” and, for it to be valid, re-
quire that more than half of the evaluated circuits are correct. For the majority
output to be valid, parties also need to enforce equality of the garbler’s input
to the majority of the circuits evaluated. This is often handled via a procedure
called input-consistency check.

The recent work of Lindell [45] shows how to reduce the number of gar-
bled circuits by a factor of 3.3 In this approach, the second player evaluates
the unchecked circuits, but is content with computing only one correct output
(instead of a majority output) due to a cheating-detection component. This
allows one to reduce the number of circuits to s and still achieve 1− 2−s security.
A more modest security guarantee for 2PC is covert security, proposed
by Aumann and Lindell [7], which provides a practical alternative to the ma-
licious setting. In this setting, the adversary can cheat with some small but
non-negligible probability. The rationale is that a reputable real-world entity
will not risk getting caught with non-negligible probability due to loss of reputa-
tion or the legal/economical costs. The protocols in the covert setting are more
eﬃcient than their malicious counterparts. For instance, in the cut-and-choose
paradigm, one can settle for only garbling s = 5 circuits if 1 − 1/s = 4/5 proba-
bility of getting caught is prohibitive enough. Back to our two banks computing
a customer’s credit score scenario, the ﬁnancial losses when a bank gets caught
cheating can be seen as prohibitive as a negligible probability of cheating.

2PC with Fairness: All the above-mentioned work focus on security with
abort, where the malicious party is allowed to abort the protocol after he learns
the output of the computation, but before the honest party obtains the output,
because it is known that achieving general fairness is impossible [20]. This limits
the real world applicability of the most eﬃcient solutions. An interested corpo-
ration is less likely to adopt 2PC solutions if it has to risk being at a competitive
disadvantage by revealing the outcome of the computation to a competitor with-
out learning it itself.

3An alternative approach for reducing the number of circuits by a factor of 1.5 was

introduced by [27].

There are two main approaches for achieving fairness in general-purpose
2PC.4 (i) Gradual release-based approaches let Alice and Bob reveal each
other’s output piece by piece, using super-constant rounds [55,33,58,57]. (ii) Ar-
biter-based approaches achieve constant round complexity by assuming that
a trusted third party is available when needed [18,44,31,32]. Optimistic ap-
proaches employ the Arbiter only if there is a dispute among the parties [5].

The most relevant work to ours is that of Cachin and Camenisch [18], and
the follow up work of [31], in the same optimistic Arbiter-based setting. Both
constructions utilize zero-knowledge proofs that require public-key operations,
and hence have a high computational cost compared to the state-of-the-art cut-
and-choose 2PC. Furthermore, in [18], the Arbiter may need to redo almost the
whole computation in case of a malicious behavior, which creates a bottleneck
in the system.

Lindell’s optimistic framework [44], on the other hand, necessitates an elec-
tronic payment system. It is possible that one party obtains the output of the
computation, whereas the other obtains a payment. [1,2,15,30,37,43] also em-
ploy such penalty-based fairness models. These constructions are incomparable
to ours as they work in a diﬀerent setting and make diﬀerent assumptions. See
Table 1 for a list of the main diﬀerences between these work and ours.

[18]

[44]

[31]

Resolutions with Arbiter
take time proportional to

Requires a payment
system and employs

Eﬃciently adds fairness,
but to zero-knowledge

the circuit size

penalty-based fairness.

based 2PC protocols only.

Table 1. Comparison to the most related previous work.

Our Contribution: In this paper we investigate fairness for 2PC in presence
of a trusted Arbiter in an optimistic setting, where the Arbiter is not involved
if the parties act fairly. We design eﬃcient protocols for fair 2PC with security
against covert and malicious adversaries. Our constructions follow the cut-and-
choose paradigm, and for the ﬁrst time, close the eﬃciency gap between fair 2PC
and the state-of-the-art unfair solutions, in this setting. In particular:
(cid:88) The overhead of our protocols against state-of-the-art unfair solutions is
small; only a constant number of extra rounds and a few messages with sizes
that only depend on the output length.
(cid:88) The Arbiter’s load is minimal, and independent of the size of computation.
(cid:88) A malicious Arbiter can only break fairness, but not covert/malicious secu-
rity even if he colludes with a party. We prove this via a simulator for the
usual security with abort deﬁnition, when the adversary is also controlling
the Arbiter.
(cid:88) Our protocols are compatible with optimizations applicable to cut-and-
choose 2PC such as free-XOR [36], FleXor [35], and half-gates [62]. It also
utilizes the cheating-recovery paradigm, and hence uses a reduced number
of garbled circuits. These render our protocols the most eﬃcient fair secure
computation protocols to date.

4A diﬀerent line of work focuses on achieving fairness not in general but for speciﬁc

applications [25,3,16,22,17].

(cid:88) Our work is the ﬁrst to consider fairness in the covert adversary model.

2 Overview of Our Constructions
We review the high level ideas behind our covert and malicious 2PC construc-
tions next, emphasizing the non-trivial parts. Our starting point in each case
is the state-of-the-art protocol with security with abort (in the cut-and-choose
paradigm). We then show how to enhance and modify each at very low cost in
order to obtain fairness in the presence of an Arbiter.

Some of our techniques are similar to that of Kılın¸c and K¨up¸c¨u [31] who also
provide an eﬃcient solution for fair 2PC in the same setting. Similar to ours,
their solution employs commitments to output labels, and veriﬁable escrows.
But they instantiate these using zero-knowledge proofs of knowledge. In fact,
veriﬁable escrow inherently employs zero-knowledge proofs. When one switches
to the cut-and-choose setting, it is unclear how to deal with the multitude of such
commitments and veriﬁable escrows, and still preserve correctness and eﬃciency.
Our solutions are the ﬁrst to combine optimistic Arbiter-based fairness and the
cut-and-choose paradigm eﬃciently.

2.1 Fair Covert 2PC

There are various ways of combining fairness and covert security in a simulation-
based deﬁnition. In this paper we consider the natural notion where both fairness
and correctness/privacy are guaranteed with a reasonable (not all-but-negligible)
probability 1 −  but both fairness and correctness/privacy are lost with proba-
bility  against active cheating. A related notion to fairness in the covert setting
is 1/p security [24,28]. In that line of work [26,53,11,10], the ideal world provides
complete fairness (as in our case for malicious adversaries), but the simulation
only needs to achieve 1/p indistinguishability between the ideal and real worlds.
Our approach is slightly diﬀerent: we directly take the covert adversary model
[7,4], and modify it to preserve fairness unless the adversary cheats and remains
undetected. Note that the 1/p security does not explicitly model detection of the
adversary’s misbehavior. It is an interesting question to understand the relation
between the two notions. Next, we review the main technical diﬃculties in our
covert construction.

Security with Abort. Recall the covert 2PC protocol of Aumann and
Lindell [7]. Alice generates s garbled circuits GC1, . . . , GCs. Then, the parties
perform (cid:96) (number of input bits) oblivious transfers (OTs) for Bob to learn
his garbled inputs (this is intentionally done for all s circuits and before the
opening). Alice sends the s garbled circuits to Bob. Parties then perform a coin-
toss to choose a random index e ∈ {1, . . . , s}. Alice opens the secrets for all
garbled circuits and OTs except for the eth one. Bob checks correctness of the
opened circuits and the corresponding OTs, and aborts if cheating is detected.
Else, Alice sends her garbled inputs for the eth circuit. Bob evaluates the circuit
and learns his own output. He also obtains the garbled values for Alice’s output,
which he sends to her for translation.

It is easy to see that the above construction is not fair. We now highlight the

main changes we make to this protocol to achieve fairness.

Delay Evaluator’s Output Translation. Note that Bob can abort the
protocol immediately after learning his output and without forwarding Alice’s
output to her. Therefore, we modify the protocol so that Alice does not send to
Bob the translation table for his output (mapping output labels to actual bits)
until he sends Alice’s garbled output to her. But note that this trivial change
fails since now Alice can abort before sending the translation table to Bob.

Hence, we need to ensure that if Alice aborts at this stage, Bob has enough
information to invoke an output resolution protocol with the Arbiter and show
evidence that he has been following the steps of the protocol and hence deserves
to know the output. After checking Bob’s claim, the Arbiter should be able to
provide him with suﬃcient information to decode his output.

Prove Bob’s Honesty to the Arbiter. Notice that eﬃciently proving
this is a non-trivial task. For example, in [18], the Arbiter and the resolving
party re-perform almost the whole computation for this purpose. In our case,
Bob’s proof of following through with the protocol will be the garbled output he
computes for Alice’s output. Note that due to the output-authenticity property of
the garbling scheme, Bob cannot forge this value except if he honestly computes
the output. In order to enable the Arbiter to check the validity of Bob’s claimed
output label, Alice will send hashes of her output labels (in permuted order) to
Bob along with the garbled circuits, and a signature for the eth one. Bob veriﬁes
validity of these hashes for the opened circuits. Now when he goes to the Arbiter,
he shows both the output labels he obtained for Alice’s output, and the signed
hashes for the eth circuit. The Arbiter can verify that the two are consistent, by
ensuring that there is one output label provided per pair.

Equip the Arbiter with the Translation Table for Bob’s Output.
Furthermore, the Arbiter should have suﬃcient information to pass along to
Bob for decoding his output. Hence, Alice encrypts the translation table for
Bob’s output under the Arbiter’s public key and sends it to Bob along with the
garbled circuits, and a signature for the eth one. Bob checks validity of these
encryptions for the opened circuits. Once Bob’s claim of behaving honestly is
veriﬁed, the Arbiter can decrypt the translation table, and send it to Bob for him
to decode his output. The signature is needed to make sure that Bob is sending
a legitimate decoding table for decryption. Since Bob veriﬁed the opened ones,
he is ensured, with good probability, that the eth decoding table is proper.

Simulation-based Proof with Fairness. One important diﬀerence be-
tween our proof and those of standard 2PC is that in our case the ideal trusted
party must only be contacted by the simulator once it is certain that both
parties can obtain the output, as ﬁrst observed by Kılın¸c and K¨up¸c¨u [31] for
indistinguishability of the ideal and real world outputs. Therefore, to overcome
this diﬃculty, Alice also commits to Bob’s output translation tables as cB
i using
a trapdoor commitment, and opens them for the opened circuits. Bob ensures
that the committed and encrypted translation tables are the same (in fact, we
encrypt the commitment openings). For the eth circuit, she opens cB
e at the last
step of the protocol. The reason we need these commitments is that, unlike stan-
dard covert 2PC, the Alice simulator in the proof for the case of corrupted Bob

does not have fB(xA, x(cid:48)
B) when sending the garbled circuits (since in the fair
protocol neither party may learn the output at this stage), and hence cannot
embed the output in the eth one at that stage. With trapdoor commitments, at a
later stage, she is able to open the translation to something diﬀerent in order to
ensure the “fake” evaluation circuit evaluates to the correct output fB(xA, x(cid:48)
B).
The hiding property of the commitment scheme ensures indistinguishability of
the simulator’s actions.

Handle Premature Resolutions. The parties have the right to contact
the Arbiter. But they may choose to do so at a stage other than the prescribed
one. For example, Bob may invoke the output resolution before he sends Alice’s
output labels to her. This behavior is mitigated by requiring that Bob provides
the Arbiter with Alice’s output labels that match the signed decoding table. Due
to output authenticity of the garbling scheme and unforgeability of the signature
scheme, Bob cannot cheat against the Arbiter and must provide correct labels.
Later on, Alice can recover her output through her own output resolution pro-
tocol. A timeout mechanism ensures that Bob must contact the Arbiter during
a predeﬁned time5, and immediately after that Alice can contact the Arbiter,
without waiting indeﬁnitely.

A Note on Synchronicity. Observe that we employ a timeout for res-
olutions with the Arbiter. Katz et al. [29] deﬁne a very nice framework for
integrating synchronicity in the Universal Composability [19] framework. They
provide a clock functionality which allows all honest parties to proceed further
once a particular clock signal is reached, allowing for synchronous protocols. In
that setting, they show input completeness and guaranteed termination can be
achieved together (though not necessarily fairness). In our protocols, the only
place we employ loosely synchronized clocks is for resolutions with the Arbiter.
The remaining (optimistic) part of the protocol employs no synchronicity as-
sumptions (just local network timeouts). There are two main reasons we choose
to proceed this way: (1) Due to a result by K¨up¸c¨u and Lysyanskaya [41] (see
also [40]), if one would like to employ multiple autonomous (independent) enti-
ties to replace a single trusted Arbiter, we are forced to employ timing models.
(2) Optimistic fair exchange literature shows that the timeout-based resolutions
can be exchanged with slightly more expensive protocols (with one more round)
that provide fairness without requiring timeouts (see e.g. [5,43]). We believe a
similar methodology may be employed here to replace the timeouts, and leave
such an extension to our protocols as future work.

Proof overview. We obtain security against malicious Bob as follows: The
simulator acts as Alice, except that she commits to and encrypts random val-
ues instead of actual output decoding table in cB
e . Towards the end, if the
simulator obtains proper output labels for Alice’s output from the adversar-
ial Bob, then she contacts the ideal trusted party to learn Bob’s output and
simulate opening of cB
e to the actual values. Hiding commitments ensure indis-
tinguishability of Alice’s behavior. If, instead of sending them directly to Alice,

e , dB

5Such timeout mechanisms are easy to implement and standard in the optimistic

fair exchange literature (see e.g. [5,43]).

Bob contacts the Arbiter and performs a proper resolution, the simulator simu-
lates the Arbiter, and upon receiving proper output labels for Alice, contacts the
ideal trusted party for obtaining Bob’s output. She then sends the correspond-
ing decoding table as if it was the decryption of dB
e . Semantic security ensures
indistinguishability of Alice’s and Arbiter’s behavior.

For security against covert Alice, diﬀerent from the unfair scenario, the sim-
ulator contacts the ideal trusted party if Alice acts properly, and obtains Alice’s
output. He sends the corresponding labels back to Alice. He simulates by himself
Bob’s Arbiter resolution should Alice not respond back with Bob’s output la-
bels’ openings. If Alice later contacts the Arbiter for resolution, he returns back
Alice’s output labels again.

2.2 Fair Malicious 2PC

Security with Abort. Our starting point is the cut-and-choose 2PC of Lindell
[45], which contains a cheating-detection component to remove the requirement
that majority of the circuits are correct, and hence reduce the number of circuits
by a factor of 3.

In this protocol, Alice garbles s circuits GC1, . . . , GCs with the exception that
she uses the same output labels for all circuits. Parties also perform (cid:96) OTs for Bob
to learn his input labels. Bob then chooses a random subset of these circuits to be
evaluated, and the rest are to be opened and checked for correctness later. Bob
evaluates the evaluation circuits. Since output labels are reused for all circuits,
Bob expects to retrieve the same labels from all evaluations. If this is indeed the
case, he only needs to ensure that one of the evaluations was correct in order to
make sure he has the correct output. If Bob obtains diﬀerent labels for at least
a single output wire, he uses the two distinct labels W0 and W1 corresponding
to values 0 and 1, as his proof of Alice’s cheating.

At this stage, parties engage in a cheating-detection phase, which itself is a
malicious cut-and-choose 2PC for evaluating a cheating-detection (CD) circuit.
This cut-and-choose is performed using 3s circuits (and a majority output),
but since the CD circuit is signiﬁcantly smaller, this will be a small overhead,
independent of the actual circuit’s size. The CD circuit takes W0 and W1 as Bob’s
input (his evidence of Alice’s cheating), and takes Alice’s input xA to the original
computation as her input. If Bob’s two labels are valid proofs (Alice embeds the
output labels in the CD circuits, and the CD circuit checks whether Bob’s two
labels are among them), he learns Alice’s input xA and can compute f (xA, xB)
on his own. Otherwise he learns a random value. It is important that Alice does
not know whether Bob learned the output by evaluating the computation circuits
or the cheating-detection circuits. Alice then opens the check circuits and Bob
aborts if any of the checks fail. Else, he sends Alice’s output labels to her.

Handle Alice’s Input Consistency. Deviating from [45], we handle the
consistency of Alice’s inputs using the technique of [60], as it seems more suitable
for the tweaks we need to make to input-consistency. In this approach a universal
hash function (UH) is evaluated on her input inside the circuits, and Bob veriﬁes
that the output of this function is the same in all circuits. Alice’s input is padded

with a short random string rx in order to increase its entropy and reduce the
amount of information that can be learned about the input from the output of
the UH. Let (cid:96) be the input length and s(cid:48) be a security parameter. [60] shows
that a random matrix of dimensions s(cid:48) × ((cid:96) + 2s(cid:48) + log s(cid:48)) over GF (2) can be
used as a UH, where the evaluation consists of multiplying this matrix with the
input vector (and getting a vector of length s(cid:48)).

Delay Bob’s Output via a One-time Pad. Similar to the covert 2PC,
it is easy to see that the above construction is not fair. In particular, Bob can
abort the protocol immediately after learning his output and without forwarding
Alice’s output to her. But unlike our fair covert 2PC, delaying the transmission
of the output translation table is not suﬃcient for preventing Bob from learning
his output early. Since the same output labels are used for all circuits and a
fraction of them are opened, Bob can reconstruct the translation table on his
own after the opening phase, and learn his output.

To overcome this issue, we encrypt Bob’s output using a one-time pad padB
that is Alice’s additional input to the computation circuit. In particular, the
circuit returns fB(xA, xB) ⊕ padB as Bob’s output, and the padB itself is only
revealed in the ﬁnal step of the protocol. Alice’s output in the circuit is also
encrypted using a separate pad padA of her choice, to prevent Bob from learning
her output even after the opening.

Commit to the Consistent Pad. Note that simply revealing the padB to
Bob does not provide Bob with suﬃcient guarantee that it is the same padB
Alice used in the computation. Hence, for each circuit Alice sends a trapdoor
commitment cB
i to the translation table PadDeci for the input wires associated
with padB. She also encrypts the opening of this commitment as dB
i using the
Arbiter’s public key, and signs it for resolution purposes. For the opened circuits,
cB
i and dB
i are opened and checked. In the ﬁnal stage, in order to reveal padB,
Alice opens cB
for the evaluated circuits. But, we are not done yet. Bob learns one
i
or more pad values used in the evaluation circuits, and needs to determine which
is the correct one for decrypting his output. To facilitate this, we apply a separate
UH to padB (i.e. Mp · (padB(cid:107)rp) for a random matrix Mp) in the computation
circuits, which Bob uses in the ﬁnal stage to determine the “correct” pad among
those retrieved. Without this, we could not have guaranteed correctness.

Simulate with Fairness. For simulation purposes, similar to the fair covert
2PC, the fact that the simulator can open cB
to an arbitrary pad in the ﬁnal
i
stage allows the simulation to go through by postponing the query to the ideal
trusted party for obtaining the output, until we are sure both parties can learn
the output. Remember that such a simulation is a necessity for simulating fair
secure computation protocols properly [31].

Commit to Alice’s Output Early. Similar to the fair covert 2PC, we
also need to ensure that if Alice aborts before revealing padB, Bob has enough
information to invoke an output resolution protocol with the Arbiter and show
evidence that he has been following the steps of the protocol. In the covert
protocol, we used the output-authenticity property of the garbling scheme for
this purpose, but in the current protocol, output-authenticity is lost after the

opening stage, since all circuits use the same output labels. To circumvent this
issue, we have Bob commit to the output labels for Alice’s output before the
opening stage, and have Alice sign the commitment. In case of a resolution, Bob
opens the signed commitment for the Arbiter, who checks its correctness and
consistency with a signed translation table provided by Alice, and only then
decrypts dB

i escrows for Bob to learn the pads and obtain his output.

Fix Cheating-Detection. Note that in regular cheating-detection, Bob
only learns xA and hence the plaintext version of Alice’s output fA(xA, xB).
But, Bob needs to commit to the output labels for Alice’s output, and because
the output translation table of Alice corresponds to a padded output, knowing
fA(xA, xB) is not suﬃcient for simulation. Therefore, we need to modify the CD
circuit as well. We ﬁx this by having the CD circuit also output padA. Bob can
now compute fA(xA, xB)⊕padA, and use Alice’s output translation table GDecA
to determine which evaluated circuit returned the correct output (we know there
is at least one such circuit with all but negligible probability). He commits to
those labels as Alice’s output labels.

Proof overview. Our proofs are very similar in essence to the above ma-
licious Bob case. Simulator Alice would commit to and encrypt random values,
and later when she obtains the actual output from the ideal trusted party, she
would simulate opening them to the correct values. For malicious Alice case, sim-
ulator Bob also commits to random labels for Alice’s outputs, and later simulates
opening them to proper labels.

3 Preliminaries
Bellare et al. [13] introduce the notion of a garbling scheme Garble as a crypto-
graphic primitive. Besides the standard privacy guarantees, we heavily take ad-
vantage of the output-authenticity of a garbling scheme, which intuitively guar-
antees that the evaluator cannot forge valid output labels except by honestly
evaluating the garbled circuit.

In a standard oblivious transfer (OT) protocol [56], the receiver has a selec-
tion bit σ, and the sender has two messages a0, a1. At the end of the protocol,
the receiver learns aσ while the sender does not learn anything. In a commit-
ting oblivious transfer [34,59], at the end of the interaction, the receiver also
receives a commitment to the sender’s input messages, and the sender obtains
the opening to those commitments. As a result, the receiver can ask the sender
to open his messages at a later stage. Eﬃcient constructions for committing OT
were proposed in [59] and [52].

The optimistic fair exchange literature includes many implementation
details we skip here for the sake of clarity (see e.g. [5,42,41]). If Alice already
registered her signature veriﬁcation key with the Arbiter, our protocol can be
employed as is. But, if we want anonymity, then the Arbiter must have a way
of obtaining this veriﬁcation key. The standard mechanism is to put it into the
label of a labeled encryption scheme. In our case, Alice can generate a new key
pair for each computation (or even circuit) and put the veriﬁcation key into the
label of dB
i encryptions, and Bob can verify the signatures using this veriﬁcation
key. The Arbiter can then also use this key for veriﬁcation. Details such as these

and how to handle timeouts without tight synchronization are well-discussed in
the previous work [5,43,39,38], and hence we do not repeat for the sake of space.

4 Protocols
Due to the page limitations, we defer the security deﬁnitions of ideal and real
worlds for fair secure two party computation, as well as full security proofs via
simulation to the full version [63]. Both protocols remain secure in the unfair
sense even if the Arbiter actively cheats and colludes with one of the parties.

In Figures 1 and 2 we provide a full description of our fair covert 2PC,
and Figure 7 and 8 show the resolutions with the Arbiter for Bob and Alice,
respectively. Figures 3, 4, 5, and 6 describe the full protocol fairly secure against
malicious parties, and Figures 9 and 10 show the resolutions with the Arbiter
for Bob and Alice, respectively. The vertical lines in the ﬁgures represent parts
that would not have existed in the unfair counterpart. Tables 2 and 3 summarize
the overhead of adding fairness in covert and malicious protocols, respectively.

Extra Rounds Extra Messages’ Size Operation Type

1

O(sm)

Public Key

Table 2. Overhead for fairness (Covert). Round is a single message. s is the statistical
security parameter, m is Bob’s output length.

Extra Rounds Extra Input Length Extra Messages’ Size Operation Type

3

O(m + t)

O(s(m + t))

Public Key

Table 3. Overhead for fairness (Malicious). Round is a single message. s is the sta-
tistical security parameter, m is the output length, t is a security parameter for input
consistency.
References
1. M. Andrychowicz, S. Dziembowski, D. Malinowski, and (cid:32)L. Mazurek. Fair two-party

computations via bitcoin deposits. In FC, 2014.

2. M. Andrychowicz, S. Dziembowski, D. Malinowski, and L. Mazurek. Secure mul-

tiparty computations on bitcoin. In IEEE Security and Privacy, 2014.

3. G. Asharov. Towards characterizing complete fairness in secure two-party compu-

tation. In TCC, 2014.

4. G. Asharov and C. Orlandi. Calling out cheaters: Covert security with public

veriﬁability. In ASIACRYPT, 2012.

5. N. Asokan, V. Shoup, and M. Waidner. Optimistic fair exchange of digital signa-

tures. IEEE Selected Areas in Communications, 18:591–610, 2000.

6. G. Ateniese. Eﬃcient veriﬁable encryption (and fair exchange) of digital signatures.

In ACM CCS, 1999.

7. Y. Aumann and Y. Lindell. Security against covert adversaries: Eﬃcient protocols

for realistic adversaries. Journal of Cryptology, 23:281–343, 2010.

8. G. Avoine and S. Vaudenay. Optimistic fair exchange based on publicly veriﬁable

secret sharing. In ACISP, 2004.

9. F. Bao, R. Deng, and W. Mao. Eﬃcient and practical fair exchange protocols with

oﬀ-line ttp. In IEEE Security and Privacy, 1998.

10. A. Beimel, Y. Lindell, E. Omri, and I. Orlov. 1/p-Secure multiparty computation

without honest majority and the best of both worlds. In CRYPTO, 2011.

11. A. Beimel, E. Omri, and I. Orlov. Protocols for multiparty coin toss with dishonest

majority. In CRYPTO, 2010.

Alice’s input: xA ∈ {0, 1}(cid:96). Bob’s input: xB ∈ {0, 1}(cid:96).
Common input: Alice and Bob agree on the description of a circuit C, where
C(xA, xB) = f (xA, xB) = (fA(xA, xB), fB(xA, xB)), and a second-preimage resis-
tant hash function H : {0, 1}∗ → {0, 1}(cid:96).
s is a statistical security parameter that is inversely proportional to the bound on
the cheating probability. L is a computational security parameter, so, for example,
each key label is L-bits long. Let TCommit(·) be a trapdoor commitment scheme.
Setup: Let (P KT , SKT ) be the Arbiter’s key pair for a public key encryption, and
(SKA, V KA) be the signing-veriﬁcation key-pair for a digital signature scheme for
Alice. At the beginning of the protocol, both parties obtain the Arbiter’s public
key from the Arbiter. Alice sends her veriﬁcation key to Bob and the Arbiter.
Output: Alice learns an m-bit string fA(xA, xB) and Bob learns an m-bit string
fB(xA, xB).

be the decoding table for Bob’s

)(cid:9)m

Alice Prepares the Garbled Circuits.
1. For 1 ≤ i ≤ s, Alice computes GCi ← Garble(C).
2. Let inA,i,j

b

denote the key for bit b for Alice’s jth input wire in the ith garbled
is deﬁned similarly for

circuit for b ∈ {0, 1}, 1 ≤ i ≤ s, and 1 ≤ j ≤ (cid:96). inB,i,j
Bob’s input labels.

b

3. Let outA,i,j

b

denote the key for bit b for Alice’s jth output wire in the ith

garbled circuit. outB,i,j

is used for Bob’s output labels.

b

i = (cid:8)outB,i,j

(cid:9)m
i = (cid:8)H(outA,i,j

, outB,i,j

0

1

j=1

4. Alice lets GDecB

output.

5. Alice computes GDecA

6. She computes cB

j=1

bi,j

), H(outA,i,j¬bi,j

i = TCommit(GDecB

for random bits bi,j
as the output validity-checking table for her output. [This table is randomly
permuted based on the bits bi,j such that in case of output resolution, the
Arbiter can check validity of output labels without learning their actual value.]
i ) as the commitment to Bob’s output
decoding table. Let GDecOpenB
i be the opening of this commitment. She en-
crypts this opening as dB
i ) using the Arbiter’s public
key. [GDecA
i will be used by the Arbiter to verify Bob’s honesty, and
give back Bob’s output decoding table, respectively. cB
i will be employed by
Bob to ensure that Alice behaves honestly at the last step. Note that GDecA
i
is computed using a second-preimage resistant hash function, whereas cB
is
i
computed via trapdoor commitments.]

i = EP KT (GDecOpenB

i and dB

7. Alice signs those as σi = Sign(SKA, (sid, GDecA

i )). [This signature will tie
the two decryption tables to the same circuit, and be checked by the Arbiter.
sid is the unique session identiﬁer.]

i , dB

Oblivious Transfer for Bob’s Input.
1. Alice and Bob engage in (cid:96) committed OTs, where in the jth OT, Bob’s input is
, . . . , inB,s,j
]
]. As a result, Bob learns inB,i,j
xB,j

xB,j and Alice input is a pair where the ﬁrst component is [inB,1,j
and the second component is [inB,1,j
for 1 ≤ i ≤ s, 1 ≤ j ≤ (cid:96).
Alice Sends the Circuits.

, . . . , inB,s,j

1. Alice sends(cid:8)GCi, GDecA

(cid:9)s

to Bob.

i , cB

i , dB
i

0

0

1

1

i=1

Fig. 1. Optimistic Fair Covert 2PC

OT-based Challenge Generation.
1. Bob picks a random challenge index e, lets be = 0, and bi = 1 for all i (cid:54)= e.
2. Alice and Bob run s OTs where Bob’s input (as the receiver) in the ith OT
is bi while Alice (as the sender) inputs a pair where the ﬁrst component is
her garbled inputs {inA,i,j
}(cid:96)
j=1 along with σi, and the second component is
the openings for GCi, GDecA
i , cB
i and the input and randomness she used
in the ith committed OT above. In other words, for i (cid:54)= e Bob learns openings
for everything about the circuits, and for i = e he learns Alice’s input labels
and her signature.

i , dB

XA,j

Bob Veriﬁes Check Circuits.
1. For i (cid:54)= e, Bob uses the openings he obtained in the challenge generation phase
i both

to check the correctness of GCi. He veriﬁes the consistency of cB
of which he has openings for. He checks that GDecB
i

is consistent with GCi.

i with dB

2. For i = e, he veriﬁes the signature σe.

Bob Evaluates.
1. Note that Bob has Alice’s input labels for the eth circuit via the OT-based
challenge generation and his own input labels via the committed OT. He eval-
uates GCe.

Output Exchange.

1. Bob tells Alice that he is done with the evaluation.
2. Alice responds by sending σt = Sign(SKA, (sid, deadline)). Bob checks the
timeout and the session identiﬁer are consistent with the agreed upon values,
and aborts otherwise.

3. Denote the labels for Alice’s output by (cid:8)outA,e,j

. Bob sends these to
Alice, along with σe so that Alice will learn the evaluated circuit identiﬁer e,
and then she translates them to her actual output on her own. If Alice does
not receive the correct labels in time, she contacts the Arbiter for resolution.
e , which Bob uses to decode his
actual output. If Bob does not receive the correct decoding table in time, he
contacts the Arbiter for resolution.

e to the decoding table GDecB

4. Alice opens cB

(cid:9)m

outA,j

j=1

Fig. 2. Optimistic Fair Covert 2PC (cnt’d)

Alice’s input: xA ∈ {0, 1}(cid:96). Bob’s input: xB ∈ {0, 1}(cid:96).
Common input: Alice and Bob agree on the description of a circuit C, where
C(xA, xB) = f (xA, xB) = (fA(xA, xB), fB(xA, xB)), and a second-preimage resis-
tant hash function H : {0, 1}∗ → {0, 1}(cid:96).
s is a statistical security parameter that represents the bound on the cheating
probability. L is a computational security parameter, so, for example, each key
label is L-bits long. s(cid:48) is a statistical security parameter associated with the input-
consistency matrix. Let t = 2s(cid:48) + log s(cid:48), and (cid:96)(cid:48) = 2m + (cid:96) + 2t.
Let TCommit(·) be a trapdoor commitment scheme, and Commit(·) be a regular
commitment scheme.

Fig. 3. Optimistic Fair Malicious 2PC Inputs

Setup: Let (P KT , SKT ) be the Arbiter’s key pair for a public key encryption, and
(SKA, V KA) be the signing-veriﬁcation key-pair for a digital signature scheme for
Alice. At the beginning of the protocol, both parties obtain the commitment pa-
rameters, and the Arbiter’s public key from the Arbiter. Alice sends her veriﬁcation
key to Bob and the Arbiter.
Output: Alice learns an m-bit string outA = fA(xA, xB) and Bob learns an m-bit
string outB = fB(xA, xB).

Alice Prepares Input/Output Labels.
1. Alice chooses s PRF seeds sdA

1 , . . . , sdA

b

.

i

1 , . . . , sd(cid:48)A

1 ), . . . , Commit(sdA

3. Alice chooses inA,i,j

2. Alice chooses rx, rp ∈R {0, 1}t, padA, padB ∈R {0, 1}m and sets xC

i . Similarly, she chooses 3s PRF seeds sd(cid:48)A

s , and commits to them using
Commit(sdA
s ). All the randomness Alice will use for gen-
erating the ith garbled computation circuit and its input labels will be derived
from sdA
3s , and commits to
them, where the randomness she uses for generating the ith garbled cheating-
detection (CD) circuit and its input labels will be derived from sd(cid:48)A
padB(cid:107)rp(cid:107)xA(cid:107)padA(cid:107)rx. She will be using xC
circuits instead of xA. We denote the jth bit of xC

A =
A as her input to the computation
∈R {0, 1}L for b ∈ {0, 1}, 1 ≤ i ≤ s and 1 ≤ j ≤ (cid:96)(cid:48) . inA,i,j
would be the b-key for Alice’s jth input wire in the ith computation garbled
circuit.
)) for 1 ≤ i ≤ s, i.e. commitments to
encoding of her inputs. This is intended to commit Alice to her inputs before
the matrices associated with input-consistency are chosen.
A = xA(cid:107)padA(cid:107)rx. She chooses
random labels for the associated input wires in the CD circuits and commits
to the encoding of her inputs as she did for the computation circuits.
∈R {0, 1}L for j ∈ {1, . . . , m} and b ∈ {0, 1}. Similarly,
∈ {0, 1}L. These correspond to labels for output wires corre-
b
she chooses W B,j
sponding to Alice’s and Bob’s output (padded with Alice’s pads), respectively,
and unlike the covert protocol, will be the same across all s circuits.

5. Alice lets her input to the CD circuit be xCD

4. Alice sends Commit(H(inA,i,1

(cid:107)···(cid:107)inA,i,(cid:96)(cid:48)
xC
A,(cid:96)(cid:48)

6. Alice chooses W A,j

A by xC

A,j.

xC

A,1

b

be the decoding table for Bob’s

)(cid:9)m

b

7. Alice lets GDecB =(cid:8)H(W B,j
)(cid:9)m
output. She also lets GDecA =(cid:8)H(W A,j
(cid:9)m+t
8. Alice lets PadDeci =(cid:8)inA,i,j

), H(W B,j

, inA,i,j

0

1

j=1

. The translation table
for other outputs of the circuit (i.e. outputs of the UH functions) will be created
in the standard way and with diﬀerent labels for each circuit.

j=1

0

1

), H(W A,j

1

0

for the ith circuit (note that the ﬁrst
m+t input wires are associated with Alice’s padB and rp). This is essentially a
decoding table for input wires for Alice’s padB and rp. Alice then commits to
this table cB
i = TCommit(PadDeci) using the trapdoor commitment scheme,
and encrypts its opening as dB
i = EP KT (PadDecOpeni) using the Arbiter’s
public key.

j=1

Fig. 4. Optimistic Fair Malicious 2PC

Alice Prepares the Garbled Circuits.

choose

1. Alice

and Bob jointly

random binary matrices Mx

∈R
{0, 1}s(cid:48)×(cid:96)+m+t, Mp ∈R {0, 1}s(cid:48)×m+t. Let C(cid:48)(xC
A, xB) = (fA(xA, xB) ⊕
padA, (fB(xA, xB) ⊕ padB, Mx · (xA(cid:107)padA(cid:107)rx), Mp · (padB||rp))). In other
words, the circuit pads Alice and Bob’s output with separate pads generated
by Alice, and also outputs the result of applying the Mx and Mp to xA and
padB for input-consistency checks.
2. For 1 ≤ i ≤ s, Alice computes GCi ← Garble(C(cid:48)) with the consideration that

she uses the input and output labels she generated above for the garbling.
3. Denote by CD the cheating detection circuit. Alice’s input to this circuit is
A = xA(cid:107)padA(cid:107)rx. Bob’s input is an L-bit string pc, his (potential) proof
xCD
(cid:9)m
of Alice’s cheating. CD’s computation is as outlined in Lindell [45] with the
exception that in case of detected cheating xA and padA are both revealed to

Bob. In particular, CD has the labels(cid:8)W B,j

and(cid:8)W A,j

j=1
embedded in it and checks whether pc is the XOR of the 0-key and the 1-key
for any of the wires. If so, it outputs to Bob xA(cid:107)padA . Otherwise, it outputs
a random string. CD also outputs Mx · (xA(cid:107)padA(cid:107)rx) to Bob. Alice has no
output.
4. For 1 ≤ i ≤ 3s, Alice computes GCDi ← Garble(CD) with the consideration
that she uses the input labels she generated above for garbling. The translation
tables for GCDi are generated in the standard way.

(cid:9)m

, W B,j

, W A,j

j=1

0

1

0

1

Oblivious Transfer for Bob’s Input to Computation Circuits. Alice and
Bob engage in (cid:96) committed OTs, where in the jth OT, Bob’s input is xB,j and
Alice’s input is a pair where the ﬁrst component is [inB,1,j
] and the
xB,j for 1 ≤ i ≤
second component is [inB,1,j
s, 1 ≤ j ≤ (cid:96).

Alice Sends the Garbled Circuits. Alice sends (cid:8)GCi, cB
session identiﬁer). She also sends(cid:8)GCDi}3s

i=1 and GDecA,
GDecB, and σoutA = Sign(SKA, (sid, GDecA)) to Bob (where sid is the unique
i=1 and the associated output translation

]. As a result, Bob learns inB,i,j

, . . . , inB,s,j

, . . . , inB,s,j

i }s

i , dB

0

0

1

1

tables.

Challenge Generation. Alice and Bob jointly run a simulatable coin-toss to
generate a uniformly random s-bit string b and a uniformly random 3s-bit string
b(cid:48). Deﬁne the evaluation set E where i ∈ E if and only if bi = 0, and the evaluation
set E(cid:48) similarly with respect to b(cid:48). Both parties learn E and E(cid:48). Circuits are not
opened immediately, though.
Bob Evaluates Computation Circuits in E.
1. Alice sends her garbled input labels for xC

A for all GCi, i ∈ E, by open-
ing the commitments she made to them earlier. Alice also sends σi,pad =
i )) for i ∈ E. Bob uses these input labels and those of his
Sign(SKA, (sid, dB
own from the committed OTs to evaluate all GCi where i ∈ E.

oB,1 , . . . , W B,m

2. If there is at least one circuit with a valid output, and all circuits
with a valid output return the same output labels W A,1
oA,m and
W B,1
oA,m ). Note that
through these, Bob can learn oA = outA ⊕ padA and oB = outB ⊕ padB, but
since he does not know the pads, these are useless. Bob lets pc be a random
L-bit string.

oB,m , Bob lets CA = TCommit(W A,1

oA,1 , . . . , W A,m

oA,1 , . . . , W A,m

3. If there are at least two circuits with valid but diﬀerent outputs, Bob chooses
the ﬁrst output wire with diﬀerent labels and denotes the two labels by W
and W (cid:48). pc = W ⊕ W (cid:48) will constitute Bob’s input to the cheating detection
circuits.

4. If all circuits are evaluated to invalid output labels (i.e. the obtained labels
are not consistent with GDecA and GDecB) or if the output of the UHs in any
two circuits are diﬀerent Bob does not abort (until after the opening stage)
but instead commits to a random string of appropriate length in CA.

Fig. 5. Optimistic Fair Malicious 2PC (cnt’d)

Evaluating Cheating-Detection Circuits in E(cid:48).
1. Alice and Bob engage in L committed OTs, where in the jth OT, Bob’s input is
pcj and Alice’s input is a pair where the ﬁrst component is the 3s input labels
corresponding to 0 and the second component is the 3s labels corresponding
to 1.
A for GCDi where i ∈ E(cid:48), by opening
2. Alice sends her garbled input labels for xCD
the commitments she made to them earlier.
3. Bob uses the input labels to evaluate all GCDi with i ∈ E(cid:48), and uses the
translation tables to translate to plaintext outputs. If any two UH outputs are
diﬀerent or if they are diﬀerent from those output in the computation circuits
Bob postpones aborting until the opening stage, commits to a random string
of appropriate length for CA.
4. Else, he considers the majority output as the correct output. If Bob had a valid
proof of cheating pc, he learns xA(cid:107)padA. He computes oA = fA(xA, xB)⊕padA
from the evaluation circuits that is
consistent with GDecA and oA, and lets CA = TCommit(W A,1
oA,1 , . . . , W A,m
oA,m )
(with high probability there is at least one). [Note that in case Alice’s opening
of the check circuits are problematic, Bob will never decommit anyways.]

on his own. He then chooses a(cid:8)W A,j

(cid:9)m

oA,j

j=1

Bob Commits to Alice’s Garbled Output.

1. Bob sends CA as his commitment to Alice’s output labels.
2. Alice sends back σoA = Sign(SKA, (sid, deadline, CA)). Bob can use this in
case of resolution to prove to the Arbiter that he computed Alice’s output
honestly.

Alice Opens Everything for Check Circuits.
1. For i /∈ E, Alice opens sdA

i to open all secrets of GCi. She also opens cB

i , dB
i ,
and the randomness used in committed OTs for Bob’s input. Bob checks cor-
rectness of opened circuits and their consistency with GDecA, GDecB. He also
veriﬁes correctness cB
i and the opened PadDeci. He aborts if any of the
checks fail.

i , dB
2. For i /∈ E(cid:48), Alice opens sd(cid:48)A

to open all secrets of GCDi. He also reveals the ran-
domness used in committed OTs for Bob’s input. Bob checks the correctness
of the opened circuits and the OTs, and aborts in case of a fail.

i

Output Exchange.

2. Alice opens cB
i

1. Bob opens CA to Alice’s output labels. Alice translates these to her actual
output outA using padA and the translation table, on her own. In case of a
problem, Alice resolves with the Arbiter.
for i ∈ E. This allows Bob to learn the values Alice used
for padB, rp in all evaluated circuits. For each such value he computes Mp ·
(padB(cid:107)rp) and checks if the result is equal to the unique UH output he obtained
when evaluating the circuits. He chooses a pad meeting this requirement and
uses it to decode his ﬁnal output outB. In case of a problem, Bob resolves with
the Arbiter.

Fig. 6. Optimistic Fair Malicious 2PC (cnt’d)

output i.e.(cid:8)outA,e,j

1. Bob sends GDecA

e , dB
outA,j

(cid:9)m

.

j=1

e , σe, σt to the Arbiter. He also sends labels for Alice’s

2. The Arbiter veriﬁes the signatures, checks that the time is earlier than the
deadline in σt and the session identiﬁers are matching. He also makes sure
outA,e,j
e . Essentially, one output label per
outA,j
pair must be provided. He aborts if any of the checks fail.

values are consistent with GDecA

3. In case of no fails, the Arbiter decrypts dB

e and sends GDecOpenB

e to Bob. He

stores(cid:8)outA,e,j

(cid:9)m

outA,j

j=1

for Alice.

4. Bob checks that GDecOpenB

e is the correct opening for cB

e ,a and uses GDecB

e in

the opening to translate his output labels to actual outputs.

aThis check is necessary against potentially malicious Arbiter to preserve cor-

rectness.

Fig. 7. Resolution for Bob (for Optimistic Fair Covert 2PC)

1. If Alice contacts the Arbiter before the timeout and Bob has not contacted the

Arbiter yet, the Arbiter tells Alice to come after the timeout.

2. If Alice contacts the Arbiter after the timeout and Bob has not contacted the

Arbiter yet, the protocol is aborted and no party obtains the actual output.

3. Else (Bob already contacted the Arbiter and resolved), the Arbiter sends
obtained via Bob’s resolution to Alice (after making sure she
is the same Alice, e.g. by asking for the input to a one way function whose
output was in the associated signature given by Bob, see e.g. [5]).

outA,j

(cid:9)m

(cid:8)outA,e,j
4. Alice translates(cid:8)outA,e,j

j=1

(cid:9)m

outA,j

j=1

to actual outputs on her own.

Fig. 8. Resolution for Alice (for Optimistic Fair Covert 2PC)

1. Bob sends GDecA, σGDecA , CA, σoA to the Arbiter. He also sends dB

all i ∈ E to the Arbiter. He also opens CA to W A,j

oA,1 , . . . , W A,j

oA,m .

i , σi,pad for

oA,1 , . . . , W A,j

3. In case of no fails, the Arbiter decrypts dB
i

2. The Arbiter veriﬁes the signature, checks that the time is earlier than the dead-
line in the signature and the session identiﬁers match. He also makes sure the
opened values W A,j
oA,m are consistent with CA and GDecA. Essentially,
one output label per pair must be provided. He aborts if any of the checks fail.
for i ∈ E and sends PadDecOpeni
i , for i ∈ E, and then
uses PadDeci values to obtain his actual output outB as in the last step of the
main protocol.

oA,m for Alice.
is the correct opening for cB

4. Bob checks that PadDecOpenB
i

to Bob. He stores W A,1

oA,1 , . . . , W A,m

Fig. 9. Resolution for Bob (for Optimistic Fair Malicious 2PC)

1. If Alice contacts the Arbiter before the timeout and Bob has not contacted the

Arbiter yet, the Arbiter tells Alice to come after the timeout.

2. If Alice contacts the Arbiter after the timeout and Bob has not contacted the

Arbiter yet, the protocol is aborted and no party obtains the actual output.

3. Else (Bob already contacted the Arbiter and resolved), the Arbiter sends

W A,1

oA,1 , . . . , W A,m

oA,m obtained via Bob’s resolution to Alice.

4. Alice translates W A,1

oA,1 , . . . , W A,m

oA,m to her actual outputs on her own.

Fig. 10. Resolution for Alice (for Optimistic Fair Malicious 2PC)

12. M. Belenkiy, M. Chase, C. Erway, J. Jannotti, A. K¨up¸c¨u, A. Lysyanskaya, and

E. Rachlin. Making p2p accountable without losing privacy. In WPES, 2007.
13. M. Bellare, V. T. Hoang, and P. Rogaway. Foundations of garbled circuits.

In

ACM CCS, 2012.

14. M. Ben-Or, O. Goldreich, S. Micali, and R. L. Rivest. A fair protocol for signing

contracts. IEEE Transactions on Information Theory, 36:40–46, 1990.

15. I. Bentov and R. Kumaresan. How to use bitcoin to design fair protocols.

In

CRYPTO, 2014.

16. F. Boudot, B. Schoenmakers, and J. Traor´e. A fair and eﬃcient solution to the so-
cialist millionaires’ problem. Discrete Applied Mathematics, 111(1-2):23–36, 2001.
17. L. T. Brand˜ao. Secure two-party computation with reusable bit-commitments, via

a cut-and-choose with forge-and-lose technique. In ASIACRYPT, 2013.

18. C. Cachin and J. Camenisch. Optimistic fair secure computation. In CRYPTO,

2000.

19. R. Canetti. Universally composable security: A new paradigm for cryptographic

protocols. In FOCS, 2001.

20. R. Cleve. Limits on the security of coin ﬂips when half the processors are faulty.

In STOC, 1986.

21. Y. Dodis, P. J. Lee, and D. H. Yum. Optimistic fair exchange in a multi-user

setting. In PKC, 2007.

22. C. Dong, L. Chen, J. Camenisch, and G. Russello. Fair private set intersection

with a semi-trusted arbiter. In DBSec, 2013.

23. T. K. Frederiksen, T. P. Jakobsen, J. B. Nielsen, P. S. Nordholt, and C. Orlandi.
In

Minilego: Eﬃcient secure two-party computation from general assumptions.
EUROCRYPT, 2013.

24. S. Gordon and J. Katz. Partial fairness in secure two-party computation. Journal

of Cryptology, 25(1):14–40, 2012.

25. S. D. Gordon, C. Hazay, J. Katz, and Y. Lindell. Complete fairness in secure

two-party computation. Journal of ACM, 58, 2011.

26. S. D. Gordon and J. Katz. Partial fairness in secure two-party computation. In

EUROCRYPT, 2010.

27. Y. Huang, J. Katz, and D. Evans. Eﬃcient secure two-party computation using

symmetric cut-and-choose. In CRYPTO, 2013.

28. J. Katz. On achieving the best of both worlds in secure multiparty computation.

In STOC, 2007.

29. J. Katz, U. Maurer, B. Tackmann, and V. Zikas. Universally composable syn-

chronous computation. In TCC, 2013.

30. A. Kiayias, H.-S. Zhou, and V. Zikas. Fair and robust multi-party computation
using a global transaction ledger. Cryptology ePrint Archive, Report 2015/574,
2015.

31. H. Kılın¸c and A. K¨up¸c¨u. Eﬃciently making secure two-party computation fair. In

FC, 2016.

32. H. Kılın¸c and A. K¨up¸c¨u. Optimally eﬃcient multi-party fair exchange and fair

secure multi-party computation. In CT-RSA, 2015.

33. M. S. Kiraz and B. Schoenmakers. An eﬃcient protocol for fair secure two-party

computation. In CT-RSA, 2008.

34. M. S. Kiraz, B. Schoenmakers, and J. Villegas. Eﬃcient committed oblivious

transfer of bit strings. In ISC, 2007.

35. V. Kolesnikov, P. Mohassel, and M. Rosulek. Flexor: Flexible garbling for XOR

gates that beats free-XOR. In CRYPTO, 2014.

36. V. Kolesnikov and T. Schneider.

Improved garbled circuit: Free xor gates and

applications. In Automata, Languages and Programming, pages 486–498, 2008.

37. A. Kosba, A. Miller, E. Shi, Z. Wen, and C. Papamanthou. Hawk: The blockchain
model of cryptography and privacy-preserving smart contracts. Cryptology ePrint
Archive, Report 2015/675, 2015.

38. A. K¨up¸c¨u. Eﬃcient Cryptography for the Next Generation Secure Cloud. PhD

thesis, Brown University, 2010.

39. A. K¨up¸c¨u. Eﬃcient Cryptography for the Next Generation Secure Cloud: Protocols,

Proofs, and Implementation. Lambert Academic Publishing, 2010.

40. A. K¨up¸c¨u. Distributing trusted third parties. ACM SIGACT News Distributed

Computing Column, 44:92–112, 2013.

41. A. K¨up¸c¨u and A. Lysyanskaya. Optimistic fair exchange with multiple arbiters.

In ESORICS, 2010.

42. A. K¨up¸c¨u and A. Lysyanskaya. Usable optimistic fair exchange. In CT-RSA, 2010.
43. A. K¨up¸c¨u and A. Lysyanskaya. Usable optimistic fair exchange. Computer Net-

works, 56:50–63, 2012.

44. Y. Lindell. Legally-enforceable fairness in secure two-party computation. In CT-

RSA, 2008.

45. Y. Lindell. Fast cut-and-choose based protocols for malicious and covert adver-

saries. In CRYPTO, 2013.

46. Y. Lindell and B. Pinkas. A proof of yaos protocol for secure two-party computa-

tion. ECCC, 2004.

47. Y. Lindell and B. Pinkas. An eﬃcient protocol for secure two-party computation

in the presence of malicious adversaries. In EUROCRYPT, 2007.

48. Y. Lindell and B. Pinkas. Secure two-party computation via cut-and-choose obliv-

ious transfer. In TCC, 2011.

49. S. Micali. Simple and fast optimistic protocols for fair electronic exchange.

In

PODC, 2003.

50. P. Mohassel and M. Franklin. Eﬃcient polynomial operations in the shared-

coeﬃcients setting. In PKC, 2006.

51. P. Mohassel and M. K. Franklin. Eﬃciency tradeoﬀs for malicious two-party com-

putation. In PKC, 2006.

52. P. Mohassel and B. Riva. Garbled circuits checking garbled circuits: More eﬃcient

and secure two-party computation. In CRYPTO, 2013.

53. T. Moran, M. Naor, and G. Segev. An optimally fair coin toss. In TCC, 2009.
54. J. B. Nielsen, P. S. Nordholt, C. Orlandi, and S. S. Burra. A new approach to

practical active-secure two-party computation. In CRYPTO, 2012.

55. B. Pinkas. Fair secure two-party computation. In EUROCRYPT, 2003.
56. M. O. Rabin. How to exchange secrets with oblivious transfer. IACR Cryptology

ePrint Archive, 2005:187, 2005.

57. O. Ruan, J. Chen, J. Zhou, Y. Cui, and M. Zhang. An eﬃcient fair uc-secure
protocol for two-party computation. Security and Communication Networks, 2013.
58. O. Ruan, J. Zhou, M. Zheng, and G. Cui. Eﬃcient fair secure two-party compu-

tation. In IEEE APSCC, 2012.

59. A. Shelat and C.-H. Shen. Two-output secure computation with malicious adver-

saries. In EUROCRYPT, 2011.

60. A. Shelat and C.-H. Shen. Fast two-party secure computation with minimal as-

sumptions. In ACM CCS, 2013.

61. A. C.-C. Yao. How to generate and exchange secrets. In FOCS, 1986.
62. S. Zahur, M. Rosulek, and D. Evans. Two halves make a whole. In EUROCRYPT,

2015.

63. Alptekin Kupcu and Payman Mohassel. Fast Optimistically Fair Cut-and-Choose

2PC. Cryptology ePrint Archive, Report 2015/1209.

