EASEAndroid: Automatic Policy Analysis and 
Refinement for Security Enhanced Android via 

Large-Scale Semi-Supervised Learning

Ruowen Wang, Samsung Research America and North Carolina State University;  

William Enck and Douglas Reeves, North Carolina State University; Xinwen Zhang,  

Samsung Research America; Peng Ning, Samsung Research America and North Carolina State 

University; Dingbang Xu, Wu Zhou, and Ahmed M. Azab, Samsung Research America
https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/wang-ruowen

This paper is included in the Proceedings of the 24th USENIX Security SymposiumAugust 12–14, 2015 • Washington, D.C.ISBN 978-1-931971-232Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXEASEAndroid: Automatic Policy Analysis and Reﬁnement for Security

Enhanced Android via Large-Scale Semi-Supervised Learning

Ruowen Wang1,2 William Enck2 Douglas Reeves2
Peng Ning1,2

Dingbang Xu1

Wu Zhou1

Xinwen Zhang1
Ahmed M. Azab1

1Samsung KNOX R&D, Samsung Research America

{peng.ning, xinwen.z1, dingbang.xu, wu1.zhou, a.azab}@samsung.com

2Department of Computer Science, NC State University

{rwang9, whenck, reeves, pning}@ncsu.edu

Abstract
Mandatory protection systems such as SELinux and SE-
Android harden operating system integrity. Unfortu-
nately, policy development is error prone and requires
lengthy reﬁnement using audit logs from deployed sys-
tems. While prior work has studied SELinux policy in
detail, SEAndroid is relatively new and has received lit-
tle attention. SEAndroid policy engineering differs sig-
niﬁcantly from SELinux: Android fundamentally differs
from traditional Linux; the same policy is used on mil-
lions of devices for which new audit logs are continu-
ally available; and audit logs contain a mix of benign
and malicious accesses. In this paper, we propose EASE-
Android, the ﬁrst SEAndroid analytic platform for auto-
matic policy analysis and reﬁnement. Our key insight is
that the policy reﬁnement process can be modeled and
automated using semi-supervised learning. Given an ex-
isting policy and a small set of known access patterns,
EASEAndroid continually expands the knowledge base
as new audit logs become available, producing sugges-
tions for policy reﬁnement. We evaluate EASEAndroid
on 1.3 million audit logs from real-world devices. EASE-
Android successfully learns 2,518 new access patterns
and generates 331 new policy rules. During this process,
EASEAndroid discovers eight categories of attack access
patterns in real devices, two of which are new attacks di-
rectly against the SEAndroid MAC mechanism.

1

Introduction

Operating system integrity relies on the correctness of
1) trusted computing base (TCB) code and 2) access con-
trol policy protecting the TCB code and OS resources. It
is generally impractical to verify the correctness of OS
code in commodity systems. Therefore, mandatory ac-
cess control (MAC) policy is often used as a fallback
when the security of the software inevitably fails [29].

SELinux [6] is the most notable MAC policy frame-

work widely used in practice. Security Enhanced An-
droid [38] (known simply as SEAndroid) is a recent port
of SELinux to the Android platform. However, while
Android is based on a Linux kernel, the runtime environ-
ment is vastly different than existing Linux distributions
for commodity PCs. This difference resulted in a com-
plete redesign of the MAC policy rules, with several new
object classes (e.g., for Android’s binder IPC).

As with SELinux, SEAndroid policy development is a
challenging task, requiring many iterations of reﬁnement
to be ready for commercial deployment. For example,
Google introduced a very permissive SEAndroid policy
into Android version 4.3 and did not enable enforcement.
Version 4.4 enabled enforcement, but the policy was still
very permissive, containing only a few system daemons.
Finally, Android version 5.0 provides a much more ro-
bust (but not perfect) version of the policy. Additionally,
major smartphone vendors need to customize Google’s
base SEAndroid policy for their devices to add additional
protections against known attacks.

SEAndroid policy reﬁnement is currently a very man-
ual process that typically involves analyzing audit logs
to identify proposed changes. There are two general ap-
proaches to SEAndroid policy reﬁnement. The ﬁrst ap-
proach is to develop a least privilege [35] policy (also
known as a “strict” policy in SELinux terminology) and
monitor audit logs for access patterns that should be al-
lowed. The second approach is to begin with a more per-
missive policy, reﬁne the policy to prevent (or contain)
privilege escalation attacks and use audit logs to verify
the reﬁnement. Each approach has disadvantages. If the
policy is too strict, it will hurt the usability of deployed
real-world devices. If the policy is too permissive, it will
allow attacks. As a result, smartphone vendors use a
combination of these two approaches.

The goal of our research is to signiﬁcantly reduce the
manual effort required to reﬁne SEAndroid policy using
audit logs. Audit log analysis is challenging for several
reasons. First, audit logs are collected from millions of

USENIX Association  

24th USENIX Security Symposium  351

real-world devices, and purely manual analysis is im-
practical. Second, the audit logs contain both benign
access patterns and malicious access patterns. Existing
SELinux tools such as audit2allow that blindly create
rules to allow all access patterns in audit logs are error
prone. Third, the functionality of both benign applica-
tions and malicious exploits is continually changing/up-
grading, requiring frequent reassessment of the deny/al-
low boundary to reﬁne the policy.

In this paper, we present Elastic Analytics for SEAn-
droid (EASEAndroid) as the ﬁrst large-scale audit log
and policy analytic platform for automatic policy anal-
ysis and reﬁnement of SEAndroid-style MAC policy.
Our key insight is that the policy reﬁnement process can
be modeled and automated using semi-supervised learn-
ing [18], a popular knowledge-base construction tech-
nique [16, 21]. We apply EASEAndroid to a database
of 1.3 million audit logs from real-world Samsung de-
vices running Android 4.3 over the entire year of 2014.1
EASEAndroid correctly discovers 336 new benign ac-
cess patterns and 2,182 new malicious access patterns,
and automatically translates them into 331 policy rules.
The generated rules are consistent with rules manually
added by policy analysts. Among the malicious access
patterns, EASEAndroid further discovers two new types
of attacks in the wild directly targeting SEAndroid MAC
mechanism itself.

This paper makes the following contributions:

• We propose EASEAndroid, a semi-supervised learn-
ing approach for reﬁning MAC policy at large scale.
Our approach scales to millions of audit logs that
contain a mix of benign and malicious access pat-
terns. While we focus on SEAndroid,
the ap-
proach is more broadly applicable to type enforce-
ment (TE) MAC policy.

• We implement a prototype of EASEAndroid to
help policy analysts analyze SEAndroid audit logs.
The implementation generates policy reﬁnements,
and discovers new Android attacks, providing new
knowledge of both benign and malicious access pat-
terns learned from audit logs for policy analysts.

• We evaluate EASEAndroid on 1.3 million audit
logs from real-world Samsung devices. Using this
dataset, EASEAndroid successfully learns 2,518
benign and malicious access patterns and generates
331 policy rules as a reﬁnement. EASEAndroid
also discovers two new types of attacks directly tar-
geting SEAndroid. With the help of EASEAndroid,
this is the ﬁrst large-scale study on real-world mali-
cious access patterns in Android devices.

1See Appendix A for more details about audit log collection.

The remainder of this paper proceeds as follows. Sec-
tion 2 provides background on SEAndroid and semi-
supervised learning. Section 3 deﬁnes the problem ad-
dressed in this paper. Section 4 describes the EASEAn-
droid design. Section 5 evaluates EASEAndroid against
a large database of real-world audit logs. Section 6 dis-
cusses limitations. Section 7 overviews related work.
Section 8 concludes.

2 Background

2.1 SELinux and SEAndroid
SEAndroid is a port of SELinux’s type enforcement (TE)
MAC policy to the Android platform [4]. As such,
SEAndroid enforces mandatory policy on system-level
operations between subjects and objects (e.g., system
calls) [6].
In general, processes are regarded as sub-
jects, whereas ﬁles, sockets, etc. are objects in different
classes. A security context label is assigned to subjects
(or objects) that share the same semantics. Traditionally,
the subject label is called a domain, and the object label
is called a type (nomenclature from DTE [12]). A policy
rule deﬁnes which domain of subjects can operate which
class and type of objects with a set of permissions, such
as open, read, write [28]. For example,

allow app app data file:file {open read}
allows processes with the app domain to open and read
file class objects assigned the app data file type. In
addition to allow rules, SELinux provides neverallow
rules to deﬁne policy invariants for malicious accesses
that should never be allowed. These rules are enforced
at policy compile-time and are necessary due to the com-
plexity of the SELinux policy language.

SEAndroid extends SELinux’s policy semantics to
support Android-speciﬁc functionality, including media-
tion of Binder IPC and assigning security contexts based
on application digital signatures. The goal of SEAndroid
is to reduce the attack surface and limit the damage if any
ﬂaw or vulnerability is exploited causing privilege esca-
lation [38]. This goal is accomplished by conﬁning the
capabilities of different privileged Android applications
and system daemons.

The Android platform is vastly different than tradi-
tional Linux distributions, therefore the SEAndroid pol-
icy rules were created from scratch. While the regular-
ity of Android’s UNIX-level interactions results in a pol-
icy that is less complex than the example SELinux pol-
icy for PCs, the SEAndroid policy is still nontrivial and
error prone. It requires careful understanding of subtle
interactions between different privileged processes.
In
practice, policy development requires continual manual
reﬁnement based on audit logs.

352  24th USENIX Security Symposium 

USENIX Association

type=1400 msg=audit(1399587808.122:14):
avc: denied { entrypoint } pid=285 comm="init"
scontext=u:r:init:s0
tcontext=u:object_r:system_file:s0 tclass=file

type=1300 msg=audit(1399587808.122:14):
syscall=11(execve) success=no exit=-13
items=1 ppid=1 pid=285 uid=0 gid=0
comm="init" exe="/init" subj=u:r:init:s0

type=1302 msg=audit(1399587808.122:14):
item=0 name="/system/etc/install-recovery.sh"
inode=3799 dev=b3:10 mode=0100755
ouid=0 ogid=0 obj=u:object_r:system_file:s0
Listing 1: A denied access event example recorded at the epoch time
1399587808.122 in an audit log. It consists of three entries: labels &
permission (1400), syscall & process info (1300), object info (1302).

An audit log captures security labels and system calls
of the operations that are not explicitly allowed by a
rule. As shown in Listing 1, a denied operation gen-
erally has three entries with epoch timestamps. Log
entries with type=1400 record the denied permission
(e.g., entrypoint), the security labels of the subject
(source), called scontext, and the object (target), called
tcontext, as well as the object’s class, called tclass
(e.g., file). Log entries with type=1300 record the
system call and the subject’s process information, includ-
ing the executable ﬁle path. Log entries with type=1302
record the object information (e.g., the ﬁle name).

Traditionally, policy analysts develop and reﬁne a pol-
icy by manually analyzing audit logs. Existing SELinux
tools such as Tresys’s setools [8] are used to analyze
SEAndroid policies based on interactive user interface.
Analysts also develop simple shell and Python scripts to
parse audit logs. Unfortunately, such tools are not scal-
able to a large number of audit logs, and cannot distin-
guish benign or malicious access patterns in real-world
audit logs. In addition, analysts often use a tool called
audit2allow [9] that can create new allow rules by
directly using the security labels captured in type=1400
entries in audit logs. However, blindly using this tool
may increase attack surface, because in some cases, ex-
isting labels are too coarse-grained or semantically inap-
propriate. Therefore, policy reﬁnement usually consists
of the creation and modiﬁcation of both security labels
and policy rules. Once the policy is reﬁned by analysts,
it is pushed to users’ devices through a secure over-the-
air (OTA) channel, similar to antivirus signature updates.

2.2 Semi-Supervised Learning
Semi-supervised learning is a type of machine learn-
ing that trains on both labeled2 data (used by super-
vised learning) and unlabeled data (used by unsupervised

2Here, labeled and unlabeled are machine learning terms, not re-

lated to security labels.

learning) [18]. It is typically used when labeled data is
insufﬁcient and expensive to collect, and a large set of
unlabeled data is available. By correlating the features
in unlabeled data with labeled data, a semi-supervised
learner infers the labels of the unlabeled instances with
strong correlation. This labeling increases the size of la-
beled data set, which can be used to further re-train and
improve the learning accuracy [44]. This iterative train-
ing process is commonly referred to as bootstrapping.
Semi-supervised learning is popular for information ex-
traction and knowledge base construction. Examples in-
clude NELL [16, 17], Google Knowledge Vault [21].

We hypothesize that the process of developing and re-
ﬁning SEAndroid policy is analogous to semi-supervised
learning. Human analysts encode their knowledge about
various access patterns into a policy. When analyzing
audit logs, analysts ﬁnd semantic correlations between
known and unknown access patterns to infer whether the
unknown ones are benign or malicious, such as a known
malicious subject performing an unseen behavior (likely
malicious), or a system daemon performing a new but
similar functional operation (likely benign). These new
patterns expand analysts’ knowledge and help them re-
ﬁne the policy. However, when more and more logs
are collected containing access patterns about new An-
droid systems and new attacks, manual learning is time-
consuming and likely to miss important knowledge. Our
insight is that semi-supervised learning can automate this
process to achieve scalability in policy reﬁnement.

3 Problem

Reﬁning SEAndroid policy is more challenging than re-
ﬁning SELinux policy. Existing SELinux tools such as
audit2allow are severely limited in their ability to help
policy analysts. This task has the following challenges.

C-1: Consumer devices produce millions of audit logs.
Policy analysts cannot practically analyze audit log
entries manually. A solution must automate or
semi-automate the audit log analysis.

C-2: Real-world audit logs contain a mixture of benign
and malicious accesses. Classifying log entries as
benign or malicious is a central design challenge. It
is often difﬁcult to classify an access in isolation.
Instead, the analysis must look at the broad con-
text of the access, as well as the contexts of related
known accesses.

C-3: Target functionality is not static. The set of benign
and malicious applications continues to evolve as
new software and malware is developed, requiring
continuous audit log analysis and policy reﬁnement.

USENIX Association  

24th USENIX Security Symposium  353

For example, benign software may access new re-
sources, while malware may exploit new vulnera-
bilities to achieve privilege escalation.

We now deﬁne two terms to clarify the discussion in

the remainder of this paper.

Deﬁnition 1 (Access Event). An access event is the ac-
cess control event that causes the three audit log entries
described in Section 2. These log entries may result from
a policy denial, or an auditallow policy rule, which
allows but logs the access.

Note that this deﬁnition does not include allowed ac-

cesses that are not contained in the audit log.

Since audit logs are collected for millions of devices,
the logs contain many duplicate access events. For the
purposes of audit log analysis, it is useful to abstract the
salient details of access events into an access pattern.

Deﬁnition 2 (Access Pattern). An access pattern is a 6-
tuple (sbj, sbj label, perm, tclass, obj, obj label). Many
access events may map to the same access pattern.

Here sbj refers to a concrete subject such as an
Android application or system binary. Binaries carried
inside an application are generalized as the application.
obj refers to concrete objects such as ﬁle paths and
socket names.
In some cases, we group over-speciﬁc
ﬁles that share the same ﬁlesystem semantics as one
obj (e.g., /sdcard). The values of sbj and obj are
derived from the comm, exe, pid, and name val-
ues in the type=1300,1302 log entries.
perm and
tclass are the same as the permission and the object’s
class in the type=1400 log entries and policy rules.
sbj label and obj label are derived from the scontext
and tcontext values in type=1400 log entries.
For example, the access pattern for the access event
in Listing 1 is (“/init”, “init”, “entrypoint”,
“file”,
“/system/etc/install-recovery.sh”,
“system file”).
Problem Statement: Given 1) a large dataset of new ac-
cess patterns from audit logs, 2) a small set of known ac-
cess patterns (e.g., known attacks), and 3) an SEAndroid
policy, we seek to a) separate new benign access patterns
from new malicious access patterns in the dataset, and b)
suggest new rules and reﬁned labels for the policy.
Threat Model and Assumptions: We assume that an
audit log is collected from an Android device with a pol-
icy loaded in either enforcing or permissive mode. We
assume the integrity of audit log contents. We therefore
assume that the Linux kernel and its audit subsystem are
not compromised. However, even if the SEAndroid pol-
icy properly conﬁnes Android applications and system
daemons, they may be compromised by the adversary.

4 EASEAndroid

Elastic Analytics for SEAndroid (EASEAndroid) is a
large-scale audit log and policy analytic platform for au-
tomated policy reﬁnement. The novelty of EASEAn-
droid is that it models the policy reﬁning process as a
semi-supervised learning of new access patterns. At a
high level, EASEAndroid starts with an initial knowl-
edge base containing existing policy rules and a small
set of (potentially manually) identiﬁed access patterns.
It expands the knowledge base by correlating, classify-
ing, and incorporating new access patterns captured by
audit logs. Based on the new knowledge, EASEAndroid
suggests policy changes (new rules and new domain and
type labels in the context of SEAndroid). As more audit
logs become available, EASEAndroid continuously ex-
pands the knowledge base and reﬁnes the policy.

Figure 1 shows the architecture of EASEAndroid. The
architecture uses three machine learning algorithms that
consider different perspectives of the knowledge base
and audit logs. The output of these algorithms is fed into
a combiner that combines and appends the new knowl-
edge into the knowledge base. This learning process is
iterated multiple times until no more new knowledge can
be learned from the current audit log input. Finally, the
policy generator suggests reﬁnements.

Each machine learning algorithm analyzes a different
perspective of the data. The goal of each algorithm is to
ﬁnd semantic correlations between unknown new access
patterns and existing knowledge base, in order to classify
each new access pattern as benign or malicious.

1. The nearest-neighbors-based (NN) classiﬁer clas-
siﬁes new access patterns based on their relations
to known access patterns in the knowledge base. It
ﬁnds new access patterns that are related to known
subjects/objects (e.g., known subjects are updated
and perform new access patterns). By treating these
known subjects/objects as neighbors of the new ac-
cess patterns, it classiﬁes the new access patterns
based on the majority of their known neighbors.

2. The pattern-to-rule distance measurer calculates
the distance between new access patterns and ex-
isting policy rules. If a new access pattern is closest
to an allow rule, it is classiﬁed as benign. If it is
closest to a neverallow rule, it is classiﬁed as ma-
licious. If the access pattern is not close to either
type of rule, it remains unclassiﬁed. The pattern-
to-rule distance measurer also exposes potentially
incomplete rules in existing policy for reﬁnement.
3. The co-occurrence learner considers correlations
across access patterns using statistical relations be-
tween new and known access patterns that fre-
quently occur together in audit logs. Our intuition is

354  24th USENIX Security Symposium 

USENIX Association

: Known Access Pattern
: sbj
: obj
: <perm, tclass>
+
: benign
_ : malicious
: New Access Pattern

Existing Policy & 

Known Access Patterns

Audit Logs

allow
neverallow
_
_

+
+

Feedback & Merge to Learn 
More Knowledge Iteratively

+

+

+

+

+

allow

_

+

neverallow

_

_

1

2

3

1

2

3

1

0.9

0.2

0.8

1

0.1

0.1

0.05

1

_
_

+
+

NN Classifier

Pattern-to-Rule 
Distance Measurer

 ...
Co-Occurrence Learner

Learning Balancer 

& Combiner

Merge refined 
policy once 
confirmed 
(optional)

+
_

Policy 

Refinement
Generator

allow
neverallow
...

Refined Policy

Figure 1: EASEAndroid consists of four learning components and a policy generator to iteratively learn new patterns and reﬁne policy

that a benign functionality or a malicious attack of-
ten involves a series of access patterns that are cap-
tured together in an audit log. If known and new ac-
cess patterns occur together, we can use the known
ones to infer the classiﬁcation of the new ones.

Each learner is conﬁgured with its own threshold to
classify new access patterns independently. However,
it is non-trivial to deﬁne proper thresholds because too
relaxed thresholds could cause false classiﬁcation, low-
ering the learning precision, while too strict thresholds
could leave potential access pattern candidates unclassi-
ﬁed, lowering the learning coverage.

The learning balancer & combiner manages the
threshold of each learner, balances the precision and cov-
erage, and combines the classiﬁcation results from the
three learners. It has two modes: (1) an automated mode
that uses strict threshold in each learner to achieve high
precision with the cost of less coverage; and (2) a semi-
automated mode that relaxes each learner’s threshold to
achieve high coverage and relies on a majority vote from
the three learners to increase the precision. In practice,
the result of semi-automated mode requires policy ana-
lysts’ veriﬁcation to control error rate.

Finally, the policy generator takes newly classiﬁed ac-
cess patterns as input from the combiner, to suggest pol-
icy reﬁnements in the form of new rules and new secu-
rity labels. It uses a clustering algorithm to group similar
subjects and objects together. The clustering algorithm
follows the principle of least privilege by inferring ﬁne-
grained labels that can cover and only cover the clustered
concrete subjects and objects. In practice, the resulting
reﬁned policy can be conﬁrmed by policy analysts and
merge into the knowledge base to analyze new audit logs
after the reﬁned policy is deployed.

The remainder of this section describes each stage of

the EASEAndroid architecture in detail.

4.1 Nearest-Neighbors-based Classiﬁer
Nearest-neighbors-based (NN) learning is a common
technique for classifying an unlabeled instance based
on its nearest labeled neighbors within a deﬁned dis-
tance [41]. Our intuition of using NN for access pattern
classiﬁcation is two-fold. First, known subjects often
perform previously unseen access patterns in audit logs.
This scenario often occurs when Android applications
and system binaries are updated with new capabilities.
Second, some known access patterns are also performed
by new subjects. This scenario occurs when certain op-
erations become popular and are copied by other new ap-
plications. In practice, some exploit kits and repackaged
applications [43] have been found to share the same set
of known malicious access patterns.

These two scenarios cause known subjects and pat-
terns to be semantically connected with new subjects
and patterns. EASEAndroid leverages this connectiv-
ity as the distance metric to design the NN classiﬁer.
When multiple known subjects (or patterns) connect to
the same new pattern (or subject), the NN classiﬁer can
infer whether the new pattern (or subject) is benign or
malicious, based on the majority of the connected known
neighbors. Note that here the observation is with re-
spect to concrete subjects and objects in access patterns.
Hence, only a 4-tuple (sb j, perm,tclass,ob j) out of the
original 6-tuple is required. For completeness, our im-
plementation still includes sb j label and ob j label in the
dataset, but they are not used in this learner.

Algorithm 1 shows the procedure of the NN classiﬁer.
APk collects known 4-tuple access patterns, either benign
or malicious. In practice, our APk is a small set contain-

USENIX Association  

24th USENIX Security Symposium  355

Algorithm 1 NN-based Classiﬁcation of Access Patterns

APk ← {(sk, pk,tk,ok)|sk ∈ Sk, (pk,tk,ok) ∈ Pk}
APu ← {(su, pu,tu,ou)|su ∈ Su, (pu,tu,ou) ∈ Pu}
APc ← /0
procedure NN CLASSIFIER(APk,APu,APc)

for each (s, p,t,o) ∈ APu do

if s ∈ Sk ∩ Su and (p,t,o) ∈ Pu − Pk then
Stmp ← f indAllSb js((p,t,o),APu)
if IsMa jorityKnown(Stmp,Sk) then
APc ← APc ∪Classi f y((s, p,t,o))

end if

else if s ∈ Su − Sk and (p,t,o) ∈ Pk ∩ Pu then

Ptmp ← f indAllPatterns(s,APu)
if IsMa jorityKnown(Ptmp,Pk) then
APc ← APc ∪Classi f y((s, p,t,o))

end if

end if

end for

end procedure
return APc

ing a few well-conﬁrmed subjects and patterns, used as
the initial seed. APu collects all unknown new access pat-
terns from audit logs. To clearly describe the above two
cases, we further divide the 4-tuple into S for all subjects,
and P for the triples (perm, tclass, obj) as partial patterns
shared by multiple subjects. APc is the result set of newly
classiﬁed access patterns.

For each 4-tuple in APu, we check if it is a known sub-
ject with a new triple (partial pattern), or a new subject
with a known triple. In the ﬁrst case, besides the subject
in this 4-tuple, f indAllSb js collects all subjects Stmp that
perform (connect) the same new triple in APu, including
both known and new subjects. Then IsMa jorityKnown
checks if the majority of Stmp is a set of known subjects
from Sk with the same benign or malicious ﬂag. If so,
the new access pattern is classiﬁed as benign or mali-
cious accordingly. The second case is done in the same
way but using known triples to classify new subjects.

The function IsMa jorityKnown uses two empirically
deﬁned thresholds (m,σ ). m determines the minimum
required neighbors and σ is a percentage for how many
known neighbors in Stmp or Ptmp are required as a ma-
jority. Table 1 in the evaluation studies the effects of
different threshold values.

From the perspective of machine learning, our NN-
based classiﬁer is a type of radius-based near neigh-
bors learning [13], a variant of the common k-nearest-
neighbors (kNN). The difference is that kNN is based on
the top k neighbors while we ﬁnd all neighbors within a
radius as nearest neighbors (connectivity is the radius in
our case).

Note that, it is possible that some access patterns are

read_like_perm
open
read
write_like_perm
write
append

execute
execute_perm

common_file

file
dir

blk_file
chr_file
special_file

low_sensitive_data

app_data_file
shell_data_file
sdcard_file

system_file
imei_efs_file

high_sensitive_data

untrusted_app

Figure 2: A decision tree example based on rules related to subject
domain as untrusted app. The black nodes are from existing
rules and the blue nodes are semantic siblings.

rarely connected with known ones. Besides, an access
pattern could be evenly connected to both known benign
and malicious ones. Both cases cause IsMa jorityKnown
to return false. In this case, the NN classiﬁer leaves the
access patterns as unclassiﬁed and relies on the following
learners to complement the learning process.

4.2 Pattern-to-Rule Distance Measurer
EASEAndroid’s second data perspective is the closeness
of access patterns to policy rules. Since audit logs record
denied accesses that cannot match with an allow rule, it
is useful to know how far/close the denied access pattern
is from an existing rule.
In particular, because policy
rules are developed incrementally, they may only cover a
subset of permissions or access patterns and miss similar
access patterns belonging to the same operation.

A common case of this is an imprecise list of permis-
sions in an allow rule. For example, writing a ﬁle not
only requires write permission, but also append and
sometimes create (in case the ﬁle does not exist). Some
malicious operations can also be performed using seman-
tically equivalent, but different access patterns.

The pattern-to-rule distance measurer quantiﬁes the
difference between access patterns and existing rules.
The purpose of this measurer is two-fold. First, pattern-
to-rule distance indicates how likely a new access pattern
is to be benign or malicious. Second, if an access pattern
is very close to a policy rule, the policy reﬁnement gener-
ator (Section 4.5) can update the rule rather than creating
a new rule from scratch.

The distance measurer uses a metric based on the
1) subject label, i.e., domain, 2) object label, i.e., type,
3) tclass, e.g., file, and 4) permission, e.g., write.
Note that all four of these elements are in both the SE-

356  24th USENIX Security Symposium 

USENIX Association

Android policy allow rules, as well as the 6-tuple repre-
senting an access pattern in the audit log. Intuitively, an
access pattern is very close to a rule if it shares the same
labels and tclasses only with slightly different permis-
sions (e.g., write vs append). The distance increases a
little, but is still close, if a pattern and a rule operate on
different but similar tclasses (e.g., file vs dir).

EASEAndroid systematically measures distance using
decision trees based on existing policy rules. The dis-
tance is deﬁned by the matching depth for a speciﬁc ac-
cess pattern. Decision trees are built as follows.
Step 1: For every subject label, ﬁnd all related rules and
follow their semantic order to build a tree skeleton start-
ing from the subject as the root, followed by object la-
bels, tclasses and permissions as nodes in each layer.
Step 2: Extend each node with its semantically similar
siblings.
Figure 2 shows an example decision tree. The black
nodes indicate the tree skeleton, which uses rules such
as
allow untrusted app app data file:file
{open}, where app data file is the object node in
the second layer and file is the tclass node in the third
layer and so on. Then each node is extended with its
semantic siblings, such as sdcard file in the same
group of low sensitive data as app data.

Given an access pattern and a decision tree, the dis-
tance measurer walks the decision tree and tries to
match the access pattern’s subject label, object label,
tclass, and permission with each layer. The match-
ing depth indicates how close a pattern is to existing
rules. For the example in Figure 2, access pattern api =
(untrusted app, sdcard file, dir, read) matches
the fourth layer. The distance is computed as follows:

Dist(api) =TotalLayerDepth − MatchedDepth(api)
If we deﬁne TotalLayerDepth = 4, then Dist(api) =0,
indicating the access pattern is very close to the rule. We
create trees for both allow and neverallow rules to
compute the distances from both sides.

In practice, the effectiveness of the distance metric
depends on the correctness of semantic siblings. For-
tunately, the SEAndroid policy development frequently
uses semantic groups. A list of permissions, tclasses,
and object types are already grouped together in policy
source code using macros and attribute [7]. These groups
form a ground truth for semantic siblings.

Additionally, recall that some existing subject and ob-
ject labels are coarse-grained (e.g., labels assigned to var-
ious objects using wildcard in policy source code). If a
pattern matches with a rule with a coarse-grained label,
the distance measurer marks the distance as low conﬁ-
dence and relies on the learning balancer & combiner for
additional veriﬁcation (Section 4.4).

Finally, note that this technique can be further ex-
tended to measure access pattern to access pattern dis-
tance. Since the pattern-to-rule distance helps to infer
both new patterns as well as identify incomplete rules for
reﬁnement, our design considers policy rules and leaves
the distance between access patterns for future work.

4.3 Co-Occurrence Learner
When analyzing a large number of audit logs, some ac-
cess patterns frequently occur together in many logs.
This is because some high-level benign functionality or
some popular multi-step attacks consist of a series of ac-
cess patterns within a time period (typically minutes).
The statistics of co-occurrence is a valuable means of
correlating access patterns that have different subjects or
objects, but share the same group semantics. When a
group contains both known and new access patterns, the
known access patterns can be used to infer the seman-
tics of the new access patterns.
In fact, co-occurrence
is popular in natural language processing and knowledge
extraction. For example, it is used for ﬁnding words that
are frequently used together in a specialized domain [15].
The co-occurrence of access pattern can be repre-
sented using a n× n matrix for all n unique access pat-
terns from the audit logs, as shown below. Each row
stores one access pattern api’s co-occurrence percentage
with every other access pattern, denoted in each column.
The value ci j is the percentage of the number of times
that api co-occurs with ap j out of the total number of
api’s occurrences throughout the logs.

api
1
c ji
...

ap j
ci j
1
...



...

...

...

1 ,

COAP =

api
ap j
...

where ci j =

CoOccurNum(api,ap j)
TotalOccurNum(api)

When counting the number of co-occurrences, it is im-
portant to avoid noise and duplicates. In practice, we use
a time frame of 10 minutes to determine whether two ac-
cess patterns are part of a co-occurrence set. Recall from
Section 2 that each access pattern has an epoch times-
tamp. Additionally, when counting the occurrence at the
granularity of logs, repeated pairs of co-occurred access
patterns in one log are counted only once.

To use this co-occurrence matrix, the learner focuses
on the rows with new access patterns. For each api row,
the learner sorts columns and selects the set of known
access patterns in columns whose percentage is above a
threshold. A majority vote of this known access pattern
set determines the classiﬁcation of the new api (benign or
malicious). On the other hand, the known access pattern
rows may also have some highly co-occurred new access

USENIX Association  

24th USENIX Security Symposium  357

pattern columns. However, one known access pattern is
usually not enough to classify a new access pattern.

Note that the matrix is not symmetric. ci j can be dif-
ferent from c ji due to different total occurrence counts.
For instance, some popular known malicious access pat-
terns (e.g., remount /system) can co-occur with mul-
tiple less popular new access patterns, because multi-step
attacks often use different steppingstones to achieve the
ﬁnal privilege escalation goal.

4.4 Learning Balancer & Combiner
Each learner is conﬁgured with its own threshold to clas-
sify new access patterns independently. However, it is
non-trivial to deﬁne proper thresholds due to two rea-
sons. On the one hand, if a threshold is too relaxed,
it could cause false classiﬁcation, lowering the learning
precision and might further propagate the error to the
next iteration of semi-supervised learning. On the other
hand, if a threshold is too strict, it could miss potential
access pattern candidates and leaves them as unclassi-
ﬁed, lowering the learning coverage.

We design the learning balancer & combiner to man-
age the threshold setting of each learner, balance the pre-
cision and coverage, and combine the classiﬁcation re-
sults from the three learners (also called ensemble or
multi-view learning [17]). The ﬁnal combined classiﬁ-
cation result is added to the knowledge base and sent to
the policy reﬁnement generator. Speciﬁcally, we propose
two quantiﬁable methods to achieve the balancing:
Automated Mode: Since each learner specializes in
one dimension, each learner with a strict threshold can
directly contribute its classiﬁed access patterns with
high precision. For example, we can set a minimum
of 10 required known neighbors with a 90% bar for
IsMa jorityKnown in NN classiﬁer; Dist(api) =0 with
ﬁne-grained rules in pattern-to-rule distance measurer;
and ci j > 0.9 with known access pattern set ≥ 10 in co-
occurrence learner. The high precision of strict thresh-
olds enables EASEAndroid to be used in an automated
mode over multiple iterations of semi-supervised learn-
ing. However, with such strict thresholds, some access
pattern candidates can be left as unclassiﬁed.
Semi-Automated Mode: This mode relaxes the thresh-
olds to get more access pattern candidates. It uses a ma-
jority vote to choose the candidates shared by at least two
learners with the same classiﬁcation result, and the third
learner must not have conﬂicting result.

Note that relaxed thresholds can increase the possibil-
ity of error propagation. However, if the analysis can
tolerate a semi-automated conﬁguration, relaxed thresh-
olds can be used. Here a human analyst can investigate
low-conﬁdent candidates and input external knowledge

into EASEAndroid for better learning in future.

4.5 Policy Reﬁnement Generator

Finally, the policy reﬁnement generator translates newly
classiﬁed access patterns3 into the ﬁnal policy form. A
key part of the generator is to assign the concrete subjects
(sbjs) and objects (objs) in the access pattern with appro-
priate security labels before generating policy rules.

According to the Android Open Source Project,
Google provides a baseline deﬁnition of security labels
for common subjects (e.g., system apps and binaries) and
basic objects (e.g., basic ﬁles/dirs in Android ﬁle system
structure). However, Google recommends that manufac-
turers replace the generic default labels with ﬁne-grained
labels to decrease the attack surface [4].

Recall that both the access pattern 6-tuple and the in-
complete rules identiﬁed by the distance measurer in-
clude subject labels and object labels from the existing
policy. While some of the labels are coarse-grained, they
serve as a baseline to derive ﬁne-grained labels. Speciﬁ-
cally, the policy reﬁnement generator takes all access pat-
terns as input and clusters them into groups where each
group shares the same 4-tuple (sbj label, perm, tclass,
obj label). Each group is further clustered by sbjs and
objs to create subgroups that share the detailed seman-
tics to derive ﬁne-grained labels.

Our current generator prototype groups sbjs and de-
rives ﬁne-grained subject labels for built-in, vendor, and
untrusted applications and binaries separately. The gen-
erator also groups ﬁle-like objects (e.g., file, dir,
blk file), which comprise the majority of tclasses.
Group is performed using a longest common preﬁx search
on ﬁle paths. This optimization helps to derive more
ﬁne-grained labels than provided by the general An-
droid ﬁlesystem structure. Finally, the generator pro-
duces rules in the form of (new sbj label, perm, tclass,
new obj label) as a policy reﬁnement. If access patterns
are matched with incomplete rules by the distance mea-
surer, new rules merge with existing rules’ permissions.
The generator handles benign and malicious patterns
separately and generates allow and neverallow rules,
respectively. Note that, it is possible that newly gen-
erated rules may conﬂict with existing rules due to in-
complete or tightened access control.
In such cases,
policy analysts manually resolve conﬂicts (e.g., using
auditallow to verify). Nevertheless, EASEAndroid
exposes these conﬂicts with evidence collected through
learning, therefore easing the policy reﬁning process.

3In practice, the learning process can iterate multiple times with
current audit logs. The generator caches all classiﬁed access patterns.

358  24th USENIX Security Symposium 

USENIX Association

5 Evaluation

We implement a prototype of EASEAndroid and evalu-
ate the learning capability and the security effectiveness
of EASEAndroid from three perspectives:

1. We evaluate the coverage and precision of the clas-
siﬁcation result of EASEAndroid, and how they
are affected by different threshold settings (Sec-
tion 5.3).

2. We conduct a case study of the policy reﬁne-
ment generated by EASEAndroid, also comparing
the generated rules with human-written rules (Sec-
tion 5.4).

3. We further conduct a study on the new malicious
access patterns classiﬁed by EASEAndroid and dis-
cuss several interesting new ﬁndings of attacks in
the wild (Section 5.5).

5.1 Environment Setup
We build a prototype of EASEAndroid on an 8-node
Hadoop cluster with each node having 8-core Xeon
2GHz, 32 GB memory. We use open source Cloudera
Impala as the distributed SQL layer, with 10K SLOC
Java as the learning layer. Parallelism is heavily em-
ployed for fast analytics. A data set of 1.3 million audit
logs used in the following experiments are analyzed by
EASEAndroid within 3 hours in a cold start.

5.2 Audit Log & Existing Knowledge
Audit Logs & Existing Policy We make use of 1.3 mil-
lion audit logs over the entire 2014 from real-world de-
vices running Android 4.3 (See Appendix A about au-
dit log collection). All devices are loaded with an early
version of Samsung SEAndroid policy (the policy re-
mained unchanged) in enforcing mode4. The policy con-
tains 5,094 allow rules and 59 neverallow rules de-
veloped by policy analysts. This policy is loaded as ex-
isting knowledge into EASEAndroid’s knowledge base,
used by the pattern-to-rule distance measurer.

The audit logs contain a total of over 14 million de-
nied access events. After eliminating duplicate entries,
we identify approximately 145K unique access events
and further generalize them into 3,530 access patterns.
For example, third-party app process ids under /proc/
are generalized as /proc/app pid in access patterns.

The subjects in the audit logs consist of 113 system
(built-in) binaries, 1,182 external binaries (e.g., installed
by adb), and 626 Android apps, which are captured be-
cause they perform system-level operations that do not

4Some devices are found being rooted and may switch to permissive

mode. See Section 5.5

go through Android framework/Dalvik VM (normal app
operations are already allowed by the policy).
Initial Known Malicious Access Patterns In the initial
knowledge base, we prepare a small set of known mali-
cious access patterns as the initial seed to kick off learn-
ing. The set contains 9 conﬁrmed exploit kits with their
17 malicious access patterns (e.g., psneuter CVE-2011-
1149, Motochopper CVE-2013-2596, vroot CVE-2013-
6282 and several exploit apps). Note that we do not have
known benign access patterns initially as we rely on the
allow rules in the existing policy.
Ground Truth To analyze the classiﬁcation result of be-
nign and malicious access patterns, we use a later ver-
sion of human-written policy (6,337 allow rules, 94
neverallow rules) as the ground truth. We also consult
with experienced policy analysts about the result.

5.3 Coverage & Precision of the Classiﬁca-

tion by EASEAndroid

5.3.1 Coverage compared with naive matching

To illustrate the effect of EASEAndroid’s learning cov-
erage, we design a naive matching tool as a baseline to
compare with EASEAndroid learning when both analyz-
ing the same set of new access patterns from the audit
logs, as shown in Figure 3. The naive matching tool is a
dumb access pattern matching tool with no learning ca-
pability. It only uses the known subjects and access pat-
terns in the initial knowledge base and can only match
new access patterns directly related to them, based on the
subjects and objects in the syscall entries in audit logs. In
contrast, EASEAndroid starts from the initial knowledge
base and keeps expanding the knowledge base.

As the audit logs are continuously collected over the
year, we setup 6 analyses at a rate of every two months.
Each analysis takes as input the accumulated audit logs
from Jan 2014 to the current month (e.g., “Feb” is 2-
month logs, “Apr” is 4-month logs, “Dec” is the entire
year’s logs). It is a typical scenario of semi-supervised
learning with incremental input data. It also follows the
nature that new benign/malicious patterns are gradually
accumulated in audit logs over time.

As shown in Figure 3, EASEAndroid dramatically
outperforms the naive matching in each analysis. As the
total number of access pattern keeps increasing, EASE-
Android’s coverage reaches about 74% in the ﬁnal De-
cember analysis. EASEAndroid also discovers that the
majority of denied access patterns in real world are mali-
cious and they keep emerging while benign access pat-
terns gradually stabilize.
In contrast, the coverage of
naive matching remains around 7%, because it can only
match access patterns related to the initial known ones,
the 9 exploit kits, which are updated with a small set of

USENIX Association  

24th USENIX Security Symposium  359

# of Access Patterns
4000
3500
3000
2500
2000
1500
1000
500
0

1192

118
Feb

Results of Classification

2678

2091

3087

3228

3288

154
Apr

189
Jun

Malicious (TP)

222
Aug
Unclassified

238
Oct

242
Dec

# of Access Patterns
4000
3500
3000
2500
2000
1500
1000
500
0

332
748
226
Feb

Benign (TN)

Results of Classification

932

1578

926

1040

312
256
Apr
Jun
Malicious (TP)

920
71

1988

330
Aug

912
86

906
106

2134

2182

334
Oct

336
Dec

FP+FN Patterns

Unclassified

(a) Access patterns matched by naive matching with no learning capabil-
ity as the baseline. A small set of new malicious patterns are matched
related to the 9 exploits since they are updated and keep trying some new
malicious patterns over time. But the majority is still unclassiﬁed.

(b) Access patterns classiﬁed by EASEAndroid starting from the initial
knowledge. New patterns classiﬁed in each analysis become the incre-
mental knowledge to classify more patterns in the next analysis. Benign
patterns get stable over time, while new malicious patterns keep emerging.

Figure 3: The comparison between naive matching and EASEAndroid on analyzing the same set of access patterns

Threshold Setting

σ = 55%,Dist ≤ 2,ci j > 0.55
σ = 65%,Dist ≤ 1,ci j > 0.65
σ = 75%,Dist ≤ 1,ci j > 0.75
σ = 85%,Dist = 0,ci j > 0.85
σ = 95%,Dist = 0,ci j > 0.95

Classiﬁed
Malicious
(TP+FP)
77.2%
70.0%
65.7%
63.9%
53.1%

Classiﬁed
Benign
(TN+FN)
14.0%
11.8%
10.9%
10.5%
9.2%

Remain

Unclassiﬁed

8.8%
18.2%
23.4%
25.7%
37.7%

True

False

Malicious

Malicious

(TP)
62.96%
88.73%
91.35%
96.81%
97.27%

(FP)
37.04%
11.27%
8.65%
3.19%
2.73%

True
Benign
(TN)
58.65%
71.35%
88.92%
90.81%
100.00%

False
Benign
(FN)
41.35%
28.65%
11.08%
9.19%
0.00%

Table 1: The coverage and precision of EASEAndroid with different threshold settings after comparison with ground truth. The ﬁrst three columns
summarize the overall classiﬁcation coverage over the 3,530 patterns. The following four columns give more details about the percentages of each
set of true/false-classiﬁed benign and malicious patterns. Row 4 is the threshold setting used in Figure 3(b).

new access patterns over time. But it still leaves the ma-
jority unclassiﬁed.

Speciﬁcally, all three learners of EASEAndroid con-
tribute to the high classiﬁcation coverage.
In the ﬁrst
February analysis, EASEAndroid ﬁrst matches 118 ma-
licious access patterns, same as naive matching. Then
it performs multiple learning iterations with the cur-
rent audit logs in both automated and semi-automated
mode. In summary, in automated mode, the NN classiﬁer
ﬁnds 282 patterns using threshold (m,σ ) = (10,85%)
in IsMa jorityKnown. The pattern-to-rule distance mea-
surer ﬁnds 95 patterns using Dist(api) = 0 with existing
neverallow rules. The co-occurrence learner ﬁnds 110
patterns with ci j > 0.85. In semi-automated mode, we re-
lax the thresholds to (10,75%), Dist(api) ≤ 1, ci j > 0.75,
respectively and further ﬁnd 143 patterns based on the
majority vote of the three learners.

As for benign access patterns in the February analy-
sis, since the initial knowledge lacks benign patterns, the
pattern-to-rule distance measurer classiﬁes the ﬁrst 23
benign patterns using Dist(api) =0 with existing allow
rules and adds them to the knowledge base. Then the
three learners contribute the remaining 203 using the
same threshold settings.

Due to the strict thresholds, the automated mode clas-
siﬁes access patterns with no false positives or negatives.
However, in the semi-automated mode, we do ﬁnd 34
false-benign (False-Negative5) access patterns and the 72
false-malicious (False-Positive) ones in the ﬁnal Decem-
ber analysis, mainly due to two reasons. First, a small
set of access patterns are shared by both privileged be-
nign system binaries and malicious apps with similar oc-
currences (e.g., both access /proc/stat), which make
EASEAndroid hard to distinguish with relaxed thresh-
olds. Second, some mis-classiﬁed patterns in early anal-
yses affect the learning precision in later ones. In fact,
there are only 4 false-malicious patterns in the Febru-
ary analysis. But then the NN classiﬁer uses them to
mistakenly ﬁnd more false-malicious ones in the follow-
ing analyses. Nevertheless, this limitation of the semi-
automated mode is expected. Therefore in practice, the
semi-automated mode requires policy analysts to verify
the result to avoid error propagation. Analysts can also
input extra constraints and knowledge about the access
patterns of privileged system binaries to help EASEAn-
droid increase the precision.

There are still 906 access patterns unclassiﬁed in the

5We treat malicious as positive, benign as negative.

360  24th USENIX Security Symposium 

USENIX Association

ﬁnal analysis due to their low occurrence (less than ﬁve
days throughout the year). After manual analysis, we
ﬁnd that some access patterns are likely malicious and
might be isolated attack attempts in the wild. However,
the statistics is too low to reach the threshold. In such
cases, we have to wait for more similar access patterns
coming in future audit logs.
In Section 6, we discuss
the limitation that isolated/targeted attacks may evade
EASEAndroid’s detection if they are not widely spread.

5.3.2 Coverage & precision with different threshold

settings

The thresholds for the three learners play an important
role on the coverage and the precision of EASEAndroid.
In practice, it is important to ﬁnd a balance between
the coverage and the precision. In this section, we fur-
ther investigate the detailed coverage and precision dif-
ference by choosing 5 different threshold settings from
very relaxed to very strict as shown in Table 1. The listed
threshold settings are for the automated mode. The semi-
automated mode is relaxed by reducing 10% on both
IsMa jorityKnown (minimum neighbors unchanged) and
ci j, and increasing 1 in Dist(api). The ﬁrst three columns
show the overall percentage (adds to 100%) summariz-
ing the classiﬁed malicious and benign and unclassiﬁed
over the total 3,530 access patterns. The following four
columns provide the more detailed TP/FP and TN/FN
percentage of classiﬁed malicious and benign access pat-
terns.

We can see that the thresholds in Row 1 is largely
relaxed. Although it has the highest coverage, both FP
(37.04%) and FN (41.35%) are too high, making it prac-
tically useless. In contrast, Row 5’s thresholds achieve
100% correctness on classifying benign patterns. But it
also leaves 37.7% patterns unclassiﬁed. The middle 3
rows are more balanced. Row 3 and 4 are candidates
for practical use. In practice, analysts can also use mul-
tiple thresholds respectively, such as with Row 4 and 5
together, and only need to investigate the diff of their
learning results since we have high conﬁdence with the
result of Row 5.

Admittedly, each individual threshold for each learner
may have a different effect on the ﬁnal classiﬁcation re-
sult. To analyze more detailed threshold difference, or
ﬁnd an optimal vector of thresholds, a cross-validation
[27] can be performed with multiple real-world audit log
sets.

5.4 Case Study of Reﬁnement Generation

& Comparison with Human Policy

In the last December analysis in Figure 3, the policy
reﬁnement generator ﬁnally generates 51 new allow

rules from the 336 benign access patterns, and 280 new
neverallow rules from the 2,182 malicious access pat-
terns, by extending identiﬁed incomplete rules and cre-
ating new ﬁne-grained security labels to replace existing
coarse-grained ones. In this section, we use the follow-
ing example as a case study to illustrate the generated
reﬁnement.

in

that

(subjects)

EASEAndroid classiﬁed as benign 9 access pat-
read some time-zone data ﬁles under
terns
/data/misc/zoneinfo.
These access patterns
are found in multiple Android framework-related
binaries
including
surfaceflinger,dhcpcd,pppd and a vendor-speciﬁc
daemon. In the 6-tuples, the time-zone data ﬁles carry
system data file, which is the default label for all
ﬁles under /data. Naively generating a rule with this la-
bel (using audit2allow) would over-grant the subjects
with permissions to access all ﬁles under /data.

/system/bin,

EASEAndroid instead ﬁnds that these ﬁles all share
the same /data/misc/zoneinfo ﬁle path preﬁx, and
thus derives a new label zoneinfo file speciﬁcally for
them, adding to the labeling deﬁnition file contexts:

/data/misc/zoneinfo/.* \
u:object r:zoneinfo file:s0

the full path preﬁx can be transformed
In practice,
into an underscore-joined label to keep the semantics
and prevent conﬂict (though abbreviation may be re-
quired). EASEAndroid also creates a new attribute
access zoneinfo domain to group the above subject
domains, as the following:

attribute access zoneinfo domain;
typeattribute surfaceflinger \

access zoneinfo domain;...

Finally, EASEAndroid generates a new rule based on the
new labels deﬁned above:

allow access zoneinfo domain
zoneinfo file:file {open read}

This rule only covers the 9 patterns observed by EASE-
Android,
thus preventing unnecessary accesses being
granted, following the least privilege principle.

The rules generated by EASEAndroid for the 336 be-
nign access patterns are compared with human-written
rules in the later policy version. Semantically, all ac-
cess patterns allowed by EASEAndroid rules are also
permitted by human-written rules. However, syntacti-
cally, EASEAndroid in general creates a larger set of
more-speciﬁc rules, while human-written rules are more
concise with the frequent use of policy macros, which
ease the policy writing and are expanded during com-
pile time [7]. It may be desirable to aggregate EASEAn-
droid’s more speciﬁc rules for better human-readability;
this remains for future work.

USENIX Association  

24th USENIX Security Symposium  361

3.7%2.9%

7.0%

24.0%

10.2%

10.7%

22.3%

19.1%

Distribution of Classified Malicious Access Patterns
1. {read,write} files on /dev/graphics, /dev/block, /dev/exynos-mem, /dev/mem, /dev/android_adb, /dev/s3c-mfc
2. {dac_override,chown,fsetid} capability on /data/data, /data/local, /data/misc, /data/system, /sdcard
3. {create,write,unlink} files on /system/app, /system/bin, /system/xbin, /system/etc
4. {read,write} files on /sys/block, /sys/devices, /sys/fs, /sys/kernel
5. {kill,sys_admin,sys_ptrace,sys_chroot,setuid,setgid} capability
6. {transition,dyntransition} process
7. {read,write} files on /proc/sys, /proc/app_pid/cwd|environ|exe|mem|mounts
8. {connectto} unix domain sockets of privileged daemons directly

Figure 4: The distribution of malicious access patterns classiﬁed by EASEAndroid.

5.5 Case Study of Classiﬁed Malicious Ac-

cess Patterns

For the one-year dataset of audit logs processed by
EASEAndroid, 2,182 access patterns are classiﬁed as
malicious. The reader is reminded that the starting point
of analysis is 17 access patterns derived (manually) from
9 conﬁrmed exploit kits. The access patterns newly clas-
siﬁed as malicious by EASEAndroid capture malicious
behavior much more precisely than has previously been
possible. To the best of our knowledge, this is the ﬁrst
large-scale study of system-level malicious access pat-
terns from real-world Android devices.

The subjects in these malicious access patterns are
mostly untrusted third-party shell binaries and apps.
For the purpose of understanding and discussion, they
are categorized based on the permissions [5] (shown in
braces) and the objects they accessed, which were mainly
privileged ﬁles. Figure 4 shows the resulting 8 categories
of malicious access patterns, each discussed below. Two
of them (modify /sys/fs/selinux and transition
to privileged domains) are new attacks in Android which
directly target the SEAndroid MAC mechanism itself.
1. Exploit /dev nodes
The most common malicious access patterns are the
ones that exploit various vulnerabilities in device nodes
under /dev.
For instance, EASEAndroid found 62
different shell binaries and exploit apps trying to di-
rectly read and write /dev/graphics/* (exploiting
a previously-known framebuffer vulnerability). After
identifying these subjects, EASEAndroid further discov-
ered that they bundled various exploits targeting several
other device nodes as well (including vendor-speciﬁc
nodes). Some of these subjects were found to success-
fully gain root privileges. However, note that a good
SEAndroid policy is still able to provide protection even
on a rooted device (e.g., even init has limited permis-
sions), as long as the Linux kernel is not compromised.6

2. Request ﬁle-related privileged capabilities
The second most frequent category of malicious access
patterns are that subjects try to use privileged capabili-
ties to modify the ﬁle mode bits and ownership of var-
ious ﬁles. This is a classic privilege escalation attack
step; external binary ﬁles pushed to the device (e.g., in
/data/local/tmp) may be given unintended capabil-
ities, and important data ﬁles (e.g., in /data/system)
can be made writable for attacks to proceed.
3. Modify /system partition
This is also a common step in exploits that the /system
partition is modiﬁed with new binaries added such as
the /system partition is
su,busybox. Normally,
mounted as read-only. But some subjects were able to re-
mount the partition as writable. However, they were still
captured by the audit logs because their domain labels
were not allowed to write system file under /system.
4. Access /sys ﬁlesystem
/sys is a virtual ﬁlesystem that exports kernel-level
information to userspace, normally used by privileged
system daemons. EASEAndroid found that untrusted
subjects also try to directly access /sys, particularly
/sys/fs/selinux, which contains the policy content
and runtime state. Untrusted subjects may try to mod-
ify the policy content, either to switch to the permissive
mode, or to get more permissions. We believe this is
a new type of attack directly against SEAndroid MAC
mechanism. Although this new attack is expected to
emerge, it is still surprising to discover that the new at-
tack has already become popular in the wild.
5. Request process-related privileged capabilities
EASEAndroid also found that some untrusted subjects
ask for privileged process capabilities, such as kill’ing
other processes, or sys admin managing a list of func-
tionalities [5]. The most common example is to use
sys ptrace to ptrace another process. This capability
is attempted by several third-party management/moni-

6Since certain subjects gain root, they may be able to rollback to the

permissive mode. The audit logs might just record the malicious access
patterns but not actually block them.

362  24th USENIX Security Symposium 

USENIX Association

tor apps, and game hacking apps (to modify other game
apps’ score/rewards).
6. Transition to privileged domains
Another new type of attack directly targeting SEAndroid
is that untrusted apps try (some succeed) to gain more
privileges by transforming their subject domains from
untrusted app to domains with higher privileges, in-
cluding init,init shell,system app, and vendor
daemon domains.7 Interestingly, this case is found due
to the conﬂict reported by the majority-vote in the semi-
automated mode. An access pattern classiﬁed as mali-
cious by both the NN classiﬁer and the co-occurrence
learner, is classiﬁed as benign by the pattern-to-rule dis-
tance measurer, because it is close to an allow rule. The
conﬂict indicates that the subject carries a wrong domain.
7. Access /proc ﬁlesystem
Like /sys, /proc is also frequently accessed, espe-
cially by third-party management/monitor apps. Al-
though reading /proc/app pid/* might not be di-
rectly damaging, the information can be leveraged as a
side-channel to compose attacks [20]. Besides, EASE-
Android also showed that certain apps try to write
/proc/sys/kernel/kptr restrict to gain access to
the kernel symbol table, a common step in kernel ex-
ploits.
8. Connect to Unix sockets of privileged daemons
Unix domain socket is a more complicated case in SE-
Android. By design, some Unix sockets in system dae-
mons such as adbd,debuggerd can be connected by
apps, while others are reserved only for privileged dae-
mons. EASEAndroid is able to distinguish these two
cases, mainly by the co-occurrence learner. It found one
new benign access pattern between two vendor daemons
and several malicious ones that untrusted apps try to di-
rectly connect to Unix sockets of highly privileged dae-
mons, such as init.

In summary, with EASEAndroid’s learning, we ﬁnd a
group of interesting malicious access patterns and new
attacks in Android. EASEAndroid also generates 280
ﬁne-grained neverallow rules. 52 rules are found in the
later policy. But others still require deeper investigation,
since the knowledge learned by current EASEAndroid
prototype may not be sufﬁcient to understand the attack
mechanisms behind these malicious access patterns.

6 Discussion

Blurred line between benign and malicious In practice,
the line between benign and malicious might be blurred
and subjective. It depends on speciﬁc security require-
ments and use cases to determine whether an access pat-

7Policy analysts suggest that it is also possible that some daemons

may have zero-day vulnerabilities that are exploited to run attacks.

tern is really benign or malicious. For example, individ-
ual users may like rooting their own devices and using
the game hacking apps mentioned above, while game de-
velopers treat them as malicious because they bypass the
in-app purchase. Nevertheless, EASEAndroid’s learning
provides more detailed evidence of access patterns’ se-
mantics for policy analysts to make the ﬁnal decision.
Information missed by audit logs EASEAndroid relies
on audit logs to learn new access patterns and derive
policy reﬁnements. However, two types of information
could be missed or not available in audit logs, which can
cause EASEAndroid to miss important knowledge. First,
by default, audit logs only capture system-level opera-
tions that are denied by the policy currently loaded in a
device. If the policy is too permissive or has too coarse-
grained allow rules, malicious access patterns could be
mistakenly allowed and missed by audit logs. To miti-
gate this issue, policy analysts should use auditallow
to mark coarse-grained or uncertain rules so that audit
logs can capture the operations allowed by these rules
for EASEAndroid’s analysis.

Second, framework-level operations are not available
in audit logs, because they are controlled by Android per-
mission model. But these upper-level operations contain
valuable semantics (e.g., attack mechanisms). Without
them, it is difﬁcult to explain and distinguish certain be-
nign/malicious access patterns in audit logs. Since An-
droid 5.0, logcat is involved in SEAndroid auditing. In
future, EASEAndroid can integrate logs from logcat to
have more semantics in the knowledge base.
Countermeasure against EASEAndroid Similar to
tampering virus sampling in AntiVirus programs, attack-
ers can disable or compromise the audit log mechanism
(logging and uploading) to avoid malicious access pat-
terns being learned. Currently, we rely on Linux kernel
protection [11] to ensure the integrity of audit log mech-
anism. And we argue that enabling audit log with policy
reﬁnement updates is a recommended security service
for the majority users to have the latest security protec-
tion (or mandatory for enterprise users).

By design, if a malicious access pattern is widely
spread and affects a large number of normal users, audit
logs can catch the pattern for EASEAndroid to analyze.
However, it is possible that isolated or targeted attacks
may evade the detection of EASEAndroid if they are not
popular enough to reach the thresholds, or deliberately
avoid having semantic correlation with known malicious
access patterns. In such cases, although EASEAndroid
may leave them as unclassiﬁed, it still helps narrow down
the scope for policy analysts to investigate. And policy
analysts can input extra knowledge into EASEAndroid
to help increase the coverage and precision.

It is also potentially possible that attackers manipulate
the co-occurrence rate by intentionally forcing the be-

USENIX Association  

24th USENIX Security Symposium  363

nign and malicious patterns to co-occur in one log, such
as triggering the benign pattern ﬁrst and then launching
the attack. Such data poisoning attack may fool EASE-
Android’s learning, which requires extra constraints or
more logs from different devices to dilute the poisoned
logs [14].

7 Related Work

Though SEAndroid is fairly new, SELinux has been de-
veloped and researched for years, including SELinux
policy analysis and veriﬁcation [10, 23, 36, 42], policy
visualization [40], policy conﬂict resolving [26], pol-
icy simplifying [33, 34], policy comparison [19], policy
information-ﬂow integrity measurement [22, 24, 25, 37],
etc. Also, the above research work usually assumes a rel-
atively complete SELinux policy that has already been
well developed. And the analysis usually focuses on sta-
ble desktop Linux system or only a few speciﬁc appli-
cation programs (e.g., sshd,httpd). Due to the archi-
tecture difference, SEAndroid faces different challenges
from SELinux, because current SEAndroid policy is still
incomplete and under active development and continu-
ous reﬁnement.

In terms of SELinux policy generation, Polgen pro-
posed by MITRE is a tool that guides policy analysts to
develop policies based on system call traces [39]. How-
ever, it does not have machine learning capability and
only focuses on system call traces from a single applica-
tion program, which is not scalable. Madison proposed
by Redhat is an extension of audit2allow that can gen-
erate policy similar to the reference policy style, such as
using macros [30]. However, like audit2allow, it can-
not create new security labels to cover new access pat-
terns.

There is very little SELinux research related to ma-
chine learning. Marouf et al. proposed a similar ap-
proach to Polgen that analyzes system call traces to sim-
plify SELinux policy [32]. Markowsky et al. proposed
an IDS system that uses SELinux denials as input to an
SVM classiﬁer to detect attacks [31]. But there is no pol-
icy analysis or reﬁnement.

Android SafetyNet [1] is a new security service pro-
vided by Google, which includes analyzing SELinux
logs collected from Android devices, though no speciﬁc
technical details about the SELinux log analysis have
been disclosed.

8 Conclusion

Developing SEAndroid policies is a non-trivial task. In
this paper, we have proposed EASEAndroid, the ﬁrst
SEAndroid audit log analytic platform for automatic

logs from real-world devices.

policy analysis and reﬁnement. EASEAndroid innova-
tively applies semi-supervised learning to MAC policy
It has been evaluated with 1.3 million
development.
audit
It successfully
discovered over 2,500 new benign and malicious access
patterns, generated 331 policy rules, and found 2 new
attacks in the wild directly targeting SEAndroid MAC
mechanism.

Acknowledgement
We would like to thank Michael Grace, Kunal Patel and
Xiaoyong Zhou from Samsung Research America for
their valuable input for this paper. We also like to thank
the paper shepherd and anonymous reviewers for their
support to publish this paper.

This work is done in Samsung Research America. All
data used to conduct the experiments was handled ac-
cording to Samsung strict policies as explained in Ap-
pendix A. William Enck’s work in this paper is sup-
ported by NSF grant CNS-1253346. Douglas Reeves’s
work in this paper is supported by ARO under MURI
grant W911NF-09-1-0525. Any opinions, ﬁndings, and
conclusions or recommendations expressed in this mate-
rial are those of the authors and do not necessarily reﬂect
the views of Samsung or the funding agencies.

References
[1] Android SafetyNet, Google.

android.com/training/safetynet.

https://developer.

[2] End User License Agreement, Samsung Software.

http:

//www.samsung.com/us/Legal/PH_Warranty_2_
EULA_INDEVICE_SINGLE_EULA.pdf.

[3] Samsung Privacy Policy. http://www.samsung.com/us/

common/privacy.html.

[4] Security-Enhanced Linux in Android. https://source.

android.com/devices/tech/security/selinux.

[5] SELinux ObjectClassesPerms. http://selinuxproject.

org/page/ObjectClassesPerms.

[6] SELinux Project. http://selinuxproject.org.
[7] SELinux Type Statements.

http://selinuxproject.

org/page/TypeStatements.

[8] setools, Tresys Technology.

https://github.com/

TresysTechnology/setools.

[9] Validating SELinux.

https://source.android.com/

devices/tech/security/selinux/validate.
html.

[10] ALAM, M., SEIFERT, J.-P., LI, Q., AND ZHANG, X. Usage
Control Platformization via Trustworthy SELinux. In Proceed-
ings of the 2008 ACM Symposium on Information, Computer and
Communications Security (2008), ASIACCS ’08, ACM, pp. 245–
248.

[11] AZAB, A. M., NING, P., SHAH, J., CHEN, Q., BHUTKAR, R.,
GANESH, G., MA, J., AND SHEN, W. Hypervision Across
Worlds: Real-time Kernel Protection from the ARM TrustZone
Secure World. In Proceedings of the 2014 ACM SIGSAC Con-
ference on Computer and Communications Security (2014), CCS
’14, ACM, pp. 90–102.

364  24th USENIX Security Symposium 

USENIX Association

[12] BADGER, L., STERNE, D., SHERMAN, D., WALKER, K., AND
HAGHIGHAT, S. A Domain and Type Enforcement UNIX Proto-
type. In Proceedings of the Fifth USENIX UNIX Security Sympo-
sium (June 1995).

[28] LOSCOCCO, P., AND SMALLEY, S.

Integrating Flexible Sup-
port for Security Policies into the Linux Operating System.
In
USENIX Annual Technical Conference ’01 (2001), no. February,
pp. 29–42.

[13] BENTLEY, J. L. A Survey of Techniques for Fixed Radius Near
Neighbor Searching. Tech. rep., Stanford University, Stanford,
CA, USA, 1975.

[14] BIGGIO, B., CORONA, I., FUMERA, G., GIACINTO, G., AND
ROLI, F. Bagging Classiﬁers for Fighting Poisoning Attacks
in Adversarial Classiﬁcation Tasks. In Proceedings of the 10th
International Conference on Multiple Classiﬁer Systems (Berlin,
Heidelberg, 2011), MCS’11, Springer-Verlag, pp. 350–359.

[15] BULLINARIA, J. A., AND LEVY, J. P. Extracting semantic rep-
resentations from word co-occurrence statistics: A computational
study. Behavior Research Methods 39, 3 (2007), 510–526.

[16] CARLSON, A., BETTERIDGE, J., KISIEL, B., SETTLES, B., JR,
E. R. H., AND MITCHELL, T. M. Toward an Architecture for
Never-Ending Language Learning.
In Proceedings of the 24th
AAAI Conference on Artiﬁcial Intelligence (2010), AAAI ’10.

[17] CARLSON, A., BETTERIDGE, J., WANG, R. C., MITCHELL,
T. M., CARLOS, S., AND BRAZIL, S. P. Coupled Semi-
Supervised Learning for Information Extraction. In Proceedings
of the third ACM international conference on Web search and
data mining (2010), WSDM ’10, pp. 101–110.

[18] CHAPELLE, O., SCHOLKOPF, B., AND ZIEN, A.

Supervised Learning. The MIT Press, Sept. 2006.

Semi-

[29] LOSCOCCO, P. A., SMALLEY, S. D., MUCKELBAUER, P. A.,
TAYLOR, R. C., TURNER, S. J., AND FARRELL, J. F. The
Inevitability of Failure: The Flawed Assumption of Security in
Modern Computing Environments.
In Proceedings of the 21st
National Information Systems Security Conference (Oct. 1998).

[30] MACMILLAN, K. Madison : A New Approach to Policy Gener-

ation. In SELnux Symposium ’07 (2007).

[31] MARKOWSKY, L. Towards Making SELinux Smart Leveraging
SELinux to Protect End Nodes in a Federated Environment. Tech.
rep., University of Maine, Orono, 2012.

[32] MAROUF, S., PHUONG, D. M., AND SHEHAB, M. A Learning-
Based Approach for SELinux Policy Optimization with Type
Mining.
In Proceedings of the Sixth Annual Workshop on Cy-
ber Security and Information Intelligence Research (New York,
New York, USA, 2010), CSIIRW ’10, ACM Press, p. 70.

[33] NAKAMURA, Y. Simplifying Policy Management with SELinux

Policy Editor. In SELinux Symposium ’05 (2005), pp. 1–34.

[34] NAKAMURA, Y., SAMESHIMA, Y., AND TABATA, T. SEEdit:
SELinux Security Policy Conﬁguration System with Higher
Level Language. In Proceedings of the 23rd conference on Large
installation system administration (2009), LISA ’09.

[19] CHEN, H., LI, N., AND MAO, Z. Analyzing and Comparing the
Protection Quality of Security Enhanced Operating Systems. In
NDSS ’09 (2009).

[35] SALTZER, J., AND SCHROEDER, M. The Protection of Informa-
tion in Computer Systems. Proceedings of the IEEE 63, 9 (Sept.
1975).

[20] CHEN, Q. A., QIAN, Z., AND MAO, Z. M. Peeking into Your
App without Actually Seeing It: UI State Inference and Novel
Android Attacks.
In USENIX Security ’14 (2014), no. August,
pp. 1037–1052.

[21] DONG, X. L., GABRILOVICH, E., HEITZ, G., HORN, W., LAO,
N., MURPHY, K., STROHMANN, T., SUN, S., AND ZHANG,
W. Knowledge Vault : A Web-Scale Approach to Probabilistic
Knowledge Fusion. In Proceedings of the 20th ACM SIGKDD in-
ternational conference on Knowledge discovery and data mining
(2014), KDD ’14, pp. 601–610.

[22] GANAPATHY, V., JAEGER, T., AND JHA, S. Retroﬁtting Legacy
Code for Authorization Policy Enforcement. In 2006 IEEE Sym-
posium on Security and Privacy (2006), S&P ’06, Ieee, pp. 15
pp.–229.

[23] HICKS, B., RUEDA, S., AND CLAIR, L. S. A Logical Speciﬁca-
tion and Analysis for SELinux MLS Policy. ACM Transactions
on Information and System Security (TISSEC) 13, 3 (2010), 1–31.
[24] JAEGER, T., SAILER, R., AND SHANKAR, U. PRIMA: Policy-
reduced Integrity Measurement Architecture. In Proceedings of
the eleventh ACM symposium on Access control models and tech-
nologies (2006), SACMAT ’06, pp. 19–28.

[25] JAEGER, T., SAILER, R., AND ZHANG, X. Analyzing Integrity
Protection in the SELinux Example Policy. In USENIX Security
’03 (2003).

[26] JAEGER, T., SAILER, R., AND ZHANG, X. Resolving Constraint
Conﬂicts. In Proceedings of the ninth ACM symposium on Access
control models and technologies (New York, New York, USA,
2004), SACMAT ’04, ACM Press, pp. 105–114.

[27] KOHAVI, R. A Study of Cross-validation and Bootstrap for Ac-
curacy Estimation and Model Selection.
In Proceedings of the
14th International Joint Conference on Artiﬁcial Intelligence -
Volume 2 (San Francisco, CA, USA, 1995), IJCAI’95, pp. 1137–
1143.

[36] SASTURKAR, A., STOLLER, S. D., RAMAKRISHNAN, C. R.,
SCIENCE, C., AND BROOK, S. Policy Analysis for Administra-
tive Role Based Access Control. In 19th IEEE Computer Security
Foundations Workshop (2006), CSFW ’06.

[37] SHANKAR, U., JAEGER, T., AND SAILER, R. Toward Au-
tomated Information-Flow Integrity Veriﬁcation for Security-
Critical Applications. In NDSS ’06 (2006).

[38] SMALLEY, S., AND CRAIG, R. Security Enhanced (SE) An-
droid: Bringing Flexible MAC to Android. In NDSS ’13 (2013).

[39] SNIFFEN, B. T., HARRIS, D. R., AND RAMSDELL, J. D.
Guided Policy Generation for Application Authors. In SELnux
Symposium ’06 (2006).

[40] XU, W., SHEHAB, M., AND AHN, G.-J. J. Visualization Based
Policy Analysis: Case Study in SELinux. In Proceedings of the
13th ACM Symposium on Access control models and technologies
(2008), SACMAT ’08, pp. 165–174.

[41] YIANILOS, P. N. Data structures and algorithms for nearest
neighbor search in general metric spaces. In ACM-SIAM Sympo-
sium on Discrete Algorithms (A Conference on Theoretical and
Experimental Analysis of Discrete Algorithms (1993), vol. 93 of
SODA, pp. 311–321.

[42] ZANIN, G., LA, R., INFORMATICA, D., AND SALARIA, V. To-
wards a Formal Model for Security Policies Speciﬁcation and
Validation in the SELinux System. In Proceedings of the ninth
ACM symposium on Access control models and technologies
(2004), SACMAT ’04, pp. 136–145.

[43] ZHOU, Y., AND JIANG, X. Dissecting android malware: Char-
acterization and evolution. In 2012 IEEE Symposium on Security
and Privacy (2012), S&P ’12, IEEE, pp. 95–109.

[44] ZHU, X. Semi-Supervised Learning Literature Survey. Tech.

rep., University of Wisconsin - Madison, 2008.

USENIX Association  

24th USENIX Security Symposium  365

A Data Collection Policies

Collection of audit logs used in this research strictly fol-
lowed the Privacy Policy of Samsung [3], and conformed
to the conditions described in Samsung’s End User Li-
cense Agreement [2]. Audit logs were collected anony-
mously from users who consented to provide diagnos-
tic and usage data to help Samsung improve the quality
and the performance of its products and services. Only
Samsung authorized employees, using Samsung’s inter-
nal computer systems, had access to the audit logs. No
individual audit log information was released outside of
Samsung while conducting the experiments described in
this paper.

366  24th USENIX Security Symposium 

USENIX Association

