DupLESS: Server-Aided Encryption  

for Deduplicated Storage

Mihir Bellare and Sriram Keelveedhi, University of California, San Diego; 

Thomas Ristenpart, University of Wisconsin—Madison

Open access to the Proceedings of the 22nd USENIX Security Symposium is sponsored by USENIXThis paper is included in the Proceedings of the 22nd USENIX Security Symposium.August 14–16, 2013 • Washington, D.C., USAISBN 978-1-931971-03-4Server-Aided Encryption for Deduplicated Storage

DupLESS:

Mihir Bellare

Sriram Keelveedhi

Thomas Ristenpart

University of California, San Diego

University of California, San Diego

University of Wisconsin–Madison

Abstract

Cloud storage service providers such as Dropbox, Mozy,
and others perform deduplication to save space by only
storing one copy of each ﬁle uploaded. Should clients
conventionally encrypt their ﬁles, however, savings are
lost. Message-locked encryption (the most prominent
manifestation of which is convergent encryption) re-
solves this tension. However it is inherently subject
to brute-force attacks that can recover ﬁles falling into
a known set. We propose an architecture that pro-
vides secure deduplicated storage resisting brute-force
attacks, and realize it in a system called DupLESS. In
DupLESS, clients encrypt under message-based keys ob-
tained from a key-server via an oblivious PRF protocol.
It enables clients to store encrypted data with an exist-
ing service, have the service perform deduplication on
their behalf, and yet achieves strong conﬁdentiality guar-
antees. We show that encryption for deduplicated storage
can achieve performance and space savings close to that
of using the storage service with plaintext data.

1

Introduction

Providers of cloud-based storage such as Dropbox [3],
Google Drive [7], and Mozy [63] can save on storage
costs via deduplication: should two clients upload the
same ﬁle, the service detects this and stores only a sin-
gle copy. The savings, which can be passed back directly
or indirectly to customers, are signiﬁcant [50, 61, 74] and
central to the economics of the business.

But customers may want their data encrypted, for rea-
sons ranging from personal privacy to corporate policy
to legal regulations. A client could encrypt its ﬁle, under
a user’s key, before storing it. But common encryption
modes are randomized, making deduplication impossi-
ble since the SS (Storage Service) effectively always sees
different ciphertexts regardless of the data. If a client’s
encryption is deterministic (so that the same ﬁle will al-

ways map to the same ciphertext) deduplication is pos-
sible, but only for that user. Cross-user deduplication,
which allows more storage savings, is not possible be-
cause encryptions of different clients, being under dif-
ferent keys, are usually different. Sharing a single key
across a group of users makes the system brittle in the
face of client compromise.

One approach aimed at resolving this tension is
message-locked encryption (MLE) [18]. Its most promi-
nent instantiation is convergent encryption (CE), in-
troduced earlier by Douceur et al. [38] and others
(c.f., [76]). CE is used within a wide variety of com-
mercial and research SS systems [1, 2, 5, 6, 8, 12, 15, 32,
33, 55, 60, 66, 71, 78, 79]. Letting M be a ﬁle’s contents,
hereafter called the message, the client ﬁrst computes a
key K ← H(M) by applying a cryptographic hash func-
tion H to the message, and then computes the ciphertext
C ← E(K, M) via a deterministic symmetric encryption
scheme. The short message-derived key K is stored sep-
arately encrypted under a per-client key or password. A
second client B encrypting the same ﬁle M will produce
the same C, enabling deduplication.

However, CE is subject to an inherent security limita-
tion, namely susceptibility to ofﬂine brute-force dictio-
nary attacks. Knowing that the target message M un-
derlying a target ciphertext C is drawn from a dictio-
nary S = {M1, . . . ,M n} of size n, the attacker can recover
M in the time for n = |S| off-line encryptions: for each
i = 1, . . . ,n, it simply CE-encrypts Mi to get a ciphertext
denoted Ci and returns the Mi such that C = Ci. (This
works because CE is deterministic and keyless.) Security
is thus only possible when the target message is drawn
from a space too large to exhaust. We say that such a
message is unpredictable.

Bellare, Keelveedhi, and Ristenpart [18] treat MLE
formally, providing a deﬁnition (semantic-security for
unpredictable messages) to capture the best possible se-
curity achievable for MLE schemes in the face of the in-
herent limitation noted above. The deﬁnition is based

USENIX Association  

22nd USENIX Security Symposium  179

1

on previous ones for deterministic encryption, a primi-
tive subject to analogous inherent limitations [16,17,27].
The authors go on to show that CE and other mechanisms
achieve their deﬁnition in the random-oracle model.

The unpredictability assumption. The above-mentioned
work puts security on a ﬁrm footing in the case messages
are unpredictable. In practice, however, security only for
unpredictable data may be a limitation for, and threat to,
user privacy. We suggest two main reasons for this. The
ﬁrst is simply that data is often predictable. Parts of a
ﬁle’s contents may be known, for example because they
contain a header of known format, or because the adver-
sary has sufﬁcient contextual information. Some data,
such as very short ﬁles, are inherently low entropy. This
has long been recognized by cryptographers [43], who
typically aim to achieve security regardless of the distri-
bution of the data.

The other and perhaps more subtle fear with regard to
the unpredictability assumption is the difﬁculty of vali-
dating it or testing the extent to which it holds for “real”
data. When we do not know how predictable our data
is to an adversary, we do not know what, if any, secu-
rity we are getting from an encryption mechanism that is
safe only for unpredictable data. These concerns are not
merely theoretical, for ofﬂine dictionary attacks are rec-
ognized as a signiﬁcant threat to CE in real systems [77]
and are currently hindering deduplication of outsourced
storage for security-critical data.

This work. We design and implement a new system
called DupLESS (Duplicateless Encryption for Simple
Storage) that provides a more secure, easily-deployed
solution for encryption that supports deduplication.
In
DupLESS, a group of afﬁliated clients (e.g., company
employees) encrypt their data with the aid of a key server
(KS) that is separate from the SS. Clients authenticate
themselves to the KS, but do not leak any information
about their data to it. As long as the KS remains in-
accessible to attackers, we ensure high security.
(Ef-
fectively, semantic security [43], except that ciphertexts
leak equality of the underlying plaintexts. The latter is
necessary for deduplication.) If both the KS and SS are
compromised, we retain the current MLE guarantee of
security for unpredictable messages.

Unlike prior works that primarily incorporate CE into
new systems, our goal is to make DupLESS work trans-
parently with existing SS systems. DupLESS therefore
sits as a layer on top of existing simple storage interfaces,
wrapping store, retrieve, and other requests with algo-
rithms for encrypting ﬁlenames and data on the ﬂy. This
also means that DupLESS was built:
to be as feature-
compatible as possible with existing API commands, to
not assume any knowledge about the systems implement-
ing these APIs, to give performance very close to that of

using the SS without any encryption, and to achieve the
same availability level as provided by the SS.

We

a

implement DupLESS as

simple-to-use
command-line client that supports both Dropbox [3] and
Google Drive [7] as the SS. We design two versions of
the KS protocol that clients can use while encrypting
ﬁles. The ﬁrst protocol uses a RESTful, HTTPS based,
web interface, while the second is a custom protocol
built over UDP. The ﬁrst
is simpler, being able to
run on top of existing web servers, and the latter is
optimized for latency, and capable of servicing requests
at close to the (optimal) round-trip time of the network.
These protocols and their implementations, which at
core implement an oblivious pseudorandom function
(OPRF) [64] service, may be of independent interest.

To evaluate end-to-end performance, we deploy our
KS on Amazon EC2 [10] and experimentally evaluate
its performance. DupLESS incurs only slight overheads
compared to using the SS with plaintext data. For a
1 MB ﬁle and using Dropbox, the bandwidth overhead
is less than 1% and the overhead in the time to store a
ﬁle is about 17%. We compute storage overheads of as
little as 4.5% across a 2 TB dataset consisting of over
2,000 highly dedupable virtual machine ﬁle system im-
ages that we gathered from Amazon EC2. All this shows
that DupLESS is practical and can be immediately de-
ployed in most SS-using environments. The source code
for DupLESS is available from [4].

2 Setting

At a high level, our setting of interest is an enterprise
network, consisting of a group of afﬁliated clients (for
example, employees of a company) using a dedupli-
cated cloud storage service (SS). The SS exposes a sim-
ple interface consisting of only a handful of operations
such as storing a ﬁle, retrieving a ﬁle, listing a direc-
tory, deleting a ﬁle, etc.. Such systems are widespread
(c.f., [1, 3, 7, 11, 63]), and are often more suitable to user
ﬁle backup and synchronization applications than richer
storage abstractions (e.g., SQL) [37, 69] or block stores
(c.f., [9]). An example SS API, abstracted from Drop-
box, is detailed in Figure 5 (Section 6). The SS performs
deduplication along ﬁle boundaries, meaning it checks if
the contents of two ﬁles are the same and deduplicates
them if so, by storing only one of them.

Clients have access to a key server (KS), a semi-
trusted third party which will aid in performing dedu-
pable encryption. We will explain further the role of the
KS below. Clients are also provisioned with per-user en-
cryption keys and credentials (e.g., client certiﬁcates).

180  22nd USENIX Security Symposium 

USENIX Association

2

Threat model. Our goal is to protect the conﬁdentiality
of client data. Attackers include those that gain access
to the SS provider’s systems (including malicious insid-
ers working at the provider) and external attackers with
access to communication channels between clients and
the KS or SS. Security should hold for all ﬁles, not just
unpredictable ones.
In other words, we seek semantic
security, leaking only equality of ﬁles to attackers.

We will also be concerned with compromise re-
silience: the level of security offered by the scheme to
legitimate clients should degrade gracefully, instead of
vanishing, should other clients or even the KS be com-
promised by an attacker. Speciﬁcally, security should
hold at least for unpredictable ﬁles (of uncompromised
clients) when one or more clients are compromised and
when the KS is compromised.

We will match the availability offered by the SS, but
explicitly do not seek to ensure availability in the face
of a malicious SS: a malicious provider can always
choose to delete ﬁles. We will, however, provide pro-
tection against a malicious SS that may seek to tamper
with clients’ data, or mount chosen-ciphertext attacks,
by modifying stored ciphertexts.

Malicious clients can take advantage of an SS that per-
forms client-side deduplication to mount a side-channel
attack [46]. This arises because one user can tell if an-
other user has already stored a ﬁle, which could violate
the latter’s privacy.1 We will not introduce such side-
channels. A related issue is that client-side deduplica-
tion can be abused to perform illicit ﬁle transfers be-
tween clients [73]. We will ensure that our systems can
work in conjunction with techniques such as proofs-of-
ownership [45] that seek to prevent such issues.

We will not explicitly target resistance to trafﬁc anal-
ysis attacks that abuse leakage of access patterns [48] or
ﬁle lengths [24, 31, 40, 47, 59, 65, 72], though our system
will be compatible with potential countermeasures.

Our approaches may be used in conjunction with exist-
ing mechanisms for availability auditing [13, 41, 51, 70]
or ﬁle replication across multiple services [26]. (In the
latter case, our techniques will enable each service to in-
dependently perform deduplication.)

Design goals. In addition to our security goals, the sys-
tem we build will meet the following functionality prop-
erties. The system will be transparent, both from the per-
spective of clients and the SS. This means that the sys-
tem will be backwards-compatible, work within existing
SS APIs, make no assumptions about the implementation
details of the SS, and have performance closely matching
that of direct use of the SS. In normal operation and for
all clients of a particular KS, the space required to store

1The reader might be interested to note that our experience with the

Dropbox client suggests this side channel still exists.

all encrypted data will match closely the space required
when storing plaintext data. The system should never
reduce storage availability, even when the KS is unavail-
able or under heavy load. The system will not require any
client-side state beyond a user’s credentials. A user will
be able to sit down at any system, provide their creden-
tials, and synchronize their ﬁles. We will however allow
client-side caching of data to improve performance.

Related approaches. Several works have looked at the
general problem of enterprise network security, but none
provide solutions that meet all requirements from the
above threat model. Prior works [42,53,54,58,75] which
build a secure ﬁle system on top of a ﬂat outsourced stor-
age server break deduplication mechanisms and are unﬁt
for use in our setting. Convergent encryption (CE) based
solutions [8, 71], as we explored in the Introduction, pro-
vide security only for unpredictable messages even in the
best case, and are vulnerable to brute-force attacks. The
simple approach of sharing a secret key across clients
with a deterministic encryption scheme [16, 68] fails to
achieve compromise resilience. Using CE with an addi-
tional secret shared across all clients [76] does not work
for the same reason.

3 Overview of DupLESS

DupLESS starts with the observation that brute-force ci-
phertext recovery in a CE-type scheme can be dealt with
by using a key server (KS) to derive keys, instead of set-
ting keys to be hashes of messages. Access to the KS is
preceded by authentication, which stops external attack-
ers. The increased cost slows down brute-force attacks
from compromised clients, and now the KS can func-
tion as a (logically) single point of control for imple-
menting rate-limiting measures. We can expect that by
scrupulous choice of rate-limiting policies and parame-
ters, brute-force attacks originating from compromised
clients will be rendered less effective, while normal us-
age will remain unaffected.

We start by looking at secret-parameter MLE, an ex-
tension to MLE which endows all clients with a system-
wide secret parameter sk (see Section 4). The rationale
here is that if sk is unknown to the attacker, a high level
of security can be achieved (semantic security, except for
equality), but even if sk is leaked, security falls to that
of regular MLE. A server-aided MLE scheme then is a
transformation where the secret key is restricted to the
KS instead of being available to all clients. One sim-
ple approach to get server-aided MLE is to use a PRF
F, with a secret key K that never leaves the KS. A client
would send a hash H of a ﬁle to the KS and receive back
a message-derived key K′ ← F(K, H ). The other steps
are as in CE. However, this approach proves unsatisfying

USENIX Association  

22nd USENIX Security Symposium  181

3

from a security perspective. The KS here becomes a sin-
gle point of failure, violating our goal of compromise re-
silience: an attacker can obtain hashes of ﬁles after gain-
ing access to the KS, and can recover ﬁles with brute-
force attacks. Instead, DupLESS employs an oblivious
PRF (OPRF) protocol [64] between the KS and clients,
which ensures that the KS learns nothing about the client
inputs or the resulting PRF outputs, and that clients learn
nothing about the key. In Section 4, we propose a new
server-aided MLE scheme DupLESSMLE which com-
bines a CE-type base with the OPRF protocol based on
RSA blind-signatures [20, 29, 30].

Thus, a client, to store a ﬁle M, will engage in the
RSA OPRF protocol with the KS to compute a message-
derived key K, then encrypt M with K to produce a ci-
phertext Cdata. The client’s secret key will be used to en-
crypt K to produce a key encapsulation ciphertext Ckey.
Both Ckey and Cdata are stored on the SS. Should two
clients encrypt the same ﬁle, then the message-derived
keys and, in turn, Cdata will be the same (the key encap-
sulation Ckey will differ, but this ciphertext is small). The
DupLESS client algorithms are described in Section 6
along with how DupLESS handles ﬁlenames and paths.
Building a system around DupLESSMLE requires
careful design in order to achieve high performance. Du-
pLESS uses at most one or two SS API calls per op-
eration.
(As we shall see, SS API calls can be slow.)
Because interacting with the KS is on the critical path
for storing ﬁles, DupLESS incorporates a fast client-to-
KS protocol that supports various rate-limiting strategies.
When the KS is overloaded or subjected to denial-of-
service attacks, DupLESS clients fall back to symmet-
ric encryption, ensuring availability. On the client side,
DupLESS introduces dedup heuristics (see Section 6)
to determine whether the ﬁle about to be stored on the
SS should be selected for deduplication, or processed
with randomized encryption. For example, very small
ﬁles or ﬁles considered particularly sensitive can be pre-
vented from deduplication. We use deterministic authen-
ticated encryption (DAE) [68] to protect, in a structure-
preserving way,
the path and ﬁlename associated to
stored ﬁles. Here we have several choices along an ef-
ﬁciency/security continuum. Our approach of preserving
folder structure leaks some information to the SS, but on
the other hand, enables direct use of the SS-provided API
for ﬁle search and moving folders.

DupLESS is designed for a simple SS API, but can be
adapted to settings in which block-oriented deduplica-
tion is used, and to complex network storage and backup
solutions that use NFS [62], CIFS [56] and the like, but
we do not consider these further.

In the following sections we go into greater detail on
the various parts of the DupLESS system, starting with
the cryptographic primitives in Section 4, then moving

on to describing KS design in Section 5, and then on to
the client algorithms in Section 6, followed by perfor-
mance and security in Sections 7 and 8 respectively.

4 Cryptographic Primitives

A one-time encryption scheme SE with key space {0, 1}k
is a pair of deterministic algorithms (E, D). Encryption
E on input a key K ∈ {0, 1}k and message M ∈ {0, 1}∗
outputs a ciphertext C. Decryption D takes a key and
a ciphertext and outputs a message. CTR mode using
AES with a ﬁxed IV is such a scheme. An authen-
ticated encryption (AE) scheme is pair of algorithms
AE = (EA, DA) [19, 67]. Encryption EA takes as in-
put a key K ∈ {0, 1}k, associated data D ∈ {0, 1}∗, and
message M ∈ {0, 1}∗ and outputs a ciphertext of size
|M| +τd, where τd is the ciphertext stretch (typically, 128
bits). Decryption DA is deterministic; it takes input a
key, associated data, and a ciphertext and outputs a mes-
sage or error symbol ⊥. When encryption is determinis-
tic, we call the scheme a deterministic authenticated en-
cryption (DAE) scheme [68]. We use the Encrypt-then-
MAC [19] scheme for AE and SIV mode [68] for DAE,
both with HMAC[SHA256] and CTR[AES].

Oblivious PRFs. A (veriﬁable) oblivious PRF (OPRF)
scheme [64] consists of ﬁve algorithms OPRF =
(Kg, EvC, EvS, Vf, Ev), the last two deterministic. Key
$← Kg outputs a public key pk which
generation (pk, sk)
can be distributed freely among several clients, and a
secret key sk, which remains with a single entity, the
server. The evaluation protocol runs as follows: on the
client-side, EvC starts with an input x and ends with out-
put y such that y = Ev(sk, x), while on the server-side,
EvS starts with secret key sk and ends without output.
Figure 1 gives an example. Veriﬁcation Vf (pk, x, y) re-
turns a boolean. Security requires that (1) when keys
are picked at random, Ev(sk, ·) outputs are indistinguish-
able from random strings to efﬁcient attackers without
pk, and (2) no efﬁcient attacker, given (pk, sk), can pro-
vide x, x′, y such that Vf (pk, x, y) =Vf (pk, x′, y) = true,
or Vf (pk, x, y) = true but Ev(sk, x) �= y, or Vf (pk, x, y) =
false but Ev(sk, x) = y, except with negligible probabil-
ity. Moreover, in the OPRF protocol, the server learns
nothing about client inputs or resulting PRF outputs, and
the client learns nothing about sk.

Veriﬁable OPRF schemes can be built from deter-
ministic blind signatures [29]. The RSA-OPRF[G, H]
scheme based on RSA blind signatures [20, 30] is de-
scribed as follows. The public RSA exponent e is ﬁxed
as part of the scheme. Key generation Kg runs RSAKg
with input e to get N, d such that ed ≡ 1 mod φ(N), mod-
ulus N is the product of two distinct primes of roughly
equal length and N < e. Then, (N, (N, d)) is output as

182  22nd USENIX Security Symposium 

USENIX Association

4

EvS(N, d)

✲

x

y

✛

y ← xd mod N

EvC(N, M)

If e ≤ N then ret ⊥
r $← ZN

h ← H(M)

x ← h·re mod N

z ← y·r−1 mod N
If ze mod N �= h then ret ⊥

Else ret G(z)

Figure 1: The RSA-OPRF protocol. The key generation Kg
outputs PRF key N, d and veriﬁcation key N. The client uses
two hash functions H : {0, 1}∗ → ZN and G : ZN → {0, 1}k.

the public key, secret key pair. The evaluation proto-
col (EvC, EvS) with veriﬁcation Vf is shown in Figure 1.
The client uses a hash function H : {0, 1}∗ → ZN to ﬁrst
hash the message to an element of ZN , and then blinds
the result with a random group element r raised to the e-
th power. The resulting blinded hash, denoted x, is sent
to the KS. The KS signs it by computing y ← xd mod N,
and sends back y. Veriﬁcation then removes the blind-
ing by computing z ← yr−1 mod N, and then ensures that
ze mod N is indeed equal to H(M). Finally, the output of
the PRF is computed as G(z), where G : ZN → {0, 1}k is
another hash function.

N → Z∗

N , is a permutation on Z∗

This protocol can be shown to be secure as long as
the map fe : Z∗
N , deﬁned by fe(x) = xe mod N for
all x ∈ Z∗
N , which is assured by
gcd(ϕ(N), e) =1. In particular, this is true if the server
creates its keys honestly. However, in our setting, the
server can cheat while generating the keys, in an attempt
to glean something about H(M). This is avoided by re-
quiring that N < e, which will be veriﬁed by the client.
Given that e is prime, this standard technique ensures that
gcd(ϕ(N), e) = 1 even if N is maliciously generated, and
thus ensures that fe is a permutation. Since fe is a per-
mutation and the client checks the signature, even a ma-
licious server cannot force the output K = G(z) to be a
ﬁxed value or force two keys output for distinct messages
to collide, as long as G is collision-resistant.

MLE. A deterministic Message-Locked Encryption
(MLE) scheme is a tuple MLE = (P, K, E, D) of algo-
rithms, the last three deterministic2. Parameter gen-
eration outputs a public parameter P $← P, common to
all users of a system. To encrypt M, one generates
the message-derived key K ← K(P, M) and ciphertext

2We drop the tag generation algorithm which was part of the origi-
nal MLE formulation [18]. Since we restrict attention to deterministic
MLE schemes, we let ciphertexts work as tags.

C ← E(P, K, M). Decryption works as M ← D(P, K,C).
Security requires that no efﬁcient attacker can distin-
guish ciphertexts of unpredictable messages from ran-
dom strings except with negligible probability. Conver-
gent encryption (CE) [38] is the most prominent MLE
scheme. We use CE with parameters P set to random
128-bit strings, key generation returning the ﬁrst 128 bits
of SHA256(P � M) on input M, and encryption and de-
cryption being implemented with CTR[AES].

In a secret-parameter MLE scheme SPMLE, parame-
ter generation outputs a (system-wide) secret parameter
sk along with a public parameter P. This secret param-
eter, which is provided to all legitimate users, is used
to generate message-derived keys as K ← K(P, sk, M).
In a server-aided MLE scheme, the secret parameter is
provided only to a KS. Clients interact with the KS to
obtain message-derived keys. A simple of way of do-
ing this of course is that clients can send the messages
to the KS which would then reply with message-derived
keys. But, as we saw in the previous section, this is un-
desirable in the DupLESS setting, as the KS now be-
comes a single point of failure.
Instead, we propose
a new server-aided MLE scheme DupLESSMLE com-
bining RSA-OPRF[G, H] = (Kg, EvC, EvS, Vf, Ev) and
CTR[AES]. Here parameter generation runs Kg to get
(N, (N, d)), then outputs N as the public parameter and
(N, d) as the secret parameter (recall that e is ﬁxed as part
of the scheme). From a message M, a key K is gener-
ated as K ← Ev((N, d), M) = G(H(M)d mod N) by in-
teracting with the KS using EvC and EvS. Encryption
and decryption work as in CE, with CTR[AES]. We use
RSA1024 with full-domain-hash using SHA256 in the
standard way [22] to get H and G.

The advantage of server-aided MLE is the prospect
of multi-tiered security. In DupLESSMLE in particular,
when the adversary does not have access to the KS (but
has access to ciphertexts and OPRF inputs and outputs),
it has no knowledge of sk, and semantic-security sim-
ilar to deterministic SE schemes follows, from the se-
curity of RSA-OPRF[G, H] and CTR[AES]. When the
attacker has access to the KS additionally, attacks are
still constrained to be online and consequently slow, and
subject to rate-limiting measures that the KS imposes.
Security here relies on implementing the OPRF proto-
col correctly, and ensuring that the rate-limiting mea-
sures cannot be circumvented. We will analyze this care-
fully in Section 5. Even when sk is compromised to the
attacker, DupLESSMLE provides the usual MLE-style
security, conditioned on messages being unpredictable.
Moreover, we are guaranteed that the clients’ inputs are
hidden from the KS, even if the KS is under attack and
deviates from its default behavior, from the security of
the RSA-OPRF[G, H] protocol.

USENIX Association  

22nd USENIX Security Symposium  183

5

5 The DupLESS KS

In this section we describe the KS side of DupLESS. This
includes protocols for client-KS interaction which real-
ize RSA-OPRF[G, H], and rate limiting strategies which
limit client queries to slow down online brute-force at-
tacks. We seek low-latency protocols to avoid degrading
performance, which is important because the critical path
during encryption includes interaction with a KS. Addi-
tionally, the protocol should be light-weight, letting the
KS handle a reasonably high request volume.

We describe two protocols: OPRFv1, and OPRFv2,
which rely on a CA providing the KS and clients with
veriﬁable TLS certiﬁcates. In the following, we assume
that each client has a unique certiﬁcate, and that clients
can be identiﬁed by their certiﬁcates. Of course, the pro-
tocols can be readily converted to work with other au-
thentication frameworks. We believe our OPRF proto-
cols to be faster than previous implementations [36], and
given the support for rate-limiting, we expect that they
will be useful in other applications using OPRFs.

HTTPS based. In the ﬁrst protocol, OPRFv1, all com-
munication with the KS happens over HTTPS. The KS
exposes an interface with two procedures: KSInit and
KSReq. The ﬁrst time a client uses the KS, it makes a
KSInit request to obtain, and then locally cache, the KS’s
OPRF public key. Here the client must perform any nec-
essary checks of the public key, which for our scheme
is simply that e > N. When the client wants a key, say
for a ﬁle it is about to upload, the client will make use
of the KSReq interface, by sending an HTTPS POST
of the blinded hash value. Now, the KS checks request
validity, and performs rate-limiting measures which we
describe below. Then, the KS computes the signature
over the blinded hash value, and sends this back over the
established HTTPS channel.

OPRFv1 has the beneﬁt of extreme simplicity. With 20
lines of code (excluding rate limiting logic) in the form
of a Web-Server Gateway Interface (WSGI) Python mod-
ule, one can run the KS on top of most webservers. We
used Apache 2.0 in our implementation.

Unfortunately, while simple, this is a high latency so-
lution, as it requires four full round trips across the net-
work (1 for TCP handshake, 2 for the TLS handshake, 1
for the HTTP request) to perform KSReq. While sub-
second latency is not always critical (e.g., because of
poor SS performance or because the KS and clients share
a LAN), it will be critical in many settings, and so we
would like to do better.

UDP based. We therefore turn to OPRFv2, which re-
moves the slow per-request handshakes from the criti-
cal path of encryption. Here, the KSInit procedure starts
with a TLS handshake with mutual authentication, initi-

ated by a client. The KS responds immediately following
a valid handshake with the OPRF public key pk, a TLS
identiﬁer of a hash function H (by default SHA-256), a
random session identiﬁer S ∈ {0, 1}128, and a random
session key KS ∈ {0, 1}k (we set k = 128 in our imple-
mentations). We shave off one round trip from KSInit by
responding immediately, instead of waiting for an HTTP
message as in OPRFv1. The KS also associates a se-
quence number with this session, initialized to zero. In-
ternally the KS maintains two tables, one mapping ses-
sion identiﬁers with keys, and a second which keeps
track of sequence numbers. Each session lasts for a ﬁxed
time period (currently 20 minutes in our implementation)
and table entries are removed after the session expires.
The client caches pk, S and KS locally and initializes a
sequence number N = 0.

To make an OPRF request KSReq on a blinded value
X , the client ﬁrst increments the sequence number N ←
N + 1, then computes a MAC tag using its session key, as
T ← HMAC[H](KS, S � N � X ) and sends the concatena-
tion S � N � X � T to the KS in a single UDP packet. The
KS recovers S, N, X and T and looks up KS and NS. It
ensures that N > NS and checks correctness of the MAC
T . If the packet is malformed or if some check fails, then
the KS drops the packet without further action. If all the
checks pass, the KS sends the OPRF protocol response
in a single UDP packet.

The client waits for time tR after sending a KSReq
packet before triggering timeout behavior. In our imple-
mentation, this involves retrying the same request twice
more with time tR between the tries, incrementing the se-
quence number each time. After three attempts, the client
will try to initiate a new session, again timing out after
tR units. If this step fails, the client believes the KS to
be ofﬂine. This timeout behavior is based on DNS, and
following common parameters, we set tR = 1 second.

We implemented OPRFv2 in Python. It comes to 165
lines of code as indicated by the cloc utility, the bulk of
which is in fact the rate limiting logic discussed below.
Our current KS implementation is not yet optimized. For
example it spawns and kills a new thread for each con-
nection request (as opposed to keeping a pool of children
around, as in Apache). Nevertheless the implementation
is fully functional and performs well.

Rate limiting KS requests. We explore approaches for
per-client rate limiting.
In the ﬁrst approach, called
Bounded, the KS sets a bound q on the total number
of requests a client can make during a ﬁxed time inter-
val tE , called an epoch. Further queries by the client
will be ignored by the KS, until the end of the epoch.
Towards keeping the KS simple, a single timer controls
when epochs start and end, as opposed to separate timers
for each client that start when their client performs a ses-

184  22nd USENIX Security Symposium 

USENIX Association

6

sion handshake. It follows that no client can make more
than 2q queries within a tE -unit time period.

Setting q gives rise to a balancing act between online
brute-force attack speed and sufﬁciently low-latency KS
requests, since a legitimate client that exceeds its budget
will have to wait until the epoch ends to submit further
requests. However, when using these OPRF protocols
within DupLESS, we also have the choice of exploiting
the trade-off between dedupability and online brute-force
speed. This is because we can build clients to simply
continue with randomized encryption when they exceed
their budgets, thereby alleviating KS availability issues
for a conservative choice of q.

In any case, the bound q and epoch duration should
be set so as to not affect normal KS usage. Enterprise
network storage workloads often exhibit temporal self-
similarity [44], meaning that they are periodic. In this
case, a natural choice for the epoch duration is one pe-
riod. The bound q can be set to the expected number of
client requests plus some buffer (e.g., one or more stan-
dard deviations). Administrators will need to tune this
for their deployment; DupLESS helps ease this burden
by its tolerance of changes to q as discussed above.

We also considered two other mechanisms for rate
limiting. The ﬁxed delay mechanism works by intro-
ducing an artiﬁcial delay tD before the KS responds to
a client’s query. This delay can either be a system-wide
constant, or be set per client. Although this method is
the simplest to implement, to get good brute-force secu-
rity, the delay introduced would have to be substantially
high and directly impacts latency. The exponential delay
mechanism starts with a small delay, and doubles this
quantity after every query. The doubling stops at an up-
per limit tU . The server maintains synchronized epochs,
as in the bounded approach, and checks the status of ac-
tive clients after each epoch. If a client makes no queries
during an entire epoch, its delay is reset to the initial
value. In both these approaches, the server maintains an
active client list, which consists of all clients with queries
awaiting responses. New queries from clients in the ac-
tive client list are dropped. Client timeout in ﬁxed delay
is max(tD,tR) and in exponential delay it is max(tU ,tR).
To get a sense of how such rate-limiting mechanisms
might work in real settings, we estimate the effects on
brute-force attacks by deriving parameters from the char-
acteristics of a workload consisting of about 2,700 com-
puters running on an enterprise network at NetApp, as
reported in [57]. The workload is periodic, with simi-
lar patterns every week. The clients together make 1.65
million write queries/week, but the distribution is highly
skewed, and a single client could potentially be responsi-
ble for up to half of these writes. Let us be conservative
and say that our goal is to ensure that clients making at
most 825, 000 queries/week should be unaffected by rate-

Mechanism Rate formula NetApp Scenario

Bounded

Fixed delay

Exp. delay

None

Ofﬂine

2q/tE
1/tD
2tE /tU

3,200

2.73

1.36

2.73

3,200

120–12000

120–12000

Figure 2: Comparing brute-force rates in queries per second
for different rate limiting approaches, no rate limiting (None),
and hashes as computed using SHA-256 (Ofﬂine). The ﬁrst
column is the formula used to derive the rate as a function of
the request limit q, epoch duration tE , delay tD, and upper limit
tU . The second column is the rates as for the NetApp workload.
The None row does not include ofﬂine computation cost.

limiting. We set the epoch duration tE as one week and
query bound as q = 825k. The ﬁxed delay would need
to be set to 730 milliseconds (in order to facilitate 825k
requests in one week), which is also the upper limit tU
for the exponential technique.

The maximum query rates in queries per second that
an attacker who compromised a client can achieve are
given in Figure 2, along with the formulas used to calcu-
late them. The “None” row, corresponding to no rate lim-
iting, gives as the rate the highest number of replies per
second seen for OPRFv2 in the throughput experiment
above. The ofﬂine brute force rate was measured by run-
ning Intel’s optimized version of SHA256 [49] to get pro-
cessing speed as 120 MBps on our client system, whose
7200-RPM hard disk has peak read speed of 121MBps
(as measured by hdparm). The range then varies from
the number of hashes per second for 1 MB ﬁles up to the
number of hashes per second for 1 KB ﬁles, assuming
just a single system is used.

Despite being generous to ofﬂine brute-force attacks
(by just requiring computation of a hash, not considering
parallelization, and not including in the online attacks
any ofﬂine computational costs), the exercise shows the
huge beneﬁt of forcing brute-force attackers to query the
KS. For example, the bounded rate limiting mechanism
slows down brute-force attacks by anywhere from 43x
for large ﬁles up to 4,395x for small ﬁles. If the attacker
wants to identify a 1KB ﬁle which was picked at random
from a set S of 225 ﬁles, then the ofﬂine brute-force attack
requires less than an hour, while the bounded rate limited
attack requires more than twenty weeks.

We note that bounded rate-limiting is effective only
if the ﬁle has enough unpredictability to begin with. If
|S| < q = 825k, then the online brute-force attack will
be slowed down only by the network latency, meaning
that it will proceed at one-fourth the ofﬂine attack rate.
Moreover, parallelization will speed up both online and
ofﬂine attacks, assuming that this is permitted by the KS.

USENIX Association  

22nd USENIX Security Symposium  185

7

Operation

Latency (ms)

OPRFv1 KSReq (Low KS load)

OPRFv2 KSInit

OPRFv2 KSReq (Low KS load)

OPRFv2 KSReq (Heavy KS load)

Ping (1 RTT)

374 ± 34

278 ± 56

83 ± 16

118 ± 37

78 ± 01

Figure 3: The median time plus/minus one standard deviation
to perform KSInit and KSReq operations over 1000 trials. Low
KS load means the KS was otherwise idle, whereas Heavy KS
load means it was handling 3000 queries per second.

Performance. For the OPRF, as mentioned in Section 4,
we implement RSA1024 with full-domain-hash using
SHA256 in the standard way [22]. The PKI setup
uses RSA2048 certiﬁcates and we ﬁx the ECDHE-RSA-
AES128-SHA ciphersuite for the handshake. We set up
the two KS implementations (OPRFv1 and OPRFv2) on
Amazon EC2 m1.large instances. The client machine,
housed on a university LAN, had an x86-64 Intel Core
i7-970 processor with a clockspeed ﬁxed at 3201 MHz.
Figure 3 depicts the median times, in milliseconds, of
various operations for the two protocols. OPRFv2 signif-
icantly outperforms OPRFv1, due to the reduced number
of round trip times. On a lightly loaded server, a KS re-
quest requires almost the smallest possible time (the RTT
to the KS). The time under a heavy KS load was mea-
sured while a separate m1.large EC2 instance sent 3000
requests per second. The KS request time for OPRFv2
increases, but is still three times faster than OPRFv1
for a low KS load. Note that the time reported here is
only over successful operations; ones that timed out three
times were excluded from the median.

To understand the drop rates for the OPRFv2 protocol
on a heavily loaded server and, ultimately, the through-
put achievable with our (unoptimized) implementation,
we performed the following experiment. A client sent
100i UDP request packets per second (qps) until a total
of 10,000 packets are sent, once for each of 1 ≤ i ≤ 64.
The number of requests responded to was then recorded.
The min/max/mean/standard deviation over 100 trials are
shown in Figure 4. At rates up to around 3,000 queries
per second, almost no packets are dropped. We expect
that with further (standard) performance optimizations
this can be improved even further, allowing a single KS
to support a large volume of requests with very occa-
sional single packet drops.

Security of the KS protocols. Adversarial clients can
attempt to snoop on, as well as tamper with, commu-
nications between (uncompromised) clients and the KS.
With rate-limiting in play, adversaries can also attempt
to launch denial-of-service (DOS) attacks on uncompro-

d
e
i
l
p
e
r

s
e
i
r
e
u
q

f
o
e
g
a
t
n
e
c
r
e
P

100

80

60

40

20

Max

Min
Mean

29

210

211

212

213

214

215

Queries per second

Figure 4: Packet loss in OPRFv2 as a function of query rate.
Packet loss is negligible at rates < 3k queries per second.

mised clients, by spooﬁng packets from such clients. Fi-
nally, adversaries might try to circumvent rate-limiting.
A secure protocol must defend against all these threats.

Privacy of OPRF inputs and outputs follows from
blinding in the OPRF protocol. Clients can check
OPRF output correctness and hence detect tampering. In
OPRFv1, every KSReq interaction starts with a mutual-
authentication TLS handshake, which prevents adver-
saries from spooﬁng requests from other clients.
In
OPRFv2, creating a new session once again involves a
mutual-authentication TLS handshake, meaning that an
adversary cannot initiate a session pretending to be a un-
compromised client. Moreover, an adversary cannot cre-
ate a fresh KSReq packet belonging to a session which
it did not initiate, without a successful MAC forgery
(HMAC with SHA256 speciﬁcally). Packets cannot be
replayed across sessions, due to session identiﬁers being
picked at random and being included in the MAC, and
packets cannot be replayed within a session, due to in-
creasing sequence numbers. Overall, both protocols of-
fer protecting against request spooﬁng, and neither of the
two protocols introduce new denial-of-service vulnera-
bilities.

In the Bounded rate-limiting approach,

the server
keeps track of the total number of the queries made by
each client, across all sessions in an epoch, and stops
responding after the bound q is reached, meaning that
even adversarial clients are restricted to q queries per
epoch.
In the ﬁxed-delay and exponential-delay ap-
proaches, only one query from a client is handled at a
time by the KS in a session through the active clients list.
If a client makes a second query — even from a different
session, while a query is in process, the second query is
not processed by the KS, but simply dropped.

186  22nd USENIX Security Symposium 

USENIX Association

8

Command

Description

SSput(P, F, M)

Stores ﬁle contents M as P/F

SSget(P, F )

SSlist(P)

SSdelete(P, F )

SSsearch(P, F )

SScreate(P)

Gets ﬁle P/F

Gets metadata of P

Delete ﬁle F in P

Search for ﬁle F in P

Create directory P

SSmove(P1, F1, P2, F2) Move P1/F1 to P2/F2

Figure 5: API commands exposed by the storage service (SS)
used by DupLESS. Here F represents a ﬁlename and P is the
absolute path in a directory hierarchy.

6 The DupLESS client

The Dupless client works with an SS which implements
the interface described in Figure 5 (based on the Drop-
box API [39]), and provides an analogous set of com-
mands DLput, DLget, DLlist, etc. Figure 6 gives pseu-
docode for the DupLESS commands for storing and re-
trieving a ﬁle. We now explain the elements of these
commands, and will then discuss how other API com-
mands are handled.

Path and ﬁlename encryption. The SS provides a rudi-
mentary ﬁle system abstraction. Clients can generate
directories, use relative and absolute paths, move ﬁles
from one directory to another, etc. Following our design
goal of supporting as much of the base SS functional-
ity as possible, DupLESS should also support paths, ﬁle-
names, and related functionalities such as copying ﬁles.
One option is to treat paths and ﬁlenames as non-private,
and simply mirror in clear the directory hierarchy and
ﬁlenames asked for by a user. This has the beneﬁt of
simplicity and no path-related overheads, but it relies on
users guaranteeing that paths and ﬁlenames are, in fact,
not conﬁdential. A second option would be to hide the
directory structure from the SS by using just a single di-
rectory, and storing the client’s directory hierarchy and
ﬁlenames in completely encrypted form using some kind
of digest ﬁle. But this would increase complexity and
decrease performance as one would (essentially) have
to build a ﬁle system on top of the SS. For example,
this would bar use of the SS API to perform ﬁlename
searches on behalf of DupLESS.

We design DupLESS to provide some security for di-
rectory and ﬁlenames while still enabling effective use
of the SS APIs. To encrypt ﬁle and directory names,
we use the SIV DAE scheme [68] SIV = (ED, DD) with
HMAC[SHA256] and CTR[AES]. The EncPath subrou-
tine takes as input a DAE key Kdae, a path P (a sequence
of directory names separated by ‘/’), and a ﬁlename F,
and returns an encrypted path Cpath and an encrypted
ﬁlename F. It does so by encrypting each directory D

in P by way of ED(Kdae, 0, D) and likewise encrypting
F by ED(Kdae, 0, F ). (The associated data being set to
0 here will be used to distinguish this use from that of
the key encapsulation, see below.) Being deterministic,
twice encrypting the same ﬁle or directory name results
in the same ciphertext. We will then use the cipher-
texts, properly encoded into a character set allowed by
the SS, as the directory names requested in calls to, e.g.,
SScreate. We note that the choice of encoding as well
as the ciphertext stretch τd mean that the maximum ﬁle-
name length supported by DupLESS will be shorter than
that of the SS. Should this approach prove limiting, an
alternative approach would be to use format-preserving
encryption [21] instead to reduce ciphertext expansion.

All this means that we will be able to search for ﬁle
and directory names and have efﬁcient ﬁle copy and
move operations. That said, this approach does leak the
structure of the plaintext directory hierarchy, the lengths
of individual directory and ﬁle names, and whether two
ﬁles have the same name. While length leakage can be
addressed with padding mechanisms at a modest cost on
storage overhead, hierarchy leakage cannot be addressed
without adversely affecting some operations.

Store requests. To store a ﬁle with ﬁlename F and con-
tents M at path P, the DupLESS client ﬁrst executes the
client portion of the KS protocol (see Section 5). The re-
sult is either a message-derived key K or an error mes-
sage ⊥. The client then runs a check canDedup to
determine whether to use dedupable encryption or non-
dedupable encryption. If K = ⊥ or canDedup returns
false, then a random key is selected and will be used in
place of a message-derived key. In this case the resulting
ciphertext will not be dedupable. We discuss canDedup
more below. The client next encrypts M under K with
CTR[AES] and a ﬁxed IV to produce ciphertext Cdata,
and then wraps K using SIV to produce ciphertext Ckey.
We include the ﬁlename ciphertext Cname and Cdata in or-
der to cryptographically bind together the three cipher-
texts. The client uploads to the SS via the SSput com-
mand the ﬁle “Cname.key” with contents Ckey and Cdata
in ﬁle “Cname.data”. DupLESS encodes the ciphertexts
into character sets allowed by the SS API. Both ﬁles are
uploaded in parallel to the SS. Usually, the SS might re-
quire the client to be authorized, and if this is the case,
the authorization can be handled when the client starts.

The “.data” ﬁle contains only ciphertext Cdata, and can
be deduplicated by the SS assuming K was not replaced
by a random value. The “.key” ﬁle cannot be dedu-
plicated, its contents being essentially uniformly dis-
tributed, but requires only a ﬁxed, small number of bits
equal to k + τd. With our instantiation choices, this is
384 bits, and does not lead to signiﬁcant overheads as
we show in Section 7.

USENIX Association  

22nd USENIX Security Symposium  187

9

(P, F, M)

DLputKdae,Kae,pkks
K $← EvCEvS
Cpath,Cname ← EncPath(Kdae, P, F )
If canDedup(P, F, M) =false then

(pkks, M)

Cdata ← EA(Kae,Cname, M)
SSput(Cpath , Cname � “.data” , Cdata)

Else

If K = ⊥ then K $← {0, 1}k
Cdata ← E(K, M)
Ckey ← ED(Kdae, 1 �Cname �Cdata, K)
SSput(Cpath , Cname � “.key” , Ckey)
SSput(Cpath , Cname � “.data” , Cdata)

(P, F )

DLgetKdae,Kae
Cpath,Cname ← EncPath(Kdae, P, F )
Cdata ← SSget(Cpath , Cname � “.data”)
Ckey ← SSget(Cpath , Cname � “.key”)
If Ckey = ⊥ then

Return DA(Kae,Cname,Cdata)

Else

K ← DD(Kdae, 1 �Cname �Cdata,Ckey)
If K = ⊥ then

Ret ⊥

Else

Ret D(K,Cdata)

Figure 6: DupLESS client procedures for storage and retrieval. They use our server-aided MLE scheme DupLESSMLE =
(P, K, E, D), built with RSA-OPRF[G, H] = (Kg, EvC, EvS, Vf, Ev) along with the DAE scheme SIV = (ED, DD), and the AE
scheme EtM = (EA, DA). Instantiations are as described in text. The subroutine canDedup runs dedup heuristics while EncPath
encrypts the path and ﬁle name using SIV.

Dedupability control. The canDedup subroutine en-
ables ﬁne-grained control over which ﬁles end up get-
ting deduplicated, letting clients enforce polices such as
not deduplicating anything in a personal folder, and set-
ting a lower threshold on size. Our current implementa-
tion uses a simple length heuristic: ﬁles less than 1 KB
in size are not deduplicated. As our experiments show
in Section 7, employing this heuristic does not appear to
signiﬁcantly degrade storage savings.

By default, DLput ensures that ciphertexts are of the
same format regardless of the output of canDedup.
However, should canDedup mark ﬁles non-dedupable
based only on public information (such as ﬁle length),
then we can further optimize performance by produc-
ing only a single ciphertext ﬁle (i.e. no Ckey) using an
authenticated-encryption scheme with a key Kae derived
from the client’s secret key. We use AES in CTR mode
with random IVs with HMAC in an Encrypt-then-MAC
scheme. This provides a slight improvement in storage
savings over non-deduped ciphertexts and requires just
a single SSput call. We can also query the KS only if
needed, which is more efﬁcient.

When canDedup’s output depends on private infor-
mation (e.g., ﬁle contents), clients should always interact
with the KS. Otherwise there exists a side channel attack
in which a network adversary infers from the lack of a
KS query the outcome of canDedup.

Retrieval and other commands. The pseudocode for re-
trieval is given in Figure 6. It uses EncPath to recom-
pute the encryptions of the paths and ﬁlenames, and then
issues SSget calls to retrieve both Ckey and Cdata. It then
proceeds by decrypting Ckey, recovering K, and then us-
ing it to decrypt the ﬁle contents. If non-dedupable en-
cryption was used and Ckey was not uploaded, the second

SSget call fails and the client decrypts accordingly.

Other commands are implemented in natural ways,
and we omit pseudocode for the sake of brevity. Dup-
LESS includes listing the contents of a directory (per-
form an SSlist on the directory and decrypt the paths
and ﬁlenames); moving the contents of one directory to
another (perform an SSmove command with encrypted
path names); search by relative path and ﬁlename (per-
form an SSsearch using the encryptions of the relative
path and ﬁlename); create a directory (encrypt the direc-
tory name and then use SScreate); and delete (encrypt
the path and ﬁlename and perform a delete on that).

The operations are, by design, simple and whenever
possible, one-to-one with underlying SS API commands.
The security guarantees of SIV mean that an attacker
with access to the SS cannot tamper with stored data. An
SS-based attacker could, however, delete ﬁles or modify
the hierarchy structure. While we view these attacks as
out of scope, we note that it is easy to add directory hi-
erarchy integrity to DupLESS by having EncPath bind
ciphertexts for a directory or ﬁle to its parent: just in-
clude the parent ciphertext in the associated data during
encryption. The cost, however, is that ﬁlename search
can only be performed on full paths.

In DupLESS, only DLput requires interaction with the
KS, meaning that even if the KS goes down ﬁles are
never lost. Even DLput will simply proceed with a ran-
dom key instead of the message-derived key from the
KS. The only penalty in this case is loss of the storage
savings due to deduplication.

Other APIs. The interface in Figure 5 is based on the
Dropbox API [39]. Google Drive [7] differs by index-
ing ﬁles based on unique IDs instead of names. When a
ﬁle is uploaded, SSput returns a ﬁle ID, which should be

188  22nd USENIX Security Symposium 

USENIX Association

10

provided to SSget to retrieve the ﬁle. The SSlist func-
tion returns a mapping between the ﬁle names and their
IDs. In this case, DupLESS maintains a local map by
prefetching and caching ﬁle IDs by calling SSlist when-
ever appropriate; this caching reduces DLget latency.
When a ﬁle is uploaded, the encrypted ﬁlename and re-
turned ID are added to this map. Whenever a local map
lookup fails, the client runs SSlist again to check for an
update. Hence, the client can start without any local state
and dynamically generate the local map.

Supporting keyword search in DupLESS requires ad-
ditional techniques, such as an encrypted keyword index
as in searchable symmetric encryption [34], increasing
storage overheads. We leave exploring the addition of
keyword search to future work.

7

Implementation and Performance

We implemented a fully functional DupLESS client. The
client was written in Python and supports both Drop-
box [3] and Google Drive [7]. It will be straightforward
to extend the client to work with other services which
export an API similar to Figure 5. The client uses two
threads during store operations in order to parallelize the
two SS API requests. The client takes user credentials
as inputs during startup and provides a command line
interface for the user to type in commands and argu-
ments. When using Google Drive, a user changing di-
rectory prompts the client to fetch the ﬁle list ID map
asynchronously. We used Python’s SSL and Crypto li-
braries for the client-side crypto operations and used the
OPRFv2 KS protocol.

We now describe the experiments we ran to mea-
sure the performance and overheads of DupLESS. We
will compare both to direct use of the underlying SS
API (no encryption) as well as when using a version
of DupLESS modiﬁed to implement just MLE, in par-
ticular the convergent encryption (CE) scheme, instead
of DupLESSMLE. This variant computes the message-
derived key K by hashing the ﬁle contents, thereby avoid-
ing use of the KS. Otherwise the operations are the same.

Test setting and methodology. We used the same ma-
chine as for the KS tests (Section 5). Measurements in-
volving the network were repeated 100 times and other
measurements were repeated 1,000 times. We measured
running times using the timeit Python module. Opera-
tions involving ﬁles were repeated using ﬁles with ran-
dom contents of size 22i KB for i ∈ {0, 1, . . . , 8}, giving
us a ﬁle size range of 1 KB to 64 MB.

Dropbox exhibited signiﬁcant performance variability
in the course of our experiments. For example, the me-
dian time to upload a 1 KB ﬁle was 0.92 seconds, while
the maximum observed was 2.64 seconds, with standard

deviation at 0.22 seconds. That is close to 25% of the
median. Standard deviation decreases as the ﬁle size
increases, for example it is only 2% of the median up-
load time for 32 MB ﬁles. We never observed more than
1 Mbps throughput to Dropbox. Google Drive exhibited
even slower speeds and more variance.

Storage and retrieval latency. We now compare the time
to store and retrieve ﬁles using DupLESS, CE, and the
plain SS. Figure 7 (top left chart) reports the median time
for storage using Dropbox. The latency overhead when
storing ﬁles with DupLESS starts at about 22% for 1 KB
ﬁles and reduces to about 11% for 64 MB ﬁles.

As we mentioned earlier, Dropbox and Google Drive
exhibited signiﬁcant variation in overall upload and
download times. To reduce the effect of these variations
on the observed relative performance between DupLESS
over the SS, CE over the SS and plain SS, we ran the
tests by cycling between the three settings to store the
same ﬁle, in quick succession, as opposed to, say, run-
ning all plain Dropbox tests ﬁrst. We adopted a similar
approach with Google Drive.

We observe that the CE (Convergent Encryption) store
times are close to DupLESS store times, since the
KSReq step, which is the main overhead of DupLESS
w.r.t CE, has been optimized for low latency. For ex-
ample, median CE latency overhead for 1 KB ﬁles over
Dropbox was 15%. Put differently, the overhead of mov-
ing to DupLESS from using CE is quite small, compared
to that of using CE over the base system.

Relative retrieval latencies (bottom left, Figure 7) for
DupLESS over Dropbox were lower than the store laten-
cies, starting at about 7% for 1 KB ﬁles and reducing to
about 6% for 64 MB ﬁles.

Performance with Google Drive (Figure 7, top middle
chart) follows a similar trend, with overhead for Dup-
LESS ranging from 33% to 8% for storage, and 40% to
10% for retrieval, when ﬁle sizes go from 1 KB to 64 MB.
These experiments report data only for ﬁles larger
than 1 KB, as smaller ﬁles are not selected for dedu-
plication by canDedup. Such ﬁles are encrypted with
non-dedupable, randomized encryption and latency over-
heads for storage and retrieval in these cases are negligi-
ble in most cases.

Microbenchmarks. We ran microbenchmarks on DLput
storing 1MB ﬁles, to get a breakdown of the overhead.
We report median values over 100 trials here. Up-
loading a 1 MB ﬁle with Dropbox takes 2700 millisec-
onds (ms), while time for the whole DLput operation
is 3160 ms, with a 17% overhead. The KSReq latency,
from Section 5, is 82 ms or 3%. We measured the total
time for all DLput steps except the two SSput operations
(refer to Figure 6) to be 135 ms, and uploading the con-
tent ﬁle on top of this took 2837 ms. Then, net overhead

USENIX Association  

22nd USENIX Security Symposium  189

11

s
d
n
o
c
e
s
i
l
l
i

m
n
i

e
m
T

i

s
d
n
o
c
e
s
i
l
l
i

m
n
i

e
m
T

i

216

214

212

210

28

20

214

212

210

28

20

DupLESS

Convergent Encryption

Dropbox

24

28

212

216

DupLESS

Dropbox

24

28

212

216

File size (KB)

216

214

212

210

28

20

214

212

210

28

20

DupLESS

Convergent Encryption

Google Drive

DupLESS

Dropbox

213

211

29

27

24

28

212

216

20

24

28

212

216

DupLESS

Google Drive

DupLESS

Dropbox

213

211

29

27

24

28

212

216

20

24

28

212

216

File size (KB)

File size (KB)

Figure 7: (Left) Median time to store (top two graphs) and retrieve (bottom two graphs) as a function of ﬁle size. (Top Right)
Median time to delete a ﬁle as a function of ﬁle size. (Bottom Right) Median time to copy a ﬁle as a function of ﬁle size. All axes
are log-scale and error bars indicate one standard deviation. Standard deviations are displayed only for base Dropbox/Google Drive
times to reduce cluttering.

of KS and cryptographic operations is about 5%, while
storing the key ﬁle accounts for 12%. Our implementa-
tion of DLput stores the content and key ﬁles simultane-
ously, by spawning a new thread for storing the key, and
waiting for both the stores to complete before ﬁnishing.
If DLput exits before the key store thread completes, i.e.,
if the key is uploaded asynchronously, then the overhead
drops to 14%. On the other hand, uploading the ﬁles se-
quentially by storing the content ﬁle ﬁrst, and then stor-
ing the key, incurs a 54% overhead (for 1 MB ﬁles).

Bandwidth overhead. We measured the increase in
transmission bandwidth due to DupLESS during storage.
To do so, we used tcpdump and ﬁltered out all trafﬁc un-
related to Dropbox and DupLESS. We took from this the
total number of bytes (in either direction). For even very
small ﬁles, the Dropbox API incurs a cost of about 7 KB
per upload. Figure 8 (middle) shows the ratio of band-
width used by DupLESS to that used by plain Dropbox
as ﬁle size increases. Given the small constant size of the
extra ﬁle sent by DupLESS, overhead quickly diminishes
as ﬁles get larger.

Storage overhead. DupLESS incurs storage overhead,
due to the encrypted ﬁle name, the MLE key, and the
MAC. The sizes of these components are independent of
the length of the ﬁle. Let n denote the length of the ﬁle-
name in bytes. Then, encrypting the ﬁlename with SIV
and encoding the result with base64 encoding consumes

2n + 32 bytes. Repeating the process for the content
and key ﬁles, and adding extensions brings the ﬁle name
overhead to 4n + 72 − n = 3n + 72 bytes. The contents of
the key ﬁle include the MLE key, which is 16 bytes long
in our case, and the 32 byte HMAC output, and hence
48 bytes together. Thus, the total overhead for a ﬁle with
an n-byte ﬁlename is 3n + 120 bytes. Recall that if the
ﬁle size is smaller than 1 KB, then canDedup rejects the
ﬁle for deduplication. In this case, the overhead from en-
crypting and encoding the ﬁle name is n + 32 bytes, since
only one ﬁle is stored. Randomized encryption adds 16
bytes, bringing the total to n + 48 bytes.

To assess the overall effect of this in practice, we
collected a corpus of around 2,000 public Amazon vir-
tual machine images (AMIs) hosting Linux guests. The
AMIs were gathered using techniques similar to those
used previously [14, 28], the difference being that we
as well downloaded a snapshot of the full ﬁle system
for each public AMI. There are 101,965,188 unique ﬁles
across all the AMIs, with total content size of all ﬁles be-
ing 2,063 GB. We computed cryptographic hashes over
the content of all ﬁles in the dataset, in order to simulate
the storage footprint when using plain deduplication as
well as when using DupLESS. This dataset has signiﬁ-
cant redundancy, as one would expect, given that many
AMIs are derivative of other AMIs and so share com-
mon ﬁles. The plain dedup storage required for the ﬁle
contents is just 335 GB. DupLESS with the dedupability

190  22nd USENIX Security Symposium 

USENIX Association

12

DupLESS

Dropbox

s
d
n
o
c
e
s
i
l
l
i

m
n
i

e
m
T

i

213

211

29

27

d
a
e
h
r
e
v
o

h
t
d
i
w
d
n
a
B

1.8

1.6

1.4

1.2

1

1.4

1.3

1.2

1.1

t
e
s
a
t
a
d

.
c
n
e

f
o

e
z
i
s

e
v
i
t
a
l
e
R

20

24
Number of ﬁles

28

212

21

24

27

210

213

216

1,000 2,000

4,000

6,000

8,000

File size (KB)

Threshold size in bytes

Figure 8: (Left) Median time to list a directory as a function of number of ﬁles in the directory. Both axes are logscale and error
bars are one standard deviation. (Middle) Network bandwidth overhead of DupLESS as a function of ﬁle size (log-scale axis) for
store operations. (Right) The ratio of space required when DupLESS is used for the AMI dataset and when plain dedup is used, as
a function of the dedupable threshold length.

length threshold used by canDedup (see Section 6) set
to zero (all ﬁles were dedupable) requires 350 GB, or an
overhead of about 4.5%. In this we counted the size of
the ﬁlename and path ciphertexts for the DupLESS esti-
mate, though we did not count these in the base storage
costs. (This can only inﬂate the reported overhead.)

We also measure the effect of higher threshold val-
ues, when using non-dedupable encryption. Setting the
threshold to 100 bytes saves a few hundred megabytes in
storage. This suggests little beneﬁt from deduping small
ﬁles, which is in line with previous observations about
deduplication on small ﬁles [61].

Figure 8 plots the storage used for a wide range of
threshold values. Setting a larger threshold leads to im-
proved security (for those ﬁles) and faster uploads (due
to one less SSput request) and appears to have, at least
for this dataset, only modest impact on storage overheads
for even moderately sized thresholds.

The above results may not extend to settings with sig-
niﬁcantly different workloads. For example, we caution
when there is signiﬁcantly less deduplication across the
corpus, DupLESS may introduce greater overhead.
In
the worst case, when there is no deduplication what-
soever and all 1 KB ﬁles with long names of about
100 characters, the overhead will be almost 30%. Of
course here one could have canDedup force use of non-
dedupable encryption to reduce overhead for all ﬁles.

Overhead of other operations. The time to perform
DLmove, DLdelete, and DLlist operations are reported
in Figure 7 and Figure 8 for Dropbox. In these opera-
tions, the DupLESS overheads and the data sent over the
network involve just the ﬁlenames, and do not depend on
the length of the ﬁle. (The operations themselves may
depend on ﬁle length of course.) The overhead of Dup-
LESS therefore remains constant. For DLlist, DupLESS
times are close to those of plain Dropbox for folders with
twice as many ﬁles, since DupLESS stores an extra key

encapsulation ﬁle for each user ﬁle. We also measured
the times for DLsearch and DLcreate, but in these cases
the DupLESS overhead was negligible.

8 Security of DupLESS

We argued about the security of the KS protocols and
client encryption algorithms in sections 5 and 6. Now,
we look at the big picture, the security of DupLESS as a
whole. DupLESS provides security that is usually signif-
icantly better than current, convergent encryption based
deduplicated encryption architectures, and never worse.
To expand, security is “hedged,” or multi-tiered, and we
distinguish three tiers, always assuming that the adver-
sary has compromised the SS and has the ciphertexts.

The optimistic or best case is that

the adversary
does not have authorized access to the KS. Recall that
both OPRFv1 and OPRFv2 need clients to authenticate
ﬁrst, before requesting queries, meaning that in this set-
ting, the attacker cannot obtain any information about
message-derived keys. These keys are effectively ran-
dom to the attacker. In other words, all data stored on
the SS is encrypted with random keys, including ﬁle con-
tents, names and paths. The attacker can only learn about
equality of ﬁle contents and the topology of the ﬁle sys-
tem (including ﬁle sizes). Thus, DupLESS provides, ef-
fectively, semantic security. In particular, security holds
even for predictable messages. By using the SIV DAE
scheme, and generating tags over the ﬁle names, ﬁle con-
tents and keys, DupLESS ensures that attempts by the SS
to tamper with client data will be detected.

The semi-optimistic, or next best case is that the ad-
versary, having compromised one or more clients, has
remote access to the KS but does not have the KS’s se-
cret key. Here, security for completely predictable ﬁles
is impossible. Thus, it is crucial to slow down brute-
force attacks and push the feasibility threshold for the
attacker. We saw in Section 5 that with the right rate-

USENIX Association  

22nd USENIX Security Symposium  191

13

limiting setup (Bounded, with appropriate parameters),
brute-force attacks can be slowed down signiﬁcantly. Im-
portantly, attackers cannot circumvent the rate-limiting
measures, by say, repeating queries.

Finally, the pessimistic case is that the adversary has
compromised the KS and has obtained its key. Even then,
we retain the guarantees of MLE, and speciﬁcally CE,
meaning security for unpredictable messages [18]. Ap-
propriate deployment scenarios, such as locating the KS
within the boundary of a large corporate customer of a
SS, make the optimistic case the most prevalent, result-
ing in appreciable security gains without signiﬁcant in-
crease in cost. The security of non-deduplicated ﬁles, ﬁle
names, and path names is unaffected by these escalations
in attack severity.

9 Conclusions

We studied the problem of providing secure outsourced
storage that both supports deduplication and resists
brute-force attacks. We design a system, DupLESS, that
combines a CE-type base MLE scheme with the ability to
obtain message-derived keys with the help of a key server
(KS) shared amongst a group of clients. The clients in-
teract with the KS by a protocol for oblivious PRFs, en-
suring that the KS can cryptographically mix in secret
material to the per-message keys while learning nothing
about ﬁles stored by clients.

These mechanisms ensure that DupLESS provides
strong security against external attacks which compro-
mise the SS and communication channels (nothing is
leaked beyond ﬁle lengths, equality, and access patterns),
and that the security of DupLESS gracefully degrades
in the face of comprised systems. Should a client be
compromised, learning the plaintext underlying another
client’s ciphertext requires mounting an online brute-
force attacks (which can be slowed by a rate-limited KS).
Should the KS be compromised, the attacker must still
attempt an ofﬂine brute-force attack, matching the guar-
antees of traditional MLE schemes.

The substantial increase in security comes at a mod-
est price in terms of performance, and a small increase in
storage requirements relative to the base system. The low
performance overhead results in part from optimizing the
client-to-KS OPRF protocol, and also from ensuring Du-
pLESS uses a low number of interactions with the SS.
We show that DupLESS is easy to deploy: it can work
transparently on top of any SS implementing a simple
storage interface, as shown by our prototype for Drop-
box and Google Drive.

Acknowledgements

We thank the anonymous USENIX Security 2013 re-
viewers for their valuable comments and feedback. We
thank Matt Green for his feedback on early drafts of
the paper. Ristenpart was supported in part by generous
gifts from Microsoft, RSA Labs, and NetApp. Bellare
and Keelveedhi were supported in part by NSF grants
CNS-1228890, CNS-1116800, CNS 0904380 and CCF-
0915675.

References

[1] Bitcasa, iniﬁnite storage. http://www.bitcasa.com/.

[2] Ciphertite data backup. http://www.ciphertite.

com/.

[3] Dropbox, a ﬁle-storage and sharing service. http://www.

dropbox.com/.

[4] Dupless source code. http://cseweb.ucsd.edu/

users/skeelvee/dupless.

[5] The Flud backup system. http://flud.org/wiki/

Architecture.

[6] GNUnet, a framework for secure peer-to-peer networking.

https://gnunet.org/.

[7] Google Drive. http://drive.google.com.

[8] ADYA, A., BOLOSKY, W., CASTRO, M., CERMAK, G.,
CHAIKEN, R., DOUCEUR, J., HOWELL, J., LORCH, J.,
THEIMER, M., AND WATTENHOFER, R. Farsite: Federated,
available, and reliable storage for an incompletely trusted envi-
ronment. ACM SIGOPS Operating Systems Review 36, SI (2002),
1–14.

[9] AMAZON. Amazon Elastic Block Store (EBS). http://

aws.amazon.com/ebs.

[10] AMAZON. Amazon Elastic Compute Cloud (EC2). http://

aws.amazon.com/ec2.

[11] AMAZON. Amazon Simple Storage Service (Amazon S3).

http://aws.amazon.com/s3.

[12] ANDERSON, P., AND ZHANG, L. Fast and secure laptop backups
with encrypted de-duplication. In Proc. of USENIX LISA (2010).

[13] ATENIESE, G., BURNS, R. C., CURTMOLA, R., HERRING, J.,
KISSNER, L., PETERSON, Z. N. J., AND SONG, D. Provable
data possession at untrusted stores. In ACM CCS 07 (Alexandria,
Virginia, USA, Oct. 28–31, 2007), P. Ning, S. D. C. di Vimercati,
and P. F. Syverson, Eds., ACM Press, pp. 598–609.

[14] BALDUZZI, M., ZADDACH, J., BALZAROTTI, D., KIRDA, E.,
AND LOUREIRO, S. A security analysis of amazon’s elastic com-
pute cloud service. In Proceedings of the 27th Annual ACM Sym-
posium on Applied Computing (2012), ACM, pp. 1427–1434.

[15] BATTEN, C., BARR, K., SARAF, A., AND TREPETIN, S. pStore:
A secure peer-to-peer backup system. Unpublished report, MIT
Laboratory for Computer Science (2001).

[16] BELLARE, M., BOLDYREVA, A., AND O’NEILL, A. Deter-
ministic and efﬁciently searchable encryption. In CRYPTO 2007
(Santa Barbara, CA, USA, Aug. 19–23, 2007), A. Menezes, Ed.,
vol. 4622 of LNCS, Springer, Berlin, Germany, pp. 535–552.

[17] BELLARE, M., FISCHLIN, M., O’NEILL, A., AND RISTEN-
PART, T. Deterministic encryption: Deﬁnitional equivalences
and constructions without random oracles.
In CRYPTO 2008
(Santa Barbara, CA, USA, Aug. 17–21, 2008), D. Wagner, Ed.,
vol. 5157 of LNCS, Springer, Berlin, Germany, pp. 360–378.

192  22nd USENIX Security Symposium 

USENIX Association

14

[18] BELLARE, M., KEELVEEDHI, S., AND RISTENPART, T.
Message-locked encryption and secure deduplication.
In EU-
ROCRYPT 2013, to appear. Cryptology ePrint Archive, Report
2012/631, November 2012.

[19] BELLARE, M., AND NAMPREMPRE, C. Authenticated encryp-
tion: Relations among notions and analysis of the generic compo-
sition paradigm. In ASIACRYPT 2000 (Kyoto, Japan, Dec. 3–7,
2000), T. Okamoto, Ed., vol. 1976 of LNCS, Springer, Berlin,
Germany, pp. 531–545.

[20] BELLARE, M., NAMPREMPRE, C., POINTCHEVAL, D., AND
SEMANKO, M. The one-more-RSA-inversion problems and the
security of Chaum’s blind signature scheme. Journal of Cryptol-
ogy 16, 3 (June 2003), 185–215.

[21] BELLARE, M., RISTENPART, T., ROGAWAY, P., AND STEGERS,
T. Format-preserving encryption. In SAC 2009 (Calgary, Alberta,
Canada, Aug. 13–14, 2009), M. J. Jacobson Jr., V. Rijmen, and
R. Safavi-Naini, Eds., vol. 5867 of LNCS, Springer, Berlin, Ger-
many, pp. 295–312.

[22] BELLARE, M., AND ROGAWAY, P. Random oracles are practical:
A paradigm for designing efﬁcient protocols. In ACM CCS 93
(Fairfax, Virginia, USA, Nov. 3–5, 1993), V. Ashby, Ed., ACM
Press, pp. 62–73.

[23] BELLARE, M., AND YUNG, M. Certifying permutations: Non-
interactive zero-knowledge based on any trapdoor permutation.
Journal of Cryptology 9, 3 (1996), 149–166.

[24] BISSIAS, G., LIBERATORE, M., JENSEN, D., AND LEVINE,
B. N. Privacy Vulnerabilities in Encrypted HTTP Streams. In
Proceedings of the Privacy Enhancing Technologies Workshop
(May 2005), pp. 1–11.

[25] BONEH, D., GENTRY, C., HALEVI, S., WANG, F., AND WU,
D. Private database queries using somewhat homomorphic en-
cryption.

[26] BOWERS, K. D., JUELS, A., AND OPREA, A. HAIL: a high-
availability and integrity layer for cloud storage. In ACM CCS 09
(Chicago, Illinois, USA, Nov. 9–13, 2009), E. Al-Shaer, S. Jha,
and A. D. Keromytis, Eds., ACM Press, pp. 187–198.

[27] BRAKERSKI, Z., AND SEGEV, G. Better security for deter-
ministic public-key encryption: The auxiliary-input setting.
In
CRYPTO 2011 (Santa Barbara, CA, USA, Aug. 14–18, 2011),
P. Rogaway, Ed., vol. 6841 of LNCS, Springer, Berlin, Germany,
pp. 543–560.

[28] BUGIEL, S., N ¨URNBERGER, S., P ¨OPPELMANN, T., SADEGHI,
A., AND SCHNEIDER, T. Amazonia: when elasticity snaps back.
In ACM Conference on Computer and Communications Secu-
rity – CCS ‘11 (2011), ACM, pp. 389–400.

[29] CAMENISCH, J., NEVEN, G., AND SHELAT, A. Simulatable
adaptive oblivious transfer.
In EUROCRYPT 2007 (Barcelona,
Spain, May 20–24, 2007), M. Naor, Ed., vol. 4515 of LNCS,
Springer, Berlin, Germany, pp. 573–590.

[30] CHAUM, D. Blind signatures for untraceable payments.

In
CRYPTO’82 (Santa Barbara, CA, USA, 1983), D. Chaum, R. L.
Rivest, and A. T. Sherman, Eds., Plenum Press, New York, USA,
pp. 199–203.

[31] CHEN, S., WANG, R., WANG, X., AND ZHANG, K. Side-
Channel Leaks in Web Applications: a Reality Today, a Chal-
lenge Tomorrow. In Proceedings of the IEEE Symposium on Se-
curity and Privacy (May 2010), pp. 191–206.

[32] COOLEY, J., TAYLOR, C., AND PEACOCK, A. ABS: the ap-
portioned backup system. MIT Laboratory for Computer Science
(2004).

[34] CURTMOLA, R., GARAY, J. A., KAMARA, S., AND OSTRO-
VSKY, R. Searchable symmetric encryption: improved deﬁni-
tions and efﬁcient constructions. In ACM CCS 06 (Alexandria,
Virginia, USA, Oct. 30 – Nov. 3, 2006), A. Juels, R. N. Wright,
and S. Vimercati, Eds., ACM Press, pp. 79–88.

[35] DE CRISTOFARO, E., LU, Y., AND TSUDIK, G. Efﬁcient tech-
niques for privacy-preserving sharing of sensitive information.
In Proceedings of the 4th international conference on Trust and
trustworthy computing (Berlin, Heidelberg, 2011), TRUST’11,
Springer-Verlag, pp. 239–253.

[36] DE CRISTOFARO, E., SORIENTE, C., TSUDIK, G., AND
WILLIAMS, A. Hummingbird: Privacy at the time of twitter.
In Security and Privacy (SP), 2012 IEEE Symposium on (2012),
IEEE, pp. 285–299.

[37] DECANDIA, G., HASTORUN, D., JAMPANI, M., KAKULAPATI,
G., LAKSHMAN, A., PILCHIN, A., SIVASUBRAMANIAN, S.,
VOSSHALL, P., AND VOGELS, W. Dynamo: amazon’s highly
available key-value store. In ACM SIGOPS Operating Systems
Review (2007), vol. 41, ACM, pp. 205–220.

[38] DOUCEUR, J., ADYA, A., BOLOSKY, W., SIMON, D., AND
THEIMER, M. Reclaiming space from duplicate ﬁles in a server-
less distributed ﬁle system. In Distributed Computing Systems,
2002. Proceedings. 22nd International Conference on (2002),
IEEE, pp. 617–624.

[39] DROPBOX. Dropbox API Reference.

https://www.

dropbox.com/developers/reference/api.

[40] DYER, K., COULL, S., RISTENPART, T., AND SHRIMPTON, T.
Peek-a-boo, i still see you: Why efﬁcient trafﬁc analysis counter-
measures fail. In Security and Privacy (SP), 2012 IEEE Sympo-
sium on (2012), IEEE, pp. 332–346.

[41] ERWAY, C. C., K ¨UPC¸ ¨U, A., PAPAMANTHOU, C., AND TAMAS-
SIA, R. Dynamic provable data possession.
In ACM CCS 09
(Chicago, Illinois, USA, Nov. 9–13, 2009), E. Al-Shaer, S. Jha,
and A. D. Keromytis, Eds., ACM Press, pp. 213–222.

[42] GOH, E., SHACHAM, H., MODADUGU, N., AND BONEH, D.

Sirius: Securing remote untrusted storage. NDSS.

[43] GOLDWASSER, S., AND MICALI, S. Probabilistic encryption.
Journal of Computer and System Sciences 28, 2 (1984), 270–299.

[44] GRIBBLE, S. D., MANKU, G. S., ROSELLI, D., BREWER,
E. A., GIBSON, T. J., AND MILLER, E. L. Self-similarity in
ﬁle systems. In ACM SIGMETRICS Performance Evaluation Re-
view (1998), vol. 26, ACM, pp. 141–150.

[45] HALEVI, S., HARNIK, D., PINKAS, B., AND SHULMAN-
PELEG, A. Proofs of ownership in remote storage systems. In
Proceedings of the 18th ACM conference on Computer and com-
munications security (2011), ACM, pp. 491–500.

[46] HARNIK, D., PINKAS, B., AND SHULMAN-PELEG, A. Side
channels in cloud services: Deduplication in cloud storage. Se-
curity & Privacy, IEEE 8, 6 (2010), 40–47.

[47] HINTZ, A. Fingerprinting Websites Using Trafﬁc Analysis. In
Proceedings of the Privacy Enhancing Technologies Workshop
(April 2002), pp. 171–178.

[48] ISLAM, M., KUZU, M., AND KANTARCIOGLU, M. Access pat-
tern disclosure on searchable encryption: Ramiﬁcation, attack
and mitigation. In Network and Distributed System Security Sym-
posium (NDSS12) (2012).

[49] JIM GUILFORD, KIRK YAP, V. G.

Implementations

256
http://download.intel.com/embedded/
processor/whitepaper/327457.pdf.

Fast SHA-
Intel Architecture Processors.

on

[33] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche:
making backup cheap and easy. SIGOPS Oper. Syst. Rev. 36 (Dec.
2002), 285–298.

[50] JIN, K., AND MILLER, E. L. The effectiveness of deduplication
on virtual machine disk images. In Proceedings of SYSTOR 2009:
The Israeli Experimental Systems Conference (2009), ACM, p. 7.

USENIX Association  

22nd USENIX Security Symposium  193

15

[51] JUELS, A., AND KALISKI JR., B. S. Pors: proofs of retrievabil-
ity for large ﬁles. In ACM CCS 07 (Alexandria, Virginia, USA,
Oct. 28–31, 2007), P. Ning, S. D. C. di Vimercati, and P. F. Syver-
son, Eds., ACM Press, pp. 584–597.

[70] SHACHAM, H., AND WATERS, B. Compact proofs of retriev-
ability. In ASIACRYPT 2008 (Melbourne, Australia, Dec. 7–11,
2008), J. Pieprzyk, Ed., vol. 5350 of LNCS, Springer, Berlin, Ger-
many, pp. 90–107.

[71] STORER, M., GREENAN, K., LONG, D., AND MILLER, E. Se-
In Proceedings of the 4th ACM inter-
cure data deduplication.
national workshop on Storage security and survivability (2008),
ACM, pp. 1–10.

[72] SUN, Q., SIMON, D. R., WANG, Y.-M., RUSSELL, W., PAD-
MANABHAN, V. N., AND QIU, L. Statistical Identiﬁcation of
Encrypted Web Browsing Trafﬁc.
In Proceedings of the IEEE
Symposium on Security and Privacy (May 2002), pp. 19–30.

[73] VAN DER LAAN, W. Dropship. https://github.com/

driverdan/dropship.

[74] WALLACE, G., DOUGLIS, F., QIAN, H., SHILANE, P., SMAL-
DONE, S., CHAMNESS, M., AND HSU, W. Characteristics of
backup workloads in production systems.
In Proceedings of
the Tenth USENIX Conference on File and Storage Technologies
(FAST12) (2012).

[75] WANG, W., LI, Z., OWENS, R., AND BHARGAVA, B. Secure
and efﬁcient access to outsourced data.
In Proceedings of the
2009 ACM workshop on Cloud computing security (2009), ACM,
pp. 55–66.

[76] WILCOX-O’HEARN, Z.

Convergent encryption reconsid-
http://www.mail-archive.com/

ered, 2011.
cryptography@metzdowd.com/msg08949.
html.

[77] WILCOX-O’HEARN, Z., PERTTULA, D., AND WARNER, B.
Conﬁrmation Of A File Attack. https://tahoe-lafs.
org/hacktahoelafs/drew_perttula.html.

[78] WILCOX-O’HEARN, Z., AND WARNER, B. Tahoe: The least-
authority ﬁlesystem. In Proceedings of the 4th ACM international
workshop on Storage security and survivability (2008), ACM,
pp. 21–26.

[79] XU, J., CHANG, E.-C., AND ZHOU, J. Leakage-resilient client-
side deduplication of encrypted data in cloud storage. Cryptology
ePrint Archive, Report 2011/538, 2011. http://eprint.
iacr.org/.

[52] KAKVI, S., KILTZ, E., AND MAY, A. Certifying rsa. Advances

in Cryptology–ASIACRYPT 2012 (2012), 404–414.

[53] KALLAHALLA, M., RIEDEL, E., SWAMINATHAN, R., WANG,
Q., AND FU, K. Plutus: Scalable secure ﬁle sharing on untrusted
storage. In Proceedings of the 2nd USENIX Conference on File
and Storage Technologies (2003), pp. 29–42.

[54] KAMARA, S., PAPAMANTHOU, C., AND ROEDER, T. Cs2: A
searchable cryptographic cloud storage system. Tech. rep., Tech-
nical Report MSR-TR-2011-58, Microsoft, 2011.

[55] KILLIJIAN, M., COURT `ES, L., POWELL, D., ET AL. A survey

of cooperative backup mechanisms, 2006.

[56] LEACH, P. J., AND NAIK, D. C. A Common Internet File Sys-
tem (CIFS/1.0) Protocol. http://tools.ietf.org/
html/draft-leach-cifs-v1-spec-01.

[57] LEUNG, A. W., PASUPATHY, S., GOODSON, G., AND MILLER,
E. L. Measurement and analysis of large-scale network ﬁle sys-
tem workloads. In USENIX 2008 Annual Technical Conference
on Annual Technical Conference (2008), pp. 213–226.

[58] LI, J., KROHN, M., MAZI `ERES, D., AND SHASHA, D. Secure
untrusted data repository (SUNDR). Defense Technical Informa-
tion Center, 2003.

[59] LIBERATORE, M., AND LEVINE, B. N. Inferring the Source of
Encrypted HTTP Connections. In Proceedings of the ACM Con-
ference on Computer and Communications Security (November
2006), pp. 255–263.

[60] MARQUES, L., AND COSTA, C. Secure deduplication on mobile
devices. In Proceedings of the 2011 Workshop on Open Source
and Design of Communication (2011), ACM, pp. 19–26.

[61] MEYER, D. T., AND BOLOSKY, W. J. A study of practical dedu-

plication. ACM Transactions on Storage (TOS) 7, 4 (2012), 14.

[62] MICROSYSTEMS, S.

NFS: Network File System Proto-
col Speciﬁcation. http://tools.ietf.org/html/
rfc1094.

[63] MOZY. Mozy, a ﬁle-storage and sharing service. http://

mozy.com/.

[64] NAOR, M., AND REINGOLD, O. Number-theoretic construc-
tions of efﬁcient pseudo-random functions. In 38th FOCS (Mi-
ami Beach, Florida, Oct. 19–22, 1997), IEEE Computer Society
Press, pp. 458–467.

[65] PANCHENKO, A., NIESSEN, L., ZINNEN, A., AND ENGEL, T.
Website Fingerprinting in Onion Routing-based Anonymization
Networks.
In Proceedings of the Workshop on Privacy in the
Electronic Society (October 2011), pp. 103–114.

[66] RAHUMED, A., CHEN, H., TANG, Y., LEE, P., AND LUI, J.
A secure cloud backup system with assured deletion and version
control. In Parallel Processing Workshops (ICPPW), 2011 40th
International Conference on (2011), IEEE, pp. 160–167.

[67] ROGAWAY, P. Authenticated-encryption with associated-data.
In ACM CCS 02 (Washington D.C., USA, Nov. 18–22, 2002),
V. Atluri, Ed., ACM Press, pp. 98–107.

[68] ROGAWAY, P., AND SHRIMPTON, T. A provable-security treat-
ment of the key-wrap problem. In EUROCRYPT 2006 (St. Peters-
burg, Russia, May 28 – June 1, 2006), S. Vaudenay, Ed., vol. 4004
of LNCS, Springer, Berlin, Germany, pp. 373–390.

[69] SEARS, R., VAN INGEN, C., AND GRAY, J. To blob or not to
blob: Large object storage in a database or a ﬁlesystem? arXiv
preprint cs/0701168 (2007).

194  22nd USENIX Security Symposium 

USENIX Association

16

