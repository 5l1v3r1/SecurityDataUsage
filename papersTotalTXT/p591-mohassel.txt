Fast and Secure Three-party Computation:

The Garbled Circuit Approach

Payman Mohassel

Yahoo Labs

Sunnyvale, California
pmohassel@yahoo-

inc.com

∗

Mike Rosulek

Oregon State University

Corvallis, Oregon
rosulekm@eecs.
oregonstate.edu

Ye Zhang

Google

Mountain View, CA
zhye@google.com

†

ABSTRACT
Many deployments of secure multi-party computation (MPC)
in practice have used information-theoretic three-party pro-
tocols that tolerate a single, semi-honest corrupt party, since
these protocols enjoy very high eﬃciency.

We propose a new approach for secure three-party compu-
tation (3PC) that improves security while maintaining prac-
tical eﬃciency that is competitive with traditional information-
theoretic protocols. Our protocol is based on garbled circuits
and provides security against a single, malicious corrupt
party. Unlike information-theoretic 3PC protocols, ours uses
a constant number of rounds. Our protocol only uses inex-
pensive symmetric-key cryptography: hash functions, block
ciphers, pseudorandom generators (in particular, no obliv-
ious transfers) and has performance that is comparable to
that of Yao’s (semi-honest) 2PC protocol.

We demonstrate the practicality of our protocol with an
implementation based on the JustGarble framework of Bel-
lare et al. (S&P 2013). The implementation incorporates
various optimizations including the most recent techniques
for eﬃcient circuit garbling. We perform experiments on
several benchmarking circuits, in diﬀerent setups. Our ex-
periments conﬁrm that, despite providing a more demanding
security guarantee, our protocol has performance compara-
ble to existing information-theoretic 3PC.

1.

INTRODUCTION

Secure multi-party computation (MPC) allows a set of
parties to compute a function of their joint inputs without
revealing any information beyond the output of the func-
tion they compute. MPC has found numerous applications
not only enabling various privacy-preserving tasks on sen-
sitive data, but also removing a single point of attack by

∗Supported by NSF award CCF-1149647.
†Most of the work done while an Intern at Yahoo Labs! and

a PhD student at Penn State.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’15 October 12 - 16, 2015, Denver, CO, USA
Copyright is held by the owner/author(s). Publication rights licensed to
ACM. ACM 978-1-4503-3832-5/15/10/$15.00
DOI: http://dx.doi.org/10.1145/2810103.2813705 .

allowing for distribution of secrets and trust while main-
taining the original functionality. Since the seminal work of
[Yao86, GMW87] showing its feasibility in the two-party and
multi-party settings, MPC has been the subject of extensive
research, focusing on bettering security and eﬃciency.

The case of three-party computation (3PC) where the ad-
versary corrupts at most one party (honest majority) is an
important special case that has received particular atten-
tion. It has been the subject of active research, implementa-
tion and optimization in frameworks such as VIFF [Gei07],
Sharemind [BLW08], ShareMonad [LDDAM12, LADM14]
and MEVAL [CMF+14]. These protocols have been used in
a wide range of applications such as statistical data analy-
sis [BTW12], and email ﬁltering [LADM14]. They have also
been deployed in practice for online beet auctions [BCD+09]
and for ﬁnancial data analysis [BTW12]. A main reason for
popularity of 3PC with-one-corruption is the simplicity and
eﬃciency of the resulting protocols.
In particular, proto-
cols designed in this setting can be signiﬁcantly more eﬃ-
cient than their two-party counterparts (or dishonest major-
ity protocols in general) since they are commonly based on
secret-sharing schemes and hence only require arithmetic op-
erations that are considered faster than cryptographic ones.
However, the secret-sharing-based solutions have several
drawbacks.
In particular, the round complexity of these
protocols is proportional to the circuit-depth of the com-
putation being performed, which can be high in practice.
Also, to the best of our knowledge, With the exception of
[IKHC14], existing implementations are only secure against
semi-honest adversaries. Traditionally, one may be willing
to settle for semi-honest security given that security against
active cheating (malicious adversaries) has a reputation of
requiring signiﬁcant overhead. Our work shows that this im-
pression need not be true, and that malicious security can in
fact be obtained with little to no overhead over semi-honest
security in the 3-party setting.

1.1 Our Contributions

We design a new protocol for 3PC with one corruption
based on Garbled Circuits (GC) [Yao82, LP09, BHR12b].
Our protocol is constant-round and secure against a mali-
cious adversary that corrupts one party. Unlike the standard
approach of applying cut-and-choose techniques for compil-
ing GC-based protocols into malicious 2PC, we show that
in the setting of 3PC with one corruption one can avoid the
cut-and-choose paradigm and achieve malicious security at
a cost similar to semi-honest two-party constructions. We

591also avoid the use of public-key operations such as Oblivious
Transfer.

We prove our protocol secure in the Universal Compos-
ability (UC) model, but avoid the use of expensive UC-
secure primitives due to the honest-majority setting. The
only cryptographic tools we require are a secure garbling
scheme and a non-interactive (standalone-secure) commit-
ment scheme, both of which can be instantiated using sym-
metric key primitives.

Our protocol does not achieve fairness, and we leave it
open to design a protocol with similar level of eﬃciency that
also achieves fairness (a feasible goal in the honest majority
setting).

We implement our protocol by enhancing the implemen-
tation of JustGarble [BHKR13] in various ways and incor-
porating the state-of-the-art “half-gates” garbling scheme of
[ZRE15]. We further reduce communication (which our ex-
periments show to be the bottleneck), by a factor of two
using a hashing technique described in Section 3.4. We
run experiments evaluating benchmarking circuits such as
AES/MD5/SHA1/SHA256, and with diﬀerent communica-
tion techniques turned on/oﬀ. Our experimental results con-
ﬁrm that our construction is competitive with prior work
in the same setting while achieving the stronger malicious
security. They also conﬁrm that communication remains
the major bottleneck in GC-based constructions even in the
three-party setting. We also explore a motivating applica-
tion we call distributed credential encryption service, that
naturally lends itself to an oﬄine pre-processing stage. Our
experiments show that the online phase can be very fast.

1.2 Related Work

The most relevant line of work to ours are MPC construc-
tions with an honest majority. Starting with seminal work
of [BOGW88, CCD88] a large body of work has studied
round and communication complexity of such protocols. A
main building block for achieving security against a mali-
cious adversarie in these constructions is veriﬁable secret
sharing (VSS) [BOGW88, RBO89]. While these construc-
tions are quite eﬃcient and avoid cryptographic operations,
their practical eﬃciency and the constant factors are not
fully examined. The one implementation of 3PC with mali-
cious security we know of is [IKHC14]. Their work proposes
an approach for compiling a semi-honest 3PC into a mali-
cious one with a small overhead (we discuss the overhead
in more detail in the experiment section). The other exist-
ing implementations we know of are based on customized
3PC frameworks provided in [BLW08, LDDAM12, ZSB13,
CMF+14] which only provide security against semi-honest
adversaries. We provide a more detailed comparison with
this line of work in the experiment section. Another cus-
tomized 3PC based on garbled circuits, using the cut-and-
choose paradigm and distributed garbling, was introduced
in [CKMZ14]. Their protocol considers the stronger two-
corruption setting and is naturally more expensive.

The more general multiparty and constant-round variant
of Yao’s garbled circuit was also studied in both the semi-
honest setting [BMR90], and the malicious setting [DI05,
IKP10]. An implementation exists [BDNP08] for the semi-
honest case. These protocols are conceptually based on gar-
bled circuits but require a particular instantiation of garbled
circuits that expands the wire-labels through secret-sharing.
We leave it as interesting open work to investigate whether

recent optimizations to standard garbled circuits can be sim-
ilarly applied to these protocols, and to compare the practi-
cal eﬃciency of malicious-secure variants.

In concurrent and independent work, Ishai et al. [IKKPC15]

describe eﬃcient, constant-round secure computation proto-
cols for 3 and 4 parties, tolerating 1 malicious corruption.
Both their protocol and ours use as a starting point the pro-
tocol of Feige et al. [FKN94] in the private simultaneous mes-
sages (PSM) setting, which is in turn based on Yao’s garbled
circuit construction. The two protocols ([IKKPC15] and
ours) use incomparable techniques to strengthen the PSM
protocol against one malicious participant, and achieve a dif-
ferent mix of properties. In the 3-party setting, [IKKPC15]
achieve a 2-round protocol whose cost is essentially that of 3
garbled circuits, whereas our protocol requires 3 rounds (in
its random oracle instantiation) and has cost of 1 garbled
circuit. In the 4-party setting, [IKKPC15] achieve guaran-
teed output delivery as well.

Fast implementation of malicious 2PC and MPC in the
dishonest majority setting include cut-and-choose solutions
based on garbled circuits [LPS08, KS12, FN13, AMPR14],
OT-based solutions [NNOB12, LOS14], and implementa-
tions in the pre-processing models [DKL+12, DKL+13]. These
protocols resists a larger fraction of coalition of corrupted
parties than ours, but are signiﬁcantly less eﬃcient.
1.3 Organization

The building blocks used in our protocols such as a gar-
bling scheme, commitment schemes and coin-tossing are all
deﬁned and described in Section 2. Our main construction
and its security proof are described in Section 3. Our imple-
mentation, experimental results, and comparison with other
implementations can be found in Section 4. We discuss the
distributed encryption service application in Section 5.

2. PRELIMINARIES

2.1 Secure MPC: UC Framework

We deﬁne security of multi-party computation using the
framework of Universal Composition (UC) [Can01]. We give
a very brief overview here, and refer the reader to [Can01]
for all of the details.

An execution in the UC framework involves a collection
of (non-uniform) interactive Turing machines. In this work
we consider an adversary that can statically (i.e., at the be-
ginning of the interaction) corrupt at most one party. We
consider security against active adversaries, meaning that a
corrupt party is under complete control of the adversary and
may deviate arbitrarily from the prescribed protocol. The
parties exchange messages according to a protocol. Protocol
inputs of uncorrupted parties are chosen by an environment
machine. Uncorrupted parties also report their protocol out-
puts to the environment. At the end of the interaction, the
environment outputs a single bit. The adversary can also
interact arbitrarily with the environment — without loss of
generality the adversary is a dummy adversary which simply
forwards all received protocol messages to the environment
and acts in the protocol as instructed by the environment.
Security is deﬁned by comparing a real and ideal interac-
tion. Let real[Z,A, π, k] denote the ﬁnal (single-bit) out-
put of the environment Z when interacting with adversary
A and honest parties who execute protocol π on security

592parameter k. This interaction is referred to as the real in-
teraction involving protocol π.

In the ideal interaction, parties run a “dummy protocol”
in which they simply forward the inputs they receive to an
uncorruptable functionality machine and forward the func-
tionality’s response to the environment. Hence, the trusted
functionality performs the entire computation on behalf of
the parties. Let ideal[Z,S,F, k] denote the output of the
environment Z when interacting with adversary S and hon-
est parties who run the dummy protocol in presence of func-
tionality F on security parameter k.
We say that a protocol π securely realizes a functional-
ity F if for every adversary A attacking the real interaction
(without loss of generality, we can take A to be the dummy
adversary), there exists an adversary S (called a simulator)
attacking the ideal interaction, such that for all environ-
ments Z, the following quantity is negligible (in k):

(cid:12)(cid:12)(cid:12) Pr(cid:2)real[Z,A, π, k] = 1(cid:3) − Pr(cid:2)ideal[Z,S,F, k] = 1(cid:3)(cid:12)(cid:12)(cid:12).

Intuitively, the simulator must achieve the same eﬀect (on
the environment) in the ideal interaction that the adversary
achieves in the real interaction. Note that the environment’s
view includes (without loss of generality) all of the messages
that honest parties sent to the adversary as well as the out-
puts of the honest parties. Thus the deﬁnition captures both
the information that an adversary can learn about honest
parties’ inputs as well as the eﬀect that an adversary can
have on the honest parties’ outputs.
In a secure protocol
these capabilities cannot exceed what is possible in the ideal
interaction.

Target functionality.

The code of the functionality F implicitly deﬁnes all of the
properties that comprise the security required of a protocol
π. In Figure 1 we deﬁne the ideal functionality Ff for secure
3-party computation of a function f .

Input collection. On message (input, xi) from a
party Pi (i ∈ {1, 2, 3}), do the following:
if a pre-
vious (input,·) message was received from Pi, then
ignore. Otherwise record xi
internally and send
(inputfrom, Pi) to the adversary.

Computation. After all 3 parties have given input,
compute y = f (x1, x2, x3).
If any party is corrupt,
then send (output, y) to the adversary; otherwise
send (output, y) to all parties.

Unfair output. On message deliver from the ad-
versary, if an identical message was received before,
then ignore. Otherwise send (output, y) to all honest
parties.

Figure 1: Ideal functionality Ff for secure 3-party
computation of a function f .

In particular, Ff provides “security with abort” (i.e., un-
fair output) in which the adversary is allowed to learn its
output from the functionality before deciding whether the
uncorrupted parties should also receive their output.

Contrasting active and semi-honest security.

When one party (say, P1) is actively corrupt, it may send
unexpected messages to an honest party (say, P3). This may
have the eﬀect that P3’s view leaks extra information about
the other honest party P2. We note that this situation is in-
deed possible in our protocol (for example, P1 can send to P3
the seed used to generate the garbled circuit, which allows
everyone’s inputs to be computable from P3’s view). How-
ever, we emphasize that this is not a violation of security in
the 1-out-of-3 corruption case.

A protocol with malicious security must let the honest par-
ties handle “unexpected” messages appropriately. The secu-
rity deﬁnition only considers what eﬀect such “unexpected”
messages have on the ﬁnal output of an honest party, but not
the eﬀect they have on the view of an honest party. More
precisely, if P3 is honest, then only his ﬁnal protocol output
is given to the environment, while his entire view is not. A
participant who hands its entire view over to the environ-
ment must be at least semi-honest corrupt, but in our case
only one party (P1 in our example) is assumed to be corrupt
at all. We leave as an open problem to achieve security in
the presence of one active and one semi-honest party (simul-
taneously), with comparable eﬃciency to our protocol.

We also emphasize that our primary point of comparison
is against existing 3PC protocols that tolerate 1 semi-honest
corruption. In these protocols, a single, actively corrupt par-
ticipant can violate privacy of others’ inputs and integrity
of others’ ﬁnal outputs, often completely undetectably. So
while 1-out-of-3 active security has some limitations, it is a
signiﬁcantly stronger guarantee than 1-out-of-3 semi-honest
security.
2.2 Garbling Scheme

We employ the abstraction of garbling schemes [BHR12b]
introduced by Bellare et al. Below is a summary of garbling
scheme syntax and security:
A garbling scheme is a four-tuple of algorithms G =
(Gb, En, De, Ev) where: Gb is a randomized garbling algo-
rithm that transforms function f into a triplet (F, e, d), where
F is the garbled circuit, e is encoding information, and d
is decoding information. En is an encoding algorithm that
maps input x into garbled input via X = En(e, x). De is
a decoding algorithm that maps the garbled output Y into
plaintext output y = De(d, Y ). Ev is the algorithm that on
garbled input X and garbled circuit F , produces garbled
output Y = Ev(F, X).

The correctness property of a garbling scheme is that,
for all (F, e, d) in the support of Gb(1k, f ) and all inputs x,
we have De(d, Ev(F, En(e, x))) = f (x), where k denotes the
security parameter.
We require a projective scheme, meaning that e is an
n × 2 matrix of wire labels, and the encoding algorithm En
has the structure En(e, x) = (e[1, x1], e[2, x2], . . . , e[n, xn]).
A scheme satisﬁes privacy if there exists a simulator S
for which following two processes induce indistinguishable
output distributions:

M1(1k, f, x):

(F, e, d) ← Gb(1k, f )
X ← En(e, x)
return (F, X, d)

M2(1k, f, x):

(F, X, d) ← S(1k, f, f (x))
return (F, X, d)

In other words, the tuple (F, X, d) contains no information
beyond f (x).

593Our protocol requires an additional “soft decoding” func-

ing information d. The soft-decoding function must satisfy

A scheme satisﬁes authenticity if the following property
holds. Given (F, X) as in the output of M1 above, it is with
only negligible probability that a poly-time adversary can
generate ˜Y (cid:54)= Ev(F, X) such that De(d, ˜Y ) (cid:54)= ⊥. In other
words, without d, it is not possible to give a valid garbled
output other than Y obtained from Ev.

tion (cid:102)De that can decode garbled outputs without the decod-
(cid:102)De(Ev(F, En(e, x))) = f (x) for all (F, e, d) in the support of
Gb(1k, f ). Note that both (cid:102)De and De can decode garbled
with respect to De — that is, (cid:102)De can in principle be “fooled”
erated, the output of (cid:102)De will be correct. In our protocol,
using (cid:102)De, while the generators of the garbled circuit will use

when given maliciously crafted garbled outputs. However,
if the garbled circuit and garbled input are honestly gen-

outputs, but the authenticity security property holds only

we will let the evaluator of the garbled circuit obtain input

De (to protect against a corrupt party who tries to falsify the
garbled outputs). In practice, we can achieve soft decoding
in typical garbling schemes by simply appending the truth
value to each output wire label. The true decoding func-
tion De will still verify the entire wire labels to guarantee
authenticity.
2.3 Non-Interactive Commitment

We require a non-interactive commitment scheme (in the
common random string model). Let crs denote the common
random string and let (Comcrs, Chkcrs) be a non-interactive
commitment scheme for n-bit messages. The Comcrs algo-
rithm takes an n-bit message x and random coins r as input,
and outputs a commitment C and the corresponding open-
ing σ. We write Comcrs(x) as shorthand for the distribution
Comcrs(x; r) induced by uniform choice of r. We require the
following properties of the scheme:

• Correctness: for all crs, if (C, σ) ← Comcrs(x) then

Chkcrs(C, σ) = x.

• Binding: For all poly-time adversaries A, it is with
negligible probability (over uniform choice of crs) that
A(crs) outputs (C, σ, σ(cid:48)) such that Chkcrs(C, σ) (cid:54)=
Chkcrs(C, σ(cid:48)) and ⊥ (cid:54)∈ {Chkcrs(C, σ), Chkcrs(C, σ(cid:48))}.
• Hiding: For all poly-time adversaries A, all crs, and
all x, x(cid:48) ∈ {0, 1}n, the following diﬀerence is negligible:

Pr

(C,σ)←Comcrs(x)

[A(C) = 1]−

Pr

(C,σ)←Comcrs(x(cid:48))

[A(C) = 1]

(cid:12)(cid:12)(cid:12)

(cid:12)(cid:12)(cid:12).

Since we quantify over all crs and A together (not just
a random crs), it is not necessary to give crs to A in
this deﬁnition. The deﬁnition also implies that the crs
can be used for many commitments.

Instantations.
In the random oracle model, commitment is simple via
(C, σ) = (H(x(cid:107)r), x(cid:107)r) = Comcrs(x; r). The crs can in fact
be empty.

In the standard model, we can use a multi-bit variant of
Naor’s commitment [Nao91]. For n-bit strings, we need a
crs ∈ {0, 1}4n. Let G : {0, 1}n → {0, 1}4n be a pseudo-
random generator, and let pad : {0, 1}n → {0, 1}4n be the
function that prepends 3n zeroes to its argument. Then the
commitment scheme is:

• Comcrs(x; r): set C = G(r) + crs · pad(x), with arith-

metic in GF (24n); set σ = (r, x).

• Chkcrs(C, σ = (r, x)): return x if C = G(r) + crs ·

pad(x); otherwise return ⊥.

Security of this construction closely follows the original proof
of Naor’s construction, but is provided for completeness in
Appendix A.

3. OUR PROTOCOL

In this section we present a new and eﬃcient 3PC protocol
that is secure against 1 malicious corruption. Its complexity
is essentially the same as that of (semi-honest-secure) two-
party Yao’s protocol.
3.1 High Level Overview

Our starting point is Yao’s protocol based on garbled cir-
cuits. In that protocol, one party generates a garbled circuit
and the other evaluates it. The two parties use oblivious
transfer to allow the evaluator to receive the garbled encod-
ing of his input.

Yao’s protocol is secure against a malicious evaluator, but
secure against only a semi-honest garbler. Our 3-party pro-
tocol can be thought of as splitting the role of the garbler
between two parties (while keeping the evaluator a single
party). When only one party is corrupt, then at least one of
the garbling parties is honest, and we can leverage that fact
to protect against one malicious garbler.

In more detail, we let P1 and P2 agree on a random tape r
and run Yao’s protocol as garbler with P3 as evaluator, with
both instances using random tape r. By using the same
random tape in Yao’s protocol, P1 and P2 are expected to
send identical messages to P3 in every step, and P3 can abort
if this is not the case. Then, security against a malicious P3
follows from the security of Yao’s protocol — it is really P3
attacking a single instance of 2-party Yao’s protocol in this
case. Security against a malicious P1 or P2 follows from the
fact that Yao’s protocol is secure against a garbler who runs
the protocol honestly (even on adversarially chosen random
tape). In our protocol, the only options for malicious P1 or
P2 are to run Yao’s 2-party protocol honestly or else cause
P3 to abort (by disagreeing with the honest garbler).

Obtaining Garbled Inputs.

This overview captures the main intuition, but it does not
address the issue of garbled inputs. Indeed, P1 and P2 have
their own private inputs and so must at some point send
diﬀerent messages in order to aﬀect the ﬁnal output. To ad-
dress this, we have P1 and P2 commit to all of the input wire
labels for the circuit. For each wire, the two commitments
are randomly permuted. P1 and P2 will generate these com-
mitments using the same randomness, so their correctness
is guaranteed using the same reasoning as above. Then P1
and P2 can simply open the appropriate commitments cor-
responding to their input bits (note that the position of the
commitments does not leak their inputs).

P3’s garbled input is handled using an oblivious transfer
in Yao’s protocol, but we are able to avoid OT altogether in
our 3-party setting. We garble the circuit f(cid:48)(x1, x2, x3, x4) =
f (x1, x2, x3 ⊕ x4), so that x3, x4 are an additive secret shar-
ing of P3’s logical input. We have P3 send x3 to P1 and x4
to P2, so that P1/P2 can open the corresponding commit-
ments to garbled inputs. Since at most one of {P1, P2} is

594corrupt, an adversary can learn nothing about P3’s logical
input. To ensure that P1/P2 open the correct commitments
in this step (i.e., they do not ﬂip bits in P3’s input), we
have them both reveal the random ordering of the relevant
commitments (which can be checked against each other by
P3).

Other Optimizations.

To make the commitment non-interactive, we can either
assume a random oracle commitment scheme, or else a com-
mon random string (CRS). In the latter case, P3 can choose
the CRS himself (we use a commitment scheme that is hid-
ing for all CRS values, not just for a uniformly chosen one).
Both P1 and P2 use a common random tape r to run Yao’s
protocol as garbler. We can actually have P1 choose r him-
self; surprisingly there is no problem in a corrupt P1 choos-
ing r arbitrarily. In the case that P1 is corrupt, the security
proof needs to apply the binding security of the commitment
scheme and correctness property of garbled circuits. Bind-
ing holds with respect to malicious senders (in particular,
senders who choose r arbitrarily and use PRF(r,·) to derive
randomness to run the Comcrs(·) algorithm). Correctness of
garbled circuits holds with probability 1, i.e., for all (F, e, d)
in the support of Gb(1k, f(cid:48)). The fact that P2 must be hon-
est if P1 is corrupt guarantees that the (F, e, d) used in the
protocol is indeed in the support of Gb, so we can apply the
correctness of the garbling scheme.
3.2 Detailed Protocol Description

We denote the three parties in the protocol by P1, P2 and
3. Their goal
3). For

P3, and their respective inputs by x1, x2, and x∗
is to securely compute the function y = f (x1, x2, x∗
convenience we deﬁne the related function

(cid:48)

(x1, x2, x3, x4) = f (x1, x2, x3 ⊕ x4).

f

For simplicity we assume that |xi| = |y| = m. The proto-
col is as follows. All communication between parties is on
private point-to-point channels.

In what follows we assume that all parties learn the same
output y, but it is easy to modify the protocol such that
each party learns a diﬀerent output (i.e., a 3-output func-
tion).
In particular, P3 can return to each of P1 and P2
the garbled values for the portion of the output wires cor-
responding to their own output, while the “soft-decoding”
procedure is constrained to work only for P3’s output wires
(concretely, the cleartext truth values are appended only to
the output wires for P3’s outputs).1

1. P3 samples a random crs for the commitment scheme
3 = x3 ⊕
and randomly secret-shares his input x∗
x4. He sends x3 to P1 and x4 to P2 and broadcasts crs
to both parties.

3 as x∗

2. P1 chooses random PRF seed r ← {0, 1}k and sends it

to P2 (see the discussion in the previous section).

3. Both P1 and P2 do the following, independently, and

obtaining all required randomness via P RF (r,·):
(a) Garble the circuit f(cid:48) via Gb(1λ, f(cid:48)) → (F, e, d).

1The resulting protocol will achieve a slightly weaker notion
of security, since a corrupt P3 can choose to make only one
of {P1, P2} abort. This notion is known as security with
selective abort. [GL05]

(b) Commit to all 4m input wire labels in the fol-
lowing way. Sample b ← {0, 1}4m. Then for all
j ∈ [4m] and a ∈ {0, 1}, generate the following
commitment:

(C a

j , σa

j ) ← Comcrs(e[j, b[j] ⊕ a])

Both P1 and P2 send the following values to P3:2

(b[2m + 1··· 4m], F,{C a

j }j,a).

P3 will abort if P1 and P2 report diﬀerent values for
these items.

4. P1 and P2 additionally reveal garbled inputs to P3 in
the following way (now P1 and P2 are sending diﬀerent
messages). For j ∈ [m]:
(a) P1 sends decommitment σx1[j]⊕b[j]
(b) P2 sends decommitment σx2[j]⊕b[m+j]
(c) P1 sends decommitment σx3[j]⊕b[2m+j]
(d) P2 sends decommitment σx4[j]⊕b[3m+j]

to P3.

to P3.

to P3.

to P3.

2m+j

3m+j

j

m+j

5. P3 assembles the garbled input as follows. For j ∈
[4m], P3 computes X[j] = Chkcrs(C o[j]
), for the
appropriate o[j]. If any call to Chk returns ⊥, then P3
aborts. Similarly, P3 knows the values b[2m+1··· 4m],
and aborts if P1 or P2 did not open the “expected”
and C x4[j]⊕b[3m+j]
commitments C x3[j]⊕b[2m+j]
corre-
sponding to the garbled encodings of x3 and x4.
P3 runs Y ← Ev(F, X) and broadcasts Y to all parties.

, σo[j]

2m+j

3m+j

j

j

6. At this point, P1 and P2 can compute y = De(d, Y ). If
y (cid:54)= ⊥, then they output y, otherwise they abort. Also,

P3 can compute and output y = (cid:102)De(Y ), where (cid:102)De is

the “soft decoding” function described in Section 2.2.

3.3 Security Proof

Theorem 1. The protocol in Section 3.2 securely realizes
the Ff functionality against adversaries who actively corrupt
at most one of the parties.

Proof. First consider the case where P1 is corrupted (the
case of P2 is essentially symmetric). We show that the real
and ideal interactions are indistinguishable to all environ-
ments, in a sequence of hybrid interactions. The required
simulator is built up implicitly in the hybrid sequence be-
low. Recall that the environment’s view consists of messages
sent from honest parties to the adversary in the protocol, as
well as the ﬁnal outputs of the honest parties.
H0: This hybrid is identical to the real interaction, except
that we repackage the various components of the inter-
action. A simulator plays the role of honest P2 and P3,
receiving their inputs x2 and x∗
3 from the environment
and running the protocol on their behalf.

2Since b[2m + 1··· 4m] are given to P3, we can actually take
them to be all zeroes and eliminate them altogether. Still,
to keep the treatment of all garbled inputs consistent in the
notation, we continue with b ∈ {0, 1}4m.

595j

H1: In the previous hybrid, the simulator runs the protocol
on behalf of P2 and hence knows the value b chosen in
step (3b). Assuming P3 does not abort in step (5),
then P1 must have succesfully opened commitments
for some string o ∈ {0, 1}m. At this point in
C o[j]
H1 we have the simulator compute x1 = o⊕ b[1··· m].
The simulator also simulates an instance of the Ff
3 to the simulated Ff
functionality. It sends x1, x2, x∗
(recall that at this point in the sequence of hybrids
the simulator is receiving the other parties’ inputs x2
and x∗
3). As the simulator does nothing with anything
computed by Ff , there is no diﬀerence in the environ-
ment’s view. Note that the simulator is still using x2
and x∗
3 at this point to run the protocol on behalf of
P2 and P3.

j commitments.

H2: In the previous hybrid, the simulator runs the protocol
on behalf of P2 and hence knows what was committed
in all of the C a
We modify the simulator to abort if the simulated P3
accepts the opening of any commitment (in step 5)
to a value other than what was originally committed.
The crs is chosen uniformly by P3, so the commit-
ment scheme’s binding property guarantees that the
probability of this abort occurring is negligible, so the
hybrids are indistinguishable.3
Conditioned on this additional abort not happening,
we can see that the garbled input X used by P3 has
been computed as:

X = En(e, x1(cid:107)x2(cid:107)x3(cid:107)x4),

where x1 was the value extracted by the simulator in
step (5) as explained above.

Further note that, as long as P3 doesn’t abort in step
(3), we have that the values (F, e, d) are in the support
of Gb(1k, f(cid:48)). The garbling scheme’s correctness prop-
erty holds for all such (F, e, d), and it does not matter
that the random coins used in Gb were inﬂuenced by
P1’s selection of r in step (2).

H3: Same as above, except that in step (6), when the hon-
est parties hand their output to the environment, the
simulator instead hands the environment the value y
computed by the simulated Ff . By the correctness
condition mentioned above, we have that if the sim-
ulator doesn’t abort on behalf of P3 in step (5) then
3), where
the ﬁrst two expressions are what the simulated P2 and
P3 would have output, and the ﬁnal expression is what
Ff computes. Hence hybrids H2 and H3 induce iden-
tical views on the environment.

De(d, Ev(F, X)) =(cid:102)De(Ev(F, X)) = f (x1, x2, x∗

H4: Same as above, except that instead of computing Y via
Ev(F, X) in step (5), the simulator computes Y such
that De(d, Y ) = y, where y is the output obtained
from Ff (this is easy in all practical garbling schemes,
when the simulator knows all the randomness used to
generate the garbled circuit). By the correctness of the

3Note that we still need binding to hold against malicious
senders. The commitments are not necessarily generated
honestly; instead they are generated by having P1 (mali-
ciously) choose r which is expanded via PRF(r,·) to provide
randomness to call Comcrs.

garbling scheme, this is an equivalent way to compute
the same value, so the change has no eﬀect on the
environment’s view.

H5: Note that in hybrid H4, the garbled circuit does not
have to be evaluated during the simulation, hence the
garbled input X is not used. But generating X was the
only place x4 (the secret share of x∗
3) was used. The
3 is sent to P1. In H5 we modify
other share x3 of x∗
the simulator to send a random x3 to P1 in step (1).
The change has no eﬀect on the environment’s view.

The ﬁnal hybrid implicitly deﬁnes our protocol’s simulator.
It sends a random share x3 to P1 in step (1); it aborts in
step (5) if P1 has violated the binding property of any com-
mitment; otherwise it extracts x1 = o ⊕ b[1··· m] and sends
it to the ideal functionality Ff . It receives y, and in step (5)
sends Y to P1 such that De(d, Y ) = y. The eﬀect on the en-
vironment in this ideal interaction is indistinguishable from
the real interaction, by the arguments in the above sequence
of hybrids.

Next, we consider a corrupt P3:
H0: As before, we consider a simulator playing the role
of honest P1 and P2 running on their inputs. The
environment receives the ﬁnal outputs of the simulated
P1 and P2.

H1: Same as above, except for the following change. The
simulator will run an instance of Ff . In step (1) of the
protocol, the simulator will receive x3, x4 from P3, set
3 = x3 ⊕ x4, then send x1, x2, and x∗
x∗
3 to the instance
of Ff . This is merely an internal change, since in this
hybrid the simulator does not yet use the outputs of
Ff in any way. Hence, the two hybrids induce identical
views for the environment.

j where o = b⊕x1(cid:107)···(cid:107)x4.

H2: Same as above, except that the simulated P1 and P2
use uniform randomness rather than pseudorandom-
ness in step (2). The hybrids are indistinguishable by
the security of the PRF and the fact that the PRF
seed r is chosen uniformly by P1 and P2 in step (2).
H3: Same as above, except for the following change. In step
(3), when the simulator is generating the C a
j commit-
ments, it knows in advance which ones will be opened.
These are the commitment C o[j]
We modify the simulator to ﬁrst choose random o ←
{0, 1}4m which index the commitments that will be
opened, and then solve for b = o ⊕ x1(cid:107)···(cid:107)x4 in step
(3b). Note that the simulator indeed has all of the xi
values at this time. Then the simulator commits to
dummy values for the commitments which will not be
opened. The hybrids are indistinguishable by the hid-
ing property of the commitment scheme (which holds
with respect to all values of crs). Note that the simula-
tion now does not use all of the garbled input encoding
information e; rather, it only uses X = En(e, x1(cid:107)··· x4).
H4: In step (6) in the previous hybrid, the simulated P1 and
P2 will abort if De(d, ˜Y ) = ⊥, where ˜Y is the message
sent by P3 in step (5). We modify the simulator so that
it aborts if ˜Y (cid:54)= Ev(F, X), which is what P3 is supposed

596to send. Note that the simulator indeed knows F and
all of X at this point.

By the authenticity property of the garbling scheme,
it is only with negligible probability that P3 (who is
not given decoding information d) would produce ˜Y (cid:54)=
Ev(F, X) such that De(d, ˜Y ) (cid:54)= ⊥. Hence, the two
hybrids are indistinguishable.

H5: Conditioned on the simulator not aborting in step (6),
the correctness of the garbling scheme guarantees that
simulated P1 and P2 will output y = f (x1, x2, x∗
3).
Hence, instead of handing the environment the out-
puts of these simulated P1/P2, we have the simulator
instruct Ff to release output to honest parties if the
simulator hasn’t aborted in step (6), and give the out-
puts from Ff directly to the environment. Again, this
has no eﬀect on the environment’s view.

H6: Same as above, except for the following change. Note
that throughout the simulation in H5, the simulator
uses F , d, but only X = En(e, x1(cid:107)···(cid:107)x4) due to the
previous hybrids.
In particular, it does not use the
other parts of e. We modify the simulator to generate
(F, X, d) using the simulator of the garbling scheme,
rather than the standard Gb, En. The simulator re-
quires y which the simulator knows already in step
(1). The hybrids are indistinguishable by the security
of the garbling scheme.

The simulator implicit in hybrid H6 deﬁnes our ﬁnal simu-
3 = x3 ⊕ x4 in step (1) and sends it to
lator. It extracts x∗
Ff , receiving output y in return. It then generates a sim-
ulated garbled circuit/input (F, X) using y. In step (3) it
chooses random string o and commits to the entries of X as
C o[j]
, while committing to dummy values in the other com-
mitments. In step (4) it opens the commitments indexed by
o. After receiving ˜Y from P3 in step (5), it checks whether
˜Y = Ev(F, X); if so, then it instructs Ff to deliver output
to the honest parties.

j

3.4 Reducing Communication

We can reduce the total communication by essentially
half, as follows: Instead of both P1 and P2 sending the very
long (identical) message to P3 in step 3, we can have only
P1 send this message while P2 simply sends the hash of this
message, under a collision-resistant hash function. P3 can
then simply check the hash received from P2 against the
message received from P1. While this reduces total commu-
nication size, it does not reduce total communication latency
of the protocol in the most common scenario where P1 and
P2 communicate with P3, simultaneously.

To improve on this, we have P1 and P2 treat the message
they send to P3 as a string S, divided into equal halves
S = S1||S2. We then have P1 send S1 and H(S2) and P2
send H(S1) and S2 to P3. This still enables P3 to retrieve S
and also check that P1 and P2 agree on a common S. This
variant not only reduces total communication by half, but
also the communication latency in the scenario that P1 and
P2 run at the same time.

4.

IMPLEMENTATION AND EXPERIMEN-
TAL VALIDATION

4.1 Implementation

Our implementation is written in C++11 with STL sup-
port. For an eﬃcient implementation of a circuit garbling
scheme, we used as a starting point the JustGarble library
[BHKR13], an open-source library licensed under GNU GPL
v3 license. We also used the MsgPack 0.5.8 library to serial-
ize/deserialize data and used the openssl lib (version 1.0.1e-
ﬁps) for our implementation of SHA-256. We implement the
commitment scheme needed for our protocol using SHA-256
as a random oracle.

In our implementation, P3 initializes itself by ﬁrst reading
the circuit description ﬁle from the disk. The description
ﬁle is in JustGarble’s SCD format. Then, P3 listens on a
port via a socket. When Pi (i = 1, 2) connect to the port,
P3 creates a new thread for this connection. The rest of
communication/interaction between P3 and Pi will be within
this thread.

Then, P1 and P2 connect with each other to negotiate
a shared seed and use it to generate a garbled circuit. We
modify JustGarble to support a shared seed for the random-
ness needed in the garbling. As a result, the garbled circuits
generated by P1 and P2 are identical.4

Communication Reduction Techniques. To reduce
communication/serialization costs, we add several optimiza-
tions to JustGarble. First, we enable the free-XOR support
[KS08] in JustGarble and also modify its code to make NOT
gates free (no communication and computation) since the
original JustGarble implementation treats NOT gates like
other non-XOR gates. Additionally, we incorporated sup-
port for the recent half-gate garbling technique of [ZRE15]
which reduces sizes of garbled non-XOR gates to two ci-
phertexts (a 33% reduction compared to the best previous
technique).

Instead of sending each garbled gate ciphertext individu-
ally over a socket, which would signiﬁcantly slow down com-
munication due to overheads, we serialize multiple gates into
a larger buﬀer with a size below the max socket size, and
send it to the server who deserializes the received data. To
further reduce communication size, we have P1 send the ﬁrst
half of the serialized garbled circuit as usual, but only send
a hash of the second half, and have P2 do the reverse. P3
can put together the two unhashed halves to construct the
whole garbled circuits, and uses the hashed halves to check
equality of the two garbled circuits. This technique reduces
communication by a factor of two but requires more work
by all parties in form of hashing the garbled circuits. Note
that hashing operation increases computation cost. In fact,
hashing the garbled circuit using SHA256 is more expensive
than garbling the circuit itself which uses AES-NI instruc-
tions.5 Nevertheless the reduction in communication cost

4While doing so, we identiﬁed a small bug in JustGarbled.
Speciﬁcally,
in the garble() function, the encryption key
garblingContext.dkCipherContext.K .rd key is used without
initialization which resulted in diﬀerent garbled circuits even
when using the same seed.
5AES-NI provides high performance in the case where our
usage of AES does not involve re-keying. One might be
tempted to use AES (perhaps modeled as an ideal cipher)
to construct a collision-resistant hash function in a way that

597(which is the bottleneck) makes this a net win as our exper-
iments show.
4.2 Experiments

The experiments were conducted on Amazon EC2 Cloud
Computing instances. The instances are of type t2.micro
with 1GB memory, and Intel Xeon E5-2670 2.5Ghz CPU
with AES NI and SSE4.2 instruction sets enabled. The in-
stances are interconnected using Amazon’s network. We also
use the iperf v3.1b3 tool to measure the maximum achiev-
able bandwidth of t2.micro instances. The bandwidth is
1Gbits/s. The operating system was Red Hat Enterprise
Linux 7.0 (kernel 3.10.0-123.8.1.el7.x86 64). We run each
experiment 20 times and report the average and standard
deviation for our measurements.

We used 4 diﬀerent circuits for benchmarking our imple-
mentation: AES-128 (with key expansion), SHA-1, MD-
5 and SHA-256. Besides the circuit for AES-128 which
was provided with JustGarble, the description ﬁle for the
other circuits were obtained from http://www.cs.bris.ac.
uk/Research/CryptographySecurity/MPC/. We converted
these ﬁles into JustGarble’s SCD format using the code pro-
vided in [AMPR14].

The AES-128 circuit takes a 128-bit key and a 128-bit
message as input. In our experiments, P1 and P2 indepen-
dently choose 128-bit keys K1 and K2 and set K = K1 ⊕ K2
to be the encryption key; P3 provides the 128-bit message as
input. Hence, the total input length to the AES-128 circuit
is 384 and the output length is 128. The input/output sizes
for all other circuits and the number of AND/XOR/NOT
gates in each is presented in Table 1. Note that none of the
circuits we used contains OR gates and since XOR gates and
NOT gates are free in our implementation, the ultimate cost
driver is the number of AND gates.

Circuit
AES-128

MD-5
SHA-1

SHA-256

AND
7200
29084
37300
90825

NOT

0

34627
45135
103258

XOR Input size Output size
37638
14150
24166
42029

128
128
160
256

384
512
512
512

Table 1: Number of AND/OR/NOT gates , and in-
put/output sizes for each circuit. Input/output sizes
are in bits.

In our ﬁrst experiment, the client and server communicate
via sockets whose max size is set to 10KB. The results are
shown in Table 2. The computation time for P1/P2 measures
the time that P1/P2 need to generate the garbled circuit,
compute the commitments, serialize the data and hash half
of the data. The computation time for P3 measures the
time P3 needs to deserialize the data, compare and verify
the garbled circuits, and evaluate them. The network time
measures the time spent by P1, P2 and P3 to send/receive
data over socket.

Table 3 shows the size of parties’ communication during

the same experiment.

Next, to examine the eﬀect of the half-gate technique on
the performance, we disable it (i.e. only the single row-
reduction is enabled) and run the same experiments. The
results are shown in Tables 4 and 5. As expected, the half-

avoids frequent re-keying. Unfortunately, negative results of
[BCS05] show such a construction to be impossible.

Circuit
AES-128

MD-5
SHA-1

SHA-256

Network
13.30 ± 0.97
29.05 ± 1.12
36.60 ± 2.63
78.46 ± 2.62

P3 Comp.
2.30 ± 0.46
9.05 ± 0.38
11.50 ± 0.80
31.18 ± 0.57

P1/P2 Comp.
1.60 ± 0.59
5.85 ± 0.66
7.65 ± 0.89
21.09 ± 1.90

Table 2: Half-gates and hashing technique enabled;
times in milliseconds.

Circuit
AES-128

MD-5
SHA-1

SHA-256

P3 (KB) P1/P2 (KB)

1.19
2.05
2.78
6.11

752.37
1276.16
1732.75
3752.25

Table 3: Communication sizes for experiments of
Table 2.

gate technique has a major eﬀect on reducing the total run-
ning time as well the bandwidth of the protocol. The size
of communication increases by 50% which is expected since
garbled tabled sizes increase from 2 two 3.

Circuit
AES-128

% diﬀ
MD-5
% diﬀ
SHA-1
% diﬀ

SHA-256

% diﬀ

Network
17.80 ± 1.45
+34.57%
41.19 ± 2.20
+65.66%
51.74 ± 3.04
+64.90%
116.10 ± 4.00

+67.96%

P3 Comp.
3.10 ± 0.30
+34.78%
15.45 ± 0.80
+70.71%
19.85 ± 0.79
+72.61%
50.10 ± 1.22
+60.68%

P1/P2 Comp.
2.20 ± 0.41
+37.50%
12.93 ± 0.53
+121.02%
16.48 ± 1.13
+115.42%
44.40 ± 2.01
+110.53%

Table 4: Half-gates disabled; times in milliseconds.
Percentages show diﬀerence from Table 2.

Circuit
AES-128

% diﬀ
MD-5
% diﬀ
SHA-1
% diﬀ

1.77

+48.74%

3.05

+48.78%

4.16

+49.64%

SHA-256

9.17

% diﬀ

+50.08%

P3 (KB) P1/P2 (KB)

1104.74
+46.83%
1885.66
+47.76%
2561.82
+47.85%
5618.85
+49.75%

Table 5: Communication sizes for experiments of
Table 4. Percentages show diﬀerence from Table 2

Next, we turn the half-gate technique back on and turn-
oﬀ the hash technique and re-run the experiments. Results
are shown in Tables 6 and 7. Again, this reconﬁrms the
signiﬁcant eﬀect of the hashing technique on both the total
running time and the communication size. Note that the
computation times reduces when we turn oﬀ the hash tech-
nique which is natural since we avoid the extra hashing by
all parties. But given that serializing and sending/receiving
messages is the bottleneck, the net eﬀect of the hashing op-
timization is positive.

598Circuit
AES-128

% diﬀ
MD-5
% diﬀ
SHA-1
% diﬀ

SHA-256

% diﬀ

Network
20.89 ± 1.24
+27.39%
45.15 ± 0.97
+12.55%
57.50 ± 1.68
+14.03%
125.93 ± 2.35

+10.30%

P3 Comp.
1.30 ± 0.46
-43.48%
4.20 ± 0.40
-53.59%
5.50 ± 0.59
-52.17%
15.72 ± 0.75

-49.58%

-45%

P1/P2 Comp.
0.88 ± 0.40
3.35 ± 0.58
-42.74%
4.65 ± 0.70
-39.22%
12.90 ± 0.68

-38.83%

Table 6: Hash technique disable. times in millisec-
onds. Percentages show diﬀerence from Table 2

P3 (KB) P1/P2 (KB)

1447.58
+92.40%
2485.63
+94.77%
3380.84
+95.11%
7437.82
+98.22%

Circuit
AES-128

% diﬀ
MD-5
% diﬀ
SHA-1
% diﬀ

2.33

+95.80%

4.03

+96.59%

5.50

+97.84%

SHA-256

12.15

% diﬀ

+98.85%

Table 7: Communication size for experiments of Ta-
ble 6. Percentages show diﬀerence from Table 2

4.3 Comparison

3PC with one corruption.

As mentioned earlier, the most relevant protocols to ours
are those designed in the same setting of 3PC with one cor-
ruption, or honest majority in general. The MPC construc-
tions based on veriﬁable secret sharing [BOGW88, RBO89]
achieve the same security as our construction (malicious se-
curity), and are asymptotically very eﬃcient, as they require
O(poly(n)) bits of communication per multiplication gate
where n is number of parties, and the polynomial is rela-
tively small, and these protocols also avoid cryptographic
operations. However, to the best of our knowledge, no im-
plementation of these constructions exists, so it is hard to
provide a concrete comparison.
It is a very valuable di-
rection to explore practical eﬃciency of these constructions
even in the three-party setting, and compare their eﬃciency
and scalability with our construction in various scenarios.

The 3PC constructions with experimental results reported
include VIFF [Gei07], Sharemind [BLW08], PICCO [ZSB13],
ShareMonad [LDDAM12, LADM14], and [IKHC14]. With
the exception of [IKHC14], these protocols only provide se-
curity against semi-honest adversaries. In contrast, our pro-
tocol is secure against malicious adversaries in the same set-
ting, but demonstrates eﬃciency that is comparable to these
semi-honest counterparts.

Admittedly, an accurate/fair comparison is not possible,
given that each implementation runs in a diﬀerent envi-
ronment, using diﬀerent language/libraries and networking,
memory, and CPU speciﬁcations. For example, our ma-
chines’ memory/CPU speciﬁcations seems fairly modest com-
pared to the prior work and we do not take advantage of any
parallelism. But to demonstrate that eﬃciency of our con-
struction (for boolean circuits) is comparable to other im-
plemented constructions with only semi-honest security, a
single execution of an AES block requires 232 ms in Share-

mind [LTW13], 14.3 ms in ShareMonad [LDDAM12], and
18 ms in our implementation (See Table 2). The construc-
tion of [IKHC14] which achieves malicious security (similar
to ours) did not include an implementation of any boolean
circuits circuit but based on the provided experimental num-
bers, their construction requires a factor of k (the security
parameter) more communication and a factor of 3 more com-
putation compared to secret-sharing-based semi-honest 3PC
implementations.

Protocols with Dishonest Majority.

The bulk of other existing implementations with mali-
cious security are focused on the dishonest majority set-
ting. For example, there is large body of work on mak-
ing Yao’s two-party protocol secure against malicious adver-
saries with several implementations available [LPS08, KS12,
FN13, AMPR14]. When considering a single execution,
these protocols are at least a multiplicative factor of secu-
rity parameter (80) more expensive than semi-honest Yao’s
protocol. But as seen earlier, our protocol has complexity
that is fairly comparable to a single run of semi-honest and
hence outperforms single-execution malicious 2PC protocols
by a wide margin.

Note that when running many instances of malicious 2PC

for the same function, there are recent results [LR14, HKK+14]
that noticeably reduce the amortized multiplicative factor.
In general, our comparisons are only for a single execution
of the constructions. It is interesting to compare eﬃciency
of the existing implementations in batch execution of the
same of diﬀerent setting, and to introduce new techniques
for better batch 3PC.

We also emphasize that the above comparison is only
fair for Boolean circuits, as secret-sharing-based protocols
are often superior to garbled-circuit based ones for arith-
metic circuits given that they directly implement multipli-
cation/addition gates.

Another line of work [DKL+12, DKL+13] consider multi-

party computation with dishonest majority in the pre-processing
model where the goal is to implement a very fast online phase
after a relatively expensive pre-prceossing stage for generat-
ing authenticated triplets. Similar to malicious 2PC, the
total cost (oﬄine + online) of these protocols signiﬁcantly
higher than ours (several seconds), but a direct comparison
is not warranted give the diﬀerence in security guarantees
and their focus on a fast online phase. We discuss this line of
work again when considering the credential encryption ser-
vice application where online/oﬄine separation is natural.

5. APPLICATION: DISTRIBUTED CREDEN-

TIAL ENCRYPTION SERVICE

An interesting application of our work and an initial mo-
tivation for it was the design of a distributed credential en-
cryption service. The goal of this service is to keep creden-
tials such as hashed passwords encrypted at rest, in order
to prevent oﬄine dictionary attacks when user databases are
compromised. At the same time, the service should be easily
retroﬁtted into existing authentication systems, in which an
authentication server computes or receives a hashed pass-
word in the clear. Hence, the goal is not to use crypto to
protect the computation of a hashed password, but to simply
protect the static database of hashed passwords.

599A (non-distributed) credential encryption service receives
a hashed password from the authentication server as input,
which it encrypts to return a ciphertext that is stored in a
database. To authenticate a user, the authentication server
sends to the encryption service the hash of the purported
password along with the correct ciphertext obtained from
the database. The encryption service authenticates the user
by decrypting the ciphertext and checking whether the re-
sult matches the hashed password that is given. Overall,
the encryption service stores a secret encryption key and
provides encryption/decryption functionality. The authen-
tication server’s database remains encrypted; authenticating
a user requires interaction with the encryption service and
hence cannot be done oﬄine in a dictionary attack in the
event that the authentication database is compromised.

In order to distribute trust and avoid a single point of at-
tack we replace the encryption service by three servers run-
ning our 3PC protocol. P1 and P2 each hold a 128-bit ran-
dom strings K1 and K2, while P3 receives h(passwd) from a
log-in service to encrypt using the key K = K1 ⊕ K2, i.e. to
compute AESK (h(passwd)). Our 3PC construction guar-
antees that even if the encrypted database is compromised,
and one of the servers is compromised and even controlled
by the adversary, the encryption key is not compromised
and user credentials are not susceptible to oﬄine dictionary
attacks.

Note that unlike the general 3PC scenario, in the creden-
tial encryption service we can consider further optimizations.
For example, since the computation involves the same circuit
(e.g., AES) each time, we can in an oﬄine phase (i.e. in the
background or through a diﬀerent channel without a latency
restriction) have P1 and P2 garble many circuits separately
using randomness they agree on and transmit them to P3.
Furthermore, given that P1, P2’s inputs remain the same
across multiple executions, they can also incorporate their
garbled inputs to those circuits. A subtle issue is that for
this approach to work, we have to assume that the garbling
scheme is adaptively secure [BHR12a], a stronger assump-
tion than we need for our main protocol.

The online phase then consists of P3 obtaining the la-
bels for his input h(passwd), taking a pair of garbled cir-
cuits/commitments that are the same from a pile computed
earlier and evaluating it. Our experiments show that the on-
line running time of the protocol is on average 1.34 ± 0.47
ms, making the protocol feasible for real-world deployment.

The SPDZ protocols and followup works [DKL+12, DKL+13],

also focus on optimizing the online case at the cost of the of-
ﬂine phase, and achieve fast online performance in the order
of milliseconds for AES circuit (though higher than ours),
but have a much slower oﬄine phase compared to us. Given
than the oﬄine phase is not reusable in either ours or SPDZ
construction and has to repeated on a regular basis, our
protocol seems more suitable for this application given the
faster oﬄine phase. On the other hand, the SPDZ protocols
achieve stronger security by handling two corruptions.

6. REFERENCES
[AMPR14] Arash Afshar, Payman Mohassel, Benny

[BCD+09]

[BCS05]

Pinkas, and Ben Riva. Non-interactive secure
computation based on cut-and-choose. In
Advances in Cryptology–EUROCRYPT 2014,
pages 387–404. Springer, 2014.
Peter Bogetoft, Dan Lund Christensen, Ivan
Damg˚ard, Martin Geisler, Thomas Jakobsen,
Mikkel Krøigaard, Janus Dam Nielsen,
Jesper Buus Nielsen, Kurt Nielsen, Jakob
Pagter, et al. Secure multiparty computation
goes live. In Financial Cryptography and Data
Security, pages 325–343. Springer, 2009.
John Black, Martin Cochran, and Thomas
Shrimpton. On the impossibility of
highly-eﬃcient blockcipher-based hash
functions. In Ronald Cramer, editor,
EUROCRYPT 2005, volume 3494 of LNCS,
pages 526–541. Springer, May 2005.

[BDNP08] Assaf Ben-David, Noam Nisan, and Benny

Pinkas. FairplayMP: a system for secure
multi-party computation. In Peng Ning,
Paul F. Syverson, and Somesh Jha, editors,
ACM CCS 08, pages 257–266. ACM Press,
October 2008.

[BHKR13] Mihir Bellare, Viet Tung Hoang, Sriram

Keelveedhi, and Phillip Rogaway. Eﬃcient
garbling from a ﬁxed-key blockcipher. In
Security and Privacy (SP), 2013 IEEE
Symposium on, pages 478–492. IEEE, 2013.
[BHR12a] Mihir Bellare, Viet Tung Hoang, and Phillip

Rogaway. Adaptively secure garbling with
applications to one-time programs and secure
outsourcing. In Xiaoyun Wang and Kazue
Sako, editors, ASIACRYPT 2012, volume
7658 of LNCS, pages 134–153. Springer,
December 2012.

[BLW08]

[BHR12b] Mihir Bellare, Viet Tung Hoang, and Phillip
Rogaway. Foundations of garbled circuits. In
Ting Yu, George Danezis, and Virgil D.
Gligor, editors, ACM CCS 12, pages 784–796.
ACM Press, October 2012.
Dan Bogdanov, Sven Laur, and Jan
Willemson. Sharemind: A framework for fast
privacy-preserving computations. In Sushil
Jajodia and Javier L´opez, editors,
ESORICS 2008, volume 5283 of LNCS, pages
192–206. Springer, October 2008.
Donald Beaver, Silvio Micali, and Phillip
Rogaway. The round complexity of secure
protocols. In Proceedings of the twenty-second
annual ACM symposium on Theory of
computing, pages 503–513. ACM, 1990.

[BMR90]

[BOGW88] Michael Ben-Or, Shaﬁ Goldwasser, and Avi

Acknowledgements
We wish to thank Yan Huang and several anonymous review-
ers for many helpful suggestions to improve the writeup. We
are also appreciative of Yuval Ishai and Ranjit Kumaresan
for bringing some related work to our attention.

[BTW12]

Wigderson. Completeness theorems for
non-cryptographic fault-tolerant distributed
computation (extended abstract). In STOC
1988 [STO88], pages 1–10.
Dan Bogdanov, Riivo Talviste, and Jan
Willemson. Deploying secure multi-party
computation for ﬁnancial data analysis (short
paper). In Proceedings of the 16th

600[Can01]

[CCD88]

[CKMZ14]

International Conference on Financial
Cryptography and Data Security. FC’12,
pages 57–64, 2012.
Ran Canetti. Universally composable
security: A new paradigm for cryptographic
protocols. In 42nd FOCS, pages 136–145.
IEEE Computer Society Press, October 2001.
David Chaum, Claude Cr´epeau, and Ivan
Damg˚ard. Multiparty unconditionally secure
protocols (extended abstract). In STOC 1988
[STO88], pages 11–19.
Seung Geol Choi, Jonathan Katz, Alex J
Malozemoﬀ, and Vassilis Zikas. Eﬃcient
three-party computation from cut-and-choose.
In Advances in Cryptology–CRYPTO 2014,
pages 513–530. Springer, 2014.

[CMF+14] Koji Chida, Gembu Morohashi, Hitoshi Fuji,

Fumihiko Magata, Akiko Fujimura, Koki
Hamada, Dai Ikarashi, and Ryuichi
Yamamoto. Implementation and evaluation of
an eﬃcient secure computation system using
’R’ for healthcare statistics. Journal of the
American Medical Informatics Association,
21(e2):e326–e331, 2014.
Ivan Damg˚ard and Yuval Ishai.
Constant-round multiparty computation
using a black-box pseudorandom generator.
In Advances in Cryptology–CRYPTO 2005,
pages 378–394. Springer, 2005.
Ivan Damg˚ard, Marcel Keller, Enrique
Larraia, Christian Miles, and Nigel P. Smart.
Implementing AES via an actively/covertly
secure dishonest-majority MPC protocol. In
Ivan Visconti and Roberto De Prisco, editors,
SCN 12, volume 7485 of LNCS, pages
241–263. Springer, September 2012.
Ivan Damg˚ard, Marcel Keller, Enrique
Larraia, Valerio Pastro, Peter Scholl, and
Nigel P Smart. Practical covertly secure mpc
for dishonest majority–or: Breaking the spdz
limits. In Computer Security–ESORICS 2013,
pages 1–18. Springer, 2013.
Uriel Feige, Joe Kilian, and Moni Naor. A
minimal model for secure computation
(extended abstract). In 26th ACM STOC,
pages 554–563. ACM Press, May 1994.
Tore Kasper Frederiksen and Jesper Buus
Nielsen. Fast and maliciously secure
two-party computation using the GPU. In
Michael J. Jacobson Jr., Michael E. Locasto,
Payman Mohassel, and Reihaneh
Safavi-Naini, editors, ACNS 13, volume 7954
of LNCS, pages 339–356. Springer, June 2013.
Martin Geisler. Viﬀ: Virtual ideal
functionality framework. Homepage:
http://viﬀ. dk, 2007.
Juan A. Garay and Rosario Gennaro, editors.
CRYPTO 2014, Part II, volume 8617 of
LNCS. Springer, August 2014.
Shaﬁ Goldwasser and Yehuda Lindell. Secure
multi-party computation without agreement.

[DI05]

[DKL+12]

[DKL+13]

[FKN94]

[FN13]

[Gei07]

[GG14]

[GL05]

Journal of Cryptology, 18(3):247–287, July
2005.

[GMW87] Oded Goldreich, Silvio Micali, and Avi

Wigderson. How to play any mental game or
A completeness theorem for protocols with
honest majority. In Alfred Aho, editor, 19th
ACM STOC, pages 218–229. ACM Press,
May 1987.

[HKK+14] Yan Huang, Jonathan Katz, Vladimir

[IKHC14]

Kolesnikov, Ranjit Kumaresan, and Alex J
Malozemoﬀ. Amortizing garbled circuits. In
Advances in Cryptology–CRYPTO 2014,
pages 458–475. Springer, 2014.
Dai Ikarashi, Ryo Kikuchi, Koki Hamada,
and Koji Chida. Actively private and correct
mpc scheme in t < n/2 from passively secure
schemes with small overhead. Cryptology
ePrint Archive, Report 2014/304, 2014.
http://eprint.iacr.org/.

[IKKPC15] Yuval Ishai, Ranjit Kumaresan, Eyal

[IKP10]

[KS08]

[KS12]

[LADM14]

Kushilevitz, and Anat Paskin-Cherniavsky.
Secure computation with minimal interaction,
revisited. In Rosario Gennaro and Matthew
Robshaw, editors, CRYPTO 2015, volume
9216 of LNCS, pages 359–378. Springer, 2015.
Yuval Ishai, Eyal Kushilevitz, and Anat
Paskin. Secure multiparty computation with
minimal interaction. In Tal Rabin, editor,
CRYPTO 2010, volume 6223 of LNCS, pages
577–594. Springer, August 2010.
Vladimir Kolesnikov and Thomas Schneider.
Improved garbled circuit: Free xor gates and
applications. In Automata, Languages and
Programming, pages 486–498. Springer, 2008.
Benjamin Kreuter and Chih-hao Shen.
Billion-gate secure computation with
malicious adversaries. In In USENIX
Security. Citeseer, 2012.
John Launchbury, Dave Archer, Thomas
DuBuisson, and Eric Mertens.
Application-scale secure multiparty
computation. In Programming Languages and
Systems, pages 8–26. Springer, 2014.

[LDDAM12] John Launchbury, Iavor S Diatchki, Thomas

DuBuisson, and Andy Adams-Moran.
Eﬃcient lookup-table protocol in secure
multiparty computation. In ACM SIGPLAN
Notices, volume 47, pages 189–200. ACM,
2012.
Enrique Larraia, Emmanuela Orsini, and
Nigel P. Smart. Dishonest majority
multi-party computation for binary circuits.
In Garay and Gennaro [GG14], pages
495–512.
Yehuda Lindell and Benny Pinkas. A proof of
security of Yao’s protocol for two-party
computation. Journal of Cryptology,
22(2):161–188, April 2009.
Yehuda Lindell, Benny Pinkas, and Nigel P.
Smart. Implementing two-party computation
eﬃciently with security against malicious
adversaries. In Rafail Ostrovsky, Roberto De

[LOS14]

[LP09]

[LPS08]

601Prisco, and Ivan Visconti, editors, SCN 08,
volume 5229 of LNCS, pages 2–20. Springer,
September 2008.
Yehuda Lindell and Ben Riva. Cut-and-choose
Yao-based secure computation in the
online/oﬄine and batch settings. In Garay
and Gennaro [GG14], pages 476–494.
Sven Laur, Riivo Talviste, and Jan
Willemson. From oblivious aes to eﬃcient and
secure database join in the multiparty setting.
In Applied Cryptography and Network
Security, pages 84–101. Springer, 2013.
Moni Naor. Bit commitment using
pseudorandomness. Journal of Cryptology,
4(2):151–158, 1991.
Jesper Buus Nielsen, Peter Sebastian
Nordholt, Claudio Orlandi, and Sai Sheshank
Burra. A new approach to practical
active-secure two-party computation. In
Advances in Cryptology–CRYPTO 2012,
pages 681–700. Springer, 2012.
Tal Rabin and Michael Ben-Or. Veriﬁable
secret sharing and multiparty protocols with
honest majority (extended abstract). In 21st
ACM STOC, pages 73–85. ACM Press, May
1989.
20th ACM STOC. ACM Press, May 1988.
Andrew Chi-Chih Yao. Protocols for secure
computations (extended abstract). In 23rd
FOCS, pages 160–164. IEEE Computer
Society Press, November 1982.
Andrew Chi-Chih Yao. How to generate and
exchange secrets (extended abstract). In 27th
FOCS, pages 162–167. IEEE Computer
Society Press, October 1986.
Samee Zahur, Mike Rosulek, and David
Evans. Two halves make a whole - reducing
data transfer in garbled circuits using half
gates. In Elisabeth Oswald and Marc
Fischlin, editors, EUROCRYPT 2015, Part
II, volume 9057 of LNCS, pages 220–250.
Springer, April 2015.
Yihua Zhang, Aaron Steele, and Marina
Blanton. Picco: a general-purpose compiler

[LR14]

[LTW13]

[Nao91]

[NNOB12]

[RBO89]

[STO88]
[Yao82]

[Yao86]

[ZRE15]

[ZSB13]

for private distributed computation. In
Proceedings of the 2013 ACM SIGSAC
conference on Computer & communications
security, pages 813–826. ACM, 2013.

APPENDIX
A. SECURITY PROOF FOR NAOR COM-

MITMENT VARIANT

In Section 2.3 we deﬁned a multi-bit variant of Naor’s
commitment in the CRS model. For n-bit strings, we need
a crs ∈ {0, 1}4n. Let G : {0, 1}n → {0, 1}4n be a pseudo-
random generator, and let pad : {0, 1}n → {0, 1}4n be the
function that prepends 3n zeroes to the front of its argu-
ment. Then the commitment scheme is:

• Comcrs(x; r): set C = G(r) + crs · pad(x), with arith-
• Chkcrs(C, σ = (r, x)): return x if C = G(r) + crs ·

metic in GF (24n); set σ = (r, x).
pad(x); otherwise return ⊥.

Theorem 2. This commitment scheme satisﬁes the prop-

erties of binding and hiding given in Section 2.3.

Proof. Hiding follows easily from the security of PRG G.
In particular, for all crs and x, a commitment is generated
as C = G(r) + crs · pad(x). Since r is chosen uniformly, the
result is pseudorandom.

Binding follows from the following argument. An adver-
sary succeeds in equivocating if and only if it can produce
C, r, x, r(cid:48), x(cid:48) with x (cid:54)= x(cid:48) and:

C = G(r) + crs · pad(x) = G(r

(cid:48)

) + crs · pad(x

(cid:48)

)

⇐⇒ crs = [G(r) − G(r

(cid:48)

(cid:48)

)](pad(x

) − pad(x))

−1

Since x (cid:54)= x(cid:48) and pad is injective, pad(x(cid:48)) − pad(x) (cid:54)= 0
indeed has a multiplicative inverse in the ﬁeld.
Let us call a crs “bad” if there exists r, r(cid:48), x (cid:54)= x(cid:48) sat-
isfying the above property. Clearly an adversary’s success
probability in equivocation is bounded by Pr[crs is bad].
There are at most 22n values of G(r) − G(r(cid:48)) and at most
2n values of pad(x(cid:48))−pad(x) (under the standard encoding of
GF (2k) into {0, 1}k, we have pad(x(cid:48))−pad(x) = pad(x(cid:48)⊕x)).
Hence there are at most 23n bad values of crs. It follows that
the probability of a random crs ∈ {0, 1}4n being bad is at
most 1/2n.

602