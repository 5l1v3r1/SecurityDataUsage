2014 IEEE Symposium on Security and Privacy

Formal Analysis of Chaumian Mix Nets with Randomized Partial Checking

Ralf K¨usters

Tomasz Truderung

Andreas Vogt

University of Trier, Germany

University of Trier, Germany

University of Applied Sciences and Arts

kuesters@uni-trier.de

truderung@uni-trier.de

Northwestern Switzerland

andreas.vogt@fhnw.ch

Abstract—Mix nets with randomized partial checking (RPC
mix nets) have been introduced by Jakobsson, Juels, and Rivest
as particularly simple and efﬁcient veriﬁable mix nets. These
mix nets have been used in several implementations of promi-
nent e-voting systems to provide vote privacy and veriﬁability.
In RPC mix nets, higher efﬁciency is traded for a lower level
of privacy and veriﬁability. However, these mix nets have never
undergone a rigorous formal analysis. Recently, Kahazei and
Wikstr¨om even pointed out several severe problems in the
original proposal and in implementations of RPC mix nets in e-
voting systems, both for so-called re-encryption and Chaumian
RPC mix nets. While Kahazei and Wikstr¨om proposed several
ﬁxes, the security status of Chaumian RPC mix nets (with the
ﬁxes applied) has been left open; re-encryption RPC mix nets,
as they suggest, should not be used at all.

In this paper, we provide the ﬁrst formal security analysis of
Chaumian RPC mix nets. We propose security deﬁnitions that
allow one to measure the level of privacy and veriﬁability RPC
mix nets offer, and then based on these deﬁnitions, carry out a
rigorous analysis. Altogether, our results show that these mix
nets provide a reasonable level of privacy and veriﬁability, and
that they are still an interesting option for the use in e-voting
systems.

Keywords-Mix Nets; Random Partial Checking; Crypto-

graphic Analysis; Privacy; Veriﬁability; Accountability

I. INTRODUCTION

The concept of a mix net has been introduced by Chaum
[5] as a tool for achieving anonymity. The main application
is in electronic voting, but they have also found applications
in other domains, such as multi-party computation, payment
systems, and anonymous web browsing.

The mix nets proposed by Chaum, later called Chaumian
mix nets, consist of a sequence M0, . . . ,Mm−1 of mix servers.
Each server generates a public/private key pair (pk j,sk j)
and publishes the public key pk j. So-called senders choose
plaintexts to be sent through the mix net. In the context
of e-voting, the plaintexts might be the candidates chosen
by the senders/voters. Every sender encrypts her plaintext,
say m, under the public keys of all mix servers in the
reverse order, i.e., a sender produces a ciphertext of the
(m)··· )). Now, ﬁrst M0
form: Encpk0
decrypts all ciphertexts and shufﬂes the results, then M1
does the same with the ciphertexts received from M0, and
so on. Eventually, the last mix server, Mm−1, outputs all
plaintexts (again after having shufﬂed them ﬁrst). The goal
of such a mix net is that it should not be possible to link the

(···Encpkm−1

(Encpk1

© 2014, Ralf Küsters. Under license to IEEE.
DOI 10.1109/SP.2014.29

343

output to the input. In the context of voting, this is important
for vote privacy.

Another common form of a mix net is a so-called re-
encryption mix net [18]. Here the mix servers generate a
single joint public key for a public-key encryption scheme
that allows for random re-encryption and distributed veri-
ﬁable decryption. Senders encrypt their messages with the
public key and the mix servers do not decrypt the ciphertexts
but only randomly re-encrypt and shufﬂe them. (Decryption
is performed jointly at the very end of the mixing phase.)
In the context of e-voting, it is crucial that potential
manipulations are detected. That is, if plaintexts (votes) have
been dropped or manipulated, this should be detected. This
property is called veriﬁability.

Many constructions have been proposed to obtain veriﬁ-
able mix nets (see, e.g., [21], [17], [7], [23], [9], [10], some
of which have been broken [22]). Most of the constructions
are quite complex.

A particularly simple and efﬁcient construction is the one
proposed by Jakobsson, Juels, and Rivest [9]. They call the
new technique they introduce randomized partial checking
(RPC), which applies to both Chaumian mix nets and re-
encryption mix nets. Roughly speaking, the idea behind RPC
is that to check whether or not a mix server cheated, every
mix server is supposed to reveal some partial information
about the input/output relation. (Which information is to be
revealed is randomly chosen and the mix servers should not
know it beforehand.) Therefore, a cheating server is caught
with some probability. From the design of RPC mix nets it is
clear that they do not provide perfect security: there is some
non-negligible probability that cheating goes undetected and
some partial information about the input/output relation is
revealed. As argued in [9], in the context of e-voting the
penalties for cheating would be so severe that being caught
with some (even small) probability should deter a mix server
from cheating. Due to their simplicity and efﬁciency, RPC
mix nets have been used in real implementations of several
prominent e-voting systems, including Civitas [6] and Prˆet
`a Voter [20]. Some systems, such as Scantegrity [4], have
used a similar technique.

In [11], Kahazei and Wikstr¨om have pointed out several
severe attacks on RPC mix nets as described in the original
work [9] and as implemented in several e-voting systems.
They suggest that re-encryption RPC mix nets should not be

Given the simplicity, efﬁciency, and importance of Chau-
mian RPC mix nets, this is an interesting and practically
relevant open problem, for which we provide answers in
this paper. More speciﬁcally, the contributions of this work
are as follows.
Contribution of this paper. Based on work by K¨usters
et al. in [13], [14], we propose security deﬁnitions which
allow one to precisely measure the level of privacy and
veriﬁability Chaumian RPC mix nets provide. As mentioned
before, being able to measure the level of security is crucial
for RPC mix nets since they are not perfect. Our deﬁnitions
should be applicable also to other kinds of mix nets.

Since mix nets are mainly used in the context of e-voting,
our notion of privacy corresponds to one that has been used
in the context of e-voting before [14]. It focuses on the
level of privacy for individual senders/voters and basically
requires that for every pair of messages an adversary should
not be able to tell which of the two messages a sender has
sent.

We do not only study veriﬁability, but a stronger notion:
accountability. Veriﬁability requires that misbehavior should
be detectable. Accountability,
in addition, requires that
speciﬁc misbehaving parties can be blamed. This property,
which is expected from RPC mix nets, is important in order
to deter parties from misbehaving.

We study Chaumian RPC mix net both w.r.t. in-phase
and post-phase auditing. Post-phase auditing means that it is
checked at the very end of the mixing phase only whether or
not the mix servers behaved correctly. For in-phase auditing,
the auditing is done for every mix server immediately after
it has produced its output.

employed at all, but leave as an open problem to prove or
disprove that, with the ﬁxes they suggest, Chaumian RPC
mix nets provide sufﬁcient security. Kahazei and Wikstr¨om
mention that carrying out such a proof and even coming up
with useful security notions for privacy and veriﬁability is
challenging, considering that in any case RPC mix nets can
provide restricted forms of privacy and veriﬁability only.

In RPC mix nets, manipulation of inputs of honest senders
might give adversaries (malicious mix servers) leverage for
breaking privacy. But, as mentioned, if a mix server is caught
cheating it might face severe penalties. To be able to study
this trade-off (the risk of being caught and the information
gain), besides general (venturesome) adversaries who do not
mind being caught, we also introduce the concept of risk-
avoiding adversaries, i.e., adversaries who would only cheat
if the risk of being caught is small.

For our analysis of accountability and privacy of Chau-
mian RPC mix nets we make standard cryptographic assump-
tions. We assume the public key encryption scheme to be
IND-CCA2-secure [1] and the commitment scheme used in
such mix nets to be perfectly hiding and computationally
binding, with Pedersen commitments being an example
[19]. (However, a computationally hiding scheme would be

sufﬁcient.) As usual for Chaumian RPC mixnets, we require
that the public key encryption scheme allows for proofs of
correct decryption.

In our analysis of accountability, we discovered an attack
which does not seem to have been described in the liter-
ature before. While one of the most effective attacks on
accountability/veriﬁability, it does not further decrease the
overall level of security of RPC mix nets. We prove that
altogether Chaumian RPC mix nets have a quite good level
of accountability, no matter whether in-phase or post-phase
auditing is performed. This proves, in particular, that there
are no worse attacks on accountability/veriﬁability than those
already known.

As for the level of privacy, it matters whether post-phase
or in-phase auditing is performed and whether adversaries
are venturesome or risk-avoiding. In the case of in-phase
auditing, our results indicate that the level of privacy is very
close to the ideal case (where an adversary only learns the
plaintexts of the senders after ideal mixing), surprisingly
even for venturesome adversaries that are prepared to be
caught cheating for sure. In the case of post-phase auditing,
such adversaries can, however, break privacy completely.
Interestingly, in the more realistic case of risk-avoiding
adversaries (which do not want to be caught cheating with
a probability bigger than, say, 25% or even 75%, and hence,
which are still willing to take big risks), the level of privacy
for post-phase auditing is still very close to the ideal case.
We note that there has been no rigorous formal analysis of
RPC mix nets before. In particular, none that provides formal
security guarantees for privacy or veriﬁability/accountability.
As mentioned, Kahazei and Wikstr¨om [11] point out and
discuss attacks. In [8], the authors study the distance between
the probability distribution of the permutation links in RPC
mix nets and the uniform distribution, however, as also
pointed out in [11], this result does not capture privacy or
veriﬁability of RPC mix nets.
Structure of this paper. In Section II, we describe Chau-
mian RPC mix nets and present our formal model. Account-
ability and veriﬁability for such mix nets are deﬁned in
Section III, with the formal analysis presented in Section IV.
Our notion of privacy is introduced in Section V. The formal
analysis of the privacy of Chaumian RPC mix nets is then
provided in Section VI. We conclude in Section VII. Further
details are provided in the appendix. We point the reader to
[15] for the full version of this paper.

II. CHAUMIAN RPC MIX NET

In this section, we recall the deﬁnition of a Chaumian mix
net with randomized partial checking [9], a Chaumian RPC
mix net (or an RPC mix net for short), and then provide a
formal model of this protocol.

We focus here on a variant where duplicates are eliminated
before every mixing stage. As noted in [11], duplicate elim-
ination is necessary to prevent a serious attack on privacy.

344

We therefore need to ﬁx some details of the procedure of
duplicate elimination (see below).

We will consider two variants of the protocol, already
mentioned in [9]: i) in-phase auditing, a variant where
auditing takes place as soon as a mix server produced its
output and ii) post-phase auditing, where auditing takes
place only at then end of the mixing phase, i.e., when
the last mix server has output its result. While, as we
will see, the two variants do not make a difference for
veriﬁability/accountability, they differ in the level of privacy
they provide.

A. Description of the Protocol

Set of participants. The set of participants of the protocol
consists of a public, append-only bulletin board B, n senders
S1, . . .Sn, m mix servers M0, . . . ,Mm−1, and some number
of auditors.

The role of the auditors is to provide randomness for
the auditing phase. The auditors each output a random bit
string (more precisely, they ﬁrst commit to their random bit
strings and later open the commitments). Honest auditors
output a bit string chosen uniformly at random. These bit
strings are combined to one bit string, say by XOR. So,
if at least one auditor is honest, the resulting bit string is
chosen uniformly at random. We will indeed assume, both
for veriﬁability/accountability and for privacy, that at least
one auditor is honest. We note that sometimes heuristics are
implemented by which this assumption can be dropped (see
[9]). However, as pointed out in [11], especially in the case
of in-phase auditing, this leads to problems.

Typically, pairs of mix servers are audited. For the sake
of presentation, it is therefore convenient to assume that one
mix server performs two mixing steps. We will consider
such mix servers in this paper.

In this phase, every mix server M j,

Now, an RPC mix net consists of the following phases:
setup, submit, mixing, and auditing, where as mentioned
before, auditing might be in-phase. Chaumian RPC mix nets
require a public-key encryption scheme and a commitment
scheme. The precise assumptions required for these schemes
are formulated later in this paper.
j ∈
Setup phase.
{0, . . . ,m − 1}, invokes the key generation algorithm of a
public key encryption scheme in order to generate two pairs
of public/private keys. We denote the public keys by pk2 j
and pk2 j+1 and the corresponding private keys by sk2 j and
sk2 j+1. The public keys are posted on the bulletin board B.
Note that, altogether, the mix servers publish 2m public keys,
pk0, . . . , pk2m−1, on B.
Submit phase.
In this phase, every (honest) sender Si
chooses her input plaintext mi and performs the following
computation. She ﬁrst encrypts mi under pk2m−1, resulting
in the ciphertext αi
2m−1 under
pk2m−2, resulting in the ciphertext αi
2m−2, and so on. In

2m−1. Then, she encrypts αi

, . . . , αn

1 is encrypted under pk0, resulting in the
0. This ciphertext is posted by the sender on B

the last step, αi
ciphertext αi
as her encrypted input.
Mixing phase. The sequence C0 = α1
0 of the en-
0
crypted messages posted by the senders on B is the input
to the mixing phase. In what follows, we refer to αi
0 by
C0[i]; similarly for other sequences. These ciphertexts are
fetched by the ﬁrst mix server M0 which processes them,
as described below, and posts its output (which, again, is a
sequence of ciphertexts) on B. This output becomes the input
to the next mix server M1, and so on. We will denote the
input to the j-th mix server by C2 j and its output by C2 j+2,
reserving C2 j+1 for intermediate output (see Figure 1). Recall
that one mix server performs two mixing steps.

The output C2m of the last mix server Mm−1 is the output
of the protocol. It is supposed to contain the unencrypted
input messages m1, . . . ,mn (in random order).

The steps taken by every mix server M j are as follows

2 j

(see also Figure 1):
1. Duplicate elimination. M j removes all duplicates from
leaving only one copy each. The mix
its input C2 j,
server also removes all messages ⊥, indicating decryption
failures, from its input. We denote the resulting sequence
2 j. In what follows, we denote by l ≤ n the number
by C(cid:4)
of messages left in C(cid:4)
2 j.
2. First mixing. M j uniformly at random chooses a permuta-
tion π2 j of {1, . . . ,l} and posts the sequence C2 j+1 on B,
where C2 j+1[i] is the result of the decryption of C(cid:4)
[π2 j(i)]
under the private key sk2 j. Note that, depending on the
encryption scheme, decryption may fail, if the input is
not a valid ciphertext. Hence, C2 j+1[i] might be ⊥.
3. Second mixing. M j, again, uniformly at random chooses
a permutation π2 j+1 of {1, . . . ,l} and posts the sequence
C2 j+2 on B, where C2 j+2[i] is the result of the decryption
of C2 j+1[π2 j+1(i)] under the private sk2 j+1. The sequence
C2 j+2 is posted by M j on B. It is the input to the next
mix server.

4. Posting commitments. M j posts two sequences of commit-
ments on B: commitments to the values π2 j(1), . . . , π2 j(l)
and commitments to the values π−1
(l) (in
this order).

(1), . . . , π−1

2 j+1

2 j+1

We note that the duplicate elimination is performed only
on the input C2 j to the mix server, not on the intermediate
sequence C2 j+1. This simpliﬁes the auditing.
Auditing phase. The outputs of the mix servers are (par-
tially) audited in order to detect potential misbehavior. As
mentioned before, we consider in-phase and post-phase
auditing. In-phase auditing is performed for every mix server
M j immediately after it has posted its output C2 j+2 and the
commitments on B. In the case that misbehavior is detected,
the output of the malicious mix server is not forwarded to
the next server and the mixing process is stopped altogether.
Conversely, post-phase auditing is performed only when the

345

C2 j
x4
x4
x3
x2
x1

Mix server M j

C(cid:4)

2 j

sk2 j
π2 j

C2 j+1

sk2 j+1
π2 j+1

C2 j+2
y4
y3
y2
y1

duplicate
elimination

ﬁrst mixing

second mixing

Figure 1. Mixing by M j. Solid bold lines represent audited links and
dashed lines represent not audited links.

mixing phase is ﬁnished. However, the steps taken for every
individual mix server are the same for both types of auditing.
We now describe the auditing for the mix server M j.
First, using the randomness produced by the auditors,
for an initial empty set Ij and for every i ∈ {1, . . . ,l} it is
randomly decided, independently of other elements, whether
i is added to Ij ⊆ {1, . . . ,l} or not. Provided that the random
bit strings jointly produced by the auditors are distributed
uniformly at random, the probably that i belongs to Ij is 1
2.
Now, for every i ∈ {1, . . . ,l} the mix server Mj does the
following, depending on whether i belongs to Ij or not:
If i ∈ Ij, then the mix server M j is supposed to open (by
posting appropriate information on B) the left link for i, i.e.,
M j is supposed to open its i-th commitment from its ﬁrst
sequence of commitments, which should be a commitment
on the value π2 j(i). The mix server also has to post a (non-
interactive zero-knowledge) proof demonstrating that indeed
C2 j+1[i] is obtained by decrypting C(cid:4)
If i /∈ Ij, then, symmetrically, the mix server is supposed
to open the right link for i, i.e., M j is supposed to open its
i-th commitment from its second sequence of commitments,
which should be a commitment on the value π−1
(i). As
before, the mix server also has to post a proof that allows
an observer to verify that indeed C2 j+2[π−1
(i)] is obtained
by decrypting C2 j+1[i] using sk2 j+1.

[π2 j(i)] using sk2 j.

2 j

2 j+1

2 j+1

An observer (or a judge) can now verify correctness of
the data output by M j in the audit phase. First, the observer
veriﬁes that indeed all duplicates have been removed from
the input (by checking whether the number of messages
is as expected). Second, one veriﬁes that
output by Mj
commitments are opened correctly. Third, one veriﬁes that
the opened indices (both from the ﬁrst and the second
sequence) do not contain duplicates (if they do, this means
that the mix server has not committed to a permutation, but
to some other, non-bijective function). Finally, one veriﬁes
the decryption proofs. As pointed out in [11], the third step,
which often has been omitted in implementations and is not
mentioned in [9], is crucial for veriﬁability and privacy.

The auditing described above guarantees that for a mes-
sage from the sequence C2 j+1 either the connection to some
message from C2 j or to some message from C2 j+2 is revealed,
but never both. Otherwise, an observer could follow the path
of an input message to the corresponding output message
(see also Figure 1 for an illustration). Nevertheless, some
information about the link between the input and the output
is revealed. For example, in Figure 1 an observer knows that
the input values x1,x2 map to y2,y3 in some way and that
x3,x4 map to y1,y4 in some way, and hence, for instance,
she learns that x4 does not map to y2 or y3.

B. Modeling Chaumian RPC Mix Nets

We now provide a formal model of Chaumian RPC mix
nets, based on a computational model with interactive Turing
machines. The computational model follows the one used
in [13], [14], which we brieﬂy recall before presenting the
model of RPC mix nets and which in turn is based on the
IITM model [16], [12].

1) The Computational Model: A process is a set of proba-
bilistic polynomial-time interactive Turing machines (ITMs,
also called programs), which are connected via named tapes
(also called channels). Two programs with channels of
the same name but opposite directions (input/output) are
connected by such channels. A process may have external
input/output channels, those that are not connected internally.
In a run of a process, at any time only one program is active.
The active program may send a message to another program
via a channel. This program then becomes active and after
some computation can send a message to another program,
and so on. A process contains a master program, which is
the ﬁrst program to be activated and which is activated if the
active program did not produce output (and hence, did not
activate another program). If the master program is active
but does not produce output, a run stops.
We write a process π as π = p1 (cid:7) ··· (cid:7) pl, where p1, . . . , pl
are programs. If π1 and π2 are processes, then π1 (cid:7) π2
is a process, provided that the processes are connectible:
two processes are connectible if common external channels,
i.e., channels with the same name, have opposite directions
(input/output).

A process π where all programs are given the security
parameter (cid:4) is denoted by π((cid:4)). The processes we consider
are such that the length of a run is always polynomially
bounded in (cid:4). Clearly, a run is uniquely determined by the
random coins used by the programs in π.

Based on the notion of programs and processes, protocols

and instances of protocols are deﬁned as follows.

A protocol P speciﬁes a set of agents (also called parties
or protocol participants) and the channels these agents can
communicate over. Moreover, P speciﬁes, for every agent a,
a set Πa of all programs the agent a may run and a program
ˆπa ∈ Πa, the honest program of a, i.e., the program that a
runs if a follows the protocol.

346

f ((cid:4)) ≤ 1

As usual, a function f from the natural numbers to the
interval [0,1] is negligible if, for every c > 0, there exists
(cid:4)0 such that
is
overwhelming if the function 1− f is negligible. A function
f is λ-bounded if, for every c > 0 there exists (cid:4)0 such that
f ((cid:4)) ≤ λ + 1
2) Chaumian RPC Mix Nets Modeled as Protocols:

(cid:4)c , for all (cid:4) > (cid:4)0. The function f

(cid:4)c , for all (cid:4) > (cid:4)0.

Let P be a protocol with agents a1, . . . ,an. An instance of
(cid:7) . . . (cid:7) πan
∈ Πai.
P is a process of the form π = (πa1
An agent ai is honest in the instance π, if πai
= ˆπai. A run
of P (with security parameter (cid:4)) is a run of some instance
of P (with security parameter (cid:4)). An agent ai is honest in a
run r, if r is a run of an instance of P with honest ai.
By ¬γ we denote the complement of γ.

A property γ of P is a subset of the set of all runs of P.

) with πai

We model an RPC mix net as a protocol in the sense of
Section II-B1. The set of agents of such a protocol is as
introduced in Section II-A plus two additional agents, the
judge J and the scheduler Sch.

The programs of all agents are deﬁned to have channels
between each pair of agents. While not all channels are
necessarily used by honest agents, they may be used by
dishonest agents.
Scheduler. The honest program ˆπSch of the scheduler
will be the master program. It triggers all agents in the
appropriate order, according to the phases. It is part of
every instance of the protocol and we assume that
it
is given information about which agents are honest and
which are dishonest in order to schedule the agents in the
appropriate way. In particular, the scheduler can schedule
agents in a way advantageous for the adversary (dishonest
agensts) so that we obtain stronger security guarantees. For
example, the scheduler would ﬁrst schedule honest senders
to post their inputs on the bulletin board and then schedule
dishonest senders. By this, the input of dishonest senders (the
adversary) may depend on the input of honest senders. We
also let ˆπSch create a common reference string (CRS), which
it provides to all parties. The CRS is used by agents for non-
interactive zero-knowledge proofs of correct decryption (see
also Section IV-B).
The bulletin board B. The honest program of B accepts
messages from all agents. A message received from an agent
is stored in a list along with the identiﬁer of the agent who
posted the message. On request, B sends this list to an agent.
Auditors. For simplicity of presentation, we will simply
assume one honest auditor A. The honest program ˆπA of A,
whenever triggered by the scheduler posts its random output
on the bulletin board, as described in Section II-A.
Sender. The honest program ˆπS of a sender S implements
the procedure described in Section II-A: when triggered by
the scheduler it ﬁrst randomly picks a plaintext p according
to some ﬁxed probability distribution μ and then encrypts
p as described and posts the resulting ciphertext on the

bulletin board. The honest program that is executed once
p has been chosen is denoted by ˆπS(p). As we will see,
μ does not play any role for accountability, in which case
we could simply assume the input to be provided by the
adversary; this distribution, however, matters for our privacy
result. It models prior knowledge of the adversary about
the distribution of messages that honest senders send. In
reality, in the context of e-voting, the adversary might not
know this distribution precisely (only estimates according
to election forecasts, for example). But assuming that the
adversary knows this distribution precisely only makes the
security guarantees that we prove stronger.
Mix server. The honest program ˆπM j of a mix server
implements the procedure describe in Section II-A. When
triggered for the ﬁrst time by the scheduler, it performs the
described mixing procedure. It then waits to be triggered
again by the scheduler to run the described audit procedure.
Judge. The honest program of the judge ˆπJ whenever
triggered by the scheduler, reads data from the bulletin board
and veriﬁes it as described in Section II-A. If a mix server Mi
provides wrong output or if it simply declines to output the
required data, the judge posts a message dis(Mi), asserting
that Mi misbehaved, i.e., Mi has not followed the prescribed
protocol.
Trust assumptions. We assume that the scheduler, the bul-
letin board, the auditor, and the judge are honest. Formally,
this means that the set Πa of each such agent a consist of
only the honest program ˆπa of that agent. All the other agents
can (possibly) be dishonest. For a dishonest agent a, the set
of its programs Πa contains all probabilistic polynomially-
bounded programs.
We denote RPC mix nets modeled as above with m mix
servers and n senders that use a probability distribution μ
to determine their choices by Pmix(n,m, μ). To study privacy,
by P j
(n,m, μ) we denote the variant of the protocol, where
mix
the j-th mix server is assumed to be honest (which, again,
formally means that the set of all programs of M j contains
its honest program only).

III. DEFINING ACCOUNTABILITY AND VERIFIABILITY OF

RPC MIX NETS

In this section, we provide a deﬁnition of accountability
for RPC mix nets, followed by a deﬁnition of veriﬁability.
These notions are instantiations of the general, domain
independent deﬁnitions of accountability and veriﬁability
proposed in [13]. They should also apply to other forms
of mix nets.

The (general) deﬁnition of accountability of a protocol
from [13] is stated with respect to a property γ of the proto-
col, called the goal, a parameter λ ∈ [0,1], and an agent J of
the protocol who is supposed to blame protocol participants
in case of misbehavior (when the goal γ is not achieved).
The agent J, sometimes referred to as a judge, can be a

347

“regular” protocol participant or an (external) judge, who
is provided with information by other, possibly untrusted,
protocol participants. Informally speaking, accountability
requires two conditions to be satisﬁed:

(i) (fairness) J (almost) never blames protocol participants

who are honest, i.e., run their honest program.

(ii) (completeness) If, in a run,

the desired goal γ of
the protocol is not met—due to the misbehavior of
one or more protocol participants—, then J blames
those participants who misbehaved, or at least some
of them individually. The probability that the desired
goal is not achieved but J nevertheless does not blame
misbehaving parties should be bounded by λ.

To instantiate this deﬁnition for RPC mix nets, we ﬁrst
specify the goal γ and the parties who should be blamed in
case γ is not achieved in a run. We then present the formal
deﬁnition of accountability for mix nets, along the lines of
the general deﬁnition of accountability from [13] sketched
above.
The goal. As far as accountability (also veriﬁability) is
concerned, we expect from an RPC mix net that the output
strictly corresponds to the input, i.e., the plaintexts in the
input ciphertexts and the plaintext in the output of the
mix net should be the same multisets of plaintexts. This,
of course, can be guaranteed for honest senders only, as
dishonest parties may not follow the protocol and it might
not even be clear what their input plaintexts are. Below, we
formally describe this goal as a set of runs γ0. Moreover,
we generalize this goal by considering a family of goals γk,
for k ≥ 0, where γk is achieved if the output corresponds to
the input, up to k changed entries. In other words, for the
goal γk we tolerate up to k changes. This is useful for the
study of RPC mix nets because, due to the nature of random
partial checking, changing a small number of entries can go
unnoticed with some probability. However, this probability
should decrease very quickly with an increasing number of
manipulated entries.

To formally specify the goal γk, let us consider a run
r of an instance π of an RPC mix net P with n senders.
Let s1, . . . ,sl (for l ≤ n) be those senders that are honest
in r, (cid:8)x = x1, . . . ,xl be the input of these senders in r, and
(cid:8)y = y1, . . . ,yp (with p ≤ n) be the output of the mix net in
r (if any), i.e., the sequence of plaintexts posted by the last
mix server. We deﬁne r to belong to γk (in other words,
γk is achieved in r), if there exists a subsequence (cid:8)x(cid:4) of the
honest input (cid:8)x of size l−k such that (cid:8)x(cid:4), treated as a multiset,
is contained in (cid:8)y (again, treated as a multiset), i.e., for each
element a of (cid:8)x(cid:4), the count of a in (cid:8)x(cid:4) is less than or equal to
the count of a in (cid:8)y. Hence, we require the output to contain
l − k elements from the honest input, while the remaining
plaintexts, up to n−(l−k), can be provided by the adversary.
If in r no ﬁnal output was produced (possibly because a mix
server refused to produce output or the process was stopped

because in in-phase auditing some mix server was blamed
to have misbehaved), then r does not belong to γk, i.e., r
does not achieve γk.
Parties to be blamed. We require that if the goal γk is
not achieved, then the judge should blame at least one mix
server, i.e., post dis(Mi) for at least one i. By the fairness
property for accountability, it follows that at least this mix
server deﬁnitely misbehaved. By this, every mix server risks
to be blamed in the case it misbehaves, i.e., does not follow
the prescribed protocol. Note that we do not require the judge
to blame all misbehaving servers. This requirement would
be too strong, because not all misbehavior (i.e., deviations
from the prescribed protocol) can be detected by the judge.
However, the above guarantees that at least one mix server
is (rightly) blamed in the case that γk is not achieved. The
above requirement also implies that a sender cannot spoil
the goal γk: if γk is not achieved, this must be due to a
misbehaving mix server.

In the following deﬁnition of accountability for mix nets
we say that if the judge posts dis(a), for some agent a,
that the judge stated the verdict dis(a). Moreover, given an
instance π of a protocol P, we say that a verdict dis(a) is
true in π if and only if a is not honest in π (in the sense of
Section II-B1).

Now formally, accountability for RPC mix nets is deﬁned
as follows. We note that while this deﬁnition is formulated
for RPC mix nets as introduced in Section II-B2, it should be
useful also for other forms of mix nets. We write Pr[π((cid:4)) (cid:9)→
J : dis(a)] to denote the probability that in a run of π((cid:4))
the judge J states the verdict dis(a). We write Pr[π((cid:4)) (cid:9)→
¬γk ∧ ¬(J : dis(Mi) for some i)] to denote the probability
that in a run of π((cid:4)) the goal γk is not satisﬁed, i.e., the run
does not belong to γk, and nevertheless J does not state a
verdict dis(Mi) for any i. Both probabilities are taken over
the runs of π((cid:4)), i.e., the random coins used by the agents
in π.
Deﬁnition 1. (Accountability for RPC mix nets) Let P
be an RPC mix net protocol with an agent J (the judge),
λ ∈ [0,1], and k ≥ 0. We say that P provides λ-accountability
with tolerance k (and w.r.t. J), if the following two conditions
are satisﬁed.

(i) (Fairness) For all

instances π of P and all ver-
dicts dis(a) which are not true in π, the probability
Pr[π((cid:4)) (cid:9)→ J : dis(a)] is a negligible function in (cid:4).
(ii) (Completeness) For every instance π of P, the prob-
ability Pr[π((cid:4)) (cid:9)→ ¬γk ∧¬(J : dis(Mi) for some i)] is a
λ-bounded function in (cid:4).

The above deﬁnition requires that the judge never (more
precisely, only with negligible probability) blames mix
servers that behave honestly, i.e., run their honest program.
It also requires that the probability that the goal γk is not
satisﬁed, and hence, more than k inputs of honest senders

348

have been manipulated, but the judge nevertheless does not
blame any single mix server, is bounded by λ.

Of course, mix nets where 0-accountability with tolerance
0 is achieved are desirable,
i.e., mix nets, where even
one manipulation of an honest input goes unnoticed with
only negligible probability. While such mix nets can be
obtained with more complex cryptographic constructions
(some of which have been mentioned in the introduction),
it is in the nature of RPC mix nets that there is some
probability that manipulation goes unnoticed. One main
contribution of this work is to precisely measure the level of
accountability/veriﬁability RPC mix nets provide, and hence,
with regard to the above deﬁnition, to ﬁnd the optimal values
of λ for the goals γk. This analysis is carried out Section IV.
Veriﬁability. Accountability and veriﬁability are tightly re-
lated as shown in [13]. Accountability is a stronger property
than veriﬁability and subsumes it. While for veriﬁability
one requires protocol participants to be able to see whether
something went wrong or not, accountability additionally
demands that if something went wrong, it is possible to
blame speciﬁc misbehaving parties. This is an important
security property in practice. Mix nets and e-voting systems
should strive for accountability rather than only for veriﬁabil-
ity. Nevertheless, traditionally, in the context of e-voting, the
focus has been on veriﬁability, which is why here we also
present a deﬁnition of veriﬁability for mix nets, based on
the general, domain independent deﬁnition proposed in [13].
Similarly to the deﬁnition of accountability, the deﬁnition of
veriﬁability is parametrized by the goal γk (deﬁned just as
in the case of accountability) and assumes a judge J which
in the case of veriﬁability merely outputs accept or reject,
depending on whether she thinks that the goal is achieved
or not.
Deﬁnition 2. (Veriﬁability for RPC mix nets) Let P be an
RPC mix net protocol with an agent J (the judge), λ ∈ [0,1],
and k ≥ 0. We say that P is λ-veriﬁable w.r.t. J and tolerance
k, if the following two conditions are satisﬁed.

the probability Pr[π((cid:4)) (cid:9)→ J : accept]

(i) For all instances π of P where all mix servers are
is an
(ii) For every instance π of P, the probability Pr[π((cid:4)) (cid:9)→

honest,
overwhelming function in (cid:4).
¬γk ∧ J : accept] is a λ-bounded function in (cid:4).

Condition (ii) say that the probability that in a run the goal
is not satisﬁed but J nevertheless accepts the run should be
small (bounded by λ). This condition can easily be satisﬁed
by judges that do not accept any run. Condition (i) therefore
requires that if all mix servers are honest, then the judge
should accept the run, which together with Condition (ii)
implies that (with high probability) the goal is satisﬁed. It
follows from results shown in [13] that if an RPC mix net
provides λ-accountability with tolerance k and w.r.t. a judge
J, then the RPC mix net also provides λ-veriﬁable with

349

p3

p1

p4

p2

p1

Figure 2. Examples of cheating by the last mix server (left-hand side)
and by any mix server (right-hand side).

tolerance k and w.r.t. J(cid:4), where J(cid:4) outputs reject if J would
blame some party.

We note that for RPC mix nets every party (also external
observers) can play the role of the judge, who needs to
examine publicly available information only.

IV. ANALYSIS OF ACCOUNTABILITY OF THE CHAUMIAN

RPC MIX NETS

In this section, we provide formal results for the level of
accountability (and hence, veriﬁability) Chaumian RPC mix
nets provide. As already mentioned in the introduction, this
is the ﬁrst rigorous analysis of accountability/veriﬁability for
Chaumian RPC mix nets in the literature.

We start, in Section IV-A, with a description of some
attacks on the accountability/veriﬁability of Chaumian RPC
mix nets. We then present our formal results, which show
that these mix nets have a reasonable level of accountabil-
ity/veriﬁability. In particular, they show that there are no
worse attacks than those described in Section IV-A.

A. Attacks

The most obvious way in which a mix server can cheat
is when it replaces the result of the decryption of an input
ciphertext by another ciphertext (or another plaintext in the
case that the last mix server cheats in its second mixing
step). If the mix server does not lie about the permutation
it used, then this kind of cheating is (not) detected with
probability 1
2. If the mix server cheats in this way for k + 1
input ciphertexts at the same time (and hence, would violate
γk), its probability of not being caught is ( 1
)k+1. Of course,
2
all dishonest mix servers could cheat in this way.

However, there are more subtle ways of cheating which

result in dishonest mix servers being caught less likely.
Cheating by the last mix server. This attack does not seem
to have been described before in the literature. The attack
can be applied by the last mix server in its second mixing
step. Note that the last mix server outputs the ﬁnal plaintexts.
The idea of the attack is that if after the ﬁrst mixing step
performed by the last mix server for two different positions
p and q (marked gray on the left-hand side of Figure 2)
the ciphertexts C2m−1[p] and C2m−1[q] decrypt to the same
plaintexts (the last mix server knows this), it, instead of
committing to π−1
(q), respectively, commits
2m−1

(p) and π−1
2m−1

to, say, π−1
(p), for both p and q. Then, the plaintext at
2m−1
position q can be replaced by any other plaintext, and hence,
the mix server can replace one plaintext by a plaintext of
it’s choice. This way of cheating is detected only if both
p /∈ Im−1 and q /∈ Im−1, because in this case only it would be
visible that the mix server did not commit to a permutation
in its second sequence of commitments. The probability for
this is 1
4. Hence, the probability that this way of cheating
goes undetected is 3
4. Of course, the last mix server can apply
this attack on different pairs of ciphertexts that decrypt to the
same plaintext in order to replace many plaintexts. Applied
to k + 1 different pairs of ciphertexts results in the violation
of γk and this remains undetected with probability ( 3
)k+1.
4
This problem could be ﬁxed, for example, as follows: i)
require honest senders to add a nonce to their plaintext in
order to avoid clashes between plaintexts, or ii) add another
level of encryption (where for this last layer of encryption
no mixing is performed, only decryption). However, these
ﬁxes do not improve the level of accountability RPC mix
nets provide, as there are other, equally harmful attacks (like
the following one).
Cheating by any mix server. This attack, which seems
to have been sketched already in [11] and is illustrated on
the right-hand side of Figure 2, can be applied to the ﬁrst
mixing step of any mix server. The idea is that a mix server
M j for two positions p and q in its intermediate sequence
C2 j+1 of ciphertexts sets both C2 j+1[p] and C2 j+1[q] to be the
decryption of C(cid:4)
[π2 j(p)] (an honest M j would set C2 j+1[q]
to be the decryption of C(cid:4)
[π2 j(q)]). Moreover, in its ﬁrst
sequence of commitments, both at positions p and q it
commits to the value π2 j(p) (an honest M j would at position
q commit to π2 j(q)).

Now in the duplicate elimination phase, performed by
the next mix server after the second mixing step of M j,
if j < m − 1, one of the two copies of the result of the
decryption of C2 j+1[p] will be removed (on the right-hand
side of Figure 2, one of the gray nodes in the rightmost
column). As a result, one of the input ciphertexts from C(cid:4)
2 j
is dropped (the black node in the example).

2 j

2 j

without an obvious ﬁx.
B. Formal Analysis of Accountability of the Mix Net

We now state and prove the precise level of accountabil-
ity/veriﬁability Chaumian RPC mix nets have. While from

350

Analogously to the previous attack, this attack can be
detected with probability 1
4, because detection requires that
both p and q belong to Ij. As before, one mix server can
apply this attack for multiple pairs of positions and it can also
be performed by many mix servers in order to manipulate
(in this case drop) many input ciphertexts. Performing the
attack on k + 1 different pairs of ciphertexts (by the same
mix server or different mix servers) results in the violation
of γk and this remains undetected with probability

(cid:3)k+1.

(cid:2)

This seems to be an inherent problem for RPC mix nets,

3
4

the above it is clear that λk, i.e., the probability of more than
k manipulations going unnoticed, may be as high as ( 3
)k+1,
4
we prove that the probability is not higher, and hence, there
are no worse attacks.

Recall from Section II-B2 that we assume that

the
scheduler, the judge, the auditor, and the bulletin board are
honest. However, none of the mix servers nor the senders
are assumed to be honest.
Security assumptions. We make the following assumptions
about the cryptographic primitives used. We assume the com-
mitment scheme to be computationally binding and perfectly
hiding, with Pedersen commitments being an example [19].
(However, a scheme that is only computationally binding
and hiding would do as well.) For the public-key encryption
scheme, we assume it to be randomized such that for every
plaintext in the domain of the scheme the probability of
producing two identical ciphertext when encrypting the
plaintext twice under the same public-key is negligible. This
property is satisﬁed, for example, by all IND-CPA secure
schemes. (Later, for privacy, Section VI, we will require an
IND-CCA2 secure public key encryption scheme. But for
accountability IND-CCA2 security is not necessary.) For the
public key encryption scheme we, as usual, also assume that
mix servers can provide proofs of correct decryption. More
speciﬁcally, we require a non-interactive zero-knowledge
(NIZK) proof of correct decryption, i.e., a NIZK proof
that, for input of the form (m,c, pk), proves the statement
∃sk : (pk,sk) ∈ K ∧ Decsk(c) = m, where K denotes the set
of all public/private key pairs the key generation algorithm
of the public key scheme can produce. For this, as already
mentioned in Section II-B, all parties are provided with a
CRS by the scheduler. Note that an honest mix server knows
the secret key sk related to its public key pk, and hence, can
prove the above statement. Also observe that m might be ⊥,
in which case the statement states failure of decryption. To
prove accountability, the zero-knowledge property is actually
not needed (only completeness and soundness). But to prove
privacy, we need the NIZK property as well.

(cid:2)

Now, the following theorem holds for Chaumian RPC
mix nets as modeled in Section II-B for both in-phase and
post-phase auditing.
Theorem 1. Under the above assumptions concerning the
cryptographic primitives, Chaumian RPC mix nets provide
λk-accountability with tolerance k, where λk =
they do not provide λ-accountability for any λ < λk, i.e., λk
is optimal.
This theorem implies that even if all mix servers are dishon-
est, the probability that more than k inputs of honest voters
have been manipulated, but the judge nevertheless does not
blame any mix server, is bounded by
the probability that more than 5 manipulations go undetected
is less than 18% and 10 manipulations go undetected in

(cid:3)k+1. For example,

(cid:3)k+1, and

(cid:2)

3
4

3
4

less than 4.5% of the cases. Moreover, if manipulation is
detected, at least one mix server is blamed (and rightly so)
for its misbehavior. As explained in Section III, Theorem 1
also immediately implies that Chaumian RPC mix nets enjoy
λk-veriﬁability with tolerance k.

In Appendix A, we provide a proof sketch for Theorem 1,
with a detailed proof provided in the full version of this
paper [15].

V. DEFINING PRIVACY OF RPC MIX NETS

In this section, we propose a deﬁnition of privacy that is
suitable for RPC mix nets in that it allows one to measure the
level of privacy a protocol provides. The ability to measure
the level of privacy is important in the context of RPC mix
nets because such protocols do not achieve perfect privacy:
the adversary can learn information from a protocol run and
therefore it is essential to be able to precisely tell how much
he can learn.

Since the main application of RPC mix nets is e-voting,
our deﬁnition of privacy for RPC mix nets resembles the
deﬁnition of privacy for e-voting protocols proposed by
K¨usters et al. in [14]. In their deﬁnition, privacy is formal-
ized as the inability of an observer to distinguish whether
some voter v (called the voter under observation) voted for
candidate j or candidate j(cid:4), when running her honest voting
program (as speciﬁed by the voting protocol). Analogously,
here we formalize privacy of RPC mix nets as the inability
of an adversary to distinguish whether some sender under
observation submitted plaintexts p or p(cid:4), when running her
honest program. While this deﬁnition is quite strong (see,
e.g., the discussion in [2]), simulation-based deﬁnitions [10]
are stronger (see also [3] for a related game-based deﬁnition).
Roughly speaking, simulation-based deﬁnitions imply that
an adversary should not be able to distinguish between two
(different) vectors of honest inputs. However, as explained
at the end of Section II-A, in the case of RPC mix nets an
adversary obtains partial information about how the input
is mapped to the output, and hence, RPC mix nets do not
satisfy such simulation-based deﬁnitions.1 Nevertheless, this
does not necessarily mean that RPC mix nets do not do
a reasonably good job in hiding which speciﬁc message
an individual honest sender sent. This security requirement
corresponds to the central property in the context of e-voting,
already sketched above, and it is what our privacy notion for

1These security notions imply that the success probability of an adversary
trying to distinguish between the two input vectors is bounded by 1
2 up to
a negligible value. It is easy to see that for a ﬁxed number of honest mix
servers (our results on privacy assume even only one honest mix server),
the probability of distinguishing between the two input vectors will exceed
1
2 by a non-negligible value. RPC mix nets might satisfy the deﬁnition
if the number of (honest) mix servers grows in the length of the security
parameter, but this is unrealistic. It might be interesting future work to
see how many (honest) mix servers are needed to decrease the success
probability of the adversary for the stronger notions to a reasonable level.
However, this number might be unrealistically big.

RPC mix nets, which we deﬁne precisely below, is therefore
supposed to capture.2

In the analysis of privacy of RPC mix nets, it turns
out that it is useful to distinguish between risk-avoiding
and venturesome adversaries, i.e., between adversaries that
try to avoid being caught (i.e., blamed by the judge for
misbehavior) and those that do not care. The class of
venturesome adversary is simply the class of all probabilistic
polynomial-time adversaries. In Section V-C, we introduce
and precisely deﬁne the concept of risk-avoiding adversaries.

A. Deﬁnition of Privacy w.r.t. Venturesome Adversaries

As already mentioned in Section II-B, for studying privacy,
we consider the protocol P j
(n,m, μ), where the j-th mix
mix
server is assumed to be honest, all other mix servers may
be dishonest. Among the n senders, we consider one sender
s to be under observation. (The task of the adversary is to
ﬁgure out whether this sender sent plaintext p or p(cid:4).)

Now, given a sender s and a plaintext p, the protocol
(n,m, μ) induces a set of instances of the form ( ˆπs(p) (cid:7)
P j
π∗) where ˆπs(p) is the honest program of the sender s under
mix
observation that takes p as its unencrypted input (as deﬁned
in Section II-B) and π∗ is the composition of programs
of the remaining parties (scheduler, auditor, judge, senders,
mix servers), one program π ∈ Πa for each party a. Recall
that according to the deﬁnition of P j
(n,m, μ), if a is the
mix
scheduler, the auditor, the judge, or the j-th mix server, then
Πa contains only the honest program of that party, as they
are assumed to be honest. All other parties may run arbitrary
(adversarial) probabilistic polynomial-time programs. Since
we do not restrict these programs to avoid accusations by
the judge, this models venturesome adversaries.

Privacy for Chaumian RPC mix nets (w.r.t. venturesome
adversaries) is now deﬁned as follows, where we use the
following notation: Pr[( ˆπs(p) (cid:7) π∗)((cid:4)) (cid:9)→ 1] denotes the
probability that the adversary (i.e., some dishonest agent)
writes the output 1 on some dedicated channel in a run of
ˆπs(p) (cid:7) π∗ with security parameter (cid:4) and some plaintext p.
The probability is over the random coins used by the agents
in ˆπs(p) (cid:7) π∗.
Deﬁnition 3. For P j
(n,m, μ) as before let s be the sender
under observation, l < n − 1, and δ ∈ [0,1]. We say that
mix
P j
mix

(n,m, μ) with l honest senders achieves δ-privacy, if
Pr[( ˆπs(p) (cid:7) π∗)((cid:4)) (cid:9)→ 1]− Pr[( ˆπs(p

(cid:4)) (cid:7) π∗)((cid:4)) (cid:9)→ 1]

(1)

is δ-bounded as a function of the security parameter (cid:4), for
all valid input plaintexts p, p(cid:4) and all programs π∗ of the
remaining parties such that (at least) l senders are honest in
π∗.
2Alternatively to the deﬁnition of privacy used here, one could think of
a deﬁnition where the adversary is asked to directly link a speciﬁc output
to the input. However, such a link might not always be well-deﬁned and
such a deﬁnition seems to require a speciﬁc mix net structure.

351

Since δ typically depends on the number l of honest senders,
privacy is formulated w.r.t. this number. Note that a smaller
δ means a higher level of privacy. However, δ cannot be 0,
not even in an ideal protocol, as detailed in the following
subsection: there is, for example, a non-negligible chance
that all honest senders sent the same message. In this case,
the adversary knows the message sender s has sent, and
hence, can easily distinguish between s having sent p or p(cid:4).
B. Privacy for the Ideal Mix Net Protocol

Before we introduce the notion of privacy w.r.t. risk-
avoiding adversaries, we ﬁrst study the level of privacy
(w.r.t. venturesome adversaries) for the ideal mix net. More
speciﬁcally, we determine the optimal δid
l,μ in this case. This
is useful because i) this value constitutes a lower bound for
all kinds of mix net protocols and ii) the level of privacy
for Chaumian RPC mix nets can be expressed in terms of
this value.

the senders submit

In the ideal mix net,

their input
plaintexts on a direct channel to the ideal mix net. The ideal
mix net then outputs the submitted messages after having
applied a random permutation. Honest senders choose their
inputs according to the distribution μ.

The level of privacy provided by the ideal mix net, as well
as the justiﬁcation of the result, coincides with the level of
privacy provided by the ideal voting protocol, as studied
by K¨usters et al. in [14]. It depends on the number l of
honest senders and the probability distribution μ on valid
input plaintexts.
To deﬁne δid
l,μ, we need the following terminology. Let
{p1, . . . , pk} be the set of valid plaintexts. Since the adver-
sary knows the input plaintexts of the dishonest senders, he
can simply ﬁlter out these plaintexts from the ﬁnal output
and obtain what we call the pure output (cid:8)r = (r1, . . . ,rk) of
the protocol, where ri, i ∈ {1, . . . ,k}, is the number of times
the plaintext pi occurs in the output after having ﬁltered out
the dishonest inputs. Note that, if l is the number of honest
senders, then r1 +··· + rk = l + 1 (l honest senders plus the
sender under observation).
We denote by Out the set of all pure outputs. Let Ai
(cid:8)r
denote the probability that the choices made by the honest
senders yield the pure output (cid:8)r, given that the sender under
≤
observation submits pi. Further, let Mj, j(cid:4) = {(cid:8)r ∈ Out : A j
A j(cid:4)
l,μ is as
(cid:8)r
follows: If the observer, given a pure output (cid:8)r, wants to
decide whether the observed sender submitted p j or p j(cid:4), the
best strategy of the observer is to opt for p j(cid:4) if (cid:8)r ∈ Mj, j(cid:4), i.e.,
the pure output is more likely if the sender submitted p j(cid:4).
This leads to the following level of privacy provided by
the ideal mix net protocol with l honest senders and the
probability distribution μ:

}. Now, the intuition behind the deﬁnition of δid

(cid:8)r

δid
l,μ = max

j, j(cid:4)∈{1,...,k} ∑
(cid:8)r∈Mj, j(cid:4)

(A j(cid:4)

(cid:8)r

− A j

(cid:8)r

),

352

with example values depicted in Figure 3. (Note that A j(cid:4)
A j
(cid:8)r depend on l and μ.)
The proof of this statement is a straightforward adaption

(cid:8)r

-

of the proof for the ideal voting protocol [14].
C. Deﬁnition of Privacy w.r.t. Risk-Avoiding Adversaries

Now,

To deﬁne the notion of privacy w.r.t. risk-avoiding adver-
(n,m, μ), ˆπs(p), and π∗ be deﬁned as before.
saries, let P j
Moreover, let α ∈ [0,1].
mix
We say that π∗ is α-risk-avoiding, if the probability that
the system ( ˆπs(p) (cid:7) π∗)((cid:4)) produces a run where the judge
states a verdict dis(a) for some dishonest agent a is α-
bounded as a function in the security parameter (cid:4), for all
valid input plaintexts p. We say that π∗ is completely risk-
avoiding if it is 0-risk-avoiding. Note that it is venturesome
if it is 1-risk-avoiding.
in the deﬁnition of privacy w.r.t. risk-avoiding
adversaries, we simply restrict the set of programs π∗ to
those that are α-risk-avoiding.
Deﬁnition 4. For P j
(n,m, μ) let s be the sender under
observation, α ∈ [0,1], l < n − 1, and δ ∈ [0,1]. We say
mix
that P j
(n,m, μ) with l honest senders achieves δ-privacy
mix
w.r.t. α-risk-avoiding adversaries, if
Pr[( ˆπs(p) (cid:7) π∗)((cid:4)) (cid:9)→ 1]− Pr[( ˆπs(p

(2)
is δ-bounded as a function of the security parameter (cid:4), for all
valid input plaintexts p, p(cid:4) and all α-risk-avoiding programs
π∗ of the remaining parties such that (at least) l senders are
honest in π∗.

(cid:4)) (cid:7) π∗)((cid:4)) (cid:9)→ 1]

VI. ANALYSIS OF PRIVACY OF CHAUMIAN

RPC MIX NETS

We now state and prove the precise level of privacy
Chaumian RPC mix nets have. We consider different cases,
depending on whether in-/post-phase auditing is done and
depending on the values α for α-risk-avoiding adversaries,
ranging from completely risk-avoiding adversaries (α = 0) to
venturesome adversaries (α = 1). As we will see, altogether
the level of privacy is quite satisfying, only in the case
of post-phase auditing and venturesome adversaries privacy
is completely broken. The case of venturesome adversaries
appears to be quite unlikely in practice, e.g., in the context
of e-voting, where malicious behavior might be punished
severely. (Recall from Section IV that the probability of
being caught cheating is high.) In all other cases, the level
of privacy is quite close to the ideal case (δid
l,μ) given
sufﬁciently many senders. Surprisingly, this is even so for
venturesome adversaries in the case of in-phase voting. For
α-risk-avoiding adversaries, the level of privacy both in the
case of in-phase and post-phase auditing is high even for
quite big values of α (e.g., 75%), i.e., adversaries that are
willing to take substantial risks.

We note that in our analysis of privacy, we always make
the worst case assumption, namely that only one of the mix

servers is honest; clearly, if all mix servers are dishonest
there cannot be any privacy.

In what follows, we ﬁrst shortly discuss the reasons why
Chaumian RPC mix nets are not perfect, i.e., why they do
not offer exactly the same level of privacy as the ideal mix
net. We then state the cryptographic assumptions we use in
the privacy proof, followed by the analysis of privacy for all
the cases mentioned above.

A. Problems with Privacy

As already illustrated in Section II-A, it is in the very
nature of the RPC mix nets that some information about the
input to a mix server is mapped to its output. Consequently,
the adversary obtains some partial information about how
the input of the honest mix server is mapped to its output.
Hence, privacy cannot be as in the ideal case. Note that
for the other (dishonest) mix servers, the adversary has full
knowledge about the mapping from the input to the output.
The second reason why the level of privacy for Chaumian
RPC mix nets is worse than in the ideal case is that the level
of veriﬁability/accountability is imperfect as well. To attack
privacy, an adversary can use his ability to change unnotice-
ably (with some probability) the input to the honest server.
As we know from our analysis of veriﬁability/accountability,
an adversary who is willing to accept being caught with
probability 1 − ( 3
)k could, for example, drop k entries
originally sent by honest senders before they are processed
by the honest mix server. In the extreme case, where k is
the total number of honest senders (excluding the observed
sender), all honest entries are dropped before the honest mix
server is invoked and the adversary, knowing the plaintexts
in the dishonest entries, can easily determine the input of
the sender under observation. Note, however, that in the case
of in-phase auditing this works only if the misbehavior of
the adversary is not detected before the honest server gets
to decrypt its input.

4

In fact, a particularly interesting case from an analysis
point of view is when we consider in-phase auditing and
not completely risk-avoiding adversaries, with venturesome
adversaries being the most extreme case. In this case, an
adversary is confronted with a trade-off between the risk he
takes (of being caught and of the protocol being aborted)
and the additional information he obtains by manipulation.
Our formal analysis provides the optimal strategy for the
adversary to resolve this trade-off.

B. Cryptographic Assumptions

We make the same assumptions about the cryptographic
primitives used in the protocol as in the case of account-
ability, plus the assumption that the encryption scheme is
IND-CCA2 secure and that the proof of correct decryption
is zero-knowledge.

C. Privacy for Completely Risk-Avoiding Adversaries

As a preparation for the analysis of privacy in the general
case (for α-risk-avoiding adversaries with any value of
α), we begin with the case of completely risk-avoiding
adversaries (α = 0). The results presented here hold true
both for the case of in-phase and post-phase auditing.

By the results of Section IV, we know that whenever dis-
honest mix servers change some entry, this can be detected
with non-negligible probability. Therefore, a completely risk-
avoiding adversary will not change or drop any entry of
an honest sender. Consequently, risk-avoiding adversaries
can only attack privacy passively, that is, without changing
the input to the honest server in any signiﬁcant way. More
speciﬁcally, we obtain the following result.
Theorem 2. The protocol P j
(n,m, μ) with l honest senders
mix
achieves δl,μ-privacy w.r.t. completely risk-avoiding adver-
saries, where

(cid:4)

(cid:5)

δid
i,μ .

δl,μ = 1
2l

·

l∑

i=0

l
i

Moreover, δl,μ is optimal, i.e., this protocol does not achieve
δ-privacy w.r.t. completely risk-avoiding adversaries for any
δ < δl,μ.

Example values for δl,μ are depicted in Figure 3. As can
be seen, for completely risk-avoiding adversaries, the level
of privacy provided by the Chaumian mix net is only slightly
worse than the level of privacy in the ideal mix net protocol.
Recall that our result holds under the pessimistic assumption
that there is only one honest mix server.

Proof (sketch): We ﬁrst introduce some notation and
terminology. To simplify this notation, let us assume that
the sender under observation has index 0 and the honest
senders have indices from 1 to l. Let M j denote the honest
mix server.

)
δ
(

l
e
v
e
l

y
c
a
v
i
r
p

1

0.8

0.6

0.4

0.2

0

1

2 valid input plaintexts, ideal
2 valid input plaintexts, δl,μ (Th.2)
3 valid input plaintexts, ideal
3 valid input plaintexts, δl,μ (Th.2)
5 valid input plaintexts, ideal
5 valid input plaintexts, δl,μ (Th.2)

5
number of honest voters (without the observed voter)

100

10

20

50

200

500

Figure 3. Level of privacy (δl,μ) w.r.t. completely risk-avoiding adversaries
and in the ideal case δid
l,μ, uniform distribution of input plaintexts. These
ﬁgures have been obtained by straightforward calculations using the δ-
formulas as provided in the theorems.

353

, . . . αl

, . . . αl

the entry α0

Because we consider completely risk-avoiding adversaries,
we know that no entry is dropped or changed by the mix
server. In particular,
2 j of the sender under
observation occurs, as expected, in the input sequence C2 j
of the honest mix server M j (at some position). Similarly,
the entries α1
2 j of the honest senders occur in C2 j.
2 j
In a run of the mix net, these entries are divided by the
audit procedure into two groups GL and GR. The group GL
contains those entries amongst α0
2 j for which the left
2 j
link is opened during the audit procedure for M j, i.e., the
links from the entries in C(cid:4)
2 j to the corresponding entries in
C2 j+1 are revealed. The group GR contains those entries for
which the right links are opened. Considering, for example,
Figure 1, entries x1 and x2 belong to GL, whereas entries x3
and x4 belong to GR. We call GR and GL audit groups.

Now, the rationale behind the deﬁnition of δl,μ is the
i represents the number of entries of honest
following:
senders that are, in a given run of the system, in the same
audit group as the entry of the sender under observation.
We consider all the possible cases, from i = 0 (the entry of
the sender under observation is alone in its audit group,
and hence,
the adversary can easily see her choice) to
i = l (all the honest entries are in the same group as the
entry of the sender under observation; in this case, privacy
of the sender under observation is maximally protected).
The probability that i honest senders belong to the same
1
2l , as
audit group as the sender under observation is
it is decided independently for every honest entry if it
belongs to the audit group of the sender under observation
or not. Moreover, under the condition that the sender under
observation is in an audit group with i honest senders, the
situation corresponds to that of the ideal mix net with i
honest senders. Hence, in this case, the level of privacy is
δid
i,μ. Of course, the latter requires to use the hiding property
of the commitment scheme, the assumption that the proofs of
correct decryption are zero-knowledge, and a IND-CCA2-
security of the public-key encryption scheme, in order to
show that the adversary gains negligible advantage only by
trying to break the cryptographic primitives (see Appendix B
for some more details, and [15] for the full proof).
D. Privacy in the General Case

We now consider α-risk-avoiding adversaries, for all α ∈
[0,1], which includes, in particular, venturesome adversaries
(for α = 1), where it makes a big difference whether in-phase
or post-phase auditing is performed.
Post-phase auditing. We ﬁrst study the case of post-phase
auditing, for which, as argued next, no privacy can be
guaranteed whatsoever for venturesome adversaries, unless
the honest server happens to be the ﬁrst one (if this is the
case, all the honest entries are in its input and privacy is as
in the case of completely risk-avoiding adversaries). If the
ﬁrst mix server is not honest, an αk-risk-avoiding adversary,

(cid:3)k, can, according to his most effective

with αk = 1 −(cid:2)

3
4

(cid:2)

(cid:3)

l
i

2

strategy as discussed in Section IV, drop k honest entries
and, therefore, deliver only l(cid:4) = l − k honest entries to the
honest mix server, assuming that there is a sufﬁcient number
of dishonest mix servers preceding the honest mix server.
At this point, the situation is as in the case of completely
risk-avoiding adversary with l(cid:4) honest senders which yields
the advantage δl(cid:4),μ (and this is the best an αk-risk-avoiding
adversary can achieve). Note that one dishonest mix server
can drop (cid:14) l
(cid:15) out of l honest entries. Hence, it is easy to
calculate how many dishonest mix servers are needed to
drop k honest entries.
Formally, we obtain the following result.
Theorem 3. For all α ∈ [0,1], the protocol P1
mix(n,m, μ) with
post-phase audit and with l honest senders achieves δl,μ-
privacy w.r.t. α-risk-avoiding adversaries, where δl,μ is as
in Theorem 2.

For j > 1, the protocol P j
(n,m, μ) with post-phase audit
mix
1−(cid:2)
and with l honest senders achieves δl(cid:4),μ-privacy w.r.t. αk-
risk-avoiding adversaries, where l(cid:4) = max(0,l−k) and αk =

(cid:3)k. The protocol does not achieve δ-privacy w.r.t. αk-

risk-avoiding adversaries for any δ < δl(cid:4),μ, assuming that
the number of mix servers preceding the honest mix server
is sufﬁciently big, as discussed above.

3
4

Notice that, as a corollary of the above theorem we obtain
that RPC mix nets do not achieve δ-privacy w.r.t. venture-
some adversaries for any δ < 1 (again assuming a sufﬁcient
number of mix servers preceding the honest mix server),
which means that for venturesome adversaries privacy is
completely broken. Indeed, a venturesome adversary can
remove all the entries of the honest senders, except for the
observed sender, before the honest mix server gets to mix
its input. This will be detected with very high probability,
but only after the protocol has been ﬁnished and after the
adversary has obtained the information he wants. As a result
of this way of cheating, the only honest entry left is the
one of the sender under observation. So, for venturesome
adversaries, privacy is completely broken in this case. This
case is quite obvious and has already been pointed out
in the original proposal for RPC mix nets [9]. In [11], it
was proposed to mitigate this problem by introducing an
additional inner-most encryption with distributed decryption,
where the private keys are distributed among the mix servers.
By this, if one of the mix servers is honest, one can guarantee
that the plaintexts are only output if no mix server was
caught cheating. (This basically leads to the case of in-phase
auditing discussed below.)

The more relevant case from a practical point of view,
compared to the case of venturesome adversaries (α = 1),
seems to be the case of α-risk-avoiding adversaries, for
relatively small α (due to, as mentioned, possible penalties
for cheating). In this case, Theorem 3 means that adversaries
who are willing to accept only limited risk of being caught
gain only very little in terms of breaking privacy. For ex-

354

ample, considering the case with three valid input plaintexts
(e.g., in an election with three candidates), an adversary who
is willing to accept a risk of about 75% of being caught
(which is already very high), can drop only 5 honest entries.
For 50 honest senders, by this he gains only 0.01 in his
ability to break privacy (that is, the probability of guessing
correctly the choice the observed sender made increases only
very slightly). If the number of honest senders is 200, then
the adversary gains only 0.001, which is insigniﬁcant for all
practical purposes. Therefore, while by cheating an adversary
can obtain some advantage, for an adversary who is willing
to take only limited (but still high) risk, this advantage
is insigniﬁcant. Hence, in this realistic case the mitigation
mentioned above, which would make RPC mix nets more
complex, might not even be necessary.
In-phase auditing. Now we consider RPC mix nets with in-
phase auditing. This is the most interesting case from the
technical perspective, as the adversary, whenever he is to
remove/change an entry, needs to balance out the risk of
being caught, and hence, not learning anything useful, and
the advantage that cheating provides for breaking privacy.
Theorem 4. The protocol P j
ing and with l honest senders achieves δ∗
mix
(cid:5)l−l(cid:4)
αk-risk-avoiding adversaries, where
(cid:3)k.

(cid:6)(cid:4)
with k(cid:4) = min(k,l) and αk = 1−(cid:2)

(n,m, μ) with in-phase audit-
l,k,μ-privacy w.r.t.

δ∗
l,k,μ = max

l(cid:4)∈{l−k(cid:4),...,l}

· δl(cid:4),μ

(cid:7)

(cid:2)

(cid:3)l−l(cid:4)

The protocol does not achieve δ-privacy w.r.t. αk-risk-
avoiding adversaries for any δ < δ∗
l,k,μ, assuming the number
of mix servers preceding the honest mix server is sufﬁciently
big, as discussed above Theorem 3.
The intuition behind the constant δ∗

l,μ is the following. We
consider those strategies of the adversary (indexed with l(cid:4)),
where he always drops the same number of honest entries,
letting l(cid:4) entries reach the honest server. If cheating is not
(l − l(cid:4) is
detected, which happens with probability
the number of dropped entries), then the advantage of the
adversary is δl(cid:4),μ. This is because this case strictly corre-
sponds to the case with l(cid:4) honest senders from Theorem 2.
Otherwise, if the adversary is caught, he does not learn
anything from the protocol run. We consider all possible l(cid:4) as
above, for which the risk of being caught does not exceed αk
(hence, the range l−k(cid:4), . . . ,l), and pick the one for which the
advantage of the adversary is biggest. Clearly, in the proof,
we demonstrate that the family of strategies considered above
contains an optimal strategy which maximizes the advantage
of the adversary (see Appendix C for some more details and
[15] for the full proof of Theorem 4).

3
4

.

(3)

3
4

3
4

Note that the above theorem covers the case of venture-

some adversaries.

355

We have computed the constants δ∗

l,k,μ for those parame-
ters we also considered for δl,μ (Figure 3). For all those pa-
rameters, it has turned out that δ∗
l,k,μ = δl,μ (for all k). That is,
the optimal strategy of the adversary is to not remove/change
any of the honest entries (and, therefore, it coincides with
the optimal strategy of a completely risk-avoiding adversary).
In particular, even if we consider a venturesome adversary,
the risk of being caught, when manipulating honest entries,
and in consequence not learning anything always outweighs
the advantage these manipulations bring for breaking privacy.
Indeed, as we can see in Figure 3, the advantage in breaking
privacy increases only very little, when we decrease the
number of honest entries by, say 1, while the probability
that the adversary gets caught (and learns nothing) when
he drops even only one entry is quite substantial (25%).
So, it appears that in the case of in-phase auditing it never
makes sense for the adversary to cheat in its attempt to break
privacy.

VII. CONCLUSION

In this paper, we provided the ﬁrst formal security analysis
of Chaumian RPC mix nets. These mix nets are appealing
not only due to their simplicity and efﬁciency, but also
because they can be used with any IND-CCA2-secure public
key encryption scheme (that allows for efﬁcient proofs of
correct decryption) and can handle arbitrarily long input
messages.

We proved that these mix nets enjoy a high level of ac-
countability/veriﬁability. The probability for a mix server of
being caught cheating if it tries to manipulate k messages of
honest senders is 1− ( 3
)k. Hence, already the manipulation
of just one (two) message(s) is detected with probability
0.25 (0.43). In the context of e-voting, where cheating mix
servers might face severe penalties, this might be a strong
incentive to behave honestly.

4

The level of privacy is surprisingly good, namely close
to the ideal case (δid
l,μ), already in a settings with a few
hundred senders. The only exception is the case of post-
phase auditing and venturesome adversaries which take into
account to be caught cheating for sure (i.e., α-risk-avoiding
adversaries with α = 1), in which case there is no privacy.
Otherwise, for less bold adversaries who nevertheless are
willing to take big risks of being caught (e.g., α = 0.75),
the level of privacy is close to ideal, both for in-phase
and post-phase auditing. Interestingly, in-phase auditing is
only slightly better than post-phase auditing in this case.
Altogether, since in the context of e-voting it
is rather
unlikely that an adversary is very venturesome, the level of
privacy provided to single senders/voters is quite satisfying.
In summary, our results show that Chaumian RPC mix
nets provide a reasonable level of privacy and veriﬁability,
and that they are still an interesting option for the use in
e-voting systems.

ACKNOWLEDGMENT

This work was partially supported by Deutsche
Forschungsgemeinschaft (DFG) under Grant KU 1434/6-
2 within the priority programme 1496 “Reliably Secure
Software Systems – RS3”.

REFERENCES

[1] M. Bellare, A. Desai, D. Pointcheval, and P. Rogaway. Rela-
tions Among Notions of Security for Public-Key Encryption
Schemes. In H. Krawczyk, editor, Advances in Cryptology,
18th Annual International Cryptology Conference (CRYPTO
1998), volume 1462 of Lecture Notes in Computer Science,
pages 549–570. Springer, 1998.

[2] David Bernhard, V´eronique Cortier, Olivier Pereira, and
Bogdan Warinschi. Measuring vote privacy, revisited.
In
Ting Yu, George Danezis, and Virgil D. Gligor, editors, ACM
Conference on Computer and Communications Security (CCS
2012), pages 941–952. ACM, 2012.

[3] David Bernhard, Olivier Pereira, and Bogdan Warinschi. How
not to prove yourself: Pitfalls of the ﬁat-shamir heuristic and
applications to helios.
In Xiaoyun Wang and Kazue Sako,
editors, Advances in Cryptology - ASIACRYPT 2012 - 18th
International Conference on the Theory and Application of
Cryptology and Information Security, Proceedings, volume
7658 of Lecture Notes in Computer Science, pages 626–643.
Springer, 2012.

[4] R. Carback, D. Chaum, J. Clark, adn J. Conway, E. Essex,
P.S. Herrnson, T. Mayberry, S. Popoveniuc, R. L. Rivest,
E. Shen, A. T. Sherman, and P.L. Vora.
Scantegrity II
Municipal Election at Takoma Park: The First E2E Binding
governmental Elecion with Ballot Privacy.
In USENIX Se-
curity Symposium/ACCURATE Electronic Voting Technology
(USENIX 2010). USENIX Association, 2010.

[5] David Chaum. Untraceable Electronic Mail, Return Ad-
dresses, and Digital Pseudonyms. Commun. ACM, 24(2):84–
88, 1981.

[6] M. R. Clarkson, S. Chong, and A. C. Myers. Civitas: Toward a
Secure Voting System. In 2008 IEEE Symposium on Security
and Privacy (S&P 2008), pages 354–368. IEEE Computer
Society, 2008.

[7] Philippe Golle, Sheng Zhong, Dan Boneh, Markus Jakobsson,
and Ari Juels. Optimistic Mixing for Exit-Polls. In Yuliang
Zheng, editor, Advances in Cryptology - ASIACRYPT 2002,
8th International Conference on the Theory and Application
of Cryptology and Information Security, Proceedings, volume
2501 of Lecture Notes in Computer Science, pages 451–465.
Springer, 2002.

[8] Marcin Gomulkiewicz, Marek Klonowski, and Miroslaw
Kutylowski. Rapid mixing and security of chaum’s visual
electronic voting. In Einar Snekkenes and Dieter Gollmann,
editors, Computer Security - ESORICS 2003, 8th European
Symposium on Research in Computer Security, Proceedings,
volume 2808 of Lecture Notes in Computer Science, pages
132–145. Springer, 2003.

[9] M. Jakobsson, A. Juels, and R. L. Rivest. Making Mix Nets
Robust for Electronic Voting by Randomized Partial Checking.
In USENIX Security Symposium, pages 339–353, 2002.

[10] Shahram Khazaei, Tal Moran, and Douglas Wikstr¨om. A
Mix-Net from Any CCA2 Secure Cryptosystem. In Xiaoyun
Wang and Kazue Sako, editors, Advances in Cryptology -
ASIACRYPT 2012 - 18th International Conference on the
Theory and Application of Cryptology and Information Secu-
rity, Proceedings, volume 7658 of Lecture Notes in Computer
Science, pages 607–625. Springer, 2012.

[11] Shahram Khazaei and Douglas Wikstr¨om. Randomized
Partial Checking Revisited.
In Ed Dawson, editor, Topics
in Cryptology - CT-RSA 2013 - The Cryptographers’ Track
at the RSA Conference 2013. Proceedings, volume 7779 of
Lecture Notes in Computer Science, pages 115–128. Springer,
2013.

[12] Ralf K¨usters. Simulation-Based Security with Inexhaustible
Interactive Turing Machines. In Proceedings of the 19th IEEE
Computer Security Foundations Workshop (CSFW-19 2006),
pages 309–320. IEEE Computer Society, 2006. See [16] for
a full and revised version.

[13] Ralf K¨usters, Tomasz Truderung, and Andreas Vogt. Ac-
countability: Deﬁnition and Relationship to Veriﬁability. In
Proceedings of the 17th ACM Conference on Computer and
Communications Security (CCS 2010), pages 526–535. ACM,
2010.

[14] Ralf K¨usters, Tomasz Truderung, and Andreas Vogt. Veriﬁa-
bility, Privacy, and Coercion-Resistance: New Insights from
a Case Study. In IEEE Symposium on Security and Privacy
(S&P 2011), pages 538–553. IEEE Computer Society, 2011.

[15] Ralf K¨usters, Tomasz Truderung, and Andreas Vogt. For-
mal Analysis of Chaumian Mix Nets with Random-
ized Partial Checking.
Technical report, University of
Trier. Available at http://infsec.uni-trier.de/publications/paper/
KuestersTruderungVogt-TR-RPCChaumian-2014.pdf, 2014.

[16] Ralf K¨usters and Max Tuengerthal. The IITM Model: a
Simple and Expressive Model for Universal Composability.
Technical Report 2013/025, Cryptology ePrint Archive, 2013.
Available at http://eprint.iacr.org/2013/025.

[17] C. Andrew Neff. A veriﬁable secret shufﬂe and its application
to e-voting. In Michael K. Reiter and Pierangela Samarati,
editors, 8th ACM Conference on Computer and Communica-
tions Security (CCS 2001), pages 116–125. ACM, 2001.

[18] Choonsik Park, Kazutomo Itoh, and Kaoru Kurosawa. Efﬁ-
cient Anonymous Channel and All/Nothing Election Scheme.
In Tor Helleseth, editor, Advances in Cryptology - EURO-
CRYPT ’93, Workshop on the Theory and Application of
of Cryptographic Techniques, Proceedings, volume 765 of
Lecture Notes in Computer Science, pages 248–259. Springer,
1993.

[19] Torben P. Pedersen. Non-interactive and information-theoretic
secure veriﬁable secret sharing. In Proceedings of the 11th
Annual International Cryptology Conference (CRYPTO 1991),
volume 576 of Lecture Notes in Computer Science, pages 129–
140. Springer, 1991.

356

[20] Peter Y. A. Ryan, David Bismark, James Heather, Steve
Schneider, and Zhe Xia. The Prˆet `a Voter Veriﬁable Election
System. Technical report, University of Luxem- bourg, Univer-
sity of Surrey, 2010. http://www.pretavoter.com/publications/
PretaVoter2010.pdf.

[21] K. Sako and J. Kilian. Receipt-Free Mix-Type Voting Scheme
— A practical solution to the implementation of a voting
booth.
In Advances in Cryptology — EUROCRYPT ’95,
International Conference on the Theory and Application of
Cryptographic Techniques, volume 921 of Lecture Notes in
Computer Science, pages 393–403. Springer-Verlag, 1995.

[22] Douglas Wikstr¨om. Five Practical Attacks for ”Optimistic
Mixing for Exit-Polls”.
In Mitsuru Matsui and Robert J.
Zuccherato, editors, Selected Areas in Cryptography, 10th
Annual International Workshop, SAC 2003, Revised Papers,
volume 3006 of Lecture Notes in Computer Science, pages
160–175. Springer, 2003.

[23] Douglas Wikstr¨om. A Universally Composable Mix-Net. In
Moni Naor, editor, Theory of Cryptography, First Theory of
Cryptography Conference, TCC 2004, Proceedings, volume
2951 of Lecture Notes in Computer Science, pages 317–335.
Springer, 2004.

A. Proof Sketch of Theorem 1

APPENDIX

Here we provide a high-level intuition about the proof of

Theorem 1.

Proving fairness (the ﬁrst condition of the deﬁnition of
accountability), is easy, so the rest of this section is devoted
to the completeness property.

The basic idea is to show that the strategy of the adversary
that drops exactly k + 1 honest entries as described in
Section IV (cheating by any mix server) is optimal for
breaking the goal γk. The probability that using this strategy
the adversary successfully removes k + 1 honest entries is
λk. Note that, using this strategy, one mix server can drop
not more than half of its input entries. Therefore, if k is big,
the adversary may need to use more than one mix server.
We may simply assume that there are enough mix servers
for the adversary to carry out this strategy.

Let us now consider how a dishonest mix server M j may
behave in the general case. First, we can notice that, if a
mix server does not post messages in the expected format, it
is trivially detected. This includes the duplicate elimination
step, where every departure from the prescribed protocol is
easily detectable.
First mixing. We now focus on the ﬁrst mixing step per-
formed by a mix server M j. Let comn1, . . .comml be values
posted by M j as commitments to π2 j.

We say that an index i is unsafe, if either the mix server is
not able to open commi to a proper index (that is an integer
in the range {1, . . . ,l}) or, if it is able to open it to a proper
index i(cid:4), then it is not able to demonstrate that C2 j+1[i] is a
[i(cid:4)]. Otherwise an index is said to be safe.
decryption of C(cid:4)

2 j

C2 j+1 C2 j+2

w

v

u

x

(a)

(b)

Figure 4. An example of a collision groups (nodes in rectangles) in the
ﬁrst and the second mixing.

Now, one can show that the strategy that the adversary
uses is not optimal if there is some unsafe index. Indeed,
one unsafe index allows the adversary to change exactly
one entry, with the probability of detection 1
2 (instead of 1
4,
when the optimal strategy is used). Therefore, we can only
consider strategies that never produce unsafe indices.
We say that a (safe) index i points to i(cid:4), if i(cid:4) is the (only)
value that the mix server is able to open commi to (we know
that the adversary is able to open commi only to one value,
because otherwise we could break the binding property of the
commitments). A set Y of (safe) indices is called a collision
group if |Y| > 1 and all indices in Y point to the same index
i(cid:4). A collision group of size 3 is illustrated in Figure 4, (a),
where all the gray elements in the middle column point to
the same element in the left column.

Because of the assumption that the used ZK proofs are
sound, one can show that if the adversary does not produce
unsafe indices or collision groups, he cannot change the
outcome of the mix net even by one entry. Therefore, to
show that the deﬁned above strategy is indeed optimal (not
worse than others), as far as the ﬁrst mixing step of any
dishonest mix server is considered, we need to show that
using collisions groups of size bigger than two is suboptimal
(collision groups of size two are used in the optimal strategy).
Indeed, this can be shown by elementary calculations.
Second mixing of Mj, for j < 2m. Now let us analyze the
second mixing step excluding the last mix server. We deﬁne
the notion of safe and unsafe indices and the one of collision
groups as in the case of the ﬁrst mixing. Analogously to the
above case, it is easy to show that using unsafe indices is
not optimal.

To conclude the proof in this case, one can show that it
is completely useless for a corrupted mix server to produce
output with collision groups, because it does not cause any
honest entries to be changed/dropped. To see this, let us
consider a collision group of size k (see Figure 4, (b) for
an example). By correctness of the ZK proofs, x is the
decryption of all the ciphertexts in the collision group. If one
of the ciphertexts in this group (say w) is an honest entry
(that is w = αi
2 j+1), then, because we consider safe indices
and because of the soundness of the decryption proofs, x

357

2 j+1) to obtain αi

2 j+2) to obtain αi

In the proof of this lemma, we use an idealized variant
of the protocol, where honest senders use ideal encryption
in one of the two steps corresponding to the honest mix
server: an honest sender either encrypts a string of zeros
(instead of αi
2 j+1 or she encrypts a string of
zeros (instead of αi
2 j. We show, by reducing
this problem to IND-CCA2 security of the used encryption
scheme, that such a system (under the assumption that the
audit does not asks for revealing the ideal encryption steps),
is indistinguishable from the original system. Here we also
use the hiding property of the commitment scheme and the
assumption that the produced proofs of correct decryption
are zero-knowledge. Therefore, in the proof of Lemma 1, we
can replace the original system with the idealized one, where
the view of the adversary is completely independent of the
choices made by honest senders, as long as they produce
the same ﬁnal multiset of plaintexts.

Now, the proof of Theorem 2 proceeds as follows. Since
we consider a completely risk-avoiding adversary A, we
know that all the entries of the honest senders and of the
sender under observation make it to M j. By Lemma 1, we
can consider A∗ instead of A (which is safe to do, as it
can only make the advantage of the adversary bigger). It is
easy to see that the computations carried out by A∗ yield
the constant from the theorem, as explained in Section VI-C.
By this we can conclude that no completely risk-avoiding
adversary can achieve higher advantage.

C. Proof Sketch of Theorem 4
By Lemma 1, we can only consider adversaries A such
that A = A∗. We show that, without loss of generality (with-
out worsening the advantage of the adversary in breaking
privacy), we can consider only programs A that always try
to drop the same number of entries (and deliver the same
number l(cid:4) of honest entries). We show this using, again,
idealized protocol, as described in the proof of Lemma 1,
and proving that, given some state of the protocol execution,
the optimal choice of the adversary depends only on how
many honest entries have been dropped so far.
Let us consider a strategy that always tries to drop the
same number l − l(cid:4) of honest entries. As explained in the
paragraph after Theorem 4, the advantage of the adversary
using such a strategy is

(cid:3)l−l(cid:4) · δl(cid:4),μ.

Recall now that the adversary is assumed to be αk-risk
avoiding. By the above, the best strategy of the adversary
is to uniformly try to deliver l(cid:4) honest entries, where l(cid:4) is
picked in such a way that the risk of being caught does not
exceed αk (which is when l(cid:4) ∈ {l − k(cid:4), . . . ,l}) and otherwise
l(cid:4) maximizes the advantage of the adversary. This yields (3).

(cid:2)

3
4

must have been produced by the same (honest) sender, that is
x = αi
2 j+2. The same reasoning would apply to another entry
(say v), if it were honest. Therefore, due to our assumption
that the probability for collisions of ciphertexts is negligible,
it cannot be the case that v is an honest entry. Therefore,
a collision group can contain at most one honest entry and
this entry is not dropped.
Second mixing of the last mix server. As noted before, it is
possible to change one honest entry by cheating at this step
with the same probability of being detected ( 1
4) as in the
case of the optimal strategy (cheating by any mix server).
The last mix server can cheat both at its ﬁrst and second
mixing step at the same time. One can easily show, however,
that this combination does not make the risk of being caught
smaller.
Remark 1. As already noted in Section II-B, the probability
distribution μ does not play any role in the proof of
Theorem 1. Indeed, we could allow the adversary to provide
unencrypted input for the honest senders and the result would
still work.

B. Proof Sketch of Theorem 2

First we prove a result that is used both in the proof of this
theorem and Theorem 4. Let p and p(cid:4) be valid plaintexts and
A be an arbitrary (not necessarily risk-avoiding) program of
the adversary that, intuitively, tries to distinguish whether
the sender under observation has chosen p or p(cid:4). From the
program A, we derive a program A∗ in the following way.
A∗ simulates A up to the point where the honest mix server
M j produces its output. At this point, we consider two cases:
(1) If the entry α0
2 j of the sender under observation is not
in the input of M j, A∗ ﬂips a coin to determine its decision.
(2) Otherwise, A∗ decrypts the output of M j (recall that the
adversary subsumes all the mix servers but M j). In particular
A∗ obtains the multiset Q of all plaintexts that have been
chosen by the honest senders from the audit group to which
the sender under observation belongs, including the sender
under observation. Now, A∗ accepts the run (output 1), if and
only if the following is true: the probability that the choices
of |Q|−1 honest senders (making their choices according to
the probability distribution μ) yield Q, given that the sender
under observation chooses p, is bigger than the probability
that the choices of |Q|−1 honest senders yield Q, given that
the sender under observation chooses p(cid:4).
Now, we can prove the following result.

Lemma 1. The advantage of A (in distinguishing if the
sender under observation has chosen p or p(cid:4)) is not bigger
than the advantage of A∗.

358

