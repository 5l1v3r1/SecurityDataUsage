OFSS: Skampling for the Flow Size Distribution

Paul Tune

School of Mathematical Sciences
University of Adelaide, Australia

paul.tune@adelaide.edu.au

Darryl Veitch

Melbourne School of Engineering
University of Melbourne, Australia

dveitch@unimelb.edu.au

ABSTRACT
We introduce a new method for ﬂow size estimation, the Op-
timised Flow Sampled Sketch, which combines the optimal
properties of Flow Sampling with the computational advan-
tages of a counter array sketch. Using Fisher Information as
a deﬁnitive basis of comparison, we show that it is superior
to alternatives in both model and traﬃc based comparisons.

Categories and Subject Descriptors
C.2.3 [Computer Communications Networks]: Network
operations—Network monitoring; G.3 [Mathematics of Com-
puting]: Probability and statistics—Probabilistic algorithms

Keywords
Fisher information; ﬂow size distribution; network measure-
ment; OFSS; skampling

1.

INTRODUCTION

The distribution of ﬂow size, the number of packets in
a ﬂow, is an important metric for numerous applications
including traﬃc modelling, management, and attack detec-
tion. In resource constrained environments such as within
core Internet routers however, accurate measurement of ﬂow
size can be challenging.

The traditional approach to fast approximate measure-
ment has been traﬃc sampling. For example ﬂow size es-
timation within Cisco’s Netﬂow [1] is based on a simple
pseudo-random per-packet sampling. In our prior work [6,
10, 11] we examined available sampling techniques in depth
and showed that ﬂow sampling (FS), where the random sam-
pling decision is made directly on ﬂows, has optimal prop-
erties. This conclusion was based on a rigorous evaluation,
in terms of Fisher Information, of the inherent abilities of
the sampling methods as information collectors. Unfortu-
nately, FS requires a ﬂow table supporting collision resolu-
tion, which incurs costs in memory (entries must store a ﬂow
key in addition to a counter), and in processing and latency

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
IMC’14, November 5–7, 2014, Vancouver, BC, Canada. 
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-3213-2/14/11 ...$15.00.
http://dx.doi.org/10.1145/2663716.2663732.

(key comparison needed on all insertions). Such costs trans-
late to bottlenecks, for example ‘heavy hitter’ ﬂows gener-
ating unsustainable insertion rates.

Sketches are compact data structures with fast update
rules that are used to approximately measure properties
over data streams. Sketches have been proposed to measure
many metrics including set membership [2], entropy [14],
heavy hitters [4], and ﬂow sizes [7].

In this paper we present a hybrid skampling approach to
data collection for ﬂow size measurement, called the OFSS
or Optimised Flow Sampled Sketch. The FSS consists of a
front-end sampling component, namely FS, feeding a sketch-
ing component ‘Sk’, the counting array sketch of [7]. It in-
cludes FS and Sk as special cases. The OFSS is an FSS
tuned according to an optimal tradeoﬀ between the infor-
mation gathering strengths and weaknesses of the FS and
Sk components. The result is FS-like statistical performance
without ﬂow table costs and bottlenecks. In designing OFSS
we build on and extend the Fisher analysis of FS and Sk pre-
sented in [12].

It is natural, since OFSS is a ‘Sample then Sketch’ method,
to compare against ‘Sketch then Sample’. We accordingly
compare against the ‘Sketch Guided Sampling’ approach of
Kumar et al. [8] (SGS). We ﬁnd SGS to have much worse
performance than OFSS, both in terms of information gath-
ering, and implementation. We also compare against an
enhanced counter array based method of Ribeiro et al. [9]
which also, in an implicit sense, incorporates sampling. We
show that this Eviction Sketch (ESk) underperforms OFSS
by a wide margin at meaningful sampling rates unless it is
calibrated very diﬀerently than in [9], resulting in consid-
erably higher memory use. For each of SGS and ESk we
provide the ﬁrst Fisher-based analysis.

The goal of this paper is to introduce the OFSS scheme, to
give its key properties, and to demonstrate its eﬀectiveness.
To that end, we forgo proofs (these will appear elsewhere
[13]), and focus on providing the underlying intuition. We do
not provide a detailed implementation model, however with
only a single hash and a single counter array, OFSS is very
simple, cheap enough to implement alongside existing packet
sampling based systems. Software will be made publically
available to facilitate use of the method, in particular for the
calculation of the optimal parameter value p∗

f of OFSS.

The paper is organised as follows. Section 2 gives back-
ground on the Fisher Information framework, and deﬁnes,
recalls and derives key results for FS and Sk, SGS and ESk.
Section 3 deﬁnes FSS then OFSS and describes their key
properties. Section 4 gives the statistical performance com-

235W(cid:88)

parisons on both model based and real data. We conclude
in Section 5.

2. BACKGROUND

We assume that a unique ﬂow key can be extracted from
each incoming packet, and that the ﬁrst packet of a ﬂow
(and hence the number of ﬂows) can be identiﬁed (e.g. SYN
packet in the case of TCP ﬂows).

We write (column) vectors in bold lower-case, matrices
in bold upper case, AT denotes the transpose of A, and
diag(x) an m × m diagonal matrix whose diagonal entries
are taken from the vector x ∈ Rm. We denote the set
{1, 2, . . . , S} by [S].
2.1 Modelling Framework, Fisher Information
Consider a measurement interval of duration T containing
Nf ﬂows. Of these ﬂows, Mk have size k packets, 1 ≤ k ≤ W ,
where W < ∞ is the maximum ﬂow size. The average ﬂow

size is D =(cid:80)W

k=1 kMk/Nf .

The ﬂow size distribution, the unknown vector parameter
we seek information on, is θ = [θ1, θ2, . . . , θW ]T where θk =
Mk/Nf , and obeys

0 < θk < 1 , k ∈ [W ],

θk = 1 .

(1)

This is a deterministic model of the data over the measure-
ment interval: randomness enters later through the action
of the measurement method itself.

k=1

Any estimator of θ is based on an underlying observable
which summarises the traﬃc, where it here takes the form
of a packet count random variable C. The discrete density
cj(θ) of C, j ≥ 0, depends on the details of the summary
method. Viewed as a function of θ for a ﬁxed value j of the
observed data, it is known as the likelihood : f (j, θ) = cj(θ).
The Fisher Information (FIM) is a measure of the infor-
mation the observable holds about the unknown parameters.
The unconstrained FIM is deﬁned as

J(θ) = E[(∇θ log f (j; θ))(∇θ log f (j; θ))T]

=

(∇θ log f (j; θ))(∇θ log f (j; θ))Tcj.

(2)

(cid:88)

j≥0

The importance of J lies in the fact that J−1 is the Cram´er–
Rao Lower Bound (CRLB), which lower bounds the covari-
ance matrix Σθ of any unbiased estimator of θ, i.e. Σθ ≥
J−1 in the positive semideﬁnite sense.

(cid:16)

(cid:17)−1

The constraints on θ in (1) increase available information.

GTJ

−1.

The constrained FIM is given in [5] by
−1G

I + = J

−1 − J

−1G

GTJ

(3)
Here the constraint gradient matrix is G(θ) = ∇θ(1T
W θ −
1) = 1W , where 1W is a W × 1 vector of ones.
Of chief interest are the diagonal entries of I +, since
Var(ˆθk) ≥ (I +)kk for any unbiased estimator. Compar-
ison of these between methods corresponds to comparing
the best performance the schemes are capable of support-
ing, thus reﬂecting their comparative eﬃciency in extracting
information from the traﬃc stream.

The methods we study involve multiple identically dis-
tributed counters, which are approximately independent if
Nf is large. The Fisher information arising from the entire

measurement interval is then just that of a single counter C
multiplied by the number of counters.
2.2 Four Methods and their FIMs
We deﬁne four existing methods and describe their FIM
and I + matrices. FS is the statistical method of choice, and
Sk a canonical implementation approach. SGS and ESk are
alternative skampling methods.
Flow Sampling (FS)
In ﬂow sampling ﬂows are sampled (dropped) independently
with probability pf (resp. qf ). Sampling a ﬂow means that
each packet within it is sampled, or none.

Here C represents the size of a randomly selected (typical)
ﬂow. For a ﬂow of size k, its density is given by c0 = qf ,
ck = pf , and ci = 0 for all i (cid:54)= {0, k}. From [10, 11], an
explicit expression for per-ﬂow J is given by

−1
1 , θ
and I + = J−1 − θθT = 1

JFS = pf diag(θ

−1
2 , . . . , θ

(cid:0)diag(θ) − θθT(cid:1), and so

−1
W ) + qf 1W 1T
W ,

(I +

FS)kk =

pf

θk(1 − θk)

pf

, k ∈ [W ].

(4)

(5)

The great strength of FS compared to other methods is
that estimators based on it do not have to try to correct
distortions: collected ﬂows are perfect.
Counter Sketch (Sk)
The counter sketch, introduced by Kumar et al. [7], consists
of an array of A packet counters, each initialised to zero
at the beginning of the measurement interval.
Incoming
packets are mapped independently and uniformly over the
counters, using a hash function mapping a ﬂow key, so that
each packet in a ﬂow maps to the same counter, but collisions
can occur so that a given counter may sum the packet counts
from two or more ﬂows. We deﬁne α = Nf /A to be the ﬂow
load factor, the average number of ﬂows per counter.

Here C is the ﬁnal packet count in a typical counter, at
the end of the measurement interval when all Nf ﬂows are
in the sketch. By using a Poisson assumption for C, the
density can be shown to be (see [13])

 e

−(cid:80)W

λxk
k
xk!

k=1

cj =

x∈Ωj

W(cid:89)

(cid:88)
packet count C = (cid:80)W
(J)ik = α2(cid:16)−1 +

∞(cid:88)

where xk is the number of ﬂows of size k in the counter,
λk = Mk/A = αθk, x = [x1, x2,··· , xW ] denotes a collision
pattern, and Ωj is the set of ﬂow collision patterns with
k=1 kxk = j. It follows that the per-

counter Fisher matrix is given by

(cj−icj−k)/cj

,

(7)

j=max(i,k)

and the per-ﬂow information is JSk = AJ/Nf = J/α. The
constrained per-ﬂow CRLB, I +
Sk, is given by substituting
JSk into (3).

The strength of Sk is that all packets of all ﬂows are ef-
ﬁciently collected, but as the sketch becomes increasingly
full as α increases, we expect information-destroying ﬂow
collisions to become severe.
Sketch Guided Sampling (SGS)
Traditional Packet Sampling (PS) simply samples packets
independently with ﬁxed probability p, and is known to de-
stroy information about θ with remarkable eﬃciency [10,

k=1 λk ,

j ≥ 0

(6)

(cid:17)

236W(cid:88)

11]. Sketch Guided Sampling, introduced in [8], is at heart
a generalised packet sampling method indexed by a sampling
probability function p(k), k ∈ [W ]. A packet will be sampled
with probability p(k) if it is the k-th packet encountered so
far in its ﬂow. Of course, we do not know the in-ﬂow posi-
tion of packets, if one did θ would be already known! The
innovation in [8] was to estimate this quantity by a coarse
counter sketch, hence SGS is a skampling method.

To simplify comparisons, we assist SGS by replacing its
sketch component with oracular knowledge of each packet’s
in-ﬂow position. Assisted SGS is then a pure sampling
method, whose per-ﬂow counter density is characterised by
its sampling matrix B as

cj =

bjkθk,

0 ≤ j ≤ W,

(8)

k=1

where bjk, is the probability that if the original ﬂow had
k packets, only j remain after sampling. The matrix ele-
ment bjk can be calculated via the recursion bj,k+1 = p(k +
1)bj−1,k + q(k + 1)bj,k.

From general sampling results from [11], we can write

J = BTDB,

(9)

where D = diag(Bθ), and I + = J−1 − θθT.
Following [8], we use

p(k) = p(k; β, ) =

1

1 + 2k(2β−1) , 1/2 ≤ β ≤ 1,

(10)

a monotonically decreasing function of k. The idea is that
this creates a bias toward short ﬂows which counteracts the
strong large-ﬂow bias of traditional PS, which corresponds
to β = 1/2.

Note that (true) SGS requires both a ﬂow table and a

sketch, and so is more costly to implement than FS.

Eviction Sketch (ESk)
The data collection method proposed in [9] physically en-
hances Sk by associating to each of its A counters an own-
ership variable taking values in [L], all initialised to L. An
incoming packet is given a random priority class (cid:96) ∈ [L]. If
(cid:96) equals the value of the associated ownership variable its
counter is incremented as normal, but if it is larger (lower
priority than it) the counter is unchanged, and if smaller
(higher priority) the counter is reset to 1, and the ownership
variable is set to (cid:96) recording the fact that class (cid:96) now ‘owns’
the counter. This random eviction of lower class packets is
an implicit packet sampling, reducing the input load α to
an eﬀective load α(cid:48) < α, hence ESk is a skampling method.

It is not hard to show that the counter density is

−α,

c0 = e
cj = F (L) cSk,j(α/L),

j ≥ 0

(12)
where F (L) = (1− e−α)/(1− e−α/L) and cSk,j is the density
It follows that the per-counter Fisher
(6) with load α/L.
matrix based on C is given by

(11)

(cid:16)−1 +

∞(cid:88)

j=max(i,k)

(J)ik =

α2
L2

(cj−icj−k)/cj

,

(13)

(cid:17)

and the per-ﬂow information is JESk = AJ/Nf = J/α. The
constrained per-ﬂow CRLB, I +
ESk, is given by substituting
JESk into (3).

The degree of sampling oﬀered by ESk, p = α(cid:48)/α =
F (L)/L, is only coarsely controllable via the choice of L,
and is limited: p hits a limit of 1/L for α (cid:29) L. For a given
α and k, the CRLB of θk is minimized at L = ∞. Here ESk
reduces to FS with min(A, Nf ) sampled ﬂows, however this
requires inﬁnite memory. For L = 1 ESk reduces to Sk, a
pure sketch with p = 1.

3. FSS AND OFSS

We deﬁne the Flow Sampling Sketch (FSS), a family of
skampling methods indexed by an internal parameter pf ,
describe its properties and derive its Fisher Information. We
then introduce the Optimised Flow Sampling Sketch (OFSS),
which is FSS with pf chosen to maximise its Fisher Infor-
mation gathering ability.
3.1 FSS

We begin by contrasting the nature of FS and Sk. The
central issue is that of collision resolution. Allowing mul-
tiple ﬂows to map to the same counter is the origin of the
high speed implementation advantages of Sk, but also of its
statistical weakness: collisions create complex ambiguities
which literally destroy information (see below). In contrast,
the information loss in FS is due solely to the fact that not
all ﬂows are used, but the requirement of strict collision res-
olution makes FS, for any pf , computationally onerous at
high speed.

The key idea of FSS is the following: if α could be kept
low, then Sk could work at an ‘operating point’ with low
information loss. A natural way to achieve this is to perform
a thinning of the incoming ﬂows to reduce the input α to
an eﬀective α(cid:48) < α seen by the sketch, set to a suitable
value which trades oﬀ the need for low ambiguity (α(cid:48) not too
big), against adequate data collection as well as not under-
utilising expensive memory (α(cid:48) not too small). It is useful
to keep in mind that when α(cid:48) = 1, a proportion 1 − c0 =
1 − e−1 ≈ 0.632 of counters are used.
Deﬁnition: FSS(pf ;A) Each ﬂow is sampled with probabil-
ity pf . Packets of sampled ﬂows are inserted into a counter
sketch with A counters.

Thus FSS has an ‘FS front end’ which sends sampled ﬂows
through to an unmodiﬁed counter sketch, which sees a re-
duced eﬀective average ﬂow load of

(cid:48)

α

= pf α.

In information terms, FSS combines the loss of informa-
tion arising from FS’s ﬂow thinning, with a loss due to Sk’s
collision-induced ﬂow ambiguity.

In terms of implementation, the key advantage of FSS is
that the FS component does not require any ﬂow table or
collision resolution. Only the ﬂow selection itself remains,
but this can be easily implemented in deterministic time on
a per-packet basis by hashing ﬂow keys. As described in
[12], the hash function can be simultaneously used to index
into the sketch.
From the above, we expect FSS to behave exactly as Sk
with load α(cid:48). However, whereas the number of ﬂows Nf en-
tering FSS is a known constant, the number reaching the
counter array is, unlike for Sk, a random variable. Remark-
ably, it turns out (see [13]) that the counter density nonethe-
less takes the same form as for Sk (Equation (6)), with the
λk replaced by λ(cid:48)
k = α(cid:48)θk = pf λk. Since the dependence on θ

237is unchanged, the per-counter information for FSS is just as
for Sk with parameter α(cid:48), and therefore the information per-
incoming-ﬂow is JFSS(α) = pf JSk(α(cid:48)). The per-ﬂow CRLB
is therefore

I +
FSS(α) =

α

α(cid:48) I +

Sk(α

(cid:48)

) =

1
pf

I +
Sk(α

(cid:48)

).

(14)

FSS inherits FS’s ﬂexibility in adapting to varying traf-
ﬁc levels. If α suddenly increases then pf could be simply
decreased to keep α(cid:48) in a target range.
3.2 OFSS

The parameters considered ﬁxed in a given measurement
are the counter array size A, the number of ﬂows Nf , and θ.
The input load to the FSS is therefore ﬁxed at α = Nf /A,
whereas pf is an internal parameter free to be tuned to any
value in [0, 1].

In deﬁning OFSS our aim is to select pf to maximise the
total amount of information captured by FSS, or equiva-
lently, to minimise the CRLB when using all A counters.
Thus, for each α > 0, we seek to minimise the diagonal
elements of

I T (pf ) =

I +
FSS(α)
Nf

I +
FSS(α)
Aα

=

=

1

Aα(cid:48) I +

Sk(α

(cid:48)

)

(15)

over pf ∈ [0, 1], or equivalently, α(cid:48) ∈ [0, α].
Equation (15) is a product of two competing terms, each
a function of pf through α(cid:48) = pf α. The scalar 1/(Aα(cid:48)) de-
pends on the number of ﬂows delivered to the sketch by the
FS component and is monotonically decreasing with pf .
The matrix I +
Sk(α(cid:48)) corresponds to the information stored
per-ﬂow in the counter array. It is monotonically increas-
ing with pf in a positive semideﬁnite sense [13]. The key
question is whether an optimal point exists for any α, that
is, if there is a maximum amount of information that can
be stored in the sketch, so that excessive load is not just a
matter of diminishing returns but actually results in infor-
mation destruction. To answer it, let Ik(x) = (I +
Sk(x)/x)kk.
From (15), (I T (pf ))kk = Ik(α(cid:48))/A.

Theorem 1. For each k, Ik(x) has a global minimum at

k > 0 for any θ with W > 3.

ﬁnite x = α∗∗
The proof is based on the fact that the largest eigenvalue of
I +
Sk(x) is O(xW−2), which defeats the 1/x factor for large x
if W > 3 [13].
k ≤ α∗∗
of a ﬁrst local minimum α∗
now ready to deﬁne OFSS.
Deﬁnition: OFSS(k; A) OFSS(k; A) is FSS(p∗
f (k; α) ∈ (0, 1] is the value that minimises
p∗
(IT (pf ))kk, subject to α(cid:48) = αp∗

The existence of the global minimum implies the existence
k . We are

k > 0 obeying α∗

f ; A), where

f ≤ α∗
k.

Apart from the trivial case of W = 2, we do not know of
any examples where the ﬁrst local minima is not equal to
the global minimum, and conjecture that α∗
in all
cases with W > 3.

k = α∗∗

k

Even if there are cases when α∗

k is not optimal, it is ad-

vantageous to base a deﬁnition on it because

(cid:26) 1,
α < α∗
k,
α∗
α , α ≥ α∗
k.

k

∗
f (k; α) =
p
In other words, if α > α∗
k, select pf to cut back the input
so that α(cid:48) = α∗
k, otherwise let all ﬂows in. The signiﬁ-
cance of this property is that one only needs to calculate α∗
k

(16)

to know p∗
f (k; α) for all α, a signiﬁcant practical advantage
when adapting p∗
f (k; α) to changing traﬃc conditions, or dif-
ferent resource allocation (A value). Calculation details for
α∗
k can be found in [13].
4. PERFORMANCE COMPARISON

We compare the CRLB performance of OFSS against that
of FS, Sk, and enhanced versions of our skampling competi-
tors SGS and ESk. For SGS(β, ), we use the assisted form
as described above, and also test using β = 0.75 in addition
to the β = 1 value used in [8]. For ESk(L), we compare not
only against the L = 2 favoured in [9], but also larger values
adapted to α, and ignore the additional memory required to
maintain the ownership variables. In data estimation com-
parisons, we use ML estimators for all methods. Previously
a sub-optimal estimator was used to test SGS and ESk.

We compare on a basis of equal counter memory. The
methods Sk, FSS, OFSS, ESk are each given an array with A
counters, whereas the sampling methods FS, SGS are given
ﬂow tables with A entries. This means that if Nf > A,
only N(cid:48)
f = min(Nf , A) ﬂows will actually be delivered to the
methods (we ignore ﬂow expiry).
With A and Nf (or equivalently α = Nf /A) ﬁxed, meth-
ods Sk, ESk(2) and FS(pf =N(cid:48)
f /Nf = min(1, 1/α)) are deter-
mined, as are OFSS(k) given the target θk. For SGS, for
each of β = {0.75, 1} we set  to match the average number
of captured packets to that of FS. For ESk, at larger α val-
ues we select two values of L > 2 to bracket OFSS (at the
chosen k∗). Finally, we also compare against FS(1), that is
perfect ﬂow collection.
We compare over an operating range of 1 < α ≤ 100, since
α ≈ 1 is theoretically important, and α = 100 corresponds
to a commonly quoted sampling probability of 0.01. Values
as high as α = 10000 are now typical in big data contexts.
The structure of OFSS is such that its performance will be
unaﬀected by higher loads, whereas other methods suﬀer
in information or implementation terms, or both, as load
increases.

Since A enters in only as a multiplicative factor, we plot
per-counter variance rather than total variance. Here the
objective is to compare methods, the absolute CRLB values
depend on θ and are not important.
4.1 CRLB Comparisons

We evaluate (I T (pf ))kk numerically from the exact ex-
pressions given earlier, initially using a truncated geometric
model TG(W, R) for θ, where R = θ1/θW . The R = 1 case
is a uniform distribution, which has a heavier tail than any
(truncated) Pareto distribution.
Consider Figure 1 where θ is uniform, W = 50. In plot(a)
α ≈ 1, a load so light that results are close to degenerate:
f ) ≈ FSS(1) = Sk ≈ ESk(2), FS(pf ) ≈ FS(1). De-
OFSS(p∗
spite this SGS already shows poor behavior. At α = 2 it
is already orders of magnitude worse than other methods
for k > 3, and becomes almost impossible to calculate for
α = 100. This is consistent with the poor behaviour of
packet sampling [11], whose structure SGS generalises, but
does not fundamentally change. For small α ESk(2) outper-
forms OFSS, however as α increases both Sk and ESk(2) also
have variances orders of magnitude beyond OFSS for all k,
and then become diﬃcult to calculate. At α = 100 the ﬁeld
therefore narrows to ESk(L) for well chosen L (cid:29) 2 versus
OFSS. For each of plots (c) and (d) L values are used so that

238(a) α = 1.1

(b) α = 2

(c) α = 10

(d) α = 100

Figure 1: CRLB Comparisons with uniform θ, W = 50. We plot SGS(β, ) when possible; ESk(2) and Sk for
α ≤ 2, else ESk(L) for values bracketing OFSS(p∗

f (1)), and FS(1/α). Here p∗

f ≈ 1/α. since α∗

1 ≈ 1.

(a) θ from TG(50, 1000)

(b) θ from TG(1000, 1000)

(c) θ from Abilene-III

(d) θ from Leipzig-II

Figure 2: CRLB Comparisons, α = 100. [Abilene, Leipzig] truncated at W = [1000, 200].

ESk brackets OFSS. In plot(d) we see that OFSS is within
a constant factor of, and the same order of magnitude as,
the benchmark FS(1/α). We see that to (just) defeat OFSS
requires ESk with L = 64. Assuming a generous 32 bits per
counter, this means that ≈ 19% extra memory is needed to
achieve this, more for larger α.

Comparing plot(d) with Figure 2(a) shows that similar
conclusions hold even after changing the distribution shape
quite radically from uniform to TG(50, 1000). For TG(W, R)
with R = {10, 1000}, W = {50, 1000}, similar results were
found. Changing from optimising for θ1 to other θk changes
variance values somewhat for OFSS(k) and the matching L
slightly for ESk(L), but not the conclusions.

Figure 2 provides a bridge from models to data with load
ﬁxed at α = 100. From plots(a) to (b) we increase W from
W = 50 to a more realistic W = 1000. The picture is
remarkably unchanged. From plot(b) to (c) we move from a
very rough traﬃc model, TG(1000, 1000), to data from the
Abilene-III dataset (see Table 1), truncated at W = 1000.
Again the same model-comparison conclusions hold. Finally,
plot(d) uses θ from the Leipzig-II dataset where θk = 0 for
many k, resulting in zeros manifesting as gaps in the FS and
FS(1) curves. Associated ‘spiky’ far-tail estimates for OFSS
and ESk are a sign of the need for truncation, here we used
W = 200.

4.2 Estimation Comparisons

We now compare ˆθ estimates, again for α = 100, for FS,
OFSS, SGS(1, ), and ESk(64) using maximum likelihood
estimation (see [13] for MLE derivations).

Trace

Leipzig-II
Abilene-III

Link

Capacity
50 Mbps
10 Gbps

Nf

2,277,052
23,806,285

Duration
(hh:mm:ss)
02:46:01
00:59:49

D

19.76
16.12

Table 1: Summary of the data traces used.

The datasets, summarised in Table 1, are old but adequate
for testing the methods. We extract TCP ﬂows according
to the standard 5-tuple (with no timeout).

Figure 3 plots ˆθ for Abilene-III, truncated at W = 2000,
which is approximately the largest value for which θk > 0
for all k. The grey curve, FS(1), corresponds to θ itself. The
estimate for SGS: ˆθ1 = 1, and ˆθk = 0 for all k > 1, is as
expected very poor, in fact degenerate. All other methods
appear to perform quite well, however it is very diﬃcult to
assess performance reliably from such plots, in particular

Figure 3: ˆθ for Abilene, W = 2000. Here α = 100,
and OFSS and ESk are optimised for θ1.

1510152025303540455010−2100102104106kCRLB(θk)  SGS(0.75,0.162)SGS(1,0.0777)ESk(2)SkOFSS(0.9089)FS(0.9091)FS(1)1510152025303540455010−2100102kCRLB(θk)  SGS(0.75,0.531)SGS(1,0.278)ESk(2)SkOFSS(0.4999)FS(0.5)FS(1)1510152025303540455010−210−1kCRLB(θk)  ESk(4)ESk(8)OFSS(0.09998)FS(0.1)FS(1)1510152025303540455010−310−210−1kCRLB(θk)  ESk(32)ESk(64)OFSS(0.009998)FS(0.01)FS(1)1510152025303540455010−410−2100kCRLB(θk)  ESk(32)ESk(64)OFSS(0.009529)FS(0.01)FS(1)1200400600800100010−610−410−2kCRLB(θk)  ESk(32)ESk(64)OFSS(0.009529)FS(0.01)FS(1)1200400600800100010−5100kCRLB(θk)  ESk(32)ESk(64)OFSS(0.009382)FS(0.01)FS(1)15010015020010−5100kCRLB(θk)  ESk(32)ESk(64)OFSS(0.008822)FS(0.01)FS(1)10010210−1010−5100kθk  SGS(1,5.21)ESk(64)OFSS(0.00938)FS(0.01)FS(1)10010110210−610−410−2100ZOOMkθk239f

k∗
1
1

p∗
L
Trace
0.009 64
Abilene
0.009 64
Leipzig
Abilene W 0.005 64
Leipzig W 0.013 64

FS

OFSS
5.6e-3

ESk
SGS
1.6e-3
7.8e-2 8.9e-1
9.4e-2 2.1e-2 2.5e-1 2.8e-1
1.6e-3
7.8e-2 8.9e-1
9.4e-2 2.1e-2 2.5e-1 2.5e-1

4.1e-3

Table 2: (cid:96)2 error: Abi. (W=2000), Leip. (W=200).

ror (cid:107) ˆθ − θ(cid:107)2 = ((cid:80)W

in the far tail because of the high variablility inherent in
single point estimates as the data ‘runs out’. Smoothing is
typically used to improve behaviour in such cases [3].

For a more objective assessment, we employ the (cid:96)2 er-
k=1(ˆθk − θk)2)1/2 to summarise perfor-
mance of each method over all k. Overall, for each trace
the results of Table 2 reﬂect the variance pecking order
FS<OFSS<ESk(64)(cid:28)SGS from the CRLB analysis aver-
aged over all k, both when optimised for θ1 and θW . Four
exceptions are noted in bold. In two of these OFSS is seen
to defeat FS. This is due to an implicit smoothing of the
sketch component of OFSS improving the ﬁt over the tail
where for many indices θk = 0 for Leipzig.
In the other
two cases SGS appears comparable to ESk for Leipzig when
k∗ = W instead of much worse. This results from the fact
that θ1, θ2 are fairly large and SGS is able to give rough
estimates for them given its deliberate small ﬂow bias, while
setting ˆθk = 0 for all k > 2. Note that these exceptions are
in part due to the limitations of (cid:96)2 as a summary metric.
Leipzig-II provides an instructive example of diﬃculties (for
all methods) which arise when the assumption of θk > 0 is
violated. Abilene-III avoids this by a suitable, and larger,
choice of W .
5. CONCLUSION

We have introduced OFSS, a hybrid ‘skampling’ method
for ﬂow size estimation.
Its Fisher information gathering
ability is of the same order as Flow Sampling (the optimum),
but its sketch data structure allows its use in resource con-
strained applications. It is clearly superior to the alternative
SGS and ESk in implementation terms, and in information
terms, except for ESk for large enough L. However ESk is
more complex and requires supplementary memory which
increases both with L and hence with load. OFSS(k∗) is
tuned to minimise the CRLB of θk∗ , but for any k∗, it per-
forms well for all θk.
Acknowledgment
Partially supported by Australian Research Council’s Dis-
covery Projects funding schemes # DP120102834 and #
DP110103505.

6. REFERENCES
[1] Cisco NetFlow.

http://www.cisco.com/en/US/products/ps6601/
products ios protocol group home.html.

[2] B. H. Bloom. Space-time trade-oﬀs in hash coding

with allowable errors. Communications of the ACM,
13(7):422–426, 1970.

[3] N. Duﬃeld, C. Lund, and M. Thorup. Estimating ﬂow
distributions from sampled ﬂow statistics. IEEE/ACM
Transactions on Networking, 13(5):933–946, 2005.

[4] C. Estan and G. Varghese. New directions in traﬃc
measurement and accounting. ACM Transactions on
Computer Systems, 21(3):270–313, August 2003.
[5] J. D. Gorman and A. O. Hero. Lower bounds for

parametric estimation with constraints. IEEE Trans.
Info. Th., 36(6):1285–1301, Nov. 1990.

[6] N. Hohn and D. Veitch. Inverting Sampled Traﬃc. In

Proc. 2003 ACM SIGCOMM Internet Measurement
Conference, pages 222–233, Miami, Oct. 2003.

[7] A. Kumar, M. Sung, J. Xu, and J. Wang. Data
streaming algorithms for eﬃcient and accurate
estimation of ﬂow size distribution. In Proceedings of
ACM SIGMETRICS / IFIP WG 7.3 Performance
2004, New York, June 2004.

[8] A. Kumar and J. Xu. Sketch Guided Sampling: Using

online estimates of ﬂow size for adaptive data
collection. In Proceedings of IEEE Infocom 2006,
Barcelona, Spain, April 2006.

[9] B. Ribeiro, D. Towsley, and T. Ye. A

Resource-minimalist Flow Size Histogram Estimator.
In Proc. ACM/SIGCOMM Internet Measurement
Conf., pages 285–290, Vouliagmeni, Greece, Oct. 20-22
2008.

[10] P. Tune and D. Veitch. Towards Optimal Sampling for

Flow Size Estimation. In Proc. ACM SIGCOMM
Internet Measurement Conf., pages 243–256,
Vouliagmeni, Greece, Oct. 20-22 2008.

[11] P. Tune and D. Veitch. Fisher Information in Flow

Size Distribution Estimation. IEEE Transactions on
Information Theory, 57(10):7011–7035, Oct. 2011.
[12] P. Tune and D. Veitch. Sampling vs Sketching: An

Information Theoretic Comparison. In IEEE Infocom
2011, pages 2105–2113, Shanghai, China, April 10-15
2011.

[13] P. Tune and D. Veitch. OFSS: Skampling for the Flow
Size Distribution: Technical Report. Technical report,
Dept. E&EE, The University of Melbourne, 2014.
copy available upon request.

[14] H. Zhao, A. Lall, M. Ogihara, O. Spatscheck, J. Wang,
and J. Xu. A data streaming algorithm for estimating
entropies of OD ﬂows. In Proc. 7th ACM SIGCOMM
Internet Measurement Conf., pages 279–290, New
York, NY, USA, 2007. ACM.

240