AutoCog: Measuring the Description-to-permission

Fidelity in Android Applications

Zhengyang Qu1, Vaibhav Rastogi1, Xinyi Zhang2, Yan Chen1,

Tiantian Zhu3, Zhong Chen4

1Department of Electrical Engineering and Computer Science,Northwestern University, Illinois, USA

2Software School, Fudan University, Shanghai, China

3Software College, Northeastern University, Shenyang, China

{zhengyangqu2017, vrastogi}@u.northwestern.edu, ychen@northwestern.edu,
10302010070@fudan.edu.cn, laozhutt@gmail.com, zhong.chen@utoronto.ca

4Wind Mobile,Toronto, Ontario, Canada

ABSTRACT
The booming popularity of smartphones is partly a result of
application markets where users can easily download wide
range of third-party applications. However, due to the open
nature of markets, especially on Android, there have been
several privacy and security concerns with these applica-
tions. On Google Play, as with most other markets, users
have direct access to natural-language descriptions of those
applications, which give an intuitive idea of the functionality
including the security-related information of those applica-
tions. Google Play also provides the permissions requested
by applications to access security and privacy-sensitive APIs
on the devices. Users may use such a list to evaluate the
risks of using these applications. To best assist the end
users, the descriptions should reﬂect the need for permis-
sions, which we term description-to-permission ﬁdelity. In
this paper, we present a system AutoCog to automati-
cally assess description-to-permission ﬁdelity of applications.
AutoCog employs state-of-the-art techniques in natural lan-
guage processing and our own learning-based algorithm to
relate description with permissions. In our evaluation, Auto-
Cog outperforms other related work on both performance
of detection and ability of generalization over various per-
missions by a large extent. On an evaluation of eleven per-
missions, we achieve an average precision of 92.6% and an
average recall of 92.0%. Our large-scale measurements over
45,811 applications demonstrate the severity of the problem
of low description-to-permission ﬁdelity. AutoCog helps
bridge the long-lasting usability gap between security tech-
niques and average users.

Categories and Subject Descriptors
D.0 [Software]: General

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
Copyright 2014 ACM 978-1-4503-2957-6/14/11 ...$15.00.
http://dx.doi.org/10.1145/2660267.2660287.

Keywords
Android, Natural language processing, Machine learning,
Mobile, Google play, Permissions

1.

INTRODUCTION

Modern operating systems such as Android have promoted
global ecosystems centered around large repositories or mar-
ketplaces of applications. Success of these platforms may in
part be attributed to these marketplaces. Besides serving
applications themselves, these marketplaces also host appli-
cation metadata, such as descriptions, screenshots, ratings,
reviews, and, in case of Android, permissions requested by
the application, to assist users in making an informed deci-
sion before installing and using the applications. From the
security perspective, applications may access users’ private
information and perform security-sensitive operations on the
devices. With the application developers having no obvious
trust relationships with the user, these metadata may help
the users evaluate the risks in running these applications.

It is however generally known [14] that few users are dis-
creet enough or have the professional knowledge to under-
stand the security implications that may be derived from
metadata. On Google Play, users are shown both the ap-
plication descriptions and the permissions1 declared by ap-
plications. An application’s description describes the func-
tionality of an application and should give an idea about
the permissions that would be requested by that application.
We call this description-to-permission ﬁdelity. For example,
an application that describes itself as a social networking
application will likely need permissions related to device’s
address book. A number of malware and privacy-invasive
applications have been known to declare more permissions
than their purported functionality warrants [10, 33].

With this belief that descriptions and permissions should
generally correspond, we present AutoCog, a system that
automatically identiﬁes if the permissions declared by an
application are consistent with its description. AutoCog
has multi-fold uses.
• Application developers can use this tool to receive an
early, automatic feedback on the quality of descriptions

1In Android, security-sensitive system APIs are guarded by
permissions, which applications have to declare and which
have to be approved at install-time.

1354so that they improve the descriptions to better reﬂect the
security-related aspects of the applications.
• End users may use this system to understand if an appli-
• Application markets can deploy this tool to bolster their

cation is over-privileged and risky to use.

overall trustworthiness.
The key challenge is to gather enough semantics from de-
scriptions in natural language to reason about the permis-
sions declared. We apply state-of-the-art techniques from
natural language processing (NLP) for sentence structure
analysis and computing semantic relatedness of natural lan-
guage texts. We further develop our own learning-based al-
gorithm to automatically derive a model that can be queried
against with descriptions to get the expected permissions.

AutoCog is a substantial advancement over the previous
state-of-the-art technique by Pandita et al.
[26], who have
also attempted to develop solutions with the same goals.
Their tool called Whyper is primarily limited by the use of
a ﬁxed vocabulary derived from the platforms’ API docu-
ments and the English synonyms of keywords there. Our in-
vestigations show that Whyper’s methodology is inherently
limited regarding the following issues: (a) Limited semantic
information: not all textual patterns associated with a per-
mission can be extracted from API documents, e.g., <“ﬁnd ”,
“branch atm”> relate to location permissions and <“scan”,
“barcode”> relate to the permission for accessing the cam-
era in our models but cannot conceivably be found from API
documents; (b) Lack of associated APIs: certain permissions
do not have associated APIs so that this methodology can-
not be used; and (c) Lack of automation:
it is not clear
how the techniques could be automated. We have conﬁrmed
these limitations with Whyper’s authors as well.

Our methodology is radically diﬀerent from Whyper’s as
is evident from the following contributions of this paper.
• Relating descriptions and permissions. We design a novel
learning-based algorithm for modeling the relatedness of
descriptions to permissions. Our algorithm correlates tex-
tual semantic entities (second contribution) to the de-
clared permissions.
It is noteworthy that the model is
trained entirely from application descriptions and declared
permissions over a large set of applications without de-
pending on external data such as API documents, so that
we do not have the problems of limited semantic informa-
tion or lack of associated APIs from the very outset. Both
training and classiﬁcation are completely automatic.
• Extracting semantics from descriptions. We utilize state-
of-the-art NLP techniques to automatically extract se-
mantic information from descriptions. The key compo-
nent for semantics-extraction in our design is Explicit Se-
mantic Analysis (ESA), which leverages big corpuses like
Wikipedia to create a large-scale semantics database, and
which has been shown to be superior to dictionary-based
synonyms and other methods [16] and is being increas-
ingly adopted by numerous research and commercial en-
deavors. Such superior analysis further largely mitigates
the problem of limited semantic information.
• System prototype. We design and implement an end-to-
end tool called AutoCog to automatically extract rele-
vant semantics from Android application descriptions and
permissions to produce permission models. These mod-
els are used to measure description-to-permission ﬁdelity:
given an application description, a permission model out-
puts whether the permission is expected to be declared

by that application. If the answer is yes, AutoCog fur-
ther provides relevant parts of description that warrant
the permission. This tool is published on Google Play2
and the backend data is available on our web portal3.

We further have the following evaluation and measure-

ment highlights.
• Evaluation. Our evaluation on a set of 1,785 applications
shows that AutoCog outperforms the previous work on
detection performance and ability of generalization over
various permissions by a large extent. AutoCog closely
aligns with human readers in inferring the evaluated per-
missions from textual descriptions with an average preci-
sion of 92.6% and average recall of 92.0% as opposed to
previous state-of-the-art precision and recall of 85.5% and
66.5% respectively.

• Measurements. Our ﬁndings on 45,811 applications us-
ing AutoCog show that the description-to-permissions
ﬁdelity is generally low on Google Play with only 9.1% of
applications having permissions that can all be inferred
from the descriptions. Moreover, we observe the negative
correlation between ﬁdelity and application popularity.

The remainder of this paper is organized as follows. Sec-
tion 2 gives further motivation of our work and presents a
brief background and problem statement. Next we cover
AutoCog design in detail in Section 3, followed by the im-
plementation aspects in Section 4. Section 5 deals with the
evaluation of AutoCog and introduces our measurement
results. We have relevant discussion and related work in
Sections 6 and 7. Finally, we conclude our work in Section 8.

2. BACKGROUND AND PROBLEM

STATE-MENT
2.1 Background

Android is the most popular smartphone operating system
with over 80% market share [1].
It introduces a sophisti-
cated permission-based security model, whereby an applica-
tion declares a list of permissions, which must be approved
by the user at application installation. These permissions
guard speciﬁc functionalities on the device, including some
security and privacy-sensitive APIs such as access contacts.
Modern operating systems such as Android, iOS, and Win-
dows 8 have brought about the advent of big, centralized ap-
plication stores that host third-party applications for users
to view and install. Google Play, the oﬃcial application
store for Android, hosts both free and paid applications to-
gether with a variety of metadata including the title and de-
scription, reviews, ratings, and so on. Additionally, it also
provides the user with the ability to study the permissions
requested by an application.
2.2 Problem Statement

The application descriptions on Google Play are a means
for the developers to communicate the application function-
ality to the users. From the security and privacy standpoint,
these descriptions should thus indicate the reasons for the

2https://play.google.com/store/apps/details?id=
com.version1.autocog
3http://python-autocog.rhcloud.com

1355permissions requested by an application, either explicitly or
implicitly4. We call it ﬁdelity of descriptions to permissions.
As stated in Section 1, Android applications often have
little in their descriptions to indicate to the users why they
need the permissions declared. Speciﬁcally, there is fre-
quently a gap between the access of the sensitive device APIs
by the applications and their stated functionality. This may
not always be out of malicious intent; however users are
known to be concerned about the use of sensitive permis-
sions [12]. Moreover, Felt et al. [14] show that few users are
careful enough or able to understand the security implica-
tions derived from the metadata. In this work we thus look
into the problem of automatically assessing the ﬁdelity of the
application descriptions with respect to the permissions.

Detection of malicious smartphone applications is possible
through static/run-time analysis of binaries [9, 18, 32]. How-
ever, the techniques to evaluate whether application over-
steps the user expectation are still lacking. Our tool can
assist the users and other entities in the Android ecosystem
assess whether the descriptions are faithful to the permis-
sions requested. AutoCog may be used by users or devel-
opers individually or deployed at application markets such as
Google Play. It may automatically alert the end users if an
application requests more permissions than required for the
stated functionalities. The tool can provide useful feedback
about the shortcomings of the descriptions to the develop-
ers and further help bolster the overall trustworthiness of
the mobile ecosystem by being deployed at the markets.

As for automatically measuring description-to-permission
ﬁdelity, we need to deal with two concepts: (a), the descrip-
tion semantics, which relates to the meaning of the descrip-
tion, and (b), the permission semantics, which relates to the
functionality provided (or protected) by the permission. The
challenges in solving our problem therefore lie in:
• Inferring description semantics: Same meaning may be
conveyed in a vast diversity of natural language text. For
example, the noun phrases “contact list”, “address book ”,
and “friends” share similar semantic meaning.
• Correlating description semantics with permission seman-
tics: A number of functionalities described may map to
the same permission. For example, the permission to
access user location might be expressed with the texts
“enable navigation”, “display map”, and “ﬁnd restaurant
nearby”. The need for permission to write to external disk
can be implied as “save photo” or “download ringtone”.
In AutoCog, we consider the decision version of the prob-
lem stated above: given a description and a permission, does
the description warrant the declaration of the permission? If
AutoCog answers yes, it provides the sentences that war-
rant the permission, thus assisting users in reasoning about
the requested permission. As a complete system, AutoCog
solves this decision problem for each permission declared.

Whyper [26] is a previous work with goals similar to ours.
Whyper correlates the description and permission seman-
tics by extracting natural language keywords from an exter-
nal source, Android API documents. Since APIs and per-
missions can be related together [2], the intuition is that
keywords and patterns expressed in the API documenta-
tion will also be found in the application descriptions and
are therefore adequate in representing the respective permis-

Figure 1: Overall architecture of AutoCog

sions. Based on our investigation, the methodology has the
following fundamental limitations:
• Limited semantic information: the API documents are
limited in the functionality they describe and so Whyper
cannot cover a complete set of semantic patterns corre-
lated with permissions. For example, in our ﬁndings, the
pattern <“deposit”, “check ”> is related to the permission
CAMERA with high conﬁdence but cannot be extracted
from API documents. The mobile banking applications,
such as Bank of America5, support depositing by snap-
ping its photo with the device’s camera. Analysis on this
issue in detail will be shown in Section 5.2.
• Lack of associated APIs: certain sensitive permissions such
as RECEIVE BOOT COMPLETED do not have any as-
sociated APIs [2]. It is thus not possible to generate the
correlated textual pattern set with the API documents.
• Lack of automation: Whyper’s extraction of patterns
from API documents involved manual selection to pre-
serve the quality of patterns; what policies could be used
to automate this process in a systematic manner is an
open question.

Our learning-based approach automatically discovers a set
of textual patterns correlated with permissions from the
descriptions of a rich set of applications, hence enabling
our description-to-permission relatedness model to achieve
a complete coverage over the natural language texts with
great diversity. Besides, the training process works directly
on descriptions. So we easily overcome the limitations of the
previous work as stated above.

3. SYSTEM DESIGN

Figure 1 gives an architectural overview of AutoCog.
The description of the application is ﬁrst processed by the
NLP module, which disambiguates sentence boundaries and
analyzes each sentence for grammatical structure. The out-
put of the NLP module is then passed in together with
the application permissions into the decision module, which,
based on models of description semantics and description-
to-permission relatedness outputs the questionable permis-
sions that are not warranted from the description and the
sentences from which the other permissions may be inferred.

4By implicit, we mean that the need for permission is evident
from stated functionality.

5https://play.google.com/store/apps/details?id=
com.infonow.bofa

App#Descrip*onDescrip*on-to-Permission#Relatedness#(DPR)#ModelDecisionDescrip*on#Seman*cs#(DS)#Model#(ESA)App#Permission<NP-counterpart,#Noun#Phrase>Seman*c#Relatedness#Labeled#SentencesQues*onable#PermissionsSentence#Boundary#Disambigua*on#(SBD)Gramma*cal#Structure#Analysis#(Stanford#Parser)#NLP#ModuleSentencesDescrip*on-to-Permission#Fidelity1356These outputs together provide description–to-permission ﬁ-
delity. This section provides a detailed design of each of the
modules and the models that constitute AutoCog.
3.1 NLP Module

The goal of the NLP module is to identify speciﬁc con-
structs in the description such as noun and verb phrases and
understand relationship among them. Use of such related
constructs alleviates the shortcomings of simple keyword-
based analysis. The NLP module consists of two compo-
nents, sentence boundary disambiguation and grammatical
structure analysis.
3.1.1 Sentence boundary disambiguation (SBD)
The whole description is split into sentences for subse-
quent sentence structure analysis [21, 30]. Characters such
as “.”, “:”, “-”, and some others like “*”, “♠”, “♦” that may
start bullet points are treated as sentence separators. Regu-
lar expressions are used to annotate email addresses, URLs,
IP addresses, Phone numbers, decimal numbers, abbrevia-
tions, and ellipses, which interfere with SBD as they contain
the sentence separator characters.
3.1.2 Grammatical structure analysis
We leverage Stanford Parser [31] to identify the grammat-
ical structure of sentences. While our design depends on
constructs provided by the Stanford Parser, it is conceivable
that other NLP parsers could be used as well.

We ﬁrst use the Stanford Parser to output typed dependen-
cies, which are semantic hierarchies of sentences, i.e., how
diﬀerent parts of sentences depend on each other. As illus-
trated in Figure 2, the dependencies are triplets: name of the
relation, governor and dependent. Part of Speech (PoS) tag-
ging additionally assigns a part-of-speech tag to each word;
for example, a verb, a noun, or an adjective. The results are
fed into phrase parsing provided by Stanford Parser to break
sentences into phrases, which could be noun phrases, verb
phrases or other kinds of phrases. We obtain a hierarchy of
marked phrases and tagged words for each sentence.

The governor-dependent pair provides the knowledge of
logic relationship between various parts of sentence, which
provides the guideline of our ontology modeling. The con-
cept of ontology is a description of things that exist and how
they relate to each other. In our experience, we ﬁnd the fol-
lowing ontologies, which are governor-dependent pairs based
on noun phrase, to be most suitable for our purposes.
• Logical dependency between verb phrase and noun phrase
potentially implies the actions of applications performing
on the system resources. For example, the pairs <“scan”,
“barcode”> and <“record”, “voice”> reveal the use of per-
missions camera and recording.
• Logical dependency between noun phrases is likely to show
the functionalities mapped with permissions. For instance,
users may interpret the pairs <“scanner”, “barcode”> and
<“note”, “voice”> as using camera and microphone.
• Noun phrase with own relationship (possessive, such as
“your”, followed by resource names) is recognized as re-
questing permissions. For example, the CAMERA and
RECORD AUDIO permissions could be revealed by the
pairs <“your”, “camera”> and <“own”, “voice”>.
We extract all the noun phrases in the leaf nodes of the hi-
erarchical tree output from grammatical structure analysis.
For each noun phrase, we record all the verb phrases and

Figure 2: Example output of Stanford Parser

noun phrases that are its ancestors or siblings of its ances-
tors. We also record the possessive, if the noun phrase itself
contains the own relationship. For the sake of simplicity,
we call the extracted verb phrases, noun phrases, and pos-
sessives as np-counterpart for the target noun phrase. The
noun-phrase based governor-dependent pairs obtained sig-
nify direct or indirect dependency. The example hierarchy
tree for sentence “Search for a place near your location as
well as on our interactive maps” is shown in Figure 2 with
the pairs extracted: <“search”, “interactive map”>, <“our”,
“interactive map”>, <“search”, “place”>, <“search”, “loca-
tion”>, <“place”, “location”>, and <“your”, “location”>.

We process these pairs to remove stopwords and named
entities. Stopwords are common words that cannot provide
much semantic information in our context, e.g., “the”, “and”,
“which”, and so on. Named entities include names of per-
sons, places, companies, and so on. These also do not com-
municate security-relevant information in our context. To
ﬁlter out named entities, we employ named entity recog-
nition, a well-researched NLP topic, also implemented in
Stanford Parser. The remaining words are normalized by
lowercasing and lemmatization [8]. Example normalizations
include “better” → “good” and “computers” → “computer”.
3.2 Description Semantics (DS) Model

The goal here is to understand the meaning of a natural
language description, i.e., how diﬀerent words and phrases in
a vocabulary relate to each other. Similarly meaning natural
language descriptions can diﬀer vastly; so such an analysis is
necessary. Our model is constructed using Explicit Semantic
Analysis (ESA), the state of the art for computing seman-
tic relatedness of texts [16]. The model is used directly by
the decision module and also for training the description-to-
permission relatedness model discussed in Section 3.3.

ESA is an algorithm to measure the semantic related-
ness between two pieces of text. It leverages big document
corpuses such as Wikipedia as its knowledge base and con-
structs a vector representation of text. In ESA, each (Wiki)
article is called a concept, and transformed into a weighted
vector of words within the article. As processing an input
article, ESA computes the relatedness of the input to ev-

Sample	  Sentence:	  "Search	  for	  a	  place	  near	  your	  loca/on	  as	  well	  as	  on	  our	  interac/ve	  maps"(ROOT	  	  (S	  	  	  	  (VP	  (VB	  Search	  -­‐	  1)	  	  	  	  	  	  (PP	  	  	  	  	  	  	  	  (PP	  (IN	  for	  -­‐	  2)	  	  	  	  	  	  	  	  	  	  (NP	  	  	  	  	  	  	  	  	  	  	  	  (NP	  (DT	  a	  -­‐	  3)	  (NN	  place	  -­‐	  4))	  	  	  	  	  	  	  	  	  	  	  	  (PP	  (IN	  near	  -­‐	  5)	  	  	  	  	  	  	  	  	  	  	  	  	  	  (NP	  (PRP$	  your	  -­‐	  6)	  (NN	  locaFon	  -­‐	  7)))))	  	  	  	  	  	  	  	  (CONJP	  (RB	  as	  -­‐	  8)	  (RB	  well	  -­‐	  9)	  (IN	  as	  -­‐	  10))	  	  	  	  	  	  	  	  (PP	  (IN	  on	  -­‐	  11)	  	  	  	  	  	  	  	  	  	  (NP	  (PRP$	  our	  -­‐	  12)	  (JJ	  interacFve	  -­‐	  13)	  (NNS	  maps	  -­‐	  14)))))))det(place-­‐4,	  a-­‐3)prep_for(Search-­‐1,	  place-­‐4)poss(locaFon-­‐7,	  your-­‐6)prep_near(place-­‐4,	  locaFon-­‐7)poss(maps-­‐14,	  our-­‐12)amod(maps-­‐14,	  interacFve-­‐13)prep_on(Search-­‐1,	  maps-­‐14)1357Table 1: Distribution of noun phrase patterns

Pattern

Noun

Noun + Noun

Adjective + Noun

Total

#Noun Phrase (Percentage %)

1,120,850 (52.37 %)

414,614(19.37 %)
278,785 (13.03 %)

1,814,249 (84.77 %)

Pattern of noun phrase; Number/percentage of
noun phrases in the pattern within 2,140,225

noun phrases extracted from 37,845 applications

ery concept, i.e. projects the input article into the concept
space, by the common words between them. In NLP and in-
formation retrieval applications, ESA computes the related-
ness of two input articles using the cosine distance between
the two projected vectors.

We choose ESA because it has been shown to outperform
other known algorithms for computing semantic relatedness
such as WordNet and latent semantic analysis [16]. We oﬀer
intuitive reasons of out-performance over WordNet as this
has been used in Whyper. First, WordNet-based methods
are inherently limited to individual words, and adoption for
comparing longer text requires an extra level of sophistica-
tion [24]. Second, considering words in context allows ESA
to perform word sense disambiguation. Using WordNet can-
not achieve disambiguation, since information about synsets
(sets of synonyms) is limited to a few words; while in ESA,
concepts are associated with huge amounts of text. Finally,
even for individual words, ESA oﬀers a much more detailed
and quantitative representation of semantics. It maps the
meaning of words/phrases to a weighted combination of con-
cepts, while mapping a word in WordNet amounts to simple
lookup, without any weight.
3.3 Description-to-Permission Relatedness

(DPR) Model

Description-to-permission relatedness (DPR) model is a
decisive factor in enhancing the accuracy of AutoCog. We
design a learning-based algorithm by analyzing the descrip-
tions and permissions of a large dataset of applications to
measure how closely a noun-phrase based governor-dependent
pair is related to a permission. The ﬂowchart for building
the DPR model is shown in Figure 3. We ﬁrst leverage ESA
to group the noun phrases with similar semantics. Next, for
each permission, we produce a list of noun phrases whose oc-
currence in descriptions is positively related to the declara-
tion of that permission. Such phrases may potentially reveal
the need for the given permission. In the third stage, we fur-
ther enhance the results by adding in the np-counterparts (of
the noun-phrase based governor-dependent pairs) and keep-
ing only the pairs whose occurrence statistically correlates
with the declaration of the given permission.

3.3.1 Grouping Noun Phrases
A noun phrase contains a noun possibly together with
adjectives, adverbs, etc. During the learning phase, since
analyzing long phrases is not eﬃcient, we consider phrases
of only three patterns: single noun, two nouns, and noun
following adjective (Table 1). In our dataset of 37,845 ap-
plications, these patterns account for 85% of the 302,739
distinct noun phrases. We further note that we focus on
these restricted patterns only during DPR model construc-
tion; all noun phrases are considered in the decision module
of AutoCog, which checks whether the description of ap-

Figure 3: Flowchart of description-to-permission re-
latedness (DPR) model construction

plication indicates a given permission. The DS model, which
is also employed during decision-making, can match longer
patterns with similarly meaning noun phrases grouped here.
Hence the negative eﬀect of such simpliﬁcation is negligible.
We construct a semantic relatedness score matrix leverag-
ing DS model with ESA. Each cell in the matrix depicts the
semantic relatedness score between a pair of noun phrases.
Deﬁne the frequency of noun phrase to be the number of
applications whose descriptions contain the noun phrase.
As constructing the semantic relatedness score matrix has
quadratic runtime, it is not scalable and eﬃcient. We ﬁl-
ter out noun phrases with low frequencies from this ma-
trix, as the small number of samples cannot provide enough
conﬁdence in our frequency-based measurement. If a low-
frequency phrase is similar to a high-frequency phrase, our
decision process will not be aﬀected as the decision module
employs DS model. We choose a threshold; only phrases
with frequency above 15 are used to construct the matrix.
The number of such phrases in our dataset is 9,428 (3.11%).
Using the semantic relatedness score matrix, we create a
relatedness dictionary, which maps a given noun phrase to
a list of noun phrases, all of which have a semantic related-
ness score higher than the threshold θg. The interpretation
is that the given noun phrase may be grouped with its list
of noun phrases as far as semantics is concerned. Our im-
plementation takes θg to be 0.67. The lists also record the
corresponding semantic relatedness scores for later use. A
sample dictionary entry of the noun phrase “map” is:
<“map”, [(“map”, 1.00), (“map view”, 0.96), (“interactive
map”, 0.89),...]>

3.3.2

Selecting Noun Phrases Correlated With Per-
missions

Whether a certain noun phrase is related to a permission
is learnt statistically from our dataset. If a permission perm
and a noun phrase np appear together (i.e., perm in permis-
sion declarations and np in the description) in a high num-
ber of applications, it implies a close relationship between
the two. This is however not trivial; some noun phrases
(e.g., “game” and “application”) may occur more frequently
than others, biasing such calculations. Moreover, some noun
phrases may actually be related to permissions but statisti-

Training'SetNLP'ModuleNoun'Phrases'(NP)NP7counterpartPermissionsRelatedness'DictionarySelect'NPPair'NP7counterpart'with'NPGroup'NPDescriptionOutput'ModelDPR'Model'Construction1358cal techniques may not correlate them if they occur together
in only a few cases in the dataset. The latter is partially re-
solved by leveraging the relatedness dictionary from the pre-
vious step. Based on existing data mining techniques [25],
we design a quality evaluation method that (a) is not biased
to frequently occurring noun phrases, and (b) takes into ac-
count semantic relatedness between noun phrases to improve
the statics of meaningful noun phrases that occurs less than
often. For the permission perm and the noun phrase np, the
variables in the learning algorithm are deﬁned as:
MP(perm, np): An application declares perm. Either np
or any noun phrase with the semantic relatedness score to
np above the threshold θg is found in the description. This
variable will increase by 1, if np is in the description, or it
will increase by the maximal relatedness score of the noun
phrase(s) related to np.
MMP(perm, np): An application does NOT declare perm.
Either np or any noun phrase with the semantic relatedness
score to np above the threshold θg is found in the description.
This variable will increase by 1, if np is in the description,
or it will increase by the maximal relatedness score of the
noun phrase(s) related to np.
PR(perm, np): The ratio of M P (perm, np) to the sum of
M P (perm, np) and M M P (perm, np):

P R(perm, np) =

M P (perm, np)

M P (perm, np) + M M P (perm, np)

.

AVGPR(perm): The percentage of all the applications in
our training set that request perm.
INCPR(perm, np): This variable measures the increment
of the probability that perm is requested with the presence
of np or its related noun phrases given the unconditional
probability as the baseline:

IN CP R(perm, np) =

P R(perm, np) − AV GP R(perm)

AV GP R(perm)

MMNP(perm, np): An application declares perm. This
variable will increase by 1, if none of np and noun phrases
related to it in the Relatedness Dictionary are found in the
description.
NPR(perm, np): The ratio of M P (perm, np) to the sum
of M P (perm, np) and M M N P (perm, np):

N P R(perm, np) =

M P (perm, np)

M P (perm, np) + M M N P (perm, np)

.

AVGNP(np): Expectation on the probability that one de-
scription contains np or related noun phrases over the train-
ing set. Assume the total number of applications is M . This
variable is expressed as:

AV GN P (np) =

Σi=M
i=1 λi
M

,

where λi equals 1, if np is in the description of the i-th ap-
plication. Or it equals to the maximal semantic relatedness
score of its related noun phrase(s) found in description. If
neither np nor noun phrases related to it in the Relatedness
Dictionary are found, λi = 0.
INCNP(perm, np): This variable measures the growth on
the probability that one description includes np or the re-
lated noun phrases with the declaration of perm given ex-
pectation as the baseline:

IN CN P (perm, np) =

N P R(perm, np) − AV GN P (np)

AV GN P (np)

Semantic relatedness score is taken as weight in the cal-
culations of variables M P (perm, np) and M M P (perm, np),
which groups the related noun phrases and resolves the mi-
nor case issue. We should note that IN CP R(perm, np) and
IN CN P (perm, np) evaluate the quality of np by the growth
of the probabilities that perm is declared and np (or noun
phrases related to np) is detected in description with the
average level as baseline. This design largely mitigates the
negative eﬀect caused by the intrinsic frequency of noun
phrase. To roundly evaluate the quality of np of describ-
ing perm, we deﬁne the Q(perm, np), which is the harmonic
mean of IN CP R(perm, np) and IN CN P (perm, np):

Q(perm, np) =

2 · IN CP R(perm, np) · IN CN P (perm, np)
IN CP R(perm, np) + IN CN P (perm, np)

.

np with negative values of IN CP R or IN CN P is discarded
as it shows no relevance to perm. Each permission has a list
of noun phrases, arranged in descending order by the quality
value. The top-k noun phrases are selected for the permis-
sion. We set k=500 after checking the distribution of quality
value for each permission. It is able to give a relatively com-
plete semantic coverage of the permission.
Increasing the
threshold k excessively would enlarge the number of noun-
phrase based governor-dependent pairs in the DPR model.
So it would reduce the eﬃciency of AutoCog in matching
the semantic meaning for the incoming descriptions.

3.3.3 Pair np-counterpart with Noun Phrase
By following the procedure presented in Section 3.3.2, we
can ﬁnd a list of noun phrases closely related to each permis-
sion. However, simply matching the permission with noun
phrase alone fails to explore the context and semantic de-
pendencies, which increases false positives. Although a noun
phrase related to “map” is detected in the example sentence
below, it does not reveal any location permission.
“Retrieve Running Apps” permission is required because, if
the user is not looking at the widget actively (for e.g. he
might using another app like Google Maps)”
To resolve this problem, we leverage Stanford Parser to get
the knowledge of context and typed dependencies. For each
selected noun phrase np, we denote as G(np) the set of noun
phrases that have semantic relatedness scores with np higher
than θg. Given a sentence in description, our mechanism
identiﬁes any noun phrase np(cid:48) ∈ G(np) and records each np-
counterpart nc (recall that np-counterpart was deﬁned as a
collective term for verb phrases, noun phrases, and posses-
sives for the target noun phrase), which has direct/indirect
relation with np(cid:48). For each noun-phrase based governor-
dependent pair < nc, np >, let the total number of descrip-
tions where the pair < nc, np(cid:48) > is detected be SP . In the
SP applications, let the number of application requesting
the permission is tc. We keep only those pairs for which
(1) tc/SP > P reT , (2) SP > F reT , where P reT and F reT
are conﬁgurable thresholds. Thus we maintain the precision
and the number of samples large enough to yield statistical
results with conﬁdence.
3.4 Decision

In DPR model, each permission has a list of related pairs
of np-counterpart ncdpr and noun phrase npdpr, which reveal
the security features of the permission. For an input appli-
cation whose description has to be checked, the NLP module
extracts the pairs of np-counterpart ncnew and noun phrase

.

.

1359npnew in each sentence. We leverage the DS model to mea-
sure the semantic relatedness score RelScore(txtA, txtB) be-
tween the two texts txtA and txtB. The sentence is identiﬁed
as revealing the permission, if < ncnew, npnew > is matched
with a pair < ncdpr, npdpr > by fulﬁlling the conduction:

RelScore(ncnew, ncdpr) > Υ,
RelScore(npnew, npdpr) > Θ.

Here, Υ and Θ are the thresholds of the semantic relatedness
score for np-counterparts and noun phrases. The sentences
indicating permissions will be annotated. Besides, Auto-
Cog ﬁnds all the questionable permissions, which are not
warranted in description.

IMPLEMENTATION

4.
NLP Module: We use the NLTK library in Python and reg-
ular expression matching to implement the SBD. NLTK is
also used for removing stopwords and normalizing words us-
ing lemmatization based on WordNet. Stanford Named En-
tity Recognizer is used for removing named entities.
DS and DPR Models: Noun phrases are classiﬁed by fre-
quency. High-frequency noun phrases are grouped based on
semantic relatedness score by utilizing the library esalib6.
This library is the only currently maintained, open-source
implementation of ESA that we could ﬁnd. Our training al-
gorithm on descriptions and permissions of large-scale appli-
cations selects the semantic patterns, which strongly corre-
late with the target permission by leveraging the frequency-
based measurement and ESA. Our current implementation
pairs np-counterpart of length one (noun, verb, and posses-
sive) with noun phrases. The np-counterpart could be easily
extended to multiple words, possibly with a few considera-
tions about maximum phrase length, and so on.

Overall, We implement AutoCog with over 7,000 lines of

code in Python and 500 lines of code in Java.

5. EVALUATION

We ﬁrst describe our dataset and methodology for col-
lecting sensitive permissions. Then, AutoCog’s accuracy is
evaluated by comparing with Whyper [26]. Finally, we dis-
cuss our measurements, which investigate the overall trust-
worthiness of market and the correlation between description-
to-permission ﬁdelity and application popularity.
5.1 Permission Selection and Dataset

The Android APIs have over a hundred permissions. How-
ever, some permissions such as the permission VIBRATE,
which enables vibrating the device, may not be as sensitive
as, for example, the permission RECORD AUDIO, which
enables accessing the microphone input.
It is not so use-
ful to identify permissions that are not considered sensitive.
The question to ask then is, what permissions are the users
most concerned about from the security/privacy perspective?
[12] surveyed 3,115 smartphone users about
99 risks and asked the participants to rate how upset they
would be if a given risk occurred. We infer 36 Android plat-
form permissions from the risks with highest user concerns.
Since we focus here on third-party applications, we ﬁrst re-
move from this list the Signature/System permissions, which
are granted only to applications that are signed with the

Felt et al.

Table 2: Permissions used in evaluation

Permission

#App (Percentage %)

WRITE EXTERNAL STORAGE

ACCESS FINE LOCATION

ACCESS COARSE LOCATION

GET ACCOUNTS

RECEIVE BOOT COMPLETED

CAMERA

GET TASKS

READ CONTACTS
RECORD AUDIO

CALL PHONE

WRITE SETTINGS
READ CALL LOG

WRITE CONTACTS
READ CALENDAR

30384 (80.29 %)
16239 (42.91 %)
15987 (42.24 %)
12271 (32.42 %)
9912 (26.19 %)
6537 (17.27 %)
6214 (16.42 %)
5185 (13.70 %)
4202 (11.10 %)
3130 (8.27 %)
3056 (8.07 %)
2870 (7.58 %)
2176 (5.74 %)
817 (2.16 %)

Permission name; Number/percentage of applications

request the permission within 37,845 applications;

device manufacturer’s certiﬁcate. Seven permissions were
removed as a result. The 29 remaining permissions are ar-
ranged in descending order by the percentage of applications
requesting it in our dataset, which is collected randomly. We
select the top 14 permissions in our evaluation, because the
ground-truth of our evaluation relies on readers to identify
whether sentences in application description imply sensitive
permissions; the consequent human eﬀorts make it diﬃcult
to review large number of descriptions.

We collected the declared permissions and descriptions of
37,845 Android applications from Google Play in August
2013 for the purpose of training the DPR model and evalu-
ate AutoCog’s accuracy. The permissions that constitute
the subject of our study can be divided into 3 categories ac-
cording to the abilities that they entail: (1) accessing user
privacy, (2) costing money, and (3) other sensitive function-
alities. Applications request the permissions to access pri-
vacy may leak users’ personal information such as location
to third parties without being awared. Permissions costing
money, such as CALL PHONE, may be exploited resulting
in ﬁnancial loss to the users. Other sensitive permissions
may change settings, start applications on boot, thus possi-
bly wasting phone’s battery, and so on. In Table 2, we list
the number and percentage of applications declaring each
permission in our dataset.

We also parsed the metadata of another 45,811 Android
applications from Google Play in May 2014 for our measure-
ments, which assess the description-to-permission ﬁdelity of
large-scale applications in Google Play and investigate the
correlation between description-to-permission ﬁdelity with
application popularity. The metadata include the following
features: category of application, developer of application,
number of installations, average rating, number of ratings,
descriptions and declared permissions of application.
5.2 Accuracy Evaluation

5.2.1 Methodology
Whyper studied three permissions: READ CALENDAR,
READ CONTACTS, and RECORD AUDIO; Their public
results are directly utilized7 as the ground-truth. The vali-
dation set contains around 200 applications for each of the
three permissions, where each sentence in the descriptions
is identiﬁed if revealing the permission by human readers.

6https://github.com/ticcky/esalib

7https://sites.google.com/site/whypermission/

1360Moreover, to assess AutoCog’s ability of generalization over
other permissions in Table 2, we further randomly select 150
applications requiring each one (except the three permissions
previously evaluated in public results of Whyper) as the
validation set. For each permission, the complementary set
of the validation set is used as the training set to construct
the DPR model, which ensures that the validation set is in-
dependent of the training set. To get the results of Whyper
on other permissions, we leverage the output of PScout [2]
and manually extract the semantic pattern set from Android
API document8 following the method presented by Pan-
dita et al. [26]. Whyper’s methodology does not work for
some permissions such as RECEIVE BOOT COMPLETED
as they do not have any associated API. To ensure the cor-
rectness of our understanding of Whyper’s methodology,
we contacted Whyper’s authors and conﬁrmed our under-
standing and conclusions. We also tested the system over
the applications in their public results and get exactly the
same output as those published, further validating the sys-
tem deployment (source code is released publicly).

Regarding the ground-truth of other permissions that we
extend to, we invite 3 participants who are not authors
of this paper to read the description and label each sen-
tence as whether or not it suggests the target permission.
The description will be classiﬁed as “good” when at least
two human readers could infer the permission by one sen-
tence in that, or it will be labeled as “bad”. Column Gd”
in Table 3 is the percentage of “good” descriptions for ap-
plications requesting each sensitive permission. The per-
centage values of “good” descriptions for the 3 permissions
GET TASKS, CALL PHONE, and READ CALL LOG are
lower than 10%. We call these permissions rarely described
well in descriptions, hidden permissions. The scarcity of
qualiﬁed descriptions leads to the lack of correlated semantic
patterns. It would hinder the measurement of description-
to-permission ﬁdelity. After removing the 3 hidden permis-
sions, our evaluation focuses on the other 11 permissions.

In training the DPR model, the two thresholds P reT and
F reT balance the performance on precision and coverage of
AutoCog. The settings in Table 3 depend on the percent-
age of applications requesting the permission in the training
set. For a permission with fewer positive samples (applica-
tion requires that permission), each pair of np-counterpart
and noun phrase related to it tends to be less dominant in
amount, we adjust F reT accordingly to maintain the per-
formance on recall. We keep P reT high across permissions,
which aims at enhancing the precision of detection.

Within the process of deciding if each application descrip-
tion in valuation set warrants permissions, we set the two
thresholds Υ=0.8 and Θ=0.67 by empirically ﬁnding the
best values for them. Low threshold reduces the perfor-
mance on precision and increasing the threshold excessively
causes the increment on false negatives. We set up the
threshold Θ lower than Υ, because noun phrases has more
diversity in patterns than np-counterparts; phrases contain-
ing various numbers of words organized in diﬀerent orders
may express the similar meaning.

Our objective is to assess how closely the decision made
by AutoCog on the declaration of permission approaches
human recognition given a description. The number of true
positives, false positives, false negatives, and true negatives

8http://pscout.csl.toronto.edu/download.php?file=
results/jellybean\_publishedapimapping

Table 3: Statistics and settings for evaluation
Gd(%)

Permission

GET ACCOUNTS

RECEIVE BOOT COMPLETED

WRITE EXTERNAL STORAGE

ACCESS FINE LOCATION

ACCESS COARSE LOCATION

CAMERA

GET TASKS

F reT

P reT
0.87
0.85
0.8
0.8
0.85
0.8
0.9
0.8
0.8
0.8
0.85
0.95
0.9
0.85
Hidden permissions are shadowed;

9
6
5
4
5
3
3
3
3
2
2
3
2
1

READ CONTACTS*
RECORD AUDIO*

CALL PHONE

WRITE SETTINGS
READ CALL LOG

WRITE CONTACTS
READ CALENDAR*

38.7
40.7
35.3
26.0
37.3
48.7
2.0
56.8
64.0
10.0
44.7
6.0
42.0
43.6

* sampled by around 200 applications, others by 150 applications

Figure 4: Interpretation of metrics in evaluation

are denoted as T P : the system correctly identiﬁes a descrip-
tion as revealing the permission, F P : the system incorrectly
identiﬁes a description as revealing the permission, F N : the
system incorrectly identiﬁes a description as not revealing
the permission, and T N : the system correctly identiﬁes a
description as not revealing the permission. Interpretation
of the metrics is shown in Figure 4.
Intersection of deci-
sions made by AutoCog and human is true positive. Diﬀer-
ence sets between decisions made by AutoCog and human
are false positive and false negative, respectively. Comple-
mentary set of the union of decisions made by AutoCog
and human is true negative. Values of precision, recall, F -
score, and accuracy represent the degree to which Auto-
Cog matches human reader’s recognition in inferring per-
mission by description.

P recision =

Recall =

F -score =

T P

T P + F P

T P

,

,

T P + F N
2 · P recision · Recall
P recision + Recall

,

Accuracy =

T P + T N

T P + F P + T N + F N

.

5.2.2 Results
Results of our evaluation are given in Table 4. AutoCog
matches human in inferring 11 permissions with the aver-
age precision, recall, F-score, and accuracy as 92.6%, 92.0%,
92.3%, and 93.2%. As discussed before, Whyper fails to get
results for permission RECEIVE BOOT COMPLETED. For

1361System
AutoCog WRITE EXTERNAL STORAGE

Permission

ACCESS FINE LOCATION

ACCESS COARSE LOCATION

GET ACCOUNTS

RECEIVE BOOT COMPLETED

CAMERA

READ CONTACTS
RECORD AUDIO
WRITE SETTINGS
WRITE CONTACTS
READ CALENDAR

Total

Whyper WRITE EXTERNAL STORAGE

ACCESS FINE LOCATION

ACCESS COARSE LOCATION

GET ACCOUNTS

RECEIVE BOOT COMPLETED

CAMERA

READ CONTACTS
RECORD AUDIO
WRITE SETTINGS
WRITE CONTACTS
READ CALENDAR

Total

5
4
4
5
5
6
9
11
2
6
6
63

47
30
25
30

47
19
23
8
10
7

246

86
86
96
107
88
70
77
62
76
83
105
936

84
88
96
109

73
73
62
59
78
95
817

89.8
95.0
98.0
89.5
89.5
90.5
95.2
92.1
90.3
93.4
94.0
92.6

57.9
96.9
96.6
81.8

91.4
93.4
92.5
87.2
91.1
91.8
91.7
91.4
97.0
90.5
92.9
92.0

19.0
50.8
52.8
23.1

Fail to get results

86.7
90.8
91.3
71.1
85.5
83.9
85.5

35.6
82.4
82.0
88.1
84.1
91.8
66.5

90.6
94.2
95.1
88.3
90.3
91.2
93.4
91.8
93.5
91.9
93.5
92.3

28.6
66.7
68.3
36.0

50.5
86.4
86.4
78.7
84.8
87.6
74.8

92.7
95.3
96.7
94.0
92.7
91.3
92.6
89.5
94.0
93.3
94.4
93.2

63.3
79.3
82.7
78.7

66.0
85.3
83.5
78.7
87.3
88.7
79.9

Table 4: Results of evaluation

F N T N P rec (%) Rec (%)

F (%) Accu (%)

T P
53
57
49
34
51
67
99
117
65
57
79
728

F P
6
3
1
4
6
7
5
10
7
4
5
58

11
31
28
9

26
89
105
59
53
78
489

8
1
1
2

4
9
10
24
9
15
83

the remaining 10 permissions, Whyper achieves the aver-
age precision, recall, F-score, and accuracy as 85.5%, 66.5%,
74.8%, and 79.9%.

Across the permissions evaluated, the least precision and
recall of AutoCog are 89.5% and 87.2%. Even for the cases
with low percentage of “good” descriptions and low num-
ber of positive samples (permissions GET ACCOUNT and
READ CALENDAR), our learning-based algorithm and em-
ployment of ESA could still get the DPR model aligning
with user’s recognition well. Whyper could only infer 5
permissions from description (last 5 in Table 4) with both
the values of precision and recall higher than 70%. For these
permissions, the API documents provide a relatively com-
plete and accurate semantic pattern set. The example pat-
terns such as <“scan”,“wiﬁ ”>, <“enable”,“bluetooth”>, and
<“set”,“sound ”> could be extracted from the API document
of the permission WRITE SETTINGS. However, Whyper
does not perform well on the other 5 permissions. Our un-
derstanding is that the patterns extracted from API docu-
ments in these cases are very limited to cover the natural-
language descriptions with great diversity. For example, the
APIs mapped with the permission to write to external stor-
age are related only to download management. Many in-
tuitive patterns, such as <“save”, “sd card ”>, <“transfer ”,
“ﬁle”>, <“store”, “photo”> cannot be found in its API doc-
ument. It is the same with <“scan”, “barcode”>, <“record ”,
“video”> for camera permission, <“integrate”, “facebook ”>
(in-app login) for permission to get user’s accounts, and
<“ﬁnd ”, “branch”>, <“locate”, “gas station”> for location
permissions. Given Whyper’s big variance of performance
and our investigation on its source of textual pattern set, we
ﬁnd that suitability of API document to generate a complete
and accurate set of patterns varies with permissions due to
the limited semantic information in APIs. AutoCog relies
on large number of descriptions in training, which would not
be restricted by the limited semantic information issue and
has stronger ability of generalization over permissions.

Whether or not the API documents are suitable for the
evaluated permissions, we note that AutoCog outperforms
Whyper on both precision and recall. Next we discuss

several case studies to thoroughly analyze the beneﬁts and
limitations of our design.
AutoCog TP/Whyper FN : The advantage of AutoCog
over Whyper on false negative rate (or recall) is caused by:
(1) the diﬀerence in the fundamental method to ﬁnd seman-
tic patterns related to permissions, (2) we include the logical
dependency between noun phrases as extra ontology. Why-
per is limited by the use of a ﬁxed and limited set of vocab-
ularies derived from the Android API documents and their
synonyms. Our correlation of permission with noun-phrase
based governor-dependent pair is based on clustering results
from a large application dataset, which is much richer than
that extracted from API documents. Below are 3 examples:
“Filter by contact, in/out SMS ”
“Blow into the mic to extinguish the ﬂame like a real candle”
“5 calendar views (day, week, month, year, list)”
The ﬁrst sentence describes the function of backing up SMS
by selected contact. The second sentence reveals a seman-
tic action of blowing into the microphone. The last sen-
tence introduces one calendar application, which provides
various views. In our DPR model, the noun-phrase based
governor-dependent pairs <ﬁlter, contact>, <blow, mic>,
and <view, calendar > are found to be correlated to the 3
permissions, READ CONTACTS, RECORD AUDIO, and
READ CALENDAR. While the semantic information for
the ﬁrst two sentences cannot be found by leveraging the
API documents. For the last one, Whyper could only de-
tect it, as “view ” and “calendar ” are tagged with verb and
noun, respectively (both of them are tagged as noun here).
AutoCog TN /Whyper FP: One major reason for this
diﬀerence in detection is that Whyper is not able to ac-
curately explore the meaning of noun phrase with multiple
words. Below is one example:
“Saving event attendance status now works on Android 4.0 ”
The sentence tells nothing about requiring the permission
to access calendar. However, Whyper incorrectly labels it
as revealing the permission READ CALENDAR, because it
parses resource name “event” and maps it with action “save”.
AutoCog diﬀerentiates the two phrases “ event attendance

1362status” and “event” by using ESA and eﬀectively ﬁlters the
interference in DPR model training and decision-making.
AutoCog FN /Whyper TP: This diﬀerence is caused by
the fact that some semantic patterns implying permissions
are not included in the DPR model. Below is one example:
“Ability to navigate to a Contact if that Contact has address”
Whyper detects the word “contact” as resource name and
maps it with the verb “navigate”. The sentence is thus iden-
tiﬁed as revealing the permission to read the address book.
However, no noun-phrase based governor-dependent pair in
our DPR model could be mapped to the permission sentence
above, because the pair <navigate, contact> is not domi-
nant in the training process. The DPR model might not
be knowledgeable enough to completely cover the semantic
patterns related to the permission. However, the coverage
could be enhanced as the size of training set increases.
AutoCog FP/Whyper TN : In the training process, some
semantic patterns, which do not directly describe the reason
for requesting the permission in the perspective of user ex-
pectation, are selected in the frequency-based measurement.
One example is given as:
“Set recordings as ringtone”
From this sentence, user could customize her/his ringtone
with recording, but it does not directly imply the functional-
ity of recording sound. Our model assigns a high relatedness
score between <set, recording> and RECORD AUDIO due
to quite a few training samples with related keywords and
this permission together. Such cases are due to the funda-
mental gap between machine learning and human cognition.
AutoCog and Whyper both leverage Stanford Parser
[31] to get the tagged words and hierarchal dependency tree.
The major cause of the common erroneous detection of two
systems (FP, FN ) is the incorrect parsing of sentence by
underlying NLP infrastructure, which has been well stated
by Pandita et al.
[26]. Thus, we would not discuss it in
detail given the page limit. As the research in the ﬁeld of
NLP advances underlying NLP infrastructure, the number
of such errors will be reduced.

We further list some representative semantic patterns in
Table 5, which are found to be closely correlated by our DPR
model to the permissions evaluated.

Apart from the accuracy of detection, the runtime latency
is a key metric in the practical deployment of AutoCog.
We select 500 applications requiring each permission and
assess the runtime latency of our system in measuring the
description-to-permission ﬁdelity. AutoCog achieves the
latency less than 4.5s for all the 11 permissions.

5.3 Measurement Results

Our measurements begin with assessing the overall trust-
worthiness of application market, which is depicted by the
distribution of questionable permissions. We utilize Auto-
Cog with the DPR model trained in the accuracy evalua-
tion to analyze 45,811 applications. The training set and
dataset for measurements are thus disjoint. The histogram
for distribution of questionable permissions is illustrated in
Figure 5. Only 9.1% of applications are clear of question-
able permissions. Moreover, we measure and observe the
negative spearman correlation [19] between the number of
questionable permissions of one application by a speciﬁc de-
veloper with the total number of applications published by
that developer (with r = −0.405, p < 0.001). A possible
explanation is that developer publishing more applications

Table 5: Sample semantic patterns

Permission

WRITE EXTERNAL STORAGE

ACCESS FINE LOCATION

ACCESS COARSE LOCATION

GET ACCOUNTS

RECEIVE BOOT COMPLETED

CAMERA

READ CONTACTS

RECORD AUDIO

WRITE SETTINGS

WRITE CONTACTS

READ CALENDAR

Semantic Patterns
<delete, audio ﬁle>

<convert, ﬁle format>
<download, ringtone>

<display, map>

<ﬁnd, branch atm>

<your, location>

<set, gps navigation>
<remember, location>
<inform, local traﬃc>

<manage, account>
<integrate, facebook >

<support, single sign-on>
<change, hd wallpaper >
<display, notiﬁcation>

<allow, news alert>

<deposit, check >

<scanner, barcode>

<snap, photo>

<block, text message>
<beat, facebook friend>

<backup, contact>

<send, voice message>

<note, voice>

<blow, microphone>

<set, ringtone>

<customize, alarm>
<enable, ﬂight mode>
<wipe, contact list>

<secure, text message>

<merge, speciﬁc contact>

<optimize, time>

<synchronize, calendar >
<schedule, appointment>

Table 6: Correlation between application popular-
ity and the number of questionable permissions and
permissions requested. All values are statistically
signiﬁcant with p<0.001

Permission Type #install #rating

avg rating

Correlation with application popularity

#Pq
#P

-0.106
0.044

-0.105
0.050

-0.110
0.044

are more experienced and likely to be a development team in
a company, who is more standardized and better regulated
at developing and deploying its mobile software. The above
results reﬂect the severity of the permission-to-description
ﬁdelity issue: application publishers, especially the new or
personal developer, generally fail to completely cover all
the sensitive permissions. The deployment of AutoCog
could thus assist developers produce applications with high
description-to-permissions ﬁdelity.

We further investigate the correlation between description-
to-permission ﬁdelity and application popularity. Applica-
tion popularity reveals the developers’ beneﬁt and users’
attitude towards the application, which thus plays a key
role in the interaction between users and developers.
In
our measurements, application popularity is interpreted by
the following features: number of installations (#install),
number of ratings (#rating), average ratings (avg rating).
Thus, we measure the (spearman) correlation between these
three features with the number of questionable permissions
(#Pq) and the number of permissions (#P ) requested by
application, respectively. Table 6 shows that there is a weak
positive correlation between application popularity and the
number of permissions requested, which is consistent with
the results in [5, 13]. It is because that rich functionality

1363For the implementation of AutoCog, we could possibly
improve the accuracy by including longer noun phrases and
np-counterparts. It is an eﬃciency-accuracy tradeoﬀ. The
evaluation of AutoCog also had some limitations. Manual
reading is subjective and the results may be biased. How-
ever, given that our readers have a technical background,
they may be able to discover many implicit relationships
that average users ignore, thus putting up greater challenges
for AutoCog. Given that whether a description implies a
permission itself is subjective and is consequently lack of
ground-truth, manual labeling is the best we can do here.

Malicious developers may provide wrong descriptions to
evade this approach. But it will be much easier for even
average users to ﬁnd such mismatch between the app’s de-
scription and its functionality. And given that most apps
are not malicious, such attacks will not aﬀect the training
of AutoCog.

7. RELATED WORK

NLP has been widely used in the security area. Potharaju
et al.
[28] propose an approach to analyzing natural lan-
guage text in network tickets to infer the problem symp-
toms and resolution actions. Some eﬀorts have focused on
automating mining of network failures from syslogs [29] and
network logs [22]. Compared with the network tickets and
logs, descriptions of applications have much more complex
structures and diverse contents, which largely increases the
diﬃculties of ontology modeling. For example, the developer
could choose to use either complete sentences or enumeration
lists in description;
introduction and contact of company
may be included for commercial purpose. There are also
approaches using a mix of NLP and learning algorithm to
infer speciﬁcations from API descriptions, code comments,
and formal requirement documents [27]. The methods pro-
posed in these papers require meta-information from source
code. Our design only needs the natural language text of
descriptions, which is not constrained by the availability of
source code and meta-information.

The permission system in Android security framework
manages the access of third-party applications to privacy-
and security-relevant parts of API. Many previous studies
analyze the permission system and resolve the overprivilege
issue [2, 11], confused deputy [6, 15, 7] and collusion attack
[4]. Moreover, some studies also investigate the eﬀective-
ness of permission model [13, 20]. Some researchers have
alluded to lack of correlation between permissions and de-
scriptions [3]; however, even if permissions and descriptions
do not correlate, our solution can bring an improvement to
the current situation. Lin et al.
[23] utilize crowdsourcing
collect users expectations of the permissions required by ap-
plication and Han et al.
[17] propose a text mining-based
similarity measure method to obtain similar security polices
among Android applications, which are both complimentary
to our work. While the static/run-time analysis of binaries
and programming language analysis enable these approaches
to detect overprivilege and confused deputy attack, the end
user does not have knowledge about why the permission is
requested or tools to assess whether applications overstep
user expectation. Our system analyzes the descriptions of
applications that the end user has direct and easy access
to and labels the sentences revealing sensitive permissions,
which enables users to know the reason for declaring the
permission in the semantic level.

Figure 5: Histogram for distribution of questionable
permissions

of application which implies the need of more permissions is
the main feature to drive application popularity.

However, we also ﬁnd the weak negative correlation be-
tween the number of questionable permissions and the pop-
ularity of application. We should note that all the measured
results achieve a p-value less than 0.001, which means the
statistical signiﬁcance. We have the following two guesses.
First, for the negative correlation, there are a small part
of users who are discreet enough or have the professional
knowledge to fully understand the security aspects of appli-
cation metadata [14]. They expect to get permission-related
information from the description. Thus the low description-
to-permission ﬁdelity negatively aﬀects their decisions of ap-
plication installation, application assessment, and interest
in applications. Secondly, such correlation is weak because
most average users cannot tell the questionable permissions
based on the description without a tool like AutoCog. Al-
though we could only conﬁrm correlation but not causation
here, we expect that wide adoption of AutoCog will help
average users to be more security conscious.

6. DISCUSSION

AutoCog measures the description-to-permission ﬁdelity
by ﬁnding relationships between textual patterns in the de-
scriptions and the permissions. Because of the state-of-the-
art techniques used and the new modeling techniques devel-
oped, AutoCog achieves good accuracy. Still, AutoCog
does have limitations because of the approach it uses and
the current implementation.

The models learnt in AutoCog are examples of unsuper-
vised learning, which has the drawback of picking relation-
ships that may not actually exist directly. If a noun phrase
appears frequently with a permission, the DPR model will
learn that they are actually related. For example, if many
antivirus applications use the permission GET TASKS, the
“antivirus” noun may become associated with this permis-
sion even if there is no direct relationship between the two.
From another perspective though, one could argue that this
is even better because AutoCog may be able to extract
implicit relationships that human readers may easily miss.
Anecdotally, for applications with permission GET TASKS
in our experiments, even if human readers could ﬁnd only
2% of applications whose descriptions reveal that permis-
sion, AutoCog ﬁnds 18% of such applications.

012345678910110510152025303540Distribution of Questionable Permissions#Questionable PermissionsPercentage of Applications (%)1364The most relevant work is Whyper [26], which is the only
previous work to our knowledge on bridging the gap be-
tween what user expects an application to do and what it re-
ally does. Our automatic learning-based approach works di-
rectly on large-scale descriptions to select noun-phrase based
governor-dependent pairs related to each permission. Thus
we would not come across the limitations of Whyper dis-
cussed in Section 2.2.

8. CONCLUSION

In this paper, we propose the system AutoCog that mea-
sures the description-to-permissions ﬁdelity in Android, i.e.,
whether the permissions requested by Android applications
match or can be inferred from the applications’ descrip-
tions. The use of a novel learning-based algorithm and
advanced NLP techniques allows us to mine relationships
between textual patterns and permissions. AutoCog out-
performs previous work on both performance of detection
and ability of generalization over permissions by a large ex-
tent. In inferring eleven permissions by description, our sys-
tem achieves the average precision of 92.6% and the aver-
age recall of 92.0% as compared to previous state-of-the-art
85.5% and 66.5%. Our measurements show a generally weak
description-to-permissions ﬁdelity on the Google Play store.

9. ACKNOWLEDGMENTS

This material is based upon work supported in part by
Qatar National Research Fund under award ID SP0022512.
Any opinions, ﬁndings, and conclusions or recommendations
expressed in this material are those of the authors and do
not necessarily reﬂect the views of the Qatar foundation.

10. REFERENCES
[1] Android Captures Record 81 Percent Share of Global

Smartphone Shipments in Q3 2013.
http://blogs.strategyanalytics.com/WSS/post/2013/10/
31/Android-Captures-Record-81-Percent-Share-of-
Global-Smartphone-Shipments-in-Q3-2013.aspx.

[2] K. W. Y. Au, Y. F. Zhou, Z. Huang, and D. Lie. Pscout:

analyzing the android permission speciﬁcation. In ACM
CCS, 2012.

[3] K. Benton, L. J. Camp, and V. Garg. Studying the

eﬀectiveness of android application permissions requests. In
IEEE PERCOM Workshops, 2013.

[4] S. Bugiel, L. Davi, A. Dmitrienko, T. Fischer, A.-R.

Sadeghi, and B. Shastry. Towards taming
privilege-escalation attacks on android. In NDSS
Symposium, 2012.

[5] P. H. Chia, Y. Yamamoto, and N. Asokan. Is this app

safe?: a large scale study on application permissions and
risk signals. In ACM WWW, 2012.

[6] E. Chin, A. P. Felt, K. Greenwood, and D. Wagner.

Analyzing inter-application communication in android. In
ACM MobiSys, 2011.

[7] M. Dietz, S. Shekhar, Y. Pisetsky, A. Shu, and D. S.

Wallach. Quire: Lightweight provenance for smart phone
operating systems. In USENIX Security Symposium, 2011.
[8] Q. Do, D. Roth, M. Sammons, Y. Tu, and V. Vydiswaran.

Robust, light-weight approaches to compute lexical
similarity. Computer Science Research and Technical
Reports, University of Illinois, 2009.

[9] W. Enck, P. Gilbert, B. Chun, L. Cox, J. Jung,

P. McDaniel, and A. Sheth. Taintdroid: An
information-ﬂow tracking system for realtime privacy
monitoring on smartphones. In USENIX OSDI, 2010.

[10] A. Felt, M. Finifter, E. Chin, S. Hanna, and D. Wagner. A
survey of mobile malware in the wild. In ACM SPSM, 2011.

[11] A. P. Felt, E. Chin, S. Hanna, D. Song, and D. Wagner.

Android permissions demystiﬁed. In ACM CCS, 2011.

[12] A. P. Felt, S. Egelman, and D. Wagner. I’ve got 99

problems, but vibration ain’t one: A survey of smartphone
users’ concerns. In ACM SPSM, 2012.

[13] A. P. Felt, K. Greenwood, and D. Wagner. The eﬀectiveness

of application permissions. In USENIX WebApps, 2011.

[14] A. P. Felt, E. Ha, S. Egelman, A. Haney, E. Chin, and

D. Wagner. Android permissions: User attention,
comprehension, and behavior. In ACM SOUPS, 2012.

[15] A. P. Felt, H. J. Wang, A. Moshchuk, S. Hanna, and

E. Chin. Permission re-delegation: Attacks and defenses. In
USENIX Security Symposium, 2011.

[16] E. Gabrilovich and S. Markovitch. Computing semantic

relatedness using wikipedia-based explicit semantic
analysis. In IJCAI, 2007.

[17] W. Han, Z. Fang, L. T. Yang, G. Pan, and Z. Wu.
Collaborative policy administration. IEEE TPDS,
25(2):498–507, 2014.

[18] P. Hornyack, S. Han, J. Jung, S. Schechter, and

D. Wetherall. These aren’t the droids you’re looking for:
retroﬁtting android to protect data from imperious
applications. In ACM CCS, 2011.

[19] M. G. Kendall. Rank correlation methods. 1948.
[20] K. Kennedy, E. Gustafson, and H. Chen. Quantifying the
eﬀects of removing permissions from android applications.
In IEEE MoST, 2013.

[21] T. Kiss and J. Strunk. Unsupervised multilingual sentence

boundary detection. Computational Linguistics,
32(4):485–525, 2006.

[22] C. Lim, N. Singh, and S. Yajnik. A log mining approach to

failure analysis of enterprise telephony systems. In IEEE
DSN, 2008.

[23] J. Lin, S. Amini, J. I. Hong, N. Sadeh, J. Lindqvist, and
J. Zhang. Expectation and purpose: understanding users’
mental models of mobile app privacy through
crowdsourcing. In ACM Ubicomp, 2012.

[24] R. Mihalcea, C. Corley, and C. Strapparava. Corpus-based
and knowledge-based measures of text semantic similarity.
In AAAI, 2006.

[25] D. L. Olson and D. Delen. Advanced data mining

techniques. Springer, 2008.

[26] R. Pandita, X. Xiao, W. Yang, W. Enck, and T. Xie.

Whyper: Towards automating risk assessment of mobile
applications. In USENIX Security, 2013.

[27] R. Pandita, X. Xiao, H. Zhong, T. Xie, S. Oney, and

A. Paradkar. Inferring method speciﬁcations from natural
language api descriptions. In IEEE ICSE, 2012.

[28] R. Potharaju, N. Jain, and C. Nita-Rotaru. Juggling the

jigsaw: Towards automated problem inference from
network trouble tickets. In USENIX NSDI, 2013.

[29] T. Qiu, Z. Ge, D. Pei, J. Wang, and J. Xu. What happened
in my network: mining network events from router syslogs.
In ACM SIGCOMM, 2010.

[30] J. C. Reynar and A. Ratnaparkhi. A maximum entropy

approach to identifying sentence boundaries. In Proceedings
of the ﬁfth conference on Applied natural language
processing, 1997.

[31] R. Socher, J. Bauer, C. D. Manning, and A. Y. Ng. Parsing
with compositional vector grammars. In Proceedings of the
ACL, 2013.

[32] L. K. Yan and H. Yin. Droidscope: seamlessly

reconstructing the os and dalvik semantic views for
dynamic android malware analysis. In USENIX Security
Symposium, 2012.

[33] Y. Zhou, Z. Wang, W. Zhou, and X. Jiang. Hey, you, get
oﬀ of my market: Detecting malicious apps in oﬃcial and
alternative android markets. In NDSS, 2012.

1365