XRay: Enhancing the Web’s Transparency with 

Differential Correlation

Mathias Lécuyer, Guillaume Ducoffe, Francis Lan, Andrei Papancea, Theofilos Petsios,  

Riley Spahn, Augustin Chaintreau, and Roxana Geambasu, Columbia University
https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/lecuyer

This paper is included in the Proceedings of the 23rd USENIX Security Symposium.August 20–22, 2014 • San Diego, CAISBN 978-1-931971-15-7Open access to the Proceedings of  the 23rd USENIX Security Symposium is sponsored by USENIXXRay: Enhancing the Web’s Transparency with Differential Correlation

Mathias L´ecuyer, Guillaume Ducoffe, Francis Lan, Andrei Papancea, Theoﬁlos Petsios,

Riley Spahn, Augustin Chaintreau, and Roxana Geambasu

Columbia University

Abstract

Today’s Web services – such as Google, Amazon, and
Facebook – leverage user data for varied purposes,
including personalizing recommendations,
targeting
advertisements, and adjusting prices. At present, users
have little insight into how their data is being used.
Hence, they cannot make informed choices about the
services they choose.

To increase transparency, we developed XRay,

the
ﬁrst ﬁne-grained, robust, and scalable personal data
tracking system for the Web. XRay predicts which
data in an arbitrary Web account (such as emails,
searches, or viewed products) is being used to target
which outputs (such as ads, recommended products, or
prices). XRay’s core functions are service agnostic and
easy to instantiate for new services, and they can track
data within and across services. To make predictions
independent of the audited service, XRay relies on the
following insight: by comparing outputs from different
accounts with similar, but not identical, subsets of data,
one can pinpoint targeting through correlation. We
show both theoretically, and through experiments on
Gmail, Amazon, and YouTube,
that XRay achieves
high precision and recall by correlating data from a
surprisingly small number of extra accounts.

Introduction

1
We live in a “big data” world. Staggering amounts
of personal data – our as locations, search histories,
emails, posts, and photos – are constantly collected and
analyzed by Google, Amazon, Facebook, and a myriad
of other Web services. This presents rich opportunities
for marshaling big data to improve daily life and social
well-being. For example, personal data improves the
usability of applications by letting them predict and
seamlessly adapt to future user needs and preferences.
It
improves business revenues by enabling effective
product placement and targeted advertisements. Twitter
data has been successfully applied to public health
problems [36], crime prevention [44], and emergency
response [22]. These beneﬁcial uses have generated a
big data frenzy, with Web services aggressively pursuing
new ways to acquire and commercialize it.

Despite its innovative potential,

the personal data
frenzy has transformed the Web into an opaque and
privacy-insensitive environment. Web services accumu-
late data, exploit it for varied and undisclosed purposes,
retain it for extended periods of time, and possibly share
it with others – all without the data owner’s knowledge
or consent. Who has what data, and for what purposes is
it used? Are the uses in the data owners’ best interests?
Does the service adhere to its own privacy policy? How
long is data used after its owner deletes it? Who shares
data with whom?

At present, users lack answers to these questions,
and investigators (such as FTC agents, journalists, or
researchers) lack robust tools to track data in the ever-
changing Web to provide the answers. Left unchecked,
the exciting potential of big data threatens to become a
breeding ground for data abuses, privacy vulnerabilities,
and unfair or deceptive business practices. Examples of
such practices have begun to surface. In a recent inci-
dent, Google was found to have used institutional emails
from ad-free Google Apps for Education to target ads in
users’ personal accounts [18, 37]. MySpace was found
to have violated its privacy policy by leaking personally
identiﬁable information to advertisers [25].
Several
consumer sites, such as Orbitz and Staples, were found
to have adjusted their product pricing based on user
location [29, 43]. And Facebook’s 2010 ad targeting was
shown to be vulnerable to micro-targeted ads specially
crafted to reveal a user’s private proﬁle data [23].

To increase transparency and provide checks and
balances on data abuse, we argue that new, robust, and
versatile tools are needed to effectively track the use of
personal data on the Web. Tracking data in a controlled
environment, such as a modiﬁed operating system, lan-
guage, or runtime, is an old problem with a well-known
solution: taint tracking systems [12, 16, 7, 48]. However,
is it possible to track data in an uncontrolled environ-
ment, such as the Web? Can robust, generic mechanisms
assist in doing so? What kinds of data uses are trackable
and what are not? How would the mechanisms scale
with the amount of data being tracked?

As a ﬁrst step toward answering these questions, we
built XRay, a personal data tracking system for the Web.

USENIX Association  

23rd USENIX Security Symposium  49

1

XRay correlates designated data inputs (be they emails,
searches, or visited products) with data outputs results
(such as ads, recommended products, or prices).
Its
correlation mechanism is service agnostic and easy to
instantiate, and it can track data use within and across
services. For example, it lets a data owners track how
their emails, Google+, and YouTube activities are used
to target ads in Gmail.

At its core, XRay relies on a differential correlation
mechanism that pinpoints targeting by comparing out-
puts in different accounts with similar, but not identical,
subsets of data inputs. To do so, it associates with every
personal account a number of shadow accounts, each of
which contains different data subsets. The correlation
mechanism uses a simple Bayesian model to compute
and rank scores for every data input that may have
triggered a speciﬁc output.
Intuitively, if an ad were
seen in many accounts that share a certain email, and
never in accounts that lack that email, then the email is
likely to be responsible for a characteristic that triggers
the ad. The email’s score for that ad would therefore be
high. Conversely, if the ad were seen rarely in accounts
with or lacking that email, that email’s score for this ad
would be low.

Constructing a practical auditing system around dif-
ferential correlation raises signiﬁcant challenges. Chief
among them is scalability with the number of data items.
Theoretically, XRay requires a shadow account for
each combination of data inputs to accurately pinpoint
correlation. That would suggest an exponential number
of accounts! Upon closer examination, however, we ﬁnd
that a few realistic assumptions and novel mechanisms
let XRay reach high precision and recall with only
a logarithmic number of accounts in number of data
inputs. We deem this a major new result for the science
of tracking data-targeting on the Web.

We built an XRay prototype and used it to correlate
Gmail ads, Amazon product recommendations, and
YouTube video suggestions to user emails, wish lists,
and previously watched videos, respectively. While
Amazon and YouTube provide detailed explanations of
their targeting, Gmail does not, so we manually vali-
dated associations. For all cases, XRay achieved 80-90%
precision and recall. Moreover, we integrated our Gmail
and YouTube prototypes so we could track cross-service
ad targeting.
Although several prior measurement
studies [10, 47, 21, 20, 31] used methodologies akin
to differential correlation, we believe we are the ﬁrst to
build a generic, service agnostic, and scalable tool based
on it. Overall, we make the following contributions:
1. The ﬁrst general, versatile, and open system to track
arbitrary personal Web data use by uncontrolled
services. The code is available from our Web page
https://xray.cs.columbia.edu/.

2. The ﬁrst

in-depth exploration into the scalability

challenges of tracking personal data on the Web.

3. The design and implementation of robust mechanisms

to address scaling, including data matching.

4. System instantiation to track data on three services
(Gmail, Amazon, YouTube) and across services
(YouTube to Gmail).

5. An evaluation of our system’s precision and recall on
Gmail, Amazon, and YouTube. We show that XRay
is accurate and scalable. Further, it reveals intriguing
practices now in use by Web services and advertisers.

2 Motivation
This paper lays the algorithmic foundations for a new
generation of scalable, robust, and versatile tools to
lift the curtain on how personal data is being targeted.
We underscore the need for such tools by describing
potential usage scenarios inspired by real-life examples
(§2.1). We do this not to point ﬁngers at speciﬁc service
providers; rather, we aim to show the many situations
where transparency tools would be valuable for end-
users and auditors alike. We conclude this section by
brieﬂy analyzing how current approaches fail to address
these usage scenarios (§2.2).
2.1 Usage Scenarios
Scenario 1: Why This Ad? Ann often uses her Gmail
ads to discover new retail offerings. Recently, she
discussed her ad-clicking practices with her friend Tom,
a computer security expert. Tom warned her about
potential privacy implications of clicking on ads without
knowing what data they target. For example, if she
clicks on an ad targeting the keyword “gay” and then
authenticates to purchase something from that vendor,
she is unwittingly volunteering potentially sensitive
information to the vendor. Tom tells Ann about two
options to protect her privacy. She can either disable
the ads altogether (using a system like AdBlock [1]),
or install the XRay Gmail plugin to uncover targeting
against her data. Unwilling to give up the convenience
of ads, Ann chooses the latter. XRay clearly annotates
the ads in the Gmail UI with their target email or
combination, if any. Ann now inspects this targeting
before clicking on an ad and avoids clicking if highly
sensitive emails are being targeted.
Scenario 2: They’re Targeting What? Bob, an FTC
investigator, uses the XRay Gmail plugin for a differ-
ent purpose:
to study sensitive-data targeting practices
by advertisers. He suspects a potentially unfair practice
whereby companies use Google’s ad network to collect
sensitive information about their customers. Therefore,
Bob creates a number of emails containing keywords
such as “cancer,” “AIDS,” “bankruptcy,” and “unemploy-
ment.” He refreshes the Gmail page many times, each
time recording the targeted ads and XRay’s explanations

50  23rd USENIX Security Symposium 

USENIX Association

2

for them. The experiment reveals an interesting result:
an online insurance company, TrustInUs.com, has tar-
geted multiple ads against his illness-related emails. Bob
hypothesizes that the company might use the data to set
higher premiums for users reaching their site through a
disease-targeted ad. He uses XRay results as initial evi-
dence to open an investigation of TrustInUs.com.
Scenario 3: What’s With The New Policy?1 Carla, an
investigative journalist, has set up a watcher on privacy
policies for major Web services. When a change occurs,
the watcher notiﬁes her of the difference. Recently, an
important sentence in Google’s privacy policy has been
scrapped:

If you are using Google Apps (free edition),
email is scanned so we can display concep-
tually relevant advertising in some circum-
stances. Note that
there is no ad-related
scanning or processing in Google Apps for
Education or Business with ads disabled.

To investigate scientiﬁcally whether this omission repre-
sents a shift in implemented policy, she obtains institu-
tional accounts, connects them to personal accounts, and
uses XRay to detect the correlation between emails in
institutional accounts and ads in corresponding personal
accounts. Finding a strong correlation, Carla writes an
article to expose the policy change and its implications.
Scenario 4: Does Delete Mean Delete? Dan, a
CS researcher, has seen the latest news that Snapchat,
an ephemeral-image sharing Website, does not destroy
users’ images after the requested timeout but instead just
unlinks them [41]. He wonders whether the reasons for
this are purely technical as the company has declared
(e.g., ﬂash wearing levels, undelete support, spam ﬁlter-
ing) [39, 38] or whether these photos, or metadata drawn
from them, are mined to target ads or other products
on the Website. The answer will inﬂuence his decision
about whether to continue using the service. Dan instan-
tiates XRay to track the correlation between his expired
Snapchat photos and ads.
2.2 Alternative Approaches
The preceding scenarios illustrate the importance of
transparency in protecting privacy across a range of
use cases. We need robust, generic auditing tools to
track the use of personal data at ﬁne granularity (e.g.,
individual emails, photos) within and across arbitrary
Web services. At present, no such tools exist, and the
science of tracking the use of personal Web data at a ﬁne
grain is largely non-existent.

1In Feb. 2014, it was revealed based on court documents that
Google could have used institutional emails to target ads in personal
accounts [18]. In May 2014, Google committed to disable that fea-
ture [30]. Scenario 3 presents an XRay-based approach to investigate
the original allegation.

Existing approaches can be broadly classiﬁed in
two categories: protection tools, which prevent Web
services’ acquisition or use of personal data, and (2)
auditing tools, which uncover Web services’ acquisition
or use of personal data. We discuss these approaches
next; further related work is in §9.
Protection Tools. A variety of protection tools ex-
ist [11, 35, 1, 49]. For example, Ann could disable ads
using an ad blocker [1]. Alternatively, she could en-
crypt her emails, particularly the sensitive ones, to pre-
vent Google from using them to target ads. Dan could
use a self-destructing data system, such as Vanish [14],
to ensure the ephemerality of his Snapchat photos.

While we encourage the use of protection tools, they
impose difﬁcult tradeoffs that make them inapplicable in
many cases. If Ann blocks all her ads, she cannot beneﬁt
from those she might ﬁnd useful; if she encrypts all of her
emails, she cannot search them; if she encrypts only her
sensitive emails, she cannot protect any sensitive emails
she neglected to encrypt in advance. Similarly, if Dan
encrypts his Snapchat photos, sharing them becomes
more difﬁcult. While more sophisticated protection
systems address certain limitations (e.g., searchable [5],
homomorphic [15, 33], and attribute-based encryp-
tion [19], or privacy-preserving advertising [42, 13]),
they are generally heavyweight [15], difﬁcult to use [45],
or require major service-side changes [15, 42, 13].
Auditing Tools. Given the limitations of protection
tools, transparency is gaining increased attention [47, 12,
21]. If protecting data proves too cumbersome, limiting,
or unsupportive of business needs, then users should at
least be able to know: (1) who is handling their data?,
and (2) what is it being used for?

Several tools developed in recent years partially ad-
dress the ﬁrst question by revealing where personal data
ﬂows from a local device [34, 12, 8]. TaintDroid [12]
uses taint tracking to detect leakage of personal data
from a mobile application to a service or third-party
backend. ShareMeNot [34] and Mozilla’s Lightbeam
Firefox add-on [27] identify third parties that are ob-
serving user activities across the Web. These systems
track personal data – such as location, sensor data, Web
searches, or visited sites – until it leaves the user’s
device. Once the data is uploaded to Web services, it
can be used or sold without a trace. In contrast, XRay’s
tracking just begins: we aim to tell users how services
use their data once they have it.

Several new tools and personalization measurement
studies partially address the second question: what
data is being used for [10, 47, 21, 20, 31]. In general,
all existing tools are highly specialized, focusing on
speciﬁc input types, outputs, or services. No general,
principled foundation for data use auditing exists, that
can be applied effectively to many services, a primary

USENIX Association  

23rd USENIX Security Symposium  51

3

52  23rd USENIX Security Symposium 

USENIX Association

motivationforthisourwork.Forexample,Bobble[47]revealssearchresultpersonalizationbasedonuserlocation(e.g.,IP)andsearchhistory.Moreover,existingtoolsaimtodiscoveronlywhethercertaintypesofuserinputs–suchassearchhistory,browsinghistory,IP,etc.–inﬂuencetheoutput.Nonepinpointsatﬁnegrainwhichspeciﬁcinput–whichsearchquery,whichvisitedsite,orwhichviewedproduct–orcombinationofinputsexplainwhichoutput.XRay,whosegoalswedescribenext,aimstodojustthat.3GoalsandModelsOuroverarchinggoalistodevelopthecoreabstractionsandmechanismsfortrackingdatawithinandacrossarbitraryWebsites.Afterdescribingspeciﬁcgoals(§3.1),wenarrowourscopewithasetofsimplifyingas-sumptionsregardingthedatausesthatXRayisdesignedtoaudit(§3.2)andthethreatsitaddresses(§3.3).3.1GoalsThreespeciﬁcgoalshaveguidedXRay’sdesign:Goal1:Fine-GrainedandAccurateDataTracking.Detectwhichspeciﬁcdatainputs(e.g.,emails)havelikelytriggeredaparticularoutput(e.g.,anad).Whilecoarse-graineddatauseinformation(suchasGmail’stypicalstatement,“Thisadisbasedonemailsfromyourmailbox.”)maysufﬁceattimes,knowingthespeciﬁcscanberevelatory,particularlywhentheinputishighlysensitiveandaggressivelytargeted.Goal2:Scalability.Makeitpracticaltotracksignif-icantamountsofdata(e.g.,pastmonth’semails).Weaimtosupportthetrackingofhundredsofinputswithreasonablecostsintermsofshadowaccounts.Theseac-countsaregenerallyscarceresourcesincetheircreationisbeingconstrainedbyWebservices.WhileweassumethatusersandauditorscanobtainsomeaccountsontheWebservicestheyaudit(e.g.,acoupledozen),westrivetominimizethenumberrequiredforaccurateandﬁne-graineddatatracking.Goal3:Extensibility,Generality,andSelf-Tuning.MakeXRaygenericandeasytoinstantiateformanyser-vicesandinput/outputtypes.InstantiatingXRaytotrackdataonnewsitesshouldbesimple,althoughitmayre-quiresomeservice-speciﬁcimplementationofinput/out-putmonitoring.However,XRay’scorrelationmachinery–theconceptuallychallengingpartofascalableauditingtool–shouldbeturnkeyandrequirenomanualtuning.3.2WebServiceModelThesegoalsmayappearunsurmountable.Anextremelyheterogeneousenvironment,theWebhasperhapsasmanydatausesasservices.Moreover,dataminingalgorithmscanbecomplexandproprietary.Howcanweabstractawaythisdiversityandcomplexitytodesignrobustandgenericbuildingblocksforscalabledata  associations (email→ad, viewed→recommend)one or more Web servicesdata inputs(emails, searches, viewed products)targeted outputs(ads, recommended products and videos)xRay (monitor, correlate)Figure1:XRayConceptualView.XRayviewsWebservicesasblackboxes,monitorsuserinputsandoutputsto/fromthem,anddetectsdatausethroughcorrelation.Itreturnstotheuserorauditorassociationsofspeciﬁcinputsandoutputs.tracking?Fortunately,weﬁndthatcertainpopularclassesofWebdatauseslendthemselvestoprincipledabstractionsthatfacilitatescalabletracking.Figure1showsXRay’ssimpliﬁedviewofWebser-vices.Services,andnetworksofservicesthatexchangeuserdata,areblackboxesthatreceivepersonaldatainputsfromusers–suchasemails,pictures,searchqueries,locations,orpurchases–andusethemforvariedpurposes.Someusesmaterializeintooutputsvisibletousers,suchasads,productorvideorecommendations,orprices.Othersinvisibletotheusers.XRaycorrelatessomevisibledatainputswithsomevisibleoutputsbymonitoringthem,correlatingthem,andreportingstrongassociationstousers.Anexampleassociationiswhichemail(s)contributedtotheselectionofaparticularad.XRayrelatesonlystronglycorrelatedinputswithoutputs.Ifanoutputisstronglycorrelatedtoaninput(i.e.,theinput’spresenceorabsencechangestheoutput),thenXRaywilllikelybeabletodetectitsuse.Ifnot(i.e.,themonitoredinputplaysbutasmallroleintheoutput),thenitmaygoundetected.XRayalsorelatessmallcombinationsofinputswithstronglycorrelatedoutputs.Althoughsimple,thismodelefﬁcientlyaddressesseveraltypesofpersonaldatafunctions,includingproductrecommendations,pricediscriminations,andvariouspersonalizationfunctions(e.g.,search,news).WerefertosuchfunctionsgenericallyastargetingfunctionsandfocusXRay’sdesignonthem.Threepopularformsoftargetingare:1.ProﬁleTargeting,whichleveragesstaticorslowlyevolvingexplicitinformation–suchasage,gender,race,orlocation–thattheuseroftensuppliesbyﬁll-ingaform.Thistypeoftargetinghasbeenstudiedprofusely[10,47,21,20,31];wethusignoreithere.2.ContextualTargeting,whichleveragesthecontentcurrentlybeingdisplayed.InGmail,thisisthecur-rentlyopenemailnexttowhichtheadisshown.InAmazonorYoutube,thetargetistheproductorvideonexttowhichtherecommendationisshown.3.BehavioralTargeting,whichleveragesauser’spastactions.Anemailsentorreceivedtodaycantrig-geranadtomorrow;avideowatchednowcantrig-4ger a recommendation later. Use of histories makes it
harder for users to track which data is being used, a
key motivation for our development of XRay.

Theoretically, our differential correlation algorithms
could be applied to all three forms of targeting. From
a systems perspective, XRay’s design is geared towards
contextual targeting and a speciﬁc form of behavioral
targeting. The latter requires further attention. We
observe that this broad targeting class subsumes multiple
types of targeting that operate at different granularities.
For example, a service could use as inputs a user’s
most recent few emails to decide targeting. This would
be similar to an extended context. Alternatively, a
service could use historical input to learn a user’s coarse
interests or characteristics and base its targeting on that.
XRay currently aims to disclose any targeting applied
at the level of individual user data, or small combinations
thereof. Our differential correlation algorithms could
be applied to detect targeting that operates on a coarser
granularity. However, the XRay system itself would
require signiﬁcant changes. Unless otherwise noted, we
use behavioral targeting to denote the restricted form of
behavioral targeting that XRay is designed to address.
We formalize these restrictions in §4.2.
3.3 Threat Model
To further narrow our problem’s scope, we introduce
threat assumptions. We assume that data owners (users
and auditors) are trusted and do not attempt to leverage
XRay to harm Web services or the Web ecosystem.
While they trust Web services with their data, they wish
to better understand how that data is being used. Data
owners are thus assumed to upload the data in clear text
to the Web services.

The threat models relevant for Web services depend
on the use case. For example, Scenarios 1 and 2 in
§2.1 assume Google is trusted, but its users wish to
understand more about how advertisers target
them
through its ad platform. In contrast, in Scenarios 3 and
4, investigators may have reason to believe that Web
services might intentionally frustrate auditing.

This paper assumes an honest-but-curious model for
Web services: they try to use private data for ﬁnancial
or functional gains, but they do not try to frustrate our
auditing mechanism, e.g., by identifying and disabling
shadow accounts. The service might attempt to defend
itself against more general types of attacks, such as
spammers or DDoS attacks. For example, many Web
services constrain the creation of accounts so as to limit
spamming and false clicks. Similarly, Web services may
rate limit or block the IPs of aggressive data collectors.
XRay must be robust to such inherent defenses. We
discuss challenges and potential approaches for stronger
adversarial models in §7.

4 The XRay Architecture
XRay’s design addresses the preceding goals and
For concreteness, we draw examples
assumptions.
from our three XRay instantiations:
tracking email-
to-ad targeting association within Gmail, attributing
recommended videos to those already seen on YouTube,
and identifying products in a wish list that generate a
recommendation on Amazon.
4.1 Architectural Overview
XRay’s high-level architecture (Figure 2) consists
of three components:
(1) a Browser Plugin, which
intercepts tracked inputs and outputs to/from an audited
Web service and gives users visual feedback about
any input/output associations, (2) a Shadow Account
Manager, which populates shadow accounts with inputs
from the plugin and collects outputs (e.g., ads) for each
shadow account, and (3) the Correlation Engine, XRay’s
core, which infers associations and provides them to
the plugin for visualization. While the Browser Plugin
and Shadow Account Manager are service speciﬁc, the
Correlation Engine, which encapsulates the science
of Web-data tracking, is service agnostic. After we
describe each component, we focus on the design of the
Correlation Engine.
Browser Plugin. The Browser Plugin intercepts desig-
nated inputs and outputs (i.e., tracked inputs/outputs) by
recognizing speciﬁc DOM elements in an audited ser-
vice’s Web pages. Other inputs and outputs may not be
tracked by XRay (i.e., untracked inputs/outputs). The
decision of what to track belongs to an investigator or
developer who instantiates XRay to work on a speciﬁc
service. For example, we conﬁgure the XRay Gmail Plu-
gin to monitor a user’s emails as inputs and ads as out-
puts. When the Plugin gets a new tracked input (e.g., a
new email), it forwards it both to the service and to the
Shadow Account Manager. When the Plugin gets a new
tracked output (e.g., an ad), it queries the Correlation En-
gine for associations with the user’s tracked inputs (mes-
sage get assoc).
Shadow Account Manager. This component: (1) pop-
ulates the shadow accounts with subsets of a user ac-
count’s tracked inputs (denoted Di), and (2) periodically
retrieves outputs (denoted Ok) from the audited service
for each shadow account. Both functions are service spe-
ciﬁc. For Gmail, they send emails with SMTP and call
the ad API. For YouTube, they stream a video and scrape
recommendations, and for Amazon, they place products
in wish lists and scrape recommendations. The complex-
ity of these tasks depends on the availability of APIs or
the stability of a service’s page formats. Outputs col-
lected from the Web service are placed into a Correlation
Database (DB), which maps shadow accounts to their in-
put sets and output observations. Figure 2 shows a par-

USENIX Association  

23rd USENIX Security Symposium  53

5

54  23rd USENIX Security Symposium 

USENIX Association

  Browser(User Acct.)D1D2D3O1O2all inputsall outputsShadow Account Manager(service-specific)associations(D2→O1)DifferentialCorrelation Engine(service-agnostic) CorrelationAlgorithmInputPlacementInputMatchingtracked inputsoutputstracked inputsUser Acct.D1D2D3Shadow Acct. 1D1D2Shadow Acct. 2D2D3Shadow Acct. 3D1D3Correlation DBget_assoc(D2)XRay plugin(service-specific)XRayAudited Web ServiceShadow AccountTracked InputsTracked OutputsShadow 1Shadow 2Shadow 3D1D2D2D3D1D3O1O2O1Figure2:TheXRayArchitecture.ticularassignmentoftrackedinputsacrossthreeshadowaccounts.Forexample,Shadow1hasinputsD1andD2.Theﬁgurealsoshowstheoutputscollectedforeachshadowaccount.OutputO1appearsinShadows1and2butnotin3;outputO2appearsinShadow3only.DifferentialCorrelationEngine.Thisengine,XRay’sservice-agnostic“brain,”leveragesthedatacollectedintheCorrelationDBtoinferinput/outputassociations.WhennewoutputsfromshadowaccountsareaddedintotheCorrelationDB,theengineattemptstodiagnosethemusingaCorrelationAlgorithm.Wedevelopedseveralsuchalgorithmsanddescribethemin§4.3.Thisprocess,potentiallytime-consumingprocess,isdoneasaback-groundjob,asynchronouslyfromanyuserrequest.InFigure2,differentialcorrelationmightconcludethatD2triggersO1becauseO1appearsconsistentlyinaccountswiththatD2.ItmightalsoconcludethatO2isuntargetedgiveninconsistentobservations.TheenginesavestheseassociationsintheCorrelationDB.Whenthepluginmakesagetassocrequest,theCorrelationEnginelooksupthespeciﬁedoutputinitsDBandreturnsanypre-computedassociation.Ifnoout-putisfound,thentheenginerepliesunknown(e.g.,ifanadneverappearedinanyshadowaccountorthereisin-sufﬁcientinformation).Periodicdatacollection,coupledwithanonlineupdateofcorrelationmodelparameters,minimizesthenumberofunknownassociations.OurexperienceshowsthatcollectingshadowaccountoutputsinGmaileverytenhoursorsoyieldedfewunknownads.Whiletheprecedingexampleissimple,XRaycanhandlecomplexchallengesoccurringinpractice.First,outputsareneverconsistentlyseenacrossallshadowaccountscontainingtheinputtheytarget.Wecallthisthelimited-coverageproblem;XRayhandlesitbyplacingeachdatainputinmoreshadowaccounts.Second,anoutputmayhavebeentriggeredbyoneofseveraltargetedinputs(e.g.,multipleemailsonthesametopicmaycauserelatedadstoappear),aproblemwerefertoasoverlapping-inputs.Thisexacerbatesthenumberofaccountsneeded,sinceitdiminishesthedifferentialsignalwereceivefromthem.XRayusesrobust,service-agnosticmechanismsandalgorithmstomatchoverlappinginputs,placetheminthesameaccounts,anddetectstheiruseasagroup.Organization.TheremainderofthissectiondescribestheDifferentialCorrelationEngine.AfterconstructingitforGmail,weapplieditas-isforAmazonandYouTube,whereitachievedequallyhighaccuracyandscalabilitydespiteobservabledifferencesinhowtargetingworksonthesethreeservices.Afterestablishingnotationsandfor-malizingourassumptions(§4.2),wedescribemultiplecorrelationalgorithms,whichbuilduptoourself-tuningcorrelationalgorithmthatmadethisadaptationconve-nient(§4.3).§4.4describesourinputmatching.4.2NotationandAssumptionsWeuseftodenotetheblack-boxfunctionthatrepre-sentstheservice(e.g.,Gmail)associatinginputsDis(e.g.,theemailsreceivedandsent)totargetedoutputsOks(e.g.,ads).OtherinputsareeitherignoredbyXRay,knownonlytothetargetingsystem,orundernoknowncontrol.Weassumetheyareindependentorﬁxed,capturedintherandomnessoff.Weassumethatfdecidestargetingusing:(1)asingleinput(e.g.,showOkifD4isintheaccount),(2)aconjunctivecombinationofinputs(e.g.,showOkifD5andD8areintheaccount),or(3)adisjunctivecombinationoftheprevious(e.g.,showOkif(D5andD8)areintheaccountorifD4isintheaccount).WerefertoconjunctiveanddisjunctivecombinationsasANDandORcombinations,respectively,andassumethattheirisboundedbyamaximuminputsize,r.Thiscorrespondstotheprecedingdeﬁnitionofbehavioraltargetingfrom§3.2.Contextualtargetingwillalwaysbeasingle-input(size-one)combination.OurgoalistodecidewhetherfproducedeachoutputOkasareactiontoabounded-sizecombinationoftheDis.WedeﬁneasuntargetedanyadthatisnottargetedagainstanycombinationofDis,thoughinrealitytheadcouldbetargetedagainstuntrackedinputs.WedenoteuntargetingasD/0,meaningthattheadistargetedagainstthe“void”email.OuralgorithmscomputethemostlikelycombinationfromtheNinputsthatexplainsaparticularsetofobservations,(cid:31)x,obtainedbyXRay.Wedeﬁnethreeprobabilitiesuponwhichouralgo-rithmsandanalysesdepend.First,thecoverage,pin,istheprobabilitythatanaccountjcontainingtheinputDitargetedbyaparticularad,willseethatadatleastonce.Second,anaccountj(cid:30)lackinginputDiwillseetheadwithasmallerprobability,pout.Third,iftheadisnotbehaviorallytargeted,itwillappearineachaccountwiththesameprobability,p/0.Weassumethatpin,p/0,poutare6constant across all emails, ads, and time, and that pout is
strictly smaller than pin (bounded noise hypothesis).

Finally, we consider all outputs to be independent of

each other across time. §8 discusses the implications.
4.3 Correlation Algorithms
A core contribution of this paper is our service-agnostic,
self-tuning differential correlation algorithm, which
requires only a logarithmic number of shadow accounts
to achieve high accuracy. We wished not only to validate
this result experimentally, but also to prove it theoreti-
cally in the context of our assumptions. This section con-
structs the algorithm in steps, starting with a na¨ıve poly-
nomial algorithm that illustrates the scaling challenges.
We then deﬁne a base algorithm using set intersections
and prove that it has the desired logarithmic scaling prop-
erties; it has parameters which, if not carefully chosen,
can lead to poor results. We therefore extend this base
algorithm into a self-tuning Bayesian model that auto-
matically adjusts its parameters to maximize correctness.
4.3.1 Na¨ıve Non-Logarithmic Algorithm
An intuitive approach to differential correlation is to
create accounts for every combination of inputs, gather-
ing maximum information about their behaviors. With
a sufﬁcient number of observations, one could expect
to detect which accounts, and hence which subsets of
inputs, target a particular ad. Unfortunately, this method
requires a number of accounts that grows exponentially
as the number of items N to track grows. When restrict-
ing the size of combinations to r, as we do in XRay, the
number of accounts needed is polynomial (in O(Nr)),
or linear if we study unique inputs only. Even a linear
number of accounts in the number N of inputs remains
impractical to scale to large input sizes (e.g., a mailbox).
4.3.2 Threshold Set Intersection
We now show that it is possible to infer behavioral
targeting using no more than a logarithmic number
of accounts as a function of the number of inputs.
Speciﬁcally, we prove the following theorem:

Theorem 1 Under §4.2 assumptions, for any ε > 0 there
exists an algorithm that requires C × ln(N) accounts
to correctly identify the inputs of a targeted ad with
probability (1 − ε). The constant C depends on ε and
the maximum size of combinations r (O(r2r log( 1

ε ))).

To demonstrate the theorem, we deﬁne the Set Inter-
section Algorithm and prove that it has the correctness
and scaling properties speciﬁed in the theorem. Given
that outputs will appear more often in accounts con-
taining the targeting inputs, the core of the algorithm is
to determine the set of inputs appearing in the highest
number of accounts that also see a given ad. This paper
describes a basic version of the algorithm that makes





// Set Intersection Algo:
// Runs with each collected ad.
In: Output Ok (e.g. an ad).
Params: MIN ACTIVE ACCTS, THRESHOLD.
Out: Targeted input combination.
// Step 1: Compute active accounts.
Ak = the accounts that see ad Ok.
if |Ak| < MIN ACTIVE ACCTS
end
// Step 2: Create input combination hypothesis.
targeted set = /0
foreach input Di do
|Ak|

if number o f Ak containing Di

>THRESHOLD

return /0

targeted set += Di

end

end
// Step 3: Verify it is a real combination.
if number o f Ak containing entire targeted set

return /0

|Ak|

end
// targeted set triggered the output.
return targeted set





<THRESHOLD

Figure 3: The Set Intersection Algorithm. Can be proven
to predict targeting correctly under certain assumptions with a
logarithmic number of accounts.

some simplifying assumptions and provides a brief proof
sketch. The detailed proof and complete algorithm are
described in our technical report [26].

Algorithm. The algorithm relies on a randomized place-
ment of inputs into shadow accounts, with some redun-
dancy to cope with imperfect coverage. We thus pick a
probability, 0 < α < 1, create C ln(N) shadow accounts,
and place each input Di randomly into each account with
probability α. Figure 3 shows the Set Intersection algo-
rithm for a set of observations, (cid:29)x. Given an output Ok
collected from the user account, we compute the set of
active accounts, Ak, as those shadow accounts that have
seen the output (Step 1). We then compute the set of in-
puts that appear in at least a threshold fraction of active
accounts; this set is our candidate for the combination
being targeted by the ad (Step 2). Finally, we check that
the entire combination is in a threshold fraction of the ac-
tive accounts (Step 3). Theoretically, we prove that there
exists a threshold for which the algorithm is arbitrarily
correct with the available C ln(N) accounts. Practically,
this threshold must be tuned experimentally to achieve
good accuracy on every service – a key reason for our
Bayesian enhancement in §4.3.3.
Correctness Proof Sketch. The proof shows that if there
were targeting, every non-targeting input would have a
vanishingly small probability to be in a signiﬁcant frac-
tion of the active accounts. Let us call S the set of inputs

USENIX Association  

23rd USENIX Security Symposium  55

7




foreach output Ok do

Run Bayesian Prediction.

// Parameter Learning Alg:
// Runs periodically.
// Initialize params (arbitrary).
pin = .7,pout = .01,p/0 = .1
do

// Bayesian Prediction Alg:
// Runs with each collected ad.
In: Output Ok (e.g. an ad).
Out: Targeted input.
// Compute probabilities.
foreach input Di do
P [Di| (cid:31)x ] = bayes(P [(cid:31)x| Di ])
end
// Compute untargeted prob.
P [D/0| (cid:31)x ] = bayes(P [(cid:31)x| D/0 ])
// Return event with max prob.
return Di with max P [Di| (cid:31)x ]
Figure 4: Bayesian Correlation. Left: Bayesian prediction
algorithm for behavioral targeting. Right:
typical iterative
inference process to learn parameters.

end
Update pin, pout, p/0
from predictions.

until pin, pout, p/0 converge


end

contained in a signiﬁcant fraction of the active accounts.
Without targeting, these inputs would be present in the
accounts by mere chance. Since inputs are independently
distributed into the accounts, we show that the probabil-
ity of S not being empty decreases exponentially with the
number of active accounts (through Chernoff bounds).
With targeting, we show that with high probability no
other input than the explaining combination is in S, be-
cause of the bounded noise hypothesis. Appendix A.2
provides further proof details.

The proofs and algorithm included in this paper work
only for conjunctive combinations (e.g., D1 and D2,
see §4.2). The theory, however, can be extended to
disjunctive combinations (e.g., (D1 and D2) or D5), but
the algorithm for detecting such combinations is more
complex and relies on a recursive argument: if we ﬁnd
one combination from the disjunction, then the active
accounts that include this combination deﬁne a context
where the combination appears non-targeting because it
is everywhere. If we recursively apply our algorithm in
this context, we can detect the second combination in the
disjunction, then the third, etc (see technical report [26]).
4.3.3 Self-Tuning Bayesian Algorithm
The Set Intersection algorithm provides a good the-
oretical foundation; however,
it requires parameters
be tuned and applies only to behavioral targeting, not
contextual targeting. Thus, we include in XRay a more
robust, self-tuning version that leverages a Bayesian
algorithm to adjust parameters automatically through
iterated inference. Our algorithm relies on three models:
one that predicts behavioral targeting, one that predicts
contextual targeting, and one that combines the two.
Behavioral Targeting. The Bayesian behavioral tar-
geting model uses the same random assignment as the
Set Intersection algorithm, and it leverages the same in-
formation from the shadow account observations, (cid:31)x. It
counts the observations x j of ad Ok in an account j as
a binary signal: if the ad has appeared at least once in





account j, we count it once; otherwise we do not count
it. Brieﬂy, the Bayesian model is a simple generative
model that simulates the audited service given some tar-
geting associations (e.g., Di triggers Ok). It computes the
probability for this model to generate the outputs we do
observe for every targeting association. The most likely
association will be the one XRay returns.

In more detail if the ad were targeted towards Di, then
j containing Di would see this ad at least
an account
once with a coverage probability pin; otherwise, it would
miss it with probability (1− pin). An account j(cid:28) without
input Di would see the ad with a smaller probability,
pout, missing it with probability (1 − pout).
If the ad
were not behaviorally targeted, it would appear in each
account with the same probability, p/0. If we deﬁne Ak as
the set of active accounts that have seen the ad, and Ai as
the set of accounts that contain email Di, then we have
the following deﬁnitions for the probabilities:
P [(cid:31)x| Di ] = (pin)|Ai∩Ak| (1− pin)|Ai∩ ¯Ak|
P [(cid:31)x| D/0 ] = (p/0)|Ak| (1− p/0)| ¯Ak| ,

× (pout)| ¯Ai∩Ak| (1− pout)| ¯Ai∩ ¯Ak| ,

where D/0 designates the untargeted prediction.

The preceding formula has an interesting interpreta-

tion that is visible if placed in the equivalent form:

P [(cid:31)x| Di ] = (pin)|Ak| (1− pout)| ¯Ak|

1− pout(cid:30)|Ai∩ ¯Ak|(cid:31) pout
×(cid:31) 1− pin

pin(cid:30)| ¯Ai∩Ak|
From the point of view of the event Di, an account found
in Ai ∩ ¯Ak is a false positive (an ad was expected but was
not shown). This should lower the probability, especially
when the coverage pin is close to 1. Inversely, an account
found in ¯Ai ∩ Ak acts as a false negative (we observed an
ad where we did not expect it), which should decrease
the probability, especially when pout is close to 0.
These formulas let us infer the likelihood of event
Di according to Bayes’ rule: P [A| B ] = P [B| A ]×P [A ]
.
Figure 4 shows two algorithms. First, the prediction al-
gorithm (left) predicts the targeting of Ok by computing
the probabilities deﬁned above, applying Bayes’ rule,
and returning the input with the maximum probability.
Second, the parameter learning algorithm (right) com-
putes the variables that those probabilities depend upon
(pin, pout, and p/0) using an iterative process. It repeat-
edly runs the prediction algorithm for all outputs and
re-computes pin, pout, and p/0 based on the predictions.
It stops when the variables converge (i.e., their variation
from one iteration to another is small).
Contextual Targeting. Contextual targeting is more
straightforward since it uses content shown next to the
ad. XRay also uses Bayesian inference and deﬁnes the
observations as how many times ad Ok is seen next to

P [B ]





8

56  23rd USENIX Security Symposium 

USENIX Association

Input Matching and Placement

email Di. Our causal model assumes imperfect coverage:
if this ad were contextually targeted towards Di, it would
occur next to that email with probability pin < 1 and next
to any other email with probability pout. Alternatively,
if the ad were untargeted, our model predicts it would
be shown next to any email with probability p/0. Hence,
P [(cid:30)x|Di ] = (pin)xi (pout)∑i(cid:30)(cid:29)=i x(cid:30)i ,P [(cid:30)x|D/0 ] = (p/0)∑i xi. For
this model, parameters are also automatically computed
by iterated inference.
Composite Model (XRay). The contextual and behav-
ioral mechanisms were designed to detect different types
of targeting. To detect both types, XRay must combine
the two scores. We experimented with multiple combi-
nation functions, including a decision tree and the arith-
metic average, and concluded that the arithmetic aver-
age yields sufﬁciently good results. XRay thus deﬁnes
the composite model that averages scores from individ-
ual models, and we demonstrate in §6.3 that doing so
yields higher recall for no loss in precision.
4.4
Our design of differential correlation, along with our
logarithmic results for random input placement, relies
on the fundamental assumption that the probability of
getting an ad O1 targeted at an input D1 in a shadow ac-
count that lacks D1 is vanishingly small. However, when
inputs attract the same ads (a.k.a., overlapping inputs),
a naive input placement can contradict this assumption.
Imagine a Gmail account with multiple emails related
to a Caribbean trip.
If placement includes Caribbean
emails in every available shadow account, related ads
will appear in groups of accounts with no email object
in common. XRay will thus classify them as untargeted.
Our Amazon experiments showed XRay’s recall drop-
ping from 97% to 30% with overlapping inputs (§6.5).
To address this problem, XRay’s Input Matching
module identiﬁes similar inputs and directs the Place-
ment Module to co-locate them in the same shadow
accounts. The key challenge is to identify similar inputs.
One method is to use content analysis (e.g., keywords
matching), but this has limitations. First, it is not service
agnostic; one needs to reverse engineer complex and
ever-changing matching schemes. Second, it is hard to
apply to non-textual media, such as YouTube videos.

Intuitively,

In XRay, we opt for a more robust, systems technique
rooted in the key insight that we can deduce similar
inputs from contextual targeting.
inputs
that
trigger similar targeting from the Web service
should attract similar outputs in their context. The
Input Matching module builds and compare inputs’
contextual signatures. Contextual signature similarity is
the distance between inputs (e.g., email) in a Euclidean
space, where each output (e.g., ad) is a dimension. The
coordinate of an email in this dimension is the number of

times the ad was seen in the context of the email. XRay
then forwards close inputs to the same shadow accounts.
Once the placement is done, behavioral targeting against
that email’s group can be inferred effectively.

This input matching mechanism differs fundamentally
from any content analysis technique, such as keyword
matching, because it groups inputs the same way the
Web service does.2
It is robust and very general: we
used it on both Gmail and Amazon without changing a
single line of code to change.

5 XRay-based Tools
To evaluate XRay’s extensibility, we instantiated it on
Gmail, YouTube, and Amazon. The engine, about 3,000
lines of Ruby, was ﬁrst developed for Gmail. We then ex-
tended it to YouTube and Amazon, without any changes
to its correlation algorithms. We did need to do minor
code re-structuring, but the experience felt turn key when
integrating a new service into the correlation machinery.
Building the full toolset required non-trivial coding
effort, however. Instantiating XRay for a speciﬁc Web
service is a three-step process. First,
the developer
instantiates appropriate data models (less than 20 code
lines for our prototypes). Second, she implements a
service-speciﬁc shadow account manager and plugin;
care must be taken not be too aggressive to avoid ad-
versarial service reactions. While these implementations
are conceptually simple, they require some coding; our
Amazon and YouTube account managers were built
by two graduate students new to the project, and have
around 500 lines of code. Third, the developer creates
a few shadow accounts for the audited service and
runs a small exploratory experiment to determine the
service’s coverage. XRay uses the coverage to estimate
the number of shadow accounts needed for a given input
size. All other parameters are self-tuned at runtime.

6 Evaluation
We evaluated XRay with experiments on Gmail, Ama-
zon, and YouTube. While Amazon and YouTube provide
ground truth for their targeting, Gmail does not. We
therefore manually labeled ads on Gmail and measured
XRay’s accuracy, as described in §6.1 and validated in
§6.2. We sought answers to four questions:
Q1 How accurate are XRay’s inference models? (§6.3)
Q2 How does XRay scale with input size? (§6.4)
Q3 Can input matching manage overlap? (§6.5)
Q4 How useful is XRay in practice? (§6.6)

2We call this method “monkey see, monkey do” because we watch

how the service groups inputs and group them similarly.

USENIX Association  

23rd USENIX Security Symposium  57

9

Ad
Keyword
Chaldean
Poetry
Steampunk Fan of Steampunk?

Targeted
Email
Like Chaldean
Poetry?

Cosplay

Discover Cosplay.

Falconry

Learn about Falconry.

Yes

Yes

Yes

Yes

Detected XRay
# Accounts
by XRay? Scores & Displays

13/13,

1588/1622

0.99,
1.0
0.99,
1.0
0.99,
1.0
0.99,
1.0

13/13,
888/912
13/13,
440/442
13/13,

1569/1608

Figure 5: Self-Targeted Ads. Fourth column shows XRay’s
correlation scores X, Y, (Bayesian) Behavioral and Contextual
scores, respectively. Fifth column shows raw behavioral and
contextual data for interpretation: X/Y, Z/T means that the ad
was seen in X active accounts that contain the targeted email
out of a total of Y active accounts; the ad was shown Z times
in the context of the targeted email out of a total of T times.

6.1 Methodology
We evaluated XRay with experiments on Gmail, Ama-
zon, and YouTube. For inputs, we created a workload for
each service by selecting topics from well-deﬁned cate-
gories relevant for that service. For Gmail and YouTube,
we crafted emails and selected videos based on AdSense
categories [17]; for Amazon, we selected products from
its own product categories [2]. We used these categories
for most of our experiments (§6.3–§6.5). We used these
categories to create two types of workloads: (1) a non-
overlapping workload, in which each data item belonged
to a distinct category, and (2) an overlapping workload,
with multiple data items per category (described in §6.5).
To assess XRay’s accuracy, we needed the ground
truth for associations. Amazon and YouTube provide
it for their recommendations. For instance, Amazon
provides a link “Why recommended?” which explicitly
explains the recommendation. For Gmail, we manually
labeled ads based on our personal assessment. The
ads for different experiments were labeled by different
people, generally project members. A non-computer
scientist labeled the largest experiment (51 emails).

We evaluate two metrics: (1) recall, the fraction of
positive associations labeled as such, and (2) precision,
the fraction of correct associations. We deﬁne high
accuracy as having both high recall and high precision.
6.2 Sanity-Check Experiment
To build intuition into XRay’s functioning, we ran
a simple sanity-check experiment on Gmail. Recall
that, unlike Amazon and YouTube, Gmail does not
provide any ground truth, requiring us to manually label
associations, a process that can be itself faulty. Before
measuring XRay’s accuracy against labeled associations,
we checked that XRay can detect associations for our
own ads, whose targeting we control. For this, we
strayed away from the aforementioned methodology to
create a highly controlled experiment. We posted four
Google AdWords campaigns targeted on very speciﬁc
keywords (Chaldean Poetry, Steampunk, Cosplay, and

l
l

a
c
e
R

 1
 0.8
 0.6
 0.4
 0.2
 0

i

i

n
o
s
c
e
r
P

 1
 0.8
 0.6
 0.4
 0.2
 0

 0

Contextual
Behavioral
Composite (XRay)
 40
 20
 80
Number of Accounts
(b) Precision

 60

 100

Contextual
Behavioral
Composite (XRay)
 40
 20
 80
Number of Accounts

 60

 0

 100

(a) Recall

Figure 6: Bayesian Model Accuracy. Recall and precision
for each of the three Bayesian models vs.
shadow account
number, using the Bayesian algorithm. XRay needed 16
accounts to reach the “knee” with high recall and precision.

l
l

a
c
e
R

 1
 0.8
 0.6
 0.4
 0.2
 0

i

i

n
o
s
c
e
r
P

 1
 0.8
 0.6
 0.4
 0.2
 0

 0

 40

Bayesian (Behavioral)
Set Intersection
 20
 80
Number of Accounts
(b) Precision

 60

 100

Bayesian (Behavioral)
Set Intersection
 80
 20
Number of Accounts

 40

 60

 0

 100

(a) Recall

Figure 7: Bayesian vs. Set Intersection Comparison. Recall
and precision for detecting behavioral targeting with each algo.

Falconry), crafted an inbox that included one email per
keyword, and used XRay to recover the associations
between our ads and those emails. In total, we saw our
ads 1622, 912, 442, and 1608 times, respectively, across
all accounts (shadows and master). Figure 5 shows our
results. After one round of ad collection (which involved
50 refreshes per email), XRay correctly associated all
four ads with the targeted email.
It did so with very
high conﬁdence: composite model scores were 0.99
in all cases, with very high scores for both contextual
and behavioral models. The ﬁgure also shows some
of the raw contextual/behavioral data, which provides
intuition into XRay’s perfect precision and recall in this
controlled experiment. We next turn to evaluating XRay
in less controlled environments, for which we use the
workloads and labeling methodology described in §6.1.
6.3 Accuracy of XRay’s Inference Models (Q1)
To assess the accuracy of XRay’s key correlation
mechanisms (Bayesian behavioral,
and
composite), we measured their recall and precision
under non-overlapping workloads.
Figures 6(a) and
6(b) show how these two metrics varied with the number
of shadow accounts for a 20-email experiment on Gmail.
The results indicate two effects. First, both contextual
and behavioral models were required for high recall.
Of the 193 distinct ads seen in the user account, 121
(62%) were targeted, and XRay found 109 (90%) of
them, a recall we deem high. Of the associations XRay
found, 37% were found by only one of the models: 15

contextual,

58  23rd USENIX Security Symposium 

USENIX Association

10

Gmail
Amazon
Youtube

 25
 20
 15
 10
 5

s
t
n
u
o
c
c
A

 
f

o

 
r
e
b
m
u
N

 8

 4

 2

 16

 32
Number of Inputs (log)
(a) Scalability with Input Size

l
l

a
c
e
R

 1
 0.8
 0.6
 0.4
 0.2
 0

i

i

n
o
s
c
e
r
P

 1
 0.8
 0.6
 0.4
 0.2
 0

Gmail
Amazon
Youtube
 32
Number of Inputs (log)
(c) Precision with Input Size
(a) Number of accounts required to achieve the knee accuracy for varied numbers of inputs.

Gmail
Amazon
Youtube
 32
Number of Inputs (log)

(b) Recall with Input Size

 64

 16

 64

 16

 2

 4

 8

 2

 4

 8

 64

(b), (c)

Figure 8: Scalability.
Recall/precision achievable with the number of accounts in (a). Behavioral uses the Bayesian algorithm.

by the contextual model only, and 24 by the behavioral
model only. Thus, both models were necessary, and
composing them yielded high recall. Our Amazon and
YouTube experiments (which provide ground truth)
yielded very similar results: on a 20-input experiment,
we reached over 90% recall and precision with only 8
and 12 accounts, respectively.

Second,

the composite model’s recall exhibited
a knee-shaped curve for increasing shadow account
numbers, with a rapid improvement at the beginning
and slow growth thereafter. With 16 accounts, XRay
exceeded 85% recall; increasing the number of accounts
to 100 yielded a 1.9% improvement. Precision also
remained high (over 84%) past 16 accounts. We deﬁne
the knee as the minimum number of accounts needed to
reap most of the achievable recall and precision.

We also wished to compare the accuracy of the
Bayesian algorithm, which conveniently self-tunes
its parameters,
to the parameterized Set Intersection
algorithm. We manually tuned the latter as best as
we could. Figures 7(a) and 7(b) show the recall and
precision for detecting behavioral
targeting with the
two methods for a non-overlapping workload. The
two algorithms performed similarly, with the Bayesian
staying within 5% of the manually tuned algorithm.
We also tested the algorithms on an Amazon dataset,
and using a version of the Set Intersection algorithm
with empirical optimizations. The conclusion holds:
the Bayesian algorithm, with self-tuned parameters,
performs as well as the Set Intersection technique with
manually tuned parameters. We focus the remainder of
this evaluation on the Bayesian algorithm.
6.4 Scalability of XRay with Input Size (Q2)
A main contribution of this paper is the realization
that, under certain assumptions, the number of accounts
needed to achieve high accuracy for XRay scales
logarithmically with the number of tracked inputs.
We have proven that under certain assumptions,
the
Set Intersection algorithm scales logarithmically. This

theoretical result
is hard to extend to the Bayesian
algorithm, so we evaluated it experimentally by studying
three metrics with growing input size: the number of ac-
counts required to reach the recall knee and the value of
recall/precision at this knee. Figures 8(a), 8(b) and 8(c)
show the corresponding results for Gmail, YouTube and
Amazon. For Gmail, the number of accounts necessary
to reach the knee increased less than 3-fold (from 8
to 21) as input size increased more than 25-fold (from
2 to 51). For Amazon and YouTube, the increases in
accounts were 6- and 8-fold respectively, for a 32-fold
increase in input size.
In general, the roughly linear
shapes of the log-x-scale graphs in Figure 8(a) conﬁrm
the logarithmic increase in the number of accounts
required to handle different inputs. Figure 8(b) and 8(c)
conﬁrm that the “knee number” of accounts achieved
high recall and precision (over 80%).

What accounts for the large gap between the number
of accounts needed for high accuracy in Gmail versus
Amazon? For example, tracking a mere two emails in
Gmail required 8 accounts, while tracking two viewed
products in Amazon needed 2 accounts. The distinction
corresponds to the difference in coverage exhibited by
the two services. In Gmail, a targeted ad was typically
seen in a smaller fraction of the relevant accounts
compared to a recommended product in Amazon. XRay
adapted its parameters to lower coverage automatically,
but it needed more accounts to do so.

Overall,

these results conﬁrm that our theoretical
scalability results hold for real-world systems given
carefully crafted, non-overlapping input workloads. We
next investigate how more realistic overlapping input
workloads challenge the accuracy of our theoretical
models and how input matching – a purely systems
technique – helps address this challenge.
6.5
To evaluate XRay’s accuracy with overlapping inputs,
we infused our workloads with multiple items from
the same category.
(e.g., multiple emails targeting the

Input Matching Effectiveness (Q3)

USENIX Association  

23rd USENIX Security Symposium  59

11

l
l

a
c
e
R

 1
 0.8
 0.6
 0.4
 0.2
 0

i

i

n
o
s
c
e
r
P

 1
 0.8
 0.6
 0.4
 0.2
 0

With Matching
Without Matching

 0  5  10  15  20  25  30  35  40

Number of Accounts
(b) Precision

With Matching
Without Matching

 0  5  10  15  20  25  30  35  40

Number of Accounts

(a) Recall

Input Matching effectiveness.

Figure 9:
Behavioral
(Bayesian) recall and precision in Gmail with overlapping
inputs, with and without Matching.

same topic on Gmail and multiple products in the same
category in Amazon). For the Gmail experiments, we (as
users) could not tell when Gmail targeted a speciﬁc email
from a group of similar emails. We therefore ran two
different types of experiments. First, a controlled, albeit
unrealistic, one for Gmail. We replicated various emails
identically in a user’s inbox: 1 email was replicated 4
times, 2 emails 3 times, 4 emails 2 times, and 12 were
single, for a total of 30 emails. This end-of-a-spectrum
workload demonstrates how matching works ideally.
XRay matched all redundant emails correctly. More
importantly, Figures 9(a) and 9(b) show XRay’s preci-
sion/recall with and without matching-aware placement
for XRay’s behavioral model, the only model improved
by matching. Without input matching, XRay struggled
to ﬁnd differential signals: even with 35 shadow ac-
counts for a 30-email experiment, recall was only 48%.
With input matching, XRay’s correlation model drew a
stronger signal from each account and attained close to
70% recall for 16 accounts.

Second, for Amazon, we created a more realistic over-
lapping workload by selecting three distinct products in
each of six product categories (e.g., from the Outdoor
& Cycling category, we selected a helmet, pedals, and
shoes). With a total workload of 18 products, XRay’s
input matching matched all but one item (shoes) into its
correct group. With the new grouping, XRay’s recall im-
proved by a factor of 3 (from 30% to 93%) compared to
the no-matching case for 18 products with 10 accounts;
precision was 2.6 times higher (from 34% to 88%).

These results demonstrate that XRay’s matching
scheme is both portable across Web services and
essential for high accuracy with overlapping workloads.

6.6 Anecdotal Use Experience (Q4)
To gain intuition into XRay’s practical value, we ran a
small-scale, anecdotal experiment that ﬁshed for Gmail
ads targeted against a few speciﬁc topics. We created
emails focused on topics such as cancer, Alzheimer, de-
pression, HIV, race, homosexuality, pregnancy, divorce,
and debt. Each email consisted of keywords closely
related to one topic (e.g., the depression-related email

Topic

Cancer

Alzheimer

Targeted
Ads
Black Mold Allergy Symptoms?
Expert to remove Black Mold.
Adult Assisted Living.
Affordable Assisted Living.
Ford Warriors in Pink.
Join The Fight.
Rosen Method Bodywork for
physical or emotional pain.
Shamanic healing over
the phone.
Text Coach - Get the girl
you want and Desire.
Racial Harassment?
Learn your rights now.
Racial Harassment,
Hearing racial slurs?
SF Gay Pride Hotel.
Homosexuality Luxury Waterfront.

African
American

Depression

Cedars Hotel Loughborough,
36 Bedrooms, Restaurant, Bar.
Find Baby Shower Invitations.
Get Up To (60% Off) Here!
Ralph Lauren Apparel.
Ofﬁcial Online Store.
Clothing Label-USA.
Best Custom Woven Labels.
Bonobos Ofﬁcial Site,
Your Closet Will Thank You.
Law Attorneys specializing
in special needs kids education.
Cerbone Law Firm, Helping
Good People Thru Bad Times
Take a New Toyota Test Drive,
Get a $50 Gift Card On The Spot.
Great Credit Cards Search.
Apply for VISA, MasterCard...
Stop Creditor Harassment,
End the Harassing Calls.

Pregnancy

Divorce

Debt

9/9,

61/198

10/10,

627/7172

851/5808

1022/1106

31/276
10/10,

8/8,
12/14
9/9,

24/598
16/16,
117/117

XRay
# Accounts
Scores & Displays
0.99,
0.05
0.99,
0.99
0.96,
0.98
0.98,
0.05
0.99,
0.99
0.93,
0.04
0.99,
0.2
0.99,
0.2
0.99,
0.1
0.96,
1.0
0.99,
1.0
0.99,
0.6
0.99,
1.0
0.99
0.99
0.99,
0.99
0.99,
1.0
0.99,
0.9
0.99,
0.0
0.99,
0.96

9/9,
50/99
8/8,
36/43
9/9,
22/22
10/10,
85/181

635/666
10/10,
94/94
7/7,
58/65
9/9,

9/9,
14/14
9/9
64/71
9/9,

151/2358

256/373

7/7,

7/7,

8/8,

Figure 10: Example of Targeted Ads. Columns three and
four show the same data as columns four and ﬁve in Figure 5.

included depression, depressed, and sad; the homosex-
uality email included gay, homosexual, and lesbian).
We then launched XRay’s Gmail ad collection and
examined the targeting associations. We acknowledge
that a much larger-scale experiment is needed to reach
statistically-meaningful conclusions. Hence, we relate
our experience by example.

Figure 10 shows ads that XRay associated with each
topic, with its conﬁdence scores. Conservatively, we
only consider ads with high scores. We make two
observations. First, our small-scale experiment conﬁrms
that it is possible to target sensitive topics in users’
inboxes. All disease-related emails, except for the HIV
one, are strongly correlated with a number of ads. A
“Shamanic healing” ad appears exclusively in accounts
containing the depression-related email, and many times
in its context; ads for assisted living services target the
Alzheimer email; and a Ford campaign to ﬁght breast
cancer targets the cancer email. Race, homosexuality,
pregnancy, divorce, and debt also attract plenty of ads.
For example, the pregnancy email is strongly targeted by
an ad for baby-shower invitations (shown in the ﬁgure),
maternity- and lactation-related ads (not shown), and, in-
terestingly, a number of ads for general-purpose clothing

60  23rd USENIX Security Symposium 

USENIX Association

12

(shown). As another example, the debt email is strongly
targeted by a car dealership ad that entices the targeted
users to take a Toyota test drive using a $50 gift offering.
Discussing the morality of targeting such sensitive topics
is beyond our statute, however we believe that the lack
of transparency, coupled with sensitive-topic targeting,
opens users to subtle dangers, a topic we discuss next.

Second,

for many ads,

the association with the
targeted email is not obvious at all. Nothing in the
“Shamanic healing” ad suggests targeting against de-
pression; nothing in the general-purpose clothing ads
suggest targeting against pregnancy; and nothing in the
“Cedars hotel” ad suggests an orientation toward the
homosexuality email. If no keyword in the ad suggests
relation with sensitive topics, a user clicking on the ad
may not realize that they could be disclosing private in-
formation to advertisers. Imagine an insurance company
wanted to gain insight into pre-existing conditions of its
customers before signing them up. It could create two ad
campaigns – one that targets cancer and another youth
– and assign different URLs to each campaign. It could
then offer higher premium quotes to visitors who come
through the cancer-related ads to discourage them from
signing up while offering lower premium quotes to those
who come through youth-related ads. We believe that
the potential for this attack illustrates the urgent need for
increased transparency in ad targeting.
6.7 Summary
Our evaluation results show that XRay supports ﬁne-
grained, accurate data tracking in popular Web services,
scales well with the size of data being tracked, is general
and ﬂexible enough to work efﬁciently for three Web ser-
vices, and robustly uses systems techniques to discover
associations when ad contents provide no indication of
them. We next discuss how XRay meets its last goal:
robustness against honest-but-curious attackers.

7 Security Analysis
As stated in §3.3, two threat models are relevant for
XRay and applicable to different use cases. First, an
honest-but-curious Web service does not attempt
to
frustrate XRay, but it could incorporate defenses against
typical Web attacks, such as DDoS or spam, that might
interfere with XRay’s functioning. Second, a malicious
service takes an adversarial stand toward XRay, seeking
to prevent or otherwise disrupt its correlations. Our
current XRay prototype is robust against the former
threat and can be extended to be so against the latter.
In either case,
third-party advertisers can attempt to
frustrate XRay’s auditing. We discuss each threat in turn.
Non-Malicious Web Services. Many services incor-
porate protections against speciﬁc automated behaviors.
For example, Google makes it hard to create new ac-

counts, although doing so remains within reach. More-
over, many services actively try to identify spammers and
click fraud. Gmail includes sophisticated spam ﬁltering
mechanisms, while YouTube rate limits video viewing to
prevent spam video promotion. Finally, many services
rate limit access from the same IP address.

XRay-based tools must be aware of these mechanisms
and scale back their activities to avoid raising red ﬂags.
For example, our prototype for Gmail, YouTube, and
Amazon rate limit their output collection in the shadow
accounts. Moreover, XRay’s very design is sensitive to
these challenges: by requiring as few accounts as possi-
ble, we minimize: (1) the load on the service imposed by
auditing, and (2) the amount of input replication across
shadow accounts. Moreover, XRay’s workloads are of-
ten atypical of spam workloads. Our XRay Gmail plugin
sends emails from one to a few other accounts, while
spam is sent from one account to many other accounts.
Malicious Third-Party Advertisers. Third-party adver-
tisers have many ways to obfuscate their targeting from
XRay, particularly if it may arouse a public outcry. First,
an advertiser could purposefully weaken its targeting by,
for example, targeting the same ad 50% on one topic and
50% on another topic. This weakens input/output corre-
lation and may cause XRay to infer untargeting. How-
ever, it also makes the advertisers’ targeting less effec-
tive and potentially more ambiguous if their goal is to
learn speciﬁc sensitive information about users. Second,
an advertiser might target complex combinations of in-
puts that XRay’s basic design cannot discover. Our ac-
companying technical report shows an example of how
advertisers might achieve this [26]. It also extends our
theoretical models so they can detect targeting on linear
combinations with only a constant factor increase in the
number of accounts. We plan to incorporate and evaluate
these extensions in a future prototype.
Malicious Web Services. A malicious service could
identify and disable shadow accounts.
Identiﬁcation
could be based on abnormal trafﬁc (successive reloads
of email pages), data distribution within accounts (sev-
eral accounts with subsets of one account), and perhaps
more. XRay could be extended to add randomness and
deception (e.g., fake emails, varying copies). More im-
portantly, a collaborative approach to auditing, in which
users contribute their ads and input topics in an privacy-
preserving way is a promising direction for strengthening
robustness against attacks. Web services cannot, after all,
disable legitimate user accounts to frustrate auditing. We
plan to pursue this direction in future work.
8 Discussion
XRay takes a signiﬁcant step toward providing data
management transparency in Web services. As an initial
effort, it has a number of limitations. First, both the Set

USENIX Association  

23rd USENIX Security Symposium  61

13

Intersection and Bayesian algorithms assume indepen-
dent targeting across accounts and over time. In reality,
ad targeting is not always independent across either. For
example, advertisers set daily ad budgets. When the bud-
get runs out, an ad can stop appearing in accounts mid-
experiment even though it has the targeted attributes. The
system might incorrectly assume that no targeting is tak-
ing place, when it could resume the next day. XRay takes
reduced coverage into account, but differences between
ads can let some targeting pass unnoticed. XRay does not
currently account for these dependencies, but estimating
their impact is an important goal for future work.

Second, we assume that targeting noise is bounded
and smaller than the targeting signal. While this con-
dition seems to hold on the evaluated services, other
services making more local decisions may be harder to
audit. For example, Facebook might target ads based on
friends’ information, potentially creating noise that is
as high as the targeting signal. A future solution might
imitate the social network in shadow accounts.

Third, XRay uses Web services atypically. To the best
of our knowledge, it does not violate any terms of ser-
vice. It does, however, collect ads paid for by advertisers
to detect correlation. Ad payment is per impression and
pay per click. The former is vastly less expensive than
the latter [32]. XRay creates false impressions only but
never clicks on ads. A back-of-the-envelope calculation
using impression pricing from [32] of $0.6/thousand
impressions reveals that XRay’s cost should be minimal:
at most 50 cents per ad for our largest experiments.

Despite these limitations, XRay has proven itself use-
ful for many needs, particularly in an auditing context.
An auditor can craft inputs that avoid many of these
limitations. For example, emails can be written to avoid
as much overlap as possible and keep the size of inputs
used for targeting within reasonable bounds. We hope
that XRay’s solid correlation components will streamline
much-needed investigations – by researchers, journalists,
or the FTC – into how personal data is being used.

9 Related Work
While §2.2 covered Web data protection and auditing
related works, we next cover other related topics. Our
work relates to recent efforts to measure various forms
of personalization, such as search [21, 47], pricing [31],
and ad discrimination [40]. They generally employ a
methodology similar in spirit to differential correlation,
but their goals differ from ours. They aim to quantify
how much output
type of
information is used overall.
In contrast, XRay seeks
to provide ﬁne-grained diagnosis of which input data
generates which personalized results.
Through its
scaling mechanisms – unique in the personalization and

is personalized and what

data tracking literature – XRay scales well even when
the relevant inputs are many and unknown in advance.

Our work also relates to a growing body of research
measuring advertising networks.
These networks,
notably complex and difﬁcult to crawl [3], are rendered
opaque by the need to combat click fraud [9], and have
been shown to be susceptible to leakage [24] and proﬁle
reconstruction attacks [6]. As for other personalization,
prior studies focused mostly on macroscopic trends
(e.g., What fraction of ads are targeted?) [3] or quali-
tative trends (e.g., Which ads are targeted toward gay
males?) [20]. Various studies showed traces – but not a
prevalence – of potential abuse through concealed target-
ing [20] and data exchange between services [46]. These
works primarily focus on display advertising, and each
distinguishes contextual advertising using a speciﬁc clas-
siﬁer with semantic categories obtained from Google’s
Ad Preferences Managers or another public API [28].

XRay departs signiﬁcantly from these works. First,
since it entirely ignores the content and even the domain
of targeting, it is readily applied as-is to ads in Gmail,
product recommendations, and videos. Second, while
previous methods label ads as “behavioral” in bulk once
other explanations fail [28], XRay remains grounded
on positive evidence, and determines to which inputs an
output should be attributed. Third, XRay’s mechanisms
to avoid exponential
input placement and deal with
overlapping inputs are unprecedented in the Web-
data-tracking context. While they resemble black box
software testing [4], the speciﬁc targeting assumption
we leverage have, to our knowledge, no prior equivalent.
10 Conclusions
The tracking of personal data usage poses unique
challenges. XRay shows for the ﬁrst time that accurate,
ﬁne-grained tracking need not compromise portability
and scalability. For users who care about which piece
of their data has been targeted, it offers a unique level
of precision and protection. Our work calls for and pro-
motes the best practice of voluntary transparency, while
at the same time empowering investigators and watch-
dogs with a signiﬁcant new tool for increased vigilance.
11 Acknowledgements
We thank our shepherd, Dan Boneh, the anonymous
reviewers, and numerous colleagues (Jonathan Bell, San-
dra Kaplan, Michael Keller, Yoshi Kohno, Hank Levy,
Yang Tang, Nicolas Viennot, and Junfeng Yang) for their
valuable feedback. This work was supported by DARPA
Contract FA8650-11-C-7190, NSF CNS-1351089 and
CNS-1254035, Google, and Microsoft.

References
[1] Adblock plus. https://adblockplus.org.

14

62  23rd USENIX Security Symposium 

USENIX Association

[2] Amazon. Product categories.

http://services.amazo

n.com/services/soa-approval-category.htm.

[3] P. Barford, I. Canadi, D. Krushevskaja, Q. Ma, and S. Muthukr-
ishnan. Adscape: Harvesting and Analyzing Online Display Ads.
In Proc. of the 23nd International Conference on WWW, 2014.

[4] B. Beizer. Black-Box Testing. Techniques for Functional Testing

of Software and Systems. John Wiley & Sons, May 1995.

[5] D. Boneh, G. Crescenzo, R. Ostrovsky, and G. Persiano. Public
Key Encryption with Keyword Search.
In Proc. of the ACM
European Conference on Computer Systems (EuroSys), pages
506–522. Springer Berlin Heidelberg, Berlin, Heidelberg, 2004.
[6] C. Castelluccia, M. A. Kaafar, and M. Tran. Betrayed by your
ads! PETS’12: Proceedings of the 12th International Conference
on Privacy Enhancing Technologies, 2012.

[7] W. Cheng, Q. Zhao, B. Yu, and S. Hiroshige. Tainttrace: Efﬁcient
ﬂow tracing with dynamic binary rewriting. In Proc. of the 11th
IEEE Symposium on Computers and Communications, 2006.

[8] Chrome web store - collusion for chrome.

https://chro
me.google.com/webstore/detail/collusion-for-
chrome/ganlifbpkcplnldliibcbegplfmcfigp.

[9] V. Dave, S. Guha, and Y. Zhang. Measuring and ﬁngerprinting
In SIGCOMM ’12: Proceedings
the ACM SIGCOMM 2012 Conference on Applications,
for Computer

click-spam in ad networks.
of
Technologies, Crchitectures, and Protocols
Communication. ACM Request Permissions, Aug. 2012.

[10] N. Diakopoulos. Algorithmic accountability reporting: On the
investigation of black boxes. Tow Center for Digital Journalism,
Columbia University. February, 2014.

[11] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The

second-generation onion router. Technical Report, 2004.

[12] W. Enck, P. Gilbert, B. gon Chun, L. P. Cox, J. Jung, P. McDaniel,
and A. N. Sheth. TaintDroid: An information-ﬂow tracking
system for realtime privacy monitoring on smartphones. In Proc.
of the USENIX Symposium on Operating Systems Design and
Implementation (OSDI), 2010.

[13] M. Fredrikson and B. Livshits. RePriv: Re-imagining Content
Personalization and In-browser Privacy. 2011 IEEE Symposium
on Security and Privacy, pages 131–146, 2011.

[14] R. Geambasu, T. Kohno, A. Levy, and H. M. Levy. Vanish:
In Proc. of

Increasing data privacy with self-destructing data.
USENIX Security, 2009.

[15] C. Gentry.

Fhe using ideal lattices.

In Proc. of the ACM

Symposium on Theory of Computing (STOC), 2009.

[16] D. B. Gifﬁn, A. Levy, D. Stefan, D. Terei, D. Mazi`eres, J. C.
Mitchell, and A. Russo. Hails: Protecting data privacy in
untrusted web applications. In In Proc. of the 10th USENIX Con-
ference on Operating Systems Design and Implementation, 2012.
https://support.googl

[17] Google. Adsense categories.

e.com/adsense/answer/3016459.

[18] J. Gould. SafeGov.org - Google admits data mining student

emails in its free education apps, 2014.

[19] V. Goyal, O. Pandey, A. Sahai, and B. Waters. Attribute-based
encryption for ﬁne-grained access control of encrypted data. In
Proc. of the ACM Conference on Computer and Communications
Security (CCS), 2006.

[20] S. Guha, B. Cheng, and P. Francis. Challenges in measuring
online advertising systems. In IMC ’10: Proceedings of the 10th
Annual Conference on Internet Measurement, 2010.

[21] A. Hannak, P. Sapiezynski, A. M. Kakhki, B. Krishnamurthy,
D. Lazer, A. Mislove, and C. Wilson. Measuring personaliza-
tion of web search.
In WWW ’13: Proceedings of the 22nd
International Conference on World Wide Web, 2013.

[22] A. L. Hughes and L. Palen. Twitter adoption and use in mass
International Journal of

convergence and emergency events.
Emergency Management, 2009.

[23] A. Korolova. Privacy Violations Using Microtargeted Ads: A

Case Study. In ICDM Workshops, 2010.

[24] A. Korolova. Privacy violations using microtargeted ads: A
case study. Data Mining Workshops (ICDMW), 2010 IEEE
International Conference on, pages 474–482, 2010.

[25] B. Krishnamurthy and C. E. Wills. On the leakage of personally
identiﬁable information via online social networks. In Proc. of
the 2nd ACM Workshop on Online Social Networks, 2009.

[26] M. Lecuyer, G. Ducoffe, F. Lan, A. Papancea, T. Petsios,
R. Spahn, A. Chaintreau, and R. Geambasu. XRay: Enhancing
the Web’s Transparency with Differential Correlation. Technical
report, CS Department, Columbia University, 2014.

[27] Lightbeam. http://www.mozilla.org/lightbeam/.
[28] B. Liu, A. Sheth, U. Weinsberg, J. Chandrashekar, and R. Govin-
improving transparency into online targeted
In Proc. of the Twelfth ACM Workshop on Hot

dan. AdReveal:
advertising.
Topics in Networks, 2013.

[29] D. Mattioli. WSJ.com - On Orbitz, Mac Users Steered to Pricier

Hotels, 2012.

[30] V. McKalin. Techtimes.com - google: We promise not to spy on

student email accounts to deliver ads, 2014.

[31] J. Mikians, L. Gyarmati, V. Erramilli, and N. Laoutaris. De-
In
the 11th ACM Workshop on Hot Topics in

tecting price and search discrimination on the internet.
Proceedings of
Networks, pages 79–84, 2012.

[32] L. Olejnik, T. Minh-Dung, C. Castelluccia, et al. Selling off
In In Proceedings of the Network and

privacy at auction.
Distributed System Security Symposium (NDSS), 2013.

[33] R. A. Popa, C. M. S. Redﬁeld, N. Zeldovich, and H. Balakrish-
nan. Cryptdb: Protecting conﬁdentiality with encrypted query
processing. In Proceedings of the Twenty-Third ACM Symposium
on Operating Systems Principles, SOSP ’11, pages 85–100, 2011.

[34] F. Roesner. sharemenot.cs.washington.edu.
[35] F. Roesner, T. Kohno, and D. Wetherall. Detecting and defending
In NSDI’12: Pro-
against third-party tracking on the web.
ceedings of the 9th USENIX Conference on Networked Systems
Design and Implementation. USENIX Association, Apr. 2012.

[36] A. Sadilek and H. Kautz. Modeling the impact of lifestyle on
health at scale. In Proceedings of the Sixth ACM International
Conference on Web Search and Data Mining, 2013.

[37] SafeGov.org. Declaration of Kyle C. Wong in Support of Google
Inc.’s Opposition to Plaintiffs’ Motion for Class Certiﬁcation,
2013.

[38] Snapchat. http://blog.snapchat.com/.
[39] Snapchat blog - how snaps are stored and deleted.
[40] L. Sweeney. Discrimination in online ad delivery. Communica-

tions of the ACM, 56(5), May 2013.

[41] The Guardian. Snapchat’s expired snaps are not deleted, just

hidden, 2014.

[42] V. Toubiana, A. Narayanan, and D. Boneh. Adnostic: Privacy

preserving targeted advertising. Proc. NDSS, 2010.

[43] J. Valentino-Devries, J. Singer-Vine, and A. Soltani. WSJ.com -
Websites Vary Prices, Deals Based on Users’ Information, 2012.
[44] X. Wang, M. Gerber, and D. Brown. Automatic crime prediction
using events extracted from twitter posts. In S. Yang, A. Green-
berg, and M. Endsley, editors, Social Computing, Behavioral
- Cultural Modeling and Prediction, volume 7227 of Lecture
Notes in Computer Science, pages 231–238. 2012.

[45] A. Whitten and J. D. Tygar. Why Johnny can’t encrypt: A usabil-

ity evaluation of PGP 5.0. In Proc. of USENIX Security, 1999.

[46] C. E. Wills and C. Tatar. Understanding What They Do with
What They Know. WPES ’12: Proceedings of the 12th Annual
ACM Workshop on Privacy in the Electronic Society, 2012.

[47] X. Xing, W. Meng, D. Doozan, N. Feamster, W. Lee, and
A. C. Snoeren. Exposing Inconsistent Web Search Results with
Bobble. Passive and Active Measurements Conference, 2014.

[48] Y. Zhu, J. Jung, D. Song, T. Kohno, and D. Wetherall. Privacy
scope: A precise information ﬂow tracking system for ﬁnding
application leaks. Technical Report UCB/EECS-2009-145, 2009.

[49] P. R. Zimmermann. The ofﬁcial PGP user’s guide. 1995.

USENIX Association  

23rd USENIX Security Symposium  63

15

A Proof of Theorem 1
A.1 Targeting functions, Axioms and Core Family
A combination C of order r, also called r combination,
is a subset of r elements among the N inputs.

Each given ad is associated with a targeting function
deﬁned as a mapping f from any subset C of the N in-
puts into {0,1}, where f (C ) =1 denotes that an account
containing C as inputs should be targeted. By conven-
tion, untargeted ads are associated with the null function
f (.) =0. Any targeting function f satisﬁes two axioms:
• monotonicity: C ⊆ C (cid:27) =⇒ f (C ) ≤ f (C (cid:27)).
• input-sensitivity: ∃C , C (cid:27) s.t.
f (C ) =0, f (C (cid:27)) =1.
Monotonicity simply reﬂects that an account with strictly
more interest or hobbies should in theory be relevant to
more ads, and never to less. Input sensitivity prevents the
degenerate case where a targeting function is constant.

A family S of size l is any collection of l distinct
combination. The order of this family is deﬁned as the
largest order of a combination it contains. For any family
S, one can deﬁne a targeting function that takes value 1
whenever the subset contains at least one combination
in S. Indeed, as shown in [26], the converse is true:
Lemma 1 For each monotone, input-sensitive targeting
function there exists a unique family S satisfying:

(i) S has size l and order r and it explains f , which
means f (C ) =1 holds if and only if ∃C (cid:27) ∈ S, C (cid:27) ⊆ C .

(ii) No family of size l(cid:27) < l explains f .
(iii) No family of order r(cid:27) < r explains f .

Hence, associated with each ad and therefore each tar-
geting function is a unique family of input combination
that are targeted, called the ad’s core family, and we now
sketch why it is correctly identiﬁed by our algorithm.
A.2 Algorithm and Correctness
For any family of subsets S and fraction 0 ≤ x ≤ 1, we
say a subset of inputs C is an x intersecting subset of
S if x subsets in S have at least one input in C . Our
proof exploits an original connection between small
intersecting subsets (that can be found efﬁciently) to
show how they can reveal a core family. One way to
understand why is the following: say, for instance, that
the targeting function f takes value 1 exactly when one
of the inputs within C is found in the account. Then C
is exactly the union of inputs found in the core family
and intersects all accounts within scope, i.e., forms a
large fraction of those receiving the ad.

The key property to explain our algorithm is ran-
dom subsets. We can show under the conditions of the
theorem that there exists 0 < x < 1 that satisﬁes two prop-
erties related to the inputs of accounts receiving the ads:
(1) if targeting does not occur, then with a large probabil-
ity we cannot ﬁnd a subset of l inputs that meets at least a
fraction x of the accounts seeing the ad, and (2) if target-
ing does occur, we have accounts receiving the ads for

various reasons, within and outside the targeting scope.
But we can show with high probability that at least a frac-
tion x of them are within scope and hence must include
one combination in the core family. Since with each core
family of size l one can associate an intersecting subset
that contains at most l elements, checking the existence
of such a subset reveals the presence of targeting.

This explains why an algorithm can qualitatively
conclude whether targeting occurs or not, but it does not
explain how the core family can be computed. However,
leveraging stronger results of random subsets allows
to apply the same rule recursively, offering multiple
ways to determine exactly the core family even with a
polynomial number of operations.

More formally, we deﬁne: A random Bernoulli
subset, denoted by B(n, p), is a subset such that any of n
elements is contained with probability p independently
of all others. A random Bernoulli family of size m is a
collection of m independent Bernouilli subsets. We ﬁrst
show property (1) above more formally:
1
Lemma 2 Let x > 0, s ∈ N, p < 1 − (1 − x)
s , and
family B1(n, p),B2(n, p), . . . ,B m(n, p).
a Bernouilli
For any ε > 0 and polynomial P of degree ≤ r, there
P(n)(cid:30) no
exists A > 0 such that with probability (cid:31)1− ε

x intersection subset exists of size s whenever we have:

m ≥ A· ((s + r)ln(n) +ln(1/ε )) .

To prove property (2), we need to bound, among
accounts receiving an ad, the fraction that is outside
the scope of targeting but still receives the ads because
pout > 0. Formally, we have:

Lemma 3 Let x > 0, α > 0, and a core family of size l
αr
and order r pin, pout where we have pout/pin < 1−x
1−αr .
x
Let C be a combination of order r.
For any ε > 0 and polynomial P of degree ≤ r, there
exists A > 0 such that with probability (1− ε/P(n)) the
following holds: Among accounts containing C and
receiving the ad, at least x fraction of them is within the
targeting scope whenever we have:

m ≥ A· (r ln(n) +ln(1/ε )) .

The two lemmas above (proved in [26]) can be
combined whenever α satisﬁes the inequality for
p in the ﬁrst
lemma, which shows that an algo-
rithm can detect the presence of targeting whenever
pout/pin < 1−x
x

.

1
l )r
(1−(1−x)
1
l )r
1−(1−(1−x)

A naive exponential algorithm could be used to
exhaustively search for a core family using this brick.
We also show that a polynomial algorithm can reﬁne this
analysis to compute the core family at the expense of a
more complex recursion in [26].

64  23rd USENIX Security Symposium 

USENIX Association

16

