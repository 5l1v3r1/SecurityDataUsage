An Empirical Study of Textual  
Key-Fingerprint Representations

Sergej Dechand, University of Bonn; Dominik Schürmann, Technische Universität 
Braunschweig; Karoline Busse, University of Bonn; Yasemin Acar and Sascha Fahl,  

Saarland University; Matthew Smith, University of Bonn

 https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/dechand

This paper is included in the Proceedings of the 25th USENIX Security SymposiumAugust 10–12, 2016 • Austin, TXISBN 978-1-931971-32-4Open access to the Proceedings of the 25th USENIX Security Symposium is sponsored by USENIX An Empirical Study of Textual Key-Fingerprint Representations

Sergej Dechand

USECAP, University of Bonn

Yasemin Acar

CISPA, Saarland University

Dominik Sch¨urmann
IBR, TU Braunschweig

Sascha Fahl

CISPA, Saarland University

Karoline Busse

USECAP, University of Bonn

Matthew Smith

USECAP, University of Bonn

Abstract
Many security protocols still rely on manual ﬁngerprint
comparisons for authentication. The most well-known
and widely used key-ﬁngerprint representation are hexa-
decimal strings as used in various security tools. With
the introduction of end-to-end security in WhatsApp and
other messengers, the discussion on how to best repre-
sent key-ﬁngerprints for users is receiving a lot of inter-
est.

We conduct a 1047 participant study evaluating six
different textual key-ﬁngerprint representations with re-
gards to their performance and usability. We focus on
textual ﬁngerprints as the most robust and deployable
representation.

Our ﬁndings show that the currently used hexadeci-
mal representation is more prone to partial preimage at-
tacks in comparison to others. Based on our ﬁndings,
we make the recommendation that two alternative repre-
sentations should be adopted. The highest attack detec-
tion rate and best usability perception is achieved with a
sentence-based encoding. If language-based representa-
tions are not acceptable, a simple numeric approach still
outperforms the hexadecimal representation.

1

Introduction

Public key cryptography is a common method for au-
thentication in secure end-to-end communication and
has been a part of the Internet throughout the last two
decades [7, 11]. While security breaches have shown
that systems based on centralized trusted third parties
such as Certiﬁcate Authorities and Identity Based Private
Key Generators are prone to targeted attacks [42], decen-
tralized approaches such as Web of Trust and Namecoin
struggle with beeing adopted in practice due to usability
issues [7, 13, 30]. Certiﬁcate transparency systems, such
as CONIKS and others [24, 39, 27], aim to solve a subset
of these issues by providing an auditable directory of all

user keys. Still, manual key veriﬁcation, i. e., the link be-
tween public keys and the entities, such as hostnames or
people, remains a challenging subject, especially in de-
centralized systems without pre-deﬁned authorities, such
as SSH, OpenPGP, and secure messaging [12, 41].

Many traditional authentication systems still rely on
manual key-ﬁngerprint comparisons [17]. Here, key-
ﬁngerprints are generated by encoding the (hashed) pub-
lic key material into a human readable format, usually
encoded in hexadecimal representation. A variety of al-
ternatives such as QR Codes, visual ﬁngerprints, Near
Field Communication (NFC), and Short Authentication
Strings (SAS) have been proposed. Most of these sys-
tems offer speciﬁc beneﬁts, e. g., QR codes and NFC do
not require users to compare strings, but they also come
with speciﬁc disadvantages, e. g., they require hardware
and software support on all devices. While advances are
being made in these areas, the text-based representation
is still the dominant form in most applications.

However, due to the recent boom of secure messag-
ing tools, the debate of how to best represent and eval-
uate textual ﬁngerprints has opened up again and there
are many very active discussions among security ex-
perts [28, 33].
In April 2016, WhatsApp serving over
one billion users enabled end-to-end encryption as de-
fault by implementing the Signal protocol. Key veriﬁ-
cation is optional and can be done by using QR codes
or comparing numeric representations, in their case 60-
digit numbers [43]. However, it is not clear whether their
solution is more usable than traditional representations.
In this paper, we present an evaluation of different tex-
tual key-ﬁngerprint representation schemes to aid in the
secure messenger discussion. The requirements posed to
the developers are as follows:

• The ﬁngerprint representation scheme should pro-
vide ofﬂine support and work asynchronously. One
reason for this is that ﬁngerprints are often printed
on business cards or exchanged by third parties.

USENIX Association  

25th USENIX Security Symposium  193

• The ﬁngerprint should be transferable via audio
channels, e. g., it should be possible to compare ﬁn-
gerprint over the phone.

• The representation scheme should be as technically
inclusive as possible. No special hardware or soft-
ware should be required to verify the ﬁngerprints:
both require a concerted and coordinated effort be-
tween many actors to get enough coverage for a
comparison mechanism to be worthwhile for users
to adopt.

• The representation should be as inclusive as possi-
ble, i. e., excluding as few people with sensory im-
pairments (visual, color, audio, etc.) as possible.

The above requirements exclude many proposed rep-
resentation schemes and offer an explanation why they
have not seen any adoption outside of academia. For this
reason, we focus exclusively on textual ﬁngerprint rep-
resentations in our study. Textual key-ﬁngerprints do not
require hardware support and work in synchronous and
asynchronous scenarios, i. e., they can be compared via
voice or printed on business cards. Depending on the
scheme, they even could be recalled from memory and
exchanged over a voice channel.

This paper presents our study testing the usability of
various textual key-ﬁngerprint representation schemes.
Our study consists of two parts: (1) an experiment where
we measured how fast and accurate participants perform
for different schemes, and (2) a survey about their per-
ception and sentiment. These also contained a direct
comparison between the representations.

Our ﬁndings suggest that the most adopted alphanu-
meric approaches such as the Hexadecimal and Base32
scheme perform worse than other alternatives: under a
realistic threat model, more than 10% of the users failed
to detect attacks targeting Hexadecimal representations,
whereas our best system had failure rates of less than 3%.
While the best system for accuracy is not the fastest, it
is the system which received the highest usability rating
and is preferred by users.

In the following sections, we discuss related work fol-
lowed by an analysis of current implementations deploy-
ing in-persona key-ﬁngerprint representation techniques
and discuss our evaluated representation schemes. Then,
we describe our experiment evaluating text-based key-
ﬁngerprint veriﬁcation techniques with regards to their
attack-detection accuracy and speed. Our experiment
was conducted as an online study with 1047 participants
recruited via the Amazon Mechanical Turk (MTurk) plat-
form. We consider the scenario outlined above, where
a user compares two key-ﬁngerprint strings encoded by
the different representation schemes. In addition to the
implicit measurements of accuracy and speed, we also

a l i c e @ l o c a l h o s t :~ $ ssh a l i c e @ e x a m p l e . com
The a u t h e n t i c i t y of host ’ e x a m p l e . com ( 9 3 . 1 8 4 . 2 1 6 . 3 4 ) ’

can ’ t be e s t a b l i s h e d .

RSA key f i n g e r p r i n t is

6 f :85:66: da : e3 :7 a :02: c6 :5 e :62:3 f :36: b7 : d9 : b4 :2 c .

Are you sure you want to c o n t i n u e c o n n e c t i n g ( yes / no )?

(a) OpenSSH: Lowercase Hexadecimal with Colons

a l i c e @ l o c a l h o s t :~ $ gpg -- f i n g e r p r i n t Bob
pub

2048 R / 0 0 0 1 2 2 8 2 2015 -01 -01 [ e x p i r e s : 2020 -01 -01]
Key f i n g e r p r i n t =
73 EE 2314 F65F A92E C239

0 D3A 718 C 0701 0001 2282

uid

Bob < b o b @ e x a m p l e . com >

(b) GnuPG: Uppercase Hexadecimal with Spaces

Figure 1: Alphanumeric Fingerprints Used in Practice

evaluate the self-reported user perception to get feed-
back about which systems are preferred by end users.
Finally, we present our results, discuss their implications
and takeaways, and conclude our work.

2 Related Work

Various key-ﬁngerprint representations have been pro-
posed in academia and industry. Various cryptographic
protocol implementations still rely on manual ﬁngerprint
comparisons, while the hexadecimal representation is
used in most of them. However, previous work suggests
that ﬁngerprint veriﬁcations are seldom done in prac-
tice [17, 37].

2.1 Key-Fingerprint Representations
Previous work has shown that users struggle with com-
paring long and seemingly “meaningless” ﬁngerprints
and it is suspected that they even might perform poorly
in this task [19]. While most previous work has focused
on the family of visual ﬁngerprints [35, 32, 19, 10], to
our knowledge, none of those focused on the differences
between various different textual ﬁngerprint representa-
tions.

Hsiao et al. have conducted a study with some tex-
tual and visual representation methods for hash veriﬁ-
cation [19]. They compared Base32 and simple word
list representations with various algorithms for visual
ﬁngerprints and hash representation with Asian charac-
ter sets (a subset of Chinese, Japanese Hiragana, and
Korean Hangul, respectively). A within-subjects online
study with 436 participants revealed that visual ﬁnger-
prints score very well in both accuracy and speed, to-
gether with the Base32 text representation. Hsiao et al.
conclude that depending on the available computation
power and display size, either Base32 or one of the vi-
sual ﬁngerprinting schemes should be used. They explic-
itly did not evaluate hexadecimal representation or digits

194  25th USENIX Security Symposium 

USENIX Association

2

“because that scheme is similar to Base32 and known to
be error-prone” [19]. However, our work shows that nu-
meric representations actually perform signiﬁcantly bet-
ter than Base32 and is less error prone. In addition, our
results suggest that language-based schemes, e. g., gen-
erated sentences achieve excellent results comparable to
visual schemes. At the same time, textual approaches are
more ﬂexible (can be read out loud) and do not exclude
people with sensory impairments.

Another study by Olembo et al. also focused mainly
on the topic of visual ﬁngerprints [32]. They devel-
oped a new family of visual ﬁngerprints and compared
them against a Base32 representation. The Base32
strings were twelve characters long and displayed with-
out chunking. The participants performed better with
the visual ﬁngerprints than with Base32, regarding both
accuracy and speed. Olembo et al. conclude that the
Base32 representation is far away from optimal when
it comes to manual key-ﬁngerprint veriﬁcation. We
test this claim by comparing Base32 representation with
other textual key-ﬁngerprint representation and eventu-
ally prove it wrong.

Regarding chunking, Miller et al. have published The
magical number seven and succeeding work that shows
that most people can recall 7± 2 items from their mem-
It has been shown that although there
ory span [29].
are slight differences between numbers, letters and words
(numbers perform slightly better than letters, and letters
slightly better than words), they perform similar in stud-
ies. More recent studies have shown that human working
memory easily remembers up to 6 digits, 5.6 letters and
5.2 words [1, 6, 8]. Adjusting chunk sizes to these num-
bers can help users when comparing hashes.

While all of the above studies offer interesting insights
into different (mainly visual) ﬁngerprint representations,
to the best of our knowledge there is not work focusing
on which textual representation performs the best. How-
ever, this knowledge would be extremely important to
help in the current debate in the secure messaging com-
munity. The representations currently being put forward
and implemented are far from optimal and the results of
our study can help improve the accuracy and usability of
ﬁngerprint representations. Unlike the above studies we
conduct our study with a more realistic attacker strenth,
as presented in subsection 4.1).

2.2 Passwords and Passphrases
A passphrase is basically a password consisting of a se-
ries of words rather than characters.
In academic lit-
erature, passphrases are often considered as a poten-
tially more memorable and more secure alternative to
passwords and are often recommended by system ad-
ministrators [23, 40].
In contrast to most passphrase-

Scheme

Example

Hexadecimal

18e2 55fd b51b c808
601b ee5c 2d69

Base32

Numeric

PGP

Peerio

ddrf l7nv dpea
qya3 5zoc 22i

2016 507 6420 1070 394
1136 2973 991 70

locale voyager wafﬂe disable
Belfast performance slingshot Ohio
spearhead coherence hamlet liberty
reform hamburger

bates talking duke rummy slurps
iced farce pound day

Sentences

Your line works for this kind power cruelly.
That lazy snow agrees upon our tall offer.

Table 1: Examples for different textual key-ﬁngerprint repre-
sentations for the same hash value

based systems, key-ﬁngerprints cannot be chosen by
the end-user and thus are more related to the system-
assigned passphrases ﬁeld: Bonneau et al. have shown
that users are able to memorize 56-bit passwords [4].
miniLock1 and its commercial successor Peerio2 use
system-assigned passphrases to generate cryptographic
key pairs easing key backup and synchronization among
multiple devices.

Contrary to widespread expectations, Shay et al. were
not able to ﬁnd any signiﬁcant recall differences between
system-assigned passphrases and system-assigned pass-
words [40]. However, they reported reduced usability
due to longer submission times due to typing.

Similar to passphrases, the usage of language-based
key-ﬁngerprint representations is claimed to provide bet-
ter memorability than just an arbitrary series of charac-
ter strings despite the lack of empirical evidence. In our
study, we measure the performance of the different ap-
proaches and also collect perception and feedback from
end users.

3 Background

In the past years, various textual key-ﬁngerprint repre-
sentations have been proposed. In this section, we ana-
lyze currently practised in-persona key veriﬁcation tech-
niques in well-known applications. For comparison, Ta-
ble 1 lists the approaches we used in our evaluation gen-
erated from the same hash value.

Only applications requiring manual key-ﬁngerprint

1https://minilock.io
2https://peerio.com

3

USENIX Association  

25th USENIX Security Symposium  195

veriﬁcation are considered. In mechanisms like S/MIME
or X.509, ﬁngerprints play only a secondary role because
certiﬁcates are veriﬁed via certiﬁcate chains.

In the following, SHA-1(x)16 deﬁnes the execution of
16 rounds of nested SHA-1 on x, a truncation to the left-
most 16 bits is deﬁned by x[0, . . . ,16], and pk is used as
an abbreviation for the values of a public key (differs for
RSA, DSA, or ECC).

3.1 Numeric
Numeric representation describes the notation of data us-
ing only numeric digits (0-9). The primary advantage of
a such system is that Arabic numerals are universally un-
derstood, and in addition, numeric key-ﬁngerprints show
a similarity to phone numbers. The encoding is achieved
by splitting a binary hash into chunks of equal length
and expressing each chunk as a decimal number, e. g., by
simply switching the representation base from 2 to 10.

The messaging and data exchange application SafeS-
linger3 implements this as a fallback scheme for unsup-
ported languages [14]. A 24 bit SAS in SafeSlinger (cf.
Figure 2a) can be expressed by three decimal encoded
8-bit numbers.

In the messaging platform WhatsApp, a ﬁngerprint
is calculated by SHA-256(pk)5200[0, . . . ,240]. This ﬁn-
gerprint is split up into six chunks, where each chunk
is represented by a ﬁve digits long number modulo
100,000 [43]. Concatenating this ﬁngerprint with the ﬁn-
gerprint of the communication partner results in the dis-
played representation, e. g.,

77658 87428 72099 51303
34908 23247 95615 27317
09725 59699 62543 54320

3.2 Alphanumeric
Alphanumeric approaches use numbers and letters to
represent data. Depending on the representation type
and its parameters, the letters can be presented either
in lower-case or in upper-case. The string can be chun-
ked into groups of characters, which are usually of equal
length. Chunking does not alter the information con-
tained, while changing lower-case letters to upper-case
letters (and vice versa) may does, depending on the cod-
ing scheme. Commonly used representations are Hex-
adecimal, Base32, and Base64.

3.2.1 Hexadecimal
Hexadecimal digits use the letters A-F in addition to nu-
merical digits and are a common representation for key-
ﬁngerprints and primarily used in SSH and OpenPGP.

3https://www.cylab.cmu.edu/safeslinger

Note that the case of the letters do not make any differ-
ence. Regarding chunking, both spaces (cf. Figure 1b)
and colons (cf. Figure 1a) are commonly used as separa-
tion characters.

Key ﬁngerprints in OpenPGP version 4 are deﬁned in

RFC 4880 [7] by

Hex(SHA-1(0x99(cid:31) len(cid:31) 4(cid:31) creation time(cid:31) algo(cid:31) pk))
where len is the length of the packet, creation time is the
time the key has been created and algo is unique iden-
tiﬁer for the public-key algorithm. While the inclusion
of creation time makes sure that even two keys with the
same key material have different ﬁngerprints, it allows an
attacker to iterate through possible past times to generate
similar ﬁngerprints skipping the key generation step [5].
The actual representation of OpenPGP ﬁngerprints is not
deﬁned in RFC 4880, but most implementations chose to
encode them in hexadecimal form, e. g., GnuPG displays
them uppercase in 16 bit blocks separated by whitespaces
with an additional whitespace after 5 blocks (cf. Fig-
ure 1b), e. g.,

73EE 2314 F65F A92E C239

0D3A 718C 0701 0001 2282

Other implementations, such as OpenKeychain, deviate
only slightly, for example by displaying them lowercase
or with colored letters to ease comparison but still pro-
vide compatibility with GnuPG.

SSH ﬁngerprint strings, as deﬁned in RFC 4716 and

RFC 4253 [15, 44], are calculated by

Hex(MD5(Base64(algo(cid:31) pk)))

where algo is a string indicating the algorithm, for ex-
ample “ssh-rsa”. Fingerprints are displayed as “hexadec-
imal with lowercase letters and separated by colons” [15]
(cf. Figure 1a), e. g.,

6f:85:66:da:e3:7a:02:c6:5e:62:3f:36:b7:d9:b4:2c

3.2.2 Base32
Base32 uses the Latin alphabet (A-Z) without the let-
ters O and I (due to the confusion with numbers 1 and
0). There is no difference between lower-case letters and
upper-case letters. In addition, a special padding char-
acter “=” is used, since the conversion algorithm pro-
cesses blocks of 40 bit (5 Byte) in size. The source string
is padded with zeroes to achieve a compatible length
and sections containing only zeroes are represented by
“=” [20, 21].

The ZRTP key exchange scheme for real-time ap-
plications is based on a Difﬁe-Hellman key exchange
extended by a preceding hash commitment that allows
for very short ﬁngerprints, called Short Authentication

196  25th USENIX Security Symposium 

USENIX Association

4

Strings (SAS) without compromising security [45]. The
Base32 encoding used in ZRTP uses a special alphabet
to produce strings that are easier to read out loud. VoIP
applications such as CSipSimple4 use this Base32 op-
tion, usually named “B32” inside the protocol. Here, the
leftmost 20 bits of the 32 bit SAS value are encoded as
Base32. , e. g.,

5 e m g

3.2.3 Base64
There exist a number of speciﬁcations for encoding data
into the Base64 format, which uses the Latin alphabet in
both lower-case and upper-case (a-z, A-Z) as well as the
digits 0-9 and the characters “+”, “/”, and “=” to repre-
sent text data. Again, the character “=” is used to encode
padded input [20]. Starting with OpenSSH 6.8 a new
ﬁngerprint format has been introduced that uses SHA-
256 instead of MD5 and Base64 instead of hexadecimal
representation. In addition the utilized hash algorithm is
prepended, e. g.,

SHA256:mVPwvezndPv/ARoIadVY98vAC0g+P/5633yTC4d/wXE

3.3 Unrelated Words
Instead of (alpha)numeric representation, ﬁngerprints
can be mapped to lists of words. Here, the binary rep-
resentation is split into chunks, where each possible
value of a chunk is assigned to a word in a dictionary.
To increase readability, such a dictionary usually con-
tains no pronouns, articles, prepositions and such. Word
lists, such as the PGP Word List [22] and the Basic En-
glish word list compiled by K.C. Ogden [31], are pri-
marily used for veriﬁcation mechanisms based on SAS.
Key-Fingerprints represented by words have been imple-
mented for VoIP applications based on the ZRTP key
exchange and other real-time communication protocols.
Examples are Signal5, and the messaging and contact
sharing application SafeSlinger [14] (cf. Figure 2). Be-
sides their use in SAS based mechanisms, miniLock and
Peerio utilize unrelated words for passphrase generation.
An example for a modern VoIP implementation that
utilizes ZRTP for key exchange over Secure Real-Time
Transport Protocol (SRTP) is Signal’s private calling fea-
ture, previously distributed as Redphone. The devel-
opers chose to implement only a speciﬁc subset of the
ZRTP speciﬁcation [45], namely Difﬁe-Hellmann key
exchange via P-256 elliptic curves using “B256” SASs,
i. e., Base256 encoding that maps to the leftmost 16 bits
of the 32 bit SAS values to the previously introduced
PGP Word List [22], e. g.,

4https://github.com/r3gis3r/CSipSimple
5https://github.com/WhisperSystems/Signal-Android

(a) SafeSlinger: List of words

(b) OpenKeychain: Sentences

Figure 2: Language-based ﬁngerprint representations

quota holiness

The messaging application SafeSlinger is based on
a Group Difﬁe-Hellman protocol [14] implementing a
key veriﬁcation with SASs for up to 10 participants. In
SafeSlinger the leftmost 24 bits of a SHA-1 hash is used
to select 3 words from the PGP Word List, e. g.,

suspense unify talon.

Besides this, two other 3 word triples are selected to force
users to make a selection before proceeding (cf. Fig-
ure 2a).

In contrast to Signal and SafeSlinger, Peerio (based
on miniLock) does not use any SAS based veriﬁcation
mechanism.
It uses pictures for veriﬁcation and word
lists for code generation. The word list is generated from
most occurring words in movie subtitles. Besides key
veriﬁcation, these are also used to generate so called
passphrases, which are used to derive their ECC private
keys.

3.4 Generated Sentences
The words from the previous dictionaries can also be
used to generate syntactically correct sentences as pro-
posed by previous research: Goodrich et al. proposed
to use a “syntactically-correct English-like sentence”
representation for exchanging hash-derived ﬁngerprints
over audio by using text-to-speech (TTS) [16]. Michael
Rogers et al.
implemented a simple deterministic sen-
tence generator [16, 38]6 Though the sentences from
both approaches rarely make sense in a semantic fash-
ion, they are syntactically correct and are claimed to pro-

6https://github.com/akwizgran/basic-english

USENIX Association  

25th USENIX Security Symposium  197

5

vide good memorability. In our study, we used Michael
Roger’s approach for our sentence generator.

We implemented this method for PGP ﬁngerprints
in OpenKeychain 3.67 (cf. Figure 2b). To the best of
the authors’ knowledge, to this date, it is the ﬁrst inte-
gration of key veriﬁcation via sentences although other
projects are considering to change their ﬁngerprint en-
coding scheme [38, 36].

4 Methodology

In order to evaluate the effect and perception of the dif-
ferent textual key-ﬁngerprint representations, we con-
ducted an online study on Amazon’s Mechanical Turk
(MTurk) crowdsourcing service. Our Universities do not
have an IRB, but the study conformed to the strict data
protection law of Germany and informed consent was
gathered from all participants. Our online study is di-
vided into two parts: The experiment for performance
evaluation followed by a survey extracting self-reported
data from users. The survey ended with demographic
questions.

4.1 Security Assumptions
In this section, we deﬁne the underlying security assump-
tions of our study, such as ﬁngerprint method, length, and
strength against an adversary. The ﬁngerprint method
and parameters are utilized consistently for all experi-
ments in our study to offer comparability between all
possible ﬁngerprint representations. This attack model is
important for the usability since an unrealistically strong
or weak attacker could skew the results. Obviously, if the
ﬁngerprint strength is not kept equal between the systems
this would also skew the results.

4.1.1 Fingerprint Method
To decide upon a ﬁngerprint method for humanly veriﬁ-
able ﬁngerprints in our study, we ﬁrst have to differen-
tiate between human and machine veriﬁcation to illus-
trate their differences. While a full ﬁngerprint compar-
ison can be implemented for machine veriﬁcation, hu-
mans can fall for ﬁngerprints that match only partially.
Additionally, machine comparison can work with long
values, whereas for human veriﬁcation the length must
be kept short enough to ﬁt on business cards and to keep
the time needed for comparison low.

For machine comparison, full SHA-256 hashes should
be calculated binding a unique ID to the public key mate-
rial. The probability of ﬁnding a preimage or collision at-
tack is obviously negligible, but the ﬁngerprints can still
be computed fast in an ad-hoc manner when needed.

7https://www.openkeychain.org

It is important to note that collision resistance is not re-
quired for our scenarios. It is required for infrastructure-
based trust models such as X.509, where certiﬁcates are
veriﬁed by machines and trust is established by authority.
In these schemes, a signature generated by a trusted au-
thority can be requested for a certiﬁcate by proving the
control over a domain, but then reused maliciously for
a different certiﬁcate/domain. This is already possible
with a collision attack, without targeting a full preimage.
In contrast, the direct human-based trust schemes con-
sidered in this study only need to be protected against
preimage attacks, because no inherently trusted author-
ity is involved here.

While machine comparison needs to be done fast, e. g.,
on key import, manual ﬁngerprint veriﬁcation by humans
is done asynchronously in person or via voice. Thus, we
can use a key derivation function to provide a proof-of-
work, effectively trading calculation time for a shorter
ﬁngerprint length. Secure messaging applications such
as Signal or OpenPGP-based ones could pre-calculate
the ﬁngerprints after import and cache these before dis-
playing them for veriﬁcation later.

Thus, modern memory-hard key derivation functions
such as scrypt [34] or Argon2 [3] can be utilized to
shorten the ﬁngerprint length. These key derivation func-
tions are parametrized to allow for different work factors.
Suitable parameters need to be chosen by implementa-
tions based on their targeted devices and protocol.

As discussed in Section 3.2.1, while the generation of
new ﬁngerprints consists of the creation of a new key pair
and the key derivation step, an attacker can potentially
skip the key creation. Thus, in the following we only
consider the key derivation performance as the limiting
factor for brute force attacks.

When utilizing a properly parametrized key derivation
function for bit stretching, the security of a 112 bit long
ﬁngerprint can be increased to require a brute force at-
tack comparable to a classical 2128 brute force attacker.
Consequently, a ﬁngerprint length of 112 bit is assumed
throughout our study.

4.1.2 Attacker Strength for Partial Preimages

In our user study, we assume an average attacker try-
ing to impersonate an existing ID using our ﬁngerprint
method. Thus, an attacker would need to ﬁnd a 112 bit
preimage for this existing ﬁngerprint using a brute force
search executing the deployed key derivation function in
each step. Due to the work factor, we consider this to be
infeasible and instead concentrate on partial preimages.
For comparability and to narrow the scope of our study,
an attacker is assumed that can control up to 80 bits of
the full 112 bit ﬁngerprint.

Attackers might aim to ﬁnd partial preimages where

198  25th USENIX Security Symposium 

USENIX Association

6

the uncontrolled bits occur at positions that are more eas-
ily missed by inattentive users. First, the bits at the be-
ginning and the end should be ﬁxed as users often begin
their comparison with these bits. Thus, we assume that,
for any representation method, the ﬁrst 24 and last 24
bits are controlled by the attacker and thus the same as in
the existing ﬁngerprint. Based on the feedback from our
pre-study participants and reports from related work, this
can be considered best-practice [17, 37]. Second, of the
remaining 64 bits in the middle of our 112 bit ﬁngerprint,
we assume that 32 bits are controlled by the attacker in
addition to the ﬁrst 24 and last 24 bits. In total, we as-
sume that 80 bits are controlled by the attacker, i. e., are
the same as in the existing ﬁngerprint, and 32 bit are un-
controlled.

The probability of ﬁnding such a partial preimage for
a ﬁngerprint when executing 249 brute force steps is cal-
culated approximately by

1−(cid:31)2112 − ∑32

2112

k=1(cid:30)64
k(cid:29)

(cid:28)249

≈ 0.66.

32(cid:29), a sum over 32

Instead of using (cid:30)64

The inner parentheses of this equation deﬁne the prob-
ability that no partial preimage exists for one speciﬁc
bit permutation.
variations has been inserted to include permutations with
more than the uncontrolled 32 bit that are also valid par-
tial preimages. Finally, the probability to ﬁnd a par-
tial preimage is deﬁned by the inverse of the exponen-
tiation. Assuming the scrypt key derivation function
parametrized with (N,r, p) = (220,8,1), Percival calcu-
lates the computational costs of a brute force attack
against 238 (≈ 268) hashed passwords with $610k and
253 (≈ 958) with $16B [34]. These costs can be consid-
ered a lower and upper bound for our attacker, which we
assume to have average capabilities and resources. While
238 has a probability of ﬁnding a partial preimage of only
0.05%, with 242 the probability reaches nearly 1%, and
with 249, as in our example, a partial preimage is found
with over 50%.

In our study, we simulate attacks by inverting the bits
from the existing ﬁngerprint which are uncontrolled by
the attacker, while the controlled bits are unchanged.
For our theoretical approximation, we assume that the
ﬁrst 24 and last 24 bits should be controlled as well as
32 bits from the middle. In our study, we simulate an
even more careful selection of appropriate ﬁngerprints
from the ones that an attacker would brute force. A gen-
eral criteria here is to minimize the inﬂuence of uncon-
trolled bits on the entire ﬁngerprint: For numeric and al-
phanumeric representations all bits affecting a character
or digit are inverted together. For unrelated words, all
bits affecting a word are changed. Sentences are never
changed in a way that would alter the sentence structure.

Figure 3: A screenshot of the actual task a user had to per-
form in the experiment. A user rates whether the security codes
match, in this case with the Peerio word list approach, by click-
ing on the corresponding buttons shown on the phone.

4.2 Pre-Study
To get additional feedback from participants and eval-
uate our study design for ﬂaws and misunderstandings,
we conducted two small pre-studies: A lab study with 15
participants and an MTurk experiment with 200 partic-
ipants, all required to perform 10 comparisons for each
representation scheme (totally 60 comparisons in a ran-
domized order).
In our lab-study, we mainly focused
on qualitative feedback, whereas the main goal of the
MTurk pre-study was to ﬁnd ﬂaws in the presentation
and task descriptions, as well as to check whether our
proposed methodology is received as expected.

The biggest problem we found regarding the study de-
sign was that participants were uncertain if they should
check for spelling mistakes in the words and sentence-
based representation or if the all attacks would change
entire words. To clarify this, a speech bubble was in-
cluded in the task description that the participants do not
have to look for spelling mistakes for language-based ap-
proaches.

We tested different rates of attack during the pre-study.
The results showed that participants who were exposed
to frequently occurring attacks were more aware and had
a much higher attack detection rate. For our main study,
we reduced the number of attacks to 40 comparisons with
4 attacks to have a good balance between true positives
and false negatives. We received feedback that attacks
on anchor parts of the strings, i. e., in the beginning,
end, and at line breaks could be easily detected. Many
users had problems with distinguishing the hexadecimal
from the Base32 representation as well as distinguish-
ing different word list approaches (Peerio vs. OpenPGP
word list). Thus, we opted for a mixed factorial study

USENIX Association  

25th USENIX Security Symposium  199

7

design where users test only one scheme of each type.
We grouped the hexadecimal and Base32 scheme for the
alphanumeric type and the PGP and Peerio for the word-
list type together. These two groups were tested between-
subjects in a split-plot design, i. e., the participants test
either hexadecimal or Base32 for the alphanumeric type.
See Table 2 for a graphical representation of our condi-
tion assignment design.

4.3 Experiment Design
The main part of our online study is the experiment
part where users perform actual ﬁngerprint comparisons.
Here, we conducted two separate experiments with a dis-
tinct set of participants: (1) our main experiment test-
ing different textual high-level representation schemes
against each other and (2) a secondary experiment testing
different chunk sizes for the hexadecimal representation.
We opted for two distinct experiments due to the expo-
nential growth of experiment conditions, as described in
Section 4.3.1.

Before letting the participants start our experiment, we

explained the scenario:

“With this HIT, we are conducting an aca-
demic usability study followed by a short sur-
vey about different types of security codes
used in the IT world. Security codes are of-
ten used in encrypted communications to iden-
tify the participants in a communication. If the
security codes match, you are communicating
securely. If they don’t match, an eavesdropper
may be intercepting your communication”.

On MTurk, the term Human Intelligence Task, or HIT
stands for a self-contained task that a worker can work
on, submit answers, and get a reward for completing.
Since our participants might not be familiar with the key-
ﬁngerprint representation term, we replaced it with se-
curity codes for the sake of the study.

We opted not to obfuscate the goal of the study since
our research aims at ﬁnding the best possible representa-
tion for the comparison of key-ﬁngerprints in a security
context. This is closest to how users interact with ﬁnger-
prints in the real world — their secure messaging appli-
cations also ask them to compare the strings for security
purposes. The question how to motivate users to compare
ﬁngerprints is an entirely different research question. So
in our case, we believe it was not necessary or desirable
to use deception and since deception should be used as
sparingly as possible we opted for the “honest” approach.
After agreeing the terms, participants are shown a ﬁc-
titious business card next to a mobile phone, both dis-
playing a security code (as shown in Figure 3). To
become more familiar with the task, the experiment is

Type (Within-Group)
Alphanumeric
Numeric
Unrelated Words
Generated Sentences

Scheme (Between-Group)
Hexadecimal XOR Base32
Numeric
PGP XOR Peerio
Generated Sentences

Table 2: To avoid confusion between too similar approaches
(cf. Section 4.2), in our condition assignment, scheme types
(left column) can consist of multiple representation schemes
(right column). Each participant tests only one randomly as-
signed scheme of each type in a randomized order. .

started with 4 training tasks (each method once) not con-
sidered in the evaluation. The user’s only task is to
rate whether the shown ﬁngerprints match by clicking on
Match or Doesn’t Match on the phone. Based on the con-
dition assignment, participants see different approaches
in a randomized order. We measure whether their an-
swer was correct and their speed, i. e., the amount of time
spent on the comparison. The experiment is concluded
with a survey collecting feedback on the used approaches
and the tasks and demographic information discussed in
the “Results” section.

4.3.1 Variables and Conditions

In the main experiment, the used representation scheme
is our controlled independent variable whereas its val-
ues deﬁne our experiment conditions. In our additional
chunking experiment, the chunking size is our controlled
independent variable instead of the representation algo-
rithm. During all tasks, we measure how fast participants
perform with their given conditions and whether they are
able to detect attacks by rating “incorrect” (speed and
accuracy as our measured dependent variables).

In both experiments, each user had to perform 46 com-
parisons in total. To detect users clicking randomly, 2
obviously distinct comparisons were added to test a par-
ticipant’s attention. Training comparisons and attention
tests are not included in the evaluation. Based on the
feedback in our pre-study, we added tooltips during the
training comparisons giving hints for language-based ap-
proaches telling the user that spelling attacks would not
occur. We set the number of attacks to six: two obvious
attacks where all bits are altered serving as control ques-
tions and 4 actual attacks with partial 80-bit preimages
(one for each representation scheme). Participants failing
at the control attacks are not considered in the evaluation
but still received a payment if ﬁnishing all tasks. The
major challenge in the study design is a high attack de-
tection rate in general: most users perform comparisons
correctly for the given attacker strength.

To avoid side effects, we chose ﬁxed font size, color

200  25th USENIX Security Symposium 

USENIX Association

8

Figure 4: A screenshot showing a statement rating in the post-experiment survey. Since the participants might
not distinguish the different types, we have provided an example from their previous task.

and style, i. e., the same typeface for all ﬁngerprint rep-
resentations. In addition, we set ﬁxed line breaks for sen-
tences and word lists. In the main experiment, the same
chunking style was used for all representations: For (al-
pha)numeric approaches a chunk consists of four charac-
ters separated by spaces. For word lists, we opted for a
line break every four words. In the generated sentences
representation, one sentence per line is displayed. We are
aware that all these design decisions can have an effect
on the comparison of the representations. However, our
pre-study results show a signiﬁcantly lower effect size.
More importantly, we are mainly interested in compar-
ing the concepts, therefore we did not vary any of the
visual attributes like font size or style. In particular, dif-
ferences resulting from the font’s typeface have not been
evaluated. Lund showed in his meta-analysis that there
are no signiﬁcant legibility differences between serif and
sans serif typefaces [25].

Chunk-Size Testing A question was raised whether
the chunking of a hexadecimal string plays a greater role
in comparison to the different approaches. Thus, in addi-
tion to the main experiment testing different representa-
tion types, we conducted a second experiment with new
participants testing different chunk sizes for the hexadec-
imal representation. Here, we used chunk-sizes ranging
from 2 to 8 in addition to “zero-chunk size” (8 cases).
The zero-chunk size means that no spaces have been in-
cluded. To make the results more comparable, we opted
for a similar design as done in the major experiment, i. e.,
we required the same amount of comparisons, used the
same font settings, and had the same amount of attacks.
For each participant, we assigned 4 out of 8 different
chunk-sized randomly. Same as in the major experiment,
all participants had to compare 46 ﬁngerprints whereas
the ﬁrst 4 are considered as training comparisons, 4 at-
tacks (one for each chunk size), and 2 control attacks
with obviously distinct ﬁngerprints.

The major experiment is followed by a survey fo-

cusing on self-reported user perception and opinions
about the different approaches. This is the main reason
we opted to compare as much as possible in a within-
groups fashion and only selected a small number of con-
ditions in total. Since users might not notice the dif-
ference between the various dictionary or alphabet ap-
proaches, we designed a mixed factorial design where
the users would only get one of the alphabets/dictionar-
ies (between-subjects) but they would test all different
high-level systems (within-group) as depicted in Table 2.
The between-group conditions have been assigned ran-
domly with a uniform distribution. Since participants
from our pre-study had difﬁculties to distinguish the dif-
ferent chunking approaches, we skipped the survey part
in the chunk-size experiment.

4.3.2 Online Survey

The experiment was followed by an online survey gath-
ering self-reported data and demographics from partic-
ipants. To measure perception, we asked the partici-
pants whether they agreed with statements discussed in
subsection 5.2 on a 5 point Likert scale: from strongly
disagree to neural strongly agree as shown in Figure 4.
Participants had to rate each representation type for all
statements. Since users might not distinguish the differ-
ent representation schemes, we provide an example from
their previously ﬁnished task.

4.3.3 Statistical Testing
We opted for the common signiﬁcance level of α = 0.05.
To counteract the multiple comparisons problem, we use
the Holm-Bonferronicorrection for our statistical signif-
icance tests [18]. Consequently, all our p-values are re-
ported in the corrected version.

We test

the comparison duration with the Mann-
Whitney-Wilcoxon (MWW) test (two-tailed). We opt for
this signiﬁcance test due to a few outliers, consequently a

USENIX Association  

25th USENIX Security Symposium  201

9

Scheme

Hexadecimal
Hexadecimal – Base32
Hexadecimal – Numeric
Hexadecimal – PGP
Hexadecimal – Peerio
Hexadecimal – Sentences
Base32
Base32 – Hexadecimal
Base32 – Numeric
Base32 – PGP
Base32 – Peerio
Base32 – Sentences
Numeric
Numeric – Hexadecimal
Numeric – Base32
Numeric – PGP
Numeric – Peerio
Numeric – Sentences
PGP
PGP – Hexadecimal
PGP – Base32
PGP – Numeric
PGP – Peerio
PGP – Sentences
Peerio
Peerio – Hexadecimal
Peerio – Base32
Peerio – Numeric
Peerio – PGP
Peerio – Sentences
Sentences
Sentences – Hexadecimal
Sentences – Base32
Sentences – Numeric
Sentences – PGP
Sentences – Peerio

Speed

mean [s] med [s]
10.0
1.1
0.5
−1.2
2.7
−0.7
8.9
−1.1
−0.6
−2.3
1.6
−1.8
9.5
−0.5
0.6
−1.7
2.2
−1.2
11.2
1.2
2.3
1.7
3.9
0.5
7.3
−2.7
−1.6
−2.2
−3.9
−3.4
10.7
0.7
1.8
1.2
−0.5
3.4

11.2
1.0
0.6
−1.8
2.5
−1.1
10.2
−1.0
−0.4
−2.8
1.5
−2.1
10.6
−0.6
0.4
−2.4
1.9
−1.7
13.0
1.8
2.8
2.4
4.3
0.7
8.7
−2.5
−1.5
−1.9
−4.3
−3.6
12.3
1.1
2.1
1.7
−0.7
3.6

p-val

stdev
6.4
0.0 <0.001
0.6 <0.001
−1.0 <0.001
0.8 <0.001
−0.6 <0.001
6.4
−0.0 <0.001
0.6 <0.001
−1.0 <0.001
0.8 <0.001
−0.6 <0.001
5.8
−0.6 <0.001
−0.6 <0.001
−1.6 <0.001
0.2 <0.001
−1.2 <0.001
7.4
1.0 <0.001
1.0 <0.001
1.6 <0.001
1.8 <0.001
0.4 <0.001
5.6
−0.8 <0.001
−0.8 <0.001
−0.2 <0.001
−1.8 <0.001
−1.4 <0.001
7.0
0.6 <0.001
0.6 <0.001
1.2 <0.001
−0.4 <0.001
1.4 <0.001

Accuracy

p-val

f-pos
fail-rate
0.49
10.44
0.690 −2.09
−1.94
0.21
0.048
−4.10
−1.65
0.690 −0.01
0.08
0.048
−4.69
−7.45 <0.001 −0.99
2.58
8.50
2.09
1.94
0.690
−2.16
2.30
0.404
2.08
0.28
0.714
2.17
−2.75
0.404
1.10
−5.51 <0.001
6.34
0.28
0.048 −0.21
4.10
0.404 −2.30
2.16
2.45
0.404 −0.22
0.714 −0.13
−0.59
0.004 −1.20
−3.35
0.50
8.78
0.690
0.01
1.65
−0.28
0.714 −2.08
0.22
0.404
−2.45
0.337
−3.03
0.09
−5.79 <0.001 −0.98
5.75
0.41
0.048 −0.08
4.69
2.75
0.404 −2.17
0.13
0.714
0.59
0.337 −0.09
3.03
0.075 −1.07
−2.76
1.48
2.99
7.45 <0.001
0.99
5.51 <0.001 −1.10
1.20
3.35
0.004
0.98
5.79 <0.001
2.76
0.075
1.07

fails
50
12
−9
11
22
22
38
−12
−21
−1
10
10
59
9
21
20
31
31
39
−11
1
−20
11
11
28
−22
−10
−31
−11
0
28
−22
−10
−31
−11
0

Total
attacks
479
32

tests
4765
269
−452 −4527
340
35
−91
−8
−457 −4518
447
4496
−32
−269
−484 −4796
71
3
−40
−360
−489 −4787
931
9292
4527
452
4796
484
4867
487
4436
444
9
−5
4425
444
−35
−340
−3
−71
−487 −4867
−43
−431
−492 −4858
4856
487
91
8
360
40
−444 −4436
431
−449 −4427
9283
936
4518
457
4787
489
5
−9
4858
492
4427
449

43

Table 3: Our experiment results showing the differences between the representation schemes. The top rows of each row group
separated by a rule, show the raw performance of a baseline scheme, followed by italic rows showing a direct comparison delta.
Greyed-out values are not backed by statistical signiﬁcance. The columns fail-rate (undetected attacks) and false-pos (same string
rated as an attack) display percentage values.

slightly skewed normal distribution, and a large amount
of collected data. The common language effect size is
shown by mean and median comparisons [26].

The attack detection rate is tested with a pairwise
Holm-Bonferroni-corrected Barnard’s exact test (Exakt
package in R) achieving one of highest statistical power
for 2x2 contingency tables [2].

Survey ratings are, again, tested by using the MWW
signiﬁcance test (two-tailed test). As has been shown in
previous research [9], it is most suitable for 5-point Lik-
ert scales, especially if not multimodal distributed as in
our survey results. In case two ﬁngerprint representation
schemes are statistically tested against each other, only
participants encountering both schemes were considered.

5 Results

In this section, we present our results: our online study
with 1047 participants has been conducted in August and
September 2015. The study for testing the chunk size has
been conducted in February 2016 with 400 participants.
Starting with our online experiment evaluation showing
the raw performance of users, we then present user per-
ception results from the follow-up survey. Finally, we
discuss the demographics of our participants.

5.1 Online Experiment
Participants who have not ﬁnished all comparisons or
failed the attention tests were excluded from our eval-

202  25th USENIX Security Symposium 

USENIX Association

10

Scheme

Hexadecimal (4)
hex (4) – hex (0)
hex (4) – hex (2)
hex (4) – hex (3)
hex (4) – hex (5)
hex (4) – hex (6)
hex (4) – hex (7)
hex (4) – hex (8)

p-val

Speed
mean [s] med [s]
10.4
−2.6 <0.001
−0.9 <0.001
0.362
0.1
−1.2 <0.001
−1.8 <0.001
−1.8 <0.001
−3.2 <0.001

12.3
−2.4
−0.3
−0.3
−1.4
−1.9
−1.7
−2.8

fail-rate
6.78
0.33
1.37
−0.64
1.01
2.43
3.35
1.35

Accuracy

p-val

false-pos

1.000
1.000
1.000
1.000
1.000
1.000
1.000

0.38
−0.28
0.00
0.09
−0.40
0.09
0.19
−0.12

Total
attacks
236
−17
3
8
5
8
−1
−10

fails
16
−2
−3
2
−2
−5
−8
−4

tests
2360
−170
30
80
50
80
−10
−100

Table 4: Comparison of the chunking experiment results showing the differences between the representation schemes. The top row
shows the raw performance of the hexadecimal scheme with a four-character chunking, followed by italic rows showing a direct
comparison delta. Greyed-out values are not backed by statistical signiﬁcance. The columns fail-rate (undetected attacks) and
false-pos (same string rated as an attack) display percentage values.

uation: all participant compared 46 security codes in a
randomized order, whereas 40 (10 of each scheme) were
considered in the evaluation. The four training samples
and the control questions are excluded. Few comparisons
done in less than 2 seconds and more than one minute
have been excluded. The reason for such can either be
multiple clicks during the page load, or external inter-
ruptions of the participants. None of the attack could be
successfully detected in under 4 seconds.

Our experiment results, summarized in Table 3, show
the raw performance of all schemes regarding their
speed, accuracy and false-positive rate. The top rows of
each row group, separated by a rule, show the raw perfor-
mance of a representation scheme as baseline (negative
values indicate lower values than the baseline). The fol-
lowing rows show a direct comparison delta between be-
tween two schemes. The speed column group consists of
the mean and median (in seconds), the standard deviation
and the according p-values for a direct comparison. The
fail-rate column shows the rate of the undetected attacks
with the according p-values for a direct comparison. The
total column group simply shows the total numbers of
tests, attacks and undetected attacks.

The results show that the average time spent on com-
parisons plays only a minor role among the schemes:
4.3s difference between the best and the worst scheme.
Note that the Peerio word-list scheme performed best
with 8.7s mean whereas the PGP word list performed
worst with 13s mean (p < 0.001).

However, there is a clear effect regarding the attack de-
tection rate (see Table 3). All alternative key-ﬁngerprint
representations performed better than the state-of-the-
art hexadecimal representation, where 10.1% of attacks
have not been detected by the users. Previous work
shows similar numbers for Base32 [19]. To our surprise,
the numeric approach performs better in both categories:
it features an attack detection rate of 93.57% (p < 0.01)
and an average speed of 10.6s (p < 0.001). Generated
sentences achieved the highest attack detection rate of

97.97% with a similar average speed as the hexadecimal
scheme. On the downside, this scheme has produced a
slightly higher false-positive rate. We found that the false
positives occurred mostly with longer sentences where
there has been a line break on the phone mock-up due
to portrait orientation. This is a realistic problem of this
system if used with portrait orientation and not a problem
with our mock-up in itself. Improvements on making the
sentences shorter could mitigate this situation.

Chunk-Size Experiment

Table 4 summarizes the results of our secondary chunk-
size experiment. As can be seen, no statistically signif-
icant results have been achieved for the attack detection
fail-rate (undetected attacks by end users). However, we
observed that the chunk sizes with 3 and 4 characters per-
formed best in speed, even though the effect sizes were
minor: only 3.3 seconds difference with similar standard
deviations between the best and worst chunk size setting.
Firstly, we notice that despite the same attack strength
as in our major experiment, participants were able to de-
tect more attacks. We suspect that the higher attack de-
tection rate is based on (1) a higher learning effect due
to the same scheme for all comparisons and (2) in con-
trast to our major study, participants had a slightly higher
drop-out rate and thus only more motivated participants
were considered. This is supported by the numbers in the
total tests column of Table 4: here, we can see that for
the zero-chunking and chunking with 8 characters less
tests have been performed. This is based on the fact that
although the chunk sizes have been assigned almost uni-
formly, participants assigned with harder chunk settings
often dropped out before even ﬁnishing their entire task.
More importantly, our results also support the claim
from our pre-study: The chunking parameter in hexadec-
imal strings plays only a minor role in the attack detec-
tion fail-rate.

USENIX Association  

25th USENIX Security Symposium  203

11

Alphanumeric
Numeric
Unrelated Words
Generated Sentences

5%
8%
8%
12%

Alphanumeric
Numeric
Unrelated Words
Generated Sentences

17%
9%
6%
5%
100

Trustworthiness

Usability

82%
76%
75%
67%

63%
76%
80%
85%

50

0

Percentage

50

100

Response

Strongly Disagree

Disagree

Neutral

Agree

Strongly Agree

Figure 5: Aggregated survey results for statement rating regarding the usability and trustworthiness.

5.2 Online Survey
To measure the usability and trustworthiness of all rep-
resentation schemes, we asked our participants whether
they agreed with the following statements:

S1 The comparisons were easy for me with this method

S2 I am conﬁdent that I can make comparisons using this

method without making mistakes

S3 I think making comparisons using this method would

help me keep my communications secure

S4 I was able to do the comparisons very quickly with

this method

S5 I found this method difﬁcult to use

S6 Overall, I liked this method

We mixed positive and negative statements, e. g., S1
and S5, to create a more robust measure. S6 is used to
calculate the overall ranking of the different representa-
tion schemes.

Figure 5 shows the aggregated results where the us-
ability statements are grouped to one usability feature
and the trustworthiness derived from the rating on the
statement S3. Negative statement ratings have been in-
verted for a better comparison. Figure 6 shows the rating
results for each speciﬁc statement in the survey. The or-
der of the tested schemes has been chosen randomly, but
was kept consistent across all statements. Same as in
our online experiment evaluation, the pairwise statistical

tests are Holm-Bonferroni corrected. In case of a direct
statistical test between two schemes, only users encoun-
tering both schemes have been considered. All in all, the
usability perception of the participants is almost consis-
tent with the performance results from the experiment.

To measure the perception of the task difﬁculty, we
asked the participants whether they agreed with the state-
ments S1, S2 and S3 respectively. As illustrated in Fig-
ure 6 in the Appendix A, the effect size between the dif-
ferent approaches is low. However, the participants were
more likely to agree that language-based representation
schemes are easier to use. For instance, we see that in
comparison to the alphanumeric schemes (average rat-
ing of 3.4), word list (average rating of 3.9, p < 0.001)
and generated sentence schemes (average rating of 4.2,
p < 0.001 ) are rated to be easier by our participants (S1,
S5). While the experiment results of the sentence genera-
tors clearly outperformed all other approaches, they also
were rated better by the participants. Same applies for
the low-performing hexadecimal and Base32 schemes
which clearly received lower ratings. Consistently with
the surprising performance results in the experiment, the
numeric scheme is also considered to be easier by many
participants: average rating of 3.9 and p < 0.001.

The sentence generator scheme achieved the highest
user conﬁdence rating “making comparisons without any
mistakes” (S2, p < 0.001 for all pairwise comparisons).
The participants’ perception is consistent with the ex-
periment results where the word-list-based and sentence
generator schemes lead to higher attack detection rates.

204  25th USENIX Security Symposium 

USENIX Association

12

The ratings for S4 illustrate that more complex repre-
sentation schemes from the user’s point of view, such as
hexadecimal and Base32, are considered to be more se-
cure by participants, even though all approaches provide
the same level of security.

5.3 Demographics
A total of 1047 users participated in the online study
while only 1001 have been considered in the evaluation
due to our two control questions. Out of the evaluated
participants, 534 participants were male, 453 were fe-
male, 4 chose other while the rest opted to not give any
information. No signiﬁcant difference between genders
could be found, with a subtle trend of a higher accuracy
for women and higher speed among men. The median
age was 34 (34.4 average) years, while 34 participants
chose not to answer (no statistically signiﬁcant differ-
ences between ages).

A total of 39 people reported to have “medical con-
ditions that complicated the security code comparisons
(e. g., reading disorders, ADHD, visual impairments,
etc.)” with a slightly higher undetected attack rate (sta-
tistically insigniﬁcant due to small sample size and thus
low statistical power).

The majority of the participants stated to have a Bach-
elor’s degree (399 of 1047) as their highest education
whereas 34% chose not to answer. 931 participants have
started our HIT but stopped early during the experiment
(mostly after the ﬁrst few comparisons). 160 users re-
ported the general task to be annoying.

6 Discussion

The results of our study show that while there are subtle
speed variations among all approaches, the attack detec-
tion rate and user perception for the current state-of-the-
art hexadecimal key-ﬁngerprint representation is signif-
icantly lower than those of most alternative representa-
tion schemes. Language-based representations (with the
exception of the PGP word list) show improved user be-
haviour leading to a higher detection rate of attacks. To
improve the usability of key-ﬁngerprints, we propose the
following takeaways based on our study results.

6.1 Takeaways
Our results show that all representation schemes achieve
a high accuracy (high attack detection rate) and can be
performed quickly by users. As expected, language-
based ﬁngerprint
representations are more resilient
against attacks (higher attack detection rate) and achieve
better usability scores. Among all conditions, alphanu-
meric approaches performed worse and have been out-

performed. For instance, the numeric representation was
more suitable than hexadecimal and Base32. The raw
performance results suggest a similar speed for the nu-
meric representation with a higher attack detection rate,
and it also has received better usability ratings from end-
users.

Our chunking experiment has shown that chunk-sizes
play only a minor role in improving attack detection rates
(we could not ﬁnd statistically signiﬁcant differences).
However, if a hexadecimal representation is used chunks
of 3 and 4 characters perform best.

As shown by the word list representations, the compar-
ison speed can be increased by larger dictionaries leav-
ing room for improvement in this area. Even though all
representation schemes provide the same level of secu-
rity, exotic looking solutions are considered to be more
secure by end users.

6.2 Limitations
Most importantly, our study design does not test whether
end users are actually willing to compare any ﬁnger-
prints in practice. We only aim to study how easy differ-
ent representations are to compare from the users’ point
of view.

As with any user study conducted with MTurk, there
is concern about the external validity of the results: users
in the real world might show different behaviour. This
is mainly because of two reasons: (1) in practice ﬁnger-
print comparisons will seldom occur in a such frequency,
and (2) when performed in practice play a more impor-
tant role than just participating in an anonymous online
study. Additionally, MTurkers have been shown to be
more tech-savvy and are better in solving textual and vi-
sual tasks in comparison to the average population. Thus,
they could have performed better in most of the compar-
ison conditions than the average population.
It is also
known that some MTurkers just “click through” studies
to get the fee and thus distort study results. Our coun-
terbalanced study design with included control questions
and statistical signiﬁcance tests mitigate this effect. For
instance, we excluded 46 out of 1047 participants from
our main study part based on these questions being an-
swered incorrectly.

Due to the within-group part of our factorial design,
many parameter choices such as different fonts, font
sizes, attack rates, etc. could not be considered. These
are, however, interesting avenues for future work. As
shown in our additional chunking experiment, another
challenge in testing different parameters is the high at-
tack detection rate, where subtle changes would require
a high amount of users to produce statistically signiﬁcant
results.

Due to the anonymous nature of online studies, it is

USENIX Association  

25th USENIX Security Symposium  205

13

also impossible to reliably tell which languages a partic-
ipant is ﬂuent in. We speciﬁed that we only wanted par-
ticipants from English-speaking countries, however we
had no way of checking compliance except by relying
on self-reported data. Language-based representation ap-
proaches might induce additional barriers for non-native
speakers, e. g., due to unknown or unfamiliar words.

7 Conclusion and Future Work

We evaluated six different key-ﬁngerprint representation
types with regards to their comparison speed, attack de-
tection accuracy and usability, which encompasses at-
tack detection but also resilience against human errors
in short-term memory. An online study with 1047 partic-
ipants was conducted to compare numeric, alphanumeric
(Hexadecimal and Base32), word lists (PGP and Peerio),
as well as generated sentences representation schemes
for key-ﬁngerprint veriﬁcation. All ﬁngerprint represen-
tations were conﬁgured to offer the same level of security
with the same attacker strength.

Our results show that usage of the large word lists (as
used in Peerio) lead to the fastest comparison perfor-
mance, while generated sentences achieved highest at-
tack detection rates. In addition, we found that additional
parameters such as chunking of characters plays only a
minor role in the overall performance. The widely-used
hexadecimal representation scheme performed worst in
all tested categories which indicates that it should be re-
placed by more usable schemes. Unlike proposals which
call for radically new ﬁngerprint representations, we
studied only textual ﬁngerprint representations, which
means that the results of our work can be directly applied
to various encryption applications with minimal changes
needed. Speciﬁcally, no new hardware or complex soft-
ware is required: applications merely need to replace the
strings they output to achieve a signiﬁcant improvement
in both attack-detection accuracy and usability.

There are various interesting areas of future work.
Firstly, we chose to study only a selected sample from the
design space of ﬁngerprint representations in a within-
subjects design, so we could facilitate a direct compar-
ison between the different classes of ﬁngerprints. Fur-
ther work exploring line breaks, font settings, dictionar-
ies, different attacker strengths, etc. will likely lead to
further improvement possibilities.

While this work shows that there are better ways to
represent key-ﬁngerprints than currently being used, it
does not explore what can be done to motivate more users
to actually compare the ﬁngerprints in the ﬁrst place.
Follow-up studies to research this important question are
naturally an interesting and vital area of research.

Acknowledgments

The authors would like to thank the anonymous review-
ers for their insightful comments, and Trevor Perrin, Jake
McGinty, Tom Ritter and Skylar Nagao for their discus-
sion and excellent feedback.

References
[1] BADDELEY, A. Working memory. Science 255, 5044 (1992),

556–559.

[2] BARNARD, G. Signiﬁcance tests for 2×2 tables. Biometrika

(1947), 123–138.

[3] BIRYUKOV, A., DINU, D., AND KHOVRATOVICH, D. Argon2:
the memory-hard function for password hashing and other appli-
cations. Tech. rep., Password Hashing Competition (PHC), De-
cember 2015.

[4] BONNEAU, J., AND SCHECHTER, S. Towards reliable storage
of 56-bit secrets in human memory. In Proceedings of the 23rd
USENIX Security Symposium (August 2014).

[5] BREITMOSER, V. pgp-vanity-keygen. https://github.com/

Valodim/pgp-vanity-keygen, 2014.

[6] BUCKNER, R. L., PETERSEN, S. E., OJEMANN, J. G., MIEZIN,
F. M., SQUIRE, L., AND RAICHLE, M. Functional anatomical
studies of explicit and implicit memory retrieval tasks. The Jour-
nal of Neuroscience 15, 1 (1995), 12–29.

[7] CALLAS, J., DONNERHACKE, L., FINNEY, H., SHAW, D., AND
THAYER, R. OpenPGP Message Format. RFC 4880 (Proposed
Standard), Nov. 2007. Updated by RFC 5581.

[8] CRANNELL, C., AND PARRISH, J. A comparison of immedi-
ate memory span for digits, letters, and words. The Journal of
Psychology 44, 2 (1957), 319–327.

[9] DE WINTER, J. C., AND DODOU, D. Five-point Likert items: t
test versus Mann-Whitney-Wilcoxon. Practical Assessment, Re-
search & Evaluation 15, 11 (2010), 1–12.

[10] DHAMIJA, R. Hash visualization in user authentication. In CHI
’00 Extended Abstracts on Human Factors in Computing Systems
(New York, NY, USA, 2000), CHI EA ’00, ACM, pp. 279–280.
[11] DIERKS, T., AND RESCORLA, E. The Transport Layer Security
Protocol Version 1.2. RFC 5246, Aug. 2008. Updated by RFCs
5746, 5878, 6176.

[12] ELECTRONIC

FRONTIER

Messaging
secure-messaging-scorecard, 2014.

Scorecard.

FOUNDATION.

Secure
https://www.eff.org/

[13] ELLISON, C., ET AL. Establishing identity without certiﬁcation
authorities. In USENIX Security Symposium (1996), pp. 67–76.
[14] FARB, M., LIN, Y.-H., KIM, T. H.-J., MCCUNE, J., AND
PERRIG, A. Safeslinger: easy-to-use and secure public-key ex-
change. In Proceedings of the 19th annual international confer-
ence on Mobile computing & networking (2013), ACM, pp. 417–
428.

[15] GALBRAITH, J., AND THAYER, R. The Secure Shell (SSH) Pub-

lic Key File Format. RFC 4716 (Informational), Nov. 2006.

[16] GOODRICH, M. T., SIRIVIANOS, M., SOLIS, J., TSUDIK, G.,
AND UZUN, E. Loud and clear: Human-veriﬁable authentica-
tion based on audio.
In Distributed Computing Systems, 2006.
ICDCS 2006. 26th IEEE International Conference on (2006),
IEEE, pp. 10–10.

[17] GUTMANN, P. Do users verify SSH keys? USENIX;login: 36, 4

(2011).

206  25th USENIX Security Symposium 

USENIX Association

14

[18] HOLM, S. A simple sequentially rejective multiple test proce-

dure. Scandinavian journal of statistics (1979), 65–70.

[19] HSIAO, H.-C., LIN, Y.-H., STUDER, A., STUDER, C., WANG,
K.-H., KIKUCHI, H., PERRIG, A., SUN, H.-M., AND YANG,
B.-Y. A study of user-friendly hash comparison schemes.
In
Computer Security Applications Conference, 2009. ACSAC’09.
Annual (2009), IEEE, pp. 105–114.

[20] JOSEFSSON, S. The Base16, Base32, and Base64 Data Encod-

ings. RFC 3548 (Informational), July 2003.

[21] JOSEFSSON, S. The Base16, Base32, and Base64 Data Encod-

ings. RFC 4648, Oct. 2006.

[22] JUOLA, P. Whole-word phonetic distances and the PGPFone
alphabet. In Spoken Language, 1996. ICSLP 96. Proceedings.,
Fourth International Conference on (1996), vol. 1, IEEE, pp. 98–
101.

[23] KEITH, M., SHAO, B., AND STEINBART, P. A behavioral anal-
ysis of passphrase design and effectiveness. Journal of the Asso-
ciation for Information Systems 10, 2 (2009), 2.

[24] LAURIE, B., LANGLEY, A., AND KASPER, E. Certiﬁcate Trans-

parency. RFC 6962 (Experimental), June 2013.

[25] LUND, O. Knowledge construction in typography: the case of
legibility research and the legibility of sans serif typefaces. PhD
thesis, The University of Reading, Department of Typography &
Graphic Communication., 1999.

[26] MCGRAW, K. O., AND WONG, S. A common language effect

size statistic. Psychological bulletin 111, 2 (1992), 361.

[27] MELARA, M. S., BLANKSTEIN, A., BONNEAU, J., FREED-
MAN, M. J., AND FELTEN, E. W. CONIKS: A Privacy-
Preserving Consistent Key Service for Secure End-to-End Com-
munication. Tech. Rep. 2014/1004, Cryptology ePrint Archive,
December 2014.

[38] ROGERS, M., AND PERRIN, T.

Key-Fingerprint Poems.
https://moderncrypto.org/mail-archive/messaging/
2014/000125.html, 2014.

[39] RYAN, M. D. Enhanced certiﬁcate transparency and end-to-end

encrypted mail. In NDSS (2014), NDSS.

[40] SHAY, R., KELLEY, P. G., KOMANDURI, S., MAZUREK, M. L.,
UR, B., VIDAS, T., BAUER, L., CHRISTIN, N., AND CRANOR,
L. F. Correct horse battery staple: Exploring the usability of
system-assigned passphrases. In Proceedings of the Eighth Sym-
posium on Usable Privacy and Security (2012), ACM, p. 7.

[41] UNGER, N., DECHAND, S., BONNEAU, J., FAHL, S., PERL,
H., GOLDBERG, I., AND SMITH, M. Sok: Secure messaging.
In Security and Privacy (SP), 2015 IEEE Symposium on (2015),
IEEE, pp. 232–249.

[42] VASCO.COM.

http://www.vasco.com/company/

about_vasco/press_room/news_archive/2011/news_
diginotar_reports_security_incident.aspx,
2011.

Sept.

[43] WHATSAPP. Encryption Overview. https://www.whatsapp.

com/security/WhatsApp-Security-Whitepaper.pdf,
Apr. 2016.

[44] YLONEN, T., AND LONVICK, C. The Secure Shell Transport

Layer Protocol. RFC 4253, Jan. 2006. Updated by RFC 6668.

[45] ZIMMERMANN, P., JOHNSTON, A., AND CALLAS, J. ZRTP:
Media Path Key Agreement for Unicast Secure RTP. RFC 6189
(Informational), Apr. 2011.

[28] [MESSAGING] MAILING-LIST ARCHIVE.

Public-Key Fingerprints.
mail-archive/messaging/2014/000004.html, 2014.

Usability of
https://moderncrypto.org/

[29] MILLER, G. A. The magical number seven, plus or minus two:
some limits on our capacity for processing information. Psycho-
logical review 63, 2 (1956), 81.

[30] NAMECOIN PROJECT. Namecoin. http://namecoin.info,

Nov. 2014.

[31] OGDEN, C. K., ET AL. System of Basic English. Self-published

(1934).

[32] OLEMBO, M. M., KILIAN, T., STOCKHARDT, S., H ¨ULSING,
A., AND VOLKAMER, M. Developing and testing a visual hash
scheme. In EISMC (2013), pp. 91–100.

[33] [OPENPGP]

IETF MAIL ARCHIVE.

Fingerprints.

https://mailarchive.ietf.org/arch/msg/openpgp/
2C9gTsxTgh29W8VX8x70OYZqfUY, 2015.

[34] PERCIVAL, C. Stronger key derivation via sequential memory-

hard functions. Self-published (2009).

[35] PERRIG, A., AND SONG, D. Hash visualization: A new tech-
nique to improve real-world security. In International Workshop
on Cryptographic Techniques and E-Commerce (1999), pp. 131–
138.

[36] PINGEL, I., IRVING, A., GENERALMANAGER, WIKINAUT, TIN-
LOAF, FARB, M., AND JPOPPLEWELL. Fingeprint exchange -
issue #826 - whispersystems/textsecure - github.

[37] PLASMOID. Fuzzy Fingerprints: Attacking Vulnerabilities in
the Human Brain. http://www.thc.org/papers/ffp.html,
Oct. 2003.

USENIX Association  

25th USENIX Security Symposium  207

15

14%
7%
7%
5%

49%
67%
61%
71%

5%
8%
8%
12%

27%
13%
12%
8%

22%
12%
14%
11%

I am conﬁdent that I can make comparisons using this method without making mistakes

I found this method difﬁcult to use

I think making comparisons using this method would help me keep my communications secure

I was able to do the comparisons very quickly with this method

Overall, I liked this method

The comparisons were easy for me with this method

71%
82%
80%
87%

36%
18%
21%
14%

82%
76%
75%
67%

54%
71%
71%
80%

55%
64%
67%
69%

58%
76%
72%
83%

A Appendix

Alphanumeric
Numeric
Unrelated Words
Generated Sentences

Alphanumeric
Numeric
Unrelated Words
Generated Sentences

Alphanumeric
Numeric
Unrelated Words
Generated Sentences

Alphanumeric
Numeric
Unrelated Words
Generated Sentences

Alphanumeric
Numeric
Unrelated Words
Generated Sentences

Alphanumeric
Numeric
Unrelated Words
Generated Sentences

25%
11%
11%
6%
100

50

0

Percentage

50

100

Response

Strongly Disagree

Disagree

Neutral

Agree

Strongly Agree

Figure 6: Survey results for all statement ratings

208  25th USENIX Security Symposium 

USENIX Association

16

