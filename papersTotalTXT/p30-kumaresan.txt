How to Use Bitcoin to Incentivize Correct Computations

Ranjit Kumaresan and Iddo Bentov

Technion, Haifa, Israel

{ranjit | idddo }@cs.technion.ac.il

ABSTRACT
We study a model of incentivizing correct computations in a variety
of cryptographic tasks. For each of these tasks we propose a for-
mal model and design protocols satisfying our model’s constraints
in a hybrid model where parties have access to special ideal func-
tionalities that enable monetary transactions. We summarize our
results:

• Veriﬁable computation. We consider a setting where a del-
egator outsources computation to a worker who expects to
get paid in return for delivering correct outputs. We design
protocols that compile both public and private veriﬁcation
schemes to support incentivizations described above.

• Secure computation with restricted leakage. Building on
the recent work of Huang et al. (Security and Privacy 2012),
we show an efﬁcient secure computation protocol that mone-
tarily penalizes an adversary that attempts to learn one bit of
information but gets detected in the process.

• Fair secure computation. Inspired by recent work, we con-
sider a model of secure computation where a party that aborts
after learning the output is monetarily penalized. We then
propose an ideal transaction functionality F (cid:63)
ML and show a
constant-round realization on the Bitcoin network. Then, in
the F (cid:63)
ML-hybrid world we design a constant round protocol
for secure computation in this model.

• Noninteractive bounties. We provide formal deﬁnitions and
candidate realizations of noninteractive bounty mechanisms
on the Bitcoin network which (1) allow a bounty maker to
place a bounty for the solution of a hard problem by sending
a single message, and (2) allow a bounty collector (unknown
at the time of bounty creation) with the solution to claim the
bounty, while (3) ensuring that the bounty maker can learn
the solution whenever its bounty is collected, and (4) pre-
venting malicious eavesdropping parties from both claiming
the bounty as well as learning the solution.

All our protocol realizations (except those realizing fair secure
computation) rely on a special ideal functionality that is not cur-

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
Copyright 2014 ACM 978-1-4503-2957-6/14/11 ...$15.00.
http://dx.doi.org/10.1145/2660267.2660380.

rently supported in Bitcoin due to limitations imposed on Bitcoin
scripts. Motivated by this, we propose validation complexity of a
protocol, a formal complexity measure that captures the amount of
computational effort required to validate Bitcoin transactions re-
quired to implement it in Bitcoin. Our protocols are also designed
to take advantage of optimistic scenarios where participating par-
ties behave honestly.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: General—Secu-
rity and protection
Keywords
Bitcoin; secure computation; veriﬁable computation; fair exchange;
bounties
1.

INTRODUCTION

CR, F (cid:63)

We study a model of incentivizing correct computations in a va-
riety of cryptographic tasks, namely veriﬁable computation, secure
computation, fair computation, and bounty mechanisms. For each
of these tasks we propose a formal model and design protocols
satisfying our model’s constraints in a hybrid model where parties
have access to special ideal functionalities, e.g., F (cid:63)
f [11], that
enable monetary transactions. Below we explain each of the prob-
lems, provide motivation, discuss state-of-the-art, and outline our
contributions.
Veriﬁable computation. Outsourcing computation has been a ma-
jor area of research in cryptography. Recently several efﬁcient
schemes have been proposed [31]. Motivated by these develop-
ments, we consider a setting where a delegator outsources com-
putation to a worker who expects to get paid in return for deliv-
ering correct outputs. Such settings may be useful for situations
where the delegator is interested in a pay per computation model
rather than a model where the delegator subscribes to cloud service
to perform computations. We design protocols that compile both
public and private veriﬁcation schemes to support incentivizations
described above.
Secure computation with restricted leakage. Protocols for se-
cure computation anticipate worst-case behavior from malicious
parties and typically make heavy use of expensive techniques that
are meant solely to handle them. Recently, Huang et al. [23] (build-
ing on top of [29] proposed the “DualEx protocol” that restricts the
amount of leakage to at most one bit even against malicious parties.
While leaking a single bit might not sound too damaging, consider
what happens when multiple secure evaluations are performed on
the same data. This could be a server that is willing to allow com-
putations on a database it holds, or on a set of master keys that it

30possesses. In such scenarios leaking one bit of sensitive informa-
tion per execution might indeed be catastrophic. While enhance-
ments to DualEx protocol that allow (some restricted) detection of
leakage, it is quite natural to expect that an adversary may inter-
act with a server multiple times under different pseudonyms and
in each interaction learn (with some probability) a sensitive bit of
information.

Despite such severe consequences, we believe that sacriﬁcing
some leakage for (vastly) better efﬁciency is perhaps the way to
go in the area of secure protocol design. For instance, consider
state-of-the-art searchable symmetric key encryption schemes [12,
25, 30] that leak some information about access patterns to even
semihonest adversaries. Indeed, the research direction in this area
is to ﬁgure out “an acceptable balance between leakage and per-
formance” [12]. Note that in contrast, the DualEx protocol leaks
information only when parties deviate from the protocol. This jus-
tiﬁes considering a model where a deviating party may be penal-
ized if information leakage is detected. Speciﬁcally, we consider a
model where a malicious party may attempt to learn one bit of in-
formation, but with the guarantee that if its cheating attempt is de-
tected, then it is forced to pay a monetary penalty. We believe that
this constitutes a practical way to enforce honest behavior in the
DualEx protocol. We then construct a protocol that (for very large
circuits) essentially has the same performance as the DualEx proto-
col in an optimistic scenario and yet allows for enforcing penalties.
Our protocol is constructed in the F (cid:63)
CR-hybrid model [11] and thus
allows, assuming extended script support, for practical realization
over the Bitcoin network. Our protocols provide a formal proof-of-
concept that incentivizing secure computation to prevent leakage is
indeed possible. We believe that our results provided added mo-
tivation for further research in designing secure protocols with re-
stricted leakage—a relatively unexplored area—with the hope that
these protocols can be incentivized to prevent leakage.
Fair secure computation. A major deﬁciency of secure computa-
tion is that, assuming a dishonest majority among participating par-
ties, a corrupt party can always abort the protocol after learning the
output while denying the output to honest parties. Such situations
are highly undesirable if we want secure computation to be widely
adopted in practice. Inspired by the recent works of [11, 4], we
consider a model of secure computation where a party that aborts
after learning the output is monetarily penalized. We then propose
an ideal transaction functionality F (cid:63)
ML and show a constant-round
realization on the Bitcoin network. Then, in the F (cid:63)
ML-hybrid world
we design a constant round protocol for secure computation in this
model. Previous work [11] did not offer constant round implemen-
tations over Bitcoin.
Noninteractive bounties. Bitcoin users have been offering boun-
ties that can be collected anonymously by anyone who solves an
NP problem, such as SHA-1 and SHA-2 collisions [34]. The users
who place the bounty expect to learn the preimages that cause the
collision. The difﬁculty in realizing bounties arises from the fact
that the identity of the user who solves the NP problem is unknown
at the time the bounty is placed. This is a problem since other (ma-
licious) nodes in the Bitcoin network could strip the witness and
attempt to redeem the reward themselves. A recommendation out-
lined in [34] suggests that the user who claims the reward should
generate the PoW block by herself. While this may very well be
impractical, it still does not avoid the risk that other PoW miners
will re-solve the block if the bounty is high enough and broadcast
their own transaction that offers a higher fee to the Bitcoin miners.
Clearly, the above proposals for bounty mechanisms fall short of
what one would expect from a bounty mechanism. We approach
the problem by providing both formal deﬁnitions and candidate re-

alizations of noninteractive bounty mechanisms on the Bitcoin net-
work. The key constraints to keep in mind are that a noninteractive
bounty mechanism must (1) allow a bounty maker to place a bounty
for the solution of a hard problem by sending a single message,
and (2) allow a bounty collector (unknown at the time of bounty
creation) with the solution to claim the bounty, while (3) ensuring
that the bounty maker can learn the solution whenever its bounty is
collected, and (4) preventing malicious eavesdropping parties from
both claiming the bounty as well as learning the solution.

Validation complexity. Our protocols and schemes are designed in
a hybrid model where parties have access to an ideal transaction
functionality, say G(cid:63). The description of G(cid:63) typically involves a
conditional release of payment where the condition is formalized
via a circuit φ. Our design of G(cid:63) is certainly inspired by transac-
tion functionalities supported by Bitcoin. In particular, the circuit
φ corresponds to Bitcoin scripts that may be used to conditionally
release payments. Unfortunately, heavy restrictions are imposed on
the expressive power of Bitcoin scripts in the current Bitcoin sys-
tem. Consequently some of our protocols cannot be implemented
on the Bitcoin system today. On the one hand, we hope that our
models and constructions offer compelling motivation to increase
functionality of Bitcoin scripts. On the other hand, we propose
validation complexity, a new complexity measure that attempts to
capture the complexity of the Bitcoin script required in conditional
transactions. Note that Bitcoin transactions need to be conﬁrmed
by the Bitcoin miners in order to append them to the public ledger.
Thus, the miners need to ﬁrst verify whether the transaction is valid.
It is therefore natural to presume that miners levy an (additional)
transaction fee that is proportional to the validation complexity of
the transaction. As we will see, one of our main goals is to design
protocols with low validation complexity.

Optimistic complexity. We use optimistic techniques for designing
protocols to minimize the computation/communication/validation
complexity of honest executions of our protocols, i.e., when all par-
ties follow the protocol. As in prior work [26, 7, 33], our aim here
is to design protocols that can “recognize the best cases and opti-
mize for them, even in the midst of the protocol execution,” [33]
while guaranteeing security against worst-case behavior. Note that
optimistic protocols are not intended to improve worse-case perfor-
mance but are likely to offer meaningful gains in practice.

Bitcoin scripts and their limitations. Standard Bitcoin transaction
currently blacklist many of the opcodes, primarily because of ex-
ploits in code that were not vetted carefully enough [1]. Even if all
the opcodes will be whitelisted, it should be noted that the Bitcoin
scripting language is not Turing complete, to avoid denial of ser-
vice attacks. It is not enough to simply require a higher fee when
the script size is bigger, because the risk of network DoS attacks
implies that the nodes that propagate the transaction (and do not
receive the fee) must verify it before re-broadcasting it. Hence,
Bitcoin caps the transaction size, and bounds the veriﬁcation time
with a small polynomial function of the transaction size. Still, al-
ternative protocol designs with Turing complete scripts are being
considered, in particular with the Ethereum project [2]. Thus it is
conceivable that in the future, richer forms of ﬁnancial mechanisms
will be used by Bitcoin and other cryptocurrencies, though all the
users may have to pay somewhat larger fees as a result.
Other related work. The works of [21, 10] design a credit system
where users are rewarded for good work and ﬁned for cheating (as-
suming a trusted arbiter/supervisor in some settings). Fair secure
computation with reputation systems was considered in [5]. Note
that it has been claimed that reputation systems ﬁnd limited appli-

31cability because it is unclear how to deﬁne the reputation of new
users [14].

2. PRELIMINARIES
A function µ(·) is negligible in λ if for every positive polynomial
p(·) and all sufﬁciently large λ’s it holds that µ(λ) < 1/p(λ). A
probability ensemble X = {X(a, λ)}a∈{0,1}∗,n∈N is an inﬁnite
sequence of random variables indexed by a and λ ∈ N. Two dis-
tribution ensembles X = {X(a, λ)}λ∈N and Y = {Y (a, λ)}λ∈N
c≡ Y
are said to be computationally indistinguishable, denoted X
if for every non-uniform polynomial-time algorithm D there exists
a negligible function µ(·) such that for every a ∈ {0, 1}∗,

|Pr[D(X(a, λ)) = 1] − Pr[D(Y (a, λ)) = 1]| ≤ µ(λ).

All parties are assumed to run in time polynomial in the security
parameter λ. We prove security in the “secure computation with
coins” (SCC) model proposed in [11]. Note that the main difference
from standard deﬁnitions of secure computation [19] is that now the
view of Z contains the distribution of coins. Let IDEALf,S,Z (λ, z)
denote the output of environment Z initialized with input z after
interacting in the ideal process with ideal process adversary S and
(standard or special) ideal functionality Gf on security parameter
λ. Recall that our protocols will be run in a hybrid model where
parties will have access to a (standard or special) ideal functionality
Gg. We denote the output of Z after interacting in an execution of
π in such a model with A by HYBRIDg
π,A,Z (λ, z), where z denotes
Z’s input. We are now ready to deﬁne what it means for a protocol
to SCC realize a functionality.
Deﬁnition 1. Let n ∈ N. Let π be a probabilistic polynomial-
time n-party protocol and let Gf be a probabilistic polynomial-
time n-party (standard or special) ideal functionality. We say that
π SCC realizes Gf with abort in the Gg-hybrid model (where Gg
is a standard or a special ideal functionality) if for every non-
uniform probabilistic polynomial-time adversary A attacking π
there exists a non-uniform probabilistic polynomial-time adversary
S for the ideal model such that for every non-uniform probabilistic
polynomial-time adversary Z,

{IDEALf,S,Z (λ, z)}λ∈N,z∈{0,1}∗ c≡

{HYBRIDg

π,A,Z (λ, z)}λ∈N,z∈{0,1}∗ .

♦

f according to Deﬁnition 1.

Deﬁnition 2. Let π be a protocol and f be a multiparty function-
ality. We say that π securely computes f with penalties if π SCC-
realizes the functionality F (cid:63)
2.1 Standard primitives
Garbled circuits [35] allow two semihonest parties to compute an
arbitrary function f (x1, x2) that depends on their respective private
inputs x1 and x2 while not leaking any information about their in-
puts beyond what is revealed by the function output. Our overview
here follows the presentation in [23]; for more details see [27]. One
party, acting as the circuit generator, produces a garbled circuit that
is evaluated by the other party, known as the circuit evaluator. The
result is an “encrypted” output, which can then be mapped to its
actual value and revealed to either or both parties.

The basic idea is to transform a boolean circuit representing a
function f into a garbled circuit that operates on labels (ie., cryp-
tographic keys) instead of bits. We describe this transformation,
denoted Gb(1λ, f ), below. Any binary gate g which has two input
wires W0, W1 and output wire W2 can be converted into a garbled

gate. First, generate random labels w0
i to contain 0 and 1
on each wire Wi. Then generate a truth table containing the four
entries

i and w1

Encws0

0 ,ws1

1

(wg(s0,s1)

2

)

0 and ws1

1 it is possible to recover wg(s0,s1)

for each s0, s1 ∈ {0, 1} (where s0, s1 denote the 1-bit signals on
wires W0, W1, respectively), and randomly permute the table. This
truth table is called a garbled gate. Observe that given the garbled
gate and labels ws0
. That
is given the labels that correspond to some set of input values for
the entire circuit it is possible for the circuit evaluator to recover
labels corresponding to the output of the circuit on those inputs.
We denote this algorithm by Eval. If the circuit generator provides
a way to map those labels back to bits, the circuit evaluator can
recover the actual output.
Notation. We write a set of wire-label pairs as a matrix:

2

(cid:18) w0

W =

1 w0
2
1 w1
2

w1

(cid:19)

.

··· w0
··· w1

(cid:96)

(cid:96)

A vector of wire labels is denoted as

w = (w1, w2, . . . , w(cid:96)) .

If v ∈ {0, 1}(cid:96) is a string and W is a matrix as above, then we let

1 , . . . , wv(cid:96)
(cid:96) )
be the corresponding vector of wire labels.

Wv = (wv1

In some of our constructions we will use a seed-based garbling
scheme Gb proposed in [22] that takes as input a security parame-
ter λ, an explicitly speciﬁed seed ω to a pseudorandom generator
(PRG) and a description of the function f and outputs the garbled
circuit G. Note that in such a garbling scheme it is convenient
to deﬁne two garbling functions iGb and oGb that generate wire-
label pairs for only the input and output wires respectively. We use
the notation U ← iGb(1λ, ω, m) where U denotes the wire-label
pairs for the input keys and m denotes the size of each party’s in-
put, and the notation W ← oGb(1λ, ω, (cid:96)) where W denotes that
wire-label pairs for the output keys and (cid:96) denotes the size of the
ﬁnal output. Observe that iGb (resp. oGb) depend only on the in-
put (resp. output) size of f and is otherwise independent of the
description of f. The garbled gates are then computed using these
wire labels exactly as in standard garbled circuits. To prove se-
curity of secure computation protocol based on garbled circuits,
a special kind of garbled circuit ˆG is computed by the simulator
using algorithm Fake(1λ, f ). This algorithm outputs a “fake” gar-
bled circuit, a random input x(cid:48) ∈ {0, 1}m, wire labels U where
positions corresponding to input x(cid:48) are ﬁlled with random values
while all other positions contain 0λ, and output labels w such that
Eval( ˆG, Ux(cid:48)
) = w. Finally, we denote a garbling scheme by
(Gb, Eval).
Veriﬁable computation. We provide the deﬁnition of public veri-
ﬁable computation (taken from [31]).
Deﬁnition 3. A public veriﬁable computation scheme pubVC
consists of a set of three polynomial-time algorithms (KeyGen,
Compute, Verify) deﬁned as follows:
• (ekf , vkf ) ← KeyGen(f, 1λ): The randomized key generation
algorithm takes the function f to be outsourced and security pa-
rameter λ; it outputs a public evaluation key ekf , and a public
veriﬁcation key vkf .
• (y, ψy) ← Compute(ekf , u): The deterministic worker algo-
rithm uses the public evaluation key ekf and input u. It outputs
y ← f (u) and a proof ψy of y’s correctness.

32F (cid:63)
CR with session identiﬁer sid, running with parties Ps and
Pr, a parameter 1λ, and adversary S proceeds as follows:
• Deposit phase. Upon receiving the tuple (deposit, sid,
ssid, s, r, φs,r, τ, coins(x)) from Ps, record the message
(deposit, sid, ssid, s, r, φs,r, τ, x) and send it to all par-
ties. Ignore any future deposit messages with the same ssid
from Ps to Pr.
• Claim phase.

In round τ, upon receiving (claim, sid,
ssid, s, r, φs,r, τ, x, w) from Pr, check if (1) a tuple
(deposit, sid, ssid, s, r, φs,r, τ, x) was recorded, and (2) if
φs,r(w) = 1. If both checks pass, send (claim, sid, ssid,
s, r, φs,r, τ, x, w) to all parties, send (claim, sid, ssid, s,
r, φs,r, τ, coins(x)) to Pr, and delete the record (deposit,
sid, ssid, s, r, φs,r, τ, x).

• Refund phase: In round τ + 1, if the record (deposit, sid,
ssid, s, r, φs,r, τ, x) was not deleted, then send (refund,
sid, ssid, s, r, φs,r, τ, coins(x)) to Ps, and delete the
record (deposit, sid, ssid, s, r, φs,r, τ, x).

Figure 1: The special ideal functionality F (cid:63)

CR.

• {0, 1} ← Verify(vkf , u, (y, ψy)): Given the veriﬁcation key
vkf , the deterministic veriﬁcation algorithm outputs 1 if f (u) =
y, and 0 otherwise.

Pr

The scheme pubVC should satisfy:
Correctness For any function f, it holds that

(y, ψy) ← Compute(ekf , u) :

 (ekf , vkf ) ← KeyGen(f, 1λ);
(cid:20) Pr[(u(cid:48), y(cid:48), ψ(cid:48)

y) ← A(ekf , vkf ) :

negligible in λ:

1 = Verify(vkf , u, (y, ψy))

Soundness For any function f and any PPT A the following is

 = 1.
(cid:21)

Pr

f (u(cid:48)) (cid:54)= y(cid:48) ∧ 1 = Verify(vkf , u(cid:48), (y(cid:48), ψ(cid:48)

y))

.

Efﬁciency KeyGen is assumed to be a one-time operation whose
cost is amortized over many calculations, but we require that
♦
Verify is cheaper than evaluating f.

2.2 Special ideal functionalities
Ideal functionality F (cid:63)
CR [11, 9, 28]. This special ideal function-
ality has found tremendous application in the design of multiparty
fair secure computation and lottery protocols [11]. See Figure 1 for
a formal description. At a high level, F (cid:63)
CR allows a sender Ps to
conditionally send coins(x) to a receiver Pr. The condition is for-
malized as the revelation of a satisfying assignment (i.e., witness)
for a sender-speciﬁed circuit φs,r( · ; z) (i.e., relation) that may
depend on some public input z. Further, there is a “time” bound,
formalized as a round number τ, within which Pr has to act in or-
der to claim the coins. An important property that we wish to stress
is that the satisfying witness is made public by F (cid:63)
CR. In the Bitcoin
realization of F (cid:63)
CR, sending a message with coins(x) corresponds
to broadcasting a transaction to the Bitcoin network, and waiting
according to some time parameter until there is enough conﬁdence
that the transaction will not be reversed.
Secure computation with penalties. Loosely speaking, the notion
of fair secure computation as considered in [11] guarantees:

An honest party never has to pay any penalty.

F (cid:63)
f with session identiﬁer sid running with parties
P1, . . . , Pn, a parameter 1λ, and an ideal adversary S that cor-
rupts parties {Ps}s∈C proceeds as follows: Let H = [n] \ C
and h = |H|. Let d be a parameter representing the safety
deposit, and let q denote the penalty amount.
• Input phase: Wait to receive a message (input, sid, ssid, r,
yr, coins(d)) from Pr for all r ∈ H. Then wait to receive
a message (input, sid, ssid,{ys}s∈C , coins(hq)) from S.

• Output phase:

– Send (return, sid, ssid, coins(d)) to Pr for all r ∈ H.
– Compute (z1, . . . , zn) ← f (y1, . . . , yn).
– If S returns (continue, sid, ssid), then send (output,
sid, ssid, zr) to Pr for all r ∈ H, and send (return,
sid, ssid, coins(hq)) to S.
– Else if S returns (abort, sid, ssid, coins(t(cid:48)(cid:48)hq)), send
(extra, sid, ssid, coins(t(cid:48)q)) to Pr for all r ∈ H.

Figure 2: Idealizing secure computation with penalties F (cid:63)
f .

If a party aborts after learning the output and does not deliver
output to honest parties, then every honest party is compen-
sated.

f (cf. Figure 2) captures these requirements.

The functionality F (cid:63)
Ideal functionality F (cid:63)
f [11]. In the ﬁrst phase, the functionality
F (cid:63)
f receives inputs for f from all parties. In addition, F (cid:63)
f allows
the ideal world adversary S to deposit some coins which may be
used to compensate honest parties if S aborts after receiving the
outputs. Note that an honest party makes a ﬁxed deposit coins(d)
in the input phase. Then, in the output phase, F (cid:63)
f returns the de-
posit made by honest parties back to them. If S deposited sufﬁcient
number of coins, then it gets a chance to look at the output and then
decide to continue delivering output to all parties, or just abort, in
which case all honest parties are compensated using the penalty de-
posited by S. We note that our version of F (cid:63)
f varies slightly from
the one proposed in [11]. While they allowed S to deposit insufﬁ-
cient number of coins (i.e., less than hq), we do not. On the other
hand, we do allow S to send extra coins to honest parties when it
aborts. This somewhat unnatural step is required in order to make
our construction in Section 5 simulatable.

3. VERIFIABLE COMPUTATION

Loosely speaking, an incentivizable protocol for veriﬁable com-
putation between a delegator D and a worker W must provide the
following guarantee:
• (Fast veriﬁcation.) The amortized work performed by D for ver-

iﬁcation is less than the work required to compute f.

the correct output of the computation from W .

• (Pay to learn output.) W obtains coins(q) from D iff D received
We start with a naïve solution in the F (cid:63)
A naïve solution. D sends u, f to W , and then creates an F (cid:63)
CR
transaction that allows W to claim its coins(q) if it reveals y such
that y = f (u). (More concretely, φ(w; (u, f )) = 1 iff w = f (u).)
W computes y = f (u) and claims coins(q) by providing w = y
to F (cid:63)

CR-hybrid model.

CR.

Clearly, the above is sufﬁcient to incentivize veriﬁable compu-
tation but the solution has obvious drawbacks when implemented
in the Bitcoin network. Note that to validate the claim transaction
each miner has to verify whether the witness provided was indeed
valid. This means that each miner has to compute f in order to

33Motivated by this, we now minimize the “validation complex-
CR-

conﬁrm the validity of the transaction. This is clearly undesirable
because (1) it puts a heavy load on the Bitcoin network and cor-
responds to heavy loss of resources, and (2) more philosphically,
while D is expected to pay W for the computation of f, miners are
now computing the same f essentially “for free”.
ity” of our protocol. First, we give a precise deﬁnition of F (cid:63)
validation complexity for a protocol in the F (cid:63)
CR-hybrid model.
Deﬁnition 4. Let Π be a protocol among n parties P1, . . . , Pn
in the F (cid:63)
CR-hybrid model. For circuit φ, let |φ| denote its circuit
complexity. For a given execution of Π starting from a particular
initialization Ω of parties’ inputs and random tapes and distribution
Π,Ω ) denote the sum of all |φ| such that
of coins, let VΠ,Ω (resp. V hon
some honest party claimed an F (cid:63)
CR transaction by producing a wit-
ness for φ during an (resp. honest) execution of Π. Then the F (cid:63)
CR-
validation complexity of Π, denoted VΠ, equals maxΩ (VΠ,Ω). The
optimistic F (cid:63)
equals
♦
Π,Ω .
maxΩV hon

CR-validation complexity of π, denoted V opt

Π

Note that our deﬁnition extends naturally to capture the valida-
tion complexity of other transaction functionalities (e.g., F (cid:63)
ML).
Also, we simply say “(optimistic) validation complexity” instead
of “(optimistic) F (cid:63)
CR-validation complexity” in contexts where it is
obvious that we are referring to the F (cid:63)
CR-validation complexity. As
mentioned in the Introduction, validation complexity of a transac-
tion may justify the transaction fee that is required to validate it in
the Bitcoin network.
Remark. Note that validating an F (cid:63)
CR transaction also requires ver-
iﬁcation of the designated sender’s and receiver’s signatures. Our
justiﬁcation for not accounting for this in the F (cid:63)
CR-validation com-
plexity as deﬁned above is that such veriﬁcations are required even
for standard transactions between two parties.
Incentivizing public veriﬁable computation. A natural approach
to minimize the validation complexity would be to use a public
veriﬁable computation scheme pubVC.
Indeed we show how to
compile an arbitrary public veriﬁable computation scheme into an
incentivizable veriﬁable computation scheme. Perhaps the main
difﬁculty in constructing such a compiler is the need to handle ma-
licious clients in our setting. Note in contrast that in the standard
setting of veriﬁable computation, the client is always assumed to
be honest and security is required only against malicious server.
To see why it is important to safeguard against a malicious client
let us take a look at a naïve scheme based on any public veriﬁable
computation scheme pubVC.
Naïve scheme based on pubVC. D runs KeyGen(f, 1λ) to gen-
erate (ekf , vkf ), and then sends ekf , u to W , and then creates
an F (cid:63)
CR transaction that allows W to claim its coins(q) if it re-
veals (y, ψy) such that Verify(vkf , u, (y, ψy)) = 1. (More con-
cretely, φ(w; (vkf , u)) = 1 iff 1 = Verify(vkf , u, w).) W runs
Compute(ekf , u) to obtain (y, ψy) and claims coins(q) by provid-
ing w = (y, ψy) to F (cid:63)

CR.

The main problem with the above solution is that a malicious D
may not generate the veriﬁcation key honestly, and thus an honest
worker that computes y ← f (u) is not guaranteed payment. Note
however that in such a situation we may ask W to reveal y to D
only if w = (y, ψy) is such that φ(w) = 1 for the φ obtained from
F (cid:63)
CR. Still the above solution is undesirable since a honest worker
does perform the required the computation yet does not get paid by
the delegator. This motivates the following condition:
• (Guaranteed pay on honest computation.) W obtains coins(q)

from D if W followed the protocol honestly.

Note that standard secure computation protocol to jointly emu-
late KeyGen algorithm such that both D and W obtain (ekf , vkf )
at the end of the protocol sufﬁces to satisfy the condition above.
Observe that the work performed by D for securely emulating
KeyGen will be amortized over several executions.

exitCR. Recall that F (cid:63)

exitCR offers. Speciﬁcally, F (cid:63)

Although the above modiﬁed scheme does minimize the valida-
tion complexity signiﬁcantly, one may still wonder if further im-
provements are possible. Note that current state-of-the-art pub-
lic veriﬁcation schemes [31], although quite impressive relative to
prior work, still require 288 bytes storage and 9ms to verify. That is,
each miner would be required to spend 9ms to execute the veriﬁca-
tion algorithm in order to validate the F (cid:63)
CR transaction. We observe
that in an optimistic scenario (where we assume both D and W are
interested in reducing the validation complexity), it is possible to
drive the validation complexity to zero. To do this, we ﬁrst let D
and W to interact as described above. Then, in a later phase, we
simply let W reveal (y, ψy) to D. If Verify(vkf , u, (y, ψ)) = 1,
then (honest) D pays W . Note that if D does not pay W , then W
can always claim the F (cid:63)
CR transaction made by D. On the other
hand, if D does pay W , then a malicious W may attempt to get
paid twice by also claiming coins(q) from the original F (cid:63)
CR trans-
action. In order to avoid this double payment, we use a new ideal
transaction functionality F (cid:63)
exitCR. The description of our veriﬁable
computation protocol (in the F (cid:63)
exitCR-hybrid model) appears in the
full version of our paper. We provide more details on the ideal
transaction functionality F (cid:63)
exitCR and a candidate Bitcoin imple-
mentation below.
Ideal functionality F (cid:63)
CR (cf. Figure 1) allows
a sender to conditionally send coins(x) to a receiver. However,
F (cid:63)
CR does not allow parties to mutually agree to discard check-
ing the condition to release payment. It is exactly this ability that
our new ideal functionality F (cid:63)
exitCR
allows parties to mutually agree to revoke the condition φ that re-
leases payment. In addition there is a “time” bound, formalized as
a round number τ2 within which the revision has to occur. As in
F (cid:63)
CR, Pr must act within some round number τ1 in order to claim
coins(x) by revealing a witness for φ if the condition φ was not
revoked.
To realize F (cid:63)
exitCR via Bitcoin, we need to modify the realization
of F (cid:63)
CR (e.g., as in [11, Appendix F]) only slightly. The mechanism
that we rely upon for txrefund is the script in txclaim that speciﬁes
that one of the ways to redeem txclaim is by signing with secret
keys that Ps and Pr hold. This allows txrefund to be created by both
parties signing a transaction that would be considered valid by Bit-
coin nodes only if it is included in a future block (as speciﬁed by a
timelock parameter). Hence, we only require an extra intermediate
step after txclaim was broadcast, in which, upon agreement, both
parties will sign a transaction txexit that redeems txclaim to Pr.
Incentivizing private veriﬁable computation. Perhaps the main
concern about our previous scheme is that D’s input u is made
public on the Bitcoin network. This is because the veriﬁcation
algorithm Verify(vkf , u,·) is part of the Bitcoin script that each
miner needs to verify before validating the transaction. A more
desirable scheme would be one where D’s input is kept private.
However note that a malicious W is given access to D’s input u,
and hence always has the power to make u (or f (u)) public. There-
fore, to make the problem more meaningful we will consider veri-
ﬁable computation schemes which already preserve privacy against
a malicious worker. Then one may ask whether it is possible to in-
centivize a veriﬁable computation that preserves input/output pri-
vacy of D. Indeed in the full version of our paper, we show some-
what surprisingly it is possible to incentivize veriﬁable computation
schemes with designated veriﬁer (i.e., in contrast to public veriﬁ-

34cation). However, this comes at a price. Speciﬁcally we no longer
guarantee pay on honest computation. On the other hand, we show
that it is possible to penalize a malicious worker that tries to exe-
cute the “rejection” attack (typically allowed by private veriﬁcation
schemes based on fully-homomorphic encryption). In such an at-
tack, the malicious worker supplies incorrect proofs of computation
and learns information depending on whether the honest delegator
accepts its proof or not.

At a high level, our constructions use secure computation to em-
ulate all algorithms except the Compute algorithm used by the
worker.
(Observe that the amortized complexity of D depends
only on the input/output length of f and is otherwise independent
of complexity of f.) An important issue is to ensure that parties
(especially the delegator) provide consistent inputs across all these
secure emulations. However, this is easily achieved by use of (one-
time) message authentication codes (since the MAC veriﬁcation
happens inside a secure protocol). While securely emulating the
Verify algorithm to secret share the ﬁnal output of the computation
between D and W if a successful proof was supplied, and then re-
quire D to make a F (cid:63)
CR deposit in order to learn the other secret
share. This is achieved using techniques similar to the ones em-
ployed in [11]. We defer other details of the construction to the full
version due to lack of space.

In summary, we provide two protocols that incentivize veriﬁable
computation schemes (i.e., force D to pay to learn the output while
denying payment for an incorrect output). The ﬁrst scheme com-
piles any public veriﬁcation scheme, guarantees pay on computa-
tion, but does not protect client privacy. The validation complexity
equals the public veriﬁcation complexity in the worst case and is
zero in an optimistic scenario (due to use of F (cid:63)
exitCR). The second
scheme compiles the designated veriﬁer scheme of [17], protects
client privacy and also penalize malicious workers that supply in-
valid proofs, but does not guarantee pay on computation. The val-
idation complexity of this protocol equals a hash invocation (with
hash input equal to the length of output of the computation).
Remark. We note that similar techniques may be extended to al-
low penalizing deviations in publicly veriﬁable covert secure pro-
tocols [8, 6].

4. SECURE COMPUTATION

We focus on the DualEx protocol of Huang et al. [23] (which
in turn is inspired by [29]). The protocol enjoys efﬁciency com-
parable to that of semihonest Yao garbled circuits protocol while
guaranteeing that a malicious party can learn at most one bit of
information about the honest party’s input. Given that secure com-
putation protocols require a high overhead due to use of cut-and-
choose or zero-knowledge, the DualEx protocol offers an attractive
alternative in scenarios where efﬁciency is the bottleneck.

We now provide a quick outline of the DualEx protocol. The
high level idea is to let two parties P1 and P2 run two simultane-
ous instances of a semihonest garbled circuit protocol. In the ﬁrst
instance P1 acts as the circuit constructor and P2 acts as the circuit
evaluator. In the second instance they swap roles. The key observa-
tion made in [29, 23] is that appending a secure equality test to the
above step somewhat surprisingly results in a protocol that leaks at
most a single bit of information about an honest party’s input to a
malicious party. Furthermore, several enhancements to the DualEx
are possible. For instance, it is possible to design a variant that re-
leases output to the parties only if the equality test passes. In such
a scenario, a cheating adversary does so only at the expense of not
learning the actual output.
[23] also experimentally validate the
superior efﬁciency of the DualEx protocol.

F (cid:63)
f,leak with session identiﬁer sid, running with parties P1 and
P2, a parameter 1λ, and an ideal adversary S that corrupts Pi
for i ∈ {1, 2} proceeds as follows. Let j ∈ {1, 2}\{i}. Let d
be a parameter representing the safety deposit, and let q denote
the penalty amount.
• Input phase. Honest Pj sends its input (input, sid,
ssid, xj, coins(d)). S sends input (input, sid, ssid, xi, L,
coins(q)) on behalf of Pi, where x1, x2 ∈ {0, 1}(cid:96), and
L : {0, 1}(cid:96) → {0, 1}.

• Output phase.

– Send (return, sid, ssid, coins(d)) to Pj.
– Compute z ← f (x1, x2) and y ← L(xj).
– If y = 0 send message (abort, sid, ssid) to S and
(penalty, sid, ssid, coins(q)) to Pj, and terminate.
– Else send message (output, sid, ssid, z, y) to S.
– If S returns (continue, sid, ssid) then set z(cid:48) = z and
q(cid:48) = 0, and send (return, sid, ssid, coins(q)) to S. Else
if S returns (abort, sid, ssid) set z(cid:48) = ⊥ and q(cid:48) = q.

– Send (output, sid, ssid, z(cid:48), coins(q(cid:48))) to Pj.
Figure 3: The leaky functionality with penalty F (cid:63)

f,leak.

f,leak.

Ideal functionality F (cid:63)
In the ﬁrst phase, the functionality
F (cid:63)
f,leak receives inputs from both parties. In addition F (cid:63)
f,leak al-
lows the ideal world adversary S to deposit coins(q) and specify a
“leakage function” denoted L. Note that an honest party makes a
ﬁxed deposit coins(d) in the input phase which is returned to it in
the output phase. The functionality ﬁrst computes the output z us-
ing inputs received from both parties, and also computes the output
y of the leakage function on the honest party’s input. If the output
of the leakage function equals 0 (without loss of generality), then
the honest party is compensated by coins(q). On the other hand
if output of the leakage function is 1, then this goes “undetected.”
The ideal functionality F (cid:63)
f,leak also penalizes corrupt parties that
abort on learning the output.
High level overview. As observed in [23], the attacks a malicious
party may use against a DualEx protocol can be grouped into three
main types: selective failure, in which the attacker constructs a
circuit that fails along some execution paths and attempts to learn
about the party’s private inputs from the occurrence of failure, false
function, in which the attacker constructs a circuit that implements
function that is different from f, and inconsistent inputs, in which
the attacker provides different inputs to the two executions. The
DualEx protocol mitigates all of the attacks in a elegant way and
allows a malicious party to learn at most one bit of information.

Our main observation is that attacks due to selective failure or
inconsistent inputs can be prevented using techniques whose efﬁ-
ciency depends only on the input/output length and is otherwise
independent of the circuit size of the function to be evaluated. Mo-
tivated by this observation, we design our protocol to narrow down
the one-bit leakage to be launched via the false function attack. We
then use standard techniques to penalize false function attacks.
Detailed overview. Our starting point is the observation that leak-
age in the DualEx protocol is detected only at the equality test
(“secure validation”) step. More precisely, in the event of de-
tected leakage, the equality test simply fails. We take advantage
of this in the following way: (1) letting P1, P2 exchange hash val-
ues h1 = H(r1), h2 = H(r2) of random strings r1, r2 ahead of the
equality step; (2) letting P1, P2 make F (cid:63)
CR transactions that release
coins(q) to the other party if it reveals the preimage to both hash

35Input from P1: m, x1, ω1.
Input from P2: m, x2, ω2.
Output to both P1 and P2:
• Create U1 ← iGb(1λ, ω1, m) and U2 ← iGb(1λ, ω2, m).
• Compute g(cid:48)
2 = com(ω2; ρ2) where

1 = com(ω1; ρ1) and g(cid:48)

ρ1, ρ2 are picked uniformly at random.

• Output (Ux1(cid:107)x2

2

, g(cid:48)

2, ρ1) to P1 and (Ux1(cid:107)x2

1

, g(cid:48)

1, ρ2) to P2.

Figure 4: Secure key transfer subroutine KT.

Input from P1: (cid:96)1 = (cid:96), w1, ω1, ρ1, r1, h2, g(cid:48)
2.
Input from P2: (cid:96)2 = (cid:96), w2, ω2, ρ2, r2, h1, g(cid:48)
1.
Output to both P1 and P2:
• If (cid:96)1 (cid:54)= (cid:96)2 or H(r1) (cid:54)= h1 or H(r2) (cid:54)= h2 or com(ω1; ρ1) (cid:54)=
1 or com(ω2; ρ2) (cid:54)= g(cid:48)
g(cid:48)

2, output bad and terminate.

• Create W1 ← oGb(1λ, ω1, (cid:96)) and W2 ← oGb(1λ, ω2, (cid:96)).
• Check if ∃v1, v2 ∈ {0, 1}(cid:96) such that Wv1
1 = w2 and

2 = w1. If the check fails output bad and termiante.

Wv2

• Check if ∃v ∈ {0, 1}(cid:96) such that Wv

1 = w2 and Wv

2 = w1.

If check fails output (r1, r2). Else, output v.

Figure 5: Secure validation subroutine SV.

values; and (3) augmenting the equality step to let parties to also
input r1, r2 such that (r1, r2) is revealed iff the equality test fails.
Unfortunately, the above idea turns out to be naïve mainly be-
cause although the equality test detects leakage it does not quite
help in identifying the deviating party (that must then be penal-
ized). Perhaps even more severely, a malicious party that simply
supplies junk input to the equality test can easily learn (r1, r2) and
then deny honest party from learning this output. (This is possible
since the equality step is implemented using a unfair secure com-
putation protocol.) This results in a honest party losing its coins to
the malicious party.

These obstacles lead us to design a more sophisticated secure
validation subroutine. Speciﬁcally, we enforce that parties indeed
supply the correct output keys by using a very speciﬁc garbling
scheme proposed in [22]. At a high level, using a seed (for a PRG)
we generate the parties’ output keys in situ thereby preventing a
malicious party from learning (r1, r2) by supplying junk input.
Unfortunately this does not prevent other attacks. Speciﬁcally, a
malicious party may provide legitimate output keys and yet fail the
equality test (e.g., by providing inconsistent keys thereby produc-
ing different outputs). This necessitates the use of a protocol for
“secure computation with penalties” (cf. Figure 2) to implement
the secure validation step. Now a malicious party may abort the
secure validation step after learning (r1, r2) but in this case it is
forced to pay a penalty. Our secure validation subroutine SV is de-
scribed in Figure 5. Our protocol is constructed in the F (cid:63)
SV-hybrid
model. A bonus side-effect of working in the F (cid:63)
SV-hybrid model is
that our protocol guarantees fairness (in the sense of [11]).

Although, we have resolved the “fairness” problem, we are still
left with the possibility that a malicious party may force the out-
put of F (cid:63)
SV to be (r1, r2) by simply providing inconsistent inputs.
To resolve this attack, we employ a sophisticated key transfer sub-
routine (Figure 4) that generates the parties’ input keys in situ and
further distributes keys based on the parties’ inputs (i.e., subsuming
the oblivious transfer step). All of the above steps now ensure that
information leakage can happen only due to false function attacks.

Inputs: P1, P2 respectively hold inputs x1, x2 ∈ {0, 1}m.
Preliminaries. Let (com, dec) be a perfectly binding commit-
ment scheme. Let NP language L be such that u = (a, b) ∈ L
iff there exists α, β such that a = Gb(1λ, f, α) and b =
com(α; β). Let (K,P,V) be a non-interactive zero knowl-
edge scheme for L. Let crs ← K(1λ) denote the common
reference string. Let H be a collision-resistant hash function.
Protocol: For each i ∈ {1, 2}, Pi does the following: Let
j ∈ {1, 2}, j (cid:54)= i.
1. Pick ωi at random and compute Gi ← Gb(f, ωi).
2. Send (input, sid, ssid, (m, xi, ωi)) to FKT. If the output
j, g(cid:48)
j).

from FKT is abort, terminate. Else let output equal (U(cid:48)

3. Send Gi to Pj and receive Gj from Pj.
4. Compute wi ← Eval(Gj, U(cid:48)
j).
5. Choose random ri and send hi = H(ri) to Pj.
6. Let Xi = (Gj, g(cid:48)

j, hj), and let φi(w; Xi) = 1 iff w = (α,
i), α) = 1 and H(β) = hj. Send

8. Send (input, sid, ssid, ((cid:96)i, wi, ωi, ri, hj, g(cid:48)

β) such that V(crs, (Gi, g(cid:48)
(deposit, sid, ssid, i, j, φi(·; Xi), τ, coins(q)) to F (cid:63)
7. If no corresponding deposit message was received from
F (cid:63)
CR on behalf of Pj, then wait until round τ + 1 to receive
refund message from F (cid:63)
j), coins(d)) to
F (cid:63)
SV. Let zi denote the output received from F (cid:63)
SV. Do: (1)
If zi = ⊥, then terminate. (2) Else if zi = z, then out-
put z and terminate. (3) Else if zi = (r1, r2), then com-
pute πi ← P(crs, (Gi, g(cid:48)
i), ωi) and send (claim, sid, ssid,
j, i, φj, τ, q, (πi, rj)) to F (cid:63)
CR, receive (claim, sid, ssid, j,
i, φj, τ, coins(q)) and terminate.

CR and terminate.

CR.

Figure 6: Realizing F (cid:63)

f,leak.

Recall that the equality test does not help in identifying the deviat-
ing party. On the other hand, a false function attack can be readily
detected by simply asking the parties to prove in zero-knowledge
(ZK) that they computed the garbled circuit correctly. Thus, we
ask the F (cid:63)
CR transaction to release coins(q) to the other party if it
reveals the preimage to both hash values and also provides a ZK
proof that its garbled circuit was constructed correctly. (Observe
that ZK proofs are required to ensure privacy of honest inputs.)

All of the above ideas still need to be integrated together with
great care to ensure that the protocol is as secure as the DualEx
protocol of [23]. Our protocol is described in Figure 6.
Efﬁciency. Note that in an optimistic setting, i.e., when both par-
ties follow the protocol, there is no need for any party to compute
a NIZK proof (whose cost is proportional to the circuit size of f),
no F (cid:63)
CR transactions are claimed, and thus optimal validation com-
plexity is simply hash veriﬁcation (required in F (cid:63)
SV [11]). It is easy
to see that for very large circuits with |f| (cid:29) m + (cid:96), the optimal
computation/communication complexity is essentially the same as
that of the DualEx protocol. In practical instantiations, it is desir-
able to instantiate the PRG used for generating the garbled circuit
via a cryptographic hash function as described in Section 2. Also,
one may use NIZKs constructed in [18] to support very fast ver-
iﬁcation and have very short size (e.g., 7 group elements from a
bilinear group). In Appendix A we formally prove:
Theorem 1. Let f : {0, 1}m × {0, 1}m → {0, 1}(cid:96) and λ be a
computational security parameter. Assume that collision-resistant
hash functions, perfectly binding commitment schemes, and non-
interactive zero knowledge (NIZK) arguments exist for NP. Then
assuming that Gb is a secure garbling scheme as in [22], there ex-

36ists a protocol in the (FOT,F (cid:63)
F (cid:63)
f,leak (cf. Deﬁnition 1) and has the following properties:

CR)-hybrid model that SCC realizes
Its optimistic communication/computation complexity is 2 ·
|Gb(1λ, f,·)|+poly(k, m, (cid:96)) where |Gb(1λ, f,·)| denotes the
output length of Gb (i.e., size of the garbled circuit), and the
optimistic validation complexity is O(1) hash veriﬁcations.
Its worst case validation complexity equals the complexity of
NIZK veriﬁcation in addition to O(1) hash veriﬁcations.

5. FAIR COMPUTATION

In this section, we show how to design fair protocols that are
more round-efﬁcient than prior constructions [11]. Our efﬁciency
gains are due to use of a new Bitcoin transaction functionality
which we formalize as an ideal functionality below.
Ideal functionality F (cid:63)
ML (cf. Figure 7) is
to allow n parties to jointly lock their coins in an atomic fash-
ion, where each party Pi commits to a statement of the following
kind: “Before round τ, I need to reveal a witness wi that satisﬁes
φi(wi) = 1, or else I will forfeit my security deposit of x coins.”
Hence F (cid:63)

ML. The purpose of F (cid:63)

ML satisﬁes the following:

The atomic nature of F (cid:63)
ML guarantees that either all the n par-
ties agreed on the circuits φi(·), the limit τ, and the security
deposit amount x, or else none of the coins become locked.
Each corrupt party who aborts after the coins become locked
is forced to pay coins( x
If Pi reveals a correct wi then wi becomes public to everyone.
The limit τ prevents the possibility that a corrupt party learns
the witness of an honest party, and then waits for an indeﬁnite
amount of time before recovering its own coins amount.

n−1 ) to each honest party.

The Bitcoin realization of F (cid:63)
ML is presented in Figure 10. The pa-
rameter ˜τ denotes the double-spending safety distance, and the pa-
rameter τ(cid:48) denotes how many ˜τ intervals exist in a single “Bitcoin
round”. See [11, Appendices G and F] for technical Bitcoin details.

Given F (cid:63)

ML, the following theorem is easy to prove.

Theorem 2. Assuming the existence of one-way functions, for ev-
ery n-party functionality f there exists a protocol that securely
computes f with penalties in the (FOT,F (cid:63)
ML)-hybrid model. Fur-
ther, the protocol requires O(1) rounds, a single invocation of
ML, and each party deposits (n − 1) times the penalty amount.
F (cid:63)
Proof sketch. The protocol proceeds in two stages.
In the ﬁrst
stage, parties run a (unfair) secure computation protocol in the
FOT-hybrid model that accepts input yi, then computes z ←
f (y1, . . . , yn), and then uses the pubNMSS primitive [11], which
essentially additively shares z into sh1, . . . , shn, and then for ev-
ery j ∈ [n], computes (honest binding) commitments Tagj on
share with the corresponding decommitment Tokenj. At the end
of this stage, each Pj obtains (AllTags,{Tokenj}j∈[n]) where
AllTags = {Tagi}i∈[n]. In the second stage, parties run a protocol
for “fair reconstruction” of the shares.
Note that our ﬁrst stage is exactly the same as in [11]. While
they use F (cid:63)
ML. Let
φj(Tokenj; Tagj) = 1 iff Tokeni is a valid decommitment of
Tagj. Recall that {Tagj}j∈[n] are public, hence the relations φj
can be speciﬁed by anyone, but the corresponding witness Tokenj
is known only to Pj. Given this, the protocol is quite straight-
forward. Let d be a deposit parameter (which we will set later).
Let Di = (d, φ1, . . . , φn, τ ) for every i ∈ [n]. Each party sends
(lock, sid, ssid, i, Di, coins(d)) to F (cid:63)
If they receive abort
from F (cid:63)
ML, then they abort the protocol. Else, in round τ, each
Pj sends (redeem, sid, ssid, j, Tokenj) to F (cid:63)
ML, and receives back

CR to implement the second stage, we use F (cid:63)

ML.

coins(d).
If in round τ party Pi received (redeem, sid, ssid, j,
Tokenj) for Pj, then it extracts the shares from each token, and re-
constructs z, and terminates the protocol. Else it proceeds to round
τ + 1 and collects messages (payout, sid, ssid, j, i, coins(d(cid:48))) for
each j for which Pi does not possess Tokenj. This completes the
description of the protocol. The protocol has a fairly straightfor-
ward simulation and follows ideas in [11]. Due to space limitations,
we omit the simulation.

Efﬁciency. In contrast to the constructions of [11] where the n par-
ties broadcast O(n) messages in O(n) “Bitcoin rounds”, with F (cid:63)
ML
the parties broadcast O(n2) messages in O(1) rounds. Note that if
all parties are honest then F (cid:63)
ML requires only O(n) transactions on
the Bitcoin ledger, though O(n2) transaction data and O(n2) sig-
natures (to assure compensations after the τ limit) are still needed.
5.1 Bitcoin protocol enhancement proposal

In [3, Section 3.2], the authors propose to modify the Bitcoin
protocol so that in order to create a transaction txnew that re-
deems an unspent output i of an earlier transaction txold, this out-
put will be referenced in txnew via (SHA256d(txsimp
old ), i) instead of
(SHA256d(txold), i). In other words, the id of txold shall be de-
rived from the simpliﬁed form txsimp
old , i.e., the form that excludes
the input scripts which are required for txold to become valid. One
important advantage of [3, Section 3.2] is allowing a user to commit
coins on condition that another transaction would become valid, by
referencing the simpliﬁed form of that other transaction. This en-
ables users to have more rich kinds of contracts, and in particular it
enables F (cid:63)
ML. There is also a disadvantage, which is that we lose
some of the expressive power that Bitcoin scripts currently allow.
For example, suppose that P1 can redeem an unspent output by re-
vealing a witness w or w(cid:48) (e.g. preimages of hardcoded hashed
values H(w), H(w(cid:48))). When P1 broadcasts a transaction that re-
deems that output, and its transaction is added to the blockchain,
the simpliﬁed id hash will not express whether P1 revealed w or
w(cid:48). Therefore, if P2 and P3 have some contract that depend on the
witness that P1 revealed, they may not be able to settle their con-
tract since there would be plausible deniability that P1 broadcast
the other witness.

Our proposal here is to enhance [3, Section 3.2] and get the
best of both worlds, by still using SHA256d(txold) as the id
of txold for the Merkle tree in which the transaction txold re-
sides, but using SHA256d(txsimp
old ) to refer to txold in the transac-
tion txnew, i.e., the output that txnew spends shall be speciﬁed as
(SHA256d(txsimp
old ), i). This way, the PoW computations on the
root of the Merkle tree to which SHA256d(txold) belongs will com-
mit to the witness that redeemed txold, thus the disadvantage is
eliminated. Let us note that inserting SHA256d(txsimp
old ) as the id of
txold in the UTXO set (i.e. a tree of the currently unspent outputs
that Bitcoin nodes maintain) would commonly not even require an
extra SHA256d invocation, since SHA256d(txsimp
old ) has to be com-
puted when verifying the signature of txold for the ﬁrst time.

ML with the current Bitcoin protocol, in step (6) of
Figure 10 the parties need to run any unfair secure MPC protocol
to obtain idlock = SHA256d(txlock). To elaborate, the input of
each Pi for this MPC is inpi = Signski
lock ), and the output
lock , inp1, . . . , inpn). This MPC can
to all parties is SHA256d(txsimp
be unfair because the inputs {inpi}n
i=1 remain private, hence the
coins cannot become locked until step (11) of Figure 10 executes.
6. NON-INTERACTIVE BOUNTIES

(txsimp

To realize F (cid:63)

Our model consists of a bounty maker denoted M and a set of
parties P1, P2, . . . , PN (denoting parties in the Bitcoin network).

37F (cid:63)
ML with session identiﬁer sid,
running with parties
P1, . . . , Pn and a parameter 1λ, proceeds as follows:
• Lock phase. Wait to receive (lock, sid, ssid, i, Di =
(x, φ1, . . . , φn, τ ), coins(x)) from each Pi and record
(locked, sid, ssid, i, Di). Then if ∀i, j : Di = Dj send
message (locked, sid, ssid) to all parties and proceed to the
Redeem phase. Otherwise, for all i, if the message (locked,
sid, ssid, i, Di) was recorded then delete it and send mes-
sage (abort, sid, ssid, i, coins(x)) to Pi, and terminate.

• Redeem phase.

• Payout phase.

In round τ: upon receiving a message
(redeem, sid, ssid, i, wi) from Pi, if φi(wi) = 1 then
delete (locked, sid, ssid, i, Di), send (redeem, sid, ssid,
coins(x)) to Pi and (redeem, sid, ssid, i, wi) to all parties.
if
(locked, sid, ssid, i, Di) was recorded but not yet deleted,
then delete it and send the message (payout, sid, ssid, i, j,
coins( x

In round τ + 1: For all i ∈ [n]:

n−1 )) to every party Pj (cid:54)= Pi.
Figure 7: The ideal functionality F (cid:63)

ML.

Figure 8: Illustration of the F (cid:63)

ML Functionality.

M holds a relation Φx (deﬁning a NP language L) and wishes
to learn a witness w such that Φx(w) = 1.
In return for the
knowledge of the witness M is willing to pay coins(q) to a party
C ∈ {P1, . . . , PN} that ﬁnds the witness. We stress that at the
time of bounty creation, the identity of the bounty collector is un-
known. Informally, the properties that we want to guarantee from
our bounty collection problem are:
• (Noninteractive.) The bounty maker M publishes a single mes-
• (Race-free soundness.) If there exists at most one party C that
knows the witness, then no party other than C or M can claim
the bounty except with probability negligible in λ.
• (Correctness and privacy.) An honest C holding valid witness
will claim the bounty except with probability negligible in λ. In
this case, only M learns the witness.

sage to the network and remains passive otherwise.

For simplicity we assume that there exists exactly one such bounty
collector C. Furthermore, we assume that the bounty maker is hon-
est (alternatively we can ask M to give a ZK proof that its published
message corresponds to a bounty). We assume that some small
fraction of the Bitcoin miners are malicious. Therefore, if the wit-
ness is made public on the Bitcoin network, this may in turn result
in a scenario where parties “race” to claim the bounty. Afterall
in such a situation, there is nothing that distinguishes C from any
other party. Formally, we deﬁne a noninteractive private bounty
mechanism as a four-tuple of algorithms (Make, Coll, Ver, Ext):
1. (tm, ω) ← Make(1λ, Φx). The bounty maker with input φ uses

private randomness ω and runs Make to generate tm.

2. tc ← Coll(w, tm). The bounty collector with a witness w such

that φ(w) = 1 uses algorithm Coll to generate tc.

3. {0, 1} ← Ver(tm, tc). Upon receiving a claim tc the miners

use Ver to determine whether the claim is valid.

4. w∪⊥ ← Ext(ω, tc). The bounty maker runs the algorithm Ext
using the message tc. The output of the algorithm is either w
such that Φx(w) = 1 or ⊥.

The scheme should satisfy:
Correctness (with guaranteed extraction) For any x, w such
that if x ∈ L (i.e., Φx(w) = 1):

(cid:20) (tm, ω) ← Make(φ, 1λ);

tc ← Coll(w, tm)

Pr

1 = Ver(tm, tc)(cid:86)

w = Ext(ω, tc)

(cid:21)

:

= 1.

Extractability There exists a simulator Sim = (S1, S2) such that
for all PPT adversaries E and all poly q there exists a PPT extractor
E and a poly p, such that for all auxiliary inputs z and for all x ∈
{0, 1}∗ the following holds:

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) Pr

(cid:20) (tm, ω) ← Make(Φx, 1λ);
(cid:20) (tm, st) ← S1(Φx, 1λ);

tc ← Coll(w, tm)

tc ← S2(tm, st)

−Pr

(cid:21)
(cid:21)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≥ 1/q(|x|)

: 1 = E(tm, tc)
: 1 = E(tm, tc)

= 1

= 1

=⇒ Pr[E(x, z) = w : Φx(w) = 1] ≥ 1/p(|x|).

The extractability condition above essentially formalizes the
privacy property which in turn helps in satisfying the “race-free
soundness” property. The condition effectively states that an ad-
versary does not learn any information about the witness w even
after obtaining both the bounty maker’s message and the collector’s
message. More precisely, an adversary can distinguish between the
simulated messages (where the simulator does not use the witness
at all) and the actual messages generated by M and C, only if it
already knew the witness. This leads us to a contradiction since
we assumed that only C knows the witness. Our deﬁnitions are
inspired by deﬁnitions of witness encryption, a powerful crypto-
graphic primitive that excellently ﬁts to our scenario.
Deﬁnition 5 (Witness encryption [16, 20]). A witness encryption
scheme for an NP language L (with corresponding witness rela-
tion φ) consists of the following two polynomial-time algorithms:
Encryption. The algorithm Enc(1λ, x, m) takes as input a secu-
rity parameter 1λ, an unbounded-length string x, and a message
m ∈ {0, 1}, and outputs a ciphertext ψ.

Decryption. The algorithm Dec(ψ, w) takes as input a ciphertext
ψ and an unbounded-length string w, and outputs a message m
or the symbol ⊥.

These algorithms satisfy:
• Correctness. For any security parameter λ, for any m ∈ {0, 1},

and for any x ∈ L such that φ(w; x) holds, we have that
Pr[Dec(Enc(1λ, x, m), w) = m] = 1.

♦
Deﬁnition 6 (Extractable security [20]). A witness encryption
scheme for a language L ∈ NP is secure if for all PPT adver-
saries A and all poly q there exists a PPT extractor E and a poly
p, such that for all auxiliary inputs z and for all x ∈ {0, 1}∗ the
following holds:

(cid:20) b ← {0, 1}; ψ ← Enc(1λ, x, b)

(cid:21)

≥ 1/2 + 1/q(|x|)

Pr

: A(x, ψ, z) = b

=⇒ Pr[E(x, z) = w : φ(w; x) = 1] ≥ 1/p(|x|).

B.3xA.3xC.3xD.3xA?3xB?3xC?3xD?3xC.xB.xD.xC.xA.xD.xB.xA.xD.xB.xA.xC.xA.3xD.3xB.3xC.3xtime≥τ+1time≥τ+1revealwArevealwDrevealwBrevealwC138A starting point is to let the bounty maker create a witness en-
cryption ψ of a signing key sk and create a Bitcoin transaction
t that allows a party to claim the bounty only if it possesses sk.
Clearly, a party holding the witness is able to decrypt ψ and us-
ing sk is able to transfer the bounty to a different address addr of
its choice. Note however that the above solution does not allow
the bounty maker to learn the witness! Alternatively, if the bounty
maker modiﬁes t such that the bounty can be claimed only if a party
can produce w such that Φx(w) = 1, then this appears to solve the
problem. Unfortunately, this idea turns out to be naïve since a party
C that claims the transaction reveals the witness which when made
public allows malicious miners to decrypt ψ, recover the signing
(cid:48) of its choice.
key and then claim the bounty to an address addr
In other words, this leads to a network race between the legitimate
collector C and malicious nodes on the Bitcoin network.

What we need is a mechanism that simultaneously allows a le-
gitimate collector to claim the bounty while allowing the bounty
maker to extract a valid witness. We present a novel solution to this
problem via use of garbled circuits. In our construction the bounty
maker broadcasts the following: (1) witness encryption ψ of the
signing key sk, (2) a garbled circuit computing Φx(·), (3) witness
encryption ψ(cid:48) of the input labels U corresponding to GC, (4) the
output label w1 of GC corresponding to the value 1, and (5) a trans-
action that releases the bounty to a party that possesses sk and sup-
plies input labels that evaluates GC to produce the output label w1.
Clearly, a legitimate collector can claim the bounty by decrypting
ψ, ψ(cid:48) and the revealing the input labels w(cid:48) corresponding to wit-
ness w. Further, since the bounty maker knows all input labels, it
can obtain the witness using w(cid:48). On the other hand, the privacy
property of the garbling scheme ensures that a malicious miner that
obtains w(cid:48), GC still does not have any information about the actual
witness w. Although the miners can copy the value w(cid:48) and claim
it as their own, a network race is avoided because they are unable
to forge a signature without knowing the signing key. Our bounty
mechanism is presented in Figure 9. We formally prove:

Theorem 3. Let λ be a computational security parameter. As-
suming the existence of extractable witness encryption, an exis-
tentially unforgeable secure signature scheme (SigKeyGen, Sig,
SigVer), and a secure garbling scheme (Gb, Eval), there exists a
noninteractive private bounty mechanism for NP language L with
relation Φx(·) for x ∈ L whose validation complexity equals the
complexity of Eval(Gb(1λ, Φx),·) plus the complexity of SigVer.
Proof sketch. We rely on the semantic security of the extractable
witness encryption scheme as well as the existential unforgeability
of the signature scheme. Speciﬁcally, we consider a simulator that
upon receiving input Φx for x ∈ L does the following:
• Compute ( ˆGC, ˆr, ˆU, ˆw) ← Fake(1λ, Φx).
• Let ˆw ∈ ˆw. Generate (pk, sk) ← SigKeyGen(1λ).
• Compute ˆψ = Enc(1λ, x, 0λ) and ˆψ(cid:48) = Enc(1λ, x, ˆU).
• Generate ˆσ = Sigsk(r(cid:48)) for random r(cid:48) and ˆw(cid:48) = ˆUˆr.
• Output tm = (Φx, ˆψ, ˆψ(cid:48), pk, ˆGC, ˆh) and tc = (ˆσ(cid:48), ˆw(cid:48)).

We then construct a series of games starting from the real tran-
script and ending up with the simulated transcript. In the ﬁrst set of
games we replace ψ by ˆψ, and then we replace one-by-one the in-
put labels in W with encryptions of 0 in a way that ultimately ends
up in transforming U to have a structure similar to ˆU. In the second
set, we replace the actual garbled circuit GC and the legitimate in-
put labels w(cid:48) by their faked counterparts ˆGC, ˆw(cid:48). By the security
of the garbling scheme we have that the adversary’s advantage in

Let (Enc, Dec) be a witness encryption scheme for L with wit-
ness relation Φx. Let (SigKeyGen, Sig, SigVer) be an existen-
tially unforgeable secure signature scheme. Let (Gb, Eval) be
a secure garbling scheme. The bounty protocol proceeds as
follows:
• M with input Φx executes Make(1λ, Φx, ω) for random ω:

– Generate (pk, sk) ← SigKeyGen(1λ).
– Generate (GC, U, W) ← Gb(1λ, Φx; ω).
– Compute ψ = Enc(1λ, x, sk) and ψ(cid:48) = Enc(1λ, x, U).
– Let (w0, w1) = W. Set tm = (Φx, ψ, ψ(cid:48), pk, GC, w1).
• C holding w such that Φx(w) = 1 executes Coll(w, tm):

– Compute sk ← Dec(ψ, w) and U ← Dec(ψ(cid:48), w).
– Set tc = (σ = Sigsk(addr), w(cid:48) = Uw).

• Miners execute Ver(tm, tc):

– Parse tm = (Φx, ψ, ψ(cid:48), GC, w1) and tc = (˜σ, ˜w(cid:48)).

– Output 1 iff SigVer(pk, ˜σ) = 1(cid:86) Eval(GC, ˜w(cid:48)) = w1.

• M executes Ext(φ, ω, tc):

– Parse tc = (σ(cid:48), w(cid:48)). If SigVer(pk, σ(cid:48)) = 0, output ⊥.
– Output ˆw s.t. U ˆw = w(cid:48). If no such ˆw exists output ⊥.
Figure 9: A noninteractive Bitcoin bounty mechanism.

second set of games is negligible in λ. Therefore, an adversary that
has 1/poly advantage in distinguishing real transcripts from simu-
lated transcripts must have 1/poly advantage in distinguishing be-
tween the real transcript and the last of the ﬁrst set of games. Then
by appealing to the extrability of witness encryption schemes, we
can derive an extractor who succeeds in guessing the witness with
1/poly probability. Finally observe that the privacy of the scheme
and the security of the signature scheme taken together sufﬁce to
show that our mechanism provides race-free soundness.
Remark. Extractable witness encryption is a heavy assump-
tion [15] and is quite inefﬁcient in practice (cf. [13]). We sketch
a heuristic construction to replace use of witness encryption that
works for certain languages. For e.g., assume that x ∈ L iff x is
a RSA modulus. Let Φx(w) = 1 iff w = (p, q) such that both
p and q are prime and x = p · q. Our key observation is that
we can replace the witness encryption scheme simply by any RSA
encryption scheme with RSA modulus x. Note that knowing the
factorization of the RSA modulus x readily allows decryption.
Bounties via time-locked puzzles. We now sketch a noninteractive
nonprivate bounty mechanism that still enjoys race-free soundness.
To do this, we use a time-lock puzzles scheme [32]. Such a scheme
allows the bounty maker M to generate a time-locked encryption
sk(cid:48) = puzz(sk, t), so that it should take approximately time t for
anyone besides M to compute sk from sk(cid:48) (even allowing parallel
computations). The time-lock scheme allows M to generate sk(cid:48) in
time that is orders of magnitude shorter than t, hence M can esti-
mate which t0 implies that the puzzle would take e.g. ≥ 30 minutes
to solve at the year in which computing the witness w is likely to
be feasible, and use ψ = Enc(1λ, x, puzz(sk, t0)) for the witness
encryption scheme. This way, C would have a head start of t0
over other parties, and is therefore likely to win the race because its
transaction will be buried under enough PoW blocks. Depending
on the complexity of Φx(·), this bounty protocol may be realizable
with the current Bitcoin standard scripts.

397. CONCLUSIONS
In this paper we have shown that a variety of cryptographic prim-
itives can be incentivized in order to encourage honest behavior by
participants. We believe that our constructions offer compelling
motivation to change the state-of-affairs. Our work leaves a num-
ber of open questions some of which are mentioned below.
• Veriﬁable computation.

Is it possible to develop a formal
model to incentivize based on the resource usage of the worker
in private veriﬁcation schemes?

• Fair computation. Is it possible to design a protocol that needs

only O(1) rounds and O(n) transactions in the worst case?

• Secure computation with leakage. Is it possible to come up
with a general methodology to design highly efﬁcient secure
computation protocols that guarantee restricted leakage? Can
such protocols be incentivized?

Acknowledgments
This work was supported by funding received from European Com-
munity’s Seventh Framework Programme (FP7/2007-2013) under
grant agreement number 259426 and 240258. The second author
would like to thank Alex Mizrahi for useful discussions and contri-
butions to Section 5.1.

8. REFERENCES
[1] Bitcoin wiki: CVEs. https://en.bitcoin.it/wiki/CVEs#CVE-2010-5141.
[2] G. Andresen. Turing complete language vs non-turing

complete. https://bitcointalk.org/index.php?topic=431513.20#msg4882293.

[3] M. Andrychowicz, S. Dziembowski, D. Malinowski, and L.

Mazurek. Fair two-party computations via the bitcoin
deposits. In First Workshop on Bitcoin Research, FC, 2014.
[4] M. Andrychowicz, S. Dziembowski, D. Malinowski, and L.

Mazurek. Secure multiparty computations on bitcoin. In
IEEE Security and Privacy, 2014.

[5] Gilad Asharov, Yehuda Lindell, and Hila Zarosim. Fair and

efﬁcient secure multiparty computation with reputation
systems. In Asiacrypt (2), pages 201–220, 2013.

[6] Gilad Asharov and Claudio Orlandi. Calling out cheaters:

Covert security with public veriﬁability. In Asiacrypt, pages
681–698, 2012.

[7] N. Asokan, V. Shoup, and M. Waidner. Optimistic fair

exchange of digital signatures. In Eurocrypt, 1998.

[8] Yonatan Aumann and Yehuda Lindell. Security against

covert adversaries: Efﬁcient protocols for realistic
adversaries. In Salil P. Vadhan, editor, 4th Theory of
Cryptography Conference — TCC 2007, volume 4392 of
LNCS, pages 137–156. Springer, February 2007.

[9] S. Barber, X. Boyen, E. Shi, and E. Uzun. Bitter to better -

how to make bitcoin a better currency. In FC, 2012.

[10] Mira Belenkiy, Melissa Chase, C. Christopher Erway, John

Jannotti, Alptekin Kupcu, and Anna Lysyanskaya.
Incentivizing outsourced computation. In NetEcon, pages
85–90, 2008.

[11] Iddo Bentov and Ranjit Kumaresan. How to use bitcoin to

design fair protocols. In ePrint 2014/129, 2014.

[12] D. Cash, S. Jarecki, C. Jutla, H. Krawczyk, M. Rosu, and M.

Steiner. Highly-scalable searchable symmetric encryption
with support for boolean queries. In Crypto (1), 2013.

[13] J.-S. Coron, T. Lepoint, and M. Tibouchi. Practical

multlinear maps over the integers. In Crypto (1), 2013.

[14] E. Friedman and P. Resnick. The social cost of cheap

pseudonyms. In Journal of Economics and Management
Strategy, pages 173–199, 2000.

[15] S. Garg, C. Gentry, S. Halevi, and D. Wichs. On the

implausibility of differing-inputs obfuscation and extractable
witness encryption with auxiliary input. In ePrint 2013/860.

[16] S. Garg, C. Gentry, A. Sahai, and B. Waters. Witness

encryption and its applications. In STOC, 2013.

[17] R. Gennaro, C. Gentry, and B. Parno. Non-interactive

veriﬁable computing: Outsourcing computation to untrusted
workers. In Advances in Cryptology — Crypto 2010, 2010.

[18] R. Gennaro, C. Gentry, B. Parno, and M. Raykova. Quadratic

span programs and succinct nizks without pcps. In
Eurocrypt, 2013.

[19] Oded Goldreich. Foundations of cryptography - vol. 2. 2004.
[20] S. Goldwasser, Y. ˜T. Kalai, R.Ã. Popa, V. Vaikuntanathan,

and N. Zeldovich. How to run turing machines on encrypted
data. In Crypto (2), pages 536–553, 2013.

[21] Philippe Golle and Ilya Mironov. Uncheatable distributed
computations. In David Naccache, editor, Cryptographers’
Track — RSA 2001, volume 2020 of LNCS, pages 425–440.
Springer, April 2001.

[22] V. Goyal, P. Mohassel, and A. Smith. Efﬁcient two party and

multi party computation against covert adversaries. In
Advances in Cryptology — Eurocrypt 2008.

[23] Y. Huang, J. Katz, and D. Evans. Quid-pro-quo-tocols:

Strengthening semi-honest protocols with dual execution. In
IEEE Security and Privacy, pages 272–284, 2012.
[24] Y. Ishai, M. Prabhakaran, and A. Sahai. Founding

cryptography on oblivious transfer - efﬁciently. In Advances
in Cryptology — Crypto 2008, pages 572–591, 2008.

[25] S. Jarecki, C. Jutla, H. Krawczyk, M. Rosu, and M. Steiner.
Outsourced symmetric private information retrieval. In CCS,
pages 875–888.

[26] L. Lamport. Fast paxos, 2005. MSR-TR-2005-112.
[27] Y. Lindell and B. Pinkas. A proof of security of Yao’s

protocol for two-party computation. Journal of Cryptology.,
22(2):161–188, 2009.

[28] G. Maxwell. Zero knowledge contingent payment. 2011.

https://en.bitcoin.it/wiki/Zero_Knowledge_Contingent_Payment.

[29] P. Mohassel and M. Franklin. Efﬁciency tradeoffs for

malicious two-party computation. In PKC 2006.

[30] V. Pappas, B. Vo, F. Krell, S.-G. Choi, V. Kolesnikov, S.

Bellovin, A. Keromytis, and T. Malkin. Blind seer: A
scalable private dbms. In IEEE Security and Privacy, 2014.
[31] B. Parno, J. Howell, C. Gentry, and M. Raykova. Pinocchio:
Nearly practical veriﬁable computation. In IEEE S&P, 2013.

[32] R. L. Rivest, A. Shamir, and D. A. Wagner. Time-lock

puzzles and timed-release crypto. Technical Report
MIT/LCS/TR-684, MIT, 1996.

[33] A. Rosen and A. Shelat. Optimistic concurrent zero

knowledge. In Advances in Cryptology — Asiacrypt 2010.

[34] P. Todd. Reward offered for hash collisions for sha1, sha256,

ripemd160. https://bitcointalk.org/index.php?topic=293382.0, 2013.

[35] Andrew Yao. How to generate and exchange secrets
(extended abstract). In FOCS, pages 162–167, 1986.

Consider

the protocol

SV in the (FOT,F (cid:63)

APPENDIX
A. PROOF OF THEOREM 2
in Figure 6.
Using the protocol
of [11], we have that implementing F (cid:63)
CR)-
hybrid model has validation complexity the O(1) hash veriﬁca-
tions. Given this, it is easy to see that its optimistic communica-
tion/computation/validation complexity and the worst case valida-
tion complexity is exactly as stated in the theorem. In the rest of the
proof we give details about the simulation in the (FKT,F (cid:63)
CR)-
hybrid model. Note that FKT can be realized in the FOT-hybrid
model [24] and that F (cid:63)
SV can be realized in the (FOT,F (cid:63)
CR)-hybrid
model [11]. Assume that adversary A corrupts Pi. Let Pj denote
the honest party. We sketch the simulation below. Let (S1,S2) be
the NIZK simulator.
• S computes (crs, t) ← S1(1λ).
• S computes ( ˆGj, ˆx, ˆU, ˆw) ← Fake(1λ, f ).

SV,F (cid:63)

40• Acting as FKT, S next obtains (m, xi, ωi) from A. If A sends
abort, then S terminates the simulation. Else it speciﬁes output
of FKT as ( ˆU, g(cid:48)
j = com(0; ˆρj)) where ˆρj is picked uniformly
at random.

• Acting as Pj, S sends ˆGj to A and receives Gi from A.
• S chooses random rj and sends hj = H(rj) to A and receives
hi from A.
SV, S obtains (input, sid, ssid, ((cid:96)i, wi, ˜ωi, ˜ri, ˜hj,
• Acting as F (cid:63)
j), coins(q)) from A. If ˜ωi (cid:54)= ωi or H(˜ri) (cid:54)= hi or ˜hj (cid:54)= hj or
˜g(cid:48)
j (cid:54)= g(cid:48)
˜g(cid:48)
• Using the extracted ωi, S computes Ui, Wi. S speciﬁes the fol-

j or wi (cid:54)= ˆw, then set zi = bad.

lowing as the “leakage” function Lxi (xj):
– Compute wj = Eval(Gi, Ux1(cid:107)x2
– Compute v ∈ {0, 1}(cid:96) such that wj = Wv
i .
– If v = f (x1, x2) return 1, else return 0.

).

i

f,leak.

coins(q)) to F (cid:63)

f,leak, then set zi =

• If at any stage S acting as F (cid:63)

• If zi is not already set to bad, S sends (input, sid, ssid, xi, L,
• If (abort, sid, ssid) is received from F (cid:63)
• S acting as F (cid:63)
SV sets output as zi and delivers output messages
• If zi = (r1, r2), then S computes a simulated NIZK argument
CR sends message

(r1, r2).
to A.
j), t), and acting as F (cid:63)
ˆπ ← S2(crs, (Gj, g(cid:48)
(claim, sid, ssid, i, j, φi, τ, q, (ˆπ, rj)) to A.
CR receives message (claim, sid,
ssid, j, i, φj, τ, q, w) from A and it holds that φj(w) = 1, then
it outputs fail and terminates the simulation.
We ﬁrst prove that conditioned on S not outputting fail, the sim-
ulation is indistinguishable from the protocol execution throught a
series of hybrid execution. Let Hyb0 denote the protocol execu-
In Hyb1, we change the NIZK argument with a simulated
tion.
argument.
Indistinguishability of Hyb0 and Hyb1 follows from
the zero-knowledge property of NIZKs.
In Hyb2, we compute
g(cid:48)
j = com(0) (i.e., commitment on the all-zero string) instead of
com(ωj). Indistinguishability of Hyb1 and Hyb2 follows from the
hiding property of the commitment scheme. In Hyb3, we compute
Gj, U(cid:48)
j using Fake (instead of Gb and iGb). Indistinguishability of
Hyb2 and Hyb3 follows from the security of the garbling scheme
Gb. It is easy to see that Hyb3 is identical to the simulated execu-
tion.
It remains to be shown that the probability that S outputs fail is
negligible in λ. We consider two cases. Suppose the output zi = z.
In this case, observe that S outputs fail iff A produces r(cid:48) such that
H(r(cid:48)) = hj. It then follows from the collision-resistance of H that
such an event happens with negligible probability. On the other
hand suppose the output zi = (r1, r2). In this case, S outputs fail
iff A provides a valid proof that (Gi, g(cid:48)
i) ∈ L. By the soundness
property of NIZK, except with negligible probability there exists
i = com(ω; ρ) and Gi ← Gb(1λ, f, ω). Now
ω, ρ such that g(cid:48)
suppose Gi (cid:54)= Gb(1λ, f, ωi) (where ωi was extracted via FKT),
then this means that g(cid:48)
i can be opened to both ω as well as ωi and
thus we have a contradiction since we assumed a perfectly binding
commitment scheme. On the other hand, if Gi = Gb(1λ, f, ωi),
then essentially A has executed the protocol honestly. It can then
be easily veriﬁed that if zi (cid:54)= bad, then zi will not be of the form
(r1, r2) either. This completes the proof.

Lock phase.
1. Every Pi holds a public key pki for which only it knows
the corresponding secret key ski, scripts {φj}n
j=1, lock-
time value τ0 = τ · τ(cid:48) · ˜τ, and an unspent output (idi, ti) of
p = x(n − 1) coins that it controls (i.e. speciﬁed as a pair
of transaction id and output index).

2. For i ∈ [n− 1], Pi sends (lock_init, i, (idi, ti), pki) to Pn.
3. Pn creates the simpliﬁed transaction txsimp
that spends
lock

the n inputs (cid:2)(id1, t1), . . . , (idn, tn)(cid:3) to n outputs
(cid:2)(p, π1) . . . , (p, πn)(cid:3), where πi(w, s1, . . . , sn)

(cid:44)
(OP_CHECKSIG(pk1, s1) ∧ . . . ∧ OP_CHECKSIG(pkn, sn)) ∨
(OP_CHECKSIG(pki, si) ∧ φi(w) = 1).

4. Pn sends (lock_prepare, txsimp
5. Every Pi ensures that for all j ∈ [n], the jth output (yj, πj)
lock has yj = p and πj incorporates φj accordingly.

lock ) to all parties.

of txsimp

6. Let idlock ← SHA256d(txsimp

7. Every Pi creates a simpliﬁed transaction txsimp

lock ). Note: this is justiﬁed due
to Section 5.1, and the reader is referred to Section 5.1 for
an alternative that works with the current Bitcoin protocol.
pay:i that has
locktime τ0 and spends the input (idlock, i) to n − 1 out-
i (·) =
i(·)), and sends
pay:i)) to all parties.
the locktime values of

puts(cid:2)(x, ψ1
OP_CHECKSIG(pkn,·))(cid:3) excluding (x, ψi

i (·) = OP_CHECKSIG(pk1,·)), . . . , (x, ψn

(payback, i, txsimp
8. Every Pi ensures

pay:i, psi,i = Signski

that all

(txsimp

pay:j}j∈[n]\{i} equal τ0. Otherwise Pi aborts.

9. Every Pi computes n − 1 signatures Si = {psi,j =
the message

pay:j)}j∈[n]\{i},

and
Signski
(payback_ack, i, Si) to all parties.

(txsimp

sends

{txsimp

10. Every Pi extracts {pkj}j∈[n]\{i} from txsimp

lock and ensures
pay:k, psj,k) = 1 for all j ∈ [n] \ {i} and

that Vrfypkj
all k ∈ [n] \ {i}. Otherwise Pi aborts.

(txsimp

11. Every Pi computes sigi = Signski

1], Pi sends the message (lock_ﬁnalize, i, sigi) to Pn.

(txsimp

lock ). For i ∈ [n −

12. Pn transforms txsimp

lock to txlock by injecting each sigj as the
script that redeems the input (idj, tj), and broadcasts the
now valid transaction txlock to the Bitcoin network.

Redeem phase.

13. Every Pi waits until ˜τ PoW blocks extend the block in
which txlock resides, and then broadcasts to the Bitcoin net-
work a transaction that spends the ith output of txlock by
signing with ski and revealing wi that satisﬁes φi(wi) = 1.
14. Until τ0 blocks have been solved by the Bitcoin network,
every Pi listens on the network and waits until for all j ∈
[n] \ {i}, Pj redeems the jth output of txlock and thereby
reveals wj that satisﬁes φj(wj) = 1.

Payout phase. After (τ + 1)τ(cid:48) ˜τ − ˜τ blocks have been solved:
15. Every Pi checks for each j ∈ [n] \ {i} whether the jth out-
put of txlock can still be spent. If so, Pi injects the signa-
tures {psj,k}n
pay:j, and broadcasts the now valid
transaction txpay:j to the Bitcoin network.

k=1 into txsimp

Figure 10: Realizing F (cid:63)

ML in Bitcoin.

41