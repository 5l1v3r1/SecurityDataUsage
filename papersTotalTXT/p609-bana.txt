A Computationally Complete Symbolic Attacker for

Equivalence Properties

∗

Gergei Bana

INRIA Paris-Rocquencourt
bana@math.upenn.edu

Paris, France

†
Hubert Comon-Lundh

LSV, ENS Cachan
Cachan, France

comon@lsv.ens-cachan.fr

ABSTRACT
We consider the problem of computational indistinguishability of
protocols. We design a symbolic model, amenable to automated de-
duction, such that a successful inconsistency proof implies compu-
tational indistinguishability. Conversely, symbolic models of dis-
tinguishability provide clues for likely computational attacks. We
follow the idea we introduced earlier for reachability properties,
axiomatizing what an attacker cannot violate. This results a com-
putationally complete symbolic attacker, and ensures unconditional
computational soundness for the symbolic analysis. We present a
small library of computationally sound, modular axioms, and test
our technique on an example protocol. Despite additional difﬁcul-
ties stemming from the equivalence properties, the models and the
soundness proofs turn out to be simpler than they were for reacha-
bility properties.

Categories and Subject Descriptors
C.2.2 [Computer-Communication Networks]: Network Proto-
cols—Protocol veriﬁcation

Keywords
Security Protocols; Protocol Indistinguishability; Symbolic Veriﬁ-
cation; Computational Soundness

1.

INTRODUCTION

Symbolic analysis of security protocols is a well-established re-
search direction. Attacker capabilities in such a framework are
modeled by the so-called “Dolev-Yao attacker”, which can only
perform sequences of actions from a ﬁxed set of possible actions.
There are several automated tools based on this framework, includ-
ing PROVERIF [13], SCYTHER [22], AVISPA [24]. When such a
∗This work has been partially supported by the ANR project ProSe
(decision ANR-2010-VERS-004) and the ERC project CRYSP
(259639) as well as the FCT project ComFormCrypt (PTDC/EIA-
CCO/113033/2009).
†This work has been partially supported by the ANR project ProSe
(decision ANR-2010-VERS-004)

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
Copyright 2014 ACM 978-1-4503-2957-6/14/11 ...$15.00.
http://dx.doi.org/10.1145/2660267.2660276.

tool claims that there is no attack, we must be careful: this only
means there is no attack in the model that is considered. There
could be attacks relying on some actions that are not accounted for
by the Dolev-Yao attacker, for instance, exploiting imperfections of
cryptographic primitives (e.g.,[25]).

Closer to reality than the Dolev-Yao model is the so-called com-
putational model, which uses complexity theory to express security
properties. Attackers are modeled as probabilistic polynomial-time
algorithms. It is far more convincing when a protocol is proved
secure in this model than with respect to the Dolev-Yao model.

In order to overcome this discrepancy, the following directions

have been considered in the literature:

• prove computational soundness results, stating that the Dolev-
Yao model is fully abstract with respect to the computational
one, hence any attack that can be carried out on the com-
putational implementation is also possible in the Dolev-Yao
model. There is a long line of research in this direction, start-
ing with [2, 4].

• carry out the proof in a computational model. Since this is
very long and error-prone, it should be, at least partly, carried
out with the help of a formal prover. CRYPTOVERIF [14] and
EASYCRYPT [10] are examples of provers, which complete
the proofs in the computational setting.

Both directions have several drawbacks. Computational soundness
results require very strong assumptions, often unrealistic, and their
proofs are themselves very long and technical. Their scope is lim-
ited; for instance, in the case of equivalence properties (which is the
subject our paper), there are very few soundness results for active
attackers, notably [18, 21], and their assumptions are disputable. In
particular, all (unless KDM secure encryption is assumed) sound-
ness proofs require the absence of key cycles and that the keys are
honestly generated (except [19]). A further problem of such sound-
ness results is that they are not modular: including new primitives
requires a soundness proof for the whole system again.

Proving the protocols directly in the computational setting is
(currently) often not possible automatically due to the complexity
of the task. Moreover, we do not know what to do when the current
provers fail to prove a protocol: is there a ﬂaw in the protocol or
are we and the prover simply not capable enough to complete the
proof?

Our previous work, presented in [6], takes a different approach.
We also formalize the protocols and the attackers in a symbolic
way. However, instead of specifying explicitly everything that is
possible (as the Dolev-Yao approach does) for the attacker and
hence considering the least model, we speciﬁed what cannot be vi-
olated and hence considered the greatest model that the set of rules
permit. The properties that cannot be violated (because of the na-

609ture of PPT algorithms, because of assumptions on the primitives,
etc.) are called axioms. The attacker may perform any action that
is consistent with the speciﬁcation. If one manages to prove the
protocol in such a setting, then it is guaranteed that the protocol is
computationally secure, roughly because all models are considered
that do not violate the axioms, which includes the computational
model. In other words, to every successful computational attack,
there is a corresponding successful symbolic attack: all computa-
tional attacks are symbolically accounted for, and that is why we
call our symbolic attacker computationally complete symbolic at-
tacker. Therefore, we reduced protocol security to an inconsistency
proof for a set of ﬁrst-order formulas: if the negation of the security
formula is inconsistent with the set of axioms, then the protocol is
secure in any model of the axioms.

On the other hand, a model for the negation of the security for-
mula together with the axioms is a clue: from such a model we
can derive missing properties that are necessary for the protocol
security. This is an advantage over the direct methods.

Yet another advantage: with the our technique, we do not have
to assume (for instance) that the protocol does not produce key cy-
cles or that the keys are honestly generated. Such properties may
be necessary for the conclusions of some axioms, but this does not
change the scope of the method: if we complete an inconsistency
proof, then the protocol is secure, even if it produces key cycles or
uses dishonest keys etc... Basically, what is shown on the way is
that such occurrences of key-cycles, dishonest keys etc. are harm-
less for the security.

This very seducing approach has itself some difﬁculties and lim-

itations, e.g.:

• Axioms have to be designed. They are independent of the
protocol. Such formulas formally state the cryptographic
assumptions, or, more precisely, properties implied by the
cryptographic assumptions. They can be re-used for several
protocol analysis. There were several axioms (independent
of protocols) proposed by Bana et al. in [5, 7], actual pro-
tocols were veriﬁed with them, and new attacks were found.
However, handling further primitives/new security assump-
tions requires new axioms.

• Consistency proofs have to be automated. Scerri et al. are in
the process of developing a tool. In principle, it is possible to
complete an automated consistency check in an efﬁcient way
[20].

• We only consider protocols with a ﬁnite number of control

states, ruling out replicated processes.1

• In our previous work, we investigated reachability proper-
ties only. This was a weak point not only because for in-
stance privacy cannot be expressed as a reachability prop-
erty, but also because cryptographic assumptions are nowa-
days expressed using indistinguishability, making the search
for convenient axioms difﬁcult.

1We could easily drop this assumption (as in [5, 7]), however al-
lowing on the computational side only attacks each of which has
a bound on the number of exchanged messages (independently of
the security parameter as an initial input). The best we can expect
from a symbolic model that does not refer explicitly to the security
parameter is to capture computational attacks with such a bound.
In particular, none of the existing soundness results in the literature
capture attacks that do not have this bound. We choose here to in-
clude this assumption as we do not loose much, but the formulation
becomes much simpler.

The present paper intends to ﬁll the last weakness. We show how
it is possible to apply the “greatest model” approach to equivalence
properties. In some aspects the case of equivalence properties has
turned out to be simpler than that for reachability properties. The
(unconditional) computational soundness result is quite straightfor-
ward. The axioms are more natural, they correspond more closely
to the computational assumptions on the cryptographic primitives.
Before explaining the details, let us ﬁrst show on simple exam-
ples why it is not straightforward to extend our previous work on
reachability to equivalence properties.
1.1 Difﬁculties of the extension to equivalence

properties

Two protocols P1, P2 are computationally indistinguishable if
for each probabilistic polynomial-time attacker, the probability that
it outputs 1 when interacting with P1 and the probability that it
outputs 1 when interacting with P2 are only negligibly different.

In order to prove such a property without any explicit reference
to the security parameter, the ﬁrst idea that comes to mind is to con-
sider the symbolic executions of the protocols P1 and P2, and, for
each trace t1 of P1, look for a trace t2 of P2 such that t1 and t2 are
computationally indistinguishable, and vice versa. The following
example shows that this fails, even in the simplest cases:

EXAMPLE 1. Consider the two processes (b is assumed here to

be 0 or 1; we could also consider the ﬁrst bit of a nonce).

νb. out(b)

νb.if b = 0 then out(1) else out(0)

The ﬁrst process generates a random bit b and outputs it. The sec-
ond generates ﬁrst a random bit b, and if b is 0, it outputs 1, if b is
1, it outputs 0. Clearly, both processes output a random bit, so they
are computationally indistinguishable as the distributions are iden-
tical. However, symbolically there is only one trace for the ﬁrst
process, while two for the second, and both traces of the second
process (one where the output is 1 and one where the output is 0)
can be distinguished from the single trace of the ﬁrst one (where
the output is 0 or 1 with probability 1/2). That is, there is a trace t1
of P1 such that for any t2 of P2, t1 and t2 are distinguishable. 2

Clearly, the problem in the above example is that in the left pro-
tocol a single symbolic trace covers all computational traces, while
in the right protocol, a single symbolic trace covers half of the com-
putational traces. So from this (trivial) example, one may think that
it sufﬁces to split the conditions in either (or both) processes so
that symbolic traces on the two sides cover corresponding parts of
the computational traces as, for instance, this is done in the sym-
bolic veriﬁcation algorithm of [17]. It is not clear however how to
perform such a splitting systematically. Consider for instance the
following modiﬁcation of the previous example:

(cid:48)

)

. out(n

EXAMPLE 2. Consider the two processes:
(cid:48)

νb.νn.if b = 0 then out(1 · n) else out(0 · n)
νn
The dot means concatenation. Assume also that n is drawn uni-
formly at random in {0, 1}η, n(cid:48) is drawn uniformly at random in
{0, 1}η+1 and b is drawn uniformly at random in {0, 1}. The pro-
cesses are indistinguishable, since they output a random bit string
of length η + 1. Matching the branches of the two processes would
require to distinguish cases depending on the values of the ﬁrst bit
of n(cid:48).
2

It is unclear how to perform the above splitting automatically:
there is no b like in the ﬁrst process and therefore we cannot branch,
depending on a test on b. Guessing the necessary additional tests
requires a deep insight on the distributions of the output.

610The next difﬁculty is a standard one when moving from reach-
ability properties to equivalence properties. Note that even if an
attacker interacting with P1 can get the same information as an at-
tacker interacting with P2, this does not imply that P1 and P2 are
indistinguishable, since the information might be obtained in differ-
ent ways in the two experiments. A single attacker though, using
the same recipes in both experiments, may notice a difference in
the results. The other direction is also true: attackers using differ-
ent recipes may obtain different results in the two processes while
the processes are in fact equivalent.

The procedures that are designed to check trace equivalence in
the usual symbolic model ensure the same attacker’s actions for
both protocols, either by overlapping the protocols and hence re-
ducing the equivalence to a reachability property of a bi-process
[15], or else by explicitly representing the attacker’s actions (e.g.
[17]). The ﬁrst solution actually checks a stronger indistinguisha-
bility property, which prevents us from proving the equivalence
of two processes that have different control structures such as the
simple example of the private authentication protocol that we will
present in this paper. The second solution speciﬁes all computa-
tions the attacker can do, which is precisely what we want to avoid
here (following the idea in [6]), because the absence of such an ex-
plicit description is necessary to make the symbolic attacker com-
putationally complete.

EXAMPLE 3.

P1 = out((cid:104)a, b(cid:105)).in(x).if x = a then 0 else 1
P2 = out((cid:104)b, a(cid:105)).in(y).if y = b then 0 else 1

P1 and P2 are clearly computationally equivalent if the names a, b
are indistinguishable, and should be in our symbolic model as well.
In both cases, x (resp. y) is any message that can be computed by
the attacker from the output. The attacker has however to use the
same recipe in both cases, which requires an explicit reference to
the recipe: it is not possible to continue the idea of [6] and just
say that x (resp. y) is computed by the attacker from the previous
outputs since, in that case, we could choose for x the ﬁrst projection
and for y the second projection (x = y = a) which yields an output
0 in the ﬁrst process and an output 1 in the second process.
2

This example reminds us that, when checking equivalence prop-

erties, the same attacker is faced with the two experiments.
1.2 Our contributions

We use three simple tricks to solve the difﬁculties above:
• Instead of trying to match the execution branches in the two
protocols, we fold the protocols, including the control struc-
ture into the message terms so that each protocol has only
one trace. This trick is inspired by the merging of the pro-
cess branches deﬁned in [16].
In that paper, the authors’
goal was to use the PROVERIF veriﬁcation tool on proto-
cols that have different control structures. Equivalences are
checked in PROVERIF by overlapping the processes, com-
puting a so-called bi-process, and checking that they do not
diverge at any point. This yields (false) attacks, as soon as
the protocols have different control structures. To overcome
this difﬁculty, the trick of [16] is that at each step, instead of
various possible outputs on the various branches, the output
is a single term that includes a conditional branching in the
form of function symbols, while the conditional branching
was part of the control structure of the original process. We
do the same. We adapt the merging procedure of [16] to our
aims, and prove that the merging is correct in the sense that

it yields the same executions, whatever execution model is
considered. For instance, if we come back to Example 2, the
second process is folded into

νb.νn.out( if b = 0 then 1 · n else 0 · n )

introducing if _ then _ else _ as a function symbol on terms.
• Once the branches are merged, the output of each experiment
is just a single sequence of messages, whose indistinguisha-
bility we express using the predicate ∼.2 In the previous ex-
ample, we are left to check the indistinguishability of terms:

(cid:48) ∼ if b = 0 then 1 · n else 0 · n

n

• In order to express that it is the same computation that is per-
formed by the attacker on each of the experiments, we sim-
ply use free function symbols. The same function symbols
are used in both experiments, when the computations need to
be identical. This straightforward idea works in our context
because security is proved by checking the inconsistency of
a formula. First-order inconsistency means that there is no
ﬁrst-order model, in particular no interpretation (the same
for both experiments) of the these free function symbols (no
attacker’s computations) that violates the security property.
For instance in Example 3, the equivalence of the two pro-
cesses is expressed as
if g((cid:104)a, b(cid:105)) = athen 0else 1 ∼ if g((cid:104)b, a(cid:105)) = bthen 0else 1
for any free function symbol g.

These three very simple ideas are actually sufﬁcient for reduc-
ing the computational indistinguishability to the unsatisﬁability of
a (recursive) set of ﬁrst-order formulas. Then, axioms have to be
introduced for the ∼ predicate, some of which depend on the secu-
rity assumptions on the cryptographic primitives. In Section 7 we
deliver some examples of axioms and prove their soundness. We il-
lustrate our method in Section 8, showing how it is applied to prove
the computational security of a version of the private authentication
protocol [3]. We also show an attack on the ﬂawed original version
of the protocol.

The layout is the following: In Section 2 we deﬁne the syntax
of our formulas; we only consider equivalences or their Boolean
combination. In Section 3 we explain how such formulas are inter-
preted. This includes the computational semantics, which is now
much simpler than it was in case of a computability predicate (as in
[6]). In Section 4 we deﬁne the protocols: they are arbitrary ﬁnite
labeled transition systems. In Section 5 we discuss the folding pro-
cedure. In Section 6 we state and prove the unconditional sound-
ness result. In Section 7 we provide some axioms that are proved
to be computationally sound and that are sufﬁcient for proving the
correct version of the private authentication protocol in Section 8.

2. SYNTAX
2.1 Terms
Let S be a ﬁnite set of sorts that includes at least the sorts bool
and message. Function symbols: F is any (ﬁxed) set of func-
tion symbols together with a type in S∗ × S. When type(f ) =
(s1, . . . , sn, s), we also write f : s1 × . . .× sn → s and call n the
arity of f. F includes at least
2Note, the formal indistinguishability relation [8, 23] is not a pred-
icate, it is a model with a set of terms as its domain.

611• conditional branching if _ then _ else _ :

bool × message × message → message,
• Booleans true :→ bool and false :→ bool
• empty message 0 :→ message.
• equality test EQ(_) : message × message → bool
• lengths agreement test

EQL(_) : message × message → bool

This is pure syntax. For instance true and false may be interpreted
as PPT algorithms, as we will see later; the sort bool may be inter-
preted as a set that has more than 2 elements (as boolean functions).

EXAMPLE 4. We are going to illustrate our method on the pri-
vate authentication protocol [3]. This protocol does the following:
First some initiator agent a(cid:48) sends a message {pka(cid:48) , n0}r0
to re-
pkb
sponder b, where pkx denotes the public key of agent x, n0 is a
freshly generated nonce, r0 is a freshly generated random input,
and the curly brackets denote an encryption. Agent b checks if the
ﬁrst projection of the decryption of what it received is pka with a
ﬁxed agent a, and if yes, then it sends back {n0, n}r
with a fresh
pka
nonce n and a fresh randomness r. Otherwise it does not send any-
thing (outputs 0). We can sketch this as

1. a(cid:48) → b: {pka(cid:48) , n0}r0
pkb
2. b

−−−−−−−→ a(cid:48): {n0, n}r
if pka=pka(cid:48)
pka

Accordingly, the formalization of this protocol relies on the fol-
lowing function symbols (other than true, false, 0, EQ(_), EQL(_),
if _ then _ else _ ):

{_}_
dec(_, _) :
k(_) :
pk(_), sk(_) :
(cid:104)_, _(cid:105) :
π1(_), π2(_) :

_ : message × message × message → message
message × message → message
message → message
message → message
message × message → message
message → message

Here, dec(x, y) denotes decryption of x with secret key y. k(x)
is the public-key secret-key pair of agent x, pk(x) is the public
key, sk(x) is the secret key part of key x. We use the shorthands
pkx ≡ pk(k(x)) and skx ≡ sk(k(x)). (cid:104)_, _(cid:105) denotes paring of
messages, and π1(_), π2(_) denote projections to the ﬁrst and sec-
ond components of a pair respectively.
2
In addition, there is a set G of (free) function symbols, contain-
ing, for every natural number n, inﬁnitely many symbols whose
type is messagen → message. The set N of names is an inﬁ-
nite set of symbols that are treated as functions symbols of arity 0
and sort message. X is an inﬁnite set of variable symbols, each
coming with a sort s ∈ S. We assume that F, G, N , X are disjoint.
Terms are built using F, G, N , X , following the sort discipline:
for each s ∈ S, let Ts(F,G.N ,X ) be the smallest set such that

• if n ∈ N , then n ∈ Tmessage(F,G.N ,X ) and if x ∈ X has

sort s, then x ∈ Ts(F,G.N ,X )

• if f : s1 × . . . × sn → s is a symbol of F ∪ G, and
t1 ∈ Ts1 (F,G.N ,X ), . . . , tn ∈ Tsn (F,G.N ,X ), then
f (t1, . . . , tn) ∈ Ts(F,G.N ,X )

Note that we do not have implicit coercion: a term of sort bool
cannot be seen (also) as a term of sort message. We may however
add explicit coercion function symbols.

EXAMPLE 5. With F as deﬁned in Example 4, using 0-arity
symbols a, a(cid:48), b ∈ F as agent names, r ∈ N and an additional
function symbol g from G,

(cid:16)
(cid:110)(cid:68)

π1

(cid:1)(cid:17)
(cid:16)
dec(cid:0)g(pka, pka(cid:48) , pkb), skb
(cid:1)(cid:17)
(cid:16)
dec(cid:0)g(pka, pka(cid:48) , pkb), skb

π2

, pka
, n

(cid:17)
(cid:69)(cid:111)r

pka

if EQ
then
else 0

is a term of sort message. We will use this term to denote the out-
put of agent b in the protocol in Example 4 (and g(pka, pka(cid:48) , pkb)
will denote the adversary’s input computed from the initial infor-
mation of public keys pka, pka(cid:48) , pkb).
2

In order to display the formulas more concisely, we will write

if s then t instead of if s then t else 0 .
2.2 Formulas

Our atomic formulas are Boolean-valued equivalences between
sequences of terms. Formally, we have for every sequence of sorts
s1, . . . , sn a predicate symbol that takes 2 × n arguments of sort
(s1 × . . . × sn)2, which we write as t1, . . . , tn ∼ u1, . . . , un
(overloading the notations for the predicate symbols with different
types). t1, . . . , tn ∼ u1, . . . , un represents the indistinguishability
of the two sequences of terms t1, . . . , tn and u1, . . . , un.
Some of the terms t1, . . . , tn may have the sort bool, but ∼ is our
only predicate symbol: in this paper, we only consider properties
of the protocol that can be expressed with this equivalence symbol.
Our set of formulas, which will be used both for axioms and se-
curity properties are ﬁrst-order formulas built on the above atomic
formulas.

Such formulas should not be confused with tests that might be
performed in the protocol. These tests will be represented using
functions taking values in sort bool (as EQ). Since we do not ﬁx the
set of such functions, a priori any kind of test can be performed.

EXAMPLE 6. If we let g ∈ G be a function symbol that repre-
sents the attacker’s action, r ∈ N be a name and a, a(cid:48), b be distinct
agent names (constant function symbols in F), then
, pka
, n

(cid:1)(cid:17)
dec(cid:0)g(pka, pka(cid:48) , pkb), skb
(cid:16)
(cid:1)(cid:17)
dec(cid:0)g(pka, pka(cid:48) , pkb), skb
(cid:1)(cid:17)
dec(cid:0)g(pka, pka(cid:48) , pkb), skb
(cid:16)
(cid:1)(cid:17)
dec(cid:0)g(pka, pka(cid:48) , pkb), skb

(cid:16)
(cid:16)
(cid:110)(cid:68)
(cid:16)
(cid:16)
(cid:110)(cid:68)

(cid:17)
(cid:69)(cid:111)r
(cid:17)
(cid:69)(cid:111)r

, pka(cid:48)
, n

if EQ
then

if EQ
then

∼

pka

π2

π1

π2

π1

pka(cid:48)

is an atomic formula without free variable, which expresses the de-
sired privacy property for one session of the private authentication
protocol of Example 4. This property states that the adversary can-
not tell whether b is checking for the key of a or a(cid:48).
2

3. SEMANTICS
3.1 First-order interpretation

The models of our formulas are classical ﬁrst-order models. The

algebras are multi-sorted, following our sort discipline.

EXAMPLE 7. Let us consider the formula in Example 6. We
illustrate two possible models of our logic, one that is a model and
another that is a counter-model of the formula.

• Consider the interpretation domain of terms, constructed on
the encryption symbol, pairing, names and keys, as well as

612a single error message. The dec symbol is interpreted in
the model in such a way that dec({x}z
, sky) = x (here
pky
= is the identity on the domain of the model), and decryp-
tion returns an error message in all other cases (i.e., in case
the argument is not an encryption or the decryption key does
not match). The terms are evaluated in a strict way (call by
value) and any function applied to an error returns the er-
ror. bool is interpreted as a two element set: the interpre-
tation of true and the interpretation of false. EQ is inter-
preted as the term identity. if _ then _ else _ is interpreted
as usual. The equivalence is interpreted as static equivalence
(as deﬁned in [1]). Suppose we chose different a, a(cid:48), and
b. Now, if we set g(pka, pka(cid:48) , pkb) to {(cid:104)pkb, n0(cid:105)}r0
, (for
pkb
some r0 ∈ F) we get a model of the equivalence, as both
members of the equivalence consist in an empty message. If
we set g(pka, pka(cid:48) , pkb) to {(cid:104)pka, n0(cid:105)}r0
, we get a counter
pkb
model since the ﬁrst message is evaluated to {(cid:104)n0, n(cid:105)}r
pka
while the second is the empty message.

• We may consider exotic models also: Let the domain be the
set of two elements {0, 1}, let pka be interpreted as 1, pka(cid:48)
is interpreted as 0 and all function symbols return 1, except
EQ, which is interpreted as equality, 0, which is interpreted
as 0 and if _ then _ else _ , which is interpreted as usual. The
equivalence is interpreted as equality. Then the ﬁrst term in
the example is interpreted as 1 and the second one is inter-
preted as 0. The equivalence fails in this model.
2

3.2 Computational interpretation

A computational model Mc is a particular ﬁrst-order model,
which deﬁnes both the interpretations of the primitives (function
symbols in F) and the attacker’s actions (function symbols in G).
Such a model is deﬁned as follows:
1. The domain of sort message is a family of PTIME computable
bit string valued random variables indexed by the security parame-
ter. More precisely, the domain Dmessage (or Dm in short) is the set
of deterministic Turing machines A equipped with an input (and
working) tape and two extra tapes (that will be used for the random
inputs). All tapes carry bit strings only, the additional tapes con-
tain inﬁnitely long randomly generated bit strings. We require that
the computation time of A is polynomial in the worst case w.r.t the
input (not the content of the extra tapes). One of the extra tapes is
used for the honestly generated random values (that are available to
the attacker only if they are disclosed, directly or indirectly), while
the other is used by the attacker when (s)he draws random values.
The length of the machine input is the security parameter. We write
A(w; ρ1; ρ2) for the output of the machine A on input w with extra
tape contents ρ1, ρ2.
The domain of sort bool is the set of such machines whose output
is in {0, 1}. We denote this by Dbool (or Db in short).
2. A function symbol f ∈ F (resp. a function in G), f : s1 × . . .×
sn → s is interpreted as a mapping [[f ]] : Ds1 × . . . × Dsn → Ds
that it is deﬁned by some polynomial time (deterministic) Turing
machine Af as follows: Let (d1, . . . , dn) ∈ Ds1 × . . .× Dsn, that
is, Turing machines as deﬁned above.

• If f ∈ F, then [[f ]](d1, . . . , dn) is the machine, such that, on

input w and extra tapes ρ1, ρ2,

[[f ]](d1, . . . , dn)(w; ρ1; ρ2) :=
Af (d1(w; ρ1; ρ2), . . . , dn(w; ρ1; ρ2))

In other words, we compose the machine Af with the ma-
chines d1, . . . , dn.

Note that the machine Af cannot use directly the tapes ρ1, ρ2
(only through d1, . . . , dn). Intuitively, the random inputs to
the functions in F must be explicitly given as arguments. For
instance, the encryption symbol has three arguments, includ-
ing the plaintext, the key and the random seed.

• If g ∈ G, [[g]](d1, . . . , dn) is the machine such that, on input

w and extra tapes ρ1, ρ2,

[[g]](d1, . . . , dn)(w; ρ1; ρ2) :=
Ag(d1(w; ρ1; ρ2), . . . , dn(w; ρ1; ρ2); ρ2)

Note that the machine Ag cannot use directly the tape ρ1
(only through d1, . . . , dn). Intuitively, the interpretation of
function symbols in G is chosen by the attacker: they cannot
use directly the (supposedly) secret values but may use ex-
tra random choices from ρ2. Note, Ag1 and Ag2 for some
g1 and g2 may use the same random values (that is, the ad-
versary is allowed to reuse the same random input). In what
follows, the interpretation of gi ∈ G computes the attacker’s
i’th input (the attacker is active) when applied on the previ-
ous outputs (the attacker is adaptive).

• For all computational models, we require ﬁxed interpreta-

tions of the following function symbols:

– [[true]] the random variable whose value is 1 on all inputs.

Note, [[true]] is in Db.

– [[false]] is the random variable whose value is 0 on all in-

puts. Note, [[false]] is in Db.

– if _ then _ else _ is interpreted as a function

[[if _ then _ else _ ]] : Db × Dm × Dm → Dm

such that on the triple (d, d1, d2) ∈ Db × Dm × Dm, it
gives the random variable
[[if _ then _ else _ ]](d, d1, d2) with

[[if _ then _ else _ ]](d, d1, d2)(w; ρ1; ρ2)

(cid:26) d1(w; ρ1; ρ2) if d(w; ρ1; ρ2) = 1

:=

d2(w; ρ1; ρ2) if d(w; ρ1; ρ2) = 0

– EQ is interpreted as the function

[[EQ]] : Dm × Dm → Db

such that [[EQ]](d1, d2) is the random variable for which

[[EQ]](d1, d2)(w; ρ1; ρ2)

(cid:26) 1 if d1(w; ρ1; ρ2) = d2(w; ρ1; ρ2)

0 if d1(w; ρ1; ρ2) (cid:54)= d2(w; ρ1; ρ2)

:=

– Finally, EQL is interpreted as the function [[EQL]] : Dm ×
Dm → Db such that [[EQL]](d1, d2) is the random variable
for which [[EQL]](d1, d2)(w; ρ1; ρ2) := 1 if the lengths
(as bit strings) of d1(w; ρ1; ρ2) and of d2(w; ρ1; ρ2) are
equal, and [[EQL]](d1, d2)(w; ρ1; ρ2) := 0 if the lengths
of d1(w; ρ1; ρ2) and of d2(w; ρ1; ρ2) are different.

3. A name n ∈ N is interpreted as the machine [[n]] = An that,
given a word of length η, extracts a word of length η from ρ1.
Different names should extract disjoint parts of ρ1. This machine
does not use ρ2.
This way, all names are drawn uniformly at random from {0, 1}η;
other PTIME computable distribution can be represented using ad-
ditional function symbols, if necessary.

6134. Given a term t, an assignment σ of the free variables of t, taking
values in the corresponding domains Ds, a security parameter η
and a sample ρ (ρ is a pair ρ1; ρ2), [[t]]σ
η,ρ is deﬁned recursively as:

• for a variable x, [[x]]σ

η,ρ := (xσ)(1η; ρ) (the value of the
random variable xσ on 1η; ρ or the output of the machine
interpreting x, with the random tapes ρ on the input 1η),

• for a name n, [[n]]σ

η,ρ is the output of the machine An on 1η

with tape ρ (which is sometimes written ρ(n)),

• for a function symbol f ∈ F,

[[f (t1, . . . , tn)]]σ

η,ρ := [[f ]]([[t1]]σ

η,ρ, . . . , [[tn]]σ

η,ρ).

• for a function symbol g ∈ G,

[[g(t1, . . . , tn)]]σ

η,ρ := [[g]]([[t1]]σ

η,ρ, . . . , [[tn]]σ

η,ρ, ρ2).

5. The indistinguishability predicate ∼ is interpreted as computa-
tional indistinguishability ≈ of sequences of elements in D of the
same length. That is: d1, . . . , dn ≈ d(cid:48)
n iff for any deter-
ministic polynomial time Turing machine A,

1, . . . , d(cid:48)

|Prob{ρ : A(d1(1η; ρ), . . . , dn(1η; ρ); ρ2) = 1}−
Prob{ρ : A(d
n(1η; ρ); ρ2) = 1}|
(cid:48)

(cid:48)
1(1η; ρ), . . . , d

In particular, given an assignment σ of free
is negligible in η.
variables in Ds, and an interpretation [[·]] of the function symbols
as above, ∼ is interpreted as the relation ≈ between sequences
of the same length, which is deﬁned as follows: [[t1, . . . , tn]] ≈
[[u1, . . . , un]] iff for any deterministic polynomial time Turing ma-
chine A

|Prob{ρ : A([[t1]]σ
Prob{ρ : A([[u1]]σ

η,ρ, . . . , [[tn]]σ
η,ρ, . . . , [[un]]σ

η,ρ; ρ2) = 1}−
η,ρ; ρ2) = 1}|

is negligible in η.3 We write Mc, σ |= t1 . . . tn ∼ u1 . . . un in this
case, and say that Mc, σ satisﬁes t1 . . . tn ∼ u1 . . . un. Satisfac-
tion of compound formulas is deﬁned from satisfaction of atomic
formulas as usual in ﬁrst-order logic. We write Mc, σ |= θ if
Mc, σ satisﬁes the ﬁrst-order formula θ in the above sense. If (cid:126)x is
the list of free variables in θ, then Mc |= θ stands for Mc |= ∀(cid:126)xθ.
A formula is computationally valid if it is satisﬁed in all computa-
tional models.

REMARK 1. Equality (up to negligible probability) between x
and y can be expressed in the computational model by a formula
EQ(x, y) ∼ true.
2

EXAMPLE 8. If n, n(cid:48) are two names, then n ∼ n(cid:48) is compu-
tationally valid. We will see also in Section 7 other examples of
computationally valid formulas.

On the other hand, the following formula is not computationally

valid:

x ∼ z ∧ y ∼ z → if b then x else y ∼ z

Consider the random variables b1, b2 that are drawn uniformly
from {0, 1}. Then if b1 then b1 else b2 equals 0 with probability 1
4 . It is therefore not indistinguishable from
and 1 with probability 3
b2, while b1 ∼ b2 and b2 ∼ b2.

4

2

3This difference is called advantage of A.

4. PROTOCOLS

We choose to treat protocols as abstract transition systems. We
do not commit to any particular way to specify protocols. They
could be speciﬁed for instance in the applied pi-calculus [1] or any
other process calculus. As mentioned in the Introduction, we as-
sume here a bounded number of sessions: each protocol comes
with an arbitrary but ﬁxed bound on the number of steps in its ex-
ecution. We could of course deﬁne the protocols and their various
semantics without such a bound, but we chose to keep it simple:
anyway, our soundness result (just as that of [6]) holds only for
computational adversaries that exploit bounded number of sessions
in the security parameter.
4.1 The transition system

A protocol is a transition system deﬁned by
• A ﬁnite set of states Q together with an ordering >, a distin-

guished initial state q0 and a set Qf ⊆ Q of ﬁnal states.

• For each state q ∈ Q, a linearly ordered (ﬁnite) set T (q) of

transition rules

q,{x1, . . . , xn} θ−→ (q

(cid:48)

, s,{x1, . . . , xn, x})

where

– x1, . . . , xn, x are variables.
– θ is a term of sort bool with variables in x1, . . . , xn, x
– q, q(cid:48) ∈ Q are such that q > q(cid:48).
– s is a term with variables in x1, . . . , xn, x.

T (q) is empty if and only if q ∈ Qf . Otherwise, T (q) con-
tains a maximal transition, whose guard θ is true.

• An initial knowledge φ0
Intuitively, the ordering on states ensures the termination and the
ordering on transitions speciﬁes in which order the guards θ have
to be tried. The ordering on transitions will therefore exclude pro-
tocols that use non-deterministic choices. We also chose to assume
a maximal transition whose guard is true. This is always possi-
ble without loss of generality; it amounts to state explicitly what
happens when none of the guards is satisﬁed.

EXAMPLE 9. Consider the following modiﬁcation of the pro-

tocol in Example 4:

1. a(cid:48) → b: {pka(cid:48) , n0}r0
pkb
2. b
b

−−−−−−−→ a(cid:48): {n0, n}r
if pka=pka(cid:48)
pka
if pka(cid:54)=pka(cid:48)
−−−−−−−→ a(cid:48): {n, n}r
pka

This protocol can be speciﬁed in the applied π-calculus by the two
processes

A(a(cid:48), b) = νn0, r0.out({(cid:104)pka(cid:48) , n0(cid:105)}r0
pkb

)

in(x). let y = π1(dec(x, ska(cid:48) )) in
if EQ(y, n0) then OK

B(a, b) = νn, r.in(x(cid:48)). let y(cid:48) = dec(x(cid:48), skb) in

if EQ(π1(y(cid:48)), pka) then out({(cid:104)π2(y(cid:48)), n(cid:105)}r
pka
else out({(cid:104)n, n(cid:105)}r
pka

).

)

OK is an event that can be used for authentication properties, but
that will be ignored in the present paper, in which we only consider
the privacy property.

614One session of this protocol can then be described using the ini-

4.3 Computational execution

tial knowledge

(cid:48)
φ0 = a, b, a

, pka, pkb, pka(cid:48) ,{(cid:104)pka(cid:48) , n(cid:105)}r
pkb

.

and the following transition system

t1: q0

EQ(π1(dec(x(cid:48),skb)),pka)
−−−−−−−−−−−−−−→ q1,{(cid:104)π2(dec(x(cid:48), skb)), n(cid:48)(cid:105)}r(cid:48)
pka
true−−→ q2,{(cid:104)n(cid:48), n(cid:48)(cid:105)}r(cid:48)
pka
in which q0 > q1 and t1 > t2.

t2: q0

), x(cid:48)

, x(cid:48)

true−−→ {pka(cid:48) , n0}r0
pkb

In the full description of one session of the protocol we should
and do not include this
add a ﬁrst step, q−1
message in the initial knowledge of the attacker. We chose the
above version, in order to keep the protocol short in some of the
next examples.
2
Given a protocol P , we associate with each n ∈ N a function
symbol gn ∈ G, whose arity is n +|φ0|: intuitively such a function
symbol will account for the attacker’s actions and take as arguments
the initial knowledge of the attacker, as well as the n ﬁrst outputs
of the protocol and return a message that will be given as the next
input to the protocol.
4.2 Execution and indistinguishability

in a model M

Given a ﬁrst-order structure M, in which all function symbols of
F,G are interpreted, we let [[t]]σM be the interpretation of t in M,
given the assignment σ of the free variables of t in the domain of
M. Since we only consider a ﬁnite set of states, we assume w.l.o.g.
that all honestly generated names are generated at once, before the
protocol starts.

An execution of the protocol in M is a sequence
(q0, σ0, φ0) → ··· → (qn, σn, φn)

such that σ0 is empty and, for every i < n, there is a transition
qi,{x1, . . . , xi} θi−→ (qi+1, si+1,{x1, . . . , xi, xi+1})

ti :

such that:

• σi+1 = σi (cid:93) {xi+1 (cid:55)→ gi(φi)} and [[θi]]σi+1M = [[true]]M.
• [[θ]]σi+1M (cid:54)= [[true]]M for every t: qi,{x1, . . . , xn} θ−→ . . .

transition with t < ti.
• φi+1 ≡ φi, si+1σi+1.
and the state qn is a ﬁnal state.

Note that for any protocol P and any ﬁrst order structure M
there is one and only one execution of the protocol P in M. Intu-
itively, this follows from the fact that M determines in particular
the attacker’s actions, hence the assignments σi. Note also that the
number of elements in Q bounds the number of execution steps.
If M also interprets predicate symbol ∼, then we can have the

following deﬁnition.

DEFINITION 1. Given M, two protocols P and P (cid:48) are equiv-
alent in M, which we write P ∼M P (cid:48) if the two executions of P
and P (cid:48) in M respectively have the same length and yield respec-
tively (qn, σn, φn) and (q(cid:48)
n, σ(cid:48)
n are both ﬁnal
in M and M |= φn ∼ φ(cid:48)
n.

n) such that qn, q(cid:48)

n, φ(cid:48)

DEFINITION 2. Given a set of axioms A, two protocols P, P (cid:48)
are symbolically equivalent if for every model M satisfying A,
P ∼M P (cid:48).

(cid:27) A

− an attacker B

A computational trace of a protocol P is determined by:
• − an interpretation of symbols in F
• a security parameter η
• random tapes ρ = ρ1; ρ2
Informally, the attacker will implement both the function sym-
bols in G, i.e., the functions gi at each step of the protocol, and the
distinguisher between the ﬁnal frames.
Given P,B, η, ρ and the interpretation of the symbols of F in

model Mc

computational

Dm, a computational trace is a sequence:

(q0, σ0, φ0) → ··· → (qn, σn, φn)

such that,

• for every i < n, there is a transition

ti :

qi,{x1, . . . , xi} θi−→ (qi+1, si+1,{x1, . . . , xi, xi+1})

such that:
– σi+1 = σi (cid:93) {xi+1 (cid:55)→ B([[φi]]ρ,η; ρ2)} and [[θi]]σi+1
– [[θ]]σi+1
ρ,η

ρ,η = 1
(cid:54)= 1 for every t : qi,{x1, . . . , xi} θ−→ ··· transi-

tion with t < ti

– φi+1 = φi, [[si+1]]σi+1
ρ,η .

• qn is a ﬁnal state

We write Φ(P,B, η, ρ) for the ﬁnal frame φn in such a trace.
A computational trace can be seen as a particular case of execu-
tion in a model of Section 4.2, as (Mc, η, ρ) is a ﬁrst-order model
interpreting the function symbols, but not ∼.4
A computational execution of protocol P is deﬁned by an inter-
pretation of F and an attacker B and consists of all computational
traces for all values of the security parameter and the random tapes
as the input (1η; ρ) runs through all possible values.
The attacker B determines an interpretation of the function sym-
bols in G, which is the computation of B in each round. Hence we
obtain a model Mc.

We state now what it means for a PPT machine to distinguish

two protocols:

DEFINITION 3. Given two protocols P and P (cid:48), an interpreta-
tion of the function symbols in F, and an attacker B (which, alto-
gether, deﬁnes a computational model Mc), B distinguishes P and
P (cid:48) if:

Prob{ρ : B(Φ(P,B, η, ρ); ρ2) = 1}−
Prob{ρ : B(Φ(P
,B, η, ρ); ρ2) = 1}

(cid:48)

is non-negligible in η.
We also say that P and P (cid:48) are distinguishable in the model Mc.

We obtain again the usual notion of computational indistinguisha-
bility of protocols, letting Mc vary, for a ﬁxed interpretation of F:
given an interpretation I of the symbols in F, two protocols P and
P (cid:48) are computationally indistinguishable if they are indistinguish-
able in any computational model Mc extending I, that is, if for any
PPT machine B, B does not distinguish P and P (cid:48).
4Note that [[t]]σMc (with the notation of Section 4.2) and [[t]]σ
η,ρ are
not the same because Mc does not ﬁx η and ρ. We omitted Mc
from [[t]]σ

η,ρ for simplicity, but in fact [[t]]σ

η,ρ = [[t]]σMc (1η; ρ).

615has only one transition q0

EQ(b,0)−−−−→ q1, 1 · n, x and t2 : q0

EXAMPLE 10. Let us come back to Example 2. The protocol P
true−−→ q1, n(cid:48), x. The protocol P (cid:48) has two
true−−→ q2, 0 · n, x
transitions t1 : q0
with t1 > t2. Assume we interpret 0, 1 as 0, 1 and · as the con-
catenation. If [[n]]ρ = w and [[b]]ρ = 1, then the computational
execution of P (cid:48) in the model deﬁned by an attacker B and the sam-
ple ρ is (q0,∅,∅) → (q2, σ, 0w), where σ is the attacker’s input,
which is, here, irrelevant. The other execution (when [[b]]ρ = 0)
yields (q1, σ, 1w).

The two processes are computationally indistinguishable: indis-
tinguishability is deﬁned as a global property (for all samples ρ),
and the distributions of the outputs for P and P (cid:48) are identical. 2

5. FOLDING THE PROTOCOLS

We claim that it may be assumed w.l.o.g. that, for any control
state q, there is at most one transition departing from q. From any
protocol P , we construct a protocol fold(P ) that satisﬁes this prop-
erty, and which is computationally equivalent to P . They are also
equivalent with respect to any model M in which bool is inter-
preted as a two element set.
Informally, if we see P as a tree,
whose nodes are labeled with the sates and the output terms, and
edges are labeled with the conditions, then in fold(P ) all states oc-
curring at the same depth d are gathered together and there is a case
distinction in the output term: for every path of depth d, the term
gathers together the conditions along this path and at the end of the
conditions contains (as a subterm) the term labeling the target of
this path.

EXAMPLE 11. Let P be deﬁned by the transition rules

t1
0 : q0

θ2

0−→ q2

1, s2

1, x1,

t1
1 : q1

1, x1

θ2

1−→ q2, s2

2, x1, x2,

t0
0 : q0

t2
0 : q0

t0
1 : q1

1, x1

t2
1 : q1

1, x1

θ1

θ1

1, s1

0−→ q1
1, x1,
true−−→ q2, 0, x1,
1−→ q2, s1
2, x1, x2,
true−−→ q2, 0, x1, x2,
1−→ q2, s3

θ3

1, x1

t0
2 : q2
1, x1
The ordering on the transition is given by tj

2, x1, x2,

t1
2 : q2

true−−→ q2, s4

2, x1, x2.

i > tk

i if j < k.

Then fold(P ) contains two transition rules:

{q0}
1}
1, q2

{q1

1 else (if θ2

0 then s2

1 else 0 ) ,

0 then s1
1}, x1
1, q2

true−−→ if θ1
{q1
true−−→ if θ1

0

then if θ1
1

then s1
2
else ( if θ2

1 then s2

2 else 0 )

else if θ2
0

1 then s3

2 else 0 )

then ( if θ3
else s4
2 ,
{q2}, x1, x2

Formally, fold(P ) is constructed as follows. If T is a sequence
of transition rules, we deﬁne fold(T ) by induction on the number
of transition rules in T :

• If T is empty, then fold(T ) := 0

2

• If T is has one rule, i.e. T is of the form q, (cid:126)x

then fold(T ) := q(cid:48), s(cid:48)

true−−→ q(cid:48), s(cid:48), (cid:126)x(cid:48),

• If T = {q, (cid:126)x θ−→ q(cid:48), s(cid:48), (cid:126)x(cid:48)} · T (cid:48), then

fold(T ) := if θ then q

(cid:48)

(cid:48) else fold(T

(cid:48)

)

, s

We let Q0 := {q0} and e0 := q0, s0, where s0 := φ0. For ev-
ery i, We deﬁne inductively ei+1 as the expression that we obtain
from ei by replacing every pair of the form q, s occurring in ei with
fold(T (q)), where T (q) is the sequence of transition rules depart-
ing from q, in decreasing order.

The protocol P0 has an initial state Q0, the states are the sets Qi
of state symbols appearing in the expressions ei, the transitions are

Qi,{x1, . . . , xi} (cid:62)−→ Qi+1, si+1,{x1, . . . , xi, x}

where si is the term obtained by removing the states from the ex-
pression ei.

Given a protocol P , we let Φ(fold(P )) be the sequence of terms
s0, s1, . . . , sn. Note that this sequence may contain variables and
also includes the control structure of the protocol.

Note that sequences of transitions of P need not to have all the
same length: fold(T (q)) = 0 when there is no transition departing
from q and fold(P ) has only one sequence of transitions, whose
length equals the length of the longest transition sequence in P .

If-then-else basic axioms
∀x, y, z1, z2. z1, if true then x else y , z2 ∼ z1, x, z2
∀x, y, z1, z2. z1, if false then x else y , z2 ∼ z1, y, z2

Figure 1: Basic axioms

PROPOSITION 1. If M is a model satisfying the axioms of the
Figure 1 and in which the sort bool is interpreted as a two element
set {[[true]]M, [[false]]M}, then P ∼M fold(P ) for any protocol P .
Moreover, P and fold(P ) are computationally indistinguishable.

The proof is straightforward. Note that we need an assumption on
the interpretation of bool: if some condition θ is neither evaluated
to true, nor to false, then we have some freedom in the evaluation
of “if θ then s else t ” (hence in the results of fold(P )), while
the deﬁnition of an execution of P will always behave as if the
condition were false.

6. COMPUTATIONAL SOUNDNESS

The following result can be seen as an unconditional soundness
theorem: to prove the computational indistinguishability of two (ﬁ-
nite) protocols, it is sufﬁcient to check the (symbolic) inconsistency
of a set of formulas. Conversely, the consistency of the set of for-
mulas implies the existence of a model, which means that there is
an attack (for some interpretation of the function symbols).

THEOREM 1. Assume that P, P (cid:48) are two protocols. Let A be
any set of formulas (axioms). If A and Φ(fold(P )) (cid:54)∼ Φ(fold(P (cid:48)))
are inconsistent, then the protocols P and P (cid:48) are computation-
ally indistinguishable in any computational model Mc for which
Mc |= A.

PROOF. Suppose P and P (cid:48) are distinguishable, that is, there is
a model Mc with Mc |= A and a computational algorithm that

616distinguishes the two protocols. We have to construct an abstract
model M, for which M |= A ∧ Φ(fold(P )) (cid:54)∼ Φ(fold(P (cid:48))). As
noted earlier, we can assume without loss of generality that each
computational trace has equal length. Let n denote this number.
Since, in the folded protocol, the output terms are independent
of the random inputs (but the corresponding bit strings depend of
course on this input), for each i ∈ [1, . . . , n], we let ti and t(cid:48)
i be
i]] ∈ D give the elements in the
the output terms such that [[ti]], [[t(cid:48)
computational domain that correspond to the i’th message in the
corresponding protocol execution. ti and t(cid:48)
i are exactly the terms
occurring in Φ(fold(P )) and Φ(fold(P (cid:48))) respectively.
We deﬁne the domain of the model M simply to be the domain
of the computational interpretation. The function symbols in F are
interpreted in M exactly as in Mc.
The free function symbols in G denote the attacker’s computation
of its messages from the previous outputs of the agents. That is, the
attacker’s inputs are g1(t1), g2(t1, t2), g2(t1, t2, t3) etc. for proto-
col P , and g1(t(cid:48)
3) for P (cid:48); as it is the same
attacker on the two sides, so the free symbols are the same. For
i ≥ n, the interpretation of gi is irrelevant. For i < n, gi is given
by the attacker; in the speciﬁcation of the protocol attacker, there
must be a subroutine that takes as input the ﬁrst i outputs of the
protocol agents, and outputs some message to be sent to a protocol
agent again. This subroutine is the interpretation of gi. The pred-
icate ∼ is interpreted as ≈ deﬁned in section 3.2. M |= A since
Mc |= A. Finally, M |= Φ(fold(P )) (cid:54)∼ Φ(fold(P (cid:48))) also holds,
as the protocol adversary taking the last outputs of the protocol
agents distinguishes the two protocols, meaning [[Φ(fold(P ))]] (cid:54)≈
[[Φ(fold(P (cid:48)))]]. Hence M |= Φ(fold(P )) (cid:54)∼ Φ(fold(P (cid:48))).

2), g2(t(cid:48)

1), g2(t(cid:48)

1, t(cid:48)

1, t(cid:48)

2, t(cid:48)

7. AXIOMS

In this section we list some axioms that we prove to be compu-
tationally sound (some of them under some cryptographic assump-
tions) and that are sufﬁcient for the analysis of the private authen-
tication protocol in the next section.

As we will see, the ﬁrst axiom in Figure 2 is sound because func-
tion symbols are always interpreted as polynomial time algorithms.
Axioms Refl, Sym, Trans, Restr, If1, Eq1 are always com-
putationally sound.
Axiom EncCCA1 is sound as long as the encryption symbol
{_}_
_ is interpreted as and IND-CCA1 encryption [12], and axiom
EncKP is sound as long as the encryption satisﬁes key privacy [11].
Axioms EncCCA1 and EncKP are actually axiom schemes: the
symbols: r, u, u(cid:48), u(cid:48)(cid:48), a... represent any terms, (cid:126)v is any ﬁnite se-
quence of terms. They are guarded by constraints, that we explain
below. An axiom scheme is more precisely of the form

γ (cid:107) θ((cid:126)v)

where γ is a constraint and (cid:126)v are the logical variables of θ, and it
denotes the set of all instances θ((cid:126)v)σ where σ assigns closed terms
to the logical variables, and σ |= γ. Such a scheme is a recursive
set of formulas as long as the constraints are recursive (which is the
case in our examples).

fresh((cid:126)n, (cid:126)v) is satisﬁed by a substitution σ if any element of (cid:126)n
is mapped to a name by σ and none of these names appears in
(cid:126)vσ. An assignment σ satisﬁes the constraint (cid:126)sk (cid:54)(cid:118)d (cid:126)v if secret
keys in (cid:126)skσ only occur in (cid:126)vσ in decryption key position. Finally,
σ |= nodec( (cid:126)sk; (cid:126)v) if the vector of terms (cid:126)vσ does not contain any
decryption with any of the keys in the vector of secret keys (cid:126)skσ.

In the axioms below, b, w, x, y, z, x1, . . . , xn, . . . are vari-
ables, that are all implicitly universally quantiﬁed. b has sort
bool, while the other variables have arbitrary sorts, provided
the terms displayed in the axioms are well-typed.
• Indcong:

: messagen → message
x1, ..., xn ∼ y1, ..., yn −→ f (x1, ..., xn) ∼ f (y1, ..., yn)

for any f

(cid:126)x ∼ (cid:126)x
(cid:126)x ∼ (cid:126)y −→ (cid:126)y ∼ (cid:126)x

(cid:126)x ∼ (cid:126)y ∧ (cid:126)y ∼ (cid:126)z −→ (cid:126)x ∼ (cid:126)z

• Refl:
• Sym:
• Trans:
• Restr:

• If1:

If p projects and permutes onto a sublist, then

(cid:126)x ∼ (cid:126)y −→ p((cid:126)x) ∼ p((cid:126)y).

b, (cid:126)w, x ∼ b, (cid:126)w, z ∧ b, (cid:126)w, y ∼ b, (cid:126)w, z −→

(cid:126)w, if b then x else y ∼ (cid:126)w, z

(cid:126)w, EQ(x, x) ∼ (cid:126)w, true

• Eq1:
• EncCCA1 (computationally sound for
if

IND-CCA1 en-
cryptions):
the constraints
fresh(r, r(cid:48); (cid:126)v, u, u(cid:48), u(cid:48)(cid:48), pka, ska) and ska (cid:54)(cid:118)d (cid:126)v, u, u(cid:48), u(cid:48)(cid:48)
hold, then

For r, r(cid:48); (cid:126)v, u, u(cid:48), u(cid:48)(cid:48), a,

(cid:126)v, if EQL(u, u(cid:48)) then {u}r
pka
(cid:126)v, if EQL(u, u(cid:48)) then {u(cid:48)}r(cid:48)
pka

∼

else u(cid:48)(cid:48)

else u(cid:48)(cid:48)

• EncKP (Computationally sound for encryptions
if
fresh(r, r(cid:48); (cid:126)v, u, pka, ska, pka(cid:48) , ska(cid:48) )

isfying Key Privacy):
constraints
nodec(ska, ska(cid:48) ; (cid:126)v, u) and ska, ska(cid:48) (cid:54)(cid:118)d (cid:126)v, u hold, then

For r, r(cid:48); (cid:126)v, u, a, a(cid:48),

sat-
the
and

(cid:126)v,{u}r
pka

∼ (cid:126)v,{u}r(cid:48)
pka(cid:48)

Figure 2: Some axioms

PROPOSITION 2. The axioms Indcong, Refl, Sym, Trans,

Restr, If1, Eq1 are computationally sound.

PROOF. For Indcong: if σ is an assignment of the variables
such that a machine A breaks the indistinguishability f (t1, . . . , tn)
∼ f (u1, . . . , un), then we consider a machine B, which, on inputs
m1, . . . , mn, ﬁrst computes [[f ]](m1, . . . , m) and then runs A on
the result. B is still polynomial time, because we assumed that the
computational interpretation of function symbols are polynomial
time computable. The advantage of B is the same as the advantage
of A.

Axiom Refl is obvious: Something cannot be distinguished

from itself.

Axiom Sym is a consequence of the symmetry of the arguments

in the computational deﬁnition of indistinguishability.
Axiom Trans is a consequence of the triangle inequality: if the
advantage of an attacker in breaking x ∼ z is larger than p, the
very same attacker breaks either x ∼ y or y ∼ z with advantage at
2 .
least p

Axiom Restr is proved the same way as axiom Indcong.
For If1, consider the following. Assume that σ is an assign-
ment of (cid:126)w, b, x, y, z to random variables and let A be an attacker

617machine. Let

p1 = Prob{ρ : A([[ (cid:126)w, if b then x else y ]]σ
p2 = Prob{ρ : A([[ (cid:126)w, z]]σ
1,1 = Prob{ρ : A([[ (cid:126)w, x]]σ
px
1,2 = Prob{ρ : A([[ (cid:126)w, y]]σ
py

ρ,η; ρ2) = 1},
ρ,η; ρ2) = 1 & [[b]]σ
ρ,η; ρ2) = 1 & [[b]]σ

ρ,η; ρ2) = 1},
ρ,η = 1},
ρ,η = 0}.

1

ρ,η, [[ (cid:126)w, z]]σ

1,1 + pz

1,2.

1,1 +py

ρ,η, [[ (cid:126)w, x]]σ

1,1 and Prob{ρ : B1([[b]]σ

By deﬁnition of the semantics of if_then_else_, p1 = px
1,2.
On the other hand, p2 = pz
Let B1 (resp. B2) be the machine that, on input m1, m2 (and ran-
dom tape ρ2) returns A(m2; ρ2) when m1 = 1 (resp. m1 = 0) and
ﬂips a coin (use ρ2) returning either 0 or 1 with equal probability,
if m1 (cid:54)= 1 (resp. m1 (cid:54)= 0). Prob{ρ : B1([[b]]σ
ρ,η; ρ2) =
ρ,η; ρ2) = 1} =
1} = 1
4 + px
1,1. Hence B1 distinguishes b, (cid:126)w, x from b, (cid:126)w, z with prob-
4 + pz
ability at least |px
1,1|. Similarly, the machine B2 distin-
guishes b, y from b, z with probability at least |py
1,2| Since
|p1−p2| ≤ |px
1,2|, one of the machines Bi suc-
ceeds in distinguishing the two pairs of messages with advantage at
2|p1 − p2|: if an attacker can distinguish (cid:126)w, if b then x else y
least 1
from (cid:126)w, z with an advantage , then either there is a machine that
distinguishes b, (cid:126)w, x from b, (cid:126)w, z with an advantage at least 
2 or
there is a machine that distinguishes b, (cid:126)w, y from b, (cid:126)w, z with an
advantage at least 
2 .

1,1 − pz

1,1|+|py

1,2 − pz

The soundness of Eq1 is immediate from the computational in-

1,1−pz

1,2−pz

terpretation of EQ.

We do not deﬁne IND-CCA1 security here as it is a very standard
notion. The precise deﬁnition can be found for example in [12].
The idea is, the following: An oracle generates a random bit and
a secret key–public key pair, and publishes the public key. Based
on this public key, a PPT attacker algorithm submits two messages
of its choice to the oracle, and the oracle encrypts one based on
its internal bit. Before doing that though, the attacker algorithm is
allowed to request decryptions from the oracle with the secret key,
but not after. Then, when received the encryption from the oracle,
the attacker has to compute a bit. If the oracle’s internal bit and the
bit computed by the PPT attacker agree with a probability that is
never non-negligibly better than 1/2 for any such attacker, then the
encryption is IND-CCA1 secure. The absolute value of difference
between the probability that the algorithm computes the correct bit
and 1/2 is called the advantage of the attacker.

PROPOSITION 3. The axiom EncCCA1 is computationally sound

if the encryption scheme is IND-CCA1 secure.

PROOF. The proof goes as usual in the literature concerning
computational soundness. Let t ≡ ifEQL(u, u(cid:48))then{u}r
elseu(cid:48)(cid:48)
pka
and let t(cid:48) ≡ if EQL(u, u(cid:48)) then {u(cid:48)}r(cid:48)
else u(cid:48)(cid:48) . Assume that
pka
there is an instance of the axiom scheme (a substitution that satis-
ﬁes the constraints), and a computational interpretation, in which
(cid:126)v, t (cid:54)∼ (cid:126)v, t(cid:48) is satisﬁed. From this, we construct an algorithm win-
ning the IND-CCA1 game against the encryption with pka. (Note
that (cid:126)v, u, u(cid:48) were assumed to be closed, so we do not need σ.)
According to our computational semantics in Section 3.2, (cid:126)v, t (cid:54)∼
(cid:126)v, t(cid:48) is satisﬁed in the computational interpretation means that there
is a polynomial time Turing machine A such that

|Prob{ρ = (ρ1, ρ2) : A([[(cid:126)v]]η,ρ, [[t]]η,ρ; ρ2) = 1}−
Prob{ρ = (ρ1, ρ2) : A([[(cid:126)v]]η,ρ, [[t
]]η,ρ; ρ2) = 1}|

(cid:48)

(1)

is not negligible in η.
Then an algorithm B that wins the IND-CCA1 game against pka
can be constructed: B is given [[pk(k)]]ρ,η, as well as all interpre-
tations of names, except k. (More precisely, B can draw himself

]]η,ρ or [[{u(cid:48)}r(cid:48)
pka

these names). Then B computes [[(cid:126)v]]ρ, [[u]]ρ, [[u(cid:48)]]ρ, [[u(cid:48)(cid:48)]]ρ: as (cid:126)v,
u, u(cid:48), u(cid:48)(cid:48) contain ska in the position of a decryption key only, B
can perform these computations by requesting the decryption ora-
cle when necessary. Then, whenever [[u]]η,ρ, [[u(cid:48)]]η,ρ have the same
length, B submits them to the encryption oracle, which returns ei-
ther [[{u}r
]]η,ρ depending on the oracle’s internal
pka
random bit. Note that the oracle generates fresh r or r(cid:48), the ad-
versary does not have control over that. Therefore we needed the
freshness constraint in the axiom. Let c(η, ρ) denote whatever the
oracle returns. Then B runs A as a subroutine on (cid:126)v, c(η, ρ) if the
lengths of [[u]]η,ρ, [[u(cid:48)]]η,ρ are the same, and, if different, then B
runs A on [[(cid:126)v]]η,ρ, [[u(cid:48)(cid:48)]]η,ρ. Finally, B outputs whatever A returns
as the guess of the oracles internal bit.
Let b denote the oracle’s internal bit. B wins when either the or-
acle’s internal bit is 0 (encrypting [[u]]η,ρ) and A returns 0, or when
the oracle’s internal bit is 1 (encrypting [[u(cid:48)]]η,ρ) and A returns 1.
Hence, the advantage of B is only negligibly different from

|Prob{A([[(cid:126)v]]η,ρ, [[t]]η,ρ; ρ2) = 0 ∧ b = 0}
+ Prob{A([[(cid:126)v]]η,ρ, [[t

]]η,ρ; ρ2) = 1 ∧ b = 1} − 1/2|

(cid:48)

As the probability of b = 1 and b = 0 are both 1/2, with condi-
tional probabilities, the above equals
|Prob{A([[(cid:126)v]]η,ρ, [[t]]η,ρ; ρ2) = 0 | b = 0} · 1/2
+ Prob{A([[(cid:126)v]]η,ρ, [[t

]]η,ρ; ρ2) = 1 | b = 1} · 1/2 − 1/2|.

(cid:48)

However, substituting

Prob{A([[(cid:126)v]]η,ρ, [[t]]η,ρ; ρ2) = 0 | b = 0} =
1 − Prob{A([[(cid:126)v]]η,ρ, [[t]]η,ρ; ρ2) = 1 | b = 0},

we obtain

|Prob{A([[(cid:126)v]]η,ρ, [[t]]η,ρ; ρ2) = 1 | b = 0} · 1/2−
Prob{A([[(cid:126)v]]η,ρ, [[t
]]η,ρ; ρ2) = 1 | b = 1} · 1/2|.

(cid:48)

This in turn is (as the choice of b and of the other names as well as
the algorithm A are independent)

|Prob{A([[(cid:126)v]]η,ρ, [[t]]η,ρ; ρ2) = 1} · 1/2−
Prob{A([[(cid:126)v]]η,ρ, [[t
]]η,ρ; ρ2) = 1} · 1/2|,

(cid:48)

which is just the half of expression (1), which was assumed to be
non-negligible. Therefore, the IND-CCA1 attacker B wins with
non-negligible probability.

Note that we did not need to call the decryption oracle after the

encryption oracle: we do not need IND-CCA2 for this axiom.

In order to be able to verify our example protocol, we also need
the encryption to ensure key privacy. For this, we included the last
axiom, which we will see to be sound as long as the encryption
satisﬁes the following notion that appeared in [11].

DEFINITION 4

(KEY PRIVACY). Let us consider a public-key
encryption scheme (that is, computational interpretation of pk, sk,
{}, dec, such that [[dec]]([[{x}r
ρ,η).
This scheme ensures key privacy if, for any PPT B with an oracle,

ρ,η, [[sk(k)]]ρ,η) = [[x]]σ

pk(k)]]σ

Prob{ρ : BOk ([[pk(k)]]ρ,η, [[pk(k
(cid:48)
Prob{ρ : BOk(cid:48) ([[pk(k)]]ρ,η, [[pk(k

)]]ρ,η; ρ2) = 1} −
)]]ρ,η; ρ2) = 1}
(cid:48)

is negligible. Here Ok is the encryption oracle encrypting with
pk(k): Ok(x) = [[{_}_
_]](x, [[pk(k)]], s), where s is a random seed
freshly generated by the oracle.

618In other words, key privacy holds, if no algorithm B can distinguish
if the encryption oracle encrypts with key k or with key k(cid:48).

PROPOSITION 4. The axiom EncKP is computationally sound

if the encryption scheme satisﬁes key-privacy.

PROOF. Assume that there is an instance of the axiom with terms

satisfying the constraints and such that A is a PPT machine and

|Prob{ρ : A([[(cid:126)v]]ρ,η, [[{u}r
pka
−Prob{ρ : A([[(cid:126)v]]ρ,η, [[{u}r(cid:48)

]]ρ,η, ρ2) = 1}
pka(cid:48) ]]ρ,η, ρ2) = 1}|

is non negligible. That is, the axiom is broken by an attacker A.
An attacker B on key privacy can compute by himself the compu-
tational interpretation of (cid:126)v, u and submit [[u]]ρ,η to the encryption
oracle. Then his advantage on the key privacy game is the same as
the advantage of A in distinguishing the two terms.

We note that axiomatizing other notions as CPA security or CCA2
security is not particularly difﬁcult either in this framework. We
chose the above two because those were what we needed for our
example protocol in the next section.

8. EXAMPLE PROTOCOL VERIFICATION
In this section we turn to the protocol designed in [3]. The pro-
tocol was derived from an authentication protocol, which did not
ensure privacy. The authors of [3] modiﬁed that original protocol
adding a “decoy” message, and then claimed that the new protocol
preserved privacy. This is proved symbolically in [3], and also in
[17] using a general (automated) procedure. What we do here is
completely different from the existing procedures; we use a ﬁrst-
order refutation (inconsistency) proof, while in spirit, the symbolic
proofs rely on an induction over the possible attacker’s actions.
Our proof allows to identify that there is a need to check the in-
put length: this yields a new protocol. Thanks to Theorem 1, we
obtain (to our knowledge the ﬁrst) proof of the corrected protocol
in the computational model. Finally, since the inconsistency is de-
rived from the axioms of Figure 2, the privacy of the protocol only
requires the encryption scheme to be IND-CCA1 and to preserve
key-privacy.

The original protocol (in our Example 4), which does not pre-
serve privacy contains two processes, but only one is relevant here
(just like in Example 9, we include the ﬁrst message of A(a(cid:48), b) in
the initialization):
B(a, b) = νnνr.in(x). let y = dec(x, skb) in if π1(y) = pka
then out({(cid:104)π2(y), n(cid:105)}r
pka
That is, if the agent b receives an x that decrypts correctly with his
decryption key to a pair of the public key of agent a and some bit
string, then it returns that bit string encrypted with the public key
of a. Anonymity would mean that B(a, b) ∼ B(a(cid:48), b) that is, it
cannot be decided if agent b is checking for the key of a or the key
of a(cid:48). We will show that B(a, b) (cid:54)∼ B(a(cid:48), b).

.

The corrected version of this protocol is (in Example 9)

B(cid:48)(a, b) = νnνr.in(x).

let y = dec(x, skb) in
if EQ(π1(y), pka)
then out({(cid:104)π2(y), n(cid:105)}r
pka
else out({(cid:104)n, n(cid:105)}r
).
pka

)

That is, here b responds with an encryption even if the test fails.
This much correction is sufﬁcient for proving the equivalence of
B(cid:48)(a, b) and B(cid:48)(a(cid:48), b) in the symbolic (Dolev-Yao) model, but it
is not sufﬁcient to show B(cid:48)(a, b) ∼ B(cid:48)(a(cid:48), b) in our model. What
is missing is a length test (unless the encryption scheme hides the

lengths of the messages); it is easy to construct a computational
attack in case this test is not performed. We consider therefore the
following third version of the protocol:

B(cid:48)(cid:48)(a, b) = νnνr.in(x).let y = dec(x, skb) in
if EQ(π1(y), pka)

then if EQL((cid:104)π2(y), n(cid:105),(cid:104)n, n(cid:105))

then out({(cid:104)π2(y), n(cid:105)}r
pka
else out({(cid:104)n, n(cid:105)}r
)
pka
else out({(cid:104)n, n(cid:105)}r
pka

)

)

The axioms of Section 7 together with B(cid:48)(cid:48)(a, b) (cid:54)∼ B(cid:48)(cid:48)(a(cid:48), b)

and the agent checks yield an inconsistency, as we show below.

Let us consider the symbolic execution of the ﬁrst case (case
of B): For the protocols B(a, b) and B(a(cid:48), b), the ﬁrst published
message is {(cid:104)pka, na(cid:105)}ra
(compared to Example 4, we switched
pkb
here to a from a(cid:48) as it does not matter because of the symmetry
of the problem), besides the public keys. That is, we let φ0 ≡
pka, pka(cid:48) , pkb,{(cid:104)pka, na(cid:105)}ra
. Then, the next message sent by the
pkb
honest agent b is (let h = dec(g(φ0), skb) where g is the attacker’s
computation):

1 ≡ φ0, if EQ(π1(h), pka) then {(cid:104)π2(h), n(cid:105)}r
φ1

pka else 0

in case of B(a, b), and

1 ≡ φ0, if EQ(π1(h), pka(cid:48) ) then {(cid:104)π2(h), n(cid:105)}r
φ1(cid:48)

pka(cid:48) else 0

1 (cid:54)∼ φ1(cid:48)

1 ∼ φ1(cid:48)
in case of B(a(cid:48), b). Anonymity at this point would be φ1
1 ,
so consider its negation φ1
1 . In our symbolic execution, an
attack means that the negation of the security property is consis-
tent with the axioms. We therefore indicate that there is a model
satisfying all of them. The model is deﬁned as: Let bool con-
tain only true and false, and let message contain the public and
secret keys, distinct names for random inputs of the encryption
and n and terms built on them via pairing and encryption. Let
g(φ0) = {(cid:104)pka, na(cid:105)}ra
and EQ(pka, pka(cid:48) ) = false, and we take
pkb
the usual interpretation of ifthenelse and 0 (cid:54)∼ {(cid:104)π2(h), n(cid:105)}r
. In
pka
other words, the attacker just forwards {(cid:104)pka, na(cid:105)}ra
; in this case
pkb
1 = φ0,{(cid:104)π2(h), n(cid:105)}r
,
B(a, b) responds with an encryption, φ1
pka
but for B(a(cid:48), b) the test fails and φ1(cid:48)
1 = φ0, 0. Here, = is the iden-
tity in the model. It is not hard to see that the function symbols can
be deﬁned on all elements of the domain such that the axioms are
satisﬁed.
In the last case (case of B(cid:48)(cid:48)), for simplicity, we don’t display the
full transition system. We have in the symbolic execution again (let
h = dec(g(φ0), skb))

1 ≡ φ0,
φ2

if EQ(π1(h), pka) then if EQL((cid:104)π2(h), n(cid:105),(cid:104)n, n(cid:105))
then{(cid:104)π2(h), n(cid:105)}r
pka
else {(cid:104)n, n(cid:105)}r
pka

else {(cid:104)n, n(cid:105)}r
pka

1 ≡ φ0,
φ2(cid:48)

if EQ(π1(h), pka(cid:48) ) then if EQL((cid:104)π2(h), n(cid:105),(cid:104)n, n(cid:105))
then{(cid:104)π2(h), n(cid:105)}r
else {(cid:104)n, n(cid:105)}r
pka(cid:48)

pka(cid:48) else {(cid:104)n, n(cid:105)}r
pka(cid:48)

1 (cid:54)∼ φ2(cid:48)

1 . From EncCCA1, we have

where φ0 is the same as in Example 9. Negation of the security
property is again φ2
EQ(π1(h), pka),
if EQL((cid:104)π2(h), n(cid:105),(cid:104)n, n(cid:105)) then {(cid:104)π2(h), n(cid:105)}r
pka
∼
EQ(π1(h), pka),
if EQL((cid:104)π2(h), n(cid:105),(cid:104)n, n(cid:105)) then {(cid:104)n, n(cid:105)}r
pka

else {(cid:104)n, n(cid:105)}r
pka

else {(cid:104)n, n(cid:105)}r
pka

619From If1 (and Refl and Restr), we have (with the roles (cid:126)w ≡
EQ(π1(h), pka) and b ≡ EQL((cid:104)π2(h), n(cid:105),(cid:104)n, n(cid:105)) and (cid:126)x ≡ (cid:126)y ≡
(cid:126)z ≡ {(cid:104)n, n(cid:105)}r
pka

):

EQ(π1(h), pka),
if EQL((cid:104)π2(h), n(cid:105),(cid:104)n, n(cid:105)) then {(cid:104)n, n(cid:105)}r
pka
∼ EQ(π1(h), pka),{(cid:104)n, n(cid:105)}r
pka
Hence, by transitivity,
EQ(π1(h), pka),
if EQL((cid:104)π2(h), n(cid:105),(cid:104)n, n(cid:105)) then {(cid:104)π2(h), n(cid:105)}r
pka
∼ EQ(π1(h), pka),{(cid:104)n, n(cid:105)}r
pka
Applying this result on φ2
b ≡ EQ(π1(h), pka) and y ≡ x ≡ {(cid:104)n, n(cid:105)}r
pka
x ≡ if EQL((cid:104)π2(h), n(cid:105), (cid:104)n, n(cid:105)) then{(cid:104)π2(h), n(cid:105)}r
pka

.

1, using If1 (with roles (cid:126)w ≡ φ0 and

and
else{(cid:104)n, n(cid:105)}r
pka

):

else {(cid:104)n, n(cid:105)}r
pka

else {(cid:104)n, n(cid:105)}r
pka

1 ∼ φ0,{(cid:104)n, n(cid:105)}r
φ2
pka

With exactly the same reasoning, we can derive from the axioms:
1 ∼ φ0,{(cid:104)n, n(cid:105)}r
φ2(cid:48)
pka(cid:48) Now, using the axiom EncKP , we get that
1 ∼ φ2(cid:48)
φ2
This proves the security of the protocol in any model that satisﬁes
the axioms, in particular any computational model in which the
encryption scheme is IND-CCA1 and satisﬁes key privacy.

1 , with which φ2

1 is inconsistent.

1 (cid:54)∼ φ2(cid:48)

9. CONCLUSION

We designed a simple procedure for proving computational in-
distinguishability properties of protocols. In contrast with, e.g., the
CIL [9], there is no need for probabilities: we rely simply on ﬁrst-
order logic. It remains to prove its usefulness in practice. There are
however good clues that the inconsistency checks can be imple-
mented efﬁciently. Indeed, the security property is a ground state-
ment (no quantiﬁed variables), once the protocol is folded. Hence
we only have to check the consistency of a (ﬁxed) set of ﬁrst-order
formulas, together with a ground formula. It is likely that this can
be performed in polynomial time, at least for a signiﬁcant set of
axioms (as it was the case for the more complicated situation of
reachability properties [20]).

10. REFERENCES
[1] M. Abadi and C. Fournet. Mobile values, new names, and

secure communication. In POPL’01, pages 104–115. ACM,
2001.

[2] M. Abadi and P. Rogaway. Reconciling two views of
cryptography (the computational soundness of formal
encryption). Journal of Cryptology, 15(2):103–127, 2002.
[3] Martín Abadi and Cédric Fournet. Private authentication.

Theor. Comput. Sci., 322(3):427–476, September 2004.

[4] M. Backes, B. Pﬁtzmann, and M. Waidner. A composable
cryptographic library with nested operations. In CCS’03,
pages 220–230. ACM, 2003.

[5] G. Bana, P. Adão, and H. Sakurada. Computationally
Comlete Symbolic Attacker in Action. In FSTTCS’12,
LIPIcs, pages 546–560. Schloss Dagstuhl, 2012.

[6] G. Bana and H. Comon-Lundh. Towards unconditional

soundness: Computationally complete symbolic attacker. In
POST’12, LNCS, pages 189–208. Springer, 2012.

[7] G. Bana, K. Hasebe, and M. Okada. Computationally

complete symbolic attacker and key exchange. In CCS ’13,
pages 1231–1246. ACM, 2013.

[8] G. Bana, P. Mohassel, and T. Stegers. Computational

soundness of formal indistinguishability and static
equivalence. In ASIAN’06, volume 4435 of LNCS, pages
182–196. Springer, 2007.

[9] G. Barthe, M. Daubignard, B. M. Kapron, and Y. Lakhnech.
Computational indistinguishability logic. In CCS’10, pages
375–386. ACM, 2010.

[10] G. Barthe, B. Grégoire, S. Heraud, and S. Zanella-Béguelin.

Computer-aided security proofs for the working
cryptographer. In CRYPTO 2011, volume 6841 of LNCS,
pages 71–90. Springer, 2011.

[11] M. Bellare, A. Boldyreva, A. Desai, and D. Pointcheval.

Key-privacy in public-key encryption. In ASIACRYPT 2001,
volume 2248 of LNCS, pages 566–582. Springer, 2001.
[12] M. Bellare, A. Desai, D. Pointcheval, and Ph. Rogaway.

Relations among notions of security for public-key
encryption schemes. In CRYPTO’98, LNCS. Springer, 1998.
[13] B. Blanchet. An automatic security protocol veriﬁer based on

resolution theorem proving (invited tutorial). In CADE’05,
Tallinn, Estonia, July 2005.

[14] B. Blanchet. A computationally sound mechanized prover
for security protocols. IEEE Transactions on Dependable
and Secure Computing, 5(4):193–207, 2008.

[15] B. Blanchet, M. Abadi, and C. Fournet. Automated

veriﬁcation of selected equivalences for security protocols. J.
of Logic and Algebraic Programming, 75(1):3–51, 2008.
[16] V. Cheval and B. Blanchet. Proving more observational

equivalences with proverif. In POST’13, Lecture Notes in
Computer Science, pages 226–246. Springer, 2013.

[17] Vincent Cheval, Hubert Comon-Lundh, and Stéphanie

Delaune. Trace equivalence decision: Negative tests and
non-determinism. In CCS’11, pages 321–330. ACM, 2011.
[18] H. Comon-Lundh and V. Cortier. Computational soundness

of observational equivalence. In CCS’08, pages 109–118.
ACM, 2008.

[19] H. Comon-Lundh, V. Cortier, and G. Scerri. Security proof
with dishonest keys. In POST’12, LNCS, pages 149–168.
Springer, 2012.

[20] H. Comon-Lundh, V. Cortier, and G. Scerri. Tractable

inference systems: an extension with a deducibility
predicate. In CADE’13, LNAI. Springer, 2013.

[21] Hubert Comon-Lundh, Masami Hagiya, Yusuke Kawamoto,

and Hideki Sakurada. Computational soundness of
indistinguishability properties without computable parsing.
In ISPEC’12, pages 63–79. Springer, 2012.

[22] C. Cremers. The scyther tool: Veriﬁcation, falsiﬁcation, and

analysis of security protocols. In CAV’08, volume 5123 of
LNCS, pages 414–418. Springer, 2008.

[23] C. Ene, Y. Lakhnech, and V. C. Ng. Formal

indistinguishability extended to the random oracle model. In
ESORICS’09, volume 5789 of LNCS, pages 555–570.
Springer, 2009.

[24] A. Armando et al. The AVISPA Tool for the automated

validation of internet security protocols and applications. In
CAV’05, volume 3576 of LNCS, pages 281–285, 2005.

[25] Bogdan Warinschi. A computational analysis of the

needham-schroeder protocol. In 16th Computer security
foundation workshop (CSFW), pages 248–262. IEEE, 2003.

620