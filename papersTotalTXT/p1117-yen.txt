An Epidemiological Study of Malware Encounters

in a Large Enterprise

Ting-Fang Yen

E8 Security

tyen@e8security.com

Victor Heorhiadi

University of North Carolina at

Chapel Hill

victor@cs.unc.edu

Alina Oprea

RSA Laboratories

alina.oprea@rsa.com

Michael K. Reiter

University of North Carolina at

Chapel Hill

reiter@cs.unc.edu

ABSTRACT
We present an epidemiological study of malware encounters in a
large, multi-national enterprise. Our data sets allow us to observe
or infer not only malware presence on enterprise computers, but
also malware entry points, network locations of the computers (i.e.,
inside the enterprise network or outside) when the malware were
encountered, and for some web-based malware encounters, web
activities that gave rise to them. By coupling this data with demo-
graphic information for each host’s primary user, such as his or her
job title and level in the management hierarchy, we are able to paint
a reasonably comprehensive picture of malware encounters for this
enterprise. We use this analysis to build a logistic regression model
for inferring the risk of hosts encountering malware; those ranked
highly by our model have a > 3× higher rate of encountering mal-
ware than the base rate. We also discuss where our study conﬁrms
or refutes other studies and guidance that our results suggest.

Categories and Subject Descriptors
K.6.5 [Management of Computing and Information Systems]:
Security and Protection—Invasive Software; C.2.0 [Computer-
Communication Networks]: General—Security and Protection

Keywords
Malware encounters, enterprise security, measurement, logistic re-
gression

1.

INTRODUCTION

In this paper, we present the ﬁrst epidemiological study of mal-
ware encounters within a large enterprise. Formally, epidemiology
“deals with the incidence, distribution, and control of disease in a
population” [1] — the disease, in our setting, being malware. We
explore in this sense the patterns and causes of malware encoun-
ters within a population, namely the hosts and employees of the
enterprise under study. Our work beneﬁts from privileged access to
security logs generated within this enterprise, as well as databases

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage, and that copies bear this notice and the full ci-
tation on the ﬁrst page. Copyrights for third-party components of this work must be
honored. For all other uses, contact the owner/author(s). Copyright is held by the
author/owner(s).
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
ACM 978-1-4503-2957-6/14/11.
http://dx.doi.org/10.1145/2660267.2660330 .

Ari Juels
Cornell Tech

ajuels@gmail.com

containing information about the employees using the hosts on the
enterprise network. By agreement with the security administrators
of the enterprise, we omit its name from this paper.

Malware spread is a well-studied problem in consumer environ-
ments. It is far less well studied, however, in enterprise settings,
which may differ in important ways from consumer contexts. Cor-
porate computing resources are subject to tighter security policies
and beneﬁt from more expert security administration than most
consumer devices. Corporations possess digital assets, however,
including ﬁnancial data and intellectual property, far more valuable
than the data on most consumer devices. Enterprise data might
thus be subject to highly sophisticated targeted attacks in which
malware often plays a pivotal role.

Enterprise host security also merits study in its own right. Enter-
prises are interesting microcosms in which users (employees) are
assigned highly speciﬁc demographic classiﬁcations in the form of
job titles, business-unit placement, and level in the management
hierarchy. Employees are also subject to more or less uniform se-
curity policies across an enterprise and use similar (if not identi-
cal) O/S and software versions, creating a controlled environment
amenable to scientiﬁc study. As employee behavior on an enter-
prise network is subject to monitoring by the enterprise, and many
hosts are instrumented with software (e.g., anti-virus) that gener-
ates internal reports, enterprises additionally have data about the
behavior of their users unavailable in many consumer settings or
whose use would infringe upon users’ legal rights.

Our study and results: We rely on reporting by anti-virus soft-
ware (McAfee), with which 85,000+ hosts owned and managed by
the enterprise are instrumented. As these are cases where malware
was detected and presumably prevented from executing, we bor-
row from existing terminology [12] and refer to them as malware
encounters rather than infections.

We study these encounters from several distinct perspectives.
First, by examining the ﬁle system locations of detected malware
instances, we characterize the vectors by which malware gains ac-
cess to hosts (e.g., external drive, web). Second, we quantify the
frequency of “inside” encounters—those occurring while hosts are
connected to the enterprise network, either over VPN or on the
LAN—and “outside” encounters (when employees take hosts home
or to customer sites). Third, we correlate malware reports with
demographic information about hosts’ users, including their job
roles, levels in the management hierarchy of the company, and ge-
ographic locations. Finally, we examine encounters resulting from
host visits to malicious web sites, drawing on enterprise web proxy

1117logs to ascertain the browsing behavior underlying these encoun-
ters.

Many of our data sources do not provide direct indications of the
host and user behaviors of interest, and inferring these behaviors in
some cases presents interesting technical challenges. For example,
McAfee anti-virus software reports do not indicate whether hosts
are inside the enterprise network (“on-network”) or outside (“off-
network”) at the time of a malware encounter. We thus classify
encounters based on reporting delay times.

management hierarchy.

than on-network encounters.

We present a number of interesting ﬁndings, including several
that, to the best of our knowledge, reﬂect previously unstudied phe-
nomena. Some key ﬁndings in the enterprise under study are:
• Off-network encounters are roughly three times more common
• Encounter rates are lowest at the upper levels of the corporate
• External drives are the most common vector of malware en-
counters, and especially prevalent in low per-capita GDP coun-
tries.
• Roughly 31% of the web-based malware encounters (around
554 over four months, as extrapolated from encounters trace-
able to proxy logs) originate from websites classiﬁed by the
enterprise web proxy into the “business” category, and 15%
(around 266, similarly extrapolated over four months) originate
from the “travel” category.

We present these and other results and offer some conjectural ex-
planations below.

Finally, drawing together the data sources examined in our study,
we identify features (demographic and behavioral) that correlate
signiﬁcantly with a host encountering malware. We use these fea-
tures to construct a logistic regression model that estimates the en-
counter risk associated with individual hosts. This model success-
fully identiﬁes high-risk hosts: the encounter rate among the top
1,000 identiﬁed hosts is 51%, signiﬁcantly more than three times
the base rate for the enterprise as a whole.
Our contributions: Our main contributions are:
• We present the ﬁrst large-scale epidemiological study of enter-
prise malware encounters, based on analysis of a repository of
sensitive enterprise security data.
• We correlate malware encounters on hosts with a variety of de-
mographic and behavioral features for users (job roles, web
browsing behavior, etc.), many of them previously unstudied.
Our study yields a number of signiﬁcant ﬁndings.
• We build a logistic regression model across a subset of these
features that successfully identiﬁes hosts with a signiﬁcantly el-
evated risk of encountering malware.

While our ﬁndings are illuminating (and sometimes counter-
intuitive) in their own right, we believe they can also help shape
enterprise security policy, select effective security tools, and create
targeted security education programs for employees. We empha-
size that our study treats a single (albeit, large) enterprise; its wider
applicability, of course, requires further investigation. We believe
that case studies of this kind are individually informative and also
important steps toward the creation of a portfolio of real-world re-
search results that can illuminate broad practices and trends.

2. DATA

review the ethical and privacy considerations affecting our work
(Section 2.6).
2.1 Anti-Virus Reports

We examine reports collected from McAfee anti-virus agents de-
ployed on 85,000+ hosts owned and managed by the enterprise. In
addition to matching known virus signatures, the McAfee agent
also detects suspicious ﬁles using a cloud-based reputation ser-
vice (McAfee Global Threat Intelligence).1 Detection occurs in
on-access mode, where a ﬁle object is scanned as it is read into
memory, after which the suspicious ﬁle is deleted or quarantined.
Reports generated by the McAfee agent are sent from the end
hosts to a centralized data collector within the enterprise network
immediately upon generation. If the host is outside the corporate
network or the collection server is otherwise inaccessible, the agent
will buffer reports on the host and attempt to re-send every ﬁve
minutes. Due to storage and bandwidth constraints, only reports for
detected malware are collected, which excludes data about, e.g., re-
sults of virus scan on “clean” end hosts or time of the last signature
update.

Table 1 shows the ﬁelds available in each McAfee report.

In
addition to the host name, virus name, and ﬁle path, each report
also includes two timestamps: One indicating the time when the
malicious ﬁle was detected on the end host, and another the time
when this report was received at the data collection server. We note,
with conﬁrmation from the enterprise’s IT team, that no buffering
is performed during the data collection process that would affect
the timestamps we use.

Field

Host name

Virus name

File path
Detection time
Reporting time

Description

A fully-qualiﬁed domain name that
serves as an unique identiﬁer for the
end host on the enterprise network.
The name of the identiﬁed threat
(according to McAfee).
The full path of the malicious ﬁle.
Time of detection on the end host.
Time of collection at the enterprise
data collection server.

Table 1: Fields in McAfee reports.

Over a four-month period, from July 10 to November 10, 2013,
the centralized data collector received a total of 569,967 reports.
However, many of those reports appear to be redundant, with the
same {host name, virus name, ﬁle path} tuple repeated within an
interval of seconds. 87.76% of them appear less than one minute
apart from a previous, identical report. Most of these redundant
reports are due to the McAfee agent attempting to delete or quar-
antine read-only ﬁles. For reports with the same {host name, virus
name, ﬁle path} tuple, we retain the report with the earliest detec-
tion timestamp and exclude the remainder from consideration.

We also discovered an outlier host that generated over 10,000 re-
ports in four hours. The McAfee agent detected and deleted ﬁles
repeatedly created by malware on the host (but not the actual mal-
ware binary). There are also a small number of “false-positive”
reports (2,132 reports) whose detected malicious ﬁles were sample
malware from security certiﬁcation courses or research activities;
e.g., the ﬁle paths included directories names like “PenTesting” or

We leverage multiple data sources to study malware encounters
in the enterprise under study. We give details in this section on the
ﬁve major data sources in our study (Section 2.1-Section 2.5) and

1http://www.mcafee.com/us/
threat-center/technology/
global-threat-intelligence-technology.aspx

1118“CEHv8 Module”. We also ﬁlter these reports out. Our ﬁltered
dataset includes 120,161 reports from 10,941 distinct hosts.
2.2 Employee Database

The enterprise also stores information about each employee that
includes the employee’s name, the employee ID number, ofﬁce lo-
cation, business unit, job title, and manager ID number. We infer
additional information about each employee based on this dataset.
From the job title, we categorize a user’s job type as the last word
in the job title after stripping away level indicators (e.g., “engineer
I” and “engineer II” are both considered “engineers”). Given each
employee’s manager ID, we build the organization tree with the
company CEO as root. This allows us to assign a “level” to each
employee based on the number of steps down from the tree root.
2.3 Windows Authentication Logs

While the McAfee reports and employee data each contain much
useful information, correlating the two is a non-trivial task —
McAfee reports are associated with hosts, while employee data is
about users. Lacking documentation about machine assignments
in the enterprise, we draw on a third data source to bridge this gap:
Windows authentication logs from domain controllers (DC).

The DCs are responsible for validating authentication requests
to access resources on a Windows domain. For example, when a
user logs on to her corporate machine, the request is sent to the DC,
where her credentials are veriﬁed. Each authentication log includes
the user name, the host where access was requested, the timestamp,
and other ﬁelds indicating the type of logon and whether the logon
was successful.

To infer the primary user of a host, we examine Windows au-
thentication logs over one month. For every host, a list is kept
documenting the users that successfully authenticated to the host.
After this month, the user responsible for a large majority (80%) of
the logons on the host is assumed to be the primary user. If no such
user exists for a host, it is assumed to be a multi-user server and re-
moved from further consideration.2 In this way, we determined the
primary user for 62,884 enterprise-managed hosts that are instru-
mented with the McAfee client, of which 9,625 generated malware
reports during our four-month observation period. In our study, we
focus on the hosts for which a primary user can be identiﬁed.
2.4 Web Proxy Logs

In addition to anti-virus software, the enterprise network deploys
a variety of security tools to prevent unwanted software and intru-
sions. One is a Cisco IronPort web proxy that ﬁlters HTTP and
HTTPS requests. The proxy vendor provides reputation scores and
category information (e.g., business, news, sports) for known sites,
and the ﬁltering policy blocks connections to websites with low
reputation or in non-business-related categories.

In cases where a web request is made to a previously unknown
website lacking reputation and category, the proxy instead displays
a warning page to the user, stating that the site is considered higher
risk. The user is asked to acknowledge that access to the site ad-
heres to the company’s security policies before being allowed to
proceed. Once the user has acknowledged, her consent is valid for
one hour. During this time, visits to other non-categorized websites
are allowed without further prompting from the proxy.

Part of our study examines the effectiveness of the web proxy’s
ﬁltering policy at preventing malware infections. For this, we make

2Not all of the enterprise servers are instrumented with McAfee
anti-virus, unlike end hosts. Moreover, as they are multi-user, their
behaviors could not be attributed to a primary user for inclusion in
the demographics aspects of our study.

use of logs generated by the web proxy, which include the times-
tamp, the destination URL and domain, the source IP address, the
web referer, user-agent string, the website reputation and category,
and the ﬁltering policy applied to that connection.
2.5 VPN Logs

One focus of our study is on where McAfee detection occurred,
i.e., whether “inside” the corporate network (in which case the mal-
ware penetrated the network’s security perimeter to arrive on the
victim host) or “outside.” As part of that investigation, we use Vir-
tual Private Network (VPN) logs to examine employees’ accesses
to corporate resources while physically outside the company.

A VPN allows remote employees to establish a secure communi-
cation channel to the enterprise network. For each VPN session, the
Cisco VPN server records the username that logged in, the fully-
qualiﬁed domain name of the host used to log in, the time of login,
the duration of the VPN session, the number of bytes sent and re-
ceived during the session, and the external IP address from which
the login was made. This gives us an approximation of how often
a corporate laptop is brought outside of the enterprise network, and
how it is used while outside.
2.6 Ethical and Privacy Considerations

As a matter of enterprise policy, employees are notiﬁed that they
must consent to logging / monitoring of their activities by the en-
terprise IT security department in order to use enterprise networks
and computers. The supervisors of the enterprise IT security de-
partment consented to the use of all of the datasets described above
for the purposes of this study and also speciﬁcally to release of
the summary data contained in this paper. Authors were granted
access to the data only while on site at the enterprise, and not per-
mitted to handle any data outside the enterprise network beyond
the summary results presented here. Authors under the jurisdiction
of Institutional Review Boards were not provided identiﬁable data
and so did not require IRB approval.

3. MALWARE ENCOUNTER STATISTICS
Among enterprise-managed hosts whose primary user could be
identiﬁed (see Section 2.3), 15.31% encountered malware over our
four-month observation period. The hosts that generated McAfee
reports, however, are not spread uniformly across the enterprise, as
previous works have also observed in different datasets and types
of entities (e.g., the geographic locations of spamming bots [16]).
Figure 1 shows the number (and fraction) of hosts in each coun-
try from which McAfee reports were received, where the country
was determined by the corresponding employee’s ofﬁce location, as
described in Section 2.2. Only the top 20 countries with the high-
est number of employees are plotted. The encounter rate (on the
right Y-axis) is deﬁned as the fraction of enterprise managed hosts
in that country (for which the primary user could be identiﬁed, see
Section 2.3) that generated McAfee reports. The encounter rate
varies widely across geographic locations — the average encounter
rate by country is 25.68%, with a standard deviation of 27.26%.

In this section, we attempt to understand better the threat land-
scape in enterprise environments and to expand upon differences
between victims affected by malware. First, we examine the ﬁle
system location of detected malicious ﬁles to identify potential
methods by which malware arrived on victim hosts. Second, by
observing the time difference between malware detection and re-
porting, we quantify the relative frequency of malware encounters
taking place within and outside the enterprise network. Third, we
study demographic characteristics of users whose hosts encoun-
tered malware. Finally, we correlate McAfee reports with web

1119categorized or has low reputation. As a result, known web attacks
(such as those detected by anti-virus like McAfee) are prevented,
and other infection vectors (e.g., external drives) dominate.

Figure 3: Distribution of malware locations by country. The shad-
ing of a box represents, out of the hosts in that country, the fraction
where malware was found at that ﬁle system location.

Figure 3 shows, for each location category, the fraction of hosts
in each country on which malware was found at that ﬁle system
location. Rows (and columns) are sorted according to a hierarchical
clustering algorithm to minimize the Euclidean distance between
adjacent rows (and columns). It is clear that India and Egypt stand
out as having a high fraction of hosts encountering malware on
external drives (23.79% and 17.86%, respectively). Also obvious is
the dominance of malware under the web browser cache for hosts in
South Korea, perhaps due to the high number of phishing, malware
hosting, and drive-by-download sites in the country (80, 172, and
54 times higher than that in the U.S.3).

Figure 4: The rate at which malware of different ﬁle system loca-
tion categories are encountered across cities.

We also examine the temporal and spatial locality of malware en-
counters in each ﬁle system location category. The intuition is that,
even though ﬁle system location is only a rough indicator of how
malware propagates, certain ﬁle system locations commonly asso-
ciated with human-driven activities should show a “slower” mal-
ware spread across geographic regions than those associated with
automated events.

To measure this behavior, we ﬁrst identiﬁed each distinct mal-
ware (as identiﬁed by McAfee) that is primarily found in one ﬁle
system location category (i.e., accounting for over 95% of its en-
counters), and that is encountered more than 10 times within our
dataset and in multiple cities (inferred from the ofﬁce location
of the employee associated with the reporting host). For each
such malware, we computed its rate of geographic spread or, more

3http://blogs.technet.com/b/
security/archive/2011/07/18/
a-very-active-place-the-threat-landscape-in-
the-republic-of-korea.aspx.

Figure 1: The number of hosts, and the malware encounter rate, in
each country.

Figure 2: The ﬁle system location where malware was found.

proxy logs to understand the browsing behavior underlying web-
based malware encounters. In Appendix A, we report the preva-
lence of various malware types identiﬁed by the McAfee agent.

Results in this section focus on the ten countries in our dataset
with the most hosts that encountered malware: U.S., India, China,
Ireland, Egypt, the U.K., Brazil, Israel, South Korea, and Germany.
3.1 Malware Location

In this section we investigate where the detected malicious ﬁle
was found on the victim’s ﬁle system. Lacking the ability to mon-
itor host-level activities and to collect additional information at the
time of detection, we instead leverage the directory structure of the
Windows operating system to infer how (or why) a ﬁle ended up
at that location. Appendix B describes the malware locations and
how we categorize them.

Figure 2 shows the fraction of hosts reporting malware at a loca-
tion indicated on the horizontal axis, out of all hosts instrumented
with McAfee and whose primary user could be identiﬁed (see Sec-
tion 2.3). External drives are by far the most prevalent location
for malicious ﬁles, associated with 4.92% of all hosts (one-third of
the hosts that encountered malware). Temporary folders and the
browser cache follow, which likely correspond to secondary mal-
ware downloads by an initial exploit and web drive-by downloads.
This result is somewhat surprising. According to the Symantec
Internet Security Threat Report from 2012 [19], web attacks are
the favorite method for malware authors to gain access to victim
hosts. The 2011 Microsoft Security Intelligence report [11] also
found that most of the malware infections analyzed (45%) required
user interactions to compromise the host, i.e., by visiting malicious
webpages or installing malicious software, much higher than those
accounted for by infected USB or removable drives (26%). By
contrast, the detected malicious ﬁles are most commonly found on
external drives in our dataset. This discrepancy can perhaps be
partially attributed to the enforcement of web ﬁltering policies on
outbound requests (apparently motivated by the prevalence of web
attacks). As described in Section 2.4, connections are blocked if
they are destined for a blacklisted site, or if the remote site is non-

USIndiaIrelandChinaUKGermanyJapanAustraliaIsraelCanadaSingaporeFranceEgyptBrazilItalyRussiaS.KoreaSpainMexicoNetherlands05000100001500020000250003000035000TotalNumberofHosts0.000.050.100.150.200.250.300.350.40EncounterRateExternalDriveTemporaryFilesWebUnknownDownloadApplicationJavaSystemFilesProgramFilesRecycleBinBackupNetDrive0.000.010.020.030.040.05FractionofAllHostsExternalDriveDownloadApplicationProgramFilesJavaSystemFilesWebTemporaryFilesUnknownIndiaEgyptIsraelUSUKIrelandGermanyS.KoreaChinaBrazil0.0250.0500.0750.1000.1250.1500.1750.2000.225ExternalDriveWebJavaTemporaryFilesApplicationSystemFilesUnknownRecycleBinMalwareLocation0.00.20.40.60.81.0Cities/Encounter1120speciﬁcally, the number of cities in which it is encountered, divided
by the number of encounters for that malware. So, a smaller value
for a particular malware indicates that its encounters are concen-
trated in fewer cities. We then grouped the malware by their ﬁle
system location categories and summarized each group’s rates of
geographic spread using a boxplot, as shown in Figure 4. As ex-
pected, malware found on external drives spread the slowest, likely
due to them involving human interactions to move across geo-
graphic locations. Malware under the browser cache (also likely as-
sociated with human activities) and temporary folders (potentially
secondary downloads caused by web drive-bys) are slightly faster,
while those under the system or application directories spread the
fastest.
Findings: Malware on external drives are found on 4.92% of the
hosts instrumented with the McAfee client, while malware under
temporary folders are found on 3.34% of the hosts, followed by the
web cache on 3.11% of the hosts. Compared to consumer contexts,
hosts in the enterprise seem to be less exposed to web attacks (as
seen by the relative dominance of external drives and temporary
folders to the web cache). This is likely due to the enforcement of
web ﬁltering policies at the enterprise network border.

There is a geographic difference in the malware locations on the
ﬁle system — hosts in India and Egypt are more likely to encounter
malware on external drives, while a high fraction of hosts in South
Korea encounter web malware. This suggests that targeted user
education may be helpful in reducing speciﬁc risk factors in certain
regions.
3.2

Inside vs. Outside Enterprise Network

As mentioned in Section 2.1, a McAfee agent attempts to com-
municate with the centralized data collector immediately upon re-
port generation, i.e., at detection time. When the host is connected
to the enterprise network (either over VPN or on the LAN), we ex-
pect the difference between reporting time and detection time to be
small, e.g., on the order of seconds or minutes. By contrast, if the
host is outside the enterprise network when a report is generated,
the reporting time is delayed until the host is brought back inside,
which is likely to be much later (e.g., hours or days).

To estimate the fraction of McAfee reports that are generated
on the corporate network — which means that the host would po-
tentially become infected inside the enterprise, even with the de-
ployment of various security products on the enterprise network —
we examine the difference between reporting time and detection
time. Figure 5 plots the cumulative distribution of this time differ-
ence across all McAfee reports, as well as for reports generated by
hosts in the ﬁve countries where the most hosts encountered mal-
ware. Overall, only 19.13% of the reports are received by the data
collector within ﬁve minutes of generation, and 23.06% within 10
minutes. This suggests that the large majority of reports were gen-
erated when the host was outside the corporate network.

However, we do observe that the fraction of McAfee reports
generated inside (or outside) the corporate network varies widely
across countries. As shown in Figure 5, 52.46% of the McAfee
reports from hosts in Ireland are collected within 10 minutes of de-
tection, while this is true for only 10.91% of the reports from hosts
in India. Rather than suggesting that hosts in Ireland are exhibiting
more risky behaviors “inside,” we believe this reﬂects differences
in culture and working style across regions. For example, some
employees only access company resources during regular working
hours, while others bring corporate laptops home for both work and
personal use.

To investigate this diversity further, we examine VPN logs col-
lected from the enterprise VPN servers (see Section 2.5). Speciﬁ-

Figure 5: The cumulative distribution of the difference between
reporting time and detection time, for the top ﬁve countries with
the most number of malware-encountering hosts.
cally, the VPN logs allow us to infer: (1) the frequency at which
corporate machines are being taken outside, and (2) how those
hosts are used while outside. Figure 6 shows the cumulative dis-
tribution of the number of VPN logins per user and the duration of
VPN sessions for the ﬁve countries in Figure 5.

Figure 6: Cumulative distribution of the number of VPN logins per
user and the duration of VPN sessions, for the top ﬁve countries
with the most number of malware-encountering hosts.

We can make several observations by looking at the two extreme
countries in Figure 5, Ireland and India. First, users in Ireland lo-
gin to VPN less frequently than other countries. Half of the users
logged in less than 15 times during our four-month observation pe-
riod, while this number is 31 for India, and 93 for the U.S. This
perhaps indicates that employees in Ireland are less likely to bring
corporate machines outside of the enterprise network, hence the
higher fraction of “inside” McAfee reports in Figure 5. Secondly,
while users in India also have a relatively low number of VPN lo-
gins, they logon for much shorter durations (e.g., half of the users
logged off after 1.5 hours, compared to 7 hours for users in Ireland).
Relating this to the fact that around 89% of the McAfee detections
in India likely occurred “outside,” we conjecture that these employ-
ees tend to bring corporate laptops outside the enterprise, though
for personal use. Another explanation for the relatively short VPN
duration of users in India may be that home Internet connections are
less stable, and so employees who bring their laptops home tend to
work ofﬂine.

0102030405060Minutes0.00.10.20.30.40.50.6FractionofHosts(CDF)USIndiaChinaIrelandEgyptAll050100150200250NumberofVPNLogins0.00.20.40.60.81.0FractionofHosts(CDF)USIndiaChinaIrelandEgypt0100200300400500600700800DurationofVPNSessions(min)0.00.20.40.60.81.0FractionofSessions(CDF)USIndiaChinaIrelandEgypt1121In addition to the fraction of McAfee reports generated “inside”
and “outside,” we are also interested in whether there is a difference
between the ﬁle system location of the detected malicious ﬁle in the
two cases. Figure 5 shows a sharp knee in the curves at around ﬁve
minutes. To be conservative, we use 10 minutes as a threshold;
we treat reports whose difference between reporting time and de-
tection time is within 10 minutes as “inside,” and the remainder
as “outside.” Figure 7 shows the distribution of malware locations
separately for the “inside” and “outside” cases. The fractions are
computed as the number of hosts that reported malware at that ﬁle
system location while “inside” (or “outside”) over all hosts instru-
mented with McAfee and whose primary user was identiﬁed.

Section 2.2, the enterprise employee database allows us to infer the
user’s level in the organizational tree and job type.

Figure 8 shows the fraction of hosts (i.e., whose corresponding
user is) at each level in the organizational tree that encountered mal-
ware, for all hosts as well as for each country. The company CEO is
assigned the root of the tree (level 0), hence the larger the level, the
lower down the user is in the management hierarchy. Levels with
fewer than ﬁve hosts are crossed out. The countries are ordered by
the number of hosts in the country.

Figure 7: Malware locations for the “inside” and “outside” cases.
The fractions are computed as the number of hosts that reported
malware at that ﬁle system location while “inside” (or “outside”)
over all hosts instrumented with McAfee and whose primary user
was identiﬁed.

External drives are the most prevalent malware location in both
“inside” and “outside” cases. The fact that the fraction for “out-
side” is higher, in addition to a non-trivial fraction (around 8%) of
those ﬁles being multimedia ﬁles (based on the ﬁle extension, e.g.,
mp3, avi, jpg), suggests that users do bring corporate laptops home
for personal use, as noted above. If true, this result further high-
lights the risks of mobile devices being physically brought out and
back into the enterprise network.

The following two popular malware locations, web browser
cache and temporary ﬁles, also affected more hosts “outside” than
“inside.” Since they are commonly associated with drive-by or sec-
ondary downloads by initial infections, their relative popularity out-
side the corporate network is likely caused by the enforcement of
strict ﬁltering policies when the host is on the enterprise network.
More signiﬁcant “inside” than “outside” is malware found under
“System Files” and “Unknown” (the fallback category for ﬁle paths
that match no other location categories). These locations suggest
that these McAfee reports are a result of intentional user actions,
e.g., to install custom software. Security policies may thus be in-
sufﬁcient in preventing such malware, and targeted user education
a more promising approach.
Findings: The large majority of McAfee reports were generated
when the host was outside the enterprise network. However, the
fraction of “outside” reports varies widely by geographic location,
possibly caused by differences in culture and working style. The
dominant malware locations on the ﬁle system are different be-
tween the “inside” and “outside” cases, which might be attributed
to both user behavior (i.e., bringing corporate laptops home) and
the enforcement of security policies on the enterprise network.
3.3 User Demographics

In addition to the malware location and place of detection, we
also examine the relationship between user demographics and the
likelihood of a host being affected by malware. As described in

Figure 8: Malware encounter rate by level in the organizational
tree, both for all hosts (the ﬁrst column) and per country. The
countries are ordered by the number of hosts in that country. The
company CEO is assigned the root of the tree (level 0).

In general, the shading of the boxes becomes darker with the or-
ganizational level, particularly for several countries (India, China,
South Korea, and except for one outlier at the top of the column,
Brazil). We conjecture that a reason for this phenomenon is that
employees higher up the organizational tree (i.e., smaller levels)
are likely to assume managerial roles and hence exhibit less inten-
sive computer use.

Given an employee’s job title, we also categorize his or her job
type by taking the last word in the job title after stripping away
level indicators (e.g., “engineer I” and “engineer II” are both con-
sidered “engineers”). There are 12 job types that have more than
500 employees, covering 84% of all employees whose machine(s)
are instrumented with the McAfee client. Appendix D describes
each of these job types.

Figure 9 shows the number of hosts (whose corresponding user
is) of each job type, as well as the fraction of hosts with that job
type that encountered malware. It appears that job types requiring
greater technical expertise also have a greater likelihood of encoun-
tering malware. Similar results were reported by Lévesque et al. [9]
from a small study of 50 users. It is possible that technically savvy
users may be more exposed to malware by spending more time with
computers or the Internet, or they are potentially less careful about
unknown ﬁles.
Findings: The likelihood of encountering malware increases the
further the employee is from the top of the enterprise organizational
tree, and also increases with technical proﬁciency.
3.4 Web Malware

The web is reportedly the most prevalent vector for attackers and
malware authors to gain access to victim hosts [19]. In our dataset,
3.11% of the hosts likely encountered malware by visiting mali-
cious websites, i.e., the detected malicious ﬁle was found in the
browser cache (see Section 3.1). Among those hosts, 29.85% (583
hosts) generated the McAfee report while they were connected to
the corporate network. We are interested in investigating where
those malicious ﬁles came from, and in particular, why the web
proxy that ﬁlters web connections from the enterprise failed to
block them.

ExternalDriveWebTemporaryFilesApplicationUnknownDownloadJavaProgramFilesSystemFiles0.0000.0050.0100.0150.0200.0250.0300.035FractionofHostsOutsideInsideAllUSIndiaIrelandChinaUKGermanyIsraelEgyptBrazilS.Korea1110987654321Level0.000.060.120.180.240.300.360.420.480.541122Fraction of

Fraction of

Website category matching hosts matching reports
31.28%
Business
Communities
8.46%
4.36%
Search
14.87%
Travel
4.62%
Non-Categorized
2.31%
SaaS
3.59%
Sports
Food
8.46%
3.08%
Entertainment
Computers
1.03%

29.51%
11.48%
9.02%
8.19%
6.56%
6.56%
4.92%
4.92%
3.28%
3.28%

Table 2: Top website categories for matching McAfee reports in
the “Web” category.
whelming majority (95%) of the matching McAfee reports were
allowed through the web proxy, while 2.56% were blocked. This
means that although the proxy prevented the connection while the
host is inside the corporate network, the malicious ﬁle was down-
loaded when the host was brought outside the enterprise. More
interestingly, among the 2.31% matching reports whose connec-
tion required user consent, over half (55.56%) were allowed to pro-
ceed because of a previous user acknowledgment to a different site.
Given the small number of encounters we observed under this pol-
icy, more data is needed to draw conclusions on its effectiveness.

Policy

Allowed
Require user consent
Blocked

Fraction of

Fraction of

matching hosts matching reports
95.13%
2.31%
2.56%

93.44%
6.56%
0.82%

Table 3: Web ﬁltering policies applied to matching McAfee reports
in the “Web” category.

Findings: The majority of web-based encounters that we corre-
lated with the web proxy logs are from sites deemed business-
appropriate under enterprise policy. 31% of the web-based encoun-
ters (around 554 over the four-month duration of our study, ex-
trapolated from the 22% of correlatable encounters) originate from
websites in the “business” category and 15% (around 266, similarly
extrapolated over four months) originate from the “travel” category.

4.

INFERRING THE RISK OF INFECTION
We have observed in Section 3 that there are multiple factors re-
lated to the likelihood of a host encountering malware, including
demographic features of its user as well as various aspects of its
user’s behavior. In this section, we develop a statistical model to
infer the risk of a host encountering malware proactively. We eval-
uate the model accuracy and discuss applications to detection and
remediation of malware infections in early stages.
4.1 Logistic Regression Model

Motivated by results in Section 3, we extract three categories of
features to be used in the model: 1) Demographic features cap-
turing information about the user, 2) VPN activity features to infer
user behavior outside the corporate network (e.g., number of VPN
logins, duration of VPN sessions), and 3) Web activity features in-
cluding information about the user’s browsing behavior (e.g., cate-
gories of web sites visited, web trafﬁc volume). Some of the fea-
tures are numeric values (e.g., number of VPN logins), and some
are categorical (e.g., the country where the user is located). A sub-
set of the features are static (e.g., country, job type), but most vary
over time (e.g., number of domains visited or VPN logins).

We are interested in building a predictive model that estimates
the conditional probability of encountering malware given the fea-

Figure 9: Malware encounter rate by job type. The encounter rate
is the fraction of hosts (whose corresponding user has) the job type
on the horizontal axis that encountered malware.

The web proxy logs collected in the enterprise contain ﬁelds in
the HTTP request header, including the destination URL and do-
main, web referer, user-agent string, as well as auxiliary informa-
tion like the website reputation and category (provided by the web
proxy vendor), and the ﬁltering policy that was applied to that con-
nection (see Section 2.4). Since we know the name of the detected
malicious ﬁle, we can identify matching URLs in the web proxy
logs to obtain details of that connection.

This method only works for ﬁles that are stored as-is with the
same ﬁlename. For some browsers, including Chrome4 and Fire-
fox5, the cache is structured as a layered hash table for fast ac-
cess, where cached ﬁles are stored in multiple local ﬁles. The name
of the detected malicious ﬁle, as recorded in McAfee reports, is
hence an index to the actual data location, and difﬁcult to reverse-
engineer without knowledge of the cache structure and addresses
local to the host. In addition, the web proxy logs only store the
IP address of the host, while McAfee reports store only the host-
name. We further analyze DHCP logs in the enterprise to obtain an
IP-to-hostname mapping, and correlate it with the web proxy logs
to look up the host assigned that IP during that time (though clock
skew and missing or out-of-order logs sometimes cause this lookup
to fail). Even with these limitations posed by imperfect data, we
were able to match 390 McAfee reports (22% of those found in the
browser cache and from hosts inside the enterprise network at the
time of detection) with the corresponding web proxy logs.

Table 2 lists the top website categories associated with matched
McAfee reports. Surprisingly, none of these categories seem to be
intuitively suspicious or malicious. The top category, “Business,”
is a rather general one that encompasses sites related to market-
ing, commerce, business practices, human resources, transporta-
tion, payroll, and a dozen other services.6 “Search” includes search
engines and portal sites, and “Communities” are sites associated
with special interest groups, web newsgroups, and message boards.
Of particular interest is the “Non-Categorized” category, which
are new sites that have not yet been given a category label. If an
uncategorized site lacking a reputation score is contacted, the web
proxy requests that the user acknowledge the enterprise security
policies before proceeding. Once the user gives consent, it remains
valid for one hour for that host, during which the user can visit
other uncategorized sites without further prompt from the proxy.

Table 3 shows the web proxy ﬁltering policy that was applied to
connections associated with matching McAfee reports. An over-

4http://www.chromium.org/developers/
design-documents/network-stack/disk-cache
5https://code.google.com/p/
firefox-cache-forensics/wiki/FfCacheRead
6Although not the same as “malicious”, a study of Android apps
by Sounthiraraj et al. [18] also found that “business” is the top app
category with the most number of vulnerable apps.

SpecialistConsultantArchitectAdministratorEngineerAnalystRepresentativeManagerCoordinatorAssistantDirectorTechnician0500010000150002000025000NumberofHosts0.060.080.100.120.140.160.180.200.220.24EncounterRateNumberofHostsEncounterRate1123ture values at a particular moment in time. We investigated a num-
ber of statistical models based on regression (linear, logistic, Pois-
son, and proportional hazards regression) and found logistic regres-
sion to be the most suitable for constructing the predictive model.
Logistic regression is used to estimate a conditional probability
P r(Y |X) of a binary response variable Y given a set of input vari-
ables X = (X1, . . . , Xn). The model assumes that P r(Y |X) is
the logistic function and estimates unknown parameters using the
maximum likelihood method.
More precisely, let p((cid:126)x) = P r(Y = 1|X = (cid:126)x), for (cid:126)x =

(x1, . . . , xn). Logistic regression assumes that:
= α + β · (cid:126)x,

p((cid:126)x)

log

1 − p((cid:126)x)

where α is called intercept, β = (β1, . . . , βn) are regression co-
efﬁcients for the features and β · (cid:126)x denotes the scalar product of
vectors β and (cid:126)x.

We model the response variable Y as a random variable with
value 1 if the host encountered malware, and 0 otherwise. Input
variables X = (X1, . . . , Xn) denote features modeling various
aspects of user demographic information and behavior, whose se-
lection process is described in detail in Section 4.2.

To demonstrate the model’s effectiveness, we randomly split the
entire host population into two equal-size training and testing data
sets. The parameters of the logistic regression model are estimated
using the training set, which are used to compute risk scores for
hosts in the testing set. We ﬁnally demonstrate that among the hosts
with highest risk score, a large fraction (more than 50%) encoun-
tered malware. Our evaluation results are presented in Section 4.3.
4.2 Feature Selection

We employ a two-stage feature selection process to identify the
most relevant features for the model. First, we build a logistic re-
gression model separately for each category of features with the
goal of ﬁnding the “signiﬁcant” features to predict malware en-
counters. Second, we combine the statistically signiﬁcant features
selected in the ﬁrst stage to build the ﬁnal model. Here we describe
the feature selection process in more detail.
4.2.1 Details on Statistical Model
We use the glm function in R for implementing logistic regres-
sion. Based on the training data, glm outputs estimates of the inter-
cept α and regression coefﬁcients βi, as well as standard errors for
estimation. For each feature i, glm also computes the p-value for
the hypothesis test that βi is zero, implemented using the standard
Wald test. A low p-value indicates that the null hypothesis can be
rejected with high conﬁdence, implying that the feature is relevant
in the model. Signiﬁcance levels of 0.001, 0.01 and 0.05 are de-
noted by ***, **, and *; a dot (.) denotes a 0.1 signiﬁcance level;
and no star or dot means the feature is not found signiﬁcant.

For categorical (i.e., discrete) variables, R employs the follow-
ing encoding scheme. Assume that a variable V takes m possible
values v1, . . . , vm. Then R encodes this with m − 1 binary vari-
ables Z1, . . . , Zm−1. Value V = vi for i ∈ {1, . . . , m − 1} is
encoded with Zi = 1 and all other Zj binary variables set at 0, for
j (cid:54)= i. Value V = vm is encoded with all variables Zi set at 0, for
i ∈ {1, . . . , m − 1}. vm is called the reference value for V .
4.2.2 Demographic Features
The user demographic features we consider include Gender (in-
ferred user gender), Country (country of user’s ofﬁce), Level (level
in the management hierarchy) and Technical (technical level of the
user’s job type). While the employee dataset does not include user

gender, we infer this information from the employees’ ﬁrst names
using data from the U.S. census bureau.7 The gender for 65.59% of
the employees was determined this way, with the remaining users
labeled as “unknown.” Technical level is a binary variable inferred
from the job title, set to 1 for “Engineer,” “Architect,” “Specialist,”
and “Administrator,” and 0 for all other job types. There are over
70 unique countries in our employee dataset. Ordering them by the
number of employees, we focus on the top countries that cover 95%
of the employee population.

Table 4 shows the estimated coefﬁcients for each feature, the
standard error, the p-value for the hypothesis that the regression
coefﬁcient is zero, and the signiﬁcance level.8 The low p-values
for the Gender, Level, Technical variables, as well as for the ma-
jority of the binary variables encoding Country, demonstrate that
all demographic features considered are signiﬁcant. The estimated
coefﬁcient is correlated with the infection risk of that feature, con-
ﬁrming that India has the highest infection risk, while Japan has the
lowest. Six countries (Japan, Ireland, Netherlands, Germany, UK,
US) have negative coefﬁcients indicating negative correlation with
malware encounters. Another six countries have coefﬁcients close
to 0, suggesting no statistical signiﬁcance regarding infections.

Feature
Gender

Country

Levels
Technical

Value
Male
Unknown
Brazil
Canada
China
Egypt
France
Germany
India
Ireland
Israel
Italy
Japan
Korea
Mexico
Netherlands
Russia
Singapore
Spain
UAE
UK
US
Other

Est.
0.23
0.39
1.01
0.05
0.92
0.86
0.24
-0.22
1.21
-0.24
0.09
0.37
-1.64
1.02
0.87
-0.23
0.52
0.19
0.57
0.62
-0.24
-0.02
0.52
0.15
0.08

Error
0.04
0.04
0.13
0.13
0.1
0.12
0.13
0.13
0.1
0.11
0.13
0.14
0.18
0.13
0.15
0.20
0.14
0.14
0.15
0.17
0.12
0.09
0.10
0.01
0.02

p-value
1.35e-09

2e-16

6.82e-15

1.36e-12

0.67
2e-16

0.07
0.08
2e-16
0.03
0.48
0.01
2e-16

0.26
3e-04
0.18
e-04
2e-04
0.047
0.79

2e-16
7e-04

2.29e-14
5.02e-09

3.23e-07

Signif.
***
***
***

***
***

.
.

***
*

**
***
***
***

***

***
***
*

***
***
***

Table 4: Signiﬁcance of demographic features.

4.2.3 VPN Activity Features
Section 3.2 shows that, with a threshold of 10 minutes between
detection and reporting times, around 77% of all malware encoun-
ters occurred outside the corporate network. While we have no
visibility into users’ activities outside the enterprise, VPN usage
is an approximate quantitative metric. We extracted the following
features to model a user’s VPN usage: VPN_conn (total number of
connections over the monitoring period), VPN_dur (total duration
of all VPN connections in seconds), VPN_sbytes (sum of bytes
sent in VPN connections), VPN_rbytes (sum of bytes received in
VPN connections), and VPN_extip (number of distinct external IP
addresses from which VPN connections are initiated). Intuitively,
7https://raw.github.com/Bemmu/gender-from-name
8For categorical features Gender and Country, values Female and
Australia, respectively, were chosen as the reference values by the
glm function (and as such are not explicitly included in the table).

1124users connecting from many different external IPs visit multiple
networks, and can be exposed to more attack vectors. These fea-
tures were aggregated over a subset of the monitoring period, from
August 1 to November 10, 2013.

Table 5 shows that almost all features are highly signiﬁcant in
estimating the conditional probability of malware encounters. Sur-
prisingly, VPN_dur is the only feature negatively correlated with
malware encounters (i.e., users exhibiting less total time in VPN
sessions are at higher risk). One conjecture is that users who bring
their machines outside often, but spend less time on VPN, are more
exposed to threats since they lack protection by enterprise security
products while on those external networks.

Feature
VPN_conn
VPN_dur
VPN_sbytes
VPN_rbytes
VPN_extip

Est.

4.47e-03
-8.54e-08
9.65e-12
1.38e-13
1.73e-02

Error

3.22e-04
8.21e-09
1.41e-12
2.08e-12
6.62e-04

p-value
2e-16
2e-16

6.96e-12

0.947
2e-16

Signif.
***
***
***

***

Table 5: Signiﬁcance of VPN activity features.

4.2.4 Web Activity Features
Various aspects of users’ web behavior are potentially correlated
with malware encounters. We investigate features related to cate-
gories of web sites visited, aggregate volumes of web trafﬁc, and
connections to blocked or low-reputation sites.
Categories of web sites visited. The web proxy vendor classiﬁes
web sites into categories. For each host, we count the total number
of HTTP connections to each category of interest, including chat,
entertainment, ﬁle transfer, ﬁltering, freeware, gaming, gambling,
online storage and backup, peer-to-peer, social networks, online
mail, streaming, business, travel and non-categorized sites. As de-
scribed in Section 3.4, non-categorized sites are those that are new
and yet to receive a category label. The results in Table 6 show
that only seven website categories are relevant in building the sta-
tistical model. Among these, four categories in particular (chat,
ﬁle transfer, social networks and non-categorized sites) contribute
signiﬁcantly to estimating the risk of hosts encountering malware.

Category
Chat
Entertainment
File transfer
Filtering
Freeware
Gaming
Online storage
Peer-to-peer
Social networks
Online mail
Streaming
Business
Travel
Non-Categorized

Est.

1.1e-05
2.01e-08
3.62e-06
2.12e-04
2.05e-06
1.27e-05
-3.7e-08
2.09e-07
4.54e-06
6.45e-07
4.48e-07
2.44e-07
1.74e-06
4.49e-06

Error
2.8e-06
7.4e-07
1.1e-06
2.03e-04
6.44e-07
6.48e-06

e-07

2.57e-06
1.04e-06
5.05e-07
1.93e-07
2.59e-07
1.11e-06
8.98e-07

p-value
8.84e-05

0.98

9.8e-04

0.3

1.4e-03

5.65e-07

1.36e-05

0.05
0.71
0.94

0.20
0.02
0.35
0.12

Signif.
***

***

**
.

***

*

***

Table 6: Signiﬁcance of website category features.

Web usage features. We also consider a set of features measuring
the aggregate volume of web trafﬁc generated by each host. Intu-
itively, higher Internet exposure could potentially result in higher
likelihood of encountering web-based malware. These features in-
clude: No_conn (total number of web connections over the mon-
itoring period), No_doms (number of distinct domains visited by
the host), rbytes (sum of the bytes received in all web connections),
and sbytes (sum of the bytes sent in all web connections). Table 7
shows that only the number of distinct domains visited by the host
is strongly correlated with the probability of encountering malware.

Category
No_conn
No_doms
rbytes
sbytes

Est.

2.14e-08
1.84e-06
3.83e-13
-6.82e-13

Error

p-value

Signif.

1.82e-08
2.405e-07
9.47e-13
5.91e-13

2.07e-14

0.24

0.69
0.24

***

Table 7: Signiﬁcance of web usage features.

Blocked and low-reputation domains. Accessing blocked or low-
reputation sites might be indicative of risky activity. For each host,
we count the number of web connections blocked by the proxy
(Blocked), the number of connections to non-categorized sites that
required explicit user agreement (Challenged), and the number of
connections to non-categorized sites to which the user explicitly
consented (Consented).

In addition, we maintain a history of all external destinations
visited by internal hosts in the enterprise over an interval of three
months. This history is updated daily to account for newly vis-
ited domains. Connections to new domains, i.e., that have not been
visited before by any host in the organization, are also possible in-
dicators of suspicious activity. For each host, we count the number
of new domains visited each day, and then aggregate these values
over the monitoring period into a feature called New_domains.

All of these features are highly signiﬁcant in the logistic regres-
sion model, as shown in Table 8, but the most signiﬁcant are visits
to new domains (New_domains) and number of non-categorized
sites requiring user agreement (Challenged).

Category
Blocked
Challenged
Consented
New_domains

Est.

1.02e-06
7.75e-06
2.85e-03
8.25e-04

Error

3.05e-07
1.59e-06
3.46e-04
1.6e-04

p-value
8.1e-04
1.04e-06

2e-16

2.56e-07

Signif.
***
***
***
***

Table 8: Signiﬁcance of domain reputation features.

4.2.5 Combining Relevant Features
We combine in our ﬁnal logistic regression model all features
found signiﬁcant in the above analyses, listed in Table 9. We also
ran a χ2 goodness-of-ﬁt test to test the hypothesis that the ﬁnal
model ﬁts the training data set, and obtained a very high p-value
(close to 1), implying that the null hypothesis can not be rejected.
This ﬁnding gives us conﬁdence that the model is a good ﬁt to the
features modeling user demographics and behavior, and we present
our evaluation results on the predictive power of the model next.

Web

VPN

Category
Feature
Demographic Gender
Country
Level
Technical
VPN_conn
VPN_dur
VPN_sbytes
VPN_extip
Chat
File transfer
Freeware
Games
Social networks
Streaming
Non-Categorized
No_doms
Blocked
Challenged
Consented
New_domains

Description
Gender of user
Country of user’s ofﬁce
Level in management hierarchy
Technical level
Total no. VPN connections
Duration of VPN connections
Bytes sent in VPN connections
No. external IPs connecting to VPN
No. chat sites visited
No. ﬁle-transfers sites visited
No. freeware sites visited
No. gaming/gambling sites visited
No. social-networking sites visited
No. streaming sites visited
No. non-categorized sites visited
No. distinct domains visited
No. connections blocked by proxy
No. connections challenged by proxy
No. connections consented by proxy
No. new domains visited

Table 9: Features included in ﬁnal logistic regression model.

11254.3 Evaluation

To evaluate the ﬁnal model, we split the set of all hosts randomly
into equal-sized sets, training and testing. We estimate the parame-
ters of the logistic regression model with the training set, and com-
pute the risk scores of hosts in the testing set. Figure 10 shows the
cumulative distribution (CDF) of scores for hosts in the testing set.
It is clear that the CDF for malware-encountering hosts is distinct
from that for “clean” hosts, with the former having (on average)
higher scores than the latter.

Figure 10: Cumulative distribution of scores for hosts that encoun-
tered malware, and those that did not.

This suggests that the user demographic and behavior features
can be used to infer the likelihood of malware encounters. As an
example application of this result, hosts can be ranked according to
their risk score, under a model tuned to the particular organization.
Proactive measures can then be applied to hosts with the highest
scores so as to detect and remediate potential malware infections.
How well will such a prioritization approach work? To answer
this question, we ordered the hosts in the testing set based on the
risk score output by the model, and computed the malware en-
counter rate for the top n hosts. Figure 11 shows our results, aver-
aged over ten independent runs, where each run splits the hosts into
training and testing datasets, and builds the model on the training
set while computing risk scores for hosts in the testing set. Re-
sults for models built with all features and those with each feature
category are shown as separate lines in Figure 11.

Figure 11: Ordering hosts by their risk score. The malware en-
counter rate decreases with the hosts’ score ranking. Among the
top 1,000 hosts, the malware encounter rate is 51% (well more than
3× higher than the overall encounter rate of 15%).

With all 20 features combined, the malware encounter rate is
51% among the top 1,000 hosts—well more than 3× higher than
the overall malware encounter rate in the enterprise (15.31%), as
described in Section 3. Among the three feature categories, user
demographics is the most powerful at indicating risk, followed
by VPN behavior. Counter-intuitively, web activity contributes
marginally to the overall model. One explanation for this surpris-
ing result is that, in our study, only 3.11% of the hosts encountered

malware from the web (see Section 3.1), and among those, we have
visibility into only a small fraction that happened inside the corpo-
rate network.

5. PREVIOUS STUDIES

Several prior works have studied the relationship between the
likelihood of malware encounters and users’ online behavior or de-
mographic information. The datasets used in previous works vary,
as well as the methods by which they identify malware encounters.
In this section, we compare our results to those reported in prior
studies where possible, and highlight instances in which our ﬁnd-
ings corroborate or refute theirs. We also summarize some more
distantly related works in Appendix C.
Malware encounter rate: The 2013 Microsoft Security Intelli-
gence Report [12], involving over 600 million hosts installed with
Microsoft security products in the ﬁrst half of 2013, reported a
worldwide malware encounter rate of around 18%. Our enterprise
dataset, consisting of 62,884 hosts instrumented with the McAfee
client collected over four months, has a similar encounter rate of
15.31%. On average, our encounter rate during any week is 1.26%.
Other smaller datasets consisting of network packet captures ex-
hibit a similar encounter rate to ours. Maier et al. [10] found, over
a period of 14 days, that 1.23% of the users subscribed to an Eu-
ropean ISP exhibited scanning or spamming behavior or contacted
known malware sites. Carlinet et al. [4] observed 3.04% of the cus-
tomers of the Orange ISP in France generating trafﬁc that triggered
Snort alerts during the course of three hours.

User studies that surveyed or observed users showed a much
higher malware encounter rate. Among 295 university students
surveyed by Ngo and Paternoster [14], 46% reported encountering
malware at least once in the last year, while 38% of 50 participants
in a study by Lévesque et al. [9] were found to be infected over the
course of four months.

The lower encounter rate in our dataset compared to prior works
may be due to the network policies enforced in the enterprise.
A whitelist and blacklist are applied to outbound network con-
nections, and employees are not allowed by default to install
software on enterprise-managed hosts.
It is also possible that
Lévesque et al. and Ngo and Paternoster observe higher encounter
rates due to the populations they study (primarily students).
User Demographics: Ngo and Paternoster found that both age and
race are signiﬁcantly related to the likelihood of encountering mal-
ware, but not gender, marital status, or employment status. While
agreeing that those factors do not contribute to the risk of infection,
Lévesque et al. also found age to be irrelevant. The only signiﬁcant
factor they identiﬁed is technical expertise.

Our employee dataset does not include personal information
(age, gender, etc.), and obviously the users in our data were em-
ployed. That said, we did corroborate the observation that technical
expertise correlates with the likelihood of encountering malware.
User Behavior: Both Maier et al. and Ngo and Paternoster exam-
ined the relationship between the use of security products and mal-
ware encounters. The former found that neither the installation of
anti-virus scanners nor regular O/S and blacklist updates reduced
malicious activities. However, the latter found that having secu-
rity software led to a higher probability of encountering malware
(perhaps an artifact of the user study, as users would otherwise not
know that they were infected). The nature of our dataset prevents
us from observing hosts with varying software conﬁgurations, since
enterprise hosts are centrally conﬁgured and managed in our case.
One might expect that more exposure to the Internet would re-
sult in higher likelihood of malware encounters. This was the case

0.00.20.40.60.81.0FractionofHosts0.00.20.40.60.81.0Score(CDF)EncounteredMalwareNotEncounteredMalware10020004000600080001000012000IndexofHostsOrderedbyRiskScore0.10.20.30.40.5EncounterRateAllfeaturesDemographicVPNWeb1126in the studies of Carlinet et al. and Lévesque et al., as well as
of Canali et al. [3] in terms of trafﬁc volume and the number of
unique websites visited. It also holds true in our dataset. In ad-
dition, we ﬁnd some categories of websites to be correlated with
higher malware encounter rates than others, as did Carlinet et al.
and Lévesque et al., although the categories do not always agree.
Canali et al., on the other hand, use logistic regression to show
that browsing time, duration and number of distinct domains are
better indicators of a user being at risk than the domain category.
However, their deﬁnition of at risk is laxer and does not rely on
documented malware encounters.

6. LIMITATIONS

By the nature of the data available to us, our conclusions are
subject to a number of caveats. Perhaps most importantly, since
we relied on McAfee reports to indicate malware encounters, our
results do not reﬂect any potential encounters detected and elim-
inated prior to reaching McAfee analysis—e.g., by ﬁrewalls/IPS,
web browsers, or any of the other myriad security defenses com-
monly employed in IT infrastructure or leveraged by this enterprise
in particular—or that reached McAfee but evaded it.
It is well
known that no anti-virus solution detects all malware; at best, it
identiﬁes a large fraction of “mass-market” malware. As such, we
assume that our encounters are biased toward mass-market mal-
ware that entered the enterprise via poorly defended vectors.

Another caveat related to our data is that we do not have ground
truth for many aspects of our investigation, requiring us to lever-
age indirect indicators, instead. So, for example, we used McAfee
reporting delays to infer whether each malware encounter occurred
while the computer was on the corporate network (Section 3.2), and
we leveraged job titles as a surrogate for an objective measure of
technical proﬁciency (Section 3.3). It is important to bear in mind
that all such inferences come with a level of error to them, though
our belief is that the relatively large amount of data in our study
provides some statistical evidence for the correlations that we ob-
serve.

Unknowns will be a factor in virtually any study of this type,
introducing questions about the extent to which any single study—
including this one—will be representative more broadly. We be-
lieve that it is necessary to assemble a broad set of such studies to
reveal their common elements and differences. (We have attempted
to draw out such similarities and differences with other studies in
Section 5.) Only through repetition can lasting trends be identiﬁed.

7. RECOMMENDATIONS FOR THE EN-

TERPRISE

Our study suggests recommendations for reducing the rate of

malware encounters in enterprise settings:
Proactive scanning, alert prioritization. Enterprises often deploy
memory analysis tools on hosts. As use of these tools is labor-
intensive, they must be deployed selectively. Our logistic regres-
sion model identiﬁes hosts with a highly elevated risk of malware
encounters (51% among the top 1,000 such hosts). This allows
an enterprise to apply memory-scanning tools proactively, facili-
tating early detection of malware infection. Similarly, an enterprise
can prioritize investigation of alerts (e.g., generated by log-analysis
tools) based on modeled host risk.
User education. User education has the potential to reduce behav-
iors responsible for a signiﬁcant fraction of malware encounters.
A number of studies have afﬁrmed the successes of carefully tar-
geted educational campaigns, e.g., [7]. Our study highlights several

opportunities for such targeting, e.g., educating users in low GDP
countries to avoid the use of USB sticks with company laptops.
Caution with site categories. In the studied enterprise, most web-
based malware encounters permitted by the web proxy originate
from sites categorized as business-appropriate under enterprise pol-
icy. This suggests that currently deployed website content cate-
gories are an inadequate basis for access restrictions. Tightening
access policies by, e.g., reﬁning website categories and/or applying
per-user (or per-group) rules, may reduce web-based encounters.

Understanding the practical implications and effectiveness of
any recommendation would require in-ﬁeld studies, and likely dif-
fer across enterprises based on their policies and compliance re-
quirements. We hope our study will motivate future research in
these areas.

8. CONCLUSION

We have presented the ﬁrst large-scale epidemiological study of
malware encounters in the setting of a large enterprise. Our study
offers several key ﬁndings, including the preponderance of mal-
ware encounters outside the enterprise network, differences across
geographies in the most important vectors of malware propagation,
differences in encounter rates according to employee position in
the management hierarchy, and a signiﬁcant risk of web-based mal-
ware encounters that originated with sites categorized as safe and
business-appropriate by the enterprise web proxy. While our study
corroborates some ﬁndings in earlier research, it also sheds new
light on the special characteristics of enterprise malware penetra-
tion and shows how these characteristics can be combined in a lo-
gistic regression model to achieve accurate identiﬁcation of at-risk
hosts. Finally, our study suggests promising, concrete policy- and
education-based approaches to driving down malware encounter
rates in enterprise environments.

Acknowledgments
We are grateful to the anonymous enterprise who permitted us ac-
cess to their data for the purposes of this study. We are also grate-
ful to James Lugabihl, Robin Norris, Todd Leetham, Christopher
Harrington, Garrett Schubert, Justin Lamarre, Andrew Rutkiewicz,
Michael Blanchard, Ronald L. Rivest and members of RSA Labo-
ratories for their many useful comments and suggestions on design-
ing the experimental framework in the paper. We thank our shep-
herd Davide Balzarotti and anonymous reviewers for their feedback
on drafts of this paper. This work was supported in part by NSF
grant 0831245.

9. REFERENCES
[1] “epidemiology”. In Merriam-Webster.com, 15 May 2014.
[2] J. Caballero, C. Grier, C. Kreibich, and V. Paxson.

Measuring pay-per-install: The commoditization of malware
distribution. In 20th USENIX Security Symposium, Aug.
2011.

[3] D. Canali, L. Bilge, and D. Balzarotti. On the effectiveness
of risk prediction based on users browsing behavior. In 9th
ACM Symposium on Information, Computer and
Commmunications Security, June 2014.

[4] Y. Carlinet, L. Mé, H. Debar, and Y. Gourhant. Analysis of
computer infection risk factors based on customer network
usage. In 2nd International Conference on Emerging
Security Information, Systems and Technologies, pages
317–325, Aug. 2008.

1127[5] M. P. Collins, T. J. Shimeall, S. Faber, J. Janies, R. Weaver,

M. De Shon, and J. B. Kadane. Using uncleanliness to
predict future botnet addresses. In 7th ACM Internet
Measurement Conference, pages 93–104, Oct. 2007.

[6] A. Kleiner, P. Nicholas, and K. Sullivan. Linking
Cybersecurity Policy and Performance. Microsoft
Trustworthy Computing, 2013.

[7] M. W. Kreuter and R. J. Wray. Tailored and targeted health

communication: Strategies for enhancing information
relevance. American Journal of Health Behavior,
27:S227–S232(6), November 2003.

[8] M. Lee. Who’s next? identifying risks factors for subjects of

targeted attacks. In Proc. Virus Bull. Conf, pages 301–306,
2012.

[9] F. Lévesque, J. Nsiempba, J. M. Fernandez, S. Chiasson, and

A. Somayaji. A clinical study of risk factors related to
malware infections. In 20th ACM Conference on Computer
and Communications Security, Nov. 2013.

[10] G. Maier, A. Feldmann, V. Paxson, R. Sommer, and

M. Vallentin. An assessment of overt malicious activity
manifest in residential networks. In Detection of Intrusion
and Malware, and Vulnerability Assessment, 8th
International Conference, pages 144–163, July 2011.

[11] Microsoft. Security Intelligence Report.

http://www.microsoft.com/security/sir/default.aspx, 2011.

[12] Microsoft. Security Intelligence Report.

http://www.microsoft.com/security/sir/default.aspx, 2013.
[13] G. R. Milne, L. I. Labrecque, and C. Cromer. Toward and
understanding of the online consumer’s risky behavior and
protection practices. Journal of Consumer Affairs,
43:449–473, 2009.

[14] F. T. Ngo and R. Paternoster. Cybercrime victimization: An

examination of individual and situational level factors.
International Journal of Cyber Criminology, 5(1):773–793,
2011.

[15] K. Onarlioglu, U. O. Yilmaz, E. Kirda, and D. Balzarotti.

Insights into user behavior in dealing with internet attacks. In
Network and Distributed System Security Symposium
(NDSS), 2012.

[16] A. Ramachandran and N. Feamster. Understanding the

network-level behavior of spammers. In 2006 ACM
SIGCOMM, pages 291–302, Sept. 2006.

[17] S. Sheng, M. Holbrook, P. Kumaraguru, L. F. Cranor, and
J. Downs. Who falls for phish? A demographic analysis of
phishing susceptibility and effectiveness of interventions. In
ACM Conference on Human Factors in Computing Systems,
pages 373–382, Apr. 2010.

[18] D. Sounthiraraj, J. Sahs, G. Greenwood, Z. Lin, and L. Khan.

Smv-hunter: Large scale, automated detection of ssl/tls
man-in-the-middle vulnerabilities in android apps. In 2014
NDSS Symposium, 2014.

[19] Symantec Corporation. Internet security threat report.

http://www.symantec.com/content/en/us/
enterprise/other_resources/b-istr_
appendices_v18_2012_221284438.en-us.pdf,
2013.

[20] M. Vasek and T. Moore. Identifying risk factors for

webserver compromise. Financial Cryptography and Data
Security, 2014.

[21] Y. Xie, F. Yu, K. Achan, R. Panigrahy, G. Hulten, and

I. Osipkov. Spamming botnets: Signatures and

characteristics. In 2008 ACM SIGCOMM, pages 171–182,
Aug. 2008.

[22] J. Zhang, Z. Durumeric, M. Bailey, M. Liu, and M. Karir. On
the mismanagement and maliciousness of networks. In 2014
NDSS Symposium, 2014.

APPENDIX
A. MALWARE TYPE

According to McAfee’s virus naming convention,9 malware
names consist of a preﬁx and sufﬁx. The preﬁx speciﬁes the type
of ﬁle or platform the malware targets (e.g., JS, PDF, W32), or its
“class” (e.g., Adware, Backdoor, Exploit, KeyLog). The sufﬁx(es)
designate variants of a malware, the byte size of the binary, or addi-
tional information about its type. In our McAfee dataset, there are
9,577 unique malware names. By stripping away the sufﬁx we are
left with 1,097 unique malware names.

The top two malware names, encountered by 5.47% and 1.73%
of the hosts, respectively, are “Artemis” and “Generic.” The for-
mer is not a malware family, but McAfee’s name for those detected
heuristically. The latter seems to be a generic detection that lacks
addition information. Excluding these two, the encounter rates of
the top 20 malware are shown in Figure 12. The shading of the
boxes denote the encounter rate for that malware in that country.
Rows (and columns) are sorted according to a hierarchical cluster-
ing algorithm to minimize the Euclidean distance between adjacent
rows (and columns).

Figure 12: The encounter rate in each country for the top 20 mal-
ware. The top ten countries with the most number of malware-
encountering hosts are plotted.

Some patterns emerge from Figure 12. First, the malware en-
countered differs by geographic location. Some can be found in
all countries (e.g., ”RDN/Generic,” “Generic Downloader”), while
others are speciﬁc to certain locations (e.g., Autorun malware and
worms in India and Egypt, and exploits in Western countries). Sec-
ondly, the diversity of malware in each country varies widely. Hosts
in India encountered more than 300 different malware, while those
in the U.K. only encountered 72. This suggests that the difference
in the encounter rate per country may be partially due to the abun-
dance of malware, and the types of malware, in that region.

To gain further insight about the categories of malware, we lever-
age the “class” information assigned by McAfee. The class key-
word, e.g., Adware, Backdoor, Exploit, when available, is included
in the preﬁx of the malware name. We ﬁnd the malware class
present in around 29.23% of the McAfee reports. Figure 13 shows
the encounter rate of each malware class in each country.

9http://download.nai.com/products/datfiles/
4.x/nai/readme.txt

IndiaIrelandGermanyUKUSBrazilIsraelEgyptChinaS.KoreaZeroAccessJS/Exploit-StykitExploit-CVE2012-1723NewAutorunGenericPWSRDN/GenericDownloaderRDN/GenericBackDoorPWS-ZbotRDN/GenericExploitRDN/GenericDropperExploit-PDF.rtW32/ConﬁckerBlacoleJS/ExploitVBS/Autorun.wormGenericDownloaderExploit-CVE2010-2568W32/SalityW32/Autorun.wormRDN/Generic0.0000.0080.0160.0240.0320.0400.0480.0560.0641128directory for Java.

• Java: The ﬁle has a “.class” extension, or found in the system
• System: The ﬁle was found in the Windows system folder (e.g.,
“C:\Windows\System). This can also be indicative of sec-
ondary downloads performed by an initial infection.
• Program ﬁles: The ﬁle was found under the “Program Files”
directory, which stores user-installed applications that are not
part of the O/S.

• Recycle: The ﬁle was found in the recycling bin.
• Backup:

The ﬁle was

restore points

“C:\System Volume Information,”

the O/S stores
E.g.,
“\Device\HarddiskVolumeShadowCopy.”

found in the directory where
recovery purposes.
or
• Network drives: The ﬁle was found on a network drive, i.e.,
• Unknown: File paths that do not match any of the above. Many

the path starts with two backslashes.

for

of these ﬁles are found in directories created by the user.

C. ADDITIONAL RELATED WORK

In addition to the studies discussed in Section 5, several other
studies have been conducted that deserve mention, albeit while us-
ing different methodologies and providing less directly comparable
results.
Regional differences:
In a study of malware distributed via pay-
per-install services, Caballero et al. [2] witnessed families of mal-
ware preferentially delivered to the U.S. and Europe, and others
exclusively targeted to a single country. Kleiner et al. [6] exam-
ined the impact of socio-economic factors in a country or region on
malware infections. They also found countries that implement poli-
cies for investigating and prosecuting cybercrime offenses to have
a lower infection rate.
Internet-wide studies: Numerous studies have investigated the
characteristics of malware proliferation by studying trafﬁc sent by
apparently infected machines (scans, spam, denial-of-service pack-
ets, etc.) on the public Internet. For example, using the malicious
trafﬁc observed at the border of a large network, Collins et al. [5]
demonstrated the tendency of malware infections to cluster within
the same networks (identiﬁed by CIDR blocks) over time and how
this tendency can be used to predict where such infections will
likely occur in the future. Ramachandran and Feamster [16] and
Xie et al. [21] studied spam feeds to quantify, at the granularity
of autonomous systems, where spam bots most often arise; the
Xie et al. study further noted that the top ﬁve autonomous sys-
tems by this measure are all Internet service providers that offer
residential network access. Zhang et al. [22] also found that “mis-
managed” autonomous systems, such as those that have open DNS
resolvers, lack egress ﬁltering, allow untrusted HTTPS certiﬁcates,
etc., are more likely to be responsible for malicious activities.
User behavior: Also distantly related are ethnographic stud-
ies focused on other online behaviors and threats. For example,
Sheng et al. [17] used Mechanical Turk to evaluate how gender,
age, technical knowledge, risk perception for ﬁnancial investment,
and prior exposure to anti-phishing training impacted susceptibility
to phishing attacks in a role-playing exercise. Via an online survey
of 449 participants, Milne et al. [13] studied the relationships of
both participant self-efﬁcacy and demographics (e.g., age) to the
participants’ online behaviors. Lee [8] conducted an epidemiologi-
cal study in an academic environment and determined that the em-
ployees’ department and job type are indicative of their suscepti-
bility to targeted phishing attacks. In an academic study with 164
participants, Onarlioglu et al. [15] found that non-technical users
demonstrated an ability comparable to that of security experts in

Figure 13: The encounter rate of each malware class in each coun-
try. The top ten countries with the most number of malware-
encountering hosts are plotted.
The top malware class, “Exploit,” is encountered by 3.67% of the
hosts. It seems to be especially common in India, Brazil, and South
Korea, who share a similar makeup of malware classes. China
stands out as having the highest “Dropper” encounter rate, perhaps
due to the abundance of custom, free software available online in
that region.10
Findings: Malware types differ by geographic location, some tar-
geting speciﬁc regions while others are common to all countries.
Exploits are the most common malware class in our dataset, partic-
ularly prevalent in India, Brazil, and S. Korea. Droppers are mostly
found in China (possibly related to the abundance of custom, free
software available online in that region). Exploits primarily target
vulnerabilities in Javascript and Java, though a non-trivial fraction
of hosts also encountered PDF exploits and those targeting the Win-
dows Shell.

B. FILE SYSTEM LOCATION CATE-

GORIES

We group McAfee reports into the following categories, based

on the paths of detected malicious ﬁles:
• External drives: The ﬁle was found on high-lettered drives
(i.e., F and above) or is named “autorun.inf” located directly
in the root directory of the drive. Even though personal ma-
chines can have multiple internal, physical drives, enterprise-
owned PCs were placed under a relatively restrictive conﬁgu-
ration policy. All were shipped with identical conﬁgurations
except in special cases. Employees were also not given admin-
istrator privileges on their machines by default. As a result, the
vast majority of hosts have only drives C and D.
• Temporary ﬁles: The ﬁle was found under a temporary
folder in the application directory (e.g., “C:\Users\User
Name\AppData\Local\Temp”). This folder is commonly
used to store secondary downloads by an initial infection.
• Web cache: The ﬁle was found in the browser’s cache, e.g.,
in the “Temporary Internet Files” directory, or the
“cache” folder under the browser’s directory. In this case, the
malware likely arrived on the victim through drive-by down-
loads.

in the default

The ﬁle was found on the user’s desktop
or
folder storing downloaded ﬁles (e.g.,
“C:\Users\User Name\Downloads”). This is often as-
sociated with intentional downloads performed by the user.
• Application: The ﬁle was found under the applications data di-
rectory, which stores user-speciﬁc application information, in-
cluding conﬁguration ﬁles, default templates, etc. An example
directory path is “C:\Documents and Settings\User
Name\Application Data\.”

• Download:

10http://www.infosecurity-magazine.com/view/
35047/googlebacked-filesharing-service-spreads
-chinese-malware/

IndiaBrazilS.KoreaIsraelGermanyUKIrelandUSChinaEgyptExploitRansomAdClickerProcKillKeylogDropperFakeAVDownloaderBackDoorPasswordStealer0.0000.0080.0160.0240.0320.0400.0480.0560.0640.0721129averting frequently encountered threats, but performed poorly at
detecting more unusual and sophisticated ones.
Server compromises: Orthogonal to our study of host malware
encounters, Vasek and Moore [20] explored factors relating to the
compromise of web servers. Speciﬁcally, they quantiﬁed the rela-
tionship between compromise and the type of web server, type of
content management system (CMS), hosting country, and secure
administration practices demonstrated on the website using logistic
regression models.

D. EMPLOYEE JOB TYPES

In this section, we summarize each job type introduced in Sec-
tion 3.3, including the fraction of all users with that job type and a
brief description of the job type.
• Engineer (27.88%) Software engineers comprise 28% of the
employees under this job type, and systems engineers another
23%. These are followed by support engineers (16%), ser-
vice engineers (11%), quality engineers (8%). There are also
hardware engineers (2%), solutions engineers (1%), test engi-
neers (0.75%), ﬁeld engineers (0.54%), performance engineers
(0.36%), etc.
• Manager (19.32%) Account managers, which are under the
sales department, make up a quarter of the “manager” employ-
ees, and project, program, and product managers another quar-
ter. Engineering managers make up another 9% of the employ-
ees of this type, and customer service and tech support 5%.
• Specialist (6.52%) The majority or employees with this job
type (70%) are responsible for maintaining special hardware
and systems, or providing support for integrating products into
customer environments. Another 11% of the employees are as-
sociated with business operations, sales, and marketing.
• Analyst (4.67%) 55% of the employees with this job type
are business operations analysts or ﬁnancial and revenue ana-
lysts. There are also process operations (7%), engineering (6%),
maintenance (6%) analysts, and others that deal with processes,
inventory, supply chain, logistics.

partment, e.g., account, renewals, and sales representatives.

• Consultant (4.41%) About half of the employee with this job
type simply have “Consultant” as their job title, hence it is dif-
ﬁcult to determine their expertise. However, we do ﬁnd 15% of
the employees with this job type to be practice or advisory con-
sultants, 9% to be business consultants, and 7% to be technical
consultants.
• Director (3.17%) Directors are typically a level up from man-
agers, and span across all business units in the enterprise. 18%
of the employees with this job type are in sales or marketing,
16% in business and products, 15% in engineering.
• Architect (2.81%) 84% of the employees of this type are So-
lutions Architects, who are primarily responsible for designing
and integrating hardware and software systems. Another 9% of
the employees of this job type simply have “Architect” as their
job title. There are also technology, application, information,
data, storage, and network architects.
• Representative (1.58%) These employees are in the sales de-
• Technician (1.40%) 45% of the employees with this job type
are either test or debug technicians, 12% are engineering tech-
nicians, and 11% are customer support technicians. Employees
with this job type appear to deal mostly with hardware systems
rather than software.
• Administrator (1.15%) 41% of the employees with this job
type are system administrators, 22% are storage or database ad-
ministrators. There are also contract administrators (6%), dis-
trict administrators (5%), account administrators (3%).
• Coordinator (1.12%) These employees deal with logistics and
processes in the company. 30% of employees of this job type
are program or project coordinators, 21% are distribution coor-
dinators, 12% are human resources coordinators, and 11% are
inventory coordinators.
• Assistant (1.07%) 94% of employees with this job type are ex-
ecutive and administrative assistants that support administrative
duties in the ofﬁce. There is also a small fraction of legal assis-
tants, marketing assistants, and sales assistants.

1130