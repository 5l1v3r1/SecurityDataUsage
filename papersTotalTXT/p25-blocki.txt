GOTCHA Password Hackers!∗

Jeremiah Blocki

Carnegie Mellon University

5000 Forbes Avenue
Pittsburgh, PA 15213
jblocki@cs.cmu.edu

Manuel Blum

Carnegie Mellon University

5000 Forbes Avenue
Pittsburgh, PA 15213

mblum@cs.cmu.edu

Anupam Datta

Carnegie Mellon University

5000 Forbes Avenue
Pittsburgh, PA 15213

danupam@cmu.edu

ABSTRACT
We introduce GOTCHAs (Generating panOptic Turing Tests
to Tell Computers and Humans Apart) as a way of pre-
venting automated oﬄine dictionary attacks against user
selected passwords. A GOTCHA is a randomized puzzle
generation protocol, which involves interaction between a
computer and a human.
Informally, a GOTCHA should
satisfy two key properties: (1) The puzzles are easy for the
human to solve. (2) The puzzles are hard for a computer
to solve even if it has the random bits used by the com-
puter to generate the ﬁnal puzzle — unlike a CAPTCHA
[44]. Our main theorem demonstrates that GOTCHAs can
be used to mitigate the threat of oﬄine dictionary attacks
against passwords by ensuring that a password cracker must
receive constant feedback from a human being while mount-
ing an attack. Finally, we provide a candidate construction
of GOTCHAs based on Inkblot images. Our construction re-
lies on the usability assumption that users can recognize the
phrases that they originally used to describe each Inkblot
image — a much weaker usability assumption than previous
password systems based on Inkblots which required users
to recall their phrase exactly. We conduct a user study to
evaluate the usability of our GOTCHA construction. We
also generate a GOTCHA challenge where we encourage ar-
tiﬁcial intelligence and security researchers to try to crack
several passwords protected with our scheme.

Categories and Subject Descriptors
K.6.5 [Computing Milieux]: Security and Protection—
Authentication

∗
This work was partially supported by the NSF Science and
Technology TRUST and the AFOSR MURI on Science of
Cybersecurity. The ﬁrst author was also partially supported
by an NSF Graduate Fellowship.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
AISec’13, November 4, 2013, Berlin, Germany.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2488-5/13/11 ...$15.00.
http://dx.doi.org/10.1145/2517312.2517319

Keywords
Human Authentication; Passwords; GOTCHA; Inkblots; Of-
ﬂine Dictionary Attack; CAPTCHA; HOSP

1.

INTRODUCTION

Any adversary who has obtained the cryptographic hash
of a user’s password can mount an automated brute-force at-
tack to crack the password by comparing the cryptographic
hash of the user’s password with the cryptographic hashes
of likely password guesses. This attack is called an oﬄine
dictionary attack, and there are many password crackers
that an adversary could use [18]. Oﬄine dictionary at-
tacks against passwords are — unfortunately — powerful
and commonplace [26]. Adversaries have been able to com-
promise servers at large companies (e.g., Zappos, LinkedIn,
Sony, Gawker [5, 2, 9, 4, 1, 3]) resulting in the release of mil-
lions of cryptographic password hashes 1. It has been repeat-
edly demonstrated that users tend to select easily guessable
passwords [28, 19, 12], and password crackers are able to
quickly break many of these passwords[40]. Oﬄine attacks
are becoming increasingly dangerous as computing hardware
improves — a modern GPU can evaluate a cryptographic
hash function like SHA2 about 250 million times per sec-
ond [50] — and as more and more training data — leaked
passwords from prior breaches — becomes available [26].
Symantec reported that compromised passwords have sig-
niﬁcant economic value to an adversary (e.g., compromised
passwords are sold on black market for between $4 and $30
) [23].

HOSPs (Human-Only Solvable Puzzles) were suggested by
Canetti, Halevi and Steiner as a way of defending against of-
ﬂine dictionary attacks [15]. The basic idea is to change the
authentication protocol so that human interaction is required
to verify a password guess. The authentication protocol be-
gins with the user entering his password. In response the
server randomly generates a challenge — using the pass-
word as a source of randomness — for the user to solve.
Finally, the server appends the user’s response to the user’s
password, and veriﬁes that the hash matches the record on
the server. To crack the user’s password oﬄine the adver-
sary must simultaneously guess the user’s password and the
answer to the corresponding puzzle. The challenge should
be easy for a human to solve consistently so that a legiti-
mate user can authenticate. To mitigate the threat of an
oﬄine dictionary attack the HOSP should be diﬃcult for a

1In a few of these cases [3, 1] the passwords were stored in
the clear.

25computer to solve — even if it has all of the random bits
used to generate the challenge.

The basic HOSP construction proposed by Canetti et al.
[15] was to to ﬁll a hard drive with regular CAPTCHAs (e.g.,
distorted text) by storing the puzzles without the answers.
This solution only provides limited protection against an ad-
versary because the number of unique puzzles that can be
generated is bounded by the size of the hard drive (e.g., the
adversary could pay people to solve all of the puzzles on the
hard drive). See the full version of this paper for more dis-
cussion[11]. Finding a usable HOSP construction which does
not rely on a very large dataset of pregenerated CAPTCHAs
is an open problem. Several candidate HOSPs were exper-
imentally tested [16] (they are called POSHs in the second
paper), but the usability results were underwhelming.

Contributions.

We introduce a simple modiﬁcation of HOSPs that we call
GOTCHAs (Generating panOptic Turing Tests to Tell Com-
puters and Humans Apart). We use the adjective Panoptic
to refer to a world without privacy — there are no hidden
random inputs to the puzzle generation protocol. The basic
goal of GOTCHAs is similar to the goal of HOSPs — de-
fending against oﬄine dictionary attacks. GOTCHAs diﬀer
from HOSPs in two ways (1) Unlike a HOSP a GOTCHA
may require human interaction during the generation of the
challenge. (2) We relax the requirement that a user needs
to be able to answer all challenges easily and consistently.
If the user can remember his password during the authen-
tication protocol then he will only ever see one challenge.
We only require that the user must be able to answer this
challenge consistently. If the user enters the wrong password
during authentication then he may see new challenges. We
do not require that the user must be able to solve these chal-
lenges consistently because authentication will fail in either
case. We do require that it is diﬃcult for a computer to dis-
tinguish between the “correct” challenge and an “incorrect”
challenge. Our main theorem demonstrates that GOTCHAs
like HOSPs can be used to defend against oﬄine dictionary
attacks. The goal of these relaxations is to enable the design
of usable GOTCHAs.

We introduce a candidate GOTCHA construction based
on Inkblot images. While the images are generated ran-
domly by a computer, the human mind can easily imagine
semantically meaningful objects in each image. To generate
a challenge the computer ﬁrst generates ten inkblot images
(e.g., ﬁgure 1). The user then provides labels for each im-
age (e.g., evil clown, big frog). During authentication the
challenge is to match each inkblot image with the corre-
sponding label. We empirically evaluate the usability of our
inkblot matching GOTCHA construction by conducting a
user study on Amazon’s Mechanical Turk. Finally, we chal-
lenge the AI community to break our GOTCHA construc-
tion.

Organization.

The rest of the paper is organized as follows: We next dis-

cuss related work in section 1.1. We formally deﬁne GOTCHAs
in section 2 and formalize the properties that a GOTCHA
should satisfy. We present our candidate GOTCHA con-
struction in section 3, and in section 3.1 we demonstrate
how our GOTCHA could be integrated into an authentica-
tion protocol. We present the results from our user study

Figure 1: Randomly Generated Inkblot Image—An evil
clown?

in section 3.2, and in section 3.3 we challenge the AI and
security communities to break our GOTCHA construction.
In section 3.4 we prove that GOTCHAs like HOSPs can also
be used to design a password storage system which mitigates
the threat of oﬄine attacks. We conclude by discussing fu-
ture directions and challenges in section 4.
1.1 Related Work

Inkblots [43] have been proposed as an alternative way to
generate and remember passwords. Stubbleﬁeld and Simon
proposed showing the user ten randomly generated inkblot
images, and having the user make up a word or a phrase to
describe each image. These phrases were then used to build
a 20 character password (e.g., users were instructed to take
the ﬁrst and last letter of each phrase). Usability results
were moderately good, but users sometimes had trouble re-
membering their association. Because the Inkblots are pub-
licly available there is also a security concern that Inkblot
passwords could be guessable if diﬀerent users consistently
picked similar phrases to describe the same Inkblot.

We stress that our use of Inkblot images is diﬀerent in two
ways: (1) Usability: We do not require users to recall the
word or phrase associated with each Inkblot. Instead we re-
quire user’s to recognize the word or phrase associated with
each Inkblot so that they can match each phrase with the
appropriate Inkblot image. Recognition is widely accepted
to be easier than the task of recall [7, 46]. (2) Security: We
do not need to assume that it would be diﬃcult for other
humans to match the phrases with each Inkblot. We only
assume that it is diﬃcult for a computer to perform this
matching automatically.

CAPTCHAs — formally introduced by Von Ahn et al.
[44] — have gained widespread adoption on the internet to
prevent bots from automatically registering for accounts. A
CAPTCHA is a program that generates a puzzle — which
should be easy for a human to solve and diﬃcult for a com-
puter to solve — as well as a solution. Many popular forms
of CAPTCHAs (e.g., reCAPTCHA [45]) generate garbled
text, which is easy 2 for a human to read, but diﬃcult for
a computer to decipher. Other versions of CAPTCHAs rely
on the natural human capacity for audio [38] or image recog-
nition [20].

2Admitedly some people would dispute the use of the label
‘easy.’

26CAPTCHAs have been used to defend against online pass-
word guessing attacks — users are sometimes required to
solve a CAPTCHA before signing into their account. An
alternative approach is to lock out a user after several incor-
rect guesses, but this can lead to denial of service attacks
[17]. However, if the adversary has access to the crypto-
graphic hash of the user’s password, then he can circum-
vent all of these requirements and execute an automatic
dictionary attack to crack the password oﬄine. By contrast
HOSPs — proposed by Canetti et al.[15] — were proposed to
defend against oﬄine attacks. HOSPs are in some ways sim-
ilar to CAPTCHAs (Completely Automated Turing Tests to
Tell Computers and Humans Apart) [44]. CAPTCHAs are
widely used on the internet to ﬁght spam by preventing bots
from automatically registering for accounts. In this setting
a CAPTCHA is sent to the user as a challenge, while the
secret solution is used to grade the user’s answer. The im-
plicit assumption is that the answer and the random bits
used to generate the puzzle remain hidden — otherwise a
spam bot could simply regenerate the puzzle and the an-
swer. While this assumption may be reasonable in the spam
bot setting, it does not hold in our oﬄine password attack
setting in which the server has already been breached. A
HOSP is diﬀerent from a CAPTCHA in several key ways:
(1) The challenge must remain diﬃcult for a computer to
solve even if the random bits used to generate the puzzle
are made public. (2) There is no single correct answer to a
HOSP. It is okay if diﬀerent people give diﬀerent responses
to a challenge as long as people can respond to the challenges
easily, and each user can consistently answer the challenges.
The only HOSP construction proposed in [15] involved
stuﬃng a hard drive with unsolved CAPTCHAs. The prob-
lem of ﬁnding a HOSP construction that does not rely on a
dataset of unsolved CAPTCHAs was left as an open prob-
lem [15]. Several other candidate HOSP constructions have
been experimentally evaluated in subsequent work [16] (they
are called POSHs in the second paper), but the usability re-
sults for every scheme that did not rely on a large dataset
on unsolved CAPTCHAs were underwhelming.

GOTCHAs are very similar to HOSPs. The basic appli-
cation — defending against oﬄine dictionary attacks — is
the same as are the key tools: exploiting the power of inter-
action during authentication, exploiting hard artiﬁcial intel-
ligence problems. While the authentication with HOSPs is
interactive, the initial generation of the puzzle is not. By
contrast, our GOTCHA construction requires human inter-
action during the initial generation of the puzzle. This sim-
ple relaxation allows for the construction of new solutions.
In the HOSP paper humans are simply modeled as a puz-
zle solving oracle, and the adversary is assumed to have a
limited number of queries to a human oracle. We introduce
a more intricate model of the human agent with the goal of
designing more usable constructions.

Password Storage.

Password storage is an incredibly challenging problem.
Adversaries have been able to compromise servers at many
large companies (e.g., Zappos, LinkedIn, Sony, Gawker [5, 2,
9, 4, 1, 3]). For example, hackers were able to obtain 32 mil-
lion plaintext passwords from RockYou using a simple SQL
injection attack [1]. While it is considered an extremely poor
security practice to store passwords in the clear [42], the
practice is still fairly common [13, 3, 1]. Many other com-

panies [4, 13] have used cryptographic hashes to store their
passwords, but failed to adopt the practice of salting (e.g.,
instead of storing the cryptographic hash of the password
h(pw) the server stores (h (pw, r) , r) for a random string r
[6]) to defend against rainbow table attacks. Rainbow ta-
bles, which consist of precomputed hashes, are often used by
an adversary to signiﬁcantly speed up a password cracking
attack because the same table can be reused to attack each
user when the passwords are unsalted [34].

Cryptographic hash functions like SHA1, SHA2 and MD5
— designed for fast hardware computation — are popular
choices for password hashing. Unfortunately, this allows an
adversary to try up to 250 million guesses per second on a
modern GPU [50]. The BCRYPT [36] hash function was de-
signed speciﬁcally with passwords in mind — BCRYPT was
intentionally designed to be slow to compute (e.g., to limit
the power of an adversary’s oﬄine attack). The BCRYPT
hash function takes a parameter which allows the program-
mer to specify how costly the hash computation should be.
The downside to this approach is that it also increases costs
for the company that stores the passwords (e.g., if we want
it to cost the adversary $1,000 for every million guesses then
it will also cost the company at least $1,000 for every million
login attempts).

Users are often advised (or required) to follow strict guide-
lines when selecting their password (e.g., use a mix of up-
per/lower case letters, include numbers and change the pass-
word frequently) [39]. However, empirical studies show that
user’s are are often frustrated by restricting policies and
commonly forget their passwords [29, 30, 21] 3. Further-
more, the cost of these restrictive policies can be quite high.
For example, a Gartner case study [48] estimated that it cost
over $17 per password-reset call. Florencio and Herley [22]
studied the economic factors that institutions consider be-
fore adopting password policies and found that they often
value usability over security.

2. DEFINITIONS

In this section we seek to establish a theoretical basis for
GOTCHAs. Several of the ideas behind our deﬁnitions are
borrowed from theoretical deﬁnitions of CAPTCHAs [44]
and HOSPs [15]. Like CAPTCHAs and HOSPs, GOTCHAs
are based on the assumption that some AI problem is hard
for a computer to solve, but easy for a person to solve. Ul-
timately, these assumptions are almost certainly false (e.g.,
because the human brain can solve a GOTCHA it is rea-
sonable to believe that there exists a computer program to
solve the problems). However, it may still be reasonable
to assume that these problems cannot be solved by applying
known ideas. By providing a formal deﬁnition of GOTCHAs
we can determine whether or not a new idea can be used to
break a candidate GOTCHA construction.
We use c ∈ C to denote the space of challenges that
might be generated. We use H to denote the set of hu-
man users and H (c, σt) to denote the response that a hu-
man H ∈ H gives to the challenge c ∈ C at time t. Here,
σt denotes the state of the human’s brain at time t. σt is
supposed to encode our user’s existing knowledge (e.g., vo-
cabulary, experiences) as well as the user’s mental state at
time t (e.g., what is the user thinking about at time t). Be-

3In fact the resulting passwords are sometimes more vulner-
able to an oﬄine attack! [29, 30]

27cause σt changes over time (e.g., new experiences) we use
H (c) = {H (c, σt)
t ∈ N} to denote the set of all answers a
human might give to a challenge c. We use A to denote the
range of possible responses (answers) that a human might
give to the challenges.

The puzzle generation process for a GOTCHA involves
interaction between the human and a computer: (1) The
computer generates a set of k challenges. (2) The human
solves these challenges. (3) The computer uses the solutions
to produce a ﬁnal challenge 5. Formally,

Definition 1. Given a metric d : A × A → R, we say
that a human H can consistently solve a challenge c ∈ C
with accuracy α if ∀t ∈ N

d (H (c, σ0) , H (c, σt)) ≤ α ,

where σ0 denotes the state of the human’s brain when he
initially answers the challenge. If |H (c)| = 1 then we simply
say that the human can consistently solve the challenge.
Notation: When we have a group of challenges ⟨c1, . . . , ck⟩
we will sometimes write H (⟨c1, . . . , ck⟩, σt) =
⟨H (c1, σt) , . . . , H (ck, σt)⟩ for notational convenience. We
use y ∼ D to denote a random sample from the distribution
D, and we use r $← {0, 1}n to denote a element drawn from
the set {0, 1}n uniformly at random.

One of the requirements of a HOSP puzzle system [15] is
that the human H must be able to consistently answer any
challenge that is generated (e.g., ∀c ∈ C, H can consistently
solve c). These requirements seem to rule out promising
ideas for HOSP constructions like Inkblots[16]. In this con-
struction the challenge is a randomly generated inkblot im-
age I, and the response H (I, σ0) is word or phrase describing
what the user initially sees in the inkblot image (e.g., evil
clown, soldier, big lady with a ponytail). User studies have
shown that H (I, σ0) does not always match H (I, σt) — the
phrase describing what the user sees at time t [16].
In a
few cases the errors may be correctable (e.g., capitalization,
plural/singular form of a word), but oftentimes the phrase
was completely diﬀerent — especially if a long time passed
in between trials 4. By contrast, our GOTCHA construction
does not require the user to remember the phrases associ-
ated with each Inkblot. Instead we rely on a much weaker
assumption — the user can consistently recognize his solu-
tions. We say that a human can recognize his solutions to
a set of challenges if he can consistently solve a matching
challenge (deﬁnition 2) in which he is asked to match each
of his solutions with the corresponding challenge.

Definition 2. Given an integer k, and a permutation π :
[k] → [k], a matching challenge ˆc(cid:25) = (⃗c, ⃗a) ∈ C of size k is
given by a k-tuple of challenges ⃗c = ⟨c(cid:25)(1), . . . , c(cid:25)(k)⟩ ∈ Ck
and solutions ⃗a = H (⟨c1, . . . , ck⟩, σ0). The response to a
matching challenge is a permutation π

= H (⃗c(cid:25), σt).

′

For permutations π : [k] → [k] we use the distance metric

dk (π1, π2) = |{i π1(i) ̸= π2(i) ∧ 1 ≤ i ≤ k}| .

dk (π1, π2) simply counts the number of entries where the
permutations don’t match. We say that a human can consis-
tently recognize his solution to a matching challenge ˆc(cid:25) with
accuracy α if ∀t.dk (H (ˆc(cid:25), σt) , π) ≤ α. We use {π
′
α} to denote the set of permutations π
π.
4We would add the requirement that the human must be
able to consistently answer the challenges without spending
time memorizing and rehearsing his response to the chal-
lenge. Otherwise we could just as easily force the user to
remember a random string to append on to his password.

that are α-close to

dk (π, π

′

′

) ≤

Definition 3. A puzzle-system is a pair (G1, G2), where
(
)
G1 is a randomized challenge generator that takes as in-
put 1k (with k security parameter) and a pair of random bit
strings r1, r2 ∈ {0, 1}∗
and outputs k challenges ⟨c1, . . . , ck⟩ ←
1k, r1, r2
(
)
. G2 is a randomized challenge generator that
G1
takes as input 1k (security parameter), a random bit string
)
(
r1 ∈ {0, 1}∗
, and proposed answers ⃗a = ⟨a1, ..., ak⟩ to the
challenges G1
ˆc ← G2
usable if
(

. We say that the puzzle-system is (α, β)-
(
[Accurate (H, ˆc, α)] ≥ β ,

and outputs a challenge

1k, r1, r2

1k, r1, ⃗a

Pr
$←H

)

)

H

whenever ⃗a = H
denotes the event that the human H can consistently solve ˆc
with accuracy α.

, where Accurate (H, ˆc, α)

, σ0

G1

1k, r1, r2

In our authentication setting the random string r1 is ex-
tracted from the user’s password using a strong pseudoran-
dom function Extract. To provide a concrete example of a
puzzle-system, G1 could be a program that generates a set of
inkblot challenges ⟨I1, . . . , Ik⟩ using random bits r1, selects
a random permutation π : [k] → [k] using random bits r2,
and returns ⟨I(cid:25)(1), . . . , I(cid:25)(k)⟩. The human’s response to an
Inkblot — H (Ij, σ0) — is whatever he/she imagines when he
sees the inkblot Ij for the ﬁrst time (e.g., some people might
imagine an evil clown when they look at ﬁgure 1). Finally,
G2 might generate Inkblots ⃗c = ⟨I1, . . . , Ik⟩ using random
bits r1, and return the matching challenge ˆc(cid:25) = (⃗c, ⃗a). In
this case the matching challenge is for the user to match his
labels with the appropriate Inkblot images to recover the
permutation π. Observe that the ﬁnal challenge — ˆc(cid:25) —
can only be generated after a round of interaction between
the computer and a human. By contrast, the challenges in
a HOSP must be generated automatically by a computer.
Also notice that if G2 is executed with a diﬀerent random
′
bit string r
1 then we do not require the resulting challenge
to be consistently recognizable (e.g., if the user enters in the
wrong password then authentication will fail regardless of
how he solves the resulting challenge). For example, if the
user enters the wrong password the user might be asked to
match his labels ⟨ℓ(cid:25)(1), ..., ℓ(cid:25)(k)⟩ = H
with Inkblots ⟨I

(⟨I(cid:25)(1), . . . , I(cid:25)(k)⟩, σ0

⟩ that he has never seen.

′
1, . . . , I

)

′
k

An adversary could attack a puzzle system by either (1)
attempting to distinguish between the correct puzzle, and
puzzles that might be meaningless to the human, or (2) by
solving the matching challenge directly.
D1 and D2 with advantage ϵ if
[A (x) = 1] − Pr
y∼D2

We say that an algorithm A can distinguish distributions

(cid:12)(cid:12)(cid:12)(cid:12) ≥ ϵ .

(cid:12)(cid:12)(cid:12)(cid:12) Pr

[A (y) = 1]

x∼D1

Our formal deﬁnition of a GOTCHA is found in deﬁni-
tion 4. Intuitively, deﬁnition 4 says that (1) The underlying
5We note that a HOSP puzzle system (G) [15] can be mod-
eled as a GOTCHA puzzle system (G1, G2) where G1 does
nothing and G2 simply runs G to generate the ﬁnal challenge
ˆc directly.

28}

$← {0, 1}n
}

{

and

D4 =

puzzle-system should be usable — so that legitimate users
can authenticate. (2) It should be diﬃcult for the adversary
to distinguish between the correct matching challenge (e.g.,
the one that the user will see when he types in the cor-
rect password), and an incorrect matching challenge (e.g.,
if the user enters the wrong password he will be asked to
match his labels with diﬀerent Inkblot images), and (3) It
should be diﬃcult for the adversary to distinguish between
the user’s matching, and a random matching drawn from a
distribution R with suﬃciently high minimum entropy.

Definition 4. A puzzle-system (G1, G2) is an (α, β, ϵ, δ, µ)-

GOTCHA if (1) (G1, G2) is (α, β)-usable (2) Given a hu-
man H ∈ H no probabilistic polynomial time algorithm can
}
distinguish between distributions

H(G1(1k;r1;r2);(cid:27)0);

G2(1k;r1;H(G1(1k;r1;r2);(cid:27)0))

$← {0, 1}n

r1, r2

r1, r2, r3

H(G1(1k;r1;r2);(cid:27)0);

$← {0, 1}n

G2(1k;r3;H(G1(1k;r1;r2);(cid:27)0))

and
D2 =
with advantage greater than ϵ, and (3) Given a human H ∈
H, there is a distribution R(c) with µ(m) bits of minimum
}
entropy such that no probabilistic polynomial time algorithm
can distinguish between distributions
D3 =

G2(1k;r1;H(G1(1k;r1;r2);(cid:27)0));

H(G1(1k;r1;r2);(cid:27)0)

{

r1, r2

H(G2(1k;r1;H(G1(1k;r1;r2);(cid:27)0));(cid:27)0)

{
D1 =
{

H(G1(1k;r1;r2);(cid:27)0)

G2(1k;r1;H(G1(1k;r1;r2);(cid:27)0));
R(G2(1m;r1;⟨a1;:::;am⟩);(cid:27)0)

$← {0, 1}n

r1, r2

with advantage greater then δ.
2.1 Password Storage and Ofﬂine Attacks

To protect users in the event of a server breach organiza-
tions are advised to store salted password hashes — using
a cryptographic hash function (h : {0, 1}∗ → {0, 1}n) and
a random bit string (s ∈ {0, 1}∗
) [39]. For example, if a
user (u) chose the password (pw) the server would store
the tuple (u, s, h (s, pw)). Any adversary who has obtained
(u, s, h (s, pw)) (e.g., through a server breach) may mount a
— fully automated — oﬄine dictionary attack using pow-
erful password crackers like John the Ripper [18]. To verify
a guess pw
) and
checks to see if this hash matches h (s, pw).

the adversary simply computes h (s, pw

′

′

We assume that an adversary Adv who breaches the server

can obtain the code for h, as well as the code for any GOTCHAs
used in the authentication protocol. Given the code for h
and the salt value s the adversary can construct a function

{

(

′)

VerifyHash

pw

=

1

0

if h (s, pw) = h (s, pw

′

)

otherwise.

.

We also allow the adversary to have black box access to
a GOTCHA solver (e.g., a human). We use cH to denote
the cost of querying a human and ch to denote the cost of
querying the function VerifyHash6, and we use nH (resp.
6The value of ch may vary widely depending on the par-
ticular cryptographic hash function — it is inexpensive to
evaluate SHA1, but BCRYPT [36] may be very expensive
to evaluate.

nh) to denote the number of queries to the human (resp.
VerifyHash). Queries to the human GOTCHA solver are
much more expensive than queries to the cryptographic hash
function (cH ≫ ch) [32]. For technical reasons we limit our
analysis to conservative adversaries.

Definition 5. We say that an adversary Adv is conser-
vative if (1) Adv uses the cryptographic hash function h
in a black box manner (e.g., the hash function h and the
stored hash value are only used to construct a subroutine
VerifyHash which is then used as a black box by Adv ),
(2) The pseudorandom function Extract is used as a black
box, and (3) The adversary only queries a human about chal-
lenges generated using a password guess.

It is reasonable to believe that our adversary is conservative.
All existing password crackers (e.g., [18]) use the hash func-
tion as a black box, and it is diﬃcult to imagine that the
adversary would beneﬁt by querying a human solver about
Inkblots that are unrelated to the password.

to denote a dictionary of likely guesses

We use D ⊆ {0, 1}∗

that the adversary would like to try,

Cost (Adv, D) = (nhch + nH cH )

to denote the cost of the queries that the adversary makes to
check each guess in D, and Succeed (Adv, D, pw) to denote
the event that the adversary makes a query to VerifyHash
that returns 1 (e.g., the adversary successfully ﬁnds the
user’s password pw). The adversary might use a computer
program to try to solve some of the GOTCHAs — to save
cost by not querying a human. However, in this case the ad-
versary might fail to crack the password because the GOTCHA
solver found the wrong solution to one of the challenges.

Definition 6. An adversary Adv is (C, γ, D)-successful

if Cost (Adv, D) ≤ C, and

[Succeed (Adv, D, pw)] ≥ γ .

Pr
$←D

pw

Our attack model is slightly diﬀerent from the attack
model in [15]. They assume that the adversary may ask
a limited number of queries to a human challenge solution
oracle. Instead we adopt an economic model similar to [10],
and assume that the adversary is instead limited by a budget
C, which may be used to either evaluate the cryptographic
hash function h or query a human H.

3.

INKBLOT CONSTRUCTION

Our candidate GOTCHA construction is based on Inkblots
images. We use algorithm 1 to generate inkblot images. Al-
gorithm 1 takes as input random bits r1 and a security pa-
rameter k — which speciﬁes the number of Inkblots to out-
put. Algorithm 1 makes use of the randomized subroutine
DrawRandomEllipsePairs (I, t, width, height) which draws
t pairs of ellipses on the image I with the speciﬁed width
and height. The ﬁrst ellipse in each pair is drawn at a ran-
dom (x, y) coordinate on the left half of the image with a
randomly selected color and angle α of rotation, and the sec-
ond ellipse is mirrored on the right half of the image. Figure
1 is an example of an Inkblot image generated by algorithm
1.

Our candidate GOTCHA is given by the pair (G1, G2)
— algorithms 2 and 3. G1 runs algorithm 1 to generate k

29Algorithm 1 GenerateInkblotImages

Input: Security Parameter 1k, Random bit string r1 ∈
{0, 1}∗
for j = 1, . . . , k do

.

Ij ← new Blank Image

◃ The
following operations only use the random bit string r1 as
a source of randomness

DrawRandomEllipsePairs (Ij, 150, 60, 60)
DrawRandomEllipsePairs (Ij, 70, 20, 20)
DrawRandomEllipsePairs (Ij, 150, 60, 20)

return ⟨I1, . . . , Ik⟩

◃ Inkblot Images

Inkblot images, and then returns these images in permuted
order — using a function
GenerateRandomPermutation (k, r), which generates a
random permutation π : [k] → [k] using random bits r. G2
also runs algorithm 1 to generate k Inkblot images, and then
outputs a matching challenge.

Security Parameter 1k, Random bit strings

Algorithm 2 G1
Input:
r1, r2 ∈ {0, 1}∗
⟨I1, . . . , Ik⟩ ← GenerateInkblotImages (k, r1)
π ← GenerateRandomPermutation (k, r2)
return ⟨I(cid:25)(1), . . . , I(cid:25)(k)⟩

.

After the Inkblots ⟨I(cid:25)(1), . . . , I(cid:25)(k)⟩ have been generated,
the human user is queried to provide labels ℓ(cid:25)(1), . . . , ℓ(cid:25)(k)
where

(⟨I(cid:25)(1), . . . , I(cid:25)(k)⟩, σ0

)

.

⟨ℓ(cid:25)(1), . . . , ℓ(cid:25)(k)⟩ = H

In our authentication setting the server would store the la-
bels ℓ(cid:25)(1), . . . , ℓ(cid:25)(k) in permuted order. The ﬁnal challenge
— generated by algorithm 3 — is to match the Inkblot im-
ages I1, . . . , Ik with the user generated labels ℓ1, ..., ℓk to
recover the permutation π.

Algorithm 3 GenerateMatchingChallenge G2

Input: Security Parameter 1k, Random bits r1 ∈ {0, 1}∗
and labels ⃗a = ⟨ℓ(cid:25)(1), . . . , ℓ(cid:25)(k)⟩.
⟨I1, . . . , Ik⟩ ← GenerateInkblotImages
return ˆc(cid:25) = (⃗c, ⃗a)

◃ Matching Challenge

1k, r1

(

)

Observation: Notice that if the random bits provided

as input to GenerateInkblotImages and
GenerateMatchingChallenge match that the user will
see the same Inkblot images in the ﬁnal matching challenge.
However, if the random bits do not match (e.g., because
the user typed the wrong password in our authentication
protocol) then the user will see diﬀerent Inkblot images. The
labels ℓ1, . . . , ℓk will be the same in both cases.
3.1 GOTCHA Authentication

To illustrate how our GOTCHAs can be used to defend
against oﬄine attacks we present the following authentica-
tion protocols: Create Account (protocol 3.1) and Au-
thenticate (protocol 3.2). Communication in both proto-
cols should take place over a secure channel. Both protocols
involve several rounds of interaction between the user and

the server. To create a new account the user sends his user-
name/password to the server, the server responds by gen-
erating k Inkblot images I1, . . . , Ik, and the user provides
a response ⟨ℓ1, . . . , ℓk⟩ = H (⟨I1, . . . , Ik⟩, σ0) based on his
mental state at the time — the server stores these labels in
7. To authenticate later the
permuted order ℓ(cid:25)(1), . . . , ℓ(cid:25)(k)
user will have to match these labels with the corresponding
inkblot images to recover the permutation π.

In section 3.4 we argue that the adversary who wishes to
mount a cost eﬀective oﬄine attack needs to obtain constant
feedback from a human. Following [15] we assume that the
function Extract : {0, 1}∗ → {0, 1}n is a strong random-
ness extractor, which can be used to extract random strings
from the user’s password. Recall that h : {0, 1}∗ → {0, 1}∗
denotes a cryptographic hash function.

Protocol 3.1: Create Account

Security Parameters: k, n.
(User): Select username (u) and password (pw) and send
(u, pw) to the server.
(
(Server): Sends Inkblots ⟨I1, . . . , Ik⟩ to the user where:
$← {0, 1}n and
Sends responses ⟨ℓ1, ..., ℓk⟩ back to the server

′ $← {0, 1}n, r1 ← Extract (pw, r
r
⟨I1, . . . , Ik⟩ ← GenerateInkblotImages

1k, r1

), r2

)

′

(User):
where:

⟨ℓ1, . . . , ℓk⟩ ← H (⟨I1, . . . , Ik⟩, σ0).

Store the tuple t where t is computed as

(Server):
follows:
Salt: s $← {0, 1}n
)
π ← GenerateRandomPermutation (k, r2).
hpw ← h (u, s, pw, π(1), ..., π(k))
, s, hpw, ℓ(cid:25)(1), . . . , ℓ(cid:25)(k)

t ←(

u, r

′

Protocol 3.2: Authenticate

′

Security Parameters: k, n.
Usability Parameter: α
(User): Send username (u) and password (pw
(
may or may not be correct.
(Server): Sends challenge ˆc to the user where ˆc is com-
puted as follows:
u, r
⟩ ← GenerateInkblotImages (r
′

ˆc(cid:25) ←(⟨I1, ..., Ik⟩,⟨ℓ(cid:25)(1), . . . , ℓ(cid:25)(k)⟩)

Find t =
1 ← Extract (pw
′
r
⟨I
′
′
1, ..., I
k

, s, hpw, ℓ(cid:25)(1), . . . , ℓ(cid:25)(k)

′
1, k)

) — pw

)

, r

)

′

′

′

′

= H (ˆc, σt).

(User): Solves ˆc(cid:25) and sends the answer π
(Server):
′
for all π0 s.t dk (π0, π
hpw;0 ← h (u, s, pw
′
if hpw;0 = hpw then

) ≤ α do
, π0(1), ..., π0(k))

Authenticate

Deny

Our protocol could be updated to allow the user to re-
ject challenges he found confusing during account creation

7For a general GOTCHA, protocol 3.1 would need to have an
extra round of communication. The server would send the
user the ﬁnal challenge generated by G2 and the user would
respond with H (G2 (, ) , σ0). Protocol 3.1 takes advantage
of the fact that π = H (G2 (, ) , σ0) is already known.

30in protocol 3.1. In this case the server would simply note
that the ﬁrst GOTCHA was confusing and generate a new
GOTCHA. Once our user has created an account he can
login by following protocol 3.2.

Claim 1 says that a legitimate user can successfully au-
thenticate if our Inkblot construction satisﬁes the usability
requirements of a GOTCHA. The proof of claim 1 can be
found in the full version [11].

Claim 1. If (G1, G2) is a (α, β, ϵ, δ, µ)-GOTCHA then at
least β-fraction of humans can successfully authenticate us-
ing protocol 3.2 after creating an account using protocol 3.1.

One way to improve usability of our authentication pro-
tocol is to increase the neighborhood of acceptably close
matchings by increasing α. The disadvantage is that the
running time for the server in protocol 3.2 increases with
the size of α. Claim 2 bounds the time needed to enumer-
ate over all close permuations. The proof of claim 2 can be
found in the full version[11].

Claim 2. For all permutations π : [k] → [k] and α ≥ 0

(cid:12)(cid:12){

′

π

(

′) ≤ α

}(cid:12)(cid:12) ≤ 1 +

dk

π, π

(

)

k
i

i! .

(cid:11)∑

i=2

For example, if the user matches k = 10 Inkblots and we
want to accept matchings that are oﬀ by at most α = 5 en-
tries then the server would need to enumerate over at most
36, 091 permutations8. Organizations are already advised to
use password hash functions like BCRYPT [36] which inten-
tionally designed to be slower than standard cryptographic
hash functions — often by a factor of millions. Instead of
making the hash function a million times slower to evaluate
the server might instead make the hash function a thousand
times slower to evaluate and use these extra computation
cycles to enumerate over close permutations. The orga-
nization’s trade-oﬀ is between: security, usability and the
resources that it needs to invest during the authentication
process.

We observe that an adversary mounting an online attack
would be naturally rate limited because he would need to
solve a GOTCHA for each new guess. Protocol 3.2 could
also be supplemented with a k-strikes policy — in which a
user is locked out for several hours after k incorrect login
attempts — if desired.
3.2 User Study

To test our candidate GOTCHA construction we con-
ducted an online user study9. We recruited participants
through Amazon’s Mechanical Turk to participate in our
study. The study was conducted in two phases. In phase
1 we generated ten random Inkblot images for each partici-
pant, and asked each participant to provide labels for their
Inkblot images. Participants were advised to use creative
titles (e.g., evil clown, frog, lady with poofy dress) because
they would not need to remember the exact titles that they
8A more precise calculation reveals that there are exactly
, π) ≤ 5 and a random
13, 264 permutations s.t.
would only be accepted with probability
permuation π
3.66 × 10
9Our study protocol was approved for exemption by the In-
stitutional Review Board (IRB) at Carnegie Mellon Univer-
sity (IRB Protocol Number: HS13-219).

d10 (π

−3

′

′

Phase 1 Phase 2

Average
StdDev

Max
Min

Average ≤ 20

9.3
9.6
57.5
1.4
6.2

4.5
3

18.5
1.6
N/A

Table 1: Completion Times
|{(cid:25)

# participants

′

′

)≤(cid:11)}|

d10((cid:25);(cid:25)

10!

α-
accurate

α = 0
α = 2
α = 3
α = 4
α = 5

#
partici-
pants
17
22
26
34
40

58

0.29
0.38
0.45
0.59
0.69

2.76 × 10
1.27 × 10
7.88 × 10
6.00 × 10
3.66 × 10

−7
−5
−5
−4
−3

Table 2: Usability Results: Fraction of Participants who
would have authenticated with accuracy parameter α

used. Participants were paid $1 for completing this ﬁrst
phase. A total of 70 users completed phase 1.

After our participants completed the ﬁrst phase we waited
ten days before asking our participants to return and com-
plete phase 2. During phase 2 we showed each participant
the Inkblot images they saw in phase 1 (in a random or-
der) as well as the titles that they created during phase 1
(in alphabetical order). Participants were asked to match
the labels with the appropriate image. The purpose of the
longer waiting time was to make sure that participants had
time to forget their images and their labels. Participants
were paid an additional $1 for completing phase 2 of the
user study. At the beginning of the user study we let par-
ticipants know that they would be paid during phase 2 even
if their answers were not correct. We adopted this policy to
discourage cheating (e.g., using screen captures from phase
1 to match the images and the labels) and avoid positively
biasing our results.

We measured the time it took each participant to complete
phase 1. Our results are summarized in table 1. It is quite
likely that some participants left their computer in the mid-
dle of the study and returned later to complete the study
(e.g., one user took 57.5 minutes to complete the study).
While we could not measure time away from the computer,
we believe that it is likely that at least 9 of our participants
left the computer. Restricting our attention to the other 61
participants who took at most 20 minutes we get an adjusted
average completion time of 6.2 minutes.

Fifty-eight of our participants returned to complete phase
2 by taking our matching test.
It took these participants
4.5 minutes on average to complete the matching test. Sev-
enteen of our participants correctly matched all ten of their
labels, and 69% of participants matched at least 5 out of ten
labels correctly. Our results are summarized in table 2.

Discussion.

Our user study provides evidence that our construction is
at least (0, 0.29)-usable or (5, 0.69)-usable. While this means
that our Inkblot Matching GOTCHA could be used by a
signiﬁcant fraction of the population to protect their pass-

31words during authentication it also means that the use of
our GOTCHA would have to be voluntary so that users who
have diﬃculty won’t get locked out of their accounts. An-
other approach would be to construct diﬀerent GOTCHAs
and allow users to choose which GOTCHA to use during
authentication.

Study Incentives: There is evidence that the lack of
monetary incentives to perform well on our matching test
may have negatively inﬂuenced the results (e.g., some par-
ticipants may have rushed through phase 1 of the study be-
cause their payment in round 2 was independent of their
ability to match their labels correctly). For example, none
of our 18 fastest participants during phase 1 matched all of
their labels correctly, and — excluding participants we be-
lieve left their computer during phase 1 (e.g., took longer
than 20 minutes) — on average participants who failed to
match at least ﬁve labels correctly took 2 minutes less time
to complete phase 1 than participants who did.

Time: We imagine that some web services may be re-
luctant to adopt GOTCHAs out of fear driving away cus-
tomers who don’t want to spend time labeling Inkblot im-
ages [22]. However, we believe that for many high security
applications (e.g., online banking) the extra security ben-
eﬁts of GOTCHAs will outweigh the costs — GOTCHAs
might even help a bank keep its customers by providing
extra assurance that users’ passwords are secure. We are
looking at modifying our Inkblot generation algorithm to
produce Inkblots which require less “mental eﬀort” to label.
In particular could techniques like Perlin Noise [35] be used
to generate Inkblots that can be labeled more quickly and
matched more accurately?

Accuracy: We believe that the usability of our Inkblot
Matching GOTCHA construction can still be improved. One
simple way to improve the usability of our GOTCHA con-
struction would be to allow the user to reject Inkblot images
that were confusing. We also believe that usability could be
improved by providing users with speciﬁc strategies for cre-
ating their labels (e.g., we found that simple labels like “a
voodoo mask” were often mismatched, while more elaborate
stories like “A happy guy on the ground, protecting himself
from ticklers” were rarely mismatched).
3.3 An Open Challenge to the AI Community
We envision a rich interaction between the security com-
munity and the artiﬁcial intelligence community. To facili-
tate this interaction we present an open challenge to break
our GOTCHA scheme.

We chose several random passwords

Challenge Setup.
$← {0, 108}. We used a
(pw1, ..., pw4) $← {0, 107} and pw5
function GenerateInkblots (pwi, 10) to generate ten inkblots
1, ..., I i
I i
10 for each password, and we had a human label each
inkblot image ⟨ℓi
. We se-
lected a random permutation πi : [10] → [10] for each ac-
)
count, and generated the tuple

10⟩ ← H

(⟨I i

1, . . . , ℓi

(

)

1, . . . , I i

10⟩, σ0

Ti =

si, h (pwi, si, πi(1), ..., πi(10)) , ℓi

(cid:25)i(1), ..., ℓi

(cid:25)i(10)

,

where si is a randomly selected salt value and h is a cryp-
tographic hash function. We are releasing the source code
that we used to generate the Inkblots and evaluate the hash

function h along with the tuples T1, ..., T5 — see
http://www.cs.cmu.edu/~jblocki/GOTCHA-Challenge.html.
Challenge: Recover each password pwi.

Approaches.

One way to accomplish this goal would be to enumer-
′
ate over every possible password guess pw
i and evaluate
′
h (pw
i, si, π(1), ..., π(10)) for every possible permutation π :
[10] → [10]. However, the goal of this challenge is to see
if AI techniques can be applied to attack our GOTCHA
construction. We intentionally selected our passwords from
a smaller space to make the challenge more tractable for
AI based attacks, but to discourage participants from try-
ing to brute force over all password/permutation pairs we
used BCRYPT (Level 15)10 — an expensive hash function
— to encrypt the passwords. Our implementation allows
the Inkblot images to be generated very quickly from a
password guess pw’ so an AI program that can use the la-
bels in the password ﬁle to distinguish between the correct
Inkblots returned by GenerateInkblots (pwi, 10) and in-
′
correct Inkblots returned by GenerateInkblots (pw
i, 10)
would be able to quickly dismiss incorrect guesses. Similarly,
an AI program which generates a small set of likely permu-
tations for each password guess could allow an attacker to
quickly dismiss incorrect guesses.
3.4 Analysis: Cost of Ofﬂine Attacks

In this section we argue that our password scheme (proto-
cols 3.2 and 3.1) signiﬁcantly mitigates the threat of oﬄine
attacks. An informal interpretation of our main technical
result — Theorem 1 — is that either (1) the adversary’s
oﬄine attack is prohibitively expensive (2) there is a good
chance that adversary’s oﬄine attack will fail, or (3) the
underlying GOTCHA construction can be broken. Observe
that the security guarantees are still meaningful even if the
security parameters ϵ and δ are not negligibly small.

Theorem 1. Suppose that our user selects his password
uniformly at random from a set D (e.g., pw $← D) and cre-
)
(
ates his account using protocol 3.1. If algorithms 2 and 3 are
an (ϵ, δ, µ)-GOTCHA then no conservative oﬄine adversary
-successful for C < γ|D|2(cid:22)(k)ch +

C, γ + ϵ + δ + nH|D| , D

is
nH cH

The proof of Theorem 1 can be found in the full version[11].
The proof uses a hybrid argument. We consider a sequence
of worlds: World 0, World 1, World 2 and World 3. World
0 denotes the real world in which the adversary may query
a human GOTCHA solver and the function VerifyHash as
a blackbox.
In World 1 the GOTCHA solver is replaced
by a faulty solver.
In World 2 the GOTCHA solution is
replaced with a solution chosen at random from a distri-
bution R with minimum entropy µ(k), and in World 3 the
GOTCHA solution is replaced with a solution for a puz-
zle completely unrelated to the password pw. We argue
that in World 3 no adversary can be (C, γ, D)-successful for
C < γ|D|2(cid:22)(k)ch + nH cH , because the GOTCHA is not cor-
related with the real password. We use the deﬁnition of

10The level parameter speciﬁes the computation complex-
ity of hashing. The amount of work necessary to evaluate
the BCRYPT hash function increases exponentially with the
level so in our case the work increases by a factor of 215.

32(α, β, ϵ, δ, µ)-GOTCHA to show that the adversary’s advan-
tage increases by at most ϵ + δ + nH|D| between World 3 and
World 0.

4. DISCUSSION

We conclude by discussing some key directions for future

work.

Other GOTCHA Constructions.

Because GOTCHAs allow for human feedback during puz-
zle generation — unlike HOSPs [15] — our deﬁnition poten-
tially opens up a much wider space of potential GOTCHA
constructions. One idea might be to have a user rate/rank
random items (e.g., movies, activities, foods). By allowing
human feedback we could allow the user to dismiss poten-
tially confusing items (e.g., movies he hasn’t seen, foods
about which he has no strong opinion). There is some
evidence that this approach could provide security (e.g.,
Narayanan and Shmatikov showed that a Netﬂix user can
often be uniquely identiﬁed from a few movie ratings [33].).

Obfuscating CAPTCHAs.

If it were possible to eﬃciently obfuscate programs then
it would be easy to construct GOTCHAs from CAPTCHAs
(e.g., just obfuscate a program that returns the CAPTCHA
without the answer). Unfortunately, there is no general pro-
gram obsfuscator [8]. However, the approach may not be en-
tirely hopeless. Point functions [47] can be obfuscated, and
our application is similar to a point function — the puz-
zle generator G2 in an GOTCHA only needs to generate a
human solvable puzzle for one input. Recently, multilinear
maps have been used to obfuscate conjunctions [14] and to
obfuscate N C 1 circuits [24] 11. Could similar techniques be
used obfuscate CAPTCHAs?

Exploiting The Power of Interaction.

Can interaction be exploited and used to improve secu-
rity or usability in human-authentication? While interac-
tion is an incredibly powerful tool in computer security (e.g.,
nonces [37], zero-knowledge proofs [25], secure multiparty
computation [49]) and in complexity theory12, human au-
thentication typically does not exploit interaction with the
human (e.g., the user simply enters his password). We view
the idea behind HOSPs and GOTCHAs — exploiting inter-
action to mitigate the threat of oﬄine attacks — as a pos-
itive step in this direction. Could interaction be exploited
to reduce memory burden on the user by allowing a user to
reuse the same secret to authenticate to multiple diﬀerent
servers? The human-authentication protocol of Hopper, et
al.
[27] — based on the noisy parity problem — could be
used by a human to repeatedly authenticate over an insecure
channel. Unfortunately, the protocol is slow and tedious for
a human to execute, and it can be broken if the adversary
is able to ask adaptive parity queries [31].
11The later result used a weaker notion of obfuscation known
as “indistinguishability obfuscation,” which (loosely) only
guarantees that the adversary cannot distinguish between
the obfuscations of two circuits which compute the same
function.
12A polynomial time veriﬁer can verify PSPACE-complete
languages by interacting with a powerful prover [41], by
contrast the same veriﬁer can only check proofs of NP-
Complete languages without interaction.

5. REFERENCES
[1] Rockyou hack: From bad to worse.

http://techcrunch.com/2009/12/14/rockyou-hack-
security-myspace-facebook-passwords/, December
2009. Retrieved 9/27/2012.

[2] Update on playstation network/qriocity services.

http://blog.us.playstation.com/2011/04/22/update-
on-playstation-network-qriocity-services/, April 2011.
Retrieved 5/22/2012.

[3] Data breach at ieee.org: 100k plaintext passwords.

http://ieeelog.com/, September 2012. Retrieved
9/27/2012.

[4] An update on linkedin member passwords

compromised.
http://blog.linkedin.com/2012/06/06/linkedin-
member-passwords-compromised/, June 2012.
Retrieved 9/27/2012.

[5] Zappos customer accounts breached.

http://www.usatoday.com/tech/news/story/2012-01-
16/mark-smith-zappos-breach-tips/52593484/1,
January 2012. Retrieved 5/22/2012.

[6] S. Alexander. Password protection for modern

operating systems. ;login, June 2004.

[7] A. Baddeley. Human memory: Theory and practice.

Psychology Pr, 1997.

[8] B. Barak, O. Goldreich, R. Impagliazzo, S. Rudich,

A. Sahai, S. Vadhan, and K. Yang. On the (im)
possibility of obfuscating programs. In Advances in
Cryptology-CRYPTO 2001, pages 1–18. Springer,
2001.

[9] S. Biddle. Anonymous leaks 90,000 military email

accounts in latest antisec attack.
http://gizmodo.com/5820049/anonymous-leaks-90000-
military-email-accounts-in-latest-antisec-attack, July
2011. Retrieved 8/16/2011.

[10] J. Blocki, M. Blum, and A. Datta. Naturally

rehearsing passwords. In Advances in
Cryptology-ASIACRYPT 2013 (to appear).

[11] J. Blocki, M. Blum, and A. Datta. Gotcha password

hackers!
http://www.cs.cmu.edu/ jblocki/papers/aisec2013-
fullversion.pdf,
2013.

[12] J. Bonneau. The science of guessing: analyzing an

anonymized corpus of 70 million passwords. In Proc.
of Oakland, pages 538–552, 2012.

[13] J. Bonneau and S. Preibusch. The password thicket:

technical and market failures in human authentication
on the web. In Proc. of WEIS, volume 2010, 2010.

[14] Z. Brakerski and G. N. Rothblum. Obfuscating

conjunctions. In Advances in Cryptology-CRYPTO
2013, pages 416–434. Springer, 2013.

[15] R. Canetti, S. Halevi, and M. Steiner. Mitigating

dictionary attacks on password-protected local
storage. In Advances in Cryptology-CRYPTO 2006,
pages 160–179. Springer, 2006.

[16] W. Daher and R. Canetti. Posh: A generalized

captcha with security applications. In Proceedings of
the 1st ACM workshop on Workshop on AISec, pages
1–10. ACM, 2008.

[17] M. Dailey and C. Namprempre. A text graphics

character captcha for password authentication. In

33TENCON 2004. 2004 IEEE Region 10 Conference,
pages 45–48. IEEE, 2004.

the 2008 IEEE Symposium on Security and Privacy,
pages 111–125. IEEE, 2008.

[18] S. Designer. John the Ripper.

http://www.openwall.com/john/, 1996-2010.

[19] K. Doel. Scary logins: Worst passwords of 2012 and

[34] P. Oechslin. Making a faster cryptanalytic

time-memory trade-oﬀ. Advances in
Cryptology-CRYPTO 2003, pages 617–630, 2003.

how to ﬁx them.
http://www.prweb.com/releases/2012/10/prweb10046001.htm,
2012. Retrieved 1/21/2013.

[20] J. Elson, J. R. Douceur, J. Howell, and J. Saul. Asirra:
a captcha that exploits interest-aligned manual image
categorization. In Proc. of CCS.

[21] D. Florencio and C. Herley. A large-scale study of web

password habits. In Proceedings of the 16th
international conference on World Wide Web, pages
657–666. ACM, 2007.

[22] D. Florˆencio and C. Herley. Where do security policies
come from? In Proceedings of the Sixth Symposium on
Usable Privacy and Security, pages 1–14. ACM, 2010.

[23] M. Fossi, E. Johnson, D. Turner, T. Mack,

J. Blackbird, D. McKinney, M. K. Low, T. Adams,
M. P. Laucht, and J. Gough. Symantec report on the
undergorund economy, November 2008. Retrieved
1/8/2013.

[24] S. Garg, C. Gentry, S. Halevi, M. Raykova, A. Sahai,

and B. Waters. Candidate indistinguishability
obfuscation and functional encryption for all circuits.
In Proc. of FOCS (to appear), 2013.

[25] O. Goldreich, A. Sahai, and S. Vadhan. Can statistical

zero knowledge be made non-interactive? or on the
relationship of SZK and NISZK. In Advances in
Cryptology-CRYPTO 1999, pages 467–484, 1999.

[26] D. Goodin. Why passwords have never been weaker

and crackers have never been stronger.
http://arstechnica.com/security/2012/08/passwords-
under-assault/,
2012.

[27] N. J. Hopper and M. Blum. Secure human

identiﬁcation protocols. In Advances in
Cryptology-ASIACRYPT 2001, pages 52–66. Springer,
2001.

[28] Imperva. Consumer password worst practices. 2010.

Retrived 1/22/2013.

[29] S. Komanduri, R. Shay, P. Kelley, M. Mazurek,

L. Bauer, N. Christin, L. Cranor, and S. Egelman. Of
passwords and people: measuring the eﬀect of
password-composition policies. In Proc. of CHI, pages
2595–2604, 2011.

[30] H. Kruger, T. Steyn, B. Medlin, and L. Drevin. An

empirical assessment of factors impeding eﬀective
password management. Journal of Information
Privacy and Security, 4(4):45–59, 2008.

[31] E. Kushilevitz and Y. Mansour. Learning decision

trees using the Fourier spectrum. SIAM J. Comput.,
22(6):1331–1348, 1993.

[32] M. Motoyama, K. Levchenko, C. Kanich, D. McCoy,

G. M. Voelker, and S. Savage. Re:
Captchas–understanding captcha-solving services in
an economic context. In USENIX Security
Symposium, volume 10, 2010.

[33] A. Narayanan and V. Shmatikov. Robust

de-anonymization of large sparse datasets. In Proc. of

[35] K. Perlin. Implementing improved perlin noise. GPU

Gems, pages 73–85, 2004.

[36] N. Provos and D. Mazieres. Bcrypt algorithm.
[37] P. Rogaway. Nonce-based symmetric encryption. In
Fast Software Encryption, pages 348–358. Springer,
2004.

[38] G. Sauer, H. Hochheiser, J. Feng, and J. Lazar.

Towards a universally usable captcha. In Proceedings
of the 4th Symposium on Usable Privacy and Security,
2008.

[39] K. Scarfone and M. Souppaya. NIST special

publication 800-118: Guide to enterprise password
management (draft), 2009.

[40] D. Seeley. Password cracking: A game of wits.

Communications of the ACM, 32(6):700–703, 1989.

[41] A. Shamir. Ip= pspace. Journal of the ACM (JACM),

39(4):869–877, 1992.

[42] A. Singer. No plaintext passwords. ;login: THE

MAGAZINE OF USENIX & SAGE, 26(7), November
2001. Retrieved 8/16/2011.

[43] A. Stubbleﬁeld and D. Simon. Inkblot authentication.

Technical report, 2004.

[44] L. Von Ahn, M. Blum, N. Hopper, and J. Langford.

Captcha: Using hard ai problems for security.
Advances in Cryptology-EUROCRYPT 2003, pages
646–646, 2003.

[45] L. Von Ahn, B. Maurer, C. McMillen, D. Abraham,

and M. Blum. recaptcha: Human-based character
recognition via web security measures. Science,
321(5895):1465–1468, 2008.

[46] M. J. Watkins and J. M. Gardiner. An appreciation of

generate-recognize theory of recall. Journal of Verbal
Learning and Verbal Behavior, 18(6):687–704, 1979.
[47] H. Wee. On obfuscating point functions. In Proc. of

STOC, pages 523–532. ACM, 2005.

[48] R. Witty, K. Brittain, and A. Allen. Justify identity

management investment with metrics. Gartner Group
report, 2004.

[49] A. C. Yao. Protocols for secure computations. In Proc.

of FOCS, pages 160–164, 1982.

[50] A. Zonenberg. Distributed hash cracker: A

cross-platform gpu-accelerated password recovery
system. Rensselaer Polytechnic Institute, page 27,
2009.

34