Efﬁcient Private File Retrieval by Combining

ORAM and PIR

Travis Mayberry Erik-Oliver Blass Agnes Hui Chan

College of Computer and Information Science

Northeastern University, Boston MA

Email: {travism|blass|ahchan}@ccs.neu.edu

Abstract—Recent research results on tree-based Oblivious
RAM by Shi et al. [15] obtain communication complexity of
O(l · log3(N )) in the worst-case for an N-capacity storage with
blocks size l. The individual nodes in the tree, however, are
constructed using traditional ORAMs which have worst-case
communication complexity linear in their capacity and block
size. PIR protocols are able to provide better worst-case bounds
(decoupling capacity from block size), but have traditionally been
less practical than ORAM due to the fact that they require O(N )
computational complexity on the server. This paper presents
Path-PIR, a hybrid ORAM construction, using techniques from
PIR, that overcomes the individual weaknesses of each. Path-PIR
signiﬁcantly reduces communication complexity when the block
size of the ORAM is large. Compared to existing work, this
leads to smaller data transfer costs by orders of magnitude for
practical sized databases and achieves worst-case communication
complexity of O(l · log2 (N )) for large block sizes. Additionally,
the typically high computational cost of PIR is negated by the tree
structure of the ORAM, which requires only a small fraction of
the database to be operated on for each query. We also investigate
the concept of an ORAM’s latency, which is the amount of
communication required before users receive the result of their
query. We show that Path-PIR achieves lower latency than any
existing scheme, only about four times the block size. Using
Amazon EC2 as an example, we demonstrate that even with
the additional cost of PIR computation, Path-PIR provides a
signiﬁcant monetary saving compared to related work.

I.

INTRODUCTION

Cloud computing and cloud storage are becoming an
attractive option for businesses and governmental organiza-
tions in need of scalable and reliable infrastructures. Cloud
providers, e.g., Amazon or Google, have substantial expertise
and resources, allowing them to rent their services at very
competitive prices. Cloud users are drawn by the ability to pay
for only what they need, but maintain the ability to scale up if
requirements change. Users can now take advantage of highly
reliable storage solutions without investing large amounts of
money for data centers upfront.

Unfortunately, there is a signiﬁcant downside to storing
data in the cloud. For various reasons, cloud providers cannot

Permission(cid:1) to(cid:1) freely(cid:1) reproduce(cid:1) all(cid:1) or(cid:1) part(cid:1) of(cid:1) this(cid:1) paper(cid:1) for(cid:1) noncommercial(cid:1)
purposes(cid:1)is(cid:1)granted(cid:1)provided(cid:1)that(cid:1)copies(cid:1)bear(cid:1)this(cid:1)notice(cid:1)and(cid:1)the(cid:1)full(cid:1)citation(cid:1)
on(cid:1)the(cid:1)ﬁrst(cid:1)page.(cid:1)Reproduction(cid:1)for(cid:1)commercial(cid:1)purposes(cid:1)is(cid:1)strictly(cid:1)prohibited(cid:1)
without(cid:1)the(cid:1)prior(cid:1)written(cid:1)consent(cid:1)of(cid:1)the(cid:1)Internet(cid:1)Society,(cid:1)the(cid:1)ﬁrst-named(cid:1)author(cid:1)
(for(cid:1) reproduction(cid:1) of(cid:1) an(cid:1) entire(cid:1) paper(cid:1) only),(cid:1) and(cid:1) the(cid:1) author’s(cid:1) employer(cid:1) if(cid:1) the(cid:1)
paper(cid:1)was(cid:1)prepared(cid:1)within(cid:1)the(cid:1)scope(cid:1)of(cid:1)employment.
NDSS(cid:1)’14,(cid:1)23-26(cid:1)February(cid:1)2014,(cid:1)San(cid:1)Diego,(cid:1)CA,(cid:1)USA
Copyright(cid:1)2014(cid:1)Internet(cid:1)Society,(cid:1)ISBN(cid:1)1-891562-35-5
http://dx.doi.org/(cid:18)(cid:17)(cid:15)(cid:18)(cid:21)(cid:24)(cid:19)(cid:19)(cid:16)(cid:79)(cid:69)(cid:84)(cid:84)(cid:15)(cid:19)(cid:17)(cid:18)(cid:21)(cid:15)(cid:19)(cid:20)(cid:17)(cid:20)(cid:20)

always be fully trusted and may not treat sensitive user data
very carefully. Seeing news of high-proﬁle hacking incidents
involving data theft has become commonplace [6, 19]. Encryp-
tion of data at rest provides a partial solution to this problem,
but it is not sufﬁcient. Even if the cloud (now the “adversary”)
cannot read the encrypted data, it may be able to learn valuable
information based on when and how often users access their
data. We call this information the user’s “access pattern”. As a
motivating example, consider a hospital that outsources patient
records to the cloud in order to save on replication and IT
costs. If the adversary sees that, e.g., an oncologist accesses a
patient’s data, he can learn with some degree of certainty that
this patient has cancer. An adversary could slowly aggregate
information on data accesses to learn potentially important
secrets. As it is generally difﬁcult to quantify what external
knowledge adversaries may have and what inferences they
could make, it is important to hide a user’s access pattern as
well as the data being accessed.

There are traditionally two ways to hide a user’s access
pattern (given only a single server/cloud): Oblivious RAM
(ORAM) [4] and Private Information Retrieval (PIR) [8]. The
traditional approach taken by ORAM is to arrange the data in
such a way that the user never touches the same piece twice,
without an intermediate “shufﬂe” which erases the correlation
between block locations. ORAMs have historically featured
low amortized communication complexity and did not require
any computation on the server, but occasionally the user was
required to download and reshufﬂe the entire database. This
could become impractical in cloud scenarios, especially if the
user is a low-powered or communication-constricted device.
in contrast with ORAM,
hides the target of each individual query,
independent of
all previous queries. This can be accomplished by using a
homomorphic encryption which the server uses to operate over
the entire database, selecting out the block of data that the user
has requested. The user generates encrypted requests and sends
them to the server. Since PIR does not try to hide a sequence
of accesses, but each access individually, the amortized cost
is equal to the worst-case cost. Unfortunately, the requirement
that the server computes over the entire database for each query
is often impractical, especially for large databases.

Private Information Retrieval,

Recently, there has been a ﬂurry of research on ORAMs
which provide a sublinear worst-case complexity. This goal
was achieved by, e.g., Shi et al. [15] and independently by
Kushilevitz et al. [9], but with very different approaches.
Since then, several additional schemes have been proposed
that achieve better communication complexity, but at the cost

of increasing client memory from constant to logarithmic [18]
or polynomial [16, 17] in N. As we will discuss below, con-
stant client memory is a desirable and an important property
expected for many applications, and even logarithmic client
memory can be a signiﬁcant drawback when it depends on
the block size l. Because of this, we focus our work on the
constant client memory complexity model and compare our
performance with ORAM techniques that use the same model.

In this paper, we present Path-PIR, a new ORAM con-
struction combining ORAM and PIR, thereby overcoming the
individual drawbacks of each of the two approaches. Path-
PIR’s strategy is to augment the recently proposed ORAM by
Shi et al. [15] using techniques from PIR. It has been shown
that PIR can be quite efﬁcient when the block size is large
in relation to the number of elements in the database [11].
Since the tree-based ORAM of Shi et al. [15] is composed
of many buckets, each of which has only a small number of
elements, we are able to take advantage of PIR’s better worst-
case communication guarantees, while at the same time using
the tree structure to limit the portion of the database which is
subject to expensive PIR operations.

Additionally, we explore the notion of an ORAM’s latency,
the amount of communication required before the client has
access to their data. This is important, because many modern
ORAM constructions involve an initial query, which returns
the data, and a more expensive “book keeping” protocol
which insures the integrity and obliviousness of the data
structure. Low latency is a highly desirable feature, since the
reorganizing and shufﬂing of the data structure can happen in
the background after the client receives their data. We also note
that low latency can be very useful in certain client settings
with restrictive data limits, i.e., smart phones.

Our Path-PIR scheme is especially suited to databases with
large block sizes, an important setting in the real world that
has not been thoroughly explored. For example, in medical
applications, the size of each patient record (block size) can
be quite large, due to medical images, test results, etc.

This paper makes the following major contributions:

1)

2)

3)

Path-PIR, an ORAM construction which uses a com-
bination of PIR and tree-based ORAM techniques to
achieve good performance while maintaining constant
client memory. Speciﬁcally, in a database that stores
a total of N ﬁles (entries), and each ﬁle is of
bit length l, Path-PIR reduces communication from
O(l·log3(N )) to O(log3(N )+l· log2 (N )). Path-PIR
is especially efﬁcient in practical real-world settings
where l ≥ 100 KB and N < 235, i.e., total databases
of up to 3 PB size.
an improvement to Path-PIR which allows for optimal
latency (the amount of communication spent before
the user has access to the requested data) in retrieving
blocks of size l > O(log2(N )).
a real-world implementation of Path-PIR, along with
an evaluation performed on Amazon’s public EC2
cloud. Our evaluation shows that the additional com-
putation imposed by PIR is outweighed by the sig-
niﬁcant data transfer savings. We show that Path-PIR
allows signiﬁcantly faster and cheaper operations

than previous constant client memory constructions.
The source code is available for download [13].

II. RELATED WORK

There exists a large body of work on improving Oblivious
RAM since the original concept introduced by Goldreich and
Ostrovsky [4]. For example, Pinkas and Reinman [14] and
Boneh et al. [3] have reduced amortized communication to
poly-logarithmic complexity. However, even if these construc-
tions feature low amortized cost, worst-case complexity is still
O(N · l), which is prohibitive in many scenarios. This is due
to the fact that, after a certain number of operations, the entire
database needs to be downloaded and reshufﬂed by the user.
Recently, there have been several approaches that provide
better-than-linear worst-case bounds. Kushilevitz et al. [9]
achieve this by deamortizing an existing ORAM constructions
and obtain O(l· log2(N )/ log log(N )) worst-case complexity.
However, it only achieves this complexity for extremely large
databases. For N where log(N ) < 7 log log(N ), this scheme
actually degrades to Ω(l · log3(N )). Since we are considering
practical sized databases up to the order of several hundred
petabytes, that is, N ≈ 237, Kushilevitz et al. [9] construction
achieves only O(l · log3(N )) performance.
In contrast, as we will see, Path-PIR only approaches l ·
O(log2(N )) for very large databases and is, in practice, much
closer to O(log(N )). Our evaluation will show that this leads
to signiﬁcant performance improvements, and Path-PIR clearly
outperforms Kushilevitz et al. [9] at the targeted database sizes.
Shi et al. [15] have proposed another ORAM with worst
case bounds O(l·log3(N )) using an entirely new construction.
Instead of deamortizing previous schemes, authors show that
a large ORAM can be composed of many smaller “bucket”
ORAMs. For each operation, a small fraction of the buckets
are shufﬂed, so there is no need for one large, expensive shufﬂe
of the entire database. Using a recursive access technique, this
scheme can achieve constant client memory. Path-PIR is based
upon this approach, overcoming its (still) expensive individual
bucket accesses with PIR as presented in Section III.

Stefanov et al. [17] have shown that a bucket-based con-
struction can achieve O(l · log(N )) amortized and worst-
case complexity. However, this is achieved only with either
linear client memory complexity or with square-root client
memory complexity at the cost of additional communication
complexity. Achieving constant client memory is an important
requirement, because it allows ORAM applications for con-
strained devices such as smart phones and embedded systems.
Unlike Shi et al. [15], the client memory required by Stefanov
et al. [17] is dependent on the block size; for example, a 1
TB database of 1 MB ﬁles consumes approximately 800 MB
of client memory in the square-root construction of Stefanov
et al. [17]. It is unrealistic to expect 800 MB of free client
memory for many real-world applications. Even in the linear
client memory setting, Shi et al. [15] requires only 4 MB.
This difference is caused by the fact that the Shi et al. [15]
scheme has client memory independent of the block size, while
Stefanov et al. [17] needs a block cache which can be very
large for large block sizes.

For tree-based schemes, the size of the client memory in
the linear setting is important, because it will govern how many

2

TABLE I.
COMMUNICATION COMPLEXITY OF PATH-PIR AND RELATED constant-memory SCHEMES. HERE, N IS THE ORAM CAPACITY, E.G., THE
NUMBER OF FILES, l IS THE BIT-LENGTH OF EACH FILE, AND k IS THE SECURITY PARAMETER. LATENCY IS THE AMOUNT OF COMMUNICATION BEFORE

THE CLIENT HAS ACCESS TO DATA. THE “PRACTICAL” SETTING IS l ≥ 100 KB AND N < 235.

Latency

O(l · log2(N ))
O( l·log2(N )
log log(N ) )

Shi et al. [15]

Kushilevitz et al. [9]

Path-PIR Linear
Path-PIR FHE

Optimal

Worst-Case
O(l · log3(N ))
O( l·log2(N )
log log(N ) )

Practical Worst-Case

O(l · log2(N ))
O(l · log3(N )
O(l · log(N ))
O(log(N ) + l)

O(k + l)

O(k · log(N ) + l) O(k · log3(N ) + l · log2(N )
O(k · log(N ) + l · log(N ))
O(log(N ) + l)

O(log(N ) + l)

O(k + l)

recursive steps are needed in the constant-memory setting.
Since linear-memory requirements are, for practical sizes,
very low, we will see later that reducing to constant-memory
requires only a small number of recursive steps (typically one).
Stefanov et al. [18] were also able to improve upon the
original
tree-based construction to achieve communication
costs of l · log2(N )/ log χ in a scheme they call Path-ORAM
(where χ = log(N )/l). However, to achieve this, the au-
thors again give up constant client memory. Although this
construction achieves relatively low complexity, its memory
still contains a block cache which means it is dependent on l
and therefore can be expensive.

One signiﬁcant down-side to schemes which contain a
block cache [15, 17, 18] is that the cache load can only be
estimated empirically. If the size of the cache is chosen to
be too small, and the actual cache needed during execution
exceeds that size, then ORAM can only abort and lose its
integrity. Even in devices with enough memory to allow for
such schemes, it may be a signiﬁcant burden on the client
compared with a scheme that requires only a small constant
memory.

Additionally,

in order to make an ORAM available to
multi-users, the client memory must be stored on the server
between data accesses [5]. In such a situation, the client must
include the size of their local memory in the communication
cost of each request, signiﬁcantly hampering the efﬁciency
of schemes with non-constant memory requirements. This
technique can be used with Path-ORAM [18] to allow for
constant long-term memory in exchange for more expensive
data access, but clients still require non-constant
transient
memory in order to execute queries. This is a fundamental
difference between Path-ORAM and other related tree-based
ORAMs.

III. OBLIVIOUS RAM

Let N denote the capacity, i.e., maximum number of blocks
that can be stored in a database D = {d0, . . . , dN−1} at one
time. We assume that all blocks are of equal size, and let l
denote the size of each block in bits. We assume that l >
c · log(N ) for some c > 1.
Deﬁnition 1. An Oblivious RAM protocol is a set of interac-
tions between a user and a server comprised of the following
user functions:
Read(x) : The user retrieves the value of the block with
identiﬁer x from the server.
Write(x, y) : The user changes the value of the block with
identiﬁer x to y. If block x is not present in the database, that
block is added.

We now deﬁne the security of an ORAM protocol Π in the

standard way.
Deﬁnition 2 (Obliviousness). Let

"y:= {(op1, a1, data1), ..., (opM , aM , dataM )}

is either the data to be written,

be a sequence of data requests of length M, where opi
is the address targeted by that
if

is either read or write, ai
operation, and datai
opi = write, or ⊥ if opi = read.
Let s be the security parameter, and let As("y) be the
sequence of accesses induced on the remote storage by the
client access pattern "yusing an ORAM protocol Π(s). We
say that protocol Π(s) is secure if, for any two same-length
sequences of data request "yand "z, and any probabilistic
polynomial time adversary A,

|P r[A(As("y)) = 1] − P r[A(As("z)) = 1]|≤ (s),

where  is a function negligible in s.

A. Shi et al. [15] ORAM

Traditionally, ORAMs support two operations: Read(x),
which reads the block with identiﬁer x, and Write(x, y), which
writes value y to the block identiﬁed by x.

However, Read(x) and Write(x, y) can be emulated with

the following set of operations:

1)

2)

3)

ReadAndRemove(x) – Returns the value of the block
with identiﬁer x, or ⊥ if x identiﬁes a dummy or
if x does not exist in the ORAM. Additionally, this
operation removes block x from the ORAM.
Add(x, y) – Adds a block with identiﬁer x and value
y to the ORAM.
Pop() – Returns a real data block if the ORAM
contains such a block and a dummy otherwise.

A traditional Read can be implemented by calling
ReadAndRemove followed by Add to put
the block back
in the ORAM. Similarly, Write can be emulated with a
ReadAndRemove (on a dummy value, if the block does not
exist in the ORAM, yet) and an Add with the new value of the
block. Conceptually, this set of operations is more conducive
to an ORAM construction, because it hints at the idea that,
when reading a block, there must be an active relocation of
that block in order to disassociate future accesses to it.

3

B. Tree Construction

Assume for simplicity that N is a power of two. In order
to amortize the cost of shufﬂing, Shi et al. [15] use a tree of
2N − 1 “bucket” ORAMs arranged in a tree of depth log(N ).
These internal ORAMs are each fully-functioning ORAMs
with a capacity of n := log(N ) “slots”. The buckets must
have three properties: (1) support a non-contiguous identiﬁer
space (2) support ReadAndRemove and Add, and (3) have zero
probability of failure. In Path-PIR, we will replace the bucket
ORAMs with PIR operations, so these are the three properties
our construction must have in order to be sound.

When blocks are added to the ORAM, they are inserted in
the root bucket. Each block is tagged with a random number
t ∈{ 0, . . . , N − 1}, which corresponds to a leaf node towards
which that block will be moving. The user stores a map M
which, for each block in the ORAM, contains the value t for
that block. M (x) denotes the value t for x, stored in the user
memory. As this would imply O(N ) user memory, Shi et al.
[15] show how this map can itself be recursively stored in an
ORAM to achieve O(1) client memory. However, for the sake
of clarity, we will assume O(N ) user memory when presenting
Path-PIR. The recursive technique can be applied equally to
our construction, since it does not depend on the makeup of the
individual buckets. This adds a log(N ) factor to each query,
because there are at most log(N ) recursive ORAMs to store
that map.

ReadAndRemove – Assuming that a block x starts at the
root bucket and moves down the tree towards its respective
leaf node, block x will always be found somewhere along the
path from the root to M (x). Therefore, a ReadAndRemove
can be performed by executing ReadAndRemove(x) on every
bucket along the path from the root to M (x). One bucket will
store block x. Block x will be removed from this bucket, and
all other buckets along the path will return ⊥.
Add – A new leaf node t ←{ 0, . . . , N − 1} is randomly
chosen, and the user inserts block x with value y into the root
bucket, tagged with leaf node t.

Every Read and Write operation consists of one
ReadAndRemove and one Add. Two Read or Write operations
to the same block will be completely independent, because
a new random t is chosen for each Add. Therefore,
this
construction achieves obliviousness.

Tree balancing. To facilitate the movement of blocks
towards leaf nodes, and to prevent
internal buckets from
overﬂowing, the user must Evict blocks from internal buckets
to their children. At each level of the tree, the user randomly
picks ξ ∈ N buckets and executes Pop to read and remove one
data block from them. The user then writes to each of the child
buckets, moving data blocks toward the correct leaf nodes and
performing dummy operations on those children which are not
on the correct path maintaining obliviousness. One can show
that ξ = 2 is sufﬁcient to keep any buckets from overﬂowing
with high probability, if Evict is performed after every Read
or Write operation [15].

Complexity. Assuming each bucket ORAM with individual
capacity of n = log(N ) has communication complexity R(n)
for its operations, we can calculate the overall cost for this
tree construction. ReadAndRemove performs one operation on

each of the log(N ) buckets, so its cost is log (N )· R(n). Add
operates only on the root bucket, and so has complexity simply
R(n). Evict operates on 3·ξ buckets (one parent and 2 children
for every bucket evicted) on each level of the tree and so has
cost 3 · ξ · log (N ) · R(n). For all bucket ORAMs, the worst-
case cost is O(n). For the individual buckets, n = log(N ), so
the worst-case cost for eviction (the most expensive operation)
is 3 · ξ · log(N ) · log(N ). Therefore, regardless of which
bucket construction is used the overall worst-case complexity
is O(l·log2(N )). Recursively storing the user memory requires
at most log(N ) additional ORAMs, adding another log(N )
factor to the overall cost resulting in O(l · log3(N )).
IV. PATH-PIR’S HYBRID CONSTRUCTION

Although the complexity of constant client memory ORAM
is only O(l · log3(N )), a large value l will render a ORAM
in practice. Our aim is to modify the
scheme impractical
scheme so that
large value l, while
it
is practical for all
maintaining constant memory complexity on the client side.

A. Oblivious Outsourced Storage

Our hybrid construction will be different from traditional
ORAM in one important way: it requires computation on the
server side. Because of this, we require a slightly different
security deﬁnition for a construct we call Oblivious Outsourced
Storage.
Deﬁnition 3. Let

"y:= {(op1, a1, data1), ..., (opM , aM , dataM )}

is either the data to be written,

be a sequence of data requests of length M, where opi
is the address targeted by that
if

is either read or write, ai
operation, and datai
opi = write, or ⊥ if opi = read.
Let s be the security parameter, and T races("y) be the
transcript of all messages sent between the client and server
during the execution of an Oblivious Outsourced Storage
protocol Π(s) on "y. We say that Π(s) is secure if, for any two
data access patterns "yand "z, and any probabilistic polynomial
time adversary A,

|P r[A(T races("y)) = 1] − P r[A(T races("z)) = 1]|≤ (s).

This deﬁnition is compatible with the traditional ORAM
security deﬁnition,
i.e., any secure ORAM will also be a
secure OOS (since the data accesses induced by the server
are part of the trace). However, it also incorporates the notion
of server computation by stipulating that the entire trace must
be indistinguishable instead of simply the access pattern on
the server. The traditional ORAM deﬁnition does not need
this requirement because there are no other interactions in
the trace besides the access pattern. In our case, however, the
trace includes PIR vectors and additional ciphertexts, so the
deﬁnition must be modiﬁed slightly.

4

Request

Database

E(0)
E(0)
E(1)
E(0)
E(0)

**
*
*
*

d1,1
d2,1
d3,1
d4,1
d5,1

d1,2
d2,2
d3,2
d4,2
d5,2

d1,3
d2,3
d3,3
d4,3
d5,3

d1,4
d2,4
d3,4
d4,4
d5,4

nk

=
=
=
=
=
+

E(0)
E(0)
E(d3,1)
E(0)
E(0)

E(0)
E(0)
E(d3,2)
E(0)
E(0)

E(0)
E(0)
E(d3,3)
E(0)
E(0)

E(0)
E(0)
E(d3,4)
E(0)
E(0)

E(d3,1) E(d3,2) E(d3,3) E(d3,4)

O(`)

Fig. 1. PIR using the linear scheme. The dot product of the request vector (size n) and the database is computed. The result has size l.

B. Private Information Retrieval

Since PIR has communication complexity which can be
very efﬁcient for retrieving large blocks, our goal will be
to replace the bucket ORAMs in the previously described
tree-based scheme with PIR queries to obtain better overall
performance. Our approach in Path-PIR is to create a “PIR-
bucket” to replace the bucket ORAMs at each node in the
tree. However, it is not sufﬁcient to simply replace the ORAM
buckets with PIR, because buckets must have the ability to add
and change blocks in order to support all the necessary ORAM
operations. Therefore, in addition to standard PIR reading, we
also need an equivalently secure writing protocol called “PIR-
writing”. To begin, we will brieﬂy deﬁne PIR and discuss
relevant details of the PIR protocol we will be using.
Deﬁnition 4. A Private Information Retrieval protocol is a set
of interactions between a user and a server comprised of the
following functions:

PrepareQuery(x) : Given a private input x ∈{ 1, 2, . . . , N},
the user generates a query which is designed to retrieve the
block with index x from the server.
ExecuteQuery(q) : The server receives query q prepared by
the user and executes it over the database D. Here, D is a
vector of N entries each of length l. The response, consisting
of the encoded requested block, is sent back to the user.
DecodeResponse(r) : The user receives the server’s response
to its query and decodes it to retrieve the requested block.

Along the same lines of “obliviousness” in ORAM, we

deﬁne security (“Privacy”) for PIR.
Deﬁnition 5 (Privacy). A Private Information Retrieval proto-
col is secure, if for any PPT adversary and any two indices y
and z, the corresponding queries Q = PrepareQuery(y) and
Q" = PrepareQuery(z) are computationally indistinguishable.

We consider only single-server, computationally-secure
PIR protocols, as multi-server schemes would not be appro-
priate for our setting. Though cloud providers may make use
of many servers, they are all controlled by the same entity
and may freely collude. It may be an interesting problem to
consider multiple, competing cloud providers as a multi-server
setting, but that is outside the scope of this paper.

In contrast with ORAM, PIR does not require keeping a
state in between queries. Consequently, it can also be used to
retrieve data from a public, unencrypted database. Since PIR
protocols are stateless, each invocation of the protocol causes
the server to perform O(l · N ) computation. At a minimum,
the server must “touch” each of the blocks in the N-capacity
database or it could learn which blocks were not chosen by
the user.

1) Linear PIR: Kushilevitz and Ostrovsky [8] have shown
that an efﬁcient protocol can be constructed using an IND-CPA
additively homomorphic encryption scheme (K,E,D). For a
scheme to be additively homomorphic, it must satisfy the fol-
lowing condition: (∃⊕)(∀x, y) : D(E(x) ⊕E (y)) = D(E(x +
y)), where ⊕ is an efﬁciently computable function. Note that,
given this property, it is also true that ∀x, y : D(E(x) · y) =
D(E(x · y)), where · denotes scalar multiplication, i.e., the
repeated application of ⊕ or +. ORAM functionality can
be implemented using an additively homomorphic cipher as
follows:

1)

2)

3)

PrepareRead(x) – The user generates a vector Q =
{q0, ..., qn} where ∀i += x : qi ←E (0) and qx ←
E(1).
ExecuteRead(q) – The server computes a dot prod-
uct of Q with the vector D (using the scalar multiply
operator of the homomorphic cipher) and returns the
result E(dx).
DecodeResponse(r) – The user computes m =
D(r).

The above computations are sound, because: ∀x : D(E(0)·
x) = D(E(0)) and ∀x : D(E(1) · x) = D(E(x)). All blocks
that the user is not interested in are “zeroed out”, and the sum
of the products will be equal to an encryption of the single
block requested. The communication cost for this protocol is
O(l + k· N ), where k is the size of the block cipher used. The
overall communication is a 1
l fraction of the database.
If l is large in relation to N, this protocol is actually very
efﬁcient, because l is independent of N in the complexity. For
instance, if l > N, then the overall communication is only
O(l) which is optimal. This is important, because no existing
ORAM can obtain optimal communication under any setting
of parameters (except the trivial case where N = 1). In our use
case, N will be very small (actually log(N ) in the notation of
the overall ORAM), so it is highly likely that l will be large in

N + k

5

comparison to it, particularly in our motivating case of large
block sizes. This is where our savings in communication comes
from, because retrieval requires only one full sized block to
be transferred, while all the “indexing” information is in small
ciphertexts.

C. PIR-Writing

We deﬁne PIR-writing [10] as follows:

Deﬁnition 6. A PIR-writing protocol is a set of interactions
between a user and a server comprised of
the following
functions:

PrepareWrite(x,y)

: Given a private

input x ∈
{0, 1, ..., N}, the user generates a query which is designed
to update block at index x on the server with the new value y.
ExecuteWrite(q) : The server receives query q prepared
by the user and executes it over the database, updating the
corresponding block to its new value.

We stress that, in contrast to PIR, PIR-writing cannot be
performed on unencrypted databases. As with ORAM, if the
database was unencrypted, the server would learn immedi-
ately which record was changed. Still, PIR-writing has one
interesting feature which is not subsumed by ORAM: it is
also stateless. PIR-writing only requires a long-term key. In
contrast, ORAM, even under constant user memory, requires
state to be updated with each operation.

1) Linear: Path-PIR’s linear PIR protocol above can be
adapted to a PIR-writing protocol in a straightforward manner.
If, instead of D, the server holds C = {E(d1), . . . ,E(dN )},
the protocol runs as follows:

1)

2)

PrepareQuery(x,y) – The user generates a vector
Q = {q1, . . . , qn} where ∀i += x : qi ←E (0) and
qx ←E (1). Additionally, the user calculates y" =
y − dx and returns the query (Q, y").
ExecuteQuery(q) – The server computes ∆C = y" ·
Q and adds it to C componentwise.

As before, multiplying by encryptions of zero will result
in encryptions of zero, meaning that every block not being
updated has an encryption of zero added to it which corre-
sponds to a re-encryption. The single block being updated has
an encryption of y" added to it, resulting in a new value of y.
This protocol requires that the user knows the current value
of dx, but this can be accomplished with a prior execution of
PIR.

An additional problem with this protocol is that the server
learns y", the difference between the old value of dx and the
new value. One might try to set qi = y" − y to get around
this, but then the size of each encryption becomes O(l), and
we lose any beneﬁt from using PIR. If, however, the user
ﬁrst encrypts the blocks with an IND-CPA encryption before
applying the homomorphic encryption, the server sees only
a difference between the two ciphertexts. This is equivalent
to seeing two ciphertexts ((c1, c2 ⊕ c1) ⇔ (c1, c2)), which
gives the adversary no information under an indistinguishable
encryption.

6

D. Replacing internal ORAM buckets with PIR

For the internal ORAM buckets, as stated above, we
only need to provide a PIR capable of performing ReadAn-
dRemove and Add, and that allows for a non-contiguous
identiﬁer space. This is because the bucket will be storing
“sparse” identiﬁers, i.e., there are N possible block identiﬁers
and a random O(log(N )) subset of them will be in any given
bucket. In order to support the Add operation and the “remove”
part of ReadAndRemove, any PIR construction requires also
PIR-writing. From a high level perspective, our idea in Path-
PIR is to implement ReadAndRemove and Add with one
invocation of PIR and PIR-writing, respectively. Again, let
n designate the capacity of a bucket and N the capacity
of the entire ORAM. Let us assume the user has an IND-
CPA additively homomorphic encryption scheme (E,D,K),
e.g., Paillier, and an IND-CPA symmetric encryption scheme
(E",D",K"), e.g., AES-CBC with random IVs. We will ﬁrst
show how to construct a basic PIR bucket and then discuss
additional
improvements that can be made and interesting
properties that arise from it.

It is sufﬁcient to show that we can implement an oblivious
bucket that supports ReadAndRemove and Add and that al-
lows for a non-contiguous identiﬁer space. By non-contiguous
identiﬁer space we mean that a bucket may hold n items, but
the identiﬁers for those items may be from the set {0, . . . , 2m}
with m > n. This is required for the tree construction, because
there are, overall, N elements in the ORAM, with N unique
identiﬁers, and each bucket has capacity only n = log(N ).
Therefore, there will be more possible identiﬁers than slots in
the bucket. Standard PIR does not support a non-contiguous
identiﬁer space, as the “identiﬁers” are the row indices of each
block in the database. We will overcome this in Path-PIR by
using an encrypted map, stored on the server, which relates
block identiﬁers to rows and allows us to use PIR with arbitrary
identiﬁers.

Note that,

in order to support

the Add operation and
the “remove” part of ReadAndRemove, any construction
attempting this will also have to use a PIR-writing protocol
to mask these operations. At a high level, the idea will be to
implement ReadAndRemove and Add with one invocation
of PIR and PIR-writing, respectively. We construct a store for
the internal ORAM buckets meeting the above conditions for
n blocks as follows:

server will

1) Data storage: The

store n tuples
(E"(t),E"(u),E(E"(v))). t is the leaf node that the block is
moving toward, u is the block identiﬁer and v is the actual data
(“value”) of the block. If the slot is empty (i.e., no block is
currently stored there) then u is set to some canonical dummy
value ⊥. The value for each block is stored double-encrypted
so that we can use the PIR-writing protocols outlined above.
2) ReadAndRemove(x): The user reads all the encrypted
u values from the server (we will call these values the map) and
learns in which slot block x resides in. If the requested block
is present in this store at slot i, the user changes its ui value
to ⊥, reencrypts all u values with fresh randomness and sends
them back to the server. This marks the row as a “dummy” and
effectively performs the “remove” part of ReadAndRemove.
All rows in the map are reencrypted so the server does not learn
which block the user was actually interested in. The user then

Request

Server Computation

Database

nk

E(0)
E(0)
E(1)
E(0)
E(0)

x

y1 - d3,1
y2 - d3,2
y3 - d3,3
y4 - d3,4

=

E(0)
E(0)
E(y1 -
d3,1 )
E(0)
E(0)

E(0)
E(0)
E(y2 -
d3,2 )
E(0)
E(0)

E(0)
E(0)
E(y3 -
d3,3 )
E(0)
E(0)

E(0)
E(0)
E(y4 - 
d3,4 )
E(0)
E(0)

l

+

E(d1,1)
E(d2,1)
E(d3,1)
E(d4,1)
E(d5,1)

E(d1,2)
E(d2,2)
E(d3,2)
E(d4,2)
E(d5,2)

E(d1,3)
E(d2,3)
E(d3,3)
E(d4,3)
E(d5,3)

E(d1,4)
E(d2,4)
E(d3,4)
E(d4,4)
E(d5,4)

=

E(d1,1)
E(d2,1)
E(y1)
E(d4,1)
E(d5,1)

E(d1,2)
E(d2,2)
E(y2)
E(d4,2)
E(d5,2)

E(d1,3)
E(d2,3)
E(y3)
E(d4,3)
E(d5,3)

E(d1,4)
E(d2,4)
E(y4)
E(d4,4)
E(d5,4)

Fig. 2.
database.

PIR-Writing using the linear scheme. The cross product of the request vector (size n) and the change value (size l) is computed and added to the

Algorithm 1: ReadAndRemove

Algorithm 2: Add

Input: Identiﬁer x of block to add and value y of said

Input: Identiﬁer x of block to retrieve
Output: Value of block x or ⊥ if block does not exist
begin
Read and decrypt the map U = {u1, .., un} from
the server
i ← 0
exists ← f alse
for j ∈{ 1, ..., n} do
if uj = x then

block

Output:
begin

executes PrepareRead(i) and sends it to the server. The server
executes the query over V = v1, ..., vn, returns the response,
and the user decrypts it with D and D" to obtain the value
for block x. We do not have to remove or change the value
v corresponding to the block that we are reading, but only
change its identiﬁer to ⊥. Future Add operations will simply
overwrite the existing value.

bucket

Q ← PrepareWrite(i, changeValue)
ExecuteQuery(Q)

end

complexity as the PIR-writing query.

3) Add(x,y) : The user reads all encrypted u values from
the server and selects an empty block i where ui = ⊥. The user
sets ui = x, reencrypts all u values and sends them back to the
server. The user then runs PrepareWrite(i, y) and the server
executes the PIR-writing query over V , changing the value in
the ith slot to y. Note that in order to calculate the query for
PIR-writing, the user must already know the old value of the
block. Therefore, there is an implicit PIR query that occurs
as part of PrepareWrite, but it has the same communication

4) Complexity Analysis: The communication complexity
for Path-PIR’s “PIR-bucket” is O(n · k + P (n)), where k is
the block size of the additively homomorphic encryption, and
P (n) is the complexity of the underlying PIR protocol. For
our linear scheme above, the communication complexity is
O(n · k + l) so the overall communication complexity of the
bucket is just O(n · k + l). Unlike ORAM, however, our PIR-
bucket requires O(n· l) computation. When used in the larger
ORAM construction, n = log(N ), so this computation is quite

7

i ← j
uj ← ⊥
exists ← true

end

end
Reencrypt U and send back to the server
Q ← PrepareRead(i)
R ← ExecuteRead(Q)
if exists then

return D"(D(DecodeResponse(R)))
return ⊥

else

end

end

Read and decrypt U = {u1, .., un} from the server
i ← 0
/* First, find an empty block in
the bucket
for j ∈{ 1, ..., n} do
if uj = ⊥ then
end

i ← j

end
/* Mark that block with its new

*/

identifier

ui ← x
Reencrypt U and send back to the server
/* Read the existing block value */
Q ← PrepareRead(i)
R ← ExecuteRead(Q)
/* Calculate the difference between
*/

the old and new values

oldV alue ←D (DecodeResponse(R)))
changeV alue ←E "(y) − oldV alue
/* Write the change back to the

*/

*/

reasonable as we will demonstrate in Section VI.

E. Improvements to the basic scheme

1) Lower latency: An interesting property to consider for
any ORAM is its data latency, that is the amount of data that is
transferred before the client has access to the requested infor-
mation. In our scheme, the client has access immediately after
ReadAndRemove. Although Evict can be quite expensive, it
can be executed in the background on the server without any
user interaction, and the user does not need to “wait” on it. At
the tree level, the cost for a ReadAndRemove operation is
log(N )· P (log(N )). With P (n) = O(n· k + l), this results in
k · log2(N ) + l · log(N ). We can then save a factor of log(N )
by executing another PIR query over the results from each
bucket in the path. As an example, if we know that the block
we want is in slot i of bucket j, we can retrieve it with cost
only O(log2(N ) + l). We can send two PIR queries: the ﬁrst
selects the ith row from every bucket, and the second selects
the response from the jth bucket (out of log(N ) buckets in
the path). The overall latency is now k · log2(N ) + l, which
is optimal for any retrieval within the constant factor k. This
leads to very low latency in practical situations (lower than
any other previous work, even allowing for non-constant client
memory).

2) Lower communication for Evict: Path-PIR’s default
approach to Evict using its PIR-bucket is to simply execute
a ReadAndRemove on the parent bucket and two Add
operations on the children. This requires three PIR queries
and two PIR-writing queries. Since the user knows which child
node the block is going to be added to, it can simply execute
a “dummy” PIR query over the other child node, where all the
encryptions in the request vector are encryptions of zero. The
same change value can then be used for both children, but
the dummy request will simply result in an entire vector of
zeroes and no change to the non-selected child bucket. With
this modiﬁcation, Path-PIR can coalesce the two reads and
writes on the child nodes into one, saving a factor of 2 · l.
Fully homomorphic encryption (FHE). An interesting
extension to our scheme would be to use a more powerful fully
homomorphic encryption (FHE). The most communication
intensive part of our scheme, which maintains a dependence
between N and l,
is
randomized, the user is required to send at least the random
choices of buckets to the server, of which there may be many.
However, if our adversary is honest-but-curious, then we can
allow him to provide the randomness needed for the eviction
process. This would eliminate any communication with the
user and actually allow for evicts with a communication
complexity of zero, given a fully homomorphic encryption
scheme. The user can encode a circuit which evicts one block
from a bucket to its children, and the server can run it on
random buckets as normally chosen by the user. This would
realize an ORAM with very close to optimal communication
complexity (l · log N), since the read/write operations were
already close to optimal, and eviction would cost nothing. It
is not surprising that one can privately retrieve a block from
a database with good communication complexity using FHE,
since retrieval is equivalent to testing equality over encrypted
bit-strings – and this can be performed quite easily. However,
it is interesting that by using a tree construction we can achieve

is Evict. Unfortunately, since Evict

low communication complexity while only computing over a
O(l · log2 N )-sized fraction of the database. Any FHE-based
approach is likely to be restricted by the expensive ciphertext
operations. Consequently, it is very helpful that computation
only needs to be done over a small portion of the database
with each user operation. Unfortunately, fully homomorphic
encryption is still too impractical to be used in this manner,
but might become attractive in the future.

F. Summary: Complexity Analysis

Table I compares the communication complexity of related
work with Path-PIR. The last column shows the performance
of each scheme in a setting with moderately large blocks (l >
100 KB) and practical sized databases of up to 3 PB. The two
bucket based schemes perform better in this setting because the
depth of recursion is limited to one (they lose a log(N ) factor).
Additionally, Path-PIR performs especially well, since all the
ciphertexts that need to be transferred are signiﬁcantly less than
the size of one block, so the communication is dominated by
the O(log(N )) blocks which are transferred during Evict.

In conclusion, Path-PIR reduces the expensive communi-
cation complexity that depends on ﬁle length l by a factor
of log (N ) using a simple “linear” PIR protocol. Although a
reduction from log3 to log2 may look small, the total savings
can be substantial in practice – as we will demonstrate by our
experimental results presented in Section VI.

We observe in Path-PIR that, although the user needs
to perform one eviction for each read or write operation,
these evictions are not required to be performed immediately
after the operation. The contribution of eviction is to keep
buckets from overﬂowing, but the correctness and security of
the ORAM remains independent of it. The user can actually
conduct O(log(N )) data accesses without any evictions before
the root node will overﬂow. Since ReadAndRemove and Add
are very efﬁcient, and the overwhelming majority of commu-
nication is consumed during Evict, this could be very useful
when a user’s cost on communication may vary in different
environments. For instance, a user with a cell phone may pays
signiﬁcantly more money for cellular data than WiFi data.
In a practical implementation of Path-PIR, one could defer
evictions while they are on expensive cellular data and choose
to perform these operations later when they are on cheap WiFi.
This allows for extremely low communication requirements
while Evict operations are being deferred. Additionally, the
size of the root bucket can be increased by any constant factor
to allow for more deferred operations without effecting the
overall complexity.

V. SECURITY

It is relatively simple to show the security of our scheme.
At a high level, we are just composing PIR and ORAM
techniques which are secure individually, and we shall see
that they remain secure together. The PIR elements that we
use result in the transfer of many ciphertexts between the client
and the server. However, these ciphertexts are freshly generated
by the client for each query, so under IND-CPA security they
should not give any information to the server.

First, we show that an individual bucket, created using PIR

techniques, is secure.

8

Lemma 1. Path-PIR’s construction of a PIR-bucket is a secure
oblivious operation.

Proof: There are three parts of each PIR-bucket operation:
retrieval of the map, execution of the PIR query and execution
of the PIR-writing query.

The map is oblivious, because it is encrypted and retrieved
in its entirety for every operation. At the conclusion of an
operation, the entire map is freshly reencrypted and sent back
to the server. In that way, it is actually a “trivial” ORAM and
therefore meets our security deﬁnition.

Next, we show that Path-PIR is insecure only,

if the
IND-CPA security of either the symmetric encryption or the
additively homomorphic encryption is invalid. Let Q("y) =
{Q1, . . . , Qn}, where Qi = {qi,0, . . . , qi,m}, denote the set
of all PIR and PIR-writing queries involved in the execution
of a set of data accesses "y. Each qi,j is an encryption of
the plaintext pi,j under our additively homomorphic IND-
CPA encryption scheme. Similarly, let P("y) = {P1, . . . , Pn}
denote the set of all plaintexts used in the construction of
Q("y). Assume that Path-PIR is insecure, that is, there exists an
adversary, A, that can distinguish between two access patterns,
"yand "z. We will construct an adversary, A" which can break
the IND-CPA security of our homomorphic encryption.
A" runs A and obtains the two access patterns, "yand "z,
which A can distinguish. A" then simulates Path-PIR on the
two access patterns, obtaining X0 = P("y) and X1 = P("z). A"
submits X0 and X1 to the IND-CPA challenger and receives
back C, an encryption of one of the two plaintexts. He then
sends C to A as the trace and A returns either y or z as
the chosen access pattern. If A returns y, then A" returns 0
to the challenger, otherwise returns 1. Thus, if A is able to
distinguish between the two access patterns with probability
1/2 + , then A" will be able to distinguish between the two
encryptions with the same probability.
Note that the trace will also include responses from the
server, but those cannot reveal any additional information,
because they are deterministically computed from the client’s
requests.

We have now established that the construction of a PIR-

bucket is a secure oblivious operation.
Theorem 1. The basic version of Path-PIR is a secure Obliv-
ious Outsourced Storage protocol.

Proof: The security proof by Shi et al. [15] shows that
the sequence of bucket accesses will be oblivious. As stated
above, the standard deﬁntion of ORAM security is compatible
with our OOS security deﬁnition, therefore the security of our
scheme depends only on the PIR-bucket itself being oblivious,
which is established by Lemma 1.
Theorem 2. The improved latency version of Path-PIR is a
secure Oblivious Outsourced Storage protocol.

Proof: The only difference between the improved latency
scheme and the original one is that a single PIR vector is
“reused” for every bucket on a path in the tree. However,
since PIR vectors are themselves indistinguishable for any
two indices being accessed, ”reusing” them does not provide

any additional information and therfore, the protocol remain
oblivious. If an adversary could distinguish in the case with
just one request vector, he could equally distinguish that same
vector in the original scheme by ignoring all other vectors.

Based on the oblivious secure protocol properties of PIR
and ORAM, we have established that Path-PIR satisﬁes the
Oblivious Outsourced Security properties.

Note that, as described thus far, Path-PIR is like related
ORAM schemes only secure in the honest-but-curious model.
Against a malicious server, we can achieve security with a
simple modiﬁcation. Along with the block IDs, the encrypted
map on the server will contain a MAC for each block. This
ensures that the server has not changed any of the actual block
data. Each map, in turn, contains a MAC for itself, over all the
block IDs contained in that map and the MACs of those blocks
in addition to the MACs of that bucket’s childrens’ maps. This
creates a Merkle tree over all the buckets, with the user storing
the root hash locally. Whenever a bucket is accessed, the hash
tree can be veriﬁed and updated with O(log n) communication,
which is less than what is required to download the map.
Therefore, the integrity of the buckets is maintained, and no
additional communication or memory complexity is required.

VI. EVALUATION

First, note that, to become deployable in a practical, real-
world cloud setting, any ORAM protocol must be paralleliz-
able. The only way to scale up in the cloud is to expand to
more nodes and CPUs in the cloud’s data center. Fortunately,
PIR as we have described is highly parallelizable. The scalar
multiplication on each ﬁle can be evaluated independently, so
Path-PIR can take advantage of up to O(log2(N )) independent
CPUs.

Typically, public cloud providers such as Amazon, charge
users for both communication/data transfer and CPU time [1].
As Path-PIR imposes additional computational requirements,
the question is how the additional computational costs relate to
the lower communication costs. We have implemented Path-
PIR in Java and run simulations in Amazon’s EC2 cloud. Path-
PIR’s source code is available for download [13]. Similar to
previous work [2], we have used the PIR scheme from Trostle
and Parrish [20], because of its conceptual simplicity and
efﬁcient server computation (adding two PIR values is simply
an integer addition). Similar results could be obtained with
efﬁcient additively homomorphic ciphers such as NTRU [7].
We chose security parameter k = 2048 as recommended by
the authors.

Setup. To benchmark our PIR protocols, we have con-
ducted our experiments using a single High-CPU Extra Large
instance. One hour of CPU time with such an instance costs
$0.58. To compare, Amazon charges $0.12 per GB trans-
ferred [1] (for the ﬁrst 12 TByte). The worst-case commu-
nication cost of Shi et al. [15] and Path-PIR can be exactly
computed based on N and l. Related work requires no server
computation, so we modeled cost based on communication
alone. To estimate communication time (download/upload), we
assume an 88 Mbps connection, in line with the maximum
speed one would expect when transferring from Amazon
S3 [12]. This is a very generous estimate, and our scheme

9

 1000

500

200

 100

)
s
(
 

e
m
T

i

50

20

 10

 0

 1000

500

)

B
M

(
 

n
o

i
t

i

a
c
n
u
m
m
o
C

200

 100

50

20

 10

5

2

 1

 10000

5000

)

B
M

(
 

n
o

i
t

i

a
c
n
u
m
m
o
C

2000

 1000

500

200

 100

 0

 1

0.5

0.2

 0.1

)

D
S
U

(
 
t
s
o
C

0.05

0.02

 0.01

 0

Path-PIR
Shi et.al.
Kushilevitz et.al.
Path-ORAM

 5

 10

 15

Database Size (TB)

(a) Communication for one read/write

Path-PIR
Shi et.al.
Kushilevitz et.al.
Path-ORAM

 5

 10

 15

Database Size (TB)

(c) Monetary cost for one read/write

Fig. 3. Path-PIR Evaluation Results

compares even more favorably in bandwidth constrained en-
vironments. Computation time for Path-PIR is calculated by
benchmarking on buckets of various sizes (using EC2).

Path-ORAM We

include
(even though it

comparison with
Path-
is not constant-memory)
ORAM [18]
since it
is currently the most efﬁcient known ORAM
protocol. We show that our scheme is very competitive with
Path-ORAM while requiring only constant client memory.

Figures 3(a), 3(b), and 3(c) show relative communication,
time, and monetary cost per read/write operation for related
work and Path-PIR. We consider databases of 1 MB blocks,
with total size between 1 and 16 TB. As the block size
increases, Path-PIR becomes more efﬁcient relative to related
work. Note that our scheme has even lower bandwidth require-
ments than Path-ORAM and very competitive monetary cost.
a) Latency: Figure 3(d) shows the extremely low cost
of ReadAndRemove operations in our scheme. This latency
property is important, because it represents the amount of
communication necessary before the client has access to their
data. The eviction, which takes up most of the communication,

10

Path-PIR
Shi et.al.
Kushilevitz et.al.
Path-ORAM

 5

 10

 15

Database Size (TB)
(b) Time for one read/write

Path-PIR
Shi et.al.
Kushilevitz et.al.
Path-ORAM

 0

 5

 10

 15

Database Size (TB)
(d) Latency ReadAndRemove

can be done in the background without user interaction. We
are able to obtain extremely low communication requirements
for this operation, since it requires transmitting only one full
block. Even compared to the best related work in any memory
setting, Path-PIR obtains vastly better latency.

VII. CONCLUSION

Outsourcing sensitive data to untrusted clouds requires not
only encryption, but also hiding user access patterns in an
efﬁcient manner. Path-PIR demonstrates that integrating PIR
into recent ORAM mechanisms provides better communication
without
incurring unreasonably large computational burden
on the cloud. Our experiments conﬁrm that Path-PIR’s cost
savings from the lowered communication complexity are sig-
niﬁcantly higher than the cost of extra computation. Addition-
ally, Path-PIR beneﬁts from constant memory complexity and
low latency that makes it especially conducive to constrained
devices like cell phones or embedded systems.

Acknowledgment: This work was partially supported by NSF grant
1218197.

Network Security Conference, pages 438–455, Beijing,
China, 2010. ISBN 978-3-642-13707-5.

[11] T. Mayberry, E.-O. Blass, and A.H. Chan. PIRMAP:
Efﬁcient Private Information Retrieval for MapReduce.
In Proceedings of Financial Cryptography, pages 371–
385, Okinawa, Japan, 2013. ISBN 978-3-642-39883-4.
[12] Nasuni. State of Cloud Storage Providers Industry Bench-
mark Report, 2011. http://cache.nasuni.com/Resources/
Nasuni Cloud Storage Benchmark Report.pdf.

[13] Path-PIR. Source Code, 2013. http://pasmac.ccs.neu.edu/

resources/pathpir.zip.

[14] B. Pinkas and T. Reinman. Oblivious RAM Revisited.
In Proceedings of Advances in Cryptology – CRYPTO,
pages 502–519, Santa Barbara, USA, 2010. ISBN 978-
3-642-14622-0.

[15] E. Shi, T.-H.H. Hubert Chan, E. Stefanov, and M. Li.
Oblivious RAM with O(log3(N )) Worst-Case Cost. In
Proceedings of Advances in Cryptology – ASIACRYPT,
volume 7073, pages 197–214, Seoul, South Korea, 2011.
ISBN 978-3-642-25384-3.

[16] E. Stefanov and E. Shi. Oblivistore: High performance
oblivious cloud storage. In Proc. of IEEE Symposium on
Security and Privacy, 2013.

[17] E. Stefanov, E. Shi, and D. Song. Towards practical obliv-
ious RAM. In Proceedings of Network and Distributed
System Security Symposium, San Diego, USA, 2012.

[18] E. Stefanov, M. van Dijk, E. Shi, C. Fletcher, L. Ren,
X. Yu, and S. Devadas. Path oram: An extremely simple
oblivious ram protocol, 2013. http://eprint.iacr.org/2013/
280.pdf.

[19] Techcrunch.

Google Conﬁrms That

It Fired
Engineer For Breaking Internal Privacy Policies,
2010.
http://techcrunch.com/2010/09/14/
google-engineer-spying-ﬁred/.

[20] J. Trostle and A. Parrish.

Efﬁcient computationally
private information retrieval from anonymity or trapdoor
groups.
In Proceedings of Conference on Information
Security, pages 114–128, Boca Raton, USA, 2010.

REFERENCES

[1] Amazon. Amazon Elastic EC2 Pricing, 2013. http://aws.

amazon.com/ec2/pricing/.

[2] E.-O. Blass, R. Di Pietro, R. Molva, and M. Onen.
PRISM – Privacy-Preserving Search in MapReduce. In
Proceedings of Privacy Enhancing Technologies, pages
180–200, Vigo, Spain, 2012. ISBN 978-3-642-31679-1.
[3] D. Boneh, D. Mazieres, and R.A. Popa. Remote Obliv-
ious Storage: Making Oblivious RAM Practical, 2011.
URL http://dspace.mit.edu/handle/1721.1/62006. Techni-
cal Report.

[4] O. Goldreich and R. Ostrovsky. Software protection and
simulation on oblivious RAMs. Journal of the ACM, 43
(3):431–473, 1996. ISSN 0004-5411.

[5] M.T. Goodrich, M. Mitzenmacher, O. Ohrimenko, and
R. Tamassia. Privacy-preserving group data access via
stateless oblivious ram simulation. In Proceedings of the
Twenty-Third Annual ACM-SIAM Symposium on Discrete
Algorithms, pages 157–167, 2012.

[6] Google.

2010.
new-approach-to-china.html.

A

new

China,
http://googleblog.blogspot.com/2010/01/

approach

to

[7] J. Hoffstein, J. Pipher, and J. Silverman. NTRU: A ring-
In Joe Buhler, editor,
based public key cryptosystem.
Algorithmic Number Theory, Lecture Notes in Computer
Science. Springer Berlin, Heidelberg, 1998.

[8] E. Kushilevitz and R. Ostrovsky. Replication is not
needed: single database, computationally-private infor-
mation retrieval. In Annual Symposium on Foundations of
Computer Science, 1997. Proceedings, pages 364 –373,
October 1997.

[9] E. Kushilevitz, S. Lu, and R. Ostrovsky.

On the
(in)security of hash-based oblivious RAM and a new
balancing scheme.
In Proceedings of Symposium on
Discrete Algorithms, pages 143–156, Kyoto, Japan, 2012.
[10] H. Lipmaa and B. Zhang. Two New Efﬁcient PIR-Writing
Protocols. In Proceedings of Applied Cryptography and

11

