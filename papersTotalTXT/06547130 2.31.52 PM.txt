2013 IEEE Symposium on Security and Privacy

Revisiting past challenges and evaluating certiﬁcate trust model enhancements

SoK: SSL and HTTPS:

Jeremy Clark and Paul C. van Oorschot

School of Computer Science
Carleton University, Canada

{clark,paulv}@scs.carleton.ca

Abstract—Internet users today depend daily on HTTPS for
secure communication with sites they intend to visit. Over
the years, many attacks on HTTPS and the certiﬁcate trust
model it uses have been hypothesized, executed, and/or evolved.
Meanwhile the number of browser-trusted (and thus, de facto,
user-trusted) certiﬁcate authorities has proliferated, while the
due diligence in baseline certiﬁcate issuance has declined. We
survey and categorize prominent security issues with HTTPS
and provide a systematic treatment of the history and on-going
challenges, intending to provide context for future directions.
We also provide a comparative evaluation of current proposals
for enhancing the certiﬁcate infrastructure used in practice.
Keywords-SSL; certiﬁcates; browser trust model; usability.

I. INTRODUCTORY REMARKS

Enabling end users to easily communicate sensitive data
online was a signiﬁcant milestone in the development of
today’s web, and, arguably, a necessary condition for its
explosive growth. Little-changed since its early days (1994–
2000), the core SSL/TLS technology persists as the basis
for securing many aspects of today’s Internet
including
software download, data transfer, user passwords, and for
site authentication. While centred on the HTTPS protocol
(HTTP over SSL/TLS), its security services—conﬁdentiality,
message integrity, and site authentication—fundamentally
rely on the correct interplay of out-of-band infrastructures,
procedures, and trust decisions.

While the web has moved from serving static information
pages to one which is relied on for billions of dollars of
commerce and for supporting critical infrastructures, there
has been an erosion of conﬁdence in the HTTPS certiﬁcate
infrastructure for multiple reasons, e.g., increasing issuance
of server certiﬁcates through fully-automated (domain val-
idated) procedures, a proliferation of certiﬁcate authorities
(CAs) which may either directly issue site certiﬁcates or
certiﬁcates for other CAs, and the compromise of real-world
CAs leading to increased concern amongst security experts
of real-world man-in-the-middle (MITM) attacks on HTTPS.
SSL/TLS has evolved in response to the discovery of
cryptographic weaknesses and protocol design ﬂaws. Prob-
lems with the certiﬁcate model appear to be more chal-
lenging, including among others: design and implementation

Extended version available [32].

issues in the CA/Browser (CA/B) trust model leading to
fragility (compromise of a single CA can, at least tem-
porarily, undermine system-wide security) and lack of trust
agility, poor support for certiﬁcate revocation, a reduction
in CA diligence in certiﬁcate issuance, and user interface
challenges related to reliably signalling to end-users,
in
ways not ignored or spoofed, security indicators and site
authentication information.

In this paper, we provide a broad perspective of the
SSL/TLS (henceforth TLS) mechanism, as employed with
web browsers for securing HTTP trafﬁc. We consider
HTTPS,
the underlying CA infrastructure, CA/B trust
model, and proposed enhancements. Among many important
HTTPS-related topics beyond our main focus are: phishing,
performance enhancements, use of certiﬁcates for client-
authentication, and the use of TLS beyond securing HTTP.
Our main contributions are the following: (1) We classify
and put into a broader context disparate contributions on
HTTPS security, spanning elements of cryptographic de-
sign and implementation, systems software, operations, and
human factors. (2) We provide a comparative evaluation
of existing proposals to enhance security aspects of the
CA/B model, deconstructing and evaluating their core ideas.
(3) Building on this contextual review, classiﬁcation, and
analysis, we summarize open problems and future research
directions. In addition, by systematic discussion of security
issues in a single place, we hope to provide perspective based
on the hindsight of a multitude of historical problems. Our
work highlights the overall complexity, including algorithms,
protocols, infrastructure, conﬁguration, and interfaces, and
contributes an overall understanding of which issues are
addressed by which enhancements and protocol revisions.

II. BACKGROUND

Historical Objectives: SSL was developed to address
Netscape’s needs for securing web trafﬁc, and speciﬁcally
designed to work well with HTTP [84]. Network protection
of data like credit card details sent from client to server
motivated two major design goals: conﬁdentiality, and server
authentication—sensitive data should be released only to
a party one would ‘intend to do business with,’ i.e., the

© 2012, Jeremy Clark. Under license to IEEE.
DOI 10.1109/SP.2013.41

511

correct web server.1 Client authentication was an optional
third goal, however the credit card number largely replaced
user identity. Even today, while TLS supports client-side au-
thentication, this feature is little-used on the public internet;
we do not consider it at length herein.

As Netscape intended SSL to be a core technology beyond
use with HTTP alone, and since most high-runner internet
protocols ran over TCP, SSL was designed to provide a gen-
eral channel that can be adopted with minimal modiﬁcation
by almost any TCP-based protocol seeking some security.
An important property was termed transparency: “the data
that one end writes is exactly what the other end reads [84].”
Protocol Speciﬁcation: HTTPS combines the network
protocol HTTP with the cryptographic protocol TLS. The
TLS protocol (v1.0, 1.1, 1.2) updates the older public
SSL protocol (v3.0). TLS provides a secure tunnel to a
server, which is most commonly authenticated by an X.509
certiﬁcate. Speciﬁcation of the cryptographic primitives used
by X.509 is largely delegated to PKCS standards. We do
not focus on protocols (e.g., IMAP or SMTP) other than
HTTP run over TLS, nor the use of TLS with transport
layer protocols other than TCP (e.g., DTLS).

III. CRYPTO PROTOCOL ISSUES IN HTTPS

In this section, we consider attacks on the TLS protocol
which relate to HTTPS security. Section IV expands focus
to the broader CA/B infrastructure and human decisions
involved. As TLS is well-documented, we assume familiarity
with the basic protocol. Many attacks reﬁne known tech-
niques; examining both historical and recent attacks provides
a fuller perspective.

A. Weaknesses in Cryptographic Primitives

1) Weak Encryption & Signature Key Lengths: Several
encryption functions offered in the ciphersuites of early
versions of TLS are no longer considered secure. Any
symmetric key encryption scheme with 40, 56, or 64 bit
keys is subject to a brute-force attack. TLS supported DES,
RC2, and RC4 with some of these key lengths. Asymmetric
encryption schemes like RSA are subject to factoring attacks
when used with a 512 bit modulus. A 2007 analysis of TLS
servers found that while only 4% of sites still offered RSA-
512, 93% supported (single) DES [68]. Note that support-
ing an insecure primitive does not imply it is ever used,
as security parameters are negotiated (but see Downgrade
Attacks below). NIST strongly recommends that primitives
hold the equivalent of 112 bits (symmetric) security strength
and will require this by 2014 [22] (e.g., phasing out 1024-bit
RSA/DSA and 193-bit ECDSA).

Key length is also an issue for certiﬁcates. Sufﬁcient key
lengths should be used by the certiﬁcate authority to sign a

1The meaning of ‘correct’ remains challenging today (see Section VI).

certiﬁcate, and CAs should only sign certiﬁcates containing
public keys that are of sufﬁcient length.2

2) Weak Hash Functions: To issue a site certiﬁcate, CAs
sign its hash. Collision-resistance of the hash is paramount:
an adversary that could construct two meaningful certiﬁcates
with the same digest could transfer a CA signature from
a benign site certiﬁcate to a malicious CA certiﬁcate. The
MD5 hash function, published in 1992, has been eligible
for providing certiﬁcate digests. However the collision re-
sistance of MD5 has deteriorated over time, from generic
attacks [102] to the ﬁrst published collision [37] to the gen-
eration of “meaningful” collisions [98], and ﬁnally ﬁnding
collisions that are structured enough to be both an acceptable
benign site certiﬁcate and a malicious root certiﬁcate [99].
Use of MD5 is discouraged (RFC 3279) and certiﬁcates
digested with MD5 are in decline [54]. MD5 remains
recommended in other places in the TLS protocol where
collision-resistance of the hash function is not critical, i.e.,
HMAC and key derivation [65], [25], [66].

B. Implementation Flaws and Related Attacks

1) PRNG Seeding: Many values in the TLS protocol
are generated randomly, including secret keys. This requires
a strong pseudorandom number generator (PRNG), seeded
with a high entropy seed. The Netscape browser (prior
to 1.22) relied on a PRNG implementation with weak
keys [51] allowing the TLS session key (master secret) to be
predictable. A 2008 change to the Debian operating system
reduced the randomness served to OpenSSL, which was
used to generate TLS certiﬁcates with predictable private
keys [24], [15], [110]. Recently, 0.5% of TLS certiﬁcates
were found to have recoverable RSA private keys due to
shared prime factors [53], [70]; most originated from poor
PRG seeding in embedded devices.

2) Remote Timing Attacks: Remote timing attacks have
been used against TLS servers that use an optimized variant
of RSA decryption, the default in OpenSSL versions prior to
0.9.7b [30], [13]. The decryption algorithm makes branching
decisions that are functionally dependent on the long-term
certiﬁed secret key. This results in measurable differences
in execution time, leaking information about the key during
TLS handshakes. Previous OpenSSL implementations of
ECDSA enabled similar remote timing attacks [29].

C. Oracle Attacks

The following attacks interactively and adaptively query
the victim’s protocol implementation, treating it as an oracle.
1) RSA Encoding: SSL 3.0 with the RSA ciphersuite uses
“textbook” RSA (which enables ciphertext malleability) for
transporting a PKCS#1 v1.5 encoded premaster secret to
the server during the handshake. If upon decryption and
decoding, the plaintext is not properly encoded, an error

2An intermediate CA in Nov 2011 was revoked for issuing certiﬁcates

for 512-bit RSA keys. http://www.entrust.net/advisories/malaysia.htm.

512

is returned to the client. An adversary could capture an
encrypted premaster secret, and,
in separate handshakes
with the same server, submit adaptively modiﬁed versions
of it, learning if they are conformant [27]. With just this
information, the adversary can eventually (∼1M queries)
recover the premaster secret. TLS 1.0 consequently recom-
mends that encoding errors are handled indistinguishably
from successful decryptions.3

2) CBC Initialization: In TLS 1.0 and earlier, all block
ciphers are used in cipher block chaining (CBC) mode.
Records are encrypted individually, however the initializa-
tion vector for each (except the ﬁrst) is set equal to the last
block of ciphertext sent (i.e., in a predictable way). CBC
with predictable IVs is not secure against chosen plaintext
attacks [23], and thus an adversary capable of injecting
partial plaintext into a TLS connection and of observing the
transmitted ciphertext can determine semantic information
about the rest of the plaintext [20], [21]. In one instantiation
of this attack, BEAST, an adversary submits adaptively
chosen cross-site requests for a domain with a secure cookie
to learn the value of the cookie (and by adjusting the amount
of the value included in a single block, due to partitioning,
the value can be guessed byte-by-byte) [38]. This issue is
resolved in TLS 1.1, not applicable to any stream cipher
(e.g., RC4), and is purportedly mitigated by ﬁrst sending
the ﬁrst byte as a separate record (‘1/n-1 record splitting’).4
3) Compression: The use of data compression is a ne-
gotiable option in TLS, although one never broadly sup-
ported by browsers. TLS does not obfuscate the length of a
compressed TLS record, thus again an adversary capable
of injecting partial plaintext into a TLS connection and
observing the post-compression record length can determine
semantic information about the rest of the plaintext [64].
An instantiation of this attack, CRIME, used a similar
setup to BEAST for recovering secret values from secure
cookies [89]. As a result, all major browsers have disabled
TLS compression.

4) CBC Padding: An extended version of this paper [32]
discusses oracle attacks on CBC padding [103], [31], which
until very recently [16] applied only to non-HTTPS proto-
cols run over TLS.

D. Protocol-level Attacks

1) Ciphersuite Downgrade Attack: The ciphersuite used
by the client and server is negotiated during the TLS hand-
shake. In SSL 2.0, a man-in-the-middle could inﬂuence the
negotiation and downgrade the strength of the ciphersuite to
the weakest acceptable by both parties. This is ﬁxed in SSL
3.0 and all versions of TLS by having the client send, once
the MAC keys have been established, an authenticated digest

3Also note that while RSA key transport support is ubiquitous, 60–70%
of servers also support Diffe-Hellmen key exchange [86], [104] which has
the added beneﬁt of perfect forward secrecy.

4A. Langley, “BEAST Followup,” ImperialViolet (blog), 15 Jan 2012.

of the previous handshake messages and waiting for an
authenticated conﬁrmation from the server. Thus, downgrade
prevention is contingent on the unavailability of weak MAC
functions for negotiation.

2) Version Downgrade Attack: The TLS version is also
negotiated and while version downgrade attacks are not
possible against a strict implementation of the TLS spec-
iﬁcation, many client implementations respond to certain
server errors by reconnecting with an older TLS version.
These server errors can be spoofed by an attacker. To prevent
an adversary from ﬁrst downgrading to SSL 2.0 and then
downgrading the ciphersuite, TLS prohibits downgrading
to SSL 2.0. TLS implementations may still be vulnerable
to downgrades from later version to earlier versions (e.g.,
from TLS 1.1+ to TLS 1.0 to exploit CBC initialization
vulnerabilities). One mitigation is to include the highest
supported version number in the list of ciphersuites during
negotiation, extending ciphersuite-downgrade protection to
versions [5].

3) Renegotiation Attack: Once a TLS connection has
been established, either party can at any point request a
new handshake, within the existing tunnel, to renegotiate
the cipher suite, session key, or other relevant connection
parameters. The renegotiation protocol was discovered to be
ﬂawed in 20095 and was subsequently updated [1]. The erro-
neous version allowed an adversary to establish a connection
to a server, send data, renegotiate, and pass the renegotiated
connection onto a client
is forming an
initial connection. This effectively allowed the adversary
to prepend chosen records to new HTTPS connections. An
extension [50] to the standardized countermeasures [1] can
provide a strong notion of renegotiation security.

that believes it

4) Cross-Protocol Attacks: An extended version of this
paper [32] addresses cross-protocol attacks [105], [74] where
parameters intended to be used in one setting (e.g., Difﬁe-
Hellmen) are replayed in a different setting (e.g., RSA).

IV. TRUST MODEL ISSUES IN HTTPS

Section III narrowly considered attacks on the TLS proto-
col and the cryptographic algorithms it involves. This section
assumes a perfectly functioning TLS protocol and considers
attacks on the broader CA/B infrastructure. Our analysis
covers the certiﬁcation process itself, who is allowed to be
a certiﬁcate authority (anchoring trust), how this authority
can be delegated (transitivity of trust), how certiﬁcates
are revoked (maintenance of trust), and how users interact
with certiﬁcate information (indication and interpretation of
trust). In what follows, we speciﬁcally note which issues
remain unresolved.

5M. Ray, “Authentication Gap in TLS Renegotiation,” Extended Subset

(blog), 4 Nov 2009.

513

A. Certiﬁcation

A web certiﬁcate binds a public signing key to an ‘iden-
tity.’ The correctness of the binding is asserted through a
digital signature, by a CA implicitly expected to maintain
the accuracy of the binding over time. TLS enables client
software to establish a conﬁdential channel terminated by the
entity holding the private key associated with the certiﬁcate.
The essential attribute that all HTTPS server certiﬁcates
have is a domain name which the certiﬁcate holder controls.
This is placed in the commonName (CN) attribute under
Subject, unless one or more domains are indicated in the
subject alternative name ﬁeld in an X.509 extension. If an
entity requests a certiﬁcate for a domain name, the CA will
typically challenge the requester to demonstrate control over
the domain. Note that this implicitly assumes that domain
names are mapped to the correct webserver (IP address), a
mapping accomplished through DNS. Such certiﬁcates are
called domain validated (DV) certiﬁcates.

Issued certiﬁcates may include additional CA-veriﬁed
information, such as organization name and postal address.
Validation procedures have degraded over time, exempliﬁed
by more CAs using a completely automated process (e.g.,
automated DV certiﬁcates). In response, the CA/Browser
Forum established extended validation (EV) certiﬁcates and
guidelines for their issuance,6 including diligent human val-
idation of a site’s identity and business registration details.

Security Issues (Certiﬁcation)

Hostname Validation (CAs): Automated domain val-
idation services provided by a CA will typically send a
validation email to a ﬁxed email address associated with
the CN’s top-level domain (e.g., admin@domain) or one
taken from CN’s WhoIS record. Both mechanisms rely on
accurate domain information; thus any disruption to the CA’s
ability to receive accurate DNS records (e.g., DNS cache
poisoning [61], [94]) could result in an improperly issued
certiﬁcate. For email validation, CAs should also ensure the
email address is only accessible to the site administrator. For
example, a certiﬁcate for the login page of Microsoft’s public
webmail service, login.live.com (formally Hotmail),
was wrongfully issued by a CA that offered to validate
through sslcertificates@live.com, an email ad-
dress that was open to public registration [111].

Even with non-automated validation, an adversary may
employ social engineering. For example, in 2001, a CA
wrongfully issued two certiﬁcates to someone posing as a
current Microsoft employee.7

Hostname Validation (Clients): Although current
browser platforms validate that a received site certiﬁcate

6CA/Browser Forum: Guidelines For The Issuance And Management Of

Extended Validation Certiﬁcates (v1.4), 2012.

7Microsoft MS01-017: Erroneous VeriSign-Issued Digital Certiﬁcates

Pose Spooﬁng Hazard, 22 Mar 2001.

matches the hostname, some non-browser software had inad-
equate validation. Many mobile applications display HTTPS
content and one study found that 1074 of 13500 Android
apps did not validate the hostname (aside from other TLS
implementation ﬂaws) [42]. A concurrent study identiﬁed
the lack of hostname validation in cloud clients (Ama-
zon’s EC2 libraries), e-commerce backend systems (Paypal’s
SDK), online shopping carts, ad networks (AdMob), and
other non-browser software employing HTTPS [49].

Parsing attacks: Flaws relating to parsing enable im-
proper issuance (incorrect CA parsing) and validation (in-
correct browser parsing) of certiﬁcates. Certiﬁcate requests
containing a null character (Ø) in the CN can be misinter-
preted. For example, a CN of bank.comØevil.com was
validated by some CAs’ automated domain validation as
evil.com while browsers have been known to accept it
as a valid CN for bank.com [62], [71]. A dangerous vari-
ation is *Øevil.com, which grants a universal wildcard
certiﬁcate acceptable to older NSS-based browsers [71].

Some CAs and browsers have also inconsistently in-
terpreted the object IDs specifying which string is the
commonName:
for example, CN is identiﬁed by OID
2.5.4.3 but some browser parsers accepted 2.5.4.003 or
2.5.4.18446744073709551619 (64-bit uint overﬂow) as the
CN, while some CAs ignore them [62].

EV downgrading: Many of the problems associated
with automated domain validation are claimed to be thwarted
by EV certiﬁcates. However a site that holds an EV certiﬁ-
cate can be downgraded to normal HTTPS by a man-in-
the-middle (MITM) attack with a fraudulent DV certiﬁcate.
Furthermore, such an adversary can arrange for the EV cer-
tiﬁcate to be displayed through a “rebinding” attack [112],
[96] that is consistent with the browsers’ origin policy [55].

B. Anchoring Trust

Validating that a certiﬁcate request comes from the entity
speciﬁed in the SubjectName is an important CA func-
tion. As no one entity has universal control of all names-
paces, it is not clear who is best suited for such validation.
As a result, there exists a spectrum of CAs, with the majority
of site certiﬁcates being issued by commercial CAs with ties
to the security or domain registration industries.

Software vendors (e.g., Microsoft, Apple, Mozilla, Opera)
conﬁgure a default
list of self-signed CA certiﬁcates in
operating systems and/or browser as trust anchors. Each
HTTPS site whose site certiﬁcate the browser accepts is thus
de facto trusted by users because its certiﬁcate has been
vouched for (directly or indirectly) by at least one of the
trust anchors. Mozilla’s Firefox 15, for example, includes
∼150 trust anchors from ∼50 organizations. However since
CAs with trust anchors can issue certiﬁcates empowering
other organizations to act as a CA (see below), the number
of automatically trusted CAs is much larger. The SSL Ob-
servatory reports that between Microsoft’s Internet Explorer

514

and Mozilla’s Firefox, ∼1500 CA certiﬁcates from ∼650
organizations8 in ∼50 countries are browser-accepted [39].
On private networks, particularly in corporate environ-
ments, a root certiﬁcate for the organization may be con-
ﬁgured as a trust anchor on employees’ machines. The
organization can then proxy (i.e., MITM) HTTPS connec-
tions with middleware boxes speciﬁcally designed for this
task to perform content inspection. The corporation may
even be able to obtain a browser-accepted CA certiﬁcate
for doing this, although issuing such a certiﬁcate is against
CA policies. For example, Trustwave admitted to issuing
certiﬁcates for this purpose but later revoked them,9 while,
purportedly by accident, TURKTRUST issued certiﬁcates
that were discovered being used this way.10 The mobile
browser OperaMini openly proxies HTTPS connections in
this way to allow compression between the client and
proxy [83]. Proxies assume all responsibility for certiﬁcate
validation, with a recent study ﬁnding that many implemen-
tations had validation ﬂaws [59].

Security Issues (Anchoring Trust)

CA Compromise: Without further enhancement (i.e.,
without the primitives evaluated in Section V), any trusted
CA can issue a browser-acceptable certiﬁcate for any site.
Thus an adversary can target the weakest CA to obtain a
fraudulent certiﬁcate and, assuming clients would not notice
a different CA,
this certiﬁcate enables the adversary to
evade detection in a MITM attack. In 2011, two CAs were
compromised: Comodo11 and DigiNotar.12 In both cases,
certiﬁcates for high proﬁle sites were illegitimately obtained
and, in the second case, reportedly used in a MITM attack.13
Compelled Certiﬁcates: Concerns have also been raised
about the abilities of nation-states to compel certiﬁcates
from a browser-accepted CA [93]. Governmental entities
are often well-positioned to proxy (i.e., MITM) HTTPS
connections by controlling network infrastructure and/or
compelling ISPs. For example, reportedly, HTTPS connec-
tions to Facebook over multiple ISPs within Syria were
MITMed with a Facebook certiﬁcate issued by the Syrian
Telecom Ministry.14 In this case, the Ministry was not a
browser-acceptable CA, and so it is not an example of a

8The reported number of organizations may be inﬂated due to variation
in organization name (or division) across certiﬁcates. Also in some cases,
the issuing CA retains actual possession of the intermediate certiﬁcate.

9Bug 724929, Bugzilla@Mozilla, reported: 7 Feb 2012.
10A. Langley, “Enhancing digital certiﬁcate security,” Google Online

Security Blog, 3 Jan 2013.

11J. Appelbaum, “Detecting Certiﬁcate Authority compromises and web

browser collusion,” Tor Blog, 22 Mar 2011.

12“Black Tulip Report of the investigation into the DigiNotar Certiﬁcate

Authority breach,” Fox-IT (Tech. Report), 13 Aug 2012.

state compelled certiﬁcate, but one that demonstrates the
danger posed.

C. Transitivity of Trust

Given that trust anchors can issue intermediate CA certiﬁ-
cates (and intermediates can be enabled to do the same), a
site certiﬁcate is browser-acceptable if the browser can build
a chain of certiﬁcates that lead to a trust anchor. One study
found 20% of valid certiﬁcates required no intermediate and
38% used one [18].

The path validation algorithm is speciﬁed in RFC 5280 to
begin with the server certiﬁcate and build the path “forward”
to the trust anchor, although there are efﬁciencies to building
in reverse [40]. Certiﬁcate chains are subject to constraints.
Intermediate CA certiﬁcates must be authorized to be a CA
(CA:TRUE under basicConstraints). CA certiﬁcates
may also restrict the number of CAs that can precede it
(i.e., toward the leaf) in the chain (e.g., pathlen:0 un-
der basicConstraints means the CA cannot delegate
further CAs and can only sign leaf certiﬁcates).

Servers are mandated to present an entire chain, but in
practice, browsers may use a chain discovery mechanism
(e.g., AIA: Authority Information Access). Intermediate CAs
are invisible to client software until
their certiﬁcate is
encountered, and yet they are essentially as trusted as an
anchor. This makes it difﬁcult for users or OSs/browsers to
preemptively know about and remove unacceptable interme-
diate CA certiﬁcates. As above, while only ∼50 organiza-
tions have visible trust anchors, many more organizations
have acceptable intermediate CA certiﬁcates. Technically,
Ford, Marks and Spencer, and the US Dept. of Homeland
Security are authorized for issuing acceptable certiﬁcates for
any website [39].

Security Issues (Transitivity of Trust)

Basic Constraints: Certiﬁcate path validation must also
check the constraints during validation, in particular that
each intermediate CA certiﬁcate has CA:TRUE set under
basicConstraints. If this is not checked, a certiﬁcate
obtained for a webserver could issue browser-acceptable
certiﬁcates for any other website. Initially not checked by
Microsoft’s CryptoAPI,15 this has now been patched.16 A
decade later, the issue resurfaced in Apple’s iOS.17

D. Maintenance of Trust

Another important function of a CA is to terminate the
validity of a certiﬁcate prior to its preconﬁgured expira-
tion date upon becoming aware of certain circumstances,
e.g., mistaken issuance, site or CA compromise, afﬁliation

13C. Arthur, “Rogue web certiﬁcate could have been used to attack Iran

(online), 5 Apr 2002.

dissidents,” The Guardian, 30 Aug 2011.

14P. Eckersley, “A Syrian Man-In-The-Middle Attack against Facebook,”

16MS02-050: Microsoft certiﬁcate validation ﬂaw, 2002.
17CVE-2011-0228: iOS certiﬁcate chain validation issue in handling of

15M. Marlinspike, “Internet Explorer SSL Vulnerability,” thoughtcrime

EFF Deeplinks (blog), 5 May 2011.

X.509 certiﬁcates, 2011.

515

change, a superseding certiﬁcate, or cessation of the holder’s
operations [45]. Revocation status must also be available
through the issuing CA, i.e., by certiﬁcate revocation lists
(CRLs) or online certiﬁcate status checking protocol (OCSP)
responders. CRLs are signed by the CA’s key while OCSP
responses are produced by servers designated by the CA.
CAs often prefer OCSP responders as they can be updated
on-demand without use of the (generally ofﬂine) CA signing
key and due to response size.

In practice, some CA certiﬁcates do not include any re-
vocation information, and when OCSP responders are spec-
iﬁed, they are often unresponsive. Thus, current browsers
fail open, accepting certiﬁcates for which revocation in-
formation cannot be located (browsers should downgrade
all EV certiﬁcates to a regular certiﬁcate, or warn, as
responsive revocation is an EV requirement).18 In response
to the failings of revocation, some browsers (e.g., Chrome)
maintain an updatable certiﬁcate blacklist (see Section V-C).
While the mandatory expiration date ﬁeld provides an
eventual default form of revocation, many certiﬁcates are
valid for multiple years (the median lifetime varies across
measurements: 12 [86], 12–15 [54], or 24 [18] months).

Security Issues (Maintenance of Trust)

Blocking Revocation: If an adversary is able to obtain
a fraudulent certiﬁcate for a site which is subsequently
revoked, it may take several days for this information to be
available to clients, even with OCSP, due to caching [101].
Even then, the clients may not be able to reach an OCSP
responder or CRL distribution point. Further, a MITM
adversary could respond to a client’s request with an HTTP
error (e.g., error 500: internal server error) or OCSP error
(response status 3: try again later [71]); in this case, the
revoked certiﬁcate typically continues to be accepted.

Similarly, a MITM adversary could prevent a browser
blacklist from updating but this would require persistent
blocking—the OCSP check would only occur when the
client encounters the fraudulent certiﬁcate and the MITM
adversary is already in position. The CA’s CRL could have
been obtained by checking an unrelated certiﬁcate.

Ownership Transfer: Since TLS site certiﬁcates are
bound to a domain name, certiﬁcates should be revoked
when domain ownership expires or is transferred. This is
however not typically enforced. For example, Facebook (the
target of the Syrian MITM attack mentioned above) acquired
fb.com for $8.5M in 2010 but can have no assurance that the
previous owner does not have a valid unexpired certiﬁcate
for the site that could enable a MITM attack.19

E. Indication and Interpretation of Trust

Some HTTPS security protections rely on user due dili-
gence. Perhaps naively, users are expected to verify the
outcome of each connection attempt, typically indicated by
a visual cue in the browser window. More diligent users
may verify certiﬁcate details; e.g., that the subject name—
organization, address, country—matches their expectation.
Finally, the browser may require users to respond to warning
dialogues in some cases.

Browser Security Cues: Desktop browsers typically use
two primary cues to indicate a website is being accessed
over HTTPS: (1) the URL in the address bar begins with
https:// and (2) a lock icon is displayed somewhere
in the browser’s chrome (i.e., the boundary region of the
window populated by the browser itself). Typically, clicking
on the lock icon will display information about the certiﬁ-
cate. One impedance to better user understanding of browser
security indicators is the inconsistency of how cues are
implemented across browsers [19]. Guidelines for browser
cues have been published.20

One study used eyetracking to ﬁnd that of 16 primed
participants interacting with an HTTPS site, 11 viewed the
lock, 7 the https:// indicator, and only 2 interacted with
the lock to display certiﬁcate information [108]. Another
study found that 63 of 67 participants logged into a hypo-
thetical banking website with all HTTPS indicators removed,
suggesting that many did not notice the difference [90]
(although one researcher argues this is enlarged by ﬂaws in
the study21). The introduction of EV certiﬁcates added a new
desktop browser cue, typically inducing the colour green in
the address bar itself or its font. Today’s desktop browsers
also display the organization name from the certiﬁcate in
the address bar, alongside the URL. One study found that
of 28 users, the “less than 40%” who actually looked at
browser cues (measured via eyetracking) was slightly but
not signiﬁcantly more likely to interact with an EV site than
a DV (domain validated) site [92]. Aside from cues, some
users appear to simply assume a page is secure based on the
information being requested [46], [35].

Browser Security Warnings: Browsers display warnings
if an HTTPS connection fails for certain reasons. One study
found that 30 of 57 users clicked through and logged into
a simulated banking website when it displayed a certiﬁcate
warning page [90]. Another study asked users about three
common warnings: expired certiﬁcates, certiﬁcate chains not
terminating in a trust anchor, and certiﬁcates not identically
matching the visited site’s domain. Of 409 users, only
36% understood the expired certiﬁcate warning, 28% the
unknown CA warning, and 40% the mismatched domain

2011.

18A. Langley, “Revocation doesn’t work,” ImperialViolet (blog), 18 Mar

20Web Security Context: User Interface Guidelines. W3C Recommenda-

19This example is meant to illustrate the principle rather than a vulner-

21A. Patrick. “Commentary on Research on New Security Indicators,”

ability with Facebook. Few users type in https://fb.com.

tion, 12 August 2010.

(online), 6 Mar 2007.

516

warning [100]. Of the users who did not understand, just
over a third claimed they would ignore each.22 Of the
users who did understand, 63% would ignore the expired
certiﬁcate warning, 33% the unknown CA warning, and
17% the mismatched domain. The study authors reworded
the warnings and saw improvements in understandability
but felt users still opened themselves to MITM attacks
in their actions. This study was replicated; users were
found to ignore warnings more than they self-report, and
no measurable difference was observed between ignoring
rewritten warnings and the browser defaults [95].

Mixed Content: A prevalent warning not considered
in the above studies is mixed content—the ability to weave
dynamic content from multiple sources into a single website.
When a site is accessed over HTTPS, browsers will issue
a mixed scripting warning if the site embeds any scripting
resources (e.g., Javascript, CSS, or even SWF [55]) that are
not accessed over HTTPS. This is important because the
script runs with the HTTPS site’s privileges. Some browsers
(e.g., Chrome) follow the lead of the Gazelle research
browser [106] and actively block insecurely loaded scripts.
Non-scripting resources (e.g., static images) or resources
loaded into an iframe will typically generate a less severe
mixed content warning (e.g., an https:// cue but no lock
or a lock with a caution sign; clicking on the cue displays
the warning). Finally, if an EV certiﬁed site embeds DV
certiﬁed scripting, the EV cues are still displayed, which
can be exploited (see Section IV-A above) [112], [96].

Mobile Browsers: With the advent of smartphones and
tablets, users also access HTTPS sites on mobile browsers.
Mobile browsers conform less to HTTPS user interface
guidelines than desktop browsers, with less support for
displaying certiﬁcate/connection details, distinguishing EV
certiﬁcates, or warning users about mixed content [19].

HTTPS Form Submit: A relatively common practice
is including a login box on an HTTP page, but arranging
any login information to be submitted over HTTPS.23 This
allows the overhead of obtaining the certiﬁcate and estab-
lishing a TLS connection to be avoided for users who visit
the page without logging in. Browsers include a general
warning (at least the ﬁrst time) when any information is
not submitted over HTTPS but since many submissions do
not require security (e.g., comments, posts, feedback, etc.),
it is sensible for users to disable this warning (an option
provided prominently). Beyond this, a user is given no cue
that sensitive information will be transmitted over HTTP or
HTTPS, let alone to which hostname. Of the Alexa top sites
with login pages, 19 of 125 offered such a post-to-HTTPS
login page while 56 of 125 only used HTTP [97].

22If they were hypothetically warned while at Craigslist or Amazon.
23E. Lawrence, “TLS and SSL in the real world,” IE Blog, 21 Apr 2005.

Security Issues (Indication and Interpretation of Trust)

Stripping TLS: Given users’ inattentiveness to HTTPS
security indicators and warnings, a MITM adversary may
thwart HTTPS in a technically detectable manner but one
unlikely to be noticed. For users being redirected to an
HTTPS site, arguably the most astute attack is to simply
relay pages back to the user over HTTP—an attack now
called SSL stripping after the sslstrip tool [71], although
it had been noted earlier [79]. On login pages served over
HTTP, the result of this attack is indistinguishable without
examining the page’s source code. On login pages typically
served over HTTPS, the user is relied on to realize the
difference or to generally refuse to log into pages served
over HTTP (which precludes using post-to-HTTPS sites).

Spooﬁng Browser Chrome: An important aspect of
security indicators is that they are placed in the browser
chrome, so the displayed cue is under the browser’s control
and not inﬂuenced by the content of the webpage being
displayed (this has been called a ‘trusted path’ [109]).
However as websites have been granted more power through
client-side scripting and control over how a browser window
is displayed, a variety of ‘web spooﬁng’ attacks [44] enable
the website to interfere with how a user perceives the
browser’s security cues. For example, a well-positioned pop-
up window without any chrome may overlap security cues
on the underlying page [69] or simulate a browser window
with complete browser chrome within the content of the
page [14], [109], [57]. In one study, a site implementing
the latter attack was classiﬁed as legitimate by 63% of
users [57]. Today’s desktop browsers typically force pop-up
windows into new tabs, maintaining a constant chrome. In
many mobile browsers, websites can position the address
bar so that
is hidden, enabling spooﬁng of security
indicators [43]. A solution suggested in the literature (but not
commercially adopted) is a dynamically changing browser
chrome [109], [34].

it

Users may also falsely attribute an HTTPS connection to
a lock displayed somewhere other than the chrome, e.g., on
the page content [35] or in the site’s favicon [72]. Of the
Alexa top sites with login pages, 29 of 125 displayed a lock
in the site content (including 70% of banks) or favicon [97].
Conceding a Warning: A MITM adversary may choose
to substitute in a certiﬁcate with an untrusted chain and hope
that users click-through or otherwise ignore the warning.
This was exempliﬁed in the previously mentioned attack
attributed to the Syrian Telecom Ministry.

V. SECURITY ENHANCEMENTS TO CA/B MODEL

Section IV reviewed the spectrum of issues with the CA/B
trust model. Here we evaluate a collection of the most
prominent among known proposals to enhance aspects of the
trust model, deconstructing and evaluating their core ideas.
A few of these ideas have been incorporated into one or two
browsers platforms; others can be achieved with a browser

517

COMPARATIVE EVALUATION OF PRIMITIVES TO IMPROVE THE CA/BROWSER MODEL. PROPERTIES (COLUMNS) ARE POSITIONED AS BENEFICIAL
WITH FULFILMENT DENOTED BY • AND PARTIAL FULFILMENT BY ◦ (FOR DETAILS, SEE SECTION V). RATINGS ARE FOR THE POTENTIAL OFFERED BY

THE GENERIC PRIMITIVE AND MAY DIFFER FROM CONCRETE INSTANTIATIONS OF PROPOSALS.

Table I

Protects ClientCredential
Intermediate CAs Visible
AfﬁrmsPOST-to-HTTPS
Trusted Entity
Responsive Revocation
DetectsLocal MIT M
Traceability
ReducesTraceability
UpdatablePins
Detects MIT M
DetectsTLS
No New
No New

Stripping

No New

Deployable withoutD NSSEC
StatusSignalled Completely
No Extra Com munications
No Server-Side Changes
User Decisions
Auth’n Tokens
No False-Rejects
InternetScalable
No New

Primitive

Security Properties Offered

Evaluation of Impact on HTTPS

B

C

Deployability

Security & Privacy
•
•
•
◦
◦

•
•
•
•

•

•

•
•
•
•
◦
◦
•
◦
•
•

•
•
•
•
•
•
•
•
•
•

•
•
•
•

•

•
•
•

•

•
•

•
•

•
•
•

•
•
•
•

•
•
•
•
•
•

•
•
•

•

◦
◦
•

◦
◦
•
•

•

•
•
•

•
•
•
•
•
•

•
•
•
•
•

Usability

•
•
•

•
•
•
•
•
•

•
•
•
•

•
•
•

•
•
•
•
•
•

•
•
•
•

◦
◦
•
◦
◦
•

◦
◦
•
•
◦
•
•

•
•

•
•
•
•
•
•

•
•
•
•
•
•

◦
◦
•
•

A

◦
◦
•
•
•

◦
◦
•
•

◦
◦

Key Pinning (Client History)
Key Pinning (Server)
Key Pinning (Preloaded)
Key Pinning (DNS)
Multipath Probing
Channel-bound Credentials
Credential-bound Channels
Key Agility/Manifest
HTTPS-only Pinning (Server)
HTTPS-only Pinning (Preloaded)
HTTPS-only Pinning (DNS)
Visual Cues for Secure POST
Browser-stored CRL
Certiﬁcate Status Stapling
Short-lived Certiﬁcates
List of Active Certiﬁcates

•
•
•

•

•
•

◦
•
•

◦
•
•
•

extension. Instead of focusing on speciﬁc tools, we distill
the main concepts behind each tool into a set of primitives
that can be combined in different ways to address security
issues within the CA/B model.

A summary is provided in Table I. The columns provide a
framework for evaluation. The ﬁrst set of columns, Security
Properties Offered, show a set of properties not met by
the current HTTPS and CA/B model but which selected
primitives (as designated in the rows) provide. Primitives
that offer a certain enhancement typically trade off aspects
of security, privacy, deployability and usability. The next set
of columns are used to evaluate the enhancement according
to Security & Privacy, Deployability, and Usability (cf. [28]).
Combination Logic: It is interesting to consider how
the primitives (rows) of Table I can be combined, to achieve
broader sets of enhanced properties. In general, if the prim-
itives of two rows are combined, the combined primitive
inherits the strongest level of individual fulﬁllment from
the Security Properties Offered columns (a logical-OR) but
the weakest level from the Evaluation of Impact on HTTPS
columns (a logical-AND).
A. Security Properties Offered by Primitives

Detecting Certiﬁcate Substitution (Table I–column A):

Section IV-B provided several examples of how adversaries

have illegitimately obtained browser-accepted certiﬁcates for
subject domains (targets) they do not control. An adversary
capable of modifying a TLS handshake intended for this
target (through e.g., wide-impact DNS hijacking or on-
path interception near the server) could actively replace the
target’s certiﬁcate with his own—a substitution allowing
read/write access to the encrypted content without triggering
browser warnings or errors. Primitives that detect such a
MITM attack involving a substituted certiﬁcate are listed
under Detects MITM (ﬁrst column, Table I). If a primitive
requires risk or “blind” trust on ﬁrst use (TOFU) to detect
these attacks, we use ◦ to denote partial fulﬁllment.

Some primitives detect only speciﬁc subclasses of such
MITM attacks. We say a MITM attack is local
if the
adversary is able to insert himself into connections to the
server from only a subset of clients (through e.g., poisoned
local DNS cache or on-path interception near the client);
if detectable,
the primitive fulﬁls Detects Local MITM.
An HTTPS connection is often used to transmit a client
authentication credential (e.g., a password or secure cookie)
to the host. Some primitives focus on protecting against
credential theft during an HTTPS MITM attack; these fulﬁll
Protects Client Credential. Again, blind TOFU primitives
partially fulﬁll (◦). Some primitives that use pinning (see

518

below) make false-reject errors if a server updates its public
key, switches issuing CAs, or uses multiple certiﬁcates for
the same host. Primitives that resolve such false-reject errors
fulﬁl Updatable Pins.

Detecting TLS Stripping (Table I–column B): Sec-
tion IV-E outlined TLS stripping attacks where HTTPS
POSTs [79] or GETs [72] are simply downgraded to HTTP
by a man-in-the-middle adversary. Since many enhance-
ments to HTTPS do not take into account security-relevant
details of a connection until there is an HTTPS request
from the client, TLS stripping bypasses them. Primitives that
can detect stripping attacks fulﬁl Detects TLS Stripping and
partially fulﬁl it if they rely on blind TOFU. Primitives that
deter (through enforcement or a security indicator) POST
requests from being submitted over HTTP fulﬁl Afﬁrms
POST-to-HTTPS.

PKI Improvements (Table I–column C): Sections IV-D
and IV-C respectively described two general problems with
the PKI infrastructure: the lack of reliable revocation and the
hidden nature of intermediate CA certiﬁcates. We assume in
evaluating the primitives that CRLs or OCSP responses are
not available and examine their ability to otherwise detect a
revoked certiﬁcate; primitives which do fulﬁll Responsive
Revocation. Primitives fulﬁl Intermediate CAs Visible if
every intermediate CA is visible to the user at any time.

B. Evaluation Criteria for Impact on HTTPS

Security & Privacy: Some primitives introduce new in-
frastructure elements, which include entities that contribute
to the trust decision or are queried when establishing an
HTTPS connection. A primitive not introducing any new
trusted parties fulﬁlls No New Trusted Entity, with partial
fulﬁllment if the responsibilities of an already trusted party
are expanded. If it does not introduce any new parties that
will become aware of all (or a fraction of) sites a user visits
over HTTPS, it fulﬁlls No New Traceability. If it eliminates
such a class of entities (such as OCSP responders) it fulﬁlls
Reduces Traceability.

In the current HTTPS model, servers authenticate them-
selves through certiﬁcates. Many primitives effectively intro-
duce new server authentication tokens, like (see below) pins
or signed OCSP responses, that are transmitted to the client.
Generally procedures for issuing, updating, and revoking
these new tokens must be established, as well as integrity
protection. Primitives that do not introduce such tokens fulﬁl
No New Auth’n Tokens.

Deployability: Primitives that do not change how web
servers implement TLS and HTTPS have the greatest poten-
tial for deployment. Primitives that do not require any server
involvement or code changes fulﬁll No Server-side Changes,
while primitives that only require servers to participate in
a way that does not
involve changing any server code
partially fulﬁlls it. Some primitives rely on DNSSEC which
has not been fully deployed;
the others are Deployable

without DNSSEC. If primitives do not introduce an extra
communication round that blocks completion of the connec-
tion, they fulﬁll No Extra Communications. Finally, Internet
Scalable systems could foreseeably support enrolment from
all current HTTPS servers and potentially beyond.

Usability: Evaluating usability properties is difﬁcult with-
out conducting user studies. However, some objective us-
ability properties can be determined from the design and
knowledge of the operating environment. A primitive fulﬁlls
No False-Rejects if it does not reject legitimate server certiﬁ-
cates. A primitive not fulﬁlling No False-Rejects requires the
user (e.g., through a warning dialogue) to distinguish false-
rejects from an actual attack. Primitives fulﬁll No New User
Decisions if they are automated and do not require users to
respond correctly to new security cues or dialogues.

In the current model, an HTTPS connection succeeds,
with a security indicator (closed lock), when a site certiﬁcate
is browser-acceptable. For some primitives, connections may
succeed for other reasons. For example, if a primitive is
blind TOFU, an indication of trust could be attributed to it
being the ﬁrst use or because the behaviour matches what
is expected. Depending on how these primitives are imple-
mented, users either (i) cannot readily determine the reason
for trust, (ii) are frequently warned, or (iii) a new security
cue is introduced. The latter two would respectively impact
No False-Rejects and No New User Decision. Instead of
assuming how these primitives should be implemented, we
identify them as not fulﬁlling Status Signalled Completely.
We award a partial fulﬁllment if the basis of trust is not clear
because server enrolment is optional, and thus a fallback
trust mechanism may be also necessary.

C. Summary and Evaluation of Proposed Primitives

Here we describe the proposals summarized in Table I.
Due to space constraints, detailed justiﬁcation of the ratings
is provided in the extended version of this paper [32].

Key Pinning (Client History): Other than the browser
trust anchors, validating an HTTPS server certiﬁcate is
a stateless process, independent of any previous browser
acceptable certiﬁcates seen for a particular site. A pinning
primitive based on client history (also called inductive
pinning) remembers the last browser-acceptable public key
encountered for a particular site and warns the user if this
information changes. This allows detection of certiﬁcate
substitution attacks, even if the adversary has somehow
obtained a browser-acceptable certiﬁcate—but only if the
user has visited the site previously. Note that the term ‘key
pinning” (used here and below) is a slight misnomer, as the
pin could specify anything from the entire certiﬁcate chain to
a predicate applied over various certiﬁcate attributes to only
the SubjectPublicKeyInfo ﬁeld of the server certiﬁcate.
Client-based key pinning is proposed in CertLock [93]
(which pins the issuing CA country) and implemented in

519

Firefox extension Certiﬁcate Patrol (which pins the entire
chain and shows differences through a dialogue).

Key Pinning (Server): With client-side key pinning, a
trade-off results from the level of granularity of certiﬁcate
information being pinned. Servers are better positioned to
themselves know which certiﬁcate attributes are likely to
remain stable over time, and certiﬁcate rollovers are typ-
ically planned in advance. Server-asserted pinning allows
the server to specify in an HTTPS header or TLS extension
which certiﬁcate attributes to pin and for how long. One
proposal, HPKP [10], suggests that servers specify a set of
public keys (the SubjectPublicKeyInfo ﬁeld of an X.509
certiﬁcate) of which one must be present in each interaction.
A second proposal, TACK [12], is similar but organizes
server keys under a new TACK signing key, to which the
hostname is pinned by the client. The TACK key is used
to sign server certiﬁcates and can allow revocation (see Key
Agility/Manifest below).

Key Pinning (Preloaded): To avoid the blind TOFU
approach of server-asserted key pinning, browser vendors
could include a list of pins within the browser itself. Google
Chrome currently pins a number of certiﬁcates for its own
domains, as well as others by request.24 Among other issues,
this pinning allowed Chrome users to detect the earlier-
mentioned MITM attack involving DigitNotar. The list could
be populated by entities other than the browser vendor.

Key Pinning (DNS): Recall that some CAs offer DV
certiﬁcates to sites that can demonstrate control over the
DNS record for their hostname. If a CA does no more than
look at a DNS record to validate ownership then couldn’t
clients do it instead, cutting out the CA? In practice, it is
easier for an adversary to manipulate the client’s view of
DNS, which could rely on a cache or local resolver [94].
However with DNSSEC, records digitally signed by the
name servers give clients the ability to validate records.
The DNS-based Authentication of Named Entities (DANE)
protocol [3] proposes that servers pin their public key in
their DNSSEC record for clients to validate against.

We note one beneﬁt of DNS-based pinning proposed [7]
not captured in our framework. Even without DNSSEC,
sites could pin certiﬁcate attributes such as acceptable CAs,
for other CAs to reference if they are ever asked, perhaps
illegitimately, to generate a certiﬁcate for the site. This offers
protection against social engineering attacks that imperson-
ate a domain owner to a CA.

Multipath Probing: Crowdsourcing is an approach with
many technological applications. Applied to making trust de-
cisions in HTTPS, crowdsourcing might take one of several
forms. First, participants could contribute objective (e.g., “I
have seen this certiﬁcate before”) or subjective (e.g., “I do
not trust the CA that issued this certiﬁcate”) information. We
cannot deﬁnitively evaluate subjective crowdsourcing as the

24A. Langley, “Public key pinning,” Imperial Violet (blog), 04 May 2011.

520

properties it achieves depend on the quality of information
provided by a client’s peers. Tools that enable subjective
trust assertions (whether crowd-sourced or from a delegated
authority) include Omnibroker [9], Monkeysphere (web of
trust PKI for HTTPS), YURLs (URLs with a built-in public
key ﬁngerprint obtained from a trusted peer), and S-Links
(links to HTTPS sites where the links specify certiﬁcate
information or extra validation steps).

Objective measurements generally fall along the dimen-
sions of time (e.g., “I see the same certiﬁcate as last
time”) and space (“I see the same certiﬁcate as my peer”).
Time-based measurements are captured by inductive client
pinning, however we note that the usefulness of blind TOFU
can be extended by ﬁnding the peer with the earliest “ﬁrst
use.” Multipath probing is a space-based measurement; the
idea is to establish if the client receives a certiﬁcate that
is consistent with the certiﬁcate received by independent
observers (notaries) distributed across the internet. Multipath
probing can detect local certiﬁcate substitution attacks, but
not attacks where all trafﬁc to the host is modiﬁed.

As a primitive, multipath probing was proposed in Per-
spectives [107], available as a Firefox extension. Conver-
gence [73], also a Firefox extension, is a reﬁnement that
provides a more general architecture for crowdsourcing that
could include subjective information as well as objective
measures. Another reﬁnement, DoubleCheck [17], probes
from multiple servers in the existing Tor anonymity network
(which cleanly eliminates the privacy threat notaries pose
in terms of tracking). In addition to network devices, any
collection of certiﬁcate data can additionally be consulted for
an independent perspective (e.g., the SSL Observatory [39]
or ICSI Notary [18]). Certiﬁcate Transparency (CT) [6]
is a proposal for creating a central audit log of HTTPS
certiﬁcates, which is veriﬁably append-only and maintained
by independent monitors.

Channel-bound Credentials: Some primitives forgo de-
tecting MITM attacks in favour of protecting some of
the information otherwise subject
to theft by a MITM
adversary. HTTPS is commonly used to provide secure
transport of client authentication credentials, e.g., passwords
and cookies. Channel-bound credentials make such creden-
tials functionally dependent on the speciﬁcs of the HTTPS
connection—speciﬁcs an adversary cannot replicate even
with a browser-acceptable certiﬁcate for the site. Rather than
modifying user-chosen passwords, these primitives modify
the authentication value in cookies. With channel-bound
cookies [36], this value is cryptographically bound to a
semi-persistent, site-speciﬁc public key certiﬁcate generated
on-the-ﬂy by the client, called an origin bound certiﬁcate
(OBC). To login with such a cookie, the client ﬁrst es-
tablishes a mutually authenticated TLS connection using
its OBC and then transmits the OBC-dependent cookie. A
MITM adversary cannot successfully use a stolen OBC-
bound cookie unless it can establish an OBC-authenticated

TLS session, which requires knowledge of the corresponding
private key. OBCs were then revised (for details not pertinent
to preventing MITM cookie theft) and renamed Channel
ID. The channel-bound credential primitive has also been
proposed for use in conjunction with a user device: e.g., a
token [78] or smartphone [81].

Credential-bound Channels: Credential-bound channels
prevent credential theft from MITM adversaries by reversing
the idea of channel-bound credentials—instead of having the
server decide to accept a credential based on its binding
to a client certiﬁcate, the client decides whether to accept
a server certiﬁcate based on its binding to the client’s
credential. This primitive assumes a pre-shared password
(and does not protect the password during the initial es-
tablishment). In one proposal called direct validation of
certiﬁcates (DVCert)25 [33], the server uses a PAKE-based
protocol to demonstrate knowledge of the client’s password
while attesting to the value of its certiﬁcate.26

Key Agility/Manifest: When preventing MITM attacks
without involving the server (i.e., through inductive client
pinning or multipath probing), it is difﬁcult to distinguish
attacks from legitimate reasons that a different certiﬁcate
may be observed at different times (certiﬁcate update) or
from different locations on the network (multiple certiﬁ-
cates used by the same host). At the cost of server-side
changes, many of the examples of the primitives evaluated
thus far address these issues with (i) a “key manifest,”
i.e., a speciﬁcation of all keys that could be used by the
domain; and/or key agility, i.e., an update mechanism for
new certiﬁcates that could be implemented as either (ii)
signing the new certiﬁcate with the old certiﬁcate’s key, or
(iii) linking the certiﬁcate changes through use of a master
secret. One or more of these can be seen in: server-side key
pinning, TACK, DANE, and DVCert. The Sovereign Key
proposal [11] is also similar to (iii), in that servers establish
and broadcast a long-term signing key used to cross-certify
all their certiﬁcates. Although Table I evaluates the primitive
in isolation, in these examples, it is combined with another
primitive, e.g., key pinning or multipath probing, to detect
MITM attacks while eliminating false-reject errors due to
certiﬁcate updates and load-balancing.

HTTPS-only Pinning (All Types): The primitives consid-
ered above do not address (or attempt to) TLS stripping
attacks. This is largely because the primitives are never
invoked unless an HTTPS connection is requested. With
TLS stripping, this stage is never reached for the client.
The chief mechanism for preventing TLS stripping is to
make certain domains only support TLS and communicate
this to clients with a pin. As with key pins, HTTPS-
only pins can be communicated by the server in request
headers or TLS extensions, pre-established in the user’s

browser, or obtained from the DNS record of the site.
Proposals for all three types exist: ForceHTTPS [56] and its
reﬁnement in HSTS [8] are server-initiated pins; Chrome 22
ships with over 100 HTTPS-only pins; and Service Security
Requirement (SSR) [4], [80] records can specify (among
other things) that a site is HTTPS-only in its DNS record
(signed through DNSSEC). Some browser extensions, like
HTTPS Everywhere, redirect the HTTPS version of sites
according to a curated whilelist of domains.

Beyond TLS stripping, HTTPS-only pins can also ensure
a cookie scoped to the domain of the pin is always sent
over HTTPS, regardless of whether the website developer
remembered to mark the cookies as secure [56], [67].

Visual Cues for Secure POST: A simple client-side prim-
itive can address certain types of TLS stripping. Sites are
frequently designed to cause login credentials to be POSTed
to an HTTPS site from an HTTP site. A persistent security
cue could be introduced to indicate if a form POSTs to
HTTP or HTTPS (beyond the easily-disengaged warning
upon an initial POST-to-HTTP). One proposal, the SSLight
browser extension [91], adds a “trafﬁc light” cue to login
form ﬁelds that displays a green light if and only if the
ﬁeld is posted to the current domain over HTTPS (a yellow
light indicates cross domain HTTPS posts and red indicates
POST-to-HTTP). Note that the browser needs to retrieve
the site certiﬁcates associated with all POSTs on the page,
largely nullifying the main performance beneﬁt from not
serving the landing page over HTTPS to begin with. Further,
the choice of displaying the cue in the login form ﬁeld itself,
which is part of the site content, risks a malicious modiﬁed
site obscuring the real cue and spooﬁng its own (cf. [109]).
Browser-stored CRL: Four prominent long-standing re-
vocation approaches are [77]: CRLs, online certiﬁcate status
checking, short-lived certiﬁcates, and trusted directories. The
CA/B model uses the ﬁrst two through CRLs and OCSP
respectively. Given the shortcomings of current revocation
procedures (Section IV-D), attention to improving the re-
sponsiveness of revocation is being pursued along the lines
of all four types. Browser-stored CRLs fall under the ﬁrst
(CRLs), modifying the architecture of CRL distribution from
the current CA/B model. Instead of user clients fetching
CRLs (and OCSP responses) directly from CRL distribution
points, the browser vendor fetches these periodically and
sends to the browser an updated master CRL for storage.
All major browsers manually revoke high risk certiﬁcates
through software updates, but Chrome has implemented a
more general CRL that can be transparently updated.27

Certiﬁcate Status Stapling: In the same way that Browser-
stored CRL is an architectural change to how CRLs are
distributed in the current CA/B model, Certiﬁcate Sta-
tus Stapling modiﬁes the distribution of OCSP responses.

25This is not to be confused with domain validation (DV) certiﬁcates.
26This is better than the server MACing its certiﬁcate with the shared

password, which would admit an ofﬂine password dictionary attack.

27A. Langley, “Revocation checking and Chrome’s CRL,” Imperial Violet

(blog), 05 Feb 2012.

521

Currently, a user client requests a status report from a
CA-designated OCSP responder, but responders are often
overwhelmed or do not usefully respond, in which case,
the HTTPS connection typically completes without warning.
Under Certiﬁcate Status Stapling,
the certiﬁcate holders
periodically obtain signed and timestamped status reports,
and include these with their certiﬁcate during a handshake
(cf. [88]). Within HTTPS, this is deﬁned as a TLS exten-
sion [2] and commonly called OCSP-stapling. The RFC
only permits a report on the server certiﬁcate, not the entire
chain—a signiﬁcant drawback. However Table I evaluates
the general idea of stapling reports on the entire chain.

Short-lived Certiﬁcates: This primitive, representing the
third type of revocation, replaces long-lasting certiﬁcates
with short-lived ones that certiﬁcate holders frequently re-
new [88]. Revocation results from simply failing to update
a certiﬁcate. In a recent proposal and implementation for
short-lived HTTPS certiﬁcates [101], servers are issued
certiﬁcates with a four-day lifespan (roughly the lifetime of
common cached OCSP responses) either on-demand or in
batches. It is proposed [101] to be used in conjunction with
Browser-stored CRL and Key Pinning (Server).

List of Active Certiﬁcates: The fourth revocation method
is trusted directories, by which we mean a publicly search-
able list of valid certiﬁcates. In HTTPS,
this could be
implemented as a whitelist of every server and CA TLS
certiﬁcate (including intermediates) that is acceptable to the
HTTPS clients that rely on this list. A certiﬁcate not on
the list is not acceptable in any part of the certiﬁcate chain.
Revocation is accomplished by removing the certiﬁcate from
the list. This primitive makes visible all intermediate CAs,
and also allows domain owners to monitor for illegitimately-
issued certiﬁcates for their domains. No proposal for full-
ﬂedged List of Active Certiﬁcates has been made. It is similar
to Certiﬁcate Transparency [6] (see above) but differs on the
issue of revocation: the CT log is meant only as a reference
for discovering suspicious certiﬁcates, not an authoritative
whitelist for making trust decisions. Also CT currently logs
site certiﬁcates only, which means intermediate CAs are
visible only if they issue site certiﬁcates.

VI. FURTHER DISCUSSION AND ON-GOING RESEARCH
Further discussion here ﬁrst mentions research areas or-
thogonal to our main focus on HTTPS and its certiﬁcate trust
model. We then discuss primary areas of ongoing research.
1) Important Orthogonal Problems: The original objec-
tive [84] of HTTPS was to provide a conﬁdential channel
with message integrity and server authentication. However
HTTPS does not bridge the cognitive gap (exposed by phish-
ing, even with the presence of TLS certiﬁcates) between the
user’s cognitive notion of what organization they intend to
connect with, and the domain name within the content of
a certiﬁcate—and the latter is the only information in DV
certiﬁcates that can be relied on. (It is interesting to ask: does

522

identiﬁcation of a syntactic domain name deliver the desired
property of “server authentication”?) As for the extremes,
many websites do not use TLS at all, while for the minority
that use EV-SSL certiﬁcates, the validated organizational
details are arguably insufﬁcient—they are not referenced by
users, nor typically endorsed by CAs familiar to users, even
if users did understand how certiﬁcates were meant to work.
For these reasons, TLS in its present form fails to close this
cognitive gap. It remains an open research problem to ﬁnd
methods to address this issue.

HTTPS can protect the secrecy and integrity of cookies in
transit; browser policy dictates the conditions for read/write
access to cookies marked as secure. Likewise, browsers must
handle mixed content carefully, including how/when to alert
users—e.g., different policy decisions are needed to handle
the mixing of secured and unsecured content according to
three delivery mechanisms (no TLS, TLS, and EV TLS) and
different content types (e.g., images, objects, scripts). Cookie
security and mixed content remain challenging problems.

A compromised client-platform (e.g., due to malware) can
subvert HTTPS protections, including how protections are
communicated to the user. Research on building veriﬁed
kernels, trusted modules, and/or trusted paths into client
platforms therefore complements HTTPS. Other orthogonal
issues include the availability of the HTTPS infrastructure
(e.g., DDOS attacks, restrictive networks, captive portals)
and improving performance (e.g., False Start, Snap Start).
2) Protocol-level TLS–Analysis and Modiﬁcation: The
complexity of TLS has signiﬁcantly enabled protocol at-
tacks, even after 15 years. Analysing TLS security in suf-
ﬁciently broad models remains an open research problem.
Among other challenges, designing a protocol with provable
security is easier than proving the security of a ﬁxed protocol
like TLS; many proof techniques require simplifying as-
sumptions or the ability to make at least minor modiﬁcations.
Security analysis of the basic functionality of TLS [105],
[75], [82], [52], [26], [76], [48], [47], [58], [50] and its use
of cryptographic primitives [65], [60] has provided results
both positive (security proofs) and negative (attacks).

The discovery of ﬂaws in non-essential or little-used
components of TLS has produced a culture of work-arounds
by disabling features (e.g., renegotiation, CBC-mode cipher-
suites, and compression as cited earlier) rather than protocol
redesign. Such quick ﬁxes are at the expense of long-term
protocol evolution: e.g., as of 2011, 99.6% of HTTPS sites
did not yet support TLS 1.1 or 1.2 [87].

Some aspects of TLS are agile, e.g., AES adoption
was “quick” [68] due to a pre-existing ability to negotiate
blockciphers. Other aspects, however, are not agile, e.g., the
two hashes used for pseudorandomness (MD5 and SHA1)
in TLS 1.0 are non-negotiable, impeding SHA2/3 adoption;
and likewise, the RSA padding format used for key transport
impedes OEAP support [85], [25]. An open challenge is how
to expedite protocol upgrades; TLS 1.2 adds agility but had

only a 0.02% adoption rate in 2011 [87].

3) Trust Model Infrastructure: Critical research questions
remain regarding the CA/B trust model—is its continued
use unavoidable, does it still solve more problems than it
creates, or has it become a liability? In the real world, trust
is transitive in at most short chains whereas the CA/B model
allows long chains. But even in a chain involving only one
intermediate CA, the end-user, de facto, ends up ‘trusting’
the browser vendor who sets hundreds of trust anchors in
the browser, the corresponding anchor CAs for endorsing
thousands of intermediate CAs, and these intermediate CAs
for certifying millions of websites. The end-user, as a relying
party, in many cases would have no knowledge of or business
relationship with CAs involved in these chains, and the CAs
are apparently not accountable to end-users for errors. It is
also worth remembering that in the original CA/B model,
there were only a handful of CAs.

For better or worse, we have achieved spontaneity, one of
the original goals [84] of TLS—an online world with great
convenience. In fact, users can now go online for the ﬁrst
time and without any personal choices, ‘trust’ millions of
sites. It would be unreasonable to expect this in the physical
world; is it a realistic reﬂection of trust in the digital world?
Progress is being made—e.g., on increasing the transparency
of the anchor selection process (e.g., Mozilla’s policies
and public discussion for CA inclusion), indexing active
CAs on the public internet [39], and providing users with
conﬁgurable (and potentially delegatable [71]) trust anchors.
4) Human Element and the Security User Interface: Once
CA trust anchors are somehow conﬁgured, browsers can
automate many HTTPS security decisions, while providing
to users status indicators through its interface. However, for a
range of ‘soft’ errors—e.g., expired certiﬁcates, mismatched
domains, mixed content/scripting, untrusted CAs (includ-
ing self-signed)—it
remains without consensus whether
browsers should fail open (with or without an indicator), fail
closed, or provide a warning dialogue. Research reviewed
in Section IV-E indicates low user conﬁdence in navigating
the current set of indicators and warnings. Testing defaults,
UI changes, and the wording of warning dialogues requires
further research, as well as protocol ‘ceremony’ [41], [63],
[83] analysis that includes humans.

The challenges in designing usable security interfaces hint
at a deeper problem with users’ mental models of HTTPS.
Experts can understand the relationship between encryption
and authentication in TLS, and that a lock icon does not
indicate that a website is safe in all senses. The inability of
the community to provide interfaces and/or mechanisms that
average users can understand remains problematic.

5) Raising the Bar (or Just Moving It): Many of the
practical security issues with today’s CA/B infrastructure
result from a lack of defence in depth—e.g., the compromise
of a single CA defeats many current deployments of the
model. Many of the enhancements in Table I aim to add

depth by addressing MITM attacks, TLS stripping attacks,
and revocation issues. Combining several primitives into the
current infrastructure (e.g., in an attempt to fully address
MITM) offers the advantage of increasing protection, at the
cost of a patchwork with increased complexity. A different
approach is to seek alternatives that replace the functionality
of CAs outright; in fact, some primitives in the table might
be viewed as doing this.

A currently high proﬁle approach that might be viewed
as doing this is DNSSEC-based pinning (e.g., DANE),
which provides an infrastructure for ubiquitous HTTPS,
largely replacing the need for CA-issued DV certiﬁcates.
(Of course, many questions remain regarding performance,
caching, and packet inspection if this were to be widely
deployed or enabled by default.) It could be argued that the
serious consideration currently being given to DANE signals
the degree to which trust in CA-validated certiﬁcates has
slipped, rather than the strength of DANE as an alternative.
DNS pinning by itself falls short of fully addressing the
original HTTPS goal related to authentication, namely to
support the transport of sensitive data to only an intended
party. As mentioned above in relation to phishing,
the
intended target is not often identiﬁed by a domain name
in the user’s mind, but rather by the user’s conception
of a real-world entity. The extent to which high-assurance
extended validation certiﬁcates can be leveraged to provide
recognizable assurances to users remains an open question.

VII. CONCLUDING REMARKS

Among our objectives, we hope to raise awareness of
the number and breadth of past and on-going security
issues with HTTPS and its certiﬁcate trust model, allowing
independent determination of their relative severities and
root causes. The sophistication and difﬁculty of attacking
the TLS protocol directly has apparently shifted attention,
over time, to the security of the CA/B infrastructure and its
reliance on human factors. Indeed, in the research literature,
it is becoming more common for threat models to assume
an adversary possesses a valid certiﬁcate for a targeted site.
From our comparative evaluation of proposals for en-
hancing the certiﬁcate infrastructure, several research trends
are apparent. Among these: a variety of pinning techniques
propose adding defence in depth (a) against attacks involving
fraudulent certiﬁcates, and (b) against SSL stripping attacks
(which are deceptively simple); many primitives rely on a
trusted initialization before providing protection; and the
continuing failure of HTTPS support as it exists today to
provide responsive certiﬁcate revocation information.

Replacing the CA infrastructure is often viewed by indi-
viduals in the computer industry as a way forward. This may
not, however, improve things unless the current underlying
weaknesses do not reappear. Though certiﬁcate issuance was
historically independent of DNS, tighter integration of the
certiﬁcate trust model with domain names, and potentially

523

[2] RFC 6066: Transport layer security (TLS) extensions: Extension

CHI, 2006.

extension, 2010.

deﬁnitions, 2011.

more tightly with DANE, has been a notable evolution.
A reasonable question to ask is: what tangible beneﬁt to
users does the best-possible commercially viable certiﬁcate
validation offer beyond a binding between domain names
and public keys? The answer may dictate the future of CAs.
Acknowledgements. We thank those who provided de-
tailed comments on the paper, including the anonymous
referees, Carlisle Adams, Joseph Bonneau, Cormac Herley,
Adam Langley, Tim Moses, Trevor Perrin, and Sid Stamm.
We acknowledge funding from the Natural Science and
Engineering Research Council (NSERC) through a PDF
(ﬁrst author), Canada Research Chair in Authentication and
Computer Security (second), and NSERC ISSNet (both).

REFERENCES

[1] RFC 5746: Transport layer security (TLS) renegotiation indication

[3] RFC 6698: The DNS-based authentication of named entities (DANE)

transport layer security (TLS) protocol: TLSA, 2012.

[4] Internet-Draft: Storing service security requirements in the domain

name system, 2006.

[5] Internet-Draft: Maximum version TLS cipher suites, 2011.
[6] Internet-Draft: Certiﬁcate transparency, 2012.
[7] Internet-Draft: DNS certiﬁcation authority authorization (CAA) re-

source record, 2012.

[8] Internet-Draft: HTTP strict transport security (HSTS), 2012.
[9] Internet-Draft: OmniBroker protocol, 2012.
[10] Internet-Draft: Public key pinning extension for HTTP, 2012.
[11] Internet-Draft: Sovereign key cryptography for internet domains,

2012.

[12] Internet-Draft: Trust assertions for certiﬁcate keys (TACK), 2012.
[13] O. Aciic¸mez, W. Schindler, and C¸ . K. Koc¸. Improving Brumley and
Boneh timing attack on unprotected SSL implementations. In CCS,
2005.

[14] A. Adelsbach, S. Gajek, and J. Schwenk. Visual spooﬁng of SSL
protected web sites and effective countermeasures. In ISPEC, 2005.
[15] D. Ahmad. Two years of broken crypto. IEEE Security and Privacy,

6(5), 2008.

[16] N. J. AlFardan and K. G. Paterson. Lucky thirteen: Breaking the
TLS and DTLS record protocols. In IEEE Symposium on Security
and Privacy, 2013.

[17] M. Alicherry and A. D. Keromytis. Doublecheck: Multi-path

veriﬁcation against man-in-the-middle attacks. In ISCC, 2009.

[18] B. Amann, M. Vallentin, S. Hall, and R. Sommer. Revisiting SSL:
A large-scale study of the internet’s most trusted protocol. Technical
report, ICSI, 2012.

[19] C. Amrutkar, P. Traynor, and P. van Oorschot. Measuring SSL
indicators on mobile browsers: Extended life or end of the road?
In ISC, 2012.

[20] G. Bard. The vulnerability of SSL to chosen-plaintext attack.

Technical Report 2004/111, IACR ePrint, 2004.

[21] G. V. Bard. A challenging but feasible blockwise-adaptive chosen-

plaintext attack on SSL. In SECRYPT, 2006.

[22] E. Barker and A. Roginsky. Transitions: Recommendation for
transitioning the use of cryptographic algorithms and key lengths.
Special Publication 800-131A, NIST, 2011.

[23] M. Bellare, A. Desai, E. Jokipii, and P. Rogaway. A concrete security

treatment of symmetric encryption. In FOCS, 1997.

[24] L. Bello and M. Bertachhini. Predictable PRNG in the vulnerable
Debian OpenSSL package: the what and the how. In DEFCON 16,
2008.

[25] S. M. Bellovin and E. Rescorla. Deploying a new hash algorithm.

In NDSS, 2006.

[26] K. Bhargavan, C. Fournet, R. Corin, and E. Zalinescu. Cryptograph-

ically veriﬁed implementations for TLS. In CCS, 2008.

[27] D. Bleichenbacher. Chosen ciphertext attacks against protocols based

on the RSA encryption standard PKCS #1. In CRYPTO, 1998.

[28] J. Bonneau, C. Herley, P. C. van Oorschot, and F. Stajano. The
quest to replace passwords: a framework for comparative evaluation
of web authentication schemes. In IEEE Symp. Security & Privacy,
2012.

[29] B. B. Brumley and N. Tuveri. Remote timing attacks are still

[30] D. Brumley and D. Boneh. Remote timing attacks are practical. In

practical. In ESORICS, 2011.

USENIX Security, 2003.

[31] B. Canvel, A. Hiltgen, S. Vaudenay, and M. Vuagnoux. Password

interception in a SSL/TSL channel. In CRYPTO, 2003.

[32] J. Clark and P. C. van Oorschot. SSL and HTTPS: Revisiting
past challenges and evaluating certiﬁcate trust model enhance-
ments. http://www.scs.carleton.ca/research/tech reports/index.php?
abstract=TR-13-01, Carleton University, 2013.

[33] I. Dacosta, M. Ahamad, and P. Traynor. Trust no one else: Detecting
MITM attacks against SSL/TLS without third-parties. In ESORICS,
2012.

[34] R. Dhamija and J. Tygar. The battle against phishing: Dynamic

security skins. In SOUPS, 2005.

[35] R. Dhamija, J. D. Tygar, and M. Hearst. Why phishing works. In

[36] M. Dietz, A. Czeskis, D. Balfanz, and D. S. Wallach. Origin-bound
certiﬁcates: A fresh approach to strong client authentication for the
web. In USENIX Security, 2012.

(Rump Session Talk), 1996.

[37] H. Dobbertin. Crytanalysis of MD5 compress.
In EUROCRYPT
[38] T. Duong and J. Rizzo. Here come the ⊕ ninjas. In Ekoparty, 2011.
[39] P. Eckersley and J. Burns. Is the SSLiverse a safe place? In Chaos

Communication Congress, 2010.

[40] Y. Elley, A. Anderson, S. Hanna, S. Mullan, R. Perlman, and
In

S. Proctor. Building certiﬁcation paths: Forward vs. reverse.
NDSS, 2001.

[41] C. Ellison. Ceremony design and analysis.

Technical Report

2007/399, IACR ePrint, 2007.

[42] S. Fahl, M. Harbach, T. Muders, L. Baumgartner, B. Freisleben, and
M. Smith. Why Eve and Mallory love Android: An analysis of
Android SSL (in)security. In CCS, 2012.

[43] A. P. Felt and D. Wagner. Phishing on mobile devices. In USEC,

2007.

[44] E. Felten, D. Balfanz, D. Dean, and D. S. Wallach. Web spooﬁng:

An internet con game. In NISSC, 1997.

[45] B. Fox and B. LaMacchia. Certiﬁcate revocation: Mechanics and

meaning. In Financial Cryptography, 1997.

[46] B. Friedman, D. Hurley, D. C. Howe, E. Felten, and H. Nissenbaum.
Users’ conceptions of web security: A comparative study (short talk).
In CHI, 2002.

[47] S. Gajek, M. Manulis, O. Pereira, A.-R. Sadeghi, and J. Schwenk.
Universally composable security analysis of TLS. In ProvSec, 2008.
[48] S. Gajek, M. Manulis, A.-R. Sadeghi, and J. Schwenk. Provably
secure browser-based user-aware mutual authentication over TLS.
In ASIACCS, 2008.

[49] M. Georgiev, S. Iyengar, S. Jana, R. Anubhai, V. Shmatikov, and
D. Boneh. The most dangerous code in the world: validating SSL
certiﬁcates in non-browser software. In CCS, 2012.

[50] F. Giesen, F. Kohlar, and D. Stebila. On the security of TLS

renegotiation. Technical Report 2012/630, IACR ePrint, 2012.

[51] I. Goldberg and D. Wagner. Randomness and the Netscape browser.

Dr. Dobb’s Journal, 1996.

[52] C. He, M. Sundararajan, A. Datta, A. Derek, and J. C. Mitchell. A
modular correctness proof of IEEE 802.11i and TLS. In CCS, 2005.
[53] N. Heninger, Z. Durumeric, E. Wustrow, and J. A. Halderman.
Mining your Ps and Qs: Detection of widespread weak keys in
network devices. In USENIX Security, 2012.

[54] R. Holz, L. Braun, N. Kammenhuber, and G. Carle. The SSL
landscape: A thorough analysis of the X.509 PKI using active and
passive measurements. In IMC, 2011.

[55] C. Jackson and A. Barth. Beware of ﬁner-grained origins. In W2SP,

2008.

[56] C. Jackson and A. Barth. ForceHTTPS: Protecting high-security web

524

Dec 2011.

ICISC, 2002.

[68] H. K. Lee, T. Malkin, and E. Nahum. Cryptographic strength of

SSL/TLS servers: Current and recent practices. In IMC, 2007.
[69] S. Lefranc and D. Naccache. Cut-&-paste attacks with JAVA.

In

[70] A. K. Lenstra, J. P. Hughes, M. Augier, J. W. Bos, T. Kleinjung, and

C. Wachter. Public keys. In CRYPTO, 2012.

[71] M. Marlinspike. More tricks for defeating SSL in practice.

In

sites from network attacks. In WWW, 2008.

[57] C. Jackson, D. R. Simon, D. S. Tan, and A. Barth. An evaluation
In

of extended validation and picture-in-picture phishing attacks.
USEC, 2007.

[58] T. Jager, F. Kohlar, S. Sch¨age, and J. Schwenk. On the security of

TLS-DHE in the standard model. In CRYPTO, 2012.

[59] J. Jarmoc. SSL/TLS interception proxies and transitive trust.

In

[60] J. Jonsson and B. S. Kaliski Jr. On the security of RSA encryption

[61] D. Kaminsky. Black Ops 2008: it’s the end of the cache as we know

Black Hat Europe, 2012.

in TLS. In CRYPTO, 2002.

it. In Black Hat USA, 2008.

[62] D. Kaminsky, M. L. Patterson, and L. Sassaman. PKI layer cake:
In

New collision attacks against the global X.509 infrastructure.
Financial Cryptography, 2010.

[63] C. Karlof, J. Tygar, and D. Wagner. Conditioned-safe ceremonies
and a user study of an appplication to web authentication. In NDSS,
2009.

[64] J. Kelsey. Compression and information leakage of plaintext.

In

FSE, 2002.

[65] H. Krawczyk. The order of encryption and authentication for
protecting communications (or: how secure is SSL?). In CRYPTO,
2001.

[66] H. Krawczyk. Cryptographic extraction and key derivation: The

HKDF scheme. In CRYPTO, 2010.

[67] A. Langley. Beyond the basics of HTTPS serving. USENIX ;Login:,

[72] M. Marlinspike. New tricks for defeating SSL in practice. In Black

[73] M. Marlinspike. SSL and the future of authenticity. In Black Hat

DEFCON 17, 2009.

Hat DC, 2009.

USA, 2011.

[74] N. Mavrogiannopoulos, F. Vercauteren, V. Velichkov, and B. Preneel.

A cross-protocol attack on the TLS protocol. In CCS, 2012.

[75] J. C. Mitchell, V. Shmatikov, and U. Stern. Finite-state analysis of

SSL 3.0. In USENIX Security, 1998.

[76] P. Morrissey, N. P. Smart, and B. Warinschi. A modular security

analysis of the TLS handshake protocol. In ASIACRYPT, 2008.

[77] M. Myers. Revocation: Options and challenges.

In Financial

Cryptography, 1998.

[78] R. Oppliger, R. Hauser, and D. Basin. SSL/TLS session-aware user

authentication. Computer Communications, 29(12), 2006.

[79] A. Ornaghi and M. Valleri. Man in the middle attacks: demos. In

Black Hat USA, 2003.

[80] A. Ozment, S. E. Schecter, and R. Dhamija. Web sites should not
need to rely on users to secure communications. In W3C Workshop
on Usability and Transparency of Web Authentication, 2006.

[81] B. Parno, C. Kuo, and A. Perrig. Phoolproof phishing prevention.

In Financial Cryptography, 2006.

[82] L. C. Paulson. Inductive analysis of the internet protocol TLS. ACM

TISSEC, 1999.

[83] K. Radke, C. Boyd, J. G. Nieto, and M. Brereton. Ceremony

analysis: Strengths and weaknesses. In IFIP SEC, 2011.

[84] E. Rescorla. SSL and TLS: Designing and Building Secure Systems.

Addison-Wesley, 2001.

[85] E. Rescorla. Stone knives and bear skins: Why does the internet still
run on pre-historic cryptography? In INDOCRYPT (Invited talk),

[86] I. Ristic. Internet SSL survey 2010. In Black Hat USA, 2010.
[87] I. Ristic and M. Small. A study of what really breaks SSL. In Hack

[88] R. Rivest. Can we eliminate certiﬁcate revocation lists? In Financial

2006.

in the Box, 2011.

Cryptography, 1998.

[89] J. Rizzo and T. Duong. The crime attack. In Ekoparty, 2012.
[90] S. E. Schecter, R. Dhamija, A. Ozment, and I. Fischer. The emperor’s
new security indicators: An evaluation of website authentication and
the effect of role playing on usability studies. In IEEE Symposium
on Security and Privacy, 2007.

[91] D. Shin and R. Lopes. An empirical study of visual security cues

to prevent the SSLstripping attack. In ACSAC, 2011.

[92] J. Sobey, R. Biddle, P. van Oorschot, and A. S. Patrick. Exploring
user reactions to new browser cues for extended validation certiﬁ-
cates. In ESORICS, 2008.

[93] C. Soghoian and S. Stamm. Certiﬁed lies: Detecting and defeating
government interception attacks against SSL. In Financial Cryptog-
raphy, 2011.

[94] S. Son and V. Shmatikov. The hitchhiker’s guide to DNS cache

poisoning. In SECURECOMM, 2010.

[95] A. Sotirakopoulos, K. Hawkey, and K. Beznosov. On the challenges
in usable security lab studies: Lessons learned from replicating a
study on SSL warnings. In SOUPS, 2011.

[96] A. Sotirov and M. Zusman. Breaking the security myths of extended

validation SSL certiﬁcates. In Black Hat USA, 2009.

[97] D. Stebila. Reinforcing bad behaviour:

the misuse of security

indicators on popular websites. In OZCHI, 2010.

[98] M. Stevens, A. Lenstra, and B. de Weger. Chosen-preﬁx collisions
for MD5 and colliding X.509 certiﬁcates for different identities. In
EUROCRYPT, 2007.

[99] M. Stevens, A. Sotirov, J. Appelbaum, A. Lenstra, D. Molnar, D. A.
Osvik, and B. de Weger. Short chosen-preﬁx collisions for MD5
and the creation of a rogue CA certiﬁcate. In CRYPTO, 2009.

[100] J. Sunshine, S. Egelman, H. Almuhimedi, N. Atri, and L. F. Cranor.
Crying wolf: An empirical study of SSL warning effectiveness. In
USENIX Security, 2009.

[101] E. Topalovic, B. Saeta, L.-S. Huang, C. Jackson, and D. Boneh.

Toward short-lived certiﬁcates. In W2SP, 2012.

[102] P. C. van Oorschot and M. J. Wiener. Parallel collision search with

cryptanalytic applications. J. Cryptology, 12:1–28, 1999.

[103] S. Vaudenay. Security ﬂaws induced by CBC padding: applications

to SSL, IPSEC, WTLS, . . . . In EUROCRYPT, 2002.

[104] N. Vratonjic, J. Freudiger, V. Bindschaedler, and J.-P. Hubaux. The

inconvenient truth about web certiﬁcates. In WEIS, 2011.

[105] D. Wagner and B. Schneier. Analysis of the SSL 3.0 protocol. In

USENIX Workshop on Electronic Commerce, 1996.

[106] H. J. Wang, C. Grier, A. Moshchuk, S. T. King, P. Choudhury, and
H. Venter. The multi-principal OS construction of the Gazelle web
browser. In USENIX Security, 2009.

[107] D. Wendlandt, D. G. Andersen, and A. Perrig.

Perspectives:
Improving SSH-style host authentication with multi-path probing.
In USENIX Annual Tech, 2008.

[108] T. Whalen and K. M. Inkpen. Gathering evidence: Use of visual

security cues in web browsers. In Graphics Interface, 2005.

[109] Z. Ye, S. Smith, and D. Anthony. Trusted paths for browsers. ACM

TISSEC, 8(2), 2005.

[110] S. Yilek, E. Rescorla, H. Shacham, B. Enright, and S. Savage. When
private keys are public: Results from the 2008 Debian OpenSSL
vulnerability. In IMC, 2009.

[111] M. Zusman. Criminal charges are not pursued: Hacking PKI.

In

DEFCON 17, 2009.

[112] M. Zusman and A. Sotirov. Sub-prime PKI: Attacking extended
validation SSL. Technical report, Black Hat Security Brieﬁngs, 2009.

525

