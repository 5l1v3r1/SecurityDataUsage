Privacy-Preserving Matrix Factorization

Stratis Ioannidis

Technicolor

Udi Weinsberg

Technicolor

Valeria Nikolaenko

Stanford University

valerini@cs.stanford.edu

stratis.ioannidis@technicolor.com

udi.weinsberg@technicolor.com

Marc Joye
Technicolor

marc.joye@technicolor.com

Nina Taft
Technicolor

nina.taft@technicolor.com

Dan Boneh

Stanford University

dabo@cs.stanford.edu

ABSTRACT
Recommender systems typically require users to reveal their
ratings to a recommender service, which subsequently uses
them to provide relevant recommendations. Revealing ra-
tings has been shown to make users susceptible to a broad
set of inference attacks, allowing the recommender to learn
private user attributes, such as gender, age, etc.
In this
work, we show that a recommender can proﬁle items with-
out ever learning the ratings users provide, or even which
items they have rated. We show this by designing a system
that performs matrix factorization, a popular method used
in a variety of modern recommendation systems, through
a cryptographic technique known as garbled circuits. Our
design uses oblivious sorting networks in a novel way to
leverage sparsity in the data. This yields an eﬃcient im-
plementation, whose running time is Θ(M log2 M ) in the
number of ratings M . Crucially, our design is also highly
parallelizable, giving a linear speedup with the number of
available processors. We further fully implement our sys-
tem, and demonstrate that even on commodity hardware
with 16 cores, our privacy-preserving implementation can
factorize a matrix with 10K ratings within a few hours.

Categories and Subject Descriptors
K.4.1 [Computers and Society]: Public Policy Issues—pri-
vacy; H.2.8 [Database Management]: Database Applications—
data mining, algorithms, design, performance; G.1.6 [Numerical
Analysis]: Optimization—gradient methods

Keywords
Garbled circuits; matrix factorization; multi-party computation;
privacy; recommender systems

1.

INTRODUCTION

A great deal of research and commercial activity in the
last decade has led to the wide-spread use of recommenda-
tion systems. Such systems oﬀer users personalized recom-

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright 2013 ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516751.

mendations for many kinds of items, such as movies, TV
shows, music, books, hotels, restaurants, and more. To re-
ceive useful recommendations, users supply substantial per-
sonal information about their preferences, trusting that the
recommender will manage this data appropriately.

Nevertheless, earlier studies [49, 37, 47, 1, 46] have iden-
tiﬁed multiple ways in which recommenders can abuse such
information or expose the user to privacy threats. Recom-
menders are often motivated to resell data for a proﬁt [6],
but also use it to extract information beyond what is in-
tentionally revealed by the user. For example, even records
of user preferences typically not perceived as sensitive, such
as movie ratings or a person’s TV viewing history, can be
used to infer a user’s political aﬃliation, gender, etc., [61].
The private information that can be inferred from the data
in a recommendation system is constantly evolving as new
data mining and inference methods are developed, for ei-
ther malicious or benign purposes. In the extreme, records
of user preferences can be used to even uniquely identify a
user : Naranyan and Shmatikov strikingly demonstrated this
by de-anonymizing the Neﬂix dataset [49]. As such, even if
the recommender is not malicious, an unintentional leakage
of such data makes users susceptible to linkage attacks [46].
Because we cannot always foresee future inference threats,
accidental information leakage, or insider threats (purpose-
ful leakage), it is appealing to consider how one might build
a recommendation system in which users do not reveal their
personal data in the clear.

In this work, we study a widely used collaborative ﬁltering
technique known as matrix factorization [31, 5], that was in-
strumental in winning the Netﬂix prize competition [35], and
is a core component in many real world recommendation sys-
tems. It is not a priori clear whether matrix factorization can
be performed in a privacy-preserving way; there are several
challenges associated with this task. First, to address the
privacy concerns raised above, matrix factorization should
be performed without the recommender ever learning the
users’ ratings, or even which items they have rated. This re-
quirement is key: earlier studies [61] show that even knowing
which movie a user has rated can be used to infer, e.g., her
gender. Second, such a privacy-preserving algorithm ought
to be eﬃcient, and scale gracefully (e.g., linearly) with the
number of ratings submitted by users. The privacy require-
ments imply that our matrix factorization algorithm ought
to be data-oblivious: its execution ought to not depend on
the user input. Moreover, the operations performed by ma-
trix factorization are non-linear; thus, it is not a-priori clear
how to implement matrix factorization eﬃciently under both

801of these constraints. Finally, in a practical, real-world sce-
nario, users have limited communication and computation
resources, and should not be expected to remain online after
they have supplied their data. We thus seek a “send-and-
forget” type solution, operating in the presence of users that
move back and forth between being online and oﬄine from
the recommendation service.

We make the following contributions.
• We design a protocol that meets all of the above goals for
privacy, eﬃciency and practicality. Our protocol is hy-
brid, combining partially homomorphic encryption with
Yao’s garbled circuits.
• We propose and use in our design a novel data-oblivious
algorithm for matrix factorization.
Implemented as a
garbled circuit, it yields complexity O(M log2 M ), where
M the number of submitted ratings. This is within a
log2 M factor of matrix factorization complexity in the
clear. We achieve this by using Batcher sorting networks,
allowing us to leverage sparsity in submitted ratings.
• Crucially, using sorting networks as a core component of
our design allows us to take full advantage of the paral-
lelization that such sorting networks enable. We incor-
porate this and several other optimizations in our design,
illustrating that garbled circuits for matrix factorization
can be brought into the realm of practicality.
• Finally, we implement our entire system using the FastGC
framework [24] and evaluate it with real-world datasets.
We modiﬁed the FastGC framework in two important
ways, by enabling parallelized garbling and computation
across multiple processors, and by reducing the memory
footprint by partitioning the circuit in layers. Further ad-
ditional optimizations, including reusing sorting results,
and implementing operations via free xor gates [34], al-
low us to run matrix factorization over 104 ratings within
a few hours. Given that recommender systems execute
matrix factorization on, e.g., a weekly basis, this is ac-
ceptable for most real-life applications.

To the best of our knowledge, we are the ﬁrst to enable
matrix factorization over encrypted data. Although sorting
networks have been used before for simple computations, our
work is the ﬁrst to apply sorting networks to leverage matrix
sparsity, especially in a numerical task as complex as matrix
factorization. Overcoming scalability and performance chal-
lenges, our solution is close to practicality for modern day
recommendation services.

The remainder of this paper is organized as follows. Sec-
tion 2 outlines the problem of privacy-preserving matrix fac-
torization. Our solution is presented in Section 3. We dis-
cuss extensions in Section 4 and our implementation and
experimental results in Sections 5 and 6, respectively.

2. PROBLEM STATEMENT

2.1 Matrix Factorization

In the standard “collaborative ﬁltering” setting [35], n users
rate a subset of m possible items (e.g., movies). For [n] :=
{1, . . . , n} the set of users, and [m] := {1, . . . , m} the set of
items, we denote by M ⊆ [n] × [m] the user/item pairs for
which a rating has been generated, and by M = |M| the
total number of ratings. Finally, for (i, j) ∈ M, we denote
by rij ∈ R the rating generated by user i for item j.

In a practical setting, both n and m are large numbers,
typically ranging between 104–106. In addition, the ratings
provided are sparse, that is, M = Θ(n + m), which is much
smaller than the total number of potential ratings n·m. This
is consistent with typical user behavior, as each user may
rate only a relatively small number of items (not depending
on m, the “catalogue” size).
Given the ratings in M, a recommender system wishes
to predict the ratings for user/item pairs in [n] × [m] \ M.
Matrix factorization performs this task by ﬁtting a bi-linear
model on the existing ratings. In particular, for some small
dimension d ∈ N, it is assumed that there exist vectors
ui ∈ Rd, i ∈ [n], and vj ∈ Rd, j ∈ [m], such that

rij = (cid:104)ui, vi(cid:105) + εij

where εij are i.i.d. Gaussian random variables. The vectors
ui and vj are called the user and item proﬁles, respectively.
i ]i∈[n] ∈ Rn×d for the n× d
We will use the notation U = [uT
matrix whose i-th row comprises the proﬁle of user i, and
j ]i∈[m] ∈ Rm×d for the m × d matrix whose j-th row
V = [vT
comprises the proﬁle of item j.
Given the ratings {rij : (i, j) ∈ M}, the recommender typ-
ically computes the proﬁles U and V by performing the fol-
lowing regularized least squares minimization:1

(rij−(cid:104)ui, vj(cid:105))2 +λ

(cid:107)ui(cid:107)2

2 +µ

(cid:107)vj(cid:107)2

2

(1)

(cid:88)

i∈[n]

(cid:88)

j∈[m]

(cid:88)

min
U,V

1
M

(i,j)∈M

for some positive λ, µ > 0. The computation of U, V through
(1) is a computationally intensive task even in the clear, and
is typically performed by recommenders in “batch-mode”,
e.g., once a week, using ratings collected thus far. These
proﬁles are subsequently used to predict ratings through:

ˆrij = (cid:104)ui, vj(cid:105),

i ∈ [n], j ∈ [m] .

(2)

The regularized mean square error in (1) is not a convex
function; several methods for performing this minimization
have been proposed in literature [35, 31, 5]. We focus on gra-
dient descent [35], a popular method used in practice, which
we review below. Denoting by F (U, V ) the regularized mean
square error in (1), gradient descent operates by iteratively
adapting the proﬁles U and V through the adaptation rule

ui(t) = ui(t − 1) − γ∇ui F (U (t − 1), V (t − 1)) ,
vi(t) = vi(t − 1) − γ∇vi F (U (t − 1), V (t − 1)) ,

where γ > 0 a small gain factor and

∇ui F (U, V ) = −2(cid:80)
∇vj F (U, V ) = −2(cid:80)

j:(i,j)∈M vj(rij − (cid:104)ui, vj(cid:105)) + 2λui ,
i:(i,j)∈M ui(rij − (cid:104)ui, vj(cid:105)) + 2µvi ,

(3)

(4)

where U (0) and V (0) consist of uniformly random norm 1
rows (i.e., proﬁles are selected u.a.r. from the norm 1 ball).
2.2 Setting
Figure 1 depicts the actors in our privacy-preserving ma-
trix factorization system. Each user i ∈ [n] wants to keep
her ratings {rij : (i, j) ∈ M} private. The recommender sys-
tem (RecSys), performs the privacy-preserving matrix fac-
torization, while a crypto-service provider (CSP), enables
this private computation.

1Assuming Gaussian priors on the proﬁles U and V , the
minimization (1) corresponds to maximum likelihood esti-
mation of U and V .

802{r1j :(1,j)∈M}

{r2j :(2,j)∈M}

x
x
...x

RecSys

CSP

V

{rnj :(n,j)∈M}

Figure 1: The parties in our ﬁrst protocol de-
sign.
The recommender system learns nothing
about users’ ratings, other than the model V .

Our objective is to design a protocol that allows the Rec-
Sys to execute matrix factorization while neither the RecSys
nor the CSP learn anything other than the item proﬁles,2
i.e., V (the sole output of RecSys in Fig. 1). In particular,
neither should learn a user’s ratings, or even which items
she has actually rated. Clearly, a protocol that allows the
recommender to learn both user and item proﬁles reveals too
much: in such a design, the recommender can trivially infer
a user’s ratings from the inner product (2). As such, our
focus is on designing a privacy-preserving protocol in which
the recommender learns only the item proﬁles.

There is a utility in learning the item proﬁles alone. First,
the embedding of items in Rd through matrix factorization
allows the recommender to infer (and encode) similarity:
items whose proﬁles have small Euclidean distance are items
that are rated similarly by users. As such, the task of learn-
ing the item proﬁles is of interest to the recommender be-
yond the actual task of recommendations. Second, having
obtained the item proﬁles, there is a way the recommender
can use them to provide relevant recommendations without
any additional data revelation by users: the recommender
can send V to a user (or release it publicly); knowing her
ratings, i can infer her (private) proﬁle ui by solving (1)
w.r.t. ui through ridge regression [15]. Having ui and V ,
she can subsequently predict all ratings through (2).

Both of these scenarios presume that neither the recom-
mender nor the users object to the public release of V . How-
ever, in Section 4.1 we show that there is also a way to easily
extend our design so that users learn their predicted ratings
while the recommender learns nothing, not even V . For the
sake of simplicity, as well as on account of the utility of such
a protocol to the recommender, our main focus is on allow-
ing the recommender to learn the item proﬁles. This design
is also the most technically challenging; we treat the second
case as an extension to this basic design.

We note that, in general, both output of the proﬁle V or
the rating predictions for a user may reveal something about
other users’ ratings. In pathological cases where there are,
e.g., only two users, both revelations may let the users dis-
cover each other’s ratings. We do not address such cases;
when the privacy implications of the revelation of item pro-
ﬁles or individual ratings are not tolerable, techniques such
as adding noise can be used, as discussed in Section 7.

Threat Model. Our security guarantees will hold under
the honest but curious threat model [17]. In other words,
the RecSys and CSP follow the protocols we propose as pre-
scribed; however, these interested parties may elect to ana-

2Technically, our algorithm also leaks the number of items
rated by each user, though this can be easily rectiﬁed
through a simple protocol modiﬁcation.

lyze protocol transcripts, even oﬀ-line, in order to infer some
additional information. We further assume that the recom-
mender and CSP do not collude; the case of a malicious
RecSys is discussed in Section 4.

3. LEARNING THE ITEM PROFILES

In this section, we present a solution allowing the rec-
ommender system to learn only the item proﬁles V . Our
approach is based on Yao’s garbled circuits. In short, in a
basic architecture, the CSP prepares a garbled circuit that
implements matrix factorization, and provides it to the Rec-
Sys. Oblivious transfer is used to obtain the garbled inputs
from users without revealing them to either the CSP or the
RecSys. Our design augments this basic architecture to en-
able users to be oﬄine during the computation phase, as
well as to submit their ratings only once.

We begin by discussing how Yao’s protocol for secure
multi-party computation applies, and then focus on the chal-
lenges that arise in implementing matrix factorization as
a circuit. Our solution yields a circuit with a complexity
within a polylogarithmic factor of matrix factorization per-
formed in the clear by using sorting networks; an additional
advantage of this implementation is that the garbling and
the execution of our circuit is highly parallelizable.
3.1 A Privacy-Preserving Protocol for Matrix

Factorization

Yao’s Garbled Circuits. Yao’s garbled circuit method,
outlined in Appendix A, can be applied to our setting in a
manner similar to the privacy-preserving auction and ridge
regression settings studied in [48] and [50], respectively. In
brief, assume for now that there exists a circuit that im-
plements matrix factorization: this circuit receives as input
user’s ratings, supplied as tuples of the form

(i, j, rij) with (i, j) ∈ M ,

where rij represents the rating rij of user i on item j, and
outputs the item proﬁles V . Given M , the CSP garbles this
circuit and sends it to the RecSys. In turn, through proxy
oblivious transfer [48] between the users, the RecSys and the
CSP, the RecSys receives the circuit inputs and evaluates V .
As garbled circuits can only be used once, any future com-
putation on the same ratings would require the users to re-
submit their data through proxy oblivious transfer. For this
reason, we adopt a hybrid approach, combining public-key
encryption with garbled circuits, as in [57, 50]. Applied to
our setting, in a hybrid approach the CSP advertises a pub-
lic key. Each user i encrypts her respective inputs (j, rij)
and submits them to the RecSys. Whenever the RecSys
wishes to perform matrix factorization over M accumulated
ratings, it reports M to the CSP. The CSP provides the
RecSys with a garbled circuit that (a) decrypts the inputs
and then (b) performs matrix factorization; (Yao’s complete
protocol can be found in Appendix A). Nikolaenko et al. [50]
avoid decryption within the circuit by using masks and ho-
momorphic encryption; we adapt this idea to matrix fac-
torization, departing however from [50] by only requiring a
partially homomorphic encryption scheme.

We note that our protocol, and the ones outlined above,
leak beyond V also the number of ratings generated by
each user. This can easily be remedied, e.g., by pre-setting
the maximum number of ratings the user may provide and

803(i1 ,c1 )

RecSys

(i2 ,c2 )

{r1j}(1,j)∈M

x User 1
x User 2

{(1, j, r1j )}
{r1j}(1,j)∈M

········· ···

{(2, j, r2j )}

(iM ,cM )

specif.

(i1,ˆc1),...,
(iM ,ˆcM )

OT

CSP

Decrypt ˆc1,

. . . , ˆcM

Choose µ’s
Compute ˆc’s

µ1,...,µM
GI(µ1),...,
GI(µM )

GI(µ1),...,
GI(µM )

V

Figure 2: Protocol overview: Learning item pro-
ﬁles V through a garbled circuit. Each user sub-
mits encrypted item-rating pairs to the RecSys. The
RecSys masks these pairs and forwards them to the
CSP. The CSP decrypts them, and embeds them in
a garbled circuit sent to the RecSys. The garbled
values of the masks (denoted by GI) are obtained by
the RecSys through oblivious transfer.

padding submitted ratings with “null” entries; for simplicity,
we describe the protocol without this padding operation.

Detailed Description. We use public key encryption as
follows. Each user i encrypts her respective inputs (j, rij)
under the CSP’s public key, pkcsp, with a semantically secure
encryption algorithm Epk, and, for each item j she rated, sub-
mits a pair (i, c) with c = Epkcsp (j, rij) to the RecSys, where
M ratings are submitted in total. A user that submitted her
ratings can go oﬀ-line.

We require that the CSP’s public-key encryption algo-
rithm is partially homomorphic: a constant can be applied
to an encrypted message without the knowledge of the cor-
responding decryption key. Clearly, an additively homomor-
phic scheme such as Paillier [52] or Regev [56] can be used
to add a constant, but hash-ElGamal (see, e.g., [7, § 3.1]),
which is only partially homomorphic, suﬃces and can be
implemented more eﬃciently in this case; we review this
implementation in Appendix B.

Upon receiving M ratings from users—recalling that the
encryption is partially homomorphic—the RecSys obscures
them with random masks ˆc = c ⊕ µ , and sends them to
the CSP together with the complete speciﬁcations needed to
build a garbled circuit. In particular, the RecSys speciﬁes
the dimension of the user and item proﬁles (i.e., parameter
d), the total number of ratings (i.e., parameter M ), the total
number of users and items (i.e., n and m), as well as the
number of bits used to represent the integer and fractional
parts of a real number in the garbled circuit.
Upon receiving the encryptions, the CSP decrypts them
and gets the masked values: (i, (j, rij)⊕ µ). Then, using the
matrix factorization circuit as a blueprint, the CSP prepares
a Yao’s garbled circuit that

(a) takes as input the garbled values corresponding to the

masks—this is denoted by GI(µ) on Figure 2;

(b) removes the mask µ to recover the corresponding tuple

(i, j, rij);

(c) performs matrix factorization; and
(d) outputs the item proﬁles V .

The CSP subsequently makes the garbled circuit available
to the RecSys. Then, it engages in an oblivious transfer
protocol with the RecSys so that the RecSys obtains garbled
values of the masks: GI(µ). Finally, the RecSys evaluates
the circuit, whose ﬁnal (ungarbled) output comprises the
requested proﬁles V .

We note that, in contrast to the solution presented in Ap-
pendix A, the circuit recovers (i, j, rij) by simply removing
the mask through the xor operation, rather than using de-
cryption. Most importantly, as discussed in Section 5, xor
operations can be performed very eﬃciently in a garbled
circuit implementation [34].

To complete the above protocol, we need to provide a cir-
cuit that implements matrix factorization. Before we discuss
our design, we ﬁrst describe a na¨ıve solution below.
3.2 A Naïve Design

The gradient descent operations outlined in Eqs. (3)–(4)
involve additions, subtractions and multiplications of real
numbers. These operations can be eﬃciently implemented
in a circuit [50]. The K iterations of gradient descent (3)
correspond to K circuit “layers”, each computing the new
values of U and V from values in the preceding layer. The
ﬁnal output of the circuit are the item proﬁles V outputted
the last layer, while the user proﬁles are discarded.

Observe that the time complexity of computing each it-
eration of gradient descent is Θ(M ), when operations are
performed in the clear, e.g., in the RAM model: each gradi-
ent computation (4) involves adding 2M terms, and proﬁle
updates (3) can be performed in Θ(n + m) = Θ(M ) time.

The main challenge in implementing gradient descent as a
circuit lies in doing so eﬃciently. To illustrate this, consider
the following na¨ıve implementation:
1. For each pair (i, j) ∈ [n] × [m], generate a circuit that
computes from input the indicators δij = 1(i,j)∈M, which
is 1 if i rated j and 0 otherwise.

∇ui F (U, V ) = −2(cid:80)
∇vj F (U, V ) = −2(cid:80)

2. At each iteration, using the outputs of these circuits,
compute each item and user gradient as a summation
over m and n products, respectively, where:

j∈[m] δij · vj(rij − (cid:104)ui, vj(cid:105)) + 2λui,
i∈[n] δij · ui(rij − (cid:104)ui, vj(cid:105)) + 2µvi.
Unfortunately, this implementation is ineﬃcient: every iter-
ation of the gradient descent algorithm has a circuit com-
plexity of Θ(nm). When M (cid:28) nm, as is usually the case in
practice, the above circuit is drastically less eﬃcient than
gradient descent in the clear;
in fact, the quadratic cost
Θ(nm) is prohibitive for most datasets.
3.3 A Simple Counting Circuit

The ineﬃciency of the na¨ıve implementation arises from
the inability to identify which users rate an item and which
items are rated by a user at the time of the circuit design,
mitigating the ability to leverage the inherent sparsity in
the data. The question that thus naturally arises is how to
perform such a matching eﬃciently within a circuit.
We illustrate our main idea for performing this matching
through a simple counting circuit. Let cj = |{i : (i, j) ∈ M}|

804 1

 1

 .

 .

be the number of ratings item j ∈ [m] received. Suppose
that we wish to design a circuit that takes as input the set
M and outputs the counts {cj}j∈[m]. This task’s complexity
in the RAM model is Θ(m + M ), as all cj can be computed
simultaneously by a single pass over M. In contrast, a na¨ıve
circuit implementation using “indicators”, as in the previous
section, yields a circuit complexity Θ(nm). Nevertheless,
we show it is possible to construct a circuit that returns

{cj}j∈[m] in Θ(cid:0)(m + M ) log2(m + M )(cid:1) steps using a sorting

network (see Appendix C).

We ﬁrst describe the algorithm that performs this opera-

tion, and then discuss how we implement it as a circuit.
1. Given M as input, construct an array S of m+M tuples.
First, for each j ∈ [m], create a tuple of the form (j,⊥, 0),
where the “null” symbol ⊥ is a placeholder. Second, for
each (i, j) ∈ M, create a tuple of the form (j, 1, 1), yield-
ing:

S =

2

. . . m j1
⊥ ⊥ . . . ⊥ 1
1
0

. . .

0

0

j2
1
1

. . .
. . .
. . .

jM
1
1

Intuitively, the ﬁrst m tuples will serve as “counters”,
storing the number of ratings per item. The remaining
M tuples contain the “input” to be counted. The third
element in each tuple serves as a binary ﬂag, separating
counters from input.

2. Sort the tuples in increasing order w.r.t. the item ids,
i.e., the 1st element in each tuple. If two ids are equal,
break ties by comparing tuple ﬂags, i.e., the 3rd elements
in each tuple. Hence, after sorting, each “counter” tuple
is succeeded by “input” tuples with the same id:

S =

⊥ 1 . . . 1 . . . ⊥ 1
1
0

1 . . . 1 . . . m m . . . m
1
1

1 . . . 1 . . .

. . .
. . .

0

3. Starting from the right-most tuple, move from right to
left, adding the values of the second entries in each tuple;
if a counter tuple (i.e., a zero ﬂag) is reached, store the
computed value at the ⊥ entry, and restart the counting.
More formally, denote by s(cid:96),k the (cid:96)-th element of the k-th
tuple. This “right-to-left” pass amounts to the following
assignments:

s2,k ← s3,k +s3,k+1·s2,k+1 ,
for k ranging from M + m − 1 down to 1.

(5)

4. Sort the array again in increasing order, this time w.r.t.
the ﬂags s3,k. The resulting array’s ﬁrst m tuples contain
the counters, which are released as output.

The above algorithm can be readily implemented as a cir-
cuit that takes as input M and outputs (j, cj) for every
item j ∈ [m]. Step 1 can be implemented as a circuit with
input the tuples (i, j) ∈ M and output the initial array
S, using Θ(m + M ) gates. The sorting operations can be
performed using, e.g., Batcher’s sorting network (cf. Ap-
pendix C) which takes as input the initial array and outputs
the sorted array, requiring Θ((m + M ) log2(m + M )) gates.
Finally, the right-to-left pass can be implemented as a cir-
cuit that performs (5) on each tuple, also with Θ(m + M )
gates. Crucially, the pass is data-oblivious: (5) discrimi-
nates “counter” from “input” tuples through ﬂags s3,k and
s3,k+1, but the same operation is performed on all k.

3.4 Our Efﬁcient Design

Algorithm 1 Matrix Factorization Circuit
Input: Tuples (i, j, rij)
Output: V
1: Initialize matrix S
2: Sort tuples with respect to rows 1 and 3
3: Copy user proﬁles (left pass): for k = 2. . .M + n

s5,k ← s3,k · s5,k−1 + (1 − s3,k) · s5,k

4: Sort tuples with respect to rows 2 and 3
5: Copy item proﬁles (left pass): for k = 2. . .M + m

s6,k ← s3,k · s6,k−1 + (1 − s3,k) · s6,k

(cid:21)

6: Compute the gradient contributions: ∀k < M + m

(cid:20)s3,k · 2γs6,k(s4,k − (cid:104)s5,k, s6,k(cid:105)) + (1 − s3,k) · s5,k

(cid:20)s5,k

s3,k · 2γs5,k(s4,k − (cid:104)s5,k, s6,k(cid:105)) + (1 − s3,k) · s6,k

←

s6,k

(cid:21)

7: Update item proﬁles (right pass): for k = M+m− 1. . .1

s6,k ← s6,k + s3,k+1 · s6,k+1 + (1 − s3,k) · 2γµs6,k

8: Sort tuples with respect to rows 1 and 3
9: Update user proﬁles (right pass): for k = M +n− 1. . .1

s5,k ← s5,k + s3,k+1 · s5,k+1 + (1 − s3,k) · 2γλs5,k

10: If # of iterations is less than K, goto 3
11: Sort tuples with respect to rows 3 and 2
12: Output item proﬁles s6,k, k = 1, . . . , m

Motivated by the above approach, we design a circuit for
matrix factorization based on sorting, whose complexity is
Θ((n + m + M ) log2(n + m + M )), i.e., within a polylogarith-
mic factor of the implementation in the clear. The circuit
operations are described in Algorithm 1.
In summary, as
in the simple counting example above, both the input data
(the tuples (i, j, rij)) and placeholders for both user and item
proﬁles are stored together in an array. Through appropri-
ate sorting operations, user or item proﬁles can be placed
close to the input with which they share an identiﬁer; linear
passes through the data allow the computation of gradients,
as well as updates of the proﬁles.

We again ﬁrst describe the algorithm in detail and then
discuss its implementation as a circuit. As before, the null
symbol ⊥ indicates a placeholder; when sorting, it is treated
as +∞, i.e., larger than any other number.

Initialization. The algorithm receives as input the sets
Li = {(j, rij) : (i, j) ∈ M}, and constructs an n + m +
M array of tuples S. The ﬁrst n and m tuples of S serve
as placeholders for the user and item proﬁles, respectively,
while the remaining M tuples store the inputs Li. More
speciﬁcally, for each user i ∈ [n], the algorithm constructs a
tuple (i,⊥, 0,⊥, ui,⊥), where ui ∈ Rd is the initial proﬁle of
user i, selected at random from the unit ball. For each item
j ∈ [m], the algorithm constructs the tuple (⊥, j, 0,⊥,⊥, vj),
where vj ∈ Rd is the initial proﬁle of item j, also selected
at random from the unit ball. Finally, for each pair (i, j) ∈
M, the corresponding tuple (i, j, 1, rij,⊥,⊥), where rij is i’s
rating to j. The resulting array is shown in Figure 3(a).

805

1

0

n ⊥ ··· ⊥

1 :
i1
··· m j1
2 : ⊥ ··· ⊥ 1
···
1
0
3 :
4 : ⊥ ··· ⊥ ⊥ ··· ⊥ ri1j1
⊥
5 : u1
6 : ⊥ ··· ⊥ v1
⊥

···
···
0
··· un ⊥ ··· ⊥
vm

0

···

(a) Initial state



iM
jM
1
riM jM
⊥
⊥

···
···
···
···
···
···



n··· n
···
1··· 1
n
1 :
1
j1 ··· jkn
··· ⊥
j1 ··· jk1
2 : ⊥
1··· 1
···
1··· 1
0
0
3 :
··· ⊥ rnj1 ··· rnjkn
4 : ⊥ r1j1 ··· r1jk1
⊥ ··· ⊥
··· un
⊥ ··· ⊥
5 : u1
··· ⊥
⊥ ··· ⊥
6 : ⊥
⊥ ··· ⊥
(b) After sorting w.r.t. user ids



⊥ ··· ⊥
··· m
1
···
0
0
⊥ ··· ⊥
⊥ ··· ⊥
vm
v1

···

Figure 3: Data structure S used by Alg. 1. Fig. (a) indicates the initial state, and (b) shows the result after
sorting w.r.t. the user ids, breaking ties through ﬂags, as in Line 2 of Alg. 1. Bold rows 5, 6 correspond to
d-dimensional (rather than scalar) values. Note that a left pass as in line 3 of Alg. 1 will copy user proﬁles
to their immediately adjacent tuples.

We again denote by s(cid:96),k the (cid:96)-th element of the k-th tuple.

Intuitively, these elements serve the following roles:

The above operations are repeated K times, the number of
desirable iterations of gradient descent.

s1,k :
s2,k :
s3,k :

s4,k :
s5,k :
s6,k :

user identiﬁers in [n]
item identiﬁers in [m]
a binary ﬂag indicating if the tuple is a “proﬁle”
or “input” tuple
ratings in “input” tuples
user proﬁles in Rd
item proﬁles in Rd

In brief, gradient descent iterations

Gradient Descent.
comprise of the following three steps:
1. Copy proﬁles. At each iteration, the proﬁles ui, vj of
each user i and each item j are copied to the correspond-
ing elements s5,k and s6,k of each “input” tuple in which
i and j appear. This is implemented in Lines 2 to 5 of
Algorithm 1. To copy, e.g., the user proﬁles, S is sorted
using the user id (i.e., s1,k) as a primary index and the
ﬂag (i.e., s3,k) as a secondary index. An example of such
a sorting applied to the initial state of S can be found
in Figure 3(b). Subsequently, the user ids are copied by
traversing the array from left to right (a “left” pass), as
described formally in Line 3. This copies s5,k from each
“proﬁle” tuple to its adjacent “input” tuples; item proﬁles
are copied similarly.

2. Compute gradient contributions. After proﬁles are
copied, each “input” tuple corresponding to, e.g., (i, j)
stores the rating rij (in s4,k) as well as the proﬁles ui and
vj (in s5,k and s6,k, respectively), as computed in the last
iteration. From these, the following are computed:

vj(rij − (cid:104)ui, vj(cid:105)), and ui(rij − (cid:104)ui, vj(cid:105)) ,

which amount to the “contribution” of the tuple in the
gradients w.r.t. ui and vj, as given by (4). These replace
the s5,k and s6,k elements of the tuple, as indicated by
Line 6. Through appropriate use of ﬂags, this operation
aﬀects “input” tuples, leaving “proﬁle” tuples unchanged.
3. Update proﬁles. Finally, the user and item proﬁles are
updated, as shown in Lines 7 to 9. Through appropriate
sorting, “proﬁle” tuples are made again adjacent to the
“input” tuples with which they share ids. The updated
proﬁles are computed through a right-to-left traversing
of the array (a “right pass”). This operation adds the
contributions of the gradients as it traverses “input” tu-
ples. Upon encountering a “proﬁle” tuple, the summed
gradient contributions are added to the proﬁle, scaled
appropriately. After passing a proﬁle, the summation of
gradient contributions restarts from zero, through appro-
priate use of the ﬂags s3,k, s3,k+1.

Output. Finally, at the termination of the last iteration,
the array is sorted w.r.t. the ﬂags (i.e., s3,k) as a primary
index, and the item ids (i.e., s2,k) as a secondary index.
This brings all item proﬁle tuples in the ﬁrst m positions in
the array, from which the item proﬁles can be extracted.

Each of the above operations is data-oblivious, and can
be implemented as a circuit. Copying and updating proﬁles
requires Θ(n+m+M ) gates, so the overall complexity is de-
termined by sorting, which yields a Θ((n + m + M ) log2(n +
m + M )) cost when using Batcher’s circuit. As we will see
in Section 6, sorting and the gradient computation in Line 6
are the most computationally intensive operations; fortu-
nately, both are highly paralellizable. In addition, sorting
can be further optimized by reusing previously computed
comparisons at each iteration. We discuss these and other
optimizations in Section 5.3.

4. EXTENSIONS
4.1 Privacy-Preserving Recommendations
We now extend our design to a system that enables a user
to learn her predicted ratings rij, for all j ∈ [m], as given by
(2). However, neither the RecSys nor the CSP learn anything
about the users beyond how many ratings they generated; in
particular, neither learns V . Again, these guarantees hold
under the honest-but-curious threat model.

To implement this functionality, at the beginning of the
protocol, each user i chooses a random mask ϑi (this mask
will be used to hide user’s i proﬁle ui), encrypts it under the
CSP’s public key using any semantically secure encryption
scheme E and sends it to the RecSys. We denote by ti =
Epkcsp (ϑi) the encrypted value.

The protocol then proceeds as described in Section 3 but
with the following modiﬁcations. Initially, the RecSys for-
wards to the CSP the encrypted masks ti (i ∈ [n]), which
are then decrypted by the CSP. Hence the CSP knows the
plain value of the masks ϑi (i ∈ [n]). Likewise, on its side,
the CSP chooses random masks j for j ∈ [m] (mask j will
be used to hide item proﬁle vj). The circuit built by the
CSP again performs matrix factorization, as described in
Section 3; however, rather than outputting V = (vT
j )j∈[m],
the circuit now outputs the item proﬁles masked with j and
the user proﬁles masked with ϑi:

ˆvj = vj + j

and ˆui = ui + ϑi

for j ∈ [m] and i ∈ [n]. At the end of the protocol, the
RecSys sends the respective ˆui to each user i, who can then
recover her proﬁle ui by removing the mask: ui = ˆui − ϑi.

806The above execution, which is as computationally intensive
as learning V in Section 3, can be performed as frequently as
matrix factorization in real-life systems, e.g., once a week.

In between such computations, whenever a user i wishes
to get recommendations, she encrypts her proﬁle under her
own public key pki with an additively homomorphic en-
cryption scheme Epki (like Paillier’s cryptosystem [52])3 and
sends the resulting value Epki (ui) to the RecSys. The Rec-
Sys forwards Epki (ui) to the CSP and also computes, for
j ∈ [m], Epki ((cid:104)ui, ˆvj(cid:105)). The CSP in turn computes for
j ∈ [m], Epki ((cid:104)ui, j(cid:105)) , and returns this value to the RecSys.
The RecSys subtracts Epki ((cid:104)ui, j(cid:105)) from Epki ((cid:104)ui, ˆvj(cid:105)) =
Epki ((cid:104)ui, vj + j(cid:105)) to obtain the encryption of the predicted
ratings ˆrij = Epki ((cid:104)ui, vj(cid:105)) for all items j ∈ [m] and sends
them to the user i. The user uses her private decryption
key to obtain in the clear the predictions ri1, . . . , rim.
4.2 Malicious RecSys

Our basic protocol, as described in Section 3, operates
under the honest-but-curious model. However, a malicious
RecSys can alter, duplicate or drop user ratings as a means
to have the output model leak information about individual
ratings. For example, the RecSys can provide inputs to the
circuit from only a single user and feed dummy ratings for
the remaining ones.
It would then learn from the output
model the set of items that were rated by this victim user:
the RecSys simply observes which of the learned item proﬁles
has a non-unit norm. This would clearly violate user privacy.
In order to prevent the RecSys from misbehaving, we need
the CSP to build a circuit that, beyond outputting V , also
veriﬁes that the input to the circuit contains all user ratings,
that the ratings were not changed, and that no dummy ra-
tings were input. To do so we require users to obtain one-
time MAC keys (one key per rating) from the CSP which
they then use to sign their ratings. The CSP builds a circuit
that veriﬁes these MACs, making sure that the ratings were
not altered, and that the exact number of ratings submitted
by each user are provided as input to the circuit.

Our approach is to have each user ﬁrst communicate with
the CSP, reporting the number of ratings that she will send
to the RecSys. The CSP in return sends the user a set of
one-time MAC keys for each rating tuple, which the user
uses for signing each tuple (j, rij). The garbled circuit the
CSP builds veriﬁes each input tuple with a speciﬁc MAC key,
requiring the RecSys to provide the exact inputs as reported
by the users to the CSP, sorted w.r.t. i and j. Any deviation
from this order or the introduction of dummy ratings will
result in a veriﬁcation failure. Assume that the output of
the veriﬁcation circuit for each signed tuple is a bit that is
set to 1 if the veriﬁcation succeeds and 0 otherwise. The
veriﬁcation bits of all input tuples are fed into an and gate,
so that if at least one veriﬁcation fails, the output of the
and gate is 0. If the outputs of this and gate is 0 then the
circuit sets its overall output to 0. This way, if at least one
veriﬁcation failed the circuit simply outputs 0. We chose to
use fast one-time MACs based on pairwise independent hash
functions so that the number of gates needed to verify these
MACs is relatively small.

3Speciﬁcally, it is required that the encryptions of two mes-
sages Epk(m1) and Epk(m2) satisfy Epk(m1) (cid:63) Epk(m2) =
Epk(m1 + m2) for some binary operator (cid:63). To ease nota-
tion, we use multiplication for (cid:63) as is the case for Paillier
encryption.

5.

IMPLEMENTATION

We implemented our system to assess its practicality. Our
garbled circuit construction was based on FastGC, a publicly
available garbled circuit framework [24].
5.1 FastGC

FastGC [24] is a Java-based open-source framework, which
enables circuit deﬁnition using elementary xor, or and and
gates. Once circuits are constructed, FastGC handles gar-
bling, oblivious transfer and garbled circuit evaluation.

FastGC incorporates several known optimizations that aim
to improve its memory foot-print and garbling and execu-
tion times. These optimizations include so-called “free” xor
gates [34], in which xor evaluation is decryption-free and
thereby of negligible cost, and garbled-row reduction for
non-xor gates [53], which reduces communication by 25%.
FastGC also provides an “addition of 3 bits” circuit [33], en-
abling additions with 4 “free” xor gates and one and gate.
OT extensions [27] are also implemented: these signiﬁcantly
increase the number of transfers made during OT, reducing
communication overhead and lowering execution time.

Finally, FastGC enables the garbling and evaluation to
take place concurrently on two separate machines. The CSP
processes gates into garbled tables and transmits them to
the RecSys in the order deﬁned by circuit structure. Once
a gate was evaluated its corresponding table is immediately
discarded, which brings memory consumption caused by the
garbled circuit to a constant.
5.2 Extensions to the Framework

Before garbling and executing the circuit, FastGC repre-
sents the entire ungarbled circuit in memory as a set of Java
objects. These objects incur a signiﬁcant memory overhead
relative to the memory footprint of the ungarbled circuit, as
only a subset of the gates is garbled and/or executed at any
point in time. Moreover, although FastGC performs gar-
bling in parallel to the execution process as described above,
both operations occur in a sequential fashion: gates are pro-
cessed one at a time, once their inputs are ready. Clearly,
this implementation is not amenable to parallelization.

We modiﬁed the framework to address these issues, re-
ducing the memory footprint of FastGC but also enabling
paralellized garbling and computation across multiple pro-
cessors. In particular, we introduced the ability to partition
a circuit horizontally into sequential “layers”, each one com-
prising a set of vertical “slices” that can be executed in par-
allel. A layer is created in memory only when all its inputs
are ready. Once it is garbled and evaluated, the entire layer
is removed from memory, and the following layer can be con-
structed, thus limiting the memory footprint to the size of
the largest layer. The execution of a layer uses a scheduler
that assigns its slices to threads, which run in parallel. Al-
though we implemented parallelization on a single machine
with multiple cores, our implementation can be extended to
run across diﬀerent machines in a straightforward manner
since no shared state between slices is assumed.

Finally, to implement the numerical operations outlined in
Algorithm 1, we extended FastGC to support addition and
multiplications over the reals with ﬁxed-point number repre-
sentation, as well as sorting. For sorting, we used Batcher’s
sorting network [3]. Fixed-point representation introduces a
tradeoﬀ between the accuracy loss resulting from truncation
and the size of circuit, which we explore in Section 6.

8075.3 Optimizing Algorithm 1

We optimize the implementation of Algorithm 1 in multi-
ple ways. In particular, we (a) reduce the cost of sorting by
reusing comparisons computed in the beginning of the cir-
cuit’s execution, (b) reduce the size of array S, (c) optimize
swap operations by using xors, and (d) parallelize compu-
tations. We describe these optimizations in detail below.

Comparison Reuse. As described in Appendix C, the
basic building block of a sorting network is a compare-and-
swap circuit, that compares two items and swaps them if
necessary, so that the output pair is ordered. Observe that
the sorting operations (Lines 4 and 8) of Algorithm 1 per-
form identical comparisons between tuples at each of the K
gradient descent iterations, using exactly the same inputs
per iteration. In fact, each sorting permutes the tuples in
array S in exactly the same manner, at each iteration.

We exploit this property by performing the comparison
operations for each of these sortings only once. In particular,
we perform sortings of tuples of the form (i, j, ﬂag, rating)
in the beginning of our computation (without the payload
of user or item proﬁles), e.g., w.r.t. i and the ﬂag ﬁrst, j
and the ﬂag, and back to i and the ﬂag. Subsequently, we
reuse the outputs of the comparison circuits in each of these
sortings as input to the swap circuits used during gradient
descent. As a result, the “sorting” network applied at each
iteration does not perform any comparisons, but simply per-
mutes tuples (i.e., it is a “permutation” network).

Row Reduction. Precomputing all comparisons allows us
to also drastically reduce the size of tuples in S. To begin
with, observe that the rows corresponding to user or item ids
are only used in Algorithm 1 as input to comparisons during
sorting. Flags and ratings are used during copy and update
phases, but their relative positions are identical at each it-
eration. Moreover, these positions are produced as outputs
when sorting the tuples (i, j, ﬂag, rating) at the beginning
of our computation. As such, “permutation” operations per-
formed at each iteration need only be applied to user and
item proﬁles; all other rows are removed from S.

One more trick reduces the cost of permutations by an ad-
ditional factor of 2. We ﬁx one set of proﬁles, e.g., users, and
permute only item proﬁles. Then, item proﬁles rotate be-
tween two states, each one reachable from the other through
permutation: one in which they are aligned with user pro-
ﬁles and partial gradients are computed, and one in which
item proﬁles are updated and copied.
XOR Optimization. Given that xor operations can be
executed for “free”, we optimize comparison, swap, update
and copying operations by using xors wherever possible.
For comparisons, we reduce the use of and and or gates
using a technique by Kolesnikov et al. [33]. Swap operations
are implemented as follows: for b ← x > y the comparison
bit between tuples x and y (which, by the above optimiza-
tions, is pre-computed at the beginning of circuit execution),
a swap is performed as:

(cid:48) ← [b ∧ (x ⊕ y)] ⊕ x, and y
x

(cid:48) ← x

(cid:48) ⊕ (x ⊕ y)

Finally, copy operations are also optimized to use xor’s.
Observe that the copy operation takes two elements x and
y and a ﬂag s and outputs a new element y(cid:48) which is equals
y if s = 0 and x, otherwise. This is performed as follows:

(cid:48) ← y ⊕ [s ∧ (x ⊕ y)]

x

Parallelization. As discussed in Section 3.4, sorting and
gradient computations constitute the bulk of the computa-
tion in our circuit (copying and updating contribute no more
than 3% of the execution time and 0.4% of the non-xor
gates); we parallelize these operations through our exten-
sion of FastGC. Gradient computations are clearly paralleliz-
able; sorting networks are also highly parallelizable (paral-
lelization is the main motivation behind their development).
Moreover, since many of the parallel slices in each sort are
identical, we reused the same FastGC objects deﬁning the
circuit slices with diﬀerent inputs, signiﬁcantly reducing the
need to repeatedly create and destroy objects in memory.

6. EXPERIMENTS

We now assess the performance of our implementation.
We use two commodity servers, 1.9GHz 16-cores 128GB
RAM each, one acting as the RecSys and the other as the
CSP. We use both real and synthetic datasets. For the real
dataset we use MovieLens, a movie rating dataset that is
commonly used for recommender systems research, that con-
sists of 943 users that submit 100K ratings to 1682 movies.
We use the following evaluation metrics. Our solution in-
troduces inaccuracies due to our use of ﬁxed-point represen-
tation of real numbers. Thus, our goal here is to understand
the relative error of our approach compared to a system that
operates in the clear with ﬂoating point representation. Let
E(U, V ) denote the squared error for a given user’s proﬁle
i vj)2;

U and items proﬁles V , E(U, V ) =(cid:80)

(i,j)∈M(rij − uT

we deﬁne the relative error as

|E(U

∗

, V

∗

) − E(U, V )|/E(U, V )

where U∗ and V ∗ are computed using our solution and U and
V are computed using gradient descent executed in the clear
over ﬂoating point arithmetic, i.e., with minimal precision
loss. Our time metric captures the execution time needed
to garble and evaluate the circuit. We note that we exclude
the encryption and decryption times performed by the users
and the CSP, since these are short in duration compared
to the circuit processing time. The communication metric
is deﬁned by the number of bytes that are transmitted be-
tween the CSP and RecSys; it captures the size of the circuit,
namely the number of non-XOR gates, but unlike the time
metric, communication is not aﬀected by parallelization.

The relative error of our solution using the complete Movie-
Lens dataset is shown in Figure 4. We study the relative
error over a range of parameters, varying the number of
bits allocated to the fractional part of the ﬁxed point repre-
sentation and the number of iterations of gradient descent.
Overall we see that for more than 20 bits, the relative errors
are very low. When the number of bits is small, the gradient
descent method may converge to a diﬀerent local minimum
of (1) than the one reached in the clear. Beyond 20 bits
allocated for the fractional part, our solution converges to
the same local minimum, and errors decrease exponentially
with additional bits. The relative error increases with the
number of iterations because the errors introduced by the
ﬁxed point representations accumulate across the iterations,
however this increase is very small. We note that this should
not be confused with the regularized least square error (1),
which actually decreases when using more iterations.

In the following experiments we used synthetic data with
100 users, 100 items, a dimension of 10 for the user and
item proﬁles, 20 bits for the fractional part of the ﬁxed-point

808Figure 4: Relative errors due to
ﬁxed point representation

Figure 5: Execution time per it-
eration w.r.t. no. of tuples

Figure 6: Communication cost
per iteration w.r.t. no. of tuples

representation (36 bits overall). We measure the time and
communication it takes to perform (garble and evaluate) a
single iteration of gradient descent. Clearly with T iterations
execution and communication grow by a factor T .

Figure 5 shows the increase in time per iteration as we in-
crease the number of ratings in the dataset (the logarithmic
x-axis corresponds to the number of tuples in S that grows
with M since n and m are ﬁxed). The plot also illustrates
the proportion of time spent in various sections of our algo-
rithm. We note that, in all executions, the time spent on
update and copy phases, which are more diﬃcult to paral-
lelize, never exceeded 3%, and thus is omitted from the plots
as it is not visible.

The plot conﬁrms that the growth is almost linear with
the number of ratings, Θ(M log2 M ). Furthermore, we ob-
serve that more than 2/3 of the execution time is spent on
gradient computations (mainly due to vector multiplication
operations), while the remaining 1/3 is due to sorting op-
erations. As both operations are highly parallelizable, this
illustrates that the execution time can be signiﬁcantly re-
duced through parallelization.

Similarly, Figure 6 plots the amount of bytes communi-
cated between the CSP and RecSys for garbling and evalu-
ating a single iteration. The plot shows the same properties
as the execution time, namely that the size scales almost
linearly with the number of ratings and that the majority of
the circuit is devoted to gradient computations. In all imple-
mentations, copy and update operations did not contribute
more that 0.4% of the gates in the circuit.

As an example for the time and communication perfor-
mance for a real dataset, we limited our MovieLens dataset
to the 40 most popular movies. This corresponds to 14683
ratings generated by 940 users. One iteration of gradient
descent with parameters set to achieve error of 10−4 took
2.9hr. These experiments were performed on a machine with
16 cores; real-life systems use much more powerful hard-
ware (e.g., hundreds of Amazon EC2 servers). Moreover,
operations are highly parallelizable. As such, with access
to industry-level equipment this timing can be brought to
the realm of practicality, especially given that recommender
systems run matrix factorization on, e.g., a weekly basis.

7. RELATED WORK

Secure multiparty computation (MPC) was initially pro-
posed by Yao [62, 63]. There are presently many frameworks
that implement Yao garbled circuits [45, 23, 24, 44, 53, 25,
36]. A diﬀerent approach to general purpose MPC is based

on secret-sharing schemes and another is based on fully-
homomorphic encryption (FHE). Secret-sharing schemes have
been proposed for a variety of linear algebra operations,
such as solving a linear system [51], linear regression [29,
30, 21], and auctions [10]. Secret-sharing requires at least
three non-colluding online authorities that equally share the
workload of the computation, and communicate over mul-
tiple rounds; the computation is secure as long as no two
of them collude. Garbled circuits assumes only two non-
colluding authorities and far less communication which is
better suited to the scenario where the RecSys is a cloud
service and the CSP is implemented in a trusted hardware
component. Non-linear computation through fully homo-
morphic encryption [16] may be used to reduce the workload
on the CSP compared to garbled circuits, but current FHE
schemes [39, 20] for simpler algebraic computations are not
as eﬃcient as garbled circuit approaches [50].

Centralized garbled-circuit computation of a function over
a large number of individual inputs was introduced by Naor
et al. in the context of auctions [48]. Our approach is clos-
est to the privacy-preserving regression computation in [50],
though implementing matrix factorization eﬃciently as a
circuit introduces challenges not present in regression. Be-
yond [50], hybrid approaches combining garbled circuits with
other methods (such as HE or secret-sharing) have been used
for, e.g., face and ﬁngerprints recognition [57, 26], and learn-
ing a decision tree [41]; such discrete function evaluations
diﬀer considerably from matrix factorization.

Irrespective of the cryptographic primitive used, the main
challenge in building an eﬃcient algorithm for secure mul-
tiparty computation is in implementing the algorithm in a
data-oblivious fashion, i.e., so that the execution path does
not depend on the input.
In general, any RAM program
executable in bounded time T can be converted to a O(T 3)
Turing machine [8], and any bounded T -time TM can be
converted to a circuit of size O(T log T ) [54], which is data-
oblivious. This results in a O(T 3 log T ) complexity, which is
prohibitive in most applications. A survey of algorithms for
which eﬃcient data-oblivious implementations are unknown
can be found in [11]: matrix factorization broadly falls into
the category of Data Mining summarization problems.

Sorting networks were originally developed to enable sort-
ing parallelization as well as an eﬃcient hardware implemen-
tation. Several recent works exploit the data-obliviousness
of sorting networks for cryptographic purposes which, in
turn, has lead to renewed interest in oblivious sorting proto-
cols beyond sorting networks (e.g., [18, 22]). There are many
recent data-oblivious algorithms using sorting as a building

5101520253010−1010−5100Number of bits for the fractional partRelative error  10 iterations8 iterations6 iterations4 iterations2 iterations128256512102420484096010002000300040005000Number of tuples: |S|Execution time (s)  Sort i −> jSort j −> iGradient12825651210242048409601234x 104Number of tuples: |S|Communication (MB)  Sort i −> jSort j −> iGradient809block, including compaction and selection [60, 19], the com-
putation of a convex hull and all-nearest neighbors [13], as
well as weighted set intersection [28]; the simple counting
protocol in Section 3.3 is a variation upon these schemes.
Nevertheless, these operations are much simpler than ma-
trix factorization; to the best of our knowledge, we are the
ﬁrst to apply oblivious sorting on such a numerical task.

Privacy in recommender systems has been studied under
several contexts, including the use of trusted hardware [1] as
well as the susceptibility of a system to shilling attacks (i.e.,
the injection of false ratings to manipulate the recommen-
dation outcome) [38, 47]. An approach orthogonal to ours
that introduces privacy in recommender systems is diﬀeren-
tial privacy [12, 46]. By adding noise, diﬀerential privacy
guarantees that the distribution of the system’s output is
insensitive to any individual’s record, preventing the infer-
ence of any single user’s data from the output. However,
diﬀerential privacy does not protect data from the recom-
mender system itself. Crucially, diﬀerential privacy can be
combined with secure computation [58], in our case by incor-
porating noise addition within the garbled circuit factorizing
the input matrix. Diﬀerential privacy can thus be used to
enhance the privacy properties of our protocol, ensuring not
only that the data remains private during computation, but
also the ﬁnal result does not expose individual user data.
8. CONCLUSIONS AND FUTURE WORK
We presented a protocol for matrix factorization on user
ratings that remain encrypted at all times. This critical
building block allows a recommender to learn item proﬁles
without learns anything about users’ ratings, providing users
protection from inference threats and accidental information
leakage. Our hybrid approach combines partially homomor-
phic encryption and Yao’s garbled circuits. To the best of
our knowledge, we are the ﬁrst to apply oblivious sorting to a
numerical task as complex as matrix factorization. Through
this key idea, that also enables us to highly parallelize our
implementation, we overcome scalability and performance
needs, and bring matrix factorization on encrypted data into
the realm of practicality.

There are several future directions for this work. First,
we hope to deploy our system over a cloud compute service
(e.g., using Hadoop on Amazon EC2), which will enable
an increase in the range of datasets that we can process.
A second direction is to investigate the application of our
approach to other equally intensive machine learning tasks,
especially ones that exhibit an underlying bipartite structure
in computations; we could thus leverage sorting networks
again to achieve performance scalability.

A third direction is to extend our protocol to work under
diﬀerent security models, e.g., a malicious CSP. A malicious
CSP can create an incorrect circuit, which can be handled
with standard techniques for verifying garbled circuits [43,
40]. Moreover, it can feed the wrong inputs to the circuit,
e.g., maliciously altered masked values as described in Sec-
tion 3.1. The latter attack reveals no additional information
to the CSP, but it may corrupt the result of the computa-
tion. Therefore additional techniques should be designed to
ensure that either the CSP provided the correct inputs to
the circuit or that the output of the recommendation circuit
closely approximates the ratings provided by users.
Acknowledgments. The last author is supported by NSF.

9. REFERENCES

[1] E. A¨ımeur, G. Brassard, J. M. Fernandez, and F. S. M.
Onana. ALAMBIC: A privacy-preserving recommender
system for electronic commerce. Int. J. Inf. Sec., 7(5), 2008.

[2] M. Ajtai, J. Koml´os, and E. Szemer´edi. An O(n log n)

sorting network. In STOC, 1983.

[3] K. E. Batcher. Sorting networks and their applications. In

Proc. AFIPS Spring Joint Computer Conference, 1968.

[4] M. Bellare and S. Micali. Non-interactive oblivious transfer

and applications. In CRYPTO, 1990.

[5] E. J. Cand`es and B. Recht. Exact matrix completion via

convex optimization. Foundations of Computational
Mathematics, 9(6), 2009.

[6] J. F. Canny. Collaborative ﬁltering with privacy. In IEEE

S&P, 2002.

[7] B. Chevallier-Mames, P. Paillier, and D. Pointcheval.

Encoding-free ElGamal encryption without random oracles.
In PKC, 2006.

[8] S. A. Cook and R. A. Reckhow. Time bounded random

access machines. J. Computer and System Sciences, 1973.
[9] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein.
Introduction to Algorithms. MIT Press, 2nd edition, 2001.

[10] I. Damg˚ard and T. Toft. Trading sugar beet quotas - secure

multiparty computation in practice. ERCIM News, 2008.

[11] W. Du and M. J. Atallah. Secure multi-party computation

problems and their applications: A review and open
problems. In New Security Paradigms Workshop, 2001.

[12] C. Dwork. Diﬀerential privacy. In ICALP, 2006.
[13] D. Eppstein, M. T. Goodrich, and R. Tamassia.

Privacy-preserving data-oblivious geometric algorithms for
geographic data. In 18th SIGSPATIAL, 2010.

[14] S. Even, O. Goldreich, and A. Lempel. A randomized

protocol for signing contracts. Commun. ACM, 28(6), 1985.
[15] J. Friedman, T. Hastie, and R. Tibshirani. The Elements of

Statistical Learning: Data Mining, Inference and
Prediction. Springer, 2nd edition, 2009.

[16] C. Gentry. Fully homomorphic encryption using ideal

lattices. In STOC, 2009.

[17] S. Goldwasser and M. Bellare. Lecture Notes on

Cryptography. MIT, 2001.

[18] M. T. Goodrich. Randomized shellsort: A simple oblivious

sorting algorithm. In SODA, 2010.

[19] M. T. Goodrich. Data-oblivious external-memory

algorithms for the compaction, selection, and sorting of
outsourced data. In SPAA, 2011.

[20] T. Graepel, K. Lauter, and M. Naehrig. ML conﬁdential:

Machine learning on encrypted data. Cryptology ePrint
Archive, Report 2012/323, 2012.

[21] R. Hall, S. E. Fienberg, and Y. Nardi. Secure multiple
linear regression based on homomorphic encryption. J.
Oﬃcial Statistics, 2011.

[22] K. Hamada, R. Kikuchi, D. Ikarashi, K. Chida, and

K. Takahashi. Practically eﬃcient multi-party sorting
protocols from comparison sort algorithms. In ICISC, 2013.

[23] W. Henecka, S. K¨ogl, A.-R. Sadeghi, T. Schneider, and

I. Wehrenberg. TASTY: Tool for automating secure
two-party computations. In CCS, 2010.

[24] Y. Huang, D. Evans, J. Katz, and L. Malka. Faster secure
two-party computation using garbled circuits. In USENIX
Security, 2011.

[25] Y. Huang, J. Katz, and D. Evans. Quid-pro-quo-tocols:

Strengthening semi-honest protocols with dual execution.
In IEEE S&P, 2012.

[26] Y. Huang, L. Malka, D. Evans, and J. Katz. Eﬃcient

privacy-preserving biometric identiﬁcation. In NDSS, 2011.

[27] Y. Ishai, J. Kilian, K. Nissim, and E. Petrank. Extending

oblivious transfers eﬃciently. In CRYPTO, 2003.
[28] K. V. J´onsson, G. Kreitz, and M. Uddin. Secure

multi-party sorting and applications. Cryptology ePrint
Archive, Report 2011/122, 2011.

810[29] A. F. Karr, W. J. Fulp, F. Vera, S. S. Young, X. Lin, and

[56] O. Regev. On lattices, learning with errors, random linear

J. P. Reiter. Secure, privacy-preserving analysis of
distributed databases. Technometrics, 2007.

[30] A. F. Karr, X. Lin, A. P. Sanil, and J. P. Reiter.

Privacy-preserving analysis of vertically partitioned data
using secure matrix products. J. Oﬃcial Statistics, 2009.
[31] R. H. Keshavan, A. Montanari, and S. Oh. Learning low

rank matrices from O(n) entries. In Allerton, 2008.

codes, and cryptography. J. ACM, 56(6), 2009.

[57] A.-R. Sadeghi, T. Schneider, and I. Wehrenberg. Eﬃcient

privacy-preserving face recognition. In ICISC, 2009.
[58] E. Shi, T.-H. H. Chan, E. G. Rieﬀel, R. Chow, and

D. Song. Privacy-preserving aggregation of time-series data.
In NDSS, 2011.

[59] Y. Tsiounis and M. Yung. On the security of ElGamal

[32] D. E. Knuth. The Art Of Computer Programming —

based encryption. In PKC, 1998.

Volume 3 / Sorting and Searching. Addison-Wesley, 2nd
edition, 1998.

[33] V. Kolesnikov, A.-R. Sadeghi, and T. Schneider. Improved
garbled circuit building blocks and applications to auctions
and computing minima. In CANS, 2009.

[34] V. Kolesnikov and T. Schneider. Improved garbled circuit:

Free XOR gates and applications. In ICALP, 2008.

[60] G. Wang, T. Luo, M. T. Goodrich, W. Du, and Z. Zhu.

Bureaucratic protocols for secure two-party sorting,
selection, and permuting. In CCS, 2010.

[61] U. Weinsberg, S. Bhagat, S. Ioannidis, and N. Taft.

BlurMe: Inferring and obfuscating user gender based on
ratings. In RecSys, 2012.

[62] A. C.-C. Yao. Protocols for secure computations. In FOCS,

[35] Y. Koren, R. M. Bell, and C. Volinsky. Matrix factorization

1982.

techniques for recommender systems. IEEE Computer,
2009.

[36] B. Kreuter, A. Shelat, and C.-H. Shen. Billion-gate secure

computation with malicious adversaries. In USENIX
Security, 2012.

[37] S. K. Lam, D. Frankowski, and J. Riedl. Do you trust your

recommendations? An exploration of security and privacy
issues in recommender systems. In ETRICS 2006, 2006.

[38] S. K. Lam and J. Riedl. Shilling recommender systems for

fun and proﬁt. In WWW, 2004.

[39] K. Lauter, M. Naehrig, and V. Vaikuntanathan. Can

homomorphic encryption be practical? In CCSW, 2011.

[40] Y. Lindell. Fast cut-and-choose based protocols for

malicious and covert adversaries. IACR Cryptology ePrint
Archive, 2013.

[41] Y. Lindell and B. Pinkas. Privacy preserving data mining.

J. Cryptology, 2002.

[42] Y. Lindell and B. Pinkas. A proof of security of Yao’s

protocol for two-party computation. J. Cryptology, 2009.
[43] Y. Lindell and B. Pinkas. Secure two-party computation

via cut-and-choose oblivious transfer. J. Cryptology, 2012.

[44] Y. Lindell, B. Pinkas, and N. P. Smart. Implementing
two-party computation eﬃciently with security against
malicious adversaries. In SCN, 2008.

[45] D. Malkhi, N. Nisan, B. Pinkas, and Y. Sella. Fairplay –

Secure two-party computation system. In USENIX
Security, 2004.

[46] F. McSherry and I. Mironov. Diﬀerentially private

recommender systems: Building privacy into the Netﬂix
prize contenders. In KDD, 2009.

[47] B. Mobasher, R. Burke, R. Bhaumik, and C. Williams.

Toward trustworthy recommender systems: An analysis of
attack models and algorithm robustness. ACM Trans.
Internet Techn., 7(4), 2007.

[48] M. Naor, B. Pinkas, and R. Sumner. Privacy preserving

auctions and mechanism design. In 1st ACM Conference on
Electronic Commerce, 1999.

[49] A. Narayanan and V. Shmatikov. Robust de-anonymization

of large sparse datasets. In IEEE S&P, 2008.

[50] V. Nikolaenko, U. Weinsberg, S. Ioannidis, M. Joye,

D. Boneh, and N. Taft. Privacy-preserving ridge regression
on hundreds of millions of records. In IEEE S&P, 2013.

[51] K. Nissim and E. Weinreb. Communication eﬃcient secure

linear algebra. In TCC, 2006.

[52] P. Paillier. Public-key cryptosystems based on composite

degree residuosity classes. In EUROCRYPT, 1999.

[53] B. Pinkas, T. Schneider, N. P. Smart, and S. C. Williams.

Secure two-party computation is practical. In
ASIACRYPT, 2009.

[54] N. Pippenger and M. J. Fischer. Relations among

complexity measures. J. ACM, 26(2), 1979.

[55] M. O. Rabin. How to exchange secrets by oblivious

transfer. Technical Report TR-81, Aiken Computation
Laboratory, Harvard University, 1981.

[63] A. C.-C. Yao. How to generate and exchange secrets. In

FOCS, 1986.

APPENDIX
A. YAO’S GARBLED CIRCUITS

Yao’s protocol (a.k.a. garbled circuits) [63] (see also [42])
is a generic method for secure multi-party computation. In
a variant thereof (adapted from [48, 50]), the protocol is run
between a set of n input owners, where ai denotes the private
input of user i, 1 ≤ i ≤ n, an evaluator, that wishes to
evaluate f (a1, . . . , an), and a third party, the crypto-service
provider or CSP in short. At the end of the protocol, the
evaluator learns the value of f (a1, a2, . . . , an) but no party
learns more than what is revealed from this output value.
The protocol requires the function f can be expressed as a
Boolean circuit, e.g. as a graph of or, and, not and xor
gates, and that the evaluator and the CSP do not collude.

Oblivious Transfer. Oblivious transfer (OT) [55, 14] is
an important building block of Yao’s protocol. OT is two-
party protocol between a chooser and a sender. The sender
has two (cid:96)-bit strings σ0 and σ1. The chooser selects a bit b
and exactly obtains from the sender the string σb, without
the sender learning the value of b. In addition, the chooser
learns nothing about σ1−b (beyond its length).

Oblivious transfer protocols can be constructed from many
cryptographic assumptions. We describe below a protocol
based on the Decision Diﬃe-Hellman assumption [4].
Let G = (cid:104)g(cid:105) be a cyclic group of order q in which the
decisional Diﬃe-Hellman (DDH) assumption holds. Let also
Ω be an encoding map from {0, 1}(cid:96) onto G. Finally, let
c ∈ G whose discrete logarithm is unknown. The chooser
chooses x ∈R Zq and computes yb = gx and y1−b = c/gx.
She sends y0 to the sender. The sender represents σ0 and
σ1 as elements in G: ω0 = Ω(σ0) and ω1 = Ω(σ1). She
chooses r0, r1 ∈R Zq, recovers y1 = c/y0, and computes
C0 = (gr0 , ω0 y0
r1 ). The sender
sends C0, C1 to the chooser. Upon receiving C0, C1, the
rb /(grb )x using secret value x
chooser computes ωb as ωb yb
and obtains σb = Ω−1(ωb).

r0 ) and C1 = (gr1 , ω1 y1

Circuit Garbling. The key idea behind Yao’s protocol
resides in the circuit encoding. To each wire wi of the circuit,
the CSP associates two random cryptographic keys, K 0
wi and
K 1
wi , that respectively correspond to the bit-values bi = 0
and bi = 1. Next, for each binary gate g (e.g., an or-
gate) with input wires (wi, wj) and output wire wk, the CSP

811bi
bj

K0

wi

,K1

wi

K0

wj

,K1

wj

g

K0

wk

,K1

wk

g(bi, bj ) = bi ∨ bj

C. SORTING NETWORKS

for some random ρ ∈ Zq. Letting c = (c(1), c(2)), it is worth
remarking that one can publicly mask the ciphertext c with
any chosen random mask µ ∈ {0, 1}(cid:96) as
ˆc = (c(1), c(2) ⊕ µ) .

Decrypting ˆc = (ˆc(1), ˆc(2)) then yields the masked message
ˆm = m ⊕ µ. Indeed, we have

ˆc(2) ⊕ H(cid:0)(ˆc(1))x(cid:1) = (c(2) ⊕ µ) ⊕ H(cid:0)(gρ)x(cid:1)

=(cid:0)(m ⊕ H(yρ)) ⊕ µ(cid:1) ⊕ H(yρ)

= m ⊕ µ .

The scheme can be shown to be semantically secure in
the random oracle model, under the Decision Diﬃe-Hellman
assumption [59].

1, a(cid:48)

2, . . . , a(cid:48)

Sorting networks [9, 32] are circuits that sort an input
sequence (a1, a2, . . . , an) into a monotonically increasing se-
quence (a(cid:48)
n). They are constructed by wiring to-
gether compare-and-swap circuits, their main building block.
A compare-and-swap circuit is a binary operator taking on
input a pair (a1, a2), and returning the sorted pair (a(cid:48)
1, a(cid:48)
2)
where a(cid:48)
2 = max(a1, a2). For graphical
convenience, a comparator is usually represented as a ver-
tical line, as illustrated in Figure 8(a). Note that elements
are swapped if and only if the ﬁrst element is larger than the
second one. Figure 8(b) shows a sorting network example.

1 = min(a1, a2) and a(cid:48)

a1

a2

a(cid:48)
1 = min(a1, a2)
a(cid:48)
2 = max(a1, a2)

a1

a2

a3

a4

1

a(cid:48)
a(cid:48)
a(cid:48)
a(cid:48)

2

3

4

(a) Compare-and-Swap circuit

(b) Sorting network

Figure 8: Networks of compare-and-swap elements.

Sorting networks were speciﬁcally designed to admit an
eﬃcient hardware implementation, but also to be highly par-
allelizable. The eﬃciency of the sorting network can be mea-
sured by its size (the total number of comparisons) or depth
(the maximum number of stages, where each stage comprises
comparisons that can be executed in parallel). The depth of
the network reﬂects the parallel running time of the sorting.
For example, in Figure 8(b) the comparisons (a1, a2) and
(a3, a4) can be executed in parallel; so can comparisons
(a1, a3) and (a2, a4). As such, the depth of this network is 3,
which is the maximum number of compare-and-swaps along
each “line”. The network can be computed in 3 timesteps
with 2 processors or in 5 timesteps with just one processor.
The best known (and asymptotically optimal) sorting net-
work is the AKS network [2] that achieves size O(n log n)
and depth O(log n). Being an important theoretical discov-
ery, the AKS network has no pratical application because of
a large constant. Eﬃcient networks that are often used in
practice achieve depth O(log2 n) and size O(n log2 n). These
include Batcher, odd-even merge sort, bitonic sort, and Shell
sort networks [32]. In the presence of p processors, the run-
ning time of these networks is O(n(log2 n/p). Empirical
studies indicate that, in practice, Batcher has better average
performance than most widely used algorithms [60].

computes the four ciphertexts
(K g(bi,bj )

Enc

wk

(K

bi
wi

,K

bj
wj

)

for bi, bj ∈ {0, 1} .

)

(6)

wi , K 1

wj ) it is possible to recover the key K 1

The set of these four randomly ordered ciphertexts deﬁnes
the garbled gate. See [45] for an eﬃcient implementation.
For example, as illustrated on Fig. 7, given the pair of keys
(K 0
wk by decrypt-
ing Enc(K0
wk ). However, the other key, namely
wi
K 0
wk , cannot be recovered. More generally, it is worth not-
ing that the knowledge of (K bi
wj ) yields only the value
of K g(bi,bj )
and that no other output values can be recovered
for the corresponding gate.

wi , K bj

)(K 1

,K1

wk

wj

bi
0

0

1

1

bj
0

1

0

1

g(bi, bj )

0

1

1

1

wj

,K0

Garbled value
)(K0
wk
)(K1
wk
)(K1
wk
)(K1
wk

Enc(K0
wi
Enc(K0
wi
Enc(K1
wi
Enc(K1
wi

,K1

,K0

,K1

wj

wj

wj

)

)

)

)

Figure 7: Example of a garbled or-gate.

Circuit Evaluation. We are now ready to present the
complete protocol for evaluating f . The CSP generates a
private and public key, and makes the latter available to the
users. Each user i encrypts her private input ai under the
CSP’s public key to get ci, and sends ci to the evaluator.
Upon receiving all encrypted inputs, the evaluator contacts
the CSP to build a garbled circuit performing the steps of
(a) decrypting the encrypted input values, using the CSP’s
private key and (b) evaluating function f .

wk , 0) and (K 1

The CSP provides the evaluator with the garbled gates of
this circuit, each comprising a random permutation of the
ciphertexts (6), as well as the graph representing how these
connect.
It also provides the correspondence between the
garbled value and the real bit-value for the circuit-output
wires (the outcome of the computation): if wk is an circuit-
output wire, the pairs (K 0
wk , 1) are given to the
evaluator. To transfer the garbled values of the input wires,
the CSP engages in an oblivious transfer with the evalua-
tor, so that evaluator obliviously obtains the garbled-circuit
input values corresponding to the ci’s; this ensures that the
CSP does not learn the user inputs and that the evaluator
can only compute the function on these inputs alone. Hav-
ing the garbled inputs, the evaluator can “evaluate” each
gate sequentially, by decrypring gate and obtaining the keys
necessary to decrypt the output of the gates it connects to.
B. HASH-ELGAMAL ENCRYPTION
Let G = (cid:104)g(cid:105) be a cyclic group of order q and H : G →
{0, 1}(cid:96) be a cryptographic hash function. The public key is
pk = (g, y) where y = gx for some random x ∈ Zq, and the
private key is sk = x. A message m ∈ {0, 1}(cid:96) is encrypted
using

Epk : {0, 1}(cid:96) → G × {0, 1}(cid:96), m (cid:55)→ c =(cid:0)gρ, m ⊕ H(yρ)(cid:1)

812