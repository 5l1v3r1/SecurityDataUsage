Computational Veriﬁcation of C Protocol Implementations

by Symbolic Execution

Mihhail Aizatulin
The Open University

Andrew D. Gordon

Microsoft Research & University of Edinburgh

Jan Jürjens

TU Dortmund & Fraunhofer ISST

ABSTRACT
We verify cryptographic protocols coded in C for correspon-
dence properties with respect to the computational model
of cryptography. Our ﬁrst step uses symbolic execution to
extract a process calculus model from a C implementation
of the protocol. The new contribution is the second step
in which we translate the extracted model to a CryptoVerif
protocol description, such that successful veriﬁcation with
CryptoVerif implies the security of the original C implemen-
tation. We implement our method and apply it to verify sev-
eral protocols out of reach of previous work in the symbolic
model (using ProVerif), either due to the use of XOR and
Diﬃe-Hellman commitments, or due to the lack of an ap-
propriate computational soundness result. We analyse only
a single execution path, so our tool is limited to code fol-
lowing a ﬁxed protocol narration. This is the ﬁrst security
analysis of C code to target a veriﬁer for the computational
model. We successfully verify over 3000 LOC. One example
(about 1000 LOC) is independently written and currently in
testing phase for industrial deployment; during its analysis
we uncovered a vulnerability now ﬁxed by its author.

Categories and Subject Descriptors
C.2.2 [Computer-Communication Networks]: Network
Protocols—Protocol veriﬁcation; D.2.4 [Software Engineer-
ing]: Software/Program Veriﬁcation

Keywords
security, veriﬁcation, protocols, symbolic execution, Cryp-
toVerif, computational

INTRODUCTION

1.
The Problem of Verifying Cryptographic Software
in C The C programming language is a popular choice for
writing cryptographic software, such as protocols or devices.
Still, both the design of protocols and their implementa-
tion in C are notoriously error prone—there are frequent

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’12, October 16–18, 2012, Raleigh, North Carolina, USA.
Copyright 2012 ACM 978-1-4503-1651-4/12/10 ...$10.00.

u n s i g n e d c h a r ∗ p a y l o a d = m a l l o c (PAYLOAD LEN ) ;
i f ( p a y l o a d == NULL) e x i t ( 1 ) ;
RAND bytes ( p a y l o a d , PAYLOAD LEN ) ;
u l o n g m s g l e n = PAYLOAD LEN + 1 ;
u n s i g n e d c h a r ∗ msg = m a l l o c ( m s g l e n ) ;
∗ msg = 0 x01 ;
// add t h e t a g
memcpy ( msg + 1 , p a y l o a d , PAYLOAD LEN ) ; // add p a y l o a d
// one−t i m e pad
u n s i g n e d c h a r ∗ pad = o t p ( m s g l e n ) ;
x o r ( msg , pad , m s g l e n ) ;
s e n d ( msg , m s g l e n ) ;

new nonce1 : fixed20;
out(XOR(01|nonce1 , pad))

Figure 1: Example C fragment and extracted model.

security advisories of design and implementation ﬂaws in
cryptographic software.
In response to this problem, re-
searchers are developing a wide range of techniques for C
cryptographic software to ﬁnd bugs and to prove security
properties. These techniques span the spectrum between
testing and veriﬁcation, and include specialist veriﬁers [36],
random testing [32, 33], model checking [39, 23], general-
purpose veriﬁers [27, 46], and symbolic execution [5, 24].

All this prior work is based on the symbolic model of cryp-
tography [26], rather than the computational model
[34].
One reason is that automated techniques for the symbolic
model were invented earlier than for the computational mo-
del, and are much better understood. Still, security in the
symbolic model is generally weaker than security in the com-
putational model, and hence is less convincing. To address
this problem, [44] uses a process calculus over a term lan-
guage that captures probabilistic polynomial time to prove
an authentication property of a cryptographic protocol. [2]
pioneered principles of computational soundness, which es-
tablish that certain properties in the symbolic model imply
corresponding properties in the computional model. [5] re-
ports on a tool, here referred to as csec-modex, which ap-
plies the CoSP framework [7] for computational soundness
to obtain computational security for one of the ProVerif [17]
models extracted from C by symbolic execution [40]; to the
best of our knowledge, that one model amounts to the only
published proof of computational security for a C program.
In general, computational soundness principles have sig-
niﬁcant limitations. For example, for [5], the authors could
only obtain a security result in the computational model for
one example out of ﬁve, which was written by the authors to
use non-standard tagging to comply with the CoSP assump-
tions. To take another example, computational soundness
for XOR is problematic. The method presented in [5] cannot
prove secrecy of nonce1 in the example in Fig. 1 because of

712XOR. Obtaining computational soundness for XOR in gen-
eral is not possible [50], although it is possible for a limited
class of protocols [41], not including the one-time pad sce-
nario of the example mentioned above. Hence, instead of re-
lying on computational soundness, recent automated tools,
including CryptoVerif [19], EasyCrypt [10], and F7 [11] en-
riched with modules for computational cryptography [30],
obtain computational security directly.
This Paper: Applying a Computational Prover to
C Code Our aim is to connect one of these computational
provers to C code, by enriching a model extraction tool csec-
modex to target its input format. We target CryptoVerif,
but our approach may well be adapted to other computa-
tional tools. The foot of Fig. 1 shows the veriﬁable Cryp-
toVerif model extracted from the C code, a small example of
the beneﬁts of switching to a computational veriﬁer. In all,
we obtain computational results for more than 3000 LOC in
C, rather more than the 450 LOC in the prior work to which
computational soundness applies. One example (about 1000
LOC) is code for smart electricity meters, written outside
our group, without veriﬁcation in mind, and in which we
found a new bug just before its test deployment.

To put the technical contributions in context, our overall
vision is to enable the veriﬁcation of new and old protocol
code in C by leveraging progress in automatic veriﬁers for
protocol models. In particular, we envisage that new proto-
cols may be developed by writing a reference implementa-
tion in C, suitable for interoperability testing and possibly
use in production, while simultaneously extracting a proto-
col model for veriﬁcation with automatic tools. We continue
the vision of a line of work on veriﬁed reference implementa-
tions in functional languages [16, 35, 13, 14, 12] but target
C because of its ubiquity, and its greater acceptability to
practitioners (and because of its challenges).

In the rest of the section we sketch the paper’s structure.
Description of the Method Section 3 introduces the
main new ideas of the paper—how to adapt the results of
the symbolic execution of C to the CryptoVerif calculus—by
way of a detailed example. Beforehand, Section 2 informally
recalls the intermediate process calculus, IML, and the tar-
get CryptoVerif calculus.

Our veriﬁcation method proceeds in several steps (cf.
Fig. 2). The method takes as input the C source code of
the protocol participants as well as a CryptoVerif template
ﬁle, which contains the cryptographic assumptions about
the primitives used by the implementation, the environment
process which spawns the participants and generates shared
cryptographic material, and a query for the property that
the implementation is supposed to satisfy. The template ﬁle
omits the actual model of the protocol participants. That
model is extracted from C code by symbolic execution and
rewriting.
If the veriﬁcation fails, typically the user must
provide more annotations in the template ﬁle. The input
also includes for each cryptographic function f called by the
implementation the C code of a function f proxy that de-
scribes the correspondence of the C arguments of f to the
formal arguments of the implemented primitive in the Cryp-
toVerif model. The template ﬁle and the proxy functions
form the trusted base of the veriﬁcation.

In the ﬁrst step, we compile the program down to a simple
stack-based instruction language (CVM) using CIL [45] to
parse and simplify the C input. In the next step we symbol-
ically execute CVM programs to eliminate memory accesses

C source

CIL

C virtual machine (CVM)

Symbolic execution [5]

Intermediate model language (IML)

Formatting Abstraction (Section 3)

CryptoVerif Calculus

CryptoVerif

Veriﬁcation Result

Figure 2: An outline of the method

and destructive updates, thus obtaining an equivalent pro-
gram in an intermediate model language (IML)—a version
of the applied pi calculus extended with bitstring manipula-
tion primitives. Both these steps are the same as in [5]. We
review them brieﬂy in Section 4.

The new part of the method, described in Section 3, is
the step that takes IML to the CryptoVerif calculus. This
step abstracts away the details of message formatting that
are present in IML by replacing the bitstring manipulation
by application of new formatting functions for encoding and
parsing bitstrings, so that, say, 01| len(x1)|x1|x2 becomes
conc(x1, x2) and x{5, x{1, 4}} becomes parse(x), where b|b(cid:48)
denotes the concatenation of b and b(cid:48) and b{o, l} is the sub-
string of b starting at position o of length l.

By constructing suitable queries to an automatic prover
(the SMT solver Yices [28]), we check that the expression un-
derlying each formatting function matches the CryptoVerif
type for the function. For instance, if x1 and x2 are both bit-
strings of at most 20 bytes then conc(x1, x2) is a bitstring of
at most 45 bytes. We also establish certain properties that,
if true, may help CryptoVerif to verify the protocol:

• parsing equations such as parse(conc(x1, x2)) = x1,
• injectivity of encoding functions,
• applications of parsing functions in which we check
that the parsed value is in the range of a certain en-
coder. In this case we can use the pattern matching
construct of CryptoVerif, and this allows more models
to be veriﬁed.

Section 4 describes two theorems that establish the sound-
ness of our method and form the theoretical justiﬁcation of
our work. Section 5 describes a practical evaluation of our
method against a range of cryptographic examples, totalling
more than 3000 LOC.

To complete the paper, Section 6 discusses related work,

while Section 7 summarizes and discusses future work.
Original Contributions of the Paper Our two main
contributions are:
• A method for automatic veriﬁcation of C code in the
computational model, by re-targetting a model extrac-
tor based on symbolic execution (csec-modex) to an
automatic veriﬁer based on game-rewriting (Crypto-
Verif).

• Veriﬁcation of a substantial codebase,

including an
independently-written real-world protocol (for smart
metering), leading to a vulnerability, acknowledged and
ﬁxed by its author.

713Thanks to CryptoVerif, our method supports a wider range
of crypto-algorithms than before: the protocols that we ver-
iﬁed make use of XOR, Diﬃe-Hellman commitments, as well
as operations including public-key encryption, MACs, and
authenticated encryption supported by the previous method.
Previously, to use a new primitive one had to prove a compu-
tational soundness theorem or ﬁnd an existing theorem and
link it to our security deﬁnition. Now we have full access to
all of the cryptography supported by CryptoVerif.
Challenges The main diﬃculty when transforming from
IML to CryptoVerif is to handle message types explicitly—
the previous work mentioned above targets an untyped ver-
sion of ProVerif. The main task is to prove that formatting
functions satisfy the given types and a peculiarity is that
we make typechecking context-sensitive: when calling f (b)
we consider the information available at the call site to help
establish that b is of the desired type (similar to contract-
based veriﬁcation).

The main challenge when justifying the method is to relate
the semantics of IML and CryptoVerif. The main issue is
that our underlying execution model (PTS) by means of
which the semantics of IML is deﬁned uses external attackers
and CryptoVerif uses internal attackers.
In other words,
in IML the attacker is part of the semantics, whereas in
CryptoVerif it is part of the process, running in parallel with
the process representing the protocol.

An interesting theoretical challenge arises from the fact
that cryptographic security deﬁnitions are given with re-
spect to a security parameter, but a C implementation is
written for a single value of the security parameter. In par-
ticular, it can only address a memory of a ﬁxed size. This
problem is also discussed in [42]. In our work we deal with
this problem by showing how to generalize the extracted
IML model to arbitrary security parameters such that all
the relevant properties of the model are preserved. Unlike
for C programs, this can be done rather easily, by construct-
ing appropriate generalised parsing and encoding functions
that can deal with messages of arbitrary sizes.
Limitations Given the complexity of the C language, anal-
ysis tools rely on front ends that translate the language into
a much simpler representation. Examples are LLVM and
CIL used by KLEE and Frama-C [21, 31]. We wrote a plu-
gin for CIL that instruments a C program to output its own
CVM representation when run. As there is no formal proof
of correctness for CIL, our formal results apply to CVM
programs, and the link to C is made only informally.

As in the initial work on csec-modex we only analyse a
single execution path of the protocol. The CVM is pro-
duced by a single run R of the program P and thus rep-
resents a pruned program P (cid:48) such that P (cid:48) produces the
same run.
In the pruned program every statement of the
form if (c){A}else{B} is replaced by if (c){A}else{exit (1);}
or if (c){ exit (1);} else{B}, depending on which branch was
taken in R, and loops are unrolled the number of times they
were executed in R. All our soundness results apply to the
program P (cid:48). In the case of crypto-protocols we believe P (cid:48) to
be a close approximation of P , as the structure the protocols
(such as those in the extensive SPORE repository [47]) is of-
ten linear. The code of libraries such as PolarSSL contains a
lot of if-statements, but many of those have conditions that
become constant for particular settings of conﬁguration vari-
ables, or deal with cryptographic security checks and abort
the execution immediately if those checks fail. We would

b ∈ MS , x, i ∈ Var , f ∈ Ops
e ∈ IExp ::=

expression

b

x
f (e1, . . . , en)
e|e(cid:48)
e{eo, el}
len(e)

P ∈ IML ::=

0
P|P (cid:48)
!i≤N P
in(c[e1, . . . , en], x); P
new x : T ; P
out(c[e1, . . . , en], e); P
let x = e in P
if e then P [else P (cid:48)]
event ev (e1, . . . , en); P

concrete bitstring

variable

function application

concatenation

substring extraction

length

process

nil

parallel composition

replication N times

input

random number

output

assignment

conditional

event

Figure 3: The syntax of IML.

like to provide a quantitative validation of this statement in
future work. In any case, P (cid:48) is a program that can success-
fully execute a session of the protocol in place of P , and so
verifying P (cid:48) increases conﬁdence in the correctness of P .

Our work is currently limited to trace properties of pro-
tocols, such as authentication or weak secrecy. We leave
treatment of observational equivalence properties, such as
strong secrecy, to future work.

An extended version of the paper with full details is avail-
able [6], together with our implementation (with outputs for
each of our examples).

2. REVIEW—IML AND CRYPTOVERIF

We present the process calculus we use, the intermediate
model language (IML), produced from symbolic execution
of C, together with the CryptoVerif calculus to which IML
models are translated.
IML is slightly modiﬁed from the
version in [5] so that the CryptoVerif calculus forms a syn-
tactic subset of it. At the same time, the subset of IML
produced by symbolic execution coincides with [5] so that it
is easy to transfer the symbolic execution soundness result
from there. This section presents an informal overview of
the calculus, details are given in the full version.

The syntax of IML is shown in Fig. 3. We work with
two semantics for IML. The ﬁrst originates from [5] and is
dictated by the semantics of C programs from which IML
models are extracted. The second is the semantics used in
the CryptoVerif tool which will be given for a subset of IML.
In this paper we shall develop a transformation from IML
to the CryptoVerif subset of IML such that the CryptoVerif
semantics of the transformed program is sound with respect
to the IML semantics of the original program.

The main diﬀerences between IML’s and CryptoVerif’s
semantics are as follows. First, CryptoVerif semantics as-
sumes an arbitrary security parameter. Since real-life cryp-
tographic protocols are typically designed and implemented
for a ﬁxed value of the security parameter, we ﬁx an arbi-
trary k0 ∈ N and deﬁne the IML semantics with respect to
k0 only. Second, CryptoVerif uses a special value ⊥ that is

714distinct from any bitstring and can be returned by a com-
putation to represent failure. The execution does not stop
when such a value is encountered. There is no such special
value in C, and the only way a function can fail is by aborting
the execution of a process. Thus in IML if any computation
returns ⊥ at any time, the execution immediately stops.
Third, CryptoVerif processes can operate on bitstrings of
any length. C programs can only operate on bitstrings of a
certain maximal length, so if any computation in IML, say,
concatenation, would return a longer bitstring, the execu-
tion stops. We choose a ﬁxed but arbitrary N ∈ N to be the
size of a machine pointer in bits and let MS = {0, 1}<2N
be the set of bitstrings that ﬁt into machine memory. Fi-
nally, CryptoVerif programs assign types to bitstrings, but
C programs and IML processes do not (in C one can assign
a type to a variable, but not to the contents of a memory
buﬀer in which a message is stored). Types will be denoted
by T . For each security parameter k the interpretation of
a type T is given by Ik(T ) ⊆ BS ∪ {⊥}, where BS is the
set of all bitstrings. We shall use the following types in our
modelling: the type bitstring representing all bitstrings
and bitstringbot representing all bitstrings together with
⊥, the type bool representing the set {true, false}, where
true = 1 and false = 0, and for each n < 2N the types
fixedn and boundedn such that for the security parameter
k0 the type fixedn is the type of bitstrings with exactly n
bits and boundedn is the type of bitstrings with up to and
including n bits.
The calculus uses a ﬁnite set Ops of functions symbols
such that each symbol f ∈ Ops has an associated arity n
and a type declaration f : T1× . . .× Tn → T . The set Ops is
meant to contain both the primitive operations of the lan-
guage (such as the arithmetic or comparison operators of
C) and the cryptographic primitives that are used by the
implementation. IML and CryptoVerif use two diﬀerent in-
terpretations of function symbols. In IML the interpretation
of a function symbol f with arity n is a function I(f ) from
MS n to MS ∪ {⊥} (a partial function). In CryptoVerif the
interpretation of f for a security parameter k is given by a
function ˜Ik(f ) from Ik(T1) × . . . × Ik(Tn) to Ik(T ). In both
cases the functions are required to be computable in poly-
nomial time in the length of the arguments and the security
parameter. The equality function is overloaded:
for each
type T there is the equality function =T : T × T → bool,
but we shall omit the type index to lighten notation. We
require that for each function symbol f the IML interpreta-
tion I(f ) and the CryptoVerif interpretation ˜Ik0 (f ) coincide
on arguments for which both are deﬁned.

The calculus uses parameters, denoted by N , to bound
the number of process replications. The value of a parame-
ter N depends on the security parameter k and is denoted
by Ik(N ) ∈ N. As IML is deﬁned with respect to a ﬁxed
security parameter k0, its semantics uses the value Ik0 (N ).
The calculus assumes a countable set of channel names. We
denote channels by c.

Expressions are evaluated with respect to an environment
η : Var (cid:42) BS that assigns variables to bitstrings. The ex-
pression f (e1, . . . , en) applies a function to its arguments,
the expression e|e(cid:48) concatenates two bitstrings, the expres-
sion e{eo, el} extracts a substring of e starting at position
eo of length el, and the expression len(e) returns an N -
bit value containing the length of e.
In IML if the result
of any subexpression evaluation is not well-deﬁned (for in-

x, i ∈ Var , f ∈ Ops

e ::=

x
f (e1, . . . , en)

Q ∈ CV ::=

0
Q|Q(cid:48)
!i≤N Q
in(c[e1, . . . , en], x); P

P ::=

out(c[e1, . . . , en], e); Q
new x : T ; P

let x = e in P
if e then P [else P (cid:48)]
event ev (e1, . . . , en); P

expression

variable

function application

input process

nil

parallel composition

replication N times

input

output process

output

random number

assignment

conditional

event

Figure 4: The syntax of the CryptoVerif calculus.

stance, substring extraction is out of bounds), the overall
result is ⊥. Also if the result of any subexpression evalua-
tion is longer than 2N − 1 bits, the overall result is ⊥. This
models the fact that a machine would crash if an interme-
diate result does not ﬁt into memory.
In CryptoVerif the
bitstring-manipulation expressions are not available.

The process structure of IML is standard and is designed
to mimic the CryptoVerif structure. The process 0 does
nothing, the process P|P (cid:48) executes P and P (cid:48) in parallel, the
process !i≤N P executes N copies of P in parallel, where N is
a parameter that depends on k, as deﬁned above. In the nth
copy of P the replication index i is set to n. Communica-
tion is performed using the in and out constructs in which
channel names are used with parameters, typically replica-
tion indices. The communication between two endpoints is
performed only when the parameters match. This gives the
attacker the power to precisely specify the recipient of a
message. The construct new x : T generates a value of type
T uniformly at random. For this T must be a ﬁxed-length
type. The construct event ev (e1, . . . , en) with an event la-
bel ev is used to ﬂag an event during the execution. The
security deﬁnitions will refer to probabilities of certain event
traces in an execution. The rest of the language is standard.
The CryptoVerif calculus shown in Fig. 4 is a subset of
IML in which the bitstring manipulation primitives are no
longer available and the processes are separated into alter-
nating input and output processes. We require CryptoVerif
processes to be well-typed with respect to function types
introduced above. The diﬀerences from the original Cryp-
toVerif calculus in [19] are as follows:

ted as we do not require it for modelling.

• The ﬁnd form of the full CryptoVerif calculus is omit-
• In [19], each variable is an array accessed using repli-
cation indices, that is, variable access has the form
x[i1, . . . , in]. This is used in the ﬁnd construct to ac-
cess variables of other processes by bringing into scope
a replication index of another process. Given that we
omit the ﬁnd construct, such access is no longer pos-
sible, so in our version array access is not explicit, and
the semantics uses local environments for each process
instead of a single global environment. The replication
indices are only used as channel parameters.

715A

: event client begin(A, B , request)

A → B : A,{request, kS}kAB
B → A : {response}kS

B

: event server reply(A, B , request, response)

A

: event client accept(A, B , request, response)

Figure 5: Authenticated RPC: RPC-enc

let A =

if clientID = xClient then
event client begin(clientID, serverID, request);
new kS seed1: keyseed;
let k S = kgen(kS seed1) in
let msg1 = ’p’|len(request)|request|k S in
new nonce1: seed;
let cipher1 = E(msg1, lookup(clientID, serverID, db), nonce1) in
let msg2 = ’p’|len(clientID)|clientID|cipher1 in
out(c, msg2);
in(c, msg3);
event client accept(clientID, serverID, request,

injbot−1(D(msg3, k S))); 0 .

let B =
in(c, msg1);
if ’p’ = msg1{0, 1} then
if len(msg1) ≥ 5 + msg1{1, 4} then
let client1 = msg1{5, msg1{1, 4}} in
let cipher1 = msg1{5 + msg1{1, 4},

len(msg1) − (5 + msg1{1, 4})} in

if client1 = xClient then
let msg2 = injbot−1(D(cipher1, lookup(client1, serverID, db))) in
if ’p’ = msg2{0, 1} then
if len(msg2) ≥ 5 + msg2{1, 4} then
let var2 = msg2{5, msg2{1, 4}} in
event server reply(client1, serverID, var2, response);
let k S = msg2{5 + msg2{1, 4},
if len(msg2) − (5 + msg2{1, 4}) = 16 then
new nonce1: seed;
let cipher2 = E(response, k S, nonce1) in
out(c, cipher2); 0 .

len(msg2) − (5 + msg2{1, 4})} in

Figure 6: The IML model of RPC-enc extracted
from the C code.
3. TRANSLATING IML TO CRYPTOVERIF
We show the transformations that turn an IML process
into a CryptoVerif process on an example. The extended
version formalizes these transformations and includes the
full CryptoVerif input of the example.

The Example Protocol and its Security Goals Our
example protocol, due to [30], is an encryption-based vari-
ant of the RPC protocol, already considered in the papers
In the following, {m}k stands for the en-
[14, 27, 5, 4].
cryption, using an authenticated encryption mechanism, of
plaintext m under key k while the comma represents an in-
jective pairing operation. The protocol narration in Fig. 5
describes the process of A in client role communicating to B
in server role. The key kAB is a unidirectional long-term key
shared between A and B (should B wish to play the client
role, they would rely on a key kBA, distinct from kAB). The
key kS is the session key freshly generated by A and the
payloads request and response are freshly generated. Like
in [4] we assume that the server is always honest, but the
client may be compromised. We write bad(A) to mean that
the client A is compromised.

We aim to prove authentication and secrecy properties:

1. Authentication properties state that each principal can
ensure that a received message was produced by the
correct protocol participant. These properties are spec-
iﬁed using event correspondences of the form:

let A =

in(c in, ());
if clientID = xClient then
event client begin(clientID, serverID, request);
new kS seed1: keyseed;
let k S = kgen(kS seed1) in
let msg1 = conc1(request, castfixed16→bitstring(k S)) in
new nonce1: seed;
let cipher1 = E(msg1, lookup(clientID, serverID, db), nonce1) in
let msg2 = conc1(clientID, cipher1) in
out(c out, msg2);
in(c in, msg3: bitstring);
let injbot(var1) = D(msg3, k S) in
event client accept(clientID, serverID, request, var1);
out(c out, ()); 0 .

let B =

in(c in, msg1: bitstring);
let conc1(client1, cipher1) = msg1 in
if client1 = xClient then
let injbot(msg2) = D(cipher1, lookup(client1, serverID, db)) in
let conc1(var2, k S) = msg2 in
event server reply(client1, serverID, var2, response);
new nonce1: seed;
let cipher2 = E(response, castbitstring→fixed16 (k S), nonce1) in
out(c out, cipher2); 0 .

Figure 7: The CryptoVerif translation of the IML
model of RPC-enc.

server reply(A, B, req, resp)

=⇒ client begin(A, B, req) ∨ bad(A)

client accept(A, B, req, resp)

=⇒ server reply(A, B, req, resp)

The ﬁrst property states that, whenever server reply
happens, either client begin has happened with cor-
responding parameters or the client is compromised.
Similarly, the second property states that, whenever
the event client accept happens, the event server reply
has happened before. There is no compromise in this
case, as we assume the server to be honest.

2. Secrecy properties state that the attacker cannot learn
values of payloads, where the secrecy of response is
conditional on the client being honest.

Transforming IML to CryptoVerif
The main goal of our transformations is to eliminate the
string-manipulating expressions that contain concatenation
and substring extraction operations. A crucial observation is
that these primitives are used to implement tupling and pro-
jection operations: we replace them by application of newly
introduced function symbols for tupling and projection.
We call an expression e with variables x1, . . . , xn an en-
coding expression when e = e1| . . .|em and each ei is either
a constant, a variable xj for some j ≤ n, or has the form
len(xj) for some j ≤ n. We call an expression e with a single
variable x a parsing expression when e = x{eo, el} and eo
and el are arithmetic expressions that can themselves con-
tain len(x) or other parsing expressions with the variable
x. An encoder is a function fc such that fc(b1, . . . , bn) =
ec[b1/x1, . . . , bn/xn] for some encoding expression ec and a
parser is a function fp such that fp(b) = ep[b/x] for some
parsing expression ep. Encoders and parsers are collectively
called formatting functions.

To describe our transformation steps, we use RPC-enc
as a running example: Fig. 6 shows the initial IML code,
while Fig. 7 shows the resulting CryptoVerif model. For

716e : T E, FP , T (cid:96) e (cid:32) e(cid:48)

E{x (cid:55)→ T} (cid:96) P (cid:32) P (cid:48)

E (cid:96) let x = e in P (cid:32) let x = e(cid:48) in P (cid:48)

prove(F ⇒ f (e1, . . . , en) : T )

f : T1 × . . . × Tn → T E, FP , Ti (cid:96) ei (cid:32) e(cid:48)
1, . . . , e(cid:48)

E, F , T (cid:48) (cid:96) f (e1, . . . , en) (cid:32) castT→T (cid:48) (f (e(cid:48)

prove(F ⇒ f (e1, . . . , en) : T (cid:48))

i

n))

Figure 8: Selected typechecking rules.

the details of how IML is extracted from C by symbolic
execution see our prior work [5, 4]. The intended meaning
of the variables is as follows: clientID and serverID are
global constants containing the names of an honest client
and an honest server, xClient is the attacker-chosen name of
the client that the server should communicate with, request
and response are attacker-chosen bitstrings, and db is the
key database used to look up shared keys (some of which
may be compromised).

Next, we consider each transformation step in turn.

Collecting facts We record the facts that hold at each
point in the process. For each subprocess P , let the con-
text FP be the set of conditions that are checked in the
if-statements above P . During the transformations, we im-
plicitly propagate these fact sets, that is, whenever we sub-
stitute a subprocess P by P (cid:48), we also set FP (cid:48) = FP .
Extracting Encoders We replace each subexpression of
the form e[e1/x1, . . . , em/xm], where e is an encoding ex-
pression, by an application of a fresh function symbol c. In
our example, the deﬁnitions of msg1 and msg2 in A become

let msg1 = conc1 (request, kS) in ...
let msg2 = conc1 (clientID, cipher1 ) in ...

where conc1 (x1, x2) = ’p’| len(x1)|x1|x2.
Extracting Parsers We replace each subexpression of the
form e[e(cid:48)/x], where e is a parsing expression, by an appli-
cation of a fresh function symbol p.
In our example, the
deﬁnitions of client1 and cipher1 in B are changed to

let client1 = parse1 (msg1 ) in ...
let cipher1 = parse2 (msg1 ) in ...

where

parse1 (x) = x{5, x{1, 4}},
parse2 (x) = x{5 + x{1, 4}, len(x) − (5 + x{1, 4})}.

Parsing Equations We record the result of applying each
parser to each encoder. For each parser fp and encoder fc
we simplify the expression ep[ec/x], where ep and ec are the
parsing and the encoding expression that deﬁne fp and fc.
If the expression simpliﬁes to a variable xi, we record the
equation fp(fc(x1, . . . , xn)) = xi. In our example, we obtain
the equations:

parse1 (conc1 (x1, x2)) = x1
parse2 (conc1 (x1, x2)) = x2

A detail that we omit here is that the equation will not
hold in IML if the arguments x1 and x2 are too long and
conc1 would create a result longer than 2N .
In the full
version we treat this problem and show that the deﬁnitions
of encoders and parsers can be generalised in the CryptoVerif
interpretation such that the equation holds unconditionally.

Typechecking We typecheck the process, proving types of
newly introduced formatting functions, and introduce type-
casts where necessary. For simplicity we assume that the
types for the formatting functions are given by the user along
with the types of cryptographic operations. In the full ver-
sion we infer most of these types during typechecking.

The fact that an expression e has type T will be denoted

by a predicate intype(e, T ), in particular, for each e

intype(e, fixedn) = (getLen(e) = n),
intype(e, boundedn) = (getLen(e) ≤ n),
intype(e, bitstring) = true .

where the function getLen returns for each symbolic expres-
sion an expression representing its length in bits:

getLen(len(. . .)) = N ,
getLen(b) = |b| , for b ∈ MS ,
getLen(x) = len(x), for x ∈ Var ,
getLen(op(e1, . . . , en)) = len(op(e1, . . . , en)),
getLen(e1|e2) = getLen(e1) + getLen(e2),
getLen(e{eo, el}) = el.

Let f : T1 × . . .× Tn → T be a formatting function and let
ef be the deﬁning expression for f with variables x1, . . . , xn.
Given a context F and expressions e1, . . . , en, we denote by
prove(F ⇒ f (e1, . . . , en) : T (cid:48)) the fact that the application
of f satisﬁes the type T (cid:48) (which may be diﬀerent from T )
in context F: assuming the arguments ei have types Ti, the
expression f (e1, . . . , en) must belong to type T (cid:48). Formally

intype(e1, T1) ∧ . . . ∧ intype(en, Tn) ∧ F

⇒ intype(ef [e1/x1, . . . , en/xn], T

(cid:48)

).

We use two typing judgements. The judgement E (cid:96) P (cid:32)
P (cid:48) means that in the typing environment E (a mapping from
variables to types) the process P can be rewritten to a type-
correct process P (cid:48). The judgement E,F, T (cid:96) e (cid:32) e(cid:48) means
that in the typing environment E, given a context F, the
expression e can be rewritten to a type-correct expression
e(cid:48) of type T . We also use the judgement e : T to mean that
the declared type of e is T . In particular, f (. . .) : T when
the return type of f is T .

Two crucial typechecking rules are shown in Fig. 8. The
ﬁrst rule rewrites let-statements in straightforward manner.
The second rule rewrites formatting function applications.
It checks that the function satisﬁes both its declared type
T and its required type T (cid:48) and inserts a typecast if neces-
sary. A typecast from a type T to a type T (cid:48) is performed
by a function castT→T (cid:48) : T → T (cid:48) which is identity on the
intersection of T and T (cid:48) and arbitrary elsewhere.

In our RPC-enc example we declare

conc1 : bitstring × bitstring → bitstring

parse1 , parse2 : bitstring → bitstring

We cannot give a more precise type to conc1 because it is
used to carry data of diﬀerent type in the ﬁrst and the sec-
ond message. In particular, the session key kS has the type
bitstring on the server side, as it is the result of parsing the
incoming message. At the same time the encryption func-
tion E has type bitstring × fixed16 × seed → bitstring.
Thus kS must be guaranteed to be 16 bytes long before being
passed to the encryption function. This is indeed checked

717by the IML process before applying the function, and the
typechecking algorithm makes use of this context informa-
tion before replacing kS by castbitstring→fixed16 (kS) in the
encryption.

1, . . . , x(cid:48)

Injectivity of Encoders We check which encoders fc are
injective, meaning that fc(x1, . . . , xn) = fc(x(cid:48)
n) im-
plies xi = x(cid:48)
i for all i. Our check takes into account the type
of the encoder. A suﬃcient condition for the encoder to be
injective is when there is at most one argument which is not
preceded by its length in the encoding and is not of a ﬁxed-
length type. Formally, an encoder fc : T1 × . . . × Tn → T is
injective whenever in its deﬁning expression ec = e1| . . .|em
there is at most one i such that ei = xj for some j ≤ n,
there is no expression len(xj) preceding ei in e, and Tj is
not a ﬁxed-length type. Applying this criterion, we see that
conc1 is injective: there is only one argument variable (x2)
that is not preceded by its length.

uses

process

Treatment of Inverse Functions Some functions in the
IML input may be marked by the user as inverses of other
functions (this information forms part of the trusted cryp-
tographic model). In our example these are the functions
injbot and injbot−1. The deﬁnition of the encryption scheme
in CryptoVerif provides the natural injection function injbot :
T → bitstringbot from the plaintext type T associated
with the encryption scheme into the type of all bitstrings.
injbot−1 :
The
bitstringbot → T to check that the result of the decryption
is not ⊥ and belongs to the type T (in the case of RPC-enc
the type T is simply bitstring). The IML implementation
Ainjbot−1 is assumed to return ⊥ whenever its argument is
not in the range of injbot (the CryptoVerif implementation
˜Ik0 (injbot−1) is allowed to return anything in this case).
If a function f−1 is marked as an inverse of an injective
function f , whenever an expression f−1(e) occurs at the top
of a subprocess P , we make explicit the check that e is in
the range of f :

function

inverse

the

let x = f−1(e) in if f (x) = e then P

In CryptoVerif, this can be abbreviated using pattern match-
ing as let f (x) = e in P , and CryptoVerif succeeds more of-
ten when given the pattern-matching form. In our example
we replace the applications of injbot−1 by pattern matching
on injbot:

let injbot(var1 ) = D(msg3 , kS) in
event client accept(clientID, serverID, request, var1 );
...
let injbot(msg2 )

= D(cipher1 , lookup(client1 , serverID, db)) in ...

Parsing Safety In some cases before an application of a
parser fp(e) at the top of a subprocess P , the facts in the
context FP are suﬃcient to establish that the parsing is safe,
that is, e is actually in the range of some encoder fc. The
exact method is the same as in [5] and is described in the
extended version of the paper. In summary, given a bitstring
b, to check that b is in the range of fc, it is suﬃcient to check
all the constant (tag) ﬁelds and to check that the sum of the
length ﬁelds is consistent with the actual length of b. For
instance, the following facts (checked in lines 2 and 3 of B)
establish that msg1 belongs to the range of conc1 :

’p’ = msg1{0, 1};

len(msg1 ) ≤ 5 + msg1{1, 4}.

The ﬁrst fact says that msg1 has the correct tag for conc1
and the second says that the sum of all ﬁeld lengths is con-
sistent with the overall length of msg1 . Any parsing of msg1
that occurs after these facts have been checked is safe.
If fc is an injective encoder of arity n and the parsing
equation fp(fc(x1, . . . , xn)) = xi holds for some i ≤ n, the
subprocess above is replaced by let fc(x1, . . . , xn) = e in
P [xi/fp(e)], which is an abbreviation for

−1
c,1 (e) in ... let xn = f−1

let x1 = f
if fc(x1, . . . , xn) = e then P [xi/fp(e)]

c,n(e) in

−1
where f
c,i are the partial inverses of fc provided by injec-
tivity. In our example the messages msg1 and msg2 in B
get decomposed as

let conc1 (client1 , cipher1 ) = msg1 in ...
let conc1 (var2 , key) = msg2 in ...

Input-Output Normalisation We insert dummy inputs
and outputs to make sure that the input-output alternation
is correct. In our example, we add the dummy input at the
beginning of A and the dummy output at the end of A.

each subprocess of

Replication Indices We add explicit replication indices to
inputs and outputs to make sure the attacker can speciﬁcally
pinpoint the process he wants to send a message to. We re-
place
form in(c[], x); P by
in(cin[b, i1, . . . , in], x); P , where b is a fresh constant and
i1, . . . , in are the replication indices in replications above P .
Similarly we
form
out(c[], x); P by out(cout[b, i1, . . . , in], x); P .

each subprocess

replace

the

the

of

In the implementation we only need to give distinct names
to all the channels, as replication indices are already implicit
in the CryptoVerif input.

Removing Auxiliary Tests We remove if-statements in
which the condition is unlikely to help CryptoVerif, in par-
ticular those that contain inequalities or arithmetic expres-
sions. Removing if-statements may only add new-behaviours,
so if the process after removal satisﬁes a trace property then
so does the original process.
Generating Additional Facts for CryptoVerif
We describe the additional information that we supply to
CryptoVerif, beyond the process generated from IML, to
help it verify the model. This information is automatically
generated during the translation.
Disjointness of Encoders If two encoders f : T1 × . . . ×
Tn → T and f(cid:48) : T (cid:48)
m → T (cid:48) are known to have
disjoint ranges, that is, f (b1, . . . , bn) (cid:54)= f(cid:48)(b(cid:48)
m) for
any b1, . . . , bn and b(cid:48)
m of suitable types then in case
T = T (cid:48) we add the following fact to the CryptoVerif input:

1 × . . . × T (cid:48)
1, . . . , b(cid:48)

1, . . . , b(cid:48)

forall x1 : T1, . . . , xn : Tn, x(cid:48)

f (x1, . . . , xn) (cid:54)= f(cid:48)(x(cid:48)

1 : T (cid:48)
1, . . . , x(cid:48)
1, . . . , x(cid:48)
m).

m : T (cid:48)
m;

Currently we make use of constant tags in the encoding
expressions to establish disjointness: if two encoding expres-
sions have diﬀerent constant ﬁelds at the same position, then
the encoders that they deﬁne are disjoint. We give details
in the extended version.

Parsing Equations The parsing equations that we com-
pute during the translation are made available to Cryp-
toVerif.

718Length-Regularity of Encoders By construction all the
encoders that we deﬁne are length-regular, that is, the length
of the encoding only depends on the length of the argu-
ments. This property is important to establish the secu-
rity of RPC-enc, where the client sends the encryption of
msg1 = conc1 (request1 , kS) and we need to prove that this
encryption does not leak any information about the key kS.
By security assumption the only information that the en-
cryption leaks is the length of the plaintext, therefore it is
important that the length of msg1 does not depend on the
value of kS.

When CryptoVerif applies the security deﬁnition of the
symmetric encryption,
it replaces the plaintext msg1 by
Zbitstring(msg1 ) where the intended meaning of Zbitstring is
to set all bits of the input to 0. Thus we need to give enough
facts to CryptoVerif so that it can rewrite Zbitstring(msg1 ) to
a value that does not depend on kS. This is done as follows:
for each encoder fc : T1×. . .×Tn → T we consider a function
ZT : T → T such that ZT (b) = 0|b| for every b ∈ Ik0 (T ) and
a function Zfc = ZT ◦ fc. By length-regularity of fc these
functions satisfy the following equation, which is given to
CryptoVerif:

forall x1 : T1, . . . , xn : Tn;

ZT (fc(x1, . . . , xn)) = Zfc (ZT1 (x1), . . . , ZTn (xn)).

In the case of RPC-enc we add the equation

forall x1 : bitstring, x2 : bitstring;

Zbitstring(conc1 (x1, x2))

= Zconc1 (Zbitstring(x1), Zbitstring(x2)).

To verify RPC-enc we also require that all honestly gener-
ated keys have the same length. This assumption must be
added manually to the model:

const Zkey : bitstring.
forall x : keyseed; Zbitstring(kgen(x))) = Zkey .

Injectivity The encoders that have been determined to be
injective are marked as such by adding [compos] to their
CryptoVerif deﬁnition.

4. SOUNDNESS RESULTS

This section presents our results regarding the soundness
of our approach. Theorem 1 states the main theoretical re-
sult of the present work: the translation from IML to Cryp-
toVerif described in Section 3 preserves insecurity. Theo-
rem 2 reviews the result from our previous work [5] stating
that our method for extracting IML models from C also pre-
serves insecurity. Together these theorems allow us to use
CryptoVerif to provide security guarantees for C code as de-
scribed in Section 1. Formal statements and proofs for these
theorems are contained in the extended version of the paper.
IML to CryptoVerif Translation Soundness In our work
we concentrate on proving trace properties of protocols. A
trace property is a preﬁx-closed set of sequences of events
ev (b1, . . . , bn), where ev is an event label and b1, . . . , bn are
bitstrings. A typical trace property would be the authentica-
tion property described in Section 3. Given a trace property
ρ we are interested in the probability that the sequence of
events raised during a protocol execution does not belong to
ρ. We shall call this probability the insecurity of a protocol.
The IML semantics and the CryptoVerif semantics nat-
urally give rise to two diﬀerent insecurity deﬁnitions. The

purpose of the soundness theorem below is to relate these
two deﬁnitions. Both semantics describe a probabilistic la-
belled transition system generated by a process, with events
as labels. An important diﬀerence between the two seman-
tics, in addition to the diﬀerences outlined in Section 2 is
that in IML semantics the attacker is an external entity (a
probabilistic machine) that interacts with the protocol tran-
sition system, and in CryptoVerif semantics the attacker is
a part of the process. In IML we deﬁne insecurity as follows:
given an IML process Q, an attacker E and a trace property
ρ we let insec(Q, E, ρ) be the probability that the sequence
of events generated by Q interacting with E does not belong
to ρ.

CryptoVerif uses an evaluation context (a process with a
hole) to model the attacker, so that for a given protocol
process Q and a context C we study the transition system
generated by C[Q]. In addition to the protocol process Q
CryptoVerif takes as input a set of facts Φ that describe
the interpretation ˜I of the function symbols used by the
process. For a CryptoVerif process Q, a set of facts Φ, a
trace property ρ, and a security parameter k let

(cid:110)

(cid:12)(cid:12)(cid:12) ˜Ik |= Φ

(cid:111)

(cid:48)

(Q, ˜Ik, ρ, k)

cvinsec

cvinsec(Q, Φ, ρ, k) = sup
,
where cvinsec(cid:48)(Q, ˜Ik, ρ, k) is the probability that the sequence
of events generated by Q with respect to CryptoVerif se-
mantics for security parameter k and with interpretation of
function symbols given by ˜Ik does not belong to ρ. Given
a process Q and a set of facts Φ CryptoVerif checks that Q
and Φ satisfy the property ρ, that is, cvinsec(C[Q], Φ, ρ, k)
is negligible in k for any evaluation context C.

Given an IML process Q the translation described in Sec-
tion 3 generates a CryptoVerif process ˜Q and a set of facts
Φ. The soundness of this translation is captured by the fol-
lowing theorem:

Theorem 1 (CryptoVerif Translation is Sound) Let
Q be an IML process that successfully translates to a Cryp-
toVerif process ˜Q and a set of facts Φ. Then for any at-
tacker E there exists an evaluation context C whose run-
time is polynomial in the runtime of E such that for any
correspondence property ρ

insec(Q, E, ρ) ≤ cvinsec(C[ ˜Q], Φ, ρ, k0).

2

CryptoVerif checks that ˜Q satisﬁes the correspondence ρ,
that is, cvinsec(C[ ˜Q], ρ, k) is negligible in k for any evalua-
tion context C. Theorem 1 implies that Q is a secure real-
isation of ˜Q with respect to the property ρ for a particular
security parameter k0. In fact, CryptoVerif can provide ex-
plicit bounds on cvinsec(C[ ˜Q], ρ, k) with respect to k, which
allows us to give an explicit bound on insec(Q, E, ρ, t).
Symbolic Execution Soundness In [5] we introduced a
simple low-level instruction language CVM to which we com-
pile C using the CIL framework [45]. The semantics of CVM
is given using the same formalism as for IML, which allows
us to combine both languages in the same execution. For
instance, CVM processes P1, . . . , Pn can be subprocesses of
an IML process PE with n holes, forming a mixed process
PE[P1, . . . , Pn]. This allows us to write protocol partici-
pants in C, and then specify their intended execution envi-
ronments, including long-term shared key infrastructure and
corruption models, in IML. The semantics and the insecu-
rity measure are deﬁned in such a way as to include mixed
processes.

719In [5], we developed a symbolic execution algorithm that,
if successful, extracts an IML model from a CVM process.
Even though IML deﬁned in this paper is slightly diﬀerent,
it is straightforward to adapt the soundness theorem from
[5] to our new setting:

Theorem 2 (Symbolic Execution is Sound) If P1, . . . ,
Pn are CVM processes and ˜P1, . . . , ˜Pn are IML processes
resulting from their symbolic execution then for any IML
process PE, attacker E, and trace property ρ the following
holds:
insec(PE[P1, . . . , Pn], E, ρ) ≤ insec(PE[ ˜P1, . . . , ˜Pn], E, ρ).2

Unlike [5] we do not use the parameter that bounds the
number of execution steps. The reason is that the execu-
tion time of both IML and CVM processes is polynomially
bounded—CVM processes are linear and do not include any
looping, and IML processes have polynomial bounds on the
number of replications.
In [5] replication was unbounded,
and so we needed to force a bound on the runtime in the
security deﬁnition.

In a nutshell, the signiﬁcance of our soundness theorems
is as follows: let P1, . . . , Pn be implementations of protocol
participants in CVM and let PE be an IML process that de-
scribes an execution environment. Assume that P1, . . . , Pn
are successfully symbolically executed with resulting models
˜P1, . . . , ˜Pn, and the IML process PE[ ˜P1, . . . , ˜Pn] is success-
fully translated to a CryptoVerif process Q that satisﬁes a
trace property ρ, as checked by CryptoVerif. Then we know
that Q is a protocol model that is (asymptotically) secure
with respect to ρ. By Theorems 1 and 2 we know that
P1, . . . , Pn form a secure implementation of the protocol de-
scribed by Q for the security parameter k0.

Furthermore, even though [18] only mentions asymptotic
security, CryptoVerif provides explicit bounds on the inse-
curity of the protocol. This can be used to give concrete
bounds on insecurity of the original C protocol implementa-
tion.

5.

IMPLEMENTATION & EXPERIMENTS
We have implemented our approach by reusing the sym-
bolic execution stage from the implementation in [5] (4600
lines of OCaml code) and adding to it an implementation of
the translation described in this paper (about 700 lines of
OCaml code).

Fig. 9 shows a list of protocol implementations from the
Csec Challenge repository (presented in [4]) on which we
tested our method. We list some statistics regarding the
sizes of the diﬀerent stages of the translation: the size of the
original C code, the number of generated CVM instructions,
the number of lines in the extracted IML model, the number
of lines in the CryptoVerif template to be provided by the
user (containing the environment process and cryptographic
assumptions), and the size of the CryptoVerif input, which
consists of the user template and the automatically gener-
ated model. We also show execution times (with runtimes of
the symbolic execution and CryptoVerif combined) and the
list of used cryptographic primitives/assumptions for each
protocol.

Simple MAC is an implementation of the example protocol
from [5], in which a single payload is concatenated with its
MAC. We successfully verify the authenticity of the payload.

Simple XOR is the one-time pad example from Fig. 1.
CryptoVerif proves strong secrecy of the payload. As our
soundness results apply to trace properties only, we can
claim weak secrecy of the payload in the C implementation.
The NSL example is our implementation of the Needham-
Schroeder-Lowe protocol. The work reported in [5] obtained
a computational veriﬁcation result using the soundness the-
orem from [7]. The theorem assumes that all cryptographic
material is tagged, and in particular that nonces should be
tagged. In the work we present here, we removed this as-
sumption which led to the discovery of a potential ﬂaw: if
the 3rd message (B’s nonce) is sent out without any tag-
ging, it can be decrypted and parsed as the ﬁrst message
of the protocol (an encoding of the concatenation of A’s
nonce and A’s identity). The failure of the parsing may
reveal information about the nonce to the attacker. Once
we ﬁxed the problem by explicitly tagging the 3rd message,
CryptoVerif successfully veriﬁed the protocol. This high-
lights that computational soundness results are not suitable
for verifying existing protocol implementations because they
assume conditions that are rarely enforced in practice.

RPC is an implementation due to Fran¸cois Dupressoir of
the MAC-based remote procedure call protocol described in
[11]. We veriﬁed the authenticity of the client request and
the server response, this time with computational guaran-
tees.

RPC-enc is the version of the remote procedure call pro-
tocol that uses authenticated encryption, described in detail
in Section 3. We veriﬁed the authenticity of the request
and the response, and the secrecy of the payloads (which is
not protected by the MAC-based RPC). The extended ver-
sion of the paper contains our full CryptoVerif model of this
protocol.

The metering example is an implementation of a privacy-
friendly protocol for smart electricity meters [48] developed
at Microsoft Research. In the work reported in [5], an IML
model of the protocol was extracted which revealed several
bugs, but there was no veriﬁcation result because the pro-
tocol uses XOR and Diﬃe-Hellman commitments. In this
work, we close the gap and provide the veriﬁcation result for
the metering protocol, showing both authentication (when-
ever the consumer accepts a reading, it does indeed origi-
nate from the meter) and the strong secrecy of the readings,
which implies at least weak secrecy for the C implementa-
tion. The protocol implementation works with an arbitrary
number of messages, that are all batched and signed to-
gether. Neither our symbolic execution nor CryptoVerif can
deal with loops, so we unroll the main loop of the protocol
and only analyse it for a ﬁxed number of messages. The ta-
ble of results contains numbers for the veriﬁcation with one
and three messages.

When trying to verify the protocol for more than one
message, we uncovered a potential security ﬂaw that led
to a ﬁx in the code. Given two readings r1 and r2, the
protocol would generate commitments C1 and C2 by using
calls to bignum operations of the OpenSSL crypto library.
It would then concatenate the commitments without using
their lengths as “tag”|C1|C2 (with some extra constant ﬁelds
which we omit for simplicity). As bignums in OpenSSL can
have arbitrary length, this could lead to a collision where
two diﬀerent bignums C(cid:48)
2 form the same string and
lead to the same signature.

1 and C(cid:48)

In summary, we were able to verify six protocols in the

720Simple MAC
Simple XOR
NSL
RPC
RPC-enc
Metering(1)
Metering(3)

—

C LOC CVM Instructions IML LOC Template LOC CV LOC
∼ 250
∼ 100
∼ 450
∼ 600
∼ 700
∼ 1000

7K
3K
25K
44K
19K
69K
96K

54
51
156
58
135
181
181

27
6
83
48
60
58
98

Outcome

Time

Primitives

107
90
241
126
200
266
280

veriﬁed
veriﬁed

ﬂaw, veriﬁed

veriﬁed
veriﬁed

ﬂaw, veriﬁed

as above

UF-CMA MAC

XOR

4s
4s
26s
5s
6s
21s UF-CMA sig, CR/PRF hash
41s

IND-CCA2 PKE
UF-CMA MAC

IND-CPA INT-CTXT AE

XOR, DH

Figure 9: Summary of analysed implementations.

computational model (as opposed to only one specially de-
signed implementation in previous work). The veriﬁcation
has also become much easier, as one does not need to look for
a computational soundness result each time one deals with a
new set of primitives, and to prove that the new soundness
result is compatible with our security deﬁnitions.
6. RELATED WORK

We describe the most closely related work. A more de-
tailed discussion of further related work (including [32, 33,
49]) can be found in [4]; for recent surveys of related work
in higher-level languages, see [29] and [38].

The most closely related works include [36, 23, 24, 27,
22]. Csur [36] is one of the ﬁrst attempts at cryptographic
veriﬁcation of C code. Here a C program is used to generate
a set of Horn clauses, which are then solved using a theorem
prover. ASPIER [23] applies software model checking to
verify properties of bounded instances of the handshake of
OpenSSL, within the symbolic model. ASPIER handled a
codebase of 2400 LOC consisting of the client side and the
server side of the handshake; to the best of our knowledge,
this was previously the largest codebase of cryptographic
software in C to be veriﬁed with a single tool. [24] presents
an approach based on the KLEE test-generation tool [21]
to verify cryptographic protocol implementations. Testing
for trace properties is not supported (as documented in the
paper). KLEE is based on symbolic execution similar to our
work, however, [24] only supports buﬀers of ﬁxed length.
[27] uses a general-purpose veriﬁer for security veriﬁcation
of C code. In comparison to the work presented here, this
approach requires the code to be annotated (about one line
of annotation per line of code) and performs veriﬁcation only
in the symbolic model. [22] nicely complements our work, by
showing how to start from a veriﬁed CryptoVerif model and
to transform to executable protocol code in OCaml. The
transformation is illustrated on the SSH Transport Layer
Protocol.

We successfully verify over 3000 LOC, more than any prior
work on cryptographic code in C. On the other hand, the
tools mentioned above (CSur, ASPIER, KLEE, VCC, and
the CryptoVerif to OCaml compiler) have the advantage
that they are not limited to single execution paths.

In recent work,

[46] develop a stepwise reﬁnement ap-

proach to verifying invariants of security code using VCC.

There is also related work on veriﬁcation of crypto-protocol
implementations in functional languages such as F# wrt. a
symbolic or computational model. [15] presents implementa-
tions of cryptographic protocols veriﬁed against a symbolic
security model using the tool fs2pv. [13] presents a veriﬁca-
tion of a small functional implementation of the Transport
Layer Security protocol (TLS 1.0) using automated compu-
tational cryptographic veriﬁcation with the fs2cv tool that
translates F# to CryptoVerif. [8] presents an approach for

security protocol veriﬁcation on the source code level in a
computationally sound way at the hand of F# implemen-
tations. The diﬀerence to our work lies in the complexity
of C code compared to code in functional programming lan-
guages, e.g. memory and pointers. We manage this com-
plexity in so far as our extracted models are much shorter
and simpler than the original C.

This work also has to be seen within the context of other
applications of the fs2cv tool, including work on computa-
tionally sound mechanized proofs for basic and public-key
Kerberos [20], as well as other work on computational sound-
ness for formal security veriﬁcation of crypto-protocols, such
as [2, 37, 1, 43, 25]. General-purpose veriﬁers have also been
applied to the related problem of verifying the code of cryp-
tographic algorithms [9]. [42] considers the problem of estab-
lishing computational indistinguishability for Java-like pro-
grams that use cryptography. It proposes an approach that
combines techniques from program analysis and simulation-
based security. The approach is orthogonal to ours in that
it considers observation equivalence, but not trace proper-
ties. Since the paper does not report on large examples, we
cannot compare scalability aspects with our approach.
7. CONCLUSION

To summarize, we adapted our existing symbolic execu-
tion tool to generate models for CryptoVerif. Qualitatively,
we obtain much stronger security results, in the computa-
tional model, than in existing work—the security theorems
of [4] applied only to one example. Quantitatively, we verify
a larger codebase of cryptographic code in C than any prior
method. In a sense, we have repeated the experiment of us-
ing symbolic execution to extract veriﬁable models from C
code, and for a second time we ﬁnd that it scales eﬀectively.
In future, it would be valuable to further validate the scal-
ability and usability of the method. Our tools are available
online, and we are interested to work with protocol designers
who are developing new protocols, towards the vision of a
toolset to allow reference implementations to be developed
concurrently with protocol design and veriﬁcation.

The aim of our work is to verify a broad set of realistic
protocol implementations while preserving soundness. We
did not provide any formal completeness results, partly be-
cause no such results are known for CryptoVerif that we use
as part of our toolchain. Nevertheless, an informal outline
of the applicability of our method is useful, and we provide
such an outline in the extended version.
Acknowledgments. We are grateful to Bruno Blanchet for
his help with running CryptoVerif. George Danezis provided
access and advice regarding his metering code. Fran¸cois
Dupressoir commented on a draft. Anupam Datta provided
statistics on the codebase analysed by ASPIER. The work is
supported by the Microsoft Research PhD Scholarship. We
thank the anonymous referees for their helpful comments.

7218. REFERENCES
[1] M. Abadi, B. Blanchet, and H. Comon-Lundh. Models

and proofs of protocol security: A progress report. In
A. Bouajjani and O. Maler, editors, CAV, volume
5643 of Lecture Notes in Computer Science, pages
35–49. Springer, 2009.

[2] M. Abadi and P. Rogaway. Reconciling two views of

cryptography (the computational soundness of formal
encryption). J. Cryptology, 15(2):103–127, 2002.

[3] M. Abe and V. D. Gligor, editors. Proceedings of the

2008 ACM Symposium on Information, Computer and
Communications Security, ASIACCS 2008, Tokyo,
Japan, March 18-20, 2008. ACM, 2008.

[4] M. Aizatulin, F. Dupressoir, A. D. Gordon, and

J. J¨urjens. Verifying cryptographic code in C: Some
experience and the Csec challenge. In Formal Aspects
of Security and Trust (FAST 2011), Lecture Notes in
Computer Science. Springer, 2011.

[5] M. Aizatulin, A. D. Gordon, and J. J¨urjens.

Extracting and verifying cryptographic models from C
protocol code by symbolic execution. In 18th ACM
Conference on Computer and Communications
Security (CCS 2011), 2011. Full version available at
http://arxiv.org/abs/1107.1017.

[6] M. Aizatulin, A. D. Gordon, and J. J¨urjens.

Computational veriﬁcation of C protocol
implementations by symbolic execution. Technical
Report MSR–TR–2012–80, Microsoft Research, 2012.

[7] M. Backes, D. Hofheinz, and D. Unruh. CoSP: A

general framework for computational soundness
proofs. In ACM Conference on Computer and
Communications Security, pages 66–78, 2009. Preprint
on IACR ePrint 2009/080.

[8] M. Backes, M. Maﬀei, and D. Unruh. Computationally

sound veriﬁcation of source code. In CCS, 2010.

[9] M. Barbosa, J. Pinto, J. Filliˆatre, and B. Vieira. A

deductive veriﬁcation platform for cryptographic
software. In Proceedings of the Fourth International
Workshop on Foundations and Techniques for Open
Source Software Certiﬁcation (OpenCert 2010),
volume 33 of Electronic Communications of the
EASST. EASST, 2010.

[10] G. Barthe, B. Gr´egoire, S. Heraud, and S. Zanella

B´eguelin. Computer-aided security proofs for the
working cryptographer. In Advances in Cryptology –
CRYPTO 2011, Lecture Notes in Computer Science.
Springer, 2011.

[11] J. Bengtson, K. Bhargavan, C. Fournet, A. D.

Gordon, and S. Maﬀeis. Reﬁnement types for secure
implementations. In CSF ’08: Proceedings of the 2008
21st IEEE Computer Security Foundations
Symposium, pages 17–32. IEEE Computer Society,
2008.

[12] K. Bhargavan, R. Corin, C. Fournet, and E. Zalinescu.

Automated computational veriﬁcation for
cryptographic protocol implementations. Unpublished
draft, Oct. 2009.

[13] K. Bhargavan, C. Fournet, R. Corin, and E. Z˘alinescu.

Cryptographically veriﬁed implementations for TLS.
In CCS ’08: Proceedings of the 15th ACM conference
on Computer and communications security, pages
459–468, Alexandria, VA, Oct. 2008. ACM.

[14] K. Bhargavan, C. Fournet, and A. D. Gordon.

Modular veriﬁcation of security protocol code by
typing. In ACM Symposium on Principles of
Programming Languages (POPL’10), pages 445–456,
2010.

[15] K. Bhargavan, C. Fournet, A. D. Gordon, and

N. Swamy. Veriﬁed implementations of the
information card federated identity-management
protocol. In Abe and Gligor [3], pages 123–135.

[16] K. Bhargavan, C. Fournet, A. D. Gordon, and S. Tse.

Veriﬁed interoperable implementations of security
protocols. In CSFW ’06: Proceedings of the 19th IEEE
workshop on Computer Security Foundations, pages
139–152. IEEE Computer Society, 2006.

[17] B. Blanchet. An eﬃcient cryptographic protocol

veriﬁer based on prolog rules. In CSFW, pages 82–96.
IEEE Computer Society, 2001.

[18] B. Blanchet. Computationally sound mechanized
proofs of correspondence assertions. In 20th IEEE
Computer Security Foundations Symposium (CSF’07),
pages 97–111, Venice, Italy, July 2007. IEEE.

[19] B. Blanchet. A computationally sound mechanized

prover for security protocols. IEEE Transactions on
Dependable and Secure Computing, 5(4):193–207,
Oct.–Dec. 2008.

[20] B. Blanchet, A. D. Jaggard, A. Scedrov, and J.-K.

Tsay. Computationally sound mechanized proofs for
basic and public-key kerberos. In Abe and Gligor [3],
pages 87–99.

[21] C. Cadar, D. Dunbar, and D. Engler. KLEE:

Unassisted and automatic generation of high-coverage
tests for complex systems programs. In USENIX
Symposium on Operating Systems Design and
Implementation (OSDI 2008), San Diego, CA, Dec.
2008.

[22] D. Cad´e and B. Blanchet. From

computationally-proved protocol speciﬁcations to
implementations. In International Conference on
Availability, Reliability and Security (ARES 2012),
2012.

[23] S. Chaki and A. Datta. ASPIER: An automated

framework for verifying security protocol
implementations. In Computer Security Foundations
Workshop, pages 172–185, 2009.

[24] R. Corin and F. A. Manzano. Eﬃcient symbolic

execution for analysing cryptographic protocol
implementations. In International Symposium on
Engineering Secure Software and Systems
(ESSOS’11), LNCS. Springer, 2011.

[25] V. Cortier, S. Kremer, and B. Warinschi. A survey of

symbolic methods in computational analysis of
cryptographic systems. J. Autom. Reasoning,
46(3-4):225–259, 2011.

[26] D. Dolev and A. Yao. On the Security of Public-Key

Protocols. IEEE Transactions on Information Theory,
29(2):198–208, 1983.

[27] F. Dupressoir, A. D. Gordon, J. J¨urjens, and D. A.
Naumann. Guiding a general-purpose C veriﬁer to
prove cryptographic protocols. In 24th IEEE
Computer Security Foundations Symposium, 2011.

[28] B. Dutertre and L. D. Moura. The Yices SMT Solver.

722Technical report, Computer Science Laboratory, SRI
International, 2006.

[40] J. C. King. Symbolic execution and program testing.

Commun. ACM, 19(7):385–394, 1976.

[29] C. Fournet, K. Bhargavan, and A. D. Gordon.

[41] R. K¨usters and T. Truderung. Reducing protocol

Cryptographic veriﬁcation by typing for a sample
protocol implementation. In Foundations of Security
and Design VI (FOSAD 2010), Lecture Notes in
Computer Science. Springer, 2011. To appear.

[30] C. Fournet, M. Kohlweiss, and P.-Y. Strub. Modular
code-based cryptographic veriﬁcation. In 18th ACM
Conference on Computer and Communications
Security (CCS 2011), 2011.

[31] http://frama-c.cea.fr/, 2009.
[32] P. Godefroid and S. Khurshid. Exploring very large
state spaces using genetic algorithms. In Tools and
Algorithms for Construction and Analysis of Systems
(TACAS’02), volume 2280, pages 266–280. Springer,
2002.

[33] P. Godefroid, N. Klarlund, and K. Sen. DART:

directed automated random testing. In Programming
Language Design and Implementation (PLDI’05),
pages 213–223. ACM, 2005.

[34] S. Goldwasser and S. Micali. Probabilistic encryption.

Journal of Computer and System Science,
28(2):270–299, 1984.

[35] A. D. Gordon. Provable implementations of security

protocols. In LICS, pages 345–346, 2006.

[36] J. Goubault-Larrecq and F. Parrennes. Cryptographic
protocol analysis on real C code. In Proceedings of the
6th International Conference on Veriﬁcation, Model
Checking and Abstract Interpretation (VMCAI’05),
volume 3385 of Lecture Notes in Computer Science,
pages 363–379. Springer, 2005.

[37] P. Gupta and V. Shmatikov. Towards computationally
sound symbolic analysis of key exchange protocols. In
V. Atluri, P. Samarati, R. K¨usters, and J. C. Mitchell,
editors, FMSE, pages 23–32. ACM, 2005.

[38] C. Hri¸tcu. Union, Intersection, and Reﬁnement Types

and Reasoning About Type Disjointness for Security
Protocol Analysis. PhD thesis, Department of
Computer Science, Saarland University, 2011.

[39] A. Jeﬀrey and R. Ley-Wild. Dynamic model checking

of C cryptographic protocol implementations. In
Proceedings of Workshop on Foundations of Computer
Security and Automated Reasoning for Security
Protocol Analysis, 2006.

analysis with XOR to the XOR-free case in the horn
theory based approach. Journal of Automated
Reasoning, 46(3):325–352, 2011.

[42] R. K¨usters, T. Truderung, and J. Graf. A Framework

for the Cryptographic Veriﬁcation of Java-like
Programs. In IEEE Computer Security Foundations
Symposium, CSF 2012. IEEE Computer Society, 2012.

[43] R. K¨usters and M. Tuengerthal. Computational

soundness for key exchange protocols with symmetric
encryption. In E. Al-Shaer, S. Jha, and A. D.
Keromytis, editors, ACM Conference on Computer
and Communications Security, pages 91–100. ACM,
2009.

[44] P. Lincoln, J. C. Mitchell, M. Mitchell, and

A. Scedrov. Probabilistic polynomial-time equivalence
and security analysis. In J. M. Wing, J. Woodcock,
and J. Davies, editors, World Congress on Formal
Methods, volume 1708 of Lecture Notes in Computer
Science, pages 776–793. Springer, 1999.

[45] G. C. Necula, S. McPeak, S. P. Rahul, and

W. Weimer. CIL: Intermediate Language and Tools
for Analysis and Transformation of C Programs. In
Proceedings of the 11th International Conference on
Compiler Construction, CC ’02, pages 213–228,
London, UK, 2002. Springer-Verlag.

[46] N. Polikarpova and M. Moskal. Verifying

implementations of security protocols by reﬁnement.
In Veriﬁed Software: Theories, Tools and Experiments
(VSTTE 2012), volume 7152 of Lecture Notes in
Computer Science, pages 50–65. Springer, 2012.

[47] Project EVA. Security protocols open repository,

2007. http://www.lsv.ens-cachan.fr/spore/.
[48] A. Rial and G. Danezis. Privacy-friendly smart

metering. Technical Report MSR–TR–2010–150,
Microsoft Research, 2010.

[49] O. Udrea, C. Lumezanu, and J. S. Foster. Rule-Based

static analysis of network protocol implementations.
IN PROCEEDINGS OF THE 15TH USENIX
SECURITY SYMPOSIUM, pages 193–208, 2006.

[50] D. Unruh. The impossibility of computationally sound

XOR, July 2010. Preprint on IACR ePrint 2010/389.

723