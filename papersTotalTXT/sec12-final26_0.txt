Taking proof-based veriﬁed computation a few steps closer to practicality

Srinath Setty, Victor Vu, Nikhil Panpalia, Benjamin Braun, Andrew J. Blumberg, and Michael Walﬁsh

The University of Texas at Austin

Abstract. We describe GINGER, a built system for un-
conditional, general-purpose, and nearly practical veriﬁ-
cation of outsourced computation. GINGER is based on
PEPPER, which uses the PCP theorem and cryptographic
techniques to implement an efﬁcient argument system (a
kind of interactive protocol). GINGER slashes the query
size and costs via theoretical reﬁnements that are of in-
dependent interest; broadens the computational model
to include (primitive) ﬂoating-point fractions, inequality
comparisons, logical operations, and conditional control
ﬂow; and includes a parallel GPU-based implementation
that dramatically reduces latency.
1
We are motivated by outsourced computing: cloud com-
puting (in which clients outsource computations to re-
mote computers), peer-to-peer computing (in which
peers outsource storage and computation to each other),
volunteer computing (in which projects outsource com-
putations to volunteers’ desktops), etc.

Introduction

Our goal is to build a system that lets a client outsource
computation veriﬁably. The client should be able to send
a description of a computation and the input to a server,
and receive back the result together with some auxiliary
information that lets the client verify that the result is cor-
rect. For this to be sensible, the veriﬁcation must be faster
than executing the computation locally.

Ideally, we would like such a system to be uncondi-
tional, general-purpose, and practical. That is, we don’t
want to make assumptions about the server (trusted hard-
ware, independent failures of replicas, etc.), we want a
setup that works for a broad range of computations, and
we want the system to be usable by real people for real
computations in the near future.

the ﬁrst

In principle,

two properties above have
been achievable for almost thirty years, using powerful
tools from complexity theory and cryptography. Interac-
tive proofs (IPs) and probabilistically checkable proofs
(PCPs) show how one entity (usually called the veri-
ﬁer) can be convinced by another (usually called the
prover) of a given mathematical assertion—without the
veriﬁer having to fully inspect a proof [5, 6, 19, 32]. In
our context, the mathematical assertion is that a given
computation was carried out correctly; though the proof
is as long as the computation, the theory implies—
surprisingly—that
the
proof in a small number of randomly-chosen locations
or query the prover a relatively small number of times.

the veriﬁer need only inspect

The rub has been the third property: practicality. These
protocols have required expensive encoding of compu-

tations, monstrously large proofs, high error bounds,
prohibitive overhead for the prover, and intricate con-
structions that make the asymptotically efﬁcient schemes
challenging to implement correctly.

However, a line of recent work indicates that ap-
proaches based on IPs and PCPs are closer to practicality
than previously thought [21, 44, 45, 49]. More generally,
there has been a groundswell of work that aims for poten-
tially practical veriﬁable outsourced computation, using
theoretical tools [11, 12, 20, 24, 25].

Nonetheless, these works have notable limitations.
Only a handful [21, 44, 45, 49] have produced work-
ing implementations, all of which impose high costs on
the veriﬁer and prover. Moreover, their model of com-
putation is arithmetic circuits over ﬁnite ﬁelds, which
represent non-integers awkwardly, control ﬂow inefﬁ-
ciently, and comparisons and logical operations only by
degenerating to verbose Boolean circuits. Arithmetic cir-
cuits are well-suited to integer computations and numeri-
cal straight line computations (e.g., multiplying matrices
and computing second moments), but the intersection of
these two domains leaves few realistic applications.

This paper describes a built system, called GINGER,
that addresses these problems, thereby taking general-
purpose proof-based veriﬁed computation several steps
closer to practicality. GINGER is an efﬁcient argument
system [37, 38]: an interactive proof system that assumes
the prover to be computationally bounded. Its starting
point is the PEPPER protocol [45] (which is summarized
in Section 2). GINGER’s contributions are as follows.

(1) GINGER demonstrates the strength of linear com-
mitment (§3). This paper proves that PEPPER’s com-
mitment primitive [45], which generalizes the commit-
ment primitive of Ishai et al. [35], is surprisingly pow-
erful: it not only commits an untrusted entity to a func-
tion and extracts evaluations of that function (as previ-
ously shown) but also ensures that the function is linear.
(The primitive embeds a strong linearity test.) This re-
sult sharply reduces the required number of queries (from
500 to 3) and a key error bound, and hence overhead.

(2) GINGER supports a general-purpose programming
model (§4). Although the model does not handle looping
concisely, it includes primitive ﬂoating-point quantities,
inequality comparisons, logical expressions, and condi-
tional control ﬂow. Moreover, we have a compiler (de-
rived from Fairplay [39]) that transforms computations
expressed in a general-purpose language to an executable
veriﬁer and prover. The core technical challenge is rep-
resenting computations as additions and multiplications
over a ﬁnite ﬁeld (as required by the veriﬁcation proto-

1

col); for instance, “not equal” and “if/else” do not obvi-
ously map to this formalism, inequalities are problematic
because ﬁnite ﬁelds are not ordered, and fractions com-
pound the difﬁculties. GINGER overcomes these chal-
lenges with techniques that, while not deep, require care
and detail.1 These techniques should apply to other pro-
tocols that use arithmetic constraints or circuits.

(3) GINGER exploits parallelism to slash latency (§5).
The prover can be distributed across machines, and some
of its functions are implemented in graphics hardware
(GPUs). Moreover, GINGER’s veriﬁer can use a GPU
for its cryptographic operations. Allowing the veriﬁer to
have a GPU models the present (many computers have
GPUs) and a plausible future in which specialized hard-
ware for cryptographic operations is common.2

We have implemented and evaluated GINGER (§6).
Compared to PEPPER [45], its base, GINGER lowers net-
work costs by 1–2 orders of magnitude (to hundreds
of KB or less in our experiments). The veriﬁer’s costs
drop by multiples and possibly orders of magnitude, de-
pending on the cost of encryption; if we model encryp-
tion as free, the veriﬁer can gain from outsourcing when
batch-verifying as few as 20 computations (down from
3900 in PEPPER). The prover’s CPU costs drop by 10–
15%, which is not much, but our parallel implementa-
tion reduces latency with near-linear speedup. Comput-
ing with rational numbers in GINGER is roughly three
times more expensive than computing with integers, and
arithmetic constraints permit far smaller representations
than a naive use of Boolean or arithmetic circuits.

Despite all of the above, GINGER is not quite ready
for the big leagues. However, PEPPER and GINGER have
made argument systems far more practical (in some cases
improving costs by 23 orders of magnitude over a naive
implementation). We are thus optimistic about ultimately
achieving true practicality.
2 Problem statement and background
Problem statement. A computer V, known as the veri-
ﬁer, has a computation Ψ and some desired input x that
it wants a computer P, known as the prover, to perform.
P returns y, the purported output of the computation, and
then V and P conduct an efﬁcient interaction. This in-
teraction should be cheaper for V than locally comput-
ing Ψ(x). Furthermore, if P returned the correct answer,
it should be able to convince V of that fact; otherwise,
V should be able to reject the answer as incorrect, with
high probability. (The converse will not hold: rejection
does not imply that P returned incorrect output, only that

1We elide some of these details for space; they are documented in a
longer version of this paper [46].
2One may wonder why, if the veriﬁer has this hardware, it needs to
outsource. GPUs are amenable only to certain computations (which
include the cryptographic underpinnings of GINGER).

2

it misbehaved somehow.) Our goal is that this guarantee
be unconditional: it should hold regardless of whether
P obeys the protocol (given standard cryptographic as-
sumptions about P’s computational power). If P deviates
from the protocol at any point (computing incorrectly,
proving incorrectly, etc.), we call it malicious.

2.1 Tools
In principle, we can meet our goal using PCPs. The PCP
theorem [5, 6] says that if a set of constraints is satisﬁ-
able (see below), there exists a probabilistically check-
able proof (a PCP) and a veriﬁcation procedure that ac-
cepts the proof after querying it in only a small number
of locations. On the other hand, if the constraints cannot
be satisﬁed, then the veriﬁcation procedure rejects any
purported proof, with probability at least 1 − .

To apply the theorem, we represent the computation
as a set of quadratic constraints over a ﬁnite ﬁeld. A
quadratic constraint is an equation of degree 2 that uses
additions and multiplications (e.g., A·Z1 +Z2−Z3·Z4 =
0). A set of constraints is satisﬁable if the variables can
be set to make all of the equations hold simultaneously;
such an assignment is called a satisfying assignment. In
our context, a set of constraints C will have a designated
input variable X and output variable Y (this generalizes
to multiple inputs and outputs), and C(X = x, Y = y)
denotes C with variable X bound to x and Y bound to y.
We say that a set of constraints C is equivalent to a
desired computation Ψ if: for all x, y, C(X = x, Y = y) is
satisﬁable if and only if y = Ψ(x). As a simple example,
increment-by-1 is equivalent to the constraint set {Y =
Z + 1, Z = X}. (For convenience, we will sometimes
refer to a given input x and purported output y implicitly
in statements such as, “If constraints C are satisﬁable,
then Ψ executed correctly”.) To verify a computation y =
Ψ(x), one could in principle apply the PCP theorem to
the constraints C(X = x, Y = y).

Unfortunately, PCPs are too large to be transferred.
However, if we assume a computational bound on the
prover P, then efﬁcient arguments apply [37, 38]: V is-
sues its PCP queries to P (so V need not receive the entire
PCP). For this to work, P must commit to the PCP be-
fore seeing V’s queries, thereby simulating a ﬁxed proof
whose contents are independent of the queries. V thus ex-
tracts a cryptographic commitment to the PCP (e.g., with
a collision-resistant hash tree [40]) and veriﬁes that P’s
query responses are consistent with the commitment.

This approach can be taken a step further: not even
P has to materialize the entire PCP. As Ishai et al. [35]
observe, in some PCP constructions, which they call lin-
ear PCPs, the PCP itself is a linear function: the veriﬁer
submits queries to the function, and the function’s out-
puts serve as the PCP responses. Ishai et al. thus design
a linear commitment primitive in which P can commit to

a linear function (the PCP) and V can submit function
inputs (the PCP queries) to P, getting back outputs (the
PCP responses) as if P itself were a ﬁxed function.

PEPPER [45] reﬁnes and implements the outline
above. In the rest of the section, we summarize the lin-
ear PCPs that PEPPER incorporates, give an overview of
PEPPER, and provide formal deﬁnitions. Additional de-
tails are in Appendix A.1.
2.2 Linear PCPs, applied to verifying computations
Imagine that V has a desired computation Ψ and desired
input x, and somehow obtains purported output y. To use
PCP machinery to check whether y = Ψ(x), V compiles
Ψ into equivalent constraints C, and then asks whether
C(X = x, Y = y) is satisﬁable, by consulting an oracle
π: a ﬁxed function (that depends on C, x, y) that V can
query. A correct oracle π is the proof (or PCP); V should
accept a correct oracle and reject an incorrect one.

A correct oracle π has three properties. First, π is a
linear function, meaning that π(a) + π(b) = π(a +b) for
all a, b in the domain of π. A linear function π : Fn → F
is determined by a vector w; i.e., π(a) = (cid:104)a, w(cid:105) for all
a ∈ Fn. Here, F is a ﬁnite ﬁeld, and (cid:104)a, b(cid:105) denotes the
inner (dot) product of two vectors a and b. The parameter
n is the size of w; in general, n is quadratic in the number
of variables in C [5], but we can sometimes tailor the
encoding of w to make n smaller [45].

Second, one set of the entries in w must be a redundant
encoding of the other entries. Third, w encodes the actual
satisfying assignment to C(X = x, Y = y).

A surprising aspect of PCPs is that each of these prop-
erties can be tested by making a small number of queries
to π; if π is constructed incorrectly, the probability that
the tests pass is upper-bounded by  > 0. A key test for
us—we return to it in Section 3—is the linearity test [16]:
V randomly selects q1 and q2 from Fn and checks if
π(q1) + π(q2) = π(q1 + q2). The other two PCP tests
are the quadratic correction test and the circuit test.

The completeness and soundness properties of linear
PCPs are deﬁned in Section 2.4. A detailed explanation
of why the mechanics above satisfy those properties is
outside our scope but can be found in [5, 13, 35, 45].
2.3 Our base: PEPPER
We now walk through the three phases of PEPPER [45],
which is depicted in Figure 1. The approach is to com-
pose a linear PCP and a linear commitment primitive that
forces the prover to act like an oracle.
Specify and compute. V transforms its desired compu-
tation, Ψ, into a set of equivalent constraints, C. V sends
Ψ (or C) to P, or P may come with them installed.
To gain from outsourcing, V must amortize the costs of
compiling Ψ to C and generating queries. Thus, V veriﬁes
computations in batches [45] (although they need not be

Figure 1—The PEPPER protocol [45], which is GINGER’s base.
Though not depicted, many of the protocol steps happen in par-
allel, to facilitate batching.

executed in a batch). A batch (of size β) refers to a set of
computations in which Ψ is the same but the inputs are
different; a member of the batch is called an instance.
In the protocol, V has inputs x1, . . . , xβ that it sends to
P (not necessarily all at once), which returns y1, . . . , yβ;
for each instance i, yi is supposed to equal Ψ(xi).
For each instance i, an honest P stores a proof vector
wi that encodes a satisfying assignment to C(X = xi, Y =
yi); wi is constructed as described in Section 2.2. Being a
vector, wi can also be regarded as a linear function πi—or
an oracle of the kind described above.
Extract commitment. V cannot inspect {πi} directly
(they are functions; written out, they would have an en-
try for each value in a huge domain). Instead, V extracts a
commitment to each πi. To do so, V randomly generates a
commitment vector r ∈ Fn. V then homomorphically en-
crypts each entry of r under a public key pk to get a vector
Enc(pk, r) = (Enc(pk, r1), Enc(pk, r2), . . . , Enc(pk, rn)).
We emphasize that Enc(·) need not be fully homomor-
phic encryption [27] (which remains unfeasibly expen-
sive); PEPPER uses ElGamal [23, 45].
V sends (Enc(pk, r), pk) to P. If P is honest, then πi is
linear, so P can use the homomorphism of Enc(·) to com-
pute Enc(pk, πi(r)) from Enc(pk, r), without learning
r. P replies with (Enc(pk, π1(r)), . . . , Enc(pk, πβ(r))),
which is P’s commitment to {πi}. V then decrypts to get
(π1(r), . . . , πβ(r)).
Verify. V now generates PCP queries q1, . . . , qµ ∈ Fn,
as described in Section 2.2. V sends these queries to P,
j=1 αj·qj, where
each αj is randomly chosen from F (here, · represents
scalar multiplication).

along with a consistency query t = r+(cid:80)µ

For ease of exposition, we focus on a single proof πi;
however, the following steps happen β times in parallel,
using the same queries for each of the β instances. If P
is honest, it returns (πi(q1), . . . , πi(qµ), πi(t)). V checks
j=1 αj · πi(qj); this is known as

that πi(t) = πi(r) +(cid:80)µ

3

  xyEnc(r)y ←Ψ(x) q1, q2, ..., qµ, tprover (P) Enc(π(r))consistency testπ(q1), …, π(qµ), π(t)linear PCP verifierlinearity testπ(q1), …, π(qµ)q1, q2, ..., qµrπ(r)tπ(t)quad. testcircuit testverifier (V) πthe consistency test. If P is honest, then this test passes,
by the linearity of π. Conversely, if this test passes then,
regardless of P’s honesty, V can treat P’s responses as the
output of an oracle (this is shown in previous work [35,
45]). Thus, V can use {πi(q1), . . . , πi(qµ)} in the PCP
tests described in Section 2.2.

2.4 PCPs and arguments deﬁned more formally
The deﬁnitions of PCPs [5, 6] and argument systems [19,
32] below are borrowed from [35, 45].

A PCP protocol with soundness error  includes a
probabilistic polynomial time veriﬁer V that has access to
a constraint set C. V makes a constant number of queries
to an oracle π. This process has the following properties:
• PCP Completeness. If C is satisﬁable, then there ex-
ists a linear function π such that, after V queries π,
Pr{V accepts C as satisﬁable} = 1, where the proba-
bility is over V’s random choices.
If C is not

• PCP Soundness.
then
Pr{V accepts C as satisﬁable} <  for all purported
proof functions ˜π.

satisﬁable,

An argument (P, V) with soundness error  comprises P
and V, two probabilistic polynomial time (PPT) entities
that take a set of constraints C as input and provide:
• Argument Completeness. If C is satisﬁable and P has
access to a satisfying assignment z, then the interac-
tion of V(C) and P(C, z) makes V(C) accept C’s satis-
ﬁability, regardless of V’s random choices.
• Argument Soundness. If C is not satisﬁable, then for
every malicious PPT P∗, the probability over V’s ran-
dom choices that the interaction of V(C) and P∗(C)
makes V(C) accept C as satisﬁable is less than .

3 Protocol reﬁnements in GINGER
In principle, PEPPER solves the problem of veriﬁed com-
putation. The reality is less attractive: PEPPER’s com-
putational burden is high, its network costs are absurd,
and its applicability is limited (to straight line numeri-
cal computations). Our system, GINGER, mitigates these
issues: it lowers costs through protocol reﬁnements (pre-
sented in this section), and it applies to a much wider
class of computations (as we discuss in Section 4).

GINGER’s reﬁnements eliminate many queries, by re-
lying on a new analysis of the base commitment primi-
tive. To motivate this analysis, we note that there is some-
thing seemingly redundant in the base machinery (see
Figure 1): why does the linear PCP require a linearity
test (§2.2) if an honest prover depends on the linear-
ity of its function π to pass the linear commitment pro-
tocol’s consistency test (§2.3)? Can we remove one of
these tests, or combine them somehow? The reason that

4

PEPPER appears to need both tests is that their guarantees
are (so far) subtly different:

• Consistency test (§2.3): First, an honest prover is
guaranteed to pass this test. Second, if the prover—
even a cheating one—passes this test, then it is very
likely bound to some function (as shown in [35, 45]).
• Linearity test (§2.2): This test is needed in case the
prover cheats—it establishes that π is linear (as re-
quired by the rest of the PCP protocol). More accu-
rately, if π is far from being linear, the test is some-
what likely to catch that case.

Yet, it seems unsatisfying that both tests are required
when composing linear commitment and the linear PCP:
can a prover really pass the consistency test systemati-
cally with a function that the linearity test would reject?
In fact, our intuitive dissatisfaction is well-founded: this
paper proves that the commitment primitive (which in-
cludes the consistency test) is far stronger than the linear-
ity test. Put simply, even a cheating prover is very likely
bound to a function that is linear, or almost so.

Practically, this result saves query generation and re-
sponse costs. For one thing, we can eliminate linearity
tests from the protocol. More signiﬁcantly, we eliminate
ampliﬁcation: PEPPER needed to repeat the protocol to
turn the linearity test’s guarantee of “somewhat likely”
into “very likely”. In contrast, our result already gives a
guarantee of “very likely”, so no repetition is required.

More broadly, this result means that the commit-
ment primitive is considerably more powerful
than
was realized—it efﬁciently commits an untrusted en-
tity to a linear function and extracts evaluations of that
function—and may apply elsewhere.

Details. The protocol
reﬁnements are rooted in a
strengthened soundness analysis. Soundness error (for
example,  in Section 2.4) refers to the probability that
a protocol or test succeeds when the condition that it is
verifying or testing is actually false. The ideal is to have
a small upper-bound on soundness error.

The soundness of the PCP protocol in Section 2.2 and
Appendix A.1 is connected to the soundness of linearity
testing [16]. Speciﬁcally, the base analysis proves that if
the prover returns y (cid:54)= Ψ(x), then the prover survives all
tests (linearity, quadratic correction, circuit) with prob-
ability less than 7/9 (requiring ρ runs to make (7/9)ρ
small). The 7/9 derives from a result [8] that if the proof
oracle is not “somewhat close” to linear, then the linear-
ity test passes with probability < 7/9 (though fascinat-
ing, this result is inconveniently weak in our context).

Our analysis, detailed in Appendix A.2, establishes
that the commitment protocol binds the prover to a func-
tion that is extremely close to linear (otherwise, the
prover could break the semantic security of the homo-

PCP encoding size (n)
V’s per-instance CPU costs
Issue commit queries
Process commit responses
Issue PCP queries
Process PCP responses
P’s per-instance CPU costs
Issue commit responses
Issue PCP responses
Network cost (per instance)
PCP soundness error
Overall soundness error

PEPPER [45]
s2 + s, in general

GINGER
s2 + s, in general

(e + 2c) · n/β
d
ρ·(χ·f +(cid:96)(cid:48)·f +5c)·n/β
ρ · (2(cid:96)(cid:48) + |x| + |y|) · f

(e + 2c) · n/β
d
(χ·f + (cid:96)·f +2c)·n/β
(2(cid:96) + |x| + |y|) · f

h · n
(ρ · (cid:96)(cid:48) + 1) · f · n
((ρ·(cid:96)(cid:48)+1)·|p|+|ξ|)·n/β
(7/9)ρ = 2.3 · 10−8
2.4 · 10−8

h · n
((cid:96) + 1) · f · n
(((cid:96)+1)·|p|+|ξ|)·n/β
κ = 2.6 · 10−6
4.5 · 10−6

|x|,|y|: # of elements in input, output
n: # of components in linear function π (§2.2)
s: # of variables in constraint set (§2.1)
χ: # of constraints in constraint set (§2.1)
(cid:96) = 3: # of high-order PCP queries in
(cid:96)(cid:48) = 7: # of high-order PCP queries in

GINGER (§A.2, §A.3)

PEPPER (§A.1)

ρ = 70: # of PCP reps. in base scheme (§A.1)
β: batch size (# of instances) (§2.3)
e: cost of encrypting an element in F
d: cost of decrypting an encrypted element
f : cost of multiplying in F
h: cost of ciphertext add plus multiply
c: cost to generate 192-bit pseudorandom #
|p|: length of an element in F
|ξ|: length of an encrypted element in F

Figure 2—High-order costs and error in GINGER, compared to its base (PEPPER [45]), for a computation represented as χ constraints
over s variables (§2.1). The soundness error depends on ﬁeld size (Appendix A.2); the table assumes |F| = 2128. Many of the
cryptographic costs enter through the commitment protocol (see Section 2.3 or Figure 12); Section 6 quantiﬁes the parameters. The
“PCP” row include the consistency query and check. The network costs slightly underestimate by not including query responses.

morphic encryption used by GINGER and PEPPER). This
results in the PCP soundness error improving from 7/9

to κ, where κ ≈ 4 6(cid:112)1/|F|; this analysis does not depend

on linearity tests, so they can be dropped.

The soundness error is somewhat

low by crypto-
graphic standards, but in practice, a failure rate (when
the prover is malicious) of 1 in 200,000 is reasonable.
A further optimization. GINGER reuses some queries
across the quadratic correction and circuit tests; this re-
ﬁnement is detailed and justiﬁed in Appendix A.3.
Savings. Most signiﬁcantly, V can take advantage of the
lower soundness error to run ρ = 1 instead of ρ = 70
repetitions of the PCP protocol. Also, per repetition,
V’s work to generate pseudorandom queries decreases
by 3/5 (2/5 coming from the elimination of linearity
tests and 1/5 from reusing queries). These gains are de-
picted in Figure 2, most notably in the reduction from
ρ · (cid:96)(cid:48) ≈ 500 to (cid:96) = 3 total PCP queries.

The total savings for the veriﬁer depend on the relative
cost of pseudorandom number generation (encapsulated
by c) and encryption (encapsulated by e). These savings
show up in β∗, the minimum batch size (§2.3) at which
V gains from outsourcing. As shown in Section 6.1, the
reduction in β∗ can be several orders of magnitude (when
e is small). Finally, taking |p| = 128 bits and |ξ| = 2 ·
1024 bits, the savings in network costs are 1–2 orders of
magnitude (holding β constant).

4 Broadening the space of computations
GINGER extends to computations over ﬂoating-point
fractional quantities and to a restricted general-purpose
programming model that includes inequality tests, log-

ical expressions, conditional branching, etc. To do so,
GINGER maps computations to the constraint-over-ﬁnite-
ﬁeld formalism (§2.1), and thus the core protocol in Sec-
tion 3 applies. In fact, our techniques3 apply to the many
protocols that use the constraint formalism or arithmetic
circuits. Moreover, we have implemented a compiler (de-
rived from Fairplay’s [39]) that transforms high-level
computations ﬁrst into constraints and then into veriﬁer
and prover executables.

The challenges of representing computations as con-
straints over ﬁnite ﬁelds include: the “true answer” to the
computation may live outside of the ﬁeld; sign and or-
dering in ﬁnite ﬁelds interact in an unintuitive fashion;
and constraints are simply equations, so it is not obvi-
ous how to represent comparisons, logical expressions,
and control ﬂow. To explain GINGER’s solutions, we ﬁrst
present an abstract framework that illustrates how GIN-
GER broadens the set of computations soundly and how
one can apply the approach to further computations.
Framework to map computations to constraints. To
map a computation Ψ over some domain D (such as the
integers, Z, or the rationals, Q) to equivalent constraints
over a ﬁnite ﬁeld, the programmer or compiler performs
three steps, as illustrated and described below:

Ψ over D (C1)−−−−→ Ψ over U (C2)−−−−→ θ(Ψ) over F

(cid:121)(C3)

C over F

3We suspect that many of the individual techniques are known. How-
ever, when the techniques combine, the material is surprisingly hard
to get right, so we will delve into (excruciating) detail, consistent with
our focus on built systems.

5

C1 Bound the computation. Deﬁne a set U ⊂ D and re-
strict the input to Ψ such that the output and interme-
diate values stay in U.

C2 Represent the computation faithfully in a suitable ﬁ-
nite ﬁeld. Choose a ﬁnite ﬁeld, F, and a map θ : U →
F such that computing θ(Ψ) over θ(U) ⊂ F is iso-
morphic to computing Ψ over U. (By “θ(Ψ)”, we
mean Ψ with all inputs and literals mapped by θ.)

C3 Transform the ﬁnite ﬁeld version of the computation
into constraints. Write a set of constraints over F that
are equivalent (in the sense of Section 2.1) to θ(Ψ).

(cid:80)m

4.1 Signed integers and ﬂoating-point rationals
We now instantiate C1 and C2 for integer and rational
number computations; the next section addresses C3.
Consider m × m matrix multiplication over N-bit
signed integers. For step C1, each term in the output,
k=1 AikBkj, has m additions of 2N-bit subterms so is
contained in [−m · 22N−1, m · 22N−1); this is our set U.
For step C2, take F = Z/p (the integers mod a prime
p, to be chosen shortly) and deﬁne θ : U → Z/p as
θ(u) = u mod p. Observe that θ maps negative integers
2 , . . . , p − 1}, analogous to how processors
to { p+1
represent negative numbers with a 1 in the most signiﬁ-
cant bit (this technique is standard [17, 50]). Of course,
addition and multiplication in Z/p do not “know” when
their operands are negative. Nevertheless, the compu-
tation over Z/p is isomorphic to the computation over
U, provided that |Z/p| > |U| (as shown in Appendix
B [46]).4 Thus, for the given U, we require p > m · 22N.
Note that a larger p brings larger costs (see Figure 2), so
there is a three-way trade-off among p, m, N.

2 , p+3

We now turn to rational numbers. For step C1, we re-
strict the inputs as follows: when written in lowest terms,
their numerators are (Na + 1)-bit signed integers, and
their denominators are in {1, 2, 22, 23, . . . , 2Nb}. Note
that such numbers are (primitive) ﬂoating-point num-
bers: they can be represented as a · 2−q, so the decimal
point ﬂoats based on q. Now, for m×m matrix multiplica-
tion, the computation does not “leave” U = {a/b: |a| <
b}}, for N(cid:48)
a, b ∈ {1, 2, 22, 23, . . . , 2N(cid:48)
2N(cid:48)
a = 2Na + 2Nb +
log2 m and N(cid:48)
b = 2Nb [46, Appendix B].
For step C2, we take F = Q/p, the quotient ﬁeld of
b ) = (a mod p, b mod p). For any U ⊂ Q,
Z/p. Take θ( a
there is a choice of p such that the mapped computation
over Q/p is isomorphic to the original computation over
Q [46, Appendix B]. For our U above, p > (m + 1)2 ·
24(Na+Nb) sufﬁces.
Limitations and costs. To understand the limitations
of GINGER’s ﬂoating-point representation, consider the
number a · 2−q, where |a| < 2Na and |q| ≤ Nq.

4For space, Appendices B–E appear only in the extended version [46].

6

To represent this number, the IEEE standard requires
roughly Na + log Nq bits [29] while GINGER requires
2 · (max(Na, Nq) + 1) bits [46, Appendix B]. As a re-
sult, GINGER’s range is vastly more limited: with 64 bits,
the IEEE standard can represent numbers on the order of
21023 and 2−1022 (with Na = 53 bits of precision) while
64 bits buys GINGER only numbers on the order of 232
and 2−32 (with Na = 32). Moreover, unlike the IEEE
standard, GINGER does not support a division operation
or rounding.

However, comparing GINGER’s ﬂoating-point repre-
sentation to its integer representation, the extra costs are
not terrible. First, the prover and veriﬁer take an extra
pass over the input and output (for implementation rea-
sons; see Appendix B [46] for details). Second, a larger
prime p is required. For example, m × m matrix mul-
tiplication with 32-bit integer inputs requires p to have
at least log2 m + 64 bits; if the inputs are rationals with
Na = Nq = 32, then p requires 2 log2(m + 1) + 256 bits.
Roughly speaking, the end-to-end costs are 3× those of
the integers case (see Section 6.2). Of course, the ac-
tual numbers depend on the computation. (Our compiler
computes suitable bounds with static analysis.)
4.2 General-purpose program constructs
Case study: branch on order comparison. We now il-
lustrate C3 with a case study of a computation, Ψ, that
includes a less-than test and a conditional branch; pseu-
docode for Ψ is in Figure 3. For clarity, we will restrict
Ψ to signed integers; handling rational numbers requires
additional mechanisms [46, Appendix C].

How can we represent the test x1 < x2 using con-
straint equations? The solution is to use special range
constraints that decompose a number into its bits to test
whether it is in a given range; in this case, C<, depicted
in Figure 3, tests whether e = θ(x1) − θ(x2) is in the
“negative” range of Z/p (see Section 4.1). Now, under
the input restriction x1 − x2 ∈ U, C< is satisﬁable if and
only if x1 < x2 [46, Appendix C]. Analogously, we can
construct C>= that is satisﬁable if and only if x1 ≥ x2.

Finally, we introduce a 0/1 variable M that encodes
a choice of branch, and then arrange for M to “pull in”
the constraints of that branch and “exclude” those of the
other. (Note that the prover need not execute the untaken
branch.) Figure 3 depicts the complete set of constraints,
CΨ; these constraints are satisﬁable if and only if the
prover correctly computes Ψ [46, Appendix C].
Logical expressions and conditionals. Besides order
comparisons and if-else, GINGER can represent ==, &&,
and || as constraints. An interesting case is !=: we can
represent Z1!=Z2 with {M · (Z1 − Z2) − 1 = 0} because
this constraint is satisﬁable when (Z1 − Z2) has a multi-
plicative inverse and hence is not zero. These constructs
and others are detailed in Appendix D [46].

Ψ :

if (X1 < X2)

Y = 3

else

Y = 4



C< =

B0(1 − B0)
B1(2 − B1)
...
θ(X1) − θ(X2) − (p − 2N−1) −(cid:80)N−2
BN−2(2N−2 − BN−2)

= 0,
= 0,
...
= 0,
i=0 Bi = 0





CΨ =

M{C<},
M(Y − 3) = 0,
(1 − M){C>=},
(1 − M)(Y − 4) = 0



Figure 3—Pseudocode for our case study of Ψ, and corresponding constraints CΨ. Ψ’s inputs are signed integers x1, x2; per steps
C1 and C2 (§4.1), we assume x1 − x2 ∈ U ⊂ [−2N−1, 2N−1), where p > 2N. The constraints C< test x1 < x2 by testing whether the
bits of θ(x1) − θ(x2) place it in [p − 2N−1, p). M{C} means multiplying all constraints in C by M and then reducing to degree-2.

Limitations and costs. We compile a subset of SFDL,
the language of the Fairplay compiler [39]. Thus, our
limitations are essentially those of SFDL; notably, loop
bounds have to be known at compile time.

hardware in the context of [21]). We exploit three levels
of parallelism here. First, the prover performs a cipher-
text operation for each component in the commitment
vector (§2.3); each operation is (to ﬁrst approximation)
separate. Second, each operation computes two indepen-
dent modular exponentiations (the ciphertext of an ElGa-
mal encryption has two elements). Third, modular expo-
nentiation itself admits a parallel implementation (each
input is a multiprecision number encoded in multiple ma-
chine words). Thus, in our GPU implementation, a group
of CUDA [1] threads computes each exponentiation.

We also parallelize the veriﬁer’s encryption work dur-
ing the commitment phase (§2.3), using the approach
above plus an optimization: the veriﬁer’s exponentiations
are ﬁxed base, letting us memoize intermediate squares.
We implement exponentiations for the prover and veri-
ﬁer with the libgpucrypto library of SSLShader [36],
modiﬁed to implement the memoization.
Implementation details. Our compiler consists of two
stages, which a future publication will detail. The front-
end compiles a subset of Fairplay’s SFDL [39] to con-
straints; it is derived from Fairplay and is implemented
in 5294 lines of Java, starting from Fairplay’s 3886 lines
(per [51]). The back-end transforms constraints into C++
code that implements the veriﬁer and prover and then in-
vokes gcc; this component is 1105 lines of Python code.
For efﬁciency, PEPPER [45] introduced specialized
PCP protocols for certain computations. For some exper-
iments we use specialized PCPs in GINGER also; in these
cases we write the prover and veriﬁer manually, which
typically requires a few hundred lines of C++. Automat-
ing the compilation of specialized PCPs is future work.
The veriﬁer and prover are separate processes that ex-
change data using Open MPI [2]. GINGER uses the El-
Gamal cryptosystem [23] with 1024-bit keys.

6 Experimental evaluation
Our evaluation answers the following questions:
• What is the effect of the protocol reﬁnements (§3)?
• What are the costs of supporting rational numbers and

the additional program structures (§4)?

• What is GINGER’s speedup from parallelizing (§5)?
Figure 4 summarizes the results.

7

How efﬁcient is our representation? The program con-
structs above mostly have concise constraint representa-
tions. Consider, for instance, comp1==comp2; the equiv-
alent constraint set C consists of the constraints that rep-
resent comp1, the constraints that represent comp2, and
an additional constraint to relate the outputs of comp1
and comp2. Thus, C is the same size as its two compo-
nents, as one would expect.

However, two classes of computations are costly. First,
inequality comparisons require variables and a con-
straint for every bit position; see Figure 3. Second, the
constraints for if-else and ||, as written, seem to be
degree-3; notice, for instance, the M{C} in Figure 3. To
be compatible with the core protocol, these constraints
must be rewritten to be degree-2 (§2.1), which carries
costs. Speciﬁcally, if C has s variables and χ constraints,
an equivalent degree-2 representation of M{C} has s + χ
variables and 2 · χ constraints [46, Appendix D].
5 Parallelization and implementation
Many of GINGER’s remaining costs are in the crypto-
graphic operations in the commitment protocol (see Ap-
pendix A.1). To address these costs, we distribute the
prover over multiple machines, leveraging GINGER’s in-
herent parallelism. We also implement the prover and
veriﬁer on GPUs, which raises two questions. (1) Isn’t
this just moving the problem? Yes, and this is good:
GPUs are optimized for the types of operations that bot-
tleneck GINGER. (2) Why do we assume that the veriﬁer
has a GPU? Desktops are more likely than servers to have
GPUs, and the prevalence of GPUs is increasing. Also,
this setup models a future in which specialized hardware
for cryptographic operations is common.
Parallelization. To distribute GINGER’s prover, we run
multiple copies of it (one per host), each copy receiving
a fraction of the batch (Section 2.3). In this conﬁgura-
tion, the provers use the Open MPI [2] message-passing
library to synchronize and exchange data.

To further reduce latency, each prover ofﬂoads work
to a GPU (see also [49] for an independent study of GPU

GINGER’s protocol reﬁnements reduce per-instance network costs by 25–30× (to hundreds of KBs for the computations
we study), prover CPU costs by about 10–14% (leaving them still high), and break-even batch size (β∗) by about 4×.
With accelerated encryption GINGER breaks even from outsourcing short computations at small batch sizes; for 400×400
matrix multiplication, the veriﬁer gains from outsourcing at a batch size of 20 (tens of seconds of computation).
Rational arithmetic costs roughly 3× integer arithmetic under GINGER (but much more than native ﬂoating-point).
Parallelizing results in near-linear reduction in the prover’s latency.

§6.1

§6.1

§6.2
§6.3

Figure 4—Summary of main evaluation results.

computation (Ψ)

matrix mult.
matrix mult. (Q)
deg-2 poly. eval.
deg-3 poly. eval.
m-Hamming dist.
bisection method

O(·)
O(m3)
O(m3)
O(m2)
O(m3)
O(m2)
O(m2)

input domain (see §4.1)

32-bit signed integers
rationals (Na = 32, Nb = 32)
32-bit signed integers
32-bit signed integers
32-bit unsigned
rationals (Na = 32, Nb = 5)

size of F
128 bits
320 bits
128 bits
192 bits
128 bits
320 bits

s
2m2
2m2
m
m
2m2 + m
16 · (m + |C<|)

n
m3
m3
m2
m3
2m3
256 · (m + |C<|)2

default

m = 200
m = 100
m = 100
m = 200
m = 100
m = 25

local

800 ms
5.90 ms
0.40 ms
160 ms
0.90 ms
180 ms

Figure 5—Benchmark computations. s is the number of constraint variables; s affects n, which is the size of V’s queries and of P’s
linear function π (see Figure 2). Only high-order terms are reported for n. The latter two columns give our experimental defaults and
the cost of local computation (i.e., no outsourcing) at those defaults. In polynomial evaluation, V and P hold a polynomial; the input
is values for the m variables. The latter two computations exercise the program constructs in Section 4.2. In m-Hamming distance,
V and P hold a ﬁxed set of strings; the input is a length m string, and the output is a vector of the Hamming distance between the
input and the set of strings. Bisection method refers to root-ﬁnding via bisection: both V and P hold a degree-2 polynomial in m
variables, the input is two m-element endpoints that bracket a root, and the output is a small interval that contains the root.

We use six benchmark computations, summarized in
Figure 5 (Appendix E [46] has details). For bisection
method and degree-2 polynomial evaluation, V and P
were produced by our compiler; for the other compu-
tations, we use tailored encodings (see Section 5). We
implemented and analyzed other computations (e.g., edit
distance and circle packing) but found that V gained from
outsourcing only at implausibly large batch sizes.

Method and setup. We measure latency and comput-
ing cycles used by the veriﬁer and the prover, and the
amount of data exchanged between them. We account
for the prover’s cost in per-instance terms. Because the
veriﬁer amortizes costs over a batch (§2.3), we focus on
the break-even batch size, β∗: the batch size at which the
veriﬁer’s CPU cost from GINGER equals the cost of com-
puting the batch locally. We measure local computation
using implementations built on the GMP library (except
for matrix multiplication over rationals, where we use na-
tive ﬂoating-point).

For each result that we report, we run at least three ex-
periments and take the averages (the standard deviations
are always within 5% of the means). We measure CPU
time using getrusage, latency using PAPI’s real time
counter [3], and network costs by recording the number
of application-level bytes transferred.

Our experiments use a cluster at the Texas Advanced
Computing Center (TACC). Each machine is conﬁgured
identically and runs Linux on an Intel Xeon processor
E5540 2.53 GHz with 48GB of RAM. Experiments with
GPUs use machines with an NVIDIA Tesla M2070. Each

GPU has 448 CUDA cores and 6GB of memory.
Validating the cost model. We will sometimes predict
β∗, V’s costs, and P’s costs by using our cost model
(Figure 2), so we now validate this model. We run mi-
crobenchmarks to quantify the model’s parameters—e is
reported in this section; Appendix E [46] quantiﬁes the
other parameters—and then compare the parameterized
model to GINGER’s measured performance. GINGER’s
empirical results are at most 2%–15% more than are pre-
dicted by the model. However, local computation costs
about 1.2–4.0 times more than is predicted; we think that
the divergence results from adverse caching effects that
increase the cost of a multiplication. Thus, we expect the
veriﬁer to break even at batch sizes that are about a factor
of 1.2–4.0 smaller than predicted by the model.
6.1 The effect of GINGER’s protocol reﬁnements
We begin with m × m matrix multiplication (m =
100, 200) and degree-3 polynomial evaluation (m =
100, 200), and batch size of β = 5000. We report per-
instance network and CPU costs: the total network and
CPU costs over the batch, divided by β.

Figure 6 depicts network costs. For matrix multipli-
cation, these are about the same as the cost to send the
inputs and receive the outputs; for polynomial evalua-
tion, these are about 10 times the size of the inputs and
outputs. Also, GINGER improves on PEPPER by 20–30×.
In this experiment, GINGER’s prover incurs about 10–
14% less CPU time compared to PEPPER (estimated us-
ing a cost model from [45]) but still takes tens of min-
utes per-instance; this is obviously a lot, but we reduce

8

local
veriﬁer per-instance
veriﬁer aggregate
prover per-instance
prover aggregate

mat. mult.

17.6 ms
17.6 ms
76.1 s
3.1 min
9.3 days

mat. mult. (Q)
5.90 ms
80.2 ms
5.7 min
9.4 min
28 days

Figure 8—Predicted running times of GINGER’s veriﬁer and
prover for matrix multiplication (m = 100), under integer and
ﬂoating-point inputs, at β = 4300 (the break-even batch size
for this computation over integers). The “local” row refers to
GMP arithmetic for Z and native ﬂoating-point arithmetic for
Q. Handling rationals costs GINGER roughly 3× more than
handling integers, but both are still far from native.

computation (Ψ)

m-Hamming dist.
bisection method

# Boolean gates (est.)
1.3 · 106
3.0 · 108

# constraint vars.
2 · 104
1528

Figure 9—GINGER’s constraints compared to Boolean circuits,
for m-Hamming distance (m = 100) and bisection method
(m = 25). The Boolean circuits are estimated using the un-
modiﬁed Fairplay [39] compiler. GINGER’s constraints are not
concise but are far more so than Boolean circuits.

Under scenario (3), we take e = 0µs. What about sce-
nario (2)? Our cost model concerns CPU costs, so we
need an exchange rate between GPU and CPU exponen-
tations. We make a crude estimate: we measure the num-
ber of encryptions per second achievable on an NVIDIA
Tesla M2070 (which is 180,000) and on an Intel 2.5
GHz CPU (which is 13,700), normalize by the dollar
cost of the chips, and obtain that their throughput-per-
dollar ratio is 1.8×. We thus (very conservatively) take
e = 72.1/1.8 = 40µs.

We plug these three values of e into the cost model in
Figure 2, set the cost under GINGER equal to the cost of
local computing, and solve for β∗. The values of β∗ are
4150 (CPU), 2300 (crude GPU estimate), and 20 (crypto
hardware). We also use the model to predict V’s and P’s
costs at β∗, under PEPPER and GINGER. Figure 7 summa-
rizes. GINGER is very sensitive to the value of e because
its reﬁnements have eliminated many of the other costs.
Moreover, the aggregate veriﬁer computing time drops
signiﬁcantly under all three cost models. The prover’s
per-instance work is mostly unaffected, but as the batch
size decreases, so does its aggregate work.

6.2 Evaluating GINGER’s computational model
To understand the costs of the ﬂoating-point representa-
tion (§4.1), we compare it to two baselines: GINGER’s
signed integer representation and the computation exe-
cuted locally, using the CPU’s ﬂoating point unit. Our
benchmark application is matrix multiplication (m =
100). Figure 8 details the comparison.

We also consider GINGER’s general-purpose program
constructs (§4). Our baseline is Boolean circuits (we are

Figure 6—Per-instance network costs of GINGER and its base
(PEPPER [45]), compared to the size of the inputs and outputs.
At this batch size (β = 5000), GINGER’s reﬁnements reduce
per-instance network costs by a factor of 25–30 compared to
PEPPER. GINGER’s network costs here are hundreds of KB or
less. The y-axis is log-scaled.

PEPPER

GINGER

local
β∗
veriﬁer aggregate
prover aggregate
prover per-instance
β∗
veriﬁer aggregate
prover aggregate
prover per-instance
β∗
veriﬁer aggregate
prover aggregate
prover per-instance

1.1 s

13000
3.9 hr
5.0 yr
3.5 hr

8700
2.7 hr
3.5 yr
3.5 hr

3900
1.2 hr
1.6 yr
3.5 hr

CPU

GPU

crypto
hardware

1.1 s

4100
1.3 hr
1.6 yr
3.3 hr

2300
43.4 min
320 days
3.3 hr

20
22.3 s
2.8 days
3.3 hr

Figure 7—Break-even batch sizes (β∗) and predicted running
times of prover and veriﬁer at β = β∗, for matrix multiplication
(m = 400), under three models of the encryption cost. The
veriﬁer’s per-instance work is not depicted because it equals the
local running time, by deﬁnition of β∗. The local running time
is high in part because the local implementation uses GMP.

latency by parallelizing (§6.3). For this computation and
at this batch size (β = 5000), GINGER’s veriﬁer takes a
few hundreds of milliseconds per-instance, less than lo-
cally computing using our baseline of GMP.
Amortizing the veriﬁer’s costs. Batching is both a lim-
itation and a strength of GINGER: GINGER’s veriﬁer must
batch to gain from outsourcing but can batch to drive per-
instance overhead arbitrarily low. Nevertheless, we want
break-even batch sizes (β∗) to be as small as possible.
But β∗ mostly depends on e, the cost of encryption (Fig-
ure 2), because after our reﬁnements the veriﬁer’s main
burden is creating Enc(pk, r) (see §2.3), the cost of which
amortizes over the batch.

What values of e make sense? We consider three sce-
narios: (1) the veriﬁer uses a CPU for encryptions, (2)
the veriﬁer ofﬂoads encryptions to a GPU, and (3) the
veriﬁer has special-purpose hardware that can only per-
form encryptions. (See Section 5 for motivation.) Under
scenario (1), we measure e = 72.1µs on a 2.5 GHz CPU.

9

100102104106matrix mult(m=100)matrix mult(m=200)d-3 poly eval(m=100)d-3 poly eval(m=200)network costs(KB)input+outputinput+outputinput+outputinput+outputPepperPepperPepperPepperGingerGingerGingerGingerFigure 10—Latency speedup observed by GINGER’s veriﬁer when the prover is parallelized. We run with m = 100, β = 150 for
matrix multiplication and degree-3 polynomial evaluation; m = 100, β = 1500 for degree-2 polynomial evaluation; m = 100, β =
15 for m-Hamming distance; and m = 25, β = 15 for bisection method. GINGER’s prover achieves near-linear speedups except
when the problem sizes are small and hence the overhead from parallelizing is signiﬁcant (e.g., degree-2 polynomial evaluation).

unaware of efﬁcient arithmetic representations of these
constructs). We compare the number of Boolean circuit
gates and the number of GINGER’s arithmetic constraint
variables, since these determine the proving and verify-
ing costs under the respective formalisms (see [5, 45]).
Taken individually, GINGER’s constructs (<=, &&, etc.)
are the same cost or more than those of Boolean cir-
cuits (e.g., || introduces auxiliary variables). However,
Boolean circuits are in general far more verbose: they
represent quantities by their bits (which GINGER does
only when computing inequalities). Figure 9 gives a
rough end-to-end comparison.

6.3 Scalability of the parallel implementation
To demonstrate the scalability of GINGER’s paralleliza-
tion, we run the prover using many CPU cores, many
GPUs, and many machines. We measure end-to-end la-
tency, as observed by the veriﬁer. Figure 10 summarizes
the results for various computations. In most cases, the
speedup is near-linear.

7 Related work
A substantial body of work achieves two of our goals—
it is general-purpose and practical—but it makes strong
assumptions about the servers (e.g., trusted hardware).
There is also a large body of work on protocols for
special-purpose computation. We regard this work as
orthogonal to our efforts; for a survey of this land-
scape, see [45]. Herein, we focus on approaches that are
general-purpose and unconditional.
Homomorphic encryption and secure multi-party
protocols. Homomorphic encryption (which enables
computation over ciphertext) and secure multi-party pro-
tocols (in which participants compute over private data,
revealing only the result [34, 39, 52]) provide only pri-
vacy guarantees, but one can build on them for veriﬁable
computation. For instance, the Boneh-Goh-Nissim ho-
momorphic cryptosystem [18] can be adapted to evaluate
circuits, Groth uses homomorphic commitments to pro-
duce a zero-knowledge argument protocol [33], and Ap-
plebaum et al. use secure multi-party protocols for ver-

10

ifying computations [4]. Also, Gentry’s fully homomor-
phic encryption [27] has engendered protocols for veriﬁ-
able non-interactive computation [20, 24, 26]. However,
despite striking improvements [28, 42, 47], the costs of
hiding inputs (among other expenses) prevent any of the
aforementioned veriﬁed computation schemes from get-
ting close to practical (even by our relaxed standards).
PCPs, argument systems, and interactive proofs. Ap-
plying proof systems to veriﬁable computation is stan-
dard in the theory community [5–7, 10, 15, 32, 37, 38,
41], and the asymptotics continue to improve [13, 14, 22,
43]. However, none of this work has paid much attention
to building systems.

Very recently, researchers have begun to explore using
this theory for practical veriﬁed outsourced computation.
In a recent preprint, Ben-Sasson et al. [12] investigate
when PCP protocols might be beneﬁcial for outsourcing.
Since many of the protocols require representing compu-
tations as constraints, Ben-Sasson et al. [11] study im-
proved reductions to constraints from a RAM model of
computation. And Gennaro et al. [25] give a new charac-
terization of NP to provide asymptotically efﬁcient argu-
ments without using PCPs.

However, as far as we know, only two research groups
have made serious efforts toward practical systems. Our
previous work [44, 45] built upon the efﬁcient argument
system of Ishai et al. [35]. In contrast, Cormode, Mitzen-
macher, and Thaler [21] (hereafter, CMT) built upon the
protocol of Goldwasser et al. [31], and a follow-up effort
studies a GPU-based parallel implementation [49].
Comparison of GINGER and CMT [21, 49]. We
compared three different implementations: CMT-native,
CMT-GMP, and GINGER. CMT-native refers to the code
and conﬁguration released by Thaler et al. [49]; it works
over a small ﬁeld and thereby exploits highly efﬁcient
machine arithmetic but restricts the inputs to the compu-
tation unrealistically (see Section 4.1). CMT-GMP refers
to an implementation based on CMT-native but modiﬁed
by us to use the GMP library for multi-precision arith-
metic; this allows more realistic computation sizes and
inputs, as well as rational numbers.

 0 20 40 60 80matrix multdegree-2 poly eval(compiler-output code)degree-3 poly evalm-Hamming distancebisection method(compiler-output code)speedup1 core1 core1 core1 core1 core4 cores4 cores4 cores4 cores4 cores1 GPU1 GPU1 GPU1 GPU1 GPU3 GPUs3 GPUs3 GPUs3 GPUs3 GPUs60 cores60 cores60 cores60 cores60 cores60 cores (ideal)60 cores (ideal)60 cores (ideal)60 cores (ideal)60 cores (ideal)m

256

Z

128 Q

domain component

veriﬁer
prover
network

veriﬁer
prover
network

CMT-native
40 ms
22 min
88 KB

–
–
–

CMT-GMP
0.6 s
2.5 hr
0.3 MB

260 ms
1.0 hr
1.8 MB

GINGER

0.3 s
36 min
1.1 MB

190 ms
21 min
1.4 MB

Figure 11—CMT [21] compared to GINGER, in terms of amor-
tized CPU and network costs (GINGER’s total costs are divided
by a batch size of β=5000 instances), for m × m matrix mul-
tiplication. CMT-native uses native data types but is restricted
to small problem sizes and domains. CMT-GMP uses the GMP
library for multi-precision arithmetic (as does GINGER).

We perform two experiments using m× m matrix mul-
tiplication. Our testbed is the same as in Section 6. In the
ﬁrst one, we run with m = 256 and integer inputs. For
CMT-GMP and GINGER, the inputs are 32-bit unsigned
integers, and the prime (the ﬁeld modulus) is 128 bits.
For CMT-native, the prime is 261 − 1. In the second ex-
periment, m is 128, the inputs are rational numbers (with
Na = Nb = 32; see Section 4.1), the prime is 320 bits,
and we experiment only with CMT-GMP and GINGER.
We measure total CPU time and network cost; for
CMT, we measure “network” trafﬁc by counting bytes
(the CMT veriﬁer and prover run in the same process
and hence the same machine). Each reported datum is an
average over 3 sample runs; there is little experimental
variation (less than 5% of the means).

Figure 11 depicts the results. CMT incurs a signiﬁcant
penalty when moving from native to GMP (and hence
to realistic problem sizes). Comparing CMT-GMP and
GINGER, the network and prover costs are similar (al-
though network costs for CMT reﬂect high ﬁxed over-
head for their circuit). The per-instance veriﬁer costs
are also similar, but GINGER is batch verifying whereas
CMT does not need to do so (a signiﬁcant advantage).

A qualitative comparison is as follows. On the one
hand, CMT does not require cryptography, has better
asymptotic prover and network costs, and for some com-
putations the veriﬁer does not need batching to gain from
outsourcing [49]. On the other hand, CMT applies to a
smaller set of computations: if the computation is not ef-
ﬁciently parallelizable or does not naturally map to arith-
metic circuits (e.g., it has order comparisons or condi-
tionality), then CMT in its current form will be inappli-
cable or inefﬁcient, respectively. Ultimately, GINGER and
CMT should be complementary, as one can likely ease or
eliminate some of the restrictions on CMT by incorporat-
ing the constraint formalism together with batching [48].

8 Summary and conclusion
This paper is a contribution to the emerging area of
practical PCP-based systems for unconditional veriﬁable

11

computation. GINGER has combined theoretical reﬁne-
ments (slashing query costs and network overhead); a
general computational model (including fractions and
standard program constructs) with a compiler; and a mas-
sively parallel implementation that takes advantage of
modern hardware. Together, these changes have brought
us closer to a truly deployable system. Nevertheless,
much work remains: the efﬁciency of the veriﬁer depends
on special hardware, the costs for the prover are still too
high, and looping cannot yet be handled concisely.
Acknowledgments
Detailed attention from Edmund L. Wong substantially
clariﬁed this paper. Yuval Ishai, Mike Lee, Bryan Parno,
Mark Silberstein, Chung-chieh (Ken) Shan, Sara L. Su,
Justin Thaler, and the anonymous reviewers gave useful
comments that improved this draft. The Texas Advanced
Computing Center (TACC) at UT supplied computing
resources. We thank Jane-Ellen Long, of USENIX, for
her good nature and inexhaustible patience. The research
was supported by AFOSR grant FA9550-10-1-0073 and
by NSF grants 1055057 and 1040083.

Our code and experimental conﬁgurations are avail-

able at http://www.cs.utexas.edu/pepper

References
[1] CUDA (http://developer.nvidia.com/what-cuda).
[2] Open MPI (http://www.open-mpi.org).
[3] PAPI: Performance Application Programming Interface.
[4] B. Applebaum, Y. Ishai, and E. Kushilevitz. From secrecy to

soundness: efﬁcient veriﬁcation via secure computation. In
ICALP, 2010.

[5] S. Arora, C. Lund, R. Motwani, M. Sudan, and M. Szegedy.

Proof veriﬁcation and the hardness of approximation problems.
J. of the ACM, 45(3):501–555, May 1998.

[6] S. Arora and S. Safra. Probabilistic checking of proofs: a new

characterization of NP. J. of the ACM, 45(1):70–122, Jan. 1998.

[7] L. Babai, L. Fortnow, L. A. Levin, and M. Szegedy. Checking

computations in polylogarithmic time. In STOC, 1991.

[8] M. Bellare, D. Coppersmith, J. H˚astad, M. Kiwi, and M. Sudan.

Linearity testing in characteristic two. IEEE Transactions on
Information Theory, 42(6):1781–1795, Nov. 1996.

[9] M. Bellare, S. Goldwasser, C. Lund, and A. Russell. Efﬁcient

probabilistically checkable proofs and applications to
approximations. In STOC, 1993.

[10] M. Ben-Or, S. Goldwasser, J. Kilian, and A. Wigderson.

Multi-prover interactive proofs: how to remove intractability
assumptions. In STOC, 1988.

[11] E. Ben-Sasson, A. Chiesa, D. Genkin, and E. Tromer. Fast

reductions from RAMs to delegatable succinct constraint
satisfaction problems. Feb. 2012. Cryptology eprint 071.

[12] E. Ben-Sasson, A. Chiesa, D. Genkin, and E. Tromer. On the

concrete-efﬁciency threshold of probabilistically-checkable
proofs. ECCC, (045), Apr. 2012.

[13] E. Ben-Sasson, O. Goldreich, P. Harsha, M. Sudan, and
S. Vadhan. Robust PCPs of proximity, shorter PCPs and
applications to coding. SIAM J. on Comp., 36(4):889–974, Dec.
2006.

[14] E. Ben-Sasson and M. Sudan. Short PCPs with polylog query

[40] R. C. Merkle. Digital signature based on a conventional

complexity. SIAM J. on Comp., 38(2):551–607, May 2008.

encryption function. In CRYPTO, 1987.

[15] M. Blum and S. Kannan. Designing programs that check their

[41] S. Micali. Computationally sound proofs. SIAM J. on Comp.,

work. J. of the ACM, 42(1):269–291, 1995.

[16] M. Blum, M. Luby, and R. Rubinfeld. Self-testing/correcting
with applications to numerical problems. J. of Comp. and Sys.
Sciences, 47(3):549–595, Dec. 1993.

[17] D. Boneh and D. M. Freeman. Homomorphic signatures for

polynomial functions. In EUROCRYPT, 2011.

[18] D. Boneh, E. J. Goh, and K. Nissim. Evaluating 2-DNF

formulas on ciphertexts. In TCC, 2005.

[19] G. Brassard, D. Chaum, and C. Cr´epeau. Minimum disclosure

proofs of knowledge. J. of Comp. and Sys. Sciences,
37(2):156–189, 1988.

[20] K.-M. Chung, Y. Kalai, and S. Vadhan. Improved delegation of
computation using fully homomorphic encryption. In CRYPTO,
2010.

[21] G. Cormode, M. Mitzenmacher, and J. Thaler. Practical veriﬁed

computation with streaming interactive proofs. In ITCS, 2012.

[22] I. Dinur. The PCP theorem by gap ampliﬁcation. J. of the ACM,

54(3), June 2007.

[23] T. ElGamal. A public key cryptosystem and a signature scheme
based on discrete logarithms. IEEE Transactions on Information
Theory, 31:469–472, 1985.

[24] R. Gennaro, C. Gentry, and B. Parno. Non-interactive veriﬁable

computing: Outsourcing computation to untrusted workers. In
CRYPTO, 2010.

[25] R. Gennaro, C. Gentry, B. Parno, and M. Raykova. Quadratic
span programs and succinct NIZKs without PCPs. Apr. 2012.
Cryptology eprint 215.

[26] R. Gennaro and D. Wichs. Fully homomorphic message

authenticators. May 2012. Cryptology eprint 290.

[27] C. Gentry. A fully homomorphic encryption scheme. PhD thesis,

Stanford University, 2009.

[28] C. Gentry, S. Halevi, and N. Smart. Homomorphic evaluation of

the AES circuit. In CRYPTO, 2012.

[29] D. Goldberg. What every computer scientist should know about
ﬂoating-point arithmetic. ACM Computing Surveys, 23(1):5–48,
Mar. 1991.

[30] O. Goldreich. Foundations of Cryptography: II Basic

Applications. Cambridge University Press, 2004.

[31] S. Goldwasser, Y. T. Kalai, and G. N. Rothblum. Delegating
computation: Interactive proofs for muggles. In STOC, 2008.

[32] S. Goldwasser, S. Micali, and C. Rackoff. The knowledge

complexity of interactive proof systems. SIAM J. on Comp.,
18(1):186–208, 1989.

[33] J. Groth. Linear algebra with sub-linear zero-knowledge

arguments. In CRYPTO, 2009.

[34] Y. Huang, D. Evans, J. Katz, and L. Malka. Faster secure
two-party computation using garbled circuits. In USENIX
Security, 2011.

[35] Y. Ishai, E. Kushilevitz, and R. Ostrovsky. Efﬁcient arguments

without short PCPs. In Conference on Computational
Complexity (CCC), 2007.

[36] K. Jang, S. Han, S. Han, S. Moon, and K. Park. SSLShader:

Cheap SSL acceleration with commodity processors. In NSDI,
2011.

[37] J. Kilian. A note on efﬁcient zero-knowledge proofs and

arguments (extended abstract). In STOC, 1992.

[38] J. Kilian. Improved efﬁcient arguments (preliminary version). In

CRYPTO, 1995.

[39] D. Malkhi, N. Nisan, B. Pinkas, and Y. Sella. Fairplay—a secure

two-party computation system. In USENIX Security, 2004.

30(4):1253–1298, 2000.

[42] M. Naehrig, K. Lauter, and V. Vaikuntanathan. Can

homomorphic encryption be practical? In ACM Workshop on
Cloud Computing Security, 2011.

[43] A. Polishchuk and D. A. Spielman. Nearly-linear size

holographic proofs. In STOC, 1994.

[44] S. Setty, A. J. Blumberg, and M. Walﬁsh. Toward practical and
unconditional veriﬁcation of remote computations. In HotOS,
2011.

[45] S. Setty, R. McPherson, A. J. Blumberg, and M. Walﬁsh.

Making argument systems for outsourced computation practical
(sometimes). In NDSS, 2012.

[46] S. Setty, V. Vu, N. Panpalia, B. Braun, A. J. Blumberg, and

M. Walﬁsh. Taking proof-based veriﬁed computation a few steps
closer to practicality (extended version). Technical Report
TR-12-14, Dept. of CS, UT Austin, June 2012.

[47] N. Smart and F. Vercauteren. Fully homomorphic SIMD

operations. Aug. 2011. Cryptology eprint 133.
[48] J. Thaler. Personal communication, June 2012.
[49] J. Thaler, M. Roberts, M. Mitzenmacher, and H. Pﬁster.

Veriﬁable computation with massively parallel interactive
proofs. In USENIX HotCloud Workshop, June 2012. Full paper
at http://arxiv.org/abs/1202.1350, Feb. 2012.

[50] C. Wang, K. Ren, J. Wang, and K. M. R. Urs. Harnessing the

cloud for securely outsourcing large-scale systems of linear
equations. In Intl. Conf. on Dist. Computing Sys. (ICDCS), 2011.

[51] D. A. Wheeler. SLOCCount.
[52] A. C.-C. Yao. How to generate and exchange secrets. In FOCS,

1986.

A Efﬁcient arguments with linear PCPs

but no linearity tests

Whereas previous work [35, 45] established that the
commitment protocol in phases 2 and 3 of PEPPER (§2.3)
binds the prover to a particular function, there were no
constraints on that function. The principal result of this
section is that the prover is actually bound to a function
that is linear, or very nearly so. As a consequence, we can
eliminate linearity testing from the PCP protocol. Fur-
thermore, the error bound from one run of this modiﬁed
PCP protocol is far stronger (lower) than was known.

This section describes the base protocols (A.1), states
the reﬁnements and proves their soundness (A.2), and de-
scribes a few other optimizations (A.3).
A.1 Base protocols
GINGER uses a linear commitment protocol that is bor-
rowed from PEPPER [45]; this protocol is depicted in Fig-
ure 12.5 As described in Section 2.3, PEPPER composes
this protocol and a linear PCP; that PCP is depicted in
Figure 13. The purpose of {γ0, γ1, γ2} in this ﬁgure is to
make a maliciously constructed oracle unlikely to pass

5Like PEPPER, GINGER veriﬁes in batches (§2.3), which changes the
protocols a bit; see [45, Appendix C] for details.

12

Commit+Multidecommit

The protocol assumes an additive homomorphic encryption scheme (Gen, Enc, Dec) over a ﬁnite ﬁeld, F.
Commit phase
Input: Prover holds a vector w ∈ Fn, which deﬁnes a linear function π : Fn → F, where π(q) = (cid:104)w, q(cid:105).
1. Veriﬁer does the following:

• Generates public and secret keys (pk, sk) ← Gen(1k), where k is a security parameter.
• Generates vector r ∈R Fn and encrypts r component-wise, so Enc(pk, r) = (Enc(pk, r1), . . . , Enc(pk, rn)).
• Sends Enc(pk, r) and pk to the prover.

2. Using the homomorphism in the encryption scheme, the prover computes e ← Enc(pk, π(r)) without learning r. The prover

sends e to the veriﬁer.

= s + α1a1 + ··· + αµaµ. If so, it outputs (a1, a2, . . . , aµ). If not, it rejects, outputting ⊥.

3. The veriﬁer computes s ← Dec(sk, e), retaining s and r.
Decommit phase
Input: the veriﬁer holds q1, . . . , qµ ∈ Fn and wants to obtain π(q1), . . . , π(qµ).
4. The veriﬁer picks µ secrets α1, . . . , αµ ∈R F and sends to the prover (q1, . . . , qµ, t), where t = r + α1q1 + ··· + αµqµ ∈ Fn.
5. The prover returns (a1, a2, . . . , aµ, b), where ai, b ∈ F. If the prover behaved, then ai = π(qi) for all i ∈ [µ], and b = π(t).
6. The veriﬁer checks: b ?
Figure 12—The commitment protocol of PEPPER [45], which generalizes a protocol of Ishai et al. [35]. q1, . . . , qµ are the PCP
queries, and n is the size of the proof encoding. The protocol is written in terms of an additive homomorphic encryption scheme, but
as stated elsewhere [35, 45], the protocol can be modiﬁed to work with a multiplicative homomorphic scheme, such as ElGamal [23].
the circuit test; to generate the {γi}, V multiplies each
constraint by a random value and collects like terms, a
process described in [5, 13, 35, 45]. The completeness
and soundness of this PCP are explained in those sources,
and our notation is borrowed from [45]. Here we just as-
sert that the soundness error of this PCP is  = (7/9)ρ;
that is, if the proof π is incorrect, the veriﬁer detects that
fact with probability greater than 1 − . To make  small,
PEPPER takes ρ = 70.
A.2 Stronger soundness analysis and consequences
GINGER retains the (P, V) argument system of PEP-
PER [45] but uses a modiﬁed PCP protocol (depicted in
Figure 14) that makes the following changes to the base
PCP protocol (Figure 13):

tors (S, R) (a sender and receiver, which correspond to
our prover and veriﬁer) in an environment E that gener-
ates F, w and Q = (q1, . . . , qµ). In the ﬁrst phase, the
commit phase, S has w, and S and R interact, based on
their random inputs. In the decommit phase, E gives Q
to R, and S and R interact again, based on further ran-
dom inputs. At the end of this second phase, R outputs
A = (a1, . . . , aµ) ∈ Fµ or ⊥. A CFMD meets the fol-
lowing properties:

• Correctness. At the end of the decommit phase, R
outputs π(qi) = (cid:104)w, qi(cid:105) (for all i), if S is honest.
• B-Binding. Consider the following experiment. The
environment E produces two (possibly distinct) µ-
tuples of queries: Q = (q1, . . . , qµ) and ˆQ =
(ˆq1, . . . , ˆqµ). R and a cheating S∗ run the commit
phase once and two independent instances of the de-
commit phase. In the two instances R presents the
queries as Q and ˆQ, respectively. We say that S∗ wins
binding if R’s outputs at the end of the respective
decommit phases are A = (a1, . . . , aµ) and ˆA =
(ˆa1, . . . , ˆaµ), and for some i, j, we have qi = ˆqj but
ai (cid:54)= ˆaj. We say that the protocol meets the B-Binding
property if for all E and for all efﬁcient S∗, the proba-
bility of S∗ winning binding is less than B. The proba-
bility is taken over three sets of independent random-
ness: the commit phase and the two runnings of the
decommit phase.
• L-Linearity. Consider the same experiment above.
We say that S∗ wins linearity if R’s outputs at the
end of the respective decommit phases are A =
(a1, . . . , aµ) and ˆA = (ˆa1, . . . , ˆaµ), and for some i, j, k,
we have ˆqk = qi + qj but ˆak (cid:54)= ai + aj. We say that

• Remove the linearity queries and tests.
• Set ρ = 1.

ment system with soundness G ≈ 6(cid:112)1/|F|. (The exact

Theorem A.1. The (P, V) described above is an argu-

value of G depends on intermediate lemmas and will be
given at the end of the section.)

We will prove this theorem at the end of this section.
To build up to the proof, we ﬁrst strengthen the deﬁni-
tion of a linear commitment primitive. We note that only
the third property (linearity) in the deﬁnition is new; the
rest is taken from [45, Appendix B], which itself heavily
borrows framing, notation, and text from Ishai et al. [35].
Deﬁnition A.1 (Commitment to a function with multi-
ple decommitments (CFMD)). Deﬁne a two-phase ex-
periment between two probabilistic polynomial time ac-

13

The linear PCP from [5]

GINGER’s PCP protocol

Loop ρ times:
• Generate linearity queries: Select q1, q2 ∈R Fs and
q4, q5 ∈R Fs2. Take q3 ← q1 + q2 and q6 ← q4 + q5.
• Generate quadratic correction queries: Select q7, q8 ∈R Fs
and q10 ∈R Fs2. Take q9 ← (q7 ⊗ q8 + q10).
• Generate circuit queries: Select q12 ∈R Fs and q14 ∈R Fs2.
Take q11 ← γ1 + q12 and q13 ← γ2 + q14.
• Issue queries. Send q1, . . . , q14 to oracle π, getting back
π(q1), . . . , π(q14).
• Linearity tests: Check that π(q1) + π(q2) = π(q3) and that
π(q4) + π(q5) = π(q6). If not, reject.
• Quadratic correction test: Check that π(q7) · π(q8) =
π(q9) − π(q10). If not, reject.
(π(q11) − π(q12)) +
• Circuit
that
(π(q13) − π(q14)) = −γ0. If not, reject.

Check

test:

If V makes it here, accept.

Figure 13—The linear PCP that PEPPER uses. It is from [5].
The notation x ⊗ y refers to the outer product of two vectors x
and y (meaning the vector or matrix consisting of all pairs of
components from the two vectors). The values {γ0, γ1, γ2} are
described brieﬂy in the text.

the protocol meets the L-linearity property if for all E
and for all efﬁcient S∗, the probability of S∗ winning
linearity is less than L. As with the prior property,
the probability is taken over three sets of independent
randomness: the commit phase and the two runnings
of the decommit phase.
Prior work proved that Commit+Multidecommit (Fig-
ure 12) meets the ﬁrst two properties above [45]. We will
now show that it also meets the third property.
Lemma A.1. Commit+Multidecommit meets the deﬁni-
tion of L-linearity, with L = 1/|F| + S, where S comes
from the semantic security of the homomorphic encryp-
tion scheme.
Proof. We will show that if S∗ can systematically cheat,
then an adversary A could use S∗ to break the semantic
security of the encryption scheme.
Let r ∈R Fn and Z1, Z2 ∈R F (we use ∈R to mean
“drawn uniformly at random from”). Semantic security
(see [30], deﬁnitions 5.2.2, 5.2.8 and Exercise 17) im-
plies that for all PPT A (A can be non-uniform),

Gen,Enc,r,Z1,Z2

Pr
< 1/|F| + S.

{A(pk, Enc(pk, r), r + Z1q, r + Z2q) = Z1}
(1)

This holds for all q ∈ Fn.6
6We are being loose here. Under the actual deﬁnition of semantic secu-
rity, (a) S should be replaced with a negligible function of n, and (b)
the claim holds only for n sufﬁciently large.

14

• Generate quadratic correction queries: Select q1, q2 ∈R Fs
and q4 ∈R Fs2. Deﬁne q3 ← (q1 ⊗ q2 + q4). Note that q3
will not travel, as P can derive it.
• Generate circuit queries: Take q5 ← γ1 + q1. Take q6 ←
γ2 + q4.
• Issue queries. Send (q1, q2, q4, q5, q6) to oracle π, getting
back π(q1), π(q2), π(q3), π(q4), π(q5), π(q6).
• Quadratic correction test: Check that π(q1) · π(q2) =
π(q3) − π(q4). If not, reject.
(π(q5) − π(q1)) +
• Circuit
(π(q6) − π(q4)) = −γ0. If so, accept.

Check

test:

that

Figure 14—GINGER’s PCP protocol, which reﬁnes PEPPER’s
protocol (Figure 13). This protocol eliminates linearity testing
and repetition, and recycles queries [9].

to

the

Now,

assume

contrary

that Com-
mit+Multidecommit does not meet
the deﬁnition of
L-linearity. Then there exists an environment E produc-
ing qi, qj, i, j, k, Q, ˆQ, S∗ (where Q has qi, qj in the ith and
jth positions and ˆQ has qi + qj in the kth position) such
that Prall 3 phases{S∗ wins linearity under E} > 1/|F|+S.
Let q(cid:48) (cid:44) ˆqk = qi + qj.
We now describe an algorithm A that, when given
input I = (pk, Enc(pk, r), r + Z1q(cid:48), r + Z2q(cid:48)), can re-
cover Z1 with probability more than 1/|F| + S. A has
Q, ˆQ, qi, qj, i, j, k hard-wired (because it is working under
environment E) and works as follows:
(a) A gives (pk, Enc(pk, r)) to S∗ and ignores the reply.
(b) A randomly generates α1, . . . , αµ and sends to S∗
the input (Q, r+α1q1+···+(αi+Z1)qi+···+(αj+
Z1)qj +···+αµqµ). A is able to construct this input
because A was given r + Z1q(cid:48) = r + Z1qi + Z1qj. In
response, S∗ returns (b, a1, . . . , ai, . . . , aj, . . . , aµ).
(c) A randomly generates ˆα1, . . . , ˆαµ. A sends to S∗ the
input ( ˆQ, r + ˆα1ˆq1 +··· + Z2ˆqk +··· + ˆαµˆqµ). A is
able to construct this input because A was given r +
Z2q(cid:48) = r+Z2ˆqk. A gets back (ˆb, ˆa1, . . . , ˆak, . . . , ˆaµ).
At this point, A assumes that the responses from S∗
pass the decommitment phase; that is, A acts as if b =
s+α1a1+···+(αi+Z1)ai+···+(αj+Z1)aj+···+αµaµ
and ˆb = s + ˆα1ˆa1 +··· + Z2ˆak +··· + ˆαµˆaµ. A can write

K1 = Z2ˆak − Z1(ai + aj),

ι(cid:54)=k ˆαιˆaι +(cid:80)

where A can derive K1 = ˆb− b−(cid:80)

(2)
ι αιaι.
Now, let t = r + Z1q(cid:48) and let ˆt = r + Z2q(cid:48) (both of
these were supplied as input to A). These two equations
concern vectors. However, by choosing an index ι in the
vector q(cid:48) where q(cid:48) is not zero (if the vector is zero every-
where, then r is revealed), A can derive

K2 = Z2 − Z1,

(3)

where K2 = (ˆt(ι) − t(ι))/q(cid:48)(ι).
Now, observe that if ˆak (cid:54)= ai + aj (as happens when
S∗ wins), then A can recover Z1 by solving equations (2)
and (3). Thus,

Pr

{A(I) = Z1}

Gen,Enc,r,Z1,Z2,(cid:126)α,(cid:126)ˆα
≥

Gen,Enc,r,Z1,Z2,(cid:126)α,(cid:126)ˆα

{S∗ wins linearity under E}

Pr
{S∗ wins linearity under E}

all 3 phases

= Pr
> 1/|F| + S.

(4)

the

holds

because

equality

(α1, . . . , αi + Z1, . . . , αj + Z1, . . . , αµ)

distribution
The
and
of
(ˆα1, . . . , Z2, . . . , ˆαµ)
to the distribu-
tion from which R selects in the decommit phases of the
three-phase experiment, under Commit+Multidecommit.
Meanwhile, inequality (4) contradicts inequality (1).

is equivalent

The

ahead

lemmas

show that,

under Com-
mit+Multidecommit, S is bound to a nearly linear
function, ˜f (·); speciﬁcally, ˜f (·) is δ∗-close to linear for
small δ∗. By contrast, previous work [35, 45] showed
only that S was bound to some function ˜f (·).

We now give some notation and restate two claims
from [45]. Let ζ be the event that R’s output is a vec-
tor (a1, . . . , aµ); equivalently, ζ is the event that R’s out-
put is non-⊥. Below, we sometimes write Prcomm{·} or
Prdecomm{·} to mean the probability over the random
choices of the commit or decommit phases.

√

C = µ · 2 · (2 3(cid:112)9/2 + 1) · 3

Lemma A.2 (Existence of an extractor function [45]).
Let (S, R) be a CFMD protocol with binding error B. Let
B. Let v = (vS∗, vR) rep-
resent the views of S∗ and R after the commit phase (v
captures the randomness of the commit phase). For ev-
ery efﬁcient S∗ and for every v, there exists a function
˜fv : Fn → F such that the following holds.7 For any en-
vironment E, the output of R at the end of the decommit
phase is, except with probability C, either ⊥ or satisﬁes
ai = ˜fv(qi) for all i ∈ [µ], where (q1, . . . , qµ) are the de-
commitment queries generated by E, and the probability
is over the random inputs of S∗ and R in both phases.

Lemma A.3. Let 3 = (2 3(cid:112)9/2 + 1)· 3

B . Label the ith
query in Q as qi and the ith response as ai. For all Q, i,
we have Prcomm,decomm{ζ ∩ {ai (cid:54)= ˜fv(qi)}} < 23.
Proof. Follows from a claim in [45] (Claim B.4).
Lemma A.4. For all q1, q2 ∈ Fn, Prcomm{˜fv(q1) +
˜fv(q2) (cid:54)= ˜fv(q1 + q2)} < F (cid:44) L + 63.

√

7Note that after the commit phase, ˜fv(·) is deterministic. (˜fv(·) is de-
ﬁned [35, 45] to map q to the value that R is most likely to successfully
output in the decommit phase.)

15

Proof. Assume otherwise. Then for some q1 and q2, we
have Prcomm{˜fv(q1) + ˜fv(q2) (cid:54)= ˜fv(q1 + q2)} ≥ F, which
implies Prall 3 phases{˜fv(q1) + ˜fv(q2) (cid:54)= ˜fv(q1 + q2)} ≥ F,
since we can “add coin ﬂips that don’t matter”, namely
those of the two decommit phases.

Now, consider the game in the deﬁnition of L-
linearity, and set Q = (q1, q2, . . .) and ˆQ = (q1 +
q2, . . .). Let η be the event that S∗ wins in this game.
Let ν be the event that the outputs a1, a2, ˆa1 are given
by the function ˜fv(·). Then Prall 3 phases{(cid:113)ν} < 63, by
Lemma A.3, by the union bound, and by (again) “adding
coin ﬂips that don’t matter” to get from a probability
over two phases to one over three phases. Now, note that
Prall 3 phases{η|ν} ≥ F, by the contrary hypothesis. This
implies that Prall 3 phases{η} ≥ F − 63 = L, which con-
tradicts the deﬁnition of L-linearity.

Lemma A.4 almost talks about a linearity test [16]!
But linearity testing theory [8] relates (a) the probabil-
ity over randomly chosen queries that the test fails and
(b) the closeness-to-linearity of the tested function. Thus,
to apply the theory, we line up Lemma A.4 and (a).
Lemma A.5. With probability greater than 1−√
F over
the commit phase, the fraction of (q1, q2) pairs that cause
˜fv(·) to fail the linearity test is ≤ √
Proof. Let Iv,q1,q2 be an indicator random variable that
equals 1 if, in view v (that is, given the randomness of
the commit phase), ˜fv(q1 + q2) (cid:54)= ˜fv(q1) + ˜fv(q2). The
lemma is equivalent to the statement
√

F.

√

{Iv,q1,q2 = 1} >

F} <

{ Pr
q1,q2

Pr
comm

q1,q2

Now, deﬁne a random variable Yv = 1
Iv,q1,q2,
Q2
where Q = |F|n is the number of possibilities for each
of q1 and q2. By linearity of expectation, Ecomm[Yv] =
Q2 · (E[Iv,1] +··· + E[Iv,Q2 ]), where E[Iv,i] is the probabil-
1
ity, over the commit phase, that a particular (qj, qk) pair
causes ˜fv(·) to fail the linearity test. Lemma A.4 implies
that E[Iv,i] < F for all i; hence, Ecomm[Yv] < F. We now
apply a Markov bound to Yv:

{Yv >

√

F} <

Pr
comm

Ecomm[Yv]

√

F

√

F.

=

<

F√
F

√

But Yv is equivalent to Prq1,q2{Iv,q1,q2 = 1}; making this
substitution immediately above yields the lemma.
Lemma A.6. Let δ∗ be the lesser root of 6δ2 − 3δ +
√
F = 0. If
9, then with probability greater than
1−√
F over the commit phase, ˜fv(·) is δ∗-close to linear.
Proof. We use the linearity testing results of Bellare et
al. [8, 9] and the terminology of [8]. Deﬁne Dist(f , g)
to be the fraction of inputs on which f and g disagree.

F < 2

F.

(cid:80)

By inspection (of the lemmas), the dominant contributor
to G, namely

F, is proportional to 6(cid:112)1/|F|.

√

We compute a bound on G as follows.

√

√

Since κ and

F < 2/9, as required.

• C is given in Lemma A.2. We take µ = 6 (per Fig-
ure 14). We also take B = 1/|F| (following [45]; this
amounts to ignoring the error from the semantic se-
curity of the homomorphic encryption scheme) and
|F| = 2128, giving C < 7.4 · 10−12.
• F = L + 63 (from Lemma A.4). 3 is given in
Lemma A.3. We set L = 1/|F| (which again amounts
to ignoring S). Again taking |F| = 2128, we get
√
F < 1.9 · 10−6. Thus,
• κ = 4δ∗ + 2|F|, where δ∗ is the lesser root of 6δ2−3δ+
√
F. This gives δ∗ = 6.4 · 10−7 and κ = 2.6 · 10−6.
F are roughly the same, there is not
much point to taking ρ > 1. Thus, we take ρ = 1, giving
G < 4.5 · 10−6 when |F| = 2128. When |F| = 2192, we
get G < 2.8 · 10−9.
A.3 Optimizing out queries
GINGER’s PCP protocol
includes two further reﬁne-
ments. First, the protocol reuses q4 and q1 from test to
test. This reuse is sound because the PCP soundness
lemma [5] is of the form, “if all tests pass with proba-
bility greater than X, then the proof oracle π has a cer-
tain desired property”; meanwhile, as Bellare et al. [9]
observe, the tests need not be independent! One can ob-
serve the savings by comparing Figure 13 (minus the lin-
earity queries) to Figure 14. The protocol goes from 8
queries (the original 14 minus 6 linearity queries) to 6
queries, though the real savings for the prover is in re-
ducing the 4 high-order queries (that is, queries to the
Fs2 component of π) to 3. Moreover, the veriﬁer saves
because it goes from generating pseudorandomness for 3
high-order queries (including γ2) to 2. Second, V avoids
transmitting a query (q3) that P can generate for itself.
This optimization offsets the consistency query, which is
computed over Z not Z/p (owing to the details of our
use of ElGamal [45, Appendix E]) and thus has roughly
twice as many bits as a PCP query.

4, then Rej(f ) ≥ 2

Deﬁne Dist(f ) to be the fraction of inputs on which
f disagrees with its “closest linear function” [8]. De-
ﬁne Rej(f ) to be the probability, over uniformly random
choices of x and y from the domain of f , that f (x)+f (y) (cid:54)=
f (x + y); Rej(f ) is the probability that f fails the linearity
test. As stated by Bellare et al. [8]:
• If Dist(f ) = δ, then Rej(f ) ≥ 3δ − 6δ2.
4, then Rej(f ) ≥ 2
• If Dist(f ) ≥ 1
9.
The above implies the following claim: for all δ(cid:48) ∈
4}, if Rej(f ) ≤ 3δ(cid:48) −
9 and 0 ≤ δ(cid:48) ≤ 1
{δ(cid:48) | 3δ(cid:48) − 6δ(cid:48)2 < 2
6δ(cid:48)2, then Dist(f ) ≤ δ(cid:48). (To see this, ﬁx δ(cid:48). Assume to the
contrary that δ = Dist(f ) > δ(cid:48). There are two cases, and
4, then Rej(f ) ≥ 3δ −
both contradict the given. If δ < 1
6δ2 > 3δ(cid:48)−6δ(cid:48)2. If δ ≥ 1
9 > 3δ(cid:48)−6δ(cid:48)2.)
From lemma A.5, the probability is greater than 1 −
√
F over the commit phase that Rej(˜fv) ≤ √
F. We call
such commit phases usual. Under a usual commit phase,
we can apply the claim just above. To do so, we assume
√
F = 3δ∗ − 6δ∗2
9, and we set δ∗ so that
that
and δ∗ ≤ 1
4 (such a δ∗ is guaranteed to exist because the
parabola is symmetric about δ = 1
4). The claim implies
that Dist(˜fv) ≤ δ∗, or that ˜fv is δ∗-close to linear.
Lemma A.7. If the PCP oracle π is known to be δ∗-close
to linear, then the linear PCP (Section A.1) with linearity
testing removed has soundness error κ > max{4δ∗ +
2|F|, 4δ∗ + 1|F|}.
Proof. This follows from the proof ﬂow that establishes
the soundness of linear PCPs, as in [5]. (A self-contained
example is in Appendix D of [45].) Those proofs ﬁrst
establish that if the linearity test passes with probabil-
ity higher than the soundness error, then π is δ-close to
linear, for some δ. However, if we are given that π is δ∗-
close to linear, then we can start those proofs midway
and obtain the soundness of π as κ.

F < 2

√

Proof of Theorem A.1. Lemma A.2 implies that there
exists an extractor function that determines a (possibly
incorrect) oracle ˜π such that, if V(cid:48) does not reject during
decommit, then with all but probability C, V(cid:48) receives
back ˜π(q1), . . . , ˜π(qµ). We can thus “pay” probability
C in the union bound (below) to assume that V(cid:48) hears
back from ˜π itself. This allows us to apply Lemma A.6,
F more probability (again
at which point we can “pay”
in the union bound below) to get that ˜π is δ∗-close to lin-
ear. (Applying the lemma requires that
9, and we
will verify below that this bound holds.) Now, we can ap-
ply Lemma A.7 to ρ runs of the PCP protocol, giving a
PCP soundness error of κρ. Thus, the probability that V(cid:48)
wrongly accepts a proof is bounded from above by:

F < 2

√

√

√

G = C +

F + κρ.

16

