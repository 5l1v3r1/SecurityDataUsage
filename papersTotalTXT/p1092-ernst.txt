Collaborative Veriﬁcation of Information Flow

for a High-Assurance App Store

Michael D. Ernst, René Just, Suzanne Millstein, Werner Dietl*,

Stuart Pernsteiner, Franziska Roesner, Karl Koscher,

Paulo Barros, Ravi Bhoraskar, Seungyeop Han, Paul Vines, and Edward X. Wu

Computer Science and Engineering

University of Washington, Seattle, WA, USA
{mernst, rjust, smillst, spernste, franzi,
supersat, pbfs, bhora, syhan, plvines,

edwardwu}@cs.washington.edu

ABSTRACT
Current app stores distribute some malware to unsuspecting users,
even though the app approval process may be costly and time-
consuming. High-integrity app stores must provide stronger guar-
antees that their apps are not malicious. We propose a veriﬁcation
model for use in such app stores to guarantee that the apps are free
of malicious information ﬂows. In our model, the software vendor
and the app store auditor collaborate — each does tasks that are
easy for her/him, reducing overall veriﬁcation cost. The software
vendor provides a behavioral speciﬁcation of information ﬂow (at a
ﬁner granularity than used by current app stores) and source code
annotated with information-ﬂow type qualiﬁers. A ﬂow-sensitive,
context-sensitive information-ﬂow type system checks the informa-
tion ﬂow type qualiﬁers in the source code and proves that only
information ﬂows in the speciﬁcation can occur at run time. The
app store auditor uses the vendor-provided source code to manually
verify declassiﬁcations.

We have implemented the information-ﬂow type system for An-
droid apps written in Java, and we evaluated both its effectiveness at
detecting information-ﬂow violations and its usability in practice. In
an adversarial Red Team evaluation, we analyzed 72 apps (576,000
LOC) for malware. The 57 Trojans among these had been written
speciﬁcally to defeat a malware analysis such as ours. Nonetheless,
our information-ﬂow type system was effective: it detected 96% of
malware whose malicious behavior was related to information ﬂow
and 82% of all malware. In addition to the adversarial evaluation,
we evaluated the practicality of using the collaborative model. The
programmer annotation burden is low: 6 annotations per 100 LOC.
Every sound analysis requires a human to review potential false
alarms, and in our experiments, this took 30 minutes per 1,000 LOC
for an auditor unfamiliar with the app.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
Copyright 2014 ACM 978-1-4503-2957-6/14/11 ...$15.00.
http://dx.doi.org/10.1145/2660267.2660343.

*Electrical and Computer Engineering

University of Waterloo, Waterloo, ON, Canada

wdietl@uwaterloo.ca

Categories and Subject Descriptors
D.2.4 [Software Engineering]: Software/program veriﬁcation;
D.4.6 [Security and Protection]: Information ﬂow control
General Terms
Veriﬁcation, Security
Keywords
Information ﬂow; static analysis; Android security; collaborative
veriﬁcation
1.

INTRODUCTION

App stores make it easy for users to download and run applica-
tions on their personal devices. App stores also provide a tempting
vector for an attacker. An attacker can take advantage of bugdoors
(software defects that permit undesired functionality) or can insert
malicious Trojan behavior into an application and upload the appli-
cation to the app store.

For current app stores, the software vendor typically uploads a
compiled binary application. The app store then analyzes the binary
to detect Trojan behavior or other violations of the app store’s terms
of service. Finally, the app store approves and publishes the app.
Unfortunately, the process offers few guarantees, and every major
app store has approved Trojans [6, 23, 28, 31, 33, 49, 52, 59].

We are exploring the practicality of a high-assurance app store
that gives greater understanding of, and conﬁdence in, its apps’ be-
havior in order to reduce the likelihood that a Trojan is approved and
distributed to users. A high-assurance app store would be particu-
larly valuable in certain sensitive settings. For example, corporations
already provide lists of apps approved for use by employees (often
vetted by ad hoc processes). The U.S. Department of Defense is
also actively pursuing the creation of high-assurance app stores.

Four contributing factors in the approval of Trojans by existing
app stores are: (1) Existing analysis tools are poorly automated and
hard to use; much manual, error-prone human effort is required.
(2) The vendor provides only a very coarse description of appli-
cation behavior in the form of permissions it will access: system
resources such as the camera, microphone, network, and address
book. This characterization provides insufﬁcient limitations on the
application’s behavior. (3) The binary executable lacks much se-
mantic information that is available in the source code but has been
lost or obfuscated by the process of compilation. (4) The vendor
has little incentive to make the application easy for the app store to
analyze and understand.

1092We have developed a new approach to verifying apps that ad-
dresses each of these factors.
(1) We have created a powerful,
ﬂow-sensitive, context-sensitive type system that veriﬁes informa-
tion ﬂows. The type system is easy to use and works with Java
and Android. (2) Our type system proves that apps conform to
ﬁner-grained information-ﬂow speciﬁcations than current app stores.
These speciﬁcations indicate not just which resources may be ac-
cessed but which information ﬂows are legal — how the resources
may be used by the program. (3) Our approach uses source code
rather than binaries, because source code provides more informa-
tion, enables more accurate and powerful analyses, and allows an
auditor to evaluate false positive warnings. While not all application
developers may wish to provide their source code to an app store,
we argue that this requirement is reasonable for app stores in certain
settings, e.g., in the context of corporate, military, government, or
medical applications. (4) We propose a collaborative veriﬁcation
methodology in which the vendor participates in and contributes to
the veriﬁcation process, rather than casting the vendor and the app
store in an antagonistic relationship. However, the developer is not
trusted: all information provided by the developer is veriﬁed.

We report on initial experience with this system, including an
adversarial Red Team exercise in which 5 corporate teams (funded
externally, not by us) were given access to our source code and
design documents then tasked with creating Trojans that would be
difﬁcult to detect. Our type system detected 82% of the Trojans,
and 96% of the Trojans whose malicious behavior was related to
information ﬂow. (We have identiﬁed an enhancement to our system
that would increase the latter number to 100%.) As with any pro-
gram analysis, a human must investigate tool warnings to determine
whether they are false positives. On average, it took an auditor
unfamiliar with the programs 30 minutes per KLOC to analyze
the information ﬂow policy and the tool warnings. The annotation
burden for programmers (application vendors) is also low.

Overall, our goal is to make it difﬁcult to write Trojans and easy
to determine when code is not a Trojan. Our information-ﬂow type-
checker cannot catch all malware, but it raises the bar for malware
authors and thus improve security.
1.1 Veriﬁcation of source code

An app store can be made more secure by requiring vendors
to provide their applications in source code, and then performing
strong veriﬁcation on that source code. While today’s commercial
app stores do not require source code, we discuss in Sect. 1.2 the
market forces that enable an app store such as we propose. This app
store would analyze the source code, compile it, and distribute it as a
binary (signed by the app store’s private key) to protect the vendor’s
intellectual property. Availability of source code fundamentally
changes the approval process in favor of veriﬁcation by providing
more information to both the analysis and the analyst.

Source code veriﬁcation is relevant for other domains than high-
integrity application stores. One public example of inserting mali-
cious behavior into an open source program is an attempt to insert
a backdoor in the Linux kernel [32]. As another example, Liu et
al. developed proof-of-concept malware as Chrome extensions [37],
which are essentially distributed as source code. The Heartbleed
bug appeared in open-source software. We believe that source code
analysis for security will become increasingly important, so it is
worthy of attention from security researchers.

Our approach is for Java source code, but since the type qualiﬁers
are persisted to the classﬁle, it would be possible to re-implement
our type system for bytecode in order to verify compiled apps.
1.2 Collaborative veriﬁcation model

Most app store approval policies assume an adversarial, or at least
non-cooperative, relationship between the developer and the app

Figure 1: The collaborative veriﬁcation model for information
ﬂow. The ﬂow policy is a high-level speciﬁcation that expresses
application behavior in terms of user-visible information ﬂows.

store. The developer delivers an app in binary form, and the app
store uses an opaque process to make a decision about whether to
offer the app on the app store.

We propose to augment existing app store approval processes with
a collaborative model (Fig. 1) for veriﬁcation of information ﬂow.
The application vendor provides more information to the auditor
(an app store employee). This information is easy for the vendor to
provide, but it would be difﬁcult for the auditor to infer. The auditor
is able to make a decision about information ﬂow more quickly and
with greater conﬁdence, which is advantageous to both parties.

As shown in Fig. 1, the auditor receives two artifacts from the ven-
dor. The ﬁrst vendor-provided artifact is the ﬂow policy, a high-level
speciﬁcation of the intended information ﬂows in the program from
the user point of view. In our experiments, this averaged 6 lines long.
For example, it might state that location information is permitted to
ﬂow to the network and that camera images may be written to the
local disk. Any information ﬂow not stated in the ﬂow policy is im-
plicitly forbidden. The second vendor-provided artifact is the source
code, annotated with information ﬂow type qualiﬁers. The annota-
tion burden is low: on average 6 annotations per 100 lines of code.
Both the annotations and the vendor are untrusted. Our implemen-
tation, Information Flow Type-checker (IFT), automatically ensures
that the type qualiﬁers are both permitted by the ﬂow policy and
are an accurate description of the source code’s behavior (modulo
any auditor-veriﬁed declassiﬁcations). If not, the app is rejected.
Unannotated apps are also rejected. Thus, the application vendor
must provide accurate type qualiﬁers and ﬂow policy.

The auditor has two tasks, corresponding to the two vendor-
provided artifacts. The ﬁrst task is to evaluate the app’s ﬂow policy.
This is a manual step, in which the auditor compares the ﬂow policy
to the app’s documentation and to any app store or enterprise poli-
cies. The app store analyst must approve that the requested ﬂows
are reasonable given the app’s purpose; apps with unreasonable ﬂow
policies are rejected as potential Trojans. The second task is to ver-
ify each declassiﬁcation, using some other veriﬁcation methodology
(e.g., [5]). Sect. 3.3.2 further describes the auditing process.

Not every app store will desire to differentiate itself through
increased security, and not every vendor will desire to participate
in high-assurance app stores. But market forces will enable such
stores to exist where there are appropriate economic incentives —
that is, whenever some organizations or individuals are willing to
pay more for increased security. Increased security is especially
important in sensitive contexts such as government, corporate, and
medical applications. Even if some vendors will never participate in
a high-assurance app store, we believe there is value in researchers
investigating and improving the practicality of such stores.

It makes economic sense for the vendor to annotate their code
and possibly to be paid a premium: based on our experience, the
effort is much less for the author of the code than for an auditor
who would have to reverse-engineer the code before writing down
the information about the information ﬂows. The effort is small

Annotated !.java!Flow policy!App store policies!Vendor"provides!App store"provides!Type-checker automatically veriﬁes:!•!Type qualiﬁers are compatible with ﬂow policy!•!Type qualiﬁers describe code behavior"(modulo declassiﬁcations)!App store employee manually veriﬁes:!•!Acceptable behavior!•!Declassiﬁcations are justiﬁed!1093compared to overall development time and is comparable to writing
types in a Java program. If the type qualiﬁers are written as the code
is ﬁrst developed, they may even save time by preventing errors or
directing the author to a better design.

Some vendors may be concerned with conﬁdentiality of their
source code. Large organizations already require their vendors to
provide and/or escrow source code. For Android apps, it is easy to
decompile a Java program from .class or .dex format, so even an app
in binary format does not protect the vendor’s algorithms, protocols,
and other secrets. These facts may reduce vendors’ reluctance to
provide source code.

The U.S. Department of Defense is also interested in high-assur-
ance app stores, for example through DARPA’s “Transformative
Apps” and “Automated Program Analysis for Cybersecurity,” along
with related software veriﬁcation programs such as “High-Assurance
Cyber Military Systems” and “Crowd-Sourced Formal Veriﬁca-
tion”. Our collaborative veriﬁcation model is novel and differs from
DARPA’s existing programs.
1.3 Threat model

While there are many different types of malicious activities, we
focus on Trojans whose undesired behavior involves information
ﬂow from sensitive sources to sensitive sinks. This approach is sur-
prisingly general: we have found that our approach can be adapted to
other threats, such as detecting when data is not properly encrypted,
by treating encryption as another type of resource or permission.

More speciﬁcally, IFT uses a ﬂow policy as a speciﬁcation or
formal model of behavior. If IFT issues no warnings, then the app
does not permit information ﬂows beyond those in the ﬂow policy
— that is, each output value is affected only by inputs speciﬁed in
the ﬂow policy. IFT issues a warning at every declassiﬁcation, and
manual checking is required for each one. IFT does not perform
labor-intensive full functional veriﬁcation, only information-ﬂow
veriﬁcation, which we show can be done at low cost.

Our threat model includes the exﬁltration of personal or sensitive
information and contacting premium services. However, it does not
cover phishing, denial of service, or side channels such as battery
drain or timing. It does not address arbitrary malware (such as
Slammer, Code Red, etc.). We treat the operating system, our type
checker, and annotations on unveriﬁed libraries as trusted compo-
nents — if they have vulnerabilities or errors, then an app could be
compromised even if it passes our type system. App developers and
app source code (including type qualiﬁers) are not trusted.

There have been previous studies of the kinds of malware present
in the wild [17, 64]. Felt et al. [17] classify malware into 7 distinct
categories based on behavior. Our system can catch malware from
the 4 most prevalent and important ones: stealing user information
(60%), premium calls or SMSs (53%), sending SMS advertising
spam (18%), and exﬁltrating user credentials (9%). The other 3
categories are: novelty and amusement (13%), search engine opti-
mization (2%), ransom (2%).

Our approach is intended to be augmented by complementary
research and app store activities that focus on other threats. Our
approach raises the bar for attackers rather than providing a silver
bullet. Sect. 2.9 discusses limitations of our system in greater detail.
1.4 Contributions

The idea of verifying information ﬂow is not new, nor is using a
type system. Rather, our contributions are a new design that makes
this approach practical for the ﬁrst time, and realistic experiments
that show its effectiveness. In particular, the contributions are:

We have proposed a collaborative veriﬁcation model that reduces
cost and uncertainty, and increases security, when investigating
the information ﬂow of apps submitted to an app store. Our work

explores a promising point in the trade-off between human and
machine effort.

We have extended information-ﬂow veriﬁcation to a real, unmod-
iﬁed language (Java) and platform (Android). Our design is easy
to use yet supports polymorphism, reﬂection, intents, defaulting,
library annotations, and other mechanisms that increase expressive-
ness and reduce human effort.

We have designed a mechanism for expressing information ﬂow
policies, and we have reﬁned the existing Android permission sys-
tem to make it less porous.

We have implemented our design in a publicly-available system
(http://types.cs.washington.edu/sparta/), and we have ex-
perimentally evaluated our work. Our system effectively detected
realistic malware targeted against it, built by skilled Red Teams. The
effort to use our system was low for both programmers and auditors:
our system is powerful, yet it requires less annotation overhead than
previous systems and is simpler to use and understand.
2.

INFORMATION FLOW TYPE-CHECKER
This section describes our implementation, called Information
Flow Type-checker (IFT), and the type system it enforces. IFT
guarantees that if a program is well typed, no information ﬂows
exist in the program beyond those expressed in the ﬂow policy that
expresses the high-level speciﬁcation. IFT is sound and conserva-
tive: if IFT approves a program, then the program has no undesired
information ﬂows, but if IFT issues a warning, then the program
might or might not actually have undesired information ﬂows at run
time. The guarantee is modulo human examination of a small num-
ber of declassiﬁcations, including ones about implicit information
ﬂow through conditionals.

As shown in Fig. 1, a programmer using IFT provides two kinds
of information about the information ﬂows in the program. First,
the programmer provides a ﬂow policy ﬁle, which describes the
types of information ﬂows that are permitted in the program (see
Sect. 2.3). For example, a simple app for recording audio to the ﬁle
system would have a ﬂow policy containing only RECORD_AUDIO
→FILESYSTEM. It would be suspicious if this app’s ﬂow policy
contained RECORD_AUDIO→INTERNET, because that ﬂow allows
audio to be leaked to an attacker’s server.

Second, the programmer writes Java type annotations to express
information-ﬂow type qualiﬁers. Each qualiﬁed type includes a
set of sensitive sources from which the data may have originated
and a set of sinks to which the data may be sent. For example, the
programmer of the audio recording app would annotate the type
of the recorded data with @Source(RECORD_AUDIO) @Sink(FILESYSTEM).
IFT uses type-checking over an information ﬂow type system to
verify that the annotated code is consistent with the ﬂow policy.
2.1 Types: sources and sinks

The type qualiﬁer @Source on a variable’s type indicates what
sensitive sources might affect the variable’s value. The type qualiﬁer
@Sink indicates where (information computed from) the value might
be output. These qualiﬁers can be used on any occurrence of a type,
including in type parameters, object instantiation, and cast types.

As an example, consider the following declaration:
@Source(LOCATION) @Sink(INTERNET) double loc;

The type of variable loc is @Source(LOCATION) @Sink(INTERNET) double.
The type qualiﬁer @Source(LOCATION) indicates that the value of loc
might have been derived from location information. The type qual-
iﬁer @Sink(INTERNET) indicates that loc might be output to the net-
work.

The arguments to @Source and @Sink are permissions drawn from
our enriched permission system (Sect. 2.2). The argument may be a
set of permissions to indicate that a value might combine information

1094@Source(ANY)

@Sink({})

Table 1: Additional sources and sinks used by IFT, beyond the
built-in 145 Android permissions.

@Source({INTERNET, LOCATION})

@Sink(INTERNET)

@Sink(FILESYSTEM)

Sources

Sinks

CONDITIONAL
DISPLAY
SPEAKER
WRITE_CLIPBOARD
WRITE_EMAIL
WRITE_LOGS

ACCELEROMETER
BUNDLE
LITERAL
MEDIA
PHONE_NUMBER
RANDOM
READ_CLIPBOARD
READ_EMAIL
READ_TIME
USER_INPUT

Both source and sink

CAMERA_SETTINGS
CONTENT_PROVIDER
DATABASE
FILESYSTEM
PARCEL
PROCESS_BUILDER
SECURE_HASH
SHARED_PREFERENCES
SQLITE_DATABASE
SYSTEM_PROPERTIES

@Source(INTERNET)

@Source(LOCATION)

@Sink({INTERNET, FILESYSTEM})

@Source({})

@Sink(ANY)

Figure 2: Partial qualiﬁer hierarchy for source and sink type
qualiﬁers @Source and @Sink.

from multiple sources or ﬂow to multiple locations. The special
constant ANY denotes the set of all sources or the set of all sinks; the
empty set denotes the absence of sources or sinks.
2.1.1 Subtyping
Adding type qualiﬁers to the Java type system only requires
extending the subsumption rule in a standard way; other Java typing
rules remain unchanged. A type qualiﬁer hierarchy indicates which
assignments, method calls, and overridings are legal, according to
standard object-oriented typing rules. Fig. 2 shows parts of the
@Source and @Sink qualiﬁer hierarchies.

@Source(B) is a subtype of @Source(A) iff B is a subset of A [10].
For example, @Source(INTERNET) is a subtype of @Source({INTERNET,
LOCATION}). This rule reﬂects the fact that the @Source qualiﬁer
places an upper bound on the set of sensitive sources that were
actually used to compute the value. If the type of x is qualiﬁed
by @Source({INTERNET, LOCATION}), then the value in x might have
been derived from both INTERNET and LOCATION data, or only from
INTERNET, or only from LOCATION, or from no sensitive source at all.
The opposite rule applies for sinks: @Sink(B) is a subtype of
@Sink(A) iff A is a subset of B. For example, the type @Sink({INTERNET,
FILESYSTEM}) indicates that the value is permitted to ﬂow to both
INTERNET and FILESYSTEM. This is a subtype of @Sink(INTERNET), as
the latter type provides fewer routes through which the information
may be leaked.

Based on these rules, the top type qualiﬁers of these hierarchies
are @Source(ANY) and @Sink({}), and the bottom type qualiﬁers are
@Source({}) and @Sink(ANY).
2.1.2 Polymorphism
Information ﬂow type qualiﬁers interact seamlessly with paramet-
ric polymorphism (Java generics). For example, a programmer can
declare

List<@Source(CONTACTS) @Sink(WRITE_SMS) String> myList;

to indicate that the elements of myList are strings that are obtained
from CONTACTS and that may ﬂow to WRITE_SMS.

IFT also supports qualiﬁer polymorphism, in which the type qual-
iﬁers can change independently of the underlying Java type. This
allows a programmer to write a generic method that can operate on
values of any information ﬂow type and return a result of a different
Java type with the same sources/sinks as the input. It also enables
qualiﬁer polymorphism even for non-generic Java methods.

For example, the method @PolySource int f(@PolySource int x)
can be passed an int with any sources, and the result has exactly
the same sources as the input. This qualiﬁer polymorphism can
be viewed as the declaration and two uses of a type qualiﬁer vari-
able. The implicit type qualiﬁer variable is automatically instan-
tiated by IFT at the point of use. Given variable netarg of type
@Source(INTERNET) int, in an invocation f(netarg) the type qualiﬁer
variable is instantiated to @Source(INTERNET) and the return type of
this method invocation is therefore @Source(INTERNET) int.

Polymorphism allows IFT to be context-sensitive.

2.2 Comparison to Android permissions

IFT’s permission model differs from the Android permission
model in three ways. (1) IFT’s permissions are statically guaran-
teed at compile time, whereas Android permissions are enforced
at run time, potentially resulting in an exception during execution.
If an app inherits a permission from another app with the same
sharedUserId, IFT requires that permission to be listed in the ﬂow
policy. (2) IFT’s permission ﬂows are ﬁner-grained than standard
Android manifest permissions. Android permits any ﬂow between
any pair of permissions in the manifest — that is, an Android pro-
gram may use any resource mentioned in the manifest in an arbitrary
way. (3) IFT reﬁnes Android’s permissions, as discussed in this
section.

Sinks and sources for additional resources

2.2.1
IFT adds additional sources and sinks to the Android permissions.
For example, IFT requires a permission to retrieve data from the
accelerometer, which can indicate the user’s physical activity, and
to write to the logs, which a colluding app could potentially read.
Table 1 lists the additional sources and sinks. We selected and
reﬁned these by examining the Android API and Android programs,
and it is easy to add additional ones. Our system does not add much
complexity — it only adds 26 (18%) to the 145 Android permissions.
Some researchers feel that the Android permission model is al-
ready too complicated for users to understand [16], but our per-
spective is that of a full-time auditor who is trained to analyze
applications. The ﬂow policy is examined once per application by
that skilled engineer, not on every download by a user, so the total
human burden is less (Sect. 3.3.2 provides empirical measurements).
The more detailed ﬂow policy yields more insight than standard
Android permissions, because the ﬂow policy makes clear how each
resource is used, not just that it is used.

We now discuss two permissions, LITERAL and CONDITIONAL,

whose meaning may not be obvious.

Literal. The LITERAL source is used for programmer-written
constants (in the source code, Android manifest, or resource ﬁles)
such as "Hello world!", and for any variable whose value is com-
puted using only those constants. This enables IFT to distinguish
information derived from the program source code from other in-
puts. Program literals are not trusted, since the app vendor may be
malicious. The ﬂow policy shows how they are used in the program.
Conditional. The CONDITIONAL sink is used for conditional
expressions — every value used in a conditional expression ﬂows to
that sink. This enables IFT to raise a warning at locations where the
control ﬂow of the program branches on sensitive information. The
auditor reviews those warnings to detect implicit information ﬂows,
as explained in greater detail in Sect. 2.7.

10952.2.2 Restricting existing permissions
The standard Android permissions might be too coarse-grained to
express the developer’s intention. For example, Android’s INTERNET
permission represents all reachable hosts on the Internet. IFT allows
this permission to be parameterized with a domain name, as in IN-
TERNET(“*.google.com”). Other permissions can be parameterized in a
similar style, and the meaning of the optional parameter varies based
on the permission it reﬁnes. For example, a parameter to FILESYS-
TEM represents a ﬁle or directory name or wildcard, whereas the
parameter to SEND_SMS represents the phone number that receives
the SMS. Other permissions that can be parameterized include
CONTACTS, *_EXTERNAL_FILESYSTEM, NFC, *_SMS, and USE_SIP.
Several of the additional sources and sinks (Table 1) can also be
parameterized, such as USER_INPUT to distinguish sensitive from
non-sensitive user input.

IFT performs intraprocedural constant value propagation to en-

able precise analysis of parameterized permissions.
2.3 Flow policy

A ﬂow policy is a list of all the information ﬂows that are permit-
ted to occur in an application. A ﬂow policy ﬁle expresses a ﬂow
policy, as a list of ﬂowsource → ﬂowsink pairs. Just as the Android
manifest lists all the permissions that an app uses, the ﬂow policy
ﬁle lists the ﬂows among permissions and other sensitive locations.
Consider the “Block SMS” application of Table 5, which blocks
SMS messages from a blacklist of blocked numbers and saves them
to a ﬁle for the user to review later. Its ﬂow policy must contain
READ_SMS→FILESYSTEM to indicate that information obtained us-
ing the READ_SMS permission is permitted to ﬂow to the ﬁle system.
The ﬂow policy speciﬁes what types are legal. Every ﬂow in
a program is explicit in the types of the program’s expressions.
For example, if there is no expression whose type has the type
qualiﬁers @Source(CAMERA) @Sink(INTERNET), then the program never
sends data from the camera to the Internet (modulo conditionals
and transitive ﬂows). The expression’s type might be written by a
programmer or might be automatically inferred by IFT.

IFT guarantees that there is no information ﬂow except what is
explicitly permitted by the ﬂow policy. If the type of a variable or
expression indicates a ﬂow that is not permitted by the ﬂow policy,
then IFT issues a warning even if the program otherwise would
type-check. For example, the following declaration type-checks, but
IFT would still produce an error unless the ﬂow policy permits the
CAMERA→INTERNET ﬂow:

@Source(CAMERA) @Sink(INTERNET) Video video = getVideo();

Transitive ﬂows. Transitive ﬂows through on-device source-sink
pairs must be explicitly written in the ﬂow policy. This is because
apps can use on-device sinks to whitewash sensitive information.
For example, if a ﬂow policy permits USER_INPUT→FILESYSTEM
and FILESYSTEM→INTERNET, then an application might write user
input to a ﬁle and then send the contents of that ﬁle to a malicious
server. Therefore, the transitive ﬂow USER_INPUT→INTERNET must
be explicitly stated in the ﬂow policy.

Parameterized permissions (Sect. 2.2.2) reduce the number of
transitive ﬂows. For example, if user input is only written to
ﬁles in the notes directory (USER_INPUT→FILESYSTEM(“notes/*”))
and only ﬁles in the cat-photos directory are sent to the Internet
(FILESYSTEM(“cat-photos/*”)→INTERNET), then the transitive ﬂow
USER_INPUT→FILESYSTEM is not required.

On-device source-sink pairs involving resources that may be ac-
cessed by other apps could be used by colluding apps to leak infor-
mation. To prevent this, the ﬂow policies of all apps on a device or
in an app store are checked against each other for inter-app transitive
ﬂows. If a transitive ﬂow is found that violates a ﬂow policy of an

app, then one or more apps may need to be excluded or rewritten.
In practice, app stores will specify standard policies for ﬂows in-
cluding these source-sink pairs, so that developers can avoid writing
conﬂicting apps.

An off-device sink, such as a website or the recipient of an SMS,
might leak data to some sink not allowed by the ﬂow policy. Off-
device sinks must be either trusted or veriﬁed by other means.
2.4 Inference and defaults

A complete type consists of a @Source qualiﬁer, a @Sink qualiﬁer,
and a Java type. To reduce programmer effort and code clutter, most
of the qualiﬁers are inferred or defaulted rather than written as type
annotations. A programmer need not write type annotations within
method bodies, because such types are inferred by IFT. For method
signatures and ﬁelds, a programmer generally writes either @Source
or @Sink, but not both. We now explain the inference and defaulting
features. For experimental measurements, see Sect. 3.3.1.
2.4.1 Type inference and ﬂow-sensitivity
A programmer does not write information ﬂow types within

method bodies. Rather, local variable types are inferred.

IFT implements this inference via ﬂow-sensitive type reﬁnement.
Each local variable declaration (also casts and resource variables)
defaults to the top type qualiﬁers, @Source(ANY) @Sink({}). At every
properly-typed assignment statement, the type of the left-hand side
is ﬂow-sensitively reﬁned to that of the right-hand side, which must
be a subtype of the left-hand side’s declared type. The reﬁned type
applies until the next side effect that might invalidate it.

Consider the following simple method:

void process(@Source(INTERNET) int netint,

@Source(LOCATION) int locint) {

// x is defaulted to @Source(ANY) @Sink({}) int

int x;
x = netint; // x is refined to @Source(INTERNET) int
x = locint; // x is refined to @Source(LOCATION) int

}

Flow-sensitive type reﬁnement spares the programmer from writing
type qualiﬁers on local variable x, and the system automatically
determines the most precise type in each context.

IFT limits type inference to method bodies to ensure that each
method can be type-checked in isolation, with a guarantee that the
entire program is type-safe if each method has been type-checked.
It would be possible to perform a whole-program type inference,
but such an approach would be heavier-weight, would need to be
cognizant of cooperating or communicating applications, could
cause a change in one part of a program to cause new type-checking
errors elsewhere, and would provide fewer documentation beneﬁts.
2.4.2 Determining sources from sinks and vice versa
If a type is annotated with only a source or only a sink, the other
qualiﬁer is ﬁlled in with the most general value that is consistent
with the ﬂow policy. If the programmer writes @Source(α), IFT
defaults this to @Source(α) @Sink(ω) where ω is the set of sinks that
all sources in α can ﬂow to. Similarly, @Sink(ω) is defaulted to
@Source(α) @Sink(ω) where α is the set of sources allowed to ﬂow
to all sinks in ω. Defaults are not applied if the programmer writes
both a source and a sink qualiﬁer.

Suppose the ﬂow policy contains the following:

CAMERA -> DISPLAY,DATABASE
LOCATION -> DATABASE

Then these pairs are equivalent:

@Source({LOCATION}) = @Source({LOCATION}) @Sink(DATABASE)
@Sink(DATABASE) = @Source({CAMERA,LOCATION}) @Sink(DATABASE)
This mechanism is useful because oftentimes a programmer
thinks about a computation in terms of only its sources or only

1096Table 2: Default information ﬂow qualiﬁers for unannotated types.

Location
Method parameters & receivers
Return types
Fields
null
Other literals
Type arguments
Upper bounds
Local & resource variables

Default information ﬂow qualiﬁer

@Sink(CONDITIONAL)
@Source(LITERAL)
@Source(LITERAL)
@Source({}) @Sink(ANY)
@Source(LITERAL)
@Source(LITERAL)
@Source(ANY) @Sink({})
@Source(ANY) @Sink({})

its sinks. The programmer should not have to consider the rest of the
program that provides context indicating the other end of the ﬂow.
An example of a method that uses only a @Source qualiﬁer is the
File constructor: a newly-created readable ﬁle should be annotated
with @Source(FILESYSTEM), but there is no possible @Sink qualiﬁer
that would be correct for all programs. Instead, the @Sink qualiﬁer is
omitted, and our defaulting mechanism provides the correct value
based on the application’s ﬂow policy.

This defaulting mechanism is essential for annotating libraries.
We wrote manual annotations for 10,470 methods of the Android
standard library. Only 7 of the API methods annotated so far use
both a @Source and a @Sink qualiﬁer. For example,

Camera.setPreviewDisplay(

@Source(CAMERA) @Sink(DISPLAY) SurfaceHolder holder)

The parameter holder both receives photos from the camera and
displays them.

This mechanism can be viewed as another application of type
polymorphism: defaulting of types depends on the ﬂow policy and
the same source code can be reused in different scenarios by using a
different ﬂow policy.
2.4.3 Defaults for unannotated types
Table 2 shows the default qualiﬁers for completely unannotated
types. When the default is only a source or only a sink, the other
qualiﬁer is inferred from the ﬂow policy as explained in Sect. 2.4.2.
Most unannotated types (including ﬁeld types, return types, generic
type arguments, and non-null literals) are given the qualiﬁer @Source(
LITERAL). This is so that a simple computation involving only con-
stants does not require annotations.

As is standard, the null literal is given the bottom type qualiﬁers

@Source({}) @Sink(ANY), enabling an assignment to any variable.
2.5 Declassiﬁcations

Every sound static analysis is conservative: that is, there exists
source code that never misbehaves at run time, but the static analysis
cannot prove that fact and issues a warning about possible misbe-
havior. Every downcast in a Java program is an example of such
conservatism in the Java type system. In the context of informa-
tion ﬂow analyses, an example would be a database: in general, a
database query can return arbitrary sensitive data, but application
invariants might guarantee that a particular query always returns
non-sensitive data. IFT would warn about use of any database query
result in a context that could leak the result, but in the example the
warning would be a false positive.

In order to suppress a warning that is a false positive, the developer
declassiﬁes data that was typed too conservatively using a downcast.
The developer is required by the app store to write a justiﬁcation for
each declassiﬁcation. The app store auditor manually veriﬁes both
the justiﬁcation and the declassiﬁcation. Thus, the auditor validates
the developer’s claim that the code is well-behaved for some reason
that is beyond the precision of the type checker.

In 11 Android apps (9437 LOC), IFT suffered 26 false positives,

or fewer than 3 per 1,000 LOC (see Sect. 3.3.1).
2.6 Indirect control ﬂow

Indirect control ﬂow, for example in reﬂection, intents, or ex-
ception handling, is challenging for a static analysis. IFT soundly
handles these constructs through additional analyses and conserva-
tive assumptions.

IFT analyzes Java reﬂection to determine the target method of a
reﬂective call. This enables a downstream analysis, such as IFT’s
information-ﬂow type-checking, to treat the reﬂective code as a
direct method call, which has a much more precise annotated signa-
ture than does Method.invoke. IFT’s analysis resolves the reﬂective
call to a single concrete method in 96% of cases in our experiments,
including malicious examples where reﬂection is used intentionally
as a form of code obfuscation. The library’s conservative annota-
tions for Method.invoke ensure that any unresolved reﬂective call is
treated soundly.

Intents are an Android mechanism for interprocess communica-
tion, and they can also create processes (Android activities). To
handle intents, we extended IFT with map types (similar to record
types) that represent the mappings of data in an intent payload. Each
app implements intent-receiving methods, and their type signatures
act as interface speciﬁcations and permit modular checking. As long
as new apps are consistent with annotations on previously-checked
apps that they may communicate with, the old apps need not be
re-checked.

IFT soundly handles other indirect control ﬂows, such as excep-
tion handling. For example, types in catch clauses are enforced to
be supertypes of any exception they may catch.
2.7 Implicit information ﬂow

Implicit information ﬂow through conditionals can leak private
information. For example, consider the following code and a ﬂow
policy containing LITERAL→INTERNET:

@Source(USER_INPUT) long creditCard = getCC();
final long MAX_CC_NUM = 9999999999999999;
for (long i = 0 ; i < MAX_CC_NUM ; i++) {

if (i == creditCard)

sendToInternet(i);

}

This code leaks the credit card number to the Internet using the ﬂow
LITERAL→INTERNET and the fact that i is only sent to the Internet
when i == creditCard evaluates to true.

The classic approach of Denning and Denning [11] to detect im-
plicit information ﬂow is to taint all computations in the dynamic
scope of a conditional statement with all the sources from the con-
ditional’s predicate. This includes all statements in the body of
the conditional and all statements in any method directly or indi-
rectly called by the body. Over-tainting of computations within
the dynamic scope of conditionals leads to many false positive
alarms. These alarms occur far from the conditional statement or
other statement(s) that caused them. In order to determine whether
an implicit information ﬂow truly occurs, the auditor has to work
backward from the location of an alarm to the conditional statement
or statements that caused it.

In our approach, the auditor reviews every conditional statement
that uses a sensitive source in its predicate. The auditor ﬁrst decides
whether the knowledge about the boolean result of the predicate
is sensitive information. For example, checking whether a credit
card number has 16 digits does not reveal anything sensitive — in
this case, the auditor need not review the body of the conditional.
However, if the auditor decides that the conditional predicate is
sensitive, he/she must rule out any implicit information ﬂow that
violates the ﬂow policy. In order to determine whether an implicit

1097information ﬂow truly occurs, the auditor works from the body of the
conditional forward to all statements in dynamic scope that might
implicitly leak information.

In both the classic approach and our approach, the auditor has
to carefully review the dynamic scope of the conditional body to
rule out false positives. However, unlike the classic approach, in
our approach, the reviewer is aware of the context of the conditional
and can make a more informed decision about whether an implicit
information ﬂow might occur at runtime.

The auditors in our experiments (Sect. 3.3.2) felt that our approach
was easier for them than the classic one. They preferred to think
about an entire conditional expression at once rather than statement-
by-statement. Oftentimes, examining a conditional expression en-
abled the auditors to rule out bad behavior without needing to exam-
ine any statement in its dynamic scope; this was particularly true for
simple conditionals such as tests against null.
2.8 Implementation

IFT is implemented as a pluggable type system built on top of the
Checker Framework [12] and uses standard Java type annotations.
The implementation of IFT consists of 3,731 lines of Java, plus an-
notations for 10,470 library methods. IFT’s source code is available
at http://types.cs.washington.edu/sparta/. Version 0.9.6
was used for the experiments presented in this paper.
2.9 Limitations

IFT is focused on Trojans that cause an undesired information
ﬂow, as indicated by the threat model of Sect. 1.3. IFT should be
used in conjunction with complementary techniques that address
other security properties. This section discusses further limitations.
As with any static analysis, IFT’s soundness guarantee only ex-
tends to code that is analyzed at compile time. Use of native code
and un-analyzed Android activities requires a different analysis or
trusted annotations that describe the information ﬂows induced by
those components. IFT currently forbids dynamic code loading,
because IFT type-checks source code. Dynamic class loading could
be soundly allowed if the loaded classes type-check and their public
signatures are the same as were assumed at compile time. To achieve
this would require load-time type-checking of compiled (.class or
.dex) ﬁles. Re-implementing the IFT type rules for binaries would
be an engineering challenge, but not a conceptual one.

Our cooperative veriﬁcation model means that the vendor knows
one of the techniques that the app store will use to verify an app. This
knowledge might permit a malicious developer to design Trojans that
are beyond the capabilities of IFT or that exploit IFT’s limitations.
As with many security mechanisms, human judgment can be a
weak link. A malicious developer could write a misleading expla-
nation for an information ﬂow in the ﬂow policy or for a declassiﬁ-
cation, in an effort to convince the auditor to approve malware. Our
work does not address how to establish an app store’s policies.

Despite these limitations, use of IFT increases the difﬁculty of
hiding Trojans in source code. The requirement that code be ac-
cepted by IFT may also make the Trojan more likely to be detected
using other tools or manual veriﬁcation.
2.10 Future work

We plan to enrich ﬂow policies in three ways, while retaining
the simple and high-level ﬂavor of these speciﬁcations. (1) We will
reﬁne permissions, such as splitting the WRITE_CONTACTS permis-
sion so that separate policies can be speciﬁed for email addresses,
phone numbers, and notes ﬁelds. (2) The ﬂow policy will indicate
not just the endpoints of the information ﬂow, but an entire path.
For example, it might be valid to send personal information to the
Internet only if it has passed through an encryption module ﬁrst. (3)

The ﬂow policy will indicate conditional information ﬂows, such
as permitting information ﬂow from the microphone to the network
only when the user presses the “transmit” button.
3. EMPIRICAL STUDIES

This section describes three different evaluations of IFT. Sect. 3.1
describes the effectiveness of IFT in an adversarial Red Team evalu-
ation. Sect. 3.2 evaluates the effectiveness and efﬁciency of IFT in a
control team study. Sect. 3.3 presents a study of IFT’s usability for
vendors during the development of apps and for app store auditors
while reviewing those apps.
3.1 Red Team evaluation

The sponsor of our research (DARPA) wished to evaluate IFT. To
this end, they hired ﬁve development companies (in the following
referred to as Red Teams) to create Android applications with and
without Trojans. We had neither control over the Red Teams nor
any knowledge of the malware they were creating. While they
were creating the malware, the Red Teams had access to a current
version of IFT, including source code, documentation, and our own
analysis of IFT’s vulnerabilities. A total of 20 people worked on
the Red Teams. On average they had more than 2 years of Android
experience. Other than two interns, they hold BS or MS degrees
and work full-time as computer security analysts. Most have been
exposed to information ﬂow theory, with the maximum experience
being 6 years working with information ﬂow.

The Red Teams created both malware and non-malware apps.
The malware had to be written in Java. The Red Teams started out
by surveying real-world mobile malware. They tried to produce
diverse malware, including malware that is representative of that
found in the wild, novel malware that they devised, and malware
speciﬁcally targeting the limitations of IFT. They had two goals: to
evaluate how well IFT might work in practice, and to see how IFT
could be defeated.

Overall, the Red Teams created 72 Java applications. Our sponsor
provided us with the apps in ﬁve batches over an eight-month period.
For each batch, we were given a few hours or days to analyze the
applications with IFT. The Red Teams were given our results for the
ﬁrst three batches, and they used this information to create malware
that was harder for IFT to ﬁnd.

We received the applications in source code form. IFT does not
run the applications. The applications were not obfuscated, but
they were also not well-documented, and the Red Teams had no
motivation to make them understandable. The user documentation
was only a few sentences stating the general purpose of the app,
but usually omitting signiﬁcant details about the functionality —
considerably less than a typical app has in an app store. The Red
Teams also had no incentive to provide code documentation or fol-
low a speciﬁc design — code comments and design documentation
were absent, and the apps contained neither ﬂow policies nor the
information ﬂow annotations used by IFT.
3.1.1
Of the 72 apps, 57 are malicious (see Table 5 for details):
• 47 contain malicious information ﬂow that is at odds with the
application’s description. IFT detected 96% of this malware.
◦ 19 use an information ﬂow between Android permissions;
◦ 17 use an information ﬂow involving our new sources or
◦ 11 use an information ﬂow involving parameterized sources

Summary of results

sinks; see Sect. 3.1.3.

see Sect. 3.1.2.

or sinks; see Sect. 3.1.4.

• 10 are not detected by IFT because the malware is not related

to information ﬂow; see Sect. 3.1.5.

10983.1.2 Unjustiﬁed information ﬂows
For 19 apps, the Android permissions in the manifest can be
justiﬁed based on the purpose of the app; however, the apps leak
information from one Android permission to another. For example,
the app 2D Game has a malicious ﬂow, READ_EXTERNAL_STORAGE
→INTERNET. The app accesses the external storage to load photos
in the game, so READ_EXTERNAL_STORAGE is justiﬁed. The app
description states that the app sends high scores to a leaderboard
on a server, so INTERNET is justiﬁed. The description says nothing
about uploading the photos directly to the server, nor would a user
expect the game to do so. Therefore, READ_EXTERNAL_STORAGE
→INTERNET is a malicious ﬂow.

An unjustiﬁed Android permission would be grounds for rejection
from a high-assurance app store; however, some permissions can
be easily justiﬁed. For example, one of the Red Teams used an
automatic update functionality as a reason to justify the INTERNET
permission. In our experiments, we did not reject any app based
on requested permissions since none of them were at odds with the
app’s purpose or description.
3.1.3 Information ﬂows using new sources/sinks
For 17 apps, the malicious information ﬂow is apparent only via
use of the additional permissions listed in Table 1. For example,
RSS Reader has a malicious ﬂow of RANDOM→VIBRATE. RANDOM
is not an Android permission and the description of the app gives no
reason to use a random number. The app is supposed to vibrate the
phone when one of the user’s feeds is updated, so VIBRATE is listed
in the manifest ﬁle as expected. However, the app’s user would not
expect the app to cause random vibrations, so RANDOM→VIBRATE
is malicious.

For two apps (PGP Encryption 2 and Password Saver) the leaked
information is allowed to ﬂow to the sensitive sink, but only if it is
encrypted ﬁrst. IFT cannot yet express this property, but Sect. 2.10
describes how to extend IFT to catch this sort of vulnerability.
3.1.5 Malware not related to information ﬂow
The malware in 10 out of the 57 malicious applications is not
related to information ﬂow — these apps do not exhibit an unjustiﬁed
information ﬂow and implement types of attacks that are out of the
scope of IFT. For example, Backup transposes digits in a phone
number during backup. This is a functional correctness error, which
IFT does not address. In a high-assurance app store, IFT would be
used with complementary tools designed to ﬁnd malware not related
to information ﬂow. The auditor’s conﬁdence that an app has no
information-ﬂow malware would let the auditor spend more time
looking for other malware, such as denial of service.

The CONDITIONAL sink detected triggers for malicious behavior
in 2 apps. Countdown Timer and System Monitoring 3 triggered
non-information-ﬂow related malware after receiving SMSes with
certain characters.

Other apps used time of day, random numbers, or location to
trigger information-ﬂow malware. We found these triggers while
reviewing the conditional statements.
3.1.4 Flows using parameterized permissions
For 11 apps, the malicious information ﬂow is apparent only via
use of parameterized permissions (Sect. 2.2.2). For example, in
GPS 3, the location data should only ﬂow to maps.google.com, but
it also ﬂows to maps.google-cc.com. To express this, the ﬂow policy
lists LOCATION→INTERNET(“maps.google.com”) but not LOCATION→
INTERNET(“maps.google-cc.com”). Another app, Geocaching, should
only send data from speciﬁc geocaching NFC tags to the server,
but it collects all NFC tags in range and sends them to the server,
NFC(“*”)→INTERNET.

3.1.6 Bugdoors
In 8 apps, IFT found a bugdoor (undesired, exploitable functional-
ity) that the Red Team was unaware of. Even though the Red Team
had written and/or modiﬁed the app before presenting it to us for
analysis, they had not noticed these. GPS 1 passes the device ID as
a way-point ID to the remote server. This allows the remote server
to correlate location to speciﬁc devices and to other information
collected using the device ID. Password Saver saves unencrypted
passwords in shared preferences, where they are accessible to other
applications on the device.

Furthermore, 6 apps exﬁltrated sensitive data to the log, which
It does, how-
Android does not require a permission to write.
ever, require a permission in our ﬁner-grained permission model
(see Sect. 2.2). Consequently, IFT reported an information ﬂow
violation.
3.2 Control team study

For the third and ﬁfth batches of applications, our sponsor hired
a control team to evaluate the applications and search for malware.
The control team consisted of 4 PhD students with, on average, 11
years of Java experience and .5 years of Android experience — very
similar to our team. The control team used both static and dynamic
analysis tools, including Androguard, Eclipse, and emulators.

For the third batch of apps, the control team took an average of
9.5 hours per application to declare it malicious or benign, and their
answer was right 60% of the time. Our team, using IFT plus simple
tools that search for suspicious code, spent 42 minutes on average
per application and correctly classiﬁed 80% of the applications.

For the ﬁfth batch of apps, the control team took an average of 2.3
hours per application and correctly classiﬁed 63% of the apps. Our
team spent 1.25 hours per app on average and correctly classiﬁed
75% of the apps.
3.3 Usability study

The collaborative veriﬁcation model and IFT provide guarantees,
but can they be used in the real world? This section presents three
studies addressing this question. Sect. 3.3.1 measures the time to
add information-ﬂow type annotations to apps. Sect. 3.3.2 measures
how quickly and accurately the app store auditors can approve or
reject apps. Sect. 3.3.3 evaluates how hard it is for information-ﬂow
type system novices to learn to use IFT.
3.3.1 Annotation burden
In order to estimate the cost of adding information ﬂow anno-
tations, ﬁve members of our team annotated 11 arbitrarily chosen
applications. 1 app was a malicious app written by the Red Teams
and 10 apps were benign apps written by third-party developers or
the Red Teams. Each annotator was given an unannotated applica-
tion and a ﬂow policy ﬁle. The annotators annotated the application
until IFT issued no more warnings; if they found malware, they used
a declassiﬁcation and continued the task. The annotators had never
seen the applications before, so the vast majority of their time was
spent reverse-engineering the application.

Table 3 shows the results. On average, the annotators annotated
6 lines of code per minute, which was primarily the effort to un-
derstand the code. This compares favorably with industry-standard
averages of about 20 lines of delivered code per day [7, 40, 54, 29].
(On average, the annotators annotated 20 lines of code in 3.3 min-
utes.) Recall that in the proposed collaborative veriﬁcation model,
the app’s developer would annotate the code, which would be faster.
The annotated code contained on average 6 annotations per 100
lines of code. This is less than 1/4 of the annotation burden for
Jif, another information-ﬂow system for Java [2, 9, 63]. In our
case studies, the annotator wrote an annotation in 4% of the places

1099Table 3: Results from the annotation burden experiment.

App Name

LOC

CameraTest
Shares Pictures†
BusinessCard
Calculator 3
Dynalogin
TeaTimer
FourTrack
RingyDingy
VoiceNotify
Sky
Pedometer

Total

92
141
183
520
625
1098
1108
1322
1360
1441
1547

9437

Time
(min.)
20
10
10
40
300
295
120
180
185
240
165

.22
.07
.05
.08
.48
.27
.11
.14
.14
.17
.11

De-
class.

1
0
1
0
0
7
0
2
11
5
0

Annotations

src.+sink=total
.12
6 + 5 = 11
.09
12 + 0 = 12
.05
9 + 0 = 9
.01
7 + 0 = 7
.11
66 + 0 = 66
.05
51 + 3 = 54
.04
27 + 18 = 45
.05
41 + 26 = 67
.08
68 + 44 =112
.05
33 + 35 = 68
.08
71 + 58 =129

ratio
6%
4%
3%
1%
6%
3%
3%
4%
4%
3%
5%

1565

.17

26 391+189=580

.06

4%

Boldfaced numbers (time, annotations) are per line of code. “Declass.” is declassiﬁca-
tions. Annotation ratio compares the number of annotations written to how many could
have been written — the number of uses of types in the app’s source code. Through-
out this paper, lines of code (generated using David A. Wheeler’s “SLOCCount”) omit
whitespace and comment lines. †Malicious applications.
Table 4: Results from the collaborative app store experiment.
App Name

Accepted?

Reviewed

Review

CameraTest
Shares Pictures†
BusinessCard
Calculator 3
Dynalogin
TeaTimer
FourTrack
RingyDingy
VoiceNotify
Sky
Pedometer

time (min.) Declass.
26
5
11
11
10
50
61
20
35
25
15

.28
.04
.06
.02
.02
.05
.06
.02
.03
.02
.01

1
0
1
0
0
7
0
2
11
5
0

Cond.
0
0
1
3
10
20
11
11
73
19
65

0%
0%
14%
5%
37%
22%
14%
9%
47%
15%
57%

Accept
Reject
Accept
Accept
Accept
Accept
Accept
Accept
Accept
Accept
Accept

Total

269

.03

27

213

27%

Boldfaced times are per line of code. All declassiﬁcations were reviewed. The Re-
viewed Cond. column gives the number and percentage of conditions with a sensitive
source, all of which were reviewed. †Malicious applications.
an annotation could have been written; the other locations were
defaulted or inferred.

The number of annotations per application is not correlated with
the number of lines of code nor the number of possible annotations.
Rather, the number of annotations is dependent on how, and how
much, information ﬂows through the code. When information ﬂow
is contained within procedures, type inference reduces the number
of annotations required (Sect. 2.4.1).
3.3.2 Auditing burden
Another cost in the use of a static tool is the need to examine
warnings to determine which ones are false positives. This cost
falls on the developer who writes declassiﬁcations to suppress false
positives, then again on the auditor who must review the declassi-
ﬁcations. We wished to determine the cost of approving an app,
which in addition to reviewing declassiﬁcations requires auditing
the ﬂow policy and reviewing implicit information ﬂow.

Two graduate students acted as app store auditors. Neither one
had previously used IFT or a similar framework. The auditors had
never before seen the applications that they reviewed, and they did
not know whether the apps were malware. The review was split into
two phases: a review of the app description and ﬂow policy, then a
review of the declassiﬁcations and conditionals in the source code.
This is exactly the same workﬂow as an app store auditor. Table 4
summarizes the results.

The ﬁrst part of the review ensures that the description of the
app matches the ﬂow policy. An auditor begins by reading the app

description and writing a ﬂow policy; then the auditor compares that
to the submitted ﬂow policy. If there is any difference, the developer
must modify the description or ﬂow policy. The ﬂow policy review
took 35% of total auditing time.

The second part of the review ensures that all declassiﬁcations
and implicit information ﬂows are valid. The auditor ﬁrst reviewed
the developer-written justiﬁcation for each declassiﬁcation. Only
CameraTest had one rejected justiﬁcation, which the developer rec-
tiﬁed in a re-submission. The other justiﬁcations were accepted
by the auditors. Then, the auditors investigated possible implicit
information ﬂow via conditionals (Sect. 2.7). Out of a total of 789
conditional statements, only 27% contained data from a sensitive
source, so the auditors only reviewed those to rule out implicit in-
formation ﬂows. For some of these conditionals, the auditor did
not need to review the conditional body, because the conditional
expression did not reveal anything about the content of the source.
For example, 41 of the 271 conditionals with sensitive data (15%)
were comparisons against null.

After the experiment, auditors mentioned that there were many
unexpected ﬂows, which ended up being necessary. Also, they
wanted clear guidelines to accept or reject ﬂow policies. We believe
that both concerns will be resolved as auditors and app stores get
more experience; this was their ﬁrst time to audit apps.

We have not evaluated the effort of analyzing an update to an
existing app, but this should be low. An update can re-use most
or all of the previous ﬂow policy speciﬁcation, annotations, and
justiﬁcations for declassiﬁcations.
3.3.3 Learnability
IFT integrates smoothly with Java and re-uses type system con-
cepts familiar to programmers. Nonetheless, learning about informa-
tion ﬂow, or learning how to use IFT, may prove a barrier to some
programmers. The programmers in the study of Sect. 3.3.1 were
already familiar with Android and IFT. We wished to determine
how difﬁcult it is to come up to speed on IFT.

We conducted a study involving 32 third-year undergraduate
students enrolled in an introductory compilers class. 60% of the
students had no previous experience with Android. They received a
two-hour presentation, then worked in pairs to annotate an app of
1000–1500 LOC. The apps came from the f-droid.org catalog;
we used F-Droid because we do not have access to the source code
of most apps in the Google Play Store.

The students’ task was to learn Android, information ﬂow theory,
and IFT, then to reverse-engineer and to annotate the app such that
IFT issues no warnings. On average the task required 15 hours.
The students reported that the ﬁrst annotations were the most time-
consuming because they were still learning to understand IFT; after
that the task was easier.

This learnability study was extremely preliminary, but it does
suggest that a developer with little experience can quickly come up
to speed on IFT.
3.4 Lessons learned
This section states a few lessons we learned during our experiments.
Generality of our analysis. Our information-ﬂow based ap-
proach turned out to be surprisingly general. IFT revealed malicious
data ﬂow of the payload as well as the injected triggers. We found,
for instance, malware in applications that give wrong results based
on a certain time of day or a random value. Perhaps more impor-
tantly, we were able to easily extend our system as we discovered
new properties that we wished IFT to handle — we did so over
the course of our own usage and also between batches of malware
analysis in the experiments.

1100In response to Red Team apps, we added new permissions (like
RANDOM and READ_TIME), inference, intents, reﬂection, parameter-
ized permissions, and more.

Effectiveness of CONDITIONAL. Initially, the Red Teams used
location data, time of the day, or random numbers to trigger mal-
ware. They stopped because IFT warnings made it quite easy to
detect those triggers. None of the Red Teams’ apps used implicit
information ﬂow maliciously — we do not know if this was because
it was too hard for them or if they did not consider this attack vector.
3.5 Threats to validity

IFT’s success in the experiments shows promise for our approach.
Nonetheless, we highlight a few of the most important threats to
validity in this section.

Characteristics of malware. The malware we analyzed was
created by ﬁve different Red Teams, each consisting of multiple
engineers working full-time on the task of creating malware. The
teams had previously surveyed real malware, and they created mal-
ware representative both of commercial malware that makes a proﬁt
and of advanced persistent threats who aim to steal information.
Nonetheless, we have no assurance that this malware was represen-
tative of malware in the wild, either in terms of types of malware or
its quality. It is also possible that IFT became tuned to the sort of
malware created by those ﬁve Red Teams.

Skill of the analysts. The same instrument may be more or less
effective depending on who is using it. It is possible that our team
was particularly skilled or lucky in classifying the apps that it an-
alyzed — or that another team would have done a better job. An
analyst needs time to come up to speed on IFT; we have found that
a few weeks is sufﬁcient for an undergraduate working part time,
as conﬁrmed by experiments (Sect. 3.3.3). Training only needs to
occur once, and our team’s unfamiliarity with the apps was a bigger
impediment.

Collaborative app veriﬁcation model. Our model assumes that
application vendors are willing to annotate their source code. We
believe this is true for high-assurance app stores, but our approach
may not be applicable to ordinary app stores.
4. RELATED WORK
4.1 Information ﬂow

Information ﬂow tracking has been investigated for several lan-
guages and paradigms [18, 48, 36, 25, 60]. These approaches are
largely complementary to our work as they are theoretical or do
not employ type systems to achieve static guarantees of informa-
tion ﬂow properties. Besides statically verifying properties, several
approaches for enforcing information ﬂow properties have been pro-
posed, such as refactoring [53], dynamic analysis [39], or encoding
as safety properties [56, 44]. Milanova and Huang [41] recently
presented a system that combines information ﬂow with reference
immutability to improve precision. Yet, the system has not been
applied in a security context. Engelhardt et al. [15] discuss handling
intransitive information-ﬂow policies; IFT makes transitive ﬂows
explicit. Sun et al. [55] discusses modular inference for information
ﬂow; IFT does inference within method bodies.

In the domain of information ﬂow tracking for Java programs, the
closest related work is Jif (Java information ﬂow) [43, 42, 51]. Jif
uses an incompatible extension of the Java programming language
and its own compiler to express and check information ﬂow prop-
erties of a program. In contrast, IFT uses standard Java annotations
and the code can be compiled with the standard Java compiler. Fur-
thermore, IFT achieves its effects with a simpler, easier-to-use type
system. While Jif focuses on the expressiveness and ﬂexibility of the

type system and trust model, IFT aims at practicality and scalability
to be applicable on large real-world Android applications. IFT has
better support for defaults, inference, reﬂection, intents, libraries,
separate compilation, and many other language features. Jif has not
been evaluated in an adversarial challenge exercise comparable to
our experiments using IFT.

In the context of implicit information ﬂow, the classic approach is
to taint all computations within the dynamic scope of a conditional
statement. Suggested by Denning and Denning [11] and formu-
lated as a type system by Volpano et al. [58], this approach causes
over-tainting and suffers from taint explosion. Kang et al. [30] inves-
tigated the problem of under-tainting in benign applications. They
found that under-tainting usually occurs at only a few locations and
proposed an analysis to identify and taint such additional targets.
However, malicious applications are out of scope.

WebSSARI [27] focuses on web applications written in PHP and
aims at preventing vulnerabilities such as Cross-Site Scripting or
SQL Injection. In this context, static analysis is applied to reveal ex-
isting weaknesses and to insert run-time checks. In contrast, IFT stat-
ically veriﬁes information ﬂow properties for Android applications.
4.2 Android malware

Many Android apps are overprivileged, i.e., they are granted more
permissions than they use [4, 16, 57]. These studies also provided
a mapping of API calls to required permissions. IFT utilizes those
existing mappings and enhances the Android permission system by
adding ﬁner-grained sources and sinks for sensitive APIs. Chin et
al. [8] described a weakness of Android Intents: implicitly sent
intents can be intercepted by malicious applications. IFT analyzes
communication through intents to detect such attacks.

The Google Play Store runs Bouncer to detect and reject malicious
applications. Unfortunately, Bouncer can be circumvented [47,
31], which motivates our work. Ongtang et al. [45] suggest an
application-centric security model to strengthen Android’s security.
Woodpecker [21] uses static analysis to detect capability leaks.
ComDroid [8] uses static analysis to locate Intent-related vulnera-
bilities. Several systems have been proposed to detect the leakage
of personal data (e.g., [19, 38]). In this context, PiOS [13] detects
privacy leaks in iOS applications by constructing a control ﬂow
graph from compiled code and performing data ﬂow analysis. Flow-
Droid [3] is a static taint analysis tool for Android apps that that
has not been used to ﬁnd malware. FlowDroid propagates sources
and sinks found using SuSi [50], which uses machine learning to
classify and categorize Android library methods as source and sinks.
Unlike those existing approaches, IFT uses a ﬁner-grained model
for sources and sinks, operates on the source code, and is not limited
to explicit information ﬂow. RiskRanker [22] and DroidRanger [65]
combine multiple analyses in an attempt to detect likely malware.
Beyond detection, dynamic enforcement tools have been pro-
posed to monitor the execution of an application at run time and
intervene, if necessary, to ensure safe behavior [14, 62, 26, 61].
These techniques are non-portable or suffer high overheads. An-
other disadvantage of a dynamic analysis is that it may cause an app
to fail at run time. By contrast, a static analysis such as IFT gives
a guarantee ahead of time, with no run-time overhead, no special
runtime environment, and no risk of failures in the ﬁeld.
4.3 Collaborative model

A similar collaborative veriﬁcation model has been proposed in
prior work on the veriﬁcation of browser extensions. For exam-
ple, Guha et al. [24] describe a model in which browser extension
developers specify a policy; as in our approach, the program’s ad-
herence to the policy is statically veriﬁed, and the reasonableness
of the policy is manually veriﬁed by an auditor. IFT applies the

1101collaborate veriﬁcation approach to Android, with a signiﬁcantly
simpler policy language, easing the auditor’s burden of verifying
the reasonableness of the policy.

Similarly, Lerner et al. [34, 35] extend JavaScript with a type sys-
tem to statically verify that extensions do not violate the browser’s
private browsing mode; their approach requires developers to write
annotations only where code might violate private browsing ex-
pectations.
It also requires a skilled auditor to manually verify
declassiﬁcations. IFT poses a lower annotation and audit burden
and supports a broader range of information ﬂow guarantees.

Our collaborative veriﬁcation model requires a trained auditor to
ensure an app’s description matches the app’s ﬂow policy. Other
work has used crowd-sourcing [1], natural language processing [46],
or clustering [20] to verify that an app’s description matches an app’s
functionality. The functionality is modeled by private information
accessed, permissions requested, or APIs used. These techniques
could be modiﬁed to compare a ﬂow policy to an app’s description,
thereby reducing the auditors effort.

5. CONCLUSIONS

We have described a collaborate veriﬁcation model for high assur-
ance app stores, in which app developers provide annotated source
code whose information ﬂow properties are veriﬁed by the app
store’s auditors. In this model, the application developer and the au-
ditor each do tasks that are easy for them, reducing the overall cost.
We designed IFT, a ﬂow-sensitive, context-sensitive type system
that enables collaborative veriﬁcation of information ﬂow proper-
ties in Android applications. Its design focuses on usability and
practicality, and it supports a rich programming model.

We evaluated IFT by analyzing 72 new applications (57 of them
malicious), which were written by 5 different corporate Red Teams
who were not under our control. IFT detected 96% of the information-
ﬂow-related malware (Sect. 2.10 describes an extension to IFT that
would increase this to 100%) and 82% of all malware. Other ex-
periments show that IFT is easy to use for both programmers and
auditors, making a collaborative veriﬁcation model practical for a
high-assurance app store.

Our system is freely available at http://types.cs.washington.

edu/sparta/, including source code, library API annotations, user
manual, and example annotated applications.

6. ACKNOWLEDGMENTS

We thank Yoshi Kohno, David Wetherall, Andrew Myers, Dylan
McNamee, David Naumann, John Singleton, David Brumley, Zach
Tatlock, and Marcelo d’Amorim for helpful discussions. We thank
the students at UFPE for participating in our learnabilty study.

This material is based on research sponsored by DARPA under
agreement number FA8750-12-2-0107. The U.S. Government is
authorized to reproduce and distribute reprints for Governmental
purposes notwithstanding any copyright notation thereon.

7. REFERENCES
[1] Y. Agarwal and M. Hall. ProtectMyPrivacy: Detecting and

mitigating privacy leaks on iOS devices using crowdsourcing.
In MobiSys, pages 97–110, 2013.

[2] O. Arden, M. D. George, J. Liu, K. Vikram, A. Askarov, and
A. C. Myers. Sharing mobile code securely with information
ﬂow control. In IEEE S&P, 2012.

[3] S. Arzt, S. Rasthofer, C. Fritz, E. Bodden, A. Bartel, J. Klein,
Y. Le Traon, D. Octeau, and P. McDaniel. FlowDroid: Precise
context, ﬂow, ﬁeld, object-sensitive and lifecycle-aware taint
analysis for android apps. In PLDI, pages 259–269, 2014.

[4] K. W. Y. Au, Y. F. Zhou, Z. Huang, and D. Lie. PScout:
Analyzing the Android permission speciﬁcation. In CCS,
pages 217–228, 2012.

[5] A. Banerjee, D. A. Naumann, and S. Rosenberg. Expressive
declassiﬁcation policies and modular static enforcement. In
IEEE S&P, 2008.

[6] C. Bonnington. First instance of iOS app store malware

detected, removed, 2012.
http://www.wired.com/gadgetlab/2012/07/first-
ios-malware-found/.

[7] F. P. Brooks, Jr. The Mythical Man-Month: Essays on

Software Engineering. Addison-Wesley, Boston, MA, USA,
1975.

[8] E. Chin, A. P. Felt, K. Greenwood, and D. Wagner. Analyzing

inter-application communication in Android. In MobiSys,
pages 239–252, 2011.

[9] S. Chong, K. Vikram, and A. C. Myers. SIF: Enforcing

conﬁdentiality and integrity in web applications. In USENIX
Security, 2007.

[10] D. E. Denning. A lattice model of secure information ﬂow.

CACM, 19(5):236–243, 1976.

[11] D. E. Denning and P. J. Denning. Certiﬁcation of programs for

secure information ﬂow. CACM, 20(7):504–513, 1977.

[12] W. Dietl, S. Dietzel, M. D. Ernst, K. Mu¸slu, and T. Schiller.
Building and using pluggable type-checkers. In ICSE, pages
681–690, 2011.

[13] M. Egele, C. Kruegel, E. Kirdaz, and G. Vigna. PiOS:

Detecting privacy leaks in iOS applications. In NDSS, 2011.

[14] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung,

P. McDaniel, and A. N. Sheth. TaintDroid: an
information-ﬂow tracking system for realtime privacy
monitoring on smartphones. In OSDI, 2010.

[15] K. Engelhardt, R. van der Meyden, and C. Zhang. Intransitive

noninterference in nondeterministic systems. In CCS, 2012.

[16] A. P. Felt, E. Chin, S. Hanna, D. Song, and D. Wagner.

Android permissions demystiﬁed. In CCS, pages 627–638,
2011.

[17] A. P. Felt, M. Finifter, E. Chin, S. Hanna, and D. Wagner. A

survey of mobile malware in the wild. In SPSM, 2011.

[18] E. Ferrari, P. Samarati, E. Bertino, and S. Jajodia. Providing

ﬂexibility in information ﬂow control for object-oriented
systems. In IEEE S&P, pages 130–140, 1997.

[19] C. Gibler, J. Crussell, J. Erickson, and H. Chen.

AndroidLeaks: Automatically detecting potential privacy
leaks in Android applications on a large scale. In TRUST,
pages 291–307, 2012.

[20] A. Gorla, I. Tavecchia, F. Gross, and A. Zeller. Checking app
behavior against app descriptions. In ICSE, pages 1025–1035,
2014.

[21] M. Grace, Y. Zhou, Z. Wang, and X. Jiang. Systematic

detection of capability leaks in stock Android smartphones. In
NDSS, 2012.

[22] M. Grace, Y. Zhou, Q. Zhang, S. Zou, and X. Jiang.

RiskRanker: Scalable and accurate zero-day Android malware
detection. In MobiSys, pages 281–294, 2012.

[23] A. Greenberg. iPhone security bug lets innocent-looking apps
go bad. http://www.forbes.com/sites/andygreenberg/
2011/11/07/iphone-security-bug-lets-innocent-
looking-apps-go-bad/, 2011.

[24] A. Guha, M. Fredrikson, B. Livshits, and N. Swamy. Veriﬁed

security for browser extensions. In IEEE S&P, 2011.

1102[25] C. Hammer, J. Krinke, and G. Snelting. Information ﬂow
control for java based on path conditions in dependence
graphs. In ISSSE, pages 87–96, 2006.

[26] P. Hornyack, S. Han, J. Jung, S. Schechter, and D. Wetherall.

These aren’t the droids you’re looking for: Retroﬁtting
Android to protect data from imperious applications. In CCS,
pages 639–652, 2011.

[27] Y.-W. Huang, F. Yu, C. Hang, C.-H. Tsai, D.-T. Lee, and S.-Y.

Kuo. Securing web application code by static analysis and
runtime protection. In WWW, pages 40–52, 2004.

[28] M. Isaac. Android malware found in angry birds add-on apps.

http://www.wired.com/2011/06/android-malware-
angry-birds/, 2011.

[29] C. Jones. The Economics of Software Quality.

Addison-Wesley, 2011.

[30] M. G. Kang, S. McCamant, P. Poosankam, and D. Song.

DTA++: Dynamic taint analysis with targeted control-ﬂow
propagation. In NDSS, 2011.

[31] M. Kassner. Google Play: Android’s Bouncer can be pwned.

http://www.techrepublic.com/blog/it-security/-
google-play-androids-bouncer-can-be-pwned/, 2012.

[32] C. Kitching and L. McVoy. BK2CVS problem.

http://lkml.indiana.edu/hypermail/linux/kernel/
0311.0/0635.html, 2003.

[33] D. Kravets. Android market apps hit with malware.

http://www.wired.com/2011/03/android-malware-2/,
2011.

[34] B. S. Lerner, L. Elberty, N. Poole, and S. Krishnamurthi.

Verifying web browser extensions’ compliance with
private-browsing mode. In ESORICS, 2013.

[35] B. S. Lerner, L. Elberty, N. Poole, and S. Krishnamurthi.

Verifying web browser extensions’ compliance with
private-browsing mode. Technical Report CS-13-02, Brown
University, 2013.

[36] P. Li and S. Zdancewic. Encoding information ﬂow in Haskell.

In CSFW, pages 16–27, 2006.

[37] L. Liu, X. Zhang, G. Yan, and S. Chen. Chrome extensions:

Threat analysis and countermeasures. In NDSS, 2012.

[38] C. Mann and A. Starostin. A framework for static detection of

privacy leaks in Android applications. In SAC, pages
1457–1462, 2012.

[39] W. Masri, A. Podgurski, and D. Leon. Detecting and

debugging insecure information ﬂows. In ISSRE, pages
198–209, 2004.

[40] S. McConnell. Software Estimation: Demystifying the Black

Art. Microsoft Press, 2006.

[41] A. Milanova and W. Huang. Composing polymorphic

information ﬂow systems with reference immutability. In
FTfJP, pages 5:1–5:7, 2013.

[42] A. C. Myers. JFlow: Practical mostly-static information ﬂow

control. In POPL, pages 228–241, 1999.

[43] A. C. Myers, L. Zheng, S. Zdancewic, S. Chong, and

N. Nystrom. Jif: Java + information ﬂow.
http://www.cs.cornell.edu/jif.

[44] D. A. Naumann. From coupling relations to mated invariants

for checking information ﬂow. In ESORICS, 2006.

[45] M. Ongtang, S. McLaughlin, W. Enck, and P. McDaniel.

Semantically rich application-centric security in Android. In
ACSAC, pages 340–349, Dec., 2009.

[46] R. Pandita, X. Xiao, W. Yang, W. Enck, and T. Xie.

WHYPER: Towards automating risk assessment of mobile
applications. In USENIX Security, pages 527–542, 2013.

[47] N. J. Peroco and S. Schulte. Adventures in BouncerLand. In

Black Hat USA, 2012.

[48] F. Pottier and V. Simonet. Information ﬂow inference for ML.

In POPL, pages 319–330, 2002.

[49] F. Rashid. Android malware makes up this week’s dangerous
apps list. https://www.appthority.com/news/android-
malware-makes-up-this-weeks-dangerous-apps-list,
2013.

[50] S. Rasthofer, S. Arzt, and E. Bodden. A machine-learning

approach for classifying and categorizing android sources and
sinks. In NDSS, 2014.

[51] A. Sabelfeld and A. C. Myers. Language-based

information-ﬂow security. J. Sel. Areas in Commun.,
21(1):5–19, 2003.

[52] R. Schouwenberg. Malware in the amazon app store.

https://www.securelist.com/en/blog/208194054/
Malware_in_the_Amazon_App_Store, 2012.

[53] S. Smith and M. Thober. Refactoring programs to secure

information ﬂows. In PLAS, pages 75–84, 2006.

[54] P. Su. Broken Windows theory. http://blogs.msdn.com/
b/philipsu/archive/2006/06/14/631438.aspx, 2006.

[55] Q. Sun, A. Banerjee, and D. A. Naumann. Modular and

constraint-based information ﬂow inference for an
object-oriented language. In SAS, 2004.

[56] T. Terauchi and A. Aiken. Secure information ﬂow as a safety

problem. In SAS, pages 352–367, 2005.

[57] T. Vidas, N. Christin, and L. Cranor. Curbing Android

permission creep. In W2SP, 2011.

[58] D. Volpano, G. Smith, and C. Irvine. A sound type system for

secure ﬂow analysis. Journal of Computer Security,
4(3):167–187, 1996.

[59] T. Wang, K. Lu, L. Lu, S. Chung, and W. Lee. Jekyll on iOS:
When benign apps become evil. In USENIX Security, pages
559–572, 2013.

[60] X. Xiao, N. Tillmann, M. Fähndrich, J. De Halleux, and

M. Moskal. User-aware privacy control via extended
static-information-ﬂow analysis. In ASE, pages 80–89, 2012.
[61] R. Xu, H. Saïdi, and R. Anderson. Aurasium: Practical policy

enforcement for Android applications. In USENIX Security,
2012.

[62] L. K. Yan and H. Yin. DroidScope: Seamlessly reconstructing

the OS and Dalvik semantic views for dynamic Android
malware analysis. In USENIX Security, 2012.

[63] L. Zheng, S. Chong, A. C. Myers, and S. Zdancewic. Using

replication and partitioning to build secure distributed systems.
In IEEE S&P, pages 236–250, 2003.

[64] Y. Zhou and X. Jiang. Dissecting Android malware:
Characterization and evolution. In IEEE S&P, 2012.

[65] Y. Zhou, Z. Wang, W. Zhou, and X. Jiang. Hey, you, get off of

my market: Detecting malicious apps in ofﬁcial and
alternative Android markets. In NDSS, 2012.

1103APPENDIX
A. SUMMARY OF MALICIOUS APPS

Table 5: Applications analyzed by IFT. All listed applications are malicious and were written by 5 independent corporate Red Teams.

Description

LOC Information Flow Violation

IFT

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19

20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36

Adventure Game
Note Taker
SMS Pager
Battery Indicator
Block SMS
Fortune
WiFi Finder
Replacement launcher
2D Game
Displays source code
System Monitoring 2
SMS Encryption
Bible
GPS 1
GPS Logger
Shares Pictures
Cat Pictures
SMS Messenger
Running Log

Countdown Timer
Cookbook
SMS Notiﬁcation
Calculator 2
SMS Backup
Password Protects Apps
System Monitoring 1
Calculator 1
RSS Reader
Text to Morse code
Shares Location
Calculator 4
Device Admin 1
Device Admin 2
DropBox Uploader
System Monitoring 3
Phone silencer

Screen Saver 1
GPS 3
Geocaching
Instant Messenger
App Backup

37
38
39
40
41
42 Mapping
43
44 Word Game
45
46
47

PGP Encryption 1
PGP Encryption 2
Password Saver

SIP VoIP Phone

17,896
3,251
1,834
4,214
2,087
2,998
852
1,069
33,017
242
9,530
27,764
19,775
720
6,907
135
639
1,210
1,333

1,065
2,542
9,678
640
293
11,743
9,402
510
3,503
263
248
482
1,474
1,700
5,902
3,334
1,415

147
1,512
27,892
1,253
2,010
5,587
1,480
1,191
9,904
9,945
508

Information ﬂow violations involving only Android permissions (Sect. 3.1.2)
READ_EXTERNAL_STORAGE→WRITE_EXTERNAL_STORAGE
CAPTURE_AUDIO_OUTPUT→INTERNET
READ_SMS→INTERNET
READ_EXTERNAL_STORAGE→INTERNET
RECEIVE_SMS→INTERNET
READ_PHONE_STATE→INTERNET
ACCESS_FINE_LOCATION→INTERNET
READ_PHONE_STATE→WRITE_EXTERNAL_STORAGE
READ_EXTERNAL_STORAGE→INTERNET
READ_PHONE_STATE→INTERNET
ACCESS_FINE_LOCATION→WRITE_EXTERNAL_STORAGE
READ_SMS→SEND_SMS
INTERNET→WRITE_EXTERNAL_STORAGE
READ_PHONE_STATE→INTERNET
ACCESS_FINE_LOCATION→INTERNET
READ_EXTERNAL_STORAGE→INTERNET
READ_EXTERNAL_STORAGE→INTERNET
READ_SMS→WRITE_SMS
READ_PHONE_STATE→NFC
Information ﬂow violations involving IFT’s additional permissions (Sect. 3.1.3)
RECEIVE_SMS→CONDITIONAL
LITERAL→WRITE_CONTACTS
READ_SMS→WRITE_LOGS
USER_INPUT→FILESYSTEM
READ_EXTERNAL_STORAGE→WRITE_LOG
RANDOM→MODIFY_PHONE_STATE
LITERAL→WRITE_SETTINGS
RANDOM→DISPLAY
RANDOM→VIBRATE
USER_INPUT→FILESYSTEM
ACCESS_FINE_LOCATION→PROCESS_BUILDER
RANDOM→DISPLAY
ACCESS_FINE_LOCATION→INTENT
FILESYSTEM→INTERNET
DISPLAY→INTERNET
RECEIVE_SMS→CONDITIONAL
LITERAL→MODIFY_PHONE_STATE
Information ﬂow violations involving parameterized permissions (Sect. 3.1.4)
LITERAL("")→WRITE_EXTERNAL_STORAGE
LOCATION→INTERNET("maps.google-cc.com")
NFC("*")→INTERNET
LITERAL("0xFFFF")→INTERNET
LITERAL→WRITE_EXTERNAL_STORAGE("*")
LOCATION→INTERNET("mapxplore.com")
USER_INPUT →USE_SIP("2233520413@sip2sip.info")
LITERAL →SEND_SMS("12025551212")
USER_INPUT("EditText.passPhrase")→EMAIL
USER_INPUT("EditText.message")→EMAIL
USER_INPUT("EditText.createPassword")→SHARED_PREFERENCES
Malware not related to information ﬂow (Sect. 3.1.5)

(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
∗
∗

Podcast Player
Screen Saver 2
To Do List
Sudoku
Expense reports
Automatic SMS replies
Screen Saver 3
Backup
SMS Reminders
Game 3

48
49
50
51
52
53
54
55
56
57
(cid:88) The malicious ﬂows or permissions in these apps were found using IFT.
∗ These malicious ﬂows will be caught by IFT after future work is complete. See Sect. 2.10.

none — Battery DoS
none — Battery DoS
none — Battery DoS
none — Battery DoS
none — Performance DoS
none — Performance DoS
none — Performance DoS
none — Data corruption
none — Data corruption
none — Clickjacking

1,711
419
5,123
1,505
2,293
33,296
457
2,554
2,917
1,211

1104