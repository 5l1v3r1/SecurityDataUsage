Towards Network-level Efﬁciency for

Cloud Storage Services

Zhenhua Li

Tsinghua University
Peking University

lizhenhua1983@tsinghua.edu.cn

Christo Wilson

Northeastern University

Boston, MA, US
cbw@ccs.neu.edu

Yunhao Liu

Tsinghua University

Beijing, China

yunhao@tsinghua.edu.cn

Cheng Jin

University of Minnesota

Twin Cities

cheng@cs.umn.edu

Yao Liu

State University of New York

Binghamton University

yaoliu@cs.binghamton.edu

Yafei Dai

Peking University

Beijing, China
dyf@pku.edu.cn

Tianyin Xu

University of California

San Diego

tixu@cs.ucsd.edu
Linsong Cheng
Tsinghua University

Beijing, China

chengls10@mails.tsinghua.edu.cn

Zhi-Li Zhang

University of Minnesota

Twin Cities

zhzhang@cs.umn.edu

ABSTRACT
Cloud storage services such as Dropbox, Google Drive, and Mi-
crosoft OneDrive provide users with a convenient and reliable way
to store and share data from anywhere, on any device, and at any
time. The cornerstone of these services is the data synchronization
(sync) operation which automatically maps the changes in users’
local ﬁlesystems to the cloud via a series of network communica-
tions in a timely manner. If not designed properly, however, the
tremendous amount of data sync trafﬁc can potentially cause (ﬁ-
nancial) pains to both service providers and users.

This paper addresses a simple yet critical question: Is the cur-
rent data sync trafﬁc of cloud storage services efﬁciently used?
We ﬁrst deﬁne a novel metric named TUE to quantify the Trafﬁc
Usage Efﬁciency of data synchronization. Based on both real-world
traces and comprehensive experiments, we study and characterize
the TUE of six widely used cloud storage services. Our results
demonstrate that a considerable portion of the data sync trafﬁc is
in a sense wasteful, and can be effectively avoided or signiﬁcant-
ly reduced via carefully designed data sync mechanisms. All in
all, our study of TUE of cloud storage services not only provides
guidance for service providers to develop more efﬁcient, trafﬁc-
economic services, but also helps users pick appropriate services
that best ﬁt their needs and budgets.

Categories and Subject Descriptors
C.2.4 [Computer-communication Networks]: Distributed Sys-
tems—Distributed applications; D.4.3 [Operating Systems]: File
Systems Management—Distributed ﬁle systems

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
IMC’14, November 5–7, 2014, Vancouver, BC, Canada.
Copyright 2014 ACM 978-1-4503-3213-2/14/11 ...$15.00.
http://dx.doi.org/10.1145/2663716.2663747.

General Terms
Design, Experimentation, Measurement, Performance

Keywords
Cloud storage service; network-level efﬁciency; data synchroniza-
tion; trafﬁc usage efﬁciency

1.

INTRODUCTION

Cloud storage services such as Dropbox, Google Drive, and Mi-
crosoft OneDrive (renamed from SkyDrive since Feb. 2014) pro-
vide users with a convenient and reliable way to store and share
data from anywhere, on any device, and at any time. The users’ da-
ta (e.g., documents, photos, and music) stored in cloud storage are
automatically synchronized across all the designated devices (e.g.,
PCs, tablets, and smartphones) connected to the cloud in a timely
manner. With multiplicity of devices – especially mobile devices
– that users possess today, such “anywhere, anytime” features sig-
niﬁcantly simplify data management and consistency maintenance,
and thus provide an ideal tool for data sharing and collaboration.

In a few short years, cloud storage services have reached phe-
nomenal levels of success, with the user base growing rapidly. For
example, Microsoft OneDrive claims that over 200 million cus-
tomers have stored more than 14 PB of data using their service [9],
while Dropbox has claimed more than 100 million users who store
or update 1 billion ﬁles every day [6]. Despite the late entry into
this market (in Apr. 2012), Google Drive obtained 10 million users
just in its ﬁrst two months [7].

The key operation of cloud storage services is data synchroniza-
tion (sync) which automatically maps the changes in users’ local
ﬁlesystems to the cloud via a series of network communications.
Figure 1 demonstrates the general data sync principle. In a cloud
storage service, the user usually needs to assign a designated lo-
cal folder (called a “sync folder”) in which every ﬁle operation is
noticed and synchronized to the cloud by the client software de-
veloped by the service provider. Synchronizing a ﬁle involves a
sequence of data sync events, such as transferring the data index,
data content, sync notiﬁcation, sync status/statistics, and sync ac-
knowledgement. Naturally, each data sync event incurs network
trafﬁc. In this paper, this trafﬁc is referred to as data sync trafﬁc.

115To answer the question thoroughly, we ﬁrst deﬁne a novel metric
named TUE to quantify the Trafﬁc Usage Efﬁciency of data syn-
chronization. Borrowing a term similar to PUE (i.e., the Power Us-
age Effectiveness = Total facility power
IT equipment power [14], a widely adopted metric
for evaluating the cloud computing energy efﬁciency), we deﬁne

TUE =

Total data sync trafﬁc

Data update size

.

(1)

When a ﬁle is updated (e.g., created, modiﬁed, or deleted) at the us-
er side, the data update size denotes the size of altered bits relative
to the cloud-stored ﬁle 2. From the users’ point of view, the data up-
date size is an intuitive and natural signiﬁer about how much trafﬁc
should be consumed. Compared with the absolute value of sync
trafﬁc (used in previous studies), TUE better reveals the essential
trafﬁc harnessing capability of cloud storage services.

In order to gain a practical and in-depth understanding of TUE,
we collect a real-world user trace and conduct comprehensive bench-
mark experiments of six widely used cloud storage services, in-
cluding Google Drive, OneDrive, Dropbox, Box, Ubuntu One, and
SugarSync. We examine key impact factors and design choices that
are common across all of these services. Impact factors include ﬁle
size, ﬁle operation, data update size, network environment, hard-
ware conﬁguration, access method, and so on. Here the “access
method” refers to PC client software, web browsers, and mobile
apps. Design choices (of data sync mechanisms) include data sync
granularity, data compression level, data deduplication granularity,
and sync deferment (for improved batching).

By analyzing these factors and choices, we are able to thoroughly
unravel the TUE related characteristics, design tradeoffs, and opti-
mization opportunities of these state-of-the-art cloud storage ser-
vices. The major ﬁndings in this paper and their implications are
summarized as follows:

• The majority (77%) of ﬁles in our collected trace are smal-
l in size (less than 100 KB). Nearly two-thirds (66%) of
these small ﬁles can be logically combined into larger ﬁles
for batched data sync (BDS) in order to reduce sync trafﬁc.
However, only Dropbox and Ubuntu One have partially im-
plemented BDS so far.

• The majority (84%) of ﬁles are modiﬁed by users at least
once. Unfortunately, most of today’s cloud storage services
are built on top of RESTful infrastructure (e.g., Amazon S3,
Microsoft Azure, and OpenStack Swift) that typically only
support data access operations at the full-ﬁle level [26, 17].
For these services, enabling the efﬁcient incremental data
sync (IDS) mechanism requires an extra mid-layer for trans-
forming MODIFY into GET + PUT + DELETE ﬁle operations.
Given that ﬁle modiﬁcations frequently happen, implement-
ing IDS is worthwhile for improved network-level efﬁciency.
• 52% of ﬁles can be effectively compressed and 18% of ﬁles
can be deduplicated. Nevertheless, Google Drive, OneDrive,
Box, and SugarSync never compress or deduplicate data. Even
for Dropbox and Ubuntu One, the effect of compression and
deduplication is largely inﬂuenced by the access method.

• Implementing compression and block-level deduplication to-
gether is technically challenging. Based on our trace analy-
sis, we suggest providers to implement compression and full-
ﬁle deduplication because the combination of these two tech-
niques is sufﬁcient to provide efﬁcient usage of sync trafﬁc.
2If data compression is utilized by the cloud storage service, the
data update size denotes the compressed size of altered bits.

Figure 1: Data synchronization principle.

If not designed properly, the amount of data sync trafﬁc can
potentially cause (ﬁnancial) pains to both providers and users of
cloud storage services. From the providers’ perspective, the aggre-
gate sync trafﬁc from all users is enormous (given the huge number
of ﬁles uploaded and modiﬁed each day!). This imposes a heavy
burden in terms of infrastructure support and monetary costs (e.g.,
as payments to ISPs or cloud infrastructure providers). To get a
quantitative understanding, we analyze a recent large-scale Drop-
box trace [12] collected at the ISP level [25]. The analysis reveals:
(1) The sync trafﬁc contributes to more than 90% of the total ser-
vice trafﬁc. Note that the total service trafﬁc is equivalent to one
third of the trafﬁc consumed by YouTube [25]; (2) Data synchro-
nization of a ﬁle (sometimes a batch of ﬁles) generates 2.8 MB of
inbound (client to cloud) trafﬁc and 5.18 MB of outbound (cloud
to client) trafﬁc on average. According to the Amazon S3 pricing
policy [1] (Dropbox stores all the data content in S3 and S3 only
charges for outbound trafﬁc), the Dropbox trafﬁc would consume
nearly $0.05/GB × 5.18 MB × 1 billion = $260,000 every day1.
These costs grow even further when we consider that all cloud stor-
age service providers must bear similar costs, not just Dropbox [4].
Data sync trafﬁc can also bring considerable (and unexpected) ﬁ-
nancial costs to end users, despite that basic cloud storage services
are generally free. News media has reported about user complaints
of unexpected, additional charges from ISPs, typically from mobile
users with limited data usage caps [8, 2]. As a consequence, some
users have warned: “Keep a close eye on your data usage if you
have a mobile cloud storage app.” In addition, some cloud stor-
age applications (e.g., large data backup [3]) are also impaired by
the bandwidth constraints between the user clients and the cloud.
This limitation is regarded as the “dirty secrets” of cloud storage
services [5]. Hence users likewise would also beneﬁt from more
efﬁcient sync trafﬁc usage.

This paper addresses a simple yet critical question: Is the current
data sync trafﬁc of cloud storage services efﬁciently used? Our goal
is to quantify and optimize the efﬁciency of data sync trafﬁc usage,
i.e., the pivotal network-level efﬁciency for cloud storage services.
Without impairing user experience, providers would like to limit
data sync trafﬁc as much as possible to reduce operational costs. On
the other side, users also desire more efﬁcient trafﬁc usage, which
can save money and result in better quality of experience. Although
several studies have measured cloud storage services [30, 33, 25,
20, 24, 36, 32, 48], none have addressed the issue of sync trafﬁc
efﬁciency using real-world, large-scale data from multiple cloud
storage services.

1We assume that there is no special pricing contract between Drop-
box and Amazon S3, so our calculation of the trafﬁc costs may
involve potential overestimation.

ClientUserData Sync Event(data index, data content, sync notification, ...)File Operation(file creation, file deletion,file modification, ...)Cloud116• Frequent modiﬁcations to a ﬁle often lead to large TUE. For
instance, for 8.5% of Dropbox users, more than 10% of their
sync trafﬁc is caused by frequent modiﬁcations [36]. Some
services deal with this issue by batching ﬁle updates using
a ﬁxed sync deferment. However, ﬁxed sync deferments are
inefﬁcient in some scenarios. We propose an adaptive sync
defer (ASD) mechanism to overcome this limitation.

• In the presence of frequent ﬁle modiﬁcations, surprisingly,
users with relatively “poor” hardware or Internet access save
on sync trafﬁc, because their ﬁle updates are naturally batched.

In a nutshell, our research ﬁndings demonstrate that for today’s
cloud storage services, a considerable portion of the data sync traf-
ﬁc is in a sense wasteful, and can be effectively avoided or signif-
icantly reduced through carefully designed data sync mechanisms.
In other words, there is plenty of space for optimizing the network-
level efﬁciency of these services. Our study of TUE provides guid-
ance in two folds: (1) help service providers develop more efﬁcient,
trafﬁc-economic cloud storage services; and (2) help end users se-
lect appropriate services that best ﬁt their needs and budgets.
Roadmap.
In the remainder of the paper, we ﬁrst describe the
common design framework of cloud storage services in § 2, and
then introduce our research methodology in § 3. Next, we present
research results and ﬁndings, broken down logically into three ar-
eas: simple ﬁle operations (§ 4), compression and deduplication
(§ 5), and frequent ﬁle modiﬁcations (§ 6). Finally, we discuss
the tradeoffs for cloud storage system design in § 7, review related
work in § 8, and conclude the paper with future work in § 9.

2. COMMON DESIGN FRAMEWORK OF

CLOUD STORAGE SERVICES

From the perspective of sync trafﬁc usage, the common design
framework of cloud storage services involves a number of impact
factors and design choices, which can be on the client side, serv-
er (cloud) side, or network side. The impact factors refer to those
(objective) factors such as the client location, hardware, ﬁle size,
data update size, network environment, and so on that must be ac-
counted for in the design and usage of cloud storage services. The
design choices (of data sync mechanisms) refer to those (subjec-
tive) design decisions which the system designers make, such as
the data sync granularity, data compression level, data deduplica-
tion granularity, and so forth.

Both the impact factors and design choices may inﬂuence the
data sync TUE. To avoid being trapped by trivial or elusive issues,
we select key impact factors and design choices according to the
following two rules:

• Rule 1: The impact factors should be relatively constant or

stable, so that our research results can be easily repeated.

• Rule 2: The design choices should be measurable and ser-
vice/implementation independent, so as to make our research
methodology widely applicable.

Following Rule 1, we do not study impact factors such as sync
delay3, cloud server location, etc. For example, we observe that
uploading a 1-MB JPEG photo to Google Drive may incur an elu-
sive sync delay varying between several seconds and several min-
utes (under different network environments). Instead, we choose
to study the sync trafﬁc, which is almost invariable in all cases.
3Sync delay measures how long the user client synchronizes a ﬁle
to the cloud.

Table 1: Key impact factors and design choices.
Client location Client hardware

Client side

Access method

File size

File operation

Data update size Data update rate

Data compression level

Sync deferment

Server side

Data sync granularity

Data deduplication granularity

(Data compression level) *

Network side
* Note: The server-side data compression level may be differ-

Sync trafﬁc Bandwidth

Latency

ent from the client-side data compression level.

Besides, we observe that the cloud server location serving a given
ﬁle is not constant. This is because a cloud storage service usual-
ly hosts a user’s ﬁles across multiple geographically dispersed data
centers, and it often migrates or copies a ﬁle from one cloud serv-
er to another. Instead, we record the bandwidth and delay between
the client and the cloud, as they can be reproduced using client-side
methods (introduced in § 3.2).

Following Rule 2, we do not consider design choices such as the
metadata structures, ﬁle segmentation and replication on the cloud
side, because they require speciﬁc knowledge of the back-end cloud
implementation. For example, the metadata structure (including the
list of the user’s ﬁles, their attributes, and indices to where the ﬁles
can be found inside the cloud) cannot be extracted from the net-
work communication packets, because almost all the commercial
cloud storage services have encrypted their application-layer data
in certain (unknown) ways.

In the end, ten key impact factors and four design choices are
selected, as listed in Table 1. Some of them are self-explanatory or
have been explained before. Below we further explain a few:

• File operation includes ﬁle creation, ﬁle deletion, ﬁle modi-

ﬁcation, and frequent ﬁle modiﬁcations.

• Data update rate denotes how often a ﬁle operation happens.
• Sync deferment. When frequent ﬁle modiﬁcations happen,
some cloud storage services intentionally defer the sync pro-
cess for a certain period of time for batching ﬁle updates.

• Data sync granularity. A ﬁle operation is synchronized to
the cloud either in a full-ﬁle granularity or in an incremen-
tal, chunk-level granularity. When the former is adopted, the
whole updated ﬁle is delivered to the cloud; when the lat-
ter is adopted, only those ﬁle chunks that contain altered bits
(relative to the ﬁle stored in the cloud) are delivered.

• Data deduplication granularity denotes the unit at which da-
ta ﬁngerprints are computed and compared to avoid deliver-
ing duplicate data units to the cloud. The unit can be either
a full ﬁle or a ﬁle block. Note that data deduplication can be
performed across different ﬁles owned by different users.

• Bandwidth is deﬁned as the peak upload rate between the
client and the cloud server. We measure it by uploading a
large ﬁle to the cloud and meanwhile recording the network
trafﬁc with the Wireshark network protocol analyzer [18].

• Latency is deﬁned as the round trip time (RT T ) between the
client and the cloud. We measure it by using the standard
Ping command.

117Table 2: Number of users and ﬁles recorded in our collected cloud storage trace.

Google Drive OneDrive Dropbox

Number of users
Number of ﬁles

33

32677

24

17903

55

106493

Box
13

19995

Ubuntu One

SugarSync

13

27281

15

18283

Table 3: File attributes recorded in our collected trace.

User name

File name MD5 Original ﬁle size

Compressed ﬁle size Creation time
Full-ﬁle MD5

Last modiﬁcation time
128 KB/256 KB/512 KB/1 MB/2 MB/4 MB/

8 MB/16 MB block-level MD5 hash codes

Figure 2: CDF (cumulative distribution function) of 1) original
ﬁle size and 2) compressed ﬁle size, corresponding to our col-
lected trace. For original ﬁles, the maximum size is 2.0 GB, the
average size is 962 KB, and the median size is 7.5 KB. For com-
pressed ﬁles, the maximum size is 1.97 GB, the average size is
732 KB, and the median size is 3.2 KB. Clearly, the tracked ﬁles
can be effectively compressed on the whole, and the majority of
them are small in size.

3. METHODOLOGY

This section describes our methodology for studying the TUE
of cloud storage services. First, we introduce a real-world cloud
storage trace collected to characterize the key impact factors. Next,
we design a variety of benchmark experiments to uncover the key
design choices of data sync mechanisms. Last but not the least, we
provide an overview of the research results.
3.1 Real-world Cloud Storage Trace

Our measurement study takes advantage of a real-world user
trace of cloud storage services.
It is collected in several univer-
sities and companies in the US and China from Jul. 2013 to Mar.
2014, including 153 long-term users with 222,632 ﬁles inside their
sync folders. Refer to Table 2 for the per service statistics. This
trace is used to characterize the key impact factors with regard to
the six widely used services. It is also used to guide the design
of benchmark experiments and enable further macro-level analysis
(in particular, the TUE related optimization opportunities of cloud
storage services).

This cloud storage trace records detailed information of every
tracked ﬁle in multiple aspects. Table 3 lists the concrete ﬁle at-
tributes recorded. Figure 2 depicts the distributions of original ﬁle
size and compressed ﬁle size corresponding to the trace. We have
made this trace publicly available to beneﬁt other researchers. It
can be downloaded via the following link:

http://www.greenorbs.org/people/lzh/public/traces.zip

.

3.2 Benchmark Experiments

To obtain an in-depth understanding of TUE and the key design
choices of data sync mechanisms, we design a variety of bench-
marks for performing comprehensive controlled experiments. The
benchmarks span multiple commercial cloud storage services, in-
volving diverse client machines locating at distinct locations and
network environments.
Cloud storage services.
Among today’s dozens of commer-
cial cloud storage services, our research focuses on the following
six mainstream services: Google Drive, OneDrive, Dropbox, Box,
Ubuntu One, and SugarSync, as they are either the most popular
(in terms of user base) or the most representative (in terms of da-
ta sync mechanism). Other cloud storage services are also brieﬂy
discussed when necessary.
Client locations. Since the above cloud storage services are main-
ly deployed in the US, we select two distinct locations to perfor-
m each experiment: MN (i.e., Minnesota, US) and BJ (i.e., Bei-
In a coarse-grained manner, MN represents a lo-
jing, China).
cation close to the cloud:
the bandwidth is nearly 20 Mbps and
the latency ∈ (42, 77) msec, while BJ represents a location re-
mote from the cloud: the bandwidth is nearly 1.6 Mbps the latency
∈ (200, 480) msec.
Controlled bandwidth and latency. To tune the network environ-
ment in a ﬁne-grained manner, we interpose a pair of packet ﬁlters
in the communication channel between the client and the cloud in
MN. These ﬁlters enable ﬁne-grained adjustment of the bandwidth
(the maximum possible speed is 20 Mbps) and latency in either di-
rection. Speciﬁcally, the packet ﬁlters are interposed by using an
intermediate proxy that runs the Linux Netﬁlter/Iptables tool, thus
behaving like a common software ﬁrewall.
Controlled ﬁle operations. We synthetically generate almost
all kinds of ﬁle operations appearing in the literature. Moreover,
these operations are applied upon both compressed and compress-
ible ﬁles. These controlled ﬁle operations will be elaborated in § 4,
§ 5, and § 6.
Client machine hardware. A total of eight client machines are
employed in the experiments: four in MN (i.e., M1, M2, M3, and
M4) and four in BJ (i.e., B1, B2, B3, and B4). Their detailed hard-
ware information is listed in Table 4. M1/B1 represents a typical
client machine at the moment, M2/B2 an outdated machine, M3/B3
an advanced machine with SSD storage, and M4/B4 an Android s-
martphone. M1–M3 and B1–B3 are installed with Windows 7-SP1
and the Chrome-30.0 web browser.
Benchmark software and access methods.
For each cloud s-
torage service, all the experiments regarding M1–M3 and B1–B3
are performed with the latest version (as of Jan. 2014) of the client
software on Windows 7. For the M4 and B4 smartphones, we ex-
periment with the latest-version Android apps (as of Jan. 2014).
The corresponding sync trafﬁc (i.e., incoming/outgoing packets)
are recorded using Wireshark. For the Android smartphones, we
route the network trafﬁc through a PC that promiscuously monitors
the packets using Wireshark.

 0.82 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 1 0 20 40 60 80 100CDFFile Size (MB)CompressedOriginal118Table 4: Hardware information of the experimental client machines.

CPU

Machine
M1 @ MN Quad-core Intel i5 @ 1.70 GHz
M2 @ MN Intel Atom @ 1.00 GHz
M3 @ MN Quad-core Intel i7 @ 1.90 GHz
M4 @ MN Dual-core ARM @ 1.50 GHz
B1 @ BJ
B2 @ BJ
B3 @ BJ
B4 @ BJ

Quad-core Intel i5 @ 1.70 GHz
Intel Atom @ 1.00 GHz
Quad-core Intel i7 @ 1.90 GHz
Dual-core ARM @ 1.53 GHz

Memory Disk Storage
4 GB
1 GB
4 GB
1 GB
4 GB
1 GB
4 GB
1 GB

7200 RPM, 500 GB
5400 RPM, 320 GB
SSD, 250 GB
MicroSD, 16 GB
7200 RPM, 500 GB
5400 RPM, 250 GB
SSD, 250 GB
MicroSD, 16 GB

Table 5: Our major ﬁndings, their implications, and locations of relevant sections.

Simple File Operations

Implications

Section 4.1 (File creation): The majority (77%) of ﬁles in our trace
are small in size (<100 KB), which may result in poor TUE.

Section 4.2 (File deletion): Deletion of a ﬁle usually incurs negli-
gible sync trafﬁc.

Section 4.3 (File modiﬁcation): The majority (84%) of ﬁles are
modiﬁed by users at least once. Most cloud storage services em-
ploy full-ﬁle sync, while Dropbox and SugarSync utilize incremen-
tal data sync (IDS) to save trafﬁc for PC clients (but not for mobile
or web-based access methods).

Compression and Deduplication

Section 5.1 (Data compression): 52% of ﬁles can be effectively
compressed. However, Google Drive, OneDrive, Box, and Sug-
arSync never compress data, while Dropbox is the only one that
compresses data for every access method.
Section 5.2 (Data deduplication): Although we observe that 18%
of ﬁles can be deduplicated, most cloud storage services do not
support data deduplication, especially for the web-based access
method.

Frequent File Modiﬁcations

Section 6.1 (Sync deferment): Frequent modiﬁcations to a ﬁle of-
ten lead to large TUE. Some services deal with this issue by batch-
ing ﬁle updates using a ﬁxed sync deferment. However, we ﬁnd
that ﬁxed sync deferments are inefﬁcient in some scenarios.
Section 6.2 (Network and hardware): Suprisingly, we observe that
users with relatively low bandwidth, high latency, or slow hardware
save on sync trafﬁc, because their ﬁle updates are naturally batched
together.

3.3 Overview of Our Major Findings

Based on the above methodology, we are able to thoroughly un-
ravel the TUE relevant characteristics, design tradeoffs, and op-
timization opportunities of the six mainstream cloud storage ser-
vices. The detailed research results (from simple to complex) will
be presented in the following three sections: simple ﬁle operations
(§ 4), compression and deduplication (§ 5), and frequent ﬁle modiﬁ-
cations (§ 6). As an overview and a roadmap of our research results,
Table 5 summarizes the major ﬁndings and their implications.

4. SIMPLE FILE OPERATIONS

This section presents our major measurement results, ﬁndings,
and implications on the TUE of simple ﬁle operations. For each
measurement, we ﬁrst introduce the experiment process and result-

For providers, nearly two thirds (66%) of small ﬁles can be logical-
ly combined into larger ﬁles for batched data sync (BDS). Howev-
er, only Dropbox and Ubuntu One have partially implemented BDS
so far.

For users, no need to worry about the trafﬁc for ﬁle deletion.
Most of today’s cloud storage services are built on top of RESTful
infrastructure (e.g., Amazon S3, Microsoft Azure, and OpenStack
Swift) that only support data access operations at the full-ﬁle lev-
el. TUE can be signiﬁcantly improved by implementing IDS with
an extra mid-layer that transforms MODIFY into GET + PUT +
DELETE ﬁle operations.

Implications

For providers, data compression is able to reduce 24% of the to-
tal sync trafﬁc. For users, PC clients are more likely to support
compression versus mobile or web-based access methods.
For providers, implementing compression and block-level dedupli-
cation together is technically challenging. Based on the trace anal-
ysis, we suggest providers implement compression and full-ﬁle d-
eduplication since the two techniques work together seamlessly.

Implications

For providers, we demonstrate that an adaptive sync defer (ASD)
mechanism that dynamically adjusts the sync deferment is superior
to ﬁxed sync deferment.

For users, in the presence of frequent ﬁle modiﬁcations, today’s
cloud storage services actually bring good news (in terms of TUE)
to those users with relatively “poor” hardware or Internet access.

s, and then unravel several interesting ﬁndings and implications. In
this section, we do not mention the client locations, network envi-
ronments, and hardware conﬁgurations, because the TUE of simple
ﬁle operations is independent to these impact factors.

4.1 File Creation
[Experiment 1] : We ﬁrst study the simple case of creating a high-
ly compressed ﬁle of Z bytes inside the sync folder (we will further
study the data compression in detail in § 5.1). Thereby, calculat-
ing the TUE of ﬁle creation becomes straightforward (i.e., TUE
= Total sync trafﬁc
). According to Figure 2, most compressed ﬁles are
small in size (several KBs), and the maximum compressed ﬁle size
is below 2.0 GB. Therefore, we experiment with

Z ∈ {1, 1 K, 10 K, 100 K, 1 M, 10 M, 100 M, 1 G}.

Z bytes

119Table 6: Sync trafﬁc of a (compressed) ﬁle creation.

Service
Google Drive
OneDrive
Dropbox
Box
Ubuntu One
SugarSync

1 M

Web-based sync trafﬁc (Bytes) Mobile app sync trafﬁc (Bytes)
PC client sync trafﬁc (Bytes)
1 K
10 M
1
1
10 M
9 K
1.06 M 10.6 M 32 K 71 K 1.27 M 11.0 M
10 K 1.13 M 11.2 M 6 K
19 K 20 K 1.14 M 11.4 M 28 K 31 K 1.11 M 11.7 M 29 K 44 K 1.23 M 10.7 M
38 K 40 K 1.28 M 12.5 M 31 K 37 K 1.09 M 10.6 M 18 K 32 K 1.08 M 10.9 M
55 K 47 K 1.10 M 10.6 M 55 K 58 K 1.10 M 10.5 M 16 K 34 K 1.29 M 10.8 M
3 K
2 K
1.11 M 11.2 M 37 K 39 K 1.20 M 11.3 M 20 K 24 K 1.08 M 10.9 M
9 K
19 K 1.17 M 11.4 M 31 K 32 K 1.10 M 10.7 M 31 K 47 K 1.22 M 10.9 M

1 K
7 K

10 M

1 M

1

1 K

1 M

Table 7: Total trafﬁc for synchronizing 100 compressed ﬁle creations. Each ﬁle is 1 KB in size.

Service
Google Drive
OneDrive
Dropbox
Box
Ubuntu One
SugarSync

PC client

Sync trafﬁc

(TUE)

Web-based

Sync trafﬁc

(TUE)

Mobile app

Sync trafﬁc

(TUE)

1.1 MB (11)
1.3 MB (13)
120 KB (1.2)
1.2 MB (12)
140 KB (1.4)
0.9 MB (9)

1.2 MB (12)
2.2 MB (22)
600 KB (6.0)
3.2 MB (32)
500 KB (5.0)
4.0 MB (40)

5.6 MB (56)
1.9 MB (19)
360 KB (3.6)
3.2 MB (32)
2.5 MB (25)
1.5 MB (15)

The second goal of Experiment 1 is to get a quantitative un-
derstanding of the overhead trafﬁc, as TUE heavily depends on
the ratio of the overhead trafﬁc over the total sync trafﬁc. Syn-
chronizing a ﬁle to the cloud always involves a certain amount of
overhead trafﬁc, which arises from TCP/HTTP(S) connection setup
and maintenance, metadata delivery, etc. Speciﬁcally, the overhead
trafﬁc is equal to the total sync trafﬁc excluding the payload trafﬁc
for delivering the ﬁle content, so in Experiment 1,
Overhead trafﬁc ≈ Total sync trafﬁc - Z bytes.

Table 6 lists the results of Experiment 1 regarding the six con-
cerned cloud storage services. We vary the ﬁle size from 1 B to
1 GB, but for brevity only list four typical sizes: 1 B, 1 KB, 1 MB,
and 10 MB. The table records the sync trafﬁc generated by the three
typical service access methods: PC client, web (browser) based,
and mobile app. In general, from Table 6 we have the following
ﬁnding and implication:

• TUE for synchronizing a (compressed) ﬁle creation mainly
depends on the ﬁle size. A small ﬁle results in big TUE up
to 40000, while a big ﬁle incurs small TUE approaching 1.0.
Therefore, for providers, a number of small ﬁles can be log-
ically combined into a moderate-size ﬁle for batched data
sync (BDS) to save trafﬁc, in particular the overhead trafﬁc.

This ﬁnding poses a key question: What is a small size and what
is a moderate size? By plotting the TUE vs. File Size relationship
(for PC clients) in Figure 3, we get an intuitive conclusion that
a moderate size should be at least 100 KB and had better exceed 1
MB, in order to achieve small TUE – at most 1.5 and had better stay
below 1.2. Here we only draw the curve for PC clients since the
corresponding curves for web-based and mobile apps are similar.

As a consequence, small size is regarded as less than 100 KB,
which together with Figure 2 reveals that the majority (77%) of
tracked ﬁles are small in size (meanwhile, 81% in terms of com-
pressed size). More importantly, by analyzing our collected trace,
we ﬁnd that nearly two-thirds (66%) of these small ﬁles can be cre-
ated in batches and thus can effectively beneﬁt from BDS.
[Experiment 1’] : Given that the BDS mechanism can effectively
optimize TUE, a new question comes out: Is BDS adopted by the

Figure 3: TUE vs. Size of the created ﬁle.

six mainstream cloud storage services? To get the answer, we ﬁrst
generate 100 (distinct) highly compressed ﬁles, and then move all
of them into the sync folder in a batch. Each ﬁle is 1 KB in size,
so TUE = Total sync trafﬁc
. If BDS is adopted, the total sync trafﬁc
should be around 100 KB and TUE should be close to 1.0.

100 KB

The results of Experiment 1’ listed in Table 7 reveal that Drop-
box and Ubuntu One have adopted BDS for PC clients. Further, it
is possible that Dropbox has adopted BDS for web-based and mo-
bile access methods, because the corresponding sync trafﬁc (600
KB and 360 KB) is within an order of magnitude of the data up-
date size (100 KB). Also, Ubuntu One may have used BDS in its
web-based data synchronization, since the sync trafﬁc (500 KB)
lies between 600 KB and 360 KB. On the contrary, Google Drive,
OneDrive, Box, and SugarSync have not adopted BDS yet.
4.2 File Deletion
[Experiment 2] : Each ﬁle created in Experiment 1 is deleted
after it is completely synchronized to the cloud, so as to acquire the
sync trafﬁc information of a ﬁle deletion.

The Experiment 2 results indicate that deletion of a ﬁle usual-
ly generates negligible (< 100 KB) sync trafﬁc, regardless of the
cloud storage service, ﬁle size, or access method. The reason is s-
traightforward: when a ﬁle f is deleted in the user’s local sync fold-

 0 10 20 30 40 501K5K10K100K250K0.5M1M10MTUESize of the Created File (Bytes)Google DriveOneDriveDropboxBoxUbuntu OneSugarSync120Figure 4: Sync trafﬁc of a random byte modiﬁcation, corresponding to the three typical service access methods: (a) PC client, (b)
Web-based, and (c) Mobile app. By comparing the three subﬁgures, we discover that only the PC clients of Dropbox and SugarSync
utilize the incremental data sync (IDS) mechanism for improved network-level efﬁciency.

er, the user client just notiﬁes the cloud to change some attributes of
f rather than remove the content of f. In fact, such “fake deletion”
also facilitates users’ data recovery, such as the version rollback of
a ﬁle. Naturally, we get the following implication:

• Cloud storage service users do not need to worry about the

sync trafﬁc when deleting a ﬁle.

4.3 File Modiﬁcation and Sync Granularity
[Experiment 3] : The analysis of our collected cloud storage trace
reveals that the majority (84%) of ﬁles are modiﬁed by users at
least once. That is to say, ﬁle modiﬁcations are frequently made by
cloud storage users. This subsection studies a simple case of ﬁle
modiﬁcation, i.e., modifying a random byte in a compressed ﬁle of
Z bytes inside the sync folder. In this case, TUE = Total sync trafﬁc
.
Similar as § 4.1, we experiment with

Z ∈ {1, 1 K, 10 K, 100 K, 1 M, 10 M, 100 M, 1 G}

1 Byte

and plot the sync trafﬁc of four typical sizes: Z = 1 K, 10 K, 100 K,
and 1 M in Figure 4.

Figure 4 shows that today’s cloud storage services generally u-
tilize two kinds of data sync granularity: 1) full-ﬁle and 2) chunk-
level. Accordingly, their data sync mechanisms are classiﬁed into
full-ﬁle sync and incremental sync as follows:

• Full-ﬁle sync. Google Drive is an example to use the full-
ﬁle sync mechanism. When a random byte is modiﬁed in a
Z-byte compressed ﬁle, the resulting sync trafﬁc is almost
the same as that of creating a new Z-byte compressed ﬁle.
In other words, Google Drive deals with each ﬁle modiﬁ-
cation by simply uploading the full content of the modiﬁed
ﬁle to the cloud and then deleting the old ﬁle. Consequent-
ly, Google Drive is more suitable for hosting media ﬁles
(like photos, music, and videos) which are rarely modiﬁed
by users. The full-ﬁle sync mechanism is also employed
by OneDrive, Box, Ubuntu One, Amazon Cloud Drive, and
some popular cloud storage services in China like Kuaipan,
Kanbox, Baidu CloudDisk, and 115 CloudDisk.

• Incremental sync (or delta sync). Dropbox (PC client) is
an example to use the incremental data sync (IDS) mecha-
nism. When a random byte modiﬁcation happens, the result-
ing sync trafﬁc stays around 50 KB, regardless of the size of
the modiﬁed ﬁle. According to the working principle of the
incremental sync algorithm: rsync [16], once a random byte
is changed in a ﬁle f, in most cases the whole data chunk
that contains this byte must be delivered for synchronizing
f. Therefore, the sync granularity (i.e., the chunk size C)
can be approximately estimated as

C ≈ Total sync trafﬁc − Overhead trafﬁc.

From the Experiment 1 results, we understand that the overhead
trafﬁc of synchronizing a one-byte ﬁle with the Dropbox PC client
is nearly 40 KB. Therefore, the data sync granularity of Dropbox
PC client is estimated as: C ≈ 50 KB −40 KB = 10 KB. This
is further validated by the recommended default chunk size (i.e.,
from 700 B to 16 KB) in the original rsync implementation [15].
Moreover, we ﬁnd that SugarSync, IDriveSync, and 360 CloudDisk
also utilize the IDS mechanism for their PC clients.

On the contrary, as depicted in Figure 4 (b) and 4 (c), web-based
apps and mobile apps for all the six services still use the full-ﬁle
sync mechanism, probably because IDS is hard to implement in
JavaScript (for web-based apps) or due to energy concerns (for mo-
bile apps). Speciﬁcally, JavaScript is the most widely used script
language for the development of web-based apps (including cloud
storage apps). Nevertheless, for security concerns, JavaScript is
unable to directly invoke ﬁle-level system calls/APIs like open,
close, read, write, stat, rsync, and gzip [11]. Instead, JavaScrip-
t can only access users’ local ﬁles in an indirect and constrained
manner, which is of less efﬁciency in terms of implementing IDS.
In summary, we have the following ﬁnding about simple ﬁle

modiﬁcation and the data sync granularity:

• When a ﬁle modiﬁcation is synchronized to the cloud, TUE
is mostly affected by the data sync granularity which varies
signiﬁcantly among different cloud storage services. Most
services simply use full-ﬁle sync, but some services (like
Dropbox and SugarSync) utilize IDS to achieve improved
network-level efﬁciency for PC clients.

Conﬂicts between IDS and RESTful infrastructure. Although
enabling the IDS mechanism can help service providers reduce the
data sync trafﬁc, implementing IDS is not an easy job in practice.
Most of today’s cloud storage services (e.g., OneDrive, Dropbox,
and Ubuntu One) are built on top of RESTful infrastructure (e.g.,
Amazon S3, Microsoft Azure, and OpenStack Swift). For simplify-
ing both the providers’ implementation complexities and the devel-
opers’ programming complexities, RESTful infrastructure typically
only supports data access operations at the full-ﬁle level, like PUT
(upload a new ﬁle), GET (download a whole ﬁle), DELETE (delete
a whole ﬁle), and so forth. Note that the PUT, GET, and DELETE
operations may have aliases in other RESTful infrastructure.

Thus, enabling IDS usually requires an extra mid-layer for trans-
forming MODIFY into GET + PUT + DELETE ﬁle operations in an
efﬁcient manner (like what Dropbox has done [25, 36]) 4. Since ﬁle
modiﬁcations frequently happen, implementing such a mid-layer is
worthwhile for improved network-level efﬁciency.
4An alternative to enable IDS is to store every chunk of a ﬁle as a
separate data object. When a ﬁle is modiﬁed, the modiﬁed chunks
are deleted with the new chunks being stored as new objects; also,
ﬁle metadata has to be updated (as what is used in Cumulus [43]).

 0 0.2 0.4 0.6 0.8 1 1.21K10K100K1MSync Traffic (MB)Size of the Modified File (Bytes)(a) PC clientGoogle DriveOneDriveDropboxBoxUbuntu OneSugarSync 0 0.2 0.4 0.6 0.8 1 1.21K10K100K1MSync Traffic (MB)Size of the Modified File (Bytes)(b) Web-basedGoogle DriveOneDriveDropboxBoxUbuntu OneSugarSync 0 0.2 0.4 0.6 0.8 1 1.21K10K100K1MSync Traffic (MB)Size of the Modified File (Bytes)(c) Mobile appGoogle DriveOneDriveDropboxBoxUbuntu OneSugarSync121Table 8: Sync trafﬁc of a 10-MB text ﬁle creation. UP: The user
uploads the ﬁle to the cloud. DN: The user downloads the ﬁle
from the cloud.

Service

Google Drive
OneDrive
Dropbox
Box
Ubuntu One
SugarSync

Sync trafﬁc (MB)

PC client Web-based Mobile app
UP DN
UP DN
11.3
11.0
11.8
10.8
10.7
12.2
11.2
11.4
5.5
8.1
5.5
6.1
11.1
10.4
11.2
10.6
8.6
5.3
5.6
10.6
11.3
11.5
11.6
11.8

UP DN
10.6
11.7
11.0
11.0
5.5
10.6
11.3
10.5
5.3
10.9
10.4
10.7

5. COMPRESSION AND DEDUPLICATION
In a real-world storage system, compression and deduplication
are the two most commonly used techniques for saving space and
trafﬁc. This section makes a detailed study of cloud storage com-
pression and deduplication, from both the system designers’ and
users’ perspectives.

5.1 Data Compression Level
[Experiment 4] : To study whether data updates are compressed
before they are synchronized to the cloud, we create an X-byte tex-
t ﬁle inside the sync folder. As a small ﬁle is hard to compress,
we experiment with X = 1 M, 10 M, 100 M, and 1 G. Each tex-
t ﬁle is ﬁlled with random English words. If data compression is
actually used, the resulting sync trafﬁc should be much less than
the original ﬁle size. Furthermore, after each text ﬁle is complete-
ly synchronized, we download it from the cloud with a PC client,
a web browser, and a mobile app, respectively, so as to examine
whether the cloud delivers data updates in a compressed form.

As a typical case, the Experiment 4 results corresponding to
a 10-MB text ﬁle are listed in Table 8. First, in the ﬁle upload
(UP) phase, among the six mainstream cloud storage services, on-
ly Dropbox and Ubuntu One compress data with PC clients and
mobile apps. No service ever compresses data with web browser-
s. Further, we observe that the 10-MB text ﬁle can be compressed
to nearly 4.5 MB using the highest-level WinZip compression on
our desktop. Thus, for Dropbox and Ubuntu One, the compression
level with PC clients seems moderate, while the compression level
with mobile apps is quite low. The motivation of such a difference
is intuitive: to reduce the battery consumption of mobile devices
caused by the computation-intensive data compressions.

Next, in the ﬁle download (DN) phase, only Dropbox and Ubun-
tu One compress data with PC clients and web browsers, and the
compression level is higher than that in the ﬁle upload phase. For
mobile apps, only Dropbox compresses data.

By analyzing our collected cloud storage trace, we ﬁnd that 52%
of ﬁles can be effectively compressed. Here “effectively compressed”
implies that Compressed ﬁle size
Original ﬁle size < 90% when the highest-level WinZip
compression is applied. As a result, the total compression ratio
(= Size of data before compression
Size of data after compression ) regarding all the ﬁles recorded in the
trace reaches 1.31. In other words, data compression is able to re-
duce 24% of the data sync trafﬁc (compared with no compression).
These observations lead to the following ﬁndings and implications:
• Data compression provides obvious beneﬁts by reducing the
sync trafﬁc, but is not supported by every cloud storage ser-
vice. Google Drive, OneDrive, Box, and SugarSync never

Algorithm 1 : Iterative Self Duplication Algorithm
1: Set the lower bound: L = 0 bytes, and the upper bound: U = +∞

bytes. Guess a deduplication block size: B1;

2: Step 1:
3:
4:

5: Step 2:
6:

Generate a new compressed ﬁle f1 of B1 bytes;
Upload f1 to the cloud. When f1 is completely synchronized to the

cloud, record the total sync trafﬁc: T r1;

Generate another ﬁle f2 by appending f1 to itself, that is f2 = f1 +

f1 (the so-called “self duplication”);

7:

Upload f2 to the cloud. When f2 is completely synchronized to the

cloud, record the total sync trafﬁc: T r2;

8: Step 3:
9: if T r2 (cid:28) T r1 and T r2 is small (≈ tens of KBs) then
10: B1 is actually the deduplication block size (B);
11:
12: else there are two cases
13:

exit;

case 1: T r2 < 2B1 and T r2 is not small (implying that
B1 > B) then
Set B1 as the upper bound: U ← B1, and decrease the
guessing value of B1: B1 ← L+U
case 2: T r2 > 2B1 (implying that B1 < B) then
Set B1 as the lower bound: L ← B1, and increase the
guessing value of B1: B1 ← L+U

2

14:

15:
16:

;

;

2

17: goto Step 1;

compress data, while Dropbox is the only service that com-
presses data for every access method.

• Web browser typically does not compress a ﬁle when upload-
ing it to the cloud storage, probably also due to the limitation-
s of JavaScript or other web-based script languages (refer to
§ 4.3). Besides, using a mobile app is usually not as efﬁcient
as using a PC client.

5.2 Data Deduplication Granularity
[Experiment 5] : Data deduplication is another potential method
to reduce data sync trafﬁc, with the intuition that users often upload
duplicated ﬁles with similar content. Inferring the deduplication
granularity of a cloud storage service requires some efforts, espe-
cially when the deduplication block size B (bytes) is not a power
of two (i.e., B (cid:54)= 2n, where n is a positive integer) 5. To measure
the deduplication granularity, we design and implement Algorith-
m 1 (named the “Iterative Self Duplication Algorithm”). It infers
the deduplication granularity by iteratively duplicating and upload-
ing one or multiple synthetic ﬁle(s) and meanwhile analyzing the
incurred data sync trafﬁc. It is easy to prove that the iteration pro-
cedure can ﬁnish in O(log(B)) rounds.

First, we study inter-ﬁle data deduplication with respect to an
identical user account. By applying Experiment 5 to the six main-
stream cloud storage services, we ﬁgure out their data deduplica-
tion granularity in Table 9 (the 2nd column). In this table, “Full
ﬁle” (only for Ubuntu One) means that data deduplication only hap-
pens at the full-ﬁle level, “4 MB” (only for Dropbox) indicates that
the deduplication block size B = 4 MB, and “No” shows that there
is no deduplication performed. Note that block-level deduplication
naturally implies full-ﬁle deduplication, but not vice versa.

Second, we study cross-user data deduplication. For each cloud
storage service, we ﬁrst upload a ﬁle f to the cloud, and then
5The deduplication block size B (bytes) is traditionally a power of
two [39], but we still have to thoughtfully consider the exception
when B (cid:54)= 2n .

122Table 9: Data deduplication granularity. We do not list the
web-based case because the web-based ﬁle synchronization typ-
ically does not apply data deduplication.

Service
Google Drive
OneDrive
Dropbox
Box
Ubuntu One
SugarSync

Same user

PC client & Mobile app

Cross users

PC client & Mobile app

No
No
4 MB
No

Full ﬁle

No

No
No
No
No

No

Full ﬁle

Figure 5: Deduplication ratio (cross-user) vs. Block size. Here
the deduplication ratio = Size of data before deduplication
Size of data after deduplication .

use another user account to upload f to the cloud again. In this
case, the sync trafﬁc should be trivial if full-ﬁle deduplication is
performed across users. If the cross-user full-ﬁle deduplication is
conﬁrmed, Experiment 5 is run again to ﬁgure out the accurate
cross-user deduplication granularity; otherwise, we can conclude
that there is no cross-user data deduplication at all. The results are
also shown in Table 9 (the 3rd column). Obviously, only Dropbox
employs a different cross-user data deduplication granularity from
the identical-user case.

From the above measurements, we get the following ﬁndings and

implications:

• A cloud storage service usually adopts the same data dedu-
plication granularity for PC clients and mobile apps, while
the web-based data synchronization typically does not apply
data deduplication.

• By analyzing our collected trace, we ﬁnd that cross-user data
(block) duplication pervasively exists: even the full-ﬁle level
duplication ratio (= Size of duplicate ﬁles
) reaches 18.8%. How-
ever, most cloud storage services do not support cross-user
deduplication (perhaps for privacy and security concerns) or
block-level deduplication at the moment, thus losing consid-
erable opportunities for optimizing TUE.

Size of all ﬁles

Further, we compare the two types of deduplication granularity
to answer a question: Is the block-level deduplication much bet-
ter (i.e., has a much larger deduplication ratio) than the full-ﬁle
deduplication? Since the computation complexity of block-level d-
eduplication is much higher than that of full-ﬁle deduplication, the
answer could help decide whether or not the block-level dedupli-
cation is worthwhile. Note that when referring to the “ﬁle blocks”,
we are dividing ﬁles to blocks in a simple and natural way, that is
to say, by starting from the head of a ﬁle with a ﬁxed block size.
So clearly, we are not dividing ﬁles to blocks in the best possible
manner [19, 39] which is much more complicated and computation
intensive.

As our collected trace contains both the full-ﬁle hash codes and
the block-level (128 KB – 16 MB blocks) hash codes of each tracked
ﬁle (refer to § 3.1, Table 3), we perform the trace-driven simulation
to ﬁgure out the (cross-user) deduplication ratio when each dedupli-
cation granularity is adopted. The simulation results demonstrate
that the block-level deduplication usually exhibits trivial superior-
ity to the full-ﬁle deduplication, as shown in Figure 5. Therefore,
we have the following implication:

• For providers, in terms of deduplication granularity, support-

ing full-ﬁle deduplication is basically sufﬁcient.

Conﬂicts between compression and block-level deduplication.
Although data deduplication can reduce the sync trafﬁc, we notice
that it has a potential performance conﬂict with data compression.
Implementing block-level deduplication and compression together
is technically challenging.

For cloud storage service providers, though storing and deliver-
ing data in its compressed form can effectively save storage space
and sync trafﬁc, it may signiﬁcantly increase the (computation and
I/O) complexity of block-level deduplication. Speciﬁcally, after a
ﬁle (f) is delivered to the cloud storage in its compressed form (f(cid:48)),
f(cid:48) must be ﬁrst uncompressed to calculate each block’s ﬁngerprint,
so as to enable block-level deduplication. Then, the uncompressed
ﬁle must be deleted from disk. Furthermore, the above operations
must be re-executed (in part) as long as one block of f is modiﬁed.
It is basically unwise for a service provider to shift these operations
to its user clients, unless the service provider does not care about
user experience.

In this subsection we have known that block-level deduplica-
tion exhibits trivial superiority to full-ﬁle deduplication. Mean-
while, full-ﬁle deduplication is not challenged by data compres-
sion, because full-ﬁle deduplication can be directly performed on
compressed ﬁles. Therefore, we suggest that providers implement
full-ﬁle deduplication and compression since these two techniques
work together seamlessly.

6. FREQUENT FILE MODIFICATIONS

In addition to backing up and retrieving ﬁles, cloud storage ser-
vices are also widely used for collaboration, such as collaborative
document editing, team project building, and database hosting. All
the above mentioned advanced functions involve a special kind of
ﬁle operations: frequent modiﬁcations to a ﬁle.
In § 4 and § 5, we have studied various simple ﬁle operations
that are each performed at once. On the contrary, frequent modiﬁ-
cations imply that a ﬁle is modiﬁed in a frequent and incremental
manner. Thus, they exhibit diverse data update patterns in terms of
data update size and rate. The large-scale trace collected by Dra-
go et al. [12] reveals that for 8.5% of Dropbox users, more than
10% of their sync trafﬁc is caused by frequent modiﬁcations [36].
Further, frequent modiﬁcations may well incur abundant overhead
trafﬁc that far exceeds the amount of useful data update trafﬁc sen-
t by the user client over time, which is referred to as the trafﬁc
overuse problem [36]. Besides, in this section we will elaborate
on client locations, network environments, and hardware conﬁgu-
rations, because the TUE of frequent ﬁle modiﬁcations is largely
inﬂuenced by these factors.
6.1 Sync Deferment
[Experiment 6] : To experiment with frequent ﬁle modiﬁcations,
we append X random kilobytes to an empty ﬁle inside the sync
folder every X seconds, until the total appended bytes reach a cer-
tain size C (typically C = 1 MB). This is denoted as the “X KB/X

 1.1 1.12 1.14 1.16 1.18 1.2 1.22 1.24Deduplication RatioBlock Size128 KB256 KB512 KB1 MB2 MB4 MB8 MB16 MBFull file123Figure 6: TUE of the six cloud storage services in response to controlled frequent ﬁle modiﬁcations. Note that the subﬁgures have
distinct Y-axes, and the (b) OneDrive subﬁgure has a different X-axis.

sec” appending experiment. We use random bytes since they are
difﬁcult to compress, thus preventing ﬁle compression from inﬂu-
encing our measurements of TUE.

Our goal is three folds by doing this experiment: 1) We observe
and understand the sync trafﬁc and TUE in response to frequent
modiﬁcations; 2) We aim to discover whether the cloud storage
service has used the sync deferment in order to avoid or mitigate
the trafﬁc overuse problem; and 3) If the sync deferment is adopted,
we want to measure how long the sync deferment is.

All the experiments in this section are performed using M1 @
MN (refer to Table 4) with 20 Mbps of bandwidth, and the latency
(between M1 and each cloud) is between 42 msec and 77 msec.
In terms of service access method, we only examine the PC client,
because almost all the frequent modiﬁcations are generated from
PC clients in practice 6. Experiments with other benchmarks will
be presented in § 6.2.

First, to investigate the impact of frequent ﬁle modiﬁcations on
TUE, we examine the cases for X ∈ {1, 2,··· , 19, 20}. As depict-
ed in Figure 6, the six mainstream cloud storage services exhibit
diverse and interesting phenomena:

• Frequent modiﬁcations to a ﬁle often lead to large TUE (the
aforementioned “trafﬁc overuse problem”). As for the six
mainstream services, the maximum TUE can reach 260, 51,
144, 75, 32, and 33, respectively.

• We observe (except in the sync defer cases: Figure 6 (a), 6
(b), and 6 (f)) that TUE generally decreases as the modiﬁ-
X ) decreases. The reason is straight-
cation frequency (= 1024
forward: though the total data update size is always C = 1
MB, a lower data update frequency implies fewer data sync
events, and thus the overhead trafﬁc is reduced.

A natural question is: Why are the maximum TUE values of
Google Drive (260), OneDrive (51), Ubuntu One (144), and Box
(75) much larger than those of Dropbox (32) and SugarSync (33)?
The answer can be found from their data sync granularity (refer
to § 4.3): Google Drive, OneDrive, Ubuntu One, and Box employ
full-ﬁle sync, while Dropbox and SugarSync employ block-level

6The UIs (user interfaces) of web browser and mobile apps for
cloud storage services are usually not ﬁt for performing frequent
modiﬁcations to a ﬁle.

incremental sync which signiﬁcantly improves the network-level
trafﬁc efﬁciency.

On the other hand, there do exist a few cases (in Figure 6 (a),
6 (b), and 6 (f)) where TUE is close to 1.0. According to our ob-
servations, (a) Google Drive, (b) OneDrive, and (f) SugarSync deal
with the trafﬁc overuse problem by batching ﬁle updates using a
ﬁxed sync deferment: T seconds (which cannot be re-conﬁgured by
users). Figure 6 (a), 6 (b), and 6 (f) indicate that TGoogleDrive ∈
(3, 5) sec, TSugarSync ∈ (4, 6) sec, and TOneDrive ∈ (10, 11)
sec. Moreover, to ﬁgure out a more accurate value of T , we fur-
ther tune X from integers to ﬂoats. For example, we experiment
with X = 3.1, 3.2, ··· , 4.9 for TGoogleDrive, and then ﬁnd that
TGoogleDrive ≈ 4.2 sec. Similarly, we ﬁnd that TSugarSync ≈ 6
sec and TOneDrive ≈ 10.5 sec.

One may have the following question: Is it possible that the de-
ferred data synchronization of (a) Google Drive, (b) OneDrive, and
(f) SugarSync is triggered by a byte counter or an update counter
rather than the time threshold (T )? In other words, the three con-
cerned services may trigger the data synchronization once the num-
ber of uncommitted bytes or updates exceeds a certain value. This
question can be addressed in two cases:

• Case 1: If the data synchronization is triggered by a byte
counter, the resulting TUE would be close to 1.0 according
to our previous study on the byte-counter based “efﬁcien-
t batched synchronization” (UDS) [36]. This is clearly not
true as illustrated by Figure 6 (a), 6 (b), and 6 (f).

• Case 2: If the data synchronization is triggered by an update
counter, the resulting TUE in Figure 6 (a), 6 (b), and 6 (f)
would linearly decrease as the modiﬁcation period (X sec)
increases. Obviously, this is not true, either.

Therefore, we conclude that the deferred data synchronization is
not triggered by a byte counter or an update counter.

Unfortunately, ﬁxed sync deferments are limited in terms of us-
age scenarios. As shown in Figures 6 (a), 6 (b), and 6 (f), the trafﬁc
overuse problem still occurs when X > T .

To overcome the limitation of ﬁxed sync deferments, we propose
an adaptive sync defer (ASD) mechanism. ASD adaptively tunes
its sync deferment (Ti) to follow the latest (say, the i-th) data up-
date. In other words, when data updates happen more frequently,
Ti gets shorter; when data updates happen less frequently, Ti gets

 0 50 100 150 200 25012345678910TUEX KB/X sec appending(a) Google Drive 0 10 20 30 40 50 5 10 15 20TUEX KB/X sec appending(b) OneDrive 0 20 40 60 80 100 120 14012345678910TUEX KB/X sec appending(c) Ubuntu One 0 10 20 30 40 50 60 70 8012345678910TUEX KB/X sec appending(d) Box 0 5 10 15 20 25 3012345678910TUEX KB/X sec appending(e) Dropbox 0 5 10 15 20 25 30 3512345678910TUEX KB/X sec appending(f) SugarSync124Figure 7: TUE of (a) OneDrive, (b) Box, and (c) Dropbox on handling the “X KB/X sec” appending experiment, in Minnesota (MN)
and Beijing (BJ), respectively.

Figure 8: TUE of Dropbox on handling the (a) “1 KB/sec” appending experiment with variable bandwidths, (b) “1 KB/sec” appending
experiment with variable latencies, and (c) “X KB/X sec” appending experiment with distinct hardware conﬁgurations.

longer. In either case, Ti tends to be slightly longer than the lat-
est inter-update time, so that frequent modiﬁcations can be proper-
ly batched for synchronization (without harming user experience).
Speciﬁcally, Ti can be adapted in such an iterative manner:

Ti = min (

Ti−1

2

+

∆ti
2

+ , Tmax)

(2)

where ∆ti is the inter-update time between the (i-1)-th and the i-th
data updates, and  ∈ (0, 1.0) is a small constant that guarantees
Ti to be slightly longer than ∆ti in a small number of iteration
rounds. Tmax is also a constant representing the upper bound of
Ti, as a too large Ti will harm user experience by bringing about
intolerably long sync delay.

If Google Drive would utilize ASD on handling the “X KB/X
sec” (X > TGoogleDrive) appending experiments, the resulting
TUE will be close to 1.0 rather than the original 260 (X = 5), 100
(X = 6), 83 (X = 7), and so forth. The situation is similar for
OneDrive and SugarSync. More detailed performance evaluation
of ASD can be found in our previous work [37].
6.2 Impact of Network and Hardware

In this subsection, we ﬁrst study the impact of network and hard-

ware on TUE, and then explore why they impact TUE.
[Experiment 7, Network environment] : To study the impact of
network environment (including both bandwidth and latency) on
TUE, we conduct the following two batches of experiments.

The ﬁrst batch of experiments are performed on B1 @ BJ. It
represents a relatively poor network environment: low bandwidth
(nearly 1.6 Mbps) and long latency (between 200 msec and 480 m-
sec) relative to the cloud, because the six mainstream cloud storage
services are mainly deployed in US. After repeating Experiments
1 – 6 in this network environment, we compare the results with
the corresponding results by using M1 @ MN with abundant band-
width (nearly 20 Mbps) and short latency (between 42 msec and 77
msec), which represents a good network environment.

The second batch of experiments are performed by using M1 @
MN with controlled bandwidth (between 1.6 Mbps and 20 Mbp-
s) and latency (between 40 msec and 1000 msec), so that we are

able to get ﬁne-grained results about how the network environment
impacts TUE.

From the two batches of experiments, we mainly get the follow-

ing ﬁndings and implications:

• TUE of a simple ﬁle operation is usually not affected by net-

work environment.

• However, in the case of frequent ﬁle modiﬁcations, a user
client with relatively low bandwidth or long latency can save
more sync trafﬁc.

Speciﬁcally, for the ﬁrst batch of experiments, we plot the TUE
of (a) OneDrive, (b) Box, and (c) Dropbox on handling the “X
KB/X sec” appending experiment in Minnesota and Beijing in Fig-
ure 7 (a), 7 (b), and 7 (c), respectively. The situation of Google
Drive and SugarSync is similar to Figure 7 (a), and the situation
of Ubuntu One looks like Figure 7 (b). In each subﬁgure, the two
curves (“@ MN” vs. “@ BJ”) clearly illustrate that poor network
environment leads to smaller TUE, especially when the modiﬁca-
tion period (X sec) is short (excluding the sync defer cases).

For the second batch of experiments, as a typical example, we
plot the TUE of Dropbox on handling the “1 KB/sec” appending
experiment with variable bandwidths and latencies in Figure 8 (a)
and Figure 8 (b), respectively. In Figure 8 (a), the latency is ﬁxed
to around 50 msec and the bandwidth is tuned from 1.6 Mbps to
20 Mbps. In Figure 8 (b), the bandwidth is ﬁxed to around 20 Mbps
and the latency is tuned from 40 msec to 1000 msec. Obviously,
higher bandwidth or shorter latency leads to larger TUE.
[Experiment 7’, Hardware conﬁguration] : Next, we examine
the impact of hardware conﬁguration on TUE by repeating Experi-
ments 1 – 6 with distinct client machines: M1 (a typical machine),
M2 (an outdated machine), and M3 (an advanced machine). Their
detailed hardware information is listed in Table 4. All the experi-
ments are performed in Minnesota with abundant bandwidth (near-
ly 20 Mbps) and short latency (between 42 msec and 77 msec).

Through the Experiment 7’ results, we observe that TUE of a
simple ﬁle operation generally has no relation with hardware con-

 0 10 20 30 40 50 5 10 15 20TUEX KB/X sec appending(a) OneDrive @ MN@ BJ 0 10 20 30 40 50 60 70 8012345678910TUEX KB/X sec appending(b) Box@ MN@ BJ 0 5 10 15 20 25 3012345678910TUEX KB/X sec appending(c) Dropbox@ MN@ BJ 20 22 24 26 28 30 32 34 36 0 5 10 15 20TUEBandwidth (Mbps)(a)Dropbox 5 10 15 20 25 30 0 200 400 600 800 1000TUELatency (msec)(b)Dropbox 0 5 10 15 20 25 30 35 40 4512345678910TUEX KB/X sec appending(c)Dropbox-MN-M3Dropbox-MN-M1Dropbox-MN-M2125ﬁguration, but TUE of frequent ﬁle modiﬁcations is actually affect-
ed by hardware conﬁguration. As a typical example, in Figure 8
(c) we plot the TUE of Dropbox on handling the “X KB/X sec”
appending experiment with M1, M2, and M3. The three curves
clearly demonstrate that slower hardware incurs less sync trafﬁc.

Why do network environment and hardware conﬁguration im-
pact TUE? To explore the reason why network environment and
hardware conﬁguration impact TUE, we analyze the communica-
tion packets of data synchronization, in particular the TCP data
ﬂows. The analysis reveals that in the presence of frequent modiﬁ-
cations to a ﬁle, the user client does not always synchronize every
ﬁle modiﬁcation to the cloud separately. Instead, the user client
often batches multiple ﬁle modiﬁcations for data synchronization.
Speciﬁcally, a new ﬁle modiﬁcation (or a sequence of new ﬁle mod-
iﬁcations) is synchronized to the cloud when at least the following
two conditions are both satisﬁed:

• Condition 1: The previous ﬁle modiﬁcation (or the previ-
ous batch of ﬁle modiﬁcations) has been completely synchro-
nized to the cloud.

• Condition 2: The client machine has ﬁnished calculating the

latest metatata of the modiﬁed ﬁle.

As to Condition 1, when the network environment is relatively
poor, synchronizing the previous ﬁle modiﬁcation (or the previous
batch of ﬁle modiﬁcations) takes more time, so the client needs to
wait for a longer period of time to synchronize the new ﬁle modi-
ﬁcation. As to Condition 2, when the client runs on top of slower
hardware, calculating the latest metatata (which is computation-
intensive) also requires a longer period of time. Because the failure
of either condition will cause the new ﬁle modiﬁcation (or the se-
quence of new ﬁle modiﬁcations) to be naturally batched, poor net-
work environment or poor hardware increases the probability that
a ﬁle modiﬁcation gets batched, and thereby optimizes the TUE.

Finally, combining all the ﬁndings in this subsection, we get the

following implication:

• In the case of frequent ﬁle modiﬁcations, today’s cloud stor-
age services actually bring good news (in terms of TUE) to
those users with relatively poor hardware or Internet access.

7. DISCUSSION

While this paper mainly focuses on the trafﬁc costs of cloud stor-
age services, we keep in mind that the total costs of running a cloud
storage service also involves the computation costs, storage costs,
operation costs, and so forth. Therefore, we would like to fur-
ther study and understand the trafﬁc usage from an insider’s point
of view. In particular, we want to quantify the tradeoff between
TUE and other system metrics. For example, regarding data sync
granularity, incremental synchronization is a double-edge sword:
It effectively saves trafﬁc and storage compared with full-ﬁle syn-
chronization, but it also puts more computational burden on both
service providers and end users. Likewise, determining the best
data compression level to achieve a good balance between trafﬁc,
storage, and computation deserves further research efforts.

Speciﬁcally, studying the aforementioned system tradeoffs would
require at least the following three-fold information from cloud s-
torage providers:

• The user device composition (i.e., the percentages of PCs,
tablets, and smartphones) is the most important information

required. For PCs, it is generally ﬁne to sacriﬁce computa-
tion, storage, and/or network-level efﬁciency for better ser-
vice quality (e.g., faster synchronization of ﬁle operations).
For example, PC clients usually maintain a local sync fold-
er that stores a copy for almost every synchronized ﬁle at
the cloud side. On the other hand, smartphones are sensitive
to computation cost, storage space, and sometimes network
overhead (in 2G/3G/4G modes). Accordingly, mobile apps
usually maintain a small-size local folder that caches only a
few most recently accessed ﬁles.

• The logical interfaces of the storage infrastructure decides
the implementation difﬁculty and working efﬁciency of ID-
S (incremental data sync) for ﬁle modiﬁcations. The logical
interfaces mainly include the RESTful (full-ﬁle level) inter-
faces, ﬁle-level interfaces, and block-level interfaces. For ex-
ample, Microsoft Azure, Amazon S3, and OpenStack Swift
provide RESTful interfaces, and thus implementing IDS on
top of them is not an easy job. On the contrary, implement-
ing IDS on top of a NFS-based infrastructure (with ﬁle-level
interfaces) is quite straightforward. In addition, as GFS and
HDFS provide seemingly ﬁle-level interfaces based on block-
level infrastructure, the corresponding implementation difﬁ-
culty and working efﬁciency of IDS lie between those with
RESTful and ﬁle-level interfaces. Finally, the logical stor-
age interfaces also impact the working efﬁciency of BDS
(batched data sync) for small ﬁles.

• The physical devices of the storage infrastructure have non-
negligible inﬂuence on the working efﬁciency and imple-
mentation (monetary) costs of a cloud storage service. Obvi-
ously, a single SSD is faster while much more expensive than
a single HDD, but up to now it is still not clear which is the
most cost-effective among an SSD cluster, an HDD cluster, a
hybrid SSD+HDD cluster, or even a tape-based cluster [41].
Moreover, the performance of the ﬁlesystem can affect the
working efﬁciency of a cloud storage service. For instance,
OpenStack Swift works better with XFS than EXT3/EXT4,
as pointed out by the ofﬁcial OpenStack development doc-
ument [13]. In addition, even those seemingly independen-
t infrastructure components may share deep, hidden depen-
dencies that lead to unexpected correlated failures, thus un-
dermining the redundancy efforts and working efﬁciencies of
cloud storage services [46, 47].

We hope cloud storage service providers to release their propri-

etary traces to promote future research in this ﬁeld.

8. RELATED WORK

As cloud storage services are becoming more pervasive and chang-

ing the way people store and share data, a number of research ef-
forts have been made in academia, including the design and im-
plementation of the service infrastructure [22, 43, 44, 31], integra-
tion services with various features and functionalities [29, 28, 23,
42, 36, 35, 34], performance measurement [33, 25, 24, 20, 45], as
well as privacy and security issues [40, 21, 38, 27, 32]. While the
previous work covers the data sync mechanism as one of the key
operations and the resulting trafﬁc usage, none of them tries to un-
derstand the efﬁciency of the trafﬁc usage comprehensively. Due
to the system complexity and implementation difference, one can
hardly form a general and uniﬁed view of the trafﬁc usage efﬁcien-
cy, not to mention the further improvement.

Our work is different from and complementary to previous s-
tudies by quantifying and optimizing trafﬁc usage efﬁciency, the

126pivotal network-level efﬁciency for cloud storage services. Based
on the measurements and analysis of six state-of-the-art cloud stor-
age services, we unravel the key impact factors and design choices
that may signiﬁcantly affect the trafﬁc usage efﬁciency. Most im-
portantly, we provide guidance and implications for both service
providers and end users to economize their sync trafﬁc usage.

Dropbox is one of the earliest and most popular cloud storage
services, and its data sync mechanism has been studied in depth
in [25, 36]. Through an ISP-level large-scale measurement, Dra-
go et al. ﬁrst uncover the performance bottlenecks of Dropbox due
to both the system architecture and the data sync mechanism [25].
They suggest a bundling sync scheme with delayed sync ACK to
improve the sync performance of Dropbox. In addition, Li et al.
identify a pathological issue that may lead to the “trafﬁc overuse
problem” in Dropbox by uploading a large amount of unnecessary
(overhead) trafﬁc [36]. They propose an efﬁcient batched sync al-
gorithm (named UDS) to address this issue. Complementary to
these studies, our results are not limited to Dropbox. Instead, we
unravel the general factors that may signiﬁcantly affect the data
sync trafﬁc. In consequence, our results are more general and appli-
cable for designing network-level efﬁcient cloud storage services,
rather than improving one particular service.

Some measurement studies have partially covered the trafﬁc us-
age of cloud storage services. Hu et al. examine “the good, the bad
and the ugly” of four cloud storage services by comparing their traf-
ﬁc usage, delay time, and CPU usage of uploading new ﬁles [30].
They observe that the sync trafﬁc usage varies substantially with
factors such as ﬁle size, data compressibility, and data duplication
levels. Drago et al. further compare the system capabilities of ﬁve
cloud storage services, and ﬁnd that each service has limitations
with regard to data synchronization [24]. Both of these two studies
conﬁrm the importance of sync trafﬁc usage, and the possibility of
further optimizing the sync trafﬁc usage.

In this paper, we zoom into the problem towards a comprehen-
sive understanding of trafﬁc usage efﬁciency. Different from the
simpliﬁed benchmarks used in the above mentioned studies [36, 30,
24], we consider the diversity of access methods, client locations,
hardware conﬁgurations, and network conditions to match the real-
world usage. Indeed, we discover that these factors lead to different
trafﬁc usage patterns, some of which are even not expected. Last
but not the least, different from previous studies that never consider
mobile usage, one of our focus is the mobile usage of sync trafﬁc –
mobile users are those who mostly suffer from trafﬁc overuse.

9. CONCLUSION AND FUTURE WORK

The tremendous increase in data sync trafﬁc has brought growing
pains to today’s cloud storage services, in terms of both infrastruc-
ture support and monetary costs. Driven by this problem, this paper
quantiﬁes and analyzes the data sync trafﬁc usage efﬁciency (TUE)
of six widely used cloud storage services, using a real-world trace
and comprehensive experiments. Our results and ﬁndings conﬁrm
that much of the data sync trafﬁc is unnecessary and can be avoided
or mitigated by careful design of data sync mechanisms. In other
words, there is enormous space for optimizing the network-level
efﬁciency of existing cloud storage services. We sincerely hope
that our work can inspire the cloud storage designers to enhance
their system and software, and meanwhile guide the users to pick
appropriate services.

In Jun. 2014, Apple Inc. announced its cloud storage service,
iCloud Drive, in its annual WWDC conference.
iCloud Drive is
planned as an important component of iCloud, the popular cloud
service provided by Apple that has amassed over 300 million user-
s. Therefore, in the near future, iCloud Drive may be ranked higher

than several cloud storage services studied in this paper (e.g., Drop-
box and Box). To our knowledge, multiple groups of researchers
(including us) have been anxious to investigate the network-level
efﬁciency of iCloud Drive, in the hopes of harvesting novel and
interesting discoveries. Unfortunately, up to now (Aug. 2014),
the iCloud Drive service is still unavailable to common users [10].
In general, we believe that the network-level efﬁciency of iCloud
Drive would be a promising research topic, as iCloud Drive lives in
a unique and closed ecological system fully operated by Apple.
10. ACKNOWLEDGEMENTS

This work is supported by the High-Tech Research and Devel-
opment Program of China (“863 – China Cloud” Major Program)
under grant SQ2015AAJY1595, the National Basic Research Pro-
gram of China (“973”) under grant 2011CB302305, the China NSF
(Natural Science Foundation) under grants 61232004 and 61471217,
the China Postdoctoral Science Fund under grant 2014M550735,
and the US NSF under grants CNS-1054233, CNS-1017647, CNS-
1017092, CNS-1117536 and CRI-1305237.

We would like to thank our shepherd Theophilus Benson and our
team member He Xiao for the valuable help. We thank every vol-
unteer who contributes their data and makes our research possible.
11. REFERENCES
[1] Amazon S3 pricing policy (Jan. 2014).

http://aws.amazon.com/s3/#pricing.
[2] Bandwidth costs for cloud storage.

http://blog.dshr.org/2012/11/bandwidth-costs-for-cloud-
storage.html.

[3] Bandwidth limitations are a concern with cloud backup.

http://searchdatabackup.techtarget.com/video/Bandwidth-
limitations-are-a-concern-with-cloud-backup.

[4] Cisco Global Cloud Index: Forecast and Methodology,
2012-2017. Trend 3: Remote Data Services and Storage
Access Services Growth.
http://www.cisco.com/en/US/solutions/collateral/ns341/ns525
/ns537/ns705/ns1175/Cloud_Index_White_Paper.html.

[5] Dirty Secrets: 5 Weaknesses of Cloud Storage Gateways.

http://www.nasuni.com/blog/28-
dirty_secrets_5_weaknesses_of_cloud_storage.

[6] Dropbox Is Now The Data Fabric Tying Together Devices

For 100M Registered Users Who Save 1B Files A Day.
http://techcrunch.com/2012/11/13/dropbox-100-million.

[7] Google Drive Now Has 10 Million Users: Available on iOS
and Chrome OS. http://techcrunch.com/2012/06/28/google-
drive-now-has-10-million-users-available-on-ios-and-
chrome-os-ofﬂine-editing-in-docs.

[8] Hidden Costs of Cloud Storage.

http://www.onlineﬁlestorage.com/hidden-costs-of-cloud-
storage-1756.

[9] How fast is SkyDrive (OneDrive) growing?

http://www.liveside.net/2012/10/27/how-fast-is-skydrive-
growing.

[10] iCloud Drive features preview.

http://www.apple.com/ios/ios8/icloud-drive.

[11] JavaScript Tutorials, Refernces, and Documentation.

http://developer.mozilla.org/en-US/docs/Web/javascript.

[12] Large-scale Dropbox trace collected at the ISP level.

http://traces.simpleweb.org/wiki/Dropbox_Traces.

[13] OpenStack Installation Guide for Ubuntu 12.04/14.04 (LTS).

http://docs.openstack.org/icehouse/install-
guide/install/apt/content.

127[14] PUE (Power Usage Effectiveness).

http://en.wikipedia.org/wiki/Power_usage_effectiveness.

[15] A question about the default chunk size of rsync.

http://lists.samba.org/archive/rsync/2001-
November/000595.html.

[16] rsync web site. http://www.samba.org/rsync.
[17] Why RESTful Design for Cloud is Best.

http://www.redhat.com/promo/summit/2010/presentations
/cloud/fri/galder-945-why-
RESTful/RestfulDesignJBWRH2010.pdf.

[18] Wireshark network protocol analyzer.

http://www.wireshark.org.

[19] B. Aggarwal, A. Akella, A. Anand, A. Balachandran,

P. Chitnis, C. Muthukrishnan, R. Ramjee, and G. Varghese.
EndRE: An End-system Redundancy Elimination Service for
Enterprises. In Proc. of NSDI, pages 419–432. USENIX,
2010.

[20] A. Bergen, Y. Coady, and R. McGeer. Client Bandwidth: The

Forgotten Metric of Online Storage Providers. In Proc. of
PacRim, pages 543–548. IEEE, 2011.

[21] A. Bessani, M. Correia, B. Quaresma, F. André, and

P. Sousa. DepSky: Dependable and Secure Storage in a
Cloud-of-clouds. ACM Transactions on Storage (TOS),
9(4):12, 2013.

[22] B. Calder, J. Wang, A. Ogus, N. Nilakantan, A. Skjolsvold,

S. McKelvie, Y. Xu, et al. Windows Azure Storage: A
Highly Available Cloud Storage Service with Strong
Consistency. In Proc. of SOSP, pages 143–157. ACM, 2011.

[23] Y. Chen, K. Srinivasan, G. Goodson, and R. Katz. Design

Implications for Enterprise Storage Systems via
Multi-dimensional Trace Analysis. In Proc. of SOSP, pages
43–56. ACM, 2011.

[24] I. Drago, E. Bocchi, M. Mellia, H. Slatman, and A. Pras.
Benchmarking Personal Cloud Storage. In Proc. of IMC,
pages 205–212. ACM, 2013.

[25] I. Drago, M. Mellia, M.M Munafò, A. Sperotto, R. Sadre,

and A. Pras. Inside Dropbox: Understanding Personal Cloud
Storage Services. In Proc. of IMC, pages 481–494. ACM,
2012.

[26] R.T. Fielding. Architectural Styles and the Design of
Network-based Software Architectures. PhD thesis,
University of California, Irvine, 2000.

[27] S. Halevi, D. Harnik, B. Pinkas, and A. Shulman-Peleg.

Proofs of Ownership in Remote Storage Systems. In Proc. of
CCS, pages 491–500. ACM, 2011.

[28] D. Harnik, R. Kat, D. Sotnikov, A. Traeger, and O. Margalit.

To Zip or Not to Zip: Effective Resource Usage for
Real-Time Compression. In Proc. of FAST, pages 229–242.
USENIX, 2013.

[29] D. Harnik, B. Pinkas, and A. Shulman-Peleg. Side Channels

in Cloud Services: Deduplication in Cloud Storage. IEEE
Security & Privacy, 8(6):40–47, 2010.

[30] W. Hu, T. Yang, and J.N. Matthews. The Good, the Bad and

the Ugly of Consumer Cloud Storage. ACM SIGOPS
Operating Systems Review, 44(3):110–115, 2010.

[31] Y. Huang, Z. Li, G. Liu, and Y. Dai. Cloud Download: Using
Cloud Utilities to Achieve High-quality Content Distribution
for Unpopular Videos. In Proc. of ACM Multimedia, pages
213–222. ACM, 2011.

[32] D. Kholia and P. Wegrzyn. Looking Inside the (Drop) box. In

Proc. of the 7th USENIX Workshop on Offensive
Technologies (WOOT), 2013.

[33] A. Li, X. Yang, S. Kandula, and M. Zhang. CloudCmp:

Comparing Public Cloud Providers. In Proc. of IMC, pages
1–14. ACM, 2010.

[34] Z. Li, Y. Huang, G. Liu, F. Wang, Z.-L. Zhang, and Y. Dai.
Cloud Transcoder: Bridging the Format and Resolution Gap
between Internet Videos and Mobile Devices. In Proc. of
NOSSDAV, pages 33–38. ACM, 2012.

[35] Z. Li and J. Li. Deﬁciency of Scientiﬁc Research behind the

Price War of Cloud Storage Services. Communications of
China Computer Federation (CCCF), 10(8):36–41, 2014.
[36] Z. Li, C. Wilson, Z. Jiang, Y. Liu, B.Y. Zhao, C. Jin, Z.-L.

Zhang, and Y. Dai. Efﬁcient Batched Synchronization in
Dropbox-like Cloud Storage Services. In Proc. of
Middleware, pages 307–327. Springer, 2013.

[37] Z. Li, Z.-L. Zhang, and Y. Dai. Coarse-grained Cloud

Synchronization Mechanism Design May Lead to Severe
Trafﬁc Overuse. Elsevier Journal of Tsinghua Science and
Technology, 18(3):286–297, 2013.

[38] P. Mahajan, S. Setty, S. Lee, A. Clement, L. Alvisi,

M. Dahlin, and M. Walﬁsh. Depot: Cloud Storage with
Minimal Trust. ACM Transactions on Computer Systems
(TOCS), 29(4):12, 2011.

[39] D.T. Meyer and W.J. Bolosky. A Study of Practical

Deduplication. ACM Transactions on Storage (TOS),
7(4):14, 2012.

[40] M. Mulazzani, S. Schrittwieser, M. Leithner, M. Huber, and

E. Weippl. Dark Clouds on the Horizon: Using Cloud
Storage as Attack Vector and Online Slack Space. In Proc. of
USENIX Security, 2011.

[41] V.S. Prakash, X. Zhao, Y. Wen, and W. Shi. Back to the
Future: Using Magnetic Tapes in Cloud Based Storage
Infrastructures. In Proc. of Middleware, pages 328–347.
Springer, 2013.

[42] P. Shilane, M. Huang, G. Wallace, and W. Hsu.

WAN-optimized Replication of Backup Datasets using
Stream-informed Delta Compression. ACM Transactions on
Storage (TOS), 8(4):13, 2012.

[43] M. Vrable, S. Savage, and G.M. Voelker. Cumulus:

Filesystem Backup to the Cloud. ACM Transactions on
Storage (TOS), 5(4):14, 2009.

[44] M. Vrable, S. Savage, and G.M. Voelker. Bluesky: A

Cloud-backed File System for the Enterprise. In Proc. of
FAST. USENIX, 2012.

[45] G. Wallace, F. Douglis, H. Qian, P. Shilane, S. Smaldone,

M. Chamness, and W. Hsu. Characteristics of Backup
Workloads in Production Systems. In Proc. of FAST.
USENIX, 2012.

[46] E. Zhai, R. Chen, D.I. Wolinsky, and B. Ford. An Untold

Story of Redundant Clouds: Making Your Service
Deployment Truly Reliable. In Proc. of HotDep. ACM, 2013.

[47] E. Zhai, R. Chen, D.I. Wolinsky, and B. Ford. Heading Off
Correlated Failures through Independence-as-a-Service. In
Proc. of OSDI. USENIX, 2014.

[48] Y. Zhang, C. Dragga, A. Arpaci-Dusseau, and

R. Arpaci-Dusseau. ViewBox: Integrating Local File
Systems with Cloud Storage Services. In Proc. of FAST,
pages 119–132. USENIX, 2014.

128